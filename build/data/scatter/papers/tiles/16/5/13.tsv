id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
688c8734094c48435b0b7eb3df8d735a341cee64	one-round and authenticated three-party multiple key exchange protocol from parings		Abastract: One round three-party authenticated key exchange protocols are extremely important to secure communications and are now extensively adopted in network communications. These protocols allow users to communicate securely over public networks simply by using easy-to-remember long-term private keys. In 2001, Harn and Lin proposed an authentication key exchange protocol in which two parties generate four shared keys in one round, and three of these keys can provide perfect forward secrecy.This work,which aims to generalize two-party multiple key agreement sets to three-party key agreement sets,presents a three-party multiple key exchange protocol based on bilinear pairing.The proposed protocol does not require server's public key and requires only a single round. Compared with existing protocols, the proposed protocol is more efficient and provide greater security.	authenticated key exchange;authentication;bilinear filtering;communications protocol;computation;cryptographic protocol;diffie–hellman key exchange;forward secrecy;key-agreement protocol;overhead (computing);public-key cryptography;secure channel;secure communication;server (computing)	Feng Liu	2010	IACR Cryptology ePrint Archive		computer network;oakley protocol;authentication;key exchange;computer science	Security	-42.25285684687089	74.91974091973204	62210
3ba18769fb68cb941c2ee6f2e9ad4844939061b8	finding good differential patterns for attacks on sha-1	macquarie university institutional repository;researchonline;digital repository;macquarie university;linear code	In this paper we analyse properties of the message expansion algorithm of SHA-1 and describe a method of finding differential patterns that may be used to attack reduced versions of SHA-1. We show that the problem of finding optimal differential patterns for SHA-1 is equivalent to the problem of finding minimal weight codeword in a large linear code. Finally, we present a number of patterns of different lengths suitable for finding collisions and near-collisions and discuss some bounds on minimal weights of them.	algorithm;code word;differential cryptanalysis;entity–relationship model;linear code;minimum weight;sha-1	Krystian Matusiewicz;Josef Pieprzyk	2004		10.1007/11779360_14	computer science;theoretical computer science;data mining;algorithm	ML	-37.264549069339445	81.38319765385837	62295
bf4804836d64d7644491f663421d8dde551ecba9	a new efficient key agreement scheme for vsat satellite communications based on elliptic curve cryptosystem	satellite communication;authentication;vsat;key agreement;elliptic curve cryptosystem	A satellite communication is suitable for broadcasting service and long-hual transmission based on telecommunications. In the satellite communication environment, unauthorized user should not have to obtain his/her required services from the satellite communication systems without authentication. Therefore, authentication is an important security technique to prevent illegal service requests. Quite recently, Lee-Lin-Hwang [C. C. Lee, T. C. Lin, M. S. Hwang. A key agreement scheme for satellite communications, Information Technology and Control, 2010, Vol. 39, No. 1, 43-47.] proposed a secure scheme based on key agreement scheme with mutual authentication to solve the security problems on the VSAT satellite communications. However, Lee-Lin-Hwang’s scheme is inefficiently designed because it is based on the RSA cryptosystem. Therefore, the scheme cannot be applicable for the low-power satellite communication environments because it involves high communication and computation costs. Based on these motivations, this paper proposes a new efficient and secure key agreement scheme for VSAT satellite communications based on elliptic curve cryptosystem (ECC) to minimize the complexity of computational costs between VSAT and HUB and fit VSAT satellite communication environments. Compared with previous schemes, the newly proposed scheme has the following more practical merits: (1) it provides secure session key agreement function by adopting elliptic curve cryptosystem, (2) it can reduce the total execution time and memory requirement due to the elliptic curve cryptography, and (3) it not only is secure against well-known cryptographical attacks but also provides perfect forward secrecy. As a result, the proposed scheme is extremely suitable for use in satellite communication environments since it provides security, reliability, and efficiency.	authorization;communications satellite;computation;computer security;cryptosystem;elliptic curve cryptography;forward secrecy;key-agreement protocol;local interconnect network;low-power broadcasting;mutual authentication;rsa (cryptosystem);run time (program lifecycle phase);session key	Jeong-Woo Hong;Sang-Yoon Yoon;Dong-In Park;Myung-Jin Choi;Eun-Jun Yoon;Kee-Young Yoo	2011	ITC	10.5755/j01.itc.40.3.634	telecommunications;computer science;authentication;computer security;communications satellite;computer network	Security	-46.07093277011374	74.69926611469104	62351
91ab24919aa6bd918c7ee489c5a975bcf398c2b6	toward separating the strong adaptive pseudo-freeness from the strong rsa assumption		The notion of pseudo-freeness of a group was introduced by Hohenberger, and formalized by Rivest in order to unify cryptographic assumptions. Catalano, Fiore and Warinschi proposed the adaptive pseudo-free group as a generalization of pseudo-free group. They showed that the RSA group (mathbb{Z}_N^times) is pseudo-free even if the adversary against pseudo-freeness is allowed to operate adaptively, provided that the adaptive behavior of the adversary is restricted by some specific parametric distribution. They also proposed the notion of strong adaptive pseudo-freeness in which the adaptive behavior of the adversary is not restricted. However, it remains open whether (mathbb{Z}_N^times) is also strongly-adaptive pseudo-free under the strong RSA (SRSA) assumption.		Masayuki Fukumitsu;Shingo Hasegawa;Shuji Isobe;Eisuke Koizumi;Hiroki Shizuya	2013		10.1007/978-3-642-39059-3_6	discrete mathematics;theoretical computer science;free abelian group;cryptography;parametric statistics;adversary;computer science;adaptive behavior;strong rsa assumption	Vision	-37.965212176693186	76.18086805089264	62697
c4a7a0bf14eb6c4b3aead1e1ced7b45142e75cdf	cryptanalysis of the structure-preserving signature scheme on equivalence classes from asiacrypt 2014	euf cma;uf cma;structure preserving signature;equivalence classes	At Asiacrypt 2014, Hanser and Slamanig presented a new cryptographic primitive called structure-preserving signature scheme on equivalence classes in the message space (G1), where G1 is some additive cyclic group. Based on the signature scheme, they constructed an efficient multi-show attribute-based anonymous credential system that allows to encode an arbitrary number of attributes. The signature scheme was claimed to be existentially unforgeable under the adaptive chosen message attacks in the generic group model. However, for ` = 2, Fuchsbauer pointed out a valid existential forgery can be generated with overwhelming probability by using 4 adaptive chosen-message queries. Hence, the scheme is existentially forgeable under the adaptive chosen message attack at least when ` = 2. In this paper, we show that even for the general case ` ≥ 2, the scheme is existentially forgeable under the non-adaptive chosen message attack and universally forgeable under the adaptive chosen message attack. It is surprising that our attacks will succeed all the time and need fewer queries, which give a better description of the scheme’s security.	asiacrypt;cryptanalysis;cryptographic primitive;cryptography;digital credential;digital signature forgery;encode;forge;generic group model;ibm 1401 symbolic programming system;relational operator;turing completeness;utility functions on indivisible goods	Yanbin Pan	2016		10.1007/978-3-319-29485-8_17	combinatorics;discrete mathematics;mathematics;algorithm	Crypto	-39.337099471767786	76.26296296353004	62763
c5448151d0b2cbab7835bb97515dfd5171edc308	γ-mac[h, p] - a new universal mac scheme	provable security;universal hashing;message authentication code	In this paper, we introduce a new class of universal hash function families called almost regular universal (e−ARU). Informally, an e−ARU hash function family is almost universal, and additionally provides almost regularity. Furthermore, we present $\Gamma\mbox{-MAC}\lbrack \rbrack$, a new MAC scheme based on a e−ARU hash function family. It is the first stateless MAC scheme based on universal hash functions, which requires only one n-bit key. $\Gamma\mbox{-MAC}\lbrack H,P\rbrack$ is provable secure and an alternative to the Wegman-Carter-Shoup (WCS) based MAC scheme, where the security breaks apart in the nonce-reuse scenario [11, 28].#R##N##R##N#In addition, we show that $\Gamma\mbox{-MAC}\lbrack H,P\rbrack$ can be implemented very efficiently in software. For messages longer than one kilobyte, our $\Gamma\mbox{-MAC}\lbrack H,P\rbrack$ implementation is even faster than the optimized AES-128 implementations from Schwabe and Bernstein from the eBash project.		Ewan Fleischmann;Christian Forler;Stefan Lucks	2011		10.1007/978-3-642-34159-5_6	theoretical computer science;mathematics;distributed computing;computer security	Crypto	-38.29272535941036	78.00588992408014	62977
000e56a52af01dae3012dfcea11195c07231afcc	a novel identity authentication technique without trustworthy third-party based on fingerprint verification	homeland security;novel identity authentication;identity based encryption;technology;biometrie;authentication;securite informatique;biometrics;biometria;intelligence artificielle;data communication;interconnection network;computer network;authentification;computer security;empreinte digitale;autenticacion;science technology;computer science interdisciplinary applications;seguridad informatica;fingerprint;artificial intelligence;huella digital;inteligencia artificial;computer science;intelligence;computer science information systems;computer science theory methods;information;public key infrastructure;fingerprint verification	Computer networks have evolved from close local networks to open interconnected networks and the operations from data communication to online transaction. As such, identity authentication is indispensable in today's computing platform. Current identity authentication techniques primarily focus on Public Key Infrastructure (PKI) or Identity Based Encryption (IBE). However, these techniques authenticate users' identity relying on tokens or keys and one or many trustworthy third-party(s) that require databases running online, with multiple points of vulnerability and low efficiency.	authentication;fingerprint;trustworthy computing	Liang Li;Jie Tian;Xin Yang	2006		10.1007/11734628_29	computer science;artificial intelligence;operating system;authentication;database;distributed computing;internet privacy;world wide web;computer security;identity management	Security	-45.115001847889836	77.70608487364701	63020
3c345451fe1cba8fd0165f83f8a7bd7e319450bf	of unicorns and random programs.		We provide a theoretical and practical notion of white-box security for protecting integrity and privacy of software. This notion provides a useful framework to analyze and implement software encryption mechanisms. We relate strength of program encryption to properties of random programs and take a purposefully different view of security than the traditionally cited virtual black-box method of Barek et al. [1]. We pose and answer several questions of interest: what are random programs, do they exist, and how can they be used to evaluate effectiveness of proposed algorithms. Further, a theoretical foundation for program security based on the random oracle model is defined using our definition of random programs.	algorithm;black box;cipher;copy protection;encryption;random graph;random oracle	Alec Yasinsac;Jeffrey Todd McDonald	2005			computer science	Security	-36.121244025178775	75.4094662098577	63119
5d5ca979fa979bba020dc64016f0658d9be80a13	a note on security of public-key cryptosystem provably as secure as subset sum problem	subset sum problem;provable security;attack		cryptosystem;subset sum problem	Shinsuke Hamasho;Yasuyuki Murakami	2014	IEICE Transactions		attack;discrete mathematics;goldwasser–micali cryptosystem;computer science;provable security;distributed computing;subset sum problem;computer security	Crypto	-39.83009326817282	79.63185587237882	63274
82265855b886fb5efafda3c10ba8cc13648b9e45	a new provably secure certificateless short signature scheme	public key cryptography;provable security;short signature;security model;certificateless signature;satisfiability;bilinear map;signature scheme;random oracle model;identity based cryptography;bilinear maps	Certificateless public key cryptography simplifies the complex certificate management in the traditional public key cryptography and resolves the key escrow problem in identity-based cryptography. In 2007, Huang et al. revisited the security models of certificateless signature scheme. They classified adversaries according to their attack power into normal, strong, and super adversaries (ordered by their attack power). Recently, Du and Wen proposed a short certificateless signature scheme and presented that their scheme is secure against the strong adversary in the random oracle model. In this paper, we show that their short signature scheme is insecure against the strong adversary. We then propose a new short certificateless signature scheme which is secure against the super adversary. Our scheme is the first certificateless signature scheme which satisfies both the strongest security level and the shortest signature length.	digital signature;provable security	Kyu Young Choi;Jong Hwan Park;Dong Hoon Lee	2011	Computers & Mathematics with Applications	10.1016/j.camwa.2011.02.003	random oracle;ring signature;computer security model;merkle signature scheme;eddsa;bilinear map;provable security;mathematics;distributed computing;internet privacy;public-key cryptography;blind signature;schnorr signature;computer security;satisfiability	Crypto	-41.67078837981286	75.94406604120324	63702
40b78047987f181b3e9a84316737700d932c8003	new approaches for the design and analysis of cryptographic hash functions	traditional hash design;hash function;provable security;cryptographic hash function;certain use;traditional design approach;disparate security property;security property;new approach;multi-property hash function;cryptographic hash function;hash design	"""Cryptographic hash functions deterministically generate a short digest """"summary"""" of an input message. Their functionality and perceived security properties have contributed to their use in a wide variety of applications. Unfortunately, traditional design approaches for hash functions target only a single application. This gap between use and design has lead to hash functions not providing the security properties required by certain uses, and, in turn, to vulnerabilities in applications.#R##N#This thesis argues for the construction of multi-property hash functions. Such a function should enjoy strong guarantees that it simultaneously provides multiple, disparate security properties, while remaining efficient and easy to use. That is, these hash functions are built to reflect the diverse needs of applications. Towards this end, we introduce the notion of a multi-property-preserving domain extension transform, which formalizes the goal of multi-property hashing for a key step in hash design. By analyzing existing transforms from the lense of multiproperty-preservation, we explain the inability of traditional hash designs to be multi-property. We propose new domain extension transforms, provide new techniques for their formal analysis in modern cryptography's framework of provable security, and use the techniques to show that the proposed constructions provide the multi-property-preservation guarantees needed to build the next generation of hash functions."""	cryptographic hash function	Thomas Ristenpart	2010			security of cryptographic hash functions;double hashing;hash function;sha-2;computer science;theoretical computer science;universal hashing;hash chain;distributed computing;computer security;cryptographic hash function;swifft;hash tree	Theory	-36.15878563933539	75.28520797630281	63910
25aac884719bca81fc8dd53ec0b2f5d308f1942e	compact and flexible resolution of cbt multicast key-distribution	protection information;reseau information;arquitectura red;information technology;key distribution center;technologie information;architecture reseau;group communication;information network;computer network;proteccion informacion;criptografia;cryptography;information protection;reseau informatique;cryptographie;network architecture;routing protocol;tecnologia informacion;red informacion;key distribution	In an open network such as the Internet, multicast security services typically start with group session-key distribution. Considering scalability for group communication among widely-distributed members, we can nd a currently-leading approach based on a CBT (Core-Based Tree) routing protocol, where Group Key Distribution Centers (GKDCs) are dynamically constructed during group-member joining process. In search of practical use of it, this paper rst analyzes the CBT protocol in terms of its e ciency as well as security management. Then the paper proposes several improvements on the protocol with an aim to solve the problem identi ed. In particular, (1) an overuse of encryption and signatures is avoided and (2) a hybrid trust model is introduced by a simple mechanism for controling the GKDC distribution. A comprehensive comparison among the costs of several implementations is also carried out.	antivirus software;core-based trees;encryption;group key;internet;key distribution;multicast;routing;scalability;security management	Kanta Matsuura;Yuliang Zheng;Hideki Imai	1998		10.1007/3-540-64216-1_49	multicast;network architecture;telecommunications;protocol independent multicast;computer science;cryptography;routing protocol;information technology;key distribution;computer security;key distribution center;computer network	Security	-46.832399415035816	78.42822508978479	64437
1915c10b222393ea14aca0dfdebb630347392d5a	generic implementations of elliptic curve cryptography using partial reduction	elliptic curve;elliptic curve cryptography;public key;elliptic curve digital signature algorithm;software implementation;security protocol;modular reduction	Elliptic Curve Cryptography (ECC) is evolving as an attractive alternative to other public-key schemes such as RSA by offering the smallest key size and the highest strength per bit. The importance of ECC has been recognized by the US government and the standards bodies NIST and SECG. Standards for preferred elliptic curves over prime fields GF(p) and binary polynomial fields GF(2m) as well as the Elliptic Curve Digital Signature Algorithm (ECDSA) have been created. A security protocol based on ECC requires support for different curves representing different security levels. This is particularly true for server applications that are exposed to requests for secure connections with different parameters generated by a multitude of client devices. Reported implementations of ECC over GF(2m) typically choose to implement each curve as a special case so that modular reduction can be optimized, thus improving the overall performance. In contrast, this paper focuses on generic implementations of ECC point multiplication for arbitrary curves over GF(2m). We present a novel reduction algorithm that allows hardware and software implementations for variable field degrees m. Though not as high in performance as an implementation optimized for a specific curve, it offers an attractive solution to supporting infrequently used curves or curves not known at the time of the implementation.	algorithm;digital signature;elliptic curve cryptography;key size;polynomial;public-key cryptography;secg;server (computing);tokenization (data security)	Nils Gura;Hans Eberle;Sheueling Chang Shantz	2002		10.1145/586110.586126	elliptic curve diffie–hellman;jacobian curve;elliptic curve digital signature algorithm;tripling-oriented doche–icart–kohel curve;schoof–elkies–atkin algorithm;computer science;theoretical computer science;counting points on elliptic curves;curve25519;distributed computing;elliptic curve cryptography;public-key cryptography;elliptic curve;elliptic curve point multiplication;computer security	Crypto	-38.51056590714685	78.23117028718862	64459
7e35ce39632b91f21b110601f7b8bb04b2c957b6	partial fairness in secure two-party computation	fairness;secure computation;secure two party computation	A protocol for secure computation is fair if either both parties learn the output or else neither party does. A seminal result of Cleve (STOC ’86) is that, in general, complete fairness is impossible to achieve in two-party computation. In light of this, various techniques for obtaining partial fairness have been suggested in the literature. We propose a definition of partial fairness within the standard real-/ideal-world paradigm. We also show broad feasibility results with respect to our definition: partial fairness is possible for any (randomized) functionality f:X×Y→Z 1×Z 2 at least one of whose domains or ranges is polynomial in size. Our protocols are always private, and when one of the domains has polynomial size our protocols also achieve the usual notion of security with abort. We work in the standard communication model (in particular, we do not assume simultaneous channels) and, in contrast to some prior work, rely only on standard cryptographic assumptions (e.g., enhanced trapdoor permutations). We also show that, as far as general feasibility is concerned, our results are optimal. Specifically, there exist functions with super-polynomial domains and ranges for which it is impossible to achieve our definition.	cryptography;existential quantification;fairness measure;polynomial;programming paradigm;randomized algorithm;secure multi-party computation;secure two-party computation;symposium on theory of computing;trapdoor function	S. Dov Gordon;Jonathan Katz	2010	Journal of Cryptology	10.1007/s00145-010-9079-5	computer science;secure two-party computation;theoretical computer science;mathematics;distributed computing;secure multi-party computation;computer security	Crypto	-38.16001126856047	75.18571068797597	64595
bbeed3bda9f92368fea702680277818eb12bd8eb	reducing packet loss in cbc secured voip using interleaved encryption	telecommunication security cryptography internet telephony quality of service;packet loss;packet loss voip interleaved encryption cbc mode qos;internet telephony;packet loss rate;cryptography;telecommunication security;packet loss reduction interleaved encryption quality of service qos secure voip cipher block chaining mode cipher decryption;cipher block chaining;quality of service;cryptography quality of service time factors systems engineering and theory electronic mail degradation internet telephony cryptographic protocols data security packet switching;time constraint	In this paper we introduce the use of interleaved encryption to improve quality of service (QoS) in VoIP secured using cipher block chaining (CBC) mode ciphers. In current secure VoIP implementations using CBC mode ciphers, a late ciphertext block causes a decryption failure in the next ciphertext block due to inter-block decryption dependencies. The decryption failure in turn further degrades the QoS of the overall communication. This paper introduces an approach to relax the inter-block decryption time constraints such that the QoS of CBC mode secured VoIP asymptotically approach that of non-secure VoIP. Experimental results on a number of captured VoIP traces show that packet loss rate can be reduced by 1-2% depending on network conditions	block cipher mode of operation;ciphertext;context switch;encryption;europe card bus;experiment;network packet;quality of service;tracing (software)	Richard M. Dansereau;Shuyu Jin;Rafik A. Goubran	2006	2006 Canadian Conference on Electrical and Computer Engineering	10.1109/CCECE.2006.277417	quality of service;computer science;cryptography;internet privacy;packet loss;computer security;cbc-mac;computer network	Crypto	-47.23007264379353	81.35074990308041	64995
31b5190a257cf4e5bb231301e4a22dc5027b2922	equivalent keys in multivariate quadratic public key systems	matsumoto-imai scheme a;public key signature;stepwise triangular systems;unbalanced oil and vinegar;c∗;hidden field equations;multivariate quadratic polynomials;public key	Multivariate Quadratic public key schemes have been suggested back in 1985 by Matsumoto and Imai as an alternative for the RSA scheme. Since then, several other schemes have been proposed, for example Hidden Field Equations, Unbalanced Oil and Vinegar schemes, and Stepwise Triangular Schemes. All these schemes have a rather large key space for a secure choice of parameters. Surprisingly, the question of equivalent keys has not been discussed in the open literature until recently. In this article, we show that for all basic classes mentioned above, it is possible to reduce the private — and hence the public — key space by several orders of magnitude. For the Matsumoto-Imai scheme, we are even able to show that the reductions we found are the only ones possible, i.e., that these reductions are tight. While the theorems developed in this article are of independent interest themselves as they broaden our understanding of Multivariate Quadratic public key systems, we see applications of our results both in cryptanalysis and in memory efficient implementations of MQ-schemes.	binary logarithm;cryptanalysis;database normalization;human factors and ergonomics;key escrow;key space (cryptography);key-recovery attack;nl (complexity);numerical analysis;public-key cryptography;requirement;stepwise regression;turing completeness;unbalanced oil and vinegar;utility functions on indivisible goods	Christopher Wolf;Bart Preneel	2005	IACR Cryptology ePrint Archive		discrete mathematics;theoretical computer science;mathematics;public-key cryptography;computer security;algorithm	Crypto	-39.891811154936114	79.31189545288514	65121
271be477fda5bb096706bbb2615240dd3282f6db	minding your p's and q's	public key cryptosystem;failure mode;discrete logarithm;public key;col;key exchange;degeneration;discrete logarithm problem;digital signature standard	Over the last year or two, a large number of attacks have been found by the authors and others on protocols based on the discrete logarithm problem, such as ElGamal signature and Diffie Hellman key exchange. These attacks depend on causing variables to assume values whose discrete logarithms can be calculated, whether by forcing a protocol exchange into a smooth subgroup or by choosing degenerate values directly. We survey these attacks and discuss how to build systems that are robust against them. In the process we elucidate a number of the design decisions behind the US Digital Signature Standard.	diffie–hellman key exchange;digital signature;discrete logarithm	Ross J. Anderson;Serge Vaudenay	1996		10.1007/BFb0034832	arithmetic;discrete logarithm;discrete mathematics;computer science;baby-step giant-step;xtr;mathematics;public-key cryptography;elgamal signature scheme;computer security;algorithm	Security	-39.609312362674615	80.62187823791982	65374
3c187d27d07b23f67c1f2d57e03d9af1e510c90e	building trust for lambda-congenial secret groups	informatica;protocols;encryption;authentication private matching;computer model;cryptographic protocols;private matching trust establishment λ congenial secret groups privacy preservation trusted partners authentication protocols security requirements;polynomials;authentication private matching privacy;security of data cryptographic protocols data privacy;computational modeling;data privacy;security requirements;security of data;protocols polynomials encryption privacy computational modeling;privacy;authentication protocol	Establishing trust while preserving privacy is a challenging research problem. In this paper we introduce lambda -congenial secret groups which allow users to recognize trusted partners based on common attributes while preserving their anonymity and privacy. Such protocols are different from authentication protocols, since the latter are based on identities, while the former are based on attributes. Introducing attributes in trust establishment allows a greater flexibility but also brings up several issues. In this paper, we investigate the problem of building trust with attributes by presenting motivating examples, analyzing the security requirements and giving an informal definition. We also survey one of the most related techniques, namely private matching, and finally present solutions based on it.	authentication protocol;matching (graph theory);requirement	Di Ma;Claudio Soriente	2011	2011 International Conference on Broadband and Wireless Computing, Communication and Applications	10.1109/BWCCA.2011.35	communications protocol;information privacy;computer science;authentication protocol;cryptographic protocol;internet privacy;privacy;computational model;world wide web;computer security;encryption;polynomial	DB	-41.49930559865973	74.66313587791068	65376
a51f7daeeea7b37535155bdf519035ddb2570f89	chameleon all-but-one tdfs and their application to chosen-ciphertext security	lossy trapdoor functions;chosen ciphertext security;signature scheme;chameleon all but one trapdoor functions	In STOC'08, Peikert and Waters introduced a new powerful primitive called lossy trapdoor functions (LTDFs) and a richer abstraction called all-but-one trapdoor functions (ABO-TDFs). They also presented a black-box construction of CCA-secure PKE from an LTDF and an ABO-TDF. An important component of their construction is the use of a strongly unforgeable one-time signature scheme for CCA-security.#R##N##R##N#In this paper, we introduce the notion of chameleon ABO-TDFs, which is a special kind of ABO-TDFs. We give a generic as well as a concrete construction of chameleon ABO-TDFs. Based on an LTDF and a chameleon ABO-TDF, we presented a black-box construction, free of one-time signature, of variant of the CCA secure PKE proposed by Peikert and Waters.		Junzuo Lai;Robert H. Deng;Shengli Liu	2011		10.1007/978-3-642-19379-8_14	mathematics;internet privacy;trapdoor function;computer security;algorithm	Crypto	-39.76641442634454	75.92464233249288	65534
06d364437150ca511ab76117afffed2ab46a3787	idealizing identity-based encryption		We formalize the standard application of identity-based encryption (IBE), namely noninteractive secure communication, as realizing an ideal system which we call delivery controlled channel (DCC). This system allows users to be registered (by a central authority) for an identity and to send messages securely to other users only known by their identity. Quite surprisingly, we show that existing security definitions for IBE are not sufficient to realize DCC. In fact, it is impossible to do so in the standard model. We show, however, how to adjust any IBE scheme that satisfies the standard security definition IND-ID-CPA to achieve this goal in the random oracle model. We also show that the impossibility result can be avoided in the standard model by considering a weaker ideal system that requires all users to be registered in an initial phase before any messages are sent. To achieve this, a weaker security notion, which we introduce and call IND-ID1-CPA, is actually sufficient. This justifies our new security definition and might open the door for more efficient schemes. We further investigate which ideal systems can be realized with schemes satisfying the standard notion and variants of selective security. As a contribution of independent interest, we show how to model features of an ideal system that are potentially available to dishonest parties but not guaranteed, and which such features arise when using IBE.	id-based encryption;interactivity;random oracle;secure communication	Dennis Hofheinz;Christian Matt;Ueli Maurer	2015		10.1007/978-3-662-48797-6_21	mathematics;internet privacy;world wide web;computer security	Crypto	-39.44327386197177	74.67627633158331	65563
265e8f97d6cb1eb116587a15ffb91aa8c2e42b6c	an attack to an anonymous certificateless group key agreement scheme and its improvement		In this paper, we demonstrate that Kumar-Tripathi’s anonymous authenticated group key agreement protocol is insufficient in authenticity and unlinkability. Then the scheme is improved based on the Computational Diffie-Hellman (CDH) problem and Divisible Computational Diffie-Hellman (DCDH) problem. Compared with available schemes, the improved scheme satisfies strengthened security with lower computational overhead. The security is proven formally using AVISPA.	group key;key-agreement protocol	Xuefei Cao;Lanjun Dang;Kai Fan;Yulong Fu	2017		10.1007/978-3-319-72389-1_5	group key;overhead (computing);certificateless cryptography;anonymity;distributed computing;authentication;computer science	Crypto	-42.41757866122127	75.12183644494553	65903
4cb9b6e5bf7c33d51c6323d38f3894335a28851b	optimization of key distribution protocols based on extractors for noisy channels within active adversaries	privacy amplification;extractors;active adversary;cryptography;key distribution	We consider the information-theoretic secure key distribution problem (KDP) over noisy binary symmetric channels with public discussion and in the presence of an active adversary. There are several versions of such protocols proposed by Maurer, Wolf, Renner, Dodis, Reyzin et al. We describe two new versions of KDP for the same channel model and with the use of extractors as a mean of privacy amplification but with the goal to maximize the key rate under an optimization of the protocol parameters. There are two novelties in solution of KDP: we get the extractor's seed directly from the distributed initial strings and we prove the main results in terms of explicit estimates without the use of the uncertain symbols O, Ω, Θ. Both asymptotic and non-asymptotic cases are presented. It is shown that the extractors can be superior to conventional hashing for very large lengths of initially distributed strings.	key distribution	Viktor Yakovlev;Valery I. Korzhik;Mihail Bakaev;Guillermo Morales-Luna	2012		10.1007/978-3-642-33704-8_5	computer science;cryptography;theoretical computer science;distributed computing;key distribution;computer security	Crypto	-37.00983380965486	75.02009566189682	65908
a7255ff5dd05e75c22eddd31883ef23d978e0639	linearly homomorphic structure preserving signatures: new methodologies and applications			electronic signature	Dario Catalano;Antonio Marcedone;Orazio Puglisi	2013	IACR Cryptology ePrint Archive		discrete mathematics;theoretical computer science;homomorphic encryption;computer science	Crypto	-40.46076029474589	80.32075737108892	65937
6df440b6a23b7499b5741f242a82d3df6eec0458	improved truncated differential attacks on safer	game theory;algorithm performance;complexite calcul;teoria juego;theorie jeu;algorithme;algorithm;differential game;jeu differentiel;juego diferencial;complejidad computacion;computational complexity;resultado algoritmo;criptografia;scheduling;cryptography;performance algorithme;cryptographie;ordonamiento;ordonnancement;exhaustive search;algoritmo	Knudsen and Berson have applied truncated differential attack on 5 round SAFER K-64 successfully. However, their attack is not efficient when applied on 5 round SAFER SK-64 (with the modified key schedule) and can not be applied on 6 round SAFER. In this paper, we improve the truncated differential attack on SAFER by using better truncated differential and additional filtering method. Our attack on 5 round SAFER (both SAFER K-64 and SAFER SK-64) can find the secret key much faster than by exhaustive search. Also, the number of chosen plaintexts required are less than those needed in Knudsen and Bersonís attack. Our attack on 6 round SAFER (both SAFER K-64 and SAFER SK-64) can find the secret key faster than by exhaustive search.	brute-force search;key (cryptography);key schedule;plaintext;truncated differential cryptanalysis	Hongjun Wu;Feng Bao;Robert H. Deng;Qin-Zhong Ye	1998		10.1007/3-540-49649-1_12	game theory;simulation;computer science;cryptography;mathematics;scheduling;computer security;algorithm	Crypto	-40.55162403215061	82.82755129656132	65940
377b43e7d3df9bedf2bb1449c4127895d43bb051	digital signatures with minimal overhead from indifferentiable random invertible functions	cayley graph;digital signatures	In a digital signature scheme with message recovery, rather than transmitting the message m and its signature σ, a single enhanced signature τ is transmitted. The verifier is able to recover m from τ and at the same time verify its authenticity. The two most important parameters of such a scheme are its security and overhead |τ | − |m|. A simple argument shows that for any scheme with “n bits security” |τ | − |m| ≥ n, i.e., the overhead is lower bounded by the security parameter n. Currently, the best known constructions in the random oracle model are far from this lower bound requiring an overhead of n + log qh, where qh is the number of queries to the random oracle. In this paper we give a construction which basically matches the n bit lower bound. We propose a simple digital signature scheme with n + o(log qh) bits overhead, where qh denotes the number of random oracle queries. Our construction works in two steps. First, we propose a signature scheme with message recovery having optimal overhead in a new ideal model, the random invertible function model. Second, we show that a four-round Feistel network with random oracles as round functions is tightly “public-indifferentiable” from a random invertible function. At the core of our indifferentiability proof is an almost tight upper bound for the expected number of edges of the densest “small” subgraph of a random Cayley graph, which may be of independent interest.	digital signature;electronic signature;feistel cipher;function model;magma;overhead (computing);random oracle;security parameter;transmitter	Eike Kiltz;Krzysztof Pietrzak;Mario Szegedy	2013		10.1007/978-3-642-40041-4_31	discrete mathematics;theoretical computer science;random function;mathematics;schnorr signature;algorithm	Crypto	-37.12133444658591	77.27881958658917	65962
dd0a7547299b7498bd6f3338f324881043cbf233	security examination of a cellular automata based pseudorandom bit generator using an algebraic replica approach	criptografia;informatique theorique;cryptography;automate cellulaire;cryptographie;cellular automata;cellular automaton;computer theory;automata celular;informatica teorica	A recently proposed scheme for key stream generators based on the programmable cellular automata and a read only memory is considered. It is shown that, the effective secret key size is significantly smaller than its formal length. The scheme is cryptanalyzed assuming ciphertext only attack, and novel cryptanalytic approach is proposed much more efficient than the reported one based on the known plaintext attack. As a development of the proposed basic algorithm for the secret key reconstruction the fast one is also given. Efficiency of the fast algorithm originates from the iterative error-correction procedure based on the algebraic replica approach.	cellular automaton;pseudorandom number generator;pseudorandomness	Miodrag J. Mihaljevic	1997		10.1007/3-540-63163-1_20	cellular automaton;cryptography;theoretical computer science;mathematics;mobile automaton;algorithm	Crypto	-39.65880010397485	81.99653821873524	66141
2b33db981ef8e876bc68b3d128fdb3a2a9f579cc	new approaches for deniable authentication	protocolo acceso;deniability;metodo estadistico;encryption;authentication;simulation;simulacion;statistical method;cifrado;securite donnee;satisfiability;access protocol;authentification;autenticacion;cryptage;methode statistique;protocole acces;zero knowledge;security of data;authentication protocol	Deniable Authentication protocols allow a Sender to authenticate a message for a Receiver, in a way that the Receiver cannot convince a third party that such authentication (or any authentication) ever took place.We present two new approaches to the problem of deniable authentication. The novelty of our schemes is that they do not require the use of CCA-secure encryption (all previous known solutions did), thus showing a different generic approach to the problem of deniable authentication. This new approach is practically relevant as it leads to more efficient protocols and security reductions.In the process we point out a subtle definitional issue for deniability. In particular we propose the notion of forward deniability, which requires that the authentications remain deniable even if the Sender wants to later prove that she authenticated a message. We show that forward deniability is not implied by the original notion of deniability, by showing some deniable protocols which are not forward deniable. Our new proposals are forward deniable.	authentication protocol;definition;deniable authentication;deniable encryption	Mario Di Raimondo;Rosario Gennaro	2005	Journal of Cryptology	10.1007/s00145-009-9044-3	telecommunications;computer science;deniable encryption;authentication;distributed computing;computer security	Security	-43.16628290785541	77.10737701570244	66626
594e44ca2656a6d8a3ae7e4a671f67e01f30cd4e	secure vanet applications with a refined group signature	wireless sensor networks data privacy digital signatures handwriting recognition mobile computing telecommunication security vehicular ad hoc networks;vanet group signature;signature verification secure vanet applications refined group signature application friendly group signature model gs model wireless ad hoc network wireless sensor networks wsn vehicle ad hoc network gs properties boneh boyen and shacham short gs bbs short gs privacy properties linking direct opening message dependent opening revoking batch verification link manager application requirement ad hoc network security value added service provider vsp mdo properties gs friendly vanet architecture rekeying verifier local revocation vlr illegitimate signers batch verification system;vehicles vehicular ad hoc networks security privacy joining processes proposals accidents	This paper proposes an application-friendly group signature (GS) model for wireless ad hoc network like Wireless Sensor Networks (WSN) or Vehicle ad hoc Network (VANET). Our new GS properties can be used to carry out potential solution to some real life problems. We modify Boneh, Boyen and Shacham (BBS) short GS to meet a restricted, but arguably sufficient set of privacy properties. In particular, we aggregate linking, direct opening, message-dependent opening (MDO), revoking, batch-verification in a single short GS scheme. Our link manager can link messages whether they are coming from the same messages or not without colluding to the opener. It helps relaxing strong privacy properties of GS to a lightly lesser one that fit certain application requirement. We introduce a new application to the ad hoc network security, that is, value-added service provider (VSP) with the help of MDO properties and redesign the traditional GS-friendly VANET architecture. Our revocation algorithm adapts both rekeying and verifier-local revocation (VLR) approaches to revoke illegitimate signers in a constant time. Finally, we present an optional batch verification system to expedite signature verification. Note that all these properties have already been shown in the literature scatteredly. The novelty of our proposal stems from accumulating all these properties in a single GS scheme that can best fit to the application demand.	aggregate data;algorithm;curve fitting;formal verification;group signature;hoc (programming language);mike lesser;multidisciplinary design optimization;network security;privacy;real life;roland gs;time complexity	Mohammad Saiful Islam Mamun;Atsuko Miyaji	2014	2014 Twelfth Annual International Conference on Privacy, Security and Trust	10.1109/PST.2014.6890940	vehicular ad hoc network;wireless ad hoc network;mobile ad hoc network;computer science;ad hoc wireless distribution service;internet privacy;computer security;computer network	Mobile	-47.75828180074353	75.44010312546565	66844
0ca8a7fb202e79e38aaac25cb48f175042eefeaa	leakage-resilient chosen-ciphertext secure public-key encryption from hash proof system and one-time lossy filter	efficient construction;public key encryption;leakage resilience;会议论文;chosen ciphertext security;cramer shoup scheme;generic construction;hash proof systems;chosen ciphertext attack	We present a new generic construction of a public-key encryption (PKE) scheme secure against leakage-resilient chosen-ciphertext attacks (LR-CCA), from any Hash Proof System (HPS) and any one-time lossy filter (OT-LF). Efficient constructions of HPSs and OT-LFs from the DDH and DCR assumptions suggest that our construction is a practical approach to LR-CCA security. Most of practical PKEs with LR-CCA security, like variants of Cramer-Shoup scheme, rooted from Hash Proof Systems, but with leakage rates at most 1/4 − o(1) (defined as the ratio of leakage amount to secret-key size). The instantiations of our construction from the DDH and DCR assumptions result in LR-CCA secure PKEs with leakage rate of 1/2 − o(1). On the other hand, our construction also creates a new approach for constructing IND-CCA secure (leakage-free) PKE schemes, which may be of independent interest.	adaptive chosen-ciphertext attack;ciphertext;encryption;key size;lr parser;lossy compression;proof calculus;public-key cryptography;spectral leakage	Baodong Qin;Shengli Liu	2013		10.1007/978-3-642-42045-0_20	chosen-ciphertext attack;computer science;secure hash algorithm;theoretical computer science;secure hash standard;hash chain;mathematics;internet privacy;public-key cryptography;computer security	Crypto	-39.39828198630626	77.10111835381073	66873
5dc749350f0024154d08f884dbe065619cc3284b	avoid mask re-use in masked galois multipliers	article	"""This work examines a weakness in re-using masks for masked Galois inversion, speci cally in the masked Galois multipliers. Here we show that the mask re-use scheme included in our work[1] cannot result in \perfect masking,"""" regardless of the order in which the terms are added; explicit distributions are derived for each step. The same problem requires new masks in the sub eld calculations, not included in [1]. Hence, for resistance to rst-order di erential attacks, the masked S-box must use distinct, independent masks for input and output bytes of the masked inverter, and new masks in the sub elds, resulting in a larger size. keywords: AES, S-box, masking, DPA, composite Galois eld"""	byte;input/output;power inverter;s-box;unsharp masking;variable shadowing	D. Canright	2009	IACR Cryptology ePrint Archive		computer hardware;theoretical computer science	Crypto	-35.63340156614841	79.46678941510588	66932
20840c8d0a6d958e234142edf0207bfbfdb56238	secure prngs from specialized polynomial maps over any fq	provable security;prng;sparse multivariate polynomial map;hash function	Berbain, Gilbert, and Patarin presented QUAD, a pseudo random number generator (PRNG) at Eurocrypt 2006. QUAD (as PRNG and stream cipher) may be proved secure based on an interesting hardness assumption about the one-wayness of multivariate quadratic polynomial systems over F2. The original BGP proof only worked for F2 and left a gap to general Fq. We show that the result can be generalized to any arbitrary finite field Fq, and thus produces a stream cipher with alphabets in Fq. Further, we generalize the underlying hardness assumption to specialized systems in Fq (including F2) that can be evaluated more efficiently. Barring breakthroughs in the current state-of-the-art for system-solving, a rough implementation of a provably secure instance of our new PRNG is twice as fast and takes 1/10 the storage of an instance of QUAD with the same level of provable security. Recent results on specialization on security are also examined. And we conclude that our ideas are consistent with these new developments and complement them. This gives a clue that we may build secure primitives based on specialized polynomial maps which are more efficient.	border gateway protocol;computational hardness assumption;eurocrypt;gilbert cell;map;partial template specialization;polynomial;provable security;pseudorandom number generator;pseudorandomness;quadratic function;random number generation;stream cipher	Feng-Hao Liu;Chi-Jen Lu;Bo-Yin Yang;Jintai Ding	2007	IACR Cryptology ePrint Archive	10.1007/978-3-540-88403-3_13	combinatorics;discrete mathematics;theoretical computer science;mathematics	Crypto	-38.103753237535905	79.59154433249635	66943
4f5a32de8d6db35f6781930ee54e1da6e7bf1463	key classification attack on block ciphers		In this paper, security analysis of block ciphers with key length greater than block length is proposed. For a welldesigned block cipher with key length k and block length n s.t. k>n and for all P, C, there are n k 2 keys which map P to C. For given block cipher, if there is an efficient algorithm that can classify such keys, we propose an algorithm will be able to recover the secret key with complexity { } ( ) n k n , max O − 2 2 . We apply this method on 2-round block cipher KASUMI. KeywordsBlock cipher, Key classes, key length, block length, KASUMI.	algebraic equation;algorithm;block cipher;block code;cryptanalysis;feistel cipher;key (cryptography);key size;key space (cryptography);triple des	Maghsood Parviz;Seyed Hassan Mousavi;Saeed Mirahmadi	2013	IACR Cryptology ePrint Archive		weak key;substitution-permutation network;block cipher;transposition cipher;triple des;key whitening;differential cryptanalysis;discrete mathematics;residual block termination;two-square cipher;running key cipher;ciphertext stealing;block cipher mode of operation;key clustering;theoretical computer science;block size;key schedule;mathematics;stream cipher;affine cipher;computer security;cbc-mac;3-way	Crypto	-39.29748600960275	80.88959221185542	67324
eef20fc8cc7d414b775c0096a8e9d4efd4f9afdc	a new constant-size accountable ring signature scheme without random oracles		Accountable ring signature (ARS), introduced by Xu and Yung (CARDIS 2004), combines many useful properties of ring and group signatures. In particular, the signer in an ARS scheme has the flexibility of choosing an ad hoc group of users, and signing on their behalf (like a ring signature). Furthermore, the signer can designate an opener who may later reveal his identity, if required (like a group signature). In 2015, Bootle et al. (ESORICS 2015) formalized the notion and gave an efficient construction for ARS with signature-size logarithmic in the size of the ring. Their scheme is proven to be secure in the random oracle model. Recently, Russell et al. (ESORICS 2016) gave a construction with constant signature-size that is secure in the standard model. Their scheme is based on q-type assumptions (q-SDH). In this paper, we give a new construction for ARS having the following properties: signature is constant-sized, secure in the standard model, and based on indistinguishability obfuscation (iO) and one-way functions. To the best of our knowledge, this is the first iO-based ARS scheme. Independent of this, our work can be viewed as a new application of puncturable programming and hidden sparse trigger techniques introduced by Sahai and Waters (STOC 2014) to design iO-based deniable encryption.	antivirus software;asiacrypt;ciphertext indistinguishability;communications security;computer security;deniable encryption;electronic signature;eurocrypt;functional encryption;group signature;hoc (programming language);information security;journal of the acm;map;mental poker;one-way function;oracle machine;pkc (conference);phelim boyle;probabilistic encryption;pseudorandomness;public-key cryptography;random oracle;ring signature;sparse matrix;springer (tank);symposium on foundations of computer science;symposium on theory of computing;synchronous optical networking;the new york times;type signature	Sudhakar Kumawat;Souradyuti Paul	2017	IACR Cryptology ePrint Archive	10.1007/978-3-319-75160-3_11	ring signature;computer science;discrete mathematics;group signature;random oracle;logarithm	Crypto	-40.60861549524757	76.26048103837661	67423
e7d6fadda1ff37a62888f7502cbfe3353c812ddd	accelerated verification of ecdsa signatures	elliptic curve;caracter manuscrito;manuscript character;securite informatique;signature electronique;courbe elliptique;computer security;reconnaissance caractere;curva eliptica;digital signature;criptografia;cryptography;seguridad informatica;cryptographie;firma numerica;caractere manuscrit;character recognition;reconocimiento caracter	Verification of ECDSA signatures is considerably slower than generation of ECDSA signatures. This paper describes a method that can be used to accelerate verification of ECDSA signatures by more than 40% with virtually no added implementation complexity. The method can also be used to accelerate verification for other ElGamal-like signature algorithms, including DSA.	algorithm;antivirus software;centre for applied cryptographic research;conformance testing;digital signature;elliptic curve cryptography;speedup;type signature	Adrian Antipa;Daniel R. L. Brown;Robert P. Gallant;Robert J. Lambert;René Struik;Scott A. Vanstone	2005		10.1007/11693383_21	artificial intelligence;mathematics;algorithm;cartography	Logic	-41.35219370680548	80.86422162363074	67672
cdc32f0d58bf6644b13013493b54c4620e8c81c1	novel method of chaotic systems evaluation for implementations of encryption algorithms	chaotic communication;chaotic system;encryption;chaos;chaotic systems evaluation;attractor;region of valid initial conditions;region of valid initial conditions chaos encryption attractor key space;cryptography chaotic communication;logistics;algorithm strength;cryptography;implementation complexity;algorithm strength chaotic systems evaluation encryption algorithms microelectronic chaos implementation complexity;initial condition;transmitters;key space;chaos cryptography logistics equations microelectronics transmitters security algorithm design and analysis telecommunications computer science;mathematical model;microelectronic chaos;encryption algorithms;computer science;microelectronics;dispersion;security;integrated circuits;algorithm design and analysis;telecommunications	Many papers reporting microelectronic chaos based applications have appeared in recent years. The focus of cryptology has been mainly on the algorithm implementation rather than on the chaotic system choice. In this paper, a novel method is proposed which aims at properly selecting a chaotic system to be used with encryption algorithms. The properties directly related to the algorithm strength and implementation complexity are the parameters that guide the system choice. Six chaotic systems have been examined with a summary of the data for quick design application made available.	algorithm;chaos theory;cryptography;encryption	Élvio Dutra;Manfred Glesner;Weiler Alves Finamore;Leandro Soares Indrusiak	2010	2010 17th International Conference on Telecommunications	10.1109/ICTEL.2010.5478834	simulation;computer science;information security;theoretical computer science;distributed computing;encryption	EDA	-41.64810791600968	83.92643610776045	67799
cb9a998a1ee7f5f6db918807476e10773aadabb6	cryptanalysis of a dynamic id-based remote user authentication scheme with access control for multi-server environments	anonymity;authentication scheme;dynamic id-based;multi-server environment		access control;authentication;cryptanalysis	Debiao He;Hao Hu	2013	IEICE Transactions		data authentication algorithm;anonymity;computer science;authentication protocol;internet authentication service;lightweight extensible authentication protocol;multi-factor authentication;internet privacy;computer security;computer network	Security	-44.941940661457615	74.57560770584575	67801
34dd9b029c35028b0bf661a545c7cd7cd34ba4d6	a new strongly secure authenticated key exchange protocol	extended canetti krawczyk model;authenticated key exchange;random oracle model;gap diffie hellman assumption	In 2007, LaMacchia et al. proposed the extended Canetti-Krawczyk (eCK) model, which is currently regarded as the strongest security model for authenticated key exchange (AKE) protocols. In the eCK model, the adversary can reveal a party's ephemeral private key or static private key on the test session, but can't reveal the ephemeral value which was computed using ephemeral private key and static private key. In this paper, we first present the modified eCK (meCK) model by adding a new reveal query. The adversary can reveal all ephemeral secret information of the test session according to the meCK model's freshness definition. Then we propose a new strongly secure AKE protocol, called E-NAXOS, and prove its security in the meCK model under the random oracle assumption and the gap Diffie-Hellman assumption.	authenticated key exchange;authentication	Qingfeng Cheng;Chuangui Ma;Xuexian Hu	2009		10.1007/978-3-642-02617-1_14	random oracle;computer science;distributed computing;internet privacy;computer security	Crypto	-42.01006859635153	75.44219376890534	67892
9c29f98c58f24850a639ec0587c317c06756f57d	revisiting aes related-key differential attacks with constraint programming		The Advanced Encryption Standard (AES) is one of the most studied symmetric encryption schemes. During the last years, several attacks have been discovered in different adversarial models. In this paper, we focus on related-key differential attacks, where the adversary may introduce differences in plaintext pairs and also in keys. We show that Constraint Programming (CP) can be used to model these attacks, and that it allows us to efficiently find all optimal related-key differential characteristics for AES-128, AES-192 and AES-256. In particular, we improve the best related-key differential for the whole AES-256 and give the best related-key differential on 10 rounds of AES-192, which is the differential trail with the longest path. Those results allow us to improve existing related-key distinguishers, basic related-key attacks and q-multicollisions on AES-256.		David Gérault;Pascal Lafourcade;Marine Minier;Christine Solnon	2017	Inf. Process. Lett.	10.1016/j.ipl.2018.07.001	constraint programming;discrete mathematics;mathematics;longest path problem;advanced encryption standard;plaintext;adversary;symmetric-key algorithm	Crypto	-37.267769765629204	81.30104296365039	68039
05bd97ec6787756a9c4486d9d9de55e9b5682bef	knapsack cryptosystems built on np-hard instances	knapsack problem;computational complexity;discrete mathematics;secure computation;data structure;public key	We construct three public key knapsack cryptosystems. Standard knapsack cryptosystems hide easy instances of the knapsack problem and have been broken. The systems considered in the article face this problem: They hide a random (possibly hard) instance of the knapsack problem. We provide both complexity results (size of the key, time needed to encypher/decypher...) and experimental results. Security results are given for the second cryptosystem (the fastest one and the one with the shortest key). Probabilistic polynomial reductions show that finding the private key is as difficult as factorizing a product of two primes. We also consider heuristic attacks. First, the density of the cryptosystem can be chosen arbitrarily close to one, discarding low density attacks. Finally, we consider explicit heuristic attacks based on the LLL algorithm and we prove that with respect to these attacks, the public key is as secure as a random key.	cryptosystem;knapsack cryptosystems;np-hardness	Laurent Evain	2008	IACR Cryptology ePrint Archive		knapsack cryptosystems;theoretical computer science;hybrid cryptosystem;change-making problem;continuous knapsack problem;discrete mathematics;cutting stock problem;cryptosystem;knapsack problem;merkle–hellman knapsack cryptosystem;mathematics	Crypto	-37.98010363561773	79.30468394850884	68283
d53da88640f0183050845dacaf2434d686ed69d2	a key agreement method for wireless body area networks	wireless channels body area networks telecommunication security;communication channel wireless body area network intersensor controller communication physical layer information based key generation physical layer information based key agreement method;reed solomon encoding decoding wireless body area network wban improved juels and sudan ijs algorithm;encoding reed solomon codes wireless communication decoding body area networks physical layer galois fields	A secure and efficient key agreement method is required by Wireless Body Area Network, especially for intersensor/controller communication. The communicating parties share similar channel information at physical layer that the others cannot grasp. The physical layer information-based key generation and agreement will only pass check symbols from one side to the other side of the communication channel. Then the receiving side can recover the original information stored at the sending side from the received check symbols and the similar local information. This way can achieve both high security and efficiency. This paper further improves the security and efficiency of the above method.	channel (communications);key generation;key-agreement protocol;reed–solomon error correction;simulation;time complexity	Zhouzhou Li;Honggang Wang	2016	2016 IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)	10.1109/INFCOMW.2016.7562165	wireless wan;telecommunications;computer science;wireless network;key distribution in wireless sensor networks;wi-fi array;computer network	Mobile	-46.117340926951094	82.22931931484723	68411
477309dd75c3cee687298479377926d7f75397b0	spooky interaction and its discontents: compilers for succinct two-message argument systems		We are interested in constructing short two-message arguments for various languages, where the complexity of the verifier is small (e.g. linear in the input size, or even sublinear if it is coded properly). Suppose that we have a low communication public-coin interactive protocol for proving (or arguing) membership in the language. We consider a “compiler” from the literature that takes a protocol consisting of several rounds and produces a two-message argument system. The compiler is based on any Fully Homomorphic Encryption (FHE) scheme, or on PIR (under additional conditions on the protocol). This compiler has been used successfully in several proposed protocols. We investigate the question of whether this compiler can be proven to work under standard cryptographic assumptions. We prove (i) If FHEs or PIR systems exist, then there is a sound interactive proof protocol that, when run through the compiler, results in a protocol that is not sound. (ii) If the verifier in the original protocol runs in logarithmic space and has no “longterm” secret memory (a generalization of public coins), then the compiled protocol is sound. This yields a succinct two-message argument system for any language in NC, where the verifier’s work is linear (or even polylog if the input is coded appropriately). This is the first (non trivial) two-message succinct argument system that is based on a standard polynomial-time hardness assumption. ∗Microsoft Research Silicon Valley. †Dept of Computer Science and Applied Math, Weizmann Institute of Science. Incumbent of the Judith Kleeman Professorial Chair. Research supported in part by grants from the Israel Science Foundation, BSF and Israeli Ministry of Science and Technology and from the I-CORE Program of the Planning and Budgeting Committee and the Israel Science Foundation (grant No. 4/11). Part of this work was done while visiting Microsoft Research. ‡Samsung Research America.	bean scripting framework;compiler;computer science;cryptographic hash function;cryptography;homomorphic encryption;l (complexity);microsoft research;nl (complexity);norm (social);protein information resource;time complexity	Cynthia Dwork;Moni Naor;Guy N. Rothblum	2016		10.1007/978-3-662-53015-3_5	econometrics;mathematical optimization;statistics	Theory	-35.39500911277759	76.5666407068677	68692
36d54112511393eab87ad5bde095d5cfa8366061	a new algorithm for switching from arithmetic to boolean masking	hachage;switching;logica booleana;arithmetic operation;calculateur embarque;metodo diferencial;algorithm analysis;encryption;gollete estrangulamiento;implementation;operation arithmetique;cryptanalyse;cifrado;operacion aritmetica;probabilistic approach;differential method;cryptanalysis;criptoanalisis;goulot etranglement;cryptographic algorithm;hashing;boolean operation;masquage;general methods;cryptage;criptografia;enfoque probabilista;cryptography;approche probabiliste;enmascaramiento;differential power analysis;conmutacion;boarded computer;methode differentielle;masking;logique booleenne;cryptographie;analyse algorithme;implementacion;boolean logic;bottleneck;calculador embarque;commutation;analisis algoritmo	To protect a cryptographic algorithm against Differential Power Analysis, a general method consists in masking all intermediate data with a random value. When a cryptographic algorithm combines boolean operations with arithmetic operations, it is then necessary to perform conversions between boolean masking and arithmetic masking. A very efficient method was proposed by Louis Goubin in [6] to convert from boolean masking to arithmetic masking. However, the method in [6] for converting from arithmetic to boolean masking is less efficient. In some implementations, this conversion can be a bottleneck. In this paper, we propose an improved algorithm to convert from arithmetic masking to boolean masking. Our method can be applied to encryption schemes such as IDEA and RC6, and hashing algorithms such as SHA-1.	32-bit;algorithm;boolean satisfiability problem;bottleneck (engineering);encryption;hash function;microprocessor;sha-1	Jean-Sébastien Coron;Alexei Tchulkine	2003		10.1007/978-3-540-45238-6_8	boolean circuit;cryptanalysis;discrete mathematics;boolean expression;computer science;cryptography;theoretical computer science;masking;mathematics;implementation;encryption;algorithm;statistics	Crypto	-40.56459959447077	81.52495326409063	68707
79c4a23a558809d98bf51e7cfa5eec5598da258b	bootstrappable identity-based fully homomorphic encryption		It has been an open problem for a number of years to construct an identity-based fully homomorphic encryption (IBFHE) scheme (first mentioned by Naccache at CHES/CRYPTO 2010). At CRYPTO 2013, Gentry, Sahai and Waters largely settled the problem by presenting leveled IBFHE constructions based on the Learning With Errors problem. However their constructions are not bootstrappable, and as a result, are not “pure” IBFHE schemes. The major challenge with bootstrapping in the identity-based setting is that it must be possible to non-interactively derive from the public parameters an “encryption” of the secret key for an arbitrary identity. All presently-known leveled IBFHE schemes only allow bootstrapping if such an “encryption” of the secret key is supplied out-of-band. In this work, we present a “pure” IBFHE scheme from indistinguishability obfuscation, and extend the result to the attribute-based setting. Our attribute-based scheme is the first to support homomorphic evaluation on ciphertexts with different attributes. Finally, we characterize presently-known leveled IBFHE schemes with a view to developing a “compiler” from a leveled IBFHE scheme to a bootstrappable IBFHE scheme, and sufficient conditions are identified.	bootstrapping (compilers);compiler;homomorphic encryption;interactivity;key (cryptography);learning with errors;out-of-band agreement	Michael Clear;Ciaran McGoldrick	2014	IACR Cryptology ePrint Archive	10.1007/978-3-319-12280-9_1	theoretical computer science;mathematics;internet privacy;computer security;attribute-based encryption	Crypto	-38.789322598239	75.61748083245185	68767
acefe09254c9c305a0722c5f48520a59eac44a12	advances in cryptology – eurocrypt 2016		An accumulator is a function that hashes a set of inputs into a short, constant-size string while preserving the ability to efficiently prove the inclusion of a specific input element in the hashed set. It has proved useful in the design of numerous privacy-enhancing protocols, in order to handle revocation or simply prove set membership. In the lattice setting, currently known instantiations of the primitive are based on Merkle trees, which do not interact well with zero-knowledge proofs. In order to efficiently prove the membership of some element in a zeroknowledge manner, the prover has to demonstrate knowledge of a hash chain without revealing it, which is not known to be efficiently possible under well-studied hardness assumptions. In this paper, we provide an efficient method of proving such statements using involved extensions of Stern’s protocol. Under the Small Integer Solution assumption, we provide zero-knowledge arguments showing possession of a hash chain. As an application, we describe new lattice-based group and ring signatures in the random oracle model. In particular, we obtain: (i) The first latticebased ring signatures with logarithmic size in the cardinality of the ring; (ii) The first lattice-based group signature that does not require any GPV trapdoor and thus allows for a much more efficient choice of parameters.	accumulator (computing);antivirus software;cryptographic hash function;cryptography;eurocrypt;group signature;hash chain;merkle tree;privacy;random oracle;ring signature;type signature;zero-knowledge proof	Josef Kittler;John C. Mitchell;Moni Naor	2016		10.1007/978-3-662-49896-5	computational biology;mathematics	Crypto	-38.88600016795921	76.12118246121115	68774
ed8f9b835c9e0df12b6be0a0b51d9c88c28a27a5	synchronized aggregate signatures from the rsa assumption		In this work we construct efficient aggregate signatures from the RSA assumption in the synchronized setting. In this setting, the signing algorithm takes as input a (time) period t as well the secret key and message. A signer should sign at most once for each t. A set of signatures can be aggregated so long as they were all created for the same period t. Synchronized aggregate signatures are useful in systems where there is a natural reporting period such as log and sensor data, or for signatures embedded in a blockchain protocol where the creation of an additional block is a natural synchronization event. We design a synchronized aggregate signature scheme that works for a bounded number of periods T that is given as a parameter to a global system setup. The big technical question is whether we can create solutions that will perform well with the large T values that we might use in practice. For instance, if one wanted signing keys to last up to ten years and be able to issue signatures every second, then we would need to support a period bound of upwards of 2. We build our solution in stages where we start with an initial solution that establishes feasibility, but has an impractically large signing time where the number of exponentiations and prime searches grows linearly with T . We prove this scheme secure in the standard model under the RSA assumption with respect to honestly-generated keys. We then provide a tradeoff method where one can tradeoff the time to create signatures with the space required to store private keys. One point in the tradeoff is where each scales with √ T . Finally, we reach our main innovation which is a scheme where both the signing time and storage scale with lg T which allows for us to keep both computation and storage costs modest even for large values of T . Conveniently, our final scheme uses the same verification algorithm, and has the same distribution of public keys and signatures as the first scheme. Thus we are able to recycle the existing security proof for the new scheme. We also show how to extend our results to the identity-based setting in the random oracle model, which can further reduce the overall cryptographic overhead. We conclude with a detailed evaluation of the signing time and storage requirements for various practical settings of the system parameters. ∗Supported by the National Science Foundation CNS-1228443 and CNS-1414023, the Office of Naval Research N00014-15-1-2778, and a Microsoft Faculty Fellowship. †Supported by NSF CNS-1414082, DARPA SafeWare, Microsoft Faculty Fellowship, and Packard Foundation Fellowship. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the Department of Defense or the U.S. Government.	aggregate data;aggregate function;algorithm;antivirus software;code signing;computation;cryptography;digital signature;electronic signature;embedded system;ibm notes;key (cryptography);overhead (computing);provable security;random oracle;requirement;type signature	Susan Hohenberger;Brent Waters	2018		10.1007/978-3-319-78375-8_7	theoretical computer science;computer science;blockchain	Crypto	-34.96017239742758	76.50867705723384	68900
7c916e96bc3608bebfc35d6bfd923bc690a56681	a subliminal channel in secret block ciphers	broadcast channel;block cipher	In this paper we present the first general purpose subliminal channel that can be built into a secret symmetric cipher by a malicious designer. Subliminal channels traditionally exploit randomness that is used in probabilistic cryptosystems. In contrast, our channel is built into a deterministic block cipher, and thus it is based on a new principle. It is a broadcast channel that assumes that the sender and the receiver know the subliminal message ms (i.e., something derived from their common key). We show that the designer can expect to be able to read ms when O(|ms|log|ms|) plaintext/ciphertext pairs are obtained. Here |ms| is the length of ms in bits. We show how to turn the channel into a narrowcast channel using a deterministic asymmetric cipher and then present an application of the narrowcast channel. In this application, the secret block cipher securely and subliminally transmits the symmetric key of the sender and receiver to the malicious designer and confidentiality holds even when the cipher is made public.	block cipher;ciphertext;confidentiality;cryptosystem;embedded system;plaintext;public-key cryptography;randomness;reverse engineering;subliminal channel;symmetric-key algorithm;universal instantiation	Adam L. Young;Moti Yung	2004		10.1007/978-3-540-30564-4_14	substitution-permutation network;transposition cipher;residual block termination;running key cipher;ciphertext stealing;block cipher mode of operation;telecommunications;computer science;stream cipher;affine cipher;internet privacy;computer security;cbc-mac;ciphertext	Crypto	-43.994739329752925	80.25161933675122	68984
85364f539eb3315ef2e173bc607ab5fa026b1d16	differential fault attacks on elliptic curve cryptosystems	elliptic curves;elliptic curve;differential fault attack;courbe elliptique;curva eliptica;criptografia;cryptography;fault attack;rsa cryptosystem;differential fault attacks;cryptographie;cryptosysteme;elliptic curve cryptosystem	In this paper we extend the ideas for differential fault attacks on the RSA cryptosystem (see [4]) to schemes using elliptic curves. We present three different types of attacks that can be used to derive information about the secret key if bit errors can be inserted into the elliptic curve computations in a tamper-proof device. The effectiveness of the attacks was proven in a software simulation of the described ideas.	computation;computer simulation;cryptosystem;differential fault analysis;elliptic curve cryptography;key (cryptography);rsa (cryptosystem);tamper resistance	Ingrid Biehl;Bernd Meyer;Volker Müller	2000		10.1007/3-540-44598-6_8	discrete mathematics;elliptic curve diffie–hellman;jacobian curve;elliptic curve digital signature algorithm;theoretical computer science;counting points on elliptic curves;curve25519;mathematics;elliptic curve cryptography;elliptic curve;elliptic curve point multiplication;computer security	Crypto	-39.90815873082965	81.03770774535256	69167
86535c9655dea0458ee31728a58df0224fe0cd90	faster isogeny-based compressed key agreement		Supersingular isogeny-based cryptography is one of the more recent families of post-quantum proposals. An interesting feature is the comparatively low bandwidth occupation in key agreement protocols, which stems from the possibility of key compression. However, compression and decompression introduce a significant overhead to the overall processing cost despite recent progress. In this paper we address the main processing bottlenecks involved in key compression and decompression, and suggest substantial improvements for each of them. Some of our techniques may have an independent interest for other, more conventional areas of elliptic curve cryptography as well.	data compression;elliptic curve cryptography;key-agreement protocol;overhead (computing);post-quantum cryptography	Gustavo Zanon;Marcos A. Simplício;Geovandro C. C. F. Pereira;Javad Doliskani;Paulo S. L. M. Barreto	2017		10.1007/978-3-319-79063-3_12	compression (physics);theoretical computer science;elliptic curve cryptography;cryptography;isogeny;computer science;bandwidth (signal processing)	Crypto	-36.59024772552288	78.3345650689991	69229
1988ff5cf2426c1250d3e3e92ab401a1f598e345	a strong and efficient certificateless digital signature scheme		This paper extends the certificateless public key infrastructure model that was proposed by Hassouna et al by proposing new digital signature scheme to provide true non-repudiation, the proposed signature scheme is short and efficient, it is also has strength point that the KGC has no contribution in signature generation/verification process, therefore any compromise of the KGC does not affect the non-repudiation service of the system. Furthermore, even the KGC cannot do signature forgery by (temporary) replacing the user’s public key.	digital signature;non-repudiation;public key infrastructure;public-key cryptography	Mohammed Hassouna;Mohsin Hashim	2014	IACR Cryptology ePrint Archive		elgamal signature scheme;digital signature;theoretical computer science;mathematics	Security	-42.3025945683991	75.4941338331793	69280
b8f88f8d2db6174a4a60bd88592eb94f3ee7b1d8	revisiting rc4 key collision: faster search algorithm and new 22-byte colliding key pairs	colliding pair;key collision;near colliding pair;rc4;related key cryptanalysis;stream cipher;94a60	If two different secret keys of stream cipher RC4 yield the same internal state after the key scheduling algorithm (KSA) and hence generate the same sequence of keystream bits, they are called a colliding key pair. The number of possible internal states of RC4 stream cipher is very large (approximately 21700), which makes finding key collision hard for practical key lengths (i.e., less than 30 bytes). Matsui (2009) for the first time reported a 24-byte colliding key pair and one 20-byte near-colliding key pair (i.e., for which the state arrays after the KSA differ in at most two positions) for RC4. Subsequently, Chen and Miyaji (2011) designed a more efficient search algorithm using Matsui’s collision pattern and reported a 22-byte colliding key pair which remains the only shortest known colliding key pair so far. In this paper, we show some limitations of both the above approaches and propose a faster collision search algorithm that overcomes these limitations. Using our algorithm, we are able to find three additional 22-byte colliding key pairs that are different from the one reported by Chen and Miyaji. We additionally give 12 new 20-byte near-colliding key pairs. These results are significant, considering the argument by Biham and Dunkelman (2007), that for shorter keys there might be no instances of collision at all.	byte;entity–relationship model;key schedule;public-key cryptography;rc4;scheduling (computing);search algorithm;stream cipher	Amit Jana;Goutam Paul	2016	Cryptography and Communications	10.1007/s12095-017-0231-z	rc4;mathematics;discrete mathematics;collision;public-key cryptography;keystream;key (lock);byte;search algorithm;distributed computing;stream cipher	Crypto	-36.38039286246716	81.15673680448899	69497
d6beb2199a3fb89ebab64404e3791ee3b5bac0ea	information-theoretic cryptography	unconditional security;oblivious transfer;securite;multi party computation;authentication;and key agreement;authentification;computer security;autenticacion;criptografia;cryptography;random function;safety;random oracle;cryptographie;theorie information;seguridad;information theoretic;information theory;teoria informacion	We discuss several applications of information theory in cryptography, both for unconditional and for computational security. Unconditionally-secure secrecy, authentication, and key agreement are reviewed. It is argued that unconditional security can practically be achieved by exploiting the fact that cryptography takes place in a physical world in which, for instance due to noise, nobody can have complete information about the state of a system. The general concept of an information-theoretic cryptographic primitive is proposed which covers many previously considered primitives like oblivious transfer, noisy channels, and multi-party computation. Many results in information-theoretic cryptography can be phrased as reductions among such primitives We also propose the concept of a generalized random oracle which answers more general queries than the evaluation of a random function. They have applications in proofs of the computational security of certain cryptographic schemes. This extended abstract summarizes in an informal and non-technical way some of the material presented in the author’s lecture to be given at Crypto ’99.	authentication;computation;computational hardness assumption;cryptographic primitive;cryptography;information theory;information-theoretic security;key-agreement protocol;oblivious transfer;random oracle;semantic security	Ueli Maurer	1999		10.1007/3-540-48405-1_4	cdmf;lattice-based cryptography;strong cryptography;financial cryptography;information theory;computer science;theoretical computer science;authentication;mathematics;internet privacy;computational hardness assumption;computer security;algorithm	Crypto	-42.8118803043053	79.13182185224947	69613
013ccab2593e32484aec4544bf56876edd51da43	efficient deniable authentication protocol based on generalized elgamal signature scheme	authentication;signature scheme;impersonation attack;digital signature;cryptography;security;authentication protocol	An efficient and non-interactive deniable authentication protocol is presented to enable a receiver to identify the source of a given message, but not prove the identity of the sender to a third party. The proposed protocol is based on the generalized ElGamal signature scheme and is more efficient than the previous protocols. We show that if an adversary could forge signatures of this protocol, he would forge signatures of the generalized ElGamal signature scheme. Moreover, the new protocol is more secure than the previous deniable authentication protocols, since anyone can not impersonate the intended receiver. D 2003 Elsevier B.V. All rights reserved.	adversary (cryptography);antivirus software;authentication protocol;communications protocol;computation;deniable authentication;diffie–hellman problem;digital signature;forge;interactivity	Zuhua Shao	2004	Computer Standards & Interfaces	10.1016/j.csi.2003.11.001	ring signature;otway–rees protocol;digital signature;computer science;cryptography;information security;authentication protocol;authentication;internet privacy;elgamal encryption;elgamal signature scheme;computer security;challenge-handshake authentication protocol;computer network	Security	-42.74756444551977	75.4520968072006	69721
2380dd19e53a4760c02e4c47c5540667504a8130	comparative analysis of distributed group key establishment protocols based on subgroup approach	routing protocols;protocols;comparative analysis;group communication applications comparative analysis distributed group key establishment protocols internet;group communication;distributed group key establishment protocols;protocols cryptography security servers routing protocols internet delay;servers;internet;cryptography;data transformation;protocols internet;security;group communication applications;key establishment;group communication internet	Nowadays, Internet has become the common media of communication. Many group communication applications can easily be conducted on the Internet. Some group communication applications pose strict requirement that in case of network partitions or on each join/leave event, a group key establishment protocol should not execute itself afresh. Although many group key establishment protocols have been proposed in the literature, yet nothing has been done to establish their suitability for aforementioned scenarios. In this paper, we present the succinct description of different decentralized group key establishment protocols based on independent subgroup key approach. And analyze them against parameters such as key independence, one-affects-all, local rekey, data transformation.	group key;internet;key exchange	Rakesh Chandra Gangwar;Anil K. Sarje	2008	2008 First International Conference on Emerging Trends in Engineering and Technology	10.1109/ICETET.2008.45	computer science;distributed computing;computer security;computer network	Networks	-48.077565757336046	76.7013750065849	69832
660fb956053c28ce5a03986a133eb6ce39993237	a new side-channel attack on rsa prime generation	side channel attack;rsa prime generation;key generation;side channel attacks	We introduce and analyze a side-channel attack on a straightforward implementation of the RSA key generation step. The attack exploits power information that allows to determine the number of the trial divisions for each prime candidate. Practical experiments are conducted, and countermeasures are proposed. For realistic parameters the success probability of our attack is in the order of 10–15 %.	countermeasure (computer);experiment;key generation;side-channel attack	Thomas Finke;Max Gebhardt;Werner Schindler	2009		10.1007/978-3-642-04138-9_11	chosen-ciphertext attack;timing attack;power analysis;md2;telecommunications;computer science;side channel attack;internet privacy;brute-force attack;computer security	Security	-39.506562979974184	79.33305486718979	69873
ab0d014d81d84799e1f7fb232a92ac4e7ab199e4	secure classical bit commitment using fixed capacity communication channels	relativite restreinte;relatividad restringida;unconditional security;criptografia cuantica;capacidad canal;cryptographie quantique;implementation;canal transmision;capacite canal;transmission message;securite donnee;message transmission;it security;taux transmission;quantum physics;channel capacity;canal transmission;transmission channel;relacion transmision;special relativity;bit commitment;transmission rate;mise en gage bit;quantum cryptography;implementacion;communication channels;security of data;transmision mensaje;relativistic cryptography	If mutually mistrustful parties A and B control two or more appropriately located sites, special relativity can be used to guarantee that a pair of messages exchanged by A and B are independent. In earlier work we used this fact to define a relativistic bit commitment protocol, RBC1, in which security is maintained by exchanging a sequence of messages whose transmission rate increases exponentially in time. We define here a new relativistic protocol, RBC2, which requires only a constant transmission rate and could be practically implemented. We prove that RBC2 allows a bit commitment to be indefinitely maintained with unconditional security against all classical attacks. We examine its security against quantum attacks, and show that it is immune from the class of attacks shown by Mayers and Lo-Chau to render non-relativistic quantum bit commitment protocols insecure.	commitment scheme;norm (social);qubit	Adrian Kent	2005	Journal of Cryptology	10.1007/s00145-005-0905-8	telecommunications;computer science;implementation;computer security;special relativity;channel capacity;quantum cryptography;channel	Crypto	-43.63960582286006	78.2301880087334	70111
1e251c4eee32115e47314894ce955668236d4f47	enhancements of a three-party password-based authenticated key exchange protocol	authenticated key exchange;dictionary attack;password-based;three-party	This paper discusses the security for a simple and efficient three-party password-based authenticated key exchange protocol proposed by Huang most recently. Our analysis shows her protocol is still vulnerable to three kinds of attacks: 1). undetectable on-line dictionary attacks, 2). key-compromise impersonation attack. Thereafter we propose an enhanced protocol that can defeat the attacks described and yet is reasonably efficient.	authenticated key exchange;authentication;dictionary attack;online and offline;password	Shuhua Wu;Kefei Chen;Yuefei Zhu	2013	Int. Arab J. Inf. Technol.		otway–rees protocol;oakley protocol;internet privacy;world wide web;computer security	Security	-44.618587301517145	74.75986512951587	70217
b101185880e6789ea9f468cf40faefc31d165456	mikey-sakke: sakai-kasahara key encryption in multimedia internet keying (mikey)		This document describes the Multimedia Internet KEYing-Sakai-Kasahara Key Encryption (MIKEY-SAKKE), a method of key exchange that uses Identity-based Public Key Cryptography (IDPKC) to establish a shared secret value and certificateless signatures to provide source authentication. MIKEY-SAKKE has a number of desirable features, including simplex transmission, scalability, low-latency call setup, and support for secure deferred delivery.	encryption;mikey;sakai project	Michael Groves	2012	RFC	10.17487/RFC6509	key;40-bit encryption;security association;computer science;internet privacy;pre-shared key;key distribution;computer security;encryption;probabilistic encryption;attribute-based encryption;computer network	Theory	-44.78735646833487	75.77540227994929	70262
a0f7d4fc85c528ce881f0ad7a5696a97fc341106	differential cryptanalysis of a reduced-round seed	block ciphering;characteristic;probability;information security;block cipher;cryptanalyse;cryptanalysis;criptoanalisis;differential attack;criptografia;cryptography;chiffrement bloc;differential cryptanalysis;cryptanalyse differentielle;symmetric block cipher;cifrado en bloque;cryptographie;seed	We analyze the security of the SEED block cipher against di erential attacks. SEED is a 16-round Feistel cipher developed by the Korea Information Security Agency. The SEED proposers estimated their cipher against di erential cryptanalysis in a self-estimation document and found a six-round di erential characteristic with probability 2 130 . We present an improved method of examining the di erential characteristics of SEED and show three six-round di erential characteristics with probability 2 124 . These characteristics allow us to attack seven-round SEED, which surpasses the proposers estimation. Our di erential attack needs 2 126 chosen-plaintext pairs and 2 126 computations of the F function to deduce the subkey used in the last round of seven-round SEED.	block cipher;computation;differential cryptanalysis;feistel cipher;information security;plaintext;seed	Hitoshi Yanami;Takeshi Shimoyama	2002		10.1007/3-540-36413-7_14	block cipher;cryptanalysis;differential cryptanalysis;computer science;cryptography;information security;theoretical computer science;probability;higher-order differential cryptanalysis;characteristic;computer security	Crypto	-39.29424044122146	82.02072625853617	70288
611f8a4217467e45fae660a61ee7d7951570d0a3	message transmission with reverse firewalls - secure communication on corrupted machines		Suppose Alice wishes to send a message to Bob privately over an untrusted channel. Cryptographers have developed a whole suite of tools to accomplish this task, with a wide variety of notions of security, setup assumptions, and running times. However, almost all prior work on this topic made a seemingly innocent assumption: that Alice has access to a trusted computer with a proper implementation of the protocol. The Snowden revelations show us that, in fact, powerful adversaries can and will corrupt users' machines in order to compromise their security. And, (presumably) accidental vulnerabilities are regularly found in popular cryptographic software, showing that users cannot even trust implementations that were created honestly. This leads to the following (seemingly absurd) question: Can Alice securely send a message to Bob even if she cannot trust her own computer?! Bellare, Paterson, and Rogaway recently studied this question. They show a strong lower bound that in particular rules out even semantically secure public-key encryption in their model. However, Mironov and Stephens-Davidowitz recently introduced a new framework for solving such problems: reverse rewalls. A secure reverse rewall is a third party that sits between Alice and the outside world and modi es her sent and received messages so that even if the her machine has been corrupted, Alice's security is still guaranteed. We show how to use reverse rewalls to sidestep the impossibility result of Bellare et al., and we achieve strong security guarantees in this extreme setting. Indeed, we nd a rich structure of solutions that vary in e ciency, security, and setup assumptions, in close analogy with message transmission in the classical setting. Our strongest and most important result shows a protocol that achieves interactive, concurrent CCA-secure message transmission with a reverse rewall i.e., CCA-secure message transmission on a possibly compromised machine! Surprisingly, this protocol is quite e cient and simple, requiring only four rounds and a small constant number of public-key operations for each party. It could easily be used in practice. Behind this result is a technical composition theorem that shows how key agreement with a su ciently secure reverse rewall can be used to construct a message-transmission protocol with its own secure reverse rewall.	alice and bob;computer security;encryption software;error-tolerant design;firewall (computing);public-key cryptography;secure communication;semantic security;snowden	Yevgeniy Dodis;Ilya Mironov;Noah Stephens-Davidowitz	2015		10.1007/978-3-662-53018-4_13	real-time computing;telecommunications	Crypto	-37.80056584884886	74.683411191868	70379
13f31775adb4a0b96b83681389c230214e4db006	some timestamping protocol failures	security protocol	Protocol failures are presented for two timestamping schemes. These failures emphasize the importance and di culty of implementing a secure protocol even though there exist secure underlying algorithms. As well, they indicate the importance of clearly de ning the goals for a protocol. For the scheme of Benaloh and de Mare (Eurocrypt '93), it is shown that although an indication of time can be included during the computation of the timestamp, the veri ation of the timestamp does not allow for the recovery of this temporal measure. For the scheme of Haber and Stornetta (Journal of Cryptology '91), we demonstrate how a collusion attack between a single user and a timestamping service allows for the backdating of timestamps. This attack is successful despite the claim that the timestamping service need not be trusted. For each of these schemes we discuss methods for improvement.	algorithm;authentication;basic stamp;born–haber cycle;centralized computing;communications protocol;computation;cryptography;cryptosystem;eurocrypt;existential quantification;journal of cryptology;paul van oorschot;requirement;trusted timestamping	Mike Just	1998			timestamp;computer science;collusion;computer security;cryptography;computation;otway–rees protocol;cryptographic protocol;distributed computing;timestamping	Crypto	-43.080827930349905	75.62493077063014	70407
3b3c17a0b776761be5aef5a6e98f76d5af769805	full security: fuzzy identity based encryption		At EUROCRYPT 2005, Sahai and Waters presented the Fuzzy Identity Based Encryption (Fuzzy-IBE) which could be used for biometrics and attribute-based encryption in the selective-identity model. When a secure Fuzzy-IBE scheme in the selective-identity model is transformed to full identity model it exist an exponential loss of security. In this paper, we use the CPA secure Gentry's IBE (exponent inversion IBE) to construct the first Fuzzy IBE that is fully secure without random oracles. In addition, the same technique is used to the modification of CCA secure Gentry's IBE which introduced by Kiltz and Vahlis to get the CCA secure Fuzzy IBE in the full-identity model.	attribute-based encryption;biometrics;eurocrypt;id-based encryption;time complexity	Liming Fang;Jinyue Xia	2008	IACR Cryptology ePrint Archive		encryption;fuzzy logic;theoretical computer science;exponential function;biometrics;deterministic encryption;probabilistic encryption;computer science;attribute-based encryption	Crypto	-39.99882563363958	76.99104970391245	70476
0bb29a8bf80dbe15bcf44367c481a7c742095a3e	fault tolerant authentication in mobile computing.	fault tolerant;mobile computer		authentication;mobile computing	Bharat K. Bhargava;Sarat Babu Kamisetty;Sanjay Kumar Madria	2000			computer network;fault tolerance;authentication;computer science;mobile computing	Mobile	-47.27570324043131	77.50284265767904	70705
a1ca9472cf3f2f0edc8d75bf6954c028327efc4e	toward wireless security without computational assumptions—oblivious transfer based on wireless channel characteristics	protocols;security oblivious transfer physical channel characteristics;oblivious transfer;general;channel estimation;probes;wireless communication;wireless devices wireless security computational assumptions wireless channel characteristics cryptographic tools cryptographic protocol polynomial time computable function 1 out of 2 oblivious transfer protocol private communications privacy preserving password verification;network protocols;communication networking and information technology;cryptography;protocols communication system security cryptography probes wireless communication channel estimation;physical channel characteristics;wireless channels computational complexity cryptographic protocols data privacy transport protocols;network level security and protection;security;communication system security;computer systems organization	Wireless security has been an active research area since the last decade. A lot of studies of wireless security use cryptographic tools, but traditional cryptographic tools are normally based on computational assumptions, which may turn out to be invalid in the future. Consequently, it is very desirable to build cryptographic tools that do not rely on computational assumptions. In this paper, we focus on a crucial cryptographic tool, namely 1-out-of-2 oblivious transfer. This tool plays a central role in cryptography because we can build a cryptographic protocol for any polynomial-time computable function using this tool. We present a novel 1-out-of-2 oblivious transfer protocol based on wireless channel characteristics, which does not rely on any computational assumption. We also illustrate the potential broad applications of this protocol by giving two applications, one on private communications and the other on privacy preserving password verification. We have fully implemented this protocol on wireless devices and conducted experiments in real environments to evaluate the protocol. Our experimental results demonstrate that it has reasonable efficiency.	computable function;computation;computational hardness assumption;cryptographic protocol;cryptography;experiment;oblivious transfer;password;time complexity;wireless security	Zhuo Hao;Yunlong Mao;Sheng Zhong;Erran L. Li;Haifan Yao;Nenghai Yu	2014	IEEE Transactions on Computers	10.1109/TC.2013.27	cryptographic primitive;communications protocol;security of cryptographic hash functions;computer science;information security;cryptographic protocol;internet privacy;computer security;computer network	Security	-46.796472925805425	76.39730784916371	70806
6a7fe59092a196b13d598cc27bcaf579245d6f09	a note on the random oracle methodology	tecnologia electronica telecomunicaciones;encryption scheme;computer model;signature scheme;random oracle model;necessary and sufficient condition;random oracle;tecnologias;grupo a;standard computational model	Canetti et al. [5] showed that there exist signature and encryption schemes that are secure in the random oracle (RO) model, but for which any implementation of the RO (by a single function or a function ensemble) results in insecure schemes. Their result greatly motivates the design of cryptographic schemes that are secure in the standard computational model. This paper gives some new results on the RO methodology. First, we give the necessary and sufficient condition for the existence of a signature scheme that is secure in the RO model but where, for any implementation of the RO, the resulting scheme is insecure. Next, we show that this condition induces a signature scheme that is insecure in the RO model, but that there is an implementation of the RO that makes the scheme secure.	random oracle	Mototsugu Nishioka;Naohisa Komatsu	2008	IEICE Transactions	10.1093/ietfec/e91-a.2.650	computer simulation;random oracle;computer science;theoretical computer science;mathematics;schnorr signature;computer security;algorithm	Crypto	-40.998930800807216	77.57316133652822	70835
142d2b8fe2f79a31052842c5fba7c53d681102e8	a general construction of tweakable block ciphers and different modes of operations	block ciphering;cryptage bloc;message authentication code;ae;securite informatique;linear feedback shift register;modes of operations;tweakable block cipher;anneau;authenticated encryption;computer security;masquage;criptografia;cryptography;enmascaramiento;seguridad informatica;automate cellulaire;mac;cifrado en bloque;registro dispersion;masking;cryptographie;ring;cellular automata;modes of operation;registre decalage;cellular automaton;shift register;aead;anillo;automata celular	This work builds on earlier work by Rogaway at Asiacrypt 2004 on tweakable block cipher (TBC) and modes of operations. Our first contribution is to generalize Rogaway's TBC construction by working over a ring and by the use of a masking sequence of functions. The ring can be instantiated as either GF or as . Further, over GF, efficient instantiations of the masking sequence of functions can be done using either a binary linear feedback shift register (LFSR); a powering construction; a cellular automata map; or by using a word-oriented LFSR. Rogaway's TBC construction was built from the powering construction over GF. Our second contribution is to use the general TBC construction to instantiate constructions of various modes of operations including authenticated encryption (AE) and message authentication code (MAC). In particular, this gives rise to a family of efficient one-pass AE modes of operation. Out of these, the mode of operation obtained by the use of word-oriented LFSR promises to provide a masking method which is more efficient than the one used in the well known AE protocol called OCB1.	asiacrypt;authenticated encryption;automata theory;block cipher mode of operation;cellular automaton;grammatical framework;instance (computer science);linear-feedback shift register;message authentication code;phillip rogaway;whole earth 'lectronic link	Debrup Chakraborty;Palash Sarkar	2006	IEEE Transactions on Information Theory	10.1007/11937807_8	message authentication code;cellular automaton;embedded system;telecommunications;computer science;cryptography;operating system;masking;distributed computing;shift register;linear feedback shift register;authenticated encryption;computer security;algorithm;ring	Crypto	-40.95254031517747	81.00983728765246	70963
307dc553e897981853845b6c846e81ba0f80ee99	the salsa20 family of stream ciphers	stream cipher	Salsa20 is a family of 256-bit stream ciphers designed in 2005 and submitted to eSTREAM, the ECRYPT Stream Cipher Project. Salsa20 has progressed to the third round of eSTREAM without any changes. The 20-round stream cipher Salsa20/20 is consistently faster than AES and is recommended by the designer for typical cryptographic applications. The reduced-round ciphers Salsa20/12 and Salsa20/8 are among the fastest 256-bit stream ciphers available and are recommended for applications where speed is more important than confidence. The fastest known attacks use ≈ 2 simple operations against Salsa20/7, ≈ 2 simple operations against Salsa20/8, and ≈ 2 simple operations against Salsa20/9, Salsa20/10, etc. In this paper, the Salsa20 designer presents Salsa20 and discusses the decisions made in the Salsa20 design.	cryptography;ecrypt;estream;fastest;stream cipher	Daniel J. Bernstein	2008		10.1007/978-3-540-68351-3_8	differential cryptanalysis;parallel computing;computer science;theoretical computer science;block size;key schedule;stream cipher attack;stream cipher;computer security	Crypto	-36.13621978749707	80.41667812295108	71044
298c3a477103d612860afd5a6a85d8058aa41a2e	an identity-based signature from gap diffie-hellman groups	public key cryptography;key management;cryptographie cle publique;elliptic curve;cle publique;diffie hellman protocol;gdh group;signature scheme;public key;protocole diffie hellman;id based signature;digital signature;criptografia;random oracle model;cryptography;weil pairing;identification;llave publica;signature numerique;cryptographie;identificacion;firma numerica;bilinear pairing;diffie hellman;public key infrastructure;identity based signature	In this paper we propose an identity(ID)-based signature scheme using gap Diffie-Hellman (GDH) groups. Our scheme is proved secure against existential forgery on adaptively chosen message and ID attack under the random oracle model. Using GDH groups obtained from bilinear pairings, as a special case of our scheme, we obtain an ID-based signature scheme that shares the same system parameters with the IDbased encryption scheme (BF-IBE) by Boneh and Franklin [BF01], and is as efficient as the BF-IBE. Combining our signature scheme with the BF-IBE yields a complete solution of an ID-based public key system. It can be an alternative for certificate-based public key infrastructures, especially when efficient key management and moderate security are required.	bilinear filtering;brainfuck;canonical account;computational diffie–hellman assumption;decisional diffie–hellman assumption;digital signature forgery;email;franklin electronic publishers;id-based encryption;key (cryptography);key escrow;key generation;key management;mobile phone;public key infrastructure;public-key cryptography;random oracle	Jae Choon Cha;Jung Hee Cheon	2002	IACR Cryptology ePrint Archive	10.1007/3-540-36288-6_2	merkle signature scheme;computer science;mathematics;internet privacy;public-key cryptography;computer security;algorithm	Crypto	-43.10874833528956	76.65955807514261	71384
489504545d71d914f841c338317422f1bdfaeb43	notions of black-box reductions, revisited		Reductions are the common technique to prove security of cryptographic constructions based on a primitive. They take an allegedly successful adversary against the construction and turn it into a successful adversary against the underlying primitive. To a large extent, these reductions are black-box in the sense that they consider the primitive and/or the adversary against the construction only via the input-output behavior, but do not depend on internals like the code of the primitive or of the adversary. Reingold, Trevisan, and Vadhan (TCC, 2004) provided a widely adopted framework, called the RTV framework from hereon, to classify and relate different notions of black-box reductions. Having precise notions for such reductions is very important when it comes to black-box separations, where one shows that black-box reductions cannot exist. An impossibility result, which clearly specifies the type of reduction it rules out, enables us to identify the potential leverages to bypass the separation. We acknowledge this by extending the RTV framework in several respects using a more fine-grained approach. First, we capture a type of reduction—frequently ruled out by so-called meta-reductions—which escapes the RTV framework so far. Second, we consider notions that are “almost black-box”, i.e., where the reduction receives additional information about the adversary, such as its success probability. Third, we distinguish explicitly between efficient and inefficient primitives and adversaries, allowing us to determine how relativizing reductions in the sense of Impagliazzo and Rudich (STOC, 1989) fit into the picture.	adversary (cryptography);black box;black-box testing;cryptography;many-one reduction;steven rudich;symposium on theory of computing	Paul Baecher;Christina Brzuska;Marc Fischlin	2013		10.1007/978-3-642-42033-7_16	theoretical computer science;mathematics;computer security;algorithm	Crypto	-37.33939012058803	76.23052868266886	71389
21600b7b1eb4de8d38856d570abbbdfc67a0c846	commitment and authentication systems	commitment;authentication;galois field.;unconditional security	In the present paper, we answer a question raised in the paper Constructions and Bounds for Unconditionally Secure Non-Interactive Commitment Schemes, by Blundo et al, 2002, showing that there is a close relation between unconditionally secure commitment schemes and unconditionally secure authentication schemes, and that an unconditionally secure commitment scheme can be built from such an authentication scheme and an unconditionally secure cipher system. This parallel is then used to analyse an attack against commitment schemes that is the counterpart of the impersonation attack in an authentication system. To investigate the opposite direction, we start by defining an optimal commitment system and showing that this must be a resolvable design commitment scheme as proposed in the aforementioned paper. Then, a proof is given that the resolvable design commitment schemes are a composition of an authentication system and a cipher system and the conclusion follows that this is the case for all optimal commitment systems. We also show how to build optimal schemes from transversal designs that are easy to build and can be more efficiently implemented than the proposal in the previously cited paper.	authentication;cipher;commitment scheme;man-in-the-middle attack	Alexandre Pinto;André Souto;Armando Matos;Luis Filipe Coelho Antunes	2009	Des. Codes Cryptography	10.1007/s10623-009-9303-1	galois theory;commitment scheme;computer science;authentication;mathematics;computer security;algebra	Crypto	-40.74929769024074	76.11591869070666	71532
24adb0b26e217574ce33b2d7c13d89a397360fe3	linear cryptanalysis of the tsc family of stream ciphers	metodo correlacion;approximation lineaire;cle secrete;mise a jour;stream ciphering;securite;correlation method;approximation algorithm;cryptanalyse;linear approximation;probabilistic approach;actualizacion;cryptanalysis;linear cryptanalysis;criptoanalisis;stream cipher;secret key;criptografia;clave secreta;enfoque probabilista;cryptography;approche probabiliste;safety;aproximacion lineal;security key;algoritmo aproximacion;registro dispersion;cryptographie;algorithme approximation;cle securite;seguridad;cifrado continuo;registre decalage;shift register;updating;methode correlation;llave seguridad;cryptage continu	In this paper, we introduce a new cryptanalysis method for stream ciphers based on T-functions and apply it to the TSC family which was proposed by Hong et al.. Our attack are based on linear approximations of the algorithms (in particular of the T-function). Hence, it is related to correlation attack, a popular technique to break stream ciphers with a linear update, like those using LFSR’s. We show a key-recovery attack for the two algorithms proposed at FSE 2005 : TSC-1 in 2 computation steps, and TSC-2 in 2 steps. The first attack has been implemented and takes about 4 minutes to recover the whole key on an average PC. Another algorithm in the family, called TSC-3, was proposed at the ECRYPT call for stream ciphers. Despite some differences with its predecessors, it can be broken by similar techniques. Our attack has complexity of 2 known keystream bits to distinguish it from random, and about 2 steps of computation to recover the full secret key. An extended version of this paper can be found on the ECRYPT website [23].	algorithm;approximation;comment (computer programming);computation;correlation attack;ecrypt;fast software encryption;key (cryptography);key escrow;key-recovery attack;least significant bit;linear cryptanalysis;linear-feedback shift register;personal computer;remote desktop services;stream cipher;t-function;tsc-3	Frédéric Muller;Thomas Peyrin	2005		10.1007/11593447_20	integral cryptanalysis;cryptanalysis;contact analysis;chosen-ciphertext attack;differential cryptanalysis;interpolation attack;telecommunications;xsl attack;computer science;cryptography;fluhrer, mantin and shamir attack;block size;key schedule;correlation attack;stream cipher attack;mathematics;shift register;s-box;stream cipher;t-function;slide attack;computer security;approximation algorithm;algorithm;statistics;linear approximation;linear cryptanalysis	Crypto	-40.36472993087668	82.45834624721691	71686
22a0912dec3585d0523efebda864ee11953e8119	efficient multi-party concurrent signature from lattices	multi party;sis;cryptography;concurrent signature;lattice	Concurrent signature is a novel paradigm, which can achieve fair exchange of signatures between users. Since its appearance, the topic has been widely concerned, while the study of concurrent signature in multi-user setting suffers from some criticism. Almost all known multi-user concurrent signature schemes rely on the hardness assumptions that is insecure against quantum analysis. Furthermore, most of multi-party concurrent signature (MCS) schemes are lacking of formal security models. In the paper, in the random oracle model, we propose a construction of lattice-based MCS scheme and prove its security under the hardness of the small integer solution (SIS) problem. Since our proposed scheme is based on the lattice assumptions, which is believed to be quantum-resistant, the mathematical properties make our scheme simpler and more flexible. A novel lattice-based concurrent signature in multi-user setting is proposed.Its security is proven in the random oracle model under the small integer solution assumption.It can be immune to quantum analysis.		Xinyin Xiang;Hui Li;Mingyu Wang;Xingwen Zhao	2016	Inf. Process. Lett.	10.1016/j.ipl.2016.02.007	discrete mathematics;cryptography;theoretical computer science;lattice;mathematics;schnorr signature;algorithm	DB	-39.264458967362785	76.01899098224395	71827
15266148ef27b0a7f6fa255de74b7fe972da3fed	towards strong adaptive corruption security of authenticated key exchange			authenticated key exchange;authentication		2011	IACR Cryptology ePrint Archive			Crypto	-43.862968996359655	75.81763080849576	71866
858516d364d796302e91ce7d0d413bb2b79b1f11	constant phase efficient protocols for secure message transmission in directed networks	networks and distributed systems;theoretical foundations;information theoretic security	We present efficient protocols for Perfectly Secure Message Transmission (PSMT) in directed wire model where a sender S and a receiver R are connected by directed wires. We assume that n wires are directed from S to R (also termed as top band) and u wires are directed from R to S (also termed as bottom band) and out of these u + n wires, at most t wires are under the control of a Byzantine adversary having unbounded computing power. Also the wires in the top band and bottom band are disjoint. S wishes to send a message m from a finite field F in a perfectly secure manner to R and the perfect security here means that the adversary gets no information whatsoever on m, though he has unbounded computing power. In [1], Desmedt et.al. showed that PSMT is possible in such a network iff n = max{3t − 2u + 1, 2t + 1} and presented an exponential phase protocol (and hence exponential communication and computational complexity), where a phase is a send from S to R or vice-versa. They also proposed a polynomial phase PSMT protocol if n = max{3t − u + 1, 2t + 1}. We significantly improve both the protocols. Specifically our first protocol runs in three phases and has a communication complexity of O(nu) while our second protocol further reduces the communication complexity to O(n). In our protocols, we have used Reed-Solomon codes [2] whose error correcting and detecting capability is as follows:	adversary (cryptography);byzantine fault tolerance;code;communication complexity;computational complexity theory;exponential time hypothesis;information-theoretic security;polynomial;reed–solomon error correction;sensor;time complexity	Arpita Patra;Ashish Choudhury;C. Pandu Rangan	2007		10.1145/1281100.1281153	information-theoretic security;computer science;theoretical computer science;distributed computing;computer network	Crypto	-36.65274682994545	77.1330191861371	72267
31f5c8d98160ea0579689fe208e1cbe32abf9865	on improvements to password security	mot passe;public key cryptography;protection information;securite;cle publique;public key;cryptography;information protection;safety;cryptographie;password authentication;value of information;user authentication;exhaustive search;securidad	Due to the increasing value of information being stored in computers, it is important that unforgeable user authentication policies are implemented. Existing password authentication schemes, threats and counter-measures are described. A solution to eavesdropping problems using public-key cryptography is proposed. A technique to allow long password-phrases that makes an exhaustive search impracticable is presented.	authentication;brute-force search;computer;passphrase;password;public-key cryptography	Kamaljit Singh	1985	Operating Systems Review	10.1145/1041490.1041496	zero-knowledge password proof;cognitive password;password policy;s/key;challenge–response authentication;computer science;authentication protocol;internet privacy;public-key cryptography;one-time password;world wide web;password;computer security;password strength	Security	-43.82183910932646	77.63155955451201	72307
4364c5608afa66c44b8ed54c4c05300250b76485	key agreement protocols based on multivariate polynomials over fq		In this paper we propose new key agreement protocols based on multivariate polynomials over finite field Fq. We concretely generate the multivariate polynomial F(X)∈Fq[x1,..,xn] such that F(X)=Σi=1 m ki[Ai(X) d + Ai(X) d-1 + ..+ Ai(X)] where Ai(X) =ai1x1+...+ainxn ,coefficients ki , aij ∈ Fq (i=1,..,m:j=1,..,n) and variables X=(x1,..,xn) T ∈ Fq[x1,..,xn] . The common key K(X) has the form such that K(X)=Σi=1 m hi F((bi1x1,...,binxn) T ) where hi ,bij ∈Fq (i=1,..,m:j=1,..,n) to be the temporary secret keys of the partner . Our system is immune from the Gröbner bases attacks because obtaining coefficients of F(X) to be secret keys arrives at solving the multivariate algebraic equations, that is, one of NP complete problems .Our protocols are also thought to be immune from the differential attacks because of the equations of high degree.	algebraic equation;coefficient;differential cryptanalysis;gröbner basis;key (cryptography);key-agreement protocol;np-completeness;polynomial	Masahiro Yagisawa	2010	IACR Cryptology ePrint Archive		np-complete;algebra;multivariate statistics;polynomial;mathematics;finite field;algebraic equation	Crypto	-40.048173563224445	79.96292004600669	72322
3b7d4547ef7e28dc3ce6974b141a4b85ee96f410	new results on the genetic cryptanalysis of tea and reduced-round versions of xtea	block cipher;genetics;distinguishers;cryptanalysis;block ciphers;genetic algorithm;xtea;hash function;tea	Recently, a quick and simple way of creating very efficient distinguishers for cryptographic primitives such as block ciphers or hash functions, was presented and proved useful by the authors. In this paper, this cryptanalytic attack (named genetic cryptanalysis after its use of genetic algorithms) is shown to be successful when applied over reduced-round versions of the block cipher XTEA. Efficient distinguishers for XTEA are proposed for up to 4 cycles (8 rounds). Additionally, a variant of this genetic attack is also introduced, and their results over the block cipher TEA presented, which are the most powerful published to date.	block cipher;cryptanalysis;cryptographic primitive;cryptography;genetic algorithm;hash function;tea	Julio César Hernández Castro;Pedro Isasi Viñuela	2005	New Generation Computing	10.1007/BF03037657	block cipher;differential cryptanalysis;computer science;theoretical computer science;boomerang attack;higher-order differential cryptanalysis;impossible differential cryptanalysis;algorithm;mdc-2;linear cryptanalysis	Crypto	-36.84031625507236	81.62638851686778	72336
461aa44f2826f494c3d84150b60545336d76b7b1	block ciphers sensitive to groebner basis attacks	block ciphering;cryptage bloc;approximation lineaire;metodo diferencial;securite;block cipher;analizador diferencial;cryptanalyse;grobner basis;linear approximation;algebraic attack;base grobner;grobner bases;differential method;equation polynomiale;polynomial equation;cryptanalysis;criptoanalisis;sound design;analyseur differentiel;ecuacion polinomial;criptografia;cryptography;safety;aproximacion lineal;differential analyzer;security key;methode differentielle;cifrado en bloque;cryptographie;cle securite;seguridad;llave seguridad	We construct and analyze Feistel and SPN ciphers that have a sound design strategy against linear and differential attacks but for which the encryption process can be described by very simple polynomial equations. For a block and key size of 128 bits, we present ciphers for which practical Gröbner basis attacks can recover the full cipher key requiring only a minimal number of plaintext/ciphertext pairs. We show how Gröbner bases for a subset of these ciphers can be constructed with neglegible computational effort. This reduces the key–recovery problem to a Gröbner basis conversion problem. By bounding the running time of a Gröbner basis conversion algorithm, FGLM, we demonstrate the existence of block ciphers resistant against differential and linear cryptanalysis but vulnerable against Gröbner basis attacks.	algorithm;block cipher;ciphertext;differential cryptanalysis;encryption;feistel cipher;gröbner basis;key escrow;key size;known-plaintext attack;lexicographical order;lexicography;linear cryptanalysis;modulo operation;plaintext;polynomial ring;substitution-permutation network;system of polynomial equations;time complexity	Johannes A. Buchmann;Andrei Pychkine;Ralf-Philipp Weinmann	2005		10.1007/11605805_20	differential cryptanalysis;discrete mathematics;block size;key schedule;avalanche effect;higher-order differential cryptanalysis;correlation attack;mathematics;s-box;t-function;algorithm;ciphertext;algebra;linear cryptanalysis	Crypto	-40.0630848737639	81.2567253874684	72557
ad5646f257730d6f247a2dea2f65fee2857b2111	cryptanalysis of hash-based tamed transformation and minus signature scheme	algebraic attack;hash-based tamed transformation;minus method;multivariate public key cryptosystem	In 2011, wang et al. proposed a security enhancement method of Multivariate Public Key Cryptosystems (MPKCs), named Extended Multivariate public key Cryptosystems (EMC). They introduced more variables in an original MPKC by a so-called Hash-based Tamed (HT) transformation in order to resist existing attack on the original MPKC. They proposed Hash-based Tamed Transformation and Minus (HTTM) signature scheme which combined EMC method with minus method. Through our analysis, the HTTM is not secure as they declared. If we can forge a valid signature of the original MPKC-minus signature scheme, we could forge a valid signature of HTTM scheme successfully. © 2013 Springer-Verlag.	cryptanalysis;scheme	Xuyun Nie;Zhaohu Xu;Johannes A. Buchmann	2013		10.1007/978-3-642-38616-9_10	security enhancement;public-key cryptography;cryptosystem;hash function;theoretical computer science;cryptanalysis;computer science	Crypto	-40.59611830268895	77.85150976768885	72616
d878fb5a7d1ea14649f590de5ebb806d1414f0b6	highly-scalable searchable symmetric encryption with support for boolean queries		This work presents the design, analysis and implementation of the first searchable symmetric encryption (SSE) protocol that supports conjunctive search and general Boolean queries on outsourced symmetrically-encrypted data and that scales to very large databases and arbitrarilystructured data including free text search. To date, work in this area has focused mainly on single-keyword search. For the case of conjunctive search, prior dedivated SSE constructions (not using generic technique such as FHE or ORAM) required work linear in the total number of documents in the database and provided good privacy only for structured attribute-value data, rendering these solutions too slow and inflexible for large practical databases. In contrast, our solution provides a realistic and practical trade-off between performance and privacy by efficiently supporting very large databases at the cost of moderate and welldefined leakage to the outsourced server (leakage is in the form of data access patterns, never as direct exposure of plaintext data or searched values). Our design follows a careful process of trading security for efficiency which are both quantified via rigorous analysis. We present a detailed formal cryptographic analysis of the privacy and security of our protocols and establish precise upper bounds on the allowed leakage. To demonstrate the real-world practicality of our approach, we provide performance results of a prototype applied to several large representative data sets, including encrypted search over the whole English Wikipedia (and beyond). This is the full version of the paper with same title appearing at Crypto’2013. Rutgers U. Email: david.cash@cs.rutgers.edu. U. California Irvine. Email: stasio@ics.uci.edu. IBM Research. Email: csjutla@us.ibm.com IBM Research. Email: hugo@ee.technion.ac.il IBM Research. Email: marcelrosu@gmail.com IBM Research. Email: steiner@acm.org	black box;boolean algebra;computation;cryptanalysis;cryptography;data access;database;deterministic encryption;differential privacy;dummy variable (statistics);email;encryption;ibm research;information leakage;input/output;merge sort;outsourcing;plaintext;precomputation;privacy;prototype;requirement;result set;scalability;search algorithm;server (computing);sorting;spectral leakage;symmetric-key algorithm;text corpus;wikipedia;x terminal;yet another	David Cash;Stanislaw Jarecki;Charanjit S. Jutla;Hugo Krawczyk;Marcel-Catalin Rosu;Michael Steiner	2013	IACR Cryptology ePrint Archive	10.1007/978-3-642-40041-4_20	discrete mathematics;theoretical computer science;distributed computing;probabilistic encryption	Crypto	-34.84208790907158	76.32171517400579	72690
86f129526f0b3836c9282410ebc13f48468437cd	srmap and islap authentication protocols: attacks and improvements		RFID technology is a system which uses radio frequency to transmit data. Data transmission between Tags and Readers is wireless which can be easily eavesdropped by adversary. Due to security and privacy reasons, various authentication protocols proposed. In this paper, we cryptanalyze two different RFID authentication protocols and it is shown that either of them have some weaknesses. In 2014, Chang et al. proposed a mutual authentication protocol for RFID technology based on EPC Class 1 Generation 2 standard. We show that their protocol is not safe regard to privacy and cannot repulse neither Traceability attack nor Forward Traceability attack. Also, in 2015, Pourpouneh et al. proposed a server-less authentication protocol. We discover that their protocol is not able to thwart security and privacy attacks such as Secret Parameter Reveal, Traceability and Forward Traceability. In addition, we robust the two schemes to defend those attacks which can protect RFID users against different threats. Then, analyzing of the protocols are compared with some state-of-art ones.	adversary (cryptography);authentication protocol;computer security;electronic product code;mutual authentication;radio frequency;radio-frequency identification;server (computing);traceability	Mohammad Mardani Shahrbabak;Shahab Abdolmaleky	2016	IACR Cryptology ePrint Archive		lightweight extensible authentication protocol;authentication protocol;computer network;computer science	Security	-46.33274643627432	74.54598509087963	72692
32e5be067a7e962c9acb25460c438e427a90142e	deniable encryption with negligible detection probability: an interactive construction	detection probability;multi party computation;public key encryption;public key;deniable encryption;electronic voting	Deniable encryption, introduced in 1997 by Canetti, Dwork, Naor, and Ostrovsky, guarantees that the sender or the receiver of a secret message is able to “fake” the message encrypted in a specific ciphertext in the presence of a coercing adversary, without the adversary detecting that he was not given the real message. To date, constructions are only known either for weakened variants with separate “honest” and “dishonest” encryption algorithms, or for single-algorithm schemes with non-negligible detection probability. We propose the first sender-deniable public key encryption system with a single encryption algorithm and negligible detection probability. We describe a generic interactive construction based on a public key bit encryption scheme that has certain properties, and we give two examples of encryption schemes with these properties, one based on the quadratic residuosity assumption and the other on trapdoor permutations.	adversary (cryptography);algorithm;algorithmic efficiency;ciphertext;computation;computational complexity theory;correctness (computer science);cryptographic protocol;cryptosystem;cynthia dwork;deniable encryption;embedded system;integer factorization;key (cryptography);learning with errors;one-time pad;overhead (computing);public-key cryptography;quadratic residue;quadratic residuosity problem;randomness;requirement;security parameter;sensor;trapdoor function;trusted third party	Markus Dürmuth;David Mandell Freeman	2011	IACR Cryptology ePrint Archive	10.1007/978-3-642-20465-4_33	multiple encryption;watermarking attack;disk encryption theory;40-bit encryption;plaintext-aware encryption;client-side encryption;computer science;deniable encryption;link encryption;distributed computing;on-the-fly encryption;internet privacy;public-key cryptography;deterministic encryption;computer security;encryption;probabilistic encryption;three-pass protocol;56-bit encryption;attribute-based encryption	Crypto	-40.19702684861561	75.40923084500456	72758
629998eed2e4d8faf5f181b43d10560b8d8353ca	linear cryptanalysis: key schedules and tweakable block ciphers	key schedule;tweakable block cipher;linear cryptanalysis;hypothesis of independent round keys	This paper serves as a systematization of knowledge of linear cryptanalysis and provides novel insights in the areas of key schedule design and tweakable block ciphers. We examine in a step by step manner the linear hull theorem in a general and consistent setting. Based on this, we study the influence of the choice of the key scheduling on linear cryptanalysis, a – notoriously difficult – but important subject. Moreover, we investigate how tweakable block ciphers can be analyzed with respect to linear cryptanalysis, a topic that surprisingly has not been scrutinized until now.		Thorsten Kranz;Friedrich Wiemer;Gregor Leander	2017	IACR Trans. Symmetric Cryptol.	10.13154/tosc.v2017.i1.474-505	block cipher;contact analysis;differential cryptanalysis;interpolation attack;piling-up lemma;theoretical computer science;block size;key schedule;boomerang attack;higher-order differential cryptanalysis;mathematics;s-box;impossible differential cryptanalysis;computer security;algorithm;linear cryptanalysis	Crypto	-37.875789327913864	79.12168526750658	72873
06a4a18ff3f3f2604e72ee926a223d513aeffec0	lattice-based snargs and their application to more efficient obfuscation		Succinct non-interactive arguments (SNARGs) enable verifying NP computations with substantially lower complexity than that required for classical NP verification. In this work, we first construct a lattice-based SNARG candidate with quasi-optimal succinctness (where the argument size is quasilinear in the security parameter). Further extension of our methods yields the first SNARG (from any assumption) that is quasi-optimal in terms of both prover overhead (polylogarithmic in the security parameter) as well as succinctness. Moreover, because our constructions are lattice-based, they plausibly resist quantum attacks. Central to our construction is a new notion of linear-only vector encryption which is a generalization of the notion of linear-only encryption introduced by Bitansky et al. (TCC 2013). We conjecture that variants of Regev encryption satisfy our new linear-only definition. Then, together with new information-theoretic approaches for building statistically-sound linear PCPs over small finite fields, we obtain the first quasi-optimal SNARGs. We then show a surprising connection between our new lattice-based SNARGs and the concrete efficiency of program obfuscation. All existing obfuscation candidates currently rely on multilinear maps. Among the constructions that make black-box use of the multilinear map, obfuscating a circuit of even moderate depth (say, 100) requires a multilinear map with multilinearity degree in excess of 2. In this work, we show that an ideal obfuscation of both the decryption function in a fully homomorphic encryption scheme and a variant of the verification algorithm of our new lattice-based SNARG yields a general-purpose obfuscator for all circuits. Finally, we give some concrete estimates needed to obfuscate this “obfuscation-complete” primitive. We estimate that at 80-bits of security, a (black-box) multilinear map with ≈ 2 levels of multilinearity suffices. This is over 2 times more efficient than existing candidates, and thus, represents an important milestone towards implementable program obfuscation for all circuits.	algorithm;black box;computation;general-purpose modeling;homomorphic encryption;information theory;interactivity;lattice model (finance);lattice-based cryptography;obfuscation (software);offset binary;overhead (computing);polylogarithmic function;security parameter;verification and validation	Dan Boneh;Yuval Ishai;Amit Sahai;David J. Wu	2017	IACR Cryptology ePrint Archive	10.1007/978-3-319-56617-7_9	conjecture;discrete mathematics;encryption;succinctness;boolean circuit;computer science;lattice (order);security parameter;homomorphic encryption;finite field	Crypto	-37.756466451909404	76.49707545627078	73083
32248f07a003e78f67ee728ef07c22e09100e054	single-round pattern matching key generation using physically unclonable function		Paral and Devadas introduced a simple key generation scheme with a physically unclonable function (PUF) that requires no error correction, e.g., by using a fuzzy extractor. Their scheme, called a pattern matching key generation (PMKG) scheme, is based on pattern matching between auxiliary data, assigned at the enrollment in advance, and a substring of PUF output, to reconstruct a key. The PMKG scheme repeats a round operation, including the pattern matching, to derive a key with high entropy. Later, to enhance the efficiency and security, a circular PMKG (C-PMKG) scheme was proposed. However, multiple round operations in these schemes make them impractical. In this paper, we propose a single-round circular PMKG (SC-PMKG) scheme. Unlike the previous schemes, our scheme invokes the PUF only once. Hence, there is no fear of information leakage by invoking the PUF with the (partially) same input multiple times in different rounds, and, therefore, the security consideration can be simplified. Moreover, we introduce another hash function to generate a check string which ensures the correctness of the key reconstruction. The string enables us not only to defeat manipulation attacks but also to prove the security theoretically. In addition to its simple construction, the SC-PMKG scheme can use a weak PUF like the SRAM-PUF as a building block if our system is properly implemented so that the PUF is directly inaccessible from the outside, and, therefore, it is suitable for tiny devices in the IoT systems. We discuss its security and show its feasibility by simulations and experiments.		Yuichi Komano;Kazuo Ohta;Kazuo Sakiyama;Mitsugu Iwamoto;Ingrid Verbauwhede	2019	Security and Communication Networks	10.1155/2019/1719585	algorithm;computer network;computer science;error detection and correction;pattern matching;hash function;correctness;information leakage;physical unclonable function;key generation;substring	Crypto	-35.45840657834785	75.39550259386665	73188
6e3282e2a295111bd575edecb85b5a2189338d8c	an agent-based model of anonymous communication protocols	protocols;information security;information science;protocols relays information technology research and development information security information science;authorisation;information technology;agent based model;anonymous communication;authorisation protocols;research and development;relay nodes;anonymous communication model;relay nodes anonymous communication protocols agent based model anonymous communication model;relays;anonymous communication protocols	So far various anonymous communication protocols have been proposed independently and aimed at different situations. As a result, it is hard to understand the essential structures ofthose protocols and each protocol must be evaluated and implemented independently. To solve these problems, we propose an anonymous communication model that can represent a wide variety of anonymous protocols. In our model, we introduce agents that work in cooperation to realize anonymous conimunication. This modeling is based on the observation that most of practical anonymous protocols have much commonality in that they have several relay nodes en route from the sender to the receiver to provide anonymity. On our model, such agents’ behaviors are expressed in a small set of primitive functions. Using these primitive functions, the essential structures of anonymous communication protocols can be described clearly.	agent-based model;communications protocol;degree of anonymity;relay	Shigeki Kitazawa;Masakazu Soshi;Atsuko Miyaji	2001		10.1109/ENABL.2001.953410	communications protocol;universal composability;information science;computer science;information security;authorization;internet privacy;information technology;computer security;computer network	Security	-47.305292614676844	77.0181894415165	73335
90abb38d6b70f696e1fb525c217ea10c8613bdc6	finding vulnerable curves over finite fields of characteristic 2 by pairing reduction		In this paper, we aim at sustaining the claim that curve-based cryptographic schemes over finite fields of characteristic 2 do not provide enough security. We present algorithms to find all the possible supersingular elliptic curves which can be embedded into a predefined finite field. We also consider the case of hyperelliptic curves with genus 2, including both supersingular and ordinary cases. As computational examples, we show even the DLP on a 3060-bit elliptic curve and the DLP on Jacobians of a 255-bit hyperelliptic curve can be solved by embedding to a 6120-bit extension field.	algorithm;cryptography;digital light processing;embedded system;genus (mathematics)	Yuhong Zhang Lmam;Meng Zhang Lmam;Maozhi Xu Lmam	2017	2017 IEEE/ACIS 16th International Conference on Computer and Information Science (ICIS)	10.1109/ICIS.2017.7960080	discrete mathematics;jacobian curve;counting points on elliptic curves;hessian form of an elliptic curve;twists of curves;supersingular elliptic curve;mathematics;hyperelliptic curve;edwards curve;hyperelliptic curve cryptography	Crypto	-39.45397989312544	81.0861097999612	73424
d4e6fa2b07f07baeeed84b66a5558574ff4090a0	improved linear analysis on block cipher multi2	bias;block cipher;feistel structure;linear analysis;multi2	Developed by Hitachi, MULTI2 is a block cipher used mainly to secure the multimedia content. It was registered in ISO/IEC 9979 and was patented in US and Japan. MULTI2 uses the Feistel structure and operates on the 64-bit blocks. The encryption key has 256 bits. This paper studies the linear analysis on MULTI2. We give a detailed bias analysis on MULTI2 round functions. For the first time formal proofs on their bias properties are given. This allows to find a new 4-round bias 2-2. Previously, the best 4-round bias 2-5.7 was proposed. Using our results on the MULTI2 round functions, we propose the linear attacks on r-round MUTLI2 to recover the encryption key. Our linear attack can recover the 256-bit encryption key in time 246, 2 60.4, 283.8, 291.7, 2123.4, 2 123.2 of r-round encryptions for r = 8, 12, 16, 20, 24, 28 respectively. Further, we can recover the 32-bit sub-key in last round much faster than the whole encryption key recovery, i.e., in time 237 for r = 8, 12, 16, 20, 24. Note that previously, the best linear key-recovery attack was a 20-round attack with time 293.4 (of 20-round encryptions) and data 239.2. As ISO register recommends to use at least 32 rounds, our attacks remain to be theoretical and do not threaten security for the practical use currently. © Springer-Verlag 2012.		Yi Lu;Liping Ding;Yongji Wang	2012		10.1007/978-3-642-35404-5_7	substitution-permutation network;block cipher;key whitening;residual block termination;two-square cipher;ciphertext stealing;stream cipher;affine cipher;cbc-mac;mdc-2	Crypto	-36.98480766255974	79.15509230977987	73549
7f23a87f3ad6d379d76150e9d9775b709117e560	identity-based zero knowledge	non interactive zero knowledge;zero knowledge	We introduce and define the notion of identity-based zeroknowledge, concentrating on the non-interactive setting. In this setting, our notion allows any prover to widely disseminate a proof of a statement while protecting the prover from plagiarism in the following sense: although proofs are transferable (i.e., publicly verifiable), they are also bound to the identity of the prover in a way which is recognizable to any verifier. Furthermore, an adversary is unable to change this identity (i.e., to claim the proof as his own, or to otherwise change the authorship), unless he could have proved the statement on his own. While we view the primary contribution of this work as a formal definition of the above notion, we also explore the relation of this notion to that of non-malleable (non-interactive) zero-knowledge. On the one hand, we show that these two notions are incomparable: that is, there are proof systems which are non-malleable but not identity-based, and vice versa. On the other hand, we show that a proof system of either type essentially implies a proof system of the other type. ⋆ Work done while this author was at Columbia University. ⋆⋆ Supported in part by a gift from Teradata and Intel equipment grant	adversary (cryptography);columbia (supercomputer);formal verification;interactivity;proof calculus;tagged union;zero-knowledge proof	Jonathan Katz;Rafail Ostrovsky;Michael O. Rabin	2004		10.1007/978-3-540-30598-9_13	computer science;proof of knowledge;algorithm;zero-knowledge proof	Crypto	-37.649899384347634	75.23600252962413	73594
3085505027cd9fa77c783b11b88464bb76275914	embedding distance-bounding protocols within intuitive interactions	trust;securite;pervasive computing;authentication;token protocol;protocole jeton;ease of use;authentification;autenticacion;informatique diffuse;eurecom ecole d ingenieur telecommunication centre de recherche graduate school research center communication systems;safety;access control;seguridad;drag and drop;distance bounding protocols	Although much research was conducted on devising intuitive interaction paradigms with pervasive computing devices, it has not been realized that authentication, an important need in this context, has a strong impact on the ease of use. More specifically, distance-bounding protocols are necessary in some of the most interesting scenarios in pervasive computing. This article describes a drag-and-drop interaction paradigm that enables strong authentication by embedding such a protocol within personal authentication tokens. This article also discusses how this paradigm can be used as the basis for performing user-friendly pervasive multi-party secure interactions.	access control;distance-bounding protocol;drag and drop;hoc (programming language);ieee internet computing;interaction;pervasive informatics;programming paradigm;pseudonymity;public key infrastructure;public-key cryptography;replay attack;software appliance;strong authentication;tamper resistance;ubiquitous computing;usability	Laurent Bussard;Yves Roudier	2003		10.1007/978-3-540-39881-3_14	context-aware pervasive systems;simulation;computer science;artificial intelligence;operating system;authentication;database;distributed computing;world wide web;computer security;ubiquitous computing;algorithm	HCI	-45.04424126381359	77.31425827976656	73692
296c1e06791d4330045959247c88e1b7c9845140	password mistyping in two-factor-authenticated key exchange	authenticated key exchange;key exchange	We study the problem of Key Exchange (KE), where authentication is two-factor and based on both electronically stored long keys and human-supplied credentials (passwords or biometrics). The latter credential has low entropy and may be adversarily mistyped. Our main contribution is the first formal treatment of mistyping in this setting. Ensuring security in presence of mistyping is subtle. We show mistypingrelated limitations of previous KE definitions and constructions (of Boyen et al. [7, 6, 10] and Kolesnikov and Rackoff [16]). We concentrate on the practical two-factor authenticated KE setting where servers exchange keys with clients, who use short passwords (memorized) and long cryptographic keys (stored on a card). Our work is thus a natural generalization of Halevi-Krawczyk [15] and Kolesnikov-Rackoff [16]. We discuss the challenges that arise due to mistyping. We propose the first KE definitions in this setting, and formally discuss their guarantees. We present efficient KE protocols and prove their security.	authenticated key exchange;biometrics;credential;cryptography;key (cryptography);knowledge engineering;multi-factor authentication;password	Vladimir Kolesnikov;Charles Rackoff	2008	IACR Cryptology ePrint Archive	10.1007/978-3-540-70583-3_57	key exchange;computer science;internet privacy;world wide web;computer security	Crypto	-41.684007500383984	75.68741678405515	73693
1be0785d818da3f3f572aa03603e8e8eb8b4a9cf	one-round authenticated key exchange without implementation trick		Fujioka et al. proposed the first generic construction (FSXY construction) of exposure-resilient authenticated key exchange (AKE) from key encapsulation mechanism (KEM) without random oracles. However, the FSXY construction implicitly assumes some intermediate computation result is never exposed though other secret information can be exposed. This is a kind of physical assumption, and an implementation trick (i.e., some on-line computation is executed in a special tamper-proof module) is necessary to achieve the assumption. Unfortunately, such an implementation trick is very costly and should be avoided. In this paper, we introduce a new generic construction without the implementation trick. Our construction satisfies the same security model as the FSXY construction without increasing communication complexity. Moreover, it has another advantage that the protocol can be executed in one-round while the FSXY construction is a sequential two-move protocol. Our key idea is to use KEM with public-key-independent-ciphertext, which allows parties to be able to generate a ciphertext without depending on encryption keys.	authenticated key exchange;authentication	Kazuki Yoneyama	2013		10.1007/978-3-642-41383-4_18	computer security model;computer security;internet privacy;ciphertext;computer science;computation;key (lock);encryption;key encapsulation;authenticated key exchange;communication complexity;distributed computing	Crypto	-39.10009393920645	74.95335007248698	74231
85ad6f704deed40915e8a8de91dc4d5f021019fa	oblivious transfer with adaptive queries	confidencialidad;oblivious transfer;securite;confidentiality;confidentialite;criptografia;cryptography;safety;random oracle;cryptographie;seguridad	We provide protocols for the following two-party problem: One party, the sender, has N values and the other party, the receiver, would like to learn k of them, deciding which ones in an adaptive manner (i.e. the ith value may depend on the first i− 1 values). The sender does not want the receiver to obtain more than k values. This is a variant of the well known Oblivious Transfer (OT) problem and has applications in protecting privacy in various settings. We present efficient protocols for the problem that require an O(N) computation in the preprocessing stage and fixed computation (independent of k) for each new value the receiver obtains. The on-line computation involves roughly log N invocations of a 1-out-2 OT protocol. The protocols are based on a new primitive, sum consistent synthesizers.	computation;oblivious transfer;online and offline;preprocessor;whole earth 'lectronic link	Moni Naor;Benny Pinkas	1999		10.1007/3-540-48405-1_36	random oracle;confidentiality;computer science;cryptography;theoretical computer science;oblivious transfer;distributed computing;computer security;algorithm	Crypto	-42.5423589148862	77.71249510837434	74483
c1f7d8fc1a153bef6db43598fe6201ba4b9ca09d	running compression algorithms in the encrypted domain: a case-study on the homomorphic execution of rle		This paper is devoted to the study of the problem of running compression algorithms in the encrypted domain, using a (somewhat) fully homomorphic encryption (FHE) scheme. We do so with a particular focus on conservative compression algorithms. Despite of the encrypted domain Turingcompleteness which comes with the magic of FHE operators, we show that a number of subtleties crop up when it comes to running compression algorithms and, in particular, that guaranteed conservative compression is not possible to achieve in the FHE setting. To illustrate these points, we analyze the most elementary conservative compression algorithm of all, namely Run-Length Encoding (RLE). We first study the way to regularize this algorithm in order to make it (meaningfully) fit within the constraints of a FHE execution. Secondly, we analyze it from the angle of optimizing the resulting structure towards (as much as possible) FHE execution efficiency. The paper is concluded by concrete experimental results obtained using the Fan-Vercauteren cryptosystem as well as the Armadillo FHE compiler. It is also this paper intent to share the concrete return on experience we gained in attempting to run a simple yet practically significant algorithm over FHE.	algorithm;armadillo;compiler;cryptosystem;data compression;homomorphic encryption;performance;programmer;run-length encoding	Sébastien Canard;Sergiu Carpov;Donald Nokam Kuate;Renaud Sirdey	2017	2017 15th Annual Conference on Privacy, Security and Trust (PST)	10.1109/PST.2017.00041	compiler;computer security;operator (computer programming);computer science;encryption;data compression;cryptosystem;theoretical computer science;homomorphic encryption;compression (physics)	Theory	-35.36670645226001	78.40982943367824	74494
033020b51c7cec877966fa607a75f89a7ba8d150	a communication-efficient and fault-tolerant conference-key agreement protocol with forward secrecy	provable security;forward secrecy;fault tolerant;decisional diffie hellman;and forward;random oracle model;fault tolerance;key agreement;key agreement protocol;security;key establishment;conference key agreement;key distribution	A conference-key establishment protocol allows participants to construct a common session key that is used to encrypt/decrypt transmitted messages among the participants over an open channel. There are two kinds of conference-key establishment protocols: conference-key distribution and conference-key agreement. In a conference-key distribution protocol, a trusted or elected entity is responsible for generating and distributing the conference key. A conference-key agreement protocol involves all participants cooperatively establishing a conference key. This article designs a secure conference-key agreement protocol with constant round number and message size. Under the decision Diffie–Hellman problem assumption, the resulting protocol is demonstrated to be secure against passive adversaries. Under the random oracle model, the proposed protocol is demonstrated to be provable secure against impersonator attacks and withstand known-key attacks. Compared to previously proposed protocols with round-efficiency, the proposed protocol requires a constant message size for each participant. Furthermore, the proposed protocol possesses both fault tolerance and forward secrecy, while previously proposed protocols with round-efficiency lack one or both properties. 2006 Elsevier Inc. All rights reserved.	communications protocol;diffie–hellman problem;encryption;fault tolerance;forward secrecy;key distribution;key exchange;key-agreement protocol;known-key distinguishing attack;provable security;random oracle;session key	Yuh-Min Tseng	2007	Journal of Systems and Software	10.1016/j.jss.2006.10.053	otway–rees protocol;oakley protocol;fault tolerance;universal composability;forward secrecy;computer science;information security;key-agreement protocol;cryptographic protocol;distributed computing;computer security;station-to-station protocol;computer network	Security	-42.34097013043439	75.00503892216793	74627
18e4da0bbfb9f2f673567e6d72f3f53bc8dbc56c	a variant of pollards rho attack on elliptic curve cryptosystems	elliptic curve;random walk;cycle detection;discrete logarithm problem;pollard rho method;cycle detection discrete logarithm problem elliptic curve pollard rho method random walk	Elliptic Curve cryptosystems appear to be more secu re and efficient when requiring small key size to implement than other public key cryptosystems. Its security is based upon the difficulty of solving Elliptic Curve Discrete Logarithm Problem (ECDLP). This study proposes a variant of generic algorithm Pollard’s Rho for finding ECDLP using cycle detect ion with stack and a mixture of cycle detection an d random walks. The Pollard’s Rho using cycle detecti on with stack requires less iterations than Polla rd’s Rho original in reaching collision. Random walks al low the iteration function to act randomly than the original iteration function, thus, the Pollard rho method performs more efficiently. In practice, the experiment results show that the proposed methods d ecreases the number of iterations and speed up the computation of discrete logarithm problem on ellipt ic curves.	computation;cryptosystem;cycle detection;discrete logarithm;elliptic curve cryptography;generic programming;iteration;key size;pollard's rho algorithm;public-key cryptography;randomness	Siham Ezzouak;Mohammed El Amrani;Abdelmalek Azizi	2014	JCS	10.3844/jcssp.2014.1575.1581	discrete logarithm;cycle detection;pollard's rho algorithm for logarithms;hyperelliptic curve cryptography;counting points on elliptic curves;elliptic curve;pollard's kangaroo algorithm;random walk;algorithm	Crypto	-36.918086559123246	81.01663320916465	74698
2f8c1955bb017c963e8cb0301cb81bb1fae6dbb2	provably secure constant round contributory group key agreement in dynamic setting	public key cryptography;key management;gestion de claves;provable security;cryptographie cle publique;mise a jour;decisional diffie hellman;provable security decision diffie hellman ddh problem dynamic membership change group key agreement;authenticated burmester desmedt group key agreement protocol;cryptanalyse;cryptographic protocols;dynamic membership change;securite donnee;constant round contributory group key agreement;computation complexity authenticated burmester desmedt group key agreement protocol constant round contributory group key agreement dynamic setting;algorithme;actualizacion;cryptanalysis;algorithm;criptoanalisis;message authentication cryptographic protocols;dynamic setting;computational complexity;decision diffie hellman ddh problem;computation complexity;cryptographic protocols cryptography fasteners information security computer science communication standards authentication collaboration tree graphs;contributory group key agreement;message authentication;gestion cle;security of data;group key agreement;updating;algoritmo	In this paper, we present and analyze a variant of Burmester-Desmedt group key agreement protocol (BD) and enhance it to dynamic setting where a set of users can leave or join the group at any time during protocol execution with updated keys. In contrast to BD protocol, let us refer to our protocol as DB protocol. Although the DB protocol is similar to BD protocol, there are subtle differences between them: 1) Key computation in DB protocol is different and simpler than in BD protocol with same complexity of BD protocol; 2) Number of rounds required in our authenticated DB protocol is one less than that in authenticated BD protocol introduced by Katz-Yung; 3) DB protocol is more flexible than BD protocol in the sense that DB protocol is dynamic. The reusability of user's precomputed data in previous session enables the join and leave algorithms of our DB protocol to reduce most user's computation complexities which can be useful in real life applications; and 4) DB protocol has the ability to detect the presence of corrupted group members, although one can not detect who among the group members are behaving improperly.	algorithm;authentication;blu-ray;communication complexity;compiler;computation;cryptographic nonce;decisional diffie–hellman assumption;digital signature;group key;internet protocol suite;katz centrality;key exchange;key-agreement protocol;malware;precomputation;provable security;real life;session key	Ratna Dutta;Rana Barua	2008	IEEE Transactions on Information Theory	10.1109/TIT.2008.920224	message authentication code;cryptanalysis;universal composability;computer science;theoretical computer science;provable security;key management;cryptographic protocol;distributed computing;public-key cryptography;computational complexity theory;computer security	Security	-43.01515738987554	77.01998652263451	75327
f9168a81b9f7b27e5c2537b103210bfde0060a0d	codes based tracing and revoking scheme with constant ciphertext	traitor tracing;copyright protection;broadcast encryption;user revocation;collusion secure codes	In broadcast encryption system certain users may leak their decryption keys to build pirate decoders, so traitor tracing is quite necessary. There exist many codes based traitor tracing schemes. As pointed out by Billet and Phan in ICITS 2008, these schemes lack revocation ability. The ability of revocation can disable identified malicious users and users who fail to fulfill the payments, so that the broadcast encryption system can be more practical. Recently, Zhao and Li presented a construction of codes based tracing and revoking scheme which achieves user revocation as well as traitor tracing. However, their scheme is only secure against chosen plaintext attacks under selective-adversary model with random oracle. In this paper, we obtain a new construction of codes based tracing and revoking scheme which is proved secure against chosen ciphertext attacks under adaptive-adversary model without random oracle. Our idea is to insert codeword into Boneh and Hamburg’s identity based broadcast encryption scheme to retain the ability of user revocation and use Boneh and Naor’s method to trace traitors. Our fully secure scheme is roughly as efficient as Zhao and Li’s scheme while the security is enhanced.	adversary (cryptography);adversary model;bilinear transform;broadcast encryption;chosen-ciphertext attack;ciphertext;code word;computational diffie–hellman assumption;computational complexity theory;cryptography;malware;plaintext;random oracle;scheme;traitor tracing	Xingwen Zhao;Hui Li	2012		10.1007/978-3-642-33272-2_21	telecommunications;computer science;internet privacy;computer security	Crypto	-40.04603177392398	75.43228649024076	75459
96746975a591c53adb7d2db377aae3b6a1347627	encrypting algorithm based on rbf neural network	cryptograph;radial basis function networks cryptography;random input vector;rbf encrypting neural network;rbf;radial basis function networks;simulation experiment;rbf target vector;secret key;cryptography;rbf neural network;cryptography neural networks radial basis function networks artificial neural networks vectors information security educational institutions information science communications technology algorithm design and analysis;encrypting algorithm;rbf network;encrypting;cryptograph encrypting algorithm rbf neural network rbf target vector random input vector secret key;neural network	An encrypting algorithm based on RBF neural network is presented. The clear-text is regarded as RBF target vector. RBF network is trained with random input vector, and the trained results are regarded as the cryptograph. With the feature that the input vector of RBF neural network can be any random value, there are the infinite kinds of ways to build the input vector, so the cryptograph cannot be deciphered theoretically. The random seed used to generate the input vector is regarded as the secret-key. The receiver can get the clear-text from the cryptograph by reconstructing RBF neural network and its input vector with the secret-key. The simulation experiments prove the algorithm is feasible and effective.	algorithm;artificial neural network;cryptogram;encryption;experiment;key (cryptography);public-key cryptography;radial basis function network;random seed;simulation	Kaili Zhou;Yaohong Kang;Yan Huang;Erli Feng	2007	Third International Conference on Natural Computation (ICNC 2007)	10.1109/ICNC.2007.353	hierarchical rbf;computer science;artificial intelligence;machine learning;data mining	ML	-41.975140568521354	83.5079853554434	75685
53bb12c4ca94245b6e7257c87405e0b9b5e7f84d	communication networks keyed permutations for fast data scrambling	key management;block ciphering;gestion de claves;cryptage bloc;securite informatique;reseau ordinateur;scrambling;computer network;permutation;computer security;community networks;arbol binario;criptografia;cryptography;seguridad informatica;arbre binaire;permutacion;cifrado en bloque;red informatica;intercambio desordendo;cryptographie;gestion cle;echange desordonne;binary tree	Abstract#R##N##R##N#The hardware design of key-controlled networks that uniformly generate sets of permutations of any even number of inputs is studied. A model is developed in which a necessary and sufficient condition to obtain a one-to-one correspondence between key values and permutations is found. Furthermore the network depth corresponding to the maximum key length matching the condition is determined. An algorithm for designing networks with the stated properties is given and a generalisation to any odd number of inputs is obtained. Copyright © 2005 AEIT.		Vittorio Bagini;Guglielmo Morgari	2006	European Transactions on Telecommunications	10.1002/ett.1079	binary tree;telecommunications;computer science;cryptography;scrambling;key management;mathematics;permutation;golomb–dickman constant;algorithm	Visualization	-41.48652778048423	81.26108303158576	75847
decb971fd209abe7b67649fc834006d05b2760ad	certification of algorithm 87: permutation generator	permutation generator		algorithm	D. M. Collison	1962	Commun. ACM	10.1145/368637.368746	discrete mathematics;computer science;theoretical computer science;algorithm	Graphics	-40.610362950463475	80.55896063173827	76072
809384b291753c15eacfb3124e4a594efb9726f8	the security of ciphertext stealing	provable security;ciphertext stealing;blockwise adaptive attacks;modes of operation;cryptographic standards;cbc	We prove the security of CBC encryption with ciphertext stealing. Our results cover all versions of ciphertext stealing recently recommended by NIST. The complexity assumption is that the underlying blockcipher is a good PRP, and the security notion achieved is the strongest one commonly considered for chosen-plaintext attacks, indistinguishability from random bits (ind$security). We go on to generalize these results to show that, when intermediate outputs are slightly delayed, one achieves ind$-security in the sense of an online encryption scheme, a notion we formalize that focuses on what is delivered across an online API, generalizing prior notions of blockwiseadaptive attacks. Finally, we pair our positive results with the observation that the version of ciphertext stealing described in Meyer and Matyas’s well-known book (1982) is not secure.	block cipher mode of operation;ciphertext stealing;encryption;parallel redundancy protocol;plaintext	Phillip Rogaway;Mark Wooding;Haibin Zhang	2012		10.1007/978-3-642-34047-5_11	semantic security;ciphertext stealing;ciphertext indistinguishability;mathematics;distributed computing;internet privacy;malleability;computer security;ciphertext;attribute-based encryption	Crypto	-38.05806610091036	77.60806059761249	76196
224a1faad51c807b8c49df268e510676264c2a29	fair exchange of digital signatures with offline trusted third party	internet protocol;fair exchange;user needs;electronic commerce;protocolo internet;encryption;protocole internet;off line;besoin utilisateur;methode indirecte;necesidad usuario;cifrado;journal article;cryptage;user need;digital signature;metodo indirecto;trusted third party;signature numerique;firma numerica;indirect method;fuera linea;hors ligne	In this paper we show how fair exchange of digital signatures can be made possible without a separate verifiable encryption. This means that the fair exchange protocol can be established based on an existing signature algorithm without modification, except that the users need to get a ticket from an off-line trusted third party to enable the fair exchange. The trusted third party is needed to make a judgment only when there is a dispute. Explicit protocols based on different digital signature algorithms are proposed.	algorithm;antivirus software;cryptographic protocol;digital signature;encryption;formal verification;online and offline;trusted operating system;trusted third party;type signature;zero-knowledge proof	Chuan-Kun Wu;Vijay Varadharajan	2001		10.1007/3-540-45600-7_52	internet protocol;e-commerce;digital signature;trusted timestamping;trusted third party;computer science;internet privacy;world wide web;computer security;encryption	Security	-43.79872992316103	76.83167218821924	76727
bb7d00b083c36cdceb6634c362e0b841625aa1e6	improved preimage attacks on ripemd-160 and has-160		The hash function RIPEMD-160 is a worldwide ISO/IEC standard and the hash function HAS-160 is the Korean hash standard and is widely used in Korea. On the basis of differential meet-in-the-middle attack and biclique technique, a preimage attack on 34-step RIPEMD-160 with message padding and a pseudo-preimage attack on 71-step HAS-160 without message padding are proposed. The former is the first preimage attack from the first step, the latter increases the best pseudo-preimage attack from the first step by 5 steps. Furthermore, we locate the linear spaces in another message words and exchange the bicliques construction process and the mask vector search process. A preimage attack on 35-step RIPEMD-160 and a preimage attack on 71-step HAS-160 are presented. Both of the attacks are from the intermediate step and satisfy the message padding. They improve the best preimage attacks from the intermediate step on step-reduced RIPEMD-160 and HAS-160 by 4 and 3 steps respectively. As far as we know, they are the best preimage and pseudo-preimage attacks on step-reduced RIPEMD-160 and HAS-160 respectively in terms of number of steps.	has-160;preimage attack	Yanzhao Shen;Gaoli Wang	2018	TIIS	10.3837/tiis.2018.02.011	has-160;ripemd;complete bipartite graph;hash function;distributed computing;preimage attack;padding;cryptography;theoretical computer science;computer science;image (mathematics)	Crypto	-37.30752806194575	80.71142999119496	76733
089c9d423548af046fb7c0d906a99ec63a51a3d0	uniform first-order threshold implementations		Most masking schemes used as a countermeasure against side-channel analysis attacks require an extensive amount of fresh random bits on the fly. This is burdensome especially for lightweight cryptosystems. Threshold implementations (TIs) that are secure against firstorder attacks have the advantage that fresh randomness is not required if the sharing of the underlying function is uniform. However, finding uniform realizations of nonlinear functions that also satisfy other TI properties can be a challenging task. In this paper, we discuss several methods that advance the search for uniformly shared functions for TIs. We focus especially on three-share implementations of quadratic functions due to their low area footprint. Our methods have low computational complexity even for 8-bit Boolean functions.	8-bit;computational complexity theory;cryptosystem;first-order predicate;nonlinear system;on the fly;quadratic function;randomness;side-channel attack	Tim Beyne;Begül Bilgin	2016	IACR Cryptology ePrint Archive	10.1007/978-3-319-69453-5_5	quadratic function;randomness;boolean function;theoretical computer science;cryptosystem;computational complexity theory;masking (art);nonlinear system;computer science;countermeasure	Crypto	-37.63779948664971	77.29586483471039	76980
d1524dfc5975e63aa4d5e98a4110e05b866b81a6	public key cryptography – pkc 2009	public key cryptography;computer communication networks;algorithm analysis;data encryption;problem complexity;computers and society;information system	We address the problem of polynomial time factoring RSA moduli N1 = p1q1 with the help of an oracle. As opposed to other approaches that require an oracle that explicitly outputs bits of p1, we use an oracle that gives only implicit information about p1. Namely, our oracle outputs a different N2 = p2q2 such that p1 and p2 share the t least significant bits. Surprisingly, this implicit information is already sufficient to efficiently factor N1, N2 provided that t is large enough. We then generalize this approach to more than one oracle query.	integer factorization;least significant bit;oracle database;pkc (conference);polynomial;public-key cryptography;time complexity	Takeo Kanade;Josef Kittler;Alfred Kobsa;John C. Mitchell;Moni Naor	2009		10.1007/978-3-642-00468-1	shared secret;cdmf;key;strong cryptography;financial cryptography;neural cryptography;key exchange;computer science;cryptography;theoretical computer science;pkcs #1;key generation;distributed computing;cryptography law;public-key cryptography;key space;key distribution;computer security;id-based cryptography;encryption	Crypto	-38.644617006127646	76.78709509136176	77390
f3344cea1fd69be26fd4117581e7869b15c8cef6	cryptanalysis of nonlinear feedback shift registers	cryptanalysis;stream cipher;nonlinear feedback shift register;boyar krawczyk algorithm	For a successful cryptanalysis of an NLFSR, the needed number of known plaintext bits is about the smaller of two numbers: the period (including the preperiod if the sequence is not purely periodic) and the number of degrees of freedom of the feedback function. Therefore, under the assumption that the feedback function is completely unknown, there is no better way to cryptanalyse an NLFSR than a straightforward search for the period. If the choice of the feedback function is restricted in order to guarantee its efficient computation, then an algorithm by Boyar and Krawczyk gives an efficient cryptanalysis of the NLFSR in the sense of asymptotic complexity.	algorithm;computation;computational complexity theory;cryptanalysis;known-plaintext attack;nonlinear feedback shift register;nonlinear system;plaintext	Klaus Pommerening	2016	Cryptologia	10.1080/01611194.2015.1055385	cryptanalysis;computer science;theoretical computer science;higher-order differential cryptanalysis;mathematics;distributed computing;stream cipher;algorithm;statistics;linear cryptanalysis	Crypto	-39.124113217194804	82.80265451074077	77413
9ec56826414f5a8ac27e3db541b579f720468c67	breaking the ω̃(√n) barrier: fast consensus under a late adversary			adversary (cryptography)	Peter Robinson;Christian Scheideler;Alexander Setzer	2018	CoRR		adversary;mathematics;distributed computing	Crypto	-42.10301597588373	76.83636815657935	77417
5c717009ee192cc1e7822073b3e83848f432d4db	using data uncertainty to increase the crypto-complexity of simple private key enciphering schemes		Computational efficiency is of prime importance to any micro-processor based cryptosystem. A technique is presented here which permits a reduction in the enciphering complexity of private key schemes without a loss in security. The net result can be a simplification of the system’s implementation, a reduction in cryptographic overhead and the potential for a simple mathematical analysis of the security system.	cipher;public-key cryptography	G. M. Avis;Stafford E. Tavares	1982			econometrics;computer science;data mining;statistics	Crypto	-40.14971340085024	79.69299148738737	77826
27ebafb62578a25368545cbf78939f761fd61a7f	enhancing security of lte using a double masking technique		LTE uses the Evolved Packet System Authentication and Key Agreement (EPS-AKA) procedure to establish and verify keys. However, the EPS-AKA is vulnerable to attacks such as disclosure of the user identity, manin-the-middle attack and denial of services; therefore, a robust authentication mechanism is required. In this paper, we enhance security of LTE by using a double masking technique, in which both the identity key of the user equipment (UE), i.e., IMSI, and the random challenge key, i.e., RAND, are masked without being exposed in the authentication process. The proposed double masking technique is effective in performing mutual authentication of the user and the network. Security analysis shows that this technique is more secure than the original EPS-AKA since IMSI and RAND are well-protected and achieve practical security. Since all operators used in encrypting keys are simple and efficient, it works without degrading the performance of the existing LTE system.	authentication and key agreement (protocol);compaq lte;consistency model;dos;encryption;futures studies;man-in-the-middle attack;mutual authentication;software deployment	Jung-Chun Liu;Yi-Li Huang;Fang-Yie Leu	2016		10.1007/978-3-319-49106-6_75	telecommunications;computer security;computer network	Security	-45.72108303183955	74.77503446362014	77882
cdc6460219ef15ef532fd10df1e745448b4eb761	a comment on the 'basic security theorem' of bell and lapadula	theorems;security model;information security;military applications;prototypes;clearances;secure system	"""Many claim that the security model developed by Bell and LaPadula and used as a basis for numerous prototype military computer systems is superior to others partly because its authors prove a """"Basic Security Theorem"""" that applies to it. This paper shows that the theorem does not support such claims since it can be proven for security models that are obviously not secure. Further, the theorem provides little help to those who design and implement secure systems."""	bell–lapadula model;computer security model;military computers;prototype	John McLean	1985	Inf. Process. Lett.	10.1016/0020-0190(85)90065-1	computer security model;combinatorics;theorem;computer science;artificial intelligence;information security;theoretical computer science;mathematics;prototype;algorithm	Security	-33.92774606613077	77.29650293806736	77898
a1253bceefc5934ed9a360a2ca54f0052972848f	performance analysis and improvement of jpv primality test for smart ic cards	public key cryptography;public key cryptosystem prime generation primality test;public key cryptosystem jpv primality test smart ic cards jpv algorithm prime generation algorithm fermat test calls probabilistic analysis euclid function space requirement;statistical analysis;algorithm design and analysis probabilistic logic software algorithms tunneling magnetoresistance time measurement public key cryptography;smart cards;statistical analysis public key cryptography smart cards	JPV algorithm, proposed by Joye et al. was predicted to be faster than the combined prime generation algorithm but it runs slower in practice. This discrepancy is because only the number of Fermat test calls was compared in estimating a total running time. We present a probabilistic analysis on the total running time of JPV algorithm. This analysis is very accurate and corresponds to the experiment with only 1-2% error. Furthermore, we propose an improved JPV algorithm that uses Euclid function. It is faster than JPV algorithm and similar to the combined algorithm with the same space requirement.	discrepancy function;euclid;fermat primality test;probabilistic analysis of algorithms;profiling (computer programming);simplex algorithm;time complexity	Hosung Jo;Heejin Park	2014	2014 International Conference on Big Data and Smart Computing (BIGCOMP)	10.1109/BIGCOMP.2014.6741451	theoretical computer science;mathematics;computer security;algorithm	SE	-39.764337161247234	84.48475200904939	77905
7902a8754b84fd393b9a6cf804b9d2e992f8daa0	advances in cryptology - crypto 2003		The security of the RSA cryptosystem depends on the difficulty of factoring large integers. The best current factoring algorithm is the Number Field Sieve (NFS), and its most difficult part is the sieving step. In 1999 a large distributed computation involving hundreds of workstations working for many months managed to factor a 512-bit RSA key, but 1024-bit keys were believed to be safe for the next 15-20 years. In this paper we describe a new hardware implementation of the NFS sieving step (based on standard 0.13μm, 1GHz silicon VLSI technology) which is 3-4 orders of magnitude more cost effective than the best previously published designs (such as the optoelectronic TWINKLE and the mesh-based sieving). Based on a detailed analysis of all the critical components (but without an actual implementation), we believe that the NFS sieving step for 512-bit RSA keys can be completed in less than ten minutes by a $10K device. For 1024-bit RSA keys, analysis of the NFS parameters (backed by experimental data where possible) suggests that sieving step can be completed in less than a year by a $10M device. Coupled with recent results about the cost of the NFS matrix step, this raises some concerns about the security of this key size.	algorithm;computation;cryptography;cryptosystem;distributed computing;general number field sieve;integer factorization;key size;rsa (cryptosystem);twinkle;very-large-scale integration;workstation	Jan van Leeuwen;Dan Boneh	2003		10.1007/b11817	computer security;computer science	Crypto	-34.2932443549473	80.62816821692974	78002
21c7380efadc8c022d3e65984eb9dd885097fc3b	the complexity of robust atomic storage	time complexity;lower bounds;message passing system;lower bounds storage emulations arbitrary failures optimal resilience time complexity;timing optimization;eurecom ecole d ingenieur telecommunication centre de recherche graduate school research center communication systems;lower bound	We study the time-complexity of robust atomic read/write storage from fault-prone storage components in asynchronous message-passing systems. Robustness here means wait-free tolerating the largest possible number t of Byzantine storage component failures (optimal resilience) without relying on data authentication. We show that no single-writer multiple-reader (SWMR) robust atomic storage implementation exists if (a) read operations complete in less than four communication round-trips (rounds), and (b) the time complexity of write operations is constant. More precisely, we present two lower bounds. The first is a read lower bound stating that three rounds of communication are necessary to read from a SWMR robust atomic storage. The second is a write lower bound, showing that Ω(log(t)) write rounds are necessary to read in three rounds from such a storage. Applied to known results, our lower bounds close a fundamental gap: we show that time-optimal robust atomic storage can be obtained using well-known transformations from regular to atomic storage and existing time-optimal regular storage implementations.	emoticon;message authentication;message passing;non-blocking algorithm;time complexity	Dan Dobre;Rachid Guerraoui;Matthias Majuntke;Neeraj Suri;Marko Vukolic	2011		10.1145/1993806.1993816	time complexity;real-time computing;computer science;theoretical computer science;operating system;distributed computing;upper and lower bounds;algorithm	Theory	-34.09429012860502	74.99779867202498	78058
5bf98c7f5f9978365f6485cb8c68d9681fd9725a	k-strong privacy for radio frequency identification authentication protocols based on physically unclonable functions	physically unclonable function;rfid;security;privacy	This paper examines Vaudenay’s privacy model, which is one of the first and most complete privacy models that featured the notion of different privacy classes. We enhance this model by introducing two new generic adversary classes, k-strong and k-forward adversaries where the adversary is allowed to corrupt a tag at most k times. Moreover, we introduce an extended privacy definition that also covers all privacy classes of Vaudenay’s model. In order to achieve highest privacy level, we study low cost primitives such as physically unclonable functions (PUFs). The common assumption of PUFs is that their physical structure is destroyed once tampered. This is an ideal assumption because the tamper resistance depends on the ability of the attacker and the quality of the PUF circuits. In this paper, we have weakened this assumption by introducing a new definition k-resistant PUFs. k-PUFs are tamper resistant against at most k attacks; that is, their physical structure remains still functional and correct until at most kth physical attack. Furthermore, we prove that strong privacy can be achieved without public-key cryptography using k PUF-based authentication. We finally prove that our extended proposal achieves both reader authentication and k-strong privacy. Copyright © 2014 John Wiley & Sons, Ltd.	adversary (cryptography);authentication;authentication protocol;encryption;john d. wiley;privacy;public-key cryptography;radio frequency;radio-frequency identification;symmetric-key algorithm;tamper resistance;whole earth 'lectronic link	Süleyman Kardas;Serkan Çelik;Muhammed Ali Bingöl;Mehmet Sabir Kiraz;Hüseyin Demirci;Albert Levi	2015	Wireless Communications and Mobile Computing	10.1002/wcm.2482	radio-frequency identification;privacy software;physical unclonable function;computer science;information security;internet privacy;privacy;world wide web;computer security	Security	-41.537869177467456	76.27813641106601	78296
ad4fedb6200b61383aa4cec2e2c85b67af196b72	signatures for multi-source network coding	ring signature;network coding;multi-source;homomorphic hash;signature	We consider the problem of securing inter-flow network coding with multiple sources. We present a practical homomorphic signature scheme that makes possible to verify network coded packets composed of data originating from different sources. The multi-source signature scheme allows to circumvent the need of a secret key shared by all sources. Our solution is an extension of the pairing based homomorphic signature scheme by Boneh et al. We prove the security of the extended scheme by showing a reduction to the single-source case. We evaluated the performance of required computations and our results imply that the solution is applicable in practice.	adversary (cryptography);computation;cryptography;digital signature;electronic signature;flow network;key (cryptography);linear network coding;multi-source;network packet	László Czap;István Vajda	2010	IACR Cryptology ePrint Archive			Crypto	-40.20005013668692	76.95655899209535	78310
a1a960998ef3e6af58a83b4c26ac5b14c13f02d3	security of signed elgamal encryption	public key cryptography;protection information;provable security;cryptographie cle publique;procesamiento informacion;security model;generic model;private information retrieval;securite informatique;communication complexity;complexite communication;cryptographic protocol;public key cryptosystem;securite donnee;computer security;security proof;it security;proteccion informacion;digital signature;random oracle model;informatique theorique;information protection;information processing;cyclic group;random oracle;signature numerique;hash function;traitement information;security of data;chosen ciphertext attack;computer theory;informatica teorica	Assuming a cryptographically strong cyclic group G of prime order q and a random hash functionH, we show that ElGamal encryption with an added Schnorr signature is secure against the adaptive chosen ciphertext attack, in which an attacker can freely use a decryption oracle except for the target ciphertext. We also prove security against the novel one-more-decyption attack. Our security proofs are in a new model, corresponding to a combination of two previously introduced models, the Random Oracle model and the Generic model. The security extends to the distributed threshold version of the scheme. Moreover, we propose a very practical scheme for private information retrieval that is based on blind decryption of ElGamal ciphertexts.	adaptive chosen-ciphertext attack;ciphertext;encryption;personally identifiable information;private information retrieval;random oracle;strong cryptography	Claus-Peter Schnorr;Markus Jakobsson	2000		10.1007/3-540-44448-3_7	random oracle;semantic security;chosen-ciphertext attack;information processing;computer science;theoretical computer science;ciphertext indistinguishability;mathematics;internet privacy;malleability;elgamal encryption;elgamal signature scheme;computer security;cramer–shoup cryptosystem	Crypto	-42.50962921028161	77.83026702582693	78634
5e5b70fd2a01aed32dd74191adfc3af821475164	cryptanalysis of sober-t32	security evaluation;distinguishing attack;stream ciphering;securite;llave investigacion;cryptanalyse;decimation;cryptanalysis;criptoanalisis;stream cipher;criptografia;cryptography;safety;search key;cryptographie;cle recherche;seguridad;cifrado continuo;decimacion;cryptage continu	Sober-t32 is a candidate stream cipher in the NESSIE competition. Some new attacks are presented in this paper. A Guess and Determine attack is mounted against Sober-t32 without the decimation of the key stream by the so-called stuttering phase. Also, two distinguishing attacks are mounted against full Sober-t32. These attacks are not practically feasible, but they are theoretically more efficient than exhaustive key search.	brute-force attack;cryptanalysis;decimation (signal processing);nessie;stream cipher	Steve Babbage;Christophe De Cannière;Joseph Lano;Bart Preneel;Joos Vandewalle	2003		10.1007/978-3-540-39887-5_10	block cipher;pre-play attack;telecommunications;computer science;boomerang attack;higher-order differential cryptanalysis;internet privacy;computer security;linear cryptanalysis	Security	-40.741011471166395	81.41244776958399	78651
ee3df77ac245b3504143332efeb707bedff167ca	verifiable random functions from (leveled) multilinear maps		Verifiable random functions (VRFs), firstly proposed by Micali, Rabin, and Vadhan (FOCS 99), are pseudorandom functions with the additional property that the party holding the seed sk can generate a non-interactive, publicly verifiable proof (pi ) for the statements “(F_{sk}(x)=y)”, for any input x. To date only a few VRF schemes are known and most known constructions either allow only a small input space, or don’t achieve full adaptive security under a non-interactive complexity assumption. The only known adaptively secure VRF scheme with exponentially-large input space is based on (ell )-Decisional Diffie-Hellman Exponent assumption (Hohenberger and Waters, Eurocrypt 2010).		Bei Liang;Hongda Li;Jinyong Chang	2015		10.1007/978-3-319-26823-1_10	discrete mathematics;multilinear map;verifiable secret sharing;theoretical computer science;pi;computer science;pseudorandom number generator;exponent	Crypto	-38.68972109702261	75.92746683754878	78655
0625afd943e494913c5b2bb0d3638571a6ac7ab5	a survey of dht security techniques	hachage;distributed system;systeme reparti;environnement hostile;peer to peer network;distributed hash table;routing;peer to peer systems;par a par;securite informatique;routage;p2p;peer to peer system;medio ambiente hostil;computer security;sybil attack;hashing;sistema repartido;poste a poste;secure p2p routing and storage;seguridad informatica;eclipse attack;algorithms;design;hostile environment;distributed hash tables;peer to peer;security;enrutamiento	Peer-to-peer networks based on distributed hash tables (DHTs) have received considerable attention ever since their introduction in 2001. Unfortunately, DHT-based systems have been shown to be notoriously difficult to protect against security attacks. Various reports have been published that discuss or classify general security issues, but so far a comprehensive survey describing the various proposed defenses has been lacking. In this article, we present an overview of techniques reported in the literature for making DHT-based systems resistant to the three most important attacks that can be launched by malicious nodes participating in the DHT: (1) the Sybil attack, (2) the Eclipse attack, and (3) routing and storage attacks. We review the advantages and disadvantages of the proposed solutions and, in doing so, confirm how difficult it is to secure DHT-based systems in an adversarial environment.	distributed hash table;eclipse;malware;routing;sybil attack	Guido Urdaneta;Guillaume Pierre;Maarten van Steen	2011	ACM Comput. Surv.	10.1145/1883612.1883615	design;routing;computer science;information security;operating system;database;distributed computing;world wide web;computer security	Security	-46.44346588692248	79.21115072281516	78999
399348cd9386092e10b898e40f22b3e698f87939	"""disproving the conjectures from """"on the complexity of scrypt and proofs of space in the parallel random oracle model"""""""			random oracle;scrypt	Daniel Malinowski;Karol Zebrowski	2017		10.1007/978-3-319-72089-0_2		Crypto	-40.11703409086456	79.87519618034032	79010
aae7e2ffcf48f6654e9d05f2a3119df19e0e4217	certificateless signature revisited	provable security;security model;selected works;bepress selected works;certificateless cryptology;signature scheme;random oracle model;era2012;signature;random oracle;bepress	In this paper we revisit the security models of certificateless signatures and propose two new constructions which are provably secure in the random oracle model. We divide the potential adversaries according to their attack power, and for the first time, three new kinds of adversaries are introduced into certificateless signatures. They are Normal Adversary, Strong Adversary and Super Adversary (ordered by their attack power). Combined with the known Type I Adversary and Type II Adversary in certificateless system, we then define the security of certificateless signatures in different attack scenarios. Our new models, together with the others in the literature, will enable us to better understand the security of certificateless signatures. Two concrete schemes with different security levels are also proposed in this paper. The first scheme, which is proved secure against Normal Type I and Super Type II Adversary, enjoys the shortest signature length among all the known certificateless signature schemes. The second scheme is secure against Super Type I and Type II adversary. Compared with the scheme in ACNS 2006 which has a similar security level, our second scheme requires lower operation cost but a little longer signature length.	adversary (cryptography);antivirus software;common language infrastructure;provable security;random oracle	Xinyi Huang;Yi Mu;Willy Susilo;Duncan S. Wong;Wei Wu	2007		10.1007/978-3-540-73458-1_23	random oracle;advantage;computer science;mathematics;distributed computing;internet privacy;computer security;algorithm;adversary model	Crypto	-40.89093840218616	75.99077614114316	79118
979aebe4e893dc9728b6330bdbcb886bb0088c40	efficiently from semi-honest to malicious ot via olfe		A combiner securely implements a functionality out of a set implementations of another functionality from which some may be insecure. We present two efficient combiners for oblivious linear function evaluation (OLFE). The first is a constant-rate OLFE combiner in the semihonest model, the second combiner implements Rabin string oblivious transfer (RabinOT) from OLFE in the malicious model. As an application, we show a very efficient reductions in the malicious model of RabinOT over strings to one-out-of-two oblivious transfer over bits (OT) that is only secure in the semihonest model. For string of size ` = ω(k), our reductions uses only 4`+ o(`) instances of OT, while previous results required Ω(`k). Our new reduction leads to an efficiency improvement for general multi-party computation (MPC) based on semi-honest OT, and makes it almost as efficient as MPC based on malicious OT. All reductions are unconditionally secure, black-box, universally composable and secure against adaptive adversaries.	black box;computation;diplexer;linear function;oblivious transfer;power dividers and directional couplers;semiconductor industry	Jürg Wullschleger	2009	IACR Cryptology ePrint Archive			Crypto	-37.806503420265834	76.47539129539808	79229
2f13efe5c1ea7362358dcdf497ecbd18e1a31021	differential cryptanalysis of round-reduced lea		In this paper, we focus on the differential cryptanalysis dedicated to a particular class of cryptographic algorithms, namely ARX ciphers. We propose a new algorithm inspired by the Nested Monte-Carlo Search algorithm to find a differential path in ARX ciphers. We apply our algorithm to a round reduced variant of the block cipher LEA. For small blocks of ARX ciphers, our algorithm works perfectly and in an extremely concise time. Taking into account that our algorithm takes longer for bigger blocks, we use the concept of a partial difference distribution table (pDDT) in our algorithm. This methodology reduced the search space of the algorithm by using only those differentials whose probabilities are greater than or equal to a pre-defined threshold. Using this concept, we removed many differentials which are not valid or whose probabilities are very low. This led to a decreased time of finding a differential path by our nested algorithm due to a smaller search space. This partial difference distribution table also made our nested algorithm suitable for bigger block size ARX ciphers. In previous works, finding long differential characteristics has been shown to be a problem of a harder nature where algorithms have been shown to take many hours or days to find differential characteristics in ARX ciphers. In this paper, our algorithm finds the differential characteristics in just a few minutes with a very simple framework. We report the differential path for up to nine rounds in LEA. To construct differential characteristics for a large number of rounds, we use techniques to divide long characteristics into short ones, by constructing a large characteristic from two short characteristics. Furthermore, instead of starting from the first round as most algorithms do, we start from the middle and run experiments in the forward as well as in the reverse direction. Using this method, we improved our results and report the differential path for up to 12 rounds and with the given path we attacked 14 rounds of cipher. Overall, it is clear to see that the best property of our algorithm is that it has the potential to provide state-of-the-art results but within a simpler framework as well as in less time than previous attempts. Our algorithm provides a reusable framework for future avenues of research, as it could be applied to other ARX ciphers with the potential for interesting and efficient results.		Ashutosh Dhar Dwivedi;Gautam Srivastava	2018	IEEE Access	10.1109/ACCESS.2018.2881130	cipher;inequality;discrete mathematics;block cipher;differential cryptanalysis;cryptography;block size;encryption;distributed computing;search algorithm;computer science	Crypto	-36.413988056194704	81.17863105755058	79535
d7c4292420ef03ee87773d179509135afca4995c	inversion attack and branching	protection information;non linear filtering;securite informatique;filtrado no lineal;securite donnee;computer security;proteccion informacion;criptografia;informatique theorique;cryptography;information protection;cryptographie;theorie information;security of data;information theory;filtrage non lineaire;computer theory;informatica teorica;teoria informacion	The generalized inversion attack on nonlinear filter generators is developed and analyzed by the theory of critical branching processes. Unlike the inversion attack which requires that the filter function be linear in the first or the last input variable, this attack can be applied for any filter function. Both theory and systematic experiments conducted show that its time complexity remains close to 2 , M being the input memory size, while the additional memory space required is relatively small for most the filter functions.	dspace;experiment;nonlinear system;time complexity	Jovan Dj. Golic;Andrew J. Clark;Ed Dawson	1999		10.1007/3-540-48970-3_8	kernel adaptive filter;telecommunications;information theory;computer science;cryptography;artificial intelligence;mathematics;algorithm;statistics	Crypto	-40.352517339286905	82.63928874850416	79594
6ff796f68bbf80589a76427b5cae43edd7bc748d	identity-based trapdoor mercurial commitments and applications	prueba;trapdoor commitments;51e24;selected works;building block;non interactive zero knowledge;preuve;zero knowledge sets;informatique theorique;interactive proofs;mercurial commitments;bepress;identity based zero knowledge;connaissance zero;zero knowledge;proof;computer theory;informatica teorica	In this paper, we first introduce the notion of identity-based trapdoor mercurial commitment which enjoys the advantages of both the identity-based trapdoor commitment and trapdoor mercurial commitment, while using the idea of ‘‘Customized Identity’’. Inherently, an identity-based trapdoor mercurial commitment is an underlying building block for constructing identity-based (non-interactive) zero-knowledge sets. That is, a prover can commit to a set S in a way that reveals nothing about S and prove to a verifier, in zeroknowledge, statements of the form x ∈ S and x ∉ S. Besides, although the (non-interactive) proof is publicly verifiable, it is also bound to the identity of the prover in a way which is recognizable to any verifier. © 2011 Elsevier B.V. All rights reserved.	formal verification;interactivity;mercurial;proof calculus;theory;trapdoor function;zero-knowledge proof	Xiaofeng Chen;Willy Susilo;Fangguo Zhang;Haibo Tian;Jin Li	2011	Theor. Comput. Sci.	10.1016/j.tcs.2011.05.031	proof;mathematics;computer security;algorithm;zero-knowledge proof	Crypto	-38.11164023107186	75.8306349476929	79601
e3bfd944aa9021fa5ad0fcedad29fcdae8e3721d	visual applications of probabilistic one-time passwords for personal authentication	shoulder-surfing.;man-in-the-middle attack;index terms — authentication;visual password;indexing terms;man in the middle attack;one time password;one time pad	The probabilistic one-time password may be used to provide personal authentication in a manner which is secure against shoulder surfing and man-in- the-middle attacks. The technique is particularly suited to visual applications in which symbols, pictures or patterns on a computer screen are used to display the one-time pads. In this paper we describe the space of visual authentication applications of the probabilistic one-time password; we illustrate a few practical instantiations of the method and analyze their properties.	authentication;password	Mark Bedworth;Colin Allison	2008			computer science;computer security;lead titanate;dielectric;high-κ dielectric;tungstate;ternary operation;ceramic;phase diagram;electrostriction	Crypto	-44.19935822957242	75.75644137190729	79646
679c481fba7629dc6a725e2d5fd4784cfa3236d5	kipnis-shamir attack on unbalanced oil-vinegar scheme	search method;multivariate public key cryptosystem;finite field;kipnis shamir attack;signature scheme;public key;oil vinegar scheme	The public key of the Oil-Vinegar scheme consists of a set of m quadratic equations in m+n variables over a finite field Fq. Kipnis and Shamir broke the balanced Oil-Vinegar scheme where d = n-m = 0 by finding equivalent keys of the cryptosytem. Later their method was extended by Kipnis et al to attack the unbalanced case where 0 < d < m and d is small with a complexity of O(qd-1m4). This method uses the matrices associated with the quadratic polynomials in the public key, which needs to be symmetric and invertible. In this paper, we give an optimized search method for Kipnis el al's attack. Moreover, for the case that the finite field is of characteristic 2, we find the situation becomes very subtle, which, however, was totally neglected in the original work of Kipnis et al. We show that the Kipnis-Shamir method does not work if the field characteristic is 2 and d is a small odd number, and we fix the situation by proposing an alternative method and give an equivalent key recovery attack of complexity O(qd+1m4). We also prove an important experimental observation by Ding et al for the Kipnis-Shamir attack on balanced Oil-Vinegar schemes in characteristic 2.	buncefield fire;unbalanced line	Weiwei Cao;Lei Hu;Jintai Ding;Zhijun Yin	2011		10.1007/978-3-642-21031-0_13	computer science;public-key cryptography;computer security;finite field	Crypto	-39.18090593781351	80.71931685234952	79745
9a1081dca37b21d91f1e5be0003802c6f4b23231	secure stable matching at scale	gale shapley;multi party computation;stable matching;secure computation;roth peranson;ram secure computation	When a group of individuals and organizations wish to compute a stable matching---for example, when medical students are matched to medical residency programs---they often outsource the computation to a trusted arbiter in order to preserve the privacy of participants' preferences. Secure multi-party computation offers the possibility of private matching processes that do not rely on any common trusted third party. However, stable matching algorithms have previously been considered infeasible for execution in a secure multi-party context on non-trivial inputs because they are computationally intensive and involve complex data-dependent memory access patterns.  We adapt the classic Gale-Shapley algorithm for use in such a context, and show experimentally that our modifications yield a lower asymptotic complexity and more than an order of magnitude in practical cost improvement over previous techniques. Our main improvements stem from designing new oblivious data structures that exploit the properties of the matching algorithms. We apply a similar strategy to scale the Roth-Peranson instability chaining algorithm, currently in use by the National Resident Matching Program. The resulting protocol is efficient enough to be useful at the scale required for matching medical residents nationwide, taking just over 18 hours to complete an execution simulating the 2016 national resident match with more than 35,000 participants and 30,000 residency slots.	algorithm;arbiter (electronics);computational complexity theory;data dependency;data structure;exception chaining;experiment;instability;national resident matching program;outsourcing;privacy;realms of the haunting;secure multi-party computation;simulation;stable marriage problem;trusted third party	Jack Doerner;David Evans;Abhi Shelat	2016		10.1145/2976749.2978373	simulation;stable marriage problem;computer science;secure two-party computation;theoretical computer science;distributed computing;computer security	Security	-34.7940931234441	76.08947415738054	79792
ff69e9d957f6ce7b58ea932c3fd2e2893908cef8	a timing attack against rsa with the chinese remainder theorem	chino;montgomery multiplication;chinese remainder theorem;criptografia;cryptography;cryptographie;chinois;chinese;timing attack;timing	We introduce a new type of timing attack which enables the factorization of an RSA-modulus if the exponentiation with the secret exponent uses the Chinese Remainder Theorem and Montgomery’s algorithm. Its standard variant assumes that both exponentiations are carried out with a simple square and multiply algorithm. However, although its efficiency decreases, our attack can also be adapted to more advanced exponentiation algorithms. The previously known timing attacks do not work if the Chinese Remainder Theorem is used.	algorithm;exponentiation by squaring;modulus of continuity;montgomery modular multiplication	Werner Schindler	2000		10.1007/3-540-44499-8_8	arithmetic;discrete mathematics;timing attack;cryptography;chinese remainder theorem;mathematics;chinese;statistics;algebra	Security	-39.749596470664756	80.48575386665854	80148
4a7e5c57f52cf318082219330b84f2a131f03a03	some remarks on authentication systems	selected works;bepress	"""Brickell, Simmons and others have discussed doubly perfect authentication systems in which an opponent's chance of deceiving the receiver is a minimum for a given number of encoding rules. Brickell has shown that in some instances to achieve this minimum the system needs to have splitting. Such a system uses a larger message space. Motivated by Brickell's ideas we consider authentication systems with splitting and the problems of reducing the message space. Disciplines Physical Sciences and Mathematics Publication Details Anthony, MHG, Martin, KM, Seberry, J & Wild, P, Some remarks on authentication systems, ( Josef Pieprzyk and Jennifer Seberry, (Eds.)), Auscrypt'90 – Advances in Cryptography, 453, Lecture Notes in Computer Science, Springer-Verlag, 1990, 122-139. This journal article is available at Research Online: http://ro.uow.edu.au/infopapers/1046 Some Remarks on Authentication Systems Martin H.G. Anthony', Keith M. Martin', Jennifer Seberry"""", Peter Wild' Abstract Brickell, Simmons and others have discussed doubly perfect authentication systems in which an opponent's chance of deceiving the receiver is a minimum for a given number of encoding rules. Brickell has shown that in some instances to achieve this minimum the system needs to have splitting. Such a system uses a larger message space. Motivated by Brickell's ideas we consider authentication systems with splitting and the problems of reducing the message space.Brickell, Simmons and others have discussed doubly perfect authentication systems in which an opponent's chance of deceiving the receiver is a minimum for a given number of encoding rules. Brickell has shown that in some instances to achieve this minimum the system needs to have splitting. Such a system uses a larger message space. Motivated by Brickell's ideas we consider authentication systems with splitting and the problems of reducing the message space."""	authentication;cryptography;jennifer seberry;lecture notes in computer science;springer (tank)	Martin Anthony;Keith M. Martin;Jennifer Seberry;Peter R. Wild	1990		10.1007/BFb0030356	computer science;computer security	Security	-35.082535383924665	78.37503186287236	80339
5c8254fc7056b53ee778f03d2a413a4148d6aa3b	key based bit level genetic cryptographic technique (kbgct)	encryption;biological cells encryption algorithm design and analysis genetics computers;genetic mutation key based bit level genetic cryptographic technique encryption algorithm decryption algorithm genetic function cryptography encryption process decryption process genetic algorithm random number bit level xor operation genetic crossover;genetic algorithms cryptography error statistics;plain text;genetics;genetic algorithm key based bit level genetic cryptographic technique kbgct encryption decryption cipher text plain text;cipher text;key based bit level genetic cryptographic technique kbgct;cryptography;decryption;error statistics;genetic algorithm;genetic algorithms;random numbers	This is an encryption and decryption algorithm with the help of genetic functions cryptography. This new algorithm is developed for encryption and decryption process. This algorithm combines the features of Genetic Algorithm in Cryptography. Here we generate random numbers for “Crossover” and “Mutation”. The encryption and decryption algorithms will be made public. The algorithm contains a key, which is known to only sender and receiver. In this technique the input file is broken down into different blocks of various sizes. The main algorithm works in two stages. Bit Level XOR operation followed by Genetic Crossover and Mutation.	bit-level parallelism;cryptography;encryption;exclusive or;genetic algorithm;key (cryptography)	Subhranil Som;Niladri Shekhar Chatergee;J. K. Mandal	2011	2011 7th International Conference on Information Assurance and Security (IAS)	10.1109/ISIAS.2011.6122826	multiple encryption;cdmf;key;tiny encryption algorithm;40-bit encryption;computer science;theoretical computer science;symmetric-key algorithm;distributed computing;encryption;probabilistic encryption;algorithm;attribute-based encryption	EDA	-36.64595812251127	81.80507885764715	80519
ca4178e5d50b1ac543eaa5c6dc2c3552b67b5070	elliptic curve cryptography (ecc) support for public key cryptography for initial authentication in kerberos (pkinit)		Status of This Memo This memo provides information for the Internet community. It does not specify an Internet standard of any kind. Distribution of this memo is unlimited. Abstract This document describes the use of Elliptic Curve certificates, Elliptic Curve signature schemes and Elliptic Curve Diffie-Hellman (ECDH) key agreement within the framework of PKINIT-the Kerberos Version 5 extension that provides for the use of public key cryptography.	authentication;diffie–hellman key exchange;elliptic curve cryptography;internet;kerberos;public-key cryptography	Larry Zhu;Karthik Jaganathan;Kristin E. Lauter	2008	RFC	10.17487/RFC5349	elliptic curve diffie–hellman;speke;elliptic curve digital signature algorithm;ecc patents;curve25519;mathematics;elliptic curve cryptography;internet privacy;world wide web;computer security	Security	-42.03061762465092	78.73545676711727	80556
51aacb8ebf8480bee0ffca06752ab2c75407251a	security analysis of modified rivest scheme			scheme	Deepthi Haridas;Sarma Venkataraman;Geeta Varadan	2014	J. Mathematical Cryptology	10.1515/jmc-2013-0018	theoretical computer science;mathematics;discrete mathematics;probabilistic method;security analysis;probabilistic encryption	Crypto	-40.45113094521027	80.04397965095495	80660
da9e8efd1562fd940a16788dea9f06863c0d55ec	functional graphs and their applications in generic attacks on iterated hash constructions		We provide a survey about generic attacks on cryptographic hash constructions including hash-based message authentication codes and hash combiners. We look into attacks involving iteratively evaluating identical mappings many times. The functional graph of a random mapping also involves iteratively evaluating the mapping. These attacks essentially exploit properties of the functional graph. We map the utilization space of those properties from numerous proposed known attacks, draw a comparison among classes of attacks about their advantages and limitations. We provide a systematic exposition of concepts of cycles, deep-iterate images, collisions and their roles in cryptanalysis of iterated hash constructions. We identify the inherent relationship between these concepts, such that case-by-case theories about them can be unified into one knowledge system, that is, theories on the functional graph of random mappings. We show that the properties of the cycle search algorithm, the chain evaluation algorithm and the collision search algorithm can be described based on statistic results on the functional graph. Thereby, we can provide different viewpoints to support previous beliefs on individual knowledge. In that, we invite more sophisticated analysis of the functional graph of random mappings and more future exploitations of its properties in cryptanalysis.	cryptanalysis;cryptographic hash function;discrete logarithm;iterated function;iteration;knowledge-based systems;message authentication code;pseudoforest;search algorithm;theory	Zhenzhen Bao;Jian Guo;Lei Wang	2018	IACR Trans. Symmetric Cryptol.	10.13154/tosc.v2018.i1.201-253	iterated function;cryptographic hash function;collision;theoretical computer science;hash function;message authentication code;search algorithm;exploit;mathematics;cryptanalysis	Security	-37.928319624272206	83.28412020124343	80947
e6789794c92af12bf779f2f80fda0e7da0227797	efficient identity-based encryption with tight security reduction	tecnologia electronica telecomunicaciones;identity based encryption;tight security reduction;tecnologias;grupo a	In this paper, we present an efficient variant of the Boneh-Franklin scheme that achieves a tight security reduction. Our scheme is basically an IBE scheme under two keys, one of which is randomly chosen and given to the user. It can be viewed as a continuation of an idea introduced by Katz and Wang; however, unlike the Katz-Wang variant, our scheme is quite efficient, as its ciphertext size is roughly comparable to that of the original full Boneh-Franklin scheme. The security of our scheme can be based on either the gap bilinear Diffie-Hellman (GBDH) or the decisional bilinear Diffie-Hellman (DBDH) assumptions.	id-based encryption;provable security	Nuttapong Attrapadung;Jun Furukawa;Takeshi Gomi;Goichiro Hanaoka;Hideki Imai;Rui Zhang	2007	IEICE Transactions	10.1093/ietfec/e90-a.9.1803	telecommunications;theoretical computer science;mathematics;distributed computing;computer security	Crypto	-39.51124039999499	77.13255926241837	81005
41e8e15c2e20ca1ee15e887e8767c70cd326d5d5	study of randomness in aes ciphertexts produced by various types of dynamic s-boxes	bbs s box;aes secondary key;aes ciphertexts;block cipher;random s boxes;aes s boxes;randomness;advanced encryption standard;nist test suite;s boxes	In this paper, it has been shown that besides using the standard one, many other polynomials in GF2	encryption;randomness;s-box	Suman Das;Ranjan Ghosh	2015	IJICT	10.1504/IJICT.2015.072037	substitution-permutation network;advanced encryption standard;block cipher;computer hardware;computer science;aes implementations;computer security;randomness;statistics	Crypto	-38.60996969305618	81.44479466294221	81200
6a30daa315da4e4182810851b140038f19adf8e9	key recovery attacks on multivariate public key cryptosystems derived from quadratic forms over an extension field			cryptosystem;public-key cryptography;related-key attack	Yasufumi Hashimoto	2017	IEICE Transactions		discrete mathematics;quadratic form;field extension;theoretical computer science;post-quantum cryptography;mathematics;computer security	Crypto	-39.8283902783237	80.3393523407141	81222
03d001ed66bc24e59d383087b0f22d14e2605d96	on solving l p n using b k w and variants	b k w;94a60;walsh hadamard transform;l p n;l w e	The Learning Parity with Noise problem (L P N) is appealing in cryptography as it is considered to remain hard in the post-quantum world. It is also a good candidate for lightweight devices due to its simplicity. In this paper we provide a comprehensive analysis of the existing L P N solving algorithms, both for the general case and for the sparse secret scenario. In practice, the L P N-based cryptographic constructions use as a reference the security parameters proposed by Levieil and Fouque. But, for these parameters, there remains a gap between the theoretical analysis and the practical complexities of the algorithms we consider. The new theoretical analysis in this paper provides tighter bounds on the complexity of L P N solving algorithms and narrows this gap between theory and practice. We show that for a sparse secret there is another algorithm that outperforms B K W and its variants. Following from our results, we further propose practical parameters for different security levels.	algorithm;asiacrypt;bernoulli polynomials;covering code;information retrieval;iteration;oracle fusion architecture;parity learning;post-quantum cryptography;sparse matrix;time complexity;unified framework	Sonia Bogos;Florian Tramèr;Serge Vaudenay	2015	Cryptography and Communications	10.1007/s12095-015-0149-2	combinatorics;computer science;theoretical computer science;mathematics;algorithm;statistics;algebra	AI	-37.975445537288294	79.57463781589954	81355
eaaa5d5e002df86e1e1d0eb7497cc1d7c9262e3d	wcfb: a tweakable wide block cipher		We define a model for applications that process large data sets in a way that enables additional optimizations of encryption operations. We designed a new strong pseudo-random tweakable permutation, WCFB, to take advantage of identified characteristics. WCFB is built with only 2m + 1 block cipher invocation for m cipherblocks and ≈ 5m XOR operations. WCFB can benefit from commonly occurring plaintext, such as encryption of a 0 sector, and repeated operations on the same wide block. We prove the birthday-bound security of the mode, expressed in terms of the security of the underlying block cipher. A case analysis of disk block access requests by Windows 8.1 is provided.	birthday attack;block cipher;encryption;exclusive or;microsoft windows;plaintext;pseudorandom permutation;pseudorandomness	Andrey Jivsov	2014	IACR Cryptology ePrint Archive			Crypto	-36.84418850718127	78.70474549185515	81379
61e69c89a3b997a56a8b03890824214ff85d4cc9	function secret sharing using fourier basis		Function secret sharing (FSS) scheme, formally introduced by Boyle et al. at EUROCRYPT 2015, is a mechanism that calculates a function f(x) for (xin {0,1}^n) which is shared among p parties, by using distributed functions (f_{i}:{0,1}^n rightarrow mathbb {G}) ((1le ile p)), where (mathbb {G}) is an Abelian group, while the function (f:{0,1}^n rightarrow mathbb {G}) is kept secret to the parties. We observe that any function f can be described as a linear combination of the basis functions by regarding the function space as a vector space of dimension (2^n) and give a new framework for FSS schemes based on this observation. Based on the new framework, we introduce a new FSS scheme using the Fourier basis. This method provides efficient computation for a different class of functions (e.g., hard-core predicates of one-way functions), which may be inefficient to compute if we use the standard basis such as point functions. Our FSS scheme based on the Fourier basis is quite simple due to the fact that the Fourier basis is closed under the multiplication, while the previous constructions have to incorporate some complex mechanisms to overcome the difficulty.	basis function;computation;eurocrypt;flying-spot scanner;hard-core predicate;javaserver pages;one-way function;phelim boyle;randomness;secret sharing	Takuya Ohsawa;Naruhiro Kurokawa;Takeshi Koshiba	2017		10.1007/978-3-319-65521-5_78	discrete mathematics;linear combination;vector space;computer science;shamir's secret sharing;distributed computing;function space;homomorphic secret sharing;basis function;secret sharing;standard basis	Crypto	-40.12403188971888	76.47992348946823	81399
20df89a41c7eb61c469bdc23e846f0ad259b0b1d	efficient collision attack frameworks for ripemd-160		In this paper, we re-consider the connecting techniques to find collisions, which is achieved by connecting the middle part with the initial part. To obtain the best position of middle part, we propose two principles to deal with the case that is not ideal. Then, we reviewed the searching strategy to find a differential path presented at Asiacrypt 2017, we observe some useful characteristics of the path which is not used in their work. To fully capture the characteristics of the differential path discovered by the searching strategy, we find an efficient attack framework under the guidance of the two principles, which in turn helps improve the searching strategy. Under our efficient attack framework, we easily improve the collision attack on 30-step RIPEMD-160 by a factor of 213. And we believe that the collision attack can be further improved under this efficient framework if the differential path is discovered by taking the new strategies into consideration. For some interest, we also consider an opposite searching strategy and propose another efficient attack framework special for the differential path discovered by the new searching strategy. Under this new framework, we find we can control one more step than that special for the original searching strategy. Therefore, we expect that we can obtain better collision attack by adopting the new searching strategy and attack framework. Moreover, combining with the searching tool, it is potential to give a tight upper bound of steps to mount collision attack on reduced RIPEMD-160 when adopting the two searching strategies.	asiacrypt;collision attack	Fukang Liu	2018	IACR Cryptology ePrint Archive		collision attack;ripemd;theoretical computer science;computer science	Crypto	-36.80578448703223	80.04891861414205	81419
0a699915ecab60e77000fe78762aead6990b3939	cryptographic hashing from strong one-way functions		Constructing collision-resistant hash families (CRHFs) from one-way functions is a long-standing open problem and source of frustration in theoretical cryptography. In fact, there are strong negative results: black-box separations from one-way functions that are 2−(1−o(1))n-secure against polynomial time adversaries (Simon, EUROCRYPT ’98) and even from indistinguishability obfuscation (Asharov and Segev, FOCS ’15). In this work, we formulate a mild strengthening of exponentially secure one-way functions, and we construct CRHFs from such functions. Specifically, our security notion requires that every polynomial time algorithm has at most 2−n · negl(n) probability of inverting two independent challenges. More generally, we consider the problem of simultaneously inverting k functions f1, . . . , fk, which we say constitute a “one-way product function” (OWPF). We show that sufficiently hard OWPFs yield hash families that are multi-input correlation intractable (Canetti, Goldreich, and Halevi, STOC ’98) with respect to all sparse (bounded arity) output relations. Additionally assuming indistinguishability obfuscation, we construct hash families that achieve a broader notion of correlation intractability, extending the recent work of Kalai, Rothblum, and Rothblum (CRYPTO ’17). In particular, these families are sufficient to instantiate the Fiat-Shamir heuristic in the plain model for a natural class of interactive proofs. An interesting consequence of our results is a potential new avenue for bypassing black-box separations. In particular, proving (with necessarily non-black-box techniques) that parallel repetition amplifies the hardness of specific one-way functions – for example, all oneway permutations – suffices to directly bypass Simon’s impossibility result.	algorithm;best, worst and average case;black box;blueprint;clean;collision resistance;comment (computer programming);computational hardness assumption;cryptographic hash function;cryptography;discrete logarithm;eurocrypt;fiat–shamir heuristic;generic group model;ibm notes;jh (hash function);omer reingold;one-way function;p (complexity);plausibility structure;polynomial;provable security;react;sparse matrix;symposium on foundations of computer science;symposium on theory of computing;time complexity;universal instantiation	Justin Holmgren;Alex Lombardi	2018	IACR Cryptology ePrint Archive		cryptographic hash function;one-way function;theoretical computer science;mathematics	Crypto	-37.126733666456246	76.41018020018971	81532
f327f7811f865795e5bbf57cfdb43c9bf94d1e4f	comments on the 'm out of n oblivious transfer'	security in digital systems;procesamiento informacion;oblivious transfer;securite donnee;satisfiability;systeme numerique;digital system;criptografia;cryptography;digital systems;information processing;sistema numerico;cryptographie;traitement information;security of data	This paper analyses the 'm out of n oblivious transfer', presented at the ACISP 2002 Conference. It is shown that the schemes presented in the paper fail to satisfy the requirements of the oblivious transfer.	oblivious transfer	Hossein Ghodosi;Rahim Zaare-Nahandi	2006	Inf. Process. Lett.	10.1016/j.ipl.2005.08.014	information processing;computer science;cryptography;theoretical computer science;oblivious transfer;computer security;algorithm;satisfiability	Crypto	-43.16560384814623	79.02875374393926	81749
a9da4a0ff2644352ddde52a605ce2bf9cb24a1a0	provable secure proxy signature scheme without bilinear pairings	elliptic curve discrete logarithm problem;digital signature;bilinear pairings;proxy signature	SUMMARY#R##N##R##N#Proxy signature is an active research area in cryptography. A proxy signature scheme allows an entity to delegate his or her signing capability to another entity in such a way that the latter can sign messages on behalf of the former. Many proxy signature schemes using bilinear pairings have been proposed. But the relative computation cost of the pairing is more than 10 times of the scalar multiplication over elliptic curve group. In order to save the running time and the size of the signature, we propose a proxy signature scheme without bilinear pairings and prove its security against adaptive chosen-message attack in random oracle model. The security of our scheme is based on the hardness of the elliptic curve discrete logarithm problem. With the running time being saved greatly, our scheme is more practical than the previous related scheme for practical applications. Copyright © 2011 John Wiley & Sons, Ltd.	bilinear filtering;digital signature;provable security	Namita Tiwari;Sahadeo Padhye	2013	Int. J. Communication Systems	10.1002/dac.1367	ring signature;digital signature;merkle signature scheme;elliptic curve digital signature algorithm;computer science;theoretical computer science;internet privacy;schnorr signature;elgamal signature scheme;computer security	Security	-41.907047300536114	75.12100549887569	81811
066b9238e7e0ac5b704d4d192b675841416456aa	a model for structure attacks, with applications to present and serpent	block cipher;structure attack;present;serpent;differential	As a classic cryptanalytic method for block ciphers, hash functions and stream ciphers, many extensions and refinements of differential cryptanalysis have been developed. In this paper, we focus on the use of so-called structures in differential attacks, i.e. the use of multiple input and one output difference. We give a general model and complexity analysis for structure attacks and show how to choose the set of differentials to minimize the time and data complexities. Being a subclass of multiple differential attacks in general, structure attacks can also be analyzed in the model of Blondeau et al. from FSE 2011. In this very general model, a restrictive condition on the set of input differences is required for the complexity analysis. We demonstrate that in our dedicated model for structure attacks, this condition can be relaxed, which allows us to consider a wider range of differentials. Finally, we point out an inconsistency in the FSE 2011 attack on 18 rounds of the block cipher PRESENT and use our model for structure attacks to attack 18-round PRESENT and improve the previous structure attacks on 7-round and 8-round Serpent. To the best of our knowledge, those attacks are the best known differential attacks on these two block ciphers.	algorithm;analysis of algorithms;attack model;bcrypt;block cipher;differential cryptanalysis;ecrypt;fast software encryption;hash function;microtransaction;relevance;stream cipher;time complexity	Meiqin Wang;Yue Sun;Elmar Tischhauser;Bart Preneel	2012		10.1007/978-3-642-34047-5_4	block cipher;differential cryptanalysis;discrete mathematics;higher-order differential cryptanalysis;correlation attack;mathematics;computer security;algorithm;linear cryptanalysis	Crypto	-37.91212163032618	78.73472475405667	81837
23014eddb7438d371b2e7478a8e5c30d45e5bbe7	chaotic quantum cryptography - the ultimate for network security	quantum theory;nonlinear function;quantum cryptography;heisenberg uncertainty;quantum network;communication security;optical communication;cryptography;quantum mechanics;quantum state	As the sophistication of intruders' increases, so does the incidents of information integrity breaches and network attacks. In response, very complex cryptographic processes have started being employed, such as chaos theory and quantum theory, in an effort to create the “holy grail” of cryptographic systems and network security.	chaos theory;network security;quantum cryptography;quantum mechanics	Stamatios V. Kartalopoulos	2010	2010 International Conference on Signal Processing and Multimedia Applications (SIGMAP)			EDA	-43.09063134846711	82.72158985627858	82450
915480f391dc3269ccf4b3dfce82fec3ed79aa31	distribution of the absolute indicator of random boolean functions		The absolute indicator is one of the measures used to determine the resistance offered by a Boolean function when used in the design of a symmetric cryptosystem. It was proposed along with the sum of square indicator to evaluate the quality of the diffusion property of block ciphers and hash functions. While the behaviour of the sum of square of random Boolean functions was already known, what remained was the study of the comportment of the absolute indicator of random Boolean functions. As an application, we show that the absolute indicator can distinguish a nonrandom binary sequence from a random one.	bitstream;block cipher;cryptography;cryptosystem;hash function;nonlinear system;symmetric-key algorithm	Florian Caullery;François Rodier	2018	CoRR		discrete mathematics;boolean function;pseudorandom binary sequence;mathematics;cryptosystem;block cipher;hash function	Crypto	-38.735858261467726	82.26870298685766	83309
5a9b17fae462faa6467016afb7758283899770e8	a simplified approach to threshold and proactive rsa	blow up;probability of error;distributed computing;general techniques;digital signature;criptografia;cryptography;signature numerique;cryptographie;threshold signature	We present a solution to both the robust threshold RSA and proactive RSA problems. Our solutions are conceptually simple, and allow for an easy design of the system. The signing key, in our solution, is shared at all times in additive form, which allows for simple signing and for a particularly efficient and straightforward refreshing process for proactivization. The key size is (up to a very small constant) the size of the RSA modulus, and the protocol runs in constant time, even when faults occur, unlike previous protocols where either the size of the key has a linear blow-up (at best) in the number of players or the run time of the protocol is linear in the number of faults. The protocol is optimal in its resilience as it can tolerate a minority of faulty players. Furthermore, unlike previous solutions, the existence and availability of the key throughout the lifetime of the system, is guaranteed without probability of error. These results are derived from a new general technique for transforming distributed computations for which there is a known n-out-n solution into threshold and robust computations.	computation;key size;modulus of continuity;proactive parallel suite;rsa (cryptosystem);run time (program lifecycle phase);time complexity;utility functions on indivisible goods	Tal Rabin	1998		10.1007/BFb0055722	digital signature;computer science;cryptography;theoretical computer science;probability of error;mathematics;distributed computing;computer security;statistics	Theory	-37.62847626870656	77.08636401629336	83519
98c1c4c5e24b33f2ca24115951f9db1583ac68ed	fault attack against miller's algorithm	miller's algorithm;grbner base;pairing;magma;fault attack	We complete the study of [23] and [27] about Miller’s algorithm. Miller’s algorithm is a central step to compute the Weil, Tate and Ate pairings. The aim of this article is to analyze the weakness of Miller’s algorithm when it undergoes a fault attack. We prove that Miller’s algorithm is vulnerable to a fault attack which is valid in all coordinate systems, through the resolution of a nonlinear system. We highlight the fact that putting the secret as the first argument of the pairing is not a countermeasure. This article is an extensed version of the article [15].	algorithm;differential fault analysis;nonlinear system	Nadia El Mrabet	2011	IACR Cryptology ePrint Archive		coordinate system;nonlinear system;pairing;algorithm;side channel attack;countermeasure;mathematics;pairing-based cryptography	Crypto	-39.383854830842125	81.6258704599886	83554
410d4e5535c5f817bf8da805813f828bc3753611	on the security of rotation operation based ultra-lightweight authentication protocols for rfid systems		Passive Radio Frequency IDentification (RFID) tags are generally highly constrained and cannot support conventional encryption systems to meet the required security. Hence, designers of security protocols may try to achieve the desired security only using limited ultra-lightweight operations. In this paper, we show that the security of such protocols is not provided by using rotation functions. In the following, for an example, we investigate the security of an RFID authentication protocol that has been recently developed using rotation function named ULRAS, which stands for an Ultra-Lightweight RFID Authentication Scheme and show its security weaknesses. More precisely, we show that the ULRAS protocol is vulnerable against de-synchronization attack. The given attack has the success probability of almost ‘1’, with the complexity of only one session of the protocol. In addition, we show that the given attack can be used as a traceability attack against the protocol if the parameters’ lengths are an integer power of 2, e.g., 128. Moreover, we propose a new authentication protocol named UEAP, which stands for an Ultra-lightweight Encryption based Authentication Protocol, and then informally and formally, using Scyther tool, prove that the UEAP protocol is secure against all known active and passive attacks.		Masoumeh Safkhani;Nasour Bagheri;Mahyar Shariat	2018	Future Internet	10.3390/fi10090082	traceability;radio-frequency identification;computer network;encryption;computer science;authentication protocol;cryptographic protocol;mobile commerce;authentication	ML	-44.757508687132585	75.12374561000017	83589
9d2af57190b6d65dae23856b4cecdd7f03ad0bec	design and analysis of password-based key derivation functions	provable security;iterative method;password based security;exhaustive key search;echantillonneur bloqueur;security analysis;protocole transmission;dictionary attack;ietf protocol;securite donnee;cryptography iterative methods;metodo iterativo;iterative methods;protocolo transmision;password based security cryptography dictionary attack exhaustive key search key derivation function kdf;dictionnaire;mot de passe;sample and hold circuit;methode iterative;criptografia;cryptography;exhaustive key search password based key derivation function kdf cryptographic key security application iteration count industry standard;password;dictionaries;cryptographie;muestreador mantenedor;security cryptography raw materials entropy dictionaries construction industry computer science computer architecture laboratories electronic mail;key derivation function kdf;protocolo ietf;protocole ietf;diccionario;security of data;contrasena;transmission protocol	A password-based key derivation function (KDF)-a function that derives cryptographic keys from a password-is necessary in many security applications. Like any password-based schemes, such KDFs are subject to key search attacks (often called dictionary attacks). Salt and iteration count are used in practice to significantly increase the workload of such attacks. These techniques have also been specified in widely adopted industry standards such as PKCS and IETF. Despite the importance and widespread usage, there has been no formal security analysis on existing constructions. In this correspondence, we propose a general security framework for password-based KDFs and introduce two security definitions each capturing a different attacking scenario. We study the most commonly used construction H/sup (c)/(p/spl par/s) and prove that the iteration count c, when fixed, does have an effect of stretching the password p by log/sub 2/c bits. We then analyze the two standardized KDFs in PKCS #5. We show that both are secure if the adversary cannot influence the parameters but subject to attacks otherwise. Finally, we propose a new password-based KDF that is provably secure even when the adversary has full control of the parameters.	key derivation function;password	F. Frances Yao;Yiqun Lisa Yin	2005	IEEE Trans. Information Theory	10.1109/TIT.2005.853307	zero-knowledge password proof;pbkdf2;s/key;computer science;theoretical computer science;salt;mathematics;iterative method;internet privacy;key derivation function;one-time password;key stretching;password;computer security;password strength	Crypto	-41.17101277229235	78.21613597968592	83616
3ca33ca94e235efeb04307ca2b8d8ea70d0d0f4a	explicit optimal-rate non-malleable codes against bit-wise tampering and permutations		A non-malleable code protects messages against various classes of tampering. Informally, a code is non-malleable if the effect of applying any tampering function on an encoded message is to either retain the message or to replace it with an unrelated message. Two main challenges in this area – apart from establishing the feasibility against different families of tampering – are to obtain explicit constructions and to obtain high-rates for such constructions. In this work, we present a compiler to transform low-rate (in fact, zero rate) non-malleable codes against certain class of tampering into an optimal-rate – i.e., rate 1 – non-malleable codes against the same class. If the original code is explicit, so is the new one. When applied to the family of bit-wise tampering functions, this subsumes (and greatly simplifies) a recent result of Cheraghchi and Guruswami (TCC 2014). Further, our compiler can be applied to non-malleable codes against the class of bit-wise tampering and bit-level permutations. Combined with the rate-0 construction in a companion work, this yields the first explicit rate-1 non-malleable code for this family of tampering functions. Our compiler uses a new technique for boot-strapping non-malleability by introducing errors, that may be of independent interest.	bit-level parallelism;code;compiler;non-malleable codes	Shashank Agrawal;Divya Gupta;Hemanta K. Maji;Omkant Pandey;Manoj Prabhakaran	2014	IACR Cryptology ePrint Archive		compiler;discrete mathematics;permutation;bitwise operation;mathematics;code (cryptography)	Crypto	-37.013046837924016	78.49162021947723	83617
13b72dc80470673bb83d8dc0f145fc0d248f8799	algebraic partitioning: fully compact and (almost) tightly secure cryptography		We describe a new technique for conducting “partitioning arguments”. Partitioning arguments are a popular way to prove the security of a cryptographic scheme. For instance, to prove the security of a signature scheme, a partitioning argument could divide the set of messages into “signable” messages for which a signature can be simulated during the proof, and “unsignable” ones for which any signature would allow to solve a computational problem. During the security proof, we would then hope that an adversary only requests signatures for signable messages, and later forges a signature for an unsignable one. In this work, we develop a new class of partitioning arguments from simple assumptions. Unlike previous partitioning strategies, ours is based upon an algebraic property of the partitioned elements (e.g., the signed messages), and not on their bit structure. This allows to perform the partitioning efficiently in a “hidden” way, such that already a single “slot” for a partitioning operation in the scheme can be used to implement many different partitionings sequentially, one after the other. As a consequence, we can construct complex partitionings out of simple basic (but algebraic) partitionings in a very space-efficient way. As a demonstration of our technique, we provide the first signature and public-key encryption schemes that achieve the following properties simultaneously: they are (almost) tightly secure under a simple assumption, and they are fully compact (in the sense that parameters, keys, and signatures, resp. ciphertexts only comprise a constant number of group elements).	adversary (cryptography);antivirus software;call of duty: black ops;computational problem;digital signature;encryption;execution unit;fo (complexity);field electron emission;lu decomposition;linear algebra;mahdiyar;numerical aperture;pa-risc;preprocessor;provable security;public-key cryptography;quadratic equation;type signature	Dennis Hofheinz	2015	IACR Cryptology ePrint Archive	10.1007/978-3-662-49096-9_11	combinatorics;discrete mathematics;theoretical computer science;mathematics	Crypto	-37.40002006447839	76.95247996015324	83884
28be386a5a249e14ba9cd9b9131e9bee5078671b	weaknesses in two group diffie-hellman key exchange protocols		In this paper we show that the password-based Diffie-Hellman key exchange protocols due to Byun and Lee suffer from dictionary attacks.	dictionary attack;diffie–hellman key exchange;key-agreement protocol;mitchell corporation;password;vulnerability (computing)	Qiang Tang;Liqun Chen	2005	IACR Cryptology ePrint Archive		theoretical computer science;password;diffie–hellman key exchange;dictionary attack;key exchange;computer science	Security	-43.5428641345567	75.75820360605023	84105
b3952b61c4e895e99314343a7c51234706d5cb1a	security mechanisms with selfish players in wireless networks	game theory;wireless network	It is frequently assumed that the parties involved in a security mechanism will behave according to everyone’s expectation. However, some of them might be tempted to depart from the expected (or canonical) behavior, because such a deviation is more beneficial for them. As an illustration, we will consider that phenomenon in the framework of wireless networks. We will briefly introduce some basic background in game theory and provide an overview of several recent contributions to that field. Finally, we will consider two examples in more detail, namely revocation in high-mobility (or “ephemeral”) networks and pseudonym change in mix zones.#R##N##R##N#Notes:Some of the material of this talk appears in the book “Security and Cooperation in Wireless Networks” by L. Buttyan and J.-P. Hubaux, Cambridge University Press, 2008, available at http://secowinet.epfl.ch#R##N##R##N#A list of applications of game theory to various security (and cryptography) problems can be found at: http://lca.epfl.ch/projects/gamesec		Jean-Pierre Hubaux	2010		10.1007/978-3-642-14577-3_2	game theory;simulation;computer science;artificial intelligence;wireless network;computer security	ECom	-44.40664834984094	83.9110392354756	84724
a46f6ca0d1c8696a1f0c0be07d4904980c4271b7	cryptography and the internet	protocole transmission;protocolo transmision;internet;criptografia;cryptography;cryptographie;computer science;transmission protocol	After many years, cryptography is coming to the Internet. Some protocols are in common use; more are being developed and deployed. The major issue has been one of cryptographic engineering: turning academic papers into a secure, implementable speciication. But there is missing science as well, especially when it comes to eecient implementation techniques.	cryptographic engineering;cryptography;internet	Steven M. Bellovin	1998		10.1007/BFb0055719	financial cryptography;telecommunications;computer science;cryptography;cryptography law;world wide web;computer security;statistics	Crypto	-45.385153511686504	78.89394902067617	84841
363a6ff8936abd7b4623b4a6592d4579c8219ad6	short (identity-based) strong designated verifier signature schemes	verifier;modelizacion;distributed system;short signature;systeme reparti;formal specification;strong designated verifier signature scheme;bepress selected works;securite informatique;signature electronique;probabilistic approach;based;specification formelle;designated verifier signature;computer security;modelisation;security proof;especificacion formal;formal verification;sistema repartido;signature scheme;digital signature;random oracle model;enfoque probabilista;approche probabiliste;era2012;seguridad informatica;forth;signature;strong;random oracle;verification formelle;short;firma numerica;schemes;identity;modeling;oracle;identity based;designated	The notion of strong designated verifier signature was put forth by Jakobsson, Sako and Impagliazzo in 1996, but the formal definition was defined recently by Saeednia, Kremer and Markowitch in 2003 and revisited by Laguillaumie and Vergnaud in 2004. In this paper, we firstly propose the notion of short strong designated verifier signature scheme, and extend it to the short identity-based strong designated verifier scheme. Then, we propose the first construction of short strong designated verifier signature scheme. We also extend our scheme to construct a short identity-based strong designated verifier signature scheme. The size of the signature of our schemes is the shortest compared to any existing schemes reported in the literature. We provide formal security proofs for our schemes based on the random oracle model. Finally, we also discuss an extension of our scheme to construct a short strong designated verifier signature without random oracle.	designated verifier signature	Xinyi Huang;Willy Susilo;Yi Mu;Futai Zhang	2006		10.1007/11689522_20	random oracle;computer science;database;computer security;algorithm	Crypto	-42.2759390128158	77.19585962019856	85028
12e7577094dfba47a91c725c3a0985ee45c74e78	cryptographic key distribution and authentication protocols for secure group communication	authentication	Authentication protocols have until now focussed on two or three party interaction and neglected n party interactions as in the case of more general group communication. In this discourse, the semantics of group authentication are addressed and a separation into complete and selective group authentication techniques is proposed.	authentication protocol;key (cryptography);key distribution	Andrew Hutchison;Kurt Bauknecht	1996			data authentication algorithm;cryptographic primitive;ipsec;key exchange;challenge–response authentication;computer science;authentication protocol;cryptographic nonce;key management;lightweight extensible authentication protocol;hash-based message authentication code;authentication;cryptographic protocol;cryptographic key types;controlled cryptographic item;computer security;tls-srp;key encapsulation	Crypto	-42.64973151565991	75.7076949474484	85066
8ac0b44ff8b98af72e736493e0052ceecc5af069	secured anonymous id assignment support for lin6	internet protocol;anonymity;distributed system;red sin hilo;movilidad;systeme reparti;confidencialidad;mise a jour;informatique mobile;protocolo internet;cle privee;reseau sans fil;securite;mobility;localization;wireless network;protocole internet;cle publique;mobile computer;localizacion;mobilite;confidentiality;anonymat;actualizacion;vida privada;confidentialite;sistema repartido;localisation;public key;private life;clave privada;private key;safety;denial of service;llave publica;vie privee;mobile node;mobile computing;seguridad;updating;denegacion de servicio;deni service;anonimato;dos attack	Although mobility support protocols such as Mobile IPv6 and LIN6 are essential for a real mobile computing environment, there is an privacy issue: these protocols have to disclose an identity of the node to receive the benefit of mobility support. In this paper, we attempt to address this issue by assigning an identity to a mobile node dynamically and securely without disclosing the statically-assigned ID of the node in the LIN6 protocol. In our method, a mobile node generates an ephemeral public/private key pair and decides a LIN6 ID that is given by a hash of the public key. This LIN6 ID is called anonymized LIN6 ID. Then the mobile node requests to assign this ID dynamically to the Mapping Agent that maintains location information of the ID. The Mapping Agent issues a shared secret for updating the location information to the mobile node by using the public key. A mobile node can discard the ID or request a new ID whenever the node wants, thus it is hard to track the mobile node with the anonymized LIN6 ID. We also discuss the characteristics of anonymity and the potential of DoS attack in our proposed method.		Masahiro Ishiyama;Mitsunobu Kunishi;Michimune Kohno;Fumio Teraoka	2004		10.1007/978-3-540-25978-7_31	telecommunications;computer science;kademlia;public-key cryptography;mobile computing;world wide web;computer security;denial-of-service attack	HCI	-45.96738696922956	78.50599949721371	85111
01875108c336a90e8f4940e85cd9f2d130a63f50	ae5 security notions: definitions implicit in the caesar call		A draft call for the CAESAR authenticated-encryption competition adopts an interface that is not aligned with existing definitions in the literature. It is the purpose of this brief note to formalize what we believe to be the intended definitions.	authenticated encryption;authentication;caesar	Chanathip Namprempre;Phillip Rogaway;Thomas Shrimpton	2013	IACR Cryptology ePrint Archive		artificial intelligence;computer science	Crypto	-34.796774960973124	74.571331156409	85235
117792ee50da2442c5a7a771e92436f2368226d3	on security of koyama schemes		An attack is possible upon all three RSA analogue PKCs based on singular cubic curves given by Koyama. While saying so, Seng et al observed that the scheme become insecure if a linear relation is known between two plaintexts. In this case, attacker has to compute greatest common divisor of two polynomials corresponding to those two plaintexts. However, the computation of greatest common divisor of two polynomials is not efficient. For the reason, the degree e of both polynomials, an encryption exponent, is quite large. In this paper, we propose an algorithm, which makes the attack considerably efficient. Subsequently, we identify isomorphic attack on the Koyama schemes by using the isomorphism between two singular cubic curves.		Sahadeo Padhye	2005	IACR Cryptology ePrint Archive		discrete mathematics;pkcs;isomorphism;computation;encryption;polynomial;exponent;mathematics;greatest common divisor	Crypto	-39.29519748943229	80.52933229847754	85348
532ff27874bbd54dcbafea4b80307a5309389a2f	randomness quality of ci chaotic generators: applications to internet security	information hiding internet security chaotic sequences statistical tests discrete chaotic iterations;data hiding;ci chaotic generator;chaotic sequences;discrete chaotic iterations;information hiding;random number generation;statistical test;data hiding scheme;data encapsulation;numerous cryptosystem;internet;randomness quality;cryptography;comparative study;devaney randomness quality ci chaotic generator internet security pseudorandom number generator numerous cryptosystem data hiding scheme conference internet 09 chaotic iteration;chaotic iteration;devaney;statistical tests;conference internet 09;statistical testing;pseudo random number generator;internet security;pseudorandom number generator;statistical testing chaos generators cryptography data encapsulation internet random number generation;chaos generators	Due to the rapid development of the Internet in recent years, the need to find new tools to reinforce trust and security through the Internet has became a major concern. The discovery of new pseudo-random number generators with a strong level of security is thus becoming a hot topic, because numerous cryptosystems and data hiding schemes are directly dependent on the quality of these generators. At the conference Internet`09, we have described a generator based on chaotic iterations, which behaves chaotically as defined by Devaney. In this paper, the proposal is to improve the speed and the security of this generator, to make its use more relevant in the Internet security context. To do so, a comparative study between various generators is carried out and statistical results are given. Finally, an application in the information hiding framework is presented, to give an illustrative example of the use of such a generator in the Internet security field.	cryptosystem;internet security;iteration;pseudorandomness;random number generation;randomness	Jacques M. Bahi;Xiaole Fang;Christophe Guyeux;Qianxue Wang	2010	2010 2nd International Conference on Evolving Internet	10.1109/INTERNET.2010.30	computer security model;statistical hypothesis testing;security through obscurity;computer science;theoretical computer science;internet security;distributed computing;information hiding;pseudorandom number generator;computer security;statistics	DB	-41.50183586550158	84.06638992537351	85828
8280db5a5d99422c5a6c2e4f6a3303fe18013c51	news track		quickly unscramble computergenerated code that until now has been considered secure was presented in Prague by one of the world’s foremost cryptographers, Adi Shamir, coinventor of R.S.A., the international standard for secure transmission. Shamir’s idea combines existing technology into a special, reasonably priced computer that would make factoring numbers as long as 150 digits much easier, thus making it simpler to reveal messages scarambled with public-key encryption methods. Researchers say the machine could mean that cryptographic systems with keys of 512 bits or less—that is, keys less than 150 digits long—would be vulnerable, an exposure that was unthinkable five years ago. The longer, 1,024-bit keys available today would not be vulnerable at present.	alternating direction implicit method;encryption;foremost;integer factorization;list of cryptographers;public-key cryptography;scrambler;secure transmission	Robert Fox	1999	Commun. ACM	10.1145/306549.306552		Security	-36.353049272204274	79.42459063153345	85901
92b74904f8adb4aaf1616e2375ce45374c018397	an identity-based signature scheme from the weil pairing	public key cryptography;evaluation performance;performance evaluation;securite;evaluacion prestacion;quadraric residue;cle publique;school of engineering and science;indexing terms;id based signature scheme;quadratic residue;identity based encryption public key security public key cryptography postal services performance analysis elliptic curves equations;signature scheme;public key;280000 information computing and communication sciences;digital signature;criptografia;cryptography;weil pairing;identification;safety;llave publica;signature numerique;cryptographie;identificacion;firma numerica;seguridad;public key cryptosystem identity based signature weil pairing id based signature hard diffie hellman problem signature size;diffie hellman;diffie hellman problem;identity based signature	We come up with an ID-based signature scheme from the Weil pairing. Our scheme is secure if the Diffie-Hellman problem is hard. Furthermore, our signature size is only about a quarter of ID-based Guillou-Quisquater (1988) signature size.	computational diffie–hellman assumption;diffie–hellman problem;digital signature	Xun Yi	2003	IEEE Communications Letters	10.1109/LCOMM.2002.808397	ring signature;arithmetic;computer science;mathematics;public-key cryptography;schnorr signature;computer security;algorithm	Crypto	-42.06214123137442	78.88232394849287	86121
67a2154e66204146f35a7fa2a53d32d88d5775df	a light-weight bit commitment protocol based on unpredictable channel noise		Abstract Bit commitment is an important tool in the design of many secure cryptographic protocols, such as coin flipping, zero-knowledge proof, and secure computation. In this paper, we present a computationally light-weight bit commitment protocol over a noisy channel. For the security of the proposed protocol, we show that the receiver has almost no information about the committeru0027s secret due to unpredictability of the noises in the communication channel. Hence, the security of our bit commitment protocol does not depend on hard problems; it is information-theoretically secure. Furthermore, the protocol needs only exclusive-or operations. Thus, it is computationally light-weight, and it can be used in the devices whose computing resources are limited.		Albert Guan;Wen-Guey Tzeng	2019	Theor. Comput. Sci.	10.1016/j.tcs.2018.06.051	discrete mathematics;mathematics;computer network;binary symmetric channel;cryptographic protocol;secure multi-party computation;coin flipping;communication channel	Crypto	-37.23301497302745	75.1175781539157	86158
009ebb7e61fe4a709e6a002e6b28d5119fecdd05	intrusion-aware trust model for vehicular ad hoc networks	pedestrian safety;poison control;injury prevention;trust management;safety literature;traffic safety;injury control;home safety;injury research;safety abstracts;human factors;occupational safety;safety;safety research;ad hoc networks;accident prevention;violence prevention;vehicular networks;bicycle safety;poisoning prevention;falls;ergonomics;suicide prevention;privacy	In vehicular ad hoc networks, peers make decisions on the basis of the information provided by the other peers. If the received information is fake, then the result could be catastrophic, such as road accidents. Therefore, many researchers use the concept of trust to evaluate the trustworthiness of the received data. However, existing trust management schemes (proposed so far for the vehicular networks) are suffered from various limitations. For example, some schemes measure trust on the basis of the history of interactions, which is infeasible for vehicular networks due to its ephemeral nature. Also, none of the existing schemes operate in an identity anonymous environment. In order to overcome these limitations, we propose a novel trust management scheme for identity anonymous vehicular ad hoc networks. The proposed method is simple and completely decentralized that makes it easy to implement in the vehicular networks. Also, we prove that the proposed method is not only robust, but it also detects false location and time information. Furthermore, it introduces linear time complexity, which makes it suitable to use in real time. Copyright © 2013 John Wiley & Sons, Ltd.	ansi escape code;basic stamp;download;hoc (programming language);interaction;john d. wiley;privacy;real-time locating system;robustness (computer science);time complexity;trust (emotion);trust management (information system);trust management (managerial science)	Riaz Ahmed Shaikh;Ahmed Saeed Alzahrani	2014	Security and Communication Networks	10.1002/sec.862	vehicular ad hoc network;wireless ad hoc network;simulation;computer science;suicide prevention;human factors and ergonomics;injury prevention;internet privacy;privacy;computer security	Mobile	-46.67353750371373	75.55665421118407	86162
5e23034cdb051e0e82d58fed9a2897a358c7401b	practical secure biometrics using set intersection as a similarity measure	similarity measure	A novel scheme for securing biometric templates of variable size and order is proposed. The proposed scheme is based on new similarity measure approach, namely the set intersection, which strongly resembles the methodology used in most current state-of-the-art biometrics matching systems. The applicability of the new scheme is compared with that of the existing principal schemes, and it is shown that the new scheme has clear advantages over the existing approaches.	acm-mm;authentication;automatic identification and data capture;biometrics;chaffing and winnowing;code (cryptography);commitment scheme;communications security;confidentiality;cryptography;cryptosystem;digital rights management;encryption;fingerprint recognition;fuzzy concept;handbook;ieee transactions on computers;information theory;minutiae;pattern recognition;rsa conference;scalability;signal-to-noise ratio;similarity measure;smart card;statistical model;strong key;switzerland;synthetic intelligence	Daniel Socek;Dubravko Culibrk;Vladimir Bozovic	2007			computer science;pattern recognition;data mining	Security	-41.01392959386608	77.48456035034181	86381
740615cae52f7dbd7fbe5ab74cf6dc7aa4e14695	linkable message tagging: solving the key distribution problem of signature schemes		Digital signatures guarantee practical security only if the corresponding verification keys are distributed authentically; however, arguably, satisfying solutions for the latter have not been found yet. This paper introduces a novel approach for cryptographic message authentication where this problem does not arise: A linkable message tagging scheme (LMT) identifies pairs of messages and accompanying authentication tags as related if and only if these tags were created using the same secret key. Importantly, our primitive fully avoids public keys and hence elegantly sidesteps the key distribution problem of signature schemes. As an application of LMT we envision an email authentication system with minimal user interaction. Email clients could routinely equip all outgoing messages with corresponding tags and verify for incoming messages whether they indeed originate from the same entity as previously or subsequently received messages with identical sender address. As technical contributions we formalize the notions of LMT and its (more efficient) variant CMT (classifiable message tagging), including corresponding notions of unforgeability. For both variants we propose a range of provably secure constructions, basing on different hardness assumptions, with and without requiring random oracles. This article extends prior work of the same authors that appeared in the proceedings of ACISP 2015 (Günther and Poettering in 2015).	antivirus software;block cipher;bulldozer (microarchitecture);central processing unit;digital signature;email authentication;hash function;key (cryptography);key distribution;logistic model tree;message authentication code;oracle machine;provable security;public key infrastructure;public-key cryptography;software deployment;software documentation;software transactional memory;tag (metadata)	Felix Günther;Bertram Poettering	2014	International Journal of Information Security	10.1007/s10207-016-0327-z	computer science;internet privacy;world wide web;computer security	Crypto	-38.76539836209646	75.21398171390634	86483
96c5f3add55c76fc79ac038b72ca9988ea8e9a56	(short paper) a wild velvet fork appears! inclusive blockchain protocol changes in practice		The loosely defined terms hard fork and soft fork have established themselves as descriptors of different classes of upgrade mechanisms for the underlying consensus rules of (proof-of-work) blockchains. Recently, a novel approach termed velvet fork, which expands upon the concept of a soft fork, was outlined in [22]. Specifically, velvet forks intend to avoid the possibility of disagreement by a change of rules through rendering modifications to the protocol backward compatible and inclusive to legacy blocks. We present an overview and definitions of these different upgrade mechanisms and outline their relationships. Hereby, we expose examples where velvet forks or similar constructions are already actively employed in Bitcoin and other cryptocurrencies. Furthermore, we expand upon the concept of velvet forks by proposing possible applications and discuss potentially arising security implications.	backward compatibility;bitcoin;cryptocurrency;fork (software development);proof-of-work system	Alexei Zamyatin;Nicholas Stifter;Aljosha Judmayer;Philipp Schindler;Edgar R. Weippl;William J. Knottenbelt	2018	IACR Cryptology ePrint Archive		computer science;computer security;internet privacy;fork (system call);blockchain	Security	-35.61653364263698	74.89044153704084	86586
d30d41f2983d8bcaaa776be94c6548bb7a426390	a lightweight mutual authentication based on proxy certificate trust list	dispositivo potencia;confiance;psychologie sociale;wireless devices;informatique mobile;securite;availability;disponibilidad;real time;authentication;serveur informatique;dispositif puissance;distributed computing;mobile computer;cache memory;authentification;antememoria;grid;proxy certificate;antememoire;confidence;autenticacion;confianza;rejilla;temps reel;mutual authentication;safety;psicologia social;power device;grille;calculo repartido;tiempo real;servidor informatico;social psychology;mobile computing;seguridad;grid computing;disponibilite;calcul reparti;computer server	We propose Proxy Certificate Trust List (PCTL) to efficiently record delegation traces for grid computing. Our security solution based on PCTL provides functions as follows: (1) On-demand inquiries about real time delegation information of grid computing underway; (2) Lightweight mutual authentication that is beneficial for proxy nodes with limited computation power as wireless devices in mobile computing; (3) A kind of revocation mechanism for proxy certificates to improve the security and availability of grid computing.	computation;grid computing;mobile computing;mutual authentication;probabilistic ctl;tracing (software)	Xin Li;Mizuhito Ogawa	2004		10.1007/978-3-540-30501-9_121	computer science;operating system;authentication;database;distributed computing;mobile computing;world wide web;computer security	HPC	-45.53116178814203	78.30265713924669	86623
e6a7ad3f98ae2351a077a95dd2103805435a24f6	concurrent error detection of fault-based side-channel cryptanalysis of 128-bit rc6 block cipher	block ciphering;rc6 block cipher;detection erreur;field programmable gate array;evaluation performance;deteccion error;performance evaluation;tarea concurrente;concurrent error detection;intellectual property;implementation;block cipher;evaluacion prestacion;cryptanalyse;securite informatique;fpga;red puerta programable;reseau porte programmable;algorithme;computer security;cryptanalysis;algorithm;ejecucion;criptoanalisis;fpga implementation;low latency;chiffrement bloc;concurrent error detections;seguridad informatica;propiedad intelectual;cifrado en bloque;error detection;tâche concurrente;advanced encryption standard;propriete intellectuelle;concurrent task;symmetric encryption;algoritmo	Fault-based side channel cryptanalysis is very effective against symmetric and asymmetric encryption algorithms. Although straightforward hardware and time redundancy based concurrent error detection (CED) architectures can be used to thwart such attacks, they entail significant overhead (either area or performance). In this paper we investigate two systematic approaches to low-cost, low-latency CED for symmetric encryption algorithm RC6. The proposed techniques have been validated on FPGA implementations of RC6, one of the Advanced Encryption Standard finalists.	128-bit;block cipher;cryptanalysis;encryption;error detection and correction;field-programmable gate array;overhead (computing);public-key cryptography;side-channel attack;symmetric-key algorithm	Kaijie Wu;Piyush Mishra;Ramesh Karri	2003	Microelectronics Journal	10.1016/S0026-2692(02)00126-X	multiple encryption;embedded system;block cipher;real-time computing;40-bit encryption;computer science;higher-order differential cryptanalysis;computer security;probabilistic encryption;field-programmable gate array;linear cryptanalysis	EDA	-41.52604196857402	81.78131239123559	86698
2bbafdcba16313a1f0af5ccde7ba5bee32b9cafc	stronger security for sanitizable signatures		Sanitizable signature schemes (SSS) enable a designated party (called the sanitizer) to alter admissible blocks of a signed message. This primitive can be used to remove or alter sensitive data from already signed messages without involvement of the original signer. Current state-of-the-art security definitions of SSSs only define a “weak” form of security. Namely, the unforgeability, accountability and transparency definitions are not strong enough to be meaningful in certain use-cases. We identify some of these use-cases, close this gap by introducing stronger definitions, and show how to alter an existing construction to meet our desired security level. Moreover, we clarify a small yet important detail in the state-of-the-art privacy definition. Our work allows to deploy this primitive in more and different scenarios.	adversary (cryptography);algorithm;ciphertext indistinguishability;correctness (computer science);electronic signature;emoticon;encryption;interactivity;key (cryptography);padding (cryptography);padding oracle attack;primitive recursive function;privacy;pseudorandom function family;pseudorandomness;public-key cryptography;randomness;security parameter;strong authentication;xfig	Stephan Krenn;Kai Samelin;Dieter Sommer	2015	IACR Cryptology ePrint Archive	10.1007/978-3-319-29883-2_7	computer science;data mining;internet privacy;computer security	Security	-39.389223208505435	74.618076800792	86802
3962620d975e4bb9a322831e0f18d174276ff7de	an id-based designated verifier proxy signature scheme without bilinear pairing			bilinear transform	Namita Tiwari;Sahadeo Padhye	2011			computer science;pattern recognition;artificial intelligence;machine learning;pairing;bilinear interpolation	Crypto	-41.74869275562977	77.5524474259648	87177
aba32825246b12a4479d4e750a42b82e0ad781d4	on the security against nonadaptive chosen ciphertext attack and key-dependent message attack	期刊论文		chosen-ciphertext attack;ciphertext	Jinyong Chang;Rui Xue	2014	IEICE Transactions		semantic security;chosen-ciphertext attack;watermarking attack;adaptive chosen-ciphertext attack;pre-play attack;length extension attack;ciphertext indistinguishability;ciphertext-only attack;internet privacy;malleability;computer security;cramer–shoup cryptosystem;replay attack	Crypto	-41.864643788764404	76.86236329056057	87230
8d263d324a8e357aa1bd9b30bb4902d0e94e993c	an improved affine equivalence algorithm for random permutations		In this paper we study the affine equivalence problem, where given two functions F ,G : {0, 1} → {0, 1}, the goal is to determine whether there exist invertible affine transformations A1, A2 over GF (2) n such that G = A2◦F ◦A1. Algorithms for this problem have several wellknown applications in the design and analysis of Sboxes, cryptanalysis of white-box ciphers and breaking a generalized Even-Mansour scheme. We describe a new algorithm for the affine equivalence problem and focus on the variant where F ,G are permutations over n-bit words, as it has the widest applicability. The complexity of our algorithm is about n2 bit operations with very high probability whenever F (or G) is a random permutation. This improves upon the best known algorithms for this problem (published by Biryukov et al. at EUROCRYPT 2003), where the first algorithm has time complexity of n2 and the second has time complexity of about n2 and roughly the same memory complexity. Our algorithm is based on a new structure (called a rank table) which is used to analyze particular algebraic properties of a function that remain invariant under invertible affine transformations. Besides its standard application in our new algorithm, the rank table is of independent interest and we discuss several of its additional potential applications.	algorithm;algorithmic efficiency;cipher;cryptanalysis;eurocrypt;existential quantification;grammatical framework;linear algebra;lookup table;random permutation;time complexity;turing completeness	Itai Dinur	2018		10.1007/978-3-319-78381-9_16	permutation;discrete mathematics;equivalence (measure theory);invertible matrix;block cipher;computer science;algorithm;affine transformation;cryptanalysis	Crypto	-38.21204795829456	79.75887985043603	87375
f4b3abacbff39b173eb2520d809c9d6481070b63	an attack on a nist proposal: ranksign, a code-based signature in rank metric		RankSign is a code-based signature scheme proposed to the NIST competition for postquantum cryptography [AGH17]. It is based on the rank metric and enjoys remarkably small key sizes, about 10KBytes for an intended level of security of 128 bits. It is also one of the fundamental blocks used in the rank metric identity based encryption scheme [GHPT17]. Unfortunately we will show that all the parameters proposed for this scheme in [AGH17] can be broken by an algebraic attack that exploits the fact that the augmented LRPC codes used in this scheme have very low weight codewords.	code word;cryptography;digital signature;id-based encryption;key size	Thomas Debris-Alazard;Jean-Pierre Tillich	2018	CoRR		algebraic number;discrete mathematics;cryptography;encryption;nist;code (cryptography);exploit;mathematics	Crypto	-37.97827680169675	78.92405157143217	87473
a8f16b53461b0ca2c5b041197205cbe1af0492ee	xmss: extended merkle signature scheme		This note describes the eXtended Merkle Signature Scheme (XMSS), anhash-based digital signature system. It follows existing descriptionsnin scientific literature. The note specifies the WOTS+ one-timensignature scheme, a single-tree (XMSS) and a multi-tree variantn(XMSS^MT) of XMSS. Both variants use WOTS+ as a main building block.nXMSS provides cryptographic digital signatures without relying on thenconjectured hardness of mathematical problems. Instead, it is provennthat it only relies on the properties of cryptographic hash functions.nXMSS provides strong security guarantees and is even secure when thencollision resistance of the underlying hash function is broken. It isnsuitable for compact implementations, relatively simple to implement,nand naturally resists side-channel attacks. Unlike most othernsignature systems, hash-based signatures can withstand so far knownnattacks using quantum computers.	merkle signature scheme	Andreas Hülsing;Denis Butin;Stefan-Lukas Gazdag;Joost Rijneveld;Aziz Mohaisen	2018	RFC	10.17487/RFC8391	merkle signature scheme;mathematical problem;collision resistance;cryptographic hash function;cryptography;digital signature;hash function;theoretical computer science;quantum computer;computer science	Theory	-39.08373020946094	77.72796428659379	87780
7c9a8bb46823ec07cbe0aa8f387f9e19f0ef684e	efficient client puzzles based on repeated-squaring		In this paper, we propose a new, nonparallelizable verification-efficient client puzzle. Our puzzle is based on repeated-squaring and enables efficient verification of the puzzle solution that is reported by the client (prover). Client puzzles based on repeated-squaring were first proposed by Rivest et al. in [1] and constitute one of the first examples of nonparallelizable puzzles. The main drawback of these puzzles was their high verification overhead. In this work, we show how this overhead can be significantly reduced by transferring the puzzle verification burden to the prover that executes the puzzle. Given a 1024-bit modulus, the improvement gain in the verification overhead of our puzzle when compared to the original repeatedsquaring puzzle is almost 50 times. We achieve this by embedding a secret – only known to the verifier – within the Euler trapdoor function that is used in repeatedsquaring puzzles. We provide a security proof for this construction. We further show how our puzzle can be integrated in a number of protocols, including those used for efficient protection against DoS attacks and for the remote verification of the computing performance of devices. We validate the performance of our puzzle on a large number of PlanetLab nodes.	client puzzle protocol;dos;denial-of-service attack;euler;experiment;exponentiation by squaring;modulus robot;numerical integration;overhead (computing);planetlab;provable security;trapdoor function	Ghassan O. Karame;Srdjan Capkun	2009	IACR Cryptology ePrint Archive		computer science	Crypto	-41.82594095930474	76.541805178491	88378
f052ccd6e06c8f46c46a7a857b1994abf039bc77	classical and quantum fingerprinting with shared randomness and one-sided error	quantum fingerprinting;faculty of science environment engineering and technology;communication complexity;journal article;quantum physics;020699;quantum physics not elsewhere classified;error probability;simultaneous message passing	Computing whether two binary strings are equal or not is an important task that can be used to protect software, or used as a primitive for authentication. Unfortunately the comparison of two objects, such as two operating systems, may be expensive when the entire message strings that identify these objects must be transmitted over large distances. Fingerprinting allows a significant reduction in communication costs when a small likelihood of error in the comparison is acceptable. Then, rather than transmitting the entire message string for the object itself, a relatively shorter string, or fingerprint, that identifies the object is sent. Although errors may arise in the comparison of fingerprints, this error can be made sufficiently small by simply increasing the fingerprint length. The key question concerned with fingerprinting is, for given message and fingerprint lengths, what is the minimum achievable guaranteed error rate? In this article we partially answer this question for fingerprinting protocols described within Yao’s simultaneous message passing model of communication complexity [1, 2]. The fingerprints are then generated and transmitted by two parties, Alice and Bob, who are forbidden direct communication, but instead allowed to correspond with a referee known as Roger. Our fingerprinting scenario is described as follows (see Fig 1). A supplier, who we call Sapna, chooses two messages, x and y, from a pool of n unique messages and hands them to Alice and Bob, respectively. As communication is considered expensive, Alice and Bob are limited to sending fingerprints of their original messages to Roger, a and b respectively, which they select from a smaller pool of size m. Roger then infers	alice and bob;authentication;communication complexity;fingerprint (computing);message passing;monte carlo algorithm;operating system;quantum fingerprinting;randomness;transmitter;yao graph	Rolf T. Horn;Alison J Scott;Jonathan Walgate;Richard Cleve;A. I. Lvovsky;Barry C. Sanders	2005	Quantum Information & Computation		quantum information;quantum complexity theory;theoretical computer science;probability of error;quantum network;quantum capacity;communication complexity;physics;algorithm;quantum mechanics;quantum error correction	Crypto	-43.718875795090895	83.50129526072016	88583
7a2d43379761557925291a6b099049e802171069	a new scheme for establishing pairwise keys for wireless sensor networks	random distribution;distributed system;red sin hilo;reseau capteur;systeme reparti;cedt centre for electronic design technology;reseau sans fil;routing;wireless network;serveur informatique;distributed computing;routage;distribution aleatoire;electronic systems engineering formerly;wireless sensor network;red sensores;sistema repartido;key pre distribution;criptografia;cryptography;sensor array;calculo repartido;servidor informatico;cryptographie;distribucion aleatoria;calcul reparti;key establishment;computer server;enrutamiento	This paper addresses the problem of secure path key establishment in wireless sensor networks that uses the random key predistribution technique. Inspired by the recent proxy-based scheme in [1] and [2], we introduce a friend -based scheme for establishing pairwise keys securely. We show that the chances of finding friends in a neighbourhood are considerably more than that of finding proxies, leading to lower communication overhead. Further, we prove that the friendbased scheme performs better than the proxy-based scheme in terms of resilience against node capture.	adversary (cryptography);key escrow;key exchange;overhead (computing);proxy server	Abhishek Gupta;Joy Kuri;Pavan Nuggehalli	2006		10.1007/11947950_57	embedded system;routing;wireless sensor network;telecommunications;computer science;cryptography;operating system;wireless network;distributed computing;computer security;sensor array;computer network	Mobile	-46.35486060422156	79.03250851742399	88596
147afab641ba95fe427a8749e1c5a90452925afa	a scalable multi-service group key management scheme	macquarie university institutional repository;researchonline;identity based encryption;digital repository;service orientation;information technology;macquarie university;traitor tracing;technology management;streaming media;cryptography;difference set;access control;scalability;group key management;computer science;broadcasting;data security;data security streaming media information technology computer science technology management identity based encryption cryptography scalability broadcasting access control	Scalable multi-service oriented group key management addresses issues relating to situations where dynamic group users have different privileges for accessing different sets of services. In this paper, we propose a new flexible group key management scheme based on an ID-based distribution encryption algorithm. This scheme has several advantages over existing multi-service oriented schemes. We show that the proposed scheme has some unique scalability properties, less storage, less communication overhead and inherent traitor tracing and stateless properties than previously known schemes. We believe the proposed scheme can be used to provide a secure information distribution method for many multi-service group-oriented applications.	algorithm;data security;group key;key management;overhead (computing);scalability;stateless protocol;traitor tracing	Junqi Zhang;Vijay Varadharajan;Yi Mu	2006	Advanced Int'l Conference on Telecommunications and Int'l Conference on Internet and Web Applications and Services (AICT-ICIW'06)	10.1109/AICT-ICIW.2006.31	scalability;telecommunications;computer science;cryptography;access control;technology management;operating system;database;data security;internet privacy;information technology;world wide web;computer security;broadcasting;difference set;computer network	Security	-48.1371991641361	77.01834981233877	88653
7656d9066ac2e0ac66fe9a978dc4c41e0dcbcb61	advances in cryptology – crypto 2016		We present a new scheme for quantum homomorphic encryption which is compact and allows for efficient evaluation of arbitrary polynomial-sized quantum circuits. Building on the framework of Broadbent and Jeffery [BJ15] and recent results in the area of instantaneous non-local quantum computation [Spe15], we show how to construct quantum gadgets that allow perfect correction of the errors which occur during the homomorphic evaluation of T gates on encrypted quantum data. Our scheme can be based on any classical (leveled) fully homomorphic encryption (FHE) scheme and requires no computational assumptions besides those already used by the classical scheme. The size of our quantum gadget depends on the space complexity of the classical decryption function – which aligns well with the current efforts to minimize the complexity of the decryption function. Our scheme (or slight variants of it) offers a number of additional advantages such as ideal compactness, the ability to supply gadgets “on demand”, and circuit privacy for the evaluator against passive adver-	computation;computational hardness assumption;dspace;homomorphic encryption;interpreter (computing);kinetic data structure;polynomial;quantum computing	Matthew J. B. Robshaw;Jonathan Katz	2016		10.1007/978-3-662-53015-3	computational biology;computer science	Crypto	-37.29549808437947	76.93865901698491	89288
ac2a7379159531ccf55576dd2a8bf75b412dcf32	security of the misty structure beyond the birthday bound	pseudorandomness;coupling	In this paper, we first prove beyond-birthyday-bound security for the Misty structure. Specifically, we show that an r-round Misty structure is secure against CCA attacks up to O(2 rn r+7 ) query complexity, where n is the size of each round permutation. So for any > 0, a sufficient number of rounds would guarantee the security of the Misty structure up to 2n(1− ) query complexity.	birthday attack;decision tree model	Jooyoung Lee	2013	IEICE Transactions		theoretical computer science;mathematics;coupling;pseudorandomness;algorithm;statistics	Crypto	-37.897244012877785	77.72457848372716	89306
107b51c18efb677376f70c2bd2b42b37cccfebcb	cryptanalysis of the mst 3 public key cryptosystem	non commutative;public key cryptosystem;public key	In this paper we describe a cryptanalysis of MST 3, a public key cryptosystem based on non-commutative groups recently proposed by Lempken, Magliveras, van Trung and Wei.	cryptanalysis;cryptosystem;public-key cryptography;tame;type signature	Simon R. Blackburn;Carlos Cid;Ciaran Mullan	2009	J. Mathematical Cryptology	10.1515/JMC.2009.020	paillier cryptosystem;goldwasser–micali cryptosystem;cryptosystem;mathematics;internet privacy;public-key cryptography;computer security;computer network	Crypto	-40.677482745568696	79.47045260417376	89334
6d8f6ae97e7cfcdc0320b930a3ef5f4c62367ba0	a robust mutual authentication protocol for wsn with multiple base-stations	wsn;authentication;ban logic	Abstract Security and Privacy are very crucial for data communication in Wireless Sensor Networks (WSNs). In order to provide ample security, recently many user authentication and key agreement (UAKA) protocols with single base-station have been put forward for WSNs. The base-station experienced huge load for such type of protocol, and thus, the quality of the service is dramatically reduced with the increasing number of users. This problem can be eliminated if the load is distributed to multiple base-stations. However, multiple base-stations based UAKA (MBS-UAKA) protocol with for WSN has not yet been proposed. This paper focuses to design a robust and effective MBS-UAKA protocol for WSN, which makes the secure communication as well as authentication. We evaluated all the known security properties of our MBS-UAKA protocol through formal and informal security analysis. Besides, the BAN logic analysis ensures that our MBS-UAKA protocol satisfies the mutual authentication property. Our comparative analysis ensures better performance compared to existing research works.	authentication protocol;mutual authentication	Ruhul Amin;SK Hafizul Islam;G. P. Biswas;Mohammad S. Obaidat	2018	Ad Hoc Networks	10.1016/j.adhoc.2018.03.007	wireless sensor network;computer network;distributed computing;mutual authentication;aka;security analysis;authentication;secure communication;base station;computer science	Mobile	-47.7418920240926	74.81764525723267	89563
7a41e7dfb52427d0a1ccd520132f2841af40c5ce	provably-secure electronic cash based on certificateless partially-blind signatures	public key cryptography;provable security;digital cryptography;certificateless public key cryptography;electronic cash systems;blind signatures;algorithms;computational diffie hellman;blind signature;partially blind signature;certificateless partially blind signatures	We extend the partially-blind signature approach into certificateless public key cryptography to eliminate the key escrow problem that occurs with identities in public key cryptography. We also formalize conditions for security for certificateless partially-blind signature schemes. We also present a practical certificateless partially-blind signature scheme to make electronic cash untraceable. We prove the scheme to be unforgeable in the face of message attacks under the computational Diffie-Hellman assumption.	antivirus software;blind signature;provable security	Lei Zhang;Futai Zhang;Bo Qin;Shubo Liu	2011	Electronic Commerce Research and Applications	10.1016/j.elerap.2011.01.004	financial cryptography;computer science;provable security;internet privacy;public-key cryptography;blind signature;computer security;id-based cryptography;computer network	DB	-42.631653700743186	75.40699068851269	89686
7e8d3cecaf7fab1b9ee1010ccec7b174426f0f2c	on the black-box complexity of optimally-fair coin tossing	one way function;oblivious transfer;secure computation;optimally fair coin tossing;input output;round complexity;black box separations;random oracle;coin tossing;lower bound;security protocol	A fair two-party coin tossing protocol is one in which both parties output the same bit that is almost uniformly distributed (i.e., it equals 0 and 1 with probability that is at most negligibly far from one half). It is well known that it is impossible to achieve fair coin tossing even in the presence of fail-stop adversaries (Cleve, FOCS 1986). In fact, Cleve showed that for every coin tossing protocol running for r rounds, an efficient fail-stop adversary can bias the output by Ω(1/r). Since this is the best possible, a protocol that limits the bias of any adversary to O(1/r) is called optimally-fair. The only optimally-fair protocol that is known to exist relies on the existence of oblivious transfer, because it uses general secure computation (Moran, Naor and Segev, TCC 2009). However, it is possible to achieve a bias of O(1/ √ r) in r rounds relying only on the assumption that there exist one-way functions. In this paper we show that it is impossible to achieve optimally-fair coin tossing via a black-box construction from one-way functions for r that is less than O(n/ log n), where n is the input/output length of the one-way function used. An important corollary of this is that it is impossible to construct an optimally-fair coin tossing protocol via a black-box construction from one-way functions whose round complexity is independent of the security parameter n determining the security of the one-way function being used. Informally speaking, the main ingredient of our proof is to eliminate the random-oracle from “secure” protocols with “low round-complexity” and simulate the protocol securely against semi-honest adversaries in the plain model. We believe our simulation lemma to be of broader interest.	adversary (cryptography);black box;existential quantification;fail-stop;input/output;oblivious transfer;one-way function;random oracle;secure multi-party computation;security parameter;semiconductor industry;simulation;symposium on foundations of computer science	Dana Dachman-Soled;Yehuda Lindell;Mohammad Mahmoody;Tal Malkin	2011		10.1007/978-3-642-19571-6_27	random oracle;input/output;computer science;oblivious transfer;mathematics;distributed computing;upper and lower bounds;one-way function;computer security;algorithm	Theory	-37.77503680805657	75.30467205205282	90011
0e10c4018cc0beb374b18363bee35e914b5914a8	cryptanalysis of 6-round prince using 2 known plaintexts		In this paper we focus on the PRINCE block cipher reduced to 6 rounds, with two known plaintext/ciphertext pairs. We develop two attacks on 6-round PRINCE based on accelerated exhaustive search, one with negligible memory usage and one having moderate memory requirements. The time complexity for the first attack is 2 encryptions. Time complexity for the second attack depends on the implementation, but can be argued to be approximately 2 for a normal PC. The memory consumption of the second attack is less than 200MB and so is not a restricting factor in a real-world setting.	block cipher;brute-force search;ciphertext;cryptanalysis;dormand–prince method;known-plaintext attack;megabyte;plaintext;requirement;time complexity	Shahram Rasoolzadeh;Håvard Raddum	2016	IACR Cryptology ePrint Archive		ciphertext;time complexity;known-plaintext attack;brute-force search;theoretical computer science;block cipher;cryptanalysis;mathematics	Crypto	-37.22846420546827	80.60690964990613	90170
6fed945dcca6691199c24efe887b8aa949a201f4	concrete chosen-ciphertext secure encryption from subgroup membership problems	modelizacion;distributed system;metodo adaptativo;systeme reparti;subgrupo;subgroup;encryption;decisional diffie hellman;cryptanalyse;exponenciacion;securite informatique;public key encryption;exponentiation;methode adaptative;cifrado;cramer shoup framework;sous groupe;computer security;cryptanalysis;modelisation;chosen ciphertext security;criptoanalisis;standard model;sistema repartido;cryptage;criptografia;cryptography;seguridad informatica;adaptive method;hybrid encryption;subgroup membership problems;cryptographie;problema diffie hellman;modeling;probleme diffie hellman;chosen ciphertext attack;diffie hellman problem	Using three previously studied subgroup membership problems, we obtain new concrete encryption schemes secure against adaptive chosen-ciphertext attack in the standard model, from the Cramer-Shoup and Kurosawa-Desmedt constructions. The schemes obtained are quite efficient. In fact, the Cramer-Shoup derived schemes are more efficient than the previous schemes from this construction, including the CramerShoup cryptosystem, when long messages are considered. The hybrid variants are even more efficient, with a smaller number of exponentiations and a shorter ciphertext than the Kurosawa-Desmedt Decisional Diffie-Hellman based scheme.	ciphertext;computational diffie–hellman assumption;cryptosystem;decisional diffie–hellman assumption;encryption	Jaimee Brown;Juan Manuel González Nieto;Colin Boyd	2006		10.1007/11935070_1	arithmetic;standard model;cryptanalysis;plaintext-aware encryption;computer science;cryptography;mathematics;subgroup;exponentiation;computer security;encryption;algorithm	Crypto	-41.69178247048262	78.1780067872528	90339
ee21e845902ea5a38d08c59472bafe99998a5cec	key-dependent s-boxes and differential cryptanalysis	cryptography;block ciphers;twofish;differential cryptanalysis;s-boxes	Key-dependent S-boxes gained some prominence in block cipher design when Twofish became an AES finalist. In this paper we make some observations on how the cryptanalyst might work with key-dependent S-boxes, we begin to develop a framework for the differential cryptanalysis of key-dependent S-boxes, and we introduce some basic techniques that were used in an analysis of reduced-round Twofish.	differential cryptanalysis;s-box	Sean Murphy;Matthew J. B. Robshaw	2002	Des. Codes Cryptography		arithmetic;integral cryptanalysis;block cipher;key whitening;differential cryptanalysis;mod n cryptanalysis;theoretical computer science;boomerang attack;higher-order differential cryptanalysis;mathematics;impossible differential cryptanalysis;3-way;statistics;linear cryptanalysis	Crypto	-38.59785023018794	81.60596501840182	90345
41155a39da26fd3a60c743cb8c1b46f04b590ab0	an ecc-based blind signature scheme	cash payment system;e commerce;electronic voting system;blind signature;elliptic curve cryptosystem ecc	Cryptography is increasingly applied to the E-commerce world, especially to the untraceable payment system and the electronic voting system. Protocols for these systems strongly require the anonymous digital signature property, and thus a blind signature strategy is the answer to it. Chaum stated that every blind signature protocol should hold two fundamental properties, blindness and intractableness. All blind signature schemes proposed previously almost are based on the integer factorization problems, discrete logarithm problems, or the quadratic residues, which are shown by Lee et al. that none of the schemes is able to meet the two fundamental properties above. Therefore, an ECC-based blind signature scheme that possesses both the above properties is proposed in this paper.	blind signature;computational complexity theory;cryptographic primitive;cryptosystem;digital signature;discrete logarithm;e-commerce payment system;ecc memory;elliptic curve cryptography;integer factorization;key size;national supercomputer centre in sweden;overhead (computing);public-key cryptography;quadratic residue;requirement	Fuh-Gwo Jeng;Tzer-Long Chen;Tzer-Shyong Chen	2010	JNW	10.4304/jnw.5.8.921-928	e-commerce;ring signature;eddsa;elliptic curve digital signature algorithm;computer science;internet privacy;blind signature;schnorr signature;world wide web;elgamal signature scheme;computer security	Security	-41.42562489326514	77.78901481979106	90663
aa1a2333f5ab0b2ddf4360937ca64afeb57d2f4c	a new model for error-tolerant side-channel cube attacks	side channel attack;decoding;present;cube attack	Side-channel cube attacks are a class of leakage attacks on block ciphers in which the attacker is assumed to have access to some leaked information on the internal state of the cipher as well as the plaintext/ciphertext pairs. The known Dinur-Shamir model and its variants require error-free data for at least part of the measurements. In this paper, we consider a new and more realistic model which can deal with the case when all the leaked bits are noisy. In this model, the key recovery problem is converted to the problem of decoding a binary linear code over a binary symmetric channel with the crossover probability which is determined by the measurement quality and the cube size. We use the maximum likelihood decoding method to recover the key. As a case study, we demonstrate efficient key recovery attacks on PRESENT. We show that the full 80-bit key can be restored with 2 measurements with an error probability of 19.4% for each measurement.	binary symmetric channel;block cipher;ciphertext;cube attack;decoding methods;error-tolerant design;graph coloring;key escrow;linear code;plaintext;side-channel attack;simulation;sparse matrix;spectral leakage	Zhenqi Li;Bin Zhang;Junfeng Fan;Ingrid Verbauwhede	2013		10.1007/978-3-642-40349-1_26	telecommunications;computer science;side channel attack;ciphertext-only attack;mathematics;internet privacy;computer security;statistics	Crypto	-37.63204365155603	81.21613454399194	90721
ad4edb91d4e74aa893f4ab9658afe5161bcf76fa	side-channel analysis of the modular inversion step in the rsa key generation algorithm	side channel analysis;spa;rsa key generation;articulo;binary euclidean algorithm		algorithm;key generation	Alejandro Cabrera Aldaya;Raudel Cuiman Márquez;Alejandro Cabrera Sarmiento;Santiago Sánchez-Solano	2017	I. J. Circuit Theory and Applications	10.1002/cta.2283	arithmetic;theoretical computer science;mathematics;algorithm	Crypto	-40.032853942830144	81.13426411944322	90941
7a4f21f9be7722a51c9c3cbb9ab05581c743a7b6	a new class of convolutional codes and its use in the mceliece cryptosystem		In this paper we present a new class of convolutional codes that admits an efficient al- gebraic decoding algorithm. We study some of its properties and show that it can decode interesting sequences of errors patterns. The second part of the paper is devoted to in- vestigate its use in a variant of the McEliece cryptosystem. In contrast to the classical McEliece cryptosystems, where block codes are used, we propose the use of a convolu- tional encoder to be part of the public key. In this setting the message is a sequence of messages instead of a single block message and the errors are added randomly throughout the sequence. We conclude the paper providing some comments on the security. Although there is no obvious security threats to this new scheme, we point out several possible adaptations of existing attacks and discuss the difficulties of such attacks to succeed in breaking this cryptosystem.	algorithm;convolutional code;encoder;mceliece cryptosystem;public-key cryptography;randomness	Paulo Almeida;Diego Napp Avelli	2018	CoRR		convolutional code;block code;discrete mathematics;mathematics;encoder;decoding methods;public-key cryptography;cryptosystem;mceliece cryptosystem	Crypto	-36.98394282778335	79.16848859601585	91311
330609134a845280acd45a3724be57a71c6062dd	security protocols and specifications	public key cryptography;protection information;cryptographie cle publique;formal specification;sistema informatico;securite informatique;computer system;securite donnee;specification formelle;computer security;especificacion formal;proteccion informacion;information protection;systeme informatique;security of data;security protocol	Specifications for security protocols range from informal narrations of message flows to formal assertions of protocol properties. This paper (intended to accompany a lecture at ETAPS ’99) discusses those specifications and suggests some gaps and some opportunities for further work. Some of them pertain to the traditional core of the field; others appear when we examine the context in which protocols operate.	european joint conferences on theory and practice of software	Martín Abadi	1999		10.1007/3-540-49019-1_1	embedded system;telecommunications;computer science;formal specification;public-key cryptography;computer security;information protection policy	DB	-43.55633932316669	79.18384732236714	91608
0559dfb36680bac0808feef171825df7e7921445	a novel anonymous mutual authentication protocol with provable link-layer location privacy	anonymous mutual authentication protocol;anonymity;red sin hilo;protocolo acceso;evaluation performance;ralenti;protocols;wireless networks;telecommunication security mobile radio protocols;access point;security model;performance evaluation;forward secure location privacy;learning;reseau sans fil;securite;telecommunication sans fil;idling;authentication privacy communication system security internet protection wireless communication access protocols wireless application protocol wireless networks access control;estudio comparativo;evaluacion prestacion;localization;wireless application protocol;authentication;wireless network;telecommunication network;localizacion;access protocol;mobile users;authentification;anonymat;aprendizaje;etude comparative;wireless communication;vida privada;protection;apprentissage;autenticacion;localisation;internet;private life;wireless communication networks;red telecomunicacion;telecomunicacion sin hilo;mobile radio;mutual authentication;safety;comparative study;telecommunication security;performance analysis;provable link layer location privacy;reseau telecommunication;access protocols;vie privee;access point anonymous mutual authentication protocol provable link layer location privacy mobile users wireless communication networks security model forward secure location privacy;access control;link layer;provable forward secure location privacy;provable forward secure location privacy anonymous mutual authentication link layer;forward security;protocole acces;location privacy;seguridad;anonymous mutual authentication;privacy;communication system security;anonimato;mobile user;wireless telecommunication	Location privacy of mobile users (MUs) in wireless communication networks is very important. Ensuring location privacy for an MU is an effort to prevent any other party from learning the MU's current and past locations. In this paper, we propose a novel anonymous mutual authentication protocol with provable link-layer location privacy preservation. We first formulate the security model on the link-layer, forward-secure location privacy, which is characterized by the fact that even when an attacker corrupts an MU's current location privacy, the attacker should be kept from knowing how long the MU has stayed at the current location. Then, based on the newly devised keys with location and time awareness, a novel anonymous mutual authentication protocol between the MUs and the access point (AP) is proposed. To the best of our knowledge, this is the first developed anonymous mutual authentication scheme that can achieve provable link-layer, forward-secure location privacy. To improve efficiency, a preset in idle technique is exercised in the proposed scheme, which is further compared with a number of previously reported counterparts through extensive performance analysis.	authentication protocol;encryption;mutual authentication;performance evaluation;privacy;profiling (computer programming);provable security;semantic security;symmetric-key algorithm;telecommunications network;wireless access point	Rongxing Lu;Xiaodong Lin;Haojin Zhu;Pin-Han Ho;Xuemin Shen	2009	IEEE Transactions on Vehicular Technology	10.1109/TVT.2008.925304	telecommunications;computer science;wireless network;authentication;internet privacy;computer security;computer network	Security	-46.458923458147396	77.96456362361242	91748
3380642e1662e2dc82b577efb0426a126d35d863	rka secure pke based on the ddh and hr assumptions	4 wise independent hash;ddh assumption;hr assumption;related key attack	In this paper, we prove the security against related key attacks of two public key encryption schemes in the standard model. The first scheme is a variation of the scheme (KYPS09) presented by Kiltz, Pietrzak et al. in Eurocrypt 2009. While KYPS09 has been proved CCA secure under the DDH assumption, we show that it is not secure against related key attacks when the class of related key functions includes affine functions. We make a modification on KYPS09 and prove that the resulted scheme is secure against related key attacks in which the related key functions could be affine functions. We also prove the security against related key attacks of the scheme presented by Hofheinz and Kiltz in Crypto 2009 based on the HR assumption. The security proofs rely heavily on a randomness extractor called 4-wise independent hash functions.	decisional diffie–hellman assumption;encryption;eurocrypt;hash function;public-key cryptography;randomness extractor;related-key attack	Dingding Jia;Xianhui Lu;Bao Li;Qixiang Mei	2013		10.1007/978-3-642-41227-1_16	related-key attack;telecommunications;computer science;mathematics;internet privacy;computer security	Crypto	-39.49623064045046	76.40873429097284	91753
bbcb2bd5fd277c25fac2508b7b520e2d397549fb	relationships among differential, truncated differential, impossible differential cryptanalyses against word-oriented block ciphers like rijndael, e2	block cipher	We propose a new method for evaluating the security of block ciphers against di erential cryptanalysis and propose new structures for block ciphers. To this end, we de ne the word-wise Markov (Feistel) cipher and random output-di erential (Feistel) cipher and clarify the relations among the di erential, the truncated di erential and the impossible di erential cryptanalyses of the random output-di erential (Feistel) cipher. This random output-di erential (Feistel) cipher model uses a not too strong assumption because denying this approximation model is equivalent to denying truncated di erential cryptanalysis. Utilizing these relations, we evaluate the truncated di erential probability and the maximum average of di erential probability of the word-wise Markov (Feistel) ciphers like Rijndael, E2 and the modi ed version of block cipher E2. This evaluation indicates that all three are provably secure against di erential cryptanalysis, and that Rijndael and a modi ed version of block cipher E2 have stronger security than E2. keywords. truncated di erential cryptanalysis, truncated di erential probability, maximum average of di erential probability, generalized E2-like transformation, SPN-structure, word-wise Markov cipher, random output-di erential cipher	approximation;block cipher;feistel cipher;impossible differential cryptanalysis;integral cryptanalysis;markov chain;provable security;s-box;substitution-permutation network;truncated differential cryptanalysis	Makoto Sugita;Kazukuni Kobara;Kazuhiro Uehara;Shuji Kubota;Hideki Imai	2000			higher-order differential cryptanalysis;discrete mathematics;block cipher;advanced encryption standard;differential cryptanalysis;impossible differential cryptanalysis;block size;mathematics	Crypto	-39.0581826234888	82.12982286844264	91846
6bfd9849af0628b69240b112a8097de605b9faa7	scan-based attack against trivium stream cipher using scan signatures	scan chain;scan based attack;side channel attacks;trivium		electronic signature;stream cipher	Mika Fujishiro;Masao Yanagisawa;Nozomu Togawa	2014	IEICE Transactions		scan chain;side channel attack	Crypto	-41.687250311197936	80.30333503227995	92060
5b880e22d06748e84df690a8cdc1f90f60e238ff	an anonymous biometric-based remote user-authenticated key agreement scheme for multimedia systems	anonymity;cryptanalysis;biometric based authentication;security	We analyze the security of the Li et al. authentication scheme and show its vulnerability to off-line passwordguessing and replay attacks. We design a new anonymous authentication scheme. The proposed scheme not only removes the drawback of the scheme of the Li et al. scheme but also protects user’s anonymity. Moreover, we show validity of our proposed scheme using Burrows, Abadi, and Needham logic. Our scheme is comparable in terms of the communication and computational overhead with related schemes. Copyright © 2015 John Wiley & Sons, Ltd.	authentication;biometrics;john d. wiley;key-agreement protocol;needham–schroeder protocol;online and offline;overhead (computing);replay attack	Dheerendra Mishra;Saru Kumari;Muhammad Khurram Khan;Sourav Mukhopadhyay	2017	Int. J. Communication Systems	10.1002/dac.2946	cryptanalysis;anonymity;computer science;information security;internet privacy;world wide web;computer security	Security	-44.649392872699025	74.66590147392621	92330
ff14fd60a34791747cdf6585a61de4f7e68a304c	fast digital signature schemes as secure as diffie-hellman assumptions		This paper presents two fast digital signature schemes based on Diffie-Hellman assumptions. In the random oracle model, the first scheme S1 has a tight security reduction to the computational Diffie-Hellman (CDH) problem; and the second scheme S2 has a tight security reduction to the decisional Diffie-Hellman (DDH) problem. Comparing with existing signature schemes (whose security is tightly related to CDH problem) like EDL signature schemes, the signature generation of S1 is about 27% faster, and the verification is about 35% faster, if without considering the hash function evaluations. Comparing with existing signature schemes (whose security is tightly related to DDH problem) like KW-DDH signature scheme, the signing of S2 is about 40% faster and the verification is about 35% faster. The high efficiency of the proposed schemes is attributed to a new protocol EDL mwz which implements the proof of equality of discrete logarithm. The EDL mwz protocol outperforms its counterpart, the Chaum and Pedersen protocol, as its computation is about 38% faster and its bandwidth is |G| bits shorter. This new protocol may be of independent interests.	computation;computational diffie–hellman assumption;decisional diffie–hellman assumption;diffie–hellman key exchange;digital signature;discrete logarithm;hash function;provable security;random oracle	Changshe Ma;Jian Weng;Dong Zheng	2007	IACR Cryptology ePrint Archive		commitment scheme;random oracle;theoretical computer science;schnorr signature;digital signature;mathematics;blind signature;diffie–hellman key exchange;secure two-party computation;hash function	Security	-40.064010801214984	76.48711681180225	92497
7f1126d6fa48fca5e0b99068f024dcaa195ba7f2	on the security of wireless sensor networks	tolerancia falta;distributed system;red sin hilo;reseau capteur;systeme reparti;protocolo red;network protocol;protocole transmission;reseau sans fil;securite informatique;wireless network;resource management;sensor network;tamper resistance;wireless sensor network;computer security;gestion recursos;protocolo transmision;red sensores;sistema repartido;seguridad informatica;fault tolerance;sensor array;gestion ressources;protocole reseau;tolerance faute;transmission protocol	Wireless Sensor Networks are extremely vulnerable against any kind of internal or external attacks, due to several factors such as resource-constrained nodes and lack of tamper-resistant packages. As a result, security must be an important factor to have in mind when designing the infrastructure and protocols of sensor networks. In this paper we survey the “state-of-the-art” security issues in sensor networks and highlight the open areas of research.	algorithm;computation;data aggregation;denial-of-service attack;fault tolerance;intrusion detection system;mind;physical security;public-key cryptography;real life;routing;sensor;tamper resistance	Rodrigo Roman;Jianying Zhou;Javier López	2005		10.1007/11424857_75	wireless sensor network;telecommunications;computer science;resource management;key distribution in wireless sensor networks;mobile wireless sensor network;computer security	Mobile	-46.919101191393395	79.45617701888706	92899
36c3c38f1cdcfe151efb1ad56a993f2d47f6eb20	certification of algorithm 87: permutation generator	permutation generator		algorithm	Günther F. Schrack;M. Shimrat	1962	Commun. ACM	10.1145/368959.368989	discrete mathematics;computer science;theoretical computer science;algorithm	Graphics	-40.70771776282061	80.57464387141795	92933
7e475e3b326d4fc9f2e908a3222796031d94aec0	raziel: private and verifiable smart contracts on blockchains		Raziel combines secure multi-party computation and proof-carrying code to provide privacy, correctness and verifiability guarantees for smart contracts on blockchains. Effectively solving DAO and Gyges attacks, this paper describes an implementation and presents examples to demonstrate its practical viability (e.g., private and verifiable crowdfundings and investment funds). Additionally, we show how to use Zero-Knowledge Proofs of Proofs (i.e., Proof-Carrying Code certificates) to prove the validity of smart contracts to third parties before their execution without revealing anything else. Finally, we show how miners could get rewarded for generating pre-processing data for secure multi-party computation. ∗Corresponding author	correctness (computer science);data access object;formal verification;preprocessor;proof-carrying code;secure multi-party computation;smart contract;zero-knowledge proof	David Cerezo Sánchez	2017	IACR Cryptology ePrint Archive		theoretical computer science;verifiable secret sharing;correctness;mathematical proof;computer science;computation	Security	-39.1274546703378	74.74933119562552	93114
4ae8152f354751d6d77ae73e6785834b3eaee30b	analysis and improvement of the ban modified andrew secure rpc protocol	model checker;man in the middle attack;an identifier;sat;a remedial method;ban modified andrew secure rpc	In this paper, We have found a new man-in-the-middle attack on the BAN modified Andrew Secure RPC protocol with a protocol model-checker based on SAT. The man-in-the-middle attack, during which an intruder can impersonate an honest agent and forge a set of messages to communicate with another honest agent, destroys the assumed authentication of the protocol, one of the important properties of security protocol. Subsequently, we have reasoned about vulnerability of the protocol and proposed a remedial method to overcome the weakness of the protocol. The method, simple and effective, can be helpful to analyze and design other security protocols.		Weibo Liu;Wenping Ma;Yuanyuan Yang	2011	JNW	10.4304/jnw.6.4.662-669	man-in-the-middle attack;model checking;reflection attack;universal composability;telecommunications;computer science;wide mouth frog protocol;world wide web;computer security	Crypto	-44.118191004178136	74.6528098509677	93213
e58e8ddec9f416c8850c47a24d47a6daf3490b87	post-quantum cryptography, third international workshop, pqcrypto 2010, darmstadt, germany, may 25-28, 2010. proceedings	computer communication networks;algorithm analysis;data encryption;operating system;problem complexity;information system;quantum cryptography;data security		post-quantum cryptography;quantum cryptography		2010		10.1007/978-3-642-12929-2	cdmf;key size;strong cryptography;financial cryptography;power analysis;mceliece cryptosystem;neural cryptography;computer science;cryptography;theoretical computer science;pkcs #1;post-quantum cryptography;distributed computing;cryptography law;key space;computer security;id-based cryptography;encryption;probabilistic encryption;quantum cryptography	HPC	-41.73992411997849	79.38414195194356	93330
06fc4c55b5b094581907c4ad1b76c66a6d186afa	on security proof of mccullagh-barreto's key agreement protocol and its variants	networks;key compromise impersonation attacks;research outputs;research publications;identity based key agreement;security proof;authenticated key agreement;cryptography;pairings;security proofs;key agreement protocols;key agreement;key agreement protocol;identity based authentication	McCullagh and Barreto presented an identity-based authenticated key agreement protocol in CT-RSA 2005. Their protocol was found to be vulnerable to a key-compromise impersonation attack. In order to recover the weakness, McCullagh and Barreto, and Xie proposed two variants of the protocol respectively. In each of these works, a security proof of the proposed protocol was presented. In this paper, we revisit these three security proofs and show that all the reductions in these proofs are invalid, because the property of indistinguishability between their simulation and the real world was not held. As a replacement, we slightly modify the McCullagh and Barreto’s second protocol and then formally analyse the security of the modified scheme in the Bellare-Rogaway key agreement model.	authentication;declan mccullagh;key-agreement protocol;mihir bellare;provable security;sakai project;simulation;x image extension	Zhaohui Cheng;Liqun Chen	2005	IJSN	10.1504/IJSN.2007.013178	computer science;cryptography;distributed computing;internet privacy;computer security;computer network	Security	-41.931389059827055	75.69929006351445	93660
277bed882d601959120695395d4b1b363281aea8	how to use snarks in universally composable protocols.		The past several years have seen tremendous advances in practical, general-purpose, noninteractive proof systems called SNARKs. These building blocks are efficient and convenient, with multiple publicly available implementations, including tools to compile high-level code (e.g., written in C) to arithmetic circuits, the native representation used by SNARK constructions. However, while we would like to use these primitives in UC-secure protocols—which are provably-secure even when composed with other arbitrary concurrently-executing protocols— the SNARK definition is not directly compatible with this framework, due to its use of non black-box knowledge extraction. We show several constructions to transform SNARKs into UCsecure NIZKs, along with benchmarks and an end-to-end application example showing that the added overhead is tolerable. Our constructions rely on embedding cryptographic algorithms into the SNARK proof system. Ordinarily, cryptographic constructions are chosen and tuned for implementation on CPUs or in hardware, not as arithmetic circuits. We therefore also explore SNARK-friendly cryptography, describing several protocol parameterizations, implementations, and performance comparisons for encryption, commitments, and other tasks. This is also of independent interest for use in other SNARK-based applications.	algorithm;arithmetic circuit complexity;benchmark (computing);black box;central processing unit;compiler;cryptography;encryption;end-to-end principle;general-purpose modeling;high- and low-level;interactivity;overhead (computing);proof calculus;provable security;snark (graph theory);uc browser;universal composability	Ahmed E. Kosba;Zhichao Zhao;Andrew Miller;Yi Qian;T.-H. Hubert Chan;Charalampos Papamanthou;Rafael Pass;Abhi Shelat;Elaine Shi	2015	IACR Cryptology ePrint Archive		knowledge extraction;compiler;cryptography;implementation;encryption;theoretical computer science;embedding;computer science	Security	-36.221681015053534	77.39277704880504	93753
e633cac17439d365596e1f92bc0571df66e008c6	multiparty secret key exchange using a random deal of cards (extended abstract)	key exchange	"""We consider the problem of multiparty secret key exchange. A \team"""" of players P1 through Pk wishes to determine an n-bit secret key in the presence of a compu-tationally unlimited eavesdropper, Eve. The team players are dealt hands of cards of prespeciied sizes from a deck of d distinct cards; any remaining cards are dealt to Eve. We explore how the team can use the information contained in their hands of cards to determine an n-bit key that is secret from Eve, that is, an n bit string which each team player knows exactly but for which Eve's probability of guessing the key correctly is 1=2 n both before and after she hears the communication between the team players. We describe randomized protocols for secret key exchange that work for certain classes of deals, and we present some conditions on the deal for such a protocol to exist."""	bit array;eve;key (cryptography);key exchange;randomized algorithm	Michael J. Fischer;Rebecca N. Wright	1991		10.1007/3-540-46766-1_10	key exchange;computer science;distributed computing;internet privacy;key distribution;computer security	Crypto	-37.995301430668455	74.64381008185747	93907
6845d01bbde80cfe3fa6541b60006b93512e7c93	can we construct unbounded time-stamping schemes from collision-free hash functions?	hash function;correctness proof	It has been known for quite some time that collision-resista nce of hash functions does not seem to give any actual security guarante es for unbounded hash-tree time-stamping, where the size of the hash-tree cr eated by the timestamping service is not explicitly restricted. We focus on t he possibility of showing that there exist no black-box reductions of unbounded ti me-stamping schemes to collision-free hash functions. We propose an oracle that is probably suitable for such a separation and give strong evidence in support of that . However, the existence of a separation still remains open. We introduce the pr oblem and give a construction of the oracle relative to which there seem to be no s ecure time-stamping schemes but there still exist collision-free hash function families. Although we rule out many useful collision-finding strategies (relativ e to the oracle) and the conjecture seems quite probable after that, there still rem ains a possibility that the oracle can be abused by some very smartly constructed wra ppers. We also argue why it is probably very hard to give a correct proof for o u conjecture.	black box;comment (computer programming);cryptographic hash function;existential quantification;one-way function;oracle database	Ahto Buldas;Margus Niitsoo	2008		10.1007/978-3-540-88733-1_18	security of cryptographic hash functions;discrete mathematics;hash function;perfect hash function;collision resistance;computer science;theoretical computer science;mathematics;algorithm;swifft	Crypto	-36.97983224883521	76.41075503363747	94198
a126e85a62e597dd9e632ef2a231ba7ed2bd0267	sf-app: a secure framework for authentication and privacy preservation in opportunistic networks		Opportunistic﻿networks﻿are﻿the﻿special﻿class﻿of﻿ad﻿hoc﻿networks﻿where﻿permanent﻿link﻿among﻿the﻿ nodes﻿are﻿almost﻿absent﻿and﻿communication﻿occurs﻿when﻿an﻿“opportunity”﻿is﻿found.﻿The﻿opportunistic﻿ networks﻿have﻿more﻿diverse﻿features﻿than﻿traditional﻿ad﻿hoc﻿networks,﻿ like﻿self-organized﻿nature,﻿ intermittent﻿ connectivity,﻿ store-carry-forward﻿ routing﻿ mechanism,﻿ etc.﻿ All﻿ these﻿ features﻿ make﻿ opportunistic﻿networks﻿more﻿prone﻿to﻿security﻿threats.﻿This﻿article﻿discusses﻿security﻿challenges﻿and﻿ threats﻿to﻿opportunistic﻿networks.﻿Focusing﻿on﻿the﻿specific﻿security﻿requirements﻿of﻿opportunistic﻿ networks,﻿proposed﻿is﻿a﻿secure﻿framework﻿for﻿authentication﻿and﻿privacy﻿preservation﻿(SF-APP)﻿for﻿ opportunistic﻿networks.﻿The﻿proposed﻿algorithm﻿takes﻿care﻿of﻿authentication,﻿privacy﻿preservation,﻿ and﻿trust﻿management.﻿Within﻿this﻿article﻿is﻿a﻿performed﻿security﻿analysis﻿of﻿SF-APP﻿and﻿simulation﻿ results﻿ show﻿ that﻿ the﻿ proposed﻿ framework﻿ is﻿ capable﻿ of﻿ fulfilling﻿ the﻿ security﻿ requirements﻿ of﻿ opportunistic﻿networks. KeyWORdS Delay Tolerant Networks, Opportunistic Networks, Privacy, Security, Security Framework, Trust Management		Prashant Kumar;Naveen Chauhan;Narottam Chand;Lalit Kumar Awasthi	2018	Int. J. Web Service Res.	10.4018/IJWSR.2018040103	database;computer security;computer science;security analysis;wireless ad hoc network;authentication	Security	-48.268533132224654	75.91514936887518	94223
96bb85b479bde464fe014f3cd24f692b8f2050dc	efficient key generation leveraging wireless channel reciprocity and discrete cosine transform			discrete cosine transform;key generation	Furui Zhan;Nianmin Yao	2017	TIIS	10.3837/tiis.2017.05.022	computer network;reciprocity (social psychology);distributed computing;discrete cosine transform;computer science;wireless;key generation;communication channel	Mobile	-46.13634466760633	76.697569421882	94334
19e6f3ea035d33590a8598be68ac82e6f00ce518	public-key cryptosystems based on composite degree residuosity classes	public key cryptography;desciframiento;provable security;encryption;implementation;systeme modulaire;cle publique;decryptage;sistema modular;public key cryptosystem;arithmetique;probabilistic model;ejecucion;standard model;public key;aritmetica;cryptage;arithmetics;digital signature;criptografia;cryptography;modular arithmetic;composite residuosity class;modular system;decryption;llave publica;modele probabiliste;signature numerique;cryptographie;reduction polynomiale;modelo probabilista	This paper investigates a novel computational problem, namely the Composite Residuosity Class Problem, and its applications to public-key cryptography. We propose a new trapdoor mechanism and derive from this technique three encryption schemes : a trapdoor permutation and two homomorphic probabilistic encryption schemes computationally comparable to RSA. Our cryptosystems, based on usual modular arithmetics, are provably secure under appropriate assumptions in the standard model.	computational problem;cryptosystem;probabilistic encryption;provable security;public-key cryptography;trapdoor function	Pascal Paillier	1999		10.1007/3-540-48910-X_16	computer science;theoretical computer science;mathematics;public-key cryptography;trapdoor function;computer security;probabilistic encryption;algorithm	Crypto	-41.39493212319208	78.42009416682875	94718
92c8126be24e808e8b364de6350e37261ffbd2c9	computing a sequence of 2-isogenies on supersingular elliptic curves	supersingular elliptic curves;post quantum cryptography			Reo Yoshida;Katsuyuki Takashima	2013	IEICE Transactions		supersingular elliptic curve;discrete mathematics;twists of curves;post-quantum cryptography;edwards curve;mathematics;elliptic curve cryptography;schoof's algorithm;algebra	Crypto	-39.88448646003743	80.51960716024549	94745
60327866bc66eba9488364f8b775bf1b22e12fbc	horizontal and vertical side channel analysis of a mceliece cryptosystem	public key cryptography field programmable gate arrays private key cryptography;quasicyclic moderate density parity check mceliece decryption operation side channel attack field programmable gate array fpga secret key syndrome computation public key private key vertical side channel analysis horizontal side channel analysis;fpga differential power analysis mceliece cryptosystem qc mdpc codes;field programmable gate arrays encryption public key decoding generators	This paper presents horizontal and vertical side channel analysis techniques for an implementation of the McEliece cryptosystem. The target of this side-channel attack is a state-of-the-art field-programmable gate array (FPGA) implementation of the efficient quasi-cyclic moderate-density parity-check McEliece decryption operation, as presented at Design, Automation and Test in Europe (DATE) 2014. The presented cryptanalysis succeeds to recover the complete secret key after a few observed decryptions. It consists of a combination of a differential leakage analysis during the syndrome computation followed by an algebraic step that exploits the relation between the public key and the private key.	chosen-ciphertext attack;ciphertext;code;computation;cryptanalysis;design automation and test in europe;field-programmability;field-programmable gate array;key (cryptography);key escrow;linear algebra;mceliece cryptosystem;public-key cryptography;side-channel attack;spectral leakage;tracing (software)	Cong Chen;Thomas Eisenbarth;Ingo von Maurich;Rainer Steinwandt	2016	IEEE Transactions on Information Forensics and Security	10.1109/TIFS.2015.2509944	mceliece cryptosystem;telecommunications;theoretical computer science;mathematics;computer security	Crypto	-40.14142896902672	81.7566665474572	94836
de746bd0c9651eae15b800c9c1889d8371c1f1bc	lower bounds for key length of k-wise almost independent permutations and certain symmetric-key encryption schemes		The k-wise almost independent permutations are one of important primitives for cryptographic schemes and combinatorial constructions. Kaplan, Naor, and Reingold showed a general construction for k-wise almost independent permutations, and Kawachi, Takebe, and Tanaka provided symmetric-key encryption schemes that achieve multi-message approximate secrecy and multi-ciphertext approximate non-malleability based on Kaplan et al.’s construction. In this paper, we show lower bounds of key length for these constructions. In particular, they are nearly optimal for k-wise almost independent permutations and multi-message approximate secrecy if the approximation parameter is a constant.	encryption;key size	Akinori Kawachi;Hirotoshi Takebe;Keisuke Tanaka	2016		10.1007/978-3-319-44524-3_12	distributed computing;probabilistic encryption	Crypto	-37.912986617021076	77.78193537866254	94839
d7fb5af387ae1702e6c309bcdd0e537bb55aa91e	comments on “spam: a secure password authentication mechanism for seamless handover in proxy mobile ipv6 networks”	proxy mobile ipv6 pmipv6 burrows abadi needham ban logic fast handover security formal security analysis;manganese unsolicited electronic mail authentication handover mobile communication	Recently, Chuang et al. have introduced a secure password authentication mechanism for seamless handover in Proxy Mobile IPv6 (SPAM). SPAM aimed at providing high-security properties while optimizing the handover latency and the computation overhead. However, it is still vulnerable to replay and malicious insider attacks, as well as the compromise of a single node. This paper formally and precisely analyzes SPAM based on the Burrows–Abadi–Needham logic, followed by its weaknesses and related attacks.	burrows–abadi–needham logic;computation;insider threat;malware;needham–schroeder protocol;overhead (computing);proxy mobile ipv6;replay attack;seamless3d;secure password authentication;spamming	Ilsun You;Fang-Yie Leu	2018	IEEE Systems Journal	10.1109/JSYST.2015.2477415	handover;computer network;proxy mobile ipv6;insider;computer science;computation;latency (engineering);computer security;mobile telephony;authentication;compromise	Security	-46.235719778530765	75.07177321702417	94870
c450426e67ecf1036e37004a3232189a1a09a9f6	new integral attacks on simon		SIMON is a family of lightweight block ciphers publicly released by National Security Agency (NSA). Up to now, there have been many cryptanalytic results on it by means of impossible differential, integral, zero-correlation linear cryptanalysis and so forth. In this study, the authors analyse the characteristic of the Boolean functions of SIMON32 and find that the presentation of zero-sum property is influenced by the degree of the corresponding Boolean function. As a result, the zero-sum integral distinguisher for 14-round SIMON32 is identified which is same to the one given by Wang et.al. Inspired by this finding, they also experimentally find the zero-sum integral distinguisher for 16-round SIMON48. Then, the integral attacks on 22-round SIMON32, 22-round SIMON48/72 and 23-round SIMON48/96 are given. They improve the previous integral attack on SIMON32 from 21-round to 22-round, and the first integral attack on SIMON48 is proposed.		Kai Fu;Ling Sun;Meiqin Wang	2017	IET Information Security	10.1049/iet-ifs.2016.0241	boolean function;theoretical computer science;block cipher;computer science;united states national security agency;linear cryptanalysis	Crypto	-37.147321462701434	82.15840937645072	94880
8e8712061354d670e90b86b09cba8d05ee572f11	the cryptographic power of random selection	foundations and complexity theory;lightweight cryptography;004 informatik;algebraic attacks;algorithmic learning	The principle of random selection and the principle of adding biased noise are new paradigms used in several recent papers for constructing lightweight RFID authentication protocols. The cryptographic power of adding biased noise can be characterized by the hardness of the intensively studied Learning Parity with Noise (LPN) Problem. In analogy to this, we identify a corresponding learning problem for random selection and study its complexity. Given L secret linear functions f1, . . . , fL : {0, 1} −→ {0, 1}, RandomSelect (L, n, a) denotes the problem of learning f1, . . . , fL from values (u, fl (u)), where the secret indices l ∈ {1, . . . , L} and the inputs u ∈ {0, 1} are randomly chosen by an oracle. We take an algebraic attack approach to design a nontrivial learning algorithm for this problem, where the running time is dominated by the time needed to solve full-rank systems of linear equations over O ( n ) unknowns. In addition to the mathematical findings relating correctness and average running time of the suggested algorithm, we also provide an experimental assessment of our results.	algorithm;authentication protocol;correctness (computer science);cryptography;linear equation;linear function;oracle database;parity learning;radio-frequency identification;randomness;system of linear equations;time complexity	Matthias Krause;Matthias Hamann	2011		10.1007/978-3-642-28496-0_8	discrete mathematics;theoretical computer science;mathematics;algorithm	Theory	-37.823045865709965	79.70305934157052	94918
26a886e461248274f959db061e48259ce02b28a1	"""the hash function """"fugue"""""""		We describe Fugue, a hash function supporting inputs of length upto 2 − 1 bits and hash outputs of length upto 512 bits. Notably, Fugue is not based on a compression function. Rather, it is directly a hash function that support variable-length input. The starting point for Fugue is the hash function Grindahl, but it extends that design to protect against the kinds of attacks that were developed for Grindahl, as well as earlier hash functions like SHA-1. A key enhancement is the design of a much stronger round function which replaces the AES round function of Grindahl, using better codes (over longer words) than the AES 4× 4 MDS matrix. Also, Fugue makes judicious use of this new round function on a much larger internal state. The design of Fugue is proof-oriented: the various components are designed in such a way as to allow proofs of security. As a result, we can prove that current attack methods cannot find collisions in Fugue any faster than the trivial birthday attack. Although the proof is computer assisted, the assistance is limited to computing ranks of various matrices.	birthday attack;code;hash function;mds matrix;one-way compression function;sha-1	Shai Halevi;William Eric Hall;Charanjit S. Jutla	2014	IACR Cryptology ePrint Archive			Crypto	-36.927698622281646	79.31408725863777	94979
0ec8eccb10176d9ec48abaaa09bd83114b0efb6f	an adaptation of the nice cryptosystem to real quadratic orders	public key cryptography;integer factorization;public key cryptosystem;maximal order;public key;information society	In 2000, Paulus and Takagi introduced a public key cryptosystem called NICE that exploits the relationship between maximal and non-maximal orders in imaginary quadratic number fields. Relying on the intractability of integer factorization, NICE provides a similar level of security as RSA, but has faster decryption. This paper presents REAL-NICE, an adaptation of NICE to orders in real quadratic fields. REAL-NICE supports smaller public keys than NICE, and while preliminary computations suggest that it is somewhat slower than NICE, it still significantly outperforms RSA in decryption.	computation;cryptosystem;imaginary time;integer factorization;maximal set;nice (programming language);public-key cryptography	Michael J. Jacobson;Renate Scheidler;Daniel Weimer	2008		10.1007/978-3-540-68164-9_13	discrete mathematics;theoretical computer science;threshold cryptosystem;cryptosystem;mathematics;algorithm	Crypto	-39.24686010235939	79.68517152834562	95270
546e86278578bc8d74bf48e4ba2b2797af7a0440	collapse-binding quantum commitments without random oracles		We construct collapse-binding commitments in the standard model. Collapse-binding commitments were introduced by Unruh (Eurocrypt 2016) to model the computational-binding property of commitments against quantum adversaries, but only constructions in the random oracle model were known. Furthermore, we show that collapse-binding commitments imply selected other security definitions for quantum commitments, answering an open question by Unruh (Eurocrypt 2016).	eurocrypt;random oracle	Dominique Unruh	2016	IACR Cryptology ePrint Archive	10.1007/978-3-662-53890-6_6	theoretical computer science;discrete mathematics;quantum cryptography;random oracle;hash function;standard model;quantum;unruh effect;mathematics	Crypto	-37.85820709596306	76.82366710903712	95783
d9f56927ca6df9aa311b3aa6929f4398fe39f95b	(in)secure multimedia transmission over rtp	visualization;decoding;encryption	Multimedia encryption is an intensely discussed topic where numerous approaches have been proposed. However, the concrete application scenario and the applicable notion of security of many proposed approaches is mostly not stated precisely or even at all. In this work security notions and application scenarios for multimedia encryption are discussed and a previously proposed multimedia encryption approach, i.e., RTP-header encryption, is analysed with respect to these scenarios and notions. We show that this selective encryption approach is insecure for sensible settings and for all sensible notions of security. The analysis focuses on the RTP packetization of H.264:AVC.	encryption	Thomas Stütz;Andreas Uhl	2010	2010 18th European Signal Processing Conference			DB	-44.103020534091684	80.34613665988365	95933
e03798e5aec9198c6314de5864b6eb60039ae9b4	revocable identity-based encryption with rejoin functionality	scalability		id-based encryption	Jae Hong Seo;Keita Emura	2014	IEICE Transactions		scalability;computer science;internet privacy	Crypto	-42.341232355234915	76.10676564083744	96308
ec96bee038dd3dc850983bcf687607c303fc3f53	secure quantum network coding for controlled repeater networks	secure communication;quantum network coding;quantum repeater network;quantum one time pad	To realize efficient quantum communication based on quantum repeater, we propose a secure quantum network coding scheme for controlled repeater networks, which adds a controller as a trusted party and is able to control the process of EPR-pair distribution. As the key operations of quantum repeater, local operations and quantum communication are designed to adopt quantum one-time pad to enhance the function of identity authentication instead of local operations and classical communication. Scheme analysis shows that the proposed scheme can defend against active attacks for quantum communication and realize long-distance quantum communication with minimal resource consumption.	linear network coding;quantum network	Tao Shang;Jiao Li;Jianwei Liu	2016	Quantum Information Processing	10.1007/s11128-016-1323-y	secure communication;quantum information;quantum network;physics;quantum cryptography;bb84	Theory	-44.994183499182924	76.34177969689843	96344
0675a71594e07157e793d43ebcaf3eba2e4d1a85	towards understanding the known-key security of block ciphers		Known-key distinguishers for block ciphers were proposed by Knudsen and Rijmen at ASIACRYPT 2007 and have been a major research topic in cryptanalysis since then. A formalization of known-key attacks in general is known to be difficult. In this paper, we tackle this problem for the case of block ciphers based on ideal components such as random permutations and random functions as well as propose new generic known-key attacks on generalized Feistel ciphers. We introduce the notion of known-key indifferentiability to capture the security of such block ciphers under a known key. To show its meaningfulness, we prove that the known-key attacks on block ciphers with ideal primitives to date violate security under known-key indifferentiability. On the other hand, to demonstrate its constructiveness, we prove the balanced Feistel cipher with random functions and the multiple Even-Mansour cipher with random permutations known-key indifferentiable for a sufficient number of rounds. We note that known-key indifferentiability is more quickly and tightly attained by multiple Even-Mansour which puts it forward as a construction provably secure against known-key attacks.	asiacrypt;block cipher;cryptanalysis;feistel cipher;known-key distinguishing attack;provable security;xor-encrypt-xor	Elena Andreeva;Andrey Bogdanov;Bart Mennink	2013		10.1007/978-3-662-43933-3_18	integral cryptanalysis;block cipher;contact analysis;differential cryptanalysis;interpolation attack;theoretical computer science;block size;key schedule;avalanche effect;higher-order differential cryptanalysis;correlation attack;stream cipher attack;mathematics;s-box;t-function;computer security;algorithm;linear cryptanalysis	Crypto	-37.96976491629479	79.13850284427288	96399
69f17ff05324ebbef58dc46e8fa290799554eb49	matrix analogues of the diffie-hellman protocol		This paper presents a comparative analysis of several matrix analogs of the Diffie-Hellman algorithm, namely, Yerosh-Skuratov and Megrelishvili protocols, as well as alternative protocols based on irreducible polynomials and primitive Galois or Fibonacci matrices. Binary matrix is primitive, if the sequence of its powers in the ring of residues mod 2 forms a sequence of maximum length ( m  sequence). Offer alternative protocols and discuss ways to improve the reliability of their.	authorization;code;computational diffie–hellman assumption;cryptographic protocol;diffie–hellman key exchange;encryption;irreducibility;irreducible polynomial;key (cryptography);qualitative comparative analysis;rsa (cryptosystem);strong cryptography;symmetric-key algorithm	Alexsander Beletsky;Anatoly Beletsky;Roman Kandyba	2013			fibonacci number;discrete mathematics;logical matrix;polynomial;diffie–hellman key exchange;matrix (mathematics);mathematics	Crypto	-39.98935817521684	80.39198850448146	96473
59fa495789bb93d52519a8fe8c2b2ed31506d8c2	security in mobile ad-hoc networks using soft encryption and trust-based multi-path routing	trust;distributed system;red sin hilo;gestion crisis;multi path;confiance;systeme reparti;psychologie sociale;informatique mobile;access point;encryption;reseau sans fil;algorithme glouton;redundancia;routing;salud publica;manets;securite informatique;wireless network;algoritmo encaminamiento;reseau ad hoc mobile;routage;cifrado;ad hoc network;red ad hoc;emergency;computer security;red movil ad hoc;confidence;sistema repartido;multi path routing;redundancy;reseau ad hoc;cryptage;confianza;algorithme routage;criptografia;cryptography;seguridad informatica;urgencia;psicologia social;gestion crise;routing algorithm;greedy algorithm;urgence;sante publique;cryptographie;mobile ad hoc network;algoritmo gloton;social psychology;crisis management;mobile computing;public health;redondance;enrutamiento	Due to their applications in situations such as emergencies, crisis management, military and healthcare, message security is of paramount importance in mobile ad-hoc networks. However, because of the absence of a fixed infrastructure with designated centralized access points, implementation of hard-cryptographic security is a challenging prospect. In this paper, we propose a novel method of message security using trust-based multi-path routing. Less trusted nodes are given lower number of self-encrypted parts of a message, making it difficult for malicious nodes to gain access to the minimum information required to break through the encryption strategy. Using trust levels, we make multi-path routing flexible enough to be usable in networks with 'vital' nodes and absence of necessary redundancy. In addition, using trust levels, we avoid non-trusted routes that may use brute force attacks and may decrypt messages if enough parts of the message are available to them. Simulation results, coupled with theoretical justification, affirm that the proposed solution is much more secured than the traditional multi-path routing algorithms.	encryption;hoc (programming language);multipath routing	Prayag Narula;Sanjay Kumar Dhurandher;Sudip Misra;Isaac Woungang	2008	Computer Communications	10.1016/j.comcom.2007.10.021	routing;static routing;greedy algorithm;mobile ad hoc network;public health;telecommunications;emergency;computer science;cryptography;destination-sequenced distance vector routing;wireless network;confidence;redundancy;mobile computing;computer security;encryption;computer network	HCI	-47.08866109357671	79.4595676212158	96558
71baf41510d6ea2bcce4ff1bfd9e39146c67c9a9	secure, efficient and practical key management scheme in the complete-subtree method	key management	The complete subtree (CS) method is one of the most well-known broadcast encryptions which do not enforce the receivers to keep “online.” This paper is to reduce the size of secret information which must be stored in a terminal of the method. In the original CS method, the size of the secret information increases as the number of terminals increases. It is shown in this paper that, by making use of a one-way trapdoor permutation, we can make the size constant regardless of the number of terminals. The security of the proposed scheme is investigated, and detailed comparison with other similar schemes is presented. The proposed scheme is suitable for practical implementations of the CS method. key words: key management, broadcast encryption, complete subtree method, stateless receivers, trapdoor permutations, random oracle model	broadcast encryption;computer terminal;horner's method;key management;one-way function;random oracle;stateless protocol;trapdoor function;tree (data structure)	Ryo Nojima;Yuichi Kaji	2005	IEICE Transactions		random oracle;telecommunications;computer science;theoretical computer science;key management;mathematics;distributed computing;computer security;algorithm	Crypto	-39.809014289635996	76.79593606469415	96630
2a32eed03850ecdd4043e7e05e8a8ad415f2fbfc	cryptographic protocols based on discrete logarithms in real-quadratic orders	cryptographic protocol;discrete logarithm;discrete logarithm problem	We generalize and improve the schemes of [4]. We introduce analogues of exponentiation and cliscrele logarithms in the principle cycle of real quadratic orders. This enables us t o implement many cryptographic protocols based on discrete logarithms, e.g. a variant of the signature scheme of ElGamal [S].	cryptographic protocol;cryptography;digital signature;discrete logarithm	Ingrid Biehl;Johannes A. Buchmann;Christoph Thiel	1994		10.1007/3-540-48658-5_7	arithmetic;discrete logarithm;discrete mathematics;computer science;mathematics;elgamal signature scheme;algorithm;algebra	Crypto	-39.85957392938298	80.31160209525383	96664
315bdd41546d9133d26e1a14c1c43879feebd261	fully homomorphic encryption on octonion ring		In previous work I proposed a fully homomorphic encryption without bootstrapping which has the weak point in the enciphering function. In this paper I propose the improved fully homomorphic encryption scheme on non-associative octonion ring over finite field without bootstrapping technique. I improve the previous scheme by (1) adopting the enciphering function such that it is difficult to express simply by using the matrices and (2) constructing the composition of the plaintext p with two sub-plaintexts u and v. The improved scheme is immune from the “p and -p attack”. The improved scheme is based on multivariate algebraic equations with high degree or too many variables while the almost all multivariate cryptosystems proposed until now are based on the quadratic equations avoiding the explosion of the coefficients. The improved scheme is against the Gröbner basis attack. The key size of this scheme and complexity for enciphering /deciphering become to be small enough to handle. keywords: fully homomorphic encryption, multivariate algebraic equation, Gröbner basis, octonion	algebraic equation;cipher;coefficient;cryptosystem;gröbner basis;homomorphic encryption;key size;plaintext;quadratic equation	Masahiro Yagisawa	2015	IACR Cryptology ePrint Archive			Crypto	-39.309735941413535	80.10438493442028	96886
6bfcbcfe65c37a25ead94b541d7c902d3aefde2f	new insights on aes-like spn ciphers		It has been proved in Eurocrypt 2016 by Sun et al. that if the details of the S-boxes are not exploited, an impossible differential and a zero-correlation linear hull can extend over at most 4 rounds of the AES. This paper concentrates on distinguishing properties of AES-like SPN ciphers by investigating the details of both the underlying S-boxes and the MDS matrices, and illustrates some new insights on the security of these schemes. Firstly, we construct several types of 5-round zero-correlation linear hulls for AES-like ciphers that adopt identical S-boxes to construct the round function and that have two identical elements in a column of the inverse of their MDS matrices. We then use these linear hulls to construct 5-round integrals provided that the difference of two sub-key bytes is known. Furthermore, we prove that we can always distinguish 5 rounds of such ciphers from random permutations even when the difference of the sub-keys is unknown. Secondly, the constraints for the S-boxes and special property of the MDS matrices can be removed if the cipher is used as a building block of the Miyaguchi-Preneel hash function. As an example, we construct two types of 5-round distinguishers for the hash function Whirlpool. Finally, we show that, in the chosen-ciphertext mode, there exist some nontrivial distinguishers for 5-round AES. To the best of our knowledge, this is the longest distinguisher for the round-reduced AES in the secret-key setting. Since the 5-round distinguisher for the AES can only be constructed in the chosen-ciphertext mode, the security margin for the round-reduced AES under the chosen-plaintext attack may be different from that under the chosen-ciphertext attack. ⋆ The work in this paper is supported by the National Basic Research Program of China (973 Program) (2013CB338002), the National Natural Science Foundation of China(No: 61272484, 61379139, 61402515, 61572016, 11526215), the Program for New Century Excellent Talents in University(NCET) and the Strategic Priority Research Program of the Chinese Academy of Science, Grant No. XDA06010701). aaIACR IACR 2016. This article is the final version submitted by the authors to the IACR and to Springer-Verlag on May 30, 2016. The version published by Springer-Verlag is available at DOI....	academy;block cipher;byte;chosen-ciphertext attack;ciphertext;codebook;column (database);cryptographic hash function;eurocrypt;existential quantification;key (cryptography);key schedule;key-recovery attack;linear cryptanalysis;mds matrix;memory management controller;plaintext;public-key cryptography;route distinguisher;s-box;springer (tank);substitution-permutation network;whirlpool (cryptography)	Bing Sun;Meicheng Liu;Jian Guo;Longjiang Qu;Vincent Rijmen	2016		10.1007/978-3-662-53018-4_22	permutation;theoretical computer science;cipher;discrete mathematics;whirlpool;key schedule;hash function;block size;matrix (mathematics);linear span;mathematics	Crypto	-36.62091698951755	80.10942765131216	97444
5771c3414eae2bc4c02eaaceb49aa89774b7bd72	cryptanalysis of rapp, an rfid authentication protocol		Tian et al. proposed a novel ultralightweight RFID mutual authentication protocol [4] that has recently been analyzed in [1], [2], [5]. In this letter, we first propose a desynchronization attack that succeeds with probability almost 1, which improves upon the 0.25 given by the attack in [1]. We also show that the bad properties of the proposed permutation function can be exploited to disclose several bits of the tag’s secret (rather than just one bit as in [2]), which increases the power of a traceability attack. Finally, we show how to extend the above attack to run a full disclosure attack, which requires to eavesdrop less protocol runs than the attack described in [5] (i.e., 192 << 2).	authentication protocol;cryptanalysis;full disclosure (computer security);mutual authentication;traceability	Nasour Bagheri;Masoumeh Safkhani;Pedro Peris-Lopez;Juan E. Tapiador	2012	IACR Cryptology ePrint Archive			Security	-39.832602243168346	78.70023962784732	98088
77434bd650aac26426a25c4f1dc23f21f63f4915	enhanced security notions for dedicated-key hash functions: definitions and relationships	security properties;bepress selected works;definitions;hash functions;era2012;hash function;relationships;security notions	In this paper, we revisit security notions for dedicated-key hash functions, considering two essential theoretical aspects; namely, formal definitions for security notions, and the relationships among them. Our contribution is twofold. First, we provide a new set of enhanced security notions for dedicated-key hash functions. The provision of this set of enhanced properties has been motivated by the introduction of the enhanced target collision resistance (eTCR) property by Halevi and Krawczyk at Crypto 2006. We notice that the eTCR property does not belong to the set of the seven security notions previously investigated by Rogaway and Shrimpton at FSE 2004; namely: Coll, Sec, aSec, eSec, Pre, aPre and ePre. The fact that eTCR, as a new useful property, is the enhanced variant of the well-known TCR (a.k.a. eSec or UOWHF) property motivates one to investigate the possibility of providing enhanced variants for the other properties. We provide such an enhanced set of properties. Interestingly, there are six enhanced variants of security notions available, excluding “ePre” which can be demonstrated to be non-enhanceable. As the second and main part of our contribution, we provide a full picture of the relationships (i.e. implications and separations) among the (thirteen) security properties including the (six) enhanced properties and the previously considered seven properties. The implications and separations are supported by formal proofs (reductions) and/or counterexamples in the concrete-security framework.	collision resistance;concrete security;cryptographic hash function;fast software encryption;formal proof;transmission control room;universal one-way hash function;whole earth 'lectronic link	Reza Reyhanitabar;Willy Susilo;Yi Mu	2010	IACR Cryptology ePrint Archive	10.1007/978-3-642-13858-4_11	security of cryptographic hash functions;theoretical computer science;mathematics;computer security;algorithm	Crypto	-38.80731299051118	75.56381723576706	98185
18c10ebf202a3b2aed59ddf5204e399bfe439123	an asymmetric subspace watermarking method for copyright protection	probability;false positive;watermarking	We present an asymmetric watermarking method for copyright protection that uses different matrix operations to embed and extract a watermark. It allows for the public release of all information, except the secret key. We investigate the conditions for a high detection probability, a low false positive probability, and the possibility of unauthorized users successfully hacking into our system. The robustness of our method is demonstrated by the simulation of various attacks.	authorization;digital watermarking;key (cryptography);krylov subspace;simulation	Jengnan Tzeng;Wen-Liang Hwang;I-Liang Chern	2005	IEEE Transactions on Signal Processing	10.1109/TSP.2004.839921(410)53	matrix method;type i and type ii errors;telecommunications;image processing;digital watermarking;computer science;theoretical computer science;probability;mathematics;computer security;statistics;robustness	Vision	-42.954492412577736	80.92234769693391	98288
2192193df7a8c08d691a2a43ef371c91b0e30b44	user authentication through typing biometrics features	duracion;tiempo parada;controle acces;false reject rate;theorie type;image processing;biometrie;authentication;biometrics;biometria;procesamiento imagen;chaine caractere;temps arret;traitement image;duration;observador;authentification;code ascii;tipificacion;observateur;rejection;autenticacion;typing;type theory;cadena caracter;typage;codigo ascii;access control;stopping time;user authentication;rechazo;observer;rejet;ascii code;duree;character string	This paper uses a static keystroke dynamics in user authentication. The inputs are the key down and up times and the key ASCII codes captured while the user is typing a string. Four features (key code, two keystroke latencies, and key duration) were analyzed and seven experiments were performed combining these features. The results of the experiments were evaluated with three types of user: the legitimate, the impostor and the observer impostor users. The best results were achieved utilizing all features, obtaining a false rejection rate of 1.45% and a false acceptance rate of 1.89%. This approach can be used to improve the usual login-password authentication when the password is no more a secret. This paper innovates using four features to authenticate users.	authentication;biometrics;code;event (computing);experiment;keystroke dynamics;login;observer pattern;password;rejection sampling;string (computer science)	Lívia C. F. Araújo;Luiz H. R. Sucupira;Miguel Gustavo Lizárraga;Lee Luan Ling;João Baptista T. Yabu-uti	2005	IEEE Transactions on Signal Processing	10.1109/TSP.2004.839903(410)53	telecommunications;image processing;computer science;authentication;computer security;algorithm	Mobile	-43.980248905486846	78.87569614508413	98813
71bc5f590016814eeefdafdc1ac07ce3d6bac3b5	optimal lower bounds for 2-query locally decodable linear codes	desciframiento;code lineaire;decodage;decoding;private information retrieval;linear code;information theoretic security;lower bound;codigo lineal	This paper presents essentially optimal lower bounds on the size of linear codes C : {0, 1} → {0, 1} which have the property that, for constants δ, > 0, any bit of the message can be recovered with probability 1 2 + by an algorithm reading only 2 bits of a codeword corrupted in up to δm positions. Such codes are known to be applicable to, among other things, the construction and analysis of information-theoretically secure private information retrieval schemes. In this work, we show that m must be at least 2( δ 1−2 ). Our results extend work by Goldreich, Karloff, Schulman, and Trevisan [GKST02], which is based heavily on methods developed by Katz and Trevisan [KT00]. The key to our improved bounds is an analysis which bypasses an intermediate reduction used in both prior works. The resulting improvement in the efficiency of the overall analysis is sufficient to achieve a lower bound optimal within a constant factor in the exponent. A construction of a locally decodable linear code matching this bound is presented.	algorithm;code word;information-theoretic security;linear code;locally decodable code;personally identifiable information;private information retrieval	Kenji Obata	2002		10.1007/3-540-45726-7_4	information-theoretic security;combinatorics;discrete mathematics;private information retrieval;computer science;locally decodable code;linear code;mathematics;upper and lower bounds;algorithm;statistics	Theory	-36.752248295769704	76.92124572289511	98846
55763db8206534b7906d953232edb6be20781f5b	modified id-based threshold decryption and its application to mediated id-based encryption	desciframiento;encryption;inversion;decryptage;cifrado;probabilistic approach;cryptage;criptografia;enfoque probabilista;cryptography;approche probabiliste;decryption;random oracle;cryptographie;problema diffie hellman;diffie hellman;oracle;probleme diffie hellman;diffie hellman problem	Chai, Cao and Lu first proposed an ID-based threshold decryption scheme without random oracles. Their approach is based on the Bilinear Diffie-Hellman Inversion assumption, and prove that it is selective chosen plaintext secure without random oracles. However, to ensure correctness of their ID-based threshold decryption scheme, it is necessary to guarantee that the shared decryption is performed correctly through some public verification function. We modify Chai et al.’s scheme to ensure that all decryption shares are consistent. We also present the first mediated ID based encryption scheme based on the Bilinear Diffie Hellman Inversion assumption without random oracles. In addition, we extend it into a mediated hierarchical ID-based encryption scheme.	id-based encryption;threshold cryptosystem	Hak Soo Ju;Dae Youb Kim;Dong Hoon Lee;Haeryong Park;Kilsoo Chun	2006		10.1007/11610113_64	random oracle;inversion;arithmetic;oracle;computer science;cryptography;mathematics;computer security;encryption;algorithm	Crypto	-42.02777601744257	76.49048237840493	98995
8b4fdc70902152de2d29fe7dc48cd2aab52931e1	sustainable pseudo-random number generator		Barak and Halevi (BH) have proposed an efficient architecture for robust pseudorandom generators that ensure resilience in the presence of attackers with partial knowledge or partial controls of the generators’ entropy resources. The BH scheme is constructed from the Barak, Shaltiel and Tromer’s randomness extractor and its security is formalized in the simulation-based framework. The BH model however, does not address the scenario where an attacker completely controls the generators’ entropy resources with no knowledge of the internal state. Namely, the BH security model does not consider the security of bad-refresh conditioned on compromised = false. The security of such a case is interesting since if the output of the protocol conditioned on compromised = false looks random to the attacker, then the proposed scheme is secure even if the attacker completely controls entropy resources (recall that attackers with partial knowledge or partial controls of the generators’ entropy resources in the BH model). The BH scheme is called sustainable if the above mentioned security requirement is guaranteed. This paper studies the sustainability of the BH pseudorandom generator and makes the following two contributions: in the first fold, a new notion which we call sustainable pseudorandom generator which extends the security definition of the BH’s robust scheme is introduced and formalized in the simulation paradigm; in the second fold, we show that the BH’s robust scheme achieves the sustainability under the joint assumptions that the underlying stateless function G is a cryptographic pseudorandom number generator and the output of the underlying randomness extractor extract() is statistically close to the uniform distribution.	algorithm;cryptographic hash function;cryptographically secure pseudorandom number generator;cryptography;programming paradigm;pseudorandom generator;pseudorandomness;randomness extractor;simulation;stateless protocol;statistically close;unified model;x86	Huafei Zhu;Wee Siong Ng;See-Kiong Ng	2013		10.1007/978-3-642-39218-4_11	theoretical computer science;operating system;computer security;algorithm	Security	-39.25121630823519	75.4296500552108	99027
322149aef052f60d5473c168f18e02524a8d2963	lightweight authentication protocol (laup) for 6lowpan wireless sensor networks		6LoWPAN networks involving wireless sensors consist of resource starving miniature sensor nodes. Since secured authentication of these resource-constrained sensors is one of the important considerations during communication, use of asymmetric key distribution scheme may not be the perfect choice to achieve secure authentication. Recent research shows that Lucky Thirteen attack has compromised Datagram Transport Layer Security (DTLS) with Cipher Block Chaining (CBC) mode for key establishment. Even though EAKES6Lo and S3K techniques for key establishment follow the symmetric key establishment method, they strongly rely on a remote server and trust anchor for secure key distribution. Our proposed Lightweight Authentication Protocol (LAUP) used a symmetric key method with no preshared keys and comprised of four flights to establish authentication and session key distribution between sensors and Edge Router in a 6LoWPAN environment. Each flight uses freshly derived keys from existing information such as PAN ID (Personal Area Network IDentification) and device identities. We formally verified our scheme using the Scyther security protocol verification tool for authentication properties such as Aliveness, Secrecy, Non-Injective Agreement and Non-Injective Synchronization. We simulated and evaluated the proposed LAUP protocol using COOJA simulator with ContikiOS and achieved less computational time and low power consumption compared to existing authentication protocols such as the EAKES6Lo and SAKES.	authentication protocol;block cipher mode of operation;contiki;cryptographic nonce;datagram transport layer security;formal verification;key distribution;key exchange;lucky thirteen attack;man-in-the-middle attack;pre-shared key;public-key cryptography;replay attack;router (computing);scalability;sensor;server (computing);session key;simulation;sybil attack;symmetric-key algorithm;testbed;time complexity;tokenization (data security);trust anchor	Annie Gilda Roselin;Priyadarsi Nanda;Surya Nepal	2017	2017 IEEE Trustcom/BigDataSE/ICESS	10.1109/Trustcom/BigDataSE/ICESS.2017.260	computer security;public-key cryptography;computer network;key distribution;challenge-handshake authentication protocol;lightweight extensible authentication protocol;challenge–response authentication;session key;computer science;authentication protocol;data authentication algorithm	Mobile	-45.57556758767455	75.58854090450056	99040
013a84e7887ff51b4d810d5462632d19954c53d8	a variant of boneh-franklin ibe with a tight reduction in the random oracle model	elliptic curve;identity based encryption;tight security;pairing;94a60;random oracle model	The first practical identity based encryption (IBE) scheme was published by Boneh and Franklin at Crypto 2001, based on the elliptic curve pairing. Since that time, many other IBE schemes have been published. In this paper, we describe a variant of Boneh-Franklin with a tight reduction in the random oracle model. Our new scheme is quite efficient compared to existing schemes; moreover, upgrading from Boneh-Franklin to our new scheme is straightforward.	elliptic curve cryptography;franklin electronic publishers;id-based encryption;random oracle	Jean-Sébastien Coron	2009	Des. Codes Cryptography	10.1007/s10623-008-9218-2	random oracle;discrete mathematics;theoretical computer science;pairing;mathematics;elliptic curve;algebra	Crypto	-39.3059461984836	78.05392613517563	99061
0c1c09a8b452e67d38c6d3230f79070e4ddecea4	visual cryptography and secret image sharing	cryptography	Visual Cryptography from Halftone Error Diffusion, G.R. Arce, Z. Wang, and G. Di Crescenzo Visual Secret Sharing Halftone VSS Construction Using Error Diffusion Halftone VSS Construction Using Parallel Error Diffusion Quality of Halftone Shares Discussion Simulation Results Visual Cryptography for Color Images, S. Cimato, R. De Prisco, and A. De Santis Color Superposition Formal Models for Colored VCS Schemes for the sc Model Schemes for the nd Model Schemes for the general Model Other Schemes Visual Cryptography for Multiple Secrets, S.J. Shyu Naor and Shamiru0027s Basic Visual Secret Sharing Scheme Visual Two-Secret Sharing Schemes Visual Multiple-Secret Sharing Schemes Extended Visual Cryptography for Photograph Images, Y. Yamaguchi Basic Visual Cryptography Schemes Fundamentals of Photograph Visual Cryptography Variations of Photograph Visual Cryptography Misalignment-Tolerant Photograph Visual Cryptography Probabilistic Visual Cryptography Schemes, S. Cimato, R. De Prisco, and A. De Santis Visual Cryptography Schemes Canonical Probabilistic Schemes Probabilistic Schemes with No Pixel Expansion Trading Pixel Expansion with Probabilities Constructing Probabilistic Schemes Probabilistic Schemes with Boolean Operations Conclusions and Open Problems XOR-Based Visual Cryptography, D. Wang and L. Dong Preliminaries Visual Cryptography Scheme Using the Polarization of Light Visual Cryptography Scheme with Reversing Secret Sharing Scheme Using Boolean Operation Visual Cryptography and Random Grids, S. Jian Shyu Random Grids Visual Cryptograms of Random Grids Visual Cryptography and Contrast Bounds, A. Klein Preliminaries Approximate Inclusion Exclusion Designs and Codes Optimal 3-out-of-n Schemes Asymptotic Optimal k-out-of-n Schemes Contrast Tradeoffs for Extended Visual Cryptography Schemes Enhancing the Contrast by Nonstandard Models Visual Cryptography Schemes with Reversing, A. De Santis, A. Lisa Ferrara, and B. Masucci Visual Cryptography Schemes Almost Ideal Contrast VCS with Reversing Ideal Contrast VCS with Reversing Cheating Prevention in Visual Cryptography, Y.-C. Chen, G. Horng, and D.-S. Tsai Preliminaries Cheating Prevention Schemes Analysis of Cheating Prevention Schemes Resolving the Alignment Problem in Visual Cryptography, F. Liu Preliminaries Misalignment with Integer Number of Subpixels Misalignment with Less Than One Subpixel A Misalignment Tolerant VCS Conclusions and Discussions Acknowledgments Applications of Visual Cryptography, B. Borchert and K. Reinhardt Trojan-Secure Confirmation of Transactions Trojan-Secure Authentication Using a PIN Security Versus Multiple Use Using Refraction Technical Problems Concerning Adjustment and Parallaxes Voting with a Receipt Based on Visual Cryptography Steganography in Halftone Images, O.C. Au, Y. Guo, and J.S. Ho A Review of Error Diffusion Data Hiding by Stochastic Error Diffusion (DHSED) Data Hiding by Conjugate Error Diffusion (DHCED) Performance Analysis Image Secret Sharing, W.-Q. Yan, J. Weir, and M.S. Kankanhalli State of the Art Approaches for Image Sharing Experiment and Evaluation Polynomial-based Image Sharing, S.-J. Wang, C.-H. Yang, and Y.-T. Chen Polynomial-Based Sharing Scheme Preliminaries and Related Works Wang et al.u0027s Scheme Experimental Results Image Sharing with Steganography and Authentication, Z.-X. Yin, C.-C. Lin, and C.-C. Chang Related Work Adopted Techniques in the Proposed Scheme Proposed Scheme Experimental Results Two-Decoding-Option Image Sharing Method, C.-N. Yang, C.-B. Ciou, and T.-S. Chen Preliminaries Previous Works A New (k, n)-TiOISSS Experimental Results and Comparisons		Jeffrey Snyder	2012	J. Electronic Imaging	10.1117/1.JEI.21.1.019901	shared secret;financial cryptography;power analysis;neural cryptography;computer science;cryptography;homomorphic secret sharing;secure multi-party computation;verifiable secret sharing;id-based cryptography;statistics	Crypto	-44.89893148120958	81.664847214711	99132
a9f53b679910738b7614d0a541c54a3c9ac3048f	a simple modeling method for mobile password schemes and its analysis	shoulder surfing;generic model;password scheme;bipartite graph model;bipartite graph	Shoulder-surfing is a well-known technique to steal passwords by observing authentication sessions. While researchers have proposed many shoulder-surfing resistant password schemes, there is no general model to illustrate existing schemes and to help developing new schemes. In this paper, we introduce a graph-based model that generally describes shoulder-surfing resistant password schemes. Using this model, we present a method for analyzing some particular security threats and show some properties of, and relationship between certain security measures. Applying our proposed model to existing password systems, we demonstrate how the model can help analyze password schemes. We also discuss the usefulness of our model in designing a new password schemes.	authentication;password	Sung-Hwan Kim;Kwanghwi Kim;Hwan-Gue Cho	2011		10.1145/2095697.2095737	zero-knowledge password proof;shoulder surfing;bipartite graph;computer science;internet privacy;one-time password;key stretching;world wide web;computer security;password strength	Security	-43.75765855284171	75.01026114506632	99417
504625252472061d7b0df7dfad63cfa6301262dc	impossibility of vbb obfuscation with ideal constant-degree graded encodings		A celebrated result by Barak et al (JACM’12) shows the impossibility of general-purpose virtual black-box (VBB) obfuscation in the plain model. A recent work by Canetti, Kalai, and Paneth (TCC’15) extends this result also to the random oracle model (assuming trapdoor permutations). In contrast, Brakerski-Rothblum (TCC’15) and Barak et al (EuroCrypt’14) show that in idealized graded encoding models, generalpurpose VBB obfuscation indeed is possible; these construction require graded encoding schemes that enable evaluating high-degree (polynomial in the size of the circuit to be obfuscated) polynomials on encodings. We show a complementary impossibility of general-purpose VBB obfuscation in idealized graded encoding models that enable only evaluation of constant-degree polynomials (assuming trapdoor permutations). ∗Cornell University, rafael@cs.cornell.edu. Work supported in part by a Alfred P. Sloan Fellowship, Microsoft New Faculty Fellowship, NSF Award CNS-1217821, NSF CAREER Award CCF-0746990, NSF Award CCF-1214844, AFOSR YIP Award FA9550-10-10093, and DARPA and AFRL under contract FA8750-11-2-0211. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the Defense Advanced Research Projects Agency or the US Government. †U. of Virginia abhi@virginia.edu. Work performed while visiting Cornell Tech, and supported by NSF CAREER Award 0845811, NSF TC Award 1111781, NSF TC Award 0939718, DARPA and AFRL under contract FA8750-11-C-0080, Microsoft New Faculty Fellowship, SAIC Scholars Research Award, and Google Research Award.	black box;character encoding;general-purpose markup language;general-purpose modeling;ibm notes;microsoft research;polynomial;random oracle	Rafael Pass;Abhi Shelat	2015		10.1007/978-3-662-49096-9_1	discrete mathematics;mathematics;algorithm	Crypto	-35.166823430119216	76.80153563573909	99480
1343500e1e1ac1ca023b02d134086f3eb530d851	indifferentiability of permutation-based compression functions and tree-based modes of operation, with applications to md6	input output;random oracle;hash function;modes of operation	MD6 [16] is one of the earliest announced SHA-3 candidates, presented by Rivest at CRYPTO’08 [15]. Since then, MD6 has received a fair share of attention and has resisted several initial cryptanalytic attempts [1, 10]. Given the interest in MD6, it is important to formally verify the soundness of its design from a theoretical standpoint. In this paper, we do so in two ways: once for the MD6 compression function and once for the MD6 mode of operation. Both proofs are based on the indifferentiability framework of Maurer et al. [12] (also see [8]). The first proof demonstrates that the “prepend/map/chop” manner in which the MD6 compression function is constructed yields a compression function that is indifferentiable from a fixed-input-length (FIL), fixedoutput-length random oracle. The second proof demonstrates that the tree-based manner in which the MD6 mode of operation is defined yields a hash function that is indifferentiable from a variable-input-length (VIL), fixed-output-length random oracle. Both proofs are rather general and apply not only to MD6 but also to other sufficiently similar hash functions. These results may be interpreted as saying that the MD6 design has no structural flaws that make its input/output behavior clearly distinguishable from that of a VIL random oracle, even for an adversary who has access to inner components of the hash function. It follows that, under plausible assumptions about those inner components, the MD6 hash function may be safely plugged into any application proven secure assuming a monolithic VIL random oracle.	adversary (cryptography);block cipher mode of operation;cryptanalysis;hash function;input/output;md6;one-way compression function;random oracle;random permutation;sha-3;ueli maurer (cryptographer)	Yevgeniy Dodis;Leonid Reyzin;Ronald L. Rivest;Emily Shen	2009		10.1007/978-3-642-03317-9_7	random oracle;discrete mathematics;hash function;perfect hash function;theoretical computer science;random function;hash chain;mathematics;algorithm;cryptographic hash function;swifft	Crypto	-37.49570745171421	77.11905227061597	99485
38f50ef1a56d340c28c8a83e149b6e3787e28c39	clarifying obfuscation: improving the security of white-box encoding		To ensure the security of software executing on malicious hosts, as in digital rights management (DRM) applications, it is desirable to encrypt or decrypt content using white-box-encoded cryptographic algorithms in the manner of Chow et al. Such encoded algorithms must run on an adversarys machine without revealing the private key information used, despite the adversarys ability to observe and manipulate the running algorithm. We have implemented obfuscated (white-box) DES and 3DES algorithms along the lines of Chow et al., with alterations that improve the security of the key, eliminating attacks that extract the key from Chow et al.s obfuscated DES. Our system is secure against two previously published attacks on Chow et al.s system, as well as a new adaptation of a statistical bucketing attack on their system. During implementation of whitebox DES we found that a number of optimizations were needed for practical generation and execution. On a typical laptop we can generate obfuscated DES functions in a Lisp environment in under a minute allocating 11 MB, including the space required for the resulting function. The resulting function occupies 4.5 MB and encrypts or decrypts each block in approximately 30 ms on an 800 MHz G4 processor; slight run-time performance of the obfuscated DES could be traded to further reduce our algorithms representation to 2.3 MB. Although it is over an order of magnitude slower than typical DES systems, we believe it is fast enough for application to some DRM problems.	algorithm;digital rights management;encryption;laptop;lisp;megabyte;obfuscation (software);powerpc g4;public-key cryptography;triple des	Hamilton E. Link;William D. Neumann	2004	IACR Cryptology ePrint Archive		white box;encoding (memory);internet privacy;obfuscation;computer security;computer science	Security	-35.02777363893796	79.93832406612584	99751
1afed45b419c8ca8c2201b933156cb81dffa2868	turing, a fast stream cipher	block ciphering;cryptage bloc;machine turing;stream ciphering;turing machine;stream cipher;criptografia;cryptography;cifrado en bloque;registro dispersion;cryptographie;cifrado continuo;registre decalage;shift register;maquina turing;software implementation;cryptage continu	This paper proposes the Turing stream cipher. Turing offers up to 256-bit key strength, and is designed for extremely efficient software implementation. It combines an LFSR generator based on that of SOBER[27] with a keyed mixing function reminiscent of a block cipher round. Aspects of the block mixer round have been derived from Rijndael[20], Twofish[21], tc24[23] and SAFER[22].	block cipher;linear-feedback shift register;stream cipher;turing	Gregory G. Rose;Philip Hawkes	2002	IACR Cryptology ePrint Archive	10.1007/978-3-540-39887-5_22	computer science;theoretical computer science;distributed computing;stream cipher;algorithm	Crypto	-39.46751676122896	81.8635016211563	99890
16ec10fd690c91bd052a41c6ac6dd723fd424ad6	practical leakage-resilient identity-based encryption from simple assumptions	dual system encryption;identity based encryption;bounded retrieval model;leakage resilience;standard model;retrieval model;hash proof system;diffie hellman;system identication	We design the first Leakage-Resilient Identity-Based Encryption (LR-IBE) systems from static assumptions in the standard model. We derive these schemes by applying a hash proof technique from Alwen et.al. (Eurocrypt '10) to variants of the existing IBE schemes of Boneh-Boyen, Waters, and Lewko-Waters. As a result, we achieve leakage-resilience under the respective static assumptions of the original systems in the standard model, while also preserving the efficiency of the original schemes. Moreover, our results extend to the Bounded Retrieval Model (BRM), yielding the first regular and identity-based BRM encryption schemes from static assumptions in the standard model.  The first LR-IBE system, based on Boneh-Boyen IBE, is only selectively secure under the simple Decisional Bilinear Diffie-Hellman assumption (DBDH), and serves as a stepping stone to our second fully secure construction. This construction is based on Waters IBE, and also relies on the simple DBDH. Finally, the third system is based on Lewko-Waters IBE, and achieves full security with shorter public parameters, but is based on three static assumptions related to composite order bilinear groups.	bilinear filtering;bilinear transform;blue waters;decisional diffie–hellman assumption;diffie–hellman key exchange;eurocrypt;id-based encryption;lr parser;spectral leakage;stepping level	Sherman S. M. Chow;Yevgeniy Dodis;Yannis Rouselakis;Brent Waters	2010		10.1145/1866307.1866325	standard model;computer science;theoretical computer science;diffie–hellman key exchange;internet privacy;computer security	Security	-39.71278020392647	76.39144630311819	99920
8fcd94b5306abe50fdda454dd3c9c0f0f3c20f8d	on cryptographic schemes based on discrete logarithms and factoring	acjt group signatures;group signature scheme;discrete logarithm;ring z n;finite field;group signature;compact representation;factoring problem;discrete logarithm problem;compression;torus based cryptography	At CRYPTO 2003, Rubin and Silverberg introduced the concept of torus-based cryptography over a finite field. We extend their setting to the ring of integers modulo N . We so obtain compact representations for cryptographic systems that base their security on the discrete logarithm problem and the factoring problem. This results in smaller key sizes and substantial savings in memory and bandwidth. But unlike the case of finite fields, analogous trace-based compression methods cannot be adapted to accommodate our extended setting when the underlying systems require more than a mere exponentiation. As an application, we present an improved, torus-based implementation of the ACJT group signature scheme.	computation;digital signature;discrete logarithm;grammar-based code;group signature;integer factorization;key size;modulo operation;torus-based cryptography	Marc Joye	2009		10.1007/978-3-642-10433-6_3	discrete logarithm;combinatorics;discrete mathematics;baby-step giant-step;mathematics;group signature;algorithm;algebra	Crypto	-37.801979396945804	78.07404595256718	99982
29f8df608ddefac0e02ac334810b0e3f8486f393	progress in cryptology — indocrypt 2001		Most last-round attacks on iterated block ciphers provide some design criteria for the round function. Here, we focus on the links between the underlying properties. Most notably, we investigate the relations between the functions which oppose a high resistance to linear cryptanalysis and to differential cryptanalysis.	block cipher;cryptography;differential cryptanalysis;indocrypt;iterated function;iteration;linear cryptanalysis	Caroline Fontaine	2001		10.1007/3-540-45311-3	applied mathematics;mathematics;cryptography	Crypto	-38.87851529363914	81.25902852976104	100137
991fad16fe8246cf3abb8eb005a3c367137b91bf	hash to the rescue: space minimization for pki directories	minimisation;public key cryptography;arbre graphe;hachage;minimization;cryptographie cle publique;tree graph;cle publique;minimizacion;long terme;long term;hashing;public key;largo plazo;internet;criptografia;cryptography;llave publica;cryptographie;arbol grafo;public key infrastructure	In this paper we investigate the notion of space efficient public-key infrastructure (PKI) directories. The area of PKI is relatively young and we do not know yet the long term implications of design decisions regarding PKI and its interface with applications. Our goal is to study mechanisms for networks and systems settings where the size of directories is a significant resource (due to space restrictions).Naturally, the tools we employ are cryptographic hashing techniques combined with the tradeoffs of public storage and computation. Our mechanisms are quite simple, easy to implement and thus practical, yet they are quite powerful in making the operation substantially less costly (mainly) storage-wise and in trading storage for computation. In the past, tree based mechanisms were considered extensively to improve the complexity of PKI directories. We show that hashing techniques provide various advantages as well.	public key infrastructure	Adam L. Young;Moti Yung	2000		10.1007/3-540-45247-8_19	computer science;theoretical computer science;operating system;database;distributed computing;public-key cryptography;world wide web;computer security;algorithm;statistics	EDA	-42.71584024144667	78.48355458137225	100288
5713d6b842d42b806fc3624c66df0666599694cf	proofs of security for the unix password hashing algorithm	public key cryptography;protection information;cryptographie cle publique;securite informatique;funcion aleatoria;communication complexity;complexite communication;computer security;proteccion informacion;informatique theorique;random function;information protection;authentification message;message authentication;computer theory;fonction aleatoire;informatica teorica	We give the first proof of security for the full Unix password hashing algorithm (rather than of a simplified variant). Our results show that it is very good at extracting almost all of the available strength from the underlying cryptographic primitive and provide good reason for confidence in the Unix construction.	algorithm;hash function;key derivation function;password;unix	David A. Wagner;Ian Goldberg	2000		10.1007/3-540-44448-3_43	message authentication code;computer science;theoretical computer science;operating system;random function;salt;communication complexity;database;distributed computing;public-key cryptography;one-time password;password;computer security;information protection policy;algorithm;password strength;password cracking	Crypto	-42.66241279504034	78.17589495133967	100500
b0e57cfc7eb68e42e27a8c9233a862a75ec4eada	a hase-based saka protocol algorithm	protocols;man in the middle attack;probability density function;protocols cryptography;data mining;hash function simple authenticated key agreement saka protocol password guessing attack man in the middle attack;authenticated key agreement;saka protocol;password guessing attack;cryptography;protocols computational intelligence security sun equations;software algorithms;book reviews;hash function;security;simple authenticated key agreement	It was pointed out that the simple authenticated key agreement (SAKA) protocol suffered three weaknesses. Several improved protocols, such as improved Lin protocol, E-SAKA protocol, then were proposed as claimed being free of these three weaknesses. After reviewing of these protocols, proofs are given that these protocols still suffer from the password guessing attack. Besides, the weakness that the attacker on the E-SAKA protocol can get the session key also is pointed out. By introducing hash function a new protocol based on improved Lin’s protocol is proposed, which is free of the three weaknesses and also can prevent man-in-the-middle attack as well as the password guessing attack.	algorithm;authentication;communications protocol;hash function;local interconnect network;man-in-the-middle attack;password cracking;session key	Yipin Lin;Xiaofeng Wang	2009	2009 International Conference on Computational Intelligence and Security	10.1109/CIS.2009.280	probability density function;hash function;computer science;cryptography;information security;internet privacy;world wide web;computer security;statistics	Security	-44.6268094295219	74.71444769791074	100624
5008934c3089ac3de9fc2d45648123c60a8302c5	trading one-wayness against chosen-ciphertext security in factoring-based encryption	modelizacion;distributed system;systeme reparti;encryption;contre mesure electronique;cryptanalyse;securite informatique;chaine caractere;cle publique;cifrado;probabilistic approach;computer security;cryptanalysis;modelisation;chosen ciphertext security;criptoanalisis;standard model;sistema repartido;public key;contra medida electronica;cryptage;criptografia;enfoque probabilista;cryptography;approche probabiliste;seguridad informatica;cadena caracter;llave publica;random oracle;cryptographie;information system;electronic countermeasure;modeling;systeme information;oracle;chosen ciphertext attack;character string;sistema informacion	We revisit a long-lived folklore impossibility result for factoring-based encryption and properly establish that reaching maximally secure one-wayness (i.e. equivalent to factoring) and resisting chosenciphertext attacks (CCA) are incompatible goals for single-key cryptosystems. We pinpoint two tradeoffs between security notions in the standard model that have always remained unnoticed in the Random Oracle (RO) model. These imply that simple RO-model schemes such as Rabin/RW-SAEP[+]/OAEP[+][+], EPOC-2, etc. admit no instantiation in the standard model which CCA security is equivalent to factoring via a key-preserving reduction. We extend this impossibility to arbitrary reductions assuming non-malleable key generation, a property capturing the intuition that factoring a modulus n should not be any easier when given a factoring oracle for moduli n′ 6= n. The only known countermeasures against our impossibility results, besides malleable key generation, are the inclusion of an additional random string in the public key, or encryption twinning as in Naor-Yung or Dolev-Dwork-Naor constructions.	chosen-ciphertext attack;ciphertext;cryptosystem;cynthia dwork;encryption;integer factorization;key generation;modulus of continuity;public-key cryptography;random oracle;read-write memory;universal instantiation	Pascal Paillier;Jorge Luis Villar	2006		10.1007/11935230_17	random oracle;oracle;standard model;cryptanalysis;telecommunications;computer science;cryptography;electronic countermeasure;mathematics;computer security;encryption;information system;algorithm	Crypto	-42.59272669543397	78.08666290759137	101026
d323011648d169b1c66ce673d94ebcb7346b8c60	fast discretized gaussian sampling and post-quantum tls ciphersuite		LWE/RLWE-based cryptosystems require sampling error term from discrete Gaussian distribution. However, some existing samplers are somehow slow under certain circumstances therefore efficiency of such schemes is restricted. In this paper, we introduce a more efficient discretized Gaussian sampler based on ziggurat sampling algorithm. We also analyze statistical quality of our sampler to prove that it can be adopted in LWE/RLWE-based cryptosystems. Compared with ziggurat-based sampler by Buchmann et al., related samplers by Peikert, Ducas et al. and Knuth-Yao, our sampler achieves more than 2x speedup when standard deviation is large. This can benefit constructions rely on noise flooding (e.g., homomorphic encryption). We also present two applications: First, we use our sampler to optimize the RLWE-based authenticated key exchange (AKE) protocol by Zhang et al. We achieve 1.14x speedup on total runtime of this protocol over major parameter choices. Second, we give practical post-quantum Transport Layer Security (TLS) ciphersuite. Our ciphersuite inherits advantages from TLS and the optimized AKE protocol. Performance of our proof-of-concept implementation is close to TLS v1.2 ciphersuites and one post-quantum TLS construction.		Xinwei Gao;Lin Li;Jintai Ding;Jiqiang Liu;R. V. Saraswathy;Zhe Liu	2017		10.1007/978-3-319-72359-4_33	mathematical optimization;speedup;cryptosystem;discretization;transport layer security;sampling (statistics);post-quantum cryptography;gaussian;homomorphic encryption;mathematics	Security	-34.81283258168124	78.95940574006715	101380
8f6be85c67b9a0f95666d2b09931afb37afba2bf	multivariate profiling of hulls for linear cryptanalysis		Extensions of linear cryptanalysis making use of multiple approximations, such as multiple and multidimensional linear cryptanalysis, are an important tool in symmetric-key cryptanalysis, among others being responsible for the best known attacks on ciphers such as Serpent and present. At CRYPTO 2015, Huang et al. provided a refined analysis of the key-dependent capacity leading to a refined key equivalence hypothesis, however at the cost of additional assumptions. Their analysis was recently extended by Blondeau and Nyberg to also cover an updated wrong key randomization hypothesis, using similar assumptions. However, a recent result by Nyberg shows the equivalence of linear and statistical dependence of linear approximations, which essentially invalidates a crucial assumption on which all these multidimensional models are based. In this paper, we develop a model for linear cryptanalysis using multiple linearly independent approximations which takes key dependence into account and complies with Nyberg’s result. Our model considers an arbitrary multivariate joint distribution of the correlations, and in particular avoids any assumptions regarding normality. The analysis of this distribution is then tailored to concrete ciphers in a practically feasible way by combining a signal/noise decomposition approach for the linear hulls with a profiling of the actual multivariate distribution of the signal correlations for a large number of keys, thereby entirely avoiding assumptions regarding the shape of this distribution. As an application of our model, we provide an attack on 26 rounds of present which is faster and requires less data than previous attacks, while using more realistic assumptions and far fewer approximations. We successfully extend the attack to present the first 27 round attack which takes key-dependence into account.	approximation;cipher;kaisa nyberg;linear cryptanalysis;noise (electronics);symmetric-key algorithm;turing completeness	Andrey Bogdanov;Elmar Tischhauser;Philip S. Vejre	2018	IACR Trans. Symmetric Cryptol.	10.13154/tosc.v2018.i1.101-125	equivalence (measure theory);randomization;linear independence;statistics;joint probability distribution;multivariate statistics;linear cryptanalysis;mathematics;multivariate normal distribution;cryptanalysis	Crypto	-37.330562257749996	77.66388032334739	101421
948f922d7e3bd8e12a2bd2b7e56ad68d2b65154e	bootstrapping bgv ciphertexts with a wider choice of p and q	bootstrapping technique;plaintext modulus;reduction mod p map;full bgv packed ciphertext space;polynomial interpolation;bootstrapping;public key cryptography fhe	The authors describe a method to bootstrap a packed BGV ciphertext which does not depend (as much) on any special properties of the plaintext and ciphertext moduli. Prior ‘efficient’ methods such as that of Gentry et al. (PKC 2012) required a ciphertext modulus q which was close to a power of the plaintext modulus p. This enables the authors’ method to be applied in a larger number of situations. The authors’ basic bootstrapping technique makes use of a representation based on polynomials of the group Z q + over the finite field F p , followed by polynomial interpolation of the reduction mod p map over the coefficients of the algebraic group. This technique is then extended to the full BGV packed ciphertext space, using a method whose depth depends only logarithmically on the number of packed elements. This method may be of interest as an alternative to the method of Alperin-Sheriff and Peikert (CRYPTO 2013). To aid efficiency, the authors utilise the ring/field switching technique of Gentry et al. (SCN 2012, JCS 2013).	bootstrapping (compilers);encryption	Emmanuela Orsini;Joop van de Pol;Nigel P. Smart	2014	IET Information Security	10.1049/iet-ifs.2015.0505	semantic security;discrete mathematics;key clustering;polynomial interpolation;computer science;theoretical computer science;operating system;mathematics;computer security;algorithm;bootstrapping;statistics	Crypto	-39.00450318465284	79.24874905117599	102014
7d6713b769b549422e4d060d7427d2c5fac638dc	a block cipher mode of operation with two keys	cipher feedback mode;block cipher;counter mode;output feedback mode;output protection chain mode;chosen plaintext attack	In this paper, we propose a novel block cipher mode of operation (BCMO for short), named Output Protection Chain (OPC for short), which as a symmetric encryption structure is different from other existing BCMOs in that it employs two keys, rather than one key, to protect the output of the mode. The security threats of chosen-plaintext attacks on three existing common BCMOs, including the Cipher Feedback mode (CFB), the Output Feedback mode (OFB), and the Counter mode (CTR), are also analyzed. After that, we explain why the OPC mode (or simply the OPC) can effectively avoid chosen-plaintext attacks, and why its security level is higher than those of CFB, OFB, and CTR.	block cipher mode of operation	Yi-Li Huang;Fang-Yie Leu;Jung-Chun Liu;Jing-Hao Yang	2013		10.1007/978-3-642-36818-9_43	weak key;block cipher;triple des;real-time computing;residual block termination;ciphertext stealing;block cipher mode of operation;engineering;galois/counter mode;distributed computing;stream cipher;ccm mode;iapm;computer security;cbc-mac	Crypto	-45.72378679037267	76.20188546142685	102331
58eec14f7879783c28d03095255d9e30d9adfd09	complementing security breach of authentication by using shared authentication information in mobile wimax networks	distributed system;controle acces;intercambio informacion;transmission longue distance;ralenti;tecnologia electronica telecomunicaciones;systeme reparti;ddos attack;mobile radiocommunication;signalling;ddos;encryption;securite telecommunication;telecommunication sans fil;idling;authentication;transmision alta caudal;cifrado;vulnerability;signalisation;securite donnee;radiocommunication service mobile;protocol vulnerability;transmision larga distancia;authentification;vulnerabilite;vulnerabilidad;sistema repartido;autenticacion;cryptage;sai;echange information;telecomunicacion sin hilo;information exchange;denial of service;telecommunication security;high rate transmission;access control;tecnologias;grupo a;radiocomunicacion servicio movil;long distance transmission;security of data;senalizacion;mobile wimax;denegacion de servicio;deni service;transmission haut debit;wireless telecommunication	The signalling protocol vulnerability opens DDoS problem in Mobile WiMAX networks. This letter proposes an authentication method that uses the unrevealed upper 64 bits of Cipher-based MAC as a solution. It runs for MSs in idle mode and reduces the calculation complexity by 59% under DDoS attack while incurring 1% overhead under normal condition. key words: SAI, protocol vulnerability, DDoS, authentication, Mobile WiMAX	64-bit computing;authentication;cipher;computational complexity theory;denial-of-service attack;overhead (computing);signaling protocol	Youngwook Kim;Hyoung-Kyu Lim;Saewoong Bahk	2008	IEICE Transactions	10.1093/ietcom/e91-b.8.2728	telecommunications;computer science;authentication;computer security;denial-of-service attack;computer network	Mobile	-45.071778271335205	77.51660223186023	102480
a818124472404baa2be9d1ccddbda72ddaffb0c8	id2s password-authenticated key exchange protocols	identity based encryption and signature;protocols;encryption;identity based encryption;decisional diffie hellman problem password authenticated key exchange identity based encryption and signature diffie hellman key exchange;servers;protocols servers encryption identity based encryption;password authenticated key exchange;decisional diffie hellman problem;diffie hellman key exchange	In a two-server password-authenticated key exchange (PAKE) protocol, a client splits its password and stores two shares of its password in the two servers, respectively, and the two servers then cooperate to authenticate the client without knowing the password of the client. In case one server is compromised by an adversary, the password of the client is required to remain secure. In this paper, we present two compilers that transform any two-party PAKE protocol to a two-server PAKE protocol on the basis of the identity-based cryptography, called ID2S PAKE protocol. By the compilers, we can construct ID2S PAKE protocols which achieve implicit authentication. As long as the underlying two-party PAKE protocol and identity-based encryption or signature scheme have provable security without random oracles, the ID2S PAKE protocols constructed by the compilers can be proven to be secure without random oracles. Compared with the Katz et al.'s two-server PAKE protocol with provable security without random oracles, our ID2S PAKE protocol can save from 22 to 66 percent of computation in each server.	adversary (cryptography);authenticated key exchange;communications protocol;compiler;computation;digital signature;id-based cryptography;id-based encryption;implicit authentication;password;password-authenticated key agreement;provable security;random oracle;server (computing)	Xun Yi;Fang-Yu Rao;Zahir Tari;Feng Hao;Elisa Bertino;Ibrahim Khalil;Albert Y. Zomaya	2016	IEEE Transactions on Computers	10.1109/TC.2016.2553031	communications protocol;computer science;operating system;diffie–hellman key exchange;distributed computing;internet privacy;computer security;encryption;server	Crypto	-41.126361493491046	74.75850909814862	102508
2f90d948a857a220296680a23c724a170c71cd46	"""improved """"partial sums""""-based square attack on aes"""	cryptanalysis;square attack;advanced encryption standard	The Square attack as a means of attacking reduced round variants of AES was described in the initial description of the Rijndael block cipher. This attack can be applied to AES, with a relatively small number of chosen plaintext-ciphertext pairs, reduced to less than six rounds in the case of AES-128 and seven rounds otherwise and several extensions to this attack have been described in the literature. In this paper we describe new variants of these attacks that have a smaller time complexity than those present in the literature. Specifically, we demonstrate that the quantity of chosen plaintext-ciphertext pairs can be halved producing the same reduction in the time complexity. We also demonstrate that the time complexity can be halved again for attacks applied to AES-128 and reduced by a smaller factor for attacks applied to AES-192. This is achieved by eliminating hypotheses on-the-fly when bytes in consecutive subkeys are related because of the key schedule.	block cipher;byte;ciphertext;ecrypt;encryption;expectation propagation;integral cryptanalysis;jos stam;key schedule;plaintext;requirement;time complexity	Michael Tunstall	2012			computer network;parallel computing;time complexity;key schedule;byte;block cipher;advanced encryption standard;computer science;series (mathematics);small number;integral cryptanalysis	Crypto	-37.00590855928553	80.51492736811193	102520
e34ca1da3f666d54d9538bed1f948ffeba5e6136	security flaws in three password-based remote user authentication schemes with smart cards	secret key forward secrecy;smart card;authentication;impersonation attack;password	Since the publication of Hwang-Li’s password-based remote user authentication scheme with smart cards, a number of password-based authentication schemes with smart cards have been proposed to meet a variety of desirable security and performance requirements. In this paper, security flaws in three password-based remote user authentication schemes with smart cards are pointed out. These results demonstrate that no more password-based authentication schemes with smart cards should be constructed with such ad-hoc methods, i.e., the formal design methodology with provable security approach should be employed in future design.	authentication;cryptography;heuristic;hoc (programming language);information sciences institute;password;provable security;requirement;shim (computing);smart card	Kyung-Ah Shim	2012	Cryptologia	10.1080/01611194.2011.606352	cognitive password;smart card;password policy;s/key;challenge–response authentication;computer science;authentication protocol;multi-factor authentication;authentication;internet privacy;one-time password;world wide web;password;computer security;password strength	Security	-44.52966985840101	75.20313986697792	102531
0017577cad5bb6dc77b325402341c2054c9c2c9b	a certified e-mail protocol suitable for mobile environments	protocols;fair exchange;electronic mail;mobile environment;multisignatures 3certified e mail protocol mobile environments off line trusted third party optimistic protocols cryptographic primitives novel signature paradigm gradational signatures fair exchange;cryptography;mobile radio;trusted third party;cryptography electronic mail protocols mobile radio;electronic mail cryptographic protocols mobile computing mobile communication cryptography postal services mathematics computer science access protocols wireless application protocol	We describe a novel certified e-mail protocol that is particularly suitable for mobile environments. Our protocol uses an off-line trusted third party (TTP). Protocols with an off-line TTP—also known as optimistic protocols—have numerous practical advantages over protocols with an on-line TTP. Nonetheless, many protocols adopt an on-line TTP primarily because optimistic protocols often entail intricate cryptographic primitives that incur considerable overhead. By using a novel signa ture paradigm, which we call gradational signatures, we show that it is possible to construct optimistic protocols that are comparable to on-line protocols in terms of computation and commu nication overhead. This makes our scheme especially desirabl e in the mobile setting. Keywords—certified e-mail; fair exchange; multisigna tures	computation;cryptographic primitive;cryptography;email;online and offline;overhead (computing);programming paradigm;trusted third party;type signature	Jung-Min Jerry Park;Indrajit Ray;Edwin K. P. Chong;Howard Jay Siegel	2003		10.1109/GLOCOM.2003.1258467	trusted third party;computer science;cryptography;internet privacy;mobile computing;computer security;computer network	Security	-47.02103095845663	76.59174061842224	102847
e3771bc7bf3c1969ea4d87d7e6eb623e9fa55b62	public key cryptography – pkc 2012		Gentry’s bootstrapping technique is currently the only known method of obtaining a “pure” fully homomorphic encryption (FHE) schemes, and it may offers performance advantages even in cases that do not require pure FHE (e.g., when using the noise-control technique of Brakerski-Gentry-Vaikuntanathan). The main bottleneck in bootstrapping is the need to evaluate homomorphically the reduction of one integer modulo another. This is typically done by emulating a binary modular reduction circuit, using bit operations on binary representation of integers. We present a simpler approach that bypasses the homomorphic modularreduction bottleneck to some extent, by working with a modulus very close to a power of two. Our method is easier to describe and implement than the generic binary circuit approach, and we expect it to be faster in practice (although we did not implement it yet). In some cases it also allows us to store the encryption of the secret key as a single ciphertext, thus reducing the size of the public key. We also show how to combine our new method with the SIMD homomorphic computation techniques of Smart-Vercauteren and Gentry-Halevi-Smart, to get a bootstrapping method that works in time quasi-linear in the security parameter. This last part requires extending the techniques from prior work to handle arithmetic not only over fields, but also over some rings. (Specifically, our method uses arithmetic modulo a power of two, rather than over characteristic-two fields.)	binary number;bootstrapping (compilers);ciphertext;computation;emulator;homomorphic encryption;key (cryptography);modulo operation;modulus robot;pkc (conference);power of two;public-key cryptography;simd;security parameter	Marc Fischlin Johannes Buchmann;Mark Manulis	2012		10.1007/978-3-642-30057-8		Crypto	-36.56073657576859	77.49671766305642	102989
dbacaff7035904b7f7cb9c89a527ab07faf7b10c	elliptic curve based dynamic contributory group key agreement protocol for secure group communication over ad-hoc networks		The aim of this paper is to propose an efficient and simpler Contributory Group Key Agreement protocol (CGKA) based on Elliptic Curve Diffie Hellman (ECDH). In this CGKA protocol, a member acts as a group controller (GC) and forms two-party groups with remaining group members and generates an ECDH-style shared key per each two-party group. It then combines these keys into a single group key and acts as a normal group member. This paper also addresses a Dynamic Contributory Group Key Agreement protocol (DCGKA) by extending CGKA to dynamic groups. The proposed protocol has been compared with other popular DH and ECDH based group key distribution protocols and satisfactory results were obtained.	analysis of algorithms;authentication;computation;continuation;diffie–hellman key exchange;digital light processing;elliptic curve cryptography;forward secrecy;group key;hoc (programming language);key distribution;key-agreement protocol;mike lesser;public key infrastructure;symmetric-key algorithm	Vankamamidi Srinivasa Naresh;Nistala V. E. S. Murthy	2015	I. J. Network Security		group key;elliptic curve;computer network;communication in small groups;elliptic curve diffie–hellman;computer science;key (lock);wireless ad hoc network;distributed computing	Security	-43.001931831533305	76.00859272036884	103161
ff2f49dfbcfca279adb277c69416b72c5b3ae86d	is aez v4.1 sufficiently resilient against key-recovery attacks?	authenticated encryption;key recovery;cryptanalysis;caesar competition;aez	AEZ is a parallelizable, AES-based authenticated encryption algorithm that is well suited for software implementations on processors equipped with the AES-NI instruction set. It aims at offering exceptionally strong security properties such as nonce and decryption-misuse resistance and optimal security given the selected ciphertext expansion. AEZ was submitted to the authenticated ciphers competition CAESAR and was selected in 2015 for the second round of the competition. In this paper, we analyse the resilience of the latest algorithm version, AEZ v4.1 (October 2015), against key-recovery attacks. While AEZ modifications introduced in 2015 were partly motivated by thwarting a key-recovery attack of birthday complexity against AEZ v3 published at Asiacrypt 2015 by Fuhr, Leurent and Suder, we show that AEZ v4.1 remains vulnerable to a key-recovery attack of similar complexity and security impact. Our attack leverages the use, in AEZ, of an underlying tweakable block cipher based on a 4-round version of AES. Although the presented key-recovery attack does not violate the security claims of AEZ since the designers made no claim for beyond-birthday security, it can be interpreted as an indication that AEZ does not fully meet the objective of being an extremely conservative and misuse-resilient algorithm.	aes instruction set;algorithm;asiacrypt;authenticated encryption;authentication;birthday attack;block cipher;byte;caesar;central processing unit;ciphertext expansion;computation;cryptographic nonce;cryptography;heuristic;jean;key-recovery attack;linear algebra;pentium 4;plaintext;related-key attack;s-box	Colin Chaigneau;Henri Gilbert	2016	IACR Cryptology ePrint Archive	10.13154/tosc.v2016.i1.114-133	computer science;theoretical computer science;internet privacy;computer security	Crypto	-36.25122217206156	78.8782815873911	103254
283da762f4b60a381b8ab857467508c857996502	a comparison of schemes for certification authorities/trusted third parties	certification authority;certificate;security;digital signature;cryptography;key;trusted third party;certificate authority;public key	A comparison of schemes employed by certification authorities or trusted third parties to generate certificates.	certificate authority;trusted third party	A. van Rensburg;Sebastiaan H. von Solms	1997			chain of trust;certificate policy;implicit certificate;digital signature;intermediate certificate authorities;direct anonymous attestation;trusted third party;self-signed certificate;computer science;cryptography;information security;certificate signing request;x.509;key-agreement protocol;authorization certificate;public key certificate;certificate;internet privacy;key;root certificate;computer security;certificate authority;certification practice statement;certification path validation algorithm;computer network	Crypto	-42.83946255259047	74.71251251913684	103746
fe9ed879c9772cb9f29d009dc1a9fd67efa5f39f	improved differential fault analysis of clefia	word length 256 bit differential fault analysis dfa clefia 128 clefia 192 clefia 256 cipher secret key fault attack word length 192 bit;fault diagnosis cryptography;generalized feistel structure;cryptography;fault attack;dfa;differential fault analysis;doped fiber amplifiers circuit faults encryption ciphers equations hardware;clefia;fault diagnosis;generalized feistel structure differential fault analysis dfa fault attack clefia	CLEFIA is already shown to be vulnerable to differential fault analysis (DFA). The existing state-of-the-art DFA shows that two faults are enough to break CLEFIA-128, whereas for CLEFIA-192 and CLEFIA-256 ten faults are needed. Side-by-side it emphasizes the need for protecting last four rounds of the cipher in order to make it secure against the attack. In this paper we propose an improved DFA on CLEFIA. The analysis shows that an attack is possible even if the last four rounds of CLEFIA are protected against DFA. Further, the proposed attacks on CLEFIA-192 and CLEFIA-256 show that 8 faults are sufficient to successfully retrieve the 192 and 256-bit key respectively. The work shows improvement over the previous work. Extensive simulation results have been presented to validate the proposed attack. The simulation results show that the attack can retrieve the 128-bit secret key in around one minute of execution time whereas the attack on 192 and 256-bit key requires around one second to retrieve the secret key.	128-bit;byte;clefia;cipher;differential fault analysis;encryption;key (cryptography);run time (program lifecycle phase);simulation	Subidh Ali;Debdeep Mukhopadhyay	2013	2013 Workshop on Fault Diagnosis and Tolerance in Cryptography	10.1109/FDTC.2013.11	computer science;theoretical computer science;distributed computing;computer security	Security	-35.67149885552178	81.04815378157166	103979
4645f3ff42982fd1982eaf07784d7b3d44af124b	group key exchange enabling on-demand derivation of peer-to-peer keys	group key exchange;p2p;classical groups;diffie hellman key exchange;peer to peer;diffie hellman	We enrich the classical notion of group key exchange (GKE) protocols by a new property that allows each pair of users to derive an independent peer-to-peer (p2p) key on-demand and without any subsequent communication; this, in addition to the classical group key shared amongst all the users. We show that GKE protocols enriched in this way impose new security challenges concerning the secrecy and independence of both key types. The special attention should be paid to possible collusion attacks aiming to break the secrecy of p2p keys possibly established between any two non-colluding users. In our constructions we utilize the well-known parallel Diffie-Hellman key exchange (PDHKE) technique in which each party uses the same exponent for the computation of p2p keys with its peers. First, we consider PDHKE in GKE protocols where parties securely transport their secrets for the establishment of the group key. For this we use an efficient multi-recipient ElGamal encryption scheme. Further, based on PDHKE we design a generic compiler for GKE protocols that extend the classical Diffie-Hellman method. Finally, we investigate possible optimizations of these protocols allowing parties to re-use their exponents to compute both group and p2p keys, and show that not all such GKE protocols can be optimized.	communication complexity;compiler;computation;diffie–hellman key exchange;digital signature;encryption;gene ontology term enrichment;group key;insider threat;interactivity;kai's power tools;peer-to-peer;provable security;public-key cryptography;type signature;whole earth 'lectronic link	Mark Manulis	2009		10.1007/978-3-642-01957-9_1	computer science;diffie–hellman key exchange;mathematics;distributed computing;internet privacy;key distribution;computer security	Security	-41.73473094926048	75.27728613163308	103982
9ef03ccad4fc60a48c78236736ea9f2611786932	a novel symmetric key cryptographic technique at bit level based on spiral matrix concept		In this paper, we propose a session based bit level symmetric key cryptographic technique and it is termed as Spiral Matrix Based Bit Orientation Technique (SMBBOT). SMBBOT consider the input plain text as binary bit stream. During encryption this stream is chopped into manageable sized blocks with variable lengths. Bits of these blocks are taken from MSB to LSB to fit into a square matrix of suitable order following the concept of Spiral matrix. This square matrix splits into 2x2 sub-matrices. Bits are taken column-wise from all 2x2 sub-matrices to form the encrypted binary string. Cipher text is generated from this encrypted binary string. Combination of values of block length and no. of blocks of a session generates the session key for SMBBOT. For decryption the cipher text is considered as binary bit string. Processing the session key information, this binary string is broken down into predefined blocks. Bits of these blocks are taken from MSB to LSB to fit column-wise into 2x2 square matrices. Using these sub-matrices a single square matrix with suitable order is formed. The decrypted binary string is formed after taking the bits from the square matrix following the reverse concept of Spiral Matrix. The plain text is regenerated from decrypted binary string. A comparison of SMBBOT with existing and industrially accepted TDES and AES has been done.	bit array;bit-level parallelism;bitstream;block code;cipher;ciphertext;encryption;least significant bit;matrix multiplication;most significant bit;session key;string (computer science);symmetric-key algorithm;triple des	Manas Paul;J. K. Mandal	2013	CoRR		arithmetic;theoretical computer science;mathematics;algorithm	Theory	-36.717869602015156	80.62351207625717	104233
a7bbb281a4c5b36aa8f6011109d73812d80268e2	a recursive construction for perfect hash families			perfect hash function;recursion	Charles J. Colbourn;Alan C. H. Ling	2009	J. Mathematical Cryptology	10.1515/JMC.2009.018	arithmetic;double hashing;hash function;perfect hash function;dynamic perfect hashing;theoretical computer science;hash chain;hash buster;k-independent hashing;rolling hash;algorithm;hash tree;hash filter	Crypto	-40.54015697812976	80.33365490495464	104258
07fd1a720051d834919c5aa1e88ca5ba5a41f50a	an efficient threshold rsa digital signature scheme	interpolacion lagrange;lagrange interpolation;interpolation;matematicas aplicadas;mathematiques appliquees;approximation numerique;seuil;conspiracy attack;interpolacion;interpolation over zφ n;rsa;threshold;signature electronique;aproximacion numerica;signature scheme;interpolation lagrange;digital signature;numerical approximation;umbral;firma numerica;applied mathematics;threshold signature;digital signature scheme	Abstract   This study focuses on the two main issues related to threshold RSA signature schemes: (1) resisting conspiracy attack and (2) efficiently solving the “interpolation over ring  Z   ϕ ( n ) ” problem. In particular, no efficient solution currently exists to the problem of conspiracy attacks.  This study presents a new threshold RSA signature scheme. This scheme prevents conspiracy attacks by controlling the right to issuing the signature on behalf of the group; and the problem of “interpolation over  Z   ϕ ( n ) ” is efficiently solved by introducing a technique for converting the structure of Lagrange interpolation from the ring  Z   ϕ ( n )  into a prime field  Z   r  .	digital signature;rsa (cryptosystem)	Qiu-Liang Xu;Tzer-Shyong Chen	2005	Applied Mathematics and Computation	10.1016/j.amc.2004.04.054	discrete mathematics;applied mathematics;interpolation;calculus;mathematics;algorithm;statistics	Crypto	-40.264497028960214	80.60031424876172	104528
e18b11c1d34c503feea36897f5793721a9d75f4b	a fast signature scheme based on quadratic inequalities	handwriting recognition;digital signatures;polynomials;public key digital signatures polynomials handwriting recognition estimation;signature scheme;public key;estimation	A new digital signature scheme is proposed in which the computation time is several hundred times faster than the RSA scheme and in which the key length and signature length are almost comparable to those for the RSA. Moreover, the scheme can be easily implemented and is, therefore, most practical for many digital signature applications. This new scheme is based on both a quadratic congruent inequality and a one-way hash function. The secret key consists of two large prime numbers p and q, and the public key is their product, n=p2q. An inequality is used for signature verification. Although the degree of security in this scheme has not been proved, it is shown that security seems to be equivalent to the difficulty of factoring a large number.	computation;cryptographic hash function;digital signature;integer factorization;key (cryptography);key size;one-way function;public-key cryptography;social inequality;time complexity	Tatsuski Okamoto;Akira Shibaishi	1985	1985 IEEE Symposium on Security and Privacy	10.1109/SP.1985.10026	ring signature;estimation;digital signature;eddsa;computer science;theoretical computer science;handwriting recognition;public-key cryptography;blind signature;schnorr signature;elgamal signature scheme;computer security;polynomial	Security	-39.600754866655606	79.53244367461873	104646
199716d8395516aefc160d0c137b0b89a1313612	a hybrid lattice basis reduction and quantum search attack on lwe		Recently, an increasing amount of papers proposing postquantum schemes also provide concrete parameter sets aiming for concrete post-quantum security levels. Security evaluations of such schemes need to include all possible attacks, in particular those by quantum adversaries. In the case of lattice-based cryptography, currently existing quantum attacks are mainly classical attacks, carried out with quantum basis reduction as subroutine. In this work, we propose a new quantum attack on the learning with errors (LWE) problem, whose hardness is the foundation for many modern lattice-based cryptographic constructions. Our quantum attack is based on Howgrave-Graham’s Classical Hybrid Attack and is suitable for LWE instances in recent cryptographic proposals. We analyze its runtime complexity and optimize it over all possible choices of the attack parameters. In addition, we analyze the concrete post-quantum security levels of the parameter sets proposed for the New Hope and Frodo key exchange schemes, as well as several instances of the Lindner-Peikert encryption scheme. Our results show that – depending on the assumed basis reduction costs – our Quantum Hybrid Attack either significantly outperforms, or is at least comparable to all other attacks covered by Albrecht–Player– Scott in their work “On the concrete hardness of Learning with Errors”. We further show that our Quantum Hybrid Attack improves upon the Classical Hybrid Attack in the case of LWE with binary error.	encryption;graham scan;key exchange;lattice reduction;lattice-based cryptography;learning with errors;post-quantum cryptography;quantum;subroutine	Florian Göpfert;Christine van Vredendaal;Thomas Wunderer	2017		10.1007/978-3-319-59879-6_11	computational chemistry;condensed matter physics;quantum mechanics	Crypto	-38.67156550530935	78.32070706103461	104929
0416ad952fb5fbf9dc07dd1a7580566ec793d852	a reputation system to increase mix-net reliability	system reliability;fiabilite systeme;electronic mail;protocole transmission;encryption;concepcion sistema;correo electronico;cifrado;fiabilidad sistema;courrier electronique;protocolo transmision;reputation system;cryptage;criptografia;system design;cryptography;cryptographie;mix net;conception systeme;transmission protocol	We describe a design for a reputation system that increases the reliability and thus efficiency of remailer services. Our reputation system uses a MIX-net in which MIXes give receipts for intermediate messages. Together with a set of witnesses, these receipts allow senders to verify the correctness of each MIX and prove misbehavior to the wit-	alice;correctness (computer science);denial-of-service attack;execution unit;flow network;formal verification;local area augmentation system;marc (archive);mathematical optimization;mix network;reputation system;zero-knowledge proof	Roger Dingledine;Michael J. Freedman;David Hopwood;David Molnar	2001		10.1007/3-540-45496-9_10	embedded system;telecommunications;computer science;cryptography;computer security;encryption;statistics	PL	-43.86715006441984	77.53924352095105	104991
127be481c9ec00ccd9a52f417682f1738055b52f	a practical solution to the (t, n) threshold untraceable signature with (k, l) verification scheme	ombre;caracter manuscrito;pervasive computing;manuscript character;signature electronique;inicializacion;intelligence artificielle;group communication;informatica difusa;sombra;reconnaissance caractere;shadow;informatique diffuse;digital signature;artificial intelligence;distribution center;inteligencia artificial;firma numerica;threshold signature;caractere manuscrit;character recognition;initialization;initialisation;reconocimiento caracter	The (t, n) threshold signature scheme can delegate the signing capability to all n participants in a group, and at least t participants can cooperatively sign a message on behalf of the group, where t ≤v. For the group communication in the real society, the verification site also needs to be restricted in its associated access privileges. Therefore, this paper proposes a practical solution to the (t, n) threshold untraceable signature with (k, l) verification scheme, which requires that k out of l verifiers or more can verify the threshold signature on behalf of the verification group. Compared with the previous works, such as Wang et al.’s scheme and Chang et al.’s scheme, our proposed scheme is more practical and expansible. Our scheme allows each group to be both a signing party and a verification party, and the shadows of all group members are no need to be redistributed after the initialization has been finished. In addition, the share distribution center (SDC) is not required in our scheme.		Jen-Ho Yang;Chin-Chen Chang;Chih-Hung Wang	2006		10.1007/11833529_101	embedded system;initialization;digital signature;shadow;telecommunications;communication in small groups;computer science;artificial intelligence;database;computer security;ubiquitous computing;algorithm	Crypto	-44.09255255813969	76.60150861664546	105241
9641d41297a1a82c0a7df990e2cbd9aef1331ce2	looking back at a new hash function	block cipher;hash function	We present two (related) dedicated hash functions that deliberately borrow heavily from the block ciphers that appeared in the final stages of the AES process. We explore the computational trade-off between the key schedule and encryption in a block cipher-based hash function and we illustrate our approach with a 256-bit hash function that has a hashing rate equivalent to the encryption rate of AES-128. The design extends naturally to a 512-bit hash function.	32-bit;64-bit computing;advanced encryption standard process;block cipher;hash function;iteration;key schedule;overhead (computing)	Olivier Billet;Matthew J. B. Robshaw;Yannick Seurin;Yiqun Lisa Yin	2008		10.1007/978-3-540-70500-0_18	block cipher;double hashing;parallel computing;hash function;perfect hash function;collision attack;dynamic perfect hashing;merkle tree;primary clustering;sha-2;collision resistance;computer science;theoretical computer science;secure hash standard;hash chain;hash buster;k-independent hashing;distributed computing;rolling hash;computer security;cryptographic hash function;fowler–noll–vo hash function;mdc-2;hash tree;hash filter	Crypto	-36.1976725569309	79.7593034212388	105678
245a28316264b23073a144278bd46fc4f7ef9852	multiparty computation from threshold homomorphic encryption	boolean circuits;security evaluation;protocole transmission;seuil;threshold;protocolo transmision;multiparty protocol;criptografia;cryptography;cryptographie;multiparty computation;umbral;protocole multipartie;homomorphic encryption;transmission protocol	We introduce a new approach to multiparty computation (MPC) basing it on homomorphic threshold crypto-systems. We show that given keys for any sufficiently efficient system of this type, general MPC protocols for n players can be devised which are secure against an active adversary that corrupts any minority of the players. The total number of bits sent is O(nk|C|), where k is the security parameter and |C| is the size of a (Boolean) circuit computing the function to be securely evaluated. An earlier proposal by Franklin and Haber with the same complexity was only secure for passive adversaries, while all earlier protocols with active security had complexity at least quadratic in n. We give two examples of threshold cryptosystems that can support our construction and lead to the claimed complexities. ∗Basic Research in Computer Science, Center of the Danish National Research Foundation	adversary (cryptography);boolean circuit;born–haber cycle;computation;computer science;franklin electronic publishers;homomorphic encryption;security parameter;threshold cryptosystem	Ronald Cramer;Ivan Damgård;Jesper Buus Nielsen	2000	IACR Cryptology ePrint Archive	10.1007/3-540-44987-6_18	homomorphic encryption;computer science;cryptography;theoretical computer science;mathematics;distributed computing;computer security;algorithm	Crypto	-40.5192959507919	77.0318720547277	106158
273595d790f15197f4b71ae3f88fc3c688dac110	an extension to bellare and rogaway (1993) model: resetting compromised long-term keys	modelizacion;provable security;secrecy;keyword;confidencialidad;protocole transmission;and forward;securite informatique;palabra clave;probabilistic approach;mot cle;long terme;secret;long term;confidentiality;computer security;modelisation;security proof;confidentialite;protocolo transmision;largo plazo;enfoque probabilista;approche probabiliste;seguridad informatica;modeling;secreto;oracle;transmission protocol	A security proof in the Bellare–Rogaway model and the random oracle model is provided for a protocol closely based on one originally proposed by Boyd (1996), which enjoys some remarkable efficiency properties. The model is extended so that it can detect a known weakness of the protocol that cannot be captured in the original model. An alternative protocol, provably secure in the extended model and the random oracle model, offering the same efficiency features as the original protocol is proposed. Moreover, our alternative protocol provides key confirmation and forward secrecy. It also allows session keys to be renewed in subsequent sessions without the server’s further involvement even in the event that the long-term key or the earlier session key have been compromised.	adversary (cryptography);forward secrecy;key exchange;key-agreement protocol;mihir bellare;phillip rogaway;provable security;random oracle;server (computing);session key;symmetric-key algorithm	Colin Boyd;Kim-Kwang Raymond Choo;Anish Mathuria	2006		10.1007/11780656_31	oracle;systems modeling;confidentiality;telecommunications;computer science;provable security;computer security;algorithm	Security	-43.491668243714805	77.26460278408761	106190
9f0da343a0510844567dfeb0ddbaaaeb15925e0c	anonymous protocols: notions and equivalence	secret sets;anonymous broadcast encryption;anonymous protocols;key privacy	Article history: Received 25 October 2013 Received in revised form 31 July 2014 Accepted 14 February 2015 Available online 2 March 2015 Communicated by J. Camenisch	adaptive grammar;broadcast encryption;chosen-ciphertext attack;ciphertext;computational diffie–hellman assumption;digital signature forgery;most significant bit;public-key cryptography;random oracle;regular expression;turing completeness	Paolo D'Arco;Alfredo De Santis	2015	Theor. Comput. Sci.	10.1016/j.tcs.2015.02.042	multiple encryption;privacy software;40-bit encryption;plaintext-aware encryption;client-side encryption;computer science;key wrap;ciphertext indistinguishability;symmetric-key algorithm;link encryption;on-the-fly encryption;internet privacy;deterministic encryption;world wide web;key distribution;computer security;encryption;probabilistic encryption;56-bit encryption;attribute-based encryption;email encryption	AI	-40.54242037660523	75.87203097253801	106904
4e9015008a16e0fd1145294a345b4f2bf66eaf65	an efficient classification in ibe provide with an improvement of bb2 to an efficient commutative blinding scheme		Because of the revolution and the success of the technique IBE (Identification Based Encryption) in the recent years. The need is growing to have a standardization to this technology to streamline communication based on it. But this requires a thorough study to extract the strength and weakness of the most recognized cryptosystems. Our first goal in this work is to approach to this standardization, by applying a study which permit to extract the best cryptosystems. As we will see in this work and as Boneh and Boyen said in 2011 (Journal of Cryptology) the BB1 and BB2 are the most efficient schemes in the model selective ID and without random oracle (they are the only schemes traced in this model). This is right as those schemes are secure (under this model), efficient and useful for some applications. Our second goal behind this work is to make an approvement in BB2 to admit a more efficient schemes. We will study the security of our schemes, which is basing on an efficient strong Diffie-Hellman problem compared to BB1 and BB2. More than that our HIBE support s+ID-HIBE compared to BBG (Boneh Boyen Goh). Additionally the ID in our scheme will be in Zp instead of Zp ∗ as with BBG. We will cite more clearly all these statements in in this article.	adobe streamline;blinding (cryptography);computational diffie–hellman assumption;cryptography;cryptosystem;diffie–hellman problem;encryption;journal of cryptology;random oracle	Rkia Aouinatou;Mostafa Belkasmi	2012	CoRR		mathematics;internet privacy;computer security;algorithm	Crypto	-39.93864637912759	77.48314054429929	106907
f895b597d691c7fe2f410b79ef1d89d8b3773e12	computing with obfuscated data in arbitrary logic circuits via noise insertion and cancellation		In secure computing, sensitive data must be kept private by protecting it from being obtained by an attacker. Existing techniques for computing with encrypted data are either prohibitively expensive (e.g., fully homomorphic encryption) or only work for special cases. (e.g., only for linear circuits). This paper presents a lightweight methodology for computing with noise-obfuscated data by carefully selecting internal locations for noise cancellation in arbitrary logic circuits. Noise is inserted in the data before computation and then partially cancelled during the computation and fully cancelled at the outputs. While the proposed methodology does not provide the level of strong encryption that fully homomorphic encryption would provide, it has the advantage of being lightweight, easy to implement, and can be deployed with relatively minimal performance impact. A key idea in the proposed approach is to reduce the complexity of the noise cancellation logic by carefully selecting internal locations to do local noise canceling. This is done in a way that prevents more than one input per gate from propagating noise thereby avoiding the complexity that arises from reconvergent noise propagation paths. One important application of the proposed scheme is for protecting data inside a computing unit obtained from a third party IP provider where a hidden backdoor access mechanism or hardware Trojan could be maliciously inserted. Experimental results show that noise can be propagated to outputs with overheads ranging from (13%–56%).	backdoor (computing);computation;computer security;hardware trojan;homomorphic encryption;image noise;lightweight methodology;linear circuit;logic gate;maximal set;obfuscation (software);overhead (computing);software propagation;strong cryptography;trojan horse (computing)	Yu-Wei Lee;Nur A. Touba	2017	2017 IEEE Conference on Dependable and Secure Computing	10.1109/DESEC.2017.8073840	real-time computing;lightweight methodology;hardware trojan;strong cryptography;theoretical computer science;encryption;logic gate;active noise control;backdoor;ranging;computer science	EDA	-35.06124637297944	75.27138941720114	107221
d438c24e49b248d270f5bcfe377a3052a141c828	a cryptanalysis of the double-round quadratic cryptosystem	2r cryptosystem;multivariable cryptography;multivariate cryptography;public key cryptosystem;general techniques;double round quadratic cryptosystem	In the 80’s Matsumoto and Imai [8] proposed public key cryptosystems based on the difficulty of solving systems of polynomials in several variables. Although these first schemes were broken, many others followed, leading to a very active field known as Multivariate cryptography. In this paper, we show how to break one of these schemes, the Double-Round Quadratic cryptosystem from [12]. We stress that this cryptosystem has, in practice, already been cryptanalysed in [5]. However their attack uses several “non-standard” heuristics, they provide experimental evidence, but no proof is given, as opposed to this present article. Our attack uses a very general technique introduced in [9] to break the cryptosystem.	cryptanalysis;cryptosystem;heuristic (computer science);multivariate cryptography;polynomial;public-key cryptography	Antoine Scemama	2007		10.1007/978-3-540-76788-6_3	benaloh cryptosystem;arithmetic;paillier cryptosystem;goldwasser–micali cryptosystem;plaintext-aware encryption;theoretical computer science;side channel attack;cryptosystem;mathematics;hybrid cryptosystem;deterministic encryption;hidden field equations;computer security;cramer–shoup cryptosystem	Crypto	-39.49014118786929	80.7778862802715	107487
a8977ef761ef80a08c4d57ea16a8aa83d2647c9f	thring signatures and their applications to spender-ambiguous digital currencies		We present threshold ring multi-signatures (thring signatures) for collaborative computation of ring signatures, discuss a game of existential forgery for thring signatures, and discuss the uses of thring signatures in digital currencies, including spender-ambiguous cross-chain atomic swaps for confidential amounts without a trusted set-up. We present an implementation of thring signatures inspired by the works of [13], [20], [14], [1], [18], [15] we call linkable spontaneous threshold anonymous group (LSTAG) signatures, and we prove the implementation existentially unforgeable.	computation;confidentiality;digital currency;digital signature forgery;spontaneous order	Brandon Goodell;Sarang Noether	2018	IACR Cryptology ePrint Archive		monetary economics;digital currency;economics	Crypto	-41.60656725597686	74.78939186349332	107555
29d137528cbb4d5e594275cf55600453b769f5dd	practical identity-based encryption in multiple private key generator (pkg) environments	public key encryption pke;bilinear pairings;ad hoc networks;identity based encryption ibe	In this paper, we present a new identity-based encryption IBE scheme using bilinear pairings. Compared with the famous IBE scheme of Boneh and Franklin, ours is more practical in the multiple private key generator multiple-PKG environment. We prove that our scheme meets chosen ciphertext security in the random oracle model, assuming the intractability of the standard bilinear Diffie-Hellman problem. Copyright © 2013 John Wiley & Sons, Ltd.	id-based encryption;key generator;public-key cryptography	Shengbao Wang;Zhenfu Cao;Qi Xie;Wenhao Liu	2015	Security and Communication Networks	10.1002/sec.743	multiple encryption;wireless ad hoc network;computer science;theoretical computer science;internet privacy;computer security;encryption;probabilistic encryption;attribute-based encryption	Security	-41.137187699487775	76.60163736595071	107561
bb2d001c399bae62e340bef672204f01221a11de	a white-box cryptographic implementation for protecting against power analysis		Encoded lookup tables used in white-box cryptography are known to be vulnerable to power analysis due to the imbalanced encoding. This means that the countermeasures against white-box attacks can not even defend against gray-box attacks. For this reason, those who want to defend against power analysis through the white-box cryptographic implementation need to find other ways. In this paper, we propose a method to defend power analysis without resolving the problematic encoding problem. Compared with the existing white-box cryptography techniques, the proposed method has twice the size of the lookup table and nearly the same amount of computation. key words: white-box cryptography, power analysis, countermeasure	computation;cryptography;lookup table	Seungkwang Lee	2018	IEICE Transactions		computer vision;theoretical computer science;white box;power analysis;cryptography;artificial intelligence;computer science	Security	-35.820075130195754	80.27076553773776	107623
7991a2e1fdb87c697762d099f45140561b1f9b9c	hardware implementations of a variant of the zémor-tillich hash function: can a provably secure hash function be very efficient ?		Hash functions are widely used in Cryptography, and hardware implementations of hash functions are of interest in a variety of contexts such as speeding up the computations of a network server or providing authentication in small electronic devices such as RFID tags. Provably secure hash functions, the security of which relies on the hardness of a mathematical problem, are particularly appealing for security, but they used to be too inefficient in practice. In this paper, we study the efficiency in hardware of ZT’, a provably secure hash function based on the Zémor-Tillich hash function. We consider three kinds of implementations targeting a high throughput and a low area in different ways. We first present a high-speed implementation of ZT’ on FPGA that is nearly half as efficient as state-of-the-art SHA implementations in terms of throughput per area. We then focus on area reduction and present an ASIC implementation of ZT’ with much smaller area costs than SHA-1 and even than SQUASH, which was specially designed for low-cost RFID tags. Between these two extreme implementations, we show that the throughput and area can be traded with a lot of flexibility. Finally, we show that the inherent parallelism of ZT’ makes it particularly suitable for applications requiring high speed hashing of very long messages. Our work, together with existing reasonably efficient software implementations, shows that this variant of the Zémor-Tillich hash function is in fact very practical for a wide range of applications, while having a security related to the hardness of a mathematical problem and significant additional advantages such as scalability and parallelism.	application-specific integrated circuit;authentication;computation;cryptographic hash function;cryptography;field-programmable gate array;parallel computing;provable security;radio-frequency identification;sha-1;scalability;security of cryptographic hash functions;server (computing);throughput	Giacomo de Meulenaer;Christophe Petit;Jean-Jacques Quisquater	2009	IACR Cryptology ePrint Archive			Security	-36.504179102092145	78.21145004685766	107734
926320d99789b5c5b6e2243a1127fa6848dc6a3d	using the edwards-curve digital signature algorithm (eddsa) in the internet key exchange protocol version 2 (ikev2)		This document describes the use of the Edwards-curve digital signaturenalgorithm in the IKEv2 protocol.	algorithm;digital signature;internet key exchange	Yoav Nir	2018	RFC	10.17487/RFC8420	theoretical computer science;the internet;key exchange;digital signature algorithm;eddsa;edwards curve;computer science	Crypto	-41.874643286336976	78.82920574057927	107735
1a8868b3362e79930310f9f3fbaaa44242811712	shielding circuits with groups	leakage resistant cryptography	We show how to efficiently compile any given circuit C into a leakage-resistant circuit C' such that any function on the wires of C' that leaks information during a computation C'(x) yields advantage in computing the product of |C'|Ω(1) elements of the alternating group Au. In combination with new compression bounds for Au products, also obtained here, C' withstands leakage from virtually any class of functions against which average-case lower bounds are known. This includes communication protocols, and AC0 circuits augmented with few arbitrary symmetric gates. If NC1 ' TC0 then then the construction resists TC0 leakage as well. We also conjecture that our construction resists NC1 leakage. In addition, we extend the construction to the multi-query setting by relying on a simple secure hardware component. We build on Barrington's theorem [JCSS '89] and on the previous leakage-resistant constructions by Ishai et al. [Crypto '03] and Faust et al. [Eurocrypt '10]. Our construction exploits properties of Au beyond what is sufficient for Barrington's theorem.	ac0;best, worst and average case;compiler;computation;eurocrypt;faust;information leakage;journal of computer and system sciences;nc (complexity);spectral leakage;tc0	Eric Miles;Emanuele Viola	2013	Electronic Colloquium on Computational Complexity (ECCC)	10.1145/2488608.2488640	combinatorics;discrete mathematics;theoretical computer science;mathematics;algorithm	Theory	-37.084332609459864	77.59381197527797	107752
7267c80c39353b8aaec80656aaa2b6aa3e5ccd27	faster homomorphic function evaluation using non-integral base encoding		In this paper we present an encoding method for xed-point numbers tailored for homomorphic function evaluation. The choice of the degree of the polynomial modulus used in all popular somewhat homomorphic encryption schemes is dominated by security considerations, while with the current encoding techniques the correctness requirement allows for much smaller values. We introduce a generic encoding method using expansions with respect to a non-integral base, which exploits this large degree at the bene t of reducing the growth of the coe cients when performing homomorphic operations. In practice this allows one to choose a smaller plaintext coe cient modulus which results in a signi cant reduction of the running time. We illustrate our approach by applying this encoding in the setting of homomorphic electricity load forecasting for the smart grid which results in a speed-up by a factor 13 compared to previous work, where encoding was done using balanced ternary expansions.	balanced ternary;church encoding;correctness (computer science);homomorphic encryption;modulus robot;plaintext;polynomial;time complexity	Charlotte Bonte;Carl Bootland;Joppe W. Bos;Wouter Castryck;Ilia Iliashenko;Frederik Vercauteren	2017		10.1007/978-3-319-66787-4_28	real number;theoretical computer science;smart grid;computer science;encoding (memory);correctness;balanced ternary;homomorphic encryption;distributed computing;algorithm;polynomial;plaintext	Crypto	-38.350133201325264	78.45954080965073	108332
e34737aad307899739bdf41812556ecfc8e74527	attacks against search poly-lwe		The Ring-LWE (RLWE) problem is expected to be a computationally-hard problem even with quantum algorithms. The Poly-LWE (PLWE) problem is closely related to the RLWE problem, and in practice a security base for various recently-proposed cryptosystems. In 2014, Eisentraeger et al. proposed attacks against the decision-variant of the PLWE problem (and in 2015, Elias et al. precisely described and extended their attacks to be applied for that of the RLWE problem). Their attacks against the decision-PLWE problem succeed with sufficiently high probability in polynomial time under certain assumptions, one of which is that the defining polynomial of the PLWE instance splits completely over the ground field. In this paper, we present polynomial-time attacks against the search-variant of the PLWE problem. Our attacks are viewed as search-case variants of the previous attacks, but can deal with more general cases where the defining polynomial of the PLWE problem does not split completely over the ground field. Key words— Ring-LWE, Poly-LWE, finite field	cryptosystem;decision problem;factorization of polynomials;learning with errors;p/poly;polynomial;quantum algorithm;square-free polynomial;time complexity	Momonari Kudo	2016	IACR Cryptology ePrint Archive		computer science	Crypto	-38.03965305014641	79.38780318491138	108450
421724300201f18946e735bd59e21f99ca683acf	a face template protection approach using chaos and grp permutation	template security;fuzzy commitment scheme;grp permutation;face templates;chaotic sequence	In biometric systems, template protection is a vital issue for preventing from identity theft. Fuzzy commitment scheme is a template cryptographic method providing secure templates by binding a uniform random key to a template. Fuzzy commitment scheme suffers from its lacks in privacy, in cancelability, and also in robustness against cross-matching attacks. To improve both the security and cancelability properties simultaneously, we present a novel template protection approach for face recognition systems based on fuzzy commitment scheme, permutated features, and chaos symmetric key. To permute feature vectors, we produce pseudo random numbers by using nonlinear chaos function to fill the control array of GRP permutation method. Even if the permutated template is compromised, it is possible to substitute it with a new permutated template by changing the initial conditions of chaos map. To evaluate our proposed approach, a series of experiments have been conducted on two well-known face databases ORL and Yale. We showed that the new feature permutation leads to more secure protected templates against decodability based on cross-matching attacks. The experimental results also showed that our proposed approach outperforms existing fuzzy commitment methods both in security and privacy aspects without influencing the accuracy. Copyright © 2016 John Wiley & Sons, Ltd.	biometrics;chaos theory;commitment scheme;control array;cryptography;database;digital watermarking;experiment;facial recognition system;feature vector;fingerprint recognition;gentoo linux;initial condition;iris recognition;john d. wiley;multimodal interaction;nonlinear system;profiling (computer programming);pseudorandomness;randomness;return loss;steganography;symmetric-key algorithm	Sara Nazari;Mohammad Shahram Moin;Hamidreza Rashidy Kanan	2016	Security and Communication Networks	10.1002/sec.1667	speech recognition;theoretical computer science;algorithm	Security	-43.25703700559391	80.54851229690183	108686
4e2213470aeadad6dca9338b6dd72be55004c4a8	programmable hash functions in the multilinear setting		We adapt the concept of a programmable hash function (PHF, Crypto 2008) to a setting in which a multilinear map is available. This enables new PHFs with previously unachieved parameters. To demonstrate their usefulness, we show how our (standard-model) PHFs can replace random oracles in several well-known cryptographic constructions. Namely, we obtain standard-model versions of the BonehFranklin identity-based encryption scheme, the Boneh-Lynn-Shacham signature scheme, and the Sakai-Ohgishi-Kasahara identity-based noninteractive key exchange (ID-NIKE) scheme. The ID-NIKE scheme is the first scheme of its kind in the standard model. Our abstraction also allows to derive hierarchical versions of the above schemes in settings with multilinear maps. This in particular yields simple and efficient hierarchical generalizations of the BF, BLS, and SOK schemes. In the case of hierarchical ID-NIKE, ours is the first such scheme with full security, in either the random oracle model or the standard model. While our constructions are formulated with respect to a generic multilinear map, we also outline the necessary adaptations required for the recent “noisy” multilinear map candidate due to Garg, Gentry, and Halevi.	brainfuck;caller id;cryptography;digital signature;id-based encryption;interactivity;key exchange;oracle machine;perfect hash function;random oracle;sakai project	Eduarda S. V. Freire;Dennis Hofheinz;Kenneth G. Paterson;Christoph Striecks	2013		10.1007/978-3-642-40041-4_28	discrete mathematics;theoretical computer science;mathematics;computer security;algorithm	Crypto	-38.59797056964285	76.74379176056019	108730
9e487eea9772ba8742c5deee3f6b214ebfb79811	fully homomorphic encryption from ring-lwe and security for key dependent messages	key dependent message;rlwe assumption;homomorphic scheme;homomorphic encryption scheme;ideal lattice;additional assumption;simple scheme;own secret key;secret key;public key;cryptographic assumption	We present a somewhat homomorphic encryption scheme that is both very simple to describe and analyze, and whose security (quantumly) reduces to the worst-case hardness of problems on ideal lattices. We then transform it into a fully homomorphic encryption scheme using standard “squashing” and “bootstrapping” techniques introduced by Gentry (STOC 2009). One of the obstacles in going from “somewhat” to full homomorphism is the requirement that the somewhat homomorphic scheme be circular secure, namely, the scheme can be used to securely encrypt its own secret key. For all known somewhat homomorphic encryption schemes, this requirement was not known to be achievable under any cryptographic assumption, and had to be explicitly assumed. We take a step forward towards removing this additional assumption by proving that our scheme is in fact secure when encrypting polynomial functions of the secret key. Our scheme is based on the ring learning with errors (RLWE) assumption that was recently introduced by Lyubashevsky, Peikert and Regev (Eurocrypt 2010). The RLWE assumption is reducible to worst-case problems on ideal lattices, and allows us to completely abstract out the lattice interpretation, resulting in an extremely simple scheme. For example, our secret key is s, and our public key is (a, b = as+ 2e), where s, a, e are all degree (n− 1) integer polynomials whose coefficients are independently drawn from easy to sample distributions.	best, worst and average case;coefficient;eurocrypt;homomorphic encryption;ideal lattice cryptography;key (cryptography);learning with errors;polynomial;public-key cryptography;symposium on theory of computing	Zvika Brakerski;Vinod Vaikuntanathan	2011		10.1007/978-3-642-22792-9_29	discrete mathematics;theoretical computer science;mathematics;homomorphic secret sharing;computer security	Crypto	-37.905597368173304	76.84839528950612	108790
28b26b9c6856e431d8e1c550c8fb0331002f3756	password authenticated key exchange using quadratic residues	provable security;controle acces;llave cambio;protocole transmission;securite;dictionary attack;echange cle;cle publique;cache memory;probabilistic approach;residu;attaque;antememoria;feasibility;ataque;protocolo transmision;antememoire;dictionnaire;public key;key exchange;criptografia;random oracle model;enfoque probabilista;cryptography;approche probabiliste;dictionaries;safety;llave publica;cryptographie;problema diffie hellman;password authenticated key exchange;access control;residuo;diffie hellman key exchange;seguridad;residue;diccionario;practicabilidad;faisabilite;oracle;attacking;probleme diffie hellman;diffie hellman problem;transmission protocol	This paper investigates the feasibility of designing password- authenticated key exchange protocols using quadratic residues. To date, most of the published protocols for password-authenticated key exchange were based on the Diffie-Hellman key exchange. It appears inappropri- ate to design password-authenticated key exchange protocols using other public-key cryptographic techniques. In this paper, we show that proto- cols for password-authenticated key exchange can be constructed using quadratic residues and we present the first protocol of this type. Under the factoring assumption and the random oracle model, we show that our protocol is provably secure against off-line dictionary attacks. We also discuss the use of cache technique to improve the efficiency of our protocol.	authenticated key exchange;authentication;password;quadratic residue	Muxiang Zhang	2004		10.1007/978-3-540-24852-1_17	oracle;feasibility study;oakley protocol;key exchange;computer science;cryptography;access control;key-agreement protocol;provable security;distributed computing;internet privacy;residue;computer security;dictionary attack	Crypto	-43.47659628266359	77.21363842459148	108800
1837d693b962297903994a8a33a51040103ccebe	joint state theorems for public-key encryption and digital signature functionalities with local computation	secure composition cryptographic protocols simulation based security joint state;protocols;secure composition;cryptographic protocols;digital signatures;joint state;joints;computer security;computational modeling;public key;cryptography;public key cryptography digital signatures protocols computational modeling computer security computer simulation;security;computer simulation;simulation based security	"""Composition theorems in simulation-based approaches allow to build complex protocols from sub-protocols in a modular way. However, as first pointed out and studied by Canetti and Rabin, this modular approach often leads to impractical implementations. For example, when using a functionality for digital signatures within a more complex protocol, parties have to generate new verification and signing keys for every session of the protocol. This motivates to generalize composition theorems to so-called joint state theorems, where different copies of a functionality may share some state, e.g., the same verification and signing keys. In this paper, we present a joint state theorem which is more general than the original theorem of Canetti and Rabin, for which several problems and limitations are pointed out. We apply our theorem to obtain joint state realizations for three functionalities: public-keyencryption, replayable public-key encryption, and digital signatures. Unlike most other formulations, our functionalities model that cipher texts and signatures are computed locally, rather than being provided by the adversary. To obtain the joint state realizations, the functionalities have to be designed carefully. Other formulations are shown to be unsuitable. Our work is based on a recently proposed, rigorous model for simulation-based security by K{\""""u}sters, called the IITM model. Our definitions and results demonstrate the expressivity and simplicity of this model. For example, unlike Canetti's UC model, in the IITM model no explicit joint state operator needs to be defined and the joint state theorem follows immediately from the composition theorem in the IITM model."""	adversary (cryptography);antivirus software;cipher;code signing;computation;density matrix;digital signature;electronic signature;encryption;expressive power (computer science);public-key cryptography;simulation;type signature;uc browser	Ralf Küsters;Max Tuengerthal	2008	2008 21st IEEE Computer Security Foundations Symposium	10.1109/CSF.2008.18	computer simulation;computer science;cryptography;information security;theoretical computer science;distributed computing;computer security;algorithm	Crypto	-40.19661657910323	75.6386997125479	108816
c1ec4cb686db93e5ac1e43b4502630b18d5a7b64	on the lossiness of 2 k -th power and the instantiability of rabin-oaep	oaep;rabin;φ hiding;lossy trapdoor function	Seurin PKC 2014 proposed the 2-i¾?/4-hiding assumption which asserts the indistinguishability of Blum Numbers from pseudo Blum Numbers. In this paper, we investigate the lossiness of 2 k -th power based on the 2 k -i¾?/4-hiding assumption, which is an extension of the 2-i¾?/4-hiding assumption. And we prove that 2 k -th power function is a lossy trapdoor permutation over Quadratic Residuosity group. This new lossy trapdoor function has 2k-bits lossiness for k-bits exponent, while the RSA lossy trapdoor function given by Kiltz et al. Crypto 2010 has k-bits lossiness for k-bits exponent under i¾?-hiding assumption in lossy mode. We modify the square function in Rabin-OAEP by 2 k -th power and show the instantiability of this Modified Rabin-OAEP by the technique of Kiltz et al. Crypto 2010. The Modified Rabin-OAEP is more efficient than the RSA-OAEP scheme for the same secure bits. With the secure parameter being 80 bits and the modulus being 2048 bits, Modified Rabin-OAEP can encrypt roughly 454 bits of message, while RSA-OAEP can roughly encrypt 274 bits.		Haiyang Xue;Bao Li;Xianhui Lu;Kunpeng Wang;Yamin Liu	2014		10.1007/978-3-319-12280-9_3	discrete mathematics;computer science;theoretical computer science;optimal asymmetric encryption padding;mathematics;computer security;algorithm	Crypto	-38.705033786983456	78.85095116886285	108983
8d724d86947e9001d9e8a8e7917109cede8b948e	advances in cryptology -- eurocrypt 2010 : 29th annual international conference on the theory and applications of cryptographic techniques, french riviera, may 30-june 3, 2010 : proceedings	computer communication networks;algorithm analysis;discrete mathematics;data encryption;problem complexity;information system;data security	Cryptosystems I.- On Ideal Lattices and Learning with Errors over Rings.- Fully Homomorphic Encryption over the Integers.- Converting Pairing-Based Cryptosystems from Composite-Order Groups to Prime-Order Groups.- Fully Secure Functional Encryption: Attribute-Based Encryption and (Hierarchical) Inner Product Encryption.- Obfuscation and Side Channel Security.- Secure Obfuscation for Encrypted Signatures.- Public-Key Encryption in the Bounded-Retrieval Model.- Protecting Circuits from Leakage: the Computationally-Bounded and Noisy Cases.- 2-Party Protocols.- Partial Fairness in Secure Two-Party Computation.- Secure Message Transmission with Small Public Discussion.- On the Impossibility of Three-Move Blind Signature Schemes.- Efficient Device-Independent Quantum Key Distribution.- Cryptanalysis.- New Generic Algorithms for Hard Knapsacks.- Lattice Enumeration Using Extreme Pruning.- Algebraic Cryptanalysis of McEliece Variants with Compact Keys.- Key Recovery Attacks of Practical Complexity on AES-256 Variants with up to 10 Rounds.- IACR Distinguished Lecture.- Cryptography between Wonderland and Underland.- Automated Tools and Formal Methods.- Automatic Search for Related-Key Differential Characteristics in Byte-Oriented Block Ciphers: Application to AES, Camellia, Khazad and Others.- Plaintext-Dependent Decryption: A Formal Security Treatment of SSH-CTR.- Computational Soundness, Co-induction, and Encryption Cycles.- Models and Proofs.- Encryption Schemes Secure against Chosen-Ciphertext Selective Opening Attacks.- Cryptographic Agility and Its Relation to Circular Encryption.- Bounded Key-Dependent Message Security.- Multiparty Protocols.- Perfectly Secure Multiparty Computation and the Computational Overhead of Cryptography.- Adaptively Secure Broadcast.- Universally Composable Quantum Multi-party Computation.- Cryptosystems II.- A Simple BGN-Type Cryptosystem from LWE.- Bonsai Trees, or How to Delegate a Lattice Basis.- Efficient Lattice (H)IBE in the Standard Model.- Hash and MAC.- Multi-property-preserving Domain Extension Using Polynomial-Based Modes of Operation.- Stamu0027s Collision Resistance Conjecture.- Universal One-Way Hash Functions via Inaccessible Entropy.- Foundational Primitives.- Constant-Round Non-malleable Commitments from Sub-exponential One-Way Functions.- Constructing Verifiable Random Functions with Large Input Spaces.- Adaptive Trapdoor Functions and Chosen-Ciphertext Security.	cryptography;eurocrypt	Henri Gilbert	2010		10.1007/978-3-642-13190-5	computer science;theoretical computer science;distributed computing	EDA	-44.748946246779575	81.69813597862996	109238
07635950037b2d59bf9f1cfd74bcbd088d50eb39	cover and decomposition index calculus on elliptic curves made practical. application to a seemingly secure curve over fp6		We present a new “cover and decomposition” attack on the elliptic curve discrete logarithm problem, that combines Weil descent and decomposition-based index calculus into a single discrete logarithm algorithm. This attack applies, at least theoretically, to all composite degree extension fields, and is particularly well-suited for curves defined over Fp6 . We give a real-size example 3 of discrete logarithm computations on a curve over a 156-bit degree 6 extension field, which would not have been practically attackable using previously known algorithms. A shorter version of this work was presented at the EUROCRYPT 2012 conference.	algorithm;computation;digital light processing;discrete logarithm;elliptic curve cryptography;eurocrypt;extrapolation;gaussian elimination;linear algebra;magma;sextic equation	Antoine Joux;Vanessa Vitse	2011	IACR Cryptology ePrint Archive			Crypto	-39.07452694239871	80.45735276577618	109258
28e9c86103977299ab2690b4c39ac9f22d1ee21e	high rate fingerprinting codes and the fingerprinting capacity	upper bound;standard model	Including a unique code in each copy of a distributed document is an effective way of fighting intellectual piracy. Codes designed for this purpose that are secure against collusion attacks are called fingerprinting codes. In this paper we consider fingerprinting with the marking assumption and design codes that achieve much higher rates than previous constructions. We conjecture that these codes attain the maximum possible rate (the fingerprinting capacity) for any fixed number of pirates. We prove new upper bounds for the fingerprinting capacity that are not far from the rate of our codes. On the downside the accusation algorithm of our codes are much slower than those of earlier	algorithm;code (cryptography);fingerprint (computing);item unique identification;qr code	Ehsan Amiri;Gábor Tardos	2009			block code;standard model;combinatorics;telecommunications;mathematics;upper and lower bounds;computer security;algorithm	Theory	-33.730636308013835	78.75211117121562	109481
231aea08f5f1bdc7ecc680ac0cd4efa2a1f4915e	proxy re-encryption in a stronger security model extended from ct-rsa2012	pairings;unidirectional proxy re encryption;chosen ciphertext attack	Proxy re-encryption (PRE) realizes delegation of decryption rights, enabling a proxy holding a re-encryption key to convert a ciphertext originally intended for Alice into an encryption of the same message for Bob, and cannot learn anything about the encrypted plaintext. PRE is a very useful primitive, having many applications in distributed file systems, outsourced filtering of encrypted spam, access control over network storage, confidential email, digital right management, and so on. In CT-RSA2012, Hanaoka et al. proposed a chosen-ciphertext (CCA) security definition for PRE, and claimed that it is stronger than all the previous works. Their definition is a somewhat strengthened variant of the replayable-CCA one, however, it does not fully capture the CCA security notion. In this paper, we present a full CCA security definition which is extended from theirs. We then propose the first PRE scheme with this security in the standard model (i.e. without the random oracle idealization). Our scheme is efficient and relies on mild complexity assumptions in bilinear groups.	encryption;proxy re-encryption	Toshiyuki Isshiki;Manh Ha Nguyen;Keisuke Tanaka	2013		10.1007/978-3-642-36095-4_18	computer science;internet privacy;world wide web;computer security	Crypto	-40.00787267833474	75.02617768752684	109621
b3950b9c81b0b0007332246af92705b3bc176055	controlled homomorphic encryption: definition and construction		Fully Homomorphic Encryption schemes (FHEs) and Functional Encryption schemes (FunctEs) have a tremendous impact in Cryptography both for the natural questions that they address and for the wide range of applications in which they have been (sometimes critically) used. In this work we put forth the notion of a Controllable Homomorphic Encryption scheme (CHES), a new primitive that includes features of both FHEs and FunctEs. In a CHES it is possible (similarly to a FHE) to homomorphically evaluate a ciphertext Ct = Enc(m) and a circuit C therefore obtaining Enc(C(m)) but only if (similarly to a FunctE) a token for C has been received from the owner of the secret key. We discuss difficulties in constructing a CHES and then show a construction based on any FunctE.	ciphertext;cryptography;functional encryption;homomorphic encryption;key (cryptography)	Yvo Desmedt;Vincenzo Iovino;Giuseppe Persiano;Ivan Visconti	2014	IACR Cryptology ePrint Archive	10.1007/978-3-319-70278-0_7	multiple encryption;homomorphic secret sharing;internet privacy;computer security;probabilistic encryption;attribute-based encryption	Crypto	-38.41278401005159	75.93316565734995	109701
335eb01812a9dcfe62ab1eb76e0f30803a5e3ecc	secure and anonymous hybrid encryption from coding theory		Cryptographic schemes based on coding theory are one of the most accredited choices for cryptography in a post-quantum scenario. In this work, we present a hybrid construction based on the Niederreiter framework that provides IND-CCA security in the random oracle model. In addition, the construction satises the IK-CCA notion of anonymity whose importance is ever growing in the cryptographic community.	coding theory;encryption;hybrid cryptosystem	Edoardo Persichetti	2013		10.1007/978-3-642-38616-9_12	cryptographic primitive;computer science;theoretical computer science;internet privacy;computer security	Crypto	-40.656893716036215	78.41827909782363	109755
9872bc943697afcbba3c19681a2f74b42709bbf8	mutual authentication and key exchange protocols for roaming services in wireless mobile networks	roaming services;anonymity;telecommunication security cryptography mobile radio protocols;protocols;global mobility network;mobile radiocommunication;secret splitting;securite;telecommunication sans fil;one time session key renewal;mobile networks;roaming authentication home automation privacy cryptography ip networks mobile computing wireless application protocol protection multiaccess communication;wireless application protocol;authentication;indexing terms;service telecommunication;authenticated key exchange;communication service mobile;radiocommunication service mobile;itinerancia;authentification;key exchange protocols;anonymat;vida privada;protection;roaming service;wireless mobile networks;identity anonymity;self certified;autenticacion;key exchange;users privacy;private life;computational complexity;telecomunicacion sin hilo;cryptography;one time session key progression mutual authentication key exchange protocols roaming services wireless mobile networks global mobility network one time session key renewal identity anonymity users privacy;mobile radio;mutual authentication;safety;mobile communication;telecommunication security;itinerance;roaming;telecommunication services;vie privee;ip networks;radiocomunicacion servicio movil;autocertificacion;mobile computing;seguridad;self certification;autocertification;privacy;one time session key progression;mobile network;multiaccess communication;home automation;anonimato;mobile user;wireless telecommunication	Two novel mutual authentication and key exchange protocols with anonymity are proposed for different roaming scenarios in the global mobility network. The new features in the proposed protocols include identity anonymity and one-time session key renewal. Identity anonymity protects mobile users privacy in the roaming network environment. One-time session key progression frequently renews the session key for mobile users and reduces the risk of using a compromised session key to communicate with visited networks. It has demonstrated that the computation complexity of the proposed protocols is similar to the existing ones, while the security has been significantly improved	color gradient;computation;encryption;key (cryptography);key exchange;key-agreement protocol;mutual authentication;one-way function;security management;session key;shared secret;symmetric-key algorithm	Yixin Jiang;Chuang Lin;Xuemin Shen;Minghui Shi	2006	IEEE Transactions on Wireless Communications	10.1109/TWC.2006.05063	computer science;authentication;internet privacy;mobile computing;computer security;computer network	Security	-46.46727686826659	77.19641233706407	110019
dd9cb62a3fcceae067dda4c06716773959f2241a	watermarking prfs under standard assumptions: public marking and security with extraction queries		A software watermarking scheme can embed some information called a mark into a program while preserving its functionality. No adversary can remove the mark without damaging the functionality of the program. Cohen et al. (STOC ’16) gave the first positive results for watermarking, showing how to watermark certain pseudorandom function (PRF) families using indistinguishability obfuscation (iO). Their scheme has a secret marking procedure to embed marks in programs and a public extraction procedure to extract the marks from programs; security holds even against an attacker that has access to a marking oracle. Kim and Wu (CRYPTO ’17) later constructed a PRF watermarking scheme under only the LWE assumption. In their scheme, both the marking and extraction procedures are secret, but security only holds against an attacker with access to a marking oracle but not an extraction oracle. In fact, it is possible to completely break the security of the latter scheme using extraction queries, which is a significant limitation in any foreseeable application. In this work, we construct a new PRF watermarking scheme with the following properties. • The marking procedure is public and therefore anyone can embed marks in PRFs from the family. Previously we had no such construction even using obfuscation. • The extraction key is secret, but marks remain unremovable even if the attacker has access to an extraction oracle. Previously we had no such construction under standard assumptions. • Our scheme is simple, uses generic components and can be instantiated under many different assumptions such as DDH, Factoring or LWE. The above benefits come with one caveat compared to prior work: the PRF family that we can watermark depends on the public parameters of the watermarking scheme and the watermarking authority has a secret key which can break the security of all of the PRFs in the family. Since the watermarking authority is usually assumed to be trusted, this caveat appears to be acceptable. ∗Northeastern University. Email: quach.w@husky.neu.edu †Northeastern University. Email: wichs@ccs.neu.edu. Supported by NSF grants CNS-1314722, CNS-1413964, CNS-1750795 and the Alfred P. Sloan Research Fellowship. ‡Northeastern University. Email: zirdelis.g@husky.neu.edu	adversary (cryptography);certificate authority;ciphertext indistinguishability;decisional diffie–hellman assumption;digital watermarking;email;ibm notes;integer factorization;item unique identification;key (cryptography);learning with errors;obfuscation (software);oracle database;primitive recursive function;pseudorandom function family;pseudorandomness;symposium on theory of computing	Willy Quach;Daniel Wichs;Giorgos Zirdelis	2018		10.1007/978-3-030-03810-6_24	theoretical computer science;digital watermarking;watermark;adversary;computer science;oracle;obfuscation;pseudorandom function family;software	Crypto	-35.467305013163944	76.87824799195224	110502
0d575c0e0b490502d8c78069c99a71dd712a5379	masking against side-channel attacks: a formal security proof		Masking is a well-known countermeasure to protect block cipher implementations against side-channel attacks. The principle is to randomly split every sensitive intermediate variable occurring in the computation into d + 1 shares, where d is called the masking order and plays the role of a security parameter. Although widely used in practice, masking is often considered as an empirical solution and its effectiveness is rarely proved. In this paper, we provide a formal security proof for masked implementations of block ciphers. Specifically, we prove that the information gained by observing the leakage from one execution can be made negligible (in the masking order). To obtain this bound, we assume that every elementary calculation in the implementation leaks a noisy function of its input, where the amount of noise can be chosen by the designer (yet linearly bounded). We further assume the existence of a leak-free component that can refresh the masks of shared variables. Our work can be viewed as an extension of the seminal work of Chari et al. published at CRYPTO in 1999 on the soundness of combining masking with noise to thwart side-channel attacks.	block cipher;computation;linear bounded automaton;provable security;randomness;security parameter;shared variables;side-channel attack;spectral leakage	Emmanuel Prouff;Matthieu Rivain	2013		10.1007/978-3-642-38348-9_9	computer science;theoretical computer science;computer security;algorithm	Crypto	-37.608012608699134	76.23669640925935	110564
a0f80f2673ce0ee40a8e26a765cec7435aa67a26	a practical id-based group signature scheme	anonymity;short signature;group signature;id based signature;bilinear pairing	A new ID-based group signature scheme, in which group managers (Membership Manager and Tracing Manager) and group members are all ID-based, is presented in this paper. Due to the nice constructive method of group signature schemes and the sound properties of bilinear pairing, it is shown that our scheme has the advantages of concurrent joining of users, immediate revocation of group members, easy tracing of signature signers and short length of signatures. Furthermore, it is trapdoor-free. The security analysis is under the formal security notion of an ID-based dynamic group signature scheme.	bilinear filtering;group signature;scheme;type signature	Xiangguo Cheng;Shaojie Zhou;Jia Yu;Xin Li;Huiran Ma	2012	JCP	10.4304/jcp.7.11.2650-2654	ring signature;merkle signature scheme;anonymity;computer science;mathematics;internet privacy;group signature;blind signature;schnorr signature;world wide web;elgamal signature scheme;computer security;algorithm	Crypto	-41.971643137475354	74.90706714890402	110832
a0ac2dee1b1a2ecd060cee9bea4324e081266627	encryption algorithm using programmable cellular automata	software;principal component analysis encryption automata pipelines chaos software;high performance encryption algorithm;encryption;internet technology programmable cellular automata high performance encryption algorithm bio inspired based cryptosystem parallel information processing pca block cipher c programming language medical data;computational techniques;chaos;block cipher;bio inspired based cryptosystem;medical data;parallel information processing;medical computing;automata;internet technology;programmable cellular automata;c language;internet;cryptography;principal component analysis;pipelines;information processing;pca block cipher;parallel processing c language cellular automata cryptography internet medical computing;c programming language;cellular automata;high performance;high speed;parallel processing	In this paper is developed a high-performance encryption system that works according with the Programmable Cellular Automata (PCA) theory. The essence of the theoretical and practical efforts which are done in this new field is represented by the idea that bio-inspired based cryptosystems are capable to have similar performances regarding the classic methods based on computational techniques. The proposed encryption and decryption modules are identically and the cryptosystem is featured by its large key space and high speed due to cellular automata's parallel information processing. The PCA block cipher has been implemented in software using C# programming language and is used, as a dynamic library, in order to assure the encryption of medical data sent over the internet.	algorithm;automata theory;block cipher;british informatics olympiad;cellular automaton;cryptography;cryptosystem;dynamic linker;encryption;information processing;key space (cryptography);performance;programming language	Petre Anghelescu	2011	2011 World Congress on Internet Security (WorldCIS-2011)		multiple encryption;disk encryption theory;40-bit encryption;computer science;theoretical computer science;distributed computing;deterministic encryption;encryption;probabilistic encryption;algorithm	Crypto	-42.382598549158054	82.6590027107811	110932
f3704b80a036f3b5fdd779acc7b8b90b4f915342	efficient oblivious transfer from lossy threshold homomorphic encryption		In this article, a new oblivious transfer (OT) protocol, secure in the presence of erasure-free one-sided active adaptive adversaries is presented. The new bit OT protocol achieves better communication complexity than the existing bit OT protocol in this setting. The new bit OT protocol requires fewer number of public key encryption operations than the existing bit OT protocol in this setting. As a building block, a new two-party lossy threshold homomorphic public key cryptosystem is designed. It is secure in the same adversary model. It is of independent interest.	adversary model;communication complexity;cryptosystem;homomorphic encryption;lossy compression;oblivious transfer;public-key cryptography	Isheeta Nargis	2017		10.1007/978-3-319-57339-7_10	oblivious transfer;adversary model;lossy compression;public-key cryptography;cryptosystem;communication complexity;homomorphic encryption;distributed computing;homomorphic secret sharing;computer science	Crypto	-38.02304053832543	76.43439199383687	110963
1e7ebc661f0d3e3d50522cbb3f189e51988498de	secure verifier-based three-party password-authenticated key exchange	authenticated key exchange;dictionary attack;password-based;three-party;verifier-based	In order to secure large-scale peer-to-peer communication system, Chien recently presented a three-party password authenticated key exchange protocol using verifiers to reduce the damages of server corruption. In this paper, we first show his protocol is still vulnerable to a partition attack (offline dictionary attack). Thereafter we propose an enhanced verifier-based protocol that can defeat the attacks described and yet is reasonably efficient. Furthermore, we can provide the rigorous proof of the security for it.	authenticated key exchange;authentication;password	Qiong Pu;Jian Wang;Shuhua Wu;Ji Fu	2013	Peer-to-Peer Networking and Applications	10.1007/s12083-012-0125-y	zero-knowledge password proof;computer science;internet privacy;world wide web;computer security	Crypto	-43.05646571284722	75.44669303143213	111274
11963d0f55043e00a49879fd46836fb791514381	on a construction of stream-cipher-based hash functions	generators;nist;complexity theory;preimage resistance hash function stream cipher collision resistance second preimage resistance;clocks;design criteria;resistance;preimage resistance;collision resistant hash functions;second preimage resistance;registers resistance clocks security nist generators complexity theory;stream cipher;registers;collision resistance;hash function;security	Hash functions using stream ciphers as components perform fast on a variety of platforms. However, the security and the design policy of stream-cipher-based hash functions (SCHs) have not yet been studied sufficiently. In this paper, we analyze its design criteria based on a ideal function of SCHs. First, we show that attacks against a stream cipher can also be threats against SCHs. Then we discuss the security on each phase of SCH; message injection, blank rounds, and hash generation with this function. Finally we derive the necessary conditions on the stream cipher function for an SCH to be secure.	hash function;stream cipher;system controller hub	Yuto Nakano;Jun Kurihara;Shinsaku Kiyomoto;Toshiaki Tanaka	2010	2010 International Conference on Security and Cryptography (SECRYPT)		security of cryptographic hash functions;double hashing;hash function;perfect hash function;collision attack;merkle tree;nist;preimage attack;sha-2;collision resistance;computer science;secure hash algorithm;information security;theoretical computer science;secure hash standard;hash chain;hash buster;distributed computing;rolling hash;stream cipher;processor register;resistance;computer security;cryptographic hash function;mdc-2;swifft;hash tree;hash filter	Security	-41.373831846209555	79.90396497306602	111513
78e6db028b15bc2618e8da09f300a010d8d81d08	balancing communication for multi-party interactive coding		We consider interactive coding in a setting where n parties wish to compute a joint function of their inputs via an interactive protocol over imperfect channels. We assume that adversarial errors can comprise a O( 1 n ) fraction of the total communication, occurring anywhere on the communication network. Our goal is to maintain a constant multiplicative overhead in the total communication required, as compared to the error-free setting, and also to balance the workload over the different parties. We build upon the prior protocol of Jain, Kalai, and Lewko, but while that protocol relies on a single coordinator to shoulder a heavy burden throughout the protocol, we design a mechanism to pass the coordination duties from party to party, resulting in a more even distribution of communication over the course of the computation.	adversary (cryptography);computation;overhead (computing);telecommunications network	Allison Bishop;Ellen Vitercik	2015	CoRR		real-time computing;simulation;computer science;distributed computing	Theory	-34.23140326862664	75.00833562347334	111549
9a6d326de05613f90e30b561fb965f52f25b05e0	an untraceable temporal-credential-based two-factor authentication scheme using ecc for wireless sensor networks	smart card;authentication;wireless sensor network;elliptic curve cryptography;key agreement;untraceability;privacy	Recently, He et al. proposed an anonymous two-factor authentication scheme following the concept of temporal-credential for wireless sensor networks (WSNs), which is claimed to be secure and capable of withstanding various attacks. However, we reveal that the authentication phase of their scheme has several pitfalls. Firstly, their scheme is susceptible to malicious user impersonation attack, in which a legal but malicious user can impersonate as other registered users. In addition, their scheme is also vulnerable to stolen smart card attack. Furthermore, the scheme cannot provide untraceability and is prone to tracking attack. Then we put forward an untraceable two-factor authentication scheme based on elliptic curve cryptography (ECC) for WSNs. Our new scheme makes up for the missing security features necessary for real-life applications while maintaining the desired features of the original scheme. We prove that the scheme fulfills mutual authentication in the Burrows-Abadi-Needham (BAN) logic. Moreover, by way of informal security analysis, we show that the proposed scheme can resist a variety of attacks and provide more security features than He et al.’s scheme.	burrows–abadi–needham logic;credential;elliptic curve cryptography;malware;multi-factor authentication;mutual authentication;needham–schroeder protocol;real life;security hacker;smart card	Qi Jiang;Jianfeng Ma;Fushan Wei;Youliang Tian;Jian Shen;Yuanyuan Yang	2016	J. Network and Computer Applications	10.1016/j.jnca.2016.10.001	smart card;wireless sensor network;computer science;authentication;elliptic curve cryptography;internet privacy;privacy;computer security;computer network	Security	-46.21057263132238	74.899419431148	111606
4a4c50811c53a61ce396307c6a7ee7374a78dbec	a certified email protocol using key chains	databases;public key cryptography;one way function;electronic mail;helium;key chain;storage requirement reduction asynchronous optimistic certified email protocol key chain;cryptographic protocols;public key;storage requirement reduction;trusted third party;electronic mail cryptographic protocols;joining processes;communication system control;communication channels;security;communication channels public key cryptography security helium joining processes cryptographic protocols communication system control public key databases;asynchronous optimistic certified email protocol	This paper introduces an asynchronous optimistic certified email protocol, with stateless recipients, that relies on key chains to considerably reduce the storage requirements of the trusted third party. The proposed protocol thereby outperforms the existing schemes that achieve strong fairness. The paper also discusses the revocation of compromised keys as well as practical considerations regarding the implementation of the protocol.	communications protocol;cryptography;email;fairness measure;non-repudiation;optimistic concurrency control;requirement;stateless protocol;trusted third party	J. G. Cederquist;Muhammad Torabi Dashti;Sjouke Mauw	2007	21st International Conference on Advanced Information Networking and Applications Workshops (AINAW'07)	10.1109/AINAW.2007.10	stateless protocol;computer science;information security;distributed computing;internet privacy;public-key cryptography;computer security;computer network	Mobile	-48.05397501814805	77.1168985130637	111643
445a86bda48c042e353922107ba5b1e1a0f7f119	comments on id-based multi-signature with distinguished signing authorities	forgery attack;multi signature;matematicas aplicadas;mathematiques appliquees;signature scheme;criptografia;cryptography;attaque contrefacon;cryptographie;applied mathematics	Abstract   A multi-signature scheme with distinguished signing authorities is a multi-signature scheme where the signed document is divided into several parts and each signer signs only on the part which he is responsible for. This article shows the security weakness of Wu–Hsu’s ID-based multi-signature scheme with distinguished signing authorities.		Hung-Yu Chien	2005	Applied Mathematics and Computation	10.1016/j.amc.2005.01.019	applied mathematics;cryptography;mathematics;internet privacy;world wide web;computer security	Theory	-42.92136261219424	76.70644431687427	111645
26a0296522299339b8b1f07ca9c76033b6283b51	improved (almost) tightly-secure simulation-sound qa-nizk with applications		We construct the first (almost) tightly-secure unbounded-simulation-sound quasi-adaptive non-interactive zero-knowledge arguments (USS-QA-NIZK) for linear-subspace languages with compact (number of group elements independent of the security parameter) common reference string (CRS) and compact proofs under standard assumptions in bilinear-pairings groups. In particular, under the SXDH assumption, the USS-QA-NIZK proof size is only seventeen group elements with a factor (O(log {Q})) loss in security reduction to SXDH. The USS-QA-NIZK primitive has many applications, including structure-preserving signatures (SPS), CCA2-secure publicly-verifiable public-key encryption (PKE), which in turn have applications to CCA-anonymous group signatures, blind signatures and unbounded simulation-sound Groth-Sahai NIZK proofs. We show that the almost tight security of our USS-QA-NIZK translates into constructions of all of the above applications with (almost) tight-security to standard assumptions such as SXDH and, more generally, (mathcal{D}_k)-MDDH. Thus, we get the first publicly-verifiable (almost) tightly-secure multi-user/multi-challenge CCA2-secure PKE with practical efficiency under standard bilinear assumptions. Our (almost) tight SPS construction is also improved in the signature size over previously known constructions.	antivirus software;bilinear filtering;blind signature;common reference string model;encryption;formal verification;ibm 1401 symbolic programming system;interactivity;multi-user;non-interactive zero-knowledge proof;provable security;public-key cryptography;qa & ux manager;question answering;security parameter;simulation;software quality assurance;unix system services;uss liberty incident	Masayuki Abe;Charanjit S. Jutla;Miyako Ohkubo;Arnab Roy	2018		10.1007/978-3-030-03326-2_21	discrete mathematics;computer science;mathematical proof;public-key cryptography;encryption;security parameter;bilinear interpolation	Crypto	-38.45921336070384	75.83166629679768	111681
6f602fc4845b5a5f225bd011cbf295945e91e2fa	vmpc-r cryptographically secure pseudo-random number generator alternative to rc4		We present a new Cryptographically Secure Pseudo-Random Number Generator. It uses permutations as its internal state, similarly to the RC4 stream cipher. We describe a statistical test which revealed non-random patterns in a sample of 2 outputs of a 3-bit RC4. Our new algorithm produced 2 undistinguishable from random 3-bit outputs in the same test. We probed 2 outputs of the algorithm in different statistical tests with different word sizes and found no way of distinguishing the keystream from a random source. The size of the algorithm’s internal state is 2 (for an 8-bit implementation). The algorithm is cryptographically secure to the extent we were able to analyse it. Its design is simple and easy to implement. We present the generator along with a key scheduling algorithm processing both keys and initialization vectors.	32-bit;8-bit;algorithm;authentication;bit array;circular shift;key schedule;pseudorandom number generator;pseudorandomness;rc4;randomness;scheduling (computing);stream cipher;variably modified permutation composition	Bartosz Zoltak	2013	IACR Cryptology ePrint Archive		rc4;permutation;theoretical computer science;keystream;pre-shared key;stream cipher;initialization;computer security;pseudorandom number generator;computer science;cryptographically secure pseudorandom number generator	Crypto	-36.51972795698464	80.96802845662182	111774
0fba7809fa5b0e98caa33055a9fbfc2afcb15ba1	a post-quantum communication secure identity-based proxy-signcryption scheme	post quantum communication;quantum computer attacks;encryption;proxy signcryption;random oracle model;cryptography;post quantum cryptographic communication;communication security;identity based signcryption;proxy signatures	Proxy-signcryption is a variation of an ordinary signcryption scheme and has been used in many applications where the delegation of rights is quite common. In a proxy-signcryption scheme, an original signcrypter needs to delegate his signcryption capability to a proxy signcrypter to signcrypt messages on behalf of the original signcrypter. By combining the functionalities of proxy signature with identity-based signcryption, in this paper, we propose a novel identity-based proxy-signcryption scheme IBPSC from lattice assumptions in the random oracle model. Meanwhile, the security requirements of our IBPSC scheme have been analysed, and our scheme can even resist quantum computer attacks. Compared with existing IBPSC schemes, our scheme is more secure and more efficient. To the best of our knowledge, there is still no relevant IBPSC scheme based on lattice, which is an interesting stepping stone in the post-quantum cryptographic communication.	post-quantum cryptography;quantum channel;quantum information science;signcryption	Xiaojun Zhang;Chunxiang Xu;Chunhua Jin;Junwei Wen	2015	IJESDF	10.1504/IJESDF.2015.069607	computer science;cryptography;theoretical computer science;signcryption;internet privacy;computer security;encryption	Crypto	-41.288705716511444	75.7721137202049	111806
320b74f23ff5a1b9756377500966cc310c2c9e00	analysis of the algebraic side channel attack		At CHES 2009, Renauld, Standaert and Veyrat-Charvillon introduced a new kind of attack called algebraic side-channel attacks (ASCA). They showed that side-channel information leads to effective algebraic attacks. These results are mostly experiments since strongly based on the use of a SAT solver. This article presents a theoretical study to explain and to characterize the algebraic phase of these attacks. We study more general algebraic attacks based on Gröbner methods. We show that the complexity of the Gröbner basis computations in these attacks depends on a new notion of algebraic immunity defined in this paper, and on the distribution of the leakage information of the cryptosystem. We also study two examples of common leakage models: the Hamming weight and the Hamming distance models. For instance, the study in the case of the Hamming weight model gives that the probability of obtaining at least 64 (resp. 130) linear relations is about 50% for the substitution layer of PRESENT (resp. AES). Moreover if the S-boxes are replaced by functions maximizing the new algebraic immunity criterion then the algebraic attacks (Gröbner and SAT) are intractable. From this theoretical study, we also deduce an invariant which can be easily computed from a given S-box and provides a sufficient condition of weakness under an ASCA. This new invariant does not require any sophisticated algebraic techniques to be defined and computed. Thus, for cryptographic engineers without an advanced knowledge in algebra (e.g. Gröbner basis techniques), this invariant may represent an interesting tool for rejecting weak S-boxes.	anova–simultaneous component analysis;algebraic equation;block cipher;boolean satisfiability problem;computation;cryptography;cryptosystem;differential cryptanalysis;experiment;gröbner basis;hamming code;hamming distance;hamming weight;linear algebra;s-box;side-channel attack;solver;spectral leakage;whole earth 'lectronic link;window function	Claude Carlet;Jean-Charles Faugère;Christopher Goyet;Guénaël Renault	2012	Journal of Cryptographic Engineering	10.1007/s13389-012-0028-0	discrete mathematics;theoretical computer science;algebraic operation;mathematics;algebraic extension;algorithm	Crypto	-39.21541282943106	81.55312578394893	111850
5c77ca4db2c2b463d1952115fee7e65c983392dc	a novel id-based verifiably encrypted signature without random oracle	fair exchange;generators;authorisation;digital signatures;identity based encryption cryptography protocols public key computational intelligence national security laboratories performance analysis mathematics resists;computational diffie hellman problem;artificial neural networks;standard model;computational modeling;signature scheme;public key;cryptography;random oracle;computational diffie hellman;security;fair exchange process;digital signatures authorisation cryptography;id based verifiably encrypted signature;fair exchange process id based verifiably encrypted signature computational diffie hellman problem	The verifiably encrypted signature schemes proposed by Asokan solved the fairness problem in the fair exchange process. In the work, we propose an ID-based strong unforgeability verifiably encrypted signature scheme without random oracles, and show that the security of the scheme is based on the difficulty of solving the computational Diffie-Hellman problem. Our scheme is obtained from a modification of Waters¿ recently proposed signature schemes. This is the first time that an ID-based verifyably encrypted signature schemes is proved in the standard model.	computational diffie–hellman assumption;computer data storage;diffie–hellman problem;digital signature;electronic trading;encryption;fairness measure;provable security;random oracle	Xiao-Long Ma;Wei Cui;Lize Gu;Yixian Yang;Zhengming Hu	2008	2008 International Conference on Computational Intelligence and Security	10.1109/CIS.2008.168	random oracle;standard model;merkle signature scheme;computer science;cryptography;information security;theoretical computer science;internet privacy;schnorr signature;computer security;artificial neural network	Crypto	-41.165261060363406	75.5833593890215	111911
408800c7dc42c81ed320eb1bb4d0e6d92efe9d59	md5 hash function in image based smart card security	smart card;hash function			Syed M. Rahman;Vincent Goh Boon Yew	2000			sha-2;secure hash algorithm;smart card application protocol data unit;secure hash standard;hash chain;openpgp card;cryptographic hash function;mdc-2	Crypto	-41.473597052163015	79.36873894142764	111965
a3943802eff61acc75a92a81deda712be63b84c3	approximate-deterministic public key encryption from hard learning problems		We introduce the notion of approximate-deterministic public key encryption (A-DPKE), which extends the notion of deterministic public key encryption (DPKE) by allowing the encryption algorithm to be “slightly” randomized. However, a ciphertext convergence property is required for A-DPKE such that the ciphertexts of a message are gathering in a small metric space, while ciphertexts of different messages can be distinguished easily. Thus, A-DPKE maintains the convenience of DPKE in fast search and de-duplication on encrypted data, and encompasses new constructions. We present two simple constructions of A-DPKE, respectively from the learning parity with noise and the learning with errors assumptions.	approximation algorithm;ciphertext;data deduplication;encryption;learning with errors;linear programming relaxation;modulus of continuity;parity learning;public-key cryptography;randomized algorithm	Yamin Liu;Xianhui Lu;Bao Li;Wenpan Jing;Fuyang Fang	2016		10.1007/978-3-319-49890-4_2	computer science;theoretical computer science;internet privacy;key distribution;computer security	Crypto	-37.89516744839329	76.77060667633425	112213
29c200733e3f501ecf074fada654835266f2398c	mix and match: secure function evaluation via ciphertexts	public key cryptography;protection information;protection secret;cryptographie cle publique;protocole transmission;secure function evaluation;securite informatique;communication complexity;complexite communication;computer security;protocolo transmision;proteccion informacion;informatique theorique;information protection;secrecy protection;computer theory;informatica teorica;transmission protocol	We introduce a novel approach to general secure multiparty computation that avoids the intensive use of verifiable secret sharing characterizing nearly all previous protocols in the literature. Instead, our scheme involves manipulation of ciphertexts for which the underlying private key is shared by participants in the computation. The benefits of this protocol include a high degree of conceptual and structural simplicity, low message complexity, and substantial flexibility with respect to input and output value formats. We refer to this new approach as mix	encryption;input/output;mix;parameter (computer programming);public-key cryptography;secure multi-party computation;secure two-party computation;verifiable secret sharing	Markus Jakobsson;Ari Juels	2000		10.1007/3-540-44448-3_13	simulation;telecommunications;computer science;artificial intelligence;operating system;communication complexity;database;distributed computing;public-key cryptography;computer security;information protection policy;algorithm	Crypto	-42.543145754156	78.2350092814645	112454
9d5db3be72fe313ea031a6f92af9b2865fa8e9bd	shared authentication token secure against replay and weak key attacks	reflection attack;one time password;replay attack;authentication;one time passwide;computer systems;tamper resistance;weak key attack;cryptography;cryptographie;systeme informatique	In this paper, an authentication scheme that uses a novel design of shared tamper resistant cryptographic token is originally proposed which can be very useful to enhance the security of most remote login systems. Conceptually, the proposed scheme is a weak key protected one-time password system.		Sung-Ming Yen;Kuo-Hong Liao	1997	Inf. Process. Lett.	10.1016/S0020-0190(97)00046-X	password policy;reflection attack;s/key;pre-play attack;challenge–response authentication;computer science;cryptography;authentication protocol;cryptographic nonce;authentication;internet privacy;one-time password;pre-shared key;world wide web;password;computer security;tamper resistance;replay attack	Security	-44.229553888933374	75.3988678406892	112877
b82cb0f7b7566d631c7cc6d6932fb2081a2f9bdf	erratum to: qubit-wise teleportation and its application in public-key secret communication		In the original publication [1] of this paper, Ref. [25] should be “Yang L. Quantum public-key cryptosystem based on classical NP-complete problem. arXiv: quant-ph/0310076, 2003” [2].	cryptosystem;np-completeness;public-key cryptography;quantum;qubit;yang	Chenmiao Wu;Lei Yang	2016	Science China Information Sciences	10.1007/s11432-016-0893-y	theoretical computer science;mathematics;quantum mechanics	Crypto	-38.96026603575744	80.66391917882216	113177
6906559bd650af6b3788fe91a4e75c1de9a68db1	an improved algorithm to solve the systems of univariate modular equations		In this paper, we propose an improved algorithm to solve the univariate modular equations with mutually co-prime moduli problem. This problem was first proposed in Hastad’s original RSA broadcast attack. At PKC 2008, May and Ritzenhofen improved Hastad’s result by using a slightly different transformation from polynomial systems to a single polynomial. In this work, we propose a new construction method to combine all the k equations into a single equation (f(x)equiv 0 mod prod _{i=1}^{k}N_i). Our improved algorithm possesses two advantages compared with the two previous ones. Compared with Hastad’s approach, our algorithm only needs fewer number of equations which suffice for a recovery of all common roots. Compared with May and Ritzenhofen’s, our method obtains the single equation f(x) with a smaller degree. The benefit is that this new algorithm will find the small solution (x_0) more efficiently when we invoke Coppersmith’s algorithm.	algorithm	Jingguo Bi;Mingqiang Wang;Wei Wei	2017		10.1007/978-3-319-93563-8_5	moduli;coppersmith;mod;algorithm;modular design;polynomial;broadcasting;univariate;computer science	Logic	-39.11597793497611	78.98174786131415	113213
e3ab6a82305175c6dcda595939f8fe82fda9877c	efficient algorithms for secure outsourcing of bilinear pairings	provable security;outsourcing;untrusted program model;outsource secure algorithms;bilinear pairings;bilinear pairing;cloud computing	The computation of bilinear pairings has been considered the most expensive operation in pairing-based cryptographic protocols. In this paper, we first propose an efficient and secure outsourcing algorithm for bilinear pairings in the two untrusted program model. Compared with the state-of-the-art algorithm, a distinguishing Preprint submitted to Theoretical Computer Science 18 April 2014 property of our proposed algorithm is that the (resource-constrained) outsourcer is not required to perform any expensive operations, such as point multiplications or exponentiations. Furthermore, we utilize this algorithm as a subroutine to achieve outsource-secure identity-based encryptions and signatures.	algorithm;bilinear filtering;computation;cryptographic protocol;outsourcing;signature;subroutine;theoretical computer science	Xiaofeng Chen;Willy Susilo;Jin Li;Duncan S. Wong;Jianfeng Ma;Shaohua Tang;Qiang Tang	2015	Theor. Comput. Sci.	10.1016/j.tcs.2014.09.038	cloud computing;computer science;provable security;distributed computing;internet privacy;computer security;outsourcing	Security	-41.02517498407485	74.5948002969311	113633
3fcbadfaa2e0da96cdc19db7bc7597a8a0e99b81	parallel keyed hash function construction based on chaotic neural network	satisfiability;parallel;parallel computer;chaotic neural network;hash function;neural network	Recently, various hash functions based on chaos or neural networks were proposed. Nevertheless, none of them works efficiently in parallel computing environment. In this paper, an algorithm for parallel keyed hash function construction based on chaotic neural network is proposed. The mechanism of changeable-parameter and self-synchronization establishes a close relation between the hash value bit message blocks at different positions. The proposed algorithm can satisfy the performance requirements of hash function. These properties make it a promising choice for hashing on parallel	algorithm;artificial neural network;chaos theory;cryptographic hash function;message authentication code;parallel computing;requirement	Di Xiao;Xiaofeng Liao;Yong Wang	2009	Neurocomputing	10.1016/j.neucom.2008.12.031	hash table;double hashing;hash function;perfect hash function;dynamic perfect hashing;primary clustering;sha-2;computer science;theoretical computer science;machine learning;universal hashing;hash chain;parallel;k-independent hashing;distributed computing;rolling hash;artificial neural network;algorithm;cryptographic hash function;fowler–noll–vo hash function;mdc-2;swifft;hash tree;hash filter;satisfiability	ML	-41.54066502203108	83.09479432277185	113651
30eec0c0cd07a983b6535d8092ea1e2fc05c284e	methods of group authentication for low-resource vehicle and flying self-organizing networks		It has been suggested to provide group authentication in self-organizing networks using group signature. Due to the hardware peculiarities of unmanned aerial vehicles, the EDR-BBS scheme on elliptic curves has been selected as the group-signature scheme for FANET. Algebraic structures have been represented by elliptic curves over extended fields of special processor-oriented characteristics.	aerial photography;authentication;bluetooth;digital signature;group signature;organizing (structure);self-organization;unmanned aerial vehicle	Elena B. Aleksandrova	2017	Automatic Control and Computer Sciences	10.3103/S014641161708003X	reduced instruction set computing;group signature;theoretical computer science;algebraic structure;elliptic curve;vehicular ad hoc network;self-organizing network;computer science;authentication	Crypto	-46.91889804556662	77.00703683932058	113708
8cce24e5bccdc7a0185986acd73babbe2d9e0831	comparative power analysis of modular exponentiation algorithms	public key cryptography;software;waveform matching;m ary method;sliding window method;waveform matching technique;power analysis;collision generation methods;public key cryptosystems;clocks;double add algorithm;rsa;modular exponentiation algorithms;public key cryptosystem;fpga;data mining;clock jitter comparative power analysis modular exponentiation algorithms chosen message power analysis attacks public key cryptosystems binary method m ary method sliding window method montgomery powering ladder double add algorithm fpga powerpc processor collision generation methods waveform matching technique;chosen message power analysis attacks;left to right;general methods;estimation;montgomery powering ladder;side channel attacks;estimation computational efficiency data mining software algorithms software clocks cathode ray tubes;clock jitter;software algorithms;public key cryptography field programmable gate arrays jitter;modular exponentiation;power analysis attacks;waveform matching side channel attacks power analysis attacks rsa modular exponentiation;field programmable gate arrays;jitter;comparative power analysis;computational efficiency;powerpc processor;binary method;cathode ray tubes;sliding window;software implementation	This paper proposes new chosen-message power-analysis attacks for public-key cryptosystems based on modular exponentiation, where specific input pairs are used to generate collisions between squaring operations at different locations in the two power traces. Unlike previous attacks of this kind, the new attack can be applied to all standard implementations of the exponentiation process, namely binary (left-to-right and right-to-left), m-ary, and sliding window methods. The proposed attack can also circumvent typical countermeasures, such as the Montgomery powering ladder and the double-add algorithm. The effectiveness of the attack is demonstrated in experiments with hardware and software implementations of RSA on an FPGA and a PowerPC processor, respectively. In addition to the new collision generation methods, a highly accurate waveform matching technique is introduced for detecting the collisions even when the recorded signals are noisy and there is a certain amount of clock jitter.	algorithm;cathode ray tube;collision detection;countermeasure (computer);cryptosystem;distortion;elliptic curve cryptography;experiment;exponentiation by squaring;field-programmable gate array;matrix multiplication;modular exponentiation;montgomery modular multiplication;multiplication algorithm;numerical integration;powerpc;public-key cryptography;randomized algorithm;right-to-left;sensor;signal processing;time complexity;tracing (software);waveform	Naofumi Homma;Atsushi Miyamoto;Takafumi Aoki;Akashi Satoh;Adi Shamir	2010	IEEE Transactions on Computers	10.1109/TC.2009.176	embedded system;parallel computing;computer science;theoretical computer science;operating system;modular exponentiation;field-programmable gate array;statistics	Security	-39.68123178186366	82.0934992085591	113781
89bc830b2f991db4c9b87efb654b2e76bcb06f29	a simple balanced password-authenticated key agreement protocol	public key cryptography;peer to peer network;cryptographic protocols;dictionary attack;dictionary attacks password authentication key agreement peer to peer communication;client server systems;protocols public key dictionaries authentication dh hemts;authenticated key agreement;client server;dictionary attacks;security requirements;peer to peer communication;key agreement;password authentication;peer to peer computing;public key cryptography client server systems cryptographic protocols peer to peer computing;peer to peer;dictionary attacks balanced password authenticated key agreement protocol client server communication settings peer to peer networks public key infrastructures security requirements;public key infrastructure	Password authentication protocols have been broadly deployed in client/server communication settings for its convenient usage and low costs of deployment. Nowadays peer-to-peer networks become increasingly popular, where the role of principals is symmetric (balanced), i.e. each principal acts not only as a client but also as a server. In this setting a robust and simple password authentication protocol is highly desired, since PKIs (Public Key Infrastructures) are not always available for authentication. In this paper, we present a simple password-authenticated key agreement protocol for the use in peer-to-peer communication paradigms. It fulfills the security requirements on password authentication protocols, and is resilient to passive and active attacks as well as dictionary attacks. The proposed scheme is more efficient than the well established protocols due to its simple design concept.	client–server model;dictionary attack;key-agreement protocol;password authentication protocol;password-authenticated key agreement;peer-to-peer;requirement;server (computing);software deployment;whole earth 'lectronic link	Fuwen Liu;Hartmut König	2011	2011IEEE 10th International Conference on Trust, Security and Privacy in Computing and Communications	10.1109/TrustCom.2011.52	zero-knowledge password proof;password policy;s/key;challenge–response authentication;computer science;authentication protocol;internet privacy;one-time password;computer security;challenge-handshake authentication protocol;computer network	Security	-48.24835427536028	76.16821862781873	113793
1393e1f176a1ece9ee592bed4ae6abbc59523dcc	information theoretic security	wire-tap channel;provable security;broadcast channel;network security;basic channel;wire-tap formalism;information theoretic security;information theory;security issue;wireless networking security problem;source information;feedback wire-tap channel;basic wire-tap channel model;cross-layer design;secure network coding;passive attack;corresponding coding scheme;information theoretic approach;secure source coding;communication network	We present the notion of continuous non-malleable codes along with an instantiation and we show how to use them to securely compute any keyed cryptographic primitive on a computational architecture with a single constant size untamperable CPU and a tamperable and leaky memory in which both the secret key and the program of the cryptographic primitive is located.	central processing unit;code;cryptographic primitive;cryptography;information-theoretic security;key (cryptography);non-malleable codes;universal instantiation	Anja Lehmann;Stefan Wolf	2015		10.1007/978-3-319-17470-9	computer security model;cloud computing security;countermeasure;security through obscurity;security information and event management;vulnerability;covert channel;asset;computer science;security service;distributed computing;internet privacy;security testing;computational hardness assumption;computer security	Crypto	-44.78246588240585	80.64352648392803	113860
20a6be5cfb29390059cc8a772f4fb9c775ef7242	advances in cryptology – asiacrypt 2017		In recent years, there has been a substantial amount of research on quantum computers – machines that exploit quantum mechanical phenomena to solve mathematical problems that are difficult or intractable for conventional computers. If large-scale quantum computers are ever built, they will compromise the security of many commonly used cryptographic algorithms. In particular, quantum computers would completely break many public-key cryptosystems, including those standardized by NIST and other standards organizations. Due to this concern, many researchers have begun to investigate postquantum cryptography (also called quantum-resistant cryptography). The goal of this research is to develop cryptographic algorithms that would be secure against both quantum and classical computers, and can interoperate with existing communications protocols and networks. A significant effort will be required to develop, standardize, and deploy new post-quantum algorithms. In addition, this transition needs to take place well before any large-scale quantum computers are built, so that any information that is later compromised by quantum cryptanalysis is no longer sensitive when that compromise occurs. NIST has taken several steps in response to this potential threat. In 2015, NIST held a public workshop and later published NISTIR 8105, Report on Post-Quantum Cryptography, which shares NIST’s understanding of the status of quantum computing and post-quantum cryptography. NIST also decided to develop additional public-key cryptographic algorithms through a public standardization process, similar to the development processes for the hash function SHA-3 and the Advanced Encryption Standard (AES). To begin the process, NIST issued a detailed set of minimum acceptability requirements, submission requirements, and evaluation criteria for candidate algorithms, available at http:// www.nist.gov/pqcrypto. The deadline for algorithms to be submitted was November 30, 2017. In this talk, I will share the rationale on the major decisions NIST has made, such as excluding hybrid and (stateful) hash-based signature schemes. I will also talk about some open research questions and their potential impact on the standardization effort, in addition to some of the practical issues that arose while creating the API. Finally, I will give some preliminary information about the submitted algorithms, and discuss what we’ve learned during the first part of the standardization process. Combinatorics in Information-Theoretic Cryptography	application programming interface;asiacrypt;communications protocol;computer;cryptanalysis;cryptosystem;design rationale;encryption;hash function;information-theoretic security;interoperability;open research;post-quantum cryptography;public-key cryptography;quantum algorithm;quantum computing;quantum cryptography;quantum mechanics;requirement;sha-3;state (computer science);threat (computer)	Tsuyoshi Takagi;Thomas	2017		10.1007/978-3-319-70694-8	computational biology;cryptography;computer science	Crypto	-39.90312386473485	78.0887926724217	114296
1baf46575c43a5078fa6af660d4f525d7c708db2	provably secure threshold paillier encryption based on hyperplane geometry		In threshold encryption, the secret key is shared among a set of decryption parties, so that only a quorum of these parties can decrypt a given ciphertext. It is a useful building block in cryptology to distribute the trust of the secret key as well as increase availability. In particular, threshold Paillier encryption has been widely used in various security protocols, such as e-auction, e-voting and e-lottery. In this paper, we present the idea of designing provably secure threshold Paillier encryption using hyperplane geometry. Compared with the existing schemes that are based on polynomial interpolation, our work not only renovates the threshold Paillier cryptosystem using a different mathematical structure, but also enjoys some additional benefits: 1 our proposed method avoids the technical obstacle of computing inverses in the group whose order is unknown; 2 it gains computational advantages over Shoup's trick and it can be used as a general building block to design secure and efficient threshold cryptosystems based on factoring.	encryption;provable security	Zhe Xia;Xiaoyun Yang;Min Xiao;Debiao He	2016		10.1007/978-3-319-40367-0_5	paillier cryptosystem;discrete mathematics;theoretical computer science;threshold cryptosystem;mathematics;computer security;encryption;probabilistic encryption;attribute-based encryption	Crypto	-40.13057371617049	77.11968988017554	114346
0f5a2b0bf0dc278d9c68baa0507bfeb0e44e965b	efficient, secure, private distance bounding without key updates	cosic;distance bounding;cryptographic protocol;rfid;privacy	We propose a new distance bounding protocol, which builds upon the private RFID authentication protocol by Peeters and Hermans [25]. In contrast to most distance-bounding protocols in literature, our construction is based on public-key cryptography. Public-key cryptography (specifically Elliptic Curve Cryptography) can, contrary to popular belief, be realized on resource constrained devices such as RFID tags. Our protocol is wide-forward-insider private, achieves distance-fraud resistance and near-optimal mafia-fraud resistance. Furthermore, it provides strong impersonation security even when the number of time-critical rounds supported by the tag is very small. The computational effort for the protocol is only four scalar-EC point multiplications. Hence the required circuit area is minimal because only an ECC coprocessor is needed: no additional cryptographic primitives need to be implemented.	authentication protocol;computation;coprocessor;elliptic curve cryptography;public-key cryptography;radio-frequency identification;window of opportunity	Jens Hermans;Roel Peeters;Cristina Onete	2013		10.1145/2462096.2462129	radio-frequency identification;computer science;theoretical computer science;authentication protocol;cryptographic protocol;distributed computing;privacy;computer security;computer network	Security	-40.19406220002597	78.00976068294693	114354
2ff8f977ad109b34be63fe7c0bac24eacde8ac30	quam bene non quantum: bias in a family of quantum random number generators		Random number generation is critical to many security protocols, a basic building block on which it rests the robustness of many security solutions. Quantum physics, on the other hand, offers a very attractive approach to True Random Number Generation, based on the inherent randomness of some physical phenomena. Naturally, there are a number of quantum random number generators in the market. In this work, we present the first analysis of a popular commercial family called Quantis, designed and manufactured by ID Quantique. We subject their output to three batteries of statistical tests, for evaluating its performance. Dieharder and NIST STS 2.1.2 are included in many certification schemes, whilst ENT provides a free, simple and powerful means of expanding on the previous tests. The Quantis devices under examination have achieved METAS and other independent certifications and indeed the results over the Dieharder and NIST batteries confirm that the certifications awarded are based on an acceptable performance on both sets of tests. However, ENT finds strong evidence of significant biases in the Quantis devices. These biases are analyzed to identify their traits and attempt to isolate their root cause. We end with a discussion on the need to expand testing strategies to incorporate lesser-known tests that regularly detect problems that the commonly accepted batteries do not.	c-quam;mike lesser;nist rbac model;quantum indeterminacy;quantum mechanics;random number generation;randomness;while	Darren Hurley-Smith;Julio Hernandez-Castro	2017	IACR Cryptology ePrint Archive		combinatorics;random number generation;quantum;mathematics	Crypto	-33.836566561204855	77.98507397403239	114752
05eba145ffec520971e12aa2ff29d897f2b7959d	relations among notions of security for public-key encryption schemes	securite;cle publique;public key encryption;public key;criptografia;random oracle model;cryptography;safety;llave publica;cryptographie;seguridad;chosen ciphertext attack	1 I n t r o d u c t i o n In this paper we compare the relative strengths of various notions of security for public key encryption. We want to understand which definitions of security imply which others. We start by sorting out some of the notions we will consider. 1.1 N o t i o n s o f E n c r y p t i o n S c h e m e S e c u r i t y A convenient way to organize definitions of secure encryption is by considering separately the various possible goals and the various possible attack models, and then obtain each definition as a pairing of a particular goal and a particular at tack model. This viewpoint was suggested to us by Moni Naor [22]. We consider two different goals: indistinguishability of encryptions, due to Goldwasser and Micali [17], and non-malleability, due to Dolev, Dwork and Naor [11]. Indistinguishability (IND) formalizes an adversary's inability to learn any information about the plaintext x underlying a challenge ciphertext y, capturing a strong notion of privacy. Non-malleability (NM) formalizes an adversary's inability, given a challenge ciphertext y, to output a different ciphertext yr	adversary (cryptography);ciphertext;command & conquer:yuri's revenge;cynthia dwork;encryption;non-repudiation;plaintext;public-key cryptography;sorting	Mihir Bellare;Anand Desai;David Pointcheval;Phillip Rogaway	1998	IACR Cryptology ePrint Archive	10.1007/BFb0055718	semantic security;plaintext-aware encryption;computer science;theoretical computer science;ciphertext indistinguishability;ciphertext-only attack;optimal asymmetric encryption padding;mathematics;internet privacy;malleability;public-key cryptography;deterministic encryption;computer security;encryption;probabilistic encryption;algorithm;attribute-based encryption	Crypto	-38.644593716167144	74.63883215885853	114768
666c75ae8cbde87fd1085f6043eeb93547d3692e	an authentication scheme for ieee 802.11s mesh networks relying on sakai-kasahara id-based cryptographic algorithms	public key cryptography;computer network security;authentication ieee 802 11 standards public key generators encryption;wireless mesh network;wireless mesh networks computer network security message authentication public key cryptography wireless lan;private key generator;cryptographic algorithm;public key;key escrow attack ieee 802 11 mesh network sakai kasahara id based cryptographic algorithm authentication scheme wireless mesh network 802 1x authentication methods preshared key authentication public key infrastructure certification authority certificate management policy private key generator id based signature encryption schemes;wireless mesh networks;mesh network;wireless lan;message authentication;id based cryptography;public key infrastructure;management policy	Nowadays authentication in Wireless Mesh Networks (WMN) refers to the 802.1X authentication methods or a Preshared key authentication, and makes use of certifcates or shared secrets. In wireless environments, the management of certifcates is a cumbersome task as certifcates require deploying a Public Key Infrastructure (PKI) and Certifcation Authorities (CA). They also require defning a certifcate management policy to control the generation, transmission and revocation of certifcates. During the last decade, ID-Based Cryptography (IBC) appeared as a good alternative to PKI. IBC proposes to derive the public key from the node's identity directly thanks to the use of a Private Key Generator (PKG). In this article, we present an authentication method relying on an ID-Based signature and encryption schemes that use the Sakai-Kasahara key construction. The resulted authentication scheme is suitable to IEEE 802.11s mesh networks and resistant to the key escrow attack.	algorithm;certificate authority;encryption;fastest;id-based cryptography;information-based complexity;key authentication;key escrow;mesh networking;public key infrastructure;public-key cryptography;sakai project;shared secret;wireless mesh network	Aymen Boudguiga;Maryline Laurent-Maknavicius	2012	Third International Conference on Communications and Networking	10.1109/ComNet.2012.6217728	ieee 802.11s;data authentication algorithm;key;challenge–response authentication;computer science;authentication protocol;network security;lightweight extensible authentication protocol;internet privacy;public-key cryptography;computer security;computer network	Mobile	-47.73523219123465	75.41052982002212	114782
abeee92f8a3718f56f113505c0c8e5a2eb5eef8a	"""comments on """"dynamic key management schemes for access control in a hierarchy"""""""			access control;key management	Narn-Yih Lee;Tzonelih Hwang	1999	Computer Communications			Security	-45.3288421289008	76.63615936551722	114818
be54e980182b24c5a2e68c84c749d147a53eafc7	symmetric tardos fingerprinting codes for arbitrary alphabet sizes	collusion resistance;94b60;traitor tracing;copyright protection;central limit theorem;watermark;fingerprint	"""Fingerprinting provides a means of tracing unauthorized redistribution of digital data by individually marking each authorized copy with a personalized serial number. In order to prevent a group of users from collectively escaping identi cation, collusion-secure ngerprinting codes have been proposed. In this paper, we introduce a new construction of a collusion-secure ngerprinting code which is similar to a recent construction by Tardos but achieves shorter code lengths and allows for codes over arbitrary alphabets. We present results for `symmetric' coalition strategies. For binary alphabets and a false accusation probability """"1, a code length of m 2 c 2 0 ln 1 """"1 is provably suÆcient, for large c0, to withstand collusion attacks of up to c0 colluders. This improves Tardos' construction by a factor of 10. Furthermore, invoking the Central Limit Theorem in the case of suÆciently large c0, we show that even a code length ofm 1 2 2 c 2 0 ln 1 """"1 is adequate. Assuming the restricted digit model, the code size can be further reduced by moving from a binary alphabet to a q-ary alphabet. Numerical results show that a reduction of 35% is achievable for q = 3 and 80% for q = 10."""	authorization;code;decade (log scale);digital data;fingerprint (computing);item unique identification;personalization	Boris Skoric;Stefan Katzenbeisser;Mehmet Utku Celik	2007	Des. Codes Cryptography	10.1007/s10623-007-9142-x	arithmetic;fingerprint;combinatorics;central limit theorem;theoretical computer science;mathematics;watermark;algorithm;statistics	Crypto	-33.87825445656106	78.76154131740313	114880
e69fb1225d1965ee631d6159a2cafe295e329e93	improving divide and conquer attacks against cryptosystems by better error detection / correction strategies	error detection and correction;methode diviser pour regner;detection erreur;deteccion error;generalization error;correction erreur;cryptanalyse;metodo dividir para vencer;cle publique;cryptanalysis;criptoanalisis;chinese remainder theorem;public key;criptografia;cryptography;error correction;divide and conquer method;llave publica;side channel attacks;cryptographie;correccion error;error detection;divide and conquer;timing attack	Divide and conquer attacks try to recover small portions of cryptographic keys one by one. Usually, a wrong guess makes subsequent ones useless. Hence possible errors should be detected and corrected as soon as possible. In this paper we introduce a new (generic) error detection and correction strategy. Its efficiency is demonstrated at various examples, namely at a power attack, two timing attacks against RSA implementations with and without Chinese Remainder Theorem, and a timing attack against the future AES (Rijndael). As the design of efficient countermeasures requires a good understanding of an attack's actual power, the possible improvement induced by sophisticated error detection and correction should not be neglected. Although divide and conquer attacks are typical for side-channel attacks, we would like to stress that they are not restricted to that field, as will be illustrated by Siegenthaler's attack.	cryptosystem;error detection and correction	Werner Schindler;François Koeune;Jean-Jacques Quisquater	2001		10.1007/3-540-45325-3_22	error detection and correction;pre-play attack;computer science;theoretical computer science;correlation attack;mathematics;computer security;algorithm;statistics	NLP	-40.28251937946823	81.73017580336912	115033
b1b4379d5c17634aee1ad9e004388b7143e6fe80	self-certified ring signatures	security model;selected works;undeniability;limited transformation;security proof;proxy signature;bepress;era2015;ring signature	We present a new notion, Self-certified Ring Signature (SCRS), to provide an alternative solution to the certificate management problem in ring signatures and eliminate private key escrow problem in identity based ring signatures. Our scheme captures all features of ring signatures and exhibits the advantages such as low storage, communication and computation cost. The main contribution of this paper is a precise definition of self-certified ring signatures along with a concrete construction. We also provide a security model of SCRS and a security proof of our scheme.	computation;key escrow;provable security;public-key cryptography;ring signature	Nan Li;Yi Mu;Willy Susilo;Fuchun Guo	2011		10.1145/1966913.1966966	ring signature;computer security model;computer science;internet privacy;world wide web;computer security	Crypto	-41.772599684374896	75.14426790380546	115065
c4d6ef6b1d933c53475e69f93a3ebab2d0ffb145	revisiting the security proof of quad stream cipher: some corrections and tighter bounds		In EUROCRYPT 2006, Berbain et al. proposed a provably secure stream cipher named QUAD based on the hardness of solving multivariate quadratic equations. The authors also mentioned that whether the security bound can be made tighter or not is an open problem. Through the last decade, there have been some works on the analysis of QUAD as well as design extensions of QUAD, but to our knowledge no work has addressed the existence of tighter bounds. In this paper, we revisit the proof technique by the authors and correct some bugs in their proof. Further, we derive tighter security bounds using two approaches.	stream cipher	Goutam Paul;Abhiroop Sanyal	2016		10.1007/978-3-319-54705-3_7	computer science;theoretical computer science;distributed computing;computer security	Crypto	-38.067330993770824	79.47015623704488	115212
f922f78d7a87a74c7d1ba9111518034c178c5603	a study on information reconciliation problem in quantum key distribution	protocols;error correction technique information reconciliation problem quantum key distribution qkd systems ir protocols turkey error detection technique;protocols parity check codes quantum cryptography quantum computing;parity check codes;quantum cryptography cryptographic protocols;quantum cryptography;quantum computing;error detection and correction quantum key distribution secret key reconciliation information reconciliation	This work mentions the problem known as information reconciliation (IR) in quantum key distribution (QKD). In this context, we review a few recent QKD systems in the literature and obtain their IR requirements. Later, we also present the latest results on IR protocols. We hope that this topic will be a new hot research area of our Turkish researchers working on error detection and correction techniques.	error detection and correction;quantum key distribution;requirement	Mustafa Toyran	2016	2016 24th Signal Processing and Communication Application Conference (SIU)	10.1109/SIU.2016.7495701	quantum information;quantum key distribution;theoretical computer science;quantum network;mathematics;distributed computing;computer security;quantum cryptography;bb84	Crypto	-43.47120460251866	82.68857154451432	115239
a9f6cf353d4e1fa0a33e5e571c79f0160e3889a8	public-key quantum digital signature scheme with one-time pad private-key	quantum public-key cryptosystem;quantum digital signature;identity-based encryption;one-time pad;quantum one-way function;information-theoretic security	A quantum digital signature scheme is firstly proposed based on public-key quantum cryptosystem. In the scheme, the verification public-key is derived from the signer’s identity information (such as e-mail) on the foundation of identity-based encryption, and the signature private-key is generated by one-time pad (OTP) protocol. The public-key and private-key pair belongs to classical bits, but the signature cipher belongs to quantum qubits. After the signer announces the public-key and generates the final quantum signature, each verifier can verify publicly whether the signature is valid or not with the public-key and quantum digital digest. Analysis results show that the proposed scheme satisfies non-repudiation and unforgeability. Information-theoretic security of the scheme is ensured by quantum indistinguishability mechanics and OTP protocol. Based on the public-key cryptosystem, the proposed scheme is easier to be realized compared with other quantum signature schemes under current technical conditions.	one-time pad;quantum digital signature;symmetric-key algorithm	Feng-Lin Chen;Wan-Fang Liu;Sugen Chen;Zhi-Hua Wang	2018	Quantum Information Processing	10.1007/s11128-017-1778-5	theoretical computer science;qubit;quantum mechanics;information-theoretic security;physics;cipher;encryption;public-key cryptography;cryptosystem;one-time pad;quantum digital signature	Crypto	-40.84777747546664	75.59500740909063	115281
47fa3e8ed5e5a3cfa8060b4e69b9c9ac05c4f3e1	a kind of ecc-homomorphism key agreement in grid	forward secrecy;grid computing;cryptographic protocols	Making use of the Sander and Tschudin defined additive-multiplicative homomorphism in the integer ring and ECC, a new protocol, called the ECC-homomorphism key agreement, is presented. It can create the contributory, forward secrecy session key in grid. The security of the protocol is proved by BAN logic.	burrows–abadi–needham logic;forward secrecy;key-agreement protocol;session key;utility functions on indivisible goods	Junhong Zhang;Xinmeng Chen;Ping Zhu	2007	Third International Conference on Semantics, Knowledge and Grid (SKG 2007)	10.1109/SKG.2007.22	cryptographic primitive;forward secrecy;key exchange;computer science;theoretical computer science;key-agreement protocol;key management;cryptographic protocol;distributed computing;key distribution;computer security;grid computing	EDA	-41.71749993559372	76.66215600679655	115373
39dbec1a10a1da4b50ff107896f7a23e23359609	infinite alphabet passwords: a unified model for a class of authentication systems	software;authentication servers force semantics dictionaries software;security analysis;formal model;authentication;semantics;cryptographic protocol;force;conference papers meetings and proceedings;unified model;servers;password;dictionaries;formal model user authentication password infinite alphabet;infinite alphabet;system architecture;user authentication	In the paper we propose a formal model for class of authentication systems termed, “Infinite Alphabet Password Systems” (IAPs). We define such systems as those that use a character set for the construction of the authentication token that is theoretically infinite, only bound by practical implementation restrictions. We find that the IAP architecture can feasibly be adapted for use in many real world situations, and may be implemented using a number of system architectures and cryptographic protocols. A security analysis is conducted on an implementation of the model that utilizes images for its underlying alphabet. As a result of the analysis we find that IAPs can offer security benefits over traditional alphanumeric password schemes. In particular some of the significant problems concerning phishing, pharming, replay, dictionary and offline brute force attacks are mitigated.	authentication;brute-force search;character encoding;cryptographic protocol;dictionary;dictionary attack;formal language;keystroke logging;microtransaction;online and offline;password;pharming;phishing;replay attack;security token;social engineering (security);unified model	Marcia Gibson;Marc Conrad;Carsten Maple	2010	2010 International Conference on Security and Cryptography (SECRYPT)		password policy;computer science;theoretical computer science;unified model;authentication;cryptographic protocol;semantics;security analysis;world wide web;password;computer security;force;server	Security	-41.453556219722216	77.07538829646117	115704
28567e0246acca8e1789154be94972e820bbc727	an integer commitment scheme based on groups with hidden order	abelian group;zero knowledge;commitment scheme;class group	We present a commitment scheme allowing commitment to arbitrary size integers, based on any Abelian group with certain properties, most importantly that it is hard for the committer to compute its order. Potential examples include RSA and class groups. We also give efficient zero-knowledge protocols for proving knowledge of the contents of a commitment and for verifying multiplicative relations over the integers on committed values. This means that our scheme can support, for instance, the efficent interval proofs of Boudot[1]. The scheme can be seen as a modification and a generalization of an earlier scheme of Fujisaki and Okamoto [5], and in particular our results show that we can use a much larger class of RSA moduli than the safe prime products proposed in [5]. Also, we correct some mistakes in the proofs of [5] and give what appears to be the first multiplication protocol for a Fujisaki/Okamoto-like scheme with a complete proof of soundness.	commitment scheme;committer;interval arithmetic;rsa (cryptosystem);safe prime;verification and validation;zero-knowledge proof	Ivan Damgård;Eiichiro Fujisaki	2001	IACR Cryptology ePrint Archive		combinatorics;discrete mathematics;commitment scheme;computer science;multiplicative group;mathematics;abelian group;zero-knowledge proof;algebra	Crypto	-37.9224578429045	75.94942022051829	115871
3c2d6bd3b704baf4d85821a41c53683b43af66d3	how to strengthen the security of rsa-oaep	public key cryptography;oaep transform;provable security;cryptographie cle publique;generators;trapdoor permutation;encryption;via unica;backdoor;implementation;public key encryption;pregunta documental;oaep encryption;multiple ciphertexts;securite donnee;cryptage rsa;voie unique;rsa ciphering;telecommunication security public key cryptography;public key;cifrado rsa;random oracle model;encryption concrete generators transforms public key;transforms;telecommunication security;cryptography standards;hybrid encryption;query;rsa oaep cryptography standards encryption provable security;oaep transform public key encryption rsa oaep trapdoor permutation random oracle model security multiple ciphertexts multiquery setting oaep encryption;multiquery setting;one way;rsa oaep;implementacion;security;security of data;oracle;requete;concrete;porte derobee	OAEP is one of the few standardized and widely deployed public-key encryption schemes. It was designed by Bellare and Rogaway as a scheme based on a trapdoor permutation such as RSA. RSA-OAEP is standardized in RSA's PKCS #1 v2.1 and is part of several standards. OAEP was shown to be IND-CCA secure assuming the underlying trapdoor permutation is partial one-way, and RSA-OAEP was proven to be IND-CCA under the standard RSA assumption, both in the random oracle model. However, the latter reduction is not tight, meaning that the guaranteed level of security is not very high for a practical parameter choice. We observe that the situation is even worse because both analyses were done in the single-query setting, i.e., where an adversary gets a single challenge ciphertext. This does not take into account the fact that in reality an adversary can observe multiple ciphertexts of related messages. The results about the multiquery setting imply that the guaranteed concrete security can degrade by a factor of q , which is the number of challenge ciphertexts an adversary can get. We propose a very simple modification of the OAEP encryption, which asks that the trapdoor permutation instance is only applied to a part of the OAEP transform. We show that IND-CCA security of this scheme is tightly related to the hardness of one-wayness of the trapdoor permutation in the random oracle model. This implies tight security for RSA-OAEP under the RSA assumption. We also show that security does not degrade as the number of ciphertexts an adversary can see increases. Moreover, OAEP can be used to encrypt long messages without using hybrid encryption. We believe that this modification is easy to implement, and the benefits it provides deserves the attention of standard bodies.	adversary (cryptography);ciphertext;concrete security;encryption;hybrid cryptosystem;mihir bellare;one-way function;pkcs;public-key cryptography;random oracle;trapdoor function	Alexandra Boldyreva;Hideki Imai;Kazukuni Kobara	2010	IEEE Transactions on Information Theory	10.1109/TIT.2010.2070330	computer science;information security;theoretical computer science;optimal asymmetric encryption padding;mathematics;internet privacy;public-key cryptography;computer security	Crypto	-38.81496059452517	77.52198778954016	116196
53d37d009eaf53948e648f9104eaa07b40ac84ee	low latency anonymous communication: how long are users willing to wait?	anonymity;systeme aide decision;securite informatique;sistema ayuda decision;anonymous communication;anonymat;computer security;decision support system;low latency;seguridad informatica;retard;retraso;anonimato	One of the heavily discussed design questions for low latency anonymity systems is: “How much additional anonymity will the system provide by adding a certain amount of delay?” But current research on this topic ignores an important aspect of this question – the influence of the delay on the number of users and by this means on the anonymity provided. This paper shows some first experimental results in this area. Hopefully, it supports better design decisions for low latency anonymity systems.		Stefan Köpsell	2006		10.1007/11766155_16	decision support system;anonymity;telecommunications;computer science;world wide web;computer security;low latency	HCI	-45.05761984043619	79.45739114320632	116523
da6afb7669d81055dcbc1b20ad7811fbd1631208	maintaining authenticated communication in the presence of break-ins	protection information;distributed system;distributed signatures;description systeme;system description;systeme reparti;protocole transmission;modele mathematique;concepcion sistema;securite;generation code;authentication;generacion codigo;code generation;cle publique;transmission message;modelo matematico;recovery;message transmission;authentification;protocolo transmision;sistema repartido;autenticacion;proactive protocols;public key;proteccion informacion;criptografia;system design;cryptography;information protection;key words authentication protocols;safety;signature;llave publica;mathematical model;cryptographie;descripcion sistema;signing;proactive signatures;seguridad;firma;conception systeme;authentication protocol;break ins;transmision mensaje;transmission protocol	We study the problem of maintaining authenticated communication over untrusted communication channels, in a scenario where the communicating parties may be occasionally and repeatedly broken into for transient periods of time. Once a party is broken into, its cryptographic keys are exposed and perhaps modified. Yet, when aided by other parties it should be able to regain its ability to communicate in an authenticated way. We present a mathematical model for this highly adversarial setting, exhibiting salient properties and parameters, and then describe a practically appealing protocol for solving this problem. A key element in our solution is devising a proactive distributed signature (PDS) scheme in our model. The PDS schemes known in the literature are designed for a model where authenticated communication is available. We therefore show how these schemes can be modified to work in our model, where no such primitives are available a priori. In the process of devising these schemes, we also present a new definition of PDS schemes (and of distributed signature schemes in general). This definition may be of independent interest.	adversary (cryptography);authentication;key (cryptography);mathematical model	Ran Canetti;Shai Halevi;Amir Herzberg	1998	Journal of Cryptology	10.1007/s001459910004	telecommunications;computer science;authentication;computer security	Crypto	-44.090707420395326	78.42003262687491	116631
2707889bf44ee3da282f6bd63df60f664712eef1	a taxonomy of cryptographic techniques for securing electronic identity documents		There is a wide range of cryptographic techniques that may serve to prevent attacks on electronic identity documents (e-IDs). Many e-ID systems – including the ICAO ePass and virtually all national electronic identity cards – make intensive use of these methods. The first purpose of this work is to identify all cryptographic techniques that make an electronic identity document secure. As a second step, these techniques are grouped into several distinct classes. And third, they are evaluated according to their application areas and according to their advantages and disadvantages. In the fourth part of the paper, the ICAO ePass and the German electronic identity card (ePA) are examined with a view on the cryptographic techniques they use.	cryptography;evolutionary taxonomy	Klaus Schmeh	2009		10.1007/978-3-8348-9363-5_35	theoretical computer science;data mining;algorithm	Crypto	-40.80225303755432	78.20132915619374	116910
2d123397dacd79f468c9638c68cb46c598192686	id-based signatures from pairings on elliptic curves	cryptography;id-based signatures;bilinear pairings;elliptic curves;encryption scheme;generalised elgamal signature scheme;identity-based signature scheme;security	An efficient identity-based signature scheme is presented which makes use of bilinear pairings on elliptic curves. This scheme is similar to the generalised ElGamal signature scheme. The security of the scheme is considered		Kenneth G. Paterson	2002	IACR Cryptology ePrint Archive		ring signature;merkle signature scheme;elliptic curve digital signature algorithm;information security;elliptic curve;kcdsa;elgamal encryption;schnorr signature;elgamal signature scheme	Crypto	-41.405044010760314	77.26773242037234	117131
6b07b2e62d0e79e41eeb28f7fb9a2381319e8349	a zero-knowledge version of vsql		Zero-knowledge arguments of knowledge are powerful cryptographic primitives that allow a computationally strong prover to convince a weaker verifier for the validity of an NP statement, without revealing anything about the corresponding witness (beyond its existence). Most state-of-the art implementations of such arguments that achieve succinct communication and verification cost follow the quadratic arithmetic program paradigm. One notable exception to this is the vSQL system of [Zhang et al. IEEE S&P 2017] which takes an entirely different approach resulting is significantly fewer cryptographic operations. However, it has the notable downside that is not zero-knowledge (i.e., it does not hide the witness from the verifier), a property that has proven to be of utmost importance in many application (e.g., in cryptocurrencies). In this work, we present a zero-knowledge version of the argument upon which vSQL is based. Our construction utilizes two separate techniques: (i) a novel zero-knowledge verifiable polynomial delegation protocol, and (ii) running parts of the argument of vSQL over homomorphic commitments, thus hiding the committed values.	cryptocurrency;cryptographic primitive;cryptography;formal verification;polynomial;programming paradigm;the witness;zero-knowledge proof	Yupeng Zhang;Daniel Genkin;Jonathan Katz;Dimitrios Papadopoulos;Charalampos Papamanthou	2017	IACR Cryptology ePrint Archive		discrete mathematics;mathematics;zero-knowledge proof	Crypto	-38.11056359888842	76.40395661170116	117237
68ff70e7434b3ccf54f96d7395d33b96c0fe74ef	a key authentication scheme with non-repudiation	certificate;controle acces;certification;authentication;securite informatique;cle publique;logarithme discret;discrete logarithm;authentification;computer security;autenticacion;public key;seguridad informatica;llave publica;certificacion;non repudiation security;non repudiation;access control;authentification cle	In 1996, Horng and Yang proposed a key authentication scheme that requires no authorities. However, it is vulnerable to the guessing attack. An intruder can try out a password and forge the public key. To amend this problem, an improved authentication scheme intended to prevent the guessing attack and the forging problem was proposed by Zhan et al. in 1999. However, their scheme did not achieve non-repudiation of public key. In order to achieve non-repudiation of public key, two improvements of key authentication scheme for non-repudiation are discussed in this paper.	forge;key authentication;non-repudiation;password;public-key cryptography;yang	Min-Shiang Hwang;Li-Hua Li;Cheng-Chi Lee	2004	Operating Systems Review	10.1145/1035834.1035843	key authentication;telecommunications;challenge–response authentication;computer science;authentication;internet privacy;key distribution;computer security	Security	-43.95314907472763	76.08494682614483	117298
2bf4586f3ed71c810af45f60a6ea9d98a3293c20	saber: module-lwr based key exchange, cpa-secure encryption and cca-secure kem		In this paper, we introduce Saber, a package of cryptographic primitives whose security relies on the hardness of the Module Learning With Rounding problem (Mod-LWR). We first describe a secure DiffieHellman type key exchange protocol, which is then transformed into an IND-CPA encryption scheme and finally into an IND-CCA secure key encapsulation mechanism using a post-quantum version of the FujisakiOkamoto transform. The design goals of this package were simplicity, efficiency and flexibility resulting in the following choices: all integer moduli are powers of 2 avoiding modular reduction and rejection sampling entirely; the use of LWR halves the amount of randomness required compared to LWE-based schemes and reduces bandwidth; the module structure provides flexibility by reusing one core component for multiple security levels. A constant-time AVX2 optimized software implementation of the KEM with parameters providing more than 128 bits of post-quantum security, requires only 101K, 125K and 129K cycles for key generation, encapsulation and decapsulation respectively on a Dell laptop with an Intel i7-Haswell processor.	advanced vector extensions;ciphertext indistinguishability;cost per action;cryptographic primitive;encapsulation (networking);encryption;key encapsulation;key exchange;key generation;laptop;learning with errors;post-quantum cryptography;power of two;randomness;rejection sampling;rounding;sampling (signal processing)	Jan-Pieter D'Anvers;Angshuman Karmakar;Sujoy Sinha Roy;Frederik Vercauteren	2018	IACR Cryptology ePrint Archive	10.1007/978-3-319-89339-6_16	cryptographic primitive;parallel computing;software;encryption;key exchange;key generation;modular design;computer science;rounding;key encapsulation	Security	-36.447005283154574	77.39718678112573	117445
ff62706ac4870aa66c8ad3046d77b123d2b67d2b	a light weight security scheme for hwmp protocol using elliptic curve technique	public key cryptography;routing protocols;protocols;control packet exchange light weight security scheme hwmp protocol elliptic curve technique elliptic curve digital signature algorithm hybrid wireless mesh protocol ieee p802 11s d4 0 standard ecdsa technique path request path reply control messages mutable fields;elliptic curves;elliptic curve;routing;digital signatures;ecdsa;ad hoc network;digital signature;mesh;telecommunication security;wireless mesh networks;secure routing protocol;ad hoc networks;routing protocol;mesh ecdsa hwmp security routing protocols;security;elliptic curve digital signature algorithm;wireless mesh networks digital signatures protocols public key cryptography telecommunication security;hwmp;routing protocols digital signatures elliptic curves routing ad hoc networks	In this paper we have implemented the ECDSA (Elliptic Curve Digital Signature Algorithm) technique to provide security in HWMP (Hybrid Wireless Mesh Protocol). The motivation behind the use of ECDSA is that it is integrated into the IEEE P802.11s/D4.0 standard. We have used the ECDSA technique to secure control message in HWMP, namely PREQ (Path Request) and PREP (Path Reply). In these Control messages, we are interested only by mutable fields (i.e. fields that change during control packet exchange). Simulation results show that the ECDSA-HWMP does not too much a long overhead compared to the orignal HWMP.	algorithm;digital signature;hybrid wireless mesh protocol;immutable object;network packet;overhead (computing);powerpc reference platform;routing;simulation	Jalel Ben-Othman;Yesica Imelda Saavedra Benitez	2011	2011 IEEE 36th Conference on Local Computer Networks	10.1109/LCN.2011.6115561	wireless ad hoc network;digital signature;elliptic curve digital signature algorithm;computer science;information security;distributed computing;routing protocol;elliptic curve;computer security;computer network	Visualization	-47.78948582646532	76.39793615762382	117630
27a59a1f61f116951f05bb04dd96d8ad8c3693ec	epcgen2 pseudorandom number generators: analysis of j3gen	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;cryptanalytic attack;epcglobal gen2;uk phd theses thesis;life sciences;radio frequency identification;uk research reports;security;medical journals;pseudo random number generators;europe pmc;biomedical research;bioinformatics	This paper analyzes the cryptographic security of J3Gen, a promising pseudo random number generator for low-cost passive Radio Frequency Identification (RFID) tags. Although J3Gen has been shown to fulfill the randomness criteria set by the EPCglobal Gen2 standard and is intended for security applications, we describe here two cryptanalytic attacks that question its security claims: (i) a probabilistic attack based on solving linear equation systems; and (ii) a deterministic attack based on the decimation of the output sequence. Numerical results, supported by simulations, show that for the specific recommended values of the configurable parameters, a low number of intercepted output bits are enough to break J3Gen. We then make some recommendations that address these issues.	cryptanalysis;cryptography;decimation (signal processing);linear equation;numerical linear algebra;polynomial;population parameter;pseudo brand of pseudoephedrine;pseudorandom number generator;pseudorandomness;radio frequency identification device;radio frequency;radio-frequency identification;random number generation;randomness;simulation	Alberto Peinado;Jorge Munilla;Amparo Fúster-Sabater	2013		10.3390/s140406500	radio-frequency identification;telecommunications;computer science;bioinformatics;engineering;electrical engineering;information security;data mining;world wide web;computer security	Crypto	-41.621534103562475	83.847843520155	117959
5fc3873aadf1607d6ba50b2f76f662ff9cfc5947	selecting and reducing key sizes for multivariate cryptography		Cryptographic techniques are essential for the security of communication in modern society. As more and more business processes are performed via the Internet, the need for efficient cryptographic solutions will further increase in the future. Today, nearly all cryptographic schemes used in practice are based on the two problems of factoring large integers and  solving discrete logarithms. However, schemes based on these problems will become insecure when large enough quantum computers are built. The reason for this is Shor's algorithm, which solves number theoretic problems such as integer factorization and discrete logarithms in polynomial time on a quantum computer. Therefore one needs alternatives to those classical public key schemes. Besides lattice, code and hash based cryptosystems, multivariate cryptography seems to be a candidate for this. Additional to their (believed) resistance against quantum computer attacks, multivariate schemes are very fast and require only modest computational resources, which makes them attractive for the use on low cost devices such as RFID chips and smart cards. However, there remain some open problems to be solved, such as the unclear parameter choice of multivariate schemes, the large key sizes and the lack of more advanced multivariate schemes like signatures with special properties and key exchange protocols.#R##N#In this dissertation we address two of these open questions in the area of multivariate cryptography. In the first part we consider the question of the parameter choice of multivariate schemes. We start with the security model of Lenstra and Verheul, which, on the basis of certain assumptions like the development of the computing environment and the budget of an attacker, proposes security levels for now and the near future. Based on this model we study the known attacks against multivariate schemes in general and the Rainbow signature scheme in particular and use this analysis to propose secure parameter sets for these schemes for the years 2012 - 2050. #R##N#In the second part of this dissertation we present an approach to reduce the public key size of certain multivariate signature schemes such as UOV and Rainbow.  We achieve the reduction by inserting a structured matrix into the coefficient matrix of the public key, which enables us to store the public key in an efficient way. We propose several improved versions of UOV and Rainbow which reduce the size of the public key by factors of 8 and 3 respectively. Using the results of the first part, we  show that using structured public keys does not weaken the security of the underlying schemes against known attacks. Furthermore we show how the structure of the public key can be used to speed up the verification process of the schemes. Hereby we get a speed up of factors of 6 for UOV and 2 for Rainbow.  Finally we show how to apply our techniques to the QUAD stream cipher. By doing so we can increase the data throughput of QUAD by a factor of 7.	key size;multivariate cryptography	Albrecht Petzoldt	2013			theoretical computer science;mathematics;computer security;algorithm	Crypto	-38.13796682408642	78.760571217477	118061
4a4654e694f08fa7ec6b528f3fe97177b3710624	an optimistic fair protocol for p2p chained transaction	p2p system;modelizacion;distributed system;commerce electronique;p2p transaction;tratamiento transaccion;confiance;systeme reparti;fairness;psychologie sociale;comercio electronico;pago;par a par;electronic fund transfer;distributed computing;p2p;payment;decentralized system;modelisation;transferencia computarizada de fondos;onion;confidence;paiement;sistema repartido;poste a poste;confianza;digital content;chained transaction;trusted third party;onion payment;psicologia social;sistema descentralizado;calculo repartido;social psychology;systeme decentralise;transaction processing;peer to peer;modeling;calcul reparti;monetique;electronic trade;traitement transaction	As a decentralized technology, P2P architecture arises as a new model for distributed computing and transaction in the last few years, consequently there is a need for a scheme to incorporate payment services to enable electronic payment via P2P systems. In this paper, a new optimistic fair scheme is proposed for multi-party chained P2P transaction, which can ensure that every middleman and digital content owner can obtain the payments due to them. The disputes that might occur are analyzed and handling solution is proposed. The trusted third party need not be involved unless disputes have occurred. The optimistic payment scheme is fair, efficient, practical and suitable for multi-party chained P2P transaction.		Yichun Liu;Jianming Fu;Huanguo Zhang	2005		10.1007/11596370_13	electronic funds transfer;simulation;systems modeling;transaction processing;distributed transaction;trusted third party;decentralised system;computer science;operating system;peer-to-peer;database;distributed computing;confidence;computer security;payment	Crypto	-45.088886917658556	78.09793480144671	118169
aa6136b744e95e7cf04e3ea841e5cb19b4d97275	short proofs of knowledge for factoring	public key cryptography;cryptographie cle publique;theorie communication;securite informatique;securite donnee;discrete logarithm;teoria comunicacion;computer security;metodo factorizacion;factorization method;communication theory;codigo algebraico;point of view;methode factorisation;proof of knowledge;algebraic code;security of data;code algebrique	The aim of this paper is to design a proof of knowledge for the factorization of an integer n. We propose a statistical zero-knowledge protocol similar to proofs of knowledge of discrete logarithm a la Schnorr. The eeciency improvement in comparison with the previously known schemes can be compared with the diierence between the Fiat-Shamir scheme and the Schnorr one. Furthermore, the proof can be made non-interactive. From a practical point of view, the improvement is dramatic: the size of such a non-interactive proof is comparable to the size of the integer n and the computational resources needed can be kept low; three modular exponentiations both for the prover and the veriier are enough to reach a high level of security.	computation;computational resource;discrete logarithm;high-level programming language;integer factorization;interactive proof system;interactivity;linear algebra;point of view (computer hardware company);proof of knowledge;zero-knowledge proof	Guillaume Poupard;Jacques Stern	2000		10.1007/978-3-540-46588-1_11	discrete logarithm;computer science;theoretical computer science;mathematics;public-key cryptography;proof of knowledge;schnorr signature;computer security;algorithm;communication theory	Crypto	-39.14028316941346	79.24481781024394	118224
75aedc6dd8588b943de61bedae502d1ec97b3e69	cryptanalysis of pseudo-random generators based on vectorial fcsrs	stream cipher;fcsrs;n adic numbers	Feedback with Carry Shift Registers (FCSRs) have been first proposed in 2005 by F. Arnault and T. Berger as a promising alternative to LFSRs for the design of stream ciphers. The original proposal called F-FCSR simply filters the content of a FCSR in Galois mode using a linear function. In 2008, Hell and Johannson attacked this version using a method called LFSRization of F-FCSR. This attack is based on the fact that a single feedback bit controls the values of all the carry cells. Thus, a trail of 0 in the feedback bit annihilates the content of the carry register, leading to transform the FCSR into an LFSR during a sufficient amount of time. Following this attack, a new version of F-FCSR was proposed based on a new ring FCSR representation that guarantees that each carry cell de- pends on a distinct cell of the main register. This new proposal prevents the LFSRization from happening and remains unbroken since 2009. In parallel, Alaillou, Marjane and Mokrane proposed to replace the FCSR in Galois mode of the original proposal by a Vectorial FCSR (V-FCSR) in Galois mode. In this paper, we first introduce a general theoretical framework to show that Vectorial FCSRs could be seen as a particular case of classical FCSRs. Then, we show that Vectorial FCSRs used in Galois mode stay sensitive to the LFSRization of FCSRs. Finally, we demonstrate that hardware implementations of V-FCSRs in Galois mode are less efficient than those based on FCSRs in ring mode.	cryptanalysis	Thierry P. Berger;Marine Minier	2012		10.1007/978-3-642-34931-7_13	feedback with carry shift registers;arithmetic;computer science;theoretical computer science;mathematics;stream cipher;computer security;algorithm;statistics;algebra	Theory	-36.67076339846664	79.22030232062063	118429
96574213bea403d8627ce9d7684e332c3a70ba7f	impossible differential cryptanalysis of spn ciphers	spn ciphers;linear algebra;reduced round rijndael impossible differential cryptanalysis spn ciphers security block ciphers miss in the middle technique substitution permutation network ciphers linear transformation theory of linear algebra;theory of linear algebra;impossible differential cryptanalysis;miss in the middle technique;cryptography;linear algebra cryptography;linear transformation;block ciphers;reduced round rijndael;security;substitution permutation network ciphers	Impossible differential cryptanalysis is a very popular tool for analyzing the security of modern block ciphers and the core of such attack is based on the existence of impossible differentials. Currently, most methods for finding impossible differentials are based on the miss-in-the-middle technique and they are very ad-hoc. In this paper, we concentrate SPN ciphers whose diffusion layer is defined by a linear transformation P . Based on the theory of linear algebra, we propose several criteria on P and its inversion P−1 to characterize the existence of 3/4-round impossible differentials. We further discuss the possibility to extend these methods to analyze 5/6-round impossible differentials. Using these criteria, impossible differentials for reduced-round Rijndael are found that are consistent with the ones found before. New 4-round impossible differentials are discovered for block cipher ARIA. And many 4-round impossible differentials are firstly detected for a kind of SPN cipher that employs a 32 × 32 binary matrix proposed at ICISC 2006 as its diffusion layer. It is concluded that the linear transformation should be carefully designed in order to protect the cipher against impossible differential cryptanalysis.	block cipher;hoc (programming language);impossible differential cryptanalysis;linear algebra;substitution-permutation network	Ruilin Li;Bing Sun;Chunsheng Li	2010	IET Information Security	10.1049/iet-ifs.2010.0174	arithmetic;integral cryptanalysis;block cipher;contact analysis;differential cryptanalysis;discrete mathematics;interpolation attack;kasiski examination;piling-up lemma;computer science;cryptography;information security;linear algebra;block size;key schedule;boomerang attack;higher-order differential cryptanalysis;mathematics;s-box;impossible differential cryptanalysis;computer security;algorithm;linear cryptanalysis	Crypto	-39.28153696395818	81.24646090618012	118597
b99b69aaca40c33035546ed9c0496ea6b34586ec	tightly-secure signatures from lossy identification schemes	fiat shamir;tight reductions;signature schemes	In this paper we present three digital signature schemes with tight security reductions. Our first signature scheme is a particularly efficient version of the short exponent discrete log based scheme of Girault et al. (J. of Cryptology 2006). Our scheme has a tight reduction to the decisional Short Discrete Logarithm problem, while still maintaining the non-tight reduction to the computational version of the problem upon which the original scheme of Girault et al. is based. The second signature scheme we construct is a modification of the scheme of Lyubashevsky (Asiacrypt 2009) that is based on the worst-case hardness of the shortest vector problem in ideal lattices. And the third scheme is a very simple signature scheme that is based directly on the hardness of the Subset Sum problem. We also present a general transformation that converts, what we term lossy identification schemes, into signature schemes with tight security reductions. We believe that this greatly simplifies the task of constructing and proving the security of such signature schemes.	electronic signature;lossy compression	Michel Abdalla;Pierre-Alain Fouque;Vadim Lyubashevsky;Mehdi Tibouchi	2012		10.1007/978-3-642-29011-4_34	combinatorics;discrete mathematics;merkle signature scheme;theoretical computer science;mathematics;schnorr signature;elgamal signature scheme	Crypto	-38.546175000163046	78.35105866401612	118717
640c52a83ec0a5b82e80b9f5ea6d94a8fe71cb40	ringct 2.0: a compact accumulator-based (linkable ring signature) protocol for blockchain cryptocurrency monero		In this work, we initially study the necessary properties and security requirements of Ring Confidential Transaction (RingCT) protocol deployed in the popular anonymous cryptocurrency Monero. Firstly, we formalize the syntax of RingCT protocol and present several formal security definitions according to its application in Monero. Based on our observations on the underlying (linkable) ring signature and commitment schemes, we then put forward a new efficient RingCT protocol (RingCT 2.0), which is built upon the well-known Pedersen commitment, accumulator with one-way domain and signature of knowledge (which altogether perform the functions of a linkable ring signature). Besides, we show that it satisfies the security requirements if the underlying building blocks are secure in the random oracle model. In comparison with the original RingCT protocol, our RingCT 2.0 protocol presents a significant space saving, namely, the transaction size is independent of the number of groups of input accounts included in the generalized ring while the original RingCT suffers a linear growth with the number of groups, which would allow each block to process more transactions.	accumulator (computing);bitcoin;communications protocol;confidentiality;cryptocurrency;dspace;linear function;one-way function;random oracle;requirement;ring signature;whole earth 'lectronic link	Shifeng Sun;Man Ho Au;Joseph K. Liu;Tsz Hon Yuen	2017	IACR Cryptology ePrint Archive	10.1007/978-3-319-66399-9_25	distributed computing;ring signature;syntax;random oracle;computer science;cryptocurrency;accumulator (structured product);blockchain;database transaction	Security	-40.10732597316308	76.05021527092468	119342
01b8022f9f9ab95b8c8fcccc664fc856594fc233	secret-sharing for np	secret-sharing;witness encryption;obfuscation	A computational secret-sharing scheme is a method that enables a dealer, that has a secret, to distribute this secret among a set of parties such that a “qualified” subset of parties can efficiently reconstruct the secret while any “unqualified” subset of parties cannot efficiently learn anything about the secret. The collection of “qualified” subsets is defined by a monotone Boolean function. It has been a major open problem to understand which (monotone) functions can be realized by a computational secret-sharing scheme. Yao suggested a method for secret-sharing for any function that has a polynomial-size monotone circuit (a class which is strictly smaller than the class of monotone functions in $${\mathsf {P}}$$ P ). Around 1990 Rudich raised the possibility of obtaining secret-sharing for all monotone functions in $${\mathsf {NP}}$$ NP : in order to reconstruct the secret a set of parties must be “qualified” and provide a witness attesting to this fact. Recently, Garg et al. (Symposium on theory of computing conference, STOC, pp 467–476, 2013) put forward the concept of witness encryption, where the goal is to encrypt a message relative to a statement $$x\in L$$ x ∈ L for a language $$L\in {\mathsf {NP}}$$ L ∈ NP such that anyone holding a witness to the statement can decrypt the message; however, if $$x\notin L$$ x ∉ L , then it is computationally hard to decrypt. Garg et al. showed how to construct several cryptographic primitives from witness encryption and gave a candidate construction. One can show that computational secret-sharing implies witness encryption for the same language. Our main result is the converse: we give a construction of a computational secret-sharing scheme for any monotone function in $${\mathsf {NP}}$$ NP assuming witness encryption for $${\mathsf {NP}}$$ NP and one-way functions. As a consequence we get a completeness theorem for secret-sharing: computational secret-sharing scheme for any single monotone $${\mathsf {NP}}$$ NP -complete function implies a computational secret-sharing scheme for every monotone function in $${\mathsf {NP}}$$ NP .	circuit complexity;cryptographic primitive;cryptography;encryption;one-way function;polynomial;secret sharing;steven rudich;symposium on theory of computing;yao graph;monotone	Ilan Komargodski;Moni Naor;Eylon Yogev	2015	Journal of Cryptology	10.1007/s00145-015-9226-0	discrete mathematics;theoretical computer science;mathematics;algorithm	Theory	-38.26906626184708	76.1485476723938	119376
d914195fd4acba0dab5e79652d68e1cc01922b68	a secure and efficient data transmission technique using quantum key distribution		This paper proposes a new data transmission technique that uses Quantum Key Distribution (QKD) method, One Time Pad (OTP) encryption technique and Huffman encoding compression algorithm to transmit the data more securely and efficiently. While data is transmitted, requirements like secrecy, less overhead through compression etc are crucial issues. QKD is one of the most promising methods which provide unconditional security. It relies upon the immutable laws of quantum physics rather than computational complexity as the basis of its secrecy. To establish the trust between the sender and the receiver, this paper considers a trusted center that distributes and verifies the key. Also it uses Huffman encoding-a lossless compression algorithm to compress the transmitted data over the classical channel that reduces the data transmission overhead. Moreover for data encryption, it applies OTP technique with the key randomly generated by the QKD method that ensures the secrecy of the transmitted data over the classical channel. Thus the overhead of both quantum and classical channels are reduced. Finally the time requirements for encoding-decoding and encryption-decryption for the proposed technique are evaluated.	algorithm;computational complexity theory;download;encryption;huffman coding;immutable object;lossless compression;one-time pad;overhead (computing);procedural generation;quantum key distribution;quantum mechanics;requirement	Md. Armanuzzaman;Kazi Md. Rokibul Alam;Md. Mehadi Hassan;Yasuhiko Morimoto	2017	2017 4th International Conference on Networking, Systems and Security (NSysS)	10.1109/NSYSS2.2017.8267797	huffman coding;encryption;data compression;one-time pad;communication source;distributed computing;quantum key distribution;communication channel;computer science;lossless compression	EDA	-39.83269111190602	77.06243839005518	119706
f02ba46f0793c0c334a4227e768003396b4b0af0	a lightweight authentication protocol based on partial identifier for epcglobal class-1 gen-2 tags	rfid;security;privacy;authentication protocol	RFID is a key technology that can be used to create the pervasive society. The tag is an important part of the RFID system and most popular tags are some low-cost passive tags. These tags have limited computing and storing resources, and no more attentions are paid to their security and privacy. So the application of these tags is not secure. Lightweight authentication protocols are considered as an effective method to solve the security and privacy of lowcost RFID tags. We propose a novel lightweight authentication protocol by means of some functions provided by EPCglobal Class-1 Gen-2 tags. The protocol enhances the difficulty to reveal the tag’s secrecy by using the tag’s partial identifier to generate the session messages between the tag and the reader. The tag’s partial identifier is generated randomly for each authentication. Otherwise, the tag’s identifier is randomly divided into two separate parts so as to avoid colliding from the 16-bit cyclic redundancy coding function. Some random numbers, which are generated by the tag and the reader respectively, randomize the session messages between the tag and the reader so as to resist against tracing attack and replay attack. Our proposed protocol can assure forward security and it can resist against de-synchronized attack. This protocol only uses some lightweight functions and it is very suitable to low-cost RFID tags.	16-bit;authentication protocol;cyclic redundancy check;effective method;identifier;mutual authentication;pervasive informatics;privacy;pseudorandomness;radio-frequency identification;randomness;replay attack;requirement	Zhicai Shi;Fei Wu;Yongxiang Xia;Yihan Wang;Jian Dai;Changzhi Wang	2015	JNW	10.4304/jnw.10.6.369-375	radio-frequency identification;computer science;information security;authentication protocol;internet privacy;privacy;world wide web;computer security	Security	-46.20890986644405	74.92228611796656	119773
ac4e3d83fb9f617ab1b55521ba2261e6e7cdee1e	countermeasures against side-channel attacks for elliptic curve cryptosystems	rational point;side channel attacks;elliptic curve	In recent years, some attacks on cryptographic systems have been deviced, exploiting the leakage of information through so-called “side channels”. When a real-life device is performing a coding or decoding procedure, one can measure quantities such as the time employed, the profile of power consumption, the contents of a particular memory cell. If the algorithm is known, this information can get to the knowledge of part or all of the secret hidden in the device. This is the case when an exponentiation with secret exponent is performed according to a known deterministic algorithm, in case one can detect the order of squarings and products performed. This setting is common to several crypto-systems, involving computations in (Z/pqZ)∗, in Fq or in	computation;computer programming;cryptography;cryptosystem;decoding methods;deterministic algorithm;memory cell (binary);real life;spectral leakage	Antonio Bellezza	2001	IACR Cryptology ePrint Archive		elliptic curve point multiplication;side channel attack;theoretical computer science;decoding methods;elliptic curve cryptography;curve25519;deterministic algorithm;hyperelliptic curve cryptography;mathematics;elliptic curve digital signature algorithm	Crypto	-38.56900155431985	81.78127707989637	120077
c40e55176dc8a3c7f495101f28e45f1e64c8a71c	rocem: robust certified e-mail system based on server-supported signature	mobile device;secret sharing;fault tolerant;signature scheme;threshold cryptography	  In this paper we propose a new certified e-mail system which alleviates computational overhead of mobile devices with limited  computing power considering server-supported signatures scheme. Our system is also fault-tolerant and robust against mobile  adversary and conspiracy attacks since it distributes secure information to several servers based on the threshold cryptography.    		Jong-Phil Yang;Chul Sur;Kyung Hyune Rhee	2003		10.1007/978-3-540-39927-8_10	fault tolerance;merkle signature scheme;computer science;operating system;mobile device;distributed computing;internet privacy;secret sharing;blind signature;schnorr signature;computer security;statistics	Crypto	-44.25021315773167	75.36893580426646	120169
9264320fedbff946e48672f23bcba8126c6da357	fully secure unidirectional identity-based proxy re-encryption	proxy re encryption;singlehop;identity based encryption;multi hop	Proxy re-encryption (PRE) allows the proxy to translate a ciphertext encrypted under Alice's public key into another ciphertext that can be decrypted by Bob's secret key. Identity-based proxy re-encryption (IB-PRE) is the development of identity-based encryption and proxy re-encryption, where ciphertexts are transformed from one identity to another. In this paper, we propose two novel unidirectional identity-based proxy re-encryption schemes, which are both non-interactive and proved secure in the standard model. The first scheme is a single-hop IB-PRE scheme and has master secret security, allows the encryptor to decide whether the ciphertext can be re-encrypted. The second scheme is a multi-hop IB-PRE scheme which allows the ciphertext re-encrypted multiple times but without the size of ciphertext growing linearly as previous multi-hop IB-PRE schemes.	encryption;identity-based conditional proxy re-encryption	Song Luo;Qingni Shen;Zhong Chen	2011		10.1007/978-3-642-31912-9_8	semantic security;ciphertext indistinguishability;distributed computing;internet privacy;malleability;computer security;ciphertext;attribute-based encryption	Crypto	-40.70194283864321	75.20865736917531	120455
13ca5e20283085e1c2854325665bd7fd6497a62c	garbled circuits checking garbled circuits: more efficient and secure two-party computation		Applying cut-and-choose techniques to Yao’s garbled circuit protocol has been a promising approach for designing efficient Two-Party Computation (2PC) with malicious and covert security, as is evident from various optimizations and software implementations in the recent years. We revisit the security and efficiency properties of this popular approach and propose alternative constructions and a new definition that are more suitable for use in practice. • We design an efficient fully-secure 2PC protocol for two-output functions that only requires O(t|C|) symmetric-key operations (with small constant factors, and ignoring factors that are independent of the circuit in use) in the Random Oracle Model, where |C| is the circuit size and t is a statistical security parameter. This is essentially the optimal complexity for protocols based on cut-and-choose, resolving a main question left open by the previous work on the subject. Our protocol utilizes novel techniques for enforcing garbler’s input consistency and handling twooutput functions that are more efficient than all prior solutions. • Motivated by the goal of eliminating the all-or-nothing nature of 2PC with covert security (that privacy and correctness are fully compromised if the adversary is not caught in the challenge phase), we propose a new security definition for 2PC that strengthens the guarantees provided by the standard covert model, and offers a smoother security vs. efficiency tradeoff to protocol designers in choosing the right deterrence factor. In our new notion, correctness is always guaranteed, privacy is fully guaranteed with probability (1 − ), and with probability (i.e. the event of undetected cheating), privacy is only “partially compromised” with at most a single bit of information leaked, in case of an abort. We present two efficient 2PC constructions achieving our new notion. Both protocols are competitive with the previous covert 2PC protocols based on cut-and-choose. A distinct feature of the techniques we use in all our constructions is to check consistency of inputs and outputs using new gadgets that are themselves garbled circuits, and to verify validity of these gadgets using multi-stage cut-and-choose openings.	adversary (cryptography);correctness (computer science);garbled circuit;privacy;random oracle;secure two-party computation;security parameter;symmetric-key algorithm;two-phase commit protocol;yao graph	Payman Mohassel;Ben Riva	2013		10.1007/978-3-642-40084-1_3	divide and choose;theoretical computer science;oblivious transfer;computer science;correctness;random oracle;adversary;security parameter;secure two-party computation;covert	Security	-38.35768337849012	75.70055578633314	120537
7a3bff27fe7b1b297f281f77dd217f706cc27c5f	three-pass hybrid key establishment protocol based on esign signature	three pass hybrid key;protocole transmission;equilibrio de carga;authentication;equilibrage charge;esign signature;key distribution center;cle publique;transmission message;message transmission;authentification;protocolo transmision;autenticacion;public key;digital signature;llave publica;load balancing;signature numerique;load balance;distributed computing environment;key establishment;transmision mensaje;hybrid key establishment protocol;transmission protocol	In this paper we propose 3-pass hybrid key establishment protocol. Different from conventional protocol it doesn't need to share secret key with key distribution center (KDC) in advance since it uses both public key and symmetric key schemes. The proposed key establishment protocol guarantees mutual entity and key authentication via ESIGN signature[7] with only 3- message exchange. As each entity has the same number of messages sent or received, it also guarantees load balance of each entity's processing. Using timestamp, it supports key freshness. It can be efficiently applied to various systems in distributed computing environments since the protocol provides security, efficiency and reliability.		Sung-Min Lee;Tai-Yun Kim	1999		10.1007/3-540-48249-0_39	oakley protocol;computer science;load balancing;key-agreement protocol;static key;ephemeral key;authentication;distributed computing;pre-shared key;key distribution;computer security;key encapsulation;computer network	Crypto	-43.74170172412244	77.03421034307424	120563
df9976d23a782a9506b31f3bef917b9604871a41	improving lattice based cryptosystems using the hermite normal form	cle publique;public key encryption;trapdoor function;enrejado;public key;treillis;hermite normal form;criptografia;cryptography;llave publica;cryptographie;point of view;lattice	We describe a simple technique that can be used to substantially reduce the key and ciphertext size of various lattice based cryptosystems and trapdoor functions of the kind proposed by Goldreich, Goldwasser and Halevi (GGH). The improvement is significant both from the theoretical and practical point of view, reducing the size of both key and ciphertext by a factor n equal to the dimension of the lattice (i.e., several hundreds for typical values of the security parameter.) The efficiency improvement is obtained without decreasing the security of the functions: we formally prove that the new functions are at least as secure as the original ones, and possibly even better as the adversary gets less information in a strong information theoretical sense. The increased efficiency of the new cryptosystems allows the use of bigger values for the security parameter, making the functions secure against the best cryptanalytic attacks, while keeping the size of the key even below the smallest key size for which lattice cryptosystems were ever conjectured to be hard to break.	adversary (cryptography);algorithm;beta normal form;ciphertext;computational complexity theory;computer security;cryptanalysis;cryptosystem;database normalization;key size;lattice model (finance);lattice problem;lattice-based cryptography;ntru;public-key cryptography;randomness;requirement;security parameter;time complexity;trapdoor function	Daniele Micciancio	2001		10.1007/3-540-44670-2_11	arithmetic;discrete mathematics;computer science;mathematics;public-key cryptography;computer security;lattice problem	Crypto	-38.36508758778474	78.31909305205969	120700
9027733213f52ac4ceb5a5365cc7ab403263cd70	bayesian analysis of secure p2p sharing protocols	security properties;game theory;distributed protocol;p2p;formal reasoning;content distribution;access control;dynamic adaptation;peer to peer;bayesian analysis;security protocol;bayesian game	Ad hoc and peer-to-peer (P2P) computing paradigms pose a number of security challenges. The deployment of classic security protocols to provide services such as node authentication, content integrity or access control, presents several difficulties, most of them due to the decentralized nature of these environments and the lack of central authorities. Even though some solutions have been already proposed, a usual problem is how to formally reasoning about their security properties. In this work, we show how Game Theory –particularly Bayesian games– can be an useful tool to analyze in a formal manner a P2P security scheme. We illustrate our approach with a secure content distribution protocol, showing how nodes can dynamically adapt their strategies to highly transient communities. In our model, some security aspects rest on the formal proof of the robustness of the distribution protocol, while other properties stem from notions such as rationality, cooperative security, beliefs, or best-response strategies.	access control;authentication;centralized computing;digital distribution;formal proof;game theory;hoc (programming language);interaction;peer-to-peer;rationality;software deployment	Esther Palomar;Almudena Alcaide;Juan E. Tapiador;Julio César Hernández Castro	2007		10.1007/978-3-540-76843-2_41	computer security model;universal composability;security through obscurity;computer science;distributed computing;distributed system security architecture;internet privacy;network access control;computer security	Security	-47.9913231078341	76.03029376258773	121084
dd32e0cefa930d0da0acdd52fb0352cf407874ca	refined secure network coding scheme with no restriction on coding vectors	cryptographic hash functions;random linear network coding secure network coding scheme coding vectors security weakness linear network code design;encryption;security weakness;linear codes;one time pad;random linear network coding;indexes;network coding;telecommunication security linear codes network coding;vectors;network coding vectors encoding encryption indexes;telecommunication security;secure network coding scheme;one time pad secure network coding random linear network coding cryptographic hash functions avalanche effect random number generators;avalanche effect;linear network code design;encoding;coding vectors;random number generators;secure network coding	In this letter, we consider the secure network coding problem with no restriction on the network coding vectors. Adeli and Liu proposed a scheme achieving perfect security in a network with network coding. In order to hide a security weakness of their scheme, they imposed a restriction on the linear network code design. However, this restriction can be violated when the random linear network coding is used due to the completely decentralized nature of it. We refine Adeli and Liu's scheme into new one with no restriction and thus remove the security weakness under the computationally bounded adversary assumption.	adversary (cryptography);computationally bounded adversary;information-theoretic security;linear network coding;overhead (computing)	Young-Sik Kim	2012	IEEE Communications Letters	10.1109/LCOMM.2012.091212.121547	database index;linear network coding;random number generation;computer science;theoretical computer science;avalanche effect;distributed computing;computer security;encryption;one-time pad;cryptographic hash function;encoding;statistics	Crypto	-39.094148699975904	76.51680945654374	121173
730a53e42bf41c841e78e72341fb6313b5614b86	analyzing directional modulation techniques as block encryption ciphers for physical layer security		This paper presents a framework - PLR-Probe - consisting of two layers: (1) Mapping Layer and (2) Computing amp;amp; Decision Layer. In Mapping Layer (ML), the Directional Modulation Techniques (DMTs) are analyzed as block encryption ciphers by mapping their major components to the components of DMTs. The cryptographic strength of random stream of bits, received by eavesdropper in Physical Layer Security (PLS) techniques is explored and compared by Computing amp;amp; Decision Layer (CDL), with that of strong block ciphering algorithm (i.e. AES). To prove the effectiveness and relevance of the framework, we applied it on a recently proposed Antenna Subset Modulation (ASM) technique. We measured the cryptographic strength of the ASM technique by mapping it to a physical layer encryption method. The other major contribution is: using PLR-Probe, communication researchers can benchmark the cryptographic strength of any PLS technique with AES. In this paper, ASM is benchmarked against AES by using a novel metric (Physical Layer Randomness (PLR)). The analysis can be made comprehensive by considering PLR along with Symbol Error Rate (SER) and Secrecy Capacity (SC) as optimization parameters to improve the cryptographic strength of PLS techniques.	acoustic lobing;algorithm;benchmark (computing);block cipher;compiler description language;computation;digital monetary trust;encryption;information-theoretic security;mathematical optimization;modulation;public lending right;randomness;relevance;smartphone;strong cryptography;whole earth 'lectronic link	Abrar Ahmad;Muhammad Amin;Muddassar Farooq	2017	2017 IEEE Wireless Communications and Networking Conference (WCNC)	10.1109/WCNC.2017.7925525	telecommunications;computer science;theoretical computer science;operating system;computer security;computer network	Mobile	-47.248821621761365	83.58756483847837	121181
5a3d0ff29420afc041d7cef432c0f8a4e81ebf4d	identity-based key exchange protocols without pairings	security properties;forward secrecy;security model;elliptic curve;satisfiability;bilinear map;public key;key exchange;cyclic group;key generation center;key agreement protocol;id based cryptography;diffie hellman	This paper presents a new identity based key agreement protocol. In id-based cryptography (introduced by Adi Shamir in [34]) each party uses its own identity as public key and receives his secret key from a master Key Generation Center, whose public parameters are publicly	alternating direction implicit method;identity creation;key (cryptography);key exchange;key generation;key-agreement protocol;public-key cryptography	Dario Fiore;Rosario Gennaro	2010	Trans. Computational Science	10.1007/978-3-642-17499-5_3	otway–rees protocol;oakley protocol;elliptic curve diffie–hellman;universal composability;yak;interlock protocol;key-agreement protocol;diffie–hellman key exchange;mqv;cryptographic protocol;mathematics;distributed computing;internet privacy;public-key cryptography;key distribution;computer security;station-to-station protocol	Crypto	-41.71982479199325	75.07450367693643	121206
35596dc9b71e13e6eed1ef1ed50675d4dea09814	clarifying the subset-resilience problem		We investigate the subset-resilience problem, defined in 2002 by Reyzin and Reyzin to analyze their HORS signature scheme. We show that textbook HORS is insecure against adaptive attacks, and present a practical attack based on a greedy algorithm. We also describe weak messages for HORS, that map to smaller subsets than expected, and are thus easier to cover. This leads to an improved attack against HORS and to an improved classical attack against the signature scheme SPHINCS, of complexity 2 instead of 2. We propose the PRNG to obtain a random subset construction (PORS), which avoids weak messages, for a tiny computational overhead. We adapt PORS to SPHINCS to also deterministically select the HORST instance that is used to sign the input message. This new construction reduces the attack surface and increases the security level, improving the security of SPHINCS by 67 bits against classical attacks and 33 bits against quantum attacks. A version of SPHINCS using our PORS construction can work with smaller parameters that reduce the signature size by 4616 bytes and speed up signature and verification, for the same 128-bit post-quantum security as the original SPHINCS.	128-bit;attack surface;byte;digital signature;greedy algorithm;overhead (computing);pors;post-quantum cryptography;powerset construction;subset sum problem	Jean-Philippe Aumasson;Guillaume Endignoux	2017	IACR Cryptology ePrint Archive		psychological resilience;environmental resource management;psychology	Crypto	-37.35177082579476	80.03396066020068	121286
3a5dd7a79b6f4fcad37a6a9774061d0133988dd2	radiogatún, a belt-and-mill hash function		We present an approach to design cryptographic hash functions that builds on and improves the one underlying the Panama hash function. We discuss the properties of the resulting hash functions that need to be investigated and give a concrete design called RadioGatún that is quite competitive with SHA-1 in terms of performance. We are busy performing an analysis of RadioGatún and present in this paper some preliminary results.	cryptographic hash function;radiogatún;sha-1	Guido Bertoni;Joan Daemen;Michaël Peeters;Gilles Van Assche	2006	IACR Cryptology ePrint Archive		fowler–noll–vo hash function;double hashing;rolling hash;theoretical computer science;hash chain;hash function;swifft;mdc-2;hash buster;computer science	Crypto	-38.40701920753653	78.31111775165984	121429
237d664eca37abaa3339c6175a7e76bf87b87597	authentication from matrix conjugation	multivariate polynomial	We propose an authentication scheme where forgery (a.k.a. impersonation) seems infeasible without finding the prover’s long-term private key. The latter is equivalent to solving the conjugacy search problem in the platform (noncommutative) semigroup, i.e., to recovering X from X−1AX and A. The platform semigroup that we suggest here is the semigroup of n×n matrices over truncated multivariable polynomials over a ring.	authentication;polynomial;public-key cryptography;quaternions and spatial rotation;search problem	Dima Grigoriev;Vladimir Shpilrain	2009	Groups Complexity Cryptology	10.1515/GCC.2009.199	combinatorics;discrete mathematics;computer science;mathematics;algebra	Crypto	-39.73419083914066	80.66419482512566	121437
4a2fceb2b6355c3023683d0004a94797408e2c61	on obfuscating point functions	boolean function;standard model;random oracle model;random permutation;hash function;obfuscation	We investigate the possibility of obfuscating point functions in the framework of Barak et al. from Crypto '01. A point function is a Boolean function that assumes the value 1 at exactly one point. Our main results are as follows:We provide a simple construction of efficient obfuscators for point functions for a slightly relaxed notion of obfuscation, for which obfuscating general circuits is nonetheless impossible. Our construction relies on the existence of a very strong one-way permutation, and yields the first non-trivial obfuscator under general assumptions in the standard model. We also obtain obfuscators for point functions with multi-bit output and for prefix matching.Our assumption is that there is a one-way permutation wherein any polynomial-sized circuit inverts the permutation on at most a polynomial number of inputs. We show that a similar assumption is in fact necessary, and that our assumption holds relative to a random permutation oracle.Finally, we establish two impossibility results which indicate that the limitations on our construction, namely simulating only adversaries with single-bit output and using nonuniform advice in our simulator, are in some sense inherent.Previous work gave negative results for the general class of circuits (Barak et al., Crypto '01) and positive results in the random oracle model (Lynn et al., Eurocrypt '04) or under non-standard number-theoretic assumptions (Canetti, Crypto '97). This work represents the first effort to bridge the gap between the two for a natural class of functionalities.	ac0;cryptography;eurocrypt;fixed-point combinator;function point;jason;ke software;nc (complexity);obfuscation (software);one-way function;polynomial;pseudorandomness;random oracle;random permutation;simulation;tc0;theory;yang	Hoeteck Wee	2005		10.1145/1060590.1060669	random oracle;standard model;mathematical optimization;combinatorics;random permutation;discrete mathematics;hash function;obfuscation;computer science;mathematics;boolean function;algorithm;statistics	Theory	-37.262332219235134	76.57764138384387	121459
42e3c8bbeb62d4c86b6f06abac9703f86ff2d5ce	verified security of merkle-damgård	cryptographic hash functions;easy crypt cryptographic hash functions collision resistance indifferentiability merkle damgaard sha 3;authorisation;theorem proving authorisation cryptography digital signatures formal verification;easy crypt;digital signatures;md5 hash functions security verification merkle damgard hash functions cryptographic hash functions data authentication cryptographic functionalities block ciphers message authentication codes key exchange protocols encryption digital signature scheme easycrypt framework automated theorem prover smt solvers interactive proof assistant machine checked proof independently verifiable proof collision resistance sha 1 hash functions;merkle damgaard;theorem proving;formal verification;cryptography;collision resistance;indifferentiability;sha 3;cryptography resistance games probabilistic logic semantics electronic mail	Cryptographic hash functions provide a basic data authentication mechanism and are used pervasively as building blocks to realize many cryptographic functionalities, including block ciphers, message authentication codes, key exchange protocols, and encryption and digital signature schemes. Since weaknesses in hash functions may imply vulnerabilities in the constructions that build upon them, ensuring their security is essential. Unfortunately, many widely used hash functions, including SHA-1 and MD5, are subject to practical attacks. The search for a secure replacement is one of the most active topics in the field of cryptography. In this paper we report on the first machine-checked and independently-verifiable proofs of collision-resistance and in differentiability of Merkle-Damgaard, a construction that underlies many existing hash functions. Our proofs are built and verified using an extension of the Easy Crypt framework, which relies on state-of-the-art verification tools such as automated theorem provers, SMT solvers, and interactive proof assistants.	automated theorem proving;block cipher;collision resistance;cryptanalysis;cryptographic hash function;cryptography;digital signature;encryption;formal verification;iteration;key exchange;md5;merkle–damgård construction;message authentication code;one-way compression function;oracle machine;proof assistant;random oracle;sha-1;sha-3	Michael Backes;Gilles Barthe;Matthias Berg;Benjamin Grégoire;César Kunz;Malte Skoruppa;Santiago Zanella Béguelin	2012	2012 IEEE 25th Computer Security Foundations Symposium	10.1109/CSF.2012.14	merkle–damgård construction;message authentication code;cryptographic primitive;security of cryptographic hash functions;double hashing;hash function;tiger;collision attack;merkle tree;formal verification;preimage attack;sha-2;collision resistance;computer science;cryptography;secure hash algorithm;theoretical computer science;secure hash standard;hash chain;hash-based message authentication code;distributed computing;computer security;cryptographic hash function;fowler–noll–vo hash function;mdc-2;swifft	Crypto	-39.4123160136551	76.07553608116702	121917
419449e5e89aa1c7b4b582644312573f392fe456	simple countermeasure to non-linear collusion attacks targeted for spread-spectrum fingerprinting scheme			fingerprint (computing)	Minoru Kuribayashi	2016	IEICE Transactions		fingerprint;telecommunications;computer science;internet privacy;spread spectrum;computer security;kerckhoffs's principle	Crypto	-44.90164877795077	76.11610159035152	121938
3bed94f13ce216f1bae9db6ffc39ed3cbfec24b0	superfluous keys in multivariate quadratic asymmetric systems		In this article, we show that public key schemes based on multivariate quadratic equations allow many equivalent, and hence superfluous private keys. We achieve this result by investigating several transformations to identify these keys and show their application to Hidden Field Equations (HFE), C∗, and Unbalanced Oil and Vinegar schemes (UOV). In all cases, we are able to reduce the size of the private — and hence the public — key space by at least one order of magnitude. We see applications of our technique both in cryptanalysis of these schemes and in memory efficient implementations.	cryptanalysis;human factors and ergonomics;key space (cryptography);public-key cryptography;quadratic equation;unbalanced oil and vinegar	Christopher Wolf;Bart Preneel	2004	IACR Cryptology ePrint Archive			Crypto	-40.004001270856584	79.21607050436545	122015
07398080fad92fece2cf75da207ff2f0e64cc9fe	protecting last four rounds of clefia is not enough against differential fault analysis		In this paper we propose a new differential fault analysis (DFA) on CLEFIA of 128-bit key. The proposed attack requires to induce byte faults at the fourteenth round of CLEFIA encryption. The attack uses only two pairs of fault-free and faulty ciphertexts and uniquely determines the 128-bit secret key. The attacker does not need to know the plaintext. The most efficient reported fault attack on CLEFIA, needs fault induction at the fifteenth round of encryption and can be performed with two pairs of fault-free and faulty ciphertexts and brute-force search of around 20 bits. Therefore, the proposed attack can evade the countermeasures against the existing DFAs which only protect the last four rounds of encryption. Extensive simulation results have been presented to validate the proposed attack. The simulation results show that the attack can retrieve the 128-bit secret key in around one minute of execution time. To the best of authors’ knowledge the proposed attack is the most efficient attack in terms of both the input requirements as well as the complexity.	128-bit;brute-force search;byte;clefia;desktop computer;differential fault analysis;encryption;key (cryptography);need to know;plaintext;requirement;run time (program lifecycle phase);simulation	Subidh Ali;Debdeep Mukhopadhyay	2012	IACR Cryptology ePrint Archive		encryption;real-time computing;byte;differential fault analysis;countermeasure;need to know;clefia;plaintext;computer science	Security	-35.59869623554317	80.91049242559758	122123
23e2071ddc2cfd7872839716260eb23a5fd3a821	efficient multi-party computation: from passive to active security via secure simd circuits		A central problem in cryptography is that of converting protocols that offer security against passive (or semi-honest) adversaries into ones that offer security against active (or malicious) adversaries. This problem has been the topic of a large body of work in the area of secure multiparty computation (MPC). Despite these efforts, there are still big efficiency gaps between the best protocols in these two settings. In two recent works, Genkin et al. (STOC 2014) and Ikarashi et al. (ePrint 2014) suggested the following new paradigm for efficiently transforming passive-secure MPC protocols into active-secure ones. They start by observing that in several natural information-theoretic MPC protocols, an arbitrary active attack on the protocol can be perfectly simulated in an ideal model that allows for additive attacks on the arithmetic circuit being evaluated. That is, the simulator is allowed to (blindly) modify the original circuit by adding an arbitrary field element to each wire. To protect against such attacks, the original circuit is replaced by a so-called AMD circuit, which can offer protection against such attacks with constant multiplicative overhead to the size. Our motivating observation is that in the most efficient known informationtheoretic MPC protocols, which are based on packed secret sharing, it is not the case that general attacks reduce to additive attacks. Instead, the corresponding ideal attack can include limited forms of linear combinations of wire values. We extend the AMD circuit methodology to so-called secure SIMD circuits, which offer protection against this more general class of attacks. We apply secure SIMD circuits to obtain several asymptotic and concrete efficiency improvements over the current state of the art. In particular, we improve the additive per-layer overhead of the current best protocols from O(n) to O(n), where n is the number of parties, and obtain the first protocols based on packed secret sharing that “natively” achieve nearoptimal security without incurring the high concrete cost of Bracha’s committee-based security amplification method. Our analysis is based on a new modular framework for proving reductions from general attacks to algebraic attacks. This framework allows us to reprove previous results in a conceptually simpler and more unified way, as well as obtain our new results.	arithmetic circuit complexity;cryptography;information theory;linear algebra;malware;overhead (computing);programming paradigm;simd;secret sharing;secure multi-party computation;semiconductor industry;symposium on theory of computing;utility functions on indivisible goods	Daniel Genkin;Yuval Ishai;Antigoni Polychroniadou	2015		10.1007/978-3-662-48000-7_35	computer architecture;parallel computing;computer science;theoretical computer science	Crypto	-37.39079492304518	76.79288788795708	122304
8c77c98f3101803772ad5ea38b43297b6ff5669d	a cryptosystem based on hidden order groups and its applications in highly dynamic group key agreement			cryptosystem;group key;key-agreement protocol		2006	IACR Cryptology ePrint Archive		group key;cryptosystem;computer science;distributed computing	Crypto	-42.11350062858011	77.10703701777248	122546
86bed5a6595cf7b3972feb7d5fdfa6ac453b318f	assessing jpeg2000 encryption with key-dependent wavelet packets	signal image and speech processing;systems and data security;security science and technology;communications engineering networks	We analyze and discuss encryption schemes for JPEG2000 based on the wavelet packet transform with a keydependent subband structure. These schemes have been assumed to reduce the runtime complexity of encryption and compression. In addition to this “lightweight” nature, other advantages like encrypted domain signal processing have been reported. We systematically analyze encryption approaches based on key-dependent subband structures in terms of their impact on compression performance, their computational complexity and the level of security they provide as compared to more classical techniques. Furthermore, we analyze the prerequisites and settings in which the previously reported advantages actually hold and in which settings no advantages can be observed. As a final outcome it has to be stated that the compression integrated encryption approach based on the idea of secret wavelet packets can not be recommended.	computational complexity theory;encryption;jpeg 2000;network packet;signal processing;wavelet packet decomposition	Dominik Engel;Thomas Stütz;Andreas Uhl	2012	EURASIP J. Information Security	10.1186/1687-417X-2012-2	40-bit encryption;telecommunications;computer science;theoretical computer science;disk encryption hardware;computer security;encryption;probabilistic encryption	Security	-34.91530998049598	78.64847130576536	122617
229ede944ca4cceab25ee707a6e974124f3c6430	efficient extension of standard schnorr/rsa signatures into universal designated-verifier signatures	marco;universal design;amplitude shift keying;standards;implementation;standard;cle publique;signature electronique;modulation deplacement amplitude;probabilistic approach;cryptage rsa;rsa ciphering;signature scheme;public key;cifrado rsa;digital signature;random oracle model;enfoque probabilista;approche probabiliste;norma;llave publica;functionality;fonctionnalite;firma numerica;modulacion desplazamiento amplitud;implementacion;etalon;digital signature scheme;norme;funcionalidad;oracle	Universal Designated-Verifier Signature (UDVS) schemes are digital signature schemes with additional functionality which allows any holder of a signature to designate the signature to any desired designated-verifier such that the designated-verifier can verify that the message was signed by the signer, but is unable to convince anyone else of this fact. Since UDVS schemes reduce to standard signatures when no verifier designation is performed, it is natural to ask how to extend the classical Schnorr or RSA signature schemes into UDVS schemes, so that the existing key generation and signing implementation infrastructure for these schemes can be used without modification. We show how this can be efficiently achieved, and provide proofs of security for our schemes in the random oracle model.	designated verifier signature;digital signature;key generation;rsa (cryptosystem);random oracle	Ron Steinfeld;Huaxiong Wang;Josef Pieprzyk	2003	IACR Cryptology ePrint Archive	10.1007/978-3-540-24632-9_7	random oracle;ring signature;oracle;fabry–pérot interferometer;digital signature;universal design;computer science;theoretical computer science;mathematics;public-key cryptography;implementation;blind signature;schnorr signature;computer security;algorithm	Crypto	-41.11292254571839	77.7377302347186	122658
aca42c9e4378e18fa3ba485901c4cc5b68070ac1	lattice-based group signatures: achieving full dynamicity with ease		Lattice-based group signature is an active research topic in recent years. Since the pioneering work by Gordon, Katz and Vaikuntanathan (Asiacrypt 2010), eight other schemes have been proposed, providing various improvements in terms of security, efficiency and functionality. However, most of the existing constructions work only in the static setting where the group population is fixed at the setup phase. The only two exceptions are the schemes by Langlois et al. (PKC 2014) that handles user revocations (but new users cannot join), and by Libert et al. (Asiacrypt 2016) which addresses the orthogonal problem of dynamic user enrollments (but users cannot be revoked). In this work, we provide the first lattice-based group signature that offers full dynamicity (i.e., users have the flexibility in joining and leaving the group), and thus, resolve a prominent open problem posed by previous works. Moreover, we achieve this non-trivial feat in a relatively simple manner. Starting with Libert et al.’s fully static construction (Eurocrypt 2016) which is arguably the most efficient lattice-based group signature to date, we introduce simple-but-insightful tweaks that allow to upgrade it directly into the fully dynamic setting. More startlingly, our scheme even produces slightly shorter signatures than the former. The scheme satisfies the strong security requirements of Bootle et al.’s model (ACNS 2016), under the Short Integer Solution (SIS) and the Learning With Errors (LWE) assumptions.	antivirus software;asiacrypt;electronic signature;eurocrypt;group signature;integer (computer science);lattice model (finance);learning with errors;pkc (conference);requirement	San Ling;Khoa Nguyen;Huaxiong Wang;Yanhong Xu	2017		10.1007/978-3-319-61204-1_15	group signature;theoretical computer science;lattice (order);computer science;population	Crypto	-38.93461616416283	76.10230694090511	122662
ad77289468ceb82657a381921a46b88fee644bc2	direct cca secure identity-based broadcast encryption	provable security;direct cca technique;ibbe;standard model	In the previous works, the general transformation methods from a CPA(chosen-plaintext attacks) secure scheme to a CCA(chosen-ciphertext attacks) secure scheme are the hierarchical identity-based encryption, one-time signature and MAC. These folklore construction methods lead to the CCA secure schemes that are somewhat inefficient in the real life. In this paper, a new direct chosen-ciphertext technique is introduced and a practical identity-based broadcast encryption(IBBE) scheme that is CCA secure is proposed. The new scheme has many advantages over the available, such as constant size private keys and constant size ciphertexts, which solve the trade-off between the private keys size and ciphertexts size. In addition, under the standard model, the security of the new scheme is reduced to the hardness assumption-decision bilinear Diffie-Hellman exponent problem(DBDHE). This assumption is more natural than many of the hardness assumptions recently introduced to IBBE in the standard model.	broadcast encryption	Leyou Zhang;Qing Wu;Yupu Hu	2012		10.1007/978-3-642-34601-9_26	standard model;computer science;theoretical computer science;provable security;internet privacy;computer security	Crypto	-39.47846279086375	76.8503787067932	122743
01da4a7b58cdb2e084bd1e1c6403ff6cfbb421d4	modification of traditional rsa into symmetric-rsa cryptosystems		This paper addresses the modification of RSA cryptography namely Symmetric-RSA, which seem to be equally useful for different cryptographic applications such as encryption, digital signature, etc. In order to design Symmetric-RSA, two prime numbers are negotiated using Diffie-Hellman key exchange protocol followed by RSA algorithm. As the new scheme uses Diffie-Hellman and RSA algorithm, the security of the overall system depends on discrete logarithm as well as factorization problem and thus, its security is more than public-key RSA. Finally, some new cryptographic applications of the proposed modifications are described that certainly extend the applications of the existing RSA. KeywoRDS Cryptography, Cryptosystem, Modification, RSA, Symmetric-RSA		Prerna Mohit;G. P. Biswas	2017	IJBDCN	10.4018/IJBDCN.2017010106	hybrid cryptosystem	Crypto	-39.65910344634268	77.91129367585818	122975
0dfc3ebb8bc610b8f5ad1984cd90fc35618e38bf	joint encryption and message-efficient secure computation	boolean circuits;theorie groupe;almacenamiento informacion;complexite calcul;secure computation;distributed processing;communication complexity;distributed computing;public key encryption;transmission message;group theory;message transmission;complejidad computacion;information storage;computational complexity;criptografia;cryptography;group oriented cryptography;cryptographie;stockage information;traitement reparti;teoria grupo;privacy;tratamiento repartido;transmision mensaje	This paper addresses the message complexity of secure computation in the (passive adversary) privacy setting. We show that O(nC) encrypted bits of communication suffice for n parties to evaluate any boolean circuit of size C privately, under a specific cryptographic assumption. This work establishes a connection between secure distributed computation and group-oriented cryptography, i.e., cryptographic methods in which subsets of individuals can act jointly as single agents. Our secure computation protocol relies on a new group-oriented probablistic public-key encryption scheme with useful algebraic properties.	adversary (cryptography);boolean circuit;distributed computing;encryption;linear algebra;public-key cryptography;secure multi-party computation	Matthew K. Franklin;Stuart Haber	1996	Journal of Cryptology	10.1007/BF00189261	commitment scheme;computer science;cryptography;secure two-party computation;theoretical computer science;communication complexity;cryptographic protocol;distributed computing;secure multi-party computation;group theory;privacy;computer security;algorithm	Crypto	-42.74161205440046	77.83832618582291	123043
18997a77f04ef9fc5c13e8097fe048f39a25b1ba	a nobel key-search method for side channel attacks based on pattern recognition	private key cryptography;signal detection correlation cryptography power consumption security;key search method;signal detection pattern recognition private key cryptography;signal detection;search method;cryptography;differential power analysis;differential power analysis key search method side channel attacks pattern recognition secret keys cryptosystems power traces;cryptosystems;side channel attacks;pattern recognition;secret keys;power consumption;correlation;security;power traces;pattern recognition cryptography energy consumption frequency information analysis degradation electromagnetic radiation electromagnetic analysis pattern analysis signal analysis	Differential power analysis (DPA) has been known as an efficient attack for finding secret keys of cryptosystems but its efficiency may be lowered due to the misalignment of the acquired signals. Though the misalignment problem has been now solvable by various successful approaches in DPA, a lot of power traces are still required to find correct keys. Since the required number of power traces is directly connected with the efficiency of SCAs, we propose a key-search method even with relatively reduced number of power traces based on recognizing special patterns of the signal caused by cryptographic operations. Experimental results show that the proposed method is able to search correct keys with much smaller number of traces than the minimum number of traces with which the conventional methods of the energy-based DPA and frequency-based DPA succeed in finding keys.	cryptography;cryptosystem;decision problem;pattern recognition;side-channel attack;tracing (software)	You-Seok Lee;YongJe Choi;Dong-Guk Han;Howon Kim;Hyoung-Nam Kim	2008	2008 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2008.4517974	computer science;cryptography;information security;theoretical computer science;mathematics;internet privacy;computer security;correlation;statistics	EDA	-39.543291914412436	84.33867098849764	123076
94b884a05bc619c9942e5dcb7fa3a7687273fea6	a chaos based method for efficient cryptographic s-box design		Substitution boxes are integral parts of most of the conventional block ciphering techniques such as DES, AES, IDEA, etc. The strengths of these encryption techniques solely depend upon the quality of their nonlinear S-boxes. Therefore, the construction of cryptographically strong S-boxes is always a challenge to build secure cryptosystems. In this paper, an efficient method for designing chaos-based cryptographic S-box is presented. The chaotically-modulated system trajectory of chaotic map is sampled and pretreated to generate an initial 8×8 S-box. Elements shuffling through random circular-rotation and zig-zag scan pattern are carried out to improve its quality. The experimental results of analyses such as bijectivity, nonlinearity, strict avalanche criterion, equiprobable input/output XOR distribution, etc., demonstrate that the proposed S-box has better cryptographic properties as compared to the recently proposed chaos-based S-boxes, which justify its effectiveness for the design of strong block cryptosystem.		Musheer Ahmad;Hitesh Chugh;Avish Goel;Prateek Singla	2013		10.1007/978-3-642-40576-1_13	cryptographic primitive;security of cryptographic hash functions;theoretical computer science;cryptographic protocol	EDA	-37.656157002007056	80.23917529785984	123201
3006e082fad17189caafa4d4e637177dd461be22	an efficient pattern matching scheme in lzw compressed sequences	compressed pattern matching;lzw compression;pattern matching;malwares detection;bit parallelism;string matching;article;information search and retrieval	Compressed pattern matching (CPM) is an emerging research field addressing the problem: given a compressed sequence and a pattern, process the sequence with minimal (or no) decompression to find the pattern occurrence(s) in the uncompressed sequence. It can be applied to detect malwares and confidential information leakage in compressed files directly. In this paper, we report our work of CPM in Lempel–Ziv–Welch (LZW) compressed sequences. We propose an efficient bitmap-based realization of the Amir–Benson–Farach algorithm. We also generalize the algorithm to find all pattern occurrences and report their absolute positions in the uncompressed sequence. Experiments are conducted to test the space requirements of our proposed generalization and two related CPM schemes which can also be realized with bitmaps. Results show that our proposed generalization requires the least amount of storage for moderate and long patterns. We also conduct experiments to compare the throughput performance of our proposed generalization with these two related CPM schemes and the decompress-then-search scheme. Results show that our proposed generalization outperforms the decompress-then-search scheme significantly. When scanning a file with pattern occurrences, our proposed generalization performs slightly better than the two related CPM schemes. The difference is significant when scanning a file with no pattern occurrence. Copyright # 2008 John Wiley & Sons, Ltd.	antivirus software;applications-by-forms;bitmap;clam antivirus;compressed pattern matching;confidentiality;dspace;data compression;dijkstra's algorithm;experiment;information leakage;john d. wiley;lempel–ziv–stac;lempel–ziv–welch;malware;noise reduction;numerical recipes;regular expression;requirement;spectral leakage;throughput;welch's method;whole earth 'lectronic link	Tsern-Huei Lee;Nai-Lun Huang	2008	Security and Communication Networks	10.1002/sec.32	computer science;theoretical computer science;pattern matching;data mining;algorithm;string searching algorithm	Web+IR	-37.19873014044768	81.17213286897781	123404
1a328b4071c686ad5d885cd2b31ec3f56a51273c	a cdh-based ordered multisignature scheme in the standard model with better efficiency	public key standards aggregates computational efficiency australia educational institutions;digital signatures cryptography;stateless signatures cdh based ordered multisignature scheme digital signature scheme ordinary multisignature scheme cdh assumption random oracles waters hash function	An ordered multisignature scheme is a digital signature scheme which guarantees the signing order among a group of signers in addition to an improvement of efficiency provided by an ordinary multisignature scheme. In this primitive, Yanai et al. proposed an efficient scheme under only standard assumptions, i.e., the CDH assumption without random oracles, and their scheme is the first one whose number of bilinear maps and number of elements of public keys are independent of both the security level and the number of the signers. However, their scheme utilizes the Waters hash function and so its size of a system parameter shared between signers is quite large. In this work, we propose a more efficient CDH-based scheme without the random oracles by adopting a stateful signature. The size of a system parameter of our scheme is seven elements in bilinear groups while that of the previous works using stateless signatures is at least 160 elements. We show that in practical applications, the security is not downgraded by our stateful setting.	bilinear filtering;computational diffie–hellman assumption;digital signature;hash function;map;multisignature;oracle machine;state (computer science);stateful firewall;stateless protocol;type signature	Naoto Yanai;Masahiro Mambo;Eiji Okamoto	2014	2014 International Symposium on Information Theory and its Applications		mathematics;distributed computing;internet privacy;computer security	Crypto	-40.59979849634691	75.717475818411	123430
33aad7af83a61f33915079dd46d7b727d116751c	branching heuristics in differential collision search with applications to sha-512		In this work, we present practical semi-free-start collisions for SHA-512 on up to 38 (out of 80) steps with complexity 2. The best previously published result was on 24 steps. The attack is based on extending local collisions as proposed by Mendel et al. in their Eurocrypt 2013 attack on SHA-256. However, for SHA-512, the search space is too large for direct application of these techniques. We achieve our result by improving the branching heuristic of the guess-and-determine approach to find differential characteristics and conforming message pairs. Experiments show that for smaller problems like 27 steps of SHA-512, the heuristic can also speed up the collision search by a factor of 2.	boolean satisfiability problem;collision attack;differential cryptanalysis;eurocrypt;guess value;hash function;heuristic (computer science);high- and low-level;randomized algorithm;sha-2;search algorithm;semiconductor industry;solver	Maria Eichlseder;Florian Mendel;Martin Schläffer	2014		10.1007/978-3-662-46706-0_24	mathematical optimization;combinatorics;theoretical computer science;mathematics	Crypto	-37.03790601537913	81.3416933497299	123450
766b9b6b3e0115b45f7bdb5d0c0907cb1b1eec65	security of grouping-proof authentication protocol for distributed rfid systems		Liu et al. proposed a grouping-proof authentication protocol (GUPA) for distributed radio frequency identification systems. At the same time, Liu et al. claimed that GUPA can resist the well-known attacks such as replay, forgery, tracking, and denial of proof. However, we report that, according to Liu et al.’s assumption of the attack ability, the attacker is able to compromise all secrets by the man-in-the-middle (MIM) attacks. Although the MIM attacks were not explicitly evaluated by GUPA, the attacker can easily launch replay, forgery, tracking, and denial of proof when he knows all secrets of GUPA. That is, the lethal security flaws exist in GUPA. We also suggest employing the cryptographic hash function to protect the secrets in GUPA. Our security analysis of GUPA will be beneficial to the design of the robust grouping-proof authentication protocols in the future.	authentication protocol;cryptographic hash function;man-in-the-middle attack;radio frequency;radio-frequency identification;whole earth 'lectronic link	Da-Zhi Sun;Yi Mu	2018	IEEE Wireless Communications Letters	10.1109/LWC.2017.2770123	protected extensible authentication protocol;otway–rees protocol;distributed system security architecture;computer security;challenge-handshake authentication protocol;lightweight extensible authentication protocol;computer network;mathematics;challenge–response authentication;authentication protocol;ssliop	Security	-44.50467604409275	74.92436330706087	123462
7b3d3005c47d3184bd863d48a4c961938d7534af	provable security of digital signatures in the tamper-proof device model	digital signature;provable security		digital signature;provable security	Nick Varnovsky	2008	IACR Cryptology ePrint Archive		digital signature;provable security	Crypto	-42.02902784160137	77.06706773863685	123569
7a652182aad35f3c5c45253490b08f2cece1ed6d	performance analysis of the simple lightweight authentication protocol	authentication;side effect;theoretical analysis;rfid;performance analysis;radio frequency identification;point of view;lightweight protocol;simulation environment;authentication protocol	Radio frequency identification technology is becoming ubiquitous and as an unfortunate side effect, more and more authentication solutions come to light that have plenty of security issues to deal with.  In our former contribution we introduced a solely hash-based secure authentication algorithm that is capable of providing protection against most of the well-known attacks and performs exceptionally well even in very large systems. We gave a theoretical analysis of the SLAP protocol in the point of view of security and performance.  In this paper we illustrate the proposed protocol's performance characteristics with measurements carried out in a simulation environment and compare with the theoretical results. We show the effects of numerous attacks and the system's different parameters on the authentication time. Finally, we examine the performance of two other protocols chosen from the literature in order to compare with SLAP algorithm and give proper explanation for the differences between them.	algorithm;authentication protocol;communications protocol;computation;mutual authentication;point of view (computer hardware company);profiling (computer programming);radio frequency;radio-frequency identification;requirement;simulation;tag (metadata);tag cloud;whole earth 'lectronic link	Gyözö Gódor;Sándor Imre	2009		10.1145/1821748.1821786	radio-frequency identification;otway–rees protocol;reflection attack;telecommunications;challenge–response authentication;computer science;authentication protocol;lightweight extensible authentication protocol;wide mouth frog protocol;internet privacy;world wide web;computer security;computer network	Security	-46.77228745564557	76.28749679795787	123671
ada76f083b28bb6bf7cafb028adcd4146f8ba230	rectangle and impossible-differential cryptanalysis on versions of forkaes		The rapid distribution of lightweight devices raised the demand for efficient encryption and authenticated encryption schemes for small messages. For this purpose, Andreeva et al. recently proposed forkciphers, which fork the middle state within a cipher and encrypt it twice further under two smaller independent permutations. So, forkciphers can produce two output blocks which can allow to authenticate and encrypt small messages more efficiently. As instance of particular interest, Andreeva et al. proposed ForkAES, a tweakable forkcipher based on the AES-128 round function, which forks the state after five out of ten rounds. While their authenticated encrypted schemes were accompanied by proofs, the security discussion for ForkAES could not be covered in their work, and founded on existing results on the AES and KIASU-BC; so, the study of advanced differential attacks remained to be filled by the community. This work tries to foster the understanding of the security of ForkAES. It outlines a rectangle and an impossible-differential attack on nine rounds in the single-key related-tweak model; moreover, it describes a rectangle attack on ten rounds for a fraction of approximately 2 keys. We emphasize that our results do not break ForkAES in the single-key setting, but shed more light on its security margin.	aes gene;appendix;authenticated encryption;authentication;block cipher mode of operation;boomerang attack;cutlery fork;exclusive or;fill;fork (software development);generic drugs;impossible differential cryptanalysis;increased prf activity [pe];key space (cryptography);meet-in-the-middle attack;neoplasm metastasis;orthopedic fork;outlines (document);primitive recursive function;relevance;scanning auger spectrometer (device);secure cryptoprocessor;small;version;weak key;message	Jannis Bossert;Eik List;Stefan Lucks	2018	IACR Cryptology ePrint Archive			Crypto	-35.88879897826038	77.95469503944415	123735
c6fd621f95d7d68aa0ae59ac0611dcbbe096c014	indifferentiability of 3-round even-mansour with random oracle key derivation		We revisit the t-round Even-Mansour (EM) scheme with random oracle key derivation previously considered by Andreeva et al. (CRYPTO 2013), namely, xork ◦Pt ◦ xork ◦ . . . ◦ xork ◦P2 ◦ xork ◦P1 ◦ xork, where P1, . . . ,Pt stand for t independent n-bit random permutations, xork is the operation of xoring with the n-bit round-key k = H(K) for a κ-to-n-bit bit random oracle H on a κ-bit main key K. For this scheme, Andreeva et al. provided an indifferentiability (from an ideal (κ, n)-cipher) proof for 5 rounds while they exhibited an attack for 2 rounds. Left open is the (in)differentiability of 3 and 4 rounds. We present a proof for the indifferentiability of 3 rounds and thus close the aforementioned gap. This also separates EM ciphers with non-invertible key derivations from those with invertible ones in the “full” indifferentiability setting. Prior work only established such a separation in the weaker sequentialindifferentiability setting (ours, DCC, 2015). Our results also imply 3-round EM indifferentiable under multiple random known-keys, partially settling a problem left by Cogliati and Seurin (FSE 2016). The key point for our indifferentiability simulator is to pre-emptively prepare some chains of ideal-cipherqueries to simulate the structures due to the related-key boomerang property in the 3-round case. The length of such chains has to be as large as the number of queries issued by the distinguisher. Thus the situation somehow resembles the context of hash-of-hash H considered by Dodis et al. (CRYPTO 2012). Besides, a technical novelty of our proof is the absence of the so-called distinguisher that completes all chains.	assertion (software development);binary prefix;boomerang;cipher;cycle (graph theory);emoticon;existential quantification;fast software encryption;gnutella2;key schedule;p3m;pseudocode;qp state machine frameworks;random oracle;related-key attack;route distinguisher;simulation;xfig	Chun Guo;Dongdai Lin	2016	IACR Cryptology ePrint Archive		discrete mathematics;key derivation function;random oracle;mathematics	Crypto	-37.3627598694278	77.28762907830463	124214
fd93db1c96bb26d6ada3e352c1a8123ff1eea8b8	on removing graded encodings from functional encryption		Functional encryption (FE) has emerged as an outstanding concept. By now, we know that beyond the immediate application to computation over encrypted data, variants with succinct ciphertexts are so powerful that they yield the full might of indistinguishability obfuscation (IO). Understanding how, and under which assumptions, such succinct schemes can be constructed has become a grand challenge of current research in cryptography. Whereas the first schemes were based themselves on IO, recent progress has produced constructions based on constant-degree graded encodings. Still, our comprehension of such graded encodings remains limited, as the instantiations given so far have exhibited different vulnerabilities. Our main result is that, assuming LWE, black-box constructions of sufficiently succinct FE schemes from constant-degree graded encodings can be transformed to rely on a much better-understood object — bilinear groups. In particular, under an über assumption on bilinear groups, such constructions imply IO in the plain model. The result demonstrates that the exact level of ciphertext succinctness of FE schemes is of major importance. In particular, we draw a fine line between known FE constructions from constant-degree graded encodings, which just fall short of the required succinctness, and the holy grail of basing IO on better-understood assumptions. In the heart of our result, are new techniques for removing ideal graded encoding oracles from FE constructions. Complementing the result, for weaker ideal models, namely the generic-group model and the random-oracle model, we show a transformation from collusion-resistant FE in either of the two models directly to FE (and IO) in the plain model, without assuming bilinear groups. ∗An extended abstract of this paper appears in the proceedings of EUROCRYPT 2017. †MIT, nirbitan@csail.mit.edu. Supported by NSF Grants CNS-1350619 and CNS-1414119, and the Defense Advanced Research Projects Agency (DARPA) and the U.S. Army Research Office under contracts W911NF-15-C-0226. Part of this research was done while visiting Tel Aviv University and supported by the Leona M. & Harry B. Helmsley Charitable Trust and Check Point Institute for Information Security. ‡UCSB, rachel.lin@cs.ucsb.edu. partially supported by NSF grants CNS-1528178 and CNS-1514526. §MIT, omerpa@gmail.com.	bilinear filtering;black box;character encoding;ciphertext indistinguishability;computation;cryptography;eurocrypt;functional encryption;generic group model;grand challenges;ibm notes;information security;learning with errors;oracle machine;random oracle	Nir Bitansky;Huijia Lin;Omer Paneth	2016		10.1007/978-3-319-56614-6_1	discrete mathematics;theoretical computer science;encryption;functional encryption;cryptography;computation;random oracle;computer science;comprehension;obfuscation	Crypto	-35.520654395323525	76.88129057683355	124484
b40920f9d77f92ce17df72e81955c58d2ca60f45	a first dfa on pride: from theory to practice	lightweight cryptography;pride;dfa;em fault attacks	Abstract. PRIDE is one of the most efficient lightweight block cipher proposed so far for connected objects with high performance and lowresource constraints. In this paper we describe the first ever complete Differential Fault Analysis against PRIDE. We describe how fault attacks can be used against implementations of PRIDE to recover the entire encryption key. Our attack has been validated first through simulations, and then in practice on a software implementation of PRIDE running on a device that could typically be used in IoT devices. Faults have been injected using electromagnetic pulses during the PRIDE execution and the faulty ciphertexts have been used to recover the key bits. We also discuss some countermeasures that could be used to thwart such attacks.	32-bit;apply;block cipher;fault (technology);key (cryptography);revision control system;substitution-permutation network	Benjamin Lac;Marc Beunardeau;Anne Canteaut;Jacques J. A. Fournier;Renaud Sirdey	2016		10.1007/978-3-319-54876-0_17	direct fluorescent antibody;simulation;computer science;internet privacy;computer security	Security	-35.04518881237694	81.05630094476986	124650
4fce32bb106ffa99685c912d38243fbf1a4901a2	key distribution scheme using matched filter resistant against dos attack	wireless lan security;protocols;ieee standards;wireless lan ieee standards matched filters telecommunication security;authentication;dictionary attack;programmable control;computer crime;key distribution scheme;phase shift keying;cipher;cryptography;telecommunication security;matched filters;ieee 802 11i;wireless lan;matched filter;ieee 802 11i key distribution scheme matched filter dos attack dictionary attack wireless lan security;security;matched filter key distribution cipher dos attack;key distribution;matched filters computer crime programmable control phase shift keying security authentication protocols cryptography wireless lan costs;dos attack	The vulnerabilities, e.g., DoS attack or dictionary attack, are shown in 4-way handshake which is the re- key protocol used in wireless LAN security standard IEEE 802.11i. And the countermeasures against these are already proposed. In this paper, we propose key distribution scheme using matched filter. This paper shows that our proposal improves the resistance against DoS attack with less computational overhead compared with previous approaches, and is also effective against dictionary attack.	countermeasure (computer);denial-of-service attack;dictionary attack;ieee 802.11i-2004;key distribution;matched filter;overhead (computing);wireless security	Ryuzou Nishi;Yoshiaki Hori;Kouichi Sakurai	2008	22nd International Conference on Advanced Information Networking and Applications - Workshops (aina workshops 2008)	10.1109/WAINA.2008.180	telecommunications;computer science;information security;matched filter;computer security;computer network	Security	-45.708911334425565	74.91536184689284	124881
4829a89ac6925d4a7b6546a7c0cd1e1e83e6b6d6	constructing elliptic curve cryptosystems in characteristic 2	elliptic curve;finite field;elliptic curve cryptosystem;diffie hellman	Since the group of an elliptic curve defined over a finite field Fq, was proposed for Diffie-Hellman type cryptosystems in [7] and [15], some work on implementation has been done using special types of elliptic curves for which the order of the group is trivial to compute ([2], [13]). A consideration which discourages the use of an arbitrary elliptic curve is that one needs Schoof’s algorithm [16] to count the order of the corresponding group, and this algorithm, in addition to being rather complicated, has running time O(log9 q) for an elliptic curve defined over Fq. Thus, in applications of elliptic curves where one needs extremely large q — for example, the original version of the elliptic curve primality test ([4], [11]) — this algorithm is too time-consuming.	cryptosystem	Neal Koblitz	1990		10.1007/3-540-38424-3_11	supersingular elliptic curve;jacobian curve;lenstra elliptic curve factorization;elliptic curve digital signature algorithm;tripling-oriented doche–icart–kohel curve;schoof–elkies–atkin algorithm;hyperelliptic curve cryptography;diffie–hellman key exchange;curve25519;edwards curve;mathematics;elliptic curve cryptography;hessian form of an elliptic curve;elliptic curve;elliptic curve point multiplication;finite field;schoof's algorithm	Crypto	-39.062207504805	80.0701633921412	124967
53c625b4662ffb88c542fa8b089f6c01920ab512	statistical integral distinguisher with multi-structure and its application on aes-like ciphers	statistical integral model;multi-structure;secret s-box;secret-key;known-key;aes-like cipher;94-xx;94a60	Integral attack is one of the most powerful tools in the field of symmetric ciphers. In order to reduce the time complexity of original integral one, Wang et al. firstly proposed a statistical integral distinguisher at FSE’16. However, they don’t consider the cases that there are several integral properties on output and multiple structures of data should be used at the same time. In terms of such cases, we put forward a new statistical integral distinguisher, which enables us to reduce the data complexity comparing to the traditional integral ones under multiple structures. As illustrations, we use it into the known-key distinguishers on AES-like ciphers including AES and the permutations of Whirlpool, PHOTON and Grøstl-256 hash functions based on the Gilbert’s work at ASIACRYPT’14. These new distinguishers are the best ones comparing with previous ones under known-key setting. Moreover, we propose a secret-key distinguisher on 5-round AES under chosen-ciphertext mode. Its data, time and memory complexities are 2114.32 chosen ciphertexts, 2110 encryptions and 233.32 blocks. This is the best integral distinguisher on AES with secret S-box under secret-key setting so far.	64-bit computing;8-bit;academy;block size (cryptography);byte;chosen-ciphertext attack;cipher;ciphertext;column (database);emoticon;encryption;exclusive or;experiment;gilbert cell;hash function;integral cryptanalysis;key (cryptography);known-key distinguishing attack;modulo operation;nibble;polynomial;public-key cryptography;randomness;route distinguisher;s-box;sandy bridge;symmetric-key algorithm;the matrix;theory;time complexity;wang tile;xfig	Tingting Cui;Huaifeng Chen;Sihem Mesnager;Ling Sun;Meiqin Wang	2018	Cryptography and Communications	10.1007/s12095-018-0286-5	permutation;discrete mathematics;time complexity;mathematics;whirlpool;hash function	Crypto	-38.049250147710595	81.26651372432212	124984
33844557b20dbf2cf829781d52b15e69698aba6f	a collision-resistance hash function diha2			collision resistance;hash function	Xigen Yao	2009	IACR Cryptology ePrint Archive		discrete mathematics;collision resistance;sha-2;collision attack;double hashing;hash chain;rolling hash;mdc-2;hash buster;mathematics	Crypto	-40.36490672034666	80.11906231292251	125092
b59748df58ad52c2e9a63d034d03385b3626cd1f	secure communication using qubits	data security.;quantum cryptography;key distribution;it security;data security;one time pad;secure communication;quantum channel	A two-layer quantum protocol for secure transmission of data using qubits is pre- sented. The protocol is an improvement over the BB84 QKD protocol. BB84, in con- junction with the one-time pad algorithm, has been shown to be unconditionally secure. However it suffers from two drawbacks: (1) Its security relies on the assumption that Alice's qubit source is perfect in the sense that it does not inadvertently emit multiple copies of the same qubit. A multi-qubit emission attack can be launched if this assump- tion is violated. (2) BB84 cannot transfer predetermined keys; the keys it can distribute are generated in the process. Our protocol does not have these drawbacks. As in BB84, our protocol requires an authenticated public channel so as to detect an intruder's interaction with the quantum channel, but unlike in symmetric-key cryptog- raphy, the confidentiality of transmitted data does not rely on a shared secret key.	qubit;secure communication	Saied Hosseini-Khayat;Iman Marvian	2005	CoRR		key distribution;bb84;shared secret;secure transmission;universal composability;discrete mathematics;theoretical computer science;quantum cryptography;distributed computing;mathematics;quantum key distribution;pre-shared key	NLP	-44.438541703210504	75.51101558476257	125352
12b5b8a90144e426305ba8f2b9a656c25eb77622	multidimensional bell inequalities and quantum cryptography		The laws of quantum physics allow the design of cryptographic protocols for which the security is based on physical principles. The main cryptographic quantum protocols are key distribution schemes, in which two parties generate a shared random secret string. The privacy of the key can be checked using Bell inequalities. However, the Bell inequalities initial purpose was a fundamental one, as they showed how quantum rules are incompatible with our intuition of reality.	bell state;bell's theorem;quantum cryptography	François Arnault	2015		10.1007/978-3-319-18681-8_1	bell test experiments	Crypto	-37.55896050938158	74.71204740139667	125425
3122fbcba7c3a11c648c4c93a44365c4180c822f	a posteriori openable public key encryption		We present a public key encryption primitive called A Posteriori Openable Public Key Encryption (APO-PKE). In addition to conventional properties of public key cryptosystems, our primitive allows each user, who has encrypted messages using different public keys, to create a special decryption key. A user can give this key to a judge to open all messages that have been encrypted in a chosen time interval with the public keys of the receivers. We provide a generic efficient construction, in the sense that the complexity of the special key generation algorithm and this key size are independent of the number of ciphertexts. We give security models for our primitive against chosen plaintext attack and analyze the security of our scheme in the random oracle model.	algorithm;cryptosystem;encryption;key generation;key size;plaintext;public-key cryptography;random oracle	Xavier Bultel;Pascal Lafourcade	2016		10.1007/978-3-319-33630-5_2	computer science;computer security model;theoretical computer science;computer security;key size;chosen-plaintext attack;public-key cryptography;random oracle;encryption;cryptosystem;key generation	Crypto	-40.839487114088975	75.49560517847655	125551
40eef1d3fd62509ed68995de7a7bb619d01de8f6	nlhb: a non-linear hopper-blum protocol	provable security;protocols;complexity theory;decoding;authentication;cryptographic protocols;protocols security authentication decoding radiofrequency identification linear code humans algorithm design and analysis resists rfid tags;linear codes;cryptographic protocol;rfid tag;resists;nlhb protocol;noised linear parities;linear codes decoding;rfid tags;radiofrequency identification cryptographic protocols decoding linear codes;cryptography;linear code;rfid;linear coding attacks;cryptographic protocol nlhb protocol hopper blum protocol noised linear parities authentication light weight applications rfid linear codes decoding linear coding attacks;humans;entropy;hopper blum protocol;light weight applications;security;algorithm design and analysis;radiofrequency identification;authentication protocol	The Hopper-Blum (HB) protocol, which uses noised linear parities of a shared key for authentication, has been proposed for light-weight applications such as RFID. Recently, algorithms for decoding linear codes have been specially designed for use in passive attacks on the HB protocol. These linear coding attacks have resulted in the need for long keys in the HB protocol, making the protocol too complex for RFID in some cases. In this work, we propose the NLHB protocol, which is a non-linear variant of the HB protocol. The non-linearity is such that passive attacks on the NLHB protocol continue to be provably hard by reduction. However, the linear coding attacks cannot be directly adapted to the proposed NLHB protocol because of the non-linearity. Hence, smaller key sizes appear to be sufficient in the NLHB protocol for the same level of security as the HB protocol. We construct specific instances of the NLHB protocol and show that they can be significantly less complex for implementation than the HB protocol, in spite of the non-linearity. Further, we propose an extension, called the NLHB+ protocol, that is provably secure against a class of active attack models.	authentication;blum axioms;communications protocol;hopper;key size;linear code;nonlinear system;provable security;symmetric-key algorithm	Mukundan Madhavan;Andrew Thangaraj;Yogesh Sankarasubramaniam;Kapali Viswanathan	2010	2010 IEEE International Symposium on Information Theory	10.1109/ISIT.2010.5513440	radio-frequency identification;otway–rees protocol;computer science;information security;theoretical computer science;cryptographic protocol;distributed computing;computer security	Security	-40.29510847530432	78.02933814886748	125637
77c8dce488de0b2f1877173be4e4edd954315ad2	concurrent non-malleable commitments from any one-way function	one way function	We show the existence of concurrent non-malleable commitments based on the existence of one-way functions. Our proof of security only requires the use of black-box techniques, and additionally provides an arguably simplified proof of the existence of even stand-alone secure non-malleable commitments.	black box;one-way function	Huijia Lin;Rafael Pass;Muthuramakrishnan Venkitasubramaniam	2008		10.1007/978-3-540-78524-8_31	discrete mathematics;computer science;mathematics;one-way function;algorithm	Theory	-37.90303913668914	75.8962419473106	126117
75012709e3800a86ab7e02214297125316d38d25	short lattice signatures with constant-size public keys	variant sis;security proof;sis;lattice based signature;lattice	A digital signature scheme allows a signer to sign electronic messages using his or her secret key, and any verifier can validate the correctness according to a given verification procedure. Although a variety of lattice-based signature schemes have been proposed in the past few years, there does not exist a scheme that has short signatures and constant-size public keys simultaneously. In this paper, we propose a new method for constructing short lattice signatures with constant-size public keys in the standard model. In our scheme, each signature contains a low-dimensional lattice vector and the public key only contains three matrices plus a vector. Compared with previous constructions, our scheme is very simple and does not require any complex homomorphic computation. In order for security proof to work, we introduce a new hard lattice problem, called variant small integer solution (Variant-SIS), and give the security reduction from small integer solution to Variant-SIS. Then we define a family of hash functions based on the hardness of Variant-SIS and prove its security properties, including one-wayness and collision resistance. As a matter of independent interest, the proposed hard problem may be useful in many other lattice-based cryptographic constructions. Last, the comparison with similar works demonstrates the superiority of our scheme. Copyright © 2016 John Wiley & Sons, Ltd.	collision resistance;computation;computational complexity theory;correctness (computer science);cryptographic protocol;digital signature;hash function;john d. wiley;key (cryptography);lattice model (finance);lattice problem;overhead (computing);provable security;public-key cryptography;type signature	Dong Xie;Haipeng Peng;Lixiang Li;Yixian Yang	2016	Security and Communication Networks	10.1002/sec.1712	lattice;computer security	Crypto	-38.93301721645683	77.94330525164045	126169
8ee4caa5d2dec03a77e452305b65d2495242f45b	interpolation of the elliptic curve diffie-hellman mapping	elliptic curve;polynomial interpolation;discrete logarithm;corps fini;courbe elliptique;finite field;key exchange;curva eliptica;criptografia;cryptography;campo finito;cryptographie;lower bound;diffie hellman	We prove lower bounds on the degree of polynomials interpolating the Diffie–Hellman mapping for elliptic curves over finite fields and some related mappings including the discrete logarithm. Our results support the assumption that the elliptic curve Diffie–Hellman key exchange and related cryptosystems are secure.	cryptosystem;diffie–hellman key exchange;diffie–hellman problem;discrete logarithm;interpolation;polynomial	Tanja Lange;Arne Winterhof	2003		10.1007/3-540-44828-4_7	discrete logarithm;supersingular elliptic curve;mathematical analysis;discrete mathematics;jacobian curve;key exchange;twists of curves;polynomial interpolation;tripling-oriented doche–icart–kohel curve;cryptography;counting points on elliptic curves;mathematics;elliptic curve cryptography;hessian form of an elliptic curve;elliptic curve;modular elliptic curve;elliptic curve point multiplication;finite field;schoof's algorithm;algebra	Crypto	-39.84861815266017	80.51771872021075	126599
21cc5e46e1ed99da9c476c0e995ccb771a975d1e	evolving dpa-resistant boolean functions	part of book or chapter of book	Boolean functions are important primitives in cryptography. Accordingly, there exist numerous works on the methods of constructions of Boolean functions. However, the property specifying the resistance of Boolean functions against Differential Power Analysis (DPA) attacks was until now scarcely investigated and only for S-boxes. Here, we evolve Boolean functions that have higher resistance to DPA attacks than others published before by using two well-known evolutionary computation methods where genetic programming shows best performance.	baseline (configuration management);cartesian closed category;cryptography;evolutionary algorithm;evolutionary computation;existential quantification;experiment;genetic algorithm;genetic programming;nonlinear system;reference work;s-box	Stjepan Picek;Lejla Batina;Domagoj Jakobovic	2014		10.1007/978-3-319-10762-2_80	computer science;algorithm;cognitive science	Crypto	-37.249264516078554	82.21802144687811	126731
5dffae0114551b01a1aeb51f17e7c95c86a25968	a note on some algebraic trapdoors for block ciphers		We provide sufficient conditions to guarantee that a translation based cipher is not vulnerable with respect to the partition-based trapdoor. This trapdoor has been introduced, recently, by Bannier et al. (2016) and it generalizes that introduced by Paterson in 1999. Moreover, we discuss the fact that studying the group generated by the round functions of a block cipher may not be sufficient to guarantee security against these trapdoors for the cipher.	block cipher;linear algebra	Marco Calderini	2018	Adv. in Math. of Comm.	10.3934/amc.2018030	block size	Crypto	-38.92417927321234	78.12508632551385	126789
40445470ba25c8f32d7777fb860e8c5e98ec7e8f	towards narrative authentication: or, against boring authentication	narrative;text adventures;authentication	In this paper we propose that what-you-know authentication schemes be built using narrative elements. Specifically, we propose that stories be used as the basis of memory-based user authentication, rather than use a fixed string as the secret for authentication (as is the case with text passwords and PINs). The insight here is that secure text passwords are ``boring'' and, hence, are hard to remember. Narrative is, in contrast, extremely memorable, forming the basis of much of human communication. We present a simple, implementable scheme for narrative authentication using text adventures. We then also examine other strategies for generating and testing knowledge of narrative.	authentication;password;personal identification number	Anil Somayaji;David Mould;Carson Brown	2013		10.1145/2535813.2535820	challenge–response authentication;computer science;multi-factor authentication;authentication;narrative;internet privacy;world wide web;computer security	Security	-43.868704371041325	80.20815926674489	126818
541bc1ef5ebc39068df51bfe54d646ed8465843b	a cost-effective pay-per-multiplication comparison method for millionaires	encryption;oblivious transfer;calculo automatico;computing;calcul automatique;cryptage;multiple comparisons;criptografia;cryptography;subasta;bidding;cost effectiveness;cryptographie;protocole calcul crypte;enchere;modular multiplication	Based on the quadratic residuosity assumption we present a non-interactive crypto-computing protocol for the greater-than function, i.e., a non-interactive procedure between two parties such that only the relation of the parties’ inputs is revealed. In comparison to previous solutions our protocol reduces the number of modular multiplications significantly. We also discuss applications to conditional oblivious transfer, private bidding and the millionaires’ problem.	interactivity;oblivious transfer;quadratic residue;quadratic residuosity problem;secure multi-party computation	Marc Fischlin	2001		10.1007/3-540-45353-9_33	computing;bidding;computer science;cryptography;theoretical computer science;oblivious transfer;mathematics;distributed computing;computer security;encryption;algorithm	Crypto	-42.32929502533855	77.75320682837777	126958
fa6021a62532fd0c8607eedb2c17488ccb2a84d5	constructing witness prf and offline witness encryption without multilinear maps		Witness pseudorandom functions (witness PRFs), introduced by Zhandry [Zha16], was defined for an NP language L and generate a pseudorandom value for any instance x. The same pseudorandom value can be obtained efficiently using a valid witness w for x ∈ L. Zhandry built a subset-sum encoding scheme from multilinear maps and then converted a relation circuit corresponding to an NP language L to a subset-sum instance to achieve a witness PRF for L. The main goal in developing witness PRF in [Zha16] is to avoid obfuscation from various constructions of cryptographic primitives. Reliance on cryptographic tools built from multilinear maps may be perilous as existing multilinear maps are still heavy tools to use and suffering from many non-trivial attacks. In this work, we give constructions of the following cryptographic primitives without using multilinear maps and instantiating obfuscation from randomized encoding: – We construct witness PRFs using a puncturable pseudorandom function and subexponentially secure randomized encoding scheme in common reference string (CRS) model. A sub-exponentially secure randomized encoding scheme in CRS model can be achieved from a sub-exponentially secure public key functional encryption scheme and learning with error assumptions with sub-exponential hardness. – We turn our witness PRF into a multi-relation witness PRF where one can use the scheme with a class of relations related to an NP language. – Furthermore, we construct an offline witness encryption scheme using any extractable witness PRF. The offline witness encryption scheme of Abusalah et al. [AFP16] was built from a plain public-key encryption, a statistical simulation-sound non-interactive zero knowledge (SSS-NIZK) proof system and obfuscation. In their scheme, a(n) SSSNIZK proof is needed for the encryption whose efficiency depends on the underlying public key encryption. We replace SSS-NIZK by extractable witness PRF and construct an offline witness encryption scheme. More precisely, our scheme is based on a public-key encryption, a witness PRF and employs a sub-exponentially secure randomized encoding scheme in CRS model instantiating obfuscation. Our offline witness encryption can be turned into an offline functional witness encryption scheme where decryption releases a function of a message and witness as output.	common reference string model;cryptographic primitive;functional encryption;interactivity;l (complexity);learning with errors;line code;mind map;non-interactive zero-knowledge proof;obfuscation (software);one-way function;online and offline;polynomial;primitive recursive function;proof calculus;pseudorandom function family;pseudorandomness;public-key cryptography;randomized algorithm;randomness extractor;sss*;simulation;subset sum problem;time complexity;turing machine	Tapas Pal;Ratna Dutta	2018	IACR Cryptology ePrint Archive		witness;multilinear map;encryption;theoretical computer science;computer science	Crypto	-38.344762653078064	76.4155148057303	127346
ba3cb1a74e82371ea40828a2f211eb6a3f9759ea	security of number theoretic public key cryptosystems against random attack, ii			cryptosystem;public-key cryptography	Bob Blakley;G. R. Blakley	1979	Cryptologia	10.1080/0161-117991853774	arithmetic;discrete mathematics;computer science;mathematics;safe prime;computer security	Crypto	-40.00218192779072	80.21355410169102	127414
f325adb24c8351686d2a6faf0963c45e1fb81bc6	improved identity-based identification and signature schemes using quasi-dyadic goppa codes		In this paper, we present an improved version of an identity-based identification scheme based on error-correcting codes. Our scheme combines the Courtois-Finiasz-Sendrier signature scheme using quasi-dyadic codes (QD-CFS) proposed in [2] and the identification scheme by Stern [18]. Following the construction proposed in [5], we obtain an identity-based identification scheme which has the advantage to reduce a public data size, the communication complexity and the signature length.	climate forecast system;coding theory;communication complexity;cryptography;digital signature;dyadic transformation;error detection and correction;filesystem-level encryption;forward error correction;goppa code;identification scheme;information privacy;quantum dot	Sidi Mohamed El Yousfi Alaoui;Pierre-Louis Cayrel;Mohammed Meziani	2011		10.1007/978-3-642-23141-4_14	goppa code	Crypto	-40.928183182506324	79.08334587536987	127461
c00a6b120e4291b208ae5ae976580db895a02709	a strategy for finding roots of multivariate polynomials with new applications in attacking rsa variants	desciframiento;distributed system;systeme reparti;coppersmith s method;rsa variants;temps polynomial;lattices;securite informatique;decryptage;chino;cryptage rsa;rsa ciphering;computer security;cryptanalysis;enrejado;sistema repartido;multivariate polynomial;treillis;cifrado rsa;criptografia;cryptography;seguridad informatica;decryption;polynomial time;cryptographie;chinois;chinese;small roots;lattice;tiempo polinomial	We describe a strategy for finding small modular and integer roots of multivariate polynomials using lattice-based Coppersmith techniques. Applying our strategy, we obtain new polynomial-time attacks on two RSA variants. First, we attack the Qiao-Lam scheme that uses a Chinese Remaindering decryption process with a small difference in the private exponents. Second, we attack the so-called Common Prime RSA variant, where the RSA primes are constructed in a way that circumvents the Wiener attack.	cryptography;lam/mpi;polynomial;rsa (cryptosystem);roots;time complexity	Ellen Jochemsz;Alexander May	2006		10.1007/11935230_18	arithmetic;discrete mathematics;computer science;lattice;mathematics;computer security;algorithm;algebra	Crypto	-40.67210965868409	79.57176499883533	127473
8b3d909e1646dd9318fbd850c3360de9a330df18	leakage-resilient non-interactive key exchange in the continuous-memory leakage setting		Recently, Chakraborty et al. (Cryptoeprint:2017:441) showed a novel approach of constructing several leakage-resilient cryptographic primitives by introducing a new primitive called leakageresilient non-interactive key exchange (LR-NIKE). Their construction of LR-NIKE was only in the bounded-memory leakage model, and they left open the construction of LR-NIKE in continuous-memory leakage model. In this paper we address that open problem. Moreover, we extend the continuous-memory leakage model by addressing more realistic after-the-fact leakage. The main ingredients of our construction are a leakage-resilient storage scheme and a refreshing protocol (Dziembowski and Faust, Asiacrypt 2011) and a (standard) chameleon hash function (CHF), equipped with an additional property of oblivious sampling, which we introduce. We observe that the present constructions of CHF already satisfies our new notion. Further, our protocol can be used as a building block to construct leakage-resilient public-key encryption schemes, interactive key exchange and low-latency key exchange protocols in the continuous-memory leakage model, following the approach of Chakraborty et al. (Cryptoeprint:2017:441).	asiacrypt;cryptographic hash function;cryptographic primitive;encryption;interactivity;key exchange;lr parser;public-key cryptography;sampling (signal processing);spectral leakage	Suvradip Chakraborty;Janaka Alawatugoda;C. Pandu Rangan	2017		10.1007/978-3-319-68637-0_10	open problem;theoretical computer science;cryptographic primitive;hash function;distributed computing;faust;key exchange;leakage (electronics);encryption;computer science;memory leak	Crypto	-39.269188610105104	76.21694510186067	127524
7c27a174e0419d9f2076a3c29d06af05abef1cff	the past, evolving present, and future of the discrete logarithm		The first practical public key cryptosystem ever published, the Diffie-Hellman key exchange algorithm, relies for its security on the assumption that discrete logarithms are hard to compute. This intractability hypothesis is also the foundation for the security of a large variety of other public key systems and protocols. Since the introduction of the Diffie-Hellman key exchange more than three decades ago, there have been substantial algorithmic advances in the computation of discrete logarithms. However, in general the discrete logarithm problem is still considered to be hard. In particular, this is the case for the multiplicative group of finite fields with medium to large characteristic and for the additive group of a general elliptic curve. This paper presents a current survey of the state of the art concerning discrete logarithms and their computation.	computation;cryptosystem;diffie–hellman key exchange;discrete logarithm;greedy algorithm;public-key cryptography;utility functions on indivisible goods	Antoine Joux;Andrew M. Odlyzko;Cécile Pierrot	2014		10.1007/978-3-319-10683-0_2	discrete mathematics;logarithm;public-key cryptography;cryptosystem;discrete logarithm;key exchange;mathematics	Crypto	-39.780824965410126	78.71955570737893	127534
33b97bdde532408071f9771a0a75229b30afaf87	on the power of nonlinear secret-sharing	cryptography;access structure;authorized sets;nonlinear secret-sharing;privacy;statistical privacy;secret sharing	A secret-sharing scheme enables a dealer to distribute a secret among n parties such that only some predefined authorized sets of parties will be able to reconstruct the secret from their shares. The (monotone) collection of authorized sets is called an access structure , and is freely identified with its characteristic monotone function f : {0, 1}n → {0, 1}. A family of secret-sharing schemes is called efficient if the total length of then shares is polynomial inn. Most previously known secret-sharing schemes belonged to a class of linearschemes, whose complexity coincides with the monotone span program size of their access structure. Prior to this work there was no evidence that nonlinear schemes can be significantly more efficient than linear schemes, and in particular there were no candidates for schemes efficiently realizing access structures which do not lie in NC. The main contribution of this work is the construction of two efficient nonlinear schemes: (1) A scheme with perfect privacy whose access structure is conjectured not to lie in NC; (2) A scheme with statistical privacy whose access structure is conjectured not to lie in P/poly. Another contribution is the study of a class of nonlinear schemes, termed quasi-linearschemes, obtained by composinglinear schemes over different fields. We show that while these schemes are possibly (super-polynomially) more powerful than linear schemes, they cannot efficiently realize access structures outside NC.	access structure;authorization;information-theoretic security;nonlinear system;p/poly;polynomial;secret sharing;monotone	Amos Beimel;Yuval Ishai	2001	IACR Cryptology ePrint Archive		discrete mathematics;cryptography;theoretical computer science;mathematics;computer security;statistics	Crypto	-39.351792082864606	74.68225002575285	127719
a0bbc96a0c851fc296cca7e66231bcdcc44af1a5	improving the sphinx mix network		Secure mix networks consider the presence of multiple nodes that relay encrypted messages from one node to another in such a way that anonymous communication can be achieved. We consider the Sphinx mix formatting protocol by Danezis and Goldberg (IEEE Security and Privacy 2009), and analyze its use of symmetric-key cryptographic primitives. We scrutinize the reliance on multiple distinct primitives, as well as the use of the ancient LIONESS cipher, and suggest various paths towards improving the security and efficiency of the protocol.	cipher;cryptography;encryption;mix network;relay;sphinx;symmetric-key algorithm	Filipe Beato;Kimmo Halunen;Bart Mennink	2016		10.1007/978-3-319-48965-0_46	cryptographic primitive;theoretical computer science;cipher;disk formatting;mix network;sphinx;encryption;computer science;authenticated encryption;distributed computing	Security	-43.499722627073304	76.15379057312485	127783
5b561189081c9f506b7da1ae5dc4ac3cd8ffe42a	efficient conditional proxy re-encryption with chosen-ciphertext security	proxy re encryption;chosen ciphertext security;conditional proxy re encryption;random oracle model;random oracle;diffie hellman	Recently, a variant of proxy re-encryption, named conditional proxy re-encryption (C-PRE), has been introduced. Compared with traditional proxy re-encryption, C-PRE enables the delegator to implement fine-grained delegation of decryption rights, and thus is more useful in many applications. In this paper, based on a careful observation on the existing definitions and security notions for C-PRE, we reformalize more rigorous definition and security notions for C-PRE. We further propose a more efficient C-PRE scheme, and prove its chosenciphertext security under the decisional bilinear Diffie-Hellman (DBDH) assumption in the random oracle model. In addition, we point out that a recent C-PRE scheme fails to achieve the chosen-ciphertext security.	bilinear filtering;ciphertext;decisional diffie–hellman assumption;diffie–hellman problem;encryption;proxy re-encryption;random oracle	Jian Weng;Yanjiang Yang;Qiang Tang;Robert H. Deng;Feng Bao	2009		10.1007/978-3-642-04474-8_13	internet privacy;world wide web;computer security	Security	-40.05768314134156	75.6803325443736	127786
6a4396108d3c6ff6fe7723e9f88a63661316d4bc	on distributional collision resistant hashing		Collision resistant hashing is a fundamental concept that is the basis for many of the important cryptographic primitives and protocols. Collision resistant hashing is a family of compressing functions such that no efficient adversary can find any collision given a random function in the family. In this work we study a relaxation of collision resistance called distributional collision resistance, introduced by Dubrov and Ishai (STOC ’06). This relaxation of collision resistance only guarantees that no efficient adversary, given a random function in the family, can sample a pair (x, y) where x is uniformly random and y is uniformly random conditioned on colliding with x. Our first result shows that distributional collision resistance can be based on the existence of multi -collision resistance hash (with no additional assumptions). Multi-collision resistance is another relaxation of collision resistance which guarantees that an efficient adversary cannot find any tuple of k > 2 inputs that collide relative to a random function in the family. The construction is non-explicit, non-black-box, and yields an infinitely-often secure family. This partially resolves a question of Berman et al. (EUROCRYPT ’18). We further observe that in a black-box model such an implication (from multi-collision resistance to distributional collision resistance) does not exist. Our second result is a construction of a distributional collision resistant hash from the average-case hardness of SZK. Previously, this assumption was not known to imply any form of collision resistance (other than the ones implied by one-way functions). ∗Cornell Tech, New York, NY 10044, USA. Email: komargodski@cornell.edu. Supported in part by a Packard Foundation Fellowship and by an AFOSR grant FA9550-15-1-0262. †Department of Computer Science and Applied Mathematics, Weizmann Institute of Science Israel, Rehovot 76100, Israel. Email: eylon.yogev@weizmann.ac.il. Supported in part by a grant from the Israel Science Foundation (no. 950/16).	adversary (cryptography);best, worst and average case;black box;collision resistance;computer science;cryptographic primitive;cryptography;email;eurocrypt;hash function;linear programming relaxation;one-way function;symposium on theory of computing	Ilan Komargodski;Eylon Yogev	2018	IACR Cryptology ePrint Archive	10.1007/978-3-319-96881-0_11	random function;theoretical computer science;cryptographic primitive;collision;hash function;adversary;computer science	Crypto	-35.38652446467551	76.82165996924957	127849
1bef21e4b2d52e24af23a88aec85350af27ad088	an effective defense against first party attacks in public-key algorithms	public key cryptography;first party attack defence;nist;encryption;identity based encryption;key generation performance;public key algorithms;public key;key generation performance first party attack defence public key algorithms user generated public key pairs user generated private key pairs cryptographic standards public key cryptography;space technology;entropy;hash function;user generated private key pairs;user generated public key pairs;read only memory;public key public key cryptography space technology identity based encryption read only memory entropy data security nist;cryptographic standards;data security	This paper describes a method for assuring that user-generated public and private key pairs are cryptographically strong. This assurance is achieved by limiting the number of attempts a user can make while generating the keys. Since it takes many billions of attempts to generate so-called “weak” keys, with any significant probability of success, our method precludes users from cheating. The described method has a potential positive impact on several evolving cryptographic standards, where the strength of the keys used with public key cryptography are a matter of major concern. It has no negative impact on key generation performance. The method is simple and straightforward, and it can be easily performed with just a few computational steps.	algorithm;certificate authority;computation;discrete logarithm;integer factorization;key generation;public-key cryptography;strong cryptography;user-generated content;weak key	Stephen M. Matyas;Allen Roginsky	1999		10.1109/CSAC.1999.816023	weak key;computer science;key management;internet privacy;public-key cryptography;key space;world wide web;computer security	Web+IR	-41.08059688654012	76.69818582490846	128128
24ad2ab0ecf19646f616eebd7d49035631b64246	key derivation without entropy waste		We revisit the classical problem of converting an imperfect source of randomness into a usable cryptographic key. Assume that we have some cryptographic application P that expects a uniformly random m-bit key R and ensures that the best attack (in some complexity class) against P (R) has success probability at most δ. Our goal is to design a key-derivation function (KDF) h that converts any random source X of min-entropy k into a sufficiently “good” key h(X), guaranteeing that P (h(X)) has comparable security δ′ which is ‘close’ to δ. Seeded randomness extractors provide a generic way to solve this problem for all applications P , with resulting security δ′ = O(δ), provided that we start with entropy k ≥ m + 2 log (1/δ) − O(1). By a result of Radhakrishnan and Ta-Shma, this bound on k (called the “RT-bound”) is also known to be tight in general. Unfortunately, in many situations the loss of 2 log (1/δ) bits of entropy is unacceptable. This motivates the study KDFs with less entropy waste by placing some restrictions on the source X or the application P . In this work we obtain the following new positive and negative results in this regard: • Efficient samplability of the source X does not help beat the RT-bound for general applications. This resolves the SRT (samplable RT) conjecture of Dachman-Soled et al. [DGKM12] in the affirmative, and also shows that the existence of computationally-secure extractors beating the RT-bound implies the existence of one-way functions. • We continue in the line of work initiated by Barak et al. [BDK11] and construct new informationtheoretic KDFs which beat the RT-bound for large but restricted classes of applications. Specifically, we design efficient KDFs that work for all unpredictability applications P (e.g., signatures, MACs, one-way functions, etc.) and can either: (1) extract all of the entropy k = m with a very modest security loss δ′ = O(δ · log (1/δ)), or alternatively, (2) achieve essentially optimal security δ′ = O(δ) with a very modest entropy loss k ≥ m + loglog (1/δ). In comparison, the best prior results from [BDK11] for this class of applications would only guarantee δ′ = O( √ δ) when k = m, and would need k ≥ m+ log (1/δ) to get δ′ = O(δ). • The weaker bounds of [BDK11] hold for a larger class of so-called “square-friendly” applications (which includes all unpredictability, but also some important indistinguishability, applications). Unfortunately, we show that these weaker bounds are tight for the larger class of applications. • We abstract out a clean, information-theoretic notion of (k, δ, δ′)-unpredictability extractors, which guarantee “induced” security δ′ for any δ-secure unpredictability application P , and characterize the parameters achievable for such unpredictability extractors. Of independent interest, we also relate this notion to the previously-known notion of (min-entropy) condensers, and improve the state-of-the-art parameters for such condensers. ∗New York Unviersity. E-mail: dodis@cs.nyu.edu. Research partially supported by gifts from VMware Labs and Google, and NSF grants 1319051, 1314568, 1065288, 1017471, 0845003. †Institute of Science and Technology Austria. E-mail:pietrzak@ist.ac.at ‡Northeastern University. E-mail: wichs@ccs.neu.edu. Research supported by NSF grant 1314722.	complexity class;cryptography;division algorithm;electronic signature;entropy (information theory);ibm notes;information theory;key (cryptography);key derivation function;maxima and minima;one-way function;randomness extractor	Yevgeniy Dodis;Krzysztof Pietrzak;Daniel Wichs	2013		10.1007/978-3-642-55220-5_6	discrete mathematics;theoretical computer science;key derivation function;randomness;cryptography;complexity class;random oracle;usable;hash function;key (cryptography);computer science	Crypto	-35.817134620774596	76.60943504684151	128164
74c79b44206bbaa719cc57cb45fba800317cd796	universally composable secure mobile agent computation	code calcul;provable security;distributed system;multiagent system;systeme reparti;informatique mobile;computation code;agent mobile;protocole transmission;complex network;agente movil;securite informatique;chaine caractere;gear;intelligence artificielle;computer security;protocolo transmision;codigo computacion;mobile agent system;sistema repartido;common reference string;criptografia;cryptography;seguridad informatica;cadena caracter;mobile software;artificial intelligence;cryptographie;engrenage;inteligencia artificial;mobile agent;sistema multiagente;mobile computing;universally composable;code mobile;systeme multiagent;character string;engranaje;transmission protocol	We study the security challenges faced by the mobile agent paradigm, where code travels and performs computations on remote hosts in an autonomous manner. We define universally composable security for mobile agent computation that is geared toward a complex networking environment where arbitrary protocol instances may be executing concurrently. Our definition provides security for all the participants in the mobile agent system: the originator as well as the hosts. Finally, under the assumption of a universally composable threshold cryptosystem, we present universally composable, multi-agent protocols with provable security against either static, semi-honest or static, malicious adversaries, according to our definition, where in the latter case we need to provide access to a common	autonomous robot;computation;malware;mobile agent;multi-agent system;programming paradigm;provable security;semiconductor industry;threshold cryptosystem;universal composability	Ke Xu;Stephen R. Tate	2004		10.1007/978-3-540-30144-8_26	gear;computer science;cryptography;artificial intelligence;theoretical computer science;operating system;provable security;mobile agent;database;distributed computing;programming language;mobile computing;computer security;complex network;algorithm	Security	-44.80315771315682	78.76988627169845	128435
8606ea3beec0c3fcba064c366b5b19aad5569363	semi-homomorphic encryption and multiparty computation	linear functionals;multiparty computation;point of view;information theoretic;arithmetic circuit;homomorphic encryption	An additively-homomorphic encryption scheme enables us to compute linear functions of an encrypted input by manipulating only the ciphertexts. We define the relaxed notion of a semi-homomorphic encryption scheme, where the plaintext can be recovered as long as the computed function does not increase the size of the input “too much”. We show that a number of existing cryptosystems are captured by our relaxed notion. In particular, we give examples of semi-homomorphic encryption schemes based on lattices, subset sum and factoring. We then demonstrate how semi-homomorphic encryption schemes allow us to construct an efficient multiparty computation protocol for arithmetic circuits, UC-secure against a dishonest majority. The protocol consists of a preprocessing phase and an online phase. Neither the inputs nor the function to be computed have to be known during preprocessing. Moreover, the online phase is extremely efficient as it requires no cryptographic operations: the parties only need to exchange additive shares and verify information theoretic MACs. Our contribution is therefore twofold: from a theoretical point of view, we can base multiparty computation on a variety of different assumptions, while on the practical side we offer a protocol with better efficiency than any previous solution.	computation;cryptography;cryptosystem;homomorphic encryption;integer factorization;lagrangian relaxation;linear function;plaintext;preprocessor;semiconductor industry;subset sum problem;theory;uc browser;utility functions on indivisible goods	Rikke Bendlin;Ivan Damgård;Claudio Orlandi;Sarah Zakarias	2010		10.1007/978-3-642-20465-4_11	discrete mathematics;40-bit encryption;homomorphic encryption;plaintext-aware encryption;computer science;theoretical computer science;mathematics;distributed computing;computer security;encryption;probabilistic encryption;algorithm	Crypto	-38.63616448433987	75.71557409452524	128934
a3a940262081eb73d6c82b19c5987d1c15a8b9e6	a comparative cost/security analysis of fault attack countermeasures	institutional repositories;tolerancia falta;occupation time;detection erreur;evaluation performance;attacks and countermeasures in hardware and software;deteccion error;security analysis;fedora;performance evaluation;encryption;contre mesure electronique;asymmetry;redundancia;correction erreur;evaluacion prestacion;cryptanalyse;securite informatique;metric;cifrado;attaque informatique;asymetrie;cost analysis;injection faute;vital;analisis costo;computer security;cryptanalysis;inyeccion falta;criptoanalisis;analyse cout;redundancy;temps occupation;contra medida electronica;diagnostic panne;cryptage;criptografia;cryptography;error correction;duplication;seguridad informatica;fault diagnostic;fault attack;fault tolerance;diagnostico pana;comparative study;tiempo ocupacion;duplicacion;computer attack;asimetria;ataque informatica;cryptographie;metrico;correccion error;error detection;electronic countermeasure;vtls;fault injection;tolerance faute;metrique;ils;redondance	Deliberate injection of faults into cryptographic devices is an effective cryptanalysis technique against symmetric and asymmetric encryption algorithms. To protect cryptographic implementations (e.g. of the recent AES which will be our running example) against these attacks, a number of innovative countermeasures have been proposed, usually based on the use of space and time redundancies (e.g. error detection/correction techniques, repeated computations). In this paper, we take the next natural step in engineering studies where alternative methods exist, namely, we take a comparative perspective. For this purpose, we use unified security and efficiency metrics to evaluate various recent protections against fault attacks. The comparative study reveals security weaknesses in some of the countermeasures (e.g. intentional malicious fault injection that are unrealistically modelled). The study also demonstrates that, if fair performance evaluations are performed, many countermeasures are not better than the naive solutions, namely duplication or repetition. We finally suggest certain design improvements for some countermeasures, and further discuss security/efficiency tradeoffs.	algorithm;computation;cryptanalysis;differential fault analysis;encryption;error detection and correction;fault injection;malware;public-key cryptography;software performance testing	Tal Malkin;François-Xavier Standaert;Moti Yung	2006		10.1007/11889700_15	simulation;error detection and correction;telecommunications;computer science;computer security;statistics	Security	-41.58686767973799	81.75597201933334	128956
2b62e28cd0738245bcd9810a17cee3f9f15592ab	a compression method for homomorphic ciphertexts		In this work we describe a message packing and unpacking method for homomorphic ciphertexts. Messages are packed into the coefficients of plaintext polynomials. We propose an unpacking procedure which allows to obtain a ciphertext for each packed message. The packing and unpacking of ciphertexts represents a solution for reducing the transmission bottleneck in cloud based applications, in particular when sending homomorphic calculations results. The results we obtain (packing ratio, unpacking time) are compared to existing packing methods based on trans-ciphering.	cipher;ciphertext;coefficient;homomorphic encryption;modulo operation;plaintext;polynomial;set packing;source-to-source compiler;telecommunications link	Sergiu Carpov;Renaud Sirdey	2015	IACR Cryptology ePrint Archive		ciphertext;cloud computing;mathematics;polynomial;theoretical computer science;bottleneck;homomorphic encryption;homomorphic secret sharing;unpacking;plaintext	Crypto	-36.556973281287476	80.54627169048177	129118
991af03bf229d2c3aa9aa85927f2024115d044e6	h function based tamper-proofing software watermarking scheme	h function;opaque predicate;constant tamper proofing;cloc encoding	A novel constant tamper-proofing software watermark technique based on H encryption function is presented. First we split the watermark into smaller pieces before encoding them using CLOC scheme. With the watermark pieces, a many-to-one function (H function) as the decoding function is constructed in order to avoid the pattern-matching or reverse engineering attack. The results of the function are encoded into constants as the parameters of opaque predicates or appended to the condition branches of the program to make the pieces relevant. The feature of interaction among the pieces improves the tamper-proofing ability because there being one piece destroyed, the program will not work correctly. The simulation shows that the performance of the proposed scheme is good and can resist many kinds of attacks.	encryption;one-to-many (data model);opaque predicate;pattern matching;permutation pattern;reverse engineering;simulation	Jianqi Zhu;Yanheng Liu;Aimin Wang;KeXin Yin	2011	JSW	10.4304/jsw.6.1.148-155	computer science;theoretical computer science;computer security;algorithm	Security	-35.9823378412806	79.58761269555201	129178
8d2b32d3b0931cad3b55e0c3b5d4d0af40f17bc1	experimental quantum cryptography	uncertainty principle;unconditional security;polarized light;luz polarizada;protocol design;cle publique;public key;quantum physics;criptografia;cryptography;llave publica;cryptographie;quantum cryptography;lumiere polarisee;key distribution	We describe results from an apparatus and protocol designed to implement quantum key distribution by which two users who share no secret information initially exchange a random quantum transmission consisting of very faint ashes of polarized light by subsequent public discussion of the sent and received versions of this transmission estimate the extent of eavesdropping that might have taken place on it and nally if this estimate is small enough distill from the sent and received versions a smaller body of shared random information which is certi ably secret in the sense that any third party s ex pected information on it is an exponentially small fraction of one bit Because the system depends on the uncertainty principle of quantum physics instead of usual mathematical assumptions such as the di culty of factoring it remains secure against an adversary with unlimited computing power A preliminary version of this paper was presented at Eurocrypt May Arhus Denmark and has appeared in the proceedings pp Yorktown Heights New York NY USA z Supported in part by an Nserc Postgraduate Scholarship D epartement IRO Universit e de Montr eal C P succursale A Montr eal Qu ebec Canada H C J Supported in part by Canada s Nserc This work was performed while this author was visiting IBM Research Physics Department University of California at Los Angeles Los Angeles CA USA Introduction and History Quantum cryptography has entered the experimental era The rst convincingly successful quantum exchange took place in October After a short historical review of quantum cryptography we report on the new apparatus and the latest results obtained with it Quantum cryptography was born in the late sixties when Stephen Wiesner wrote Conjugate Coding Unfortunately this highly innovative paper was unpublished at the time and it went mostly unnoticed There Wiesner explained how quantum physics could be used in principle to produce bank notes that would be impossible to counterfeit and how to implement what he called a multiplexing channel a notion strikingly similar to what Rabin was to put forward more than ten years later under the name of oblivious transfer in our opinion it would be fair to give at least equal credit to Wiesner for the concept of oblivious transfer Fortunately Charles H Bennett knew Wiesner quite well and heard about his idea from the horse s mouth Nevertheless it was only when he met Gilles Brassard that quantum cryptography was revived This happened on the occasion of the th IEEE Symposium on the Foundations of Computer Science held in Puerto Rico in October Following their discussion of Wiesner s idea they discovered how to incorporate the almost new at the time notion of public key cryptography resulting in a Crypto paper This brought Wiesner s paper back to life and it was subsequently published in Sigact News together with a selection of papers from the earlier Crypto workshop Initially quantum cryptography was thought of by everyone including ourselves mostly as a work of science ction because the technology required to implement it was out of reach for instance quantum bank notes require the ability to store a single polarized photon or spin particle for days without signi cant absorption or loss of polarization Unfortunately the impact of the Crypto conference had left most people under the impression that everything having to do with quantum cryptography was doomed from the start to being unrealistic The main breakthrough came when Bennett and Brassard realized that photons were never meant to store information but rather to transmit it although it should be said that half of Wiesner s original paper dealt precisely with the use of quantum physics for the transmission of information This lead initially to the self winding reusable one time pad which was still not very practical Later Bennett thought of the quantum key distribution channel whose implementation is the object of the cur rent paper and Brassard designed the somewhat less realistic quantum coin tossing protocol which can be used to implement bit commitment Quantum cryp tography was also picked up by other researchers For instance Cr epeau and Kilian showed how the quantum channel could be used in principle although not in prac tice to implement oblivious transfer in a strong way Wiesner s original multiplexing channel could leak information on both channels zero knowledge protocols and se cure two party computation More recently Ekert proposed an alternative approach to implement quantum key distribution making use of EPR and Bell s theorem but a simpli ed and no less secure version of his scheme is shown in to be equivalent to the idealized quantum key distribution protocol originally put forward by Bennett and Brassard in Let us also mention that Ben nett Brassard and Cr epeau have developed practical quantum protocols to achieve oblivious transfer bit commitment and coin tossing See also The principle of quantum cryptography has been described in major popular mag azines such as Scienti c American The Economist New Scientist and Science News In New Scientist Deutsch wrote that Alan Turing s theoretical model is the basis of all computers Now for the rst time its capabilities have been ex ceeded by the quantum cryptography apparatus Also Brickell and Odlyzko close their thorough survey of recent results in cryptanalysis with these words If such systems quantum cryptography become feasible the cryptanalytic tools dis cussed here in their paper will be of no use In this paper we report on the rst experimental quantum key distribution channel ever designed and actually put together Section provides background information on quantum cryptography For further detail on the basic quantum channel see chapter of We rst review the original quantum key distribution protocol of which illustrates the method most plainly Then we describe subsequent modi cations of the protocol which give it the ability necessary in practice to function despite partial information leakage to the eavesdropper and partial corrup tion of the quantum transmissions by noise In Section we describe the physical apparatus by which quantum key distribution has actually been carried out In Sec tion we discuss the possible sources of information leakage to the eavesdropper In Section we report on actual data transmitted by the apparatus Finally the Appendix gives a new technique allowing privacy ampli cation to be applied when the eavesdropper s information is probabilistic Quantum Key Distribution The purpose of key distribution is for two users Alice and Bob who share no secret information initially to agree on a random key which remains secret from an adversary Eve who eavesdrops on their communications In conventional cryptog raphy and information theory it is taken for granted that digital communications can always be passively monitored so that the eavesdropper learns their entire contents without the sender or receiver being aware that any eavesdropping has taken place By contrast when digital information is encoded in elementary quantum systems such More precisely it is mathematically impossible for two probabilistic interactive Turing machines who share only a short secret key beforehand to achieve secure exchange of a longer secret key under the nose of a third Turing machine eavesdropping on all their communications if that third machine has unlimited computing power In sharp contrast this is precisely what the experimental quantum cryptography prototype achieves with an arbitrarily small probability of failure This does not contradict the Church Turing thesis since the purpose of the apparatus is not to compute functions as single photons it becomes possible to produce a communications channel whose transmissions cannot in principle be reliably read or copied by an eavesdropper ig norant of certain information used in forming the transmission The eavesdropper cannot even gain partial information about such a transmission without disturbing it in a random and uncontrollable way likely to be detected by the channel s legitimate users The essential quantum property involved a manifestation of Heisenberg s uncer tainty principle is the existence of pairs of properties that are incompatible in the sense that measuring one property necessarily randomizes the value of the other For example measuring a single photon s linear polarization randomizes its circular polarization and vice versa More generally any pair of polarization states will be referred to as a basis if they correspond to a reliably measurable property of a single photon and two bases will be said to be conjugate if quantum mechanics decrees that measuring one property completely randomizes the other Our quantum key distribution protocol uses two conjugate bases which we shall take to be the rectilin ear basis horizontal vs vertical polarization and the circular basis left circular vs right circular We shall refer to these as the canonical bases Similarly a canonical polarization is either horizontal vertical left circular or right circular A third basis also exists consisting of and degree diagonal polarizations which is conjugate to both the other two bases but we will not need to consider it except in connection with possible eavesdropping strategies More information on the notion of conjugate bases is given in the Appendix The protocol we describe here is secure even against an enemy possessing unlim ited computing power even if P NP under any attack in which she is limited to measuring photons or in the subsequent generalization light pulses one at a time and combining the classical results of these measurements with information subse quently overheard during the public discussion described below The formalism of quantum mechanics allows a more general kind of measurement completely infeasible at present or in the foreseeable future Such a measurement would treat the entire sequence of n photons sent during a key dist	acm sigact;adversary (cryptography);alice and bob;channel (communications);church–turing thesis;circular polarization;commitment scheme;computation;computer science;conjugate coding;cryptanalysis;digital data;epr paradox;eurocrypt;eve;ibm research;information leakage;information theory;integer factorization;key (cryptography);limbo;linear polarization;mag (cryptography);multiplexing;oblivious transfer;one-time pad;polarization (waves);prototype;public-key cryptography;quantum channel;quantum cryptography;quantum key distribution;quantum mechanics;quantum system;rico;semantics (computer science);spectral leakage;turing machine;uncertainty principle	Charles H. Bennett;François Bessette;Gilles Brassard;Louis Salvail;John A. Smolin	1990		10.1007/3-540-46877-3_23	quantum information;uncertainty principle;quantum key distribution;telecommunications;cryptography;theoretical computer science;mathematics;key distribution;computer security;quantum cryptography;algorithm;bb84	Crypto	-43.738342004062595	83.20864451720333	129264
e24afe32c1b3b735aca437ebd8191d5801c1a728	close to optimally secure variants of gcm		The Galois/Counter Mode of operation (GCM) is a widely used nonce-based authenticated encryption with associated data mode which provides the birthday-bound security in the nonce-respecting scenario; that is, it is secure up to about 2 adversarial queries if all nonces used in the encryption oracle are never repeated, where n is the block size. It is an open problem to analyze whether GCM security can be improved by using some simple operations. This paper presents a positive response for this problem. Firstly, we introduce two close to optimally secure pseudorandom functions and derive their security bound by the hybrid technique.Then, we utilize these pseudorandom functions that we design and a universal hash function to construct two improved versions of GCM, called OGCM-1 and OGCM-2. OGCM-1 and OGCM-2 are, respectively, provably secure up to approximately 2/67(n − 1) and 2/67 adversarial queries in the nonce-respecting scenario if the underlying block cipher is a secure pseudorandom permutation. Finally, we discuss the properties of OGCM-1 and OGCM-2 and describe the future works.		Ping Zhang;Honggang Hu;Qian Yuan	2018	Security and Communication Networks	10.1155/2018/9715947	computer network;computer science;pseudorandom permutation;encryption;cryptographic nonce;block cipher;authenticated encryption;block cipher mode of operation;pseudorandom number generator;universal hashing;distributed computing	Crypto	-37.894174832633965	77.9543236921553	129309
a498e855bf0dcacaac2c0e6ac9e76f4bfa0aab46	a black-box construction of strongly unforgeable signature schemes in the bounded leakage model		Due to the imperfect implementation of cryptosystems, adversaries are able to obtain secret state of the systems via side-channel attacks which are not considered in the traditional security notions of cryptographic primitives, and thus break their security. Leakage-resilient cryptography was proposed to prevent adversaries from doing so. Katz et al. and Boyle et al. proposed signature schemes which are existentially unforgeable in the bounded leakage model. However, neither takes measures to prevent the adversary from forging on messages that have been signed before. Recently, Wang et al. showed that any signature scheme can be transformed to one that is strongly unforgeable in the leakage environment with the help of a leakage-resilient chameleon hash function. However, their transformation requires changing the key pair of the signature scheme. In this work, we further improve Wang et al.'s results by proposing a black-box construction of signature schemes, which converts a leakage-resilient signature scheme to one that is both strongly unforgeable and leakage resilient. Our construction does not require adding any element to the signature key pair nor modify the signature scheme at all. It is efficient in the sense that the resulting signature scheme has almost the same computational cost in signing and verification as the underlying scheme.	spectral leakage	Jianye Huang;Qiong Huang;Chunhua Pan	2016		10.1007/978-3-319-47422-9_19	discrete mathematics	Crypto	-39.27861789634626	76.55474516048935	129438
6843769fcdb05bb128c5a5aa286a90878d023bdb	key derivation for squared-friendly applications: lower bounds		Security of a cryptographic application is typically defined by a security game. The adversary, within certain resources, cannot win with probability much better than 0 (for unpredictability applications, like one-way functions) or much better than 2 (indistinguishability applications for instance encryption schemes). In so called squared-friendly applications the winning probability of the adversary, for different values of the application secret randomness, is not only close to 0 or 1 2 on average, but also concentrated in the sense that it’s second central moment is small. The class of squared-friendly applications, which contains all unpredictability applications and many indistinguishability applications, is particularly important in the context of key derivation. Barak et al. observed that for square-friendly applications one can beat the “RT-bound”, extracting secure keys with significantly smaller entropy loss. In turn Dodis and Yu showed that in squaredfriendly applications one can directly use a “weak” key, which has only high entropy, as a secure key. In this paper we give sharp lower bounds on square security assuming security for “weak” keys. We show that any application which is either (a) secure with weak keys or (b) allows for saving entropy in a key derived by hashing, must be square-friendly. Quantitatively, our lower bounds match the positive results of Dodis and Yu and Barak et al. (TCC’13, CRYPTO’11) Hence, they can be understood as a general characterization of squared-friendly applications. Whereas the positive results on squared-friendly applications where derived by one clever application of the Cauchy-Schwarz Inequality, for tight lower bounds we need more machinery. In our approach we use convex optimization techniques and some theory of circular matrices.	adversary (cryptography);convex optimization;cryptography;emoticon;encryption;key derivation function;langrisser schwarz;mathematical optimization;one-way function;randomness;weak key	Maciej Skorski	2016	IACR Cryptology ePrint Archive			Crypto	-36.09583359209034	76.6707115010556	129618
c6e2e9cffdf9d96a657045cb112270cd9dc64e57	an improved remote user authentication scheme using smart cards	smart card;network security;indexing terms;it security;user authentication	In 2000, Hwang and Li proposed a new remote user authentication scheme using smart cards. In the same year, Chan and Cheng pointed out that Hwang and Li’s scheme is not secure against the masquerade attack. Further, in 2003, Shen, Lin and Hwang pointed out a different type of attack on Hwang and Li’s scheme and presented a modified scheme to remove its security pitfalls. This paper presents an improved scheme which is secure against Chan-Cheng and all the extended attacks.	authentication;polynomial-time approximation scheme;smart card;spoofing attack	Manoj Kumar	2005	CoRR		smart card;index term;computer science;network security;internet privacy;world wide web;computer security	Crypto	-44.89842544406712	74.72515023064891	129828
507883929d154dd24ec48370698e9265f0172f98	cca-secure cryptosystem from lattice.	. lattice;cca-security;pseudohomomorphism	We propose a simple construction of CCA- secure public- key encryption scheme based on lattice in the standard model. Our con- struction regards lattice-based cryptosystem mR05 of (21), which is the multi-bit version of single-bit cryptosystems R05 (20), as building block and makes use of its indistinguishable pseudohomomorphism property which is known to be achievable without random oracles and which is the crux that we can construct a public key encryption scheme which is CCA-secure in standard model. This makes our construction approach quite dierent from existing ones. So far as we know, our construction is the rst CCA-secure cryptosystem which is directly constructed from lattice and whose security is directly based on the standard lattice prob- lem which is hard in the worst case for quantum algorithms.		Huiyan Chen	2010	IACR Cryptology ePrint Archive		ggh encryption scheme;ntruencrypt;lattice problem	Crypto	-37.9098398382688	77.4825529752954	129870
29aec2a47acc963433894d58750fbfec61b8b281	chosen ciphertext security with optimal ciphertext overhead	semantic security;public key encryption;chosen ciphertext security;random oracle model;lower bound;chosen ciphertext attack	Every public-key encryption scheme has to incorporate a certain amount of randomness into its ciphertexts to provide semantic security against chosen ciphertext attacks (IND-CCA). The difference between the length of a ciphertext and the embedded message is called the ciphertext overhead. While a generic brute-force adversary running in 2 steps gives a theoretical lower bound of t bits on the ciphertext overhead for IND-CPA security, the best known IND-CCA secure schemes demand roughly 2t bits even in the random oracle model. Is the t-bit gap essential for achieving IND-CCA security? We close the gap by proposing an IND-CCA secure scheme whose ciphertext overhead matches the generic lower bound up to a small constant. Our scheme uses a variation of a four-round Feistel network in the random oracle model and hence belongs to the family of OAEPbased schemes. Maybe of independent interest is a new efficient method to encrypt long messages exceeding the length of the permutation while retaining the minimal overhead.	adversary (cryptography);chosen-ciphertext attack;ciphertext indistinguishability;ciphertext-only attack;embedded system;encryption;feistel cipher;overhead (computing);public-key cryptography;random oracle;randomness;semantic security	Masayuki Abe;Eike Kiltz;Tatsuaki Okamoto	2008	IACR Cryptology ePrint Archive	10.1007/978-3-540-89255-7_22	random oracle;semantic security;chosen-ciphertext attack;plaintext-aware encryption;ciphertext stealing;key clustering;computer science;unicity distance;ciphertext indistinguishability;mathematics;distributed computing;internet privacy;malleability;public-key cryptography;deterministic encryption;upper and lower bounds;computer security;cramer–shoup cryptosystem;algorithm;ciphertext;attribute-based encryption	Crypto	-37.79871789768372	77.75068750798751	130407
bb9b4c016a16df4c0a2b6d007ad0882dbbe9a4c9	crt rsa algorithm protected against fault attacks	smart card;rsa;chinese remainder theorem;it security;simple power analysis;fault attack;modular exponentiation;fault model;embedded device;fault attacks	Embedded devices performing RSA signatures are subject to Fault Attacks, particularly when the Chinese Remainder Theorem is used. In most cases, the modular exponentiation and the Garner recombination algorithms are targeted. To thwart Fault Attacks, we propose a new generic method of computing modular exponentiation and we prove its security in a realistic fault model. By construction, our proposal is also protected against Simple Power Analysis. Based on our new resistant exponentiation algorithm, we present two different ways of computing CRT RSA signatures in a secure way. We show that those methods do not increase execution time and can be easily implemented on low-resource devices.	add-ons for firefox;algorithm;antivirus software;cathode ray tube;differential fault analysis;fault model;modular exponentiation;overhead (computing);rsa (cryptosystem);right-to-left;run time (program lifecycle phase)	Arnaud Boscher;Robert Naciri;Emmanuel Prouff	2007		10.1007/978-3-540-72354-7_19	smart card;parallel computing;computer science;theoretical computer science;chinese remainder theorem;fault model;computer security;modular exponentiation	Crypto	-40.77570037105489	79.00576787130103	130535
5233cfdd874ff3b32fcfb4a6fa305d89ec6d271c	gaussian sampling over the integers: efficient, generic, constant-time		Sampling integers with Gaussian distribution is a fundamental problem that arises in almost every application of lattice cryptography, and it can be both time consuming and challenging to implement. Most previous work has focused on the optimization and implementation of integer Gaussian sampling in the context of specific applications, with fixed sets of parameters. We present new algorithms for discrete Gaussian sampling that are both generic (application independent), efficient, and more easily implemented in constant time without incurring a substantial slow-down, making them more resilient to side-channel (e.g., timing) attacks. As an additional contribution, we present new analytical techniques that can be used to simplify the precision/security evaluation of floating point cryptographic algorithms, and an experimental comparison of our algorithms with previous algorithms from the literature.	algorithm;cryptography;mathematical optimization;sampling (signal processing);side-channel attack;time complexity	Daniele Micciancio;Michael Walter	2017	IACR Cryptology ePrint Archive	10.1007/978-3-319-63715-0_16	theoretical computer science;gaussian integer;sampling (statistics);floating point;cryptography;quadratic integer;computer science;gaussian;table of gaussian integer factorizations;integer	Crypto	-34.9086217031115	79.11372095831864	131508
14f00678ddf319ffcbe637982a01e8e0f95c10ff	secure two-party computation over a z-channel	institutional repositories;cryptography on noisy channels;fedora;oblivious transfer;secure multi party computation;vital;vtls;information theoretic security;ils	In secure two-party computation, two mutually distrusting parties are interested in jointly computing a function, while preserving the privacy of their respective inputs. However, when communicating over a clear channel, security against computationally unbounded adversaries is impossible. Thus is the importance of noisy channels, over which we can build Oblivious Transfer (OT), a fundamental primitive in cryptography and the basic building block for any secure multi-party computation. The noisy channels commonly used in current constructions are mostly derived from the Binary Symmetric Channel (BSC), which is modified to extend the capabilities of an attacker. Still, these constructions are based on very strong assumptions, in particular on the error probability, which makes them hard to implement. In this paper, we provide a protocol achieving oblivious transfer over a Z-channel, a natural channel model in various contexts, ranging from optical to covert communication. The protocol proves to be particularly efficient for a large range of error probabilities p (e.g., for 0.17 ≤ p ≤ 0.29 when a security parameter ε = 10−9 is chosen), where it requires a limited amount of data to be sent through the channel. Our construction also proves to offer security against unfair adversaries, who are able to select the channel probability within a fixed range. We provide coding schemes that can further increase the efficiency of the protocol for probabilities distant from the range mentioned above, and also allow the use of a Z-channel with an error probability greater than 0.5. The flexibility and the efficiency of the construction make an actual implementation of oblivious transfer a more realistic prospect.	binary erasure channel;binary symmetric channel;channel (communications);code;computer programming;cryptography;ecc memory;noisy-channel coding theorem;oblivious transfer;promoting adversaries;real life;secure multi-party computation;secure two-party computation;security parameter	Paolo Palmieri;Olivier Pereira	2011		10.1007/978-3-642-24316-5_3	information-theoretic security;computer science;secure two-party computation;theoretical computer science;oblivious transfer;distributed computing;secure multi-party computation;computer security	Crypto	-37.109954469741126	75.00691483875829	131613
72adfd090b6e36692d84cfda4434ef1a0f53117d	new efficient and authenticated key agreement protocol in dynamic peer group	provable security;auxiliary key agreement;random oracle model dynamic peer group key agreement id based signature provable security;tgdh protocol;cryptographic protocols;peer to peer computing cryptographic protocols message authentication;dynamic peer group;authenticated key agreement;id based signature;random oracle model;bd protocol;random oracle model authenticated key agreement protocol dynamic peer group linker cluster architecture bd protocol tgdh protocol auxiliary key agreement;key agreement;message authentication;peer to peer computing;protocols computational efficiency synchronous digital hierarchy random number generation clustering algorithms availability computer security helium mathematics peer to peer computing;authenticated key agreement protocol;linker cluster architecture	The members in the dynamic peer group (DPG) are divided into several clusters according to linker cluster architecture (J.B. Dennis and E. Anthony, 1981). In each cluster, the members perform the BD protocol (M. Burmester and Y. Desmedt, 1994) to establish the cluster key and the TGDH protocol (Y. Kim et al., 2004) is performed among the clusters to generate the group key. This method can not only avoid the weakness of AKA (auxiliary key agreement) of BD, but also reduce the computation cost of TGDH scheme. In our scheme the members have been authenticated based identity, and we prove the security in random oracle model.	algorithm;authentication;blu-ray;computation;digital signature forgery;group key;key-agreement protocol;random oracle	Shengke Zeng;Mingxing He;Weidong Luo	2008	2008 Third International Conference on Availability, Reliability and Security	10.1109/ARES.2008.60	computer science;distributed computing;computer security;computer network	Crypto	-42.916995533823396	75.8633654897871	131757
1059a96dfc1bc13f2dbad3f07472d1d651ea261a	cryptography secure against related-key attacks and tampering	general theoretical question;related-key attack;primitive p2;high-level primitive;fault injection attack;rka security;practical class;negative answer;new notion;high level picture	We show how to leverage the RKA (Related-Key Attack) security of blockciphers to provide RKA security for a suite of high-level primitives. This motivates a more general theoretical question, namely, when is it possible to transfer RKA security from a primitive P1 to a primitive P2? We provide both positive and negative answers. What emerges is a broad and high level picture of the way achievability of RKA security varies across primitives, showing, in particular, that some primitives resist “more” RKAs than others. A technical challenge was to achieve RKA security even for the practical classes of related-key deriving (RKD) functions underlying fault injection attacks that fail to satisfy the “claw-freeness” assumption made in previous works. We surmount this barrier for the first time based on the construction of PRGs that are not only RKA secure but satisfy a new notion of identity-collision-resistance. 1 Department of Computer Science & Engineering, University of California San Diego, 9500 Gilman Drive, La Jolla, California 92093, USA. Email: mihir@cs.ucsd.edu. URL: http://www.cs.ucsd.edu/users/mihir. Supported in part by NSF grants CNS-0904380 and CCF-0915675. IBM T.J. Watson Research Center, Yorktown Heights, NY 10598, USA.. Email: cdc@gatech.edu. URL: http://www. cs.ucsd.edu/users/cdcash. Supported in part by NSF grant CCF-0915675. 3 Department of Electrical Engineering and Computer Science, MIT, 32 Vassar Street, Cambridge, Massachusetts 02139, USA. Email: rmiller@csail.mit.edu. URL: http://people.csail.mit.edu/rmiller/. Supported by a DOD NDSEG Graduate Fellowship.	block cipher;collision resistance;computer science;cryptography;email;fault injection;geforce 9 series;high- and low-level;high-level programming language;ibm notes;jolla;linear algebra;related-key attack;thomas j. watson research center	Mihir Bellare;David Cash;Rachel Miller	2011		10.1007/978-3-642-25385-0_26	computer science;theoretical computer science;internet privacy;computer security	Crypto	-35.20921561310124	76.83410356616685	131774
ce5d64635dfe279ff6e31218f5c5bdd6d48a8746	robust stream-cipher mode of authenticated encryption for secure communication in wireless sensor network	glomonet;authenticated encryption;integrity;authenticated cloud service;privacy	Authenticated Encryption is a cryptographic process of providing confidentiality and integrity protection of messages in a single pass without any support of conventional checksum, Message Authentication Code (MAC), or hash function. In this paper, at first, we show that how to construct the stream-cipher-based Authenticated Encryption environment, where the key-stream is generated from any secure block algorithm like Advanced Encryption Standard. In order to do that, we introduce two stream-cipher modes of Authenticated Encryption, namely, PFC-CTR (Counter-based Authenticated Encryption environment) and PFC-OCB (OCB-based Authenticated Encryption environment), which are quite robust against several active attacks, for example, message stream modification attacks, known-plain-text attacks, and chosen-plain-text attacks, and at the same time, they can also efficiently deal with some other issues like “limited error propagation” existing in several conventional stream-cipher modes of operation like Cipher Feedback, Output Feedback, and Counter. Finally, we enforce the concept of Authenticated Encryption in the sense of data communication security of the wireless sensor network (WSN), Global Mobility Networks (GLOMONET), and Cloud Computing environment, where only encryption can guarantee both the privacy and integrity in a single pass with the assurance of reasonable computational overhead. Copyright © 2015 John Wiley & Sons, Ltd.	authenticated encryption;block cipher mode of operation;checksum;ciphertext indistinguishability;cloud computing;communications security;confidentiality;cryptographic primitive;cryptography;data integrity;hash function;john d. wiley;message authentication code;overhead (computing);podium;powerbuilder foundation classes;propagation of uncertainty;secure communication;software propagation;stream cipher;symmetric-key algorithm	Tzonelih Hwang;Prosanta Gope	2016	Security and Communication Networks	10.1002/sec.1388	multiple encryption;h.235;disk encryption theory;40-bit encryption;disk encryption;block cipher mode of operation;client-side encryption;computer science;key wrap;ocb mode;sponge function;link encryption;filesystem-level encryption;on-the-fly encryption;internet privacy;disk encryption hardware;authenticated encryption;privacy;computer security;encryption;probabilistic encryption;56-bit encryption;attribute-based encryption;computer network;email encryption	Security	-45.92830795766751	76.1690369377167	131910
3acbda568d93f0f6b8a734e6cbd537a5cb58bdcc	security of number theoretic public key cryptosystems against random attack, iii			cryptosystem;public-key cryptography	Bob Blakley;G. R. Blakley	1979	Cryptologia	10.1080/0161-117991853909		Crypto	-40.12728813339266	79.92134387072457	132310
eee1061d56c57425458eb0617a73d46fdd63fa53	how to find short rc4 colliding key pairs	different secret key;rc4 colliding key pair;key pair;keystream output;different story;stream cipher rc4;key size decrease;key scheduling algorithm;colliding key pair;different key;22-byte colliding key pair	The property that the stream cipher RC4 can generate the same keystream outputs under two different secret keys has been discovered recently. The principle that how the two different keys can achieve a collision is well known by investigating the key scheduling algorithm of RC4. However, how to find those colliding key pairs is a different story, which has been largely remained unexploited. Previous researches have demonstrated that finding colliding key pairs becomes more difficult as the key size decreases. The main contribution of this paper is proposing an efficient searching algorithm which can successfully find 22-byte colliding key pairs, which are by far the shortest colliding key pairs ever found.	brute-force search;key schedule;key size;public-key cryptography;rc4;scheduling (computing);search algorithm;stream cipher	Jiageng Chen;Atsuko Miyaji	2011		10.1007/978-3-642-24861-0_3	mathematics;distributed computing;world wide web;computer security	Security	-36.349738871323545	81.16979345715482	132579
0a1fb1d4d502304faeb13870515fc095ee1fe75f	privacy amplification with asymptotically optimal entropy loss	cryptographic protocols;authentication protocols;error correcting codes;key agreement;information theoretic key agreement	We study the problem of “privacy amplification”: key agreement between two parties who both know a weak secret w, such as a password. (Such a setting is ubiquitous on the internet, where passwords are the most commonly used security device.) We assume that the key agreement protocol is taking place in the presence of an active computationally unbounded adversary Eve. The adversary may have partial knowledge about w, so we assume only that w has some entropy from Eve’s point of view. Thus, the goal of the protocol is to convert this nonuniform secret w into a uniformly distributed string R that is fully secret from Eve. R may then be used as a key for running symmetric cryptographic protocols (such as encryption, authentication, etc.).  Because we make no computational assumptions, the entropy in R can come only from w. Thus, such a protocol must minimize the entropy loss during its execution, so that R is as long as possible. The best previous results have entropy loss of Θ(κ2), where κ is the security parameter, thus requiring the password to be very long even for small values of κ. In this work, we present the first protocol for information-theoretic key agreement that has entropy loss linear in the security parameter. The result is optimal up to constant factors. We achieve our improvement through a somewhat surprising application of error-correcting codes for the edit distance.  The protocol can be extended to provide also “information reconciliation,” that is, to work even when the two parties have slightly different versions of w (e.g., when biometrics are involved).	adversary (cryptography);asymptotically optimal algorithm;authentication;biometrics;code;computational hardness assumption;cryptographic protocol;cryptography;edit distance;emoticon;encryption;entropy rate;error detection and correction;eve;forward error correction;information theory;internet;key-agreement protocol;leftover hash lemma;password;privacy;randomness extractor;security parameter;shared secret;strong secrecy;time complexity;usability	Nishanth Chandran;Bhavana Kanukurthi;Rafail Ostrovsky;Leonid Reyzin	2012	IACR Cryptology ePrint Archive	10.1145/2630064	computer science;theoretical computer science;authentication protocol;cryptographic protocol;distributed computing;computer security	Theory	-37.139715004398035	76.60379849748576	132586
449957ea34a0d6d45c102da3b0fa7ff67dd6abd5	an enhanced bilinear pairing based authenticated key agreement protocol for multiserver environment			authentication;bilinear filtering;key-agreement protocol	Venkatasamy Sureshkumar;Ruhul Amin;Anitha Ramalingam	2017	Int. J. Communication Systems	10.1002/dac.3358	key-agreement protocol;computer science;bilinear interpolation;distributed computing;authentication;pairing	Security	-43.77627286715663	75.65549150435997	132605
454e13f36c6d413e91316d4810f71497b90501e1	two practical and provably secure block ciphers: bears and lion	provable security;block cipher;stream cipher;hash function	In this paper we suggest two new provably secure block ciphers , called BEAR and LION. They both have large block sizes, and are based on the Luby-Rackoo construction. Their underlying components are a hash function and a stream cipher, and they are provably secure in the sense that attacks which nd their keys would yield attacks on one or both of the underlying components. They also have the potential to be much faster than existing block ciphers in many applications.	block cipher;hash function;michael luby;provable security;stream cipher	Ross J. Anderson;Eli Biham	1996		10.1007/3-540-60865-6_48	rail fence cipher;transposition cipher;triple des;differential cryptanalysis;residual block termination;two-square cipher;running key cipher;ciphertext stealing;block cipher mode of operation;block size;stream cipher attack;distributed computing;stream cipher;affine cipher;internet privacy;rip van winkle cipher;computer security;cbc-mac;3-way;cryptographic hash function;mdc-2	Crypto	-39.86434970876001	79.51259069700585	132807
26a34b22f674f711e9a83bac5d3da4069070b791	round-efficient concurrently composable secure computation via a robust extraction lemma		We consider the problem of constructing protocols for secure computation that achieve strong concurrent and composable notions of security in the plain model. Unfortunately UC-secure secure computation protocols are impossible in this setting, but the Angel-Based Composable Security notion offers a promising alternative. Until now, however, under standard (polynomialtime) assumptions, only protocols with polynomially many rounds were known to exist. In this work, we give the first Õ(log n)-round secure computation protocol in the plain model that achieves angel-based composable security in the concurrent setting, under standard assumptions. We do so by constructing the first Õ(log n)-round CCA-secure commitment protocol. Our CCA-secure commitment protocol is secure based on the minimal assumption that one-way functions exist. A central tool in obtaining our result is a new robust concurrent extraction lemma that we introduce and prove, based on the minimal assumptions that one-way functions exist. This robust concurrent extraction lemma shows how to build concurrent extraction procedures that work even in the context of an “external” protocol that cannot be rewound by the extractor. We believe this lemma can be used to simplify many existing works on concurrent security, and is of independent interest. In fact, our lemma when used in conjunction with the concurrent-simulation schedule of Pass and Venkitasubramaniam (TCC’08), also yields a constant round construction based additionally on the existence of quasi-polynomial time (PQT ) secure one-way functions.	communications protocol;one-way function;polynomial;quasi-polynomial;randomness extractor;secure multi-party computation;simulation;time complexity;uc browser	Vipul Goyal;Omkant Pandey;Amit Sahai	2012		10.1007/978-3-662-46494-6_12	real-time computing;computer science;theoretical computer science;distributed computing	Crypto	-38.20513130398318	75.39224658281974	132832
785cd80d87f7bc8682cbf9c7bc3b4fb8775740e7	a pki based digital rights management system for safe playback	public key cryptography;desciframiento;sistema operativo;evaluation performance;cryptographie cle publique;multiagent system;multimedia;performance evaluation;decodage;decoding;encryption;image databank;gestion archivos;evaluacion prestacion;authentication;cle publique;gestion fichier;gestion derecho autor numerico;decryptage;cifrado;intelligence artificielle;file management;delay system;system performance;digital rights management;authentification;autenticacion;public key;senal video;signal video;systeme a retard;operating system;cryptage;gestion droits numeriques;banco imagen;multimedia data;banque image;decryption;llave publica;video signal;artificial intelligence;systeme exploitation;temps retard;inteligencia artificial;delay time;sistema con retardo;sistema multiagente;user authentication;tiempo retardo;digital right management;public key infrastructure;systeme multiagent	In this paper we first propose an I-frame encryption scheme for encryption of moving image video data. Second, we propose a licensing agent which provides automatic user authentication and data decoding when multimedia data encrypted in the system server is executed in the client system by the user. The licensing agent performs user authentication based on Public Key Infrastructure (PKI) using a shared key pool and encryption/decryption of multimedia data. After designing and implementing the proposed system, performance tests were then performed using video data files of various sizes for performance evaluation. We verified that the proposed system significantly reduces delay time, including decryption time, when playing back video data files in the client system compared with existing systems.	digital rights management;public key infrastructure	Jae-Pyo Park;Hong-jin Kim;Keun-Wang Lee;Keun-Soo Lee	2005		10.1007/11538356_83	telecommunications;computer science;operating system;authentication;computer performance;filesystem-level encryption;on-the-fly encryption;public-key cryptography;world wide web;computer security;encryption	AI	-44.1226721703426	78.90242302285903	132867
144c72023fac7d91faa3b82f73b32120c7c9b41b	an experiment on des statistical cryptanalysis	passwords;human computer interaction;information security;block cipher;heuristic method;authentication;known plaintext attack;linear cryptanalysis;general methods;differential cryptanalysis;data encryption standard	Linear cryptanalysis and differential cryptanalysis are the most important methods of attack against block ciphers. Their efficiency have been demonstrated against several ciphers, including the Data Encryption Standard. We prove that both of them can be considered, improved and joined in a more general statistical framework. We also show that the very same results as those obtained in the case of DES can be found without any linear analysis and we slightly improve them into an attack with theoretical complexity 242 ·9 . We can apply another statistical attack the xcryptanalysis on the same characteristics without a definite idea of what happens in the encryption process. It appears to be roughly as efficient as both differential and linear cryptanalysis. We propose a new heuristic method to find good characteristics. It has found an attack against DES absolutely equivalent to Matsui's one by following a distinct path.	block cipher;differential cryptanalysis;encryption;experiment;heuristic;linear cryptanalysis;statistical model	Serge Vaudenay	1996		10.1145/238168.238206	integral cryptanalysis;block cipher;contact analysis;chosen-ciphertext attack;differential cryptanalysis;interpolation attack;mod n cryptanalysis;piling-up lemma;xsl attack;computer science;information security;theoretical computer science;ciphertext-only attack;boomerang attack;known-plaintext attack;higher-order differential cryptanalysis;authentication;symmetric-key algorithm;impossible differential cryptanalysis;internet privacy;password;slide attack;computer security;dictionary attack;linear cryptanalysis	Security	-38.65962644385591	80.66334367131316	133077
bbf9c84d17384974a4110dc89e3c9a763ce51af1	security enhancement for optimal strong-password authentication protocol	hash function;security enhancement;authentication;smart card;optimal strong-password authentication protocol;stolen-verifier attack;security;improved version;cryptography;password;osap protocol;password authentication	In 2001, Lin et al. proposed an optimal strong-password authentication protocol called the OSAP protocol. However, Chen and Ku pointed out that it is vulnerable to the stolen-verifier attack. In this paper, we shall propose an improved version of the OSAP protocol to enhance the security.	password authentication protocol	Chih-Wei Lin;Jau-Ji Shen;Min-Shiang Hwang	2003	Operating Systems Review	10.1145/881783.881785	otway–rees protocol;smart card;computer science;information security;authentication protocol;authentication;internet privacy;world wide web;computer security	Crypto	-44.93983739118556	74.70378281076167	133080
cd8d35bd16d39670fa79e291e42da52ed4e53a78	on the practical security bound of gf-nlfsr structure with spn round function		At ACISP 2009, Choy et al. proposed the generalised Feistel nonlinear feedback shift register structure (GF-NLFSR). The main feature of GF-NLFSR containing n sub-blocks is that it can be parallelized up to n-round for implementation, and meanwhile the provable security bound against differential cryptanalysis (DC) and linear cryptanalysis (LC) can be provided for n + 1 rounds. Thus, it maybe suit for the light-weight encryption environment, such as RFID tags, smart cards, and sensor nodes. The practical security bound of GF-NLFSR with SPN round function was further studied by Yap et al. at Africacrypt 2010, where a differential bound for 2nr-round was provided, while for the linear bound, only partial results for n = 2,4 were presented. In this paper, we eliminate such discrepancy between the practical differential and linear bound of GF-NLFSR with SPN round function by demonstrating that a unified bound could be proved using the “divide and conquer” strategy. We further find a relationship between the truncated differential characteristics and linear characteristics of GF-NLFSR, which builds a nice link between the lower differential bound and linear bound of such construction, and demonstrate that proving the cipher’s resistance against either DC or LC is enough to show its resistance against both DC and LC. We hope that the result in the current paper will be useful when designing ciphers based on GF-NLFSR structure with SPN round function.	grammatical framework;nonlinear feedback shift register;substitution-permutation network	Guangyao Zhao;Lei Cheng;Chunsheng Li;Ruilin Li;Xuan Shen	2014		10.1007/978-3-319-12475-9_4	theoretical computer science	Crypto	-36.925238150725136	77.77896230723152	133122
90792f1feecd0fc74fedb8dea1ff916a44bd5bf1	a black-box construction of non-malleable encryption from semantically secure encryption	public-key encryption;non-malleable encryption;black-box construction	We show how to transform any semantically secure encryption scheme into a non-malleable one, with a black-box construction that achieves a quasi-linear blow-up in the size of the ciphertext. This improves upon the previous non-black-box construction of Pass, Shelat and Vaikuntanathan (Crypto ’06). Our construction also extends readily to guarantee non-malleability under a bounded-CCA2 attack, thereby simultaneously improving on both results in the work of Cramer et al. (Asiacrypt ’07). Our construction departs from the oft-used paradigm of re-encrypting the same message with different keys and then proving consistency of encryption. Instead, we encrypt an encoding of the message; the encoding is based on an error-correcting code with certain properties of reconstruction and secrecy from partial views, satisfied, e.g., by a Reed–Solomon code.	asiacrypt;black box;ciphertext;encryption;error detection and correction;forward error correction;malleability (cryptography);programming paradigm;reed–solomon error correction;semantic security	Seung Geol Choi;Dana Dachman-Soled;Tal Malkin;Hoeteck Wee	2016	Journal of Cryptology	10.1007/s00145-017-9254-z	multiple encryption;40-bit encryption;plaintext-aware encryption;computer science;theoretical computer science;filesystem-level encryption;on-the-fly encryption;internet privacy;deterministic encryption;computer security;encryption;probabilistic encryption;56-bit encryption;attribute-based encryption	Crypto	-38.1743163600804	77.47169583496266	133251
29174f927ddec20420a3987a8ec27b171c4f6216	a note on negligible functions	probabilidad error;one way function;negligibilite;securite informatique;key words negligible functions;one way functions;zero knowledge arguments;computer security;criptografia;cryptography;seguridad informatica;cryptographie;error probability;zero knowledge;proof of knowledge;probabilite erreur	In theoretical cryptography, one formalizes the notion of an adversary's success probability being ``too small to matter'' by asking that it be a negligible function of the security parameter. We argue that the issue that really arises is what it might mean for a collection of functions to be ``negligible.'' We consider (and define) two such notions, and prove them equivalent. Roughly, this enables us to say that any cryptographic primitive has a specific associated ``security level.'' In particular we say this for any one-way function. We also reconcile different definitions of negligible error arguments and computational proofs of knowledge that have appeared in the literature. Although the motivation is cryptographic, the main result is purely about negligible functions.	adversary (cryptography);cryptographic primitive;cryptography;one-way function;security parameter	Mihir Bellare	1997	Journal of Cryptology	10.1007/s00145-002-0116-x	computer science;theoretical computer science;mathematics;one-way function;computer security;algorithm;statistics	Crypto	-37.20382563319002	77.1323773941511	133378
09ba534d297b546f37154e98ec7dc9ab78a6148b	key-schedule cryptanalysis of idea, g-des, gost, safer, and triple-des	block cipher;differential cryptanalysis	We present new attacks on key schedules of block ciphers. These attacks are based on the principles of related-key differential cryptanalysis: attacks that allow both keys and plaintexts to be chosen with specific differences. We show how these attacks can be exploited in actual protocols and cryptanalyze the key schedules of a variety of algorithms, including three-key triple-DES.	algorithm;block cipher;differential cryptanalysis;key distribution;key schedule;related-key attack;triple des;workbench	John Kelsey;Bruce Schneier;David A. Wagner	1996		10.1007/3-540-68697-5_19	block cipher;differential cryptanalysis;computer science;theoretical computer science;boomerang attack;higher-order differential cryptanalysis;symmetric-key algorithm;mathematics;impossible differential cryptanalysis;internet privacy;computer security;algorithm;statistics;linear cryptanalysis	Crypto	-39.99407114460756	79.54084478217656	133453
72dc74b257dcc59715a2acd64d37c9aea1a524c9	the vector-ballot e-voting approach	administracion electronica;interfase usuario;protocole transmission;encryption;pago;user interface;electronic fund transfer;integrite;cifrado;integridad;payment;electronic vote;transferencia computarizada de fondos;protocolo transmision;paiement;integrity;cryptage;criptografia;cryptography;administration electronique;electronic government;firma ciega;cryptographie;interface utilisateur;blind signature;mix network;signature aveugle;monetique;vote electronique;homomorphic encryption;voto electronico;transmission protocol	Looking at current cryptographic-based e-voting protocols, one can distinguish three basic design paradigms (or approaches): (a) Mix-Networks based, (b) Homomorphic Encryption based, and (c) Blind Signatures based. Each of the three possesses different advantages and disadvantages w.r.t. the basic properties of (i) efficient tallying, (ii) universal verifiability, and (iii) allowing write-in ballot capability (in addition to predetermined candidates). In fact, none of the approaches results in a scheme that simultaneously achieves all three. This is unfortunate, since the three basic properties are crucial for efficiency, integrity and versatility (flexibility), respectively. Further, one can argue that a serious business offering of voting technology should offer a flexible technology that achieves various election goals with a single user interface. This motivates our goal, which is to suggest a new “vector-ballot” based approach for secret-ballot e-voting that is based on three new notions: Provably Consistent Vector Ballot Encodings, Shrink-and-Mix Networks and Punch-Hole-Vector-Ballots. At the heart of our approach is the combination of mix networks and homomorphic encryption under a single user interface; given this, it is rather surprising that it achieves much more than any of the previous approaches for e-voting achieved in terms of the basic properties. Our approach is presented in two generic designs called “homomorphic vector-ballots with write-in votes” and “multi-candidate punch-hole vector-ballots”; both of our designs can be instantiated over any homomorphic encryption function.	blind signature;character encoding;cryptography;electronic signature;emoticon;formal verification;homomorphic encryption;mix network;user interface	Aggelos Kiayias;Moti Yung	2004		10.1007/978-3-540-27809-2_9	homomorphic encryption;telecommunications;computer science;cryptography;artificial intelligence;operating system;database;distributed computing;user interface;blind signature;world wide web;computer security;encryption;algorithm;payment	Security	-44.39670751346486	77.28741548849888	133519
b002a04b99dc110e9b03ef1201de7f8855796974	analysis and design of protocol for enhanced threshold proxy signature scheme based on rsa for known signers	protocol for enhanced threshold proxy signature scheme;rsa cryptosystem for known signers;secret sharing;lagrange coefficient;threshold scheme;proxy signature	Many threshold proxy signature schemes are proposed in which the t out of n threshold schemes are deployed; but they still lack the property of security. In this research paper, secret sharing proxy signature could permit the shares of designated signers, called proxy signers, renew their own proxy shares periodically without changing the secret. In particular, our scheme applies the (t, n) threshold proxy signature scheme and allows any t or more then t signers to form a designated group from n proxy signers to sign messages on behalf of the original signer. In the proposed scheme, furthermore, a proxy signer can recover his/her own share from t other proxy shares without revealing any information about other proxy shares. Unless more than t other proxy signers cooperate and collude, the secret share algorithm is always secure. We compare the performance of four schemes: Hwang et al., Wen et al., Geng et al. and Fengying et al. with the performance of a scheme that has been proposed by the authors of this article earlier. In the proposed scheme, both the combiner and the secret share holder can verify the correctness of the information that they are receiving from each other. Therefore, the enhanced threshold proxy signature scheme is secure and efficient against notorious conspiracy attacks.	scheme	Raman Kumar;Harsh Kumar Verma;Renu Dhir	2015	Wireless Personal Communications	10.1007/s11277-014-2087-2	computer science;mathematics;internet privacy;secret sharing;world wide web;computer security;statistics	Mobile	-42.73908806829561	74.65412894952121	133622
28b5bbfb9f1b4738d6ed567d62fdfe52be9cb11e	simplified vss and fast-track multiparty computations with applications to threshold cryptography	zero knowledge proof;verifiable secret sharing;threshold cryptography;multiparty computation	The goal of this paper is to introduce a simple verifiable secret sharing scheme, to improve the efficiency of known secure multiparty protocols and, by employing these techniques, to improve the efficiency of applications which use these protocols. First we present a very simple Verifiable Secret Sharing protocol which is based on fast cryptographic primitives and avoids altogether the need for expensive zero-knowledge proofs. This is followed by a highly simplified protocol to compute multiplications over shared secrets. This is a major component in secure multiparty computation protocols and accounts for much of the complexity of proposed solutions. Using our protocol as a plug-in unit in known protocols reduces their complexity. We show how to achieve efficient multiparty computations in the computational model, through the application of homomorphic commitments. Finally, we present fast-track multiparty computation protocols. In a model in which malicious faults are rare we show that it is possible to carry out a simpler and more efficient protocol which does not perform all the expensive checks needed to combat a malicious adversary from foiling the computation. Yet, the protocol still enables detection of faults and recovers the computation when faults occur without giving any information advantage to the adversary. This results in protocols which are much more efficient under normal operation of the system i.e. when there are no faults. As an example of the practical impact of our work we show how our techniques can be used to greatly improve the speed and the fault-tolerance of existing threshold cryptography protocols. * IBM T.J. Watscm Research Center, PO Box 704, Yorktowo Heights, New York 10598, USA Email: rosarioOwatsotl.ibnl.coln. + Harvard University sod Hebrew University. Email: rabin@cs.huii.ac.il * IBM ‘f.J. Watsoo Research Center, PO Box 704, Yorktowo Heights, New York 10598, USA Email: talrOwatsoll.ibtn.corlr. Contact author Permission to make digital or hard copies of all or part of this work for pelmal cr ClassroOm use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear tbii notice and the fit11 citation on the fti page. To copy otherwise, to republish, to post on servers or to redisbibute to lists, requires prior specific permission a&or a fee. PODC 98 Fkerto Vallarta Mexico Copyright ACM 1998th89791.97%7/9816...$5.00	adversary (cryptography);computational model;cryptography;email;fault tolerance;homomorphic encryption;malware;podc;plug-in (computing);secure multi-party computation;shared secret;thomas j. watson research center;verifiable secret sharing;zero-knowledge proof	Rosario Gennaro;Michael O. Rabin;Tal Rabin	1998		10.1145/277697.277716	computer science;theoretical computer science;distributed computing;secure multi-party computation;computer security;verifiable secret sharing;algorithm;zero-knowledge proof	Crypto	-41.51685885428703	74.52034803230049	133698
2ae08343b194eae4dbb4c152f0797221f171e477	lower bounds and impossibility results for concurrent self composition	oblivious transfer;lower bounds;secure computation;securite informatique;simulation;communication complexity;impossibility results;complexite communication;simulacion;self and general composition;securite donnee;computer security;criptografia;cryptography;seguridad informatica;non black box and black box simulation;borne inferieure;cryptographie;protocol composition;protocol composition self and general composition;blind signature;security of data;large classes;lower bound;security protocol;cota inferior	In the setting of concurrent self composition, a single protocol is executed many times concurrently in a network. In this paper, we prove lower bounds and impossibility results for secure protocols in this setting. First and foremost, we prove that there exist large classes of functionalities that cannot be securely computed under concurrent self composition, by any protocol. We also prove a communication complexity lower bound on protocols that securely compute a large class of functionalities in this setting. Specifically, we show that any protocol that computes a functionality from this class and remains secure for m concurrent executions, must have bandwidth of at least m bits. The above results are unconditional and hold for any type of simulation (i.e., even for non-black-box simulation). In addition, we prove a severe lower bound on protocols that are proven secure using black-box simulation. Specifically, we show that any protocol that computes the blind signature or oblivious transfer functionalities and remains secure for m concurrent executions, where security is proven via black-box simulation, must have at least m rounds of communication. Our results hold for the plain model, where no trusted setup phase is assumed. While proving our impossibility results, we also show that for many functionalities, security under concurrent self composition (where a single secure protocol is run many times) is actually equivalent to the seemingly more stringent requirement of security under concurrent general composition (where a secure protocol is run concurrently with other arbitrary protocols). This observation has significance beyond the impossibility results that are derived by it for concurrent self composition.	bandwidth (signal processing);black box;blind signature;communication complexity;concurrent computing;existential quantification;foremost;oblivious transfer;provable security;simulation	Yehuda Lindell	2004	Journal of Cryptology	10.1007/s00145-007-9015-5	universal composability;computer science;cryptography;oblivious transfer;communication complexity;distributed computing;blind signature;computer security;algorithm	Crypto	-37.80104366091642	75.00719035031415	133910
08dcc4838468659ceb14fac96fc45b8d34dd4ab1	ephemeral key compromise attack on the ib-ka protocol		Recently, Dario Fiore and Rosario Gennaro proposed the IB-KA protocol, which was inspired by MQV protocol. They provide a full proof of security of IB-KA protocol using techniques developed by Krawczyk in the Canetti-Krawczyk model. They designed the IB-KA protocol with some security properties such as perfect forward secrecy, reflection attack resilience, and key compromise impersonation resilience. But they didn’t consider ephemeral key compromise problem in the design of IB-KA protocol, and made no analysis whether the IB-KA protocol can resist ephemeral key compromise attacks. In this paper, we present ephemeral key compromise attack on the the IB-KA protocol. Our work shows that the IB-KA protocol is designed without ephemeral key compromise resilience.	communications protocol;ephemeral key;forward secrecy;ka band;reflection attack	Qingfeng Cheng;Chuangui Ma	2009	IACR Cryptology ePrint Archive		reflection attack;psychological resilience;forward secrecy;ephemeral key;mqv;compromise;distributed computing;computer science	Security	-42.37313699566861	75.96869024226872	134028
421aed3c0e9dbb1cc1b1e7323119703dc7b5bf04	enhanced safer+ algorithm for bluetooth to withstand against key pairing attack		The SAFER+-128 algorithm is the basis of all block ciphers used in Bluetooth security environment. Though the SAFER+ with key size 128 bits has yet not any practical attack on it, the pairing mechanism of bluetooth which uses this algorithm founds to be vulnerable to the brute force attack upon it. In the enhanced SAFER+ algorithm the shuffling parameter of SAFER+ has been customized in order to provide it strength against the key pairing attack. The results of the experiments and other statistical details obtained for this change are shown at the end of this paper.	algorithm;bluetooth	Payal Chaudhari;Hiteishi Diwanji	2012		10.1007/978-3-642-31513-8_66	engineering;internet privacy;computer security;computer network	Crypto	-45.51744110611923	75.1760613094836	134259
43292a6506005ea5265c50ee1630776f154123ca	security weakness in an authenticated group key agreement protocol in two rounds	public key cryptography;cryptographie cle publique;protocole transmission;securite;authentication;group communication;authentification;protocolo transmision;it security;autenticacion;safety;security key;cle securite;seguridad;group key agreement;llave seguridad;transmission protocol	Dutta and Barua recently proposed an efficient authenticated group key agreement protocol for dynamic membership. To reduce computation overhead, the protocol makes use of a simplified authentication mechanism such that only two neighbors of a participant check if a message is originated from the participant. In this paper, we show that the authenticated group key agreement protocol has some security breaches caused by the restrictive authentication. In addition, we present a simple method to fix the security breaches and prove its security under the standard assumptions.	authentication;group key;key-agreement protocol	Jung Yeon Hwang;Kyu Young Choi;Dong Hoon Lee	2008	Computer Communications	10.1016/j.comcom.2008.07.005	security association;telecommunications;computer science;authentication;internet privacy;computer security	Crypto	-43.187923009060675	75.89010645101567	134422
bb26a35934bc1e455cdb6f3596f6282612f0f3d6	an id-based quadratic-exponentiation randomized cryptographic scheme	encryption;dlp and ifp public key cryptosystem id based cryptosystem key authentication center kac qer;encryption elliptic curve cryptography face;decryption algorithms id based quadratic exponentiation randomized cryptographic scheme discrete logarithm problem integer factorization problem;elliptic curve cryptography;matrix decomposition cryptography;face	In this paper, we presented an ID-based Quadratic-Exponentiation Randomized (QER) Cryptosystem under the security assumptions of the discrete logarithm problem (DLP) and integer factorization problem (IFP). We consider the security against a conspiracy of some entities in the proposed system and show the possibility of establishing a more secure system. The obtained results show the special outcomes from the point view of security as we face the issue of solving IFP and DLP simultaneously in the multiplicative group of finite fields as compared to the other ID-based cryptographic scheme. Our proposed scheme requires a nominal operation in encryption and decryption algorithms, which makes it very effective and powerful.	cryptography;cryptosystem;digital light processing;discrete logarithm;encryption;entity;integer factorization;randomized algorithm	Chandrashekhar Meshram;Mohammad S. Obaidat	2015	2015 International Conference on Computer, Information and Telecommunication Systems (CITS)	10.1109/CITS.2015.7297722	arithmetic;discrete mathematics;theoretical computer science;post-quantum cryptography;cryptosystem;mathematics;elliptic curve cryptography	Crypto	-40.01970131664359	74.86093593194701	134588
6da57d5e4092d33ae1a0138d3bb43f37fcbb303f	design of a lattice-based access control scheme	silicon;key management;lattice based access control;and rekeying;lattices;authorisation;access control lattices cryptography computer science resource management cybernetics usa councils algorithm design and analysis permission;cryptographic keys lattice based access control dynamic key management hierarchical access control;data mining;cryptography authorisation;cryptographic keys;rekeying;cryptography;and rekeying access control cryptographic keys cryptography dynamic key management hierarchical access control lattice;access control;hierarchical access control;copper;algorithm design and analysis;lattice;partial order;dynamic key management	We survey the literature for access control schemes in a user hierarchy. Some schemes have already been shown to be insecure or incorrect. Many schemes assume very restrictive subordinating relationships existing in a hierarchy where users are grouped into partially ordered relationships without taking resources into consideration. We believe that a practical access control scheme should support access control in a lattice where users and resources are both together grouped into partially ordered relationships. In this paper, we present a scheme to achieve this goal. We also study existing schemes for their efficiency and performance. Based on the results of the study, we design an efficient scheme to support dynamic key management.	computer performance;key management;lattice-based access control	Chia-Chu Chiang;Coskun Bayrak;Remzi Seker;Umit Topaloglu;R. Murat Demirer;Nasrola Samadi;Suleyman Tek;Jiang Bian;GuangXu Zhou;Xiaoran Wang	2009	2009 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2009.5346329	computer science;lattice;distributed computing;computer security;computer network	DB	-47.61499213384426	77.34423236572908	134761
6a41248e00bfed86c3c6abc37b3d48cd8e5f0542	quantum key agreement with epr pairs and single-particle measurements	collective noise;information quantique;estado cuantico;llave cambio;criptografia cuantica;protocole transmission;escucha secreta;estado de bell;cryptographie quantique;quantum information;efficiency;ruido collectivo;bell states;quantum key agreement;quantum state;echange cle;cle publique;single particle measurements;attaque informatique;equite;equidad;quantum computation;etat bell;protocolo transmision;eficacia;etat quantique;informacion cuantica;equity;communication quantique;public key;key exchange;canal quantique;bruit collectif;security key;llave publica;canal cuantico;computer attack;efficacite;quantum communication;ataque informatica;ecoute clandestine;comunicacion cuantica;calcul quantique;block transmission;quantum cryptography;cle securite;eavesdropping;calculo cuantico;epr pairs;quantum channel;llave seguridad;transmission protocol	In this paper, we present a QKA protocol with the block transmission of EPR pairs. There are several advantages in this protocol. First, this protocol can guarantee both the fairness and security of the shared key. Second, this protocol has a high qubit efficiency since there is no need to consume any quantum state except the ones used for establishing the shared key and detecting eavesdropping. In addition, this protocol uses EPR pairs as the quantum information carriers and further utilizes single-particle measurements as the main operations. Therefore, it is more feasible than the protocols that need to perform Bell measurements. Especially, we also introduce a method for sharing EPR pairs between two participants over collective-dephasing channel and collective-rotation channel, respectively. This method is meaningful since sharing EPR pairs between two participants is an important work in many quantum cryptographic protocols, especially in the protocols over non-ideal channels. By utilizing this method, the QKA protocols, which are based on EPR pairs, can be immune to these kinds of collective noise.	epr paradox;key-agreement protocol;quantum	Wei Huang;Qiaoyan Wen;Bin Liu;Fei Gao;Ying Sun	2014	Quantum Information Processing	10.1007/s11128-013-0680-z	quantum state;quantum information;bell state;quantum information science;key exchange;efficiency;public-key cryptography;quantum channel;quantum computer;equity;physics;quantum cryptography;quantum mechanics	Theory	-43.74093571254871	78.11270723060518	134979
c0f83ed05100848a60abf82940f3374c972381e8	team: trust-extended authentication mechanism for vehicular ad hoc networks	vehicular ad hoc networks cryptography trusted computing;vehicular ad hoc networks vanets authentication decentralized lightweight trust extended;authentication vehicular ad hoc networks phase shift keying resistance;team session key agreement man in the middle attack resistance perfect forward secrecy fast error detection no verification table no clock synchronization problem replay attack resistance modification attack resistance forgery attack resistance mutual authentication location privacy vehicle to vehicle communication networks decentralized lightweight authentication scheme asymmetric cryptography secure authentication schemes wireless mobile networking vanet vehicular ad hoc networks trust extended authentication mechanism	The security of vehicular ad hoc networks (VANETs) has been receiving a significant amount of attention in the field of wireless mobile networking because VANETs are vulnerable to malicious attacks. A number of secure authentication schemes based on asymmetric cryptography have been proposed to prevent such attacks. However, these schemes are not suitable for highly dynamic environments such as VANETs, because they cannot efficiently cope with the authentication procedure. Hence, this still calls for an efficient authentication scheme for VANETs. In this paper, we propose a decentralized lightweight authentication scheme called trust-extended authentication mechanism (TEAM) for vehicle-to-vehicle communication networks. TEAM adopts the concept of transitive trust relationships to improve the performance of the authentication procedure and only needs a few storage spaces. Moreover, TEAM satisfies the following security requirements: anonymity, location privacy, mutual authentication, forgery attack resistance, modification attack resistance, replay attack resistance, no clock synchronization problem, no verification table, fast error detection, perfect forward secrecy, man-in-the-middle attack resistance, and session key agreement.	clock synchronization;cryptanalysis;digital identity;error detection and correction;exclusive or;features new to windows 8;forward secrecy;hash function;hoc (programming language);intrusion detection system;key-agreement protocol;man-in-the-middle attack;mutual authentication;network security;public-key cryptography;replay attack;requirement;routing;session key;telecommunications network;vehicle-to-vehicle	Ming-Chin Chuang;Jeng-Farn Lee	2011	IEEE Systems Journal	10.1109/JSYST.2012.2231792	vehicular ad hoc network;optimized link state routing protocol;mobile ad hoc network;challenge–response authentication;authentication protocol;ad hoc wireless distribution service;lightweight extensible authentication protocol;internet privacy;computer security;computer network	Security	-45.32492071378712	75.27503542600037	135084
dff013db15045ec0092344460dc4186e98ced065	strong id-based key distribution	tecnologia electronica telecomunicaciones;session state;identity based encryption;cryptage base identite;securite donnee;key independence;cifrado fundado sobre identidad;id based;tecnologias;grupo a;long term key;security of data;key distribution	Several ID-based key distribution schemes can be used to realize secure broadcasting systems. Unfortunately, none of the proposed schemes provide both security against long-term key reveal attacks and security against session state reveal attacks. In this letter, we suggest an ID-based key distribution scheme secure against long-term key reveal attacks and session state reveal attacks.	key distribution	Ik Rae Jeong;Jeong Ok Kwon;Dong Hoon Lee	2008	IEICE Transactions	10.1093/ietcom/e91-b.1.306	computer science;internet privacy;world wide web;key distribution;computer security	Crypto	-43.66937305970014	77.02554101459714	135388
63a345467d0a2ae758762e931644204ce95ffcf4	wireless sensor networks: a survey on the state of the art and the 802.15.4 and zigbee standards	gestion energia;distributed system;red sin hilo;reseau capteur;gestion memoire;systeme reparti;zibbee;reseau sans fil;ieee 802 15 4;energy efficient;surveillance;storage management;securite informatique;wireless network;data management;emerging technology;wireless sensor network;computer security;gestion memoria;vigilancia;red sensores;sistema repartido;gestion energie;monitoring;zigbee;seguridad informatica;sensor array;monitorage;monitoreo;article;wireless sensor networks;mac layer;energy management	Wireless sensor networks are an emerging technology for low-cost, unattended monitoring of a wide range of environments, and their importance has been enforced by the recent delivery of the IEEE 802.15.4 standard for the physical and MAC layers and the forthcoming Zigbee standard for the network and application layers. The fast progress of research on energy efficiency, networking, data management and security in wireless sensor networks, and the need to compare with the solutions adopted in the standards motivates the need for a survey on this field.		Paolo Baronti;Prashant Pillai;Vince W. C. Chook;Stefano Chessa;Alberto Gotta;Yim-Fun Hu	2007	Computer Communications	10.1016/j.comcom.2006.12.020	embedded system;neurfon;wireless sensor network;wireless site survey;telecommunications;data management;computer science;wireless network;key distribution in wireless sensor networks;computer security	Mobile	-46.98089314102652	79.72048329416535	135482
89726045eae1d6156bd66b64257dc78569cbddf8	fault attack on elliptic curve montgomery ladder implementation	montgomery ladder;elliptic curve montgomery ladder method;secg;nist;geometry cryptography;scalar product;complexity theory;elliptic curves;elliptic curve;ec cryptosystem;geometry;secg fault attack elliptic curve montgomery ladder method elliptic curve scalar product algorithms nist;elliptic curve cryptography;registers;cryptography;fault attack;cryptography elliptic curves elliptic curve cryptography registers complexity theory security galois fields;fault attack ec cryptosystem montgomery ladder;elliptic curve scalar product algorithms;security;galois fields	In this paper, we present a new fault attack on elliptic curve scalar product algorithms. This attack is tailored to work on the classical Montgomery ladder method when the y-coordinate is not used. No weakness has been reported so far on such implementations, which are very efficient and were promoted by several authors. But taking into account the twist of the elliptic curves, we show how, with few faults (around one or two faults), we can retrieve the full secret exponent even if classical countermeasures are employed to prevent fault attacks. It turns out that this attack has not been anticipated as the security of the elliptic curve parameters in most standards can be strongly reduced. Especially, the attack is meaningful on some NIST or SECG parameters.	algorithm;computation;differential fault analysis;elliptic curve cryptography;fault model;montgomery modular multiplication;secg	Pierre-Alain Fouque;Reynald Lercier;Denis Réal;Frédéric Valette	2008	2008 5th Workshop on Fault Diagnosis and Tolerance in Cryptography	10.1109/FDTC.2008.15	arithmetic;discrete mathematics;theoretical computer science;mathematics	Crypto	-39.39681691157897	81.45788658351508	135483
d24cd223d60a612219062cb0d6efeed7a5db9294	lighten encryption schemes for secure and private rfid systems	institutional repositories;fedora;public key cryptosystem;privacy preservation;vital;general methods;vtls;ils	We provide several concrete implementations of a generic method given by Vaudenay to construct secure privacy-preserving RFID authentication and identification systems. More precisely, we give the first instantiation of the Vaudenay’s result by using the IND-CCA secure DHAES cryptosystem. Next we argue that weaker cryptosystems can also be used by recalling the WIPR RFID system and giving a new protocol based on the El Gamal encryption scheme. After that, we introduce a new generic construction based on the use of any IND-CPA secure public key cryptosystem together with a MAC scheme and describe a possibility using the Hash El Gamal cryptosystem. We finally compare all these schemes, both in terms of implementation and security, proving that, nowadays the DHAES and our Hash El Gamal based solutions appear as the most promising schemes.	authentication;ciphertext indistinguishability;computation;cryptosystem;encryption;gate equivalent;hash function;precomputation;public-key cryptography;radio-frequency identification;universal instantiation	Sébastien Canard;Iwen Coisel;Jonathan Etrog	2010		10.1007/978-3-642-14992-4_3	goldwasser–micali cryptosystem;computer science;cryptosystem;hybrid cryptosystem;internet privacy;world wide web;computer security	Security	-41.32966770304438	75.71992778037698	135541
6135ab33b1713447f448281e417a74d3dfb3f6f0	on the security of hfe, hfev- and quartz	public key cryptography;hfe problem;multivariate cryptanalysis;cryptographie cle publique;finite fields;quartz;cryptanalyse;grobner basis;base grobner;grobner bases;corps fini;cryptanalysis;finite field;criptoanalisis;hidden field equation;asymmetric cryptography;criptografia;cryptography;campo finito;cryptographie;nessie project	Quartz is a signature scheme based on an HFEvtrapdoor function published at Eurocrypt 1996. In this paper we study ”inversion” attacks for Quartz, i.e. attacks that solve the system of multivariate equations used in Quartz. We do not cover some special attacks that forge signatures without inversion. We are interested in methods to invert the HFEvtrapdoor function or at least to distinguish it from a random system of the same size. There are 4 types of attacks known on HFE: Shamir-Kipnis [27], Shamir-KipnisCourtois [8], Courtois [8], and attacks related to Gröbner bases such as the F5/2 attack by Jean Charles Faugère [15, 16]. No attack has been published so far on HFEvand it was believed to be more secure than HFE. In this paper we show that even modified HFE systems can be successfully attacked. It seems that the complexity of the attack increases by at least a factor of q with tot being the total number of perturbations in HFE. From this and all the other known attacks we will estimate what is the complexity of the best ”inversion” attack for Quartz.	antivirus software;asiacrypt;computation;digital signature;eurocrypt;forge;gröbner basis;human factors and ergonomics;jean;mceliece cryptosystem;nessie;public-key cryptography;quartz (graphics layer);stochastic process;trapdoor function	Nicolas Courtois;Magnus Daum;Patrick Felke	2002		10.1007/3-540-36288-6_25	theoretical computer science;mathematics;public-key cryptography;computer security;finite field;algorithm;algebra	Security	-39.624647504941066	80.79503310990879	135650
4425013d7183846480a268f42195e3428b5e3546	a user authentication scheme with identity and location privacy	movilidad;confidencialidad;protocole transmission;telecommunication sans fil;mobility;authentication;exigence usager;exigencia usuario;cle publique;public key cryptosystem;mobilite;satisfiability;confidentiality;authentification;confidentialite;protocolo transmision;authenticated key agreement;mobile environment;autenticacion;public key;criptografia;user requirement;telecomunicacion sin hilo;cryptography;security requirements;llave publica;discrete logarithm problem;cryptographie;interaction protocol;location privacy;user authentication;wireless systems;digital signature scheme;wireless telecommunication;transmission protocol	The rapid growth of wireless systems provides us with mobility. In mobile environments, authentication of a user and confidentiality of his identity and location are two major security issues, which seem incompatible with each other. In this manuscript, we propose a user authentication scheme with identity and location privacy. This scheme is an interactive protocol based on public key cryptosystems. In the proposed scheme, to prove his authenticity, a user utilizes a digital signature scheme based on a problem with a random self-reducible relation such as the square root modulo a composite number problem and the discrete logarithm problem. We also define the security requirements for user authentication with identity and location privacy, impersonationfreeness and anonymity, against active attacks, and prove that the proposed scheme satisfies them assuming the security of the cryptographic schemes used in the scheme. Furthermore, we show that we can construct authenticated key agreement schemes by applying the proposed scheme to some existing authenticated key agreement schemes.	authentication;confidentiality;cryptosystem;digital signature;discrete logarithm;function problem;key-agreement protocol;modulo operation;privacy;provable security;public-key cryptography;random self-reducibility;requirement	Shoichi Hirose;Susumu Yoshida	2001		10.1007/3-540-47719-5_20	computer science;authentication;internet privacy;mobile computing;computer security;computer network	Security	-44.5859906980633	76.58959165296949	135685
2d11fcf34f312d8e67bd195d7f681c89c459f6a8	data security in a fixed-model arithmetic coding compression algorithm	compression algorithm;arithmetic coding;data security	The data security provided by a fixed-model arithmetic coding compression algorithm is investigated. The ''key'' to this proposed encryption system comprises the source symbol table and associated frequencies (the model). A chosen plaintext attack is described which allows determination of the key. The major weakness of the algorithm is the generation of non-random output. Repeating binary strings are produced upon input of long strings of one source symbol. This feature can be used to determine the ordering of the symbols in the source symbol table and their associated frequencies. The key is thus discovered, allowing an attacker to decipher intercepted messages. Security may be improved by choosing random symbol ordering and random frequencies. This adversely affects the performance and compression characteristics, however. The algorithm is not recommended for encryption purposes.	algorithm;arithmetic coding;data compression;data security	Helen A. Bergen;James M. Hogan	1992	Computers & Security	10.1016/0167-4048(92)90011-F	data compression;arithmetic coding;computer science;theoretical computer science;data security;context-adaptive binary arithmetic coding;computer security;algorithm	Crypto	-35.996364902658854	80.54462055886059	135788
8bb371da164806900e2c4a710241ef5a2bca8600	certified encryption revisited	security model;identity based encryption;certificateless encryption;multi user;security models;certified encryption;corrupt decryption	The notion of certified encryption had recently been suggested as a suitable setting for analyzing the security of encryption against adversaries that tamper with the key-registration process. The flexible syntax afforded by certified encryption suggests that identity-based and certificateless encryption schemes can be analyzed using the models for certified encryption. In this paper we explore the relationships between security models for these two primitives and that for certified encryption. We obtain the following results. We show that an identity-based encryption scheme is secure if and only if it is secure when viewed as a certified encryption scheme. This result holds under the (unavoidable) restriction that registration occurs over private channels. In the case of certificateless encryption we observe that a similar result cannot hold. The reason is that existent models explicitly account for attacks against the non-monolithic structure of the secret keys whereas certified encryption models treat secret keys as whole entities. We propose an extension for certified encryption where the adversary is allowed to partially modify the secret keys of honest parties. The extension that we propose is very general and may lead to unsatisfiable notions. Nevertheless, we exhibit one instantiation for which we can prove the desired result: a certificateless encryption is secure if and only if its associated certified encryption scheme is secure. As part of our analysis, and a result of separate interest we confirm the folklore belief that for both IBE and CLE, security in the single-user setting (as captured by existent models) is equivalent to security in the multi-user setting.	adversary (cryptography);conformal loop ensemble;entity;id-based encryption;multi-user;universal instantiation	Pooya Farshim;Bogdan Warinschi	2009		10.1007/978-3-642-02384-2_12	multiple encryption;h.235;disk encryption theory;40-bit encryption;plaintext-aware encryption;client-side encryption;theoretical computer science;symmetric-key algorithm;link encryption;mathematics;on-the-fly encryption;internet privacy;disk encryption hardware;deterministic encryption;computer security;encryption;probabilistic encryption;56-bit encryption;attribute-based encryption	Crypto	-39.44091251167033	74.7454456959762	135792
a06218574abcbf74a74e0dd9942cad241fb283e3	robust dynamic user authentication scheme for wireless sensor networks	strong password based authentication;wireless sensor network;password based authentication;user authentication	In recent years, wireless sensor networks (WSNs) have been widely used in different domains. For instance, WSNs can be deployed in insecure and unattended environments. In this regard, user authentication is a critical issue for WSNs. In this paper, we propose a user authentication protocol in WSNs, which is variation of strong-password based solution proposed by Wong et al. The proposed protocol is evaluated and compared with the previous schemes.	authentication protocol;password	Binod Vaidya;Jorge Sá Silva;Joel Jos&#x00E9; P. C. Rodrigues	2009		10.1145/1641944.1641962	s/key;challenge–response authentication;computer science;authentication protocol;lightweight extensible authentication protocol;key distribution in wireless sensor networks;internet privacy;computer security;challenge-handshake authentication protocol;computer network	Mobile	-47.118573175493104	74.61381223380853	136411
9aa299d878bcd14cc803cd866c04d39a0cfdb7cf	implementing cryptographic primitives in the symbolic model	one way function;computer model;symmetric encryption	When discussing protocol properties in the symbolic (DolevYao; term-based) model of cryptography, the set of cryptographic primitives is defined by the constructors of the term algebra and by the equational theory on top of it. The set of considered primitives is not easily modifiable during the discussion. In particular, it is unclear what it means to define a new primitive from the existing ones, or why a primitive in the considered set may be unnecessary because it can be modeled using other primitives. This is in stark contrast to the computational model of cryptography where the constructions and relationships between primitives are at the very foundation of the theory. In this paper, we explore how a primitive may be constructed from other primitives in the symbolic model, such that no protocol breaks if an atomic primitive is replaced by the construction. As an example, we show the construction of (symbolic) “randomized” symmetric encryption from (symbolic) one-way functions and exclusive or.	computational model;cryptographic primitive;cryptography;encryption;exclusive or;linearizability;michael luby;one-way function;powerset construction;pseudorandomness;randomized algorithm;refinement (computing);simulation;symmetric-key algorithm;term algebra	Peeter Laud	2011		10.1007/978-3-642-20398-5_20	computer simulation;discrete mathematics;computer science;theoretical computer science;cryptographic protocol;symmetric-key algorithm;mathematics;symbolic data analysis;one-way function;symbolic trajectory evaluation;algorithm	Security	-36.04170732648486	74.5250147950759	136539
031b8ce3268aed29a1ca824934095c130e9d9bdc	torus-based cryptography	public key	We introduce the concept of torus-based cryptography, give a new public key system called CEILIDH, and compare it to other discrete log based systems including Lucas-based systems and XTR. Like those systems, we obtain small key sizes. While Lucas-based systems and XTR are essentially restricted to exponentiation, we are able to perform multiplication as well. We also disprove the open conjectures from [2], and give a new algebro-geometric interpretation of the approach in that paper and of LUC and XTR.	discrete logarithm;key size;public-key cryptography;torus-based cryptography;xtr	Karl Rubin;Alice Silverberg	2003		10.1007/978-1-4419-5906-5_481	strong cryptography;financial cryptography;neural cryptography;pkcs #1;pairing-based cryptography;cryptography standards	Crypto	-39.51920908469934	79.90859131242205	136610
305494f81a8f0489f2fd2e53f2129aa2857df4d7	invertibility attack against watermarking based on forged algorithm and a countermeasure	digital watermarking;digital watermark;invertibility attack;protocol	It is shown in this paper that, even with a non-invertible watermarking algorithm or an asymmetric watermarking protocol, it is still possible to effect an invertibility attack, which relies on a forged watermarking algorithm, a counterfeit mark, and a fake key. Two examples are given to show the vulnerability of the unfortified non-invertible algorithm/ asymmetric protocol. As a solution, a secure watermarking protocol is proposed, which establishes correlation between the watermarking algorithm and the embedded mark. 2004 Elsevier B.V. All rights reserved.	algorithm;authentication;digital watermarking;embedded system;imperative programming;sensor;watermark (data file)	Xinpeng Zhang;Shuozhong Wang	2004	Pattern Recognition Letters	10.1016/j.patrec.2004.02.007	watermarking attack;digital watermarking;computer science;theoretical computer science;mathematics;internet privacy;computer security	EDA	-43.5225330007567	75.43730160751284	136613
18462dd4c5fe532f5d295b915eba65ed73873a91	improved non-committing encryption with applications to adaptively secure protocols	adaptive corruption;secure multi party computation;multi party computation;public key encryption;public key;common reference string;security protocol;non committing encryption	We present a new construction of non-committing encryption schemes. Unlike the previous constructions of Canetti et al. (STOC ’96) and of Damgård and Nielsen (Crypto ’00), our construction achieves all of the following properties: – Optimal round complexity. Our encryption scheme is a 2-round protocol, matching the round complexity of Canetti et al. and improving upon that in Damgård and Nielsen. – Weaker assumptions. Our construction is based on trapdoor simulatable cryptosystems, a new primitive that we introduce as a relaxation of those used in previous works. We also show how to realize this primitive based on hardness of factoring. – Improved efficiency. The amortized complexity of encrypting a single bit is O(1) public key operations on a constant-sized plaintext in the underlying cryptosystem. As a result, we obtain the first non-committing public-key encryption schemes under hardness of factoring and worst-case lattice assumptions; previously, such schemes were only known under the CDH and RSA assumptions. Combined with existing work on secure multi-party computation, we obtain protocols for multi-party computation secure against a malicious adversary that may adaptively corrupt an arbitrary number of parties under weaker assumptions than were previously known. Specifically, we obtain the first adaptively secure multi-party protocols based on hardness of factoring in both the stand-alone setting and the UC setting with a common reference string.	adversary (cryptography);amortized analysis;best, worst and average case;common reference string model;computational diffie–hellman assumption;cryptosystem;encryption;integer factorization;linear programming relaxation;plaintext;public-key cryptography;secure multi-party computation;symposium on theory of computing;trapdoor function;uc browser	Seung Geol Choi;Dana Dachman-Soled;Tal Malkin;Hoeteck Wee	2009		10.1007/978-3-642-10366-7_17	multiple encryption;40-bit encryption;plaintext-aware encryption;computer science;secure two-party computation;theoretical computer science;distributed computing;public-key cryptography;deterministic encryption;computer security;probabilistic encryption;56-bit encryption	Crypto	-38.92212729197042	75.99577566721484	136739
65772383d41a2d26cdee87cfc85871491457be44	designated verifier proxy signature scheme without random oracles	provable security;identity based encryption;journal;security proof;standard model;digital signature;random oracle model;cryptography;bilinear pairings;random oracle;proxy signature;bilinear pairing;diffie hellman	In a designated verifier proxy signature scheme, one can delegate his or her signing capability to another user in such a way that the latter can sign messages on behalf of the former, but the validity of the resulting signatures can only be verified by the designated verifier. Several designated verifier proxy signature schemes have been proposed so far. However, most of the schemes were proven secure in the random oracle model, which has received a lot of criticism since the security proofs in the random oracle model are not sound with respect to the standard model. In this paper, we propose a new construction of designated verifier proxy signature whose security can be proven without using the random oracle model. Our scheme is inspired by Waters' Identity-based encryption. The unforgeability of our scheme is based on the hardness of Gap Bilinear Diffie-Hellman problem. As far as we know, this is the first designated verifier proxy signature secure in the standard model.	digital signature	Yong Yu;Chunxiang Xu;Xiaosong Zhang;Yongjian Liao	2009	Computers & Mathematics with Applications	10.1016/j.camwa.2009.01.032	random oracle;non-interactive zero-knowledge proof;mathematics;internet privacy;schnorr signature;world wide web;computer security;algorithm	Crypto	-41.4223297028853	75.70989704726502	136952
1b79d19c900e1bf00ea06fbc746fb0efa8775a1e	attack the dragon	elektroteknik och elektronik;analisis estadistico;time complexity;stream ciphering;securite;information technology;technologie information;probabilistic approach;complexite temps;stream cipher;statistical analysis;filter;criptografia;enfoque probabilista;cryptography;approche probabiliste;safety;analyse statistique;security key;registro dispersion;filtre;cryptographie;complejidad tiempo;cle securite;tecnologia informacion;seguridad;cifrado continuo;registre decalage;filtro;shift register;llave seguridad;cryptage continu	1 Dragon is a word oriented stream cipher submitted to the ECRYPT project, it operates on key sizes of 128 and 256 bits. The original idea of the design is to use a nonlinear feedback shift register (NLFSR) and a linear part (counter), combined by a filter function to generate a new state of the NLFSR and produce the keystream. The internal state of the cipher is 1088 bits, i.e., any kinds of TMD attacks are not applicable. In this paper we present two statistical distinguishers that distinguish Dragon from a random source both requiring around O(2) words of the keystream. In the first scenario the time complexity is around O(2) with the memory complexity O(2), whereas the second scenario needs only O(2) of time, but O(2) of memory. The attack is based on a statistical weakness introduced into the keystream by the filter function F . This is the first paper presenting an attack on Dragon, and it shows that the cipher does not provide full security when the key of size 256 bits is used.	algorithmic efficiency;ecrypt;key size;nonlinear feedback shift register;nonlinear system;stream cipher;time complexity;tip-magnetic driving	Håkan Englund;Alexander Maximov	2005		10.1007/11596219_11	time complexity;running key cipher;telecommunications;filter;computer science;cryptography;fluhrer, mantin and shamir attack;mathematics;shift register;stream cipher;information technology;computer security;algorithm;statistics	Crypto	-40.15835941055489	82.74039211446878	137301
06d3c6456589ae4e1c7eccf5809ecbc47412d8da	a framework for game-based security proofs	proof assistant;security properties;formal verication;semantic security;security proof;formal verification;game;security	To be accepted, a cryptographic scheme must come with a proof that it satisfies some standard security properties. However, because cryptographic schemes are based on non-trivial mathematics, proofs are error-prone and difficult to check. The main contributions of this paper are a refinement of the game-based approach to security proofs, and its implementation on top of the proof assistant Coq. The proof assistant checks that the proof is correct and deals with the mundane part of the proof. An interesting feature of our framework is that our proofs are formal enough to be mechanically checked, but still readable enough to be humanly checked. We illustrate the use of our framework by proving in a systematic way the so-called semantic security of the encryption scheme Elgamal and its hashed version.	cognitive dimensions of notations;coq (software);cryptographic protocol;cryptography;cryptology eprint archive;elliptic curve cryptography;encryption;functional programming;hash function;human-readable medium;id-based encryption;information and computation;lambda calculus;lecture notes in computer science;library (computing);lisp;mental poker;monad (functional programming);pp (complexity);parsing;probabilistic encryption;process calculus;proof assistant;provable security;public-key cryptography;refinement (computing);rewriting;semantic security;springer (tank);symposium on principles of programming languages;symposium on theory of computing;time complexity;yang	David Nowak	2007	IACR Cryptology ePrint Archive	10.1007/978-3-540-77048-0_25	computer security model;games;semantic security;probabilistically checkable proof;formal verification;computer science;information security;theoretical computer science;proof assistant;computer security;proof complexity;algorithm	Crypto	-35.87569311838628	74.79017339609648	137308
ec1ae0d879f426ec0c4351641bc543079d514093	kci-resilient anonymous wireless link-layer authentication protocols	wireless networks;kci resilience;link layer anonymity;security;privacy	Recently, many works have been focusing on solving the problem of privacy protection at link-layer level by randomizing all bits of the frames at link layer so that it makes difficult for unintended recipients to associate sequences of packets to their source transmitters. Most existing schemes however assume either the pre-setup for shared secrets between communication entities or the use of public-key infrastructure. These requirements limit the use of the schemes. In this paper, we describe new techniques for protecting the privacy and security of communication entities at wireless link-layer level. Our techniques have a number of crucial advantages. They mitigate the requirement of a key setup or a public-key infrastructure. They provide not only the link-layer privacy, but also the required security properties, including key compromise impersonation resilience, impersonation resistance and forward secrecy. They are simple and relatively fast.	authentication protocol;korea citation index	Eun-Kyung Ryu;Hyun-Sung Kim;Kee-Young Yoo	2012	Mathematical and Computer Modelling	10.1016/j.mcm.2012.01.018	information security;wireless network;internet privacy;privacy;computer security;computer network	Mobile	-46.61768847004219	75.70969485284631	137373
ae6530e9c04f67f00027bb0705071cbf1d1f8198	on concrete security treatment of signatures derived from identification	signature scheme;digital signature;criptografia;cryptography;identification;random oracle;signature numerique;cryptographie;identificacion	Signature schemes that are derived from three move identification schemes such as the Fiat-Shamir, Schnorr and modified ElGamal schemes are a typical class of the most practical signature schemes. The random oracle paradigm [1,2,12] is useful to prove the security of such a class of signature schemes [4,12]. This paper presents a new key technique, “ID reduction”, to show the concrete security result of this class of signature schemes under the random oracle paradigm. First, we apply this technique to the Schnorr and modified ElGamal schemes, and show the “concrete security analysis” of these schemes. We then apply it to the multi-signature schemes.	antivirus software;blind signature;concrete security;electronic signature;programming paradigm;random oracle;undeniable signature	Kazuo Ohta;Tatsuaki Okamoto	1998		10.1007/BFb0055741	random oracle;ring signature;identification;digital signature;discrete mathematics;merkle signature scheme;eddsa;computer science;cryptography;mathematics;blind signature;schnorr signature;elgamal signature scheme;computer security;algorithm	Crypto	-41.22134735645087	78.07063639608691	137506
db982e33d32fe058c88acf4f44268cf50c9a28c3	the wonderful world of global random oracles		The random-oracle model by Bellare and Rogaway (CCS’93) is an indispensable tool for the security analysis of practical cryptographic protocols. However, the traditional random-oracle model fails to guarantee security when a protocol is composed with arbitrary protocols that use the same random oracle. Canetti, Jain, and Scafuro (CCS’14) put forth a global but non-programmable random oracle in the Generalized UC framework and showed that some basic cryptographic primitives with composable security can be efficiently realized in their model. Because their random-oracle functionality is non-programmable, there are many practical protocols that have no hope of being proved secure using it. In this paper, we study alternative definitions of a global random oracle and, perhaps surprisingly, show that these allow one to prove GUC-secure existing, very practical realizations of a number of essential cryptographic primitives including public-key encryption, non-committing encryption, commitments, Schnorr signatures, and hash-and-invert signatures. Some of our results hold generically for any suitable scheme proven secure in the traditional ROM, some hold for specific constructions only. Our results include many highly practical protocols, for example, the folklore commitment scheme (mathcal {H}(mVert r)) (where m is a message and r is the random opening information) which is far more efficient than the construction of Canetti et al.	antivirus software;commitment scheme;cryptographic protocol;encryption;mihir bellare;public-key cryptography;random oracle;uc browser	Jan Camenisch;Manu Drijvers;Tommaso Gagliardoni;Anja Lehmann;Gregory Neven	2018		10.1007/978-3-319-78381-9_11	cryptographic primitive;theoretical computer science;encryption;cryptographic protocol;commitment scheme;random oracle;computer science;security analysis	Crypto	-39.015298919888124	75.99076780198943	137516
a72251f65b3c1594a45a0b795ddf151c4e2928f0	constrained prfs for unbounded inputs	constrained prfs;identity based non interactive key exchange;broadcast encryption	A constrained pseudorandom function F : K×X → Y for a family T ⊆ 2X of subsets of X is a function where for any key k ∈ K and set S ∈ T one can efficiently compute a constrained key kS which allows to evaluate F (k, ·) on all inputs x ∈ S, while even given this key, the outputs on all inputs x / ∈ S look random. At Asiacrypt’13 Boneh and Waters gave a construction which supports the most general set family so far. Its keys kC are defined for sets decided by boolean circuits C and enable evaluation of the PRF on any x ∈ X where C(x) = 1. In their construction the PRF input length and the size of the circuits C for which constrained keys can be computed must be fixed beforehand during key generation. We construct a constrained PRF that has an unbounded input length and whose constrained keys can be defined for any set recognized by a Turing machine. The only a priori bound we make is on the description size of the machines. We prove our construction secure assuming public-coin differing-input obfuscation. As applications of our constrained PRF we build a broadcast encryption scheme where the number of potential receivers need not be fixed at setup (in particular, the length of the keys is independent of the number of parties) and the first identity-based non-interactive key exchange protocol with no bound on the number of parties that can agree on a shared key.	boolean circuit;broadcast encryption;interactivity;key exchange;key generation;obfuscation (software);primitive recursive function;pseudorandom function family;symmetric-key algorithm;turing machine	Hamza Abusalah;Georg Fuchsbauer;Krzysztof Pietrzak	2014	IACR Cryptology ePrint Archive	10.1007/978-3-319-29485-8_24	combinatorics;discrete mathematics;theoretical computer science;mathematics	Crypto	-37.98300921898791	76.31233954974752	137808
78d6516e36acdb5ed261f0be183a94d94b04d519	memoryless related-key boomerang attack on the full tiger block cipher	time complexity;block cipher;tiger block cipher;differential cryptanalysis;related key boomerang attack;hash function	In this paper we present the first attack on the full 24 round internal block cipher of Tiger [1]. Tiger is a hash function proposed by Biham and Anderson at FSE'96. It takes about ten years until the first cryptanalytic result was presented by Kelsey and Lucks [10] at FSE'06. Up to now, the best known attack on the internal block cipher of Tiger is able to break 22 rounds. Our attack on the full 24 rounds of the Tiger block cipher has a data complexity of 23.5 chosen plaintexts and ciphertexts, which can be called memoryless. This is since we do not have to store all the data generated in our attack. The time complexity is about 2259.5 24-round Tiger encryptions. Moreover, we have further reduced the time complexity using a bit fixing technique to 2195.5 24-round encryptions.	block cipher;boomerang attack;related-key attack	Ewan Fleischmann;Michael Gorski;Stefan Lucks	2009		10.1007/978-3-642-00843-6_26	time complexity;rail fence cipher;block cipher;transposition cipher;triple des;key whitening;differential cryptanalysis;residual block termination;hash function;two-square cipher;running key cipher;ciphertext stealing;block cipher mode of operation;computer science;theoretical computer science;boomerang attack;stream cipher attack;distributed computing;stream cipher;slide attack;computer security;cbc-mac;algorithm;3-way;mdc-2	Crypto	-37.65127987794217	80.82343075444193	137977
a2a390f96c3beaa26e46a9fd8b8691c652908367	remarks on the security of the strong proxy signature scheme with proxy signer privacy protection	warrant;confiance;confidencialidad;securite informatique;serveur informatique;digital signatures;trust authority;signature electronique;indice aptitud;privacy protection;confidentiality;computer security;vida privada;indice aptitude;confidentialite;proxy signer identification;confidence;private life;confianza;capability index;digital signature;criptografia;cryptography;seguridad informatica;attacks;proxy signature;servidor informatico;trusted authority;cryptographie;vie privee;firma numerica;security;proxy signatures;computer server	In 1996, Mambo et al. introduced the proxy signature scheme for digital applications to delegate the signing capability to a proxy signer. Various constructions were made to devise a strong nondesignated proxy signature scheme. In 2002, Shum and Wei proposed an extended scheme to hide the identity of the proxy signer. A Trusted Authority (TA) can reveal the proxy signer’s identity if required. In this paper we show some possible attacks on this scheme.	digital signature;proxy server	Amit K. Awasthi	2010	IJICS	10.1504/IJICS.2010.031857	digital signature;computer science;information security;internet privacy;world wide web;computer security	Security	-43.53054713856325	76.5668524082105	138095
49539b8164a55c1b113468802de99363559d3f1b	secure real-time streaming protocol (rtsp) for hierarchical proxy caching	video proxy;multi-key rsa;real-time streaming protocol;asymmetric parametric sequence functions;security;real time streaming protocol;data confidentiality;quality of service;peak signal to noise ratio	Proxies are commonly used to cache objects, especially multimedia objects, so that clients can enjoy a better quality-of-service (QoS) guarantees such as smaller start-up latency and lower loss rate. But the use of multimedia proxies increases the risk that data are exposed to unauthorized access by intruders. In this paper, we propose an enhancement of the Internet IETF’s Real-time Streaming Protocol (RTSP) which employs a notion of “asymmetric reversible parametric sequence” (ARPS) to provide the following security properties: (i) data confidentiality during transmission, (ii) end-to-end data confidentiality, (iii) data confidentiality against proxy intruders, and (iv) data confidentiality against member collusion. We present the Secure Multimedia Library (SML) which is based on ARPS and then realize these security features on a production video streaming server: Apple’s Darwin Streaming Server. Our framework guarantees the system resilience against attacks is provably strong given the standard computability assumptions. To reduce the computation demand on the receiving client, our scheme only requires the client to perform a “single decryption operation” to recover the original data even though the data packets have been encrypted by multiple proxies along the delivery path. To tradeoff between degree of confidentiality and computational overhead, we also propose the use of a set of “encryption configuration parameters” (ECP) to trade off proxy encryption throughput against the presentation quality of audio/video obtained by unauthorized parties. Our implementation prototype shows that one can simultaneously achieve high encryption throughput and extremely low audio/video quality (in terms of audio fidelity, and peak signal-to-noise ratio and visual quality of decoded video frames) for unauthorized access.	application programming interface;authorization;code;computability;computation;confidentiality;darwin;encryption;end-to-end principle;mp3;mpeg-1;network packet;overhead (computing);peak signal-to-noise ratio;prototype;proxy server;quality of service;quicktime;real-time transcription;server (computing);streaming media;throughput	Siu Fung Yeung;John C. S. Lui;David K. Y. Yau	2008	I. J. Network Security		real time streaming protocol;confidentiality;quality of service;peak signal-to-noise ratio;computer science;information security;internet privacy;computer security;computer network	Security	-45.864898169362064	84.17949210582051	138311
6557300b69210ecae6a9617f68b1aeb26a7739ec	collision based attacks in practice	public key cryptography;standards;public key cryptosystem collision based attacks chosen message simple power analysis cba collision detection modular operation leakage traces noisy circuit;cryptography;standards collision avoidance signal to noise ratio algorithm design and analysis cryptography clustering algorithms;clustering algorithms;collision avoidance;signal to noise ratio;algorithm design and analysis	Chosen-Message Simple Power Analysis, also called Collision Based Attacks (CBA), have been proposed by Fouque, Yen and Homma. These attacks aim at inducing and detecting collisions during modular operations. However, detecting collisions is a challenging task in real environments. Doing it in an automated manner is even more challenging. In this paper, we propose and compare some methods and criteria allowing to automatically (without any visual inspection) detect the occurrence of collisions in leakage traces acquired on modern (and thus noisy) circuits.	collision attack;cryptosystem;experiment;inductive reasoning;k-means clustering;modular exponentiation;preprocessor;sensor;spectral leakage;tracing (software);visual inspection	Ibrahima Diop;Pierre-Yvan Liardet;Yanis Linge;Philippe Maurine	2015	2015 Euromicro Conference on Digital System Design	10.1109/DSD.2015.24	embedded system;telecommunications;computer science;cryptography;theoretical computer science;distributed computing;computer security;algorithm;computer network	Vision	-46.062433958960895	75.58399901441426	138590
d7826bd2d12f204ce57433ca6cce2c9e91eb079d	strong authentication and strong integrity (sasi) is not that strong	institutional repositories;fedora;lightweight cryptography;passive attack;authentication;vital;rfid;mutual authentication;vtls;privacy;ils;authentication protocol	In this work, we present a practical passive attack on SASI, an ultra-lightweight mutual authentication protocol for RFID. This attack can be used to reveal with overwhelming probability the secret ID of the prover by eavesdropping about 2 authentications. The result dismantles SASI and, more generally, provides a new approach that threatens ultra-lightweight authentication protocols.	adapter pattern;adversary (cryptography);authentication protocol;bitwise operation;cryptanalysis;hamming code;hamming weight;mutual authentication;passive attack;scsi;strong authentication;top-down and bottom-up design	Gildas Avoine;Xavier Carpent;Benjamin Martin	2010		10.1007/978-3-642-16822-2_5	reflection attack;challenge–response authentication;engineering;authentication protocol;lightweight extensible authentication protocol;internet privacy;world wide web;computer security;challenge-handshake authentication protocol	Crypto	-43.73667088104428	76.01272993837132	138706
2705dd3802348d522ecbbfa5c7791f06f3415433	on the security of a password-only authenticated three-party key exchange protocol		This note reports major previously unpublished security vulnerabilities in the password-only authenticated three-party key exchange protocol due to Lee and Hwang (Information Sciences, 180, 1702–1714, 2010): (1) the Lee-Hwang protocol is susceptible to a man-in-the-middle attack and thus fails to achieve implicit key authentication; (2) the protocol cannot protect clients’ passwords against an offline dictionary attack; and (3) the indistinguishability-based security of the protocol can be easily broken even in the presence of a passive adversary.	adversary (cryptography);dictionary attack;key authentication;key exchange;man-in-the-middle attack;online and offline;password;vulnerability (computing)	Junghyun Nam;Kim-Kwang Raymond Choo;Juryon Paik;Dongho Won	2013	IACR Cryptology ePrint Archive		otway–rees protocol;oakley protocol;reflection attack;universal composability;security association;challenge–response authentication;computer science;interlock protocol;authentication protocol;key-agreement protocol;wide mouth frog protocol;cryptographic protocol;internet privacy;world wide web;computer security	Crypto	-44.76741057361244	74.64022587353898	139202
5c8e006916e7cd1da3af93c894b4f48f4f94b7d2	an identity-based security mechanism for p2p voip	public key cryptography;security streaming media identity based encryption authentication peer to peer computing cryptographic protocols public key cryptography public key signal analysis robustness;computer network security;encryption;identity based encryption;signalling protocols computer network security data privacy internet telephony media streaming message authentication peer to peer computing public key cryptography;signal analysis;authentication;cryptographic protocols;p2p;p2p voip;internet telephony;media stream encryption p2p voip authenticated key agreement identity based cryptography;media;public key infrastructure identity based security mechanism p2p voip signaling protocol security authenticated key agreement identity based cryptography key escrow problem p2p voip media stream security privacy;authenticated key agreement;public key;data privacy;streaming media;identity based cryptography;media streaming;robustness;message authentication;peer to peer computing;security;media stream encryption;public key infrastructure;signalling protocols	According to P2P VoIP signaling protocol security and its distributed features, an authenticated key agreement scheme is proposed by using identity-based cryptography, security, efficiency and key escrow problems are analyzed. According to P2P VoIP media stream security, a secure media stream scheme is proposed and the application problems are discussed. Authentication and privacy are provided for P2P VoIP, security standard-setting is promoted for P2PSIP, while the disadvantages of Public Key Infrastructure are overcome.	authentication;id-based cryptography;identity-based security;key escrow;peer-to-peer sip;privacy;public key infrastructure;signaling protocol;streaming media	Hua Jiang;Xianru Du;Yongxing Jia;Weizhi Wang	2010	2010 IEEE International Conference on Wireless Communications, Networking and Information Security	10.1109/WCINS.2010.5541825	computer security model;cloud computing security;security association;information privacy;computer science;information security;network security;signal processing;security service;internet privacy;public-key cryptography;computer security;computer network	Security	-44.6029193077576	75.26961711537079	139409
e61df90354889cb9afd42bc6a39090fa00b2af76	new convertible undeniable signature schemes	provable security;digital signature;diffie hellman;undeniable signature	Undeniable signatures are like ordinary digital signatures, except that testing validity of a signature requires interaction with the signer. This gives the signer additional control over who will benefit kom being convinced by a signature, and is particularly relevant when signing sensitive, non-public data. Convertible undeniable signatures offer additional flexibility in that there is a separate verification key that can be used to verify a signature (without interaction). This allows the signer to delegate the ability to verify signatures to one or more participants, and ultimately to convert all signatures to ordinary ones by making the verification key public. While provably secure theoretical solutions exist for convertible schemes, earlier practical schemes proposed have either been broken or their status as far &s security is concerned is very unclear. In this paper, we present two new convertible schemes, in which forging signatures is provably equivalent to forging El Gamal signatures. The difficulty of verifying signatures without interacting with the signer is based on the factoring problem for one of the schemes and on the Diffie-Hellman problem for the other scheme.	antivirus software;computational diffie–hellman assumption;diffie–hellman problem;digital signature;electronic signature;information privacy;integer factorization;interaction;provable security;undeniable signature;verification and validation	Ivan Damgård;Torben P. Pedersen	1996		10.1007/3-540-68339-9_32	ring signature;digital signature;computer science;diffie–hellman key exchange;provable security;mathematics;distributed computing;internet privacy;blind signature;computer security;undeniable signature	Crypto	-40.11526248317448	75.28949381531092	139628
8a06dc43d46ba9590b7a8587ce15cf658c59a897	verification of payment protocols via multiagent model checking	multiagent system;interconnection;pago;cryptanalyse;authentication;simultaneidad informatica;program verification;payment;satisfiability;authentification;interconexion;cryptanalysis;criptoanalisis;verificacion programa;paiement;concurrency;autenticacion;model checking;security requirements;interconnexion;verification enumerative;sistema multiagente;verification programme;simultaneite informatique;concurrent process;protocole paiement electronique;systeme multiagent	The paper presents a logic of belief and time (called MATL) that can be used to verify electronic payment protocols. This logic encompasses its predecessors in the family of logics of authentication. According to our approach, the verification is performed by means of MultiAgent Model Checking Checking, an extension of traditional model checking to cope with time and beliefs. In this framework, principals are modeled as concurrent processes able to have beliefs about other principals. The approach is applied to the verification of the Lu and Smolka protocol, a variant of SET. The results of our analysis show that the protocol does not satisfy some important security requirements, which make it subject to attacks.	agent-based model;authentication;authorization;communications protocol;lu decomposition;model checking;personal computer;requirement;transport layer security	Massimo Benerecetti;Maurizio Panti;Luca Spalazzi;Simone Tacconi	2002		10.1007/3-540-47961-9_23	computer science;authentication;database;distributed computing;computer security;abstraction model checking;algorithm	Logic	-44.30018749666904	77.41063023291233	139663
72b8e13f8b0ff767712502ba0d960a1d8a619a80	use of hamiltonian cycles in cryptograph	secure socket layer;hamiltonian cycle;man in the middle attack;transport layer security;key agreement;key agreement protocol;diffie hellman key exchange;information theory;key distribution	This paper has been withdrawn by the authors.	cryptogram;hamiltonian (quantum mechanics)	Hsieh WenBin;Leu Jenq-Shiou	2011	CoRR		information theory;computer science;mathematics;distributed computing;transport layer security;computer security;computer network	NLP	-41.764462917396976	79.2095922626109	139672
c2b2b6d22370bdb16556908ea3e75c4abb7235b4	support for multiple hash algorithms in cryptographically generated addresses (cgas)		This document analyzes the implications of recent attacks on commonly#N#used hash functions on Cryptographically Generated Addresses (CGAs)#N#and updates the CGA specification to support multiple hash algorithms.#N#[STANDARDS-TRACK]	algorithm;cryptographically generated address	Marcelo Bagnulo;Jari Arkko	2007	RFC	10.17487/RFC4982	double hashing;discrete mathematics;hash function;merkle tree;sha-2;secure hash algorithm;theoretical computer science;secure hash standard;hash chain;mathematics;hash list;algorithm;cryptographic hash function	ML	-41.02681527791631	79.20921708616645	140015
2d56be1f32323883e04475bd5057b08697a5cd5b	indistinguishability obfuscation of iterated circuits and ram programs		A key source of inefficiency in existing obfuscation schemes is that they operate on programs represented as Boolean circuits or (with stronger assumptions and costlier constructs) as Turing machines. We bring the complexity of obfuscation down to the level of RAM programs. That is, assuming injective one way functions and indistinguishability obfuscators for all circuits, we construct indistinguishability obfuscators for RAM programs with the following parameters, up to polylogarithmic factors and a multiplicative factor in the security parameter: (a) The space used by the obfuscated program, as well as the initial size of the program itself, are proportional to the maximum space s used by the plaintext program on any input of the given size. (b) On each input, the runtime of the obfuscated program is proportional to s plus the runtime of the plaintext program on that input. The security loss is proportional to the number of potential inputs for the RAM program. Our construction can be plugged into practically any existing use of indistinguishability obfuscation, such as delegation of computation, functional encryption, non-interactive zero-knowledge, and multiparty computation protocols, resulting in significant efficiency gains. It also gives the first succinct and efficient one-time garbled RAM scheme. The size of the garbled RAM is proportional to the maximum space s used by the RAM machine, and its evaluation time is proportional to the running time of the RAM machine on plaintext inputs. At the heart of our construction is a mechanism for succinctly obfuscating “iterated circuits”, namely circuits that run in iterations, and where the output of an iteration is used as input to the next. As contributions of independent interest, we also introduce (a) a new cryptographic tool called Asymmetrically Constrained Encapsulation (ACE), that allows us to succinctly and asymmetrically puncture both the encapsulation and decapsulation keys; and (b) a new program analysis tool called Inductive Properties (IP), that allows us to argue about computations that are locally different, but yet globally the same. ∗Tel Aviv University and Boston University. Email: canetti@tau.ac.il. Supported by the Check Point Institute for Information Security, ISF grant 1523/14, NSF MACS project, and an NSF Algorithmic foundations grant 1218461. †MIT. Email: holmgren@mit.edu. ‡Johns Hopkins University. Email: abhishekjain.itbhu@gmail.com. §MIT. Email: vinodv@mit.edu. Research supported in part by DARPA Grant number FA875011-2-0225, an Alfred P. Sloan Research Fellowship, the Northrop Grumman Cybersecurity Research Consortium (CRC), Microsoft Faculty Fellowship, and a Steven and Renee Finn Career Development Chair from MIT.	ace;boolean circuit;coefficient;computation;computer security;consortium;cryptography;cyclic redundancy check;email;emoticon;encapsulation (networking);functional encryption;ibm notes;inductive reasoning;information security;ink serialized format;interactivity;iterated function;iteration;obfuscation (software);plaintext;polylogarithmic function;program analysis;random-access machine;random-access memory;security parameter;time complexity;turing machine;zero-knowledge proof	Ran Canetti;Justin Holmgren;Abhishek Jain;Vinod Vaikuntanathan	2014	IACR Cryptology ePrint Archive		one-way function;theoretical computer science;program analysis;obfuscation (software);cryptography;boolean circuit;turing machine;security parameter;computer science;plaintext	Crypto	-35.22073714596876	76.83130314256864	140045
302b18525bc41383d350c486f2b3e4cbf838edd3	on the security of two group signature schemes with forward security	group signature scheme;forward security	A group signature scheme allows a group member of a group to sign messages on behalf of the group anonymously. In case of dispute, a special entity of the group, group manager, can reveal the signer of a valid group signature. In 2005, Zhang et al. proposed a new group signature with forward security based on their earlier scheme in ICICS 2003. Recently, Zhou et al. proposed a dynamic group signature scheme with forward security at GCC 2007, In the year of 2008, Zhang and Geung pointed out the scheme is insecure and suggested an improvement. In this paper, we analyze a security analysis of Zhang et al.’s group signature scheme and Zhou et al.’s group signature scheme. We also discuss why the improved Zhou et al.’s scheme by Zhang et al. is still insecure.	digital signature;group signature	Kitae Kim;Ikkwon Yie;Daehun Nyang	2010	Informatica (Slovenia)	10.31449/inf.v34i2.295	forward secrecy;computer science;computer security;statistics	Security	-42.43165275029073	74.6967010789013	140109
05250195f1acf6e2bb6b6cc5570c8353b5a0afea	contrer l'attaque simple power analysis efficacement dans les applications de la cryptographie asymétrique, algorithmes et implantations. (thwart simple power analysis efficiently in asymmetric cryptographic applications, algorithms and implementations)		The development of online communications and the Internet have made encrypted data exchange fast growing. This has been possible with the development of asymmetric cryptographic protocols, which make use of arithmetic computations such as modular exponentiation of large integer or elliptic curve scalar multiplication. These computations are performed by various platforms, including smart-cards as well as large and powerful servers. The platforms are subjects to attacks taking advantage of information leaked through side channels, such as instantaneous power consumption or electromagnetic radiations. In this thesis, we improve the performance of cryptographic computations resistant to Simple Power Analysis. On modular exponentiation, we propose to use multiple multiplications sharing a common operand to achieve this goal. On elliptic curve scalar multiplication, we suggest three different improvements : over binary fields, we make use of improved combined operations AB,AC and AB + CD applied to Double-and-add, Halve-and-add and Double/halveand-add approaches, and to the Montgomery ladder ; over binary field, we propose a parallel Montgomery ladder ; we make an implementation of a parallel approach based on the Rightto-left Double-and-add algorithm over binary and prime fields, and extend this implementation to the Halve-and-add and Double/halve-and-add over binary fields.		Jean-Marc Robert	2015				Security	-40.10705376346239	82.05273950930702	140186
7129fc3ae5002feceede9c2aa5ecbd1470086a8d	simpler session-key generation from short random passwords	mode transfert asynchrone;authentication;securite informatique;cryptographic protocols;securite donnee;authentification;computer security;standard model;dictionnaire;autenticacion;key exchange;mot de passe;common reference string;criptografia;human memorizable passwords;cryptography;seguridad informatica;password;dictionaries;cryptographie;password authenticated key exchange;secure two party computation;diccionario;security of data;asynchronous transfer mode;contrasena;modo transferencia asincrono	Goldreich and Lindell (CRYPTO ’01) recently presented the first protocol for password-authenticated key exchange in the standard model (with no common reference string or set-up assumptions other than the shared password). However, their protocol uses several heavy tools and has a complicated analysis. We present a simplification of the Goldreich–Lindell (GL) protocol and analysis for the special case when the dictionary is of the form $\mathcal{D}=\{0,1\}^{d}$ i.e., the password is a short string chosen uniformly at random (in the spirit of an ATM PIN number). The security bound achieved by our protocol is somewhat worse than the GL protocol. Roughly speaking, our protocol guarantees that the adversary can “break” the scheme with probability at most $O(\mathrm{poly}(n)/|\mathcal{D}|)^{\Omega(1)}$ , whereas the GL protocol guarantees a bound of $O(1/|\mathcal{D}|)$ . We also present an alternative, more natural definition of security than the “augmented definition” of Goldreich and Lindell, and prove that the two definitions are equivalent.	atm turbo;adversary (cryptography);authenticated key exchange;authentication;common reference string model;dictionary;hard-core predicate;iris gl;key generation;password;symbolic computation	Minh-Huyen Nguyen;Salil P. Vadhan	2007	Journal of Cryptology	10.1007/s00145-007-9008-4	computer science;authentication;distributed computing;world wide web;computer security;algorithm	Crypto	-40.84139823973493	76.44464567772302	140205
f98cd6502ec7543fd8dfbc232ed58333d3783557	speech cryptographic key regeneration based on password	cryptographic keys speech cryptographic key regeneration speech biometric cryptosystem verification performance password brute force search;cryptography;cryptography training indexes feature extraction	In this paper, we propose a way to combine a password with a speech biometric cryptosystem. We present two schemes to enhance verification performance in a biometric cryptosystem using password. Both can resist a password brute-force search if biometrics are not compromised. Even if the biometrics are compromised, attackers have to spend many more attempts in searching for cryptographic keys when we compare ours with a traditional password-based approach. In addition, the experimental results show that the verification performance is significantly improved.	align (company);biometrics;brute-force search;computation;cryptography;cryptosystem;key (cryptography);password;string (computer science);time complexity	Keerati Inthavisas;Daniel P. Lopresti	2011	2011 International Joint Conference on Biometrics (IJCB)	10.1109/IJCB.2011.6117553	zero-knowledge password proof;cognitive password;pbkdf2;s/key;rainbow table;key exchange;computer science;cryptography;key management;password psychology;cryptosystem;salt;internet privacy;key derivation function;one-time password;key stretching;world wide web;password;computer security;password strength;password cracking	Security	-39.73574798997653	78.64170939514023	140342
ba68e23b946d9702aec68d4b4b3f17944bc1d17f	leakage-resilient certificateless key encapsulation scheme		The previous adversary models of public key cryptography usually have a nature assumption that permanent/temporary secret (private) keys must be kept safely and internal secret states are not leaked to an adversary. However, in practice, it is difficult to keep away from all possible kinds of leakage on these secret data due to a new kind of threat, called “side-channel attacks”. By sidechannel attacks, an adversary could obtain partial information of these secret data so that some existing adversary models could be insufficient. Indeed, the study of leakage-resilient cryptography resistant to side-channel attacks has received significant attention recently. Up to date, no work has been done on the design of leakage-resilient certificateless key encapsulation (LR-CL-KE) or public key encryption (LR-CL-PKE) schemes under the continual leakage model. In this article, we propose the first LR-CL-KE scheme under the continual leakage model. Moreover, in the generic bilinear group (GBG) model, we formally prove that the proposed LR-CL-KE scheme is semantically secure against chosen ciphertext attacks for both Type I and Type II adversaries.	adversary (cryptography);adversary model;bilinear filtering;chosen-ciphertext attack;ciphertext;digital signature;encapsulation (networking);encryption;key (cryptography);key encapsulation;knowledge engineering;lr parser;public-key cryptography;rsa (cryptosystem);semantic security;side-channel attack;spectral leakage;threat (computer)	Jui-Di Wu;Yuh-Min Tseng;Sen-Shan Huang;Wei-Chieh Chou	2018	Informatica, Lith. Acad. Sci.			Crypto	-39.66822439764313	75.27762471837259	140371
30fa0fea675a1909843df3286bdd85003683c4c3	proactive resilience to dropping nodes in mobile ad hoc networks	internet protocol;distributed system;red sin hilo;routing protocols;systeme reparti;informatique mobile;protocole transmission;protocolo internet;reseau sans fil;routing;proactive service;wireless network;protocole internet;routage;ad hoc network;red ad hoc;protocole tcp;transmission control protocol;protocolo transmision;sistema repartido;sevicio proactivo;resilience;reseau ad hoc;protocolo tcp;malicious nodes;criptografia;cryptography;ad hoc networks;cryptographie;mobile ad hoc network;protocole routage;proactive routing;routing protocol;mobile computing;packet forwarding;service proactif;enrutamiento;transmission protocol	Proactive routing protocols for mobile ad hoc networks currently offer few mechanisms to detect and/or counter malevolent nodes. Stability and performance of most, if not all, emerging standard proactive protocols rely on cooperation between nodes. While cryptographic methods may be a solution to secure control messages, nodes not willing to cooperate may still decide not to forward data packets. In this paper, a method to enable resilience to such malevolent nodes is presented. It is non-intrusive with respect to the packet forwarding mechanisms (e.g. TCP/IP kernel stack) and particularly well suited for integration with proactive routing protocols.	hoc (programming language)	Ignacy Gawedzki;Khaldoun Al Agha	2006		10.1007/11930181_11	wireless ad hoc network;optimized link state routing protocol;telecommunications;computer science;routing protocol;mobile computing;computer security;computer network	Mobile	-46.94168914527212	79.35954253523278	140550
6b59223e6706e884bdf8c55f64952825741b9b87	an improved id-based authentication and key distribution protocol	key distribution	It has been pointed out that the Shieh-Yang-Sun ID-based authentication and key distribution protocol is vulnerable to the replay attack and the unknown key share attack. We further demonstrate that the protocol is vulnerable to the forgery attack, too. In addition, we describe an improved protocol that has better resistance ability to these attacks.	authentication;key distribution	Wei-Chi Ku	2002		10.1007/3-540-45801-8_36	otway–rees protocol;reflection attack;pre-play attack;challenge–response authentication;computer science;authentication protocol;key-agreement protocol;wide mouth frog protocol;internet privacy;key distribution;computer security;replay attack;computer network	Crypto	-44.742679945518745	74.91020336656483	140602
55c88d5179ce82c00eb872f318c34006158cad2c	hardware design of standard hash algorithm has-160	한국정보통신학회;hardware design of standard hash algorithm has 160;journal of information and communication convergence engineering 제3권 제4호;hash algorithm;vol 3 no 4;the korea institute of information and communication engineering;choong mo youn;has 160;beom geun lee	This paper is about the hardware implementation of the Hash algorithm, HAS-160, which is widely used for Internet security and authentication. VHDL modeling was used for its realization and the operation speed has been increased by the optimized scheduling of the operations required for step operations.	algorithm;has-160;hash function	Choong-Mo Youn;Beom-Geun Lee	2005	J. Inform. and Commun. Convergence Engineering		sha-2;computer science;secure hash algorithm;theoretical computer science;secure hash standard;database;distributed computing	DB	-42.320512576026196	82.2818142115613	140636
f567767911939cc1407c3f38dd6d2a121e2adbd8	access control using pairing based cryptography	identity based encryption;pairing based cryptography;public key;broadcast encryption;access control	We present a new class of signature schemes based on properties of certain bilinear algebraic maps. These signatures are secure against existential forgery under a chosen message attack in the standard model (without using the random oracle model). Security is based on the computational Diffie-Hellman problem. The concrete schemes that we get are the most efficient provable discrete-log type signature schemes to date.	access control;cryptography	Nigel P. Smart	2003		10.1007/3-540-36563-X_8	theoretical computer science;mathematics;internet privacy;computer security;id-based cryptography;encryption	Crypto	-40.420697940740354	76.16776142407045	140910
fbabe6e56d4339bd033a30913b3c5e9507a104f9	classical authentication aided three-stage quantum protocol	man in the middle attack;key distribution center;quantum cryptography;authentication protocol	This paper modifies Kak’s three-stage protocol so that it can guarantee secure transmission of information. Although avoiding man-in-the-middle attack is our primary objective in the introduction of classical authentication inside the three-stage protocol, we also benefit from the inherent advantages of the chosen classical authentication protocol. We have tried to implement ideas like key distribution center, session key, timestamp and nonce, within the quantum cryptography protocol.	authentication protocol;cryptographic nonce;key distribution center;list of quantum key distribution protocols;man-in-the-middle attack;quantum cryptography;secure transmission;session key	Partha Basuchowdhuri	2006	CoRR		man-in-the-middle attack;otway–rees protocol;oakley protocol;reflection attack;universal composability;challenge–response authentication;computer science;interlock protocol;authentication protocol;key-agreement protocol;cryptographic nonce;lightweight extensible authentication protocol;wide mouth frog protocol;distributed computing;computer security;key distribution center;quantum cryptography;bb84;challenge-handshake authentication protocol;three-pass protocol;computer network	Crypto	-44.37709923674653	75.1865156384197	140926
c51207273b8719830d640e518ffaa807f4cdeb6b	secure proxy multi-signature scheme in the standard model	provable security;proxy multi signature;standard model;signature scheme;bilinear pairings;random oracle;proxy signature	In electronic world, proxy signature is a solution of delegation of signing capabilities. Proxy multi-signature schemes allow a proxy signer to generate a proxy signature on behalf of two or more original signers. However, the security of the known proxy multi-signature schemes is proven in the random oracle which does not imply security in the real world. In this paper, we present a proxy multi-signature scheme in the standard model. The size of a proxy multi-signature is independent of the number of the original signers. Our scheme is existentially unforgeable against chosen message attack and chosen warrant attack based on the hardness of the well known CDH problem in the standard model.		Zhenhua Liu;Yupu Hu;Hua Ma	2008		10.1007/978-3-540-88733-1_9	random oracle;standard model;computer science;provable security;internet privacy;world wide web;computer security;algorithm	Crypto	-42.097743611043306	75.29267466220091	141139
44aad7e464e7c0a0335285557b4fa9939b6ec917	improving the time complexity of matsui's linear cryptanalysis	institutional repositories;fedora;limiting factor;time complexity;usu;block cipher;vital;fast fourier transform;linear cryptanalysis;block ciphers;vtls;ils	This paper reports on an improvement of Matsui’s linear cryptanalysis that reduces the complexity of an attack with algorithm 2, by taking advantage of the Fast Fourier Transform. Using this improvement, the time complexity decreases from O(2 ∗ 2) to O(k ∗ 2), where k is the number of bits in the keyguess. This improvement is very generic and can be applied against a broad variety of ciphers including SPN and Feistel schemes. In certain (practically meaningful) contexts, it also involves a reduction of the attacks data complexity (which is usually the limiting factor in the linear cryptanalysis of block ciphers). For illustration, the method is applied against the AES candidate Serpent and the speed-up is given for exemplary attacks.	aes instruction set;advanced encryption standard process;algorithm;approximation;block cipher;experiment;fast fourier transform;feistel cipher;linear cryptanalysis;sac;substitution-permutation network;time complexity	Baudoin Collard;François-Xavier Standaert;Jean-Jacques Quisquater	2007		10.1007/978-3-540-76788-6_7	integral cryptanalysis;block cipher;contact analysis;differential cryptanalysis;interpolation attack;mod n cryptanalysis;piling-up lemma;xsl attack;computer science;theoretical computer science;block size;key schedule;higher-order differential cryptanalysis;mathematics;impossible differential cryptanalysis;computer security;algorithm;linear cryptanalysis	Crypto	-35.375566537678694	79.12534277124601	141381
cd044ec776f9f6f776d2bddcb9ca144b068348b8	error correcting codes with mathematica	mathematics;matematik	Topics of This Talk The internet is an open system and therefore completely unsecure. Therefore, in principle, everybody can wiretap everything. How can the internet—nevertheless—be used for such personal things like banking? Further applications of modern cryptography are discussed. Modern cryptography uses important mathematical algorithms. An implementation of the RSA cryptographic system is demonstrated. Secure Cryptography . . . in the Internet Why does RSA work? Diffie-Hellman Key Exchange Error-Correcting Codes Finale	algorithm;cryptography;cryptosystem;diffie–hellman key exchange;forward error correction;internet;open system (computing);wolfram mathematica	Igor Gashkov	2003		10.1007/3-540-44862-4_112	computational science;computer science;theoretical computer science;algorithm	Crypto	-41.90742856996066	79.73170095321937	141395
47d25a1b7e335c695edc87bf38fabf82a05a2451	analysis of baptista-type chaotic cryptosystem	ciphertext entropy;control systems;chaotic communication;encryption time;state space methods;huffman coding;information science;chaos;huffman codes;size control;n truncated huffman coding;baptista type chaotic cryptosystem;chaos cryptography chaotic communication entropy frequency huffman coding information science size control control systems state space methods;cryptography;n truncated huffman coding baptista type chaotic cryptosystem cipher to plaintext ratio ciphertext entropy plaintext block size encryption time;huffman codes chaotic communication cryptography;cipher to plaintext ratio;entropy;plaintext block size;frequency;lower bound	To solve the two major drawbacks of Baptista-type chaotic cryptosystem - excessive length of ciphertext and unbalance frequency of bit 0 to bit 1, the lower bound of the expectation of the cipher-to-plaintext ratio is worked out by the ciphertext entropy, and the approximation formula is presented to calculate the expectation of bit 0 frequency of ciphertext. In order to improve the efficiency of Baptita-type cryptosystem, the plaintext-block size is analytically influenced upon its lower bound and the encryption time, then N-truncated Huffman coding is introduced into the scheme so as to approximately reach the lower bound. Numerical paradigms prove the validity of the analysis.	approximation;block size (cryptography);cipher;ciphertext;cryptosystem;encryption;huffman coding;plaintext	Xin Ge;Fenlin Liu;Lu Bin;Wang Ping	2007	2007 IEEE International Conference on Multimedia and Expo	10.1109/ICME.2007.4284794	arithmetic;semantic security;discrete mathematics;plaintext-aware encryption;information science;computer science;theoretical computer science;mathematics;deterministic encryption;cramer–shoup cryptosystem;ciphertext;statistics;huffman coding	Theory	-38.82736804683663	82.79617546241087	141461
034753af4277ef82f8964cd90f5d8a454efbd08e	anonymous distance-bounding identification		Anonymous Distance-Bounding (DB) protocols allow a prover to convince a verifier that they are within a distance bound from them, without revealing their identity. This is an attractive property that enables the prover to enjoy proximity based services, while their privacy is maintained. Combination of anonymity and distance-bounding however introduces new security challenges. We consider two new realistic attacks: a physical layer attack that uses directional antenna, and a collusion attack that involves multiple users. We show all existing anonymous DB protocols become insecure against at least one of these attacks, and then propose a new security model that captures these new attacks, and finally construct two protocols with provable security in this model with two different computational assumptions. Our protocols are the only known anonymous DB protocols with provable security against all known attacks.	computational hardness assumption;discrete logarithm;multi-user;provable security	Ahmad Ahmadi;Reihaneh Safavi-Naini;Md. Mamunur Rashid Akand	2018	IACR Cryptology ePrint Archive			Security	-42.09975933358238	75.53760393311688	141570
d789e91980e9f492cc57836b06c88c34494fd5aa	upper bound of the length of truncated impossible differentials for aes	truncated impossible differential;aes;s-box;linear space;94a60	On the provable security of a block cipher against impossible differential cryptanalysis, the maximal length of impossible differentials is an essential aspect. Most previous work on finding impossible differentials for AES, omits the non-linear component (S-box), which is important for the security. In EUROCRYPT 2016, Sun et al. showed how to bound the length of impossible differentials of a SPN “structure” using the primitive index of its linear layer. They proved that there do not exist impossible differentials longer than four rounds for the AES “structure”, instead of the AES cipher. Since they do not consider the details of the S-box, their bound is not feasible for a concrete cipher. With their result, the upper bound of the length of impossible differentials for AES, is still unknown. We fill this gap in our paper. By revealing some important properties of the AES S-box, we further prove that even though the details of the S-box are considered, there do not exist truncated impossible differentials covering more than four rounds for AES, under the assumption that round keys are independent and uniformly random. Specially, even though the details of the S-box and key schedule are both considered, there do not exist truncated impossible differentials covering more than four rounds for AES-256.		Qian Wang;Chenhui Jin	2018	Des. Codes Cryptography	10.1007/s10623-017-0411-z	mathematics;key schedule;discrete mathematics;impossible differential cryptanalysis;cipher;combinatorics;advanced encryption standard;s-box;block cipher;provable security;upper and lower bounds	Crypto	-37.82275242823034	79.56381373814767	141572
efd118305d1b6e4ba5853e0bf6d09a4ae1fd4bd2	the oakley key determination protocol	out of band;security association;perfect forward secrecy;diffie hellman key exchange;diffie hellman;key distribution	This document describes a protocol, named OAKLEY, by which two authenticated parties can agree on secure and secret keying material. The basic mechanism is the Diffie-Hellman key exchange algorithm. The OAKLEY protocol supports Perfect Forward Secrecy, compatibility with the ISAKMP protocol for managing security associations, user-defined abstract group structures for use with the Diffie-Hellman algorithm, key updates, and incorporation of keys distributed via out-of-band mechanisms.	authentication;diffie–hellman key exchange;forward secrecy;greedy algorithm;internet security association and key management protocol;key (cryptography);oakley protocol;out-of-band agreement	Hilarie K. Orman	1998	RFC	10.17487/RFC2412	oakley protocol;forward secrecy;computer science;key-agreement protocol;distributed computing;internet privacy;key distribution;computer security;station-to-station protocol	Security	-43.216370113861785	74.69725625987255	141646
9ecdc1880b1c48f9837d3682da839217deefdcfc	a new group key generating model for group sharing	distributed system;attaque texte simple;systeme reparti;generic model;sistema informatico;gestion fichier;transmission message;computer system;cle groupe;file management;message transmission;sistema repartido;criptografia;cryptography;manejo archivos;cryptographie;systeme informatique;information system;systeme information;protection systeme;transmision mensaje;sistema informacion	in this paper, we are interested in those secure applications that have the one-to-many property, such as broadcasting secret messages from one source to many users on a network, accessing a &arable secure file by a subgroup of users in a data event system, etc. For these secure applications, Denning and Schneider [4] have proposed two methods to derive all of the group keys, one for each nonempty possible group. These methods require the cipher to be able to withstand the chosen-plaintext attack. In this paper, we propose a model to generalize their methods. Any cipher that is used on our proposed model to generate all of the group keys is only expected to be secure against the known-plaintext attack. Therefore, on the basis of our proposed model, we can have a more efficient method to generate the group keys.	cipher;data event;dorothy e. denning;group key;known-plaintext attack;one-to-many (data model);plaintext	Kuang-Hui Chiu;Wen-Tsuen Chen	1992	Inf. Sci.	10.1016/0020-0255(92)90112-L	weak key;related-key attack;telecommunications;computer science;cryptography;computer security;information system;statistics	Security	-43.56745045717422	77.62692622301827	141743
b37c48d69bd5150db06cec9785868d97633364a6	a practical scheme for data secure transport in voip conferencing		In the Multi-party VoIP conferencing system, it is important to provide properties of non-repudiation, unforgeable, and privacy. Previous work usually achieve these goals by using digital signature, TLS, IPsec, or other cryptographic tools. However, many approaches either compromise performance or lack of formal security proof, or both. In this work, we construct a practical Multi-party VoIP conferencing scheme based on the Boneh-Canetti-Halevi-Katz construction. Our work focus on the data secure transport stage, (i.e., we assume that the group session key is already distributed in the key distribution stage.). In comparison with previous work, our scheme gives a new paradigm for achieving properties of non-repudiation, unforgeable, and privacy simultaneously. The new paradigm avoids digital signature that have been shown time-consuming. On the other hand, our scheme is provable security. We prove the non-repudiation property in a formal way, and give proof sketches of unforgeable property and privacy property.		Dali Zhu;Renjun Zhang;Xiaozhuo Gu;Haitao Zhu	2016		10.1007/978-3-319-50011-9_36	distributed computing;internet privacy;computer security	Crypto	-41.641985193926956	75.44444845881179	142190
30ab452cf1428b7a9734fb60a28b8bed13a852ee	the identity escrow (group signature) scheme at ct-rsa'05 is not non-frameable		Following an attack against exculpability, put forward on Asiacrypt’06, of ACJT’s group signature, we further found Nguyen’s identity escrow (group Signature) scheme did not satisfy non-frameabiliy either.	ct scan;group signature	Sujing Zhou;Dongdai Lin	2006	IACR Cryptology ePrint Archive		group signature;mathematics;escrow;distributed computing	Crypto	-41.82321691564614	77.54047983491185	142948
c1ef98843f15f8f2f4465d32a41570ede51b1217	cryptanalysis and further improvement of peinado's improved lhl-key authentication scheme	matematicas aplicadas;mathematiques appliquees;attaque substitution cle publique;cryptanalyse;authentication;cle publique;authentification;cryptanalysis;autenticacion;public key;llave publica;key authentication;applied mathematics;public key substitution attack	In 2004, Peinado pointed out that LHL-key authentication scheme is not secure as the intruder can obtain the private key of the users. For enhancing the security, Peinado proposed an improved LHL-key authentication scheme. However, in this paper, we will show that Peinado's improved LHL-key authentication scheme is still vulnerable to public key substitution attack, i.e., an intruder can substitute a fake public key for the genuine one. And then, we propose a further improved LHL-key authentication scheme resistant to public key substitution attack.	cryptanalysis;key authentication	Eun-Jun Yoon;Eun-Kyung Ryu;Kee-Young Yoo	2005	Applied Mathematics and Computation	10.1016/j.amc.2004.09.020	challenge–response authentication;authentication;internet privacy;world wide web;computer security	Crypto	-43.52138994997233	76.36773872016265	142969
a5dcfd489d5ea08d497ec4e16ecaa1b6e38ab217	identity-based encryptions with tight security reductions to the bdh problem	tecnologia electronica telecomunicaciones;identity based encryption;security reduction;bilinear diffie hellman problem;tecnologias;grupo a;diffie hellman	We present IND-ID-CPA secure identity-based encryption (IBE) schemes with tight reductions to the bilinear Diffie-Hellman (BDH) problem. Since the methods for obtaining IND-ID-CCA secure schemes from IND-ID-CPA secure schemes with tight reductions are already known, we can consequently obtain IND-ID-CCA secure schemes with tight reductions to the BDH problem. Our constructions are based on IBE schemes with tight reductions to the list bilinear Diffie-Hellman (LBDH) problem, and the schemes are converted to those with tight reductions to the BDH problem. Interestingly, it can be shown that there exists a black box construction, in which the former IBE schemes are given as black boxes. Our constructions are very simple and reasonably efficient.		Mototsugu Nishioka	2008	IEICE Transactions	10.1093/ietfec/e91-a.5.1241	discrete mathematics;computer science;diffie–hellman key exchange;mathematics;distributed computing;computer security	Crypto	-39.48926303727995	77.30321733959113	143290
41f5ac447ae9605b2df0bf9d1b49f312b4bbed31	sequential aggregate signatures with lazy verification from trapdoor permutations	sequential aggregate signature scheme;magnitude faster verification;n individual signature;necessary public key;postponing verification;own signature;trapdoor permutation;shorter signature;lazy verification;public key;unverified aggregate	Computer Science, Boston University. Associate Professor. (2015-Present) Computer Science, Boston University. Assistant Professor. (2010-2015) Microsoft Research New England. Postdoc Researcher. (2009-2010) Princeton University. Research Assistant (2004-2009) Cisco Systems. Research Intern. (Summer 2008) IBM Research. Cryptography Group. Research Intern. (Summer 2007) Hydro One Networks Inc. Telecom Engineer. (2003-2004) Bell Canada. Database Designer. (Summer 2002) Bell Nexxia. Junior Internetworking Engineer. (Summer 2001) Personification Inc. Intern. (1999-2000)	aggregate function;bell's theorem;computer science;cryptography;electronic signature;ibm research;internetworking;lazy evaluation;microsoft research;trapdoor function	Kyle Brogle;Sharon Goldberg;Leonid Reyzin	2011	IACR Cryptology ePrint Archive	10.1007/978-3-642-34961-4_39	computer science;distributed computing;computer security;algorithm	Crypto	-33.96596561819914	76.88165849737976	143305
9a45a2ce70a6cd02cf47ec5846e4b9a75ff9759d	differential ananlysis of 3 round kuznyechik		In January 2016, a new block encryption standard came into force in the Russian Federation - GOST R 34.12-2015. It includes two algorithms of encryption. The first cipher was previously known under the name GOST28147-89 (or simply GOST). The second algorithm was called Kuznyechik. Kuznyechik is a new symmetric encryption algorithm, based on the SP-network. Up to now there are no publications about the differential properties of the algorithm Kuznyechik. We are the first to examine the properties of main operations and suggest a scheme of 3 rounds differential analysis of cipher Kuznyechik. We examined the differential properties of the non-linear transformation S and the linear transformation L and found out that it's possible a situation when, 1 non-zero byte difference, being a result of the transformation L, is expanded into 16 non-zero bytes, then it passes through the S-boxes, and then collapses again into 1 nonzero byte. The developed scheme allows to affect the active S-boxes a minimum number of times. As a result, for the suggested scheme the possibility of finding the correct pairs of texts is equal to 2-108. We also developed the algorithm of finding a secret key, the complexity of which is equal to 6*2−120. In this way, the total complexity of the analysis, including searching for the correct pairs of texts and bits of the secret encryption key is equal to 2108 + 6*2120 encryptions.  Also the article contains theoretical calculations of the time required to implement an attack using the most powerful supercomputers in the world [2].	byte;cipher;diagram;differential cryptanalysis;encryption;key (cryptography);nonlinear system;precomputation;s-box;substitution-permutation network;supercomputer;symmetric-key algorithm	Evgeniya Ishchukova;Ekaterina Tolomanenko;Ludmila K. Babenko	2017		10.1145/3136825.3136880	computer network;cipher;symmetric-key algorithm;byte;encryption;theoretical computer science;linear map;computer science;block cipher;key (cryptography)	Crypto	-36.70748409533821	79.66099742903054	143324
723e0000b0553476c3375c6f494e049d8947a031	rethinking stream ciphers: can extracting be better than expanding?	matching pursuit algorithms;entropy matching pursuit algorithms communication system security wireless communication;tablets stream ciphers one time pad secret key exchange cryptosystems pseudo random keystream generation approach dual approach pda smartphones;wireless communication;cryptography;entropy;communication system security	In this paper the feasibility of an alternative approach to construct stream ciphers is discussed by revisiting an old friend, i.e. the popular one-time pad. The idea is that the rationale underlying the one-time pad --- which is notoriously unpractical in pure form due to the need of massive secret key exchange --- might be translated into practical cryptosystems that are different from conventional stream ciphers. In alternative to the usual pseudo- random keystream generation approach (expansion), a ``dual'' approach based on sampling of a much longer sequence (extraction) could be conceivable nowadays due to the ready availability of sufficiently large memory resources, even in mobile devices such as PDAs, smartphones and tablets. The paper presents this idea, analyzing its pros and cons versus the classical one-time pad and conventional stream ciphers.	cipher	Angelo Coluccia	2012		10.1109/ICCCN.2012.6289197	entropy;telecommunications;computer science;cryptography;theoretical computer science;operating system;key schedule;internet privacy;t-function;computer security;statistics;computer network	Crypto	-43.61189299208191	81.0612455864406	143337
04d05611bd5edeb120b1c17d2b0a8bf0004cb3e1	provable security support for kerberos (and beyond)	provable security;encryption scheme;revocation;pseudorandom generator;dissertation;kerberos	Kerberos is a widely-deployed network authentication protocol that is being considered for standardization. Like other standard protocols, Kerberos is no exception to security flaws and weaknesses, as has been demonstrated in several prior works. Provable security guarantees go a long way in restoring users' faith, thus making a protocol an even stronger candidate for standards. In this thesis, our goal was thus to provide provable security support for Kerberos and other practical protocols. Our contributions are three-fold: 1. We first look at the symmetric encryption schemes employed in the current version 5 of Kerberos. Several recent results have analyzed a significant part of Kerberos v.5 using formal-methods-based approaches, which are meaningful only if the underlying encryption schemes satisfy strong cryptographic notions of privacy and authenticity. However, to our knowledge these schemes were never analyzed and proven to satisfy such notions. This thesis aims to bridge this gap. Our provable security analyses confirm that some of the encryption scheme options in Kerberos v.5 already provide privacy and authenticity, and for the remaining we suggest slight modifications for the same. 2. We next turn our attention to the ways in which the keys and other random strings needed in cryptographic schemes employed by practical protocols are generated. Randomness needs to be carefully generated for the provable security guarantees to hold. We propose an efficient pseudorandom generator (PRG) based on hash functions. The security of our PRG relies on exponential collision-resistance and regularity of the underlying hash function. Our PRG can be used to generate various strings, like session keys, sequence numbers, confounders, etc., which are all suggested to be generated randomly in the Kerberos v.5 specification, but no algorithms are mentioned. Each of the above strings are required to satisfy different properties, all of which are trivially satisfied by the pseudorandom strings output by a PRG. 3. Finally, we look at the problem of revocation associated with two relatively new types of encryption schemes: identity-based encryption (IBE) and attribute-based encryption (ABE). While these encryption schemes are relatively less efficient compared to public-key encryption schemes, they have already been used (and are very likely to be used in future, as well) in many practical protocols due to their attractive features. Any setting, public-key, identity-based, or attribute-based, must provide a means to revoke users from the system. However, unlike public-key encryption, there has been little prior work on studying the revocation mechanisms in an IBE or ABE. We propose new primitives and their efficient and provably secure instantiations, focusing on the revocation problem. We would like to note that even though all the results presented in this thesis are motivated mainly by provable security in practice, only the first bullet above has a direct impact on a practical and widely deployed protocol Kerberos. Our PRG is the most efficient construction among theoretical PRGs, but it may still not be efficient enough to be directly usable in practical protocols. And our results and techniques for revocation in IBE and ABE have found much wider applications in information security, such as mobile social networks, cloud-based secure health records, data outsourcing systems, vehicular ad-hoc networks, etc.	kerberos;provable security	Virendra Kumar	2012			kerberos;provable security;internet privacy;generic security service algorithm for secret key transaction;computer security;computer network	Crypto	-39.20392359036138	75.376538773537	143587
f33f1e6517da9446fde8571cdf975cc3929eecae	hopfield network based neural key generation for wireless communication (hnbnkg)		In this paper, a key generation and encryption/decryption technique based on Hopfield Neural network has been proposed for wireless communication. Hopfield Neural networks at both ends forms identical input vector, weight vector which in turn produces identical output vector which is used for forming secret-key for encryption/decryption. Using this secret-key, plain text is encrypted to form the cipher text. Encryption is performed by Exclusive-OR operation between plaintext and secret-key. Decryption is performed at the receiver through Exclusive-OR operation between cipher text and identical secret-key generated. Receiver regenerate the original message sent by the sender as encrypted stream. In HNBNKG technique sender and receiver never exchange secret-key. This technique ensured that, when message is transmitting between sender-receiver nobody can regenerate the message as no key is exchanged.	hopfield network;key generation	J. K. Mandal;Debdyuti Datta;Arindam Sarkar	2014		10.1007/978-3-319-12012-6_24	hopfield network;computer network	AI	-46.0521305908842	82.24290107278165	143676
cae66de1e92196c94c7b41e49d8a280614f8f71d	a remark on hash functions for message authentication	hash function;message authentication	n A application of a special class of hash functions to cryptographic applications is considered in this paper. These hash functions arc used in cryptography to construct manipulation detection codes (MDCs), h’ h w ic arc added to messages to give some measure of assurance to the recipient that it has not been altered in transit. The basic idea is that a publicly known hash function is applied to the message to compute a hash value of fixed length. This hash value is then encrypted by the message originator and added to the message as an MDC.	code;cryptography;encryption;hash function;message authentication	Chris J. Mitchell;Dave Rush;Michael Walker	1989	Computers & Security	10.1016/0167-4048(89)90039-4	message authentication code;security of cryptographic hash functions;double hashing;hash function;perfect hash function;collision attack;merkle tree;sha-2;collision resistance;computer science;secure hash algorithm;secure hash standard;hash chain;hash-based message authentication code;hash buster;rolling hash;internet privacy;computer security;cryptographic hash function;computer network;mdc-2;swifft;hash tree;hash filter	Crypto	-37.04777603915425	80.0713773584077	143805
4f8295eed7db84ddc6dffd3abb0657f943a25e4b	group key agreement from signcryption	secure group communication;group key agreement;signcryption	There is an intuitive connection between signcryption and key agreement. Such a connector may lead to a novel way to construct authenticated and efficient group key agreement protocols. In this paper, we present a primary approach for constructing an authenticated group key agreement protocol from signcryption. This approach introduces desired properties to group key agreement. What this means is that the signcryption gives assurance to a sender that the key is available only to the recipient, and assurance to the recipient that the key indeed comes from the sender. Following the generic construction, we instantiate a distributed two-round group key agreement protocol based on signcryption scheme given by Dent [8]. We also show that this concrete protocol is secure in the outsider unforgeability notion and the outsider confidentiality notion assuming hardness of the Gap Diffie-Hellman problem.	group key;key-agreement protocol;signcryption	Xixiang Lv;Hui Li	2012	TIIS	10.3837/tiis.2012.12.017	computer science;signcryption;distributed computing;internet privacy;computer security	Crypto	-41.2932494794437	75.18667309470445	144173
1a3d7c9957a1c1ac68c1bd84833b0075aa2ca536	fault tolerant anonymous channel	commerce electronique;partage secret;comercio electronico;secret sharing;fault tolerant;securite;cle publique;public key;criptografia;cryptography;safety;llave publica;cryptographie;codigo algebraico;seguridad;algebraic code;electronic trade;code algebrique	Previous anonymous channels, called MIX nets, do not work if one center stops. This paper shows new anonymous channels which allow less than a half of faulty centers. A fault tolerant multivalued election scheme is obtained automatically. A very eecient ZKIP for the centers is also presented.	fault tolerance;mix;zero-knowledge proof	Wakaha Ogata;Kaoru Kurosawa;Kazue Sako;Kazunori Takatani	1997		10.1007/BFb0028500	telecommunications;computer science;cryptography;operating system;distributed computing;secret sharing;computer security;algorithm;statistics	Security	-43.61201431678082	77.5801741393151	144310
371d0fd0dfed46f856a1da10619d778997207ceb	an efficient identity-based signcryption scheme for multiple receivers	dynamic change;provable security;linear order;security model;security proof;multiple receivers;identity based cryptography;signcryption	This paper puts forward a new efficient construction for Multi-Receiver Signcryption in the Identity-based setting. We consider a scenario where a user wants to securely send a message to a dynamically changing subset of the receivers in such a way that non-members of the of this subset cannot learn the message. The obvious solution is to transmit an individually signcrypted message to every member of the subset. This requires a very long transmission (the number of receivers times the length of the message) and high computation cost. Another simple solution is to provide every possible subset of receivers with a key. This requires every user to store a huge number of keys. In this case, the storage efficiency is compromised. The goal of this paper is to provide solutions which are efficient in all three measures i.e. transmission length, storage of keys and computation at both ends. We propose a new scheme that achieve both confidentiality and authenticity simultaneously in this setting and is the most efficient scheme to date, in the parameters described above. It breaks the barrier of ciphertext length of linear order in the number of receivers, and achieves constant sized ciphertext, independent of the size of the receiver set. This is the first Multi-receiver Signcryption scheme to do so. We support the scheme with security proofs under a precisely defined formal security model.	ciphertext;computation;confidentiality;signcryption;storage efficiency	S. Sharmila Deva Selvi;S. Sree Vivek;Rahul Srinivasan;C. Pandu Rangan	2008	IACR Cryptology ePrint Archive	10.1007/978-3-642-04846-3_6	computer security model;computer science;provable security;signcryption;distributed computing;internet privacy;computer security;total order	Crypto	-39.3707799048943	76.88888678050955	144338
9987aabb249579b8dd4059bef07bd47b3c7ff0c3	design in type-i, run in type-iii: fast and scalable bilinear-type conversion using integer programming		Bilinear-type conversion is to convert cryptographic schemes designed over symmetric groups instantiated with imperilled curves into ones that run over more secure and efficient asymmetric groups. In this paper we introduce a novel type conversion method called IPConv using 0-1 Integer Programming. Instantiated with a widely available IP solver, it instantly converts existing intricate schemes, and can process large-scale schemes that involves more than a thousand variables and hundreds of pairings. Such a quick and scalable method allows a new approach in designing cryptographic schemes over asymmetric bilinear groups. Namely, designers work without taking much care about asymmetry of computation but the converted scheme runs well in the asymmetric setting. We demonstrate the usefulness of conversion-aided design by presenting somewhat counter-intuitive examples where converted DLIN-based Groth-Sahai proofs are more compact than manually built SXDH-based proofs.	bilinear filtering;bilinear transform;computation;cryptography;integer programming;scalability;solver;type conversion	Masayuki Abe;Fumitaka Hoshino;Miyako Ohkubo	2016		10.1007/978-3-662-53015-3_14	computer architecture;real-time computing;branch and price	Security	-35.700017398430596	77.70685951264859	144376
a42f1d6374598cf4a33d31725b1c7e91c399b654	strong identification based on a hard-on-average problem *	discrete mathematics;computational complexity;cryptography;algorithms	The aim of this work is to investigate the possibility of designing zero-knowledge identification schemes based on hard-on-average problems. It includes a new two-party identification protocol whose security relies on a discrete mathematics problem classified as DistNP-Complete under the average-case analysis, the so-called Distributional Matrix Representability Problem. Thanks to the use of the search version of the mentioned problem, the zero-knowledge property is formally proved by black-box simulation, and consequently the security of the proposed scheme is actually guaranteed. Furthermore, with the proposal of a new zero-knowledge proof based on a problem never used before for this purpose, the set of tools for designing cryptographic applications is enlarged.		Pino Caballero-Gil	2005	IEICE Transactions	10.1093/ietfec/e88-a.5.1117	computational problem;discrete mathematics;computer science;cryptography;theoretical computer science;mathematics;algorithm	Vision	-38.954208696569495	78.41833543105085	144530
294cce400f446d7ff18b748073c06c1f336f8448	an efficient group key management scheme: link tree protocol	file servers;protocols;teleconferencing;application software;technology management;internet;cryptography;engineering management;performance analysis;group key management;computer science;protocols performance analysis internet cryptography computer science technology management engineering management application software teleconferencing file servers	Many group key management schemes such as those proposed by Wallner et al, Wong et al are based on a multilevel, logical hierarchy (or tree) of keyencrypting keys. But LKH is based on the hypothesis that the tree is maintained in a balanced manner. This paper proposes a multi-link tree protocol based on LKH. LTP keeps the structure balanced and has a better performance. We analyze multi-LTP and multi- LKH’s performance in detail. We prove that 3-degree LTP is the best structure among all the LTP structures, which is also better than LKH.	group key;key management;linux test project (ltp);scalability;simulation;tree structure	Zhang Jun;Fanyuan Ma;Gu Dawu;Yingcai Bai	2005	Sixth International Conference on Parallel and Distributed Computing Applications and Technologies (PDCAT'05)	10.1109/PDCAT.2005.76	application software;parallel computing;computer science;cryptography;technology management;operating system;database;distributed computing;world wide web;computer security;computer network	DB	-48.12503121398286	77.36969956430701	144668
b3662930880decf583d6a043f308650abcc4568b	a study on the proposed korean digital signature algorithm	distributed system;preuve programme;program proof;systeme reparti;securite;digital signature algorithm;cryptanalyse;reseau ordinateur;computer network;algorithme;cryptanalysis;algorithm;sistema repartido;criptografia;cryptography;safety;signature;prueba programa;red ordenador;cryptographie;signing;seguridad;digital signature scheme;firma;algoritmo	A digital signature scheme is one of essential cryptographic primitives for secure transactions over open networks. Korean cryptographic community, in association with government-supported agencies, has made a continuous eeort over past three years to develop our own signature standard. The outcome of this long eeort is the signature algorithm called KCDSA, which is now at the nal stage of standardization process and will be published as one of KICS (Korean Information and Communication Standards). This paper describes the proposed signature algorithm and discusses its security and eeciency aspects.	algorithm;cryptography;digital signature;kcdsa	Chae Hoon Lim;Pil Joong Lee	1998		10.1007/3-540-49649-1_15	cryptanalysis;digital signature;computer science;cryptography;theoretical computer science;digital signature algorithm;mathematics;signature;kcdsa;blind signature;computer security;algorithm	Security	-43.154870151402505	78.20487659803575	144727
0184745bf9d01108a93bdfcb47f024c5e4a0a6ea	model and simulation on enhanced grid security and privacy system	estensibilidad;modelizacion;distributed system;confiance;architecture systeme;systeme reparti;confidencialidad;systeme protection;securite;system modeling;modeling and simulation;routing;routage;network simulator;qualite service;confidentiality;modelisation;vida privada;confidentialite;onion;technology transfer;reputation system;confidence;sistema repartido;private life;confianza;safety;transferencia tecnologica;protection system;vie privee;arquitectura sistema;extensibilite;scalability;quality of service;sistema proteccion;system architecture;seguridad;modeling;grid security;service quality;calidad servicio;transfert technologie;enrutamiento	The wide acceptance of the grid technology has created pressure to add some features that were not part of its original design, such as security, privacy, and quality-of-service support. In this paper, we have proposed the enhanced grid security and privacy (EGSP) system architecture including EGSP system model, identity protection system, onion routing system, reputation system, and security technology. We also present a network simulation of the model and analyze its scalability.	simulation	Jiong Yu;Xianhe Sun;Yuanda Cao;Yonggang Lin;Changyou Zhang	2006		10.1007/11610496_75	computer security model;cloud computing security;simulation;systems modeling;telecommunications;computer science;modeling and simulation;security service;computer security	Security	-46.22355223253932	78.76268291526644	145246
d6e42011107d01d0c023cee83313f59cb00edd24	a security mechanism for rfid with dependable proxy	proxy;ban logic;physical methods;security protocols;rfid	RFID (Radio Frequency Identification) is a non-contact auto identification technology widely applied in many fields nowadays, while its security issues also get much concern in practical applications. So far, experts from industry and academia have proposed a series of solutions, mainly including physical methods, security protocols based on cryptography, hardware encryption technique and so on. However, various defects still exist in all the three categories, which may lead to the failure to achieve the security requirements of RFID systems. Aiming to make a further improvement to these solutions, we propose a security mechanism designed with dependable proxy in this paper, which demonstrates a good fusion of physical methods and security protocols. In allusion to the new scheme, we use BAN logic to do the formal analysis to derive the security objectives of our mechanism. Subsequently, given the corresponding theoretic analysis and comparison, it is indicated that the new mechanism can efficiently defend RFID systems against monitoring, deception, tracking, replay attacks, and greatly decrease the possibility of suffering denial of service. The asynchronous problem that may arise on systemic information is also discussed to lessen the authentication failure of the legal tags.	authentication;burrows–abadi–needham logic;cryptography;denial-of-service attack;encryption;radio frequency;radio-frequency identification;replay attack;requirement;theory	Jun Zhou;Yongjun Xu;Xiaowei Li	2011	Intelligent Automation & Soft Computing	10.1080/10798587.2011.10643190	radio-frequency identification;computer security model;proxy;cloud computing security;security through obscurity;security information and event management;asset;computer science;cryptographic protocol;security service;internet privacy;security testing;world wide web;computer security	Security	-46.279585550749985	75.02361565391854	145318
faa5878ace989ec70a61b3de11f44132f19cd81e	toward construction of efficient privacy preserving reusable garbled circuits		In this paper, we propose an efficient way to construct privacy preserving reusable garbled circuits (RGC) with input privacy (IP) and circuit privacy (CP) (which we denote as RGC−IP−CP) based on two-to-one recoding (TOR) scheme. Currently the only way to achieve reusable garbled circuits (RGC) with input privacy (IP) and circuit privacy (CP) heavily rely on FHE, which is Goldwasser et al.’s work. Compared with GKPVZ13, our work can achieve reusable garbled circuits (RGC) with input privacy (IP) and circuit privacy (CP) with high efficiency.		Xu An Wang	2016		10.1007/978-3-319-49109-7_8	database;internet privacy;computer security	Crypto	-36.17995787854082	76.99234518072416	145365
d89d2662772d8518a74e42561502528a27d19bee	side-informed watermarking using nth-order polynomial detectors	private key cryptography;watermarking;collusion attack;differential modulation scheme;polynomial detectors;private key;side-informed watermarking;symmetric schemes	Most recent watermarking schemes differ from symmetric schemes in that the detection process does not require the use of the same private key in both the embedder and the detector. An advantage of such schemes is that estimation of the watermark by collusion attack is rendered impossible, so that the overall system is more secure. Almost all second generation schemes to date are also second-order; that is, they are based on the computation of a quadratic form in the detector. In this work, the authors propose a new class of watermarking schemes which employ an nth-order detection process. The scheme is based on a generalised differential modulation scheme. We address the question of how to choose the watermark signal in order to optimise the output of the detection and examine the efficiency and security of this new class of schemes.	computation;digital watermarking;modulation;polynomial;public-key cryptography;second generation multiplex plus;sensor	Neil J. Hurley;Guenole C. M. Silvestre;Teddy Furon	2002	2002 11th European Signal Processing Conference			Crypto	-38.20201914237271	82.68684825685881	146070
76b6e6c87f93a912b101715b6bad8923963289f9	light-weight encryption schemes for multimedia data and high-speed networks	security analysis;high speed networks;block cipher;cryptography high speed networks telecommunication traffic quality of service data security information security hardware asynchronous transfer mode protection multimedia communication;pentium vi processor light weight encryption scheme high speed networks multimedia communication highspeed cryptosystem design cryptanalysis block cipher security super fast stream cipher;stream cipher;digital communication;cryptography;multimedia data;multimedia communication;telecommunication security;high speed;telecommunication security cryptography multimedia communication	Due to the pervasiveness of high-speed networks and multimedia communications and storage, the demand for highspeed cryptosystems is ever increasing. It is widely believed that there is a tradeoff between speed and security in cryptosystem design. No existing encryption algorithms are both fast enough for high-speed operation and sufficiently secure to withstand powerful cryptanalysis. In this paper, we propose and analyze a generic construction of high-speed encryption schemes. Our solution is based on the fact that there exist secure but relatively slow block ciphers, e. g. AES, and super-fast but relatively weaker stream ciphers. We then combine a secure block cipher with a super-fast stream cipher such that the resulting encryption scheme possesses both the speed of the stream cipher and the security of the block cipher. We show the results our security analysis as well as our experiment on a 2.1 GHz Pentium VI processor.	algorithm;block cipher;cryptanalysis;cryptosystem;encryption;existential quantification;stream cipher	Feng Bao;Robert H. Deng	2007	IEEE GLOBECOM 2007 - IEEE Global Telecommunications Conference	10.1109/GLOCOM.2007.43	substitution-permutation network;cdmf;block cipher;skipjack;triple des;ciphertext stealing;block cipher mode of operation;computer science;cryptography;theoretical computer science;stream cipher attack;stream cipher;security analysis;computer security;cbc-mac;statistics;computer network	Crypto	-42.76504617643368	81.54020713404421	146096
b98a0070c8e86798ffaaf246cd9fad73800e9ffc	secret key exchange using random deals of cards on hierarchical structures	public key cryptography;protection information;protection secret;hierarchical structure;cryptographie cle publique;game theory;securite informatique;teoria juego;theorie jeu;computer security;key exchange;proteccion informacion;informatique theorique;information protection;secrecy protection;spanning tree;information theoretic security;computer theory;informatica teorica	We propose the problem of how to transmit an information-theoretically secure bit using random deals of cards among players in hierarchical groups and a computationally unlimited eavesdropper. A player in the highest group wants to send players in lower groups a secret bit which is secure from the eavesdropper and some other players. We formalize this problem and design protocols for constructing secret key exchange spanning trees on hierarchical groups. For each protocol we give sufficient conditions to successfully construct a secret key exchange spanning tree for the hand sizes of the players and the eavesdropper.		Reina Yoshikawa;Shimin Guo;Kazuhiro Motegi;Yoshihide Igarashi	2000		10.1007/3-540-40996-3_25	information-theoretic security;game theory;spanning tree;key exchange;telecommunications;computer science;mathematics;distributed computing;public-key cryptography;key distribution;computer security;information protection policy	Crypto	-42.93452203646103	77.8893373232896	146126
8c2fa355f4fdaf2d7a7683733c16a332e3c6db28	haf - a new family of hash functions		Paper presents a family of parameterized hash functions allowing for flexibility between security and performance. The family consists of three basic hash functions: HaF-256, HaF-512 and HaF-1024 with message digests equal to 256, 512 and 1024 bits, respectively. Details of functions' structure are presented. Method for obtaining function's S-box is described along with the rationale behind it. Security considerations are discussed.	design rationale;hash function;s-box	Tomasz Bilski;Krzysztof Bucholc;Anna Grocholewska-Czurylo;Janusz Stoklosa	2012			computer science;hash function;distributed computing	Crypto	-36.3003265199393	80.13019359792591	146179
2c437f51bb60d55a7ce9152a00c977750eefd474	pairings on generalized huff curves		This paper presents the Tate pairing computation on generalized Huff curves proposed by Wu and Feng in [22]. In fact, we extend the results of the Tate pairing computation on the standard Huff elliptic curves done previously by Joye, Tibouchi and Vergnaud in [14]. We show that the addition step of the Miller loop can be performed in 1M+(k+15)m+2c and the doubling one in 1M+1S+(k+12)m+5s+2c on the generalized Huff curve.	computation;cryptographic protocol;cryptography;high-frequency direction finding;miller–rabin primality test;period-doubling bifurcation	Abdoul Aziz Ciss;Djiby Sow	2012	IACR Cryptology ePrint Archive		arithmetic;calculus;mathematics;geometry	Crypto	-39.664887618832914	81.0116049646518	146239
eb19f410c08fe6a4efcbd03db93aa85b240802ed	extracting randomness from multiple independent sources	public key cryptography;key management;gestion de claves;cle secrete;multi sources extractor;insecure channel;deterministic extractor;leftover hash lemma deterministic extractor two sources extractor multisources extractor;securite donnee;group communication;random number;approche deterministe;cryptographic task;explicit deterministic extractor;deterministic approach;multiple independent source;two sources extractor;multisources extractor;secret key;criptografia;clave secreta;cryptography;message authentication telecommunication security public key cryptography telecommunication channels;random bit extraction;telecommunication security;enfoque determinista;generalized leftover hash lemma;nombre aleatoire;cryptographie;message authentication;leftover hash lemma;telecommunication channels;communication channels;gestion cle;numero aleatorio;article;security of data;multiaccess communication interference error analysis code division multiplexing multiuser detection data mining power distribution gaussian channels floors power control;insecure channel random bit extraction multiple independent source explicit deterministic extractor generalized leftover hash lemma cryptographic task secret key group communication;data security	We study the problem of deterministically extracting almost perfect random bits from multiple weakly random sources that are mutually independent. With two independent sources, we have an explicit extractor which can extract a number of random bits that matches the best construction currently known, via the generalized leftover hash lemma. We also extend our construction to extract randomness from more independent sources. One nice feature is that the extractor still works even with all but one source exposed. Finally, we apply our extractor for a cryptographic task in which a group of parties wants to agree on a secret key for group communication over an insecure channel, without using ideal local randomness.	cryptography;deterministic algorithm;key (cryptography);leftover hash lemma;randomness extractor	Chia-Jung Lee;Chi-Jen Lu;Shi-Chun Tsai;Wen-Guey Tzeng	2005	IEEE Transactions on Information Theory	10.1109/TIT.2005.847746	computer science;cryptography;theoretical computer science;key management;distributed computing;data security;randomness extractor;computer security	Theory	-36.69433213575926	74.98526145160616	146535
4fe817d7783fcf11eb8a3de5626c6fb82c5594f2	using constraint programming to solve a cryptanalytic problem	cryptanalysis;aes block cipher;constraint programming	We describe Constraint Programming (CP) models to solve a cryptanalytic problem: the chosen key differential attack against the standard block cipher AES. We show that CP solvers are able to solve these problems quicker than dedicated cryptanalysis tools, and we prove that a solution claimed to be optimal in two recent cryptanalysis papers is not optimal by providing a better solution.	block cipher;constraint programming;differential cryptanalysis;known-key distinguishing attack	David Gerault;Marine Minier;Christine Solnon	2017		10.24963/ijcai.2017/679	constraint programming;higher-order differential cryptanalysis;theoretical computer science;discrete mathematics;computer science;differential cryptanalysis;block cipher;linear cryptanalysis;cryptanalysis	Crypto	-38.49529762828169	80.62210014712812	146690
16515a66b5e29559f0b48de1ef76553083b9f880	improved information set decoding for code-based cryptosystems with constrained memory		The decoding of random linear codes is one of the most fundamental problems in both computational complexity theory and algorithmic cryptanalysis. Specifically, the best attacks known against existing code-based cryptosystems, such as McEliece, are unstructural, i.e., these attacks directly use generic decoding algorithms that treat the hidden binary codes as random linear codes. This topic is also attracting increasing interest in a post-quantum context as this area becomes increasingly active. In an attempt to solve this problem, several algorithms and their variants have recently been proposed, with increasingly lower time complexities. However, their memory complexities, which are even more important in practice for real attacks, are neglected.	cryptosystem;decoding methods	Maoning Wang;Mingjie Liu	2015		10.1007/978-3-319-19647-3_23	theoretical computer science;binary code;dissection technique;computational complexity theory;cryptosystem;cryptanalysis;decoding methods;mceliece cryptosystem;computer science;information set	Crypto	-38.04056090763197	80.21256232470341	146718
79aa3bb1ca04f45bb209b8a65bba1fb7beb43bad	on security of an efficient nonce-based authentication scheme for sip		Recently, Tsai proposed an efficient nonce-based authentication scheme for session initiation protocol (T-SIP for short). However, the author shall show that T-SIP is vulnerable to perfect forward secrecy, password guessing attacks, and insider attacks.	authentication;cryptographic nonce;forward secrecy;password cracking	Cheng-Chi Lee	2009	I. J. Network Security		computer science;cryptographic nonce;internet privacy;computer security;computer network	Security	-44.97801467622793	74.72038366003554	146720
e377b0ae23952accb76de55ee65b42336f5bc06c	cryptanalysis of an identity based proxy multi-signature scheme	forgery attack;tecnologia electronica telecomunicaciones;security model;proxy multi signature;signature scheme;bilinear pairings;tecnologias;bilinear pairing;grupo a	In a proxy multi-signature scheme, a designated proxy signer can generate the signature on behalf of a group of original signers. Recently, Wang and Cao proposed an identity based proxy multi-signature scheme along with a security model. Although they proved that their scheme is secure under this model, we disprove their claim and show that their scheme is not secure.	cryptanalysis;scheme	Fagen Li;Shijie Zhou;Rong Sun	2008	IEICE Transactions	10.1093/ietfec/e91-a.7.1820	computer security model;computer science;internet privacy;world wide web;computer security	Crypto	-42.86506865657939	75.50451408407802	146941
f762018e429f77e46f43eee57147f8934dc857ee	symmetric-key encryption scheme with multi-ciphertext non-malleability		A standard notion of non-malleability is that an adversary cannot forge a ciphertext c′ from a single valid ciphertext c for which a plaintext m′ of c′ is meaningfully related to a plaintext m of c. The multi-ciphertext non-malleability is a stronger notion; an adversary is allowed to obtain multiple ciphertexts c 1,c 2,... in order to forge c′. We provide an efficient symmetric-key encryption scheme with an information-theoretic version of the multi-ciphertext non-malleability in this paper by using l-wise almost independent permutations of Kaplan, Naor, and Reingold.	ciphertext;encryption	Akinori Kawachi;Hirotoshi Takebe;Keisuke Tanaka	2012		10.1007/978-3-642-34117-5_8	multiple encryption;disk encryption theory;40-bit encryption;plaintext-aware encryption;disk encryption;optimal asymmetric encryption padding;link encryption;filesystem-level encryption;on-the-fly encryption;disk encryption hardware;deterministic encryption;encryption;probabilistic encryption;56-bit encryption;attribute-based encryption	Crypto	-38.73287340747436	76.89954252700346	146985
7f2f345dc565aa6dc5e01fbefb060f49b1c6a819	a secure quantum communication protocol using insecure public channels	encrypted conlmunication;quantum cryptography;quantum entanglement;communication protocol;quantum computer;quantum communication	  Due to the discovery of Shor’s algorithm1, many classical crypto-systems based on the hardness of solving discrete log and factoring problem are theoretically broken  in the presence of quantum computers. This means that some of the classical secret communication protocols are no longer secure  and hence motivate us to find other secure crypto-systems. In this paper, we present a new quantum communication protocol  which allows two parties, Alice and Bob, to exchange classical messages securely. Eavesdroppers are not able to decrypt the  secret messages and will be detected if they do exist. Unlike classical crypto-systems, the security of this protocol is not  based on the hardness of any unproven mathematic or algorithmic problem. Instead, it is based on the laws of nature.    	communications protocol;quantum	I-Ming Tsai;Chia-Mu Yu;Wei-Ting Tu;Sy-Yen Kuo	2005			communications protocol;quantum information;quantum key distribution;quantum information science;quantum teleportation;theoretical computer science;quantum network;distributed computing;quantum computer;quantum entanglement;quantum cryptography;bb84	Theory	-37.512411871840314	74.68253145386	147071
995759fd4fbf34367dd1a2bc328cce911de7f70a	analysis on the sensitivity attack to watermarking schemes with patchwork detection boundaries	public key cryptography;security properties;legislation;protocols;electronic commerce;zero knowledge proof;semantic security;identity based encryption;computational intelligence;satisfiability;computer security;protection;public key;privacy identity based encryption protection protocols public key cryptography public key legislation computational intelligence computer security electronic commerce;design verification;ring signature;trust negotiation;privacy	The sensitivity attack is a main threat to the security of watermarking schemes with open detectors. By the attempts across the detection boundary, the attackers gain adequate information of the embedded watermark to remove it with- out introducing serious distortions into the watermarked works. In some image watermarking schemes, the detection boundaries are the patchworks of certain numbers of hyper- planes. Here the existing sensitivity attacks are not suitable anymore for the detection functions have numbers of differ- ent gradients. The letter proposed a new sensitivity attack in which the attacking directions were calculated with a cer- tain number of gradients estimated separately with the old sensitivity attack. Our experiments show the new attack can remove the watermarks successfully without seriously tam- pering the fidelity.	digital watermarking;distortion;embedded system;experiment;gradient;patchwork;sensor;time complexity;watermark (data file)	Qiyang Zhao;Zhonglin Wang;Baolin Yin	2007	2007 International Conference on Computational Intelligence and Security (CIS 2007)	10.1109/CIS.2007.115	computer science;computational intelligence;internet privacy;public-key cryptography;proactive secret sharing;world wide web;computer security	Vision	-43.228902246638434	74.59337426208339	147254
305ba8a2f01cf0b2136b6dde2cf4c3508901d4c3	digital signatures - explanation and usage	digital signature		digital signature;type signature	L. G. Lawrence	1993	Computers & Security	10.1016/0167-4048(93)90109-I	digital signature;computer science;computer security	Crypto	-42.56087559824964	76.11717743724817	147427
3693a6242af6d6e2016a3f3f38465faf5aa6c198	anonymity notions for public-key infrastructures in mobile vehicular networks	model design;vehicular network;satisfiability;traffic safety;data privacy;mobile communication;vehicles data privacy mobile communication;vehicles;public key vehicle safety telecommunication traffic traffic control manufacturing content addressable storage databases pressing protection concrete;public key infrastructure;efficiency requirements anonymity notions public key infrastructures mobile vehicular networks concrete anonymity requirements anonymity properties unlinkability bad actor detection	As vehicular networks approach practicality, there is wide recognition for security challenges in their use, and pressing need for security solutions. The intrinsically mobile and ad-hoc nature of vehicular networks pose rather novel challenges to the modeling, design and analysis of security solutions for them. One particularly stringent requirement in this area is that of protecting the anonymity of vehicle owners during their participation in a vehicular network, such as in traffic safety applications. In this paper we present novel models of concrete anonymity requirements for vehicular networks. We consider a case study of a simple variant of a public-key infrastructure for vehicular networks and present two techniques to augment it so that it provides improved anonymity properties. The resulting vehicular-network key infrastructures satisfy desirable combinations of anonymity, unlinkability bad actor detection, and efficiency requirements.	actor model;asiacrypt;formal language;hoc (programming language);lecture notes in computer science;public key infrastructure;public-key cryptography;requirement;springer (tank)	Giovanni Di Crescenzo;Tao Zhang;Stanley Pietrowicz	2007	2007 IEEE Internatonal Conference on Mobile Adhoc and Sensor Systems	10.1109/MOBHOC.2007.4428741	mobile telephony;information privacy;computer science;public key infrastructure;vehicular communication systems;internet privacy;computer security;computer network;satisfiability	Mobile	-47.887130384647676	75.23481253780825	147583
3a87e9208b7ab306149fd039d186c00eccd1c8ee	hashing garbled circuits for free		We introduce Free Hash, a new approach to generating Garbled Circuit (GC) hash at no extra cost during GC generation. This is in contrast with state-of-the-art approaches, which hash GCs at computational cost of up to 6× of GC generation. GC hashing is at the core of the cut-and-choose technique of GC-based secure function evaluation (SFE). Our main idea is to intertwine hash generation/verification with GC generation and evaluation. While we allow an adversary to generate a GC ĜC whose hash collides with an honestly generated GC, such a ĜC w.h.p. will fail evaluation and cheating will be discovered. Our GC hash is simply a (slightly modified) XOR of all the gate table rows of GC. It is compatible with Free XOR and half-gates garbling, and can be made to work with many cut-and-choose SFE protocols. With today’s network speeds being not far behind hardware-assisted fixed-key garbling throughput, eliminating the GC hashing cost will significantly improve SFE performance. Our estimates show substantial cost reduction in typical settings, and up to factor 6 in specialized applications relying on GC hashes. We implemented GC hashing algorithm and report on its performance.	adversary (cryptography);algorithm;algorithmic efficiency;exclusive or;garbled circuit;hash function;secure two-party computation;throughput	Xiong Fan;Chaya Ganesh;Vladimir Kolesnikov	2017		10.1007/978-3-319-56617-7_16	oblivious transfer;certificate authority;theoretical computer science;hash function;computer science;electronic circuit;block cipher;security parameter	Crypto	-36.34187047170616	78.08023262336637	147590
3bfd53856975e5e116514a538b8f6f7cbb7f85b7	efficient chosen ciphertext secure key encapsulation mechanism in standard model over ideal lattices	lattices;indistinguishability under active chosenciphertext attacks;key encapsulation mechanism;94a60;11t71;standard model;cryptography;68q30	ABSTRACTKey encapsulation mechanism (KEM) is an important key distribution mechanism that not only allows both sender and receiver to safely share a random session key, but also can be mainly applied to construct a hybrid public key encryption scheme. In this paper, we give an positive answer to the question of if it is possible to build an efficient KEM over lattices. More precisely, we design an efficient KEM scheme in standard model based on ideal lattices. We prove that the proposed scheme captures indistinguishability against active chosen ciphertext attacks (IND-CCA) under the ring learning with errors problem, or more formally, IND-CCA security. Compared with the current CCA secure KEM schemes based on lattices in the standard model, our scheme has shorter public key, secret key and encapsulation ciphertext. In addition, our KEM scheme realizes IND-CCA security in the standard model.	adaptive chosen-ciphertext attack;ciphertext;encapsulation (networking);ideal lattice cryptography;key encapsulation	Xiaopeng Yang;Wenping Ma;Chengli Zhang	2017	Int. J. Comput. Math.	10.1080/00207160.2016.1149578	standard model;cryptography;theoretical computer science;ciphertext indistinguishability;mathematics;internet privacy;computer security;algebra	Crypto	-40.82957152540808	75.65621885343015	147623
4ddd345e1207cde165b66c75f844ed23a8dae59a	error-correcting pairs for a public-key cryptosystem		Code-based cryptography is an interesting alternative to classic number-theory PKC since it is conjectured to be secure against quantum computer attacks. Many families of codes have been proposed for these cryptosystems, one of the main requirements is having high performance t-bounded decoding algorithms which in the case of having an error-correcting pair is achieved. In this article the class of codes with a t-ECP is proposed for the McEliece cryptosystem. The hardness of retrieving the t-ECP for a given code is considered. As a first step distinguishers of several subclasses are given.	algorithm;code;error detection and correction;mceliece cryptosystem;pkc (conference);public-key cryptography;quantum computing;requirement	Irene Marquez Corbella;Ruud Pellikaan	2012	CoRR		arithmetic;mceliece cryptosystem;theoretical computer science;mathematics;hybrid cryptosystem;computer security	Crypto	-38.38208780501759	79.90207934088963	147704
7848d32eb3aa6ffd6c7e6e4a6681ba0d30dd6f9d	a new type of timing attack: application to gps	institutional repositories;salida;calculateur embarque;fedora;cle privee;contre mesure electronique;securite;hamming weight;implementation;interest points;cryptanalyse;systeme gps;fuite;probabilistic approach;long terme;gps system;long term;vital;attaque;cryptanalysis;criptoanalisis;hamming distance;largo plazo;contra medida electronica;clave privada;private key;criptografia;enfoque probabilista;cryptography;approche probabiliste;safety;distance hamming;leak;boarded computer;delai d execution;side channel attacks;cryptographie;plazo ejecucion;attack;electronic countermeasure;vtls;implementacion;seguridad;calculador embarque;distancia hamming;ils;time allowed;sistema gps;timing attack	We investigate side-channel attacks where the attacker only needs the Hamming weights of several secret exponents to guess a longterm secret. Such weights can often be recovered by SPA, EMA, or simply timing attack. We apply this principle to propose a timing attack on the GPS identification scheme. We consider implementations of GPS where the running time of the exponentiation (commitment phase) leaks the exponent’s Hamming weight, which is typical of a square and multiply algorithm for example. We show that only 800 time measures allow the attacker to find the private key in a few seconds on a PC with a success probability of 80%. Besides its efficiency, two other interesting points in our attack are its resistance to some classical countermeasures against timing attacks, and the fact that it works whether the Chinese Remainder Technique is used or not.	algorithm;exponentiation by squaring;global positioning system;hamming weight;identification scheme;public-key cryptography;side-channel attack;time complexity;window function	Julien Cathalo;François Koeune;Jean-Jacques Quisquater	2003		10.1007/978-3-540-45238-6_24	cryptanalysis;hamming weight;attack;hamming distance;timing attack;pre-play attack;telecommunications;computer science;cryptography;electronic countermeasure;mathematics;implementation;computer security;statistics	Security	-40.261702087637964	82.31146813137602	147768
536b088e9238a264ba2ad4d98f3f1528a183c079	a security proof of kcdsa using an extended random oracle model		We describe a tight security reduction to the discrete logarithm problem for KCDSA under an extended Random Oracle Model. This is achieved by generalising the signature scheme and producing a security proof for the generalised scheme. We require the application of Randomized Hashing. We also introduce a Challenger to the Random Oracle Model, who is external to the Simulator and Adversary. The Challenger provides oracle returns for one hash function, and challenges which have a low probability of being met. On presentation of a forged signature the Simulator either identifies an edge case which allows solving of a challenge, or solves the discrete logarithm problem. Hence the tight reduction.	adversary (cryptography);digital signature;discrete logarithm;edge case;hash function;kcdsa;provable security;random oracle;randomized algorithm;reduction (complexity)	Vikram Singh	2014	IACR Cryptology ePrint Archive		random oracle;discrete mathematics;theoretical computer science;mathematics;schnorr signature;algorithm	Crypto	-38.08557872917582	77.34966925978601	148042
9ff3b706e0200cd400ddcd76278d02a025c56957	distance-bounding protocol with time-stamped authentication for rfid	protocols;clocks;relay attack radio frequency identification rfid distance bounding protocol;authentication;time stamped program distance bounding protocol time stamped authentication radiofrequency identification rfid relay attack challenge response authentication protocols rapid bit exchange phase spoofing attacks;distance bounding protocol;radio frequency identification rfid;relays;radiofrequency identification;protocols authentication clocks radiofrequency identification relays terrorism;telecommunication security cryptographic protocols radiofrequency identification relay networks telecommunication;terrorism;relay attack	Relay attack is one of the most challenging threats that RFID will have to face now. Distance bounding protocols form a family of challenge-response authentication protocols and confirm the round-trip time at the Rapid Bit Exchange phase that have been introduced to thwart relay attacks. They enable a reader to authenticate and to establish an upper bound on the physical distance to an entrusted tag. We provide an effective attack of a family of such protocols to implement the spoofing attacks of distance successfully, and description of existing protocols cannot completely eliminate such attacks. Corresponding we propose a new time-stamped program to correct the defect and verify the effectiveness.	authentication protocol;challenge–response authentication;distance-bounding protocol;relay attack;software bug;spoofing attack	Guo-Heng Wei;Huan-Guo Zhang;Zhijun Li	2014	2014 Ninth International Conference on P2P, Parallel, Grid, Cloud and Internet Computing	10.1109/3PGCIC.2014.47	reflection attack;challenge–response authentication;engineering;authentication protocol;internet privacy;computer security;computer network	Security	-45.52508055829512	75.1262929013045	148260
56e1213d708a3d45364ea4bc9f1bf61da9d959d0	representative system and security message transmission using re-encryption scheme based on symmetric-key cryptography	proverif;re encryption;cryptographic protocol;formal analysis		cryptography;encryption;symmetric-key algorithm	Dai Watanabe;Hisao Sakazaki;Kunihiko Miyazaki	2017	JIP	10.2197/ipsjjip.25.67	cryptographic primitive;computer science;cryptographic protocol;internet privacy;computer security;encryption;algorithm;computer network	Crypto	-42.31837614587927	76.09502410638196	148335
b39767441870d9ea1b117b2fc15d30d5f50b6ddd	a short note on secret sharing using elliptic curves	secret sharing;elliptic curve;threshold scheme;verifiable secret sharing;bilinear map	In this short note, we describe a variant of Shamir’s (n, t)-threshold scheme based on elliptic curves. Moreover, we show how pairings of elliptic curves can be used to also provide verifiability for the new elliptic curve based	bilinear filtering;ecc memory;elliptic curve cryptography;formal verification;secret sharing	Volker Müller	2008			bilinear map;shamir's secret sharing;homomorphic secret sharing;secure multi-party computation;internet privacy;elliptic curve;secret sharing;computer security;verifiable secret sharing	Crypto	-41.16219436601284	77.219814836637	148911
0a6f1ab8fd484be1fa09b4b5988be5dbb8fede39	long-lived broadcast encryption	desciframiento;encryption;securite;radiodifusion;decryptage;traitor tracing;tamper resistance;smartcard;cryptage;digital content;safety;decryption;broadcast encryption;broadcasting;seguridad;radiodiffusion;steady state	In a broadcast encryption scheme, digital content is encrypted to ensure that only privileged users can recover the content from the encrypted broadcast. Key material is usually held in a “tamperresistant,” replaceable, smartcard. A coalition of users may attack such a system by breaking their smartcards open, extracting the keys, and building “pirate decoders” based on the decryption keys they extract. In this paper we suggest the notion of long-lived broadcast encryption as a way of adapting broadcast encryption to the presence of pirate decoders and maintaining the security of broadcasts to privileged users while rendering all pirate decoders useless. When a pirate decoder is detected in a long-lived encryption scheme, the keys it contains are viewed as compromised and are no longer used for encrypting content. We provide both empirical and theoretical evidence indicating that there is a long-lived broadcast encryption scheme that achieves a steady state in which only a small fraction of cards need to be replaced in each epoch. That is, for any fraction β, the parameter values may be chosen in such a way to ensure that eventually, at most β of the cards must be replaced in each epoch. Long-lived broadcast encryption schemes are a more comprehensive solution to piracy than traitor-tracing schemes, because the latter only seek to identify the makers of pirate decoders and don’t deal with how to maintain secure broadcasts once keys have been compromised. In addition, long-lived schemes are a more efficient long-term solution than revocation schemes, because their primary goal is to minimize the amount of recarding that must be done in the long term.	alternating direction implicit method;binary decoder;broadcast encryption;cryptography;digital recording;epoch (reference date);multicast;smart card;steady state;traitor tracing	Juan A. Garay;Jessica Staddon;Avishai Wool	2000		10.1007/3-540-44598-6_21	multiple encryption;smart card;atomic broadcast;40-bit encryption;telecommunications;computer science;filesystem-level encryption;on-the-fly encryption;internet privacy;steady state;computer security;broadcasting;encryption;tamper resistance;probabilistic encryption;56-bit encryption;attribute-based encryption	Crypto	-43.7299096973593	76.92630952829396	149137
ed91331c59b4d87eb929a2995db3f047d2de79b3	universally composable rfid mutual authentication	protocols;protocols authentication public key rfid tags privacy;authentication;cryptographic protocol;universal composability;rfid tags;public key;universal composability cryptographic protocol rfid authentication;privacy;rfid authentication	Universally Composable (UC) framework provides the strongest security notion for designing fully trusted cryptographic protocols, and it is very challenging on applying UC security in the design of RFID mutual authentication protocols. In this paper, we formulate the necessary conditions for achieving UC secure RFID mutual authentication protocols which can be fully trusted in arbitrary environment, and indicate the inadequacy of some existing schemes under the UC framework. We define the ideal functionality for RFID mutual authentication and propose the first UC secure RFID mutual authentication protocol based on public key encryption and certain trusted third parties which can be modeled as functionalities. We prove the security of our protocol under the strongest adversary model assuming both the tags’ and readers’ corruptions. We also present two (public) key update protocols for the cases of multiple readers: one uses Message Authentication Code (MAC) and the other uses trusted certificates in Public Key Infrastructure (PKI). Furthermore, we address the relations between our UC framework and the zero-knowledge privacy model proposed by Deng et al. [1] .	adversary model;authentication protocol;cryptographic primitive;cryptographic protocol;electronic product code;encryption;message authentication code;mutual authentication;public key infrastructure;public-key cryptography;radio-frequency identification;secure cryptoprocessor;secure voice;trusted third party;uc browser;universal composability	Chunhua Su;Bagus Santoso;Yingjiu Li;Robert H. Deng;Xinyi Huang	2017	IEEE Transactions on Dependable and Secure Computing	10.1109/TDSC.2015.2434376	radio-frequency identification;data authentication algorithm;communications protocol;universal composability;challenge–response authentication;computer science;authentication protocol;lightweight extensible authentication protocol;authentication;cryptographic protocol;internet privacy;public-key cryptography;privacy;computer security;computer network	Security	-43.11979529708787	74.79563418878617	149205
3270aa92f8901fc2360b8abe8b8e80673341a16d	the second-preimage attack on md4	hachage;distributed system;systeme reparti;securite informatique;collision differential path;probabilistic approach;weak message;computer security;hashing;sistema repartido;hamming distance;criptografia;enfoque probabilista;cryptography;approche probabiliste;seguridad informatica;distance hamming;cryptographie;hash function;distancia hamming;second preimage	In Eurocrypt’05, Wang et al. presented new techniques to find collisions of Hash function MD4. The techniques are not only efficient to search for collisions, but also applicable to explore the secondpreimage of MD4. About the second-preimage attack, they showed that a random message was a weak message with probability 2−122 and it only needed a one-time MD4 computation to find the second-preimage corresponding to the weak message. A weak message means that there exits a more efficient attack than the brute force attack to find its secondpreimage. In this paper, we find another new collision differential path which can be used to find the second-preimage for more weak messages. For any random message, it is a weak message with probability 2−56, and it can be converted into a weak message by message modification techniques with about 2 MD4 computations. Furthermore, the original message is close to the resulting message (weak message), i.e, the Hamming weight of the difference for two messages is about 44.	brute-force attack;computation;hamming weight;hash function;key escrow;md4;message authentication code;message-oriented middleware;preimage attack;window function	Hongbo Yu;Gaoli Wang;Guoyan Zhang;Xiaoyun Wang	2005		10.1007/11599371_1	hash function;computer science;artificial intelligence;theoretical computer science;operating system;database;distributed computing;computer security;algorithm	Crypto	-43.480485241222404	78.61435642384775	149235
47475c48d4817f9d549d19b10bd0c62bcbd64127	random sampling reduction with precomputation	lattice reduction;lattice based cryptography;precomputation		precomputation	Masayuki Yoshino;Noboru Kunihiro	2013	IEICE Transactions		lattice-based cryptography;lattice reduction;computer science;precomputation;mathematics	EDA	-40.76095819686361	80.3256399735976	149603
6a2f7060833dcafd8ac330b5bdde0a0220adb61e	towards mobile cryptography	distributed algorithms;distributed system;software portability;driving force;communication networks;function composition techniques;executable code;mobile cryptography;mobile agents;encrypted functions;cryptographic protocols;homomorphic encryption schemes;malicious hosts;cryptographic primitive;untrusted execution environment;protection;marine vehicles;cryptography protection cryptographic protocols read only memory data security hardware marine vehicles mobile agents business communication networks;distributed algorithms cryptography software portability;cryptography;execution environment;business;mobile code;malicious host;function composition techniques mobile cryptography mobile code protection distributed systems executable code security malicious hosts cryptographic primitive noninteractive evaluation encrypted functions digital signing untrusted execution environment homomorphic encryption schemes;digital signing;distributed systems;noninteractive evaluation;mobile code protection;security;read only memory;homomorphic encryption;hardware;data security	Mobile code technology has become a driving force for recent advances in distributed systems. The concept of mobility of executable code raises major security problems. In this paper we deal with the protection of mobile code from possibly malicious hosts. We conceptualize on the specific cryptographic problems posed by mobile code. We are able to provide a solution for some of these problems: We present techniques how to achieve “non–interactive evaluation with encrypted functions” in certain cases and give a complete solution for this problem in important instances. We further present a way how an agent might securely perform a cryptographic primitive, digital signing, in an untrusted execution environment. Our results are based on the use of homomorphic encryption schemes and function composition techniques.	antivirus software;code mobility;coefficient;computation;computer security;cryptographic primitive;cryptography;digital signature;distributed computing;encrypted function;executable;homomorphic encryption;polynomial	Tomas Sander;Christian F. Tschudin	1998		10.1109/SECPRI.1998.674837	software portability;cryptographic primitive;distributed algorithm;homomorphic encryption;computer science;cryptography;information security;theoretical computer science;mobile agent;distributed computing;data security;computer security	Security	-46.6094559493276	77.22812639203543	149785
33c089e0a7a4656bce6a7db749f4a479f3b8e026	selected areas in cryptography		DES and triple-DES are two well-known and popular encryption algorithms, but they both have the same drawback: their block size is limited to 64 bits. While the cryptographic community is working hard to select and evaluate candidates and finalists for the AES (Advanced Encryption Standard) contest launched by NIST in 1997, it might be of interest to propose a secure and simple double block-length encryption algorithm. More than in terms of key length and block size, our Universal Encryption Standard is a new construction that remains totally compliant with DES and triple-DES specifications as well as with AES requirements.	64-bit computing;advanced encryption standard process;algorithm;block cipher;block size (cryptography);key size;requirement;selected areas in cryptography;triple des;ues (cipher)	Jan van Leeuwen;Howard M. Heys;Carlisle Adams	2000		10.1007/3-540-46513-8	neural cryptography;encryption;cryptography;theoretical computer science;information system;worst-case complexity;distributed computing;computer science;probabilistic encryption	Crypto	-36.11467827194999	79.90120077568325	149927
8d767e5daee98ba1879b8c8e66299b0e22c4fd95	multicollisions in iterated hash functions. application to cascaded constructions	hachage;securite;cryptanalyse;cryptanalysis;criptoanalisis;hashing;criptografia;cryptography;safety;cryptographie;hash function;seguridad	In this paper, we study the existence of multicollisions in iterated hash functions. We show that finding multicollisions, i.e. r-tuples of messages that all hash to the same value, is not much harder than finding ordinary collisions, i.e. pairs of messages, even for extremely large values of r. More precisely, the ratio of the complexities of the attacks is approximately equal to the logarithm of r. Then, using large multicollisions as a tool, we solve a long standing open problem and prove that concatenating the results of several iterated hash functions in order to build a larger one does not yield a secure construction. We also discuss the potential impact of our attack on several published schemes. Quite surprisingly, for subtle reasons, the schemes we study happen to be immune to our attack.	approximation;concatenation;cryptographic hash function;iterated function;iteration	Antoine Joux	2004		10.1007/978-3-540-28628-8_19	security of cryptographic hash functions;double hashing;hash function;perfect hash function;collision attack;dynamic perfect hashing;merkle tree;primary clustering;sha-2;collision resistance;computer science;theoretical computer science;universal hashing;hash chain;hash buster;mathematics;k-independent hashing;rolling hash;computer security;algorithm;cryptographic hash function;statistics;mdc-2;swifft;hash tree;hash filter	Crypto	-37.45597444506197	80.28322280006431	150103
21057923fffc1a44ed6cdc6067b0d63ba91eac9f	factoring rsa keys from certified smart cards : coppersmith in the wild	lattices;rsa;coppersmith;factorization;smart cards	This paper explains how an attacker can efficiently factor 184 distinct RSA keys out of more than two million 1024-bit RSA keys downloaded from Taiwan’s national “Citizen Digital Certificate” database. These keys were generated by government-issued smart cards that have built-in hardware random-number generators and that are advertised as having passed FIPS 140-2 Level 2 certification. These 184 keys include 103 keys that share primes and that are efficiently factored by a batch-GCD computation. This is the same type of computation that was used last year by two independent teams (USENIX Security 2012: Heninger, Durumeric, Wustrow, Halderman; Crypto 2012: Lenstra, Hughes, Augier, Bos, Kleinjung, Wachter) to factor tens of thousands of cryptographic keys on the Internet. The remaining 81 keys do not share primes. Factoring these 81 keys requires taking deeper advantage of randomness-generation failures: first using the shared primes as a springboard to characterize the failures, and then using Coppersmith-type partial-key-recovery attacks. This is the first successful public application of Coppersmith-type attacks to keys found in the wild.	arjen lenstra;canonical account;computation;cryptography;fips 140;fips 140-2;integer factorization;internet;key (cryptography);public key certificate;randomness;smart card	Daniel J. Bernstein;Yun-An Chang;Chen-Mou Cheng;Li-Ping Chou;Nadia Heninger;Tanja Lange;Nicko van Someren	2013	IACR Cryptology ePrint Archive	10.1007/978-3-642-42045-0_18	arithmetic;smart card;discrete mathematics;theoretical computer science;lattice;mathematics;factorization;algebra	Security	-35.42706423152765	76.89820182195581	150203
d1c5275744863b1f6af3ca602f49922f3df45ffb	light-hhb: a new version of hhb with improved session key exchange		This paper offers a new version of the hHB protocol denoted Light-hHB. This proposal uses the same framework as hHB, that is a two stages protocol: the first one for the establishment of a session key between the reader and the tag and the second one similar to HB+. We also introduce in this paper a novel and lightweight key exchange protocol inspired by the BB84 protocol named the non-quantum key exchange protocol. With the use of a practical implementation of the latter protocol in the first stage of Light-hHB, the transmission cost is drastically reduced compared to the one of hHB, which is its main drawback. In the context of RFID tags, LighthHB is significantly more practical than hHB and achieves the same security goals.	bb84;key exchange;radio-frequency identification;session key	Ka Ahmad Khoureich	2015	IACR Cryptology ePrint Archive		computer network;bb84;session key;key exchange;computer science	Security	-46.557373910731854	75.10466585551848	150239
f90d731a1dfa646c992537eac753484722c95f53	2n-bit hash-functions using n-bit symmetric block cipher algorithms	block cipher;hash function	We present a new hash-function, which provides 2n-bit hash-results, using any n-bit symmetric block cipher algorithm. This  hash-function can be considered as a extension of an already known one, which only provided n-bit hash-results. The difference  is crucial, because a lot of symmetric block cipher algorithms use 64-bit blocks and recent works have shown that a 64-bit  hash-result is greatly insufficient.  	algorithm;block cipher	Jean-Jacques Quisquater;Marc Girault	1989		10.1007/3-540-46885-4_13	substitution-permutation network;rail fence cipher;block cipher;transposition cipher;triple des;differential cryptanalysis;residual block termination;hash function;two-square cipher;running key cipher;ciphertext stealing;block cipher mode of operation;computer science;stream cipher;affine cipher;computer security;cbc-mac;algorithm;3-way;cryptographic hash function;mdc-2	Crypto	-37.67460419584444	80.39374933710381	150621
e0b5e478a66d63bf7cde02004bfe42f73a5c0a34	improvements to mitchell's remote user authentication protocol	institutional repositories;hachage;provable security;occupation time;fedora;cryptographic hash function;authentication;securite informatique;vital;authentification;computer security;synchronisation;hashing;autenticacion;temps occupation;synchronization;criptografia;cryptography;seguridad informatica;denial of service;tiempo ocupacion;cryptographie;sincronizacion;vtls;user authentication;public information;ils;denegacion de servicio;deni service;dos attack	A provably secure protocol for remote authentication is presented. Only public information is stored at the verifying host that makes our scheme resistant to server compromise. We use one time signatures coupled with offline transcripts for synchronization. Due to sole usage of fast cryptographic hash functions, our method is appropriate for low cost user authentication. Our construction improves over the previously proposed technique of Mitchell to overcome its problem of Denial of Service (DoS) attacks.	antivirus software;authentication protocol;cryptographic hash function;denial-of-service attack;mitchell corporation;mutual authentication;online and offline;provable security;public-key cryptography;requirement;server (computing);verification and validation	Vipul Goyal;Abhishek Jain;Jean-Jacques Quisquater	2005		10.1007/11734727_8	data authentication algorithm;synchronization;computer science;authentication protocol;operating system;authentication;database;distributed computing;internet privacy;world wide web;computer security;denial-of-service attack;challenge-handshake authentication protocol	Crypto	-44.00352129862098	76.90553496723317	150650
4882e7be12b6b8838184d12ad69135da79d5b533	weak zero-knowledge beyond the black-box barrier		The round complexity of zero-knowledge protocols is a long-standing open question, yet to be settled under standard assumptions. So far, the question has appeared equally challenging for relaxations such as weak zero-knowledge and witness hiding. Protocols satisfying these relaxed notions under standard assumptions have at least four messages, just like full-fledged zero knowledge. The difficulty in improving round complexity stems from a fundamental barrier: none of these notions can be achieved in three messages via reductions (or simulators) that treat the verifier as a black box. We introduce a new non-black-box technique and use it to obtain the first protocols that cross this barrier under standard assumptions. Our main results are: • Weak zero-knowledge for NP in two messages, assuming quasipolynomially-secure fullyhomomorphic encryption and other standard primitives (known fromquasipolynomial hardness of Learning with Errors), as well as subexponentially-secure one-way functions. • Weak zero-knowledge for NP in three messages under standard polynomial assumptions (following for example from fully-homomorphic encryption and factoring). We also give, under polynomial assumptions, a two-messagewitness-hiding protocol for any language L ∈ NP that has a witness encryption scheme. This protocol is also publicly verifiable. Our technique is based on a new homomorphic trapdoor paradigm, which can be seen as a non-black-box analog of the classic Feige-Lapidot-Shamir trapdoor paradigm. ∗Tel Aviv University, nirbitan@tau.ac.il. Member of the Check Point Institute of Information Security. Supported by the Alon Young Faculty Fellowship, by Len Blavatnik and the Blavatnik Family foundation, and an ISF grant 18/484. †Microsoft Research, New England, dakshkhurana@gmail.com ‡MIT, omerpa@mit.edu Supported by NSF Grants CNS-1350619 and CNS-1414119, and the Defense Advanced Research Projects Agency (DARPA) and the U.S. Army Research Office under contracts W911NF-15-C-0226 and W911NF-15-C0236.Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the DARPA and ARO. Part of this research was done while visiting Tel Aviv university and supported by Len Blavatnik and the Blavatnik Family foundation.	black box;formal verification;global serializability;homomorphic encryption;ibm notes;information security;integer factorization;learning with errors;microsoft research;one-way function;polynomial;programming paradigm;simulation;zero-knowledge proof	Nir Bitansky;Omer Paneth	2018	IACR Cryptology ePrint Archive			Crypto	-35.24056158121368	76.7903088123426	150853
81106e5e4585f51d167ecc15633caf4a8005fb1e	adaptively single-key secure constrained prfs for nc1		We present a construction of an adaptively single-key secure constrained PRF (CPRF) for NC1 assuming the existence of indistinguishability obfuscation (IO) and the subgroup hiding assumption over a (pairing-free) composite order group. This is the first construction of such a CPRF in the standard model without relying on a complexity leveraging argument. To achieve this, we first introduce the notion of partitionable CPRF, which is a CPRF accommodated with partitioning techniques and combine it with shadow copy techniques often used in the dual system encryption methodology. We present a construction of partitionable CPRF for NC1 based on IO and the subgroup hiding assumption over a (pairing-free) group. We finally prove that an adaptively single-key secure CPRF for NC1 can be obtained from a partitionable CPRF for NC1 and IO.	ciphertext indistinguishability;disk partitioning;encryption;nc (complexity);primitive recursive function;shadow copy	Nuttapong Attrapadung;Takahiro Matsuda;Ryo Nishimaki;Shota Yamada;Takashi Yamakawa	2018	IACR Cryptology ePrint Archive			Crypto	-39.32112314345118	74.824052249596	151528
f047d26a3af282b9b14ca69bf485899c94876d77	improved id-based ring signature scheme with constant-size signatures	accumulator;constant-size;random oracle;ring signature	Ring signature enable a user to sign a message on behalf of the ring, without revealing the actual signer. Constant-size ring signature is the ring scheme that the size of the signature does not grow with the size of the ring(or group), so it is practical for large rings. In this paper we use the Collision Resistant Accumulator from bilinear pairing to construct an identity-based ring signature scheme with constant-size signature. Our scheme actually is an improvement on the modified version of the scheme proposed by Nguyen, but we greatly improved the efficiency in terms of computational complexity and signature size. To the best of our knowledge, our scheme is the most efficient secure ID-based ring signature with constant-size based on accumulator proposed to date. Our scheme is proven secure in the random oracle model based on a simplified and general Forking Lemma under the k-strong Diffie-Hellman assumption.	accumulator (computing);antivirus software;bilinear filtering;collision resistance;computational complexity theory;decisional diffie–hellman assumption;diffie–hellman key exchange;diffie–hellman problem;digital signature;forking lemma;random oracle;ring signature	Hongwei Li;Xiao Li;Mingxing He;Shengke Zeng	2011	Informatica (Slovenia)		ring signature;artificial intelligence;computer science;machine learning;theoretical computer science	Security	-40.195948799901174	76.67814553070968	151581
1231c2b5d424766e7a174c08ec3af3db991bb8a8	lattice-based signature schemes and their sensitivity to fault attacks	computers;nist;lattices;resistance;cryptography;quantum computing	Due to their high efficiency and their strong security properties, lattice-based cryptographic schemes seem to be a very promising post-quantum replacement for currently used public key cryptography. The security of lattice-based schemes has been deeply analyzed mathematically, whereas little effort has been spent on the analysis against implementation attacks. In this paper, we start with the fault analysis of one of the most important cryptographic primitives: signature schemes. We investigate the vulnerability and resistance of the currently most efficientlattice-based signature schemes BLISS (CRYPTO 2013), ring-TESLA (AfricaCrypt 2016), and the GLP scheme (CHES 2012) and their implementations. We consider different kinds of (first-order) randomizing, zeroing, and skipping faults. For each of the signature schemes, we found at least six effective attacks. To increase the security of lattice-based signature schemes, we propose countermeasures for each of the respective attacks.	bliss;cryptographic primitive;differential fault analysis;first-order logic;first-order predicate;gateway (telecommunications);lattice model (finance);post-quantum cryptography;public-key cryptography	Nina Bindel;Johannes A. Buchmann;Juliane Krämer	2016	2016 Workshop on Fault Diagnosis and Tolerance in Cryptography (FDTC)	10.1109/FDTC.2016.11	theoretical computer science;mathematics;distributed computing;blind signature;computer security	Security	-38.88853530084926	78.36841683886817	151646
135b33a92a05f14d968b663e3a25b936ea550349	an enhanced pretty good privacy (epgp) system with mutual non-repudiation	nrr;security.;nro;pgp;mnr;non-repudiation;epgp	Enhanced Pretty Good Privacy (EPGP) is a new cryptosystem based on Pretty Good Privacy (PGP), used for the purpose of secure e-mail message communication over an open network. The idea of EPGP, introduced in this paper, addresses PGP's main drawback of incomplete non-repudiation service, and therefore, attempts to increase the degree of security and efficiency of e-mail message communication.	cryptosystem;email encryption;non-repudiation;pretty good privacy	Gregory Vert;Manaf Alfize	2006			computer science;computer security;non-repudiation;internet privacy	Security	-43.94342287811252	74.80294576516178	151774
029dc82de9579002db59e408d1c541935b9b29c6	aggregating cl-signatures revisited: extended functionality and better efficiency	bilinear map;aggregate information applications;public key signature;aggregate signature;cl signature	Aggregate signature is public-key signature that allows anyone to aggregate different signatures generated by different signers on different messages into a short (called aggregate) signature. The notion has many applications where compressing the signature space is important: in infrastructure: secure routing protocols, in security: compressed certificate chain signature, in signing incrementally changed data: such as software module authentications, and in transaction systems: like in secure high-scale repositories and logs, typical in financial transactions. In spite of its importance, the state of the art of the primitive is such that it has not been easy to devise a suitable aggregate signature scheme that satisfies the conditions of real applications, with reasonable parameters: short public key size, short aggregate signatures size, and efficient aggregate signing/verification. In this paper, we propose two aggregate signature schemes based on the Camenisch-Lysyanskaya (CL) signature scheme whose security is reduced to that of CL signature (i.e., secure under the LRSW assumption) which substantially improve efficiency conditions for real applications. The first scheme is an “efficient sequential aggregate signature” scheme with the shortest size public key, to date, and very efficient aggregate verification. The second scheme is an “efficient synchronized aggregate signature” scheme with a very short public key size, and with the shortest (to date) size of aggregate signatures among synchronized aggregate signature schemes. Signing and aggregate verification are very efficient. The security of the schemes is proved by reducing from the CL signature without random oracles (first scheme) and in the random oracle model (second scheme). Furthermore, our schemes are compatible: a signer of our aggregate signature schemes can dynamically use two modes of aggregation “sequential” and “synchronized,” employing the same private/public key. ⋆ Supported by the MKE (The Ministry of Knowledge Economy), Korea, under the ITRC (Information Technology Research Center) support program (NIPA-2012H0301-12-3007) supervised by the NIPA (National IT Industry Promotion Agency). ⋆⋆ Supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MEST) (No. 2012-0008697).	aggregate data;aggregate function;antivirus software;authentication;digital signature;electronic signature;key size;meltwater entrepreneurial school of technology;oracle machine;public key certificate;public-key cryptography;random oracle;root certificate;routing	Kwangsu Lee;Dong Hoon Lee;Moti Yung	2012		10.1007/978-3-642-39884-1_14	bilinear map;theoretical computer science;blind signature;schnorr signature;world wide web;computer security	Security	-34.88709863513917	76.5217054595909	151851
0ec104931b5a56520adddbbf9ac84e371397f863	efficient and provably secure ciphers for storage device block level encryption	provable security;one way hash function;block cipher;data encryption;random function;symmetric cipher;hash function;modes of operation;storage device encryption	Block ciphers generally have fixed and relatively small input length. Thus they are often used in some mode of operations (e.g., ECB, CBC, CFB, and CTR) that enables the encryption of longer messages. Unfortunately, all these modes of operation reveal some information on their inputs or on relationships between different inputs. As an example, in the CBC mode, encrypting two messages with an identical prefix will result in identical initial blocks in the ciphertexts. Due to the well-known birthday attack and the small input length, the CBC mode becomes less secure as the number of data blocks to be encrypted increases. This leads to a challenging task, namely to design schemes for storage device block or sector level data encryption that are efficient and do not have the disadvantages mentioned above. In this paper, we propose an efficient cipher whose data/cipher blocks can be specified flexibly to match the length of a block unit for current and foreseeable future storage devices. We show that our encryption scheme is provably secure under the assumption that the underlying one-way hash function is a random function.	birthday attack;block cipher mode of operation;cryptographic hash function;encryption;european chemicals bureau;one-way function;provable security;whole earth 'lectronic link	Yuliang Zheng;Yongge Wang	2005		10.1145/1103780.1103796	multiple encryption;block cipher;triple des;differential cryptanalysis;residual block termination;disk encryption theory;40-bit encryption;two-square cipher;ciphertext stealing;block cipher mode of operation;computer science;theoretical computer science;galois/counter mode;block size;distributed computing;filesystem-level encryption;on-the-fly encryption;deterministic encryption;computer security;cbc-mac;probabilistic encryption;cryptographic hash function;56-bit encryption;mdc-2	Crypto	-37.567894558222015	78.52895452729905	151937
3fe650da4136a4977188d9f03dc33e3436d98672	zero-knowledge arguments for lattice-based accumulators: logarithmic-size ring signatures and group signatures without trapdoors		An accumulator is a function that hashes a set of inputs into a short, constant-size string while preserving the ability to efficiently prove the inclusion of a specific input element in the hashed set. It has proved useful in the design of numerous privacy-enhancing protocols, in order to handle revocation or simply prove set membership. In the lattice setting, currently known instantiations of the primitive are based on Merkle trees, which do not interact well with zero-knowledge proofs. In order to efficiently prove the membership of some element in a zeroknowledge manner, the prover has to demonstrate knowledge of a hash chain without revealing it, which is not known to be efficiently possible under well-studied hardness assumptions. In this paper, we provide an efficient method of proving such statements using involved extensions of Stern’s protocol. Under the Small Integer Solution assumption, we provide zero-knowledge arguments showing possession of a hash chain. As an application, we describe new lattice-based group and ring signatures in the random oracle model. In particular, we obtain: (i) The first latticebased ring signatures with logarithmic size in the cardinality of the ring; (ii) The first lattice-based group signature that does not require any GPV trapdoor and thus allows for a much more efficient choice of parameters.	accumulator (computing);antivirus software;cryptographic hash function;electronic signature;group signature;hash chain;lattice model (finance);merkle tree;privacy;random oracle;ring signature;type signature;zero-knowledge proof	Benoît Libert;San Ling;Khoa Nguyen;Huaxiong Wang	2016		10.1007/978-3-662-49896-5_1	combinatorics;discrete mathematics;mathematics;algorithm	Crypto	-38.91057832337382	76.16904485077367	152060
d7e3c67d638d6398027a82b1264262bed7c30e6c	exponent blinding may not prevent timing attacks on rsa		The references [9, 3, 1] treat timing attacks on RSA with CRT and Montgomery’s multiplication algorithm in unprotected implementations. It has been widely believed that exponent blinding would prevent any timing attack on RSA. At cost of significantly more timing measurements this paper extends the before-mentioned attacks to RSA with CRT, Montgomery’s multiplication algorithm and exponent blinding. Simulation experiments are conducted, which confirm the theoretical results. Effective countermeasures exist.	blinding (cryptography);cathode ray tube;experiment;montgomery modular multiplication;multiplication algorithm;multiply–accumulate operation;simulation;threat (computer);window function	Werner Schindler	2014	IACR Cryptology ePrint Archive		computer security;timing attack;blinding;exponent;computer science	Security	-42.81878196984192	81.15305899426734	152107
d99c7d8edad3d37a2fa60df1b09cba4b08137835	information security and privacy : 14th australasian conference, acisp 2009, brisbane, australia, july 1-3, 2009 : proceedings	information security	Invited Lecture.- Is the Information Security King Naked?.- Network Security.- Measurement Study on Malicious Web Servers in the .nz Domain.- A Combinatorial Approach for an Anonymity Metric.- On Improving the Accuracy and Performance of Content-Based File Type Identification.- Symmetric Key Encryption.- Attacking 9 and 10 Rounds of AES-256.- Cryptographic Properties and Application of a Generalized Unbalanced Feistel Network Structure.- Lightweight Block Ciphers Revisited: Cryptanalysis of Reduced Round PRESENT and HIGHT.- Improved Cryptanalysis of the Common Scrambling Algorithm Stream Cipher.- Testing Stream Ciphers by Finding the Longest Substring of a Given Density.- New Correlations of RC4 PRGA Using Nonzero-Bit Differences.- Hash Functions.- Analysis of Property-Preservation Capabilities of the ROX and ESh Hash Domain Extenders.- Characterizing Padding Rules of MD Hash Functions Preserving Collision Security.- Distinguishing Attack on the Secret-Prefix MAC Based on the 39-Step SHA-256.- Inside the Hypercube.- Meet-in-the-Middle Preimage Attacks on Double-Branch Hash Functions: Application to RIPEMD and Others.- On the Weak Ideal Compression Functions.- Invited Lecture.- Hardening the Network from the Friend Within.- Public Key Cryptography.- Reducing the Complexity in the Distributed Computation of Private RSA Keys.- Efficiency Bounds for Adversary Constructions in Black-Box Reductions.- Building Key-Private Public-Key Encryption Schemes.- Multi-recipient Public-Key Encryption from Simulators in Security Proofs.- Fair Threshold Decryption with Semi-Trusted Third Parties.- Conditional Proxy Broadcast Re-Encryption.- Security on Hybrid Encryption with the Tag-KEM/DEM Framework.- Protocols.- A Highly Scalable RFID Authentication Protocol.- Strengthening the Security of Distributed Oblivious Transfer.- Towards Denial-of-Service-Resilient Key Agreement Protocols.- A Commitment-Consistent Proof of a Shuffle.- Implementation.- Finite Field Multiplication Combining AMNS and DFT Approach for Pairing Cryptography.- Random Order m-ary Exponentiation.- Jacobi Quartic Curves Revisited.		Colin Boyd;Juan Manuel González Nieto	2009		10.1007/978-3-642-02620-1	cityhash;computer science;information security;theoretical computer science;internet privacy;computer security	EDA	-44.91065799060504	81.72309459650745	152158
7f1eced102e9ea9337582919948c55c0f4f604be	symmetric hash function based secure and efficient authenticated key exchange mechanism for wireless sensor networks		Authenticated Key Exchange is one of the prominent security requirement of wireless sensor networks (WSNs) to reduce the possibility of various security attacks. In this paper, we propose symmetric hash function and bloom filter based secure authenticated key exchange (AKE) protocol for WSNs. The proposed protocol is appropriate for authentication of the users without pre-alignment between the test and the registered minutia points of the fingerprint for multi-hop WSNs. The proposed protocol eliminates unauthorized query information circulation at the initial level (i.e., at the sensor node itself) to prevent bogus information flooding from the sensor nodes to the gateway node. We show that the proposed protocol resists the resource exhaustion attacks associated with WSNs of large hop count (i.e., a large number of intermediary sensor nodes through which information must pass between source sensor node and the trusted gateway node). We present both the formal and informal security analysis of the proposed protocol using AVISPA tool and basic cryptography concepts. The analysis of computational overhead demonstrates that our proposed protocol is preferable for resource-constrained sensor motes like MicaZ. The security analysis and performance evaluation reveal that the proposed protocol is more secure, effective and resilient in comparison to other existing protocols.	adversary (cryptography);authenticated key exchange;authentication;authorization;bloom filter;cryptography;fingerprint;hash function;overhead (computing);performance evaluation;qualitative comparative analysis;resource exhaustion attack;sensor node;session key;terminate (software)	Anup Kumar Maurya;V. N. Sastry	2017	2017 IEEE International Conference on Advanced Networks and Telecommunications Systems (ANTS)	10.1109/ANTS.2017.8384158	hop (networking);password;wireless sensor network;hash function;cryptography;computer network;default gateway;authenticated key exchange;sensor node;computer science	Mobile	-47.2427185934332	75.6155982479129	152956
200a23f242eaad1ef7479eabf549bd7055b9039b	multisignatures using proofs of secret key possession, as secure as the diffie-hellman problem	bilinear map;signature scheme;public key;random oracle model;diffie hellman	A multisignature scheme allows a group of n players to produce a short string which is equivalent to n separate signatures on the same message. Assuming the Random Oracle Model (ROM), the aggregate signature schemes of Boneh et al. [BGLS03] and Bellare and Neven [BN06] provide multisignatures secure in the standard public key setting, but their multisignature verification algorithms involve respectively O(n) bilinear maps and O(n) exponentiations. Ristenpart and Yilek [RY07] recently showed two multisignature schemes relying on groups with bilinear maps, with just O(1) bilinear maps in multisignature verification, which are secure if each public key is accompanied by so-called “proof of (secret key) possession” (POP). We show how to achieve secure multisignatures in the POP model using any group where CDH or DDH problems are hard. Both schemes have multisignature verification with O(1) exponentiations, and their POP messages take O(1) group elements and require O(1) exponentiations to verify. Moreover, the security of the proposed schemes is tightly related to the CDH and DDH problems, in ROM.		Ali Bagherzandi;Stanislaw Jarecki	2008		10.1007/978-3-540-85855-3_15	random oracle;bilinear map;computer science;diffie–hellman key exchange;mathematics;internet privacy;public-key cryptography;world wide web;computer security;algorithm	Crypto	-40.86660708155164	75.31334398442755	153653
ab36122b79576f31500dbf363bb6a860c5f59eba	privacy and confidentiality in context-based and epidemic forwarding	sensibilidad contexto;distributed system;replication;confiance;systeme reparti;context aware;encryption;identity based encryption;routing;heuristic method;routage;metodo heuristico;pairing;cifrado;systeme bilineaire;replicacion;confidencialidad de datos;confidentiality;context based forwarding;vida privada;refinement method;confidence;sistema repartido;epidemia;private life;cryptage;confianza;data privacy;criptografia;cryptography;eurecom ecole d ingenieur telecommunication centre de recherche graduate school research center communication systems;opportunistic communication;epidemie;bilinear pairings;routing algorithm;bilinear system;autoorganizacion;cryptographie;vie privee;self organization;methode heuristique;emparejamiento;sensibilite contexte;methode raffinement;bilinear pairing;appariement;metodo afinamiento;requirement specification;confidentialite donnee;sistema bilineal;autoorganisation;privacy;epidemic;enrutamiento	Autonomic and opportunistic communications require specific routing algorithms, like replication-based algorithms or context-based forwarding. In addition to confidentiality, privacy is a major concern for protocols which disseminate the context of their destination. In this paper, we focus on the confidentiality and privacy issue inherent to context-based protocols, in the framework of an original epidemic forwarding scheme, which uses context as a heuristic to limit the replication of messages. We define the achievable privacy level with respect to the trusted communities assumption, and the security implications. Indeed, privacy in such an environment raises challenging problems, which lead us to a solution based on refinements of two pairing-based encryption, namely searchable encryption and identity-based encryption. This new solution enables forwarding while preserving user privacy by allowing secure partial matches in the header and by enforcing payload confidentiality.	autonomic computing;bilinear filtering;bit-length;computation;confidentiality;correctness (computer science);cryptographic hash function;dictionary attack;disk encryption software;distribution (mathematics);end-to-end principle;h2 database engine;heuristic;id-based encryption;ion beam deposition;key management;multi-user;online and offline;overhead (computing);p (complexity);privacy;public-key cryptography;rp (complexity);random number generation;randomized algorithm;routing;situated;traffic analysis;trusted third party;urban dictionary;verification and validation	Abdullatif Shikfa;Melek Önen;Refik Molva	2010	Computer Communications	10.1016/j.comcom.2010.04.035	privacy software;routing;replication;confidentiality;information privacy;telecommunications;computer science;cryptography;operating system;pairing;internet privacy;confidence;privacy;computer security;encryption;computer network	Security	-43.97574383061133	77.82301220169187	153760
20cf3d1c14693a2eb86eb56405f557cd98e03ecd	symmetric key based secure resource sharing		We focus on the problem of symmetric key distribution for securing shared resources among large groups of users in distributed applications like cloud storage, shared databases, and collaborative editing, among others. In such applications, resources such as data, are sensitive in nature and it is necessary that only authorized users are allowed access without the presence of on-line monitoring system. The de-facto approach is to encrypt a shared resource and deploy a key distribution mechanism, which enables only authorized users to generate the respective decryption key for the resource. The key distribution approach has two major challenges: first, the applications are dynamic i.e., users might join and leave arbitrarily, and second, for a large number of users, it is required that the cryptographic technique be scalable and efficient. In this work, we describe an approach that overcomes these challenges by using two key techniques: first, flattening the access structure and applying efficient symmetric key distribution techniques. By flattening the access structure, we reduce the problem to that of key distribution of a resource among all the users sharing that resource. We consider this smaller flattened access structure and devise a unified key distribution technique that is sufficient for key distribution across all such structures. Our key distribution techniques have an important feature of a public secret and a private secret, which allows the group controller to publish updates to the keying material using the public secret and therefore, does not necessitate the users to be in constant communication with the group controller. Using this model we describe two efficient key distribution techniques that scale logarithmically with the group size and also handle group additions and removals. Furthermore, a user can be off-line for any amount of time and need not be aware of the dynamics of the system, which is important as it overcomes the problems posed by lossy channels. We have performed an experimental evaluation of our scheme against a popular existing scheme and show that they perform better for this scheme with the same security guarantees. As our approaches are easy to implement they are especially suitable for practical applications where security is viewed as an overhead rather than as a necessity.	symmetric-key algorithm	Bezawada Bruhadeshwar;Kishore Kothapalli;Dugyala Raman;Rui Li	2017		10.1007/978-981-10-6898-0_15	key distribution;symmetric-key algorithm;scalability;encryption;shared resource;secure multi-party computation;pre-shared key;computer science;distributed computing;access structure	Crypto	-48.24471075569402	76.59153880440819	153961
67d8d9fd618ab5056b7712a59e97dcf04d37a2a5	a steganography system and implementation utilising pseudo random number embedding and dynamic image production with graphs	decoding;information hiding;pseudo random number embedding;dynamic image production;graphs;steganography;ciphers;encoding;graphics	This paper proposes a new steganographic system that matches the image to the message by generating coherent noise. We utilise graphs as a means to organise the coherent noise over the message. Previous steganography methodologies are reviewed. The implementation of the proposed new system, RandSteg, is presented. The algorithms employed in the implementation system are discussed. Finally, further possibilities for research on this field are suggested.	pseudorandomness;random number generation;steganography	Ruben Aguilar;Jianchao Han	2015	IJGCRSIS	10.1504/IJGCRSIS.2015.074745	discrete mathematics;steganography tools;computer science;graphics;theoretical computer science;mathematics;steganography;graph;information hiding;algorithm;encoding	Vision	-38.94417153053918	83.30809095279129	154095
9babd7641f4454795da927d1df79bea4cffeb8de	secure content access and replication in pure p2p networks	public key cryptography;tolerancia falta;modelizacion;distributed system;acces contenu;controle acces;security properties;replication;cryptographie cle publique;systeme reparti;content authentication;fault tolerant;par a par;authentication;securite informatique;cle publique;integrite;integridad;reseau;classical solution;replicacion;g500 information systems;red;authentification;computer security;modelisation;qa 75 electronic computers computer science;access control policy;sistema repartido;autenticacion;integrity;content access;public key;poste a poste;seguridad informatica;robustesse;fault tolerance;trusted third party;llave publica;peer to peer security;acceso contenido;robustness;file sharing;access control;public key certificate;p2p networks;information system;public key certificates;peer to peer;modeling;tolerance faute;systeme information;public key infrastructure;network;privilege management infrastructure;robustez;sistema informacion	Despite the advantages offered by pure Peer to Peer (P2P) networks (e.g. robustness and fault tolerance), a crucial requirement is to guarantee basic security properties, such as content authenticity and integrity, as well as to enforce appropriate access control policies. These mechanisms would pave the way for new models in which content providers can exert some control over the replication and file sharing process. However, the extremely decentralized nature of these environments makes impossible to apply classic solutions that rely on some kind of fixed infrastructure, typically in the form of on line trusted third parties (TTP). In this paper, we introduce a suite of protocols for content authentication and access control in pure P2P networks based on attribute certificates that does not rely on the existence of a public key infrastructure (PKI), privilege management infrastructure (PMI), or any other form of centralized authority. We provide an analysis concerning the efficiency (computational effort and communication overhead) and the security of our proposal.	access control;algorithmic efficiency;authentication;authorization certificate;bittorrent;centralized computing;client–server model;collaborative working environment;computation;digital distribution;edonkey network;electronic signature;encryption;fault tolerance;file sharing;hoc (programming language);multisignature;overhead (computing);peer-to-peer;privilege management infrastructure;public key certificate;public key infrastructure;public-key cryptography;replication (computing);server (computing);trusted third party;emule	Esther Palomar;Juan E. Tapiador;Julio César Hernández Castro;Arturo Ribagorda	2008	Computer Communications	10.1016/j.comcom.2007.08.015	fault tolerance;telecommunications;computer science;operating system;authentication;public-key cryptography;world wide web;computer security;computer network	Security	-45.10879826021089	78.04760554525944	154096
bf653367ec9b5934b7aa1d33df88544e5b649641	separating decision diffie–hellman from computational diffie–hellman in cryptographic groups	elliptic curve;decisional diffie hellman;logarithme discret;discrete logarithm;courbe elliptique;curva eliptica;protocole diffie hellman;criptografia;cryptography;weil pairing;discrete logarithm problem;cryptographie;computational diffie hellman;diffie hellman	In many cases the security of a cryptographic scheme based on computational Diffie–Hellman does in fact rely on the hardness of the decision Diffie–Hellman problem. In this paper we construct concrete examples of groups where the stronger hypothesis, hardness of the decision Diffie–Hellman problem, no longer holds, while the weaker hypothesis, hardness of computational Diffie–Hellman, is equivalent to the hardness of the discrete logarithm problem and still seems to be a reasonable hypothesis.	computation;cryptography;cryptosystem;decisional diffie–hellman assumption;diffie–hellman problem;discrete logarithm;formal verification	Antoine Joux;Kim Nguyen	2003	Journal of Cryptology	10.1007/s00145-003-0052-4	arithmetic;discrete logarithm;discrete mathematics;mathematics;algorithm;algebra	Crypto	-41.121042106162754	77.5812547222369	154268
3185fde7bbba7b5770e6bb74423fef4ba2d3dee0	optimal bounds for quantum weak oblivious transfer	quantum physics	Oblivious transfer is a fundamental cryptographic primitive in which Bob transfers one of two bits to Alice in such a way that Bob cannot know which of the two bits Alice has learned. We present an optimal security bound for quantum oblivious transfer protocols under a natural and demanding definition of what it means for Alice to cheat. Our lower bound is a smooth tradeoff between the probability P ? Bob with which Bob can guess Alice’s bit choice and the probability P ? Alice with which Alice can guess both of Bob’s bits given that she learns one of the bits with certainty. We prove that 2P ? Bob + P ? Alice ≥ 2 in any quantum protocol for oblivious transfer, from which it follows that one of the two parties must be able to cheat with probability at least 2/3. We prove that this bound is optimal by exhibiting a family of protocols whose cheating probabilities can be made arbitrarily close to any point on the tradeoff curve.	alice and bob;communications protocol;cryptographic primitive;cryptography;oblivious transfer	André Chailloux;Gus Gutoski;Jamie Sikora	2013	CoRR		theoretical computer science;mathematics;distributed computing;algorithm	Theory	-37.451371004550545	74.99414241448954	154394
218b2c018030dcb4f2ee2c42cda6031d79ef4468	two-step hierarchical protocols for establishing session keys in wireless sensor networks	public key cryptography;developpement logiciel;distributed system;red sin hilo;evaluation performance;reseau capteur;cryptographie cle publique;systeme reparti;calculateur embarque;environnement hostile;performance evaluation;protocole transmission;reseau sans fil;securite;evaluacion prestacion;wireless network;public key cryptosystem;satisfiability;secure communication;sensor network;wireless sensor network;medio ambiente hostil;captador medida;protocolo transmision;measurement sensor;red sensores;sistema repartido;capteur mesure;key pre distribution;common criteria;desarrollo logicial;software development;safety;security key;boarded computer;performance analysis;sensor array;sensor nodes;hostile environment;cle securite;seguridad;calculador embarque;key establishment;llave seguridad;transmission protocol	Secure communication between sensor nodes is required in most of sensor networks, especially those deployed in a hostile environment. Due to the limited energy and computational capability on each sensor node, a public key cryptosystem is not a viable option for a wireless sensor network. Hence, the idea of key pre-distribution has been widely adopted in most of the session key establishment protocols proposed so far. In this paper, 1) several typical session key establishment protocols are analyzed and compared in terms of common criteria, 2) the requirements for improving upon the existing protocols are derived, and 3) two advanced protocols which take a two-step hierarchical approach to satisfying the requirements are proposed. Through the performance analysis, it has been shown that the proposed protocols improve the connectivity of a sensor network, uniqueness of session keys and security over the existing protocols.		Kyungsan Cho;Soo-Young Lee;JongEun Kim	2005		10.1007/11599555_61	embedded system;wireless sensor network;telecommunications;computer science;key distribution in wireless sensor networks;computer security	Mobile	-46.62829356643559	79.02943005566551	154532
9237bb53223a311557a38c83bc99abeef87e3a69	function private predicate encryption for low min-entropy predicates		In this work, we propose new constructions for zero inner-product encryption (ZIPE) and non-zero inner-product encryption (NIPE) from prime-order bilinear pairings, which are both attribute and function private in the public-key setting.		Sikhar Patranabis;Debdeep Mukhopadhyay;Somindu C. Ramanna	2018	IACR Cryptology ePrint Archive		min entropy;predicate (grammar);discrete mathematics;encryption;computer science;bilinear interpolation	Crypto	-39.00527204355055	77.12617088221177	154586
0f84dcecb66922683c9eb087488e87c2421a15cc	threshold fully homomorphic encryption and secure computation		Cramer, Damgård, and Nielsen [CDN01] show how to construct an efficient secure multiparty computation scheme using a threshold homomorphic encryption scheme that has four properties i) a honest-verifier zero-knowledge proof of knowledge of encrypted values, ii) proving multiplications correct iii) threshold decryption and iv) trusted shared key setup. Naor and Nissim [NN01a] show how to construct secure multi-party protocols for a function f whose communication is proportional to the communication required to evaluate f without security, albeit at the cost of computation that might be exponential in the description of f . Gentry [Gen09a] shows how to combine both ideas with fully homomorphic encryption in order to construct secure multi-party protocol that allows evaluation of a function f using communication that is independent of the circuit description of f and computation that is polynomial in | f |. This paper addresses the major drawback’s of Gentry’s approach: we eliminate the use of non-black box methods that are inherent in Naor and Nissim’s compiler. To do this we show how to modify the fully homomorphic encryption construction of van Dijk et al. [vDGHV10] to be threshold fully homomorphic encryption schemes. We directly construct (information theoretically) secure protocols for sharing the secret key for our threshold scheme (thereby removing the setup assumptions) and for jointly decrypting a bit. All of these constructions are constant round and we thoroughly analyze their complexity; they address requirements (iii) and (iv). The fact that the encryption scheme is fully homomorphic addresses requirement (ii). To address the need for an honest-verifier zero-knowledge proof of knowledge of encrypted values, we instead argue that a weaker solution suffices. We provide a 2-round blackbox protocol that allows us to prove knowledge of encrypted bits. Our protocol is not zeroknowledge, but it provably does not release any information about the bit being discussed, and this is sufficient to prove the correctness of a simulation in a method similar to Cramer et al. Altogether, we construct the first black-box secure multi-party computation protocol that allows evaluation of a function f using communication that is independent of the circuit description of f .	black box;compiler;correctness (computer science);cryptography;eval;homomorphic encryption;information theory;key (cryptography);polynomial;proof of knowledge;requirement;secret sharing;secure multi-party computation;simulation;symmetric-key algorithm;threshold cryptosystem;time complexity;zero-knowledge proof	Steven Myers;Mona Sergi;Abhi Shelat	2011	IACR Cryptology ePrint Archive		56-bit encryption;40-bit encryption;on-the-fly encryption;encryption;theoretical computer science;mathematics;homomorphic secret sharing;secure two-party computation;probabilistic encryption;multiple encryption	Crypto	-38.41317092917624	75.64524437734083	154703
5982d192c7695b8513c8f9016494e439f95f7dbc	cryptanalysis of an authenticated encryption scheme using self-certified public keys	matematicas aplicadas;mathematiques appliquees;authentication;self certified public key;cle publique;signature electronique;authenticated encryption;authentification;autenticacion;public key;digital signature;llave publica;firma numerica;applied mathematics	Recently, Tseng et al. proposed an authenticated encryption scheme using self-certified public keys. In their scheme, only the specified receiver can verify and recover the message. In this article, we will demonstrate their scheme cannot withstand the known plaintext-ciphertext attack. The intruder has ability to expose every message sent between the signer and the specified receiver. 2004 Elsevier Inc. All rights reserved.	authenticated encryption;authentication;ciphertext;cryptanalysis;known-plaintext attack;plaintext	Chwei-Shyong Tsai;Shu-Chen Lin;Min-Shiang Hwang	2005	Applied Mathematics and Computation	10.1016/j.amc.2004.04.073	telecommunications;authentication;mathematics;internet privacy;computer security;encryption	Security	-43.46314931287433	76.05688694543652	154773
90ae6847b3cda15f25da155443924c39a406b39f	attack on liao and hsiao's secure ecc-based rfid authentication scheme integrated with id-verifier transfer protocol		We show that the Liao and Hsiao’s protocol achieves neither tag-authentication nor privacy.	authentication;ecc memory	Roel Peeters;Jens Hermans	2013	IACR Cryptology ePrint Archive			Security	-44.966864964041534	75.29142294267939	154778
bb7141d31dc6c1b3383e13b6788a599ff543debd	an efficient identity based generalized signcryption scheme	provable security;smart card;security model;wireless sensor network;identity based cryptography;generalized signcryption;signcryption	Generalized signcryption is a new cryptographic primitive, which provides separate or joint encryption and signature as per need. It is more suitable for some storage constrained environments, e.g. smart card, WSN (Wireless Sensor Networks) etc. In this paper, we propose an efficient identity based generalized signcryption scheme. We also simplify the security notions for identity based generalized signcryption and prove the security of the proposed scheme under the new security model.	signcryption	Prashant Kushwah;Sunder Lal	2011	Theor. Comput. Sci.	10.1016/j.tcs.2011.08.009	computer security model;smart card;wireless sensor network;computer science;provable security;signcryption;internet privacy;computer security;computer network	ECom	-46.98070018718805	76.00559793203773	154882
cb9d80acf76cbb3982847ff08d824e71115587a4	two-pass authenticated encryption faster than generic composition	block ciphering;provable security;cryptage bloc;omac;associated data;block cipher;authentication;004 informatik;authenticated encryption;authentification;patent rights;autenticacion;propiedad industrial;patents;criptografia;cryptography;cifrado en bloque;cryptographie;propriete industrielle;patente;brevet	This paper introduces CCFB and CCFB+H, two patent-free authenticated encryption schemes. CCFB+H also supports the authentication of associated data. Our schemes can employ any block cipher and are provably secure under standard assumptions. The schemes and their proofs of security are simple and straightforward. CCFB and CCFB+H restrict the sizes of nonce and authentication tags and can, depending on these sizes, perform significantly better than both generic composition and other two-pass schemes for authenticated encryption, such as the EAX mode.	authenticated encryption;authentication	Stefan Lucks	2005		10.1007/11502760_19	computer science;authentication;internet privacy;computer security;computer network	Crypto	-41.129933730382085	78.1318295868188	155099
04c3eddcd6400b577daaacdf0fe53aaf29d97501	qrke: resistance to attacks using the inverse of the cosine representation of chebyshev polynomials		We've been able to show recently that Permutable Chebyshev polynomials (T polynomials) defined over the field of real numbers can be used to create a Diffie-Hellman-like key exchange algorithm and certificates. The cryptosystem was theoretically proven to withstand attacks using quantum computers. We additionally prove that attacks based on the inverse of the cosine representation of T polynomials fail.	chebyshev polynomials;computer;cryptosystem;diffie–hellman key exchange;greedy algorithm;polynomial;quantum computing	G. Brands;C. B. Roellgen;Katharina U Vogel	2016	CoRR		gegenbauer polynomials;chebyshev polynomials;difference polynomials;combinatorics;discrete mathematics;jacobi polynomials;discrete orthogonal polynomials;equioscillation theorem;classical orthogonal polynomials;mathematics;algebra	Crypto	-39.28386320306854	80.40500331899918	155230
f09b4e74d7d383c30932fc7743cfa890fa3ddded	why the kuperee authentication system fails	interfase usuario;confidencialidad;protocole transmission;securite;user interface;network security;cle publique;confidentiality;confidentialite;protocolo transmision;public key;criptografia;cryptography;safety;llave publica;protocole authentication;cryptographie;interface utilisateur;seguridad;distributed system security;authentication protocol;transmission protocol	"""The Kuperee system has been proposed as an authentication system using public keys by Hardjono and Seberry at ESOI~ICS' 94. It employs the improved cryptosystem of Zheng and Seberry which is immune against chosen ciphertext attacks. The Kuperee authentication protocol has some interesting features. One of them is the binding of two entities (e.g. a client and a server) by a third entity (e.g. authentication server) so that only the cooperation of these two entities leads to the completion of an authentication protocol. Unfortunately this feature, together with other weaknesses, has led to some strong attacks such as impersonating the Ticket Granting Server, clients and servers. As a result the Kuperee authentication system is not resistant against modification attacks, replay attacks and even impersonating attacks. We discuss the serious weaknesses and show how to attack the Kuperee authentication system. Attacking the Kuperee is not the only purpose of this paper, since the Kuperee system is not widely used. We are more interested to point out the importance of paying more attention to the """"interface"""" between design of protocols and implementation using concrete cryptographic algorithms."""	algorithm;authentication protocol;authentication server;chosen-ciphertext attack;ciphertext;client (computing);cryptography;cryptosystem;entity;replay attack;server (computing)	Yun Ding;Patrick Horster	1996	Operating Systems Review	10.1145/232302.232309	data authentication algorithm;otway–rees protocol;chip authentication program;confidentiality;challenge–response authentication;computer science;cryptography;authentication protocol;network security;cryptographic nonce;lightweight extensible authentication protocol;multi-factor authentication;internet privacy;user interface;world wide web;computer security;challenge-handshake authentication protocol	Security	-44.35394890038085	76.68610309004099	155511
b6bedb1b62df6f29fb56e2fa62478f80d97ec0ef	splitcommit: implementing and analyzing homomorphic uc commitments		In this paper we present SplitCommit, a portable and efficient C++ implementation of the recent additively homomorphic commmitment scheme of Frederiksen et al. [FJNT16]. We describe numerous optimizations that go into engineering such an implementation, including highly optimized general purpose bit-matrix transposition and efficient ECC encoding given the associated generator matrix. We also survey and analyze in detail the applicability of [FJNT16] and include a detailed comparison to the canonical (non-homomorphic) commitment scheme based on a Random Oracle. We include performance benchmarks of the implementation in various network setting, for instance on a 10 Gbps LAN we achieve amortized commitment and decommitment running times of 0.65 μs and 0.27μs, respectively. Finally we also include an extensive tutorial on how to use the library.	amortized analysis;c++;commitment scheme;data rate units;generator matrix;random oracle;uc browser	Peter Rindal;Roberto Trifiletti	2017	IACR Cryptology ePrint Archive		theoretical computer science;homomorphic encryption;computer science	Security	-36.20670802206563	77.80105972143578	155534
36c7b54a873ffc525487443395080177319963b6	video streaming security: window-based hash chain signature combines with redundancy code - youtube scenario as an internet case study	hash chain;redundancy codes;window based hash chain signature;video streaming;video streaming security;authentication;digital signatures;robustness video streaming hash chain redundancy codes digital signature;servers;servers streaming media youtube digital signatures redundancy authentication;youtube;internet;redundancy;hash chain methodology video streaming security window based hash chain signature redundancy code youtube scenario internet case study media streaming;youtube scenario;streaming media;redundancy code;digital signature;cryptography;multimedia communication;social networking online;telecommunication security;media streaming;video streaming cryptography internet multimedia communication redundancy social networking online telecommunication security;internet case study;robustness;real time application;hash chain methodology	This paper provides a performance study for securing media streaming based on hash chain methodology. We introduce a new technique that combines the signature of window-based hash chain with redundancy codes for achieving high reliability and robustness against many attacks. Also, the Window technique integrates the Time-Stamped which strongly eliminates the anti-replay attack. It will also control the management of many users accessing the same video in different instant times. The Window-Based algorithm with redundancy code will be compared against Packet-Based or just Block-Based video streaming security. The analytical and simulation results indicate that, the Window-Based Hash Chain Signature combine with Redundancy Code (WB & RC) is a good solution for video streaming security in terms of reliability and robustness. The times of signature creation and verification are accepted under the standard delay recommendations of real time applications. Our case study provides You Tube as a successful scenario over Internet. The privacy of You Tube will relay on a secure email in user access which represents an efficient way in mobility issue.	algorithm;anti-replay;authentication;byte;code;computation;digital signature;email encryption;hash chain;iptv;internet;key distribution;network packet;overhead (computing);prospective search;relay;replay attack;server (computing);set-top box;simulation;streaming media;the times;video file format	Emad Abd-Elrahman;Mohamed Abid;Hossam Afifi	2010	2010 IEEE International Symposium on Multimedia	10.1109/ISM.2010.15	digital signature;hash function;computer science;hash chain;internet privacy;world wide web;cryptographic hash function;computer network	Security	-45.22753828422328	75.19314106378768	156106
b583474c9efb72ce77d861e64c8ea29c12ea7fda	twelex: a tweaked version of the lex stream cipher		LEX is a stream cipher proposed by Alex Biryukov. It was selected to phase 3 of the eSTREAM competition. LEX is based on the Advanced Encryption Standard (AES) block cipher and uses a methodology called Leak Extraction, proposed by Biryukov himself. However Dunkelman and Keller show that a key recovery attack exists against LEX. Their attack requires 2 bytes of keystream produced by the same key and works with a time complexity of 2 operations. In this work we explore LEX further and have shown that under the assumption of a related key model we can obtain 24 secret state bytes with a time complexity of 2 and a data complexity of 2. Subsequently, we introduce a tweaked version of LEX, called TweLEX, which is shown to resist all known attacks against LEX. Though the throughput of TweLEX is half of LEX, it is still 1.25 times faster than AES, the underlying block cipher. This work attempts to revive the principle of leak extraction as a simple and elegant method to design stream ciphers.	128-bit;asiacrypt;block cipher;byte;cryptanalysis;estream;encryption;information processing;key-recovery attack;lex (software);mathematical optimization;related-key attack;stream cipher;throughput;time complexity	Mainack Mondal;Avik Chakraborti;Nilanjan Datta;Debdeep Mukhopadhyay	2011	IACR Cryptology ePrint Archive		parallel computing;time complexity;advanced encryption standard;keystream;byte;key-recovery attack;stream cipher;estream;block cipher;computer science	Crypto	-37.398653952426265	80.34316593013627	156377
6cf99794243ffb309cd5b368bbd983072519c736	on the need of randomness in fault attack countermeasures - application to aes	side channel analysis;encryption;resistance;aes;infection countermeasures fault attack countermeasure aes advanced encryption standard symmetric ciphers fault attacks block cipher side channel attack higher order masking;fault attack countermeasures aes fault attack side channel analysis combined attack;cryptography;fault attack;robustness;fault attack countermeasures;doped fiber amplifiers encryption robustness resistance noise;doped fiber amplifiers;noise;combined attack	Recent works show that a combination of perturbation and observation attacks on symmetric ciphers thwarts state-of-the-art countermeasures. In this paper, we first propose a new way - to our knowledge - to classify fault attacks against block ciphers, allowing us to exhibit their capacity to be combined with observation attacks. We then present a set of common protections against side-channel and fault attacks, namely higher-order masking schemes, detection and infection countermeasures, and how they can be combined. We show that the combination of a higher-order masking scheme and a detection countermeasure can actually be defeated by a slight variant of the combined attack of Roche et al., even if one applies their patch. Furthermore, we also demonstrate that none of the published infection countermeasures is robust against fault attacks. Finally, using randomness, we propose a set of enhanced countermeasures that thwart considered threats.	block cipher;countermeasure (computer);differential fault analysis;randomness;side-channel attack	Victor Lomné;Thomas Roche;Adrian Thillard	2012	2012 Workshop on Fault Diagnosis and Tolerance in Cryptography	10.1109/FDTC.2012.19	differential fault analysis;watermarking attack;power analysis;engineering;correlation attack;internet privacy;computer security;computer network	Security	-42.75937803805453	80.81307383352075	156741
a97c40375c12b06407cd53254019ea700f652193	number theoretic attacks on secure password schemes	authenticated information exchange;protocols;secure password schemes;information security;authorisation;authentication;random number generation;dictionary attack;number theoretic attacks;password guessing attacks;active attacks;half encrypted versions;number theory;protection;randomized confounders;encrypted key exchange;public key;col;cryptography protocols dictionaries public key authentication information security protection humans random number generation;dictionary attacks;secret key cryptography;cryptography;secure protocols;computer network management;dictionaries;direct authentication protocol;computer network management message authentication authorisation cryptography number theory;humans;message authentication;secret public key protocol versions;rsa version;secret public key protocol versions number theoretic attacks secure password schemes encrypted key exchange eke authenticated information exchange insecure network secret key cryptography active attacks dictionary attacks secure protocols randomized confounders password guessing attacks rsa version half encrypted versions direct authentication protocol;eke;authentication protocol;security protocol;insecure network	Encrypted Key Exchange (EKE) [1, 2] allows two parties sharing a password to exchange authenticated information over an insecure network by using a combination of public and secret key cryptography. EKE promises security against active attacks and dictionary attacks. Other secure protocols have been proposed based on the use of randomized	authentication;cryptography;dictionary attack;encrypted key exchange;key (cryptography);password;randomized algorithm	Sarvar Patel	1997		10.1109/SECPRI.1997.601340	zero-knowledge password proof;encrypted key exchange;number theory;computer science;information security;salt;internet privacy;world wide web;computer security;dictionary attack	Crypto	-41.39862677401766	74.5558625416929	156746
75370e6e3bf5a6907cbc7d5c4253fd3246c0a206	analysis of the dvb common scrambling algorithm	dvb;stream cipher;cryptanalysis;block cipher;paytv	The Common Scrambling Algorithm (CSA) is used to encrypt streams of video data in the Digital Video Broadcasting (DVB) system. The algorithm cascades a stream and a block cipher, apparently for a larger security margin. In this paper we set out to analyze the block cipher and the stream cipher separately and give an overview of how they interact with each other. We present a practical attack on the stream cipher. Research on the block cipher so far indicates it to be resistant against linear and algebraic cryptanalysis as well as simple slide attacks.	algebraic equation;block cipher;ciphertext;common scrambling algorithm;cryptanalysis;cryptographic nonce;digital video broadcasting;encryption;key escrow;linear algebra;nonlinear system;plaintext;stream cipher;system of polynomial equations	Ralf-Philipp Weinmann;Kai Wirt	2004		10.1007/0-387-24486-7_15	common scrambling algorithm	Crypto	-38.22084772698864	82.49156572947301	156814
591575257d399e38b23279427c67d84a68a7d7c3	analysis of intermediate field systems		We study a new generic trapdoor for public key multivariate cryptosystems, called IFS for Intermediate Field Systems, which can be seen as dual to HFE. This new trapdoor relies on the possibility to invert a system of quadratic multivariate equations with few (logarithmic with respect to the security parameter) unknowns on an intermediate field thanks to Gröbner bases algorithms. We provide a comprehensive study of the security of this trapdoor and show that it is equivalent to the security provided by HFE. Therefore, while insecure in its basic form, this trapdoor may reveal quite attractive when used with, e.g., the minus modifier.	algorithm;cryptosystem;gröbner basis;human factors and ergonomics;modifier key;polynomial;public-key cryptography;security parameter	Olivier Billet;Jacques Patarin;Yannick Seurin	2009	IACR Cryptology ePrint Archive		public-key cryptography;discrete mathematics;cryptosystem;quadratic equation;logarithm;multivariate statistics;security parameter;mathematics	Crypto	-39.81283199067413	79.67218805598509	156889
69ee9026f229b0d63f853ba7589172d18069df27	oblivious transfer based on the mceliece assumptions	oblivious transfer;random matrix;linear code	We implement one-out-of-two bit oblivious transfer (OT) based on the assumptions used in the McEliece cryptosystem: the hardness of decoding random binary linear codes, and the difficulty of distinguishing a permuted generating matrix of Goppa codes from a random matrix. To our knowledge this is the first OT reduction to these problems only. We present two different constructions for oblivious transfer, one based on cut-and-choose arguments and another one which is based on a novel generalization of Bennett-Rudich commitments which may be of independent interest. Finally, we also present a variant of our protocol which is based on the Niederreiter cryptosystem.1	linear code;oblivious transfer;programming paradigm;simulation;steven rudich	Rafael Dowsley;Jeroen van de Graaf;Jörn Müller-Quade;Anderson C. A. Nascimento	2008	IEICE Transactions	10.1007/978-3-540-85093-9_11	combinatorics;discrete mathematics;mceliece cryptosystem;computer science;theoretical computer science;random matrix;oblivious transfer;linear code;mathematics;goppa code;computer security;quantum mechanics;statistics	Crypto	-37.957559966301346	78.31748983765341	157041
15c9e77cdf15164cb73496832bff3a151cfc8952	improving the message-ciphertext rate of lewko's fully secure ibe scheme	canceling;dlin assumption;dual system encryption;fully secure ibe;parameter hiding	In Eurocrypt 2012, Lewko presented a fully secure IBE scheme in the prime order setting based on the decisional linear assumption. We note that some random factor involved in the ciphertext can further be used to hide yet another message , and get a new fully secure IBE scheme with better message-ciphertext rate. Similar to Lewko’s scheme, we use dual pairing vector space in prime order bilinear groups to simulate the canceling and parameter hiding properties of composite order settings. The security of our scheme is based on the subspace assumption, which can be reduced to the decisional linear assumption. We employ the dual system encryption technique in our security proof.	bilinear filtering;ciphertext;decision linear assumption;encryption;eurocrypt;provable security;simulation;yet another	Dingding Jia;Bao Li;Yamin Liu;Qixiang Mei	2013	IACR Cryptology ePrint Archive	10.1007/978-3-642-38033-4_8		Crypto	-39.86716614816247	74.91031047736513	157547
a147d440c23e0298567304843389128d36440a40	a novel image encryption technique based on hénon chaotic map and s8 symmetric group	s8 symmetric group;chaotic maps;s boxes	The structure of cryptographically resilient substitution boxes (S-boxes) plays a central role in devising safe cryptosystems. The design of chaos-based S-boxes by means of chaotic maps obtained more devotion in current ages. We have suggested novel S-boxes based on the chaotic maps and S8 symmetric group. We have experimented our chaos-based S-box for image encryption applications and analyze its strength with statistical analyses.	algorithm;chaos theory;cipher;cryptography;cryptosystem;encryption;hénon map;list of chaotic maps;numerical analysis;pseudorandom permutation;s-box;value (ethics)	Majid Khan;Tariq Shah	2014	Neural Computing and Applications	10.1007/s00521-014-1663-4	combinatorics;discrete mathematics;theoretical computer science;mathematics	Crypto	-38.85612312497965	82.31695027509306	157554
fdc2482084525a68279180db35f240f204bddf05	fair electronic cash based on a group signature scheme	protocole transmission;pago;group signature scheme;payment;protocolo transmision;group signature;paiement;digital signature;signature groupe;signature numerique;firma numerica;electronic cash;monnaie electronique;transmission protocol	Several new group signature schemes have been proposed in recent years. In addition, several applications for group signatures (including electronic cash) have been suggested. A new cash scheme based on a recent group signature by Ateniese, Camenisch, Joye and Tsudik is presented. Its construction uses a general framework suitable for a number of group signature schemes. We also identify the challenges faced by such schemes.	antivirus software;digital signature;double-spending;group signature;online and offline	Greg Maitland;Colin Boyd	2001		10.1007/3-540-45600-7_51	telecommunications;computer science;group signature;blind signature;world wide web;computer security;algorithm	Security	-43.522341199261646	77.14098383930553	157788
f55eabb67b3c7dd4357e9d22295d49726f570224	a (n, n)-threshold secret sharing scheme for barcode application			barcode;secret sharing	Pei-Yu Lin;Yi-Hui Chen;Jun-Chou Chuang	2014		10.3233/978-1-61499-484-8-1023	barcode;parallel computing;computer science;distributed computing;secret sharing	Crypto	-42.232343118387504	79.35143773735426	157854
0ef360477de13af26a035acd241a287a1e250650	a twin algorithm for efficient generation of digital signatures	one way function;personnel identification;authentication;corps fini;authentification;interlocking equations;finite field;autenticacion;digital signature;criptografia;cryptography;interbloquage;campo finito;signature numerique;cryptographie;interlocking;firma numerica;data authentication	The paper describes two algorithms for personnel identification, data authentication and digital signatures. Both are based on the intractability of finding square roots over finite fields and also can be an identity-based scheme. The outstanding feature of these two algorithms is its speed. Also a concept of interlocking equations is introduced which in effect acts like a one-way function.		D. Ramesh	2001		10.1007/3-540-45311-3_25	computer science;authentication;computer security;algorithm	EDA	-41.33026652329322	79.33130729258215	157894
c6fc6326afed7e64e4ebd41e41aac532b19c6d22	differential path for sha-1 with complexity o(252)		Although SHA-1 has been theoretically broken for some time now, the task of finding a practical collision is yet to be completed. Using some new approaches to differential analysis, we were able to find a new differential path which can be used in a collision attack with complexity of O(2). This is currently the lowest complexity attack on SHA-1.	boomerang attack;collision attack;nonlinear system;sha-1	Cameron McDonald;Philip Hawkes;Josef Pieprzyk	2009	IACR Cryptology ePrint Archive			Crypto	-37.25703682837517	81.21319621096382	158052
79e0277a58c676d3462fe6ec0273cd72c3384ecf	a new setup for factoring based algorithms	public key cryptography;coppersmith s theorem;backdoor;rsa;coppersmiths theorem setup factoring based algorithm encryption algorithm embedded secret trapdoor public key algorithm;statistical properties;ieee computer society;public key;cryptovirology;factoring;secretly embedded trapdoor with universal protection;encryption public key cryptography signal processing algorithms computer science;cryptovirology rsa secretly embedded trapdoor with universal protection backdoor public key cryptography coppersmith s theorem factoring	When using cryptography, there is frequently the misconception that if the keys are properly stored and are not given away, then the user is safe, if he uses a strong encryption algorithm. SETUPs exploit this common misconception, be embedding secret trapdoors in the key creation procedure of public key algorithms. The essential part of a SETUP, is to provide good statistical properties for the used parameters, while maintaining the security of the encryption algorithm. In this work, a new method for creating SETUPs for factoring based encryption algorithms is presented. The SETUP takes advantage of Coppersmith's theorem in order to efficiently recover the needed parameters.	algorithm;encryption;integer factorization;public-key cryptography;strong cryptography	Constantinos Patsakis;Nikos Alexandris	2010	2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing	10.1109/IIHMSP.2010.57	cdmf;key;computer science;theoretical computer science;cryptovirology;mathematics;distributed computing;public-key cryptography;trapdoor function;key space;key distribution;computer security;encryption;probabilistic encryption	Crypto	-37.565424987039044	78.72781918363205	158213
215eeeab1c70b329ab6cb6139bf0790bab241944	provably secure and efficient certificateless authenticated tripartite key agreement protocol	authentication;certificateless cryptosystem;random oracle model;key agreement;bilinear pairing;tripartite	Authenticated key agreement (AKA) protocols are multi-party protocols in which entities exchange public information allowing them to create a common secret key that is known only to those entities over an open network. Recently, in order to circumvent the key escrow problem inherent to ID-based cryptography and the certificate management burden in traditional public key infrastructure, the notion of certificateless public key cryptography (CL-PKC) was introduced. In this paper, we first present a security model for certificateless AKA protocols for three parties, and then propose an efficient construction based on bilinear pairings. The security of the proposed scheme can be proved to be equivalent to the computational Diffie–Hellman problem in the random oracle model.	authentication;key-agreement protocol;provable security	Hu Xiong;Zhong Chen;Fagen Li	2012	Mathematical and Computer Modelling	10.1016/j.mcm.2011.10.001	random oracle;key-agreement protocol;diffie–hellman key exchange;authentication;internet privacy;key distribution;computer security;computer network	Crypto	-41.88622751018469	75.19345208988493	158254
dc58b05378ae70b240d27b281ceecc67527db887	on adaptively secure protocols		Adaptive security captures the capability of an adversary to adaptively affect a system during the course of its computation based on partial information gathered. In this work, we explore the theoretical complexity of achieving adaptive security in two settings: 1. Adaptive UC-Secure Computation: We provide a roundefficient compiler that transforms any stand-alone semi-honest adaptively secure multiparty computation to adaptive UC-security. Recently, Dana et. al (Asiacrypt 2013) showed how to acheive adaptive UC-security in any trusted setup under minimal assumptions. They achieve this by constructing an O(n)-round adaptively secure concurrent non-malleable commitment scheme. The main contribution of our work shows how to achieve the same in O(1)-rounds. 2. Zero-Knowledge with Adaptive Inputs: Lin and Pass in (TCC 2011) gave first constructions of concurrent non-malleable zeroknow-ledge proofs secure w.r.t. adaptively chosen inputs in the plain model in a restricted setting, namely, where the adversary can only ask for proofs of true (adaptively-chosen) statements. We extend their definition to the fully-adaptive setting and show how to construct a protocol that satisfies this definition. As an independent contribution we provide a simple and direct compilation of any semihonest secure protocol to a fully concurrently secure protocol under polynomial-time assumptions in the Angel-Based UC-Security.	adaptive grammar;adversary (cryptography);asiacrypt;commitment ordering;commitment scheme;compiler;secure multi-party computation;semiconductor industry;time complexity;uc browser;zero-knowledge proof	Muthuramakrishnan Venkitasubramaniam	2014		10.1007/978-3-319-10879-7_26	computer network;commitment scheme;distributed computing;computer science;computation;adversary;secure multi-party computation	Crypto	-38.28632614277047	75.40597915658057	158482
0576a41024c3fee1ab2d8fd9a81d44a5676b5c4e	improved lower bound on dhp: towards the equivalence of dhp and dlp for important elliptic curves used for implementation		In 2004, Muzereau et al. showed how to use a reduction algorithm of the discrete logarithm problem to DiffieHellman problem in order to estimate lower bound on Diffie-Hellman problem on elliptic curves. They presented their estimates for various elliptic curves that are used in practical applications. In this paper, we show that a much tighter lower bound for Diffie-Hellman problem on those curves can be achieved, if one uses the multiplicative group of a finite field as an auxiliary group. Moreover, improved lower bound estimates on Diffie-Hellman problem for various recommended curves are also given which are the tightest; thus, leading us towards the equivalence of Diffie-Hellman problem and the discrete logarithm problem for these recommended elliptic curves.	algorithm;computational diffie–hellman assumption;diffie–hellman problem;digital light processing;discrete logarithm;elliptic curve cryptography;turing completeness	Prabhat Kushwaha	2016	CoRR		mathematical optimization;combinatorics;discrete mathematics;counting points on elliptic curves;mathematics;family of curves	Crypto	-39.35711561480977	79.67943491632084	158947
b146bee1f88e046a09cf8321591d91b9cc6fe8ac	modular multiplication architecture for public key cryptosystem	modular multiplication		cryptosystem;public-key cryptography	Keon-Jik Lee;Byeong-Jik Lee;Chong-Won Park	2002			architecture;kochanski multiplication;public-key cryptography;cryptosystem;theoretical computer science;modular arithmetic;computer science	Crypto	-40.844084638420384	80.20519939482404	159006
017150530938f354c4a7f76eeb5ff9f949632d72	receiver- and sender-deniable functional encryption	public key encryption;cryptography;functional encryption;security	Deniable encryption, first introduced by Canetti et al. 1997, allows equivocation of encrypted communication. In this work, the authors generalise its study to functional encryption (FE). The authorsu0027 results are summarised as follows: They first put forward and motivate the concept of receiver-deniable FE, for which they consider two models. In the first model, as previously considered by Ou0027Neill et al. 2011 in the case of identity-based encryption, a receiver gets assistance from the master authority to generate a fake secret key. In the second model, there are `normalu0027 and `deniableu0027 secret keys, and a receiver in possession of a deniable secret key can produce a fake but authentic-looking normal key on its own. In the first model, they show a compiler from any FE scheme for circuits to a FE scheme having receiver deniability. In addition, they show an efficient receiver-deniable FE scheme for Boolean formulae from bilinear maps. In the second (multi-distributional) model, they present a specific FE scheme for circuits having receiver deniability. To the authorsu0027 knowledge, a scheme in the multi-distributional model was not previously known even for the special case of identity-based encryption. Finally, they construct the first sender (non-multi-distributional) deniable FE scheme.	functional encryption	Angelo De Caro;Vincenzo Iovino;Adam O'Neill	2018	IET Information Security	10.1049/iet-ifs.2017.0040	multiple encryption;watermarking attack;h.235;disk encryption theory;40-bit encryption;plaintext-aware encryption;disk encryption;client-side encryption;computer science;cryptography;information security;deniable encryption;signcryption;link encryption;filesystem-level encryption;on-the-fly encryption;internet privacy;deterministic encryption;computer security;encryption;probabilistic encryption;56-bit encryption;attribute-based encryption;computer network;email encryption	Crypto	-40.247026349088515	75.25485513837246	159007
44a4293f962f87aa258cd46daf76f1766a38324c	security of wang-li threshold signature scheme	secret sharing;threshold signature;trusted party;discrete logarithm problem	In 2003, Wang et al.[1] proposed a (t, n) threshold signature scheme without a trusted party based on the discrete logarithm problem. In this paper, according to [5]’s attacking method, we show that there are still some security leaks in that scheme, and give some methods of forgery attack. Moreover, we point out this scheme is vulnerable to universal forgery by an insider attacker under reasonable assumptions.	digital signature forgery;discrete logarithm;norton internet security;scheme	Lifeng Guo	2004	IACR Cryptology ePrint Archive		elgamal signature scheme;insider;schnorr signature;discrete logarithm;proactive secret sharing;computer science;distributed computing;secret sharing	Crypto	-42.80062107726217	75.07955442742399	159262
b5580925ee1bd969f5326ba2389872484dcdaf9c	compact lattice signatures		Lattice-based signature schemes have seen many improvements in the past few years with recent attempts (Güneysu et al., 2012; Ducas et al., 2013; Ducas et al., 2014; Lyubashevsky, 2016; Ducas et al., 2017) to bring lattice-based signature schemes at par with the traditional number-theoretic signature schemes. However, the trade-off between the signature size and the key size, time for a signature generation, and the practical and provable security is not necessarily the optimal. We propose a compact lattice-based signature scheme with key-size and signatures of order n, where n is the dimension of the lattice. The proposed signature scheme has faster algorithms for key generation, signing, and verification than the existing schemes. The proposed scheme is simple and is competitive with the other post-quantum signature schemes.	algorithm;digital signature;key generation;key size;lattice model (finance);post-quantum cryptography;provable security;theory;type signature	Dipayan Das;Vishal Saraswat	2018		10.5220/0006861606560661	computer network;computer science;theoretical computer science;lattice (order)	Security	-38.44628332256645	78.25895589923893	159280
f1f47e026612b6f7630536490a75d088ffc09a63	discrete physics, cellular automata and cryptography	estensibilidad;desciframiento;algorithme rapide;algorithme cellulaire;design principle;encryption;securite informatique;customization;personnalisation;analogie;decryptage;cifrado;computer security;cryptage;criptografia;cryptography;seguridad informatica;automate cellulaire;fast algorithm;decryption;analogy;analogia;personalizacion;cryptographie;extensibilite;scalability;cellular automata;cellular automaton;algoritmo rapido;cellular algorithm;algoritmo celular;automata celular	This paper aims at showing that Physics is very close to the substitution-diffusion paradigm of symmetric ciphers Based on this analogy, we present a new Cellular Automata algorithm, termed Crystal, implementing fast, parallel, scalable and secure encryption systems Our approach provides a design principle to ensure an invertible dynamics for arbitrary neighborhood Thus, several variants of our CA can be devised so as to offer customized encryption-decryption algorithms Considering larger data blocks improve both security and speed (throughput larger than 10Gbps on dedicated hardware).	cellular automaton;cryptography	Stephane Marconi;Bastien Chopard	2006		10.1007/11861201_72	cellular automaton;scalability;analogy;computer science;cryptography;theoretical computer science;encryption;algorithm	Theory	-42.02681316685712	79.07366231277884	159450
076ce7c17770737218503a936f1e723845bad446	cryptanalysis of an ad-hoc cryptosystem for mix-based e-voting robust against relation attacks	public key;relation attack;e voting	In this paper, an ad-hoc public-key cryptosystem recently proposed to implement a general countermeasure to relation attacks in mix-based e-voting is shown to be weak in the sense that the secret key is easily obtained from public-key parameters. The required measure to fix the previous flaw is analyzed and proven to lead to an unsecure system, so that we recommend the referred cryptosystem to be discarded.	cryptanalysis;cryptosystem;flaw hypothesis methodology;hoc (programming language);key (cryptography);public-key cryptography	Josep M. Miret;Francesc Sebé	2011	International Journal of Information Security	10.1007/s10207-011-0145-2	computer science;threshold cryptosystem;cryptosystem;hybrid cryptosystem;internet privacy;public-key cryptography;world wide web;computer security	Crypto	-41.82432898506466	75.95382511135769	159476
b7c078cc6fa9dc788fe08cbbb84b8c82e84434e5	simulation and cost analysis of group authentication protocols	analytical models;protocols;authentication;computational efficiency;cost benefit analysis;radiofrequency identification	Radio Frequency Identification (RFID) is an efficient technology for identification, tracking and group proof construction. The multi-round protocols for authentication and group proof construction increase the cost with increase in participants. In this work, computational and communication cost of multi-round protocol is calculated to identify the protocol with least cost and high security. The computational cost is computed using number of rounds and messages, Message Authentication Code (MACO) operations, messages sent per participant and messages received per participant. The communication cost is computed using size of message sent and size of message received. In order to reduce the computational and communication cost, two lightweight group authentication protocols are selected for refinement. The protocols are: Juel's protocol, and Saito and Sakurai protocol. Three refinements are proposed which convert these protocols from two-party group construction to n-party group construction. Results show that refinements reduce the cost compared to Juel's protocol and Saito and Sakurai's protocol. It is observed that high security in group proof construction is still infeasible, thus if security is required to be maximum then multi-round protocol should be preferred. In this work, a multi-round authentication protocol of [1] is analyzed for comparative security analysis. Simulation analysis shows that performance of proposed authentication protocol in multi-round category as well as single-round category is better than state-of-art protocols.	algorithmic efficiency;authentication protocol;bitwise operation;communications protocol;computation;confidentiality;data integrity;exclusive or;itakura–saito distance;marid;message authentication code;mike lesser;non-repudiation;powerset construction;radio frequency;radio-frequency identification;refinement (computing);simulation	Adarsh Kumar;Krishna Gopal;Alok Aggarwal	2016	2016 Ninth International Conference on Contemporary Computing (IC3)	10.1109/IC3.2016.7880249	otway–rees protocol;communications protocol;universal composability;telecommunications;computer science;cost–benefit analysis;link control protocol;authentication protocol;authentication;internet privacy;computer security;computer network	Security	-43.27104399211241	74.95902066668128	159560
35331116101fc77c4050cff609117bdc11815033	revisiting single-server algorithms for outsourcing modular exponentiation		We investigate the problem of securely outsourcing modular exponentiations to a single, malicious computational resource. We revisit recently proposed schemes using single server and analyse them against two fundamental security properties, namely privacy of inputs and verifiability of outputs. Interestingly, we observe that the chosen schemes do not appear to meet both the security properties. In fact we present a simple polynomial-time attack on each algorithm, allowing the malicious server either to recover a secret input or to convincingly fool the client with wrong outputs. Then we provide a fix to the identified problem in the ExpSOS scheme. With our fix and without pre-processing, the improved scheme becomes the best to-date outsourcing scheme for single-server case. Finally we present the first precomputation-free singleserver algorithm, πExpSOS for simultaneous exponentiations, thereby solving an important problem formulated in [6].	algorithm;computation;computational resource;cryptography;formal verification;modular exponentiation;outsourcing;polynomial;precomputation;preprocessor;privacy;requirement;server (computing);time complexity;virtual private server	Jothi Rangasamy;Lakshmi Kuppusamy	2018		10.1007/978-3-030-05378-9_1	theoretical computer science;modular exponentiation;computational resource;computer science;outsourcing;modular design;algorithm	Crypto	-38.51153559081824	74.99139578361469	159567
b77b391dd0d7541b30ac56bf2c114cd46e480155	a distributed multi-party key agreement protocol for dynamic collaborative groups using ecc	public key cryptography;distributed multi party key agreement;cryptographie cle publique;elliptic curve discrete logarithm problem;llave cambio;cle secrete;protocole transmission;elliptic curve;par a par;ecc;echange cle;logarithme discret;discrete logarithm;group communication;courbe elliptique;equation elliptique;elliptic equation;protocolo transmision;key exchange;poste a poste;curva eliptica;support group;arbol binario;secret key;clave secreta;arbre binaire;security key;peer to peer security;problema diffie hellman;key agreement;logaritmo discreto;key agreement protocol;cle securite;ecuacion eliptica;peer to peer;diffie hellman;probleme diffie hellman;diffie hellman problem;binary tree;llave seguridad;transmission protocol	We present a multi-party key agreement protocol based on a novel authenticated two-party elliptic curve Diffie–Hellman (ECDH) keyexchange protocol for dynamic collaborative peer groups. The security of our two-party and multi-party key agreement protocols is based on the computational intractability of the elliptic curve discrete logarithm problem (ECDLP). The strength-per-key-bit is substantially greater in keys generated using ECDH than in keys generated using Diffie–Hellman (DH) key exchange. Thus, with much smaller parameters like the key size, ECDH keys provide equivalent security compared to DH keys. We show that the proposed protocols establish an authenticated, distributed, and contributory group secret key among a group of members. Our multi-party key agreement protocol supports group dynamics like member-join, member-leave, group-fusion, and group-fission securely. Further, it introduces array-based binary key-trees (ABKTs), which are balanced trees that bound the key-computation cost of handling member dynamics to O(log n), where n is the number of members in the group. © 2006 Elsevier Inc. All rights reserved.	authentication;communications protocol;computation;computational complexity theory;diffie–hellman key exchange;digital light processing;discrete logarithm;ecc memory;elliptic curve cryptography;forward secrecy;group key;key (cryptography);key size;key-agreement protocol;known-key distinguishing attack;self-balancing binary search tree;singlet fission;viz: the computer game	Venkata C. Giruka;Saikat Chakrabarti;Mukesh Singhal	2006	J. Parallel Distrib. Comput.	10.1016/j.jpdc.2006.03.006	computer science;mathematics;distributed computing;elliptic curve;computer security;algorithm	Crypto	-42.685053247728554	76.49975840855257	159872
952d9ba34a848b70844b4c0208cef56bb0119f88	analysis and improvement of an anonymity scheme for p2p reputation systems	anonymity;peer to peer p2p reputation system;tecnologia electronica telecomunicaciones;p2p;unlinkability;peer to peer p2p;reputation system;blind signature;tecnologias;grupo a;peer to peer	In 2006, Miranda et al. proposed an anonymity scheme to achieve peers' anonymity in Peer-to-Peer (P2P) reputation systems. In this paper, we show that this scheme can not achieve peers' anonymity in two cases. We also propose an improvement which solves the problem and improves the degree of anonymity.	reputation system	Liming Hao;Songnian Lu;Shutang Yang;Ning Liu;Qi-shan Huang	2008	IEICE Transactions	10.1093/ietfec/e91-a.10.2893	anonymity;computer science;peer-to-peer;internet privacy;blind signature;world wide web;computer security	Crypto	-45.19992381664374	77.61004025126657	160014
129f891755598f84eca77ddc418f0371bb0fc50f	mitigation of control channel jamming via combinatorial key distribution	channel access;one way function;wireless ad hoc network;combinatorial design;multiple access control;random access;key establishment;key distribution	  The problem of countering control channel jamming against internal adversaries in wireless ad hoc networks is addressed. Using  combinatorial key distribution, a new method to secure the control channel access is introduced. This method, utilizes the  established keys in the key establishment phase to hide the location of control channels without the need for a secure BS.  This is in obtained by combination of a collision free one-way function and a combinatorial key establishment method. The  proposed scheme can be considered as a special case of the ALOHA random access schemes which uses the common established keys  as its seeds to generate the pattern of transmission.    	key distribution;radio jamming	Abolfazl Falahati;Mahdi Azarafrooz	2010		10.1007/978-3-642-15717-2_29	telecommunications;computer security;computer network	Crypto	-45.82989488494417	76.59418108986965	160253
698736664dbc45c9ab0140334e548bd2ae8b2649	alerts correlation system to enhance the performance of the network-based intrusion detection system	metodo correlacion;correlation method;securite informatique;computer security;internet technology;large scale;internet;systeme detection intrusion base reseau;side effect;seguridad informatica;intrusion detection systems;systeme detection intrusion;intrusion detection system;methode correlation;alert correlation	• • Authentication Authentication – – Requires users to provide proof of identity Requires users to provide proof of identity • • Authorization Authorization – – Grants access only to those who are authorized Grants access only to those who are authorized	authentication;authorization;intrusion detection system	Do-Hoon Lee;Jung-Taek Seo;Jaecheol Ryou	2004		10.1007/978-3-540-30208-7_48	anomaly-based intrusion detection system;intrusion detection system;embedded system;host-based intrusion detection system;telecommunications;computer science;computer security;intrusion prevention system	Security	-45.22267440329456	77.58235381515435	160304
379f5456ba06acce0bc992fe06c7aa4fa73a00db	weakness and simple improvement of a password authentication scheme based on geometric approach	message authentication formal verification mathematics computing;mathematics computing;authentication smart cards computer science costs publishing cryptography;geometric approach;formal verification;verifier free password authentication;euclidean plane;euclidean plane geometric approach verifier free password authentication;message authentication;password authentication	In 2001, Chien et al. proposed a modified verifier-free password authentication scheme without incurring much computational overhead to improve the security of Wu's scheme. Herein, we first review Chien et al.'s scheme, and then show its weakness. Furthermore, we also propose a simple improved password authentication scheme based on the geometric property of the Euclidean plane	authentication;overhead (computing);password	Wei-Chi Ku;Shen-Tien Chang;Hsi-Hung Chen;Maw-Jinn Tsaur	2005	The IEEE Conference on Local Computer Networks 30th Anniversary (LCN'05)l	10.1109/LCN.2005.137	data authentication algorithm;message authentication code;zero-knowledge password proof;euclidean geometry;s/key;challenge–response authentication;formal verification;computer science;theoretical computer science;authentication protocol;lightweight extensible authentication protocol;password authentication protocol;internet privacy;one-time password;password;computer security;challenge-handshake authentication protocol;hmac-based one-time password algorithm;password strength	Crypto	-41.63674522015509	76.97324571864284	160316
7535d9cdc2dc41491a02469e07e638008ef0c190	bilinear cryptography using groups of nilpotency class 2		In this paper, we develop a novel idea of a bilinear cryptosystem using the discrete logarithm problem in matrices. These matrices come from a linear representation of a group of nilpotency class 2. We discuss an example at the end.	bilinear transform;cryptography	Ayan Mahalanobis;Pralhad Shinde	2017		10.1007/978-3-319-71045-7_7	discrete mathematics;cryptography;cryptosystem;nilpotent group;bilinear interpolation;matrix (mathematics);discrete logarithm;mathematics	Crypto	-39.80148279601176	80.34131656898705	160356
73a6d7d532a8eaf67e2eac0053fa9e224ec06322	ciphertext-only attacks and weak long-term keys in t-310		ABSTRACTT-310 is an important Cold War cipher (Schmeh 2006). It was the principal encryption algorithm used to protect various state communication lines in Eastern Germany in the 1980s. The cipher is quite robust, and it outputs extremely few bits from the internal state. In this article, the authors study the choice of the long-term key in T-310. They show that if a key is faulty, for example if they omit to check just one condition which the keys should satisfy, and more or less each time the round function is not bijective, communications can be decrypted in a ciphertext-only scenario. The authors provide mathematical proofs that the main historical key classes KT1 and KT2 are secure against such attacks.	ciphertext	Nicolas Courtois;Maria-Bristena Oprisanu	2018	Cryptologia	10.1080/01611194.2017.1362065	encryption;cipher;theoretical computer science;bijection;mathematical proof;differential cryptanalysis;ciphertext;correlation attack;block cipher;computer science	Crypto	-38.5097220744578	81.22730639799954	160416
bc0123c261d9190d1745239e6a7f1adcf971f2c7	an anonymous property-based attestation protocol from bilinear maps	public key cryptography;provable security;security properties;protocols;elliptic curve cryptography trusted computing anonymous attestation property based attestation bilinear map;remote attestation;anonymous attestation;protocols privacy information security elliptic curve cryptography laboratories national security computational efficiency concrete joining processes springs;trust computing platform;nickel;cryptographic protocols;short length signature anonymous property based attestation protocol bilinear map remote attestation tcg specification trust computing platform elliptic curve cryptography;digital signatures;discrete logarithm;data mining;trusted computing;short length signature;property based attestation;bilinear map;elliptic curve cryptography;public key;anonymous property based attestation protocol;games;public key cryptography cryptographic protocols digital signatures;tcg specification;trusted computing platform;privacy	Remote attestation presented in TCG specification is one of the significant ways to establish trust between the two endpoints. There are two categories of remote attestation: anonymous identity attestation of TPM and the security properties attestation of trust computing platform, and the verifier can verify both at the far endpoint. In order to simplify the attestations, we propose the hybrid attestation called APA(anonymous property attestation) from the elliptic curve cryptography and bilinear map. The scheme is provable security under the LRSW assumption, the hardness of discrete logarithms. The lengths of the attestation signature in our scheme are much shorter than directly associated two attestations, and also takes the less computation cost.	bilinear filtering;bilinear transform;communication endpoint;computation;discrete logarithm;elliptic curve cryptography;provable security;trusted computing;trusted platform module	Yu Qin;Dengguo Feng;Zhen Xu	2009	2009 International Conference on Computational Science and Engineering	10.1109/CSE.2009.84	direct anonymous attestation;computer science;internet privacy;public-key cryptography;world wide web;computer security	Security	-41.44057077978294	74.80851511225096	160496
76a0944851c19cf547137df257ceaaee8ddec51d	relation of ppatmp and scalar product protocol and their applications	protocols;scalar product;secure shared generic polynomial protocol ppatmp scalar product protocol privacy preserving add to multiply protocol secure multiparty computation protocols computation complexity secure two party mean protocol secure shared x ln x protocol;complexity theory;privacy preservation;data mining;secure communication;polynomials;data privacy;computational complexity;cryptography;protocols complexity theory privacy cryptography polynomials;protocols computational complexity data mining data privacy;privacy;secure multiparty computation	Scalar product protocol and privacy preserving add to multiply protocol (PPAtMP) are two significant basic secure multiparty computation protocols. In this paper, we claim that the two protocols are equivalent to each other and we can achieve one based on the other with the same communication and computation complexity. Then, we propose Secure Two-party Mean Protocol, Secure Shared x ln x Protocol and Secure Shared Generic Polynomial Protocol based on scalar product protocol and PPAtMP. Additionally, we analyze the correctness, security, communication overheads and computation complexity of each protocol proposed in this paper.	communications protocol;correctness (computer science);distributed computing;polynomial;scalar processor;secure multi-party computation	Youwen Zhu;Liusheng Huang;Wei Yang	2010	The IEEE symposium on Computers and Communications	10.1109/ISCC.2010.5546716	secure communication;universal composability;commitment scheme;information privacy;computer science;cryptography;secure two-party computation;theoretical computer science;cryptographic protocol;distributed computing;privacy;computer security	Crypto	-40.942543516721265	75.17368850240021	160527
9222e983aa0dec52c98e0c6819b0681d7a6151b8	a new public-key cryptosystem via mersenne numbers		In this work, we propose a new public-key cryptosystem whose security is based on the computational intractability of the following problem: Given a Mersenne number p = 2 − 1, where n is a prime, a positive integer h , and two n -bit integers T,R , find two n -bit integers F,G each of Hamming weight at most h such that T = F ·R+G modulo p , under the promise that they exist.	computational complexity theory;cryptanalysis;cryptosystem;encryption;hamming weight;modulo operation;public-key cryptography;surround sound;window function	Divesh Aggarwal;Antoine Joux;Anupam Prakash;Miklos Santha	2017		10.1007/978-3-319-96878-0_16	discrete mathematics;double mersenne number;prime (order theory);largest known prime number;computer science;mersenne prime;public-key cryptography;cryptosystem;hamming weight;integer	Crypto	-38.995150033637366	80.1798818667692	160545
f6bd06bc881c099dd3ed87d6efbd9fdbcf0515e4	a new anonymous conference key distribution system based on the elliptic curve discrete logarithm problem	elliptic curve discrete logarithm problem;elliptic curve discrete logarithm;one way hash function;discrete logarithm;conference key distribution system;cryptography;discrete logarithm problem;user anonymity;key distribution	In 1999, Tseng and Jan [Comput. Commun. 22 (1999) 749] proposed two conference key distribution systems (CKDS) with user anonymity based on the discrete logarithm problem and the interpolating properties of polynomials. Their first CKDS scheme uses a one-way hash function to hide the identities of the participants and to protect each participant’s common key that is shared with the chairperson. In this article, we will propose a more efficient CKDS scheme with user anonymity that is based on the elliptic curve discrete logarithm problem and the properties of the line. Our scheme has the advantage of requiring less computing time than the Tseng–Jan CKDS with a one-way hash function. D 2003 Elsevier Science B.V. All rights reserved.	cryptographic hash function;discrete logarithm;elliptic curve cryptography;interpolation;jan bergstra;key distribution;one-way function;polynomial	Chou Chen Yang;Ting Yi Chang;Min-Shiang Hwang	2003	Computer Standards & Interfaces	10.1016/S0920-5489(03)00002-3	discrete logarithm;logarithm;binary logarithm;iterated logarithm;computer science;theoretical computer science;quantities of information;baby-step giant-step;xtr;post-quantum cryptography;computer security	Crypto	-41.289356744396805	77.51946577676678	160609
d2d44303800a68de97064df8b7ef32445e3bbfb5	address-bit differential power analysis of cryptographic schemes ok-ecdh and ok-ecdsa	carte a puce;smart card;mobile device;systeme embarque;elliptic curve;cryptanalyse;courbe elliptique;ok ecdsa;cryptanalysis;criptoanalisis;embedded systems;aleatorizacion;elliptic curve cryptosystems ecc;curva eliptica;smart cards;digital signature;criptografia;cryptography;differential power analysis;address bit dpa;randomisation;signature numerique;cryptographie;ok ecdh;scalar exponentiation;analyse puissance differentielle;firma numerica;randomization;differential power analysis dpa	The differential power analysis (DPA) is a powerful attack against the implementation of cryptographic schemes on mobile devices. This paper proposes an alternative DPA using the addresses of registers of elliptic curve based cryptosystems (ECC) implemented on smart cards. We call the analysis the address-bit DPA in this paper. The analysis was originally investigated by Messerges, Dabbish and Sloan, however it was thought to be of no effect if the intermediate data are randomized. We extend the analysis and show how the extended analysis works against scalar exponentiations even if the implementation is resistant against the data-based DPA. We show experimental results of our analysis of cryptographic schemes OK-ECDH and OK-ECDSA, which are candidates of the CRYPTREC project in Japan, and evidence of their weakness.	cryptrec;crypto++;cryptography;cryptosystem;mobile device;randomized algorithm;smart card	Kouichi Itoh;Tetsuya Izu;Masahiko Takenaka	2002		10.1007/3-540-36400-5_11	arithmetic;smart card;computer science;mathematics;computer security;algorithm;statistics	Crypto	-41.04316211546006	80.84751113738133	160850
cfa9559599f7055a2812c95b14dcaa2759e41716	using time-stamp to improve the security of a chaotic maps-based key agreement protocol	chaos;replaying attack;semi group;hash;key agreement;key agreement protocol;group key agreement;time stamp	Based on the semi-group property of Chebyshev chaotic map and time-stamp, we propose an enhanced chaotic maps-based key agreement protocol, which is more secure than the original one and can resist the replaying attack.	basic stamp;key-agreement protocol;list of chaotic maps	Di Xiao;Xiaofeng Liao;Shaojiang Deng	2008	Inf. Sci.	10.1016/j.ins.2007.11.001	timestamp;hash function;computer science;key-agreement protocol;distributed computing;internet privacy;semigroup;computer security	Crypto	-43.00092368288153	75.88072798971788	161221
128d03fb302a943a2fa3c191ba1a7eaeda2352c4	many-to-one encryption and authentication scheme and its application	many to one;software;on line systems;pairing authentication dynamic accumulator encryption group oriented cryptography identity many to one;mise a jour;encryption;complexite calcul;authentication;pairing;cifrado;securite donnee;dynamic accumulator;authentification;receivers;actualizacion;receivers encryption authentication servers software;complejidad computacion;servers;autenticacion;cryptage;computational complexity;criptografia;cryptography;systeme en ligne;group oriented cryptography;cryptographie;identity;security of data;updating;oracle	This paper is to study a subclass of group-oriented cryptographic scheme: Many-to-one encryption and authentication scheme. The many-to-one encryption and authentication scheme is to solve a practical problem, i.e., the scenario that the number of the receivers is very small compared with the number of the senders and a receiver may serve millions of senders. Compared with the traditional methods, the burdens of the receiver and the KGC are reduced greatly. How to revoke a sender from his receiver's legitimate sender group is also proposed and it is efficient compared with some traditional methods. The proposed scheme is proven in the random oracle models. The computational complexity of our scheme is independent of the number of the senders. At the end of the paper, an example is given to show how to use our scheme in online software registration and update.	authentication;cloud computing;computational complexity theory;confidentiality;cryptography;encryption;key management;one-to-many (data model);programming paradigm;random oracle	Xi Jun Lin;Chuan Kun Wu;Feng Liu	2008	Journal of Communications and Networks	10.1109/JCN.2008.6388324	telecommunications;computer science;theoretical computer science;operating system;authentication;distributed computing;computer security;encryption;computer network	Security	-42.703323131174905	77.20709235176746	161300
7dc7b2632f45871ede5aff2eff43e363c09faa2a	an authenticated encryption based grouping proof protocol for rfid systems: an authenticated encryption based grouping proof protocol for rfid systems				Samad Rostampour;Nasour Bagheri;Mehdi Hosseinzadeh;Ahmad Khademzadeh	2016	Security and Communication Networks	10.1002/sec.1718	multiple encryption;authenticated encryption;computer security	Security	-42.00662804700615	77.13535837399995	161490
c08d6cca5d433da4fff0990c14f0770fa5a19c82	concurrent non-malleable witness indistinguishable argument from any one-way function	specialsound wi proofs;concurrent non malleable witness indistinguishability;commitment;strong non malleable witness indistinguishability	Non-malleable witness indistinguishability (NMWI) is a security notion against man-in-the-middle attacks which requires that the witness encoded in the right interaction is computationally independent of that used by honest prover in the left. In STOC 2009, Lin et al. defined strongly non-malleable witness indistinguishability (SNMWI) which is similar in spirit to NMWI, and proposed a SNMWI scheme based on one-way function. In this paper, we firstly show that the two notions NMWI and SNMWI are incomparable: there exists a SNMWI argument which is not NMWI, and vice versa. Furthermore, it is pointed out that the SNMWI construction given in STOC 2009 is not NMWI. Then, we present a variant of LPV08 scheme [17] and show that this variant is a concurrent NMWI argument. Compared with the concurrent NMWI argument of [22] which was shown to be non-malleable by using non-black-box techniques and whose difficulty assumption was claw-free permutation, our new scheme is based on the existence of one-way functions and its proof of security relies on black-box techniques.	one-way function	Guifang Huang;Lei Hu	2011		10.1007/978-3-642-34704-7_25	discrete mathematics;mathematics;algorithm	Theory	-38.0645116969839	75.87957893936492	161778
664259cc923f3d1b3f09bf78f9f800efa81f9ab1	automatic encryption schemes based on the neural networks: analysis and discussions on the various adversarial models (short paper)		Modern cryptographic schemes have been focusing on protecting attacks from computational bounded adversaries. The various cryptographic primitives are designed concretely following some randomization design strategies, so that one of the goals is to make it hard for the attacker to distinguish between the real ciphers and the randomly distributed ones. Recently, Google Brain team proposed the idea to build cryptographic scheme automatically based on the neural network, and they claim that the scheme can defeat neural network adversaries. While it is a whole new direction, the security of the underlined scheme is remained unknown. In this paper, we investigate their basic statistical behavior from traditional cryptography’s point of view and extend their original scheme to discuss how the encryption protocol behave under a much more stronger adversary.	artificial neural network;encryption	Yidan Zhang;Marino Anthony James;Jiageng Chen;Chunhua Su;Jinguang Han	2017		10.1007/978-3-319-72359-4_34	cryptographic primitive;artificial neural network;cryptography;encryption;adversary;distributed computing;bounded function;cryptographic protocol;computer science;google brain	ML	-36.99573056370519	74.76220717865083	161820
dbbac00bda43d6b7fede54fb9a5b0922e6ee475b	forward-security under continual leakage		Current signature and encryption schemes secure against continual leakage fail completely if the key in any time period is fully exposed. We suggest forward security as a second line of defense, so that in the event of full exposure of the current secret key, at least uses of keys prior to this remain secure, a big benefit in practice. (For example if the signer is a certificate authority, full exposure of the current secret key would not invalidate certificates signed under prior keys.) We provide definitions for signatures and encryption that are forward-secure under continual leakage. Achieving these definitions turns out to be challenging, and we make initial progress with some constructions and transforms. 1 Department of Computer Science & Engineering, University of California San Diego, 9500 Gilman Drive, La Jolla, California 92093, USA. Email: mihir@eng.ucsd.edu. URL: http://cseweb.ucsd.edu/~mihir/. Supported in part by NSF grants CNS-1526801 and CNS-1717640, ERC Project ERCC FP7/615074 and a gift from Microsoft. 2 Department of Computer Science, Georgetown University, 3700 Reservoir Road NW, Washington, DC 20057, USA. Email: adam@cs.georgetown.edu. URL: http://people.cs.georgetown.edu/~adam/. 3 Department of Computer Science & Engineering, University of California San Diego, 9500 Gilman Drive, La Jolla, California 92093, USA. Email: istepano@eng.ucsd.edu. URL: https://cseweb.ucsd.edu/~istepano/. Supported in part by grants of first author.	antivirus software;certificate authority;computer science;email;encryption;geforce 9 series;ibm notes;jolla;key (cryptography);netware;norton internet security;spectral leakage	Mihir Bellare;Adam O'Neill;Igors Stepanovs	2017		10.1007/978-3-030-02641-7_1	forward secrecy;computer security;certificate authority;encryption;leakage (electronics);computer science	Crypto	-35.112746604967725	76.8493623036494	161839
1c388979b703b89842cacd1dd0494445ee317ba2	farfalle: parallel permutation-based cryptography		In this paper, we introduce Farfalle, a newmode for building a pseudorandom function (PRF) from a b-bit cryptographic permutation. The constructed PRF takes as input a b-bit key and a sequence of variable-length data strings, and it generates a variable-length output. It consists of a compression layer and an expansion layer, each of them involving the parallel application of the permutation. The construction aims for simplicity and efficiency, among others with the ability to compute it for incremental inputs and with its inherent parallelism. Thanks to its input-output characteristics, Farfalle is very versatile. We specify concrete modes on top of it, for authentication, encryption and authenticated encryption, as well as a wide block cipher mode. Farfalle can be instantiated with any permutation. In particular, we instantiate it with one of the K -p permutations, a ach concrete security claims to it and call the result K . To offer protection against a acks that exploit the low algebraic degree of the round function of K -p, we do domain separation with a particular rolling function that aims at preventing the construction of input sets that form affine spaces of large dimension.	acknowledgement (data networks);authenticated encryption;authentication;automated clearing house;block cipher mode of operation;central processing unit;concrete security;cryptographic hash function;cryptography;duplex (telecommunications);embedded system;monika henzinger;parallel computing;primitive recursive function;pseudorandom function family;pseudorandomness;simd;side-channel attack;symmetric-key algorithm;threat (computer)	Guido Bertoni;Joan Daemen;Michaël Peeters;Gilles Van Assche;Ronny Van Keer	2016	IACR Trans. Symmetric Cryptol.		permutation;cryptography;block cipher;pseudorandom function family;block cipher mode of operation;encryption;concrete security;arithmetic;authenticated encryption;computer science	Crypto	-40.717187142558984	79.31868835609829	161891
518fe6a5bd94bebc40501879de68fd4300f9a035	public key cryptography empowered smart dust is affordable	public key cryptography;batterie;distributed system;red sin hilo;reseau capteur;cryptographie cle publique;multiagent system;dispositivo potencia;secondary cell;systeme reparti;pkc;reseau sans fil;elliptic curve;acumulador electroquimico;ecc;power efficiency;authentication;wireless network;resource management;dispositif puissance;intelligence artificielle;hardware accelerator;mass production;cryptage rsa;courbe elliptique;energy requirement;rsa ciphering;wireless sensor network;authentification;captador medida;battery;gestion recursos;measurement sensor;red sensores;sistema repartido;autenticacion;capteur mesure;elliptic curve cryptography;bateria;curva eliptica;energy consumption;cifrado rsa;wsns;accumulateur electrochimique;duty cycle;sensor array;consommation energie;sensor nodes;power device;gestion ressources;artificial intelligence;smart dust;inteligencia artificial;power consumption;consommation energie electrique;sistema multiagente;security;wireless sensor networks;consumo energia;systeme multiagent;key distribution	Public key cryptography (PKC) has been considered for a long time to be computationally too expensive for small battery powered devices. However, PKC turned out to be very beneficial for issues such as key distribution, authentication etc. In the recent years first research groups started to cope with the challenges applying PKC in resource-constrained environments. One result is that in particular ECC seems to be very suitable for such environments, because it provides the same level of security as RSA does while requiring much shorter keys. In this paper we evaluate the power consumption resulting from using various PKC approaches with respect to calculations and transmission of signatures etc. Our findings here clearly indicate that software realisations of PKC lead to relatively long duty cycles (operating intervals) which in turn require significant amount of energy. In contrast, the energy required for computation is negligible if the PKC is performed by power efficient hardware accelerators. In such cases the corresponding transmission power becomes much more significant. So we argue for dedicated hardware for elliptic curve cryptography in order to reduce energy consumption and to prolong life time of sensor nodes. Since additional hardware equals to additional cost, we are focussing on hardware accelerators that are optimised with respect to silicon area consumption. Our solution that supports an ECC key length of 163 bit takes about 1.02 mm cell area in a 0.25μm technology and needs about 12.8 μWs per point multiplication. Due to its small size the accelerator can be manufactured for about 0.05 USD in mass production.	antivirus software;authentication;computation;dbm;elliptic curve cryptography;emoticon;hardware acceleration;key distribution;key size;microcontroller;php accelerator;pkc (conference);public-key cryptography;rsa numbers;sensor;signature block;sleep mode;smart board;transceiver;type signature	Steffen Peter;Peter Langendörfer;Krzysztof Piotrowski	2008	IJSNet	10.1504/IJSNET.2008.019258	embedded system;wireless sensor network;telecommunications;computer science;resource management;authentication;computer security	Arch	-47.777831884320975	79.12044158895759	161925
26e3d68ffaac43db196aa91297e481ebd3600de2	on the security of a group signcryption scheme from distributed signcryption scheme	anonymity;distributed system;systeme reparti;confidencialidad;encryption;securite informatique;signature electronique;cifrado;attaque informatique;confidentiality;anonymat;computer security;confidentialite;group signature;sistema repartido;cryptage;digital signature;criptografia;cryptography;seguridad informatica;forgeage;forging;computer attack;ataque informatica;cryptographie;firma numerica;forja;anonimato	Signcryption denotes a cryptographic method, which can process encryption and digital signature simultaneously. So, adopting such schemes, computational cost of encryption and signature compared to traditional signature-then-encryption can be reduced to a great extent. Based on the existing distributed signcryption schemes, Kwak and Moon proposed a new distributed signcryption scheme with sender ID confidentiality and extended it to a group signcryption. Their scheme is more efficient in both communication and computation aspects. Unfortunately we will demonstrate that their scheme is insecure by identifying some security flaws. Exploring these flaws, an attacker without any secret can mount universal forging attacks. That is, anyone (not necessary the group member) can forge valid group signatures on arbitrary messages of his/her choice.	signcryption	Haiyong Bao;Zhenfu Cao;Haifeng Qian	2005		10.1007/11599371_3	digital signature;confidentiality;anonymity;computer science;cryptography;forging;signcryption;internet privacy;group signature;world wide web;computer security;encryption	Crypto	-43.44926651537828	77.19258875050741	161988
8ee49bec7ca6ca675a9aa8cb6c2dbd0265e87c96	additive proofs of knowledge - a new notion for non-interactive proofs	interactive proofs;zero knowledge;proof of knowledge	This paper has two contributions. Firstly, we describe an efficient Non-Interactive Zero-Knowledge (NIZK) Proof of Knowledge (PoK) protocol using bilinear pairings. The protocol assumes the hardness of the Computational Diffie-Hellman (CDH) problem. The prover does not perform any pairing computations while the verifier performs 3 pairing computations. The protocol can be used for identification (eg. in smart-cards). Secondly, we extend the idea to multiple proofs and propose the notion of efficient Additive Non-Interactive Witness-Indistinguishable (A-NIWI) proofs. Intuitively an A-NIWI proof can be considered as a PoK of another A-NIWI proof. Our ideas are based on the aggregate signature scheme of Boneh et al. (proposed in Eurocrypt 2003).	additive model;aggregate data;antivirus software;bilinear filtering;computation;computational diffie–hellman assumption;decisional diffie–hellman assumption;diffie–hellman problem;digital signature;e-commerce;electronic circuit simulation;eurocrypt;interactive proof system;interactivity;non-interactive zero-knowledge proof;programming paradigm;proof of knowledge;smart card;utility functions on indivisible goods	Amitabh Saxena	2005			computer science;proof of knowledge;algorithm;zero-knowledge proof	Crypto	-40.34759719413805	75.7748405815615	162136
7d02452d6d21c260eaadaf857649a162dd6ec5ae	extended period lfsr using variable tap function	tap function;period;word length 127 bit extended period lfsr tap function linear feedback shift register primitive polynomials basic lfsr;lfsr;basic lfsr;linear feedback shift register;primitive polynomial;extended period lfsr;primitive polynomials;embeeded lfsr period extension criptosystems;word length 127 bit;shift registers;public key cryptography linear feedback shift registers information security writing public key hardware clocks polynomials robustness internet;embeeded;prime number;extension;criptosystems	This paper presents a method to extend the period of a linear feedback shift register (LFSR) by proposing an algorithm to generate primitive polynomials, this is archived by using basic LFSR with a maximum period equal to a prime number. The period extension achieved with our proposed method is statistically robust and has a very long extension of the LFSR period, as long of (2120)!(2N - 1) for a 127 bit length register. Also by separating the phases of setup and running in the algorithm avoid losing the characteristically speed of the LFSRs.	algorithm;archive;bit-length;blum blum shub;blum axioms;blum–shub–smale machine;java;linear-feedback shift register;polynomial;stream cipher	Ariel Molina-Rueda;Fernando Uceda-Ponga;Claudia Feregrino Uribe	2008	18th International Conference on Electronics, Communications and Computers (conielecomp 2008)	10.1109/CONIELECOMP.2008.8	real-time computing;theoretical computer science;mathematics;linear feedback shift register;algorithm	Robotics	-36.00482264586838	81.383141682853	162184
f3a8b53624a2e8672d0b444e7eb4068af8c323c8	the price of security: a detailed comparison of the tls handshake performance on embedded devices when using elliptic curve cryptography and rsa		The Transport Layer Security (TLS) Protocol is the current de-facto standard for secure connections over an insecure medium; it combines asymmetric and symmetric cryptography to achieve authentication, confidentiality and message integrity. The flexibility of the TLS protocol regarding the algorithms used allows it to also run efficiently on mobile devices severely constrained in terms of available memory, computing power and energy. In this work we present a thorough performance evaluation of the TLS handshake process by breaking it down into its individual phases, with a focus on the comparison between the usually applied RSA algorithm and cryptographic primitives based on Elliptic Curve Cryptography (ECC). We are especially interested how the transition to more secure TLS cipher suites (like switching from one-way to mutual authentication or to ephemeral primitives) affects the load that is put on client and server when using RSA and ECC, respectively.	elliptic curve cryptography;embedded system;transport layer security	Manuel Koschuch;Matthias Hudler;Michael Krüger	2010		10.1007/978-3-642-25206-8_4	elliptic curve digital signature algorithm;computer science;distributed computing;elliptic curve cryptography;internet privacy;computer security	Crypto	-46.715033645929815	74.82129183353669	162187
1391584f6dba0bee93cfd9b400e8868bc469c5bc	efficient signature schemes based on birational permutations	signature scheme;public key;rational function	Many public key cryptographic schemes (such a s c u b i c RSA) are based on low degree polynomials whose inverses are high degree polynomials. These functions are very easy to compute but time consuming to invert even by their legitimate users. To m a k e such s c hemes more eecient, we consider in this paper the class of birational permutations f over k-tuples of numbers, in which both f and f ;1 are low degree rational functions. We develop two n e w families of birational permutations, and show h o w to transform them into new public key signature schemes which are much faster than the known schemes.	bit-reversal permutation;polynomial;public-key cryptography	Adi Shamir	1993		10.1007/3-540-48329-2_1	rational function;combinatorics;discrete mathematics;computer science;mathematics;public-key cryptography;computer security;algebra	Crypto	-39.36228535073056	80.13515524619795	162229
68608ee164438f9f9a955c922c3aa5b3ff20bc5a	on the impact of decryption failures on the security of lwe/lwr based schemes		In this paper we investigate the impact of decryption failures on the chosen-ciphertext security of (Ring/Module)-Learning With Errors and (Ring/Module)-Learning with Rounding based primitives. Our analysis is split in three parts: First, we introduce a technique to increase the failure rate of these schemes called failure boosting. Based on this technique we investigate the minimal effort for an adversary to obtain a failure in 3 cases: when he has access to a quantum computer, when he mounts a multi-target attack or when he can only perform a limited number of oracle queries. Secondly, we examine the amount of information that an adversary can derive from failing ciphertexts. Finally, these techniques are combined in an attack on (Ring/Module)-Learning with Errors and (Ring/Module)-Learning with Rounding based schemes with decryption failures. We provide both a theoretical analysis as well as an implementation to calculate the security impact and show that an attacker can significantly reduce the security of several candidates of the NIST post-quantum standardization process if sufficient oracle queries can be performed.	adversary (cryptography);chosen-ciphertext attack;ciphertext;encryption;endoscopic retrograde cholangiography;failure rate;heart failure;key (cryptography);learning with errors;levee collapse;liver failure, acute;numerous;part dosing unit;post-quantum cryptography;quantum computing;rounding;stage a;benefit	Jan-Pieter D’Anvers;Frederik Vercauteren;Ingrid Verbauwhede	2018	IACR Cryptology ePrint Archive			Security	-35.42571449974697	81.36083012878234	162548
e0acf19af09ea1cb8b1a047a7644273cef98ff32	securing ipv6-based mobile ad hoc networks through an artificial immune system	internet protocol;modelizacion;distributed system;red sin hilo;theoretical model;systeme reparti;informatique mobile;artificial immune system;protocolo internet;reseau sans fil;securite;reseau interconnecte;routing;network security;sistema inmunitario;authentication;wireless network;protocole internet;routage;intelligence artificielle;ad hoc network;attaque informatique;red ad hoc;inmunologia;authentification;modelisation;sistema repartido;autenticacion;reseau ad hoc;immunologie;criptografia;cryptography;safety;ipv6;immune system;computer attack;ataque informatica;artificial intelligence;cryptographie;mobile ad hoc network;inteligencia artificial;reseau neuronal;mobile computing;red interconectada;seguridad;modeling;interconnected power system;red neuronal;systeme immunitaire;neural network;immunology;enrutamiento	Mobile Ad Hoc Networks are vulnerable to security attacks that aim at disrupting routing information, exhausting nodes resources, maliciously manipulating data traffic etc. Construction of security mechanisms for Mobile Ad Hoc Networks is complicated by the fact that they lack a network infrastructure and a central authority for authentication and distribution of cryptographic keys.#R##N##R##N#In this paper is presented a theoretical model of an Artificial Immune System inspired by the vertebrate immune system. The objective of the proposed AIS is protection and reaction against known and unknown dysfunctions or attacks in a Mobile Ad Hoc Network that uses IPv6 addresses. This AIS also includes features inspired by Danger Theory, one of the latest immunological findings and a point of hot debate in the area of immunology.	artificial immune system;hoc (programming language)	Julian L. Rrushi	2005		10.1007/11731177_41	wireless ad hoc network;adaptive quality of service multi-hop routing;telecommunications;computer science;artificial intelligence;network security;ad hoc wireless distribution service;geocast;authentication;mobile computing;computer security;artificial neural network	Mobile	-46.6957092017044	79.24949600808684	162678
57d49deb8a5f442d45b8169375427d34018324c6	key-escrow free multi-signature scheme using bilinear pairings		Wepresent amulti-signature scheme based on bilinear pairings. The scheme is key escrow-free and does not require any secure channel for private key issuance to users. We use a binding-blinding technique to avoid the key escrow problem and to eliminate a secure channel requirement for the key issuance stage. The basic scheme is extended to sequential and parallel multi-signature schemes. We show that the basic scheme and multi-signature schemes are secure against adaptive chosen message attacks under standard assumptions.	bilinear filtering;blinding (cryptography);digital signature;key escrow;public-key cryptography;secure channel	Manik Lal Das	2015	Groups Complexity Cryptology	10.1515/gcc-2015-0002	theoretical computer science;digital signature;key escrow;bilinear interpolation;mathematics	Crypto	-41.74755745196552	76.50399101320109	163004
14fdbde9ed120c636f349a2463a3f3d687df5f1c	the tower number field sieve		The security of pairing-based crypto-systems relies on the difficulty to compute discrete logarithms in finite fields Fpn where n is a small integer larger than 1. The state-of-art algorithm is the number field sieve (NFS) together with its many variants. When p has a special form (SNFS), as in many pairings constructions, NFS has a faster variant due to Joux and Pierrot. We present a new NFS variant for SNFS computations, which is better for some cryptographically relevant cases, according to a precise comparison of norm sizes. The new algorithm is an adaptation of Schirokauer’s variant of NFS based on tower extensions, for which we give a middlebrow presentation.	algorithm;computation;discrete logarithm;general number field sieve;special number field sieve	Razvan Barbulescu;Pierrick Gaudry;Thorsten Kleinjung	2015		10.1007/978-3-662-48800-3_2	discrete mathematics;general number field sieve;logarithm;finite field;discrete logarithm;algebraic number field;pairing;mathematics;integer	Crypto	-38.768476447554775	79.92526702568924	163247
95f6ef28217985c047535bf35b5ac6b8af49bbed	provable-security analysis of authenticated encryption in kerberos	provable security;provable security analysis;privacy provable security analysis authenticated encryption kerberos network authentication protocol formal methods based verification cryptographic security notion;satisfiability;authenticated encryption;formal method;cryptographic security notion;it security;formal methods based verification;network authentication protocol;kerberos;message authentication cryptographic protocols data privacy formal verification;privacy;authentication protocol	Kerberos is a widely-deployed network authentication protocol that is being considered for standardization. Many works have analyzed its security, identifying flaws and often suggesting fixes, thus helping the protocol’s evolution. Several recent results present successful formal-methods-based verification of a significant portion of the current version 5, and some even imply security in the computational setting. For these results to be meaningful, encryption in Kerberos should satisfy strong cryptographic security notions. However, neither currently deployed as part of Kerberos encryption schemes nor their proposed revisions are known to provably satisfy such notions. We take a close look at Kerberos’ encryption and confirm that most of the options in the current version provably provide privacy and authenticity, some with slight modification that we suggest. Our results complement the formal-methods-based analysis of Kerberos that justifies its current design.	authenticated encryption;authentication;kerberos;provable security	Alexandra Boldyreva;Virendra Kumar	2007	IACR Cryptology ePrint Archive	10.1049/iet-ifs.2011.0041	cryptographic primitive;kerberized internet negotiation of keys;formal methods;kerberos;h.235;challenge–response authentication;computer science;authentication protocol;provable security;spnego;cryptographic protocol;internet privacy;authenticated encryption;generic security service algorithm for secret key transaction;privacy;computer security;56-bit encryption;computer network;satisfiability	Crypto	-39.27452204525223	74.82115239668627	163476
5de60bf01b7ba16d583ea082da8c30cf7d3fc79d	a new rabin-type trapdoor permutation equivalent to factoring and its applications	public key cryptography;key management;one way function;random oracle model;tag kem dem framework;trapdoor one way permutations;hybrid encryption	Public key cryptography has been invented to overcome some key management problems in open networks. Although nearly all aspects of public key cryptography rely on the existence of trapdoor one-way functions, only a very few candidates of this primitive have been observed yet. In this paper, we introduce a new trapdoor one-way permutation based on the hardness of factoring integers of pq-type. We also propose a variant of this function with a different domain that provides some advantages for practical applications. To confirm this statement, we develop a simple hybrid encryption scheme based on our proposed trapdoor permutation that is CCA-secure in the random oracle model.	encryption;hybrid cryptosystem;integer factorization;key management;one-way function;public-key cryptography;random oracle;trapdoor function	Katja Schmidt-Samoa	2005	Electr. Notes Theor. Comput. Sci.	10.1016/j.entcs.2005.09.039	random oracle;claw-free permutation;computer science;theoretical computer science;key management;mathematics;hybrid cryptosystem;public-key cryptography;trapdoor function;one-way function;computer security;algorithm	Crypto	-38.86183184307325	78.45792105712381	163538
34f97d8e0ebfd99f24311bcd02d1f71e33b36e2d	blinded-key signatures: securing private keys embedded in mobile agents	mobile agents;digital signatures;mobile agent security;digital signature;cryptography;mobile agent;security;digital signature scheme	We present a new cryptographic primitive, the blinded-key signature, which allows the inclusion of private keys in autonomous mobile agents. This novel approach can be applied to many well-known digital signature schemes, such as RSA and ElGammal.	antivirus software;autonomous robot;cryptographic primitive;digital signature;embedded system;mobile agent;public-key cryptography	Lucas C. Ferreira;Ricardo Dahab	2002		10.1145/508791.508808	digital signature;computer science;information security;internet privacy;blind signature;computer security;computer network	Security	-45.33321774815986	75.74868313616241	163590
6b23532df1275959852df8783128b950204e936d	a new digital multisignature scheme with distinguished signing authorities	signature scheme;digital signature	In 1999, Harn proposed a multisignature scheme with distinguished signing authorities. In Harn’s scheme, a malice member easily confuses the signing authorities since individual signatures and multisignatures both generated on the whole document cannot be used as evidence to distinguish the signing authorities. Moreover, Harn’s scheme is also not secure against Li et al.’s attack [4]. To provide evidence and remove Li et al.’s attack, a new multisignature scheme with distinguished signing authorities is proposed in this article.	antivirus software;computation;digital signature;multisignature;public-key cryptography;scheme	Shin-Jia Hwang;Min-Shiang Hwang;Shiang-Feng Tzeng	2003	J. Inf. Sci. Eng.		ring signature;digital signature;computer science;blind signature;elgamal signature scheme;computer security	Security	-42.358094196352	74.6344916201549	163768
d8334d40ac7e836e45cab3e9cdd150d93d8f9f78	biased bit commitment and applications	search problem;modelizacion;estimacion sesgada;steganographie;biased bit commitment;protocole engagement;problema investigacion;conjugactor search problem;jeu pile ou face;modelisation;cara o cruz;steganography;esteganografia;protocolo compromiso;braid group;coin tossing;lot casting;probleme recherche;modeling;information theoretic;biased estimation;estimation biaisee;commitment scheme	We bring forward the primitive of biased bit commitment, define the security of the model, and present a concrete biased bit commitment scheme based on the braid conjugator search problem. The presented scheme is proved to be information-theoretically hiding and computationally binding in the defined model. Finally, to argue the usefulness of this work, we also sketch out some new applications based on this new primitive.	braid;commitment scheme;cryptographic protocol;cryptography;search problem	Licheng Wang;Zhenfu Cao;Feng Cao;Haifeng Qian;Haiyong Bao	2008	J. Inf. Sci. Eng.		systems modeling;commitment scheme;search problem;artificial intelligence;braid group;mathematics;steganography;computer security;algorithm;statistics	Crypto	-42.37649590582458	78.38286911719501	164393
7032d0bdf00bd2ab2128e3a928cb794d92b79509	matrix-tree based hybrid broadcast encryption	revocation problem matrix tree based hybrid broadcast encryption television system header length key storage quality of service tree based structure advanced access content system;key management;tree data structures cryptography matrix algebra quality of service television broadcasting;revocation broadcast encryption subset cover difference key storage header length;encryption vegetation media educational institutions performance evaluation;matrix algebra;tree data structures;television broadcasting;revocation;key storage;subset cover difference;cryptography;advanced access content system;header length;broadcast encryption;quality of service	Broadcast encryption in a pay television system is actually a key management issue, where smaller key storage and shorter header length are required to assure the quality of service. The existing solutions come up with two typical structures. One is the matrix-based structure without revocation capability and the other is the tree-based structure in Advanced Access Content System. In this paper, we propose two promising schemes that exploit the combination of the two structures to solve the revocation problem in the matrix-based structure to meet the requirements of the small key storage and short header. Mathematical derivations and calculations are performed to prove the feasibility of the proposed schemes.	aacs encryption key controversy;advanced access content system;broadcast encryption;key management;quality of service;requirement;the matrix	Tao Li;Huaqun Guo;Maode Ma	2011	2011 IEEE GLOBECOM Workshops (GC Wkshps)	10.1109/GLOCOMW.2011.6162525	quality of service;telecommunications;computer science;cryptography;key management;internet privacy;computer security;computer network	Mobile	-47.344538511630184	81.20533268393255	164948
74cdedf7923867270290fa937ebd1231e9ae6e21	on the q-strong diffie-hellman problem	diffie hellman	This note is an exposition of reductions among the q-strong Diffie-Hellman problem and related problems. 1 The q-Strong Diffie-Hellman Problem We discuss reductions among the q-strong Diffie-Hellman (q-sDH) problem [1, 3] and related problems. We use the following notation: 1. G1 and G2 are two cyclic groups of prime order p. 2. g1 is a generator of G1 and g2 is a generator of G2. 3. ψ is an isomorphism from G2 to G1, with ψ(g2) = g1. 1.1 The q-Strong Diffie-Hellman Problem over Two Groups Boneh and Boyen defined the q-strong Diffie-Hellman (q-sDH) problem in the Eurocrypt 2004 paper [1] as follows: Definition 1 (q-strong Diffie-Hellman Problem). Assume that ψ is efficiently computable. For an randomly chosen element x ∈ Zp and a random generator g2 ∈ G2, the q-strong Diffie-Hellman Problem is, given (g1, g2, gx 2 , g x2 2 , . . . , g xq 2 ) ∈ G1 × G q+1 2 , to compute a pair (g 1/(x+c) 1 , c) ∈ G1 × Zp. This q-sDH problem is defined based on two groups G1 and G2. We call this problem the Eurocrypt 2004 version q-sDH problem. They defined a variant of the q-sDH problem in the Journal of Cryptology paper [2] as follows: Definition 2 (q-strong Diffie-Hellman Problem (Journal of Cryptology version)). For an randomly chosen element x ∈ Zp and random generators g1 ∈ G1, g2 ∈ G2, the q-strong DiffieHellman Problem is, given (g1, gx 1 , g x2 1 , . . . , g xq 1 , g2, g x 2 ) ∈ G q+1 1 ×G2, to compute a pair (g 1/(x+c) 1 , c) ∈ G1 × Zp. They said that this Journal of Cryptology version q-sDH problem is harder than the Eurocrypt 2004 version q-sDH problem, as ψ is the former no longer requires the existence of efficiently computable isomorphism ψ. We easily see that the Eurocrypt 2004 version problem is reducible to the Journal of Cryptology version problem as follows: for a given (g1, g2, gx 2 , g x2 2 , . . . , g xq 2 ), we compute gx i 1 = ψ(g xi 2 ) for i (1 ≤ i ≤ q) to obtain (g1, gx 1 , gx 2 1 , . . . , g xq 1 , g2, g x 2 ), input it to the oracle of the Journal of Cryptology version problem, and finally obtain (g 1 , c). They [2] also said that when G1 = G2, the pair (g2, gx 2 ) is redundant. Actually, in this case, the Journal of Cryptology version q-sDH problem is equivalent to the following problem: Definition 3 (one-generator q-strong Diffie-Hellman Problem). For an randomly chosen element x ∈ Zp and a random generators g1 ∈ G1, the one-generator q-strong Diffie-Hellman Problem is, given (g1, gx 1 , g x2 1 , . . . , g xq 1 ) ∈ G q+1 1 , to compute a pair (g 1/(x+c) 1 , c) ∈ G1 × Zp. We call this problem one-generator q-strong Diffie-Hellman (one-generator q-sDH) problem. 1 This note is based on the first author’s master thesis. 1.2 The q-Strong Diffie-Hellman Problem over Single Group Here we assume that G1 = G2 and discuss reductions among the q-sDH problem over a single group and its variants. Recall that the one-generator q-sDH problem is also defined over a single group. As in the previous section, the original q-sDH (the Eurocrypt 2004 version q-sDH) problem is also reducible to the Journal of Cryptology version q-sDH problem in the single group setting G1 = G2, and then is reducible to the one-generator q-sDH problem. [the original q-sDH problem (G1 = G2)] ≤ [the JoC version problem (G1 = G2)] ≡ [the one-generator q-sDH problem] We review other two variants of q-sDH problem defined over a single group, q-weak DiffieHellman problem and exponent q-strong Diffie-Hellman Problem. Mitsunari et al. [5] defined the q-weak Diffie-Hellman (q-wDH) problem as follows: Definition 4 (q-weak Diffie-Hellman Problem). For an randomly chosen element x ∈ Zp and a random generators g1 ∈ G1, the q-weak Diffie-Hellman Problem is, given (g1, gx 1 , gx 2 1 , . . . , g xq 1 ) ∈ G 1 , to compute an element g 1/x 1 ∈ G1. Zhang et al. [7] defined the following variant problem: Definition 5 (exponent q-strong Diffie-Hellman Problem). For an randomly chosen element x ∈ Zp and a random generators g1 ∈ G1, the exponent q-strong Diffie-Hellman Problem is, given (g1, gx 1 , g x2 1 , . . . , g xq 1 ) ∈ G q+1 1 , to compute an element g xq+1 1 ∈ G1. This problem is deeply investigated by Cheon [4]. Zhang et al. [7] showed that the q-wDH problem is equivalent to the exponent q-sDH problem. [the q-wDH problem] ≡ [the exponent q-sDH problem] Reardon [6] showed that the one-generator q-sDH problem is reducible to the q-wDH problem. [the one-generator q-sDH problem] ≤ [the q-wDH problem] We summarize the reductions that appears in the subsection: [the original q-sDH problemm (G1 = G2)] ≤ [the JoC version problem (G1 = G2)] ≡ [the one-generator q-sDH problem] ≤ [the q-wDH problem] ≡ [the exponent q-sDH problem]	computable function;computable isomorphism;computational diffie–hellman assumption;cryptography;decisional diffie–hellman assumption;diffie–hellman key exchange;diffie–hellman problem;eurocrypt;gnutella2;journal of cryptology;random number generation;randomness	Naoki Tanaka;Taiichi Saito	2010	IACR Cryptology ePrint Archive		algebra;prime (order theory);isomorphism;diffie–hellman key exchange;cyclic group;function (mathematics);diffie–hellman problem;computable isomorphism;mathematics	Crypto	-38.6060356121223	80.71048826624383	165010
01918d2097f51b79298a61a256bf280bb7179c11	anonymous communication systems in p2p network with random agent nodes	internet protocol;anonymity;distributed system;tiempo parada;reseau communication;haute performance;systeme reparti;protocolo internet;par a par;protocole internet;serveur informatique;distributed computing;cache memory;temps arret;probabilistic approach;anonymous communication;antememoria;anonymat;grid;antememoire;sistema repartido;poste a poste;rejilla;enfoque probabilista;approche probabiliste;alto rendimiento;grille;calculo repartido;servidor informatico;stopping time;p2p networks;peer to peer;red de comunicacion;high performance;communication network;calcul reparti;computer server;anonimato	P2P networks provide a basic form of anonymity. The anonymity, however, breaks down at download/upload time because the IP address of the host from which the data is downloaded (or to which it is uploaded) can be known to the outside. We propose a technique to provide anonymity for both the client and the server node. A random node along the path between the client and the server node is selected as an agent node and works as a proxy: the client will see it as the server and the server looks at it as the client, hence protecting the identity of the client and the server from each other.	peer-to-peer	Byung Ryong Kim;Ki-Chang Kim	2005		10.1007/11590354_97	internet protocol;reverse proxy;upload;anonymity;cpu cache;telecommunications;stopping time;computer science;operating system;distributed computing;fat client;grid;world wide web;computer security;telecommunications network;server;remote evaluation	ECom	-45.12093034688741	78.2892264834139	165147
1e5694a88e62319c012bc57d5e0c8c7865315ae0	mcoe: a foolproof on-line authenticated encryption scheme			authenticated encryption;authentication	Ewan Fleischmann;Christian Forler;Stefan Lucks;Jakob Wenzel	2011	IACR Cryptology ePrint Archive			Crypto	-42.14568564668109	78.77379755617358	165503
0b7c84b06a0abd2a8bd4e6d967df22f09abd12a8	an escrow-free hierarchical identity-based signature model for cloud storage	cdh assumption;key escrow;cryptanalysis;hierarchical identity based signature;bilinear pairing	Hierarchical identity-based cryptography is an efficient technology to address the security issues in cloud storage. However, the inherent key escrow problem primarily hinders the widespread adoption of this cryptosystem in practice. To address the key escrow problem, this paper proposes an escrow-free hierarchical identity-based signature model, in which a user signs messages with a user-selected secret and PKG signing factor apart from the private key. For proving the full security, wei¾źformulate three security games with respect to our signature model. We instantiate the escrow-free model into a specific scheme based on the SHER-IBS scheme and prove that our scheme is secure against adaptive chosen ID and message attacks.	cloud storage	Peixin Chen;Xiaofeng Wang;Jinshu Su	2015		10.1007/978-3-319-27161-3_58	cryptanalysis;key escrow;computer science;internet privacy;world wide web;computer security	Crypto	-41.60414687430209	75.58376491818831	165696
5bf2c4c2749dff7c50b129829de04fca7f98a097	an identity-based broadcast encryption protocol for ad hoc networks	provable security;protocols;identity based broadcast encryption protocol;identity based encryption;cryptographic protocols;construction industry;ad hoc network;group key generation protocol;message exchange;telecommunication security ad hoc networks broadcasting cryptographic protocols mobile radio;standard model;public key;bilinear pair computation identity based broadcast encryption protocol mobile ad hoc network message exchange key management protocol decryption;mobile ad hoc networks;cryptography;mobile radio;decryption;telecommunication security;key management protocol;ad hoc networks;mobile ad hoc network;bilinear pair computation;broadcast encryption;group key management;provably secure;broadcasting;identity based encryption broadcasting protocols ad hoc networks cryptography computer networks mobile ad hoc networks mobile communication laboratories computer science education;bilinear pairing;security;standard model group key generation protocol identity based encryption broadcast encryption provably secure	An identity-based broadcast encryption protocol for ad hoc networks is proposed. Whenever a new mobile ad hoc network is formed, the proposed protocol only requires each group member to broadcast his/her identity to construct the group key, which avoids a large number of message exchanges between group members like group key management protocols proposed previously. Hence it is highly efficient in terms of member removal to construct a new network. In addition, our protocol is also efficient in computation since the encryption and the decryption only require two bilinear pair computations. Furthermore, we show that the new protocol is provably secure under the standard model.	algorithmic efficiency;bilinear filtering;broadcast encryption;communications protocol;computation;cryptographic protocol;group key;hoc (programming language);key (cryptography);key management;provable security	Leyou Zhang;Yupu Hu;Ningbo Mu	2008	2008 The 9th International Conference for Young Computer Scientists	10.1109/ICYCS.2008.194	wireless routing protocol;wireless ad hoc network;optimized link state routing protocol;mobile ad hoc network;computer science;information security;ad hoc wireless distribution service;internet privacy;computer security;encryption;layer 2 tunneling protocol;computer network	Crypto	-47.90997936045925	76.78581957576462	165951
e7989caf7cb17901ef2d3c6182963e0044b38251	an attack on cfb mode encryption as used by openpgp	desciframiento;metodo adaptativo;openpgp;cle secrete;encryption;securite;cipher feedback mode;cryptanalyse;interrogation base donnee;interrogacion base datos;chosen ciphertext attacks;integrite;decryptage;methode adaptative;cifrado;integridad;16 bit processor;cryptanalysis;criptoanalisis;procesador 16 bits;integrity;cryptage;secret key;criptografia;clave secreta;cryptography;adaptive method;safety;decryption;integrity checking;cryptographie;seguridad;processeur 16 bits;database query;oracle;chosen ciphertext attack	This paper describes an adaptive-chosen-ciphertext attack on the Cipher Feedback (CFB) mode of encryption as used in OpenPGP. In most circumstances it will allow an attacker to determine 16 bits of any block of plaintext with about 2 oracle queries for the initial setup work and 2 oracle queries for each block. Standard CFB mode encryption does not appear to be affected by this attack. It applies to a particular variation of CFB used by OpenPGP. In particular it exploits an ad-hoc integrity check feature in OpenPGP which was meant as a “quick check” to determine the correctness of the decrypting symmetric key.	block cipher mode of operation;byte;ciphertext;correctness (computer science);cryptanalysis;encryption;hoc (programming language);plaintext;pretty good privacy;quickcheck;stream cipher;symmetric-key algorithm	Serge Mister;Robert J. Zuccherato	2005	IACR Cryptology ePrint Archive	10.1007/11693383_6	watermarking attack;computer science;distributed computing;internet privacy;computer security	Crypto	-43.645136200741206	78.59825766538694	166007
b207a5c1850d41ee1fe149fc7c498110f959c02f	two efficient proxy signature schemes for delegation chains with nonrepudiation and untraceability.	proxy signature			Starsky H. Y. Wong;Zoe Lin Jiang;Lucas Chi Kwong Hui;Siu-Ming Yiu	2009			computer science;mathematics	Crypto	-42.317819578173975	76.20279590710275	166018
9ad7f25f2559106a082d5452c03873becfbc3dd1	cryptanalysis and improvement of a certificateless partially blind signature	secure electronic cash system;public key cryptography digital signatures electronic money;security weakness;formal security proof;cryptanalysis;signer public key;e cash system;certificateless partially blind signature scheme;electronic coins;clpbs scheme;cryptanalysis electronic coins e cash system signer public key rescued scheme formal security proof security weakness clpbs scheme secure electronic cash system certificateless partially blind signature scheme;rescued scheme	Partially blind signature is an important technique in secure electronic cash (e-cash) system. The first concrete certificateless partially blind signature (CLPBS) scheme for e-cash was constructed in 2011. Recently it was found that this construction had a security weakness and a rescued scheme was given. Unfortunately, the formal security proof was not given. In this study, the authors first give cryptanalysis of their rescued scheme. They demonstrate that a malicious user in their rescued scheme can forge a signature on any message by replacing the signer's public key. In an e-cash system, blind signatures issued by the bank are viewed as e-cash. Once they apply their scheme to an untraceable e-cash system, a malicious user can forge valid electronic coins (i.e. valid signatures) without being detected by the bank. It will result in loss of the bank. Then, they propose a newly improved CLPBS scheme which achieves the strongest security level and has higher computational efficiency than the rescued scheme published earlier. Finally, they give an example of potential application to e-cash systems using their scheme.	blind signature;cryptanalysis	Lin Cheng;Qiaoyan Wen	2015	IET Information Security	10.1049/iet-ifs.2014.0293	cryptanalysis;mathematics;internet privacy;blind signature;world wide web;computer security;statistics	Crypto	-43.23061635717735	75.00175043781114	166264
66826935b6fdf9461c1714f15cf9ce049de878f8	revisiting yasuda et al.'s biometric authentication protocol: are you private enough?		Biometric Authentication Protocols ((mathsf {BAP})s) have increasingly been employed to guarantee reliable access control to places and services. However, it is well-known that biometric traits contain sensitive information of individuals and if compromised could lead to serious security and privacy breaches. Yasuda et al. [23] proposed a distributed privacy-preserving (mathsf {BAP}) which Abidin et al. [1] have shown to be vulnerable to biometric template recovery attacks under the presence of a malicious computational server. In this paper, we fix the weaknesses of Yasuda et al.’s (mathsf {BAP}) and present a detailed instantiation of a distributed privacy-preserving (mathsf {BAP}) which is resilient against the attack presented in [1]. Our solution employs Backes et al.’s [4] verifiable computation scheme to limit the possible misbehaviours of a malicious computational server.	access control;authentication protocol;biometrics;computation;formal verification;information sensitivity;server (computing);universal instantiation	Elena Pagnin;Jing Liu;Aikaterini Mitrokotsa	2017		10.1007/978-3-030-02641-7_8	computer security;verifiable secret sharing;theoretical computer science;access control;information sensitivity;computation;computer science;biometrics	Security	-42.64300172211845	75.2800191152932	166497
a6fcb30dfbebc9dc9c24c6ed5f4dbab846c8084e	flat and one-variable clauses for single blind copying protocols: the xor case	abelian group;cryptographic protocol;satisfiability;first order;associative commutative	In cryptographic protocols with the single blind copying restriction, at most one piece of unknown data is allowed to be copied in each step of the protocol. The secrecy problem for such protocols can be modeled as the satisfiability problem for the class of first-order Horn clauses called flat and one-variable Horn clauses, and is known to be DEXPTIME-complete. We show that when an XOR operator is additionally present, then the secrecy problem is decidable in 3-EXPTIME. We also note that replacing XOR by the theory of associativity-commutativity or by the theory of Abelian groups, or removing some of the syntactic restrictions on the clauses, leads to undecidability.	exclusive or	Helmut Seidl;Kumar Neeraj Verma	2009		10.1007/978-3-642-02348-4_9	combinatorics;discrete mathematics;computer science;first-order logic;cryptographic protocol;mathematics;abelian group;algorithm;satisfiability	Crypto	-37.03539319473304	75.69968673020608	166564
de6a9465bf927a6caa6d2fc5b2f8614750745c13	a tolerant algebraic side-channel attack on aes using cp		AES is a mainstream block cipher used in many protocols and whose resilience against attack is essential for cybersecurity. In [14], Oren and Wool discuss a Tolerant Algebraic Side-Channel Analysis (TASCA) and show how to use optimization technology to exploit side-channel information and mount a computational attack against AES. This paper revisits the results and posits that Constraint Programming is a strong contender and a potent optimization solution. It extends bit-vector solving as introduced in [8], develops a CP and an IP model and compares them with the original Pseudo-Boolean formulation. The empirical results establish that CP can deliver solutions with orders of magnitude improvement in both run time and memory usage, traits that are essential to potential adoption by cryptographers.	side-channel attack	Fanghui Liu;Waldemar Cruz;Chujiao Ma;Greg Johnson;Laurent D. Michel	2017		10.1007/978-3-319-66158-2_13	constraint programming;algebraic number;mathematical optimization;side channel attack;theoretical computer science;mount;cryptography;computer science;exploit;block cipher	Crypto	-36.067196273347115	82.83688169976188	166904
f9cd600227e82d88b1e69d1fc14fd432f8b2d123	analysis of id-based restrictive partially blind signatures and applications	id based restrictive partially blind signature;satisfiability;restrictiveness;cryptanalysis;cryptography;blind signature;bilinear pairing;partially blind signature	Partially blind signatures and restrictive blind signatures are two important techniques in electronic cash systems and voting systems. Restrictive partially blind signatures incorporate the advantages of these two blind signatures. Recently, Chen-Zhang-Liu first proposed an ID-based restrictive partially blind signature from bilinear pairings (Chen, X.F., Zhang, F.G., Liu, S.L., 2007. ID-based restrictive partially blind signatures and applications. The Journal of Systems and Software 80 (2), 164-171). However, in this paper, we show that Chen-Zhang-Liu's scheme has a security weakness. Their scheme does not satisfy the property of restrictiveness as they claimed, and an account-holder cannot be revealed when double-spending happens.	blind signature;electronic signature	Xiaoming Hu;Shangteng Huang	2008	Journal of Systems and Software	10.1016/j.jss.2008.01.013	cryptanalysis;computer science;cryptography;internet privacy;blind signature;world wide web;computer security;statistics;satisfiability	OS	-43.62918003560741	75.18290859611527	167182
d22b77732eda5c877bd0d21f8967e069e19d7d3c	revisiting the bge attack on a white-box aes implementation		White-box cryptography aims to protect the secret key of a cipher in an environment in which an adversary has full access to the implementation of the cipher and its execution environment. In 2002, Chow, Eisen, Johnson and van Oorschot proposed a white-box implementation of AES. In 2004, Billet, Gilbert and Ech-Chatbi presented an efficient attack (referred to as the BGE attack) on this implementation, extracting its embedded AES key with a work factor of 2. In 2012, Tolhuizen presented an improvement of the most time-consuming phase of the BGE attack. This paper presents several improvements to the other phases of the BGE attack. The paper shows that the overall work factor of the BGE attack is reduced to 2 when all improvements are implemented. In 2010, Karroumi presented a white-box AES implementation that is designed to withstand the BGE attack. This paper shows that the implementations of Karroumi and Chow et al. are the same. As a result, Karroumi’s white-box AES implementation is vulnerable to the attack it was designed to resist.	adversary (cryptography);byte;chow–liu tree;cipher;cryptography;embedded system;gilbert cell;key (cryptography);white box (software engineering);white-box testing	Yoni De Mulder;Peter Roelse;Bart Preneel	2013	IACR Cryptology ePrint Archive		cipher;implementation;cryptography;parallel computing;aes implementations;white box;adversary;computer science	Crypto	-35.983259316184075	80.69735255102198	167394
8f5133e723e0df34bb2814b4aed4a637c3c21cc0	development of security wlan protocol based on quantum ghz stats	802 11i;wlan;ghz stats;security	This paper addresses the security WLAN protocol based on Quantum Greenberger---Horne---Zeilinger stats to overcome the flaws of wired equivalent privacy, temporal key integrity protocol, counter mode with CBC-MAC protocol, IEEE802.11i protocol, and ensure wireless communication information security. Our main theorem have two important corollaries. The first is an ingenious application of quantum mechanics to apply in wireless communication theorem. The second is the proof of the protocol that Eve invariably introduces errors within communication network if it wants to gain useful information. Here the novel idea is that quantum cryptography guarantees the security of wireless communication information.	quantum	Hongyang Ma;Shumei Wang	2015	Wireless Personal Communications	10.1007/s11277-014-2003-9	wireless transport layer security;wi-fi;universal composability;ieee 802.11i-2004;telecommunications;computer science;information security;computer security;computer network	Mobile	-43.964422295067926	82.45829459965019	167396
4a9dc7953b9ccf90b4840d78985f5d56683f2059	constructive cryptography in hol				Andreas Lochbihler;S. Reza Sefidgar	2018	Archive of Formal Proofs		constructive;cryptography;theoretical computer science;hol;computer science	Crypto	-40.46816349255065	79.84463058334235	167429
b87452df1b7072f1e8f4c3c6d39b597e79320950	discrete logarithm based chameleon hashing and signatures without key exposure	discrete logarithm;journal;signature scheme;diffie hellman	Article history: Received 8 April 2010 Received in revised form 18 March 2011 Accepted 28 March 2011 Available online 6 May 2011 0045-7906/$ see front matter 2011 Elsevier Ltd doi:10.1016/j.compeleceng.2011.03.011 q Reviews processed and approved for publication ⇑ Corresponding author. E-mail address: xfchen@xidian.edu.cn (X. Chen). Chameleon signatures simultaneously provide the properties of non-repudiation and nontransferability for the signed message. However, the initial constructions of chameleon signatures suffer from the key exposure problem of chameleon hashing. This creates a strong disincentive for the recipient to compute hash collisions, partially undermining the concept of non-transferability. Recently, some constructions of discrete logarithm based chameleon hashing and signatures without key exposure are presented, while in the setting of gap Diffie–Hellman groups with pairings. In this paper, we propose the first key-exposure free chameleon hash and signature scheme based on discrete logarithm systems, without using the gap Diffie–Hellman groups. This provides more flexible constructions of efficient key-exposure free chameleon hash and signature schemes. Moreover, one distinguishing advantage of the resulting chameleon signature scheme is that the property of ‘‘message hiding’’ or ‘‘message recovery’’ can be achieved freely by the signer, i.e., the signer can efficiently prove which message was the original one if he desires. 2011 Elsevier Ltd. All rights reserved.	antivirus software;collision (computer science);diffie–hellman key exchange;digital signature;discrete logarithm;entity–relationship model;hash function;non-repudiation;requirement;zobrist hashing	Xiaofeng Chen;Fangguo Zhang;Haibo Tian;Baodian Wei;Kwangjo Kim	2011	Computers & Electrical Engineering	10.1016/j.compeleceng.2011.03.011	discrete logarithm;computer science;theoretical computer science;diffie–hellman key exchange;mathematics;distributed computing;internet privacy;algorithm	Crypto	-42.51382325724683	75.04556697314922	168015
3ab7612a30a18e897245da36e2f3ce91c0c8f630	an ecdlp-based threshold proxy signature scheme using self-certified public key system	security properties;public key;threshold proxy signature;communication cost;proxy signature;secret sharing scheme	In a ) , ( n t threshold proxy signature scheme, one original signer delegates a group of n proxy signers to sign messages on behalf of the original signer. When the proxy signature is created, at least t proxy signers cooperate to generate valid proxy signatures and any less than t proxy signers can’t cooperatively generate valid proxy signatures. So far, all of proposed threshold proxy signature schemes are based on public key systems with certificates, which have some disadvantages such as checking the certificate list when needing certificates. Most threshold proxy signature schemes use Shamir’s threshold secret share scheme. Identity-based public key system is not pretty mature. Self-certified public key systems have attracted more and more attention because of its advantages. Based on Hsu et al’s self-certified public key system and Li et al’s proxy signature scheme, one threshold proxy signature scheme based on ECDLP and self-certified public key system is proposed. As far as we know, it is the first scheme based on ECDLP and self-certified public key system. The proposed scheme can provide the security properties of proxy protection, verifiability, strong identifiability, strong unforgeability, strong repudiability, distinguishability, known signers and prevention of misuse of proxy signing power. That is, internal attacks, external attacks, collusion attacks, equation attacks and public key substitution attacks can be resisted. In the proxy signature verification phase, the authentication of the original and the proxy signers’ public keys and the verification of the threshold proxy signature are executed together. In addition, the computation overhead and communication cost of the proposed scheme are analyzed as well. * This paper is supported by the National Natural Science Foundation of China under Grant No. 60673079 and 60873217, and National Basic Research Program of China (973 Program) under Grant No.2007CB311100. An ECDLP-Based Threshold Proxy Signature Scheme 59	antivirus software;computation;deniable authentication;digital signature;elliptic curve cryptography;formal verification;key;overhead (computing);public-key cryptography	Qingshui Xue;Fengying Li;Yuan Zhou;Jiping Zhang;Zhenfu Cao;Haifeng Qian	2009		10.1007/978-3-642-04434-2_6	computer science;threshold cryptosystem;internet privacy;public-key cryptography;computer security	Security	-42.65211979461725	74.62453630663047	168126
7cc11ef464d83562eff03a7e1e899017cb1cecd5	taxonomical security consideration of oaep variants	tecnologia electronica telecomunicaciones;oaep;padding;reduction;saep;security proof;random oracle model;random oracle;provably secure;tecnologias;grupo a	We first model the variants of OAEP and SAEP by changing a construction and position of a redundancy, and establish a universal proof technique in the random oracle model, the comprehensive event dividing tree. We then make a taxonomical security consideration of the variants of OAEP and SAEP, based on the assumptions of one-wayness and partial-domain one-wayness of the encryption permutation, by applying the tree. Furthermore, we demonstrate the concrete attack procedures against all insecure schemes; we insist that the security proof failure leads to some attacks. From the security consideration, we find that one of the variants leads to a scheme without the redundancy; the scheme is not PA (plaintext aware) but IND-CCA2 secure. Finally, we conclude that some of them are practical in terms of security tightness and short bandwidth. key words: OAEP, SAEP, provably secure, reduction, Padding, random oracle	ciphertext indistinguishability;padding (cryptography);plaintext;plaintext-aware encryption;provable security;random oracle;taxonomy (general)	Yuichi Komano;Kazuo Ohta	2006	IEICE Transactions	10.1093/ietfec/e89-a.5.1233	random oracle;telecommunications;computer science;theoretical computer science;mathematics;computer security;algorithm	Crypto	-39.08445074106992	77.93994721704316	168273
05a7ba76247dc6f6385bbf4012e57fcf89a5865c	public key locally decodable codes with short keys	public key cryptography;bounded channel;locally decodable codes	This work considers locally decodable codes in the computationally bounded channel model. The computationally bounded channel model, introduced by Lipton in 1994, views the channel as an adversary which is restricted to polynomial-time computation. Assuming the existence of IND-CPA secure public-key encryption, we present a construction of public-key locally decodable codes, with constant codeword expansion, tolerating constant error rate, with locality O(λ), and negligible probability of decoding failure, for security parameter λ. Hemenway and Ostrovsky gave a construction of locally decodable codes in the public-key model with constant codeword expansion and locality O(λ), but their construction had two major drawbacks. The keys in their scheme were proportional to n, the length of the message, and their schemes were based on the Φ-hiding assumption. Our keys are of length proportional to the security parameter instead of the message, and our construction relies only on the existence of IND-CPA secure encryption rather than on specific number-theoretic assumptions. Our scheme also decreases the locality from O(λ) to O(λ). Our construction can be modified to give a generic transformation of any private-key locally decodable code to a public-key locally decodable code based only on the existence of an IND-CPA secure public-key encryption scheme.	adversary (cryptography);channel (communications);ciphertext indistinguishability;code (cryptography);code word;computation;computational complexity theory;cryptosystem;encryption;error detection and correction;forward error correction;locality of reference;locally decodable code;public-key cryptography;security parameter;symmetric-key algorithm;theory;time complexity	Brett Hemenway;Rafail Ostrovsky;Martin Strauss;Mary Wootters	2011	Electronic Colloquium on Computational Complexity (ECCC)	10.1007/978-3-642-22935-0_51	reed–muller code;combinatorics;discrete mathematics;theoretical computer science;locally decodable code;mathematics	Crypto	-37.01386531398962	77.19771252126735	168537
ddd5dafc989e143ad9b118dd8fa56af2dad0a3f7	a new knapsack public-key cryptosystem	public key cryptography;brute force attack resistance;decryption algorithm;construction process;simultaneous diophantine approximation attack;knapsack problems;high density;public key cryptography quantum computing proposals information security resists hardware computer security laboratories computer networks computer science education;public key cryptography computational complexity knapsack problems;public key cryptosystem;data mining;knapsack problem;diophantine approximation;lattice reduction;computational complexity;shamirs key recovery attack;low density attack invulnerability;approximation methods;low density;knapsack public key cryptosystem;hardware implementation knapsack public key cryptosystem shamirs key recovery attack low density attack invulnerability brute force attack resistance simultaneous diophantine approximation attack decryption algorithm software implementation;low density attack;proposals;hardware implementation;software implementation;lattice reduction public key cryptosystem knapsack problem low density attack	A new knapsack-type public key cryptosystem is proposed by constructing an easy knapsack problem. The cryptosystem is shown to be secure against Shamir's key-recovery attack in that it does not use a super-increasing knapsack sequence in the construction process. The cryptosystem is also invulnerable to low-density attack in that it obtains a relatively high density. It is shown that the cryptosystem resists some brute-force attacks and the simultaneous Diophantine approximation attack. It only performs n addition operations for the cryptosystem to encrypt a plaintext, and the decryption algorithm only carries out n modular 2 divisions. Therefore, the cryptosystem is efficient with respect to the encryption and the decryption. Furthermore, the cryptosystem is suited for software and hardware implementations.	algorithm;approximation;brute-force attack;ciphertext expansion;cryptosystem;encryption;key-recovery attack;knapsack cryptosystems;knapsack problem;plaintext;public-key cryptography	Weidong Zhang;Baocang Wang;Yupu Hu	2009	2009 Fifth International Conference on Information Assurance and Security	10.1109/IAS.2009.300	benaloh cryptosystem;paillier cryptosystem;timing attack;goldwasser–micali cryptosystem;plaintext-aware encryption;theoretical computer science;threshold cryptosystem;ggh encryption scheme;merkle–hellman knapsack cryptosystem;cryptosystem;mathematics;distributed computing;blum–goldwasser cryptosystem;hybrid cryptosystem;deterministic encryption;computer security;cramer–shoup cryptosystem	Crypto	-41.502005246188546	82.81065665768581	168646
67eb4767872a5b3dedb177a9ff40966b9e009358	some attacks upon authenticated group key agreement protocols	institutional repositories;fedora;vital;vtls;ils	During the last few years, a number of authenticated group key agreement protocols have been proposed in the literature. We observed that the efforts in this domain were mostly dedicated to the improvement of their performance in term of bandwidth or computational requirements, but that there were very few systematic studies on their security properties. In this paper, we tried to develop a systematic way to analyse protocol suites extending the Diffie-Hellman key-exchange scheme to a group setting and presented in the context of the Cliques project. This led us to propose a very simple machinery that allowed us to manually pinpoint several unpublished attacks against the main security properties claimed in the definition of these protocols (implicit key agreement, perfect forward secrecy, resistance to known-key attacks).	authentication;bandwidth (signal processing);computation;diffie–hellman key exchange;forward secrecy;group key;key-agreement protocol;known-key distinguishing attack;protocol stack;requirement	Olivier Pereira;Jean-Jacques Quisquater	2003	Journal of Computer Security		engineering;internet privacy;world wide web;computer security	Security	-41.84565897762031	75.67362857356954	168784
031a5760fda297f2b2f9efaaaf6181b07fcf9bf0	automated proofs for asymmetric encryption	security properties;asymmetric encryption;hoare logic;security proof;chosen ciphertext security;automated verification;random oracle model;provable cryptography	Many generic constructions for building secure cryptosystems from primitives with lower level of security have been proposed. Providing security proofs has also become standard practice. There is, however, a lack of automated verification procedures that analyze such cryptosystems and provide security proofs. In this paper, we present a sound and automated procedure that allows us to verify that a generic asymmetric encryption scheme is secure against chosen-plaintext attacks in the random oracle model. It has been applied to several examples of encryption schemes among which the construction of Bellare–Rogaway 1993, of Pointcheval at PKC’2000.	cryptosystem;encryption;mihir bellare;norton internet security;phillip rogaway;plaintext;public-key cryptography;random oracle	Judicaël Courant;Marion Daubignard;Cristian Ene;Pascal Lafourcade;Yassine Lakhnech	2010	Journal of Automated Reasoning	10.1007/s10817-010-9186-x	random oracle;computer security model;multiple encryption;h.235;40-bit encryption;plaintext-aware encryption;computer science;theoretical computer science;concrete security;provable security;ciphertext indistinguishability;optimal asymmetric encryption padding;internet privacy;public-key cryptography;disk encryption hardware;deterministic encryption;hoare logic;computer security;encryption;probabilistic encryption;56-bit encryption;attribute-based encryption	Crypto	-39.64846147796641	76.03271083741966	168801
31800f3ee5ce64e34e44e082431962af0a0050f1	preventing differential analysis in glv elliptic curve scalar multiplication	fast computation;public key cryptography;institutional repositories;difierential power analysis;smart card;cryptographie cle publique;power analysis;fedora;protocole transmission;elliptic curve;analyse differentielle;cryptographic protocol;courbe elliptique;multiplication scalaire;vital;calcul rapide;cryptosystem;protocolo transmision;curva eliptica;differential power analysis;cryptosysteme;vtls;elliptic curve cryptosystem;scalar multiplication;ils;analyse puissance;transmission protocol	In [2], Gallant, Lambert and Vanstone proposed a very efficient algorithm to compute Q = kP on elliptic curves having non-trivial efficiently computable endomorphisms. Cryptographic protocols are sensitive to implementations, indeed as shown in [6, 7] information about the secret can be revealed analysing external leakage of the support, typically a smart card. Several software countermeasures have been proposed to protect the secret. However, speed computation is needed for practical use. In this paper, we propose a method to protect scalar multiplication on elliptic curves against Differential Analysis, that benefits from the speed of the Gallant, Lambert and Vanstone method. It can be viewed as a two-dimensional analogue of Coron’s method [1] of randomising the exponent k. We propose two variants of this method (one linear and one affine), the second one slightly more effective, whereas the first one offers “two in one”, combining point-blinding and exponent randomisation, which have hitherto been dealt separately. For instance, for at most a mere 37.5% (resp. 25%) computation speed loss on elliptic curves over fields with 160 (resp. 240) bits the computation of kP can take on 2 different consumption patterns.	algorithm;blinding (cryptography);computable function;computation;cryptographic hash function;grating light valve;scalar processor;smart card;spectral leakage	Mathieu Ciet;Jean-Jacques Quisquater;Francesco Sica	2002		10.1007/3-540-36400-5_39	arithmetic;discrete mathematics;power analysis;computer science;mathematics;elliptic curve point multiplication;computer security;algorithm;statistics	Crypto	-40.231199532582394	81.48570860328391	169258
83e65a28a4f99c48871f8a381450112c024742db	s-box construction from non-permutation power functions	substitution box;redundancy removal algorithm;non permutation power functions;bijective s box;s box performance	A substitution box (s-box) is a nonlinear component function used in most block ciphers. It must fulfill several cryptographic properties such as high nonlinearity, low differential uniformity and complex algebraic expression to resist against linear, differential and interpolation attacks. In this paper, we extend and improve the s-box construction method proposed by Mamadolimov et al. [26, 27] which construct an s-box from power and binomial functions over the finite field F28. We study the cryptographic properties exhibited from our s-box and do a comparative analysis with several known 8X8 bijective s-boxes. Our analysis shows that our proposed s-box is ranked seventh compared to known 8X8 bijective s-boxes in terms of strong cryptographic properties. It even surpasses some known s-boxes used in popular block ciphers.	block cipher;circuit complexity;cryptography;interpolation;nonlinear system;qualitative comparative analysis;s-box	Herman Isa;Norziana Jamil;Muhammad Reza Z'aba	2013		10.1145/2523514.2523525	computer science;s-box;bijective proof;algorithm	Crypto	-38.67967866688243	82.30701265243162	169694
03b32202d0967a0430754446e7d602c201716e6e	analysis and improvement of lindell's uc-secure commitment schemes	commitment scheme	In 2011, Lindell proposed an efficient commitment scheme, with a non-interactive opening algorithm, in the Universal Composability (UC) framework. He recently acknowledged a bug in its security analysis for the adaptive case. We analyze the proof of the original paper and propose a simple patch of the scheme. More interestingly, we then modify it and present a more efficient commitment scheme secure in the UC framework, with the same level of security as Lindell’s protocol: adaptive corruptions, with erasures. The security is proven in the standard model (with a Common Reference String) under the classical Decisional Diffie-Hellman assumption. Our proposal is the most efficient UC-secure commitment proposed to date (in terms of computational workload and communication complexity).	algorithm;commitment scheme;common reference string model;communication complexity;decisional diffie–hellman assumption;interactivity;patch (computing);uc browser;universal composability	Olivier Blazy;Céline Chevalier;David Pointcheval;Damien Vergnaud	2013		10.1007/978-3-642-38980-1_34	commitment scheme;computer science;theoretical computer science;distributed computing;computer security	Crypto	-39.42001083762856	75.74491668049421	169862
56f1778e50cc5138bafd8bed0d987e7b9b23dba8	automated design of security protocols	automated design;ban logic;automated protocol synthesis;security protocols;simulated annealing;security protocol	Security protocols play an important role in modern communications. However, security protocol development is a delicate task, and experience shows that computer security protocols are notoriously difficult to get right. Recently, Clark and Jacob provided a framework for automatic protocol generation based on combinatorial optimization techniques and the symmetric key part of BAN logic. This paper shows how such an approach can be further developed to encompass the full BAN logic without loss of efficiency and thereby synthesize public key protocols and hybrid protocols.	burrows–abadi–needham logic;combinatorial optimization;computer security;cryptographic protocol;hybrid kernel;mathematical optimization;public-key cryptography;symmetric-key algorithm	Hao Chen;John A. Clark;Jeremy L. Jacob	2004	Computational Intelligence	10.1111/j.0824-7935.2004.00249.x	computer security model;universal composability;simulated annealing;computer science;theoretical computer science;wide mouth frog protocol;cryptographic protocol;security service;distributed computing;computer security	Security	-43.745370423348504	79.58843152184872	169910
23e9c67114da273fbab0e2fecc389baddd6c6b3b	id-based multi-party authenticated key agreement protocols from multilinear forms	public key cryptography;utilisation information;uso informacion;cryptographie cle publique;keyword;protocole transmission;cle privee;information use;authentication;securite informatique;cle publique;palabra clave;mot cle;long terme;long term;computer security;protocolo transmision;authenticated key agreement;public key;largo plazo;clave privada;private key;seguridad informatica;llave publica;id based;key agreement protocol;multilinear forms;tripartite;transmission protocol	Nalla and Reddy [6] presented new ID-based tripartite authenticated key agreement protocols from parings. Recently, Boneh and Silverberg [4] studied a one round multi-party key agreement protocols using the certificates from multilinear forms. In this paper, we propose new ID-based multi-party authenticated key agreement protocols, which use the identity information of a user as his long-term public/private key, from multilinear forms. Also, these protocols are extended to provide key confirmation.	authentication;key-agreement protocol;public-key cryptography	Hyung-Mok Lee;Kyung Ju Ha;Kyo-Min Ku	2005		10.1007/11556992_8	telecommunications;computer science;public-key cryptography;computer security	Crypto	-43.52378932227526	77.16442083835196	169990
691b645ec160b2c4e63e964c077fbe2ddbfefdf9	the doubling attack - why upwards is better than downwards	complexite;calculateur embarque;contre mesure electronique;elliptic curve;securite;implementation;cryptanalyse;complejidad;complexity;courbe elliptique;attaque;cryptanalysis;criptoanalisis;contra medida electronica;curva eliptica;safety;boarded computer;side channel attacks;modular exponentiation;attack;multiplicacion;electronic countermeasure;implementacion;multiplication;seguridad;calculador embarque	The recent developments of side channel attacks have lead implementers to use more and more sophisticated countermeasures in critical operations such as modular exponentiation, or scalar multiplication in the elliptic curve setting. In this paper, we propose a new attack against a classical implementation of these operations that only requires two queries to the device. The complexity of this so-called “doubling attack” is much smaller than previously known ones. Furthermore, this approach defeats two of the three countermeasures proposed by Coron at CHES ’99.	modular exponentiation;period-doubling bifurcation;side-channel attack	Pierre-Alain Fouque;Frédéric Valette	2003		10.1007/978-3-540-45238-6_22	cryptanalysis;attack;complexity;telecommunications;computer science;electronic countermeasure;side channel attack;mathematics;elliptic curve;implementation;computer security;multiplication;algorithm;modular exponentiation	Crypto	-40.41507152230068	81.47137268562945	170037
33f7c63c0fd12f4de4686115a0aaffbf4f8dedd0	key management schemes for stateless receivers based on time varying heterogeneous logical key hierarchy	reconfiguration;key management;methode diviser pour regner;optimisation;time varying;reconfiguracion;optimizacion;encryption;reconfigurable architectures;storage structure;metodo dividir para vencer;cifrado;time varying system;probleme recouvrement;couverture;cryptage;problema recubrimiento;parametre critique;criptografia;cryptography;almacenamiento;systeme parametre variable;diffusion donnee;divide and conquer method;parametro critico;difusion dato;stockage;logical key hierarchy;cryptographie;optimization;estructura memoria;broadcast encryption;coverage;structure memoire;sistema parametro variable;data broadcast;covering problem;storage;divide and conquer;architecture reconfigurable;critical parameter;cobertura	This paper proposes a family of key management schemes for broadcast encryption based on a novel underlying structure Time Varying Heterogeneous Logical Key Hierarchy (TVH-LKH). Note that the main characteristics of the previously reported key management schemes include the following: employment of a static underlying structure for key management, and addressing the subset covering problem over the entire underlying structure. Oppositely, the main underlying ideas for developing of the novel key management schemes based on TVH-LKH include the following: (i) employment of a reconfigurable underlying structure; and (ii) employment of a divide-and-conquer approach related to the underlying structure and an appropriate communications-storageprocessing trade-off (for example, a small increase of the communication overload and large reduction of the storage and processing overload) for addressing the subset covering problem and optimization of the overloads. The design is based on a set of ”static” keys at a receiver (stateless receiver) which are used in all possible reconfiguration of the underlying structure for key management, and accordingly, in a general case, a key plays different roles depending on the employed underlying structure. A particular family of the components for developing TVH-LKH, is also proposed and discussed. The proposed technique is compared with the recently reported schemes, and the advantages of the novel one are pointed out.	broadcast encryption;covering problems;key management;mathematical optimization;stateless protocol	Miodrag J. Mihaljevic	2003		10.1007/978-3-540-40061-5_9	telecommunications;computer science;cryptography;key management;mathematics;distributed computing;computer security;encryption;algorithm	ML	-47.73121611200897	78.3868336432803	170109
7a52b429b3c4eaf3cd02e9d8d8f99b0ba3d7727c	analysis of involutional ciphers: khazad and anubis	block ciphering;cryptage bloc;securite;cosic;cryptanalyse;cryptanalysis;european community;criptoanalisis;criptografia;cryptography;safety;cifrado en bloque;linear transformation;cryptographie;seguridad;large classes;structural properties;exhaustive search	In this paper we study structural properties of SPN ciphers in which both the S-boxes and the affine layers are involutions. We apply our observations to the recently designed Rijndael-like ciphers Khazad and Anubis, and show several interesting properties of these ciphers. We also show that 5-round Khazad has 2 weak keys under a “slide-witha-twist” attack distinguisher. This is the first cryptanalytic result which is better than exhaustive search for 5-round Khazad. Analysis presented in this paper is generic and applies to a large class of ciphers built from involutional components.	brute-force search;cipher;ciphertext;cryptanalysis;nessie;route distinguisher;s-box;substitution-permutation network;weak key	Alex Biryukov	2003		10.1007/978-3-540-39887-5_5	arithmetic;integral cryptanalysis;cryptanalysis;cryptography;mathematics;computer security;algorithm;statistics	Crypto	-40.27683402912396	81.05768325646386	170296
44e733f432501b45482898e2fac046fd458f47aa	novel steganographic schemes based on row-major mapping relation	data mining;steganography;steganography computer science engineering management security writing cryptography data mining robustness signal processing;cryptography;engineering management;signal processing;writing;robustness;computer science;security	This paper presents two concise novel steganographic schemes of strings comparing and formats converting based on the Row-Major Mapping Relation (RMMR). In general, the number of concealed secret bits( m) is far smaller than that of available host bits(n). Based on the property, we proved that if n \underline{\underline > } 2^m -1, the alteration rates of our proposed schemes are independent of n, and the alteration rates are close to m-1 when m is large. Even in the worst case that the amount of the secret bits is equal to that of the host bits and over half of the host bits are altered, our proposed scheme based on the Row-Major Mapping Relation with complement (RMMRwC) can decrease the alteration rate. From practical analyses and theoretical inductions, all results show that our novel schemes have advantages over steganography.	best, worst and average case;complement (complexity);experiment;steganography;string (computer science)	Chung-Chuan Wang;Chin-Chen Chang;Jinn-ke Jan;Jieh-Shan Yeh	2006	2006 International Conference on Intelligent Information Hiding and Multimedia	10.1109/IIH-MSP.2006.138	computer science;cryptography;theoretical computer science;signal processing;steganography;internet privacy;writing;computer security;algorithm;statistics;robustness	EDA	-36.17655971746949	79.48004108457754	170637
84747c8c08d06090d487bf88094e1d74747f360b	privacy preserving context transfer schemes for 4g networks	ngn;secure context transfer;cxtp;privacy preservation;secure handover;4g;privacy	In the near future, wireless heterogeneous networks are expected to interconnect in an all-IP architecture. An open issue towards this direction is the uninterrupted continuation of the received services during handover between networks employing different access technologies. In this context, Mobile IP (MIP) is a protocol that allows fast and secure handovers. However, MIP per se cannot handle all the issues that surface during handovers in certain services, and more specifically, when the information of the current state of a service requires re-establishment on the new subnet without having to repeat the entire protocol exchange with the mobile host from the outset. A number of methods have been proposed to solve the aforementioned problem, commonly referred to as secure context transfer. However, while such methods do succeed in minimising the disruption caused by security-related delays, it seems that little has been done to protect the end-users’ privacy as well. In this paper, a number of privacy enhanced (PE) context transfer schemes are presented. The first two of them have been introduced in a previous work of ours while the other two are novel. All schemes are analysed in terms of message exchange and evaluated through simulations. The performance of our schemes is compared with the standard ones proposed by the Seamoby work group (WG). The results demonstrate that the proposed schemes are very efficient in terms of application handover times, while at the same time guarantee the privacy of the end-user. Copyright © 2010 John Wiley & Sons, Ltd.	aaa (video game industry);adversary (cryptography);approximation algorithm;attack model;computer simulation;confidentiality;continuation;converge;cryptography;denial-of-service attack;elegant degradation;experiment;john d. wiley;mobile ip;privacy;subnetwork	Iosif Terzis;Georgios Kambourakis;Georgios Karopoulos;Costas Lambrinoudakis	2011	Wireless Communications and Mobile Computing	10.1002/wcm.1019	next-generation network;telecommunications;computer science;internet privacy;privacy;computer security;computer network	Security	-48.13835005541067	80.12628659544558	170680
81b57d821edfa64a4a37b8fca9a6d303136f7833	an efficient protocol for privately determining the relationship between two straight lines		Secure multiparty computation (SMC) is now a research focus in the international cryptographic community. SMC makes participants perform secure computation without revealing their own private data. In this paper, we discuss a secure computational geometry problem, that is, to privately determine whether two straight lines intersect. This is a basic and important SMC problem. Almost all protocols addressing this problem are applicable for integers, which limits their applications. So, we propose an efficient scheme for rational numbers. We proved that the protocol is secure under the semi-honest model by using the simulation paradigm. In addition, we propose a protocol which can be applied to space problems. This protocol can be used as a building block to construct new protocols to solve some space problems. Finally, we analyze the computational complexity and communication complexity of the protocol, and present an experimental result.		Ledi Fang;Shundong Li;Wenli Wang	2018	I. J. Network Security		computer network;computer science	Crypto	-40.26401831121844	74.64081424702074	170876
10f338868a3e4e6ffe3b35b8c4a847774b511f5e	identity based strong designated verifier parallel multi-proxy signature scheme	proxy signature	This paper presents a new identity based strong designated verifier parallel multiproxy signature scheme. Multi-Proxy signatures allow the original signer to delegate his signing power to a group of proxy signers. In our scheme, the designated verifier can only validate proxy signatures created by a group of proxy signer.	antivirus software;digital signature;identity creation	Sunder Lal;Vandani Verma	2009	CoRR		computer science	Crypto	-41.41254290527777	74.85992950770613	170952
cf81847f2e274502192705e98e332d393e13a7b1	public verifiability in the covert model (almost) for free		The covert security model (Aumann and Lindell, TCC 2007) offers an important security/efficiency trade-off: a covert player may arbitrarily cheat, but is caught with a certain fixed probability. This permits more efficient protocols than the malicious setting while still giving meaningful security guarantees. However, one drawback is that cheating cannot be proven to a third party, which prevents the use of covert protocols in many practical settings. Recently, Asharov and Orlandi (ASIACRYPT 2012) enhanced the covert model by allowing the honest player to generate a proof of cheating, checkable by any third party. Their model, which we call the PVC (publicly verifiable covert) model, offers a very compelling trade-off. Asharov and Orlandi (AO) propose a practical protocol in the PVC model, which, however, relies on a specific expensive oblivious transfer (OT) protocol incompatible with OT extension. In this work, we improve the performance of the PVC model by constructing a PVC-compatible OT extension as well as making several practical improvements to the AO protocol. As compared to the state-of-the-art OT extension-based two-party covert protocol, our PVC protocol adds relatively little: four signatures and an ≈ 67% wider OT extension matrix. This is a significant improvement over the AO protocol, which requires public-key-based OTs per input bit. We present detailed estimates showing (up to orders of magnitude) concrete performance improvements over the AO protocol and a recent malicious protocol.	ambient occlusion;antivirus software;asiacrypt;covert channel;formal verification;oblivious transfer;public-key cryptography	Vladimir Kolesnikov;Alex J. Malozemoff	2015		10.1007/978-3-662-48800-3_9		Security	-38.32553171102516	75.13284656159856	171133
0f9c2cda1496c57da1c1e0e2f993d7c39ddf5506	customizing cellular message encryption algorithm	cmea;cryptanalysis;wireless security;it security;differential cryptanalysis	This paper observes the cryptanalysis of the Telecommunications Industry Association’s Cellular Message Encryption Algorithm (CMEA). The CMEA has been widely used for wireless security and the breaking of the scheme proves the requirement of alternatives. In the current paper, the properties of CMEA which have lead to the successful cryptanalysis, have been identified. Accordingly the algorithm has been modified to prevent the attacks. Finally the customized CMEA has been subjected to standard linear and differential cryptanalysis to evaluate its security margin. The endeavour demonstrates that with appropriate modifications the CMEA can be transformed into a strong cipher, which is essential for wireless security.	algorithm;cipher;differential cryptanalysis;endeavour (supercomputer);wireless security	Debdeep Mukhopadhyay;Dipanwita Roy Chowdhury	2008	I. J. Network Security		block cipher;cryptanalysis;differential cryptanalysis;computer science;internet privacy;computer security;transmission security;computer network	Crypto	-45.609230184376685	74.53260116465445	171333
5bbd3805eec2445d0222c0a1227ac6e60fb6ef5f	constructing ideal secret sharing schemes based on chinese remainder theorem		Since (t, n)-threshold secret sharing (SS) was initially proposed by Shamir and Blakley separately in 1979, it has been widely used in many aspects. Later on, Asmuth and Bloom presented a (t, n)threshold SS scheme based on the Chinese Remainder Theorem (CRT) for integers in 1983. However, compared with the most popular Shamir’s (t, n)-threshold SS scheme, existing CRT based schemes have a lower information rate, moreover, they are harder to construct due to the stringent condition on moduli. To overcome these shortcomings of CRT based schemes, 1) we first propose a generalized (t, n)-threshold SS scheme based on the CRT for polynomial ring over a finite field. We show that our scheme is ideal, i.e., it is perfect in security and has the information rate 1. Comparison show that our scheme has a better information rate and is easier to construct compared with the existing threshold SS schemes based on the CRT for integers. 2) We prove that Shamir’s scheme, which is based on the Lagrange interpolation, is a special case of our scheme. Therefore, we establish the connection among threshold schemes based on the Lagrange interpolation, schemes based on the CRT for integers and our scheme. 3) As a natural extension of our threshold scheme, we present a weighted threshold SS scheme based on the CRT for polynomial rings, which inherits the above advantages of our threshold scheme over existing weighted schemes based on the CRT for integers.	cathode ray tube;george blakley;information theory;interpolation;lagrange multiplier;lagrange polynomial;polynomial remainder theorem;polynomial ring;secret sharing	Yu Ning;Fuyou Miao;Wenchao Huang;Keju Meng;Yan Xiong;Xingfu Wang	2018		10.1007/978-3-030-03332-3_12	discrete mathematics;computer science;chinese remainder theorem;polynomial ring;special case;lagrange polynomial;finite field;secret sharing;integer;code rate	Crypto	-37.147200787768426	83.85222635117181	171441
161bfce70d1e1a46fbcedbf8a91e8fa4d2a8a7b2	on vulnerabilities of the security association in the ieee 802.15.6 standard		Wireless Body Area Networks (WBAN) support a variety of real-time health monitoring and consumer electronics applications. The latest international standard for WBAN is the IEEE 802.15.6. The security association in this standard includes four elliptic curve-based key agreement protocols that are used for generating a master key. In this paper, we challenge the security of the IEEE 802.15.6 standard by showing vulnerabilities of those four protocols to several attacks. We perform a security analysis on the protocols, and show that they all have security problems, and are vulnerable to different attacks.	authentication;confidentiality;dictionary attack;elliptic curve cryptography;forward secrecy;key-agreement protocol;korea citation index;online and offline;privacy;public-key cryptography;real-time clock;security association	Mohsen Toorani	2015		10.1007/978-3-662-48051-9_18	computer security model;security association;ieee 802.11i-2004;security service;internet privacy;computer security;computer network	Security	-45.566821097354484	74.6377684005451	171450
8245cb49b633ae0132d7c64899b32110f1c993b5	mjh: a faster alternative to mdc-2	rate-1 hash function;hash function;key scheduling;non-trivial provable security;n-bit block;n-bit key blockcipher;n-bit key blockciphers;key blockcipher;double-blocklength hash function;double-length hash;provable security	In this paper, we introduce a new class of double-block-length hash functions. Using the ideal cipher model, we prove that these hash functions, dubbed MJH, are asymptotically collision resistant up to O(2n(1− ) query complexity for any > 0 in the iteration, where n is the block size of the underlying blockcipher. When based on n-bit key blockciphers, our construction, being of rate 1/2, provides better provable security than MDC-2, the only known construction of a rate-1/2 double-length hash function based on an n-bit key blockcipher with non-trivial provable security. Moreover, since key scheduling is performed only once per message block for MJH, our proposal significantly outperforms MDC-2 in efficiency. When based on a 2n-bit key blockcipher, we can use the extra n bits of key to increase the amount of payload accordingly. Thus we get a rate-1 hash function that is much faster than existing proposals, such as Tandem-DM with comparable provable security. This is the full version of [19].	block cipher;block size (cryptography);collision resistance;decision tree model;hash function;iteration;key schedule;mdc-2;provable security;scheduling (computing)	Jooyoung Lee;Martijn Stam	2011	IACR Cryptology ePrint Archive	10.1007/978-3-642-19074-2_15	hash function;perfect hash function;sha-2;collision resistance;theoretical computer science;provable security;mathematics;computer security;cryptographic hash function;mdc-2	Crypto	-37.936287678089535	78.00577853891974	171680
1a49cbf5bb79cdd8d4a6fbe4112c96dacbe10051	an all-but-one entropic uncertainty relation, and application to password-based identification	universiteitsbibliotheek	Entropic uncertainty relations are quantitative characterizations of Heisenberg’s uncertainty principle, which make use of an entropy measure to quantify uncertainty. In quantum cryptography, they are often used as convenient tools in security proofs. We propose a new entropic uncertainty relation. It is the first such uncertainty relation that lower bounds the uncertainty of all but one measurement outcome with respect to an arbitrary (and in particular an arbitrarily large) set of possible measurements, and, at the same time, uses the minentropy as entropy measure, rather than the Shannon entropy. This makes it especially suited for quantum cryptography. As application, we propose a new quantum identification scheme in the bounded quantum storage model. It makes use of our new uncertainty relation at the core of its security proof. In contrast to the original quantum identification scheme proposed by Damg̊ard et al., our new scheme also offers some security in case the bounded quantum storage assumption fails hold. Specifically, our scheme remains secure against an adversary that has unbounded storage capabilities but is restricted to single-qubit operations. The scheme by Damg̊ard et al., on the other hand, completely breaks down under such an attack.	adversary (cryptography);entropic uncertainty;entropy (information theory);identification scheme;password;provable security;quantum cryptography;qubit;shannon (unit);storage model;uncertainty principle	Niek J. Bouman;Serge Fehr;Carlos González-Guillén;Christian Schaffner	2012		10.1007/978-3-642-35656-8_3	discrete mathematics;computer science;calculus;entropic uncertainty;mathematics	Crypto	-36.4773459680509	76.45760799330759	171737
debcc67ba35014cd33d486943fe324c09e09e3ad	fast leakage assessment		We describe a fast technique for performing the computationally heavy part of leakage assessment, in any statistical moment (or other property) of the leakage samples distributions. The proposed technique outperforms by orders of magnitude the approach presented at CHES 2015 by Schneider and Moradi. We can carry out evaluations that before took 90 CPU-days in 4 CPU-hours (about a 500-fold speed-up). As a bonus, we can work with exact arithmetic, we can apply kernel-based density estimation methods, we can employ arbitrary pre-processing functions such as absolute value to power traces, and we can perform information-theoretic leakage assessment. Our trick is simple and elegant, and lends itself to an easy and compact implementation. We fit a prototype implementation in about 130 lines of C code.	casp;central processing unit;computation;information theory;preprocessor;prototype;spectral leakage;time complexity;tracing (software)	Oscar Reparaz;Benedikt Gierlichs;Ingrid Verbauwhede	2017		10.1007/978-3-319-66787-4_19	theoretical computer science;kernel (linear algebra);computer science;density estimation;leakage (electronics);orders of magnitude (numbers);absolute value;countermeasure		-34.53857426060793	79.35715642307065	171805
16d768ec1ab8b60c9926cfd10b129a8d71788941	attribute-based traitor tracing	desciframiento;collusion;modelizacion;controle acces;encryption;decryption device;asymmetry;attribute based encryption;access rights;decryptage;tracing;cifrado;traitor tracing;asymetrie;scenario;modelisation;colusion;cryptage;argumento;criptografia;cryptography;script;decryption;tracage;asimetria;cryptographie;access control;modeling;control de acceso;trazado	In this paper, we focus on traitor tracing scheme in attribute-based encryption (ABE) scenarios. A well-known concern in the setting of attribute-based encryption is that a user (or set of colluding users) can create a new key (or decryption device) by using his legal one and distribute it for malicious use. To mitigate this problem, we introduce the notion of attribute-based traitor tracing (ABTT). We formalize the definitions and security notions for attribute-based traitor tracing scheme, and then present a construction of ABTT. Our scheme makes use of the identity-based traitor tracing technology proposed by Abdalla et al., and is based on the second construction of Sahai-Waters’ attribute-based encryption schemes, but in the asymmetric bilinear setting. Our scheme is shown to be secure in the standard model under some reasonable assumptions. To the best of our knowledge, this is the first ABTT scheme up to now.	attribute-based encryption;bilinear filtering;ciphertext;code;knowledge engineering;public-key cryptography;tao;traceability;traitor tracing	Yong-Tao Wang;Ke-Fei Chen;Jian-Hong Chen	2011	J. Inf. Sci. Eng.		tracing;computer science;cryptography;access control;scenario;theoretical computer science;internet privacy;computer security;encryption;asymmetry	Crypto	-42.49943833347678	77.56595184530397	171811
1374c57975d2d476ae7f78487f737b0bffde9dd2	breaking four mix-related schemes based on universal re-encryption	desciframiento;anonymity;protocole transmission;encryption;building block;routing;securite informatique;re encryption mix networks;routage;cle publique;decryptage;cifrado;attaque informatique;anonymous communication;adulteration;anonymat;adulteracion;computer security;protocolo transmision;public key;cryptage;anonymous communications;criptografia;cryptography;seguridad informatica;decryption;llave publica;computer attack;traffic analysis;crowd;ataque informatica;cryptographie;multitud;mix network;foule;oracle;universal re encryption;anonimato;enrutamiento;transmission protocol	Universal Re-encryption allows El-Gamal ciphertexts to be re-encrypted without knowledge of their corresponding public keys. This has made it an enticing building block for anonymous communications protocols. In this work we analyze four schemes related to mix networks that make use of Universal Re-encryption and find serious weaknesses in all of them. The Universal Re-encryption of signatures is open to existential forgery, and the two mix schemes can be fully compromised by an passive adversary observing a single message close to the sender. The fourth scheme, the rWonGoo anonymous channel, turns out to be less secure than the original Crowds scheme, on which it is based. Our attacks make extensive use of unintended ‘services’ provided by the network nodes acting as decryption and re-routing oracles. Finally, our attacks against rWonGoo demonstrate that anonymous channels are not automatically composable: using two of them in a careless manner makes the system more vulnerable to attack.	adversary (cryptography);antivirus software;communications protocol;digital signature forgery;encryption;mix network;oracle machine;routing	George Danezis	2006		10.1007/11836810_4	telecommunications;engineering;internet privacy;computer security	Security	-43.072658658278066	76.58782052599263	171946
b8ed8bc23fac2336445d3378d0b185e3e117a709	the exact security of ecies in the generic group model	preuve programme;program proof;encryption;securite informatique;cifrado;computer security;cryptage;criptografia;cryptography;seguridad informatica;prueba programa;non standard interactions;cryptographie;model of computation	In this paper we analyse the ECIES encryption algorithm in the generic group model of computation. This allows us to remove the non-standard interactive intractability assumption of the proof of security given in the literature. This is done at the expense of requiring the generic group model of computation.	generic group model;integrated encryption scheme	Nigel P. Smart	2001		10.1007/3-540-45325-3_8	model of computation;computer science;cryptography;theoretical computer science;computer security;encryption;algorithm	Crypto	-41.60187521825968	78.04686389773215	172311
11ef2ff469931dac45e2c3a13b3117405aa8b3a0	an experimental study of kannan's embedding technique for the search lwe problem		The learning with errors (LWE) problem is considered as one of the most compelling candidates as the security base for the post-quantum cryptosystems. For the application of LWE based cryptographic schemes, the concrete parameters are necessary: the length n of secret vector, the moduli q and the deviation (sigma ). In the middle of 2016, Germany TU Darmstadt group initiated the LWE Challenge in order to assess the hardness of LWE problems. There are several approaches to solve the LWE problem via reducing LWE to other lattice problems. Xu et al.’s group solved some LWE Challenge instances using Liu and Nguyen’s adapted enumeration technique (reducing LWE to BDD problem) [14] and they published this result at ACNS 2017 [23]. In this paper, we study Kannan’s embedding technique (reducing LWE to unique SVP problem) to solve the LWE problem in the aspect of practice. The lattice reduction algorithm we use is the progressive BKZ [2, 3]. At first, from our experimental results we can intuitively observe that the embedding technique is more efficient with the embedding factor M closer to 1. Then especially for the cases of (sigma /q = 0.005), we will give an preliminary analysis for the runtime and give an estimation for the proper size of parameters. Moreover, our experimental results show that for (nge 55) and the fixed (sigma /q = 0.005), the embedding technique with progressive BKZ is more efficient than Xu et al.’s implementation of the enumeration algorithm in [21, 23]. Finally, by our parameter setting, we succeeded in solving the LWE Challenge over ((n,sigma /q)=(70,0.005)) using (2^{16.8}) s (32.73 single core hours).	learning with errors	Yuntao Wang;Yoshinori Aono;Tsuyoshi Takagi	2017		10.1007/978-3-319-89500-0_47	discrete mathematics;distributed computing;enumeration;lattice (order);learning with errors;embedding;computer science;cryptosystem;lattice problem;post-quantum cryptography;lattice reduction	Crypto	-38.238896802985444	78.64809854682905	172323
333ef3dbbce63bb66a57788ff6b8d50d3483f3d4	differential fault analysis on led using super-sbox	random byte fault;super sbox analysis;lightweight block cipher;nibble based fault model;fault pattern propagation rule;light emitting diode;light emitting diodes cryptography fault diagnosis;word length 64 bit;fault attack;led;word length 128 bit differential fault analysis light emitting diode led lightweight block cipher dfa super sbox analysis fault pattern propagation rule fault attack nibble based fault model early abort technique byte based fault model random byte fault word length 64 bit;dfa;early abort technique;differential fault analysis;byte based fault model;word length 128 bit	Light encryption device (LED) is a 64 bit lightweight block cipher proposed by Guo et al. at CHES 2011, and its key size is primarily defined as 64 and 128 bits. This study studies differential fault analysis (DFA) of LED using the technique of Super-Sbox analysis. Under various fault models, the fault pattern propagation rule of the Super-Sbox can be obtained, based on which the efficiency of fault attack on LED can be greatly improved. For LED-64, under the nibble-based fault model, a random nibble fault at the 30th round can reduce the size of key search space to 27–220 (average 214.02). Even if a random nibble fault is injected into the 29th round, the size of the key search space can also be reduced to about 217.43–217.72 (average 217.65) using early-abort technique. Although under the byte-based fault model, a random byte fault at the 30th round can reduce the size of the key space to 27–216 (average 211.92). If the adversary has the capability of injecting two random nibble faults at some specified rounds, then the above fault attack on LED-64 can be similarly extended to LED-128, and the size of the exhaustive search space for the 128 bit key can be reduced to 215–227.94 (average 221.96). These results demonstrate that Super-Sbox is a powerful technique that can be used to obtain significant improvements in the key filtration, and thus improve the efficiency of DFA on some special ciphers.	differential fault analysis;s-box;super smash bros.	Guangyao Zhao;Ruilin Li;Lei Cheng;Chunsheng Li;Bing Sun	2015	IET Information Security	10.1049/iet-ifs.2013.0549	embedded system;parallel computing;real-time computing;fault coverage;computer science;stuck-at fault;light-emitting diode	Crypto	-35.47774790698952	81.33892633429768	172362
edf655f10c5d7ce7d405b2e00b32adb723686a8d	fast and secure cbc-type mac algorithms	security analysis;message authentication code;omac;block cipher;construction cost;padding rule;prf security;cipher block chaining;cbc mac	CBC-MAC or cipher block chaining message authentication code is a well known method to generate message authentication code. Unfortunately, it is not forgery secure over arbitrary domain. There are several secure variants of CBC-MAC among which OMAC (or one-key CBC-MAC) is a widely used candidate. A simple variant of it called CMAC also has been recommended by NIST and is also used widely. Both of these cost (s+ 1) blockcipher invocations to authenticate an s-block message and it takes only one blockcipher key. In this paper we propose two secure and efficient variants of CBC-MAC. Our constructions cost only s blockcipher invocations to authenticate an s-block message (except for few single block messages, in which case it costs two blockcipher invocations like OMAC) and they need only one blockcipher key. If AES is plugged into these new constructions then they are significantly faster than OMAC for short messages, roughly twice faster for messages up to 125 bits and 1.5 times faster for messages up to 256 bits.	algorithm;block cipher mode of operation;cbc-mac;calculus of constructions;encryption;key size;message authentication code	Mridul Nandi	2009		10.1007/978-3-642-03317-9_23	weak key;substitution-permutation network;pmac;block cipher;transposition cipher;triple des;residual block termination;two-square cipher;running key cipher;ciphertext stealing;block cipher mode of operation;computer science;iso/iec 9797-1;galois/counter mode;stream cipher;affine cipher;internet privacy;cmac;computer security;cbc-mac;3-way;computer network;mdc-2	Crypto	-37.57870064784529	78.55763019111737	172428
c2e4508384e1109dc26b463e403f4f56914405b5	ad-hoc threshold broadcast encryption with shorter ciphertexts	ad hoc and dynamic groups;secret sharing;public key encryption;public key cryptosystem;public key;mobile ad hoc network;broadcast encryption;elgamal cryptosystem;threshold encryption	In a threshold broadcast encryption scheme, a sender chooses (ad-hoc) a set of n receivers and a threshold t, and then encrypts a message by using the public keys of all the receivers, in such a way that the original plaintext can be recovered only if at least t receivers cooperate. This kind of scheme has many applications in mobile ad-hoc networks, characterized by their lack of infrastructure as well as for the high dynamism of their nodes. Threshold broadcast encryption schemes are much more appropriate for mobile ad-hoc scenarios than standard threshold public key encryption schemes, where the set of receivers and the threshold for decryption must be known in advance (and remain the same for the rest of the protocol). Previously proposed threshold broadcast encryption schemes have ciphertexts which contain at least n group elements. In this paper, we propose a new scheme where the ciphertexts contain essentially n − t group elements. The construction uses secret sharing techniques and the ElGamal public key cryptosystem as basic tools. We formally prove the security of the scheme, by reduction to the security of ElGamal cryptosystem.	bilinear filtering;broadcast encryption;chosen-ciphertext attack;cryptosystem;hoc (programming language);plaintext;public-key cryptography;real life;secret sharing	Vanesa Daza;Javier Herranz;Paz Morillo;Carla Ràfols	2008	Electr. Notes Theor. Comput. Sci.	10.1016/j.entcs.2008.05.002	multiple encryption;goldwasser–micali cryptosystem;40-bit encryption;plaintext-aware encryption;client-side encryption;computer science;threshold cryptosystem;link encryption;mathematics;filesystem-level encryption;on-the-fly encryption;internet privacy;public-key cryptography;deterministic encryption;elgamal encryption;key distribution;computer security;cramer–shoup cryptosystem;encryption;probabilistic encryption;56-bit encryption;attribute-based encryption;computer network	Crypto	-41.58856300994515	75.13988803183366	172474
d05ad355699a68037a9483ebbd6cf9d751e77ffd	countermeasures against differential power analysis for hyperelliptic curve cryptosystems	public key cryptography;smart card;courbe hyperelliptique;pointage;calculateur embarque;contre mesure electronique;elliptic curve;securite;cryptanalyse;probabilistic approach;courbe elliptique;attaque;cryptanalysis;criptoanalisis;contra medida electronica;curva eliptica;criptografia;enfoque probabilista;cryptography;approche probabiliste;differential power analysis;safety;hyperelliptic curve cryptosystem;boarded computer;punteo;side channel attacks;cryptographie;attack;hyperelliptic curve;electronic countermeasure;picking;dierential power analysis;seguridad;calculador embarque;timing attack	In this paper we describe some countermeasures against dif- ferential side-channel attacks on hyperelliptic curve cryptosystems. The techniques are modelled on the corresponding ones for elliptic curves. The first method consists in picking a random group isomorphic to the one where we are supposed to compute, transferring the computation to the random group and then pulling the result back. The second method consists in altering the internal representation of the divisors on the curve in a random way. The impact of the recent attack of L. Goubin is assessed and ways to avoid it are proposed.	cryptosystem	Roberto Maria Avanzi	2003		10.1007/978-3-540-45238-6_29	arithmetic;smart card;cryptanalysis;attack;discrete mathematics;timing attack;jacobian curve;computer science;cryptography;electronic countermeasure;hyperelliptic curve cryptography;mathematics;elliptic curve;hyperelliptic curve;computer security;statistics	Crypto	-40.26571059099258	81.87143786011436	172596
10f95c344066c577a61e37e59164545321ec7e50	parallizable simple authenticated key agreement protocol	public key cryptography;provable security;algoritmo paralelo;cryptographie cle publique;acuerdo;parallel algorithm;protocole transmission;execution time;cryptanalyse;authentication;echange cle;agreement;parallel computation;algorithme parallele;authentification;cryptanalysis;criptoanalisis;protocolo transmision;authenticated key agreement;calculo paralelo;autenticacion;key exchange;mot de passe;criptografia;cryptography;password;parallel computer;cost effectiveness;cryptographie;temps execution;key agreement;password authentication;tiempo ejecucion;calcul parallele;accord;transmission protocol	Recently, Yeh and Sun proposed a simple authenticated key agreement protocol resistant to password guessing attacks called SAKA that is simple and cost-effective. And they provided a formal proof of security to show its strength against both passive and active adversaries. Compared with the previous well-known protocols, SAKA has less number of steps and less computation cost. However, considering the total execution time, SAKA is not the most efficient method, since it does not provide parties with parallel computation. In this paper, we present parallelizable simple authenticated key agreement protocol for improving the efficiency of the SAKA while maintaining provable security.	authentication;key-agreement protocol	Sung-Woon Lee;Woo-Hun Kim;Hyun-Sung Kim;Kee-Young Yoo	2003	Operating Systems Review	10.1145/769782.769784	computer science;authentication;distributed computing;computer security;algorithm	Crypto	-42.78470363752017	77.54943283245478	172612
d5b0af105be56c55434dcc42b26b8cab17d9a240	a novel template attack on wnaf algorithm of ecc	public key cryptography;power analysis;algorithm design and analysis elliptic curve cryptography buildings gaussian distribution correlation power demand;elliptic curve cryptography;sm2;scalar multiplication power analysis template attack sm2 wnaf public key decryption;public key decryption;wnaf;correlation;multiple countermeasures template attack wnaf algorithm ecc spa cpa dtta chinese public key cryptosystem standard side channel attack riscure platform smart ic card template matching phase template matching method multivariate normal distribution private key;power demand;algorithm design and analysis;scalar multiplication;gaussian distribution;buildings;template attack	Template attack is more powerful than SPA and CPA in some situations. In this paper, a novel template attack named DTTA is proposed to attack the wNAF algorithm of ECC. SM2 is the Chinese public key cryptosystem standard issued in 2010. Few results of side channel attack on SM2 have been found so far. We exploit the Riscure platform to analyze decryption of SM2 in a smart IC card. We also compare 3 kinds of method which used in template matching phase. Experiment results show that template matching method of multivariate normal distribution is superior to correlation method or LSM. The maximum success rate of template matching can be 88%. That means a 256-bit private key of SM2 can be recovered 225 bits by only acquiring one measurement of SM2 decryption in average. Some general countermeasures is not safe enough for DTTA. Defensive strategy should exploit the combination of multiple countermeasures to resist DTTA.	algorithm;blinding (cryptography);cost per action;cryptosystem;dummy variable (statistics);ecc memory;encryption;public-key cryptography;side-channel attack;smart card;spectral leakage;template matching	Zhenbin Zhang;Liji Wu;Zhaoli Mu;Xiangmin Zhang	2014	2014 Tenth International Conference on Computational Intelligence and Security	10.1109/CIS.2014.66	normal distribution;algorithm design;power analysis;computer science;theoretical computer science;scalar multiplication;elliptic curve cryptography;internet privacy;public-key cryptography;computer security;correlation;statistics	Security	-39.56206556338657	84.37138271972707	172660
2702a2ff58339e8d619316f39143be85280d29ba	localisation and obfuscation techniques for enhanced multi-factor authentification in mcommerce applications			authentication;mobile commerce	Torben Kuseler	2012				Crypto	-44.964802496206005	75.9875464154622	172710
2e080895eab2ce1dc2c00318005a06e0828c6a5e	a framework for universally composable non-committing blind signatures	adaptive security;universal composability;blind signatures	This paper studies non-committing type of universally composable (UC) blind signature protocols where an adversary does not necessarily commit to a message when requesting a signature. An ordinary UC blind signature functionality requires users to commit to the message to be blindly signed. It is thereby impossible to realise in the plain model. This paper first shows that even non-committing variants cannot be realised in the plain model. We then characterise UC non-committing blind signatures in the common reference string model by presenting equivalent stand-alone security notions under static corruption. The usefulness of the characterisation is demonstrated by showing that Fischlin’s basic stand-alone blind signature scheme can be transformed into a UC non-committing blind signature protocol without using extra cryptographic components. We extend the results to the adaptive corruption model and present analogous notions, theorems, and constructions both in the erasure model and the non-erasure model.	adversary (cryptography);antivirus software;blind signature;common reference string model;cryptography;digital signature;electronic signature;signature block;uc browser;universal composability	Masayuki Abe;Miyako Ohkubo	2009	IACR Cryptology ePrint Archive	10.1504/IJACT.2012.045581	universal composability;computer science;distributed computing;internet privacy;blind signature;computer security	Crypto	-39.63931285905089	75.2972136478754	172961
dcc3b4ee9937ddb526a0a458ee309f3c3b5a45a8	side-channel attacks in ecc: a general technique for varying the parametrization of the elliptic curve	salida;diseno circuito;calculateur embarque;procesamiento informacion;curva ennegrecimiento;side channel attack;elliptic curve;circuit design;parameterization;characteristic curve;fuite;general techniques;courbe elliptique;parametrizacion;elliptic curve cryptography;curva eliptica;criptografia;cryptography;information processing;leak;boarded computer;side channel attacks;courbe noircissement;cryptographie;conception circuit;traitement information;calculador embarque;parametrisation;attaque canal lateral	Side-channel attacks in elliptic curve cryptography occur with the unintentional leakage of information during processing. A critical operation is that of computing nP where n is a positive integer and P is a point on the elliptic curve E. Implementations of the binary algorithm may reveal whether P +Q is computed for P 6= Q or P = Q as the case may be. Several methods of dealing with this problem have been suggested. Here we describe a general technique for producing a large number of different representations of the points on E in characteristic p ≥ 5, all having a uniform implementation of P + Q. The parametrization may be changed for each computation of nP at essentially no cost. It is applicable to all elliptic curves in characteristic p ≥ 5, and thus may be used with all curves included in present and future standards for p ≥ 5.	algorithm;computation;ecc memory;elliptic curve cryptography;np (complexity);spectral leakage	Loren D. Olson	2004		10.1007/978-3-540-28632-5_16	supersingular elliptic curve;discrete mathematics;jacobian curve;information processing;tripling-oriented doche–icart–kohel curve;counting points on elliptic curves;side channel attack;mathematics;geometry;hessian form of an elliptic curve;elliptic curve point multiplication;algorithm;schoof's algorithm	Crypto	-40.09464582802732	81.71760944810421	173116
42a45e590c6c54ae2515118b891be9ed82eb1a77	secure simultaneous bit extraction from koblitz curves		Secure pseudo-random number generators (PRNGs) have a lot of important applications in cryptography. In this paper, we analyze a new PRNG related to the elliptic curve power generator. The new PRNG has many desirable randomness properties such as long period, uniform distribution, etc. In particular, the proposed PRNG is provably secure under the l-strong Diffie–Hellman assumptions. An important feature of our PRNG is that many bits can be simultaneously output without significantly affecting its security. For instance, at 150-bit security, more than 100 bits can be output at each iteration, with a statistical distance from a uniform sequence less than (1/2^{150}). Our experimental results show that the new PRNG provides a secure and flexible solution for high security applications. Hence, our work is another step towards the construction of provably secure PRNGs in practice.		Xinxin Fan;Guang Gong;Berry Schoenmakers;Francesco Sica;Andrey Sidorenko	2019	Des. Codes Cryptography	10.1007/s10623-018-0484-3	statistical distance;randomness;discrete mathematics;mathematics;cryptography;elliptic curve;pseudorandom number generator;uniform distribution (continuous)	Crypto	-38.027750735386256	79.44723994537144	173288
362d1bf46a749b6c7eb73a87476734c8dee489ed	an algebraic framework for diffie–hellman assumptions	generic hardness;public key encryption;hash proof systems;groth sahai proofs;article;diffie hellman assumption	We put forward a new algebraic framework to generalize and analyze Diffie–Hellman like decisional assumptions which allows us to argue about security and applications by considering only algebraic properties. Our $$\mathcal {D}_{\ell ,k}\text{- }\textsf {MDDH}$$ D ℓ , k - MDDH Assumption states that it is hard to decide whether a vector in $$\mathbb {G}^\ell $$ G ℓ is linearly dependent of the columns of some matrix in $$\mathbb {G}^{\ell \times k}$$ G ℓ × k sampled according to distribution $$\mathcal {D}_{\ell ,k}$$ D ℓ , k . It covers known assumptions such as $$\textsf {DDH},\, 2\text{- }\textsf {Lin}$$ DDH , 2 - Lin (Linear Assumption) and $$k\text{- }\textsf {Lin}$$ k - Lin (the k-Linear Assumption). Using our algebraic viewpoint, we can relate the generic hardness of our assumptions in m-linear groups to the irreducibility of certain polynomials which describe the output of $$\mathcal {D}_{\ell ,k}$$ D ℓ , k . We use the hardness results to find new distributions for which the $$\mathcal {D}_{\ell ,k}\text{- }\textsf {MDDH}$$ D ℓ , k - MDDH Assumption holds generically in m-linear groups. In particular, our new assumptions $$2\text{- }\textsf {SCasc}$$ 2 - SCasc and $$2\text{- }\textsf {ILin}$$ 2 - ILin are generically hard in bilinear groups and, compared to $$2\text{- }\textsf {Lin}$$ 2 - Lin , have shorter description size, which is a relevant parameter for efficiency in many applications. These results support using our new assumptions as natural replacements for the $$2\text{- }\textsf {Lin}$$ 2 - Lin assumption which was already used in a large number of applications. To illustrate the conceptual advantages of our algebraic framework, we construct several fundamental primitives based on any $$\textsf {MDDH}$$ MDDH Assumption. In particular, we can give many instantiations of a primitive in a compact way, including public-key encryption, hash proof systems, pseudo-random functions, and Groth–Sahai NIZK and NIWI proofs. As an independent contribution, we give more efficient NIZK and NIWI proofs for membership in a subgroup of $$\mathbb {G}^\ell $$ G ℓ . The results imply very significant efficiency improvements for a large number of schemes.	bilinear filtering;column (database);decisional diffie–hellman assumption;diffie–hellman problem;encryption;irreducibility;linear algebra;local interconnect network;non-interactive zero-knowledge proof;polynomial;pseudorandomness;public-key cryptography	Alex Escala;Gottfried Herold;Eike Kiltz;Carla Ràfols;Jorge Luis Villar	2013	Journal of Cryptology	10.1007/s00145-015-9220-6	combinatorics;discrete mathematics;computer science;mathematics;public-key cryptography;computer security;algorithm;statistics;algebra	Crypto	-38.81028221908041	76.78260295923292	173437
0eeb318069150e52858214198ce5449e348f406c	analysis of sha-1 in encryption mode	text;encryption;cryptographic hash function;block cipher;cryptanalyse;texte;cryptanalysis;temps calcul;cryptage;criptografia;cryptography;cryptanalyse differentielle;cryptographie;tiempo computacion;computation time;texto	This paper analyses the cryptographic hash function SHA1 in encryption mode. A detailed analysis is given of the resistance of SHA-1 against the most powerful known attacks today. It is concluded that none of these attacks can be applied successfully in practice to SHA-1. Breaking SHA-1 in encryption mode requires either an unrealistic amount of computation time and known/chosen texts, or a major breakthrough in cryptanalysis. The original motivation for this analysis is to investigate a block cipher named SHACAL based on these principles. SHACAL has been submitted to the NESSIE call for cryptographic primitives.	approximation;block cipher mode of operation;brute-force search;computation;cryptographic hash function;cryptographic primitive;cryptography;differential cryptanalysis;encryption;hoc (programming language);known-plaintext attack;linear cryptanalysis;nessie;plaintext;sha-1;time complexity	Helena Handschuh;Lars R. Knudsen;Matthew J. B. Robshaw	2001		10.1007/3-540-45353-9_7	cryptographic primitive;block cipher;cryptanalysis;computer science;cryptography;theoretical computer science;computer security;encryption;algorithm;cryptographic hash function	Crypto	-40.964803811973624	81.09583943702074	173690
df6320e851f58bfffa4ae675c53cf722ea5d620a	rchb: light-weight, provably-secure variants of the hb protocol using rotation and complementation	protocols;passive attacks;lpn problem;protocols entropy authentication cryptography logic gates radiofrequency identification;hb protocol;authentication;cryptographic protocols;secure;rfid tags;rfid tags hb protocol lpn problem secure authentication protocol passive attacks;rfid tags light weight provably secure authentication protocols linear code decoding rchb protocol family secret key passive attack security prover verifier complexity low cost devices;logic gates;cryptography;entropy;radiofrequency identification;authentication protocol	In this paper, we propose a family of light-weight provably-secure authentication protocols called the RCHB family, which is a variant of the HB protocol. The HB protocol uses the complexity of decoding linear codes for security against passive attacks. The security for the RCHB protocol family to passive attacks is enhanced by the introduction of both the rotation and complement on the secret key. We demonstrate that the existing passive attacks on the HB protocol family, which have contributed to considerable reduction in its effective key-size, do not work against RCHB. Thus, smaller-key sizes are sufficient for RCHB protocols to achieve the same level of passive attack security as the HB Protocol. Furthermore, we provide implementation instances of RCHB family protocols for which the Prover/Verifier complexity is much lower than the HB protocol, enabling authentication on very low-cost devices like RFID tags.	64-bit computing;authentication protocol;chumby;code;communications protocol;computers in human behavior;key (cryptography);key size;passive attack;protocol stack;provable security;radio-frequency identification;shift register	Samia A. Ali;Refaat M. Mohamed;Mahmoud H. Fahim	2011	2011 5th International Conference on Network and System Security	10.1109/ICNSS.2011.6060008	entropy;computer science;cryptography;authentication protocol;authentication;distributed computing;internet privacy;computer security	Security	-40.2744011034115	78.21838167860489	173871
efb8ecaa6e7cf24abc4fec5eac21ef6bd8e62819	completely non-malleable encryption revisited	liverpool;man in the middle attack;public key encryption;repository;public key;university	Several security notions for public-key encryption schemes have been proposed so far, in particular considering the powerful adversary that can play a so called “man-in-the-middle” attack. In this paper we extend the notion of completely non-malleable encryption introduced in [Fischlin, ICALP 05]. This notion immunizes a scheme from adversaries that can generate related ciphertexts under new public keys. This notion is motivated by its powerful features when encryption schemes are used as subprotocols. While in [Fischlin, ICALP 05] the only notion of simulation-based completely non-malleable encryption with respect to CCA2 adversaries was given, we present new game-based definitions for completely non-malleable encryption that follow the standard separations among NM-CPA, NM-CCA1 and NM-CCA2 security given in [Bellare et al., CRYPTO 98]. This is motivated by the fact that in several cases, the simplest notion we introduce (i.e., NM-CPA*) in several cases suffices for the main application that motivated the introduction of the notion of NM-CCA2* security, i.e., the design of non-malleable commitment schemes. Further the game-based definition of NM-CPA* security actually implies the simulation-based one. We then focus on constructing encryption schemes that satisfy these strong security notions and show: 1) an NM-CCA2* secure encryption scheme in the shared random string model; 2) an NM-CCA2* secure encryption scheme in the plain model; for this second result, we use interaction and non-black-box techniques to overcome an impossibility result. Our results clarify the importance of these stronger notions of encryption schemes and show how to construct them without requiring random	adversary (cryptography);black box;chosen-ciphertext attack;encryption;icalp;malleability (cryptography);man-in-the-middle attack;mihir bellare;public-key cryptography;simulation	Carmine Ventre;Ivan Visconti	2008		10.1007/978-3-540-78440-1_5	computer science;internet privacy;public-key cryptography;computer security	Crypto	-38.8076138109963	75.6864639549819	173930
83e9fb8309973173832ecdd9fd6b1aa8404d5085	some experimental observations on the behavior of composite random number generators	random number generator;technical report departmental;historical collection till dec 2001	We describe a series of experiments with composite random number generators using shuffling tables. The research explores the issues of improvement in statistical behavior claimed for composite generators and the overhead incurred by shuffling. On the basis of the limited experimental work, three observations are warranted: 1 Shuffling does not effect significant improvement in the statistical behavior of good simple generators implemented on large-word-length machines with large periods. 2 Shuffling can significantly improve the behavior of generators on small-word-length machines, at least partly by increasing the maximum period obtained. 3 A table size of two leads to results comparable with larger tables and incurs less overhead.	random number generator attack	Richard E. Nance;Claude Overstreet	1978	Operations Research	10.1287/opre.26.5.915	computer science;operations management;algorithm;statistics	Theory	-34.32697972001927	79.5998798990802	174909
f291fb85c9538c6a18b0b120be3e063a75955f73	security proof of identity-based signature under rsa assumption, reconsidered	silicon;protocols;standards;computational modeling;public key;probabilistic logic	No direct security proof of Shamir's identity-based signature (Shamir-IBS) is known, as far as we know. In EU-ROCRYPT2004, Bellare et al. introduce a generic conversion to IBS from standard identification, and the security of the Shamir-IBS is indirectly proved from the RSA assumption with the conversion. However, in the indirect security proof, the gap between advantages of the RSA problem and the scheme may be larger than proving the security directly from the RSA assumption. In this paper, we give a direct security proof of the Shamir-IBS. We show a comparison between reduction costs of the indirect and direct security proofs. As a result, in a practical parameter setting, the direct proof is better than the indirect proof. By improving the reduction cost, the parameter size which is required to achieve the same bit-security is reduced.	mihir bellare;provable security;rsa problem	Shogo Kimura;Kazuki Yoneyama	2016	2016 International Symposium on Information Theory and Its Applications (ISITA)		communications protocol;discrete mathematics;computer science;mathematics;probabilistic logic;public-key cryptography;silicon;computational model;computer security;proof complexity;algorithm	Crypto	-39.40934157263987	76.58015874279504	175310
3eb7b3b07a1e43faeda1a1dbeee9f6656e617a30	improved meet-in-the-middle attacks on 7 and 8-round aria-192 and aria-256	aria;block cipher;multiset attack;key recovery;differential characteristic	The ARIA block cipher has been established as a Korean encryption standard by Korean government since 2004. In this work, we re-evaluate the security bound of reduced round ARIA-192 and ARIA-256 against meet-in-the-middle MITM key recovery attacks in the single key model. We present a new 4-round distinguisher to demonstrate the best 7 & 8 round MITM attacks on ARIA-192/256. Our 7-round attack on ARIA-192 has data, time and memory complexity of $$2^{113}$$, $$2^{135.1}$$ and $$2^{130}$$ respectively. For our 7-round attack on ARIA-256, the data/time/memory complexities are $$2^{115}$$, $$2^{136.1}$$ and $$2^{130}$$ respectively. These attacks improve upon the previous best MITM attack on the same in all the three dimensions. Our 8-round attack on ARIA-256 requires $$2^{113}$$ cipher calls and has time and memory complexity of $$2^{245.9}$$ and $$2^{138}$$ respectively. This improves upon the previous best MITM attack on ARIA-256 in terms of time as well as memory complexity. Further, in our attacks, we are able to recover the actual secret key unlike the previous cryptanalytic attacks existing on ARIA-192/256. To the best of our knowledge, this is the first actual key recovery attack on ARIA so far. We apply multiset attack - a variant of meet-in-the-middle attack to achieve these results.		Akshima;Donghoon Chang;Mohona Ghosh;Aarushi Goel;Somitra Kumar Sanadhya	2015		10.1007/978-3-319-26617-6_11	block cipher;computer science;mathematics;internet privacy;computer security;algorithm;statistics	Crypto	-37.894761486804285	78.20104961232033	176064
607f43ea79dc342f8c57d9c25c8bcc944e8561d3	more efficient structure-preserving signatures - or: bypassing the type-iii lower bounds		Structure-preserving signatures are an important cryptographic primitive that is useful for the design of modular cryptographic protocols. It has been proven that structure-preserving signatures (in the most efficient Type-III bilinear group setting) have a lower bound of 3 group elements in the signature (which must include elements from both source groups) and require at least 2 pairing-product equations for verification. In this paper, we show that such lower bounds can be circumvented. In particular, we define the notion of Unilateral Structure-Preserving Signatures on Diffie-Hellman pairs (USPSDH) which are structure-preserving signatures in the efficient TypeIII bilinear group setting with the message space being the set of Diffie-Hellman pairs, in the terminology of Abe et al. (Crypto 2010). The signatures in these schemes are elements of one of the source groups, i.e. unilateral, whereas the verification key elements’ are from the other source group. We construct a number of new structure-preserving signature schemes which bypass the Type-III lower bounds and hence they are much more efficient than all existing structure-preserving signature schemes. We also prove optimality of our constructions by proving lower bounds and giving some impossibility results. Our contribution can be summarized as follows: • We construct two optimal randomizable CMA-secure schemes with signatures consisting of only 2 group elements from the first short source group and therefore our signatures are at least half the size of the best existing structure-preserving scheme for unilateral messages in the (most efficient) Type-III setting. Verifying signatures in our schemes requires, besides checking the well-formedness of the message, the evaluation of a single Pairing-Product Equation (PPE) and requires a fewer pairing evaluations than all existing structure-preserving signature schemes in the Type-III setting. Our first scheme has a feature that permits controlled randomizability (combined unforgeability) where the signer can restrict some messages such that signatures on those cannot be re-randomized which might be useful for some applications. • We construct optimal strongly unforgeable CMA-secure one-time schemes with signatures consisting of 1 group element, and which can also sign a vector of messages while maintaining the same signature size. • We give a one-time strongly unforgeable CMA-secure structure-preserving scheme that signs unilateral messages, i.e. messages in one of the source groups, whose efficiency matches the best existing optimal one-time scheme in every respect. • We investigate some lower bounds and prove some impossibility results regarding this variant of structure-preserving signatures. • We give an optimal (with signatures consisting of 2 group elements and verification requiring 1 pairing-product equation) fully randomizable CMA-secure partially structure-preserving scheme that simultaneously signs a Diffie-Hellman pair and a vector in Zp. • As an example application of one of our schemes, we obtain efficient instantiations of randomizable weakly blind signatures which do not rely on random oracles. The latter is a building block that is used, for instance, in constructing Direct Anonymous Attestation (DAA) protocols, which are protocols deployed in practice. Our results offer value along two fronts: On the practical side, our constructions are more efficient than existing ones and thus could lead to more efficient instantiations of many cryptographic protocols. On the theoretical side, our results serve as a proof that many of the lower bounds for the Type-III setting can be circumvented.	antivirus software;bilinear filtering;blind signature;cma-es;computational diffie–hellman assumption;cryptographic primitive;cryptographic protocol;cryptography;diffie–hellman key exchange;direct anonymous attestation;electronic signature;power processing element;randomized algorithm;type signature;whole earth 'lectronic link	Essam Ghadafi	2016		10.1007/978-3-319-66399-9_3	computer security;direct anonymous attestation;cryptographic primitive;distributed computing;theoretical computer science;workaround;cryptographic protocol;modular design;bilinear interpolation;computer science;upper and lower bounds	Crypto	-38.877756537231775	76.22974049799005	176072
867f8494b14dd743eee5ae614e2d57e92ded6296	enhancement on strongly secure group key agreement	ephemeral secret leakage;signature;group key agreement	In 2011, Zhao et al. presented a new security model of group key agreement (GKA) by considering ephemeral secret leakage (ESL) attacks. Meanwhile, they proposed a strongly secure GKA protocol under the new model. In this paper, two security weaknesses on their protocol are pointed out and remedied, in which, their GKA protocol must rely on a signature scheme with existential unforgeability under adaptive chosen message attacks (UF-ACMA) to achieve the security goals of authenticated key exchange and mutual authentication in the new model. We argue and illustrate that a UF-ACMA secure signature scheme is insufficient to promise the security goals because the employed signature scheme does not consider the ESL attacks. For providing authentication functionality of some future cryptographic mechanisms (e.g., authenticated GKA protocols, authenticated key agreement protocols, and authentication schemes) resistant to the ESL attacks, we define a novel security notion for digital signature schemes, termed existential UF-ACM and ephemeral secret leakage attacks. On the basis of Schnorr’s signature scheme, we propose the first UF-ACM and ephemeral secret leakage attacks secure signature scheme. We demonstrate that the proposed scheme is provably secure under the hardness of computing discrete logarithms in the random oracle model. Copyright © 2014 John Wiley & Sons, Ltd.	authenticated key exchange;bilinear filtering;cryptography;digital signature;discrete logarithm;group key;john d. wiley;key-agreement protocol;mutual authentication;provable security;random oracle;spectral leakage;type signature	Yuh-Min Tseng;Tung-Tso Tsai;Sen-Shan Huang	2015	Security and Communication Networks	10.1002/sec.964	computer science;distributed computing;signature;internet privacy;schnorr signature;computer security	Security	-42.135219926010095	75.43850953652212	176144
b43b43865dcb47583f9041e24390c19c54f3414a	a new practical limited identity-based encryption scheme	identity based encryption;chosen plaintext security;identity based cryptography;email system;limited identity based encryption	Identity based cryptography was introduced by Shamir in 1984, which avoids the trust problems encountered in the traditional Public Key Infrastructures. After Boneh and Franklin proposed the first full functional identity based encryption scheme from the bilinear pairings in 2001, many other identity based schemes using pairings have been proposed. However, how to design a practical identity based encryption scheme that avoids using the pairings is still an open problem today. In this paper, after studying and combining the advantages of the traditional public key system and identity based system, we formally define a new Limited identity based system and present a concrete Limited identity based encryption scheme on a different complexity assumption. The resulting scheme is not only provably secure against the chosen plaintext attack in the random oracle, but also especially suitable for some practical system, such as an email system.	id-based encryption	Rongxing Lu;Zhenfu Cao;Xiaolei Dong	2007	Fundam. Inform.		multiple encryption;watermarking attack;40-bit encryption;plaintext-aware encryption;theoretical computer science;plaintext;optimal asymmetric encryption padding;link encryption;mathematics;internet privacy;deterministic encryption;computer security;id-based cryptography;encryption;probabilistic encryption;56-bit encryption	Crypto	-40.15330586619179	76.19055157116135	176216
0fdf0dec354309b8b44c1cc00497b0fba5dabf00	single-database private information retrieval with constant communication rate	busqueda informacion;approximation asymptotique;information communication;communaute repartie;base donnee;security analysis;subgrupo;subgroup;web community;securite;information retrieval;private information retrieval;communication complexity;database;base dato;complexite communication;automaton;sous groupe;automata;communication information;recherche information;automate;safety;comunicacion informacion;asymptotic approximation;seguridad;comunidad repartido;aproximacion asintotica	We present a single-database private information retrieval (PIR) scheme with communication complexity O(k+d), where k ≥ log n is a security parameter that depends on the database size n and d is the bit-length of the retrieved database block. This communication complexity is better asymptotically than previous single-database PIR schemes. The scheme also gives improved performance for practical parameter settings whether the user is retrieving a single bit or very large blocks. For large blocks, our scheme achieves a constant “rate” (e.g., 0.2), even when the user-side communication is very low (e.g., two 1024-bit numbers). Our scheme and security analysis is presented using general groups with hidden smooth subgroups; the scheme can be instantiated using composite moduli, in which case the security of our scheme is based on a simple variant of the “Φ-hiding” assumption by Cachin, Micali and Stadler [2].	bit-length;generic group model;overhead (computing);personally identifiable information;private information retrieval;security parameter;universal instantiation;utility functions on indivisible goods	Craig Gentry;Zulfikar Ramzan	2005		10.1007/11523468_65	discrete mathematics;computer science;artificial intelligence;theoretical computer science;database;mathematics;distributed computing;automaton;computer security;algorithm	Crypto	-42.766878982462885	78.21867319991135	176356
428623cfb2019b27c3e404a8ab8936b59b12f391	multi-pkg id based signcryption		Here we propose an identity based signcryption scheme in the multi-PKG environment where sender and receiver receive public key from different PKG. We also define security models for our scheme and give security proofs in random oracle model.	adaptive chosen-ciphertext attack;ciphertext;confidentiality;encryption;public-key cryptography;random oracle;signcryption	Sunder Lal;Prashant Kushwah	2008	IACR Cryptology ePrint Archive		public-key cryptography;random oracle;computer security model;signcryption;mathematical proof;communication source;distributed computing;computer science	Crypto	-41.735392536878535	75.78445421646668	176617
bb76d632491a2744b82411c3cd7ff971da30e56e	independent zero-knowledge sets	conjunto independiente;teoria demonstracion;theorie preuve;proof theory;independent set;protocole engagement;security proof;ensemble independant;protocolo compromiso;col;efficient implementation;protocole zero connaissance;protocolo cero conocimiento;zero knowledge protocol;zero knowledge;commitment scheme	We define and construct Independent Zero-Knowledge Sets (ZKS) protocols. In a ZKS protocols, a Prover commits to a set S, and for any x, proves non-interactively to a Verifier if x ∈ S or x / ∈ S without revealing any other information about S. In the independent ZKS protocols we introduce, the adversary is prevented from successfully correlate her set to the one of a honest prover. Our notion of independence in particular implies that the resulting ZKS protocol is non-malleable. On the way to this result we define the notion of independence for commitment schemes. It is shown that this notion implies non-malleability, and we argue that this new notion has the potential to simplify the design and security proof of non-malleable commitment schemes. Efficient implementations of ZKS protocols are based on the notion of mercurial commitments. Our efficient constructions of independent ZKS protocols requires the design of new commitment schemes that are simultaneously independent (and thus non-malleable) and mercurial.	adversary (cryptography);commitment scheme;interactivity;mercurial;provable security	Rosario Gennaro;Silvio Micali	2006		10.1007/11787006_4	commitment scheme;independent set;computer science;artificial intelligence;proof theory;mathematics;algorithm;zero-knowledge proof	Theory	-38.08805967366052	75.58088514583415	176631
70b0b883da8416b97f7347781c396964db13bc77	security research on an information-theoretically secure secret key agreement using ldpc matrices	information theoretically secure secret key agreement;protocols;parity check codes;network security;low density parity check matrices;matrix algebra;ldpc matrix;receivers;manganese;artificial neural networks;telecommunication security cryptography matrix algebra parity check codes;cryptography;protocols security parity check codes manganese artificial neural networks cryptography receivers;telecommunication security;low density parity check matrices information theoretically secure secret key agreement ldpc matrix network security solution secret key cryptosystem;key agreement;key agreement protocol;information theoretic security;side information;security;secret key cryptosystem;network security solution	Secret key agreement is a major task in network security solutions using secret-key cryptosystems. An information-theoretically secure secret key agreement protocol using LDPC matrices was introduced by Jun Muramatsu. In this paper, the enemy can obtain not only full transmitted messages but also partial side information. We are interested in the equivocation of the generated key to this more powerful enemy. A relation between the security of the secret key agreement protocol and the LDPC matrices used in it is also discussed.	cryptosystem;information-theoretic security;key (cryptography);key-agreement protocol;low-density parity-check code;network security;public-key cryptography	Jia Yu;Yuan Luo;Minglu Li	2008	The Third ChinaGrid Annual Conference (chinagrid 2008)	10.1109/ChinaGrid.2008.28	shared secret;theoretical computer science;mathematics;distributed computing;proactive secret sharing;pre-shared key;key distribution;computer security	Crypto	-42.25012361353641	82.32862539066547	176797
4bd76eb8f250069fbec828151cee0df71748f358	hierarchical multi-party key agreement for wireless networks	security properties;c c programs;automata automatic testing information security software testing mathematical model safety instruments system testing information systems memory management;team edit automata;memory management;storage management;object oriented programming;pointer manipulation flaws;c language;software security;program testing;memory management flaw;mathematical model;automata theory;c c programs team edit automata software security property testing mathematical model component automata memory management flaw pointer manipulation flaws;software security property testing;component automata;security of data;storage management automata theory c language object oriented programming program testing security of data	A common property of practically all multi-party key agreement protocols is that they are non-hierarchical, i.e., they do not support user hierarchies. However, in real life, it is likely that members of groups and organizations differ in ranking according to their job positions so that people of higher rankings are privileged the same and higher privileged information than people of lower rankings. Hierarchical access control schemes address this issue, but they assume rather fixed scenarios based on centralized key distribution with predefined root keys and key parameters set by a trusted center. In this paper, we propose a decentralized efficient hierarchical multi-party key agreement protocol well-suited for ad-hoc wireless networks that ensures secure user hierarchies.	access control;authentication;centralized computing;hoc (programming language);key distribution;key-agreement protocol;real life	Sigurd Eskeland;Vladimir A. Oleshchuk	2007	Third International Symposium on Information Assurance and Security	10.1109/IAS.2007.82	computer security model;computer science;theoretical computer science;distributed computing;programming language	Security	-47.6930295578081	77.62190734685464	177022
3f56bfd2439d94f59786658030c27f7bc902fc8f	smart: a secure multilayer credit-based incentive scheme for delay-tolerant networks	evaluation performance;optimisation;disruption tolerant networking;systeme intelligent;delay tolerant networks dtns;simulation systeme;performance evaluation;security of data distributed processing;optimizacion;nonhomogeneous media incentive schemes disruption tolerant networking relays web and internet services communication system security hardware telecommunication traffic spread spectrum communication ip networks;securite;telecommunication sans fil;and forward;optimization technique;routing;web and internet services;implementation;smart;evaluacion prestacion;sistema inteligente;distributed processing;routage;multicouche;optimization method;packet switching;conmutacion por paquete;relais;metodo optimizacion;multiple layer;distance measurement;telecommunication traffic;security delay tolerant networks dtns incentive scheme;spread spectrum communication;nonhomogeneous media;rele;network connectivity;medicion distancia;telecomunicacion sin hilo;capa multiple;opportunistic data forwarding;safety;intelligent system;methode optimisation;delay tolerant network;conexidad;ip networks;optimization;tamperproof hardware smart secure multilayer credit based incentive scheme delay tolerant network network connectivity opportunistic data forwarding;temps retard;incentive schemes;computer hardware;incentive scheme;delay time;connexite;relays;implementacion;connectedness;security;seguridad;system simulation;tiempo retardo;simulacion sistema;materiel informatique;security of data;commutation paquet;secure multilayer credit based incentive scheme;mesure de distance;tk electrical engineering electronics nuclear engineering;communication system security;hardware;relay;wireless telecommunication;enrutamiento;tamperproof hardware	Delay-tolerant networks (DTNs) provide a promising solution to support wide-ranging applications in the regions where end-to-end network connectivity is not available. In DTNs, the intermediate nodes on a communication path are expected to store, carry, and forward the in-transit messages (or bundles) in an opportunistic way, which is called opportunistic data forwarding. Such a forwarding method depends on the hypothesis that each individual node is ready to forward packets for others. This assumption, however, might easily be violated due to the existence of selfish or even malicious nodes, which may be unwilling to waste their precious wireless resources to serve as bundle relays. To address this problem, we propose a secure multilayer credit-based incentive scheme to stimulate bundle forwarding cooperation among DTN nodes. The proposed scheme can be implemented in a fully distributed manner to thwart various attacks without relying on any tamperproof hardware. In addition, we introduce several efficiency optimization techniques to improve the overall efficiency by exploiting the unique characteristics of DTNs. Extensive simulations demonstrate the efficacy and efficiency of the proposed scheme.	delay-tolerant networking;end-to-end principle;malware;mathematical optimization;operand forwarding;relay;smart;simulation	Haojin Zhu;Xiaodong Lin;Rongxing Lu;Yanfei Fan;Xuemin Shen	2009	IEEE Transactions on Vehicular Technology	10.1109/TVT.2009.2020105	telecommunications;computer science;engineering;information security;delay-tolerant networking;computer security;computer network	Mobile	-47.207285929682605	79.63093813062052	177042
29d8bd90b4a3b33a0ae1107ad3a1774a56fe97f3	sakm: a scalable and adaptive key management approach for multicast communications	key management;multicast communication;multicat;video conferencing;real time communication;group size;scalability;security	Multicasting is increasingly used as an efficient communication mechanism for group-oriented applications in the Internet. In order to offer secrecy for multicast applications, the traffic encryption key has to be changed whenever a user joins or leaves the system. Such a change has to be communicated to all the current users. The bandwidth used for such rekeying operation could be high when the group size is large. The proposed solutions to cope with this limitation, commonly called 1 affects n phenomenon, consist of organizing group members into subgroups that use independent traffic encryption keys. This kind of solutions introduce a new challenge which is the requirement of decrypting and reencrypting multicast messages whenever they pass from one subgroup to another. This is a serious drawback for applications that require real-time communication such as video-conferencing. In order to avoid the systematic decryption / reencryption of messages, we propose in this paper an adaptive solution which structures group members into clusters according to the application requirements in term of synchronization and the membership change behavior in the secure session. Simulation results show that our solution is efficient and typically adaptive compared to other schemes.	cluster analysis;encryption;heuristic;internet;key (cryptography);key management;organizing (structure);real-time clock;real-time web;requirement;scalability;secure multicast;session key;simulation;software deployment	Yacine Challal;Hatem Bettahar;Abdelmadjid Bouabdallah	2004	Computer Communication Review	10.1145/997150.997157	multicast;scalability;computer science;information security;size of groups, organizations, and communities;operating system;key management;distributed computing;videoconferencing;source-specific multicast;computer security;xcast;computer network	Security	-48.27003039781231	77.22274203898914	177462
b028cab859fecccecba90fa09b5a1bae37264522	analysis and design of an authentication protocol for space information network	svo logic;authentication protocol;space information network	With the development of mobile communication technology, space information network plays an essential role in meeting the increasing demands of mobile communications. As a basic and powerful security mechanism, authentication protocol provides primary protection. In 2012, Zheng et al. proposed an efficient four-phase authentication scheme for space information network. But we observed that it is vulnerable to various attacks, such as the identity spoofing attack, malicious service request attack and denial of service attack. In this paper, we analyze the protocol in detail. Then an improved authentication scheme based on the self-renewal and timeout retransmission mechanism of user's temporary identity is proposed. The formal verification with SVO logic proves that the proposed authentication protocol is secure.	authentication protocol;denial-of-service attack;formal verification;retransmission (data networks);sparse voxel octree;spoofing attack	Weiwei Zhao;Aixin Zhang;Jianhua Li;Xinghua Wu;Yuchen Liu	2016	MILCOM 2016 - 2016 IEEE Military Communications Conference	10.1109/MILCOM.2016.7795299	data authentication algorithm;otway–rees protocol;reflection attack;challenge–response authentication;computer science;authentication protocol;lightweight extensible authentication protocol;multi-factor authentication;wide mouth frog protocol;internet privacy;protected extensible authentication protocol;ssliop;computer security;email authentication;challenge-handshake authentication protocol;computer network	Security	-47.834159877947116	75.20217547846141	177744
b48689eeb14249193e25cc00779afe660af0e062	lossy trapdoor functions from smooth homomorphic hash proof systems		In STOC ’08, Peikert and Waters introduced a powerful new primitive called Lossy Trapdoor Functions (LTDFs). Since their introduction, lossy trapdoor functions have found many uses in cryptography. In the work of Peikert and Waters, lossy trapdoor functions were used to give an efficient construction of a chosen-ciphertext secure (IND-CCA2) cryptosystem. Lossy trapdoor functions were then shown to imply deterministic encryption by Bellare, Fischlin, O’Neill and Ristenpart in CRYPTO ’08. In TCC ’09, Rosen and Segev showed that lossy trapdoor functions are correlated product secure, meaning that they remain one-way even when evaluated on correlated inputs. In their work, Peikert and Waters gave constructions of LTDFs from the Decisional DiffieHellman (DDH) assumption and lattice assumptions. Bellare et al., and Rosen and Segev also gave (identical) efficient constructions of LTDFs from Paillier’s Decisional Composite Residuosity (DCR) assumption. To date, these remain the only known constructions of lossy trapdoor functions. In this work we extend the notion of smooth hash proof systems as defined by Cramer and Shoup in Eurocrypt ’02, to include an additional homomorphic property. We call this primitive smooth homomorphic hash proof systems. We show that smooth homomorphic projective hash proof systems include all Diverse Group Systems as defined by Cramer and Shoup. Using this definition, we show that • Smooth homomorphic hash proof systems imply LTDFs. • Diverse group systems as defined in [CS02] imply LTDFs. These are the first known generic constructions of LTDFs. • Applying our generic construction the specific constructions of smooth hash proof systems given by Cramer and Shoup, we obtain the first construction of LTDFs from the quadratic residuosity (QR) assumption. We also obtain a novel construction of LTDFs from Paillier’s decisional composite residuosity (DCR) assumption. • Applying our results to the results of Bellare et al. we obtain a construction of deterministic encryption from smooth homomorphic hash proof systems. • Applying our results to the results of Rosen and Segev, we obtain a construction of correlated product secure functions from smooth homomorphic hash proof systems. This provides the first construction of correlated product secure functions from the QR assumption. • Applying the black-box separation results of Rosen and Segev, we show that there is a blackbox separation between smooth homomorphic hash proof systems and one-way trapdoor permutations. • While homomorphic encryption can never be IND-CCA2 secure, we notice that smooth homomorphic hash proof systems yield a homomorphic IND-CCA1 secure cryptosystem.	adaptive chosen-ciphertext attack;black box;ciphertext indistinguishability;cryptography;cryptosystem;decisional diffie–hellman assumption;deterministic encryption;eurocrypt;homomorphic encryption;lossy compression;mihir bellare;one-way function;quadratic residue;symposium on theory of computing;trapdoor function	Brett Hemenway;Rafail Ostrovsky	2009	Electronic Colloquium on Computational Complexity (ECCC)		discrete mathematics;lossy compression;combinatorics;permutation;mathematics;cryptography;cryptosystem;hash function;deterministic encryption;trapdoor function;homomorphic encryption	Crypto	-38.53375706819163	77.0448588212478	177902
058e84d8ddc48ac1f03e6349c0ee04daf95a784e	cryptanalysing variants of stickel's key agreement scheme			cryptanalysis;key-agreement protocol	Ciaran Mullan	2011	J. Mathematical Cryptology	10.1515/jmc.2011.003	s/key;combinatorics;mathematics;cryptanalysis	Crypto	-40.44535705300337	79.84009261045982	178119
af10d4f7d1d904c917514e3c59f8b5308efce77c	a practical polynomial-time known-plaintext attack on a cryptosystem proposed by john nash			cryptosystem;known-plaintext attack;nash equilibrium;plaintext;time complexity	Adi Shamir;Eldad Zinger	2012	IACR Cryptology ePrint Archive		discrete mathematics;time complexity;known-plaintext attack;cryptosystem;mathematics	Crypto	-40.19347831924517	79.88464575601331	178338
927beca3b2da1d3e1e4e84e3969ff37798f3ad0d	enforcing integrity of agent migration paths by distribution of trust	agent platform;trust;protocols;movilidad;multiagent system;confiance;systeme intelligent;psychologie sociale;agent based systems;agent mobile;protocole transmission;migration;mobility;mobile agents;localization;sistema inteligente;agente movil;transport layer security;securite informatique;mas;integrite;intelligence artificielle;localizacion;mobilite;integridad;systeme ouvert;intelligent information systems;agent security;feasibility;computer security;protocolo transmision;multi agent systems;confidence;integrity;localisation;confianza;seguridad informatica;intelligent system;psicologia social;agent systems;artificial intelligence;social psychology;inteligencia artificial;information system;mobile agent;sistema multiagente;secure agent migration;open systems;sistema abierto;systeme information;practicabilidad;faisabilite;migracion;systeme multiagent;sistema informacion;transmission protocol	Agent mobility is the ability of an agent to migrate from one location to another across a network. Though conceptually relatively straightforward, in practice security of mobile agents is a challenge: from transport layer security to preservation of integrity in open environments. This paper discusses the security issues involved and proposes protocols for secure agent migration. AgentScape, an agent platform for mobile agents, is used to illustrate the feasibility of the implementation of these protocols.	mobile agent;transport layer security	Martijn Warnier;Michel A. Oey;Reinier J. Timmer;Frances M. T. Brazier;Benno J. Overeinder	2009	IJIIDS	10.1504/IJIIDS.2009.030436	communications protocol;feasibility study;internationalization and localization;telecommunications;computer science;human migration;artificial intelligence;multi-agent system;mobile agent;confidence;transport layer security;open system;trustworthy computing;mobile computing;computer security;information system	Security	-45.91797035886451	78.74371011880453	178866
f3d369fac77f3f78e242c4ba3b4e78ec91542977	differential sieving for 2-step matching meet-in-the-middle attack with application to lblock		In this paper, we propose a modified approach for the basic meet-in-the-middle attack which we call differential sieving for 2-step matching. This technique improves the scope of the basic meet in the middle attack by providing means to extend the matching point for an extra round through differential matching and hence the overall number of the attacked rounds is extended. Our approach starts by first reducing the candidate matching space through differential matching, then the remaining candidates are further filtered by examining non shared key bits for partial state matching. This 2-step matching reduces the total matching probability and accordingly the number of remaining candidate keys that need to be retested is minimized. We apply our technique to the light weight block cipher LBlock and present a two known plaintexts attack on the fifteen round reduced cipher. Moreover, we combine our technique with short restricted bicliques and present a chosen plaintext attack on Lblock reduced to eighteen rounds.	algorithmic efficiency;block cipher;differential cryptanalysis;known-plaintext attack;meet-in-the-middle attack;plaintext;symmetric-key algorithm;time complexity	Riham AlTawy;Amr M. Youssef	2014		10.1007/978-3-319-16363-5_8	cipher;block cipher;chosen-plaintext attack;mathematics;cryptanalysis;artificial intelligence;sieve;candidate key;pattern recognition;meet-in-the-middle attack	Crypto	-37.14958019415983	80.55162671383827	178991
0776f0bc538390015e93306d1045122c7decc35c	bounded-concurrent secure two-party computation without setup assumptions	model specification;secure computation;protocol design;common reference string;protocol composition;secure two party computation;security protocol	"""In this paper we study the feasibility of obtaining protocols for general two-party computation that remain secure under concurrent composition. (A general protocol can be used for obtaining secure computation of any functionality.) We consider a scenario where no trusted setup is assumed (and so, for example, there is no common reference string available to the parties); we call this the """"plain model"""". We present both negative and positive results for this model. Specifically, we show that a general two-party protocol that remains secure for m concurrent executions and can be proven via black-box simulation, must have more than m rounds of communication. An important corollary of this result is that there do not exist protocols for black-box secure general two-party computation for the case of unbounded concurrency (where any polynomial number of concurrent executions may be run). On the positive side, we show that under general cryptographic assumptions, there exist secure protocols for general two-party computation in the model of bounded concurrent composition (in this model the number of concurrent executions is fixed and the protocol design may depend on this number). Our protocol has O(m) rounds of communication, where m is the bound on the number of concurrent executions, and uses both black-box and non black-box techniques. We note that this protocol constitutes the first feasibility result for general two-party computation without setup assumptions for any model of concurrency."""	black box;common reference string model;communications protocol;concurrency (computer science);cryptography;existential quantification;multiversion concurrency control;polynomial;secure multi-party computation;secure two-party computation;simulation	Yehuda Lindell	2003	Chicago J. Theor. Comput. Sci.	10.1145/780542.780641	universal composability;real-time computing;computer science;secure two-party computation;theoretical computer science;mathematics;distributed computing;specification;statistics	Theory	-37.89103302624527	75.12693148593979	179154
239957553b3b13cf2418c887db1f1e5793b5e673	mtrust: a reputation-based trust model for a mobile agent system	modelizacion;distributed memory;bayesian network;multiagent system;confiance;psychologie sociale;informatique mobile;agent mobile;almacenamiento informacion;huesped movile;memoria compartida;agente movil;securite informatique;distributed computing;mobile host;trust model;computer security;modelisation;trusted computing;reseau bayes;reputation system;information storage;confidence;mobile agent system;confianza;hote mobile;loi beta;red bayes;ley beta;beta distribution;seguridad informatica;psicologia social;bayes network;calculo repartido;stockage information;social psychology;mobile agent;memoire repartie;sistema multiagente;mobile computing;modeling;calcul reparti;systeme multiagent	This research promotes MTrust a reputation-based trust model that will ensure cooperative interactions amongst mobile agents and visited hosts in a mobile agent system. MTrust is composed of a reputation system and a trust formation system. A reputation system relies on two components; a truthful feedback submission algorithm and a set of distributed feedback information storages. A trust formation system enables a truster to compute a trustee’s trustworthiness. It has two components namely; a feedback aggregation module (FAM) and a trust computing module (TCM). A FAM calculates a trust value from feedback information when there is a lack of direct experiences using Beta distribution. A TCM calculates a trust value using Bayesian Network (BN).	mobile agent	Suphithat Songsiri	2006		10.1007/11839569_36	simulation;trust anchor;computer science;artificial intelligence;bayesian network;mobile computing;computer security	AI	-45.36776687604158	78.27222085927228	179196
91eb9a2aee16f914e13f31f52b80a431342c6d81	garbled ram revisited, part ii		In EUROCRYPT 2013, Lu and Ostrovsky proposed the notion of Garbled RAM (GRAM) programs. These GRAM programs are analogous to the classic result of Yao’s garbled circuits: a large encrypted memory can first be provided to evaluator, and then a program can separately be garbled and sent to an evaluator to securely execute while learning nothing but the output of the program and its running time. The key feature of GRAM is that it harnesses the natural complexity-theoretic power that Random Access Memory (RAM) programs have over circuits, such as in binary search or randomized algorithms, where program can be executed in a garbled way without “unrolling” it into a circuit. The candidate Lu-Ostrovsky GRAM scheme proposed in that paper is based on the existence of one-way functions, but due to an implicit reliance on a complex “circular” use of Yao garbled circuits, the scheme requires an additional circularity assumptions and may not be secure otherwise. In this paper, we show how to construct efficient GRAM without circularity and based solely on the existence of any one-way function. The novel approach that allows us to break the circularity is a modification of the Goldreich-Goldwasser-Micali (PRF) construction. More specifically, we modify the PRF to allow PRF-keys to be “adaptively revoked” during run-time at the additive cost of roughly log n per revocation. Then, to improve the overhead of this scheme, we apply a delicate recursion technique that bootstraps mini-GRAM schemes into larger, more powerful ones while still avoiding circularity in the hybrid arguments. This results in secure GRAM with overhead of poly(κ)(min(t, n )) for any constant > 0 where n is the size of memory and t is the running time. In a companion work (Part I), Gentry, Halevi, Raykova, and Wichs show an alternative approach using identity-based encryption to solve the circularity problem. Their scheme achieves overhead of poly(κ)polylog(n) assuming the existence of IBE.	binary search algorithm;eurocrypt;id-based encryption;interpreter (computing);lu decomposition;merkle–damgård construction;one-way function;overhead (computing);primitive recursive function;random access;random-access memory;randomized algorithm;recursion;theory;time complexity;utility functions on indivisible goods;yao graph	Steve Lu;Rafail Ostrovsky	2014	IACR Cryptology ePrint Archive			Crypto	-37.51532680799019	76.5363470574708	179323
3bd59ee97249ab430de832270227fee55b037573	on the computational security of a distributed key distribution scheme	file servers cryptography distributed processing;provable security;file servers;security analysis;public key cryptosystems;decisional diffie hellman;distributed processing;cryptographic controls public key cryptosystems;indexing terms;info eu repo semantics article;computer security;computational security;random oracle model;cryptography;distributed key distribution scheme;random oracle;decisional diffie hellman problem;hash function;secret sharing scheme;noncorrupted group;hash function computational security distributed key distribution scheme noncorrupted group security analysis random oracle model decisional diffie hellman problem;article;secret sharing schemes;cryptographic controls;key distribution	In a distributed key distribution scheme, a set of servers helps a set of users in a group to securely obtain a common key. Security means that an adversary who corrupts some servers and some users has no information about the key of a noncorrupted group. In this work, we formalize the security analysis of one such scheme (Daza, V., et al, 2002) which was not considered in the original proposal. We prove the scheme is secure in the random oracle model, assuming that the Decisional Diffie-Hellman (DDH) problem is hard to solve. We also detail a possible modification of that scheme and the one in Naor, M., et al, (1999) which allows us to prove the security of the schemes without assuming that a specific hash function behaves as a random oracle. As usual, this improvement in the security of the schemes is at the cost of an efficiency loss.	adversary (cryptography);computation;computational diffie–hellman assumption;computational hardness assumption;computational resource;decisional diffie–hellman assumption;hash function;key distribution;random oracle	Vanesa Daza;Javier Herranz;Germán Sáez	2008	IEEE Transactions on Computers	10.1109/TC.2008.50	random oracle;computer security model;computer science;distributed computing;internet privacy;computer security;algorithm	Crypto	-40.91188979308211	74.76694391197194	179351
76a6796d59361771221da4646f7fdfb61c682caa	first multidimensional cryptanalysis on reduced-round $$\mathrm{prince }_{core}$$		In this paper we present the first multidimensional linear attack on (text {PRINCE}_{core}), which uses an identical round-key for each round. Traditional one-dimensional and multidimensional linear cryptanalysis based their theoretical foundation on the independent-key assumption, so that they cannot be evaluated accurately in the case of ciphers with identical round-key. In this paper we propose a new classification technique to overcome this obstacle. In our new technique, we classify the linear trails into different subsets indexed by the XOR sum of their trail masks, deal with their correlations in each subset, and get the accurate capacity for our target linear approximation. By this technique, we build an 8-round multidimensional linear distinguisher with capacity of (2^{-57.99}), and exhibit a key-recovery attack on 9 out of 12 round of (text {PRINCE}_{core}). This attack requires a data complexity of (2^{63.84}) known plaintexts and time complexity of (2^{60}) encryptions. We also present a key-recovery attack on 10-round (text {PRINCE}_{core}) with data complexity of (2^{63.84}) known plaintexts and time complexity of (2^{75.68}) encryptions.	cryptanalysis	Xiaoqian Li;Bao Li;Wenling Wu;Xiaoli Yu;Ronglin Hao;Bingke Ma	2013		10.1007/978-3-319-12160-4_10	telecommunications;computer security	Crypto	-37.83416466413313	81.26865849283945	179387
c37e16909b94944e1eb9a51f1d3952225f2ba3a2	an improvement of park-chung-cho's stream authentication scheme by using information dispersal algorithm	information dispersal algorithm	We present an efficient stream authentication scheme that improves the verification probability of Park-Chung-Cho's scheme [1] by using Rabin's Information Dispersal Algorithm. It is shown that under the same communication overhead the verification probability of the proposed scheme is higher than those of SAIDA as well as Park-Chung-Cho's scheme, and that the execution time of the proposed scheme is smaller than that of SAIDA.	algorithm;authentication	Seok-Lae Lee;Yongsu Park;Joo-Seok Song	2007		10.1007/978-3-540-72383-7_122	computer science;theoretical computer science;distributed computing;computer security	Mobile	-42.86202810631861	76.8636003631296	179488
c192df743254174643890b7f024d8a61ca83d18d	certificateless threshold ring signature	anonymity;pairing based cryptosystem;security model;bepress selected works;signature verification;certificateless cryptography;it security;digital signature;era2012;bilinear pairing;ring signature	We propose a t-out-of-n Certificateless Threshold Ring Signature (CL-TRS) scheme and prove its security under a new and stronger set of security models. The models capture a new adversarial capability called User Partial Key Replacement Attack, which has been considered practical and realistic but has never been formalized before. The new scheme requires only a constant number of bilinear pairing operations for signature verification. It also has a compact signature size which is linear to the number of non-signers (i.e. n t) rather than that of actual signers. We also propose a 1-out-of-n CL-TRS (i.e. a certificateless ring signature scheme) which has the most efficient verification among all the certificateless ring signature schemes currently known. 2009 Elsevier Inc. All rights reserved.	bilinear filtering;digital signature;ring signature	Shuang Chang;Duncan S. Wong;Yi Mu;Zhenfeng Zhang	2009	Inf. Sci.	10.1016/j.ins.2009.06.017	ring signature;computer security model;digital signature;merkle signature scheme;eddsa;anonymity;computer science;mathematics;internet privacy;blind signature;schnorr signature;elgamal signature scheme;computer security;computer network	Security	-41.75116215717498	75.53624009809499	179855
1ed685433ea44d12f9c4fc672df4c94ef1e37533	partitioning cryptanalysis	des.;. iterated block ciphers;partitioning cryptanalysis;linear cryptanalysis;partitioning crypt- analysis	Matsui's linear cryptanalysis for iterated block ciphers is generalized to an attack called . This attack exploits a weakness that can be described by an e ective partition-pair, i.e., a partition of the plaintext set and a partition of the next-to-last-round output set such that, for every key, the next-to-last-round outputs are non-uniformly distributed over the blocks of the second partition when the plaintexts are chosen uniformly at random from a particular block of the rst partition. The last-round attack by is formalized and requirements for it to be successful are stated. The success probability is approximated and a procedure for nding e ective partition-pairs is formulated. The usefulness of is demonstrated by applying it successfully to six rounds of the DES.	approximation algorithm;block cipher;iteration;linear cryptanalysis;partitioning cryptanalysis;plaintext;requirement	Carlo Harpes;James L. Massey	1997		10.1007/BFb0052331	linear cryptanalysis	Crypto	-37.896709342959866	79.76898593441196	179927
394e34620c49833ac757205cbf604bc0c2b5b3a6	a trust management scheme in structured p2p systems	cheating;p2p system;hachage;distributed system;sistema operativo;replication;multiagent system;confiance;systeme reparti;psychologie sociale;gestion archivos;par a par;trust management;distributed computing;gestion fichier;p2p;file management;replicacion;confidence;hashing;sistema repartido;poste a poste;operating system;confianza;tricherie;psicologia social;calculo repartido;systeme exploitation;social psychology;file sharing;sistema multiagente;peer to peer;calcul reparti;systeme multiagent;trampa	Since there is no method to verify the trustworthiness of shared files in P2P file sharing systems, malicious peers can spread untrustworthy files to the system. In order to prevent untrustworthy files from spreading, we propose an effective trust management scheme using peer reputation and file reputation together in a DHT-based structured P2P systems. Simulation results show that the proposed scheme effectively restrains the spreading of untrustworthy files even in cases where malicious peers change their identities. Simulation results show that the overall message cost for managing trust data is relatively low. We also propose a replication scheme so as to avoid the loss or corruption of trust data.		So Young Lee;O-Hoon Kwon;Jong Kim;Sung Je Hong	2005		10.1007/11925941_3	computer science;distributed computing;world wide web;computer security	Theory	-45.14725866287503	78.11945969467918	179989
31368a8099a752d7de90f18604c9075764152da8	non-malleability amplification	one way function;round complexity;cryptography;commitment;non malleability;commitment scheme	"""We show a technique for amplifying commitment schemes that are non-malleable with respect to identities of length t, into ones that are non-malleable with respect to identities of length Ω(2t), while only incurring a constant overhead in round-complexity. As a result we obtain a construction of O(1)log* n-round (i.e., """"essentially"""" constant-round) non-malleable commitments from any one-way function, and using a black-box proof of security."""	black box;one-way function;overhead (computing)	Huijia Lin;Rafael Pass	2009		10.1145/1536414.1536442	arithmetic;commitment scheme;computer science;cryptography;mathematics;computer security;algorithm	Theory	-37.86311806076951	76.96897015119383	180016
386c5792f49acdf50f5d520d9209d1bf2c61a4a2	tate-pairing implementations for tripartite key agreement	key agreement protocol	 We give a closed formula for the Tate-pairing on the hyperellipticcurve yx + d in characteristic p. This improves recent implementationsby Barreto et.al. and by Galbraith et.al. for the special case p = 3.As an application, we propose a n-round key agreement protocol for up toparticipants by extending Joux's pairing-based protocol to n rounds. 	key-agreement protocol	Iwan M. Duursma;Hyang-Sook Lee	2003	IACR Cryptology ePrint Archive		key-agreement protocol;discrete mathematics;tate pairing;mathematics	Crypto	-39.80352487325262	78.40104917305224	180070
3e80f9dbdf4221a0f9f353cd072191975082626f	cryptographic shuffling of random and pseudorandom sequences	shuffling stream cipher;004;pseudorandom sequence	This papers studies methods to improve the cryptographic quality of random or pseudorandom sequences by modifying the order of the original sequence. A new algorithm Cryshu is suggested, which produces its shuffled output data at the rate of the input data. 1 Cryptographic Aspects of Shuffling Random and Pseudorandom Sequences A deck of cards is shuffled to arrange the cards in a random sequence. When we have random or pseudorandom numbers, we may try to rearrange their sequence to make them even “more random”. For streamciphers, the cryptanalyst tries to keep track of the state of the internal machinery which produces the pseudorandom output sequence. The only information he obtains about what is going on internally is from the output data. When the sequence of output data is shuffled, his task becomes more difficult, since subsequent output elements do not correspond to subsequent states of the internal machinery. Hence, it is considerably more difficult to draw conclusions from the output data to the internal state. This effect of making the cryptanalysis harder is only achieved, if it is impossible to determine the original sequence from the shuffled one. So one requirement for cryptographically useful shuffling algorithms is that it must be infeasible to reconstruct the original sequence when given only the shuffled one. We suggest to use shuffling as a technique to improve the cryptographic strength of stream ciphers. A sequence of pseudorandom numbers is generated by some algorithm, then shufffling is applied to improve the cryptographic quality of the sequence. The algorithm used to generate the original sequence may be such, that succesful cryptanalytic attacks are possible. In this case, shuffling may be sufficient to thwart any attacks. Shuffling may also be useful for streamciphers for which no feasible attacks are known, to have an additional layer of security. Physical random number generators tend to have correlations between bits generated subsequently. Here shuffling turns out to be helpful, since in order to exploit the correlation, an attacker must know which bits are correlated. For the shuffled sequence, the attacker does not have this information, since the correlated bits go to distant positions which he does not know. However, shuffling does not help against the most common problem of physical random Dagstuhl Seminar Proceedings 07021 Symmetric Cryptography http://drops.dagstuhl.de/opus/volltexte/2007/1014 number generators, bias, which means that the probability of a generated bit to be zero is not equal to 0.5 . Since the numbers of zeros and ones in the sequence remains the same when it is shuffled, the bias remains the same. 2 Known Methods to Shuffle Pseudorandom Sequences Knuth [Knu81] describes two methods to shuffle sequences of pseudorandom numbers, which are called Algorithm M and Algorithm B. Algorithm M is due to MacLaren and Marsaglia, Algorithm B to Bays and Durham. Algorithm M requires, in addition to the sequence Z1 of pseudo random numbers to be shuffled, another sequence Z2 of pseudo random numbers, which controls the shuffling of Z1. Algorithm M uses an array which is initially filled with the first numbers generated by Z1. When an element of the shuffled sequence resulting from Algorithm M is required, the next element of Z2 is generated and used to determine an index into the array. The entry stored at this position of the array is returned as the result, the entry of the array is replaced with the next element of Z1. Algorithm M is suited well for cryptographic purposes, its disadvantage is that half of its random input is used up just for the shuffling. Algorithm B does not require an additional sequence Z2 to control the shuffling, the sequence Z1 to be shuffled also controls its shuffling. This can be called self shuffling. Algorithm B also uses an array which is initially filled with the first elements of Z1. The auxiliary variable Y is initialised with the next element of Z1. When an element of the shuffled sequence is required, Y is used to determine an index into the array. The entry stored at this position of the array is returned as the result, and it is also used as the new value of Y. Then the entry of the array is replaced with the next value of Z1. Algorithm B is cryptographically weak. Each number generated betrays from which entry of the array the next result will be taken. After a short period of observation, the attacker will know when this entry was changed last; with very little effort the cryptanalysis of Algorithm B is reduced to the cryptanalysis of Z1. 3 The New Algorithm Cryshu We want to overcome the cryptographic weakness of Algorithm B while keeping its attractive property, that it produces output at the same rate as it reads its input sequence Z1. The new shuffling algorithm is called Cryshu (Crypto Shuffling). The aim of its design was to leak as little information about its internal state as possible. Like Algorithm B, Cryshu also uses an array to shuffle the sequence Z1 of pseudo random numbers. Initially this array is filled with the first elements of Z1. The auxiliary variable Y is initialised with the next value of Z1. To determine an output element of Cryshu, Y is used to determine an index into the array.	array data structure;binary number;cryptanalysis;goto;hardware random number generator;pseudorandom number generator;pseudorandomness;random number generation;stream cipher;strong cryptography;symmetric-key algorithm;z1 (computer)	Markus Dichtl	2007			random number generation;computer science;theoretical computer science;pseudorandom function family;pseudorandom permutation;pseudorandom binary sequence;distributed computing;pseudorandom generator;stream cipher;pseudorandom noise;random seed;pseudorandom number generator;pseudorandom generator theorem;algorithm	Theory	-36.067109089245555	80.18862028479356	180228
545257fef9458afb43cf4155173e4bfcc60bb4b5	a computational analysis of the needham-schröeder-(lowe) protocol	access protocols cryptography authorisation;authorisation;computer model;satisfiability;security cryptographic protocols public key cryptography computational modeling computer science drives authentication context modeling history engineering profession;system security;cryptography;lowe protocol needham schroeder protocol computational analysis chosen plaintext security elgamal encryption chosen ciphertext attack authentication protocol;mutual authentication;access protocols;computer analysis;chosen ciphertext attack	We provide the first computational analysis of the well known Needham-Schr öeder(-Lowe) protocol. We show that Lowe’s attack to the original protocol can naturally be cast to the computational framework. Then we prove that chosen-plaintext security for encryption schemes is not sufficient to ensure soundness of formal proofs with respect to the computational setting, by exhibiting an attack against the corrected version of the protocol implemented using an ElGamal encryption scheme. Our main result is a proof that, when implemented using an encryption scheme that satisfies indistinguishability under chosen-ciphertext attack, the Needham-Schr öeder-Lowe protocol is indeed a secure mutual authentication protocol. The technicalities of our proof reveal new insights regarding the relation between formal and computational models for system security.	authentication protocol;chosen-ciphertext attack;ciphertext;computation;computational model;computer security;encryption;mutual authentication;needham–schroeder protocol;plaintext;whole earth 'lectronic link	Bogdan Warinschi	2003	Journal of Computer Security	10.1109/CSFW.2003.1212717	computer simulation;otway–rees protocol;semantic security;reflection attack;universal composability;watermarking attack;challenge–response authentication;computer science;cryptography;theoretical computer science;authentication protocol;ciphertext indistinguishability;ciphertext-only attack;wide mouth frog protocol;cryptographic protocol;internet privacy;elgamal encryption;computer security;three-pass protocol;satisfiability	Crypto	-40.31851523052937	75.60059259498644	180323
1f27e4b81d694baa47aa104b66ed63387b4e3fea	efficient generation of prime numbers	smart card;cryptoprocesseur;generic algorithm;securite;implementation;ejecucion;public key;criptografia;cryptography;safety;cryptographie;prime number;generation cle;nombre premier;numero primo;seguridad	The generation of prime numbers underlies the use of most public-key schemes, essentially as a major primitive needed for the creation of key pairs or as a computation stage appearing during various cryptographic setups. Surprisingly, despite decades of intense mathematical studies on primality testing and an observed progressive intensification of cryptographic usages, prime number generation algorithms remain scarcely investigated and most real-life implementations are of rather poor performance. Common generators typically output a n-bit prime in heuristic average complexity O(n) or O(n/ log n) and these figures, according to experience, seem impossible to improve significantly: this paper rather shows a simple way to substantially reduce the value of hidden constants to provide much more efficient prime generation algorithms. We apply our techniques to various contexts (DSA primes, safe primes, ANSI X9.31-compliant primes, strong primes, etc.) and show how to build fast implementations on appropriately equipped smart-cards, thus allowing on-board key generation.	ansi escape code;algorithm;color gradient;computation;heuristic;key generation;norm (social);on-board data handling;parsing expression grammar;primality test;pseudorandomness;public-key cryptography;real life;smart card	Marc Joye;Pascal Paillier;Serge Vaudenay	2000		10.1007/3-540-44499-8_27	arithmetic;provable prime;smart card;computer science;cryptography;strong prime;mathematics;implementation;computer security;prime number;algorithm	Security	-39.24323575971303	79.46883259868044	180800
7b1339eb047954bdad9c794beef66a3c11e576f4	foundations and practice of security		MaD2 is an ultra-performance stream cipher that runs into one clock cycle per byte on a typical personal computer. With an encryption/decryption rate significantly higher than the disk data transfer rate, it can be employed to secure data at rest with almost no user observable performance degradation. The cipher resists various known cryptanalytic attacks. Its keystream demonstrates good statistical properties and clears all the NIST statistical tests, the new Diehard battery of tests, and the TestU01 batteries of tests.	64-bit computing;adversary (cryptography);algorithm;algorithmic efficiency;backup;best, worst and average case;byte;central processing unit;challenge–response authentication;clock signal;cloud computing;cloud storage;computation;cryptanalysis;data at rest;download;elegant degradation;encryption;erasure code;floating point systems;formal verification;fountain code;interaction;lecture notes in computer science;list of intel core i3 microprocessors;observable;overhead (computing);parsing;personal computer;pervasive informatics;protologism;pseudorandomness;public-key cryptography;random number generation;randomness extractor;raptor code;retrievability;springer (tank);stream cipher;testu01	Joaquin Garcia - Alfaro Frédéric Cuppens Nora Cuppens - Bo Tawbi	2012		10.1007/978-3-642-37119-6	software security assurance;security engineering;computer science;systems engineering;social software engineering;software engineering;computer engineering	Security	-35.511788899530444	80.83339270051262	180829
64482f5b7f4cc5f830cb7c6235e646ca092227b6	lattice-based dual receiver encryption and more		Dual receiver encryption (DRE), proposed by Diament et al. at ACM CCS 2004, is a special extension notion of public-key encryption, which enables two independent receivers to decrypt a ciphertext into a same plaintext. This primitive is quite useful in designing combined public key cryptosystems and denial of service attack-resilient protocols. Up till now, a series of DRE schemes are constructed from bilinear pairing groups and lattices. In this work, we introduce a construction of lattice-based DRE. Our scheme is indistinguishable against chosen-ciphertext attacks (IND-CCA) from the standard Learning with Errors (LWE) assumption with a public key of bit-size about 2nm log q, where m and q are small polynomials in n. Additionally, for the DRE notion in the identity-based setting, identity-based DRE (IB-DRE), we also give a lattice-based IB-DRE scheme that achieves chosen-plaintext and adaptively chosen identity security based on the LWE assumption with public parameter size about (2`+ 1)nm log q, where ` is the bit-size of the identity in the scheme.	bilinear filtering;chosen-ciphertext attack;ciphertext;cryptosystem;denial-of-service attack;encryption;lattice model (finance);learning with errors;plaintext;polynomial;public-key cryptography	Daode Zhang;Kai Zhang;Bao Li;Xianhui Lu;Haiyang Xue;Jie Li	2018	IACR Cryptology ePrint Archive	10.1007/978-3-319-93638-3_30	theoretical computer science;encryption;ciphertext;computer science;public-key cryptography;learning with errors;cryptosystem;polynomial;plaintext;pairing	Crypto	-39.50409941881771	76.03016698443577	181199
092a7d6d69ede978276e6c7da50f6e6670c51694	an improvement on efficient anonymous auction protocols	anonymity;strand space model;formal method;auction protocol;authentication tests	In this paper, we propose an improvement on Chang et al.'s efficient anonymous auction protocols to overcome the security weakness in initiation phase of Chang et al.'s scheme. At first, we formally analyze the initiation phase of Chang et al.'s scheme on the basis of authentication tests to disclose the insecurity of the initiation phase. Then we give our attack to the initiation phase, which can make the following auction phase fail to run. Later, we propose our improvement on the initiation phase. Finally, we formally analyze our improved scheme with authentication tests, and prove the security of our improved scheme. Our improved scheme can preserve the merits of Chang et al.'s scheme and overcome the security weakness in initiation phase of Chang et al.'s scheme.	auction algorithm	Rui Jiang;Li Pan;Jianhua Li	2005	Computers & Security	10.1016/j.cose.2004.09.010	formal methods;anonymity;telecommunications;computer science;internet privacy;computer security	Crypto	-43.83762479189247	74.89801586298529	181255
8ad7061410ba426af990d68f33f57e3870376343	design weaknesses in recent ultralightweight rfid authentication protocols		In this paper we focus our attention on the design of several recently proposed ultralightweight authentication protocols and show that the underlying methodology is not sound. Indeed, the common feature of these protocols lies in the use of transforms, which are the main building blocks. We analyze these transforms and show that all of them present some weaknesses, which can be essentially reduced to poor confusion and diffusion in the input-output mappings. Then, exploiting the weaknesses of the transforms, we describe impersonation attacks against the ultralightweight authentication protocols in which they are used: precisely, RCIA, KMAP, SLAP, and SASI(^{+}). On average, an attack requires a constant number of interactions with the targeted tag, compared to the allegedly needed exponential number in the informal security analysis. Moreover, since the weaknesses are in the transforms, the attack strategies we describe can be used to subvert any other protocol that uses the same transforms or closely-related ones.	authentication protocol	Paolo D'Arco;Roberto De Prisco	2018		10.1007/978-3-319-99828-2_1	computer security;computer science;theoretical computer science;security analysis;confusion and diffusion;authentication protocol	Security	-41.423556269458956	76.4145747742647	181386
de9bab2e07f842ed7e541d353deee1028770c18c	an efficient and provable secure certificateless identification scheme in the standard model	tj mechanical engineering and machinery;privacy authorization authentication;standard model;certificateless identification;cryptography;proof of security	In Asiacrypt 2003, Al-Riyami and Paterson proposed the notion of certificateless cryptography, a technique to remove key escrow from traditional identity-based cryptography as well as circumvent the certificate management problem of traditional public key cryptography. Subsequently much research has been done in the realm of certificateless encryption and signature schemes, but little to no work has been done for the identification primitive until 2013 when Chin et al. rigorously defined certificateless identification and proposed a concrete scheme. However Chin et al.’s scheme was proven in the random oracle model and Canetti et al. has shown that certain schemes provable secure in the random oracle model can be insecure when random oracles are replaced with actual hash functions. Therefore while having a proof in the random oracle model is better than having no proof at all, a scheme to be proven in the standard model would provide stronger security guarantees. In this paper, we propose the first certificateless identification scheme that is both efficient and show our proof of security in the  tandard model, that is without having to assume random oracles exist.	identification scheme;provable security	Ji-Jian Chin;Swee-Huay Heng;Raphael C.-W. Phan	2014	TIIS	10.3837/tiis.2014.07.019	standard model;cryptography;internet privacy;world wide web;computer security;statistics	Crypto	-39.97302698255174	75.80802794171701	181486
3703aa34d508c21841e65151987fd9a66c7ca147	sha1, rsa, pss and more			physical symbol system;sha-1	Christina Lindenberg;Kai Wirt	2005	Archive of Formal Proofs			Crypto	-41.621301866315896	80.18522609000381	181839
c99092b37694b210074254e209f8209589122d18	a secure hash function based on cellular automata	cellular automata;hash function		automata theory;cellular automaton;cryptographic hash function	Jae Woo Yoon;Sang-Uk Shin;Kyung Hyune Rhee	1998			computer science;theoretical computer science;hash function;cellular automaton;hash chain	Crypto	-41.12819871280202	79.72901640361144	182068
ec2df84ce6cb51dd95977abe6428feba65cab733	side channel attacks and countermeasures on pairing based cryptosystems over binary fields	distributed system;ataque canal lateral;pairing based cryptosystem;systeme reparti;side channel attack;contre mesure electronique;elliptic curve;securite informatique;vulnerability;courbe elliptique;computer security;aleatorizacion;randomized projective coordinate systems;vulnerabilite;sistema coordenadas;vulnerabilidad;sistema repartido;contra medida electronica;curva eliptica;criptografia;cryptography;seguridad informatica;differential power analysis;side channel attacks;randomisation;cryptographie;eta pairing;pairing based cryptosystems;systeme coordonnee;electronic countermeasure;randomization;random projection;coordinate system;attaque canal lateral	Pairings on elliptic curves have been used as cryptographic primitives for the development of new applications such as identity based schemes. For the practical applications, it is crucial to provide efficient and secure implementations of the pairings. There have been several works on efficient implementations of the pairings. However, the research for secure implementations of the pairings has not been thoroughly investigated. In this paper, we investigate vulnerability of the pairing used in some pairing based protocols against side channel attacks. We propose an efficient algorithm secure against such side channel attacks of the eta pairing using randomized projective coordinate systems for the pairing computation.	computation;countermeasure (computer);cryptographic primitive;cryptography;cryptosystem;ecc memory;randomized algorithm;side-channel attack;smart card	Tae Hyun Kim;Tsuyoshi Takagi;Dong-Guk Han;Howon Kim;Jongin Lim	2006		10.1007/11935070_11	telecommunications;side channel attack;mathematics;computer security;statistics	Crypto	-42.638263870355765	78.78836393391649	182125
58ddd08b7e0725f3080a4756a991501b0934dd57	cryptanalysis of pairing-free identity-based authenticated key agreement protocols	elliptic curve;cryptanalysis;identity based key agreement;pairing free cryptography	The pairing-free ID-based authenticated key agreement ID-AKA protocol provides secure and efficient communication over the public network, which is introduced by Zhu et al. in 2007. Afterwards, a number of identity-based authenticated key agreement protocols have been proposed to meet a variety of desirable security and performance requirements. In this paper, we analyze Fiore and Gennaro's scheme and demonstrate key off-set and forgery attack. We identify that Farash and Attari's protocol is vulnerable to the forgery attack, key compromise impersonation attack, key off-set attack and known session key specific temporary information attack. We also show that Hou and Xu's scheme also fails to resist key off-set and forgery attack.	authentication;cryptanalysis;key-agreement protocol	Dheerendra Mishra;Sourav Mukhopadhyay	2013		10.1007/978-3-642-45204-8_19	cryptanalysis;chosen-ciphertext attack;speke;key generation;internet privacy;elliptic curve;pre-shared key;key space;world wide web;key distribution;computer security;dictionary attack	Crypto	-43.618506243368586	75.23034182209521	182138
17010ecacc98928b3e73990919ef2b5e213058e2	oren: optimal revocations in ephemeral networks	red sin hilo;evaluation performance;equilibrio nash;metodo analitico;game theory;performance evaluation;nash equilibrium;reseau sans fil;securite;telecommunication sans fil;evaluacion prestacion;wireless network;simulation;cle publique;teoria juego;simulacion;theorie jeu;wireless security;equilibre nash;public key;revocations;telecomunicacion sin hilo;analytical method;safety;llave publica;on the fly;methode analytique;transmision de corto alcance;public key certificate;social optimum;transmission a courte distance;dynamic adaptation;ephemeral networks;seguridad;short range transmission;wireless telecommunication	Public-key certificates allow a multitude of entities to securely exchange and verify the authenticity of data. However, the ability to effectively revoke compromised or untrustworthy certificates is of great importance when coping with misbehavior. In this paper, we design a fully distributed local certificate revocation scheme for ephemeral networks – a class of extremely volatile wireless networks with short-duration and short-range communications – based on a game-theoretic approach. First, by providing incentives, we can guarantee the successful revocation of the malicious nodes even if they collude. Second, thanks to the records of past behavior, we dynamically adapt the parameters to nodes’ reputations and establish the optimal Nash equilibrium (NE) on-the-fly, minimizing the social cost of the revocation. Third, based on the analytical results, we define OREN, a unique optimal NE selection protocol, and evaluate its performance through simulations. We show that our scheme is effective in quickly and efficiently removing malicious devices from the network. 2010 Elsevier B.V. All rights reserved.	broadcast encryption;entity;game theory;malware;nash equilibrium;public key certificate;reputation;simulation	Igor Bilogrevic;Mohammad Hossein Manshaei;Maxim Raya;Jean-Pierre Hubaux	2011	Computer Networks	10.1016/j.comnet.2010.11.010	game theory;telecommunications;computer science;wireless network;public key certificate;public-key cryptography;computer security;nash equilibrium	Security	-46.40242604761595	78.43359761877996	182170
cf2d0e9fb807ead3cf8e697f0b964099ad004d5e	prevent online identity theft - using network smart cards for secure online transactions	carte a puce;distributed system;intercambio informacion;serveur documentaire;smart card;tratamiento transaccion;confiance;systeme reparti;psychologie sociale;guerra;securite informatique;ordinateur hote;computer security;confidence;sistema repartido;war;host computer;internet;confianza;smart cards;criptografia;echange information;cryptography;documentary server;information exchange;seguridad informatica;servidor documental;psicologia social;computador huesped;cryptographie;social psychology;transaction processing;guerre;traitement transaction;identity theft	This paper presents a novel method that can be used to prevent online identity theft and thereby ensure secure online transactions. In particular, the method combats online identity theft mechanisms that capture information on the computer before the information is encrypted. The key feature of this method is the use of secure network smart cards to establish secure connections between the smart card and remote Internet nodes. Using this end-to-end secure connection, one can securely exchange confidential information between the smart card and a trusted remote server. Any intermediate node, including the host computer to which the smart card is connected, cannot compromise this secure connection.	online identity;smart card	Karen Lu;Asad M. Ali	2004		10.1007/978-3-540-30144-8_29	smart card;computer science;operating system;database;internet privacy;openpgp card;secure copy;world wide web;computer security	Crypto	-44.9750526163115	77.91551175726094	182257
17398637d914ffd7db64703ae51ef393974fcb17	how to strengthen pseudo-random generators by using compression	pseudo random generator;modelizacion;generic model;stream ciphering;securite;cryptanalyse;algebraic attack;numero seudo aleatorio;decimation;generateur nombre aleatoire;methode algebrique;permutation;cryptanalysis;modelisation;sucesion seudo aleatoria;criptoanalisis;suite pseudoaleatoire;stream cipher;nombre pseudoaleatoire;criptografia;cryptography;algebraic method;random sequence;permutacion;safety;registro dispersion;pseudorandom sequence;cryptographie;pseudorandom number;metodo algebraico;seguridad;modeling;cifrado continuo;decimacion;registre decalage;shift register;random number generators;cryptage continu	Sequence compression is one of the most promising tools for strengthening pseudo-random generators used in stream ciphers. Indeed, adding compression components can thwart algebraic attacks aimed at LFSR-based stream ciphers. Among such components are the Shrinking Generator and the Self-Shrinking Generator, as well as recent variations on Bit-Search-based decimation. We propose a general model for compression used to strengthen pseudo-random sequences. We show that there is a unique (up to length-preserving permutations) construction that reaches an optimal trade-off between output rate and security against several attacks.	decimation (signal processing);existential quantification;format-preserving encryption;linear-feedback shift register;pseudorandomness;self-shrinking generator;shrinking generator;stream cipher	Aline Gouget;Hervé Sibert	2006		10.1007/11761679_9	cryptanalysis;discrete mathematics;decimation;computer science;cryptography;theoretical computer science;random sequence;mathematics;shift register;permutation;stream cipher;algorithm;statistics	Crypto	-39.88888708959547	81.44358045968312	182377
7857e48c7de93fcbe1e84b9836c22d99e6d7cb15	lattice-based homomorphic encryption of vector spaces	encrypted messages;vector spaces;lattices;probabilistic lattice;vector space;cryptography noise security lattices public key vectors probabilistic logic;group theory;lattice based homomorphic encryption;bounded homomorphic encryption scheme;group theory cryptography;public key;vectors;cryptography;group theory lattice based homomorphic encryption vector spaces bounded homomorphic encryption scheme probabilistic lattice encrypted messages decryption operations;decryption operations;probabilistic logic;security;noise;homomorphic encryption	In this paper we introduce a new probabilistic lattice-based bounded homomorphic encryption scheme. For this scheme the sum of two encrypted messages is the encryption of the sum of two messages and the scheme is able to preserve a vector spave structure of the message. The size of the public key is rather large ap 3 Mb but the encryption and the decryption operations are very fast (of the same speed order than NTRU). The homomorphic operation, i.e. the addition of ciphertexts is dramatically fast compared to homomorphic schemes based on group theory like Paillier or El Gamal.	cryptosystem;fastest;homomorphic encryption;lattice model (finance);lenstra–lenstra–lovász lattice basis reduction algorithm;ntru;public-key cryptography;sensitivity and specificity;utility functions on indivisible goods	Carlos Aguilar Melchor;Guilhem Castagnos;Philippe Gaborit	2008	2008 IEEE International Symposium on Information Theory	10.1109/ISIT.2008.4595310	multiple encryption;discrete mathematics;40-bit encryption;vector space;theoretical computer science;link encryption;mathematics;homomorphic secret sharing;filesystem-level encryption;group theory;computer security;encryption;probabilistic encryption;56-bit encryption;attribute-based encryption	Crypto	-39.471013261770864	77.48333851769272	182625
c7bf75cbe413f9032ef3bb66788836dcdc69e297	proxy blind multi-signature scheme without a secure channel	provable security;analisis numerico;matematicas aplicadas;mathematiques appliquees;proxy multi signature;multisignature procuration;logarithme discret;discrete logarithm;analyse numerique;signature scheme;numerical analysis;criptografia;random oracle model;cryptography;proxy signature;cryptographie;blind signature;signature procuration;58a25;applied mathematics;62p12;signature aveugle;oracle	Proxy signature and blind signature are two active cryptographic research areas, and have been applied in many occasions respectively. At the same time, to cope with some particular settings, proxy blind signature, two signatures combination, also becomes a current research hotspot. To our knowledge, many proxy blind signature schemes have been put forth till now. However, most of these proposed schemes have not been provably secure and all should rely on secure channels to transmit proxy secret key, and yet a secure channel could not always be obtained in current network environment. Therefore, in this paper, we would like to present a new proxy blind multi-signature scheme, which does not need a secure channel and is provably secure under the Random Oracle model.	digital signature;proxy server;secure channel	Rongxing Lu;Zhenfu Cao;Yuan Zhou	2005	Applied Mathematics and Computation	10.1016/j.amc.2004.04.063	oracle;discrete logarithm;commitment scheme;numerical analysis;cryptography;provable security;mathematics;internet privacy;blind signature;world wide web;computer security;algorithm	Crypto	-43.66552997055551	76.8497997566862	182911
2665b91e318841d8043890e87101ea3f9015435c	analysing a batch range proof to address a security concern	security properties;malicious prover batch range proof analysis security concern address verification technique;security of data program verification;program verification;satisfiability;high efficiency;security of data;protocols computer science cryptography privacy encoding polynomials	In Africacrypt 2010, Peng and Bao propose a batch proof and verification technique and apply it to design efficient range proof with practical small ranges. Their range proof employs a batch proof and verification technique by Chida and Yamamoto. We show that the batch proof and verification fails in security such that a malicious prover without the claimed knowledge can pass the verification. As a result, there is security concern for the range proof scheme as it may be vulnerable to the attack. However, it is illustrated in this paper that the attack must work under a condition and a simple countermeasure can fail the condition and prevent the attack in the range proof scheme.		Kun Peng;Feng Bao	2011	2011 14th IEEE International Conference on Computational Science and Engineering	10.1109/CSE.2011.26	computer science;theoretical computer science;database;computer security;algorithm;satisfiability	Logic	-41.00703127684642	76.53997032851422	183332
a67358219143adf66cc29b1f907098e254ff06b0	multi-trail statistical saturation attacks	institutional repositories;fedora;block cipher;branch and bound algorithm;natural extension;vital;theoretical analysis;vtls;ils;possibility distribution	Statistical Saturation Attacks have been introduced and applied to the block cipher PRESENT at CT-RSA 2009. In this paper, we consider their natural extensions. First, we investigate the existence of better trails than the one used in the former attack. For this purpose, we provide a theoretical evaluation of the trail distributions using probability transition matrices. Since the exhaustive evaluation of all possible distributions turned out to be computationally hard, we additionally provide a heuristic branch-and-bound algorithm that allows us to generate a large number of good trails. These tools confirm that the trail of CT-RSA 2009 was among the best possible ones, but also suggest that numerous other trails have similar properties. As a consequence, we investigate the use of multiple trails and show that it allows significant improvements of the previous cryptanalysis attempts against PRESENT. Estimated complexities indicate that PRESENT-80 is safe against key recovery, by a small security margin. We also discuss the impact of multiple trails for the security of the full PRESENT-128. We finally put forward a “statistical hull” effect that makes the precise theoretical analysis of our results difficult, when the number of block cipher rounds increases.	algorithm;block cipher;branch and bound;brute-force attack;coefficient;decorrelation theory;ext js javascript framework;heuristic;key escrow;linear cryptanalysis;rsa (cryptosystem);time complexity;variable shadowing	Baudoin Collard;François-Xavier Standaert	2010		10.1007/978-3-642-13708-2_8	block cipher;simulation;computer science;mathematics;computer security;branch and bound;algorithm;statistics	AI	-37.33188257909975	80.89759363449629	183621
0c7592770ac1d8894f82eb3652fc72cd62ac3a07	gracefully degrading fair exchange with security modules	developpement logiciel;electronic trading;modelizacion;estimacion sesgada;commerce electronique;seguridad funcionamiento;fair exchange;consensus;fiabilidad;pana omision;reliability;llave cambio;surete fonctionnement;confiance;panne omission;psychologie sociale;comercio electronico;bolsa valores;omission failure;building block;arret au plus tot;courtage electronique;distributed computing;nccr mics;echange cle;algorithme deterministe;probabilistic approach;omission failures;bourse valeurs;stock exchange;modelisation;deterministic algorithms;confidence;key exchange;confianza;consenso;criptografia;desarrollo logicial;enfoque probabilista;cryptography;approche probabiliste;fiabilite;dependability;software development;psicologia social;early stopping;nccr mics cl4;calculo repartido;cryptographie;social psychology;parada mas temprana;security;modeling;biased estimation;calcul reparti;estimation biaisee;electronic trade	The fair exchange problem is key to trading electronic items in systems of mutually untrusted parties. In modern variants of such systems, each party is equipped with a security module. The security modules trust each other but can only communicate by exchanging messages through their untrusted host parties, that could drop those messages. We describe a synchronous algorithm that ensures deterministic fair exchange if a majority of parties are honest, which is optimal in terms of resilience. If there is no honest majority, our algorithm degrades gracefully: it ensures that the probability of unfairness can be made arbitrarily low. Our algorithm uses, as an underlying building block, an early-stopping subprotocol that solves, in a general omission failure model, a specific variant of consensus we call biased consensus. Interestingly, this modular approach combines concepts from both cryptography and distributed computing, to derive new results on the classical fair exchange problem.	algorithm;cryptography;distributed computing;early stopping;fault tolerance;graceful exit	Gildas Avoine;Felix C. Freiling;Rachid Guerraoui;Marko Vukolic	2005		10.1007/11408901_5	stock exchange;consensus;key exchange;early stopping;telecommunications;computer science;cryptography;artificial intelligence;information security;software development;reliability;dependability;distributed computing;electronic trading;confidence;computer security;algorithm	Crypto	-44.289112757707436	78.53406465059051	183832
36f59c691a1d3ee421f3fb092b8f7c0c90d4fe4e	a weil descent attack against elliptic curve cryptosystems over quartic extension fields	weil descent attack;hyperelliptic curve cryptosystems;scholten form;tecnologia electronica telecomunicaciones;c_ curves;cab curves;hyperelliptic curve cryptosystem;tecnologias;grupo a;elliptic curve cryptosystem;elliptic curve cryptosystems	This paper shows that many of elliptic curve cryptosystems over quartic extension fields of odd characteristics are reduced to genus two hyperelliptic curve cryptosystems over quadratic extension fields. Moreover, it shows that almost all of the genus two hyperelliptic curve cryptosystems over quadratic extension fields of odd characteristics come under Weil descent attack. This means that many of elliptic curve cryptosystems over quartic extension fields of odd characteristics can be attacked by Weil descent uniformly.	cryptosystem;descent;elliptic curve cryptography;quartic function	Seigo Arita;Kazuto Matsuo;Koh-ichi Nagao;Mahoro Shimura	2004	IEICE Transactions	10.1093/ietfec/e89-a.5.1246	arithmetic;discrete mathematics;jacobian curve;twists of curves;tripling-oriented doche–icart–kohel curve;quartic plane curve;hyperelliptic curve cryptography;edwards curve;mathematics;hessian form of an elliptic curve;modular elliptic curve;hyperelliptic curve;elliptic curve point multiplication;algebra	Crypto	-39.6161961516844	80.98916249512494	183941
330352ef71887be022330d7a9bcd6ab50cffb635	dual rsa and its security analysis	public key cryptography;key generation algorithms;secrecy;cryptographie cle publique;private key cryptography;security analysis;encryption;security public key cryptography elliptic curve cryptography sun elliptic curves computer science authentication lattices computational efficiency councils;private exponent;authentication;digital signatures;rsa;twin rsa cryptography encryption lattice basis reduction lll algorithm rebalanced rsa rsa;twin rsa;lattice basis reduction;public key cryptography digital signatures private key cryptography;indexing terms;securite donnee;cryptage rsa;secret;rsa ciphering;authentification;algorithme;algorithm;it security;autenticacion;elliptic curve cryptography;public key;rebalanced rsa;cifrado rsa;cryptography;blind signatures;public exponent;lattice basis reduction dual rsa security analysis key generation algorithms public exponent private exponent blind signatures authentication cryptography encryption;blind signature;lll algorithm;computational efficiency;security;security of data;cathode ray tubes;secreto;algoritmo;dual rsa	We present new variants of an RSA whose key generation algorithms output two distinct RSA key pairs having the same public and private exponents. This family of variants, called dual RSA, can be used in scenarios that require two instances of RSA with the advantage of reducing the storage requirements for the keys. Two applications for dual RSA, blind signatures and authentication/secrecy, are proposed. In addition, we also provide the security analysis of dual RSA. Compared to normal RSA, the security boundary should be raised when applying dual RSA to the types of small-d, small-e, and rebalanced-RSA.	algorithm;antivirus software;authentication;bit-length;blind signature;cathode ray tube;computation;computational complexity theory;correctness (computer science);cryptosystem;dspace;duality (optimization);encryption;key generation;keygen;lagrange multiplier;like button;modulus of continuity;modulus robot;ne (complexity);public-key cryptography;rsa (cryptosystem);randomness;requirement;security parameter;unique key	Hung-Min Sun;Mu-En Wu;Wei-Chi Ting;M. Jason Hinek	2007	IEEE Transactions on Information Theory	10.1109/TIT.2007.901248	computer science;information security;theoretical computer science;pkcs #1;authentication;mathematics;internet privacy;public-key cryptography;computer security	Crypto	-40.69976832862032	78.5550223086976	184006
7a36108f505cc2239e0f5ff18e329c331be9f37a	foiling birthday attacks in length-doubling transformations - benes: a non-reversible alternative to feistel		For many cryptographic primitives, e.g., hashing and pseudorandom functions & generators, doubling the output length is useful  even if the doubling transformation is not reversible. For these cases, we present a non-reversible construction based on  a Benes network, as an alternative to the traditional Feistel construction (which is the basis of DES).    Assuming that a given primitive behaves like an n-bit to n-bit random function, we present a length-doubling scheme that yields a 2n-bit to 2n-bit function that provably requires Ω(2n) queries to distinguish with Θ(1) probability from a truly random function of that length. This is true even if the adversary is of unlimited computing  power and is allowed to query the function adaptively. Our construction is minimal in the sense that omitting any operation  makes the resulting network susceptible to birthday attacks using O(2  n/2) queries.        Feistel networks also use truly random n-bit functions to achieve 2n-bit functions. Luby and Rackoff [16] showed that 3 and 4 round Feistel networks require Ω(2  n/2) queries to distinguish with Θ(1) probability from truly random. We show that these bounds are tight by showing that these networks are susceptible various  types of birthday attacks using O(2  n/2) queries.      	feistel cipher;period-doubling bifurcation	William Aiello;Ramarathnam Venkatesan	1996		10.1007/3-540-68339-9_27		Crypto	-37.27338245711357	77.29813919336846	184140
213533b18841e51628bd09b977a62ae821a31fbb	imprimitive permutation groups and trapdoors in iterated block ciphers	permutation group;encryption;securite;block cipher;cryptanalyse;differential technique;tecnica diferencial;permutation;cryptanalysis;technique differentielle;cryptage;criptografia;cryptography;permutacion;safety;cryptographie;seguridad	An iterated block cipher can be regarded as a means of producing a set of permutations of a message space. Some properties of the group generated by the round functions of such a cipher are known to be of cryptanalytic interest. It is shown here that if this group acts imprimitively on the message space then there is an exploitable weakness in the cipher. It is demonstrated that a weakness of this type can be used to construct a trapdoor that appears to be di cult to detect. An example of a DES-like cipher, resistant to both linear and di erential cryptanalysis that generates an imprimitive group and is easily broken, is given. Some implications for block cipher design are noted.	block cipher;cryptanalysis;iterated function;iteration	Kenneth G. Paterson	1999		10.1007/3-540-48519-8_15	weak key;substitution-permutation network;arithmetic;block cipher;cryptanalysis;transposition cipher;key whitening;differential cryptanalysis;discrete mathematics;residual block termination;two-square cipher;running key cipher;null cipher;ciphertext stealing;computer science;cryptography;mathematics;permutation;stream cipher;permutation group;affine cipher;cbc-mac;encryption;algorithm;3-way;statistics	Crypto	-39.70417164297334	81.02293351667764	184271
0ee23e2a7500fed1167434581c7f1095434e8ce5	a sufficient condition for secure ping-pong protocols	verification of cryptographic protocols;cryptography;cryptographic protocol	A sufficient condition for secure ping–pong protocols is repretsented. This condition, called name– suffixing, is essentially to insert identities of participants in messages. We prove its sufficiency and discuss the feature of security in terms of name–suffixing.		Masao Mori	2001	IACR Cryptology ePrint Archive			Crypto	-40.85890771334903	75.29377553879881	184378
25a8a19de93e213392835bde016ab9c7d0dfc14b	a quantum network manager that supports a one-time pad stream	quantum key synchronization;quantum network;quantum key distribution;nist cryptography switches wavelength division multiplexing hardware software algorithms cryptographic protocols delay error analysis conference management;telecommunication network management quantum cryptography;secure communication;quantum network manager;one time pad;one time pad stream;secure cryptography quantum network manager one time pad stream quantum key distribution;secure cryptography;quantum cryptography;quantum protocol;telecommunication network management;quantum key synchronization quantum key distribution quantum network secure communication quantum protocol one time pad	We have begun to expand the NIST quantum key distribution (QKD) system into a quantum network to support secure cryptography. We are starting with a simple three-node network, one Alice switched between Bob1 and Bob2. To support such a quantum network, we have implemented a quantum network manager that not only handles the switch and QKD protocol startup operations but also handles multiplexing and synchronization of secret key streams. We describe the function, structure and interfaces of this quantum network manager and report on initial switching overhead. We also discuss some steps we plan to take to optimize that overhead as well as hide its latency for certain applications.	cryptography;fifo (computing and electronics);ipsec;key (cryptography);multi-user;multiplexing;network packet;one-time pad;overhead (computing);quantum information;quantum key distribution;quantum network;random access;transport layer security	Alan Mink;Lijun Ma;Tassos Nakassis;Hai Xu;Oliver Slattery;Barry Hershman;Xiao Tang	2008	Second International Conference on Quantum, Nano and Micro Technologies (ICQNM 2008)	10.1109/ICQNM.2008.8	quantum information;quantum key distribution;computer science;theoretical computer science;quantum network;distributed computing;quantum cryptography;bb84;computer network	Theory	-46.984282368791916	81.96875995638452	184439
c65e612c84afe8e471ad3b9de7d23156db0e4760	a latency-free election scheme	pseudo random function;multiparty computation	We motivate and describe the problem of finding protocols for multiparty computations that only use a single broadcast round per computation (latency-free computations). We show that solutions exists for one multiparty computation problem, that of elections, and more generally, addition in certain groups. The protocol construction is based on an interesting pseudo-random function family with a novel property.	computation;computational problem;interrupt latency;pseudorandom function family	Kristian Gjøsteen	2006	IACR Cryptology ePrint Archive	10.1007/978-3-540-79263-5_27	discrete mathematics;theoretical computer science;mathematics;distributed computing	Crypto	-37.90926591728229	76.64630787983567	184474
8bf31c5d5394b77c150d25d5763b3ec1dcd5c7ed	winning the caucus race: continuous leader election via public randomness.		Consensus protocols inherently rely on the notion of leader election, in which one or a subset of participants are temporarily elected to authorize and announce the network’s latest state. While leader election is a well studied problem, the rise of distributed ledgers (i.e., blockchains) has led to a new perspective on how to perform large-scale leader elections via solving a computationally difficult puzzle (i.e., proof of work). In this paper, we present Caucus, a large-scale leader election protocolwithminimal coordination costs that does not require the computational cost of proof-of-work. We evaluate Caucus in terms of its security, using a new model for blockchain-focused leader election, before testing an implementation of Caucus on an Ethereum private network. Our experiments highlight that one variant of Caucus costs only $0.10 per leader election if deployed on Ethereum. ACM Reference format: Sarah Azouvi, Patrick McCorry and Sarah Meiklejohn. 2016. Winning the Caucus Race: Continuous Leader Election via Public Randomness. In Proceedings of ACM Conference, Washington, DC, USA, July 2017 (Confer-	algorithmic efficiency;ethereum;experiment;leader election;lightning;private network;proof-of-work system;randomness	Sarah Azouvi;Patrick McCorry;Sarah Meiklejohn	2018	CoRR		private network;public relations;computer security;proof-of-work system;randomness;computer science;leader election;caucus	Crypto	-42.05070737348463	76.78979545919722	184791
18e0e3c2550694f31de2f0d7bce76082c463cea7	reduction in the number of fault injections for blind fault attack on spn block ciphers	aes;fault analysis;blind fault attack;information theory	In 2014, a new fault analysis called blind fault attack (BFA) was proposed, in which attackers can only obtain the number of different faulty outputs without knowing the public data. The original BFA requires 480,000 fault injections to recover a 128-bit AES key. This work attempts to reduce the number of fault injections under the same attack assumptions. We analyze BFA from an information theoretical perspective and introduce a new probability-based distinguisher. Three approaches are proposed for different attack scenarios. The best one realized a 66.8% reduction of the number of fault injections on AES.	128-bit;cryptanalysis;differential fault analysis;error-tolerant design;fault tolerance;information gain in decision trees;information privacy;information theory;kullback–leibler divergence;route distinguisher;substitution-permutation network	Yang Li;Mengting Chen;Zhe Liu;Jian Wang	2016	ACM Trans. Embedded Comput. Syst.	10.1145/3014583	advanced encryption standard;information theory;computer science;distributed computing;computer security;algorithm	Security	-42.127174832906114	80.73361908572376	184961
45ac4d6d3d20a7d36eb86acf920ea16db65322a8	a note on game-hopping proofs		Game hopping is a method for proving the security of a cryptographic scheme. In a game hopping proof, we observe that an attacker running in a particular attack environment has an unknown probability of success. We then slowly alter the attack environment until the attackers success probability can be computed. We also bound the increase in the attacker’s success probability caused by the changes to the attack environment. Thus, we can deduce a bound for the attacker’s success probability in the original environment. Currently, there are three known “types” of game hop: transitions based on indistinguishability, transitions based on failure events, and bridging steps. This note introduces a fourth type of game hop.	bridging (networking);computer security;cryptography;frequency-hopping spread spectrum	Alexander W. Dent	2006	IACR Cryptology ePrint Archive		discrete mathematics;mathematical proof;mathematics	Security	-36.850436178328934	74.73666612568691	184967
1977c964689f6f806c069414ca6395d64ba639f1	integrity-enhancing replica coordination for byzantine fault tolerant systems	byzantine fault toler- ance;threshold signature;middleware;replica consistency;coin-tossing;fault model	Strong replica consistency is often achieved by writing deterministic applications, or by using a variety of mechanisms to render replicas deterministic. There exists a large body of work on how to render replicas deterministic under the benign fault model. However, when replicas can be subject to malicious faults, most of the previous work is no longer effective. Furthermore, the determinism of the replicas is often considered harmful from the security perspective and for many applications, their integrity strongly depends on the randomness of some of their internal operations. This calls for new approaches towards achieving replica consistency while preserving the replica randomness. In this paper, we present two such approaches. One is based on Byzantine agreement and the other on threshold coin-tossing. Each approach has its strength and weaknesses. We compare the performance of the two approaches and outline their respective best use scenarios.	algorithm;business architecture;byzantine fault tolerance;emulator;fault model;overhead (computing);random number generation;randomness;software bug;testbed	Wenbing Zhao	2008	CoRR			OS	-33.9197365816982	74.54051700287597	185060
004364e2f6832bed5e9a5ef7bd4a00de85dc2a07	a synthetic indifferentiability analysis of some block-cipher-based hash functions	provable security;68w40;block cipher based hash function;block cipher;col;random oracle;68q25;indifferentiability;hash function	Nowadays, investigating what construction is better to be a cryptographic hash function is red hot. In [13], Maurer et al. first introduced the notion of indifferentiability as a generalization of the concept of the indistinguishability of two cryptosystems. At ASIACRYPT’06, Chang et al. [6] analyzed the indifferentiability security of some popular block-cipher-based hash functions, such as PGV constructions and MDC-2. In this paper, we investigate Chang et al.’s analysis of PGV constructions and the PBGV double block length constructions. In particular, we point out a more precise adversarial advantage of indifferentiability, by considering the two situations that whether the hash function is either keyed or not. Furthermore, Chang et al.[6] designed attacks on 4 PGV hash functions and PBGV hash function to prove they are differentiable from random oracle with prefix-free padding. We find a limitation in their differentiable attacks and construct our simulations to obtain the controversy results that those schemes are indifferentiable from random oracle with prefix-free padding and some other popular constructions.	block cipher;block code;cryptographic hash function;cryptosystem;dhrystone;flaw hypothesis methodology;hash-based message authentication code;high-level programming language;mdc-2;phpgedview;random oracle;route distinguisher;simulation;ueli maurer (cryptographer)	Zheng Gong;Xuejia Lai;Kefei Chen	2007	IACR Cryptology ePrint Archive	10.1007/s10623-008-9208-4	random oracle;merkle–damgård construction;block cipher;security of cryptographic hash functions;double hashing;hash function;perfect hash function;collision attack;merkle tree;sha-2;collision resistance;theoretical computer science;provable security;secure hash standard;hash chain;hash buster;rolling hash;algorithm;cryptographic hash function;mdc-2;swifft;hash tree	Crypto	-38.71580086521262	79.85989512029825	185242
20f6cb8d4901938713506d517c4f60cc0bcd3790	dependable and secure data storage in wireless ad hoc networks: an assessment of ds 2	desciframiento;distributed system;red sin hilo;complexite;seguridad funcionamiento;reseau communication;surete fonctionnement;reseau pair;systeme reparti;confidencialidad;mobile radiocommunication;encoding decoding;informatique mobile;decodage;decoding;reseau sans fil;cellular radio;wireless network;redundant number systems;complejidad;residue number systems;wireless ad hoc network;stockage donnee;ad hoc network;complexity;red ad hoc;radiocommunication service mobile;arithmetique;confidentiality;confidentialite;data storage;igual a igual p2p;sistema repartido;information dispersal algorithm;aritmetica;paradigm;reseau ad hoc;arithmetics;redundant residue number system;systeme nombre residu;dependability;paradigme;almacenamiento datos;mobile wireless network;modele donnee;radiotelephonie cellulaire;radiocomunicacion servicio movil;paradigma;mobile computing;data confidentiality;peer to peer;red de comunicacion;communication network;systeme nombre redondant;data models	DS is a dependable and secure data storage for mobile, wireless networks based on a peer-to-peer paradigm. DS provides support to create and share files under a write-once model, and ensures data confidentiality and dependability by encoding files in a Redundant Residue Number System. The paper analyzes the code efficiency of DS using a set of moduli allowing for efficient encoding and decoding procedures based on single precision arithmetic, and discusses the security issues. The comparison of DS with the Information Dispersal Algorithm approach (IDA) shows that DS features security features which are not provided by IDA, while the two approaches are comparable from the viewpoint of code efficiency and encoding/decoding complexity.	algorithm;algorithmic efficiency;code;computation;computer data storage;confidentiality;dependability;hoc (programming language);modulus of smoothness;overhead (computing);peer-to-peer;programming paradigm;residue number system;single-precision floating-point format;write once, run anywhere	Stefano Chessa;Roberto Di Pietro;Piero Maestrini	2004		10.1007/978-3-540-24614-5_14	wireless ad hoc network;confidentiality;telecommunications;computer science;artificial intelligence;operating system;mobile computing;computer security;computer network	Mobile	-45.49466733344392	79.3523243632125	185253
d9f00cfb709dbb975674f47d0f2f19a6a30904d1	ring signature scheme based on multivariate public key cryptosystems	security model;algebraic attack;multivariate public key cryptosystem;multivariate polynomial;quantum computer;algebraic attacks;quantum computing;ring signature;security	The ring signature scheme is an important cryptographic primitive that enables a user to sign a message on behalf of a group in authentic and anonymous way, i.e. the recipient of the message is convinced that the message is valid and it comes from one of the group members, but does not know who the actual signer is. Currently, all the existing ring signatures are based on traditional cryptosystems. However, the rapid advances in the field of quantum computing indicate a growing threat to traditional cryptosystems.Multivariate public key cryptosystems (MPKCs) is one of the promising alternatives which may resist future quantum computing attacks. In this work, we propose a novel ring signature scheme based on multivariate polynomials with the security model for the first time. Our ring signature scheme has a great advantage in efficiency compared to many existing ring signature schemes, and currently it seems to be immune to quantum computing attacks. © 2011 Elsevier Ltd. All rights reserved.	cryptographic primitive;cryptosystem;digital signature;polynomial;public-key cryptography;quantum computing;ring signature	Shangping Wang;Rui Ma;Yaling Zhang;Xiaofeng Wang	2011	Computers & Mathematics with Applications	10.1016/j.camwa.2011.09.052	ring signature;information security;theoretical computer science;mathematics;internet privacy;quantum computer;computer security;quantum mechanics	Crypto	-40.40099883921463	77.73959968049525	185482
854830791c61196542d1ebc9cacd98f090a44207	a novel identity-based anonymous authentication scheme from multilinear maps		Anonymous authentication is very useful to protect the useru0027s privacy, and plays an important role in building e-commence where involves many partners, such as in cloud computing. With the anonymous property, ring signature provides a cryptographic tool to construct a secure authentication scheme. In this paper, we construct an identity-based ring signature (IBRS) based on Garg-Gentry-Halevi (GGH) graded encoding system which is a candidate multilinear maps from ideal lattice, and prove its security in random oracle model. Under the GGH graded decisional Diffie-Hellman (GDDH) assumption, the proposed ring signature guarantees the anonymity of signer against full keys exposure attacks. Considering unforgeability, under the GGH graded computational Diffie- Hellman (GCDH) assumption, the new scheme provides unforgeability both against selectively chosen subring attacks and insider corruption.	authentication;map	Zhengjun Jing;Guoping Jiang;Chunsheng Gu	2018	IJICT	10.1504/IJICT.2018.10008896	anonymity;computer network;ring signature;multilinear map;random oracle;cloud computing;cryptography;computer security;distributed computing;computer science;authentication;subring	Crypto	-41.877785274610325	74.66781789844515	185567
2eb5f748d21c15e5cb2670891e80bb7174ed61b9	pre: stronger security notions and efficient construction with non-interactive opening	proxy re encryption;public key encryption;chosen ciphertext security;dbdh;knowledge of secret key model;chosen key model	In a proxy re-encryption (PRE) scheme, a proxy is given a re-encryption key and has the ability to translate a ciphertext under one key into a ciphertext of the same message under a different key, without learning anything about the message encrypted under either key. This paper first shows that the chosen key (CK) model which allows the adversary to adaptively choose public keys for malicious users, is strictly stronger than the knowledge of secret key models (KOSK) that most of previous PREs rely on. Then, the paper presents an efficient CCA secure PRE scheme in the stronger CK model based on the decisional bilinear Diffie-Hellman (DBDH) assumption without the random oracle heuristic. The paper also considers a useful property in PRE applications, namely, ''non-interactive opening'' and an extended scheme is given to support the property. Compared with previous schemes, the PRE scheme in this paper has a good overall performance in terms of ciphertext length, computational cost, strong and realistic security model as well as a well-studied assumption.	interactivity	Jiang Zhang;Zhenfeng Zhang;Yu Ju Chen	2014	Theor. Comput. Sci.	10.1016/j.tcs.2014.04.028	key;semantic security;key clustering;computer science;ciphertext indistinguishability;distributed computing;internet privacy;malleability;public-key cryptography;key distribution;computer security;ciphertext;attribute-based encryption	Crypto	-40.09783966570657	75.21624410985358	185715
f95d56bc6c5a2f0437602e4847016cccf53ed995	new results on the key scheduling algorithm of rc4	key scheduling algorithm;state table;cryptanalysis;scheduling algorithm;stream cipher;success rate;rc4	A new bias is detected in the key scheduling algorithm of RC4 and a novel framework that advantageously combines this new bias with the existing ones is proposed. Using the new bias, a different algorithm is proposed to retrieve the RC4 key given the state table. The new method not only improves the success probability but also provides a more efficient way of calculation in comparison with the previous methods for any key size. The efficiency of the algorithm is demonstrated experimentally. If the key length is 40 bits, the secret key is retrieved with a 99% success rate in 0.007 seconds. The success probability for retrieving the 128 bit RC4 key is also increased significantly. 128-bit key can be retrieved with 3% success rate in 185 seconds and 7.45% success rate in 1572 seconds on a 2.67GHz Intel CPU.	algorithm;rc4	Mete Akgün;Pinar Kavak;Hüseyin Demirci	2008		10.1007/978-3-540-89754-5_4	state transition table;cryptanalysis;real-time computing;computer science;theoretical computer science;mathematics;distributed computing;stream cipher;rc4;scheduling;statistics	EDA	-35.908966941973816	81.13486062100195	185733
6b4c6f81c666216132aa1f68aeec885cfcd3b22c	distributed assignment of cryptographic keys for access control in a hierarchy	des;cryptography;access control;distributed algorithm;article;key assignment	The problem of how to control access in a user hierarchy by cryptography was explored recently. However, these researches focus on the centralized environment. This paper presents a new distributed approach to assigning cryptographic keys which enables a member of the organization to derive, from his own key, the keys of members below him in the hierarchy, and consequently to have access to information enciphered under those keys. This proposed scheme also maintains the strength of adding new security classes into a partially ordered hierarchy without affecting the existing keys.	access control;cryptography;key (cryptography)	Bao-Min Shao;Jing-Jang Hwang;PeCheng Wang	1994	Computers & Security	10.1016/0167-4048(94)90098-1	distributed algorithm;computer access control;related-key attack;computer science;cryptography;access control;theoretical computer science;key management;symmetric-key algorithm;distributed computing;key space;computer security	Crypto	-47.82898835343341	77.735186034571	185911
17e387752bb08058592e30c18bc03f39231f7ca0	computational complexity and information asymmetry in election audits with low-entropy randomness	combinatorial graph theory;good election audit;computationally infeasible;election audit;pre-prepared table;low-entropy randomness;malicious table;computational complexity theory;random number;certain precinct;random table;information asymmetry	We investigate the security of an election audit using a table of random numbers prepared in advance. We show how this scenario can be modeled using tools from combinatorial graph theory and computational complexity theory, and obtain the following results: (1) A randomly generated table can be used to produce a statistically good election audit that requires less randomness to be generated in real time by the auditors. (2) It is likely to be computationally infeasible for an adversary to compute, given a pre-prepared table of random numbers, how to minimize their chances of detection in an audit. (3) It is computationally infeasible to distinguish a truly random table from a malicious table that has been modified to decrease the probability of detecting cheating in certain precincts.	adversary (cryptography);computational complexity theory;computational hardness assumption;graph theory;procedural generation;random access;random graph;randomness;semantic security;sensor;vulnerability (computing)	Nadia Heninger	2010			computer science;theoretical computer science;data mining;algorithm	Theory	-34.88300114653404	77.68985686118069	186015
78040597298bd11d52f50b426eb95abe73b19dec	on the existence of secure keystream generators	protection information;modelizacion;metodo polinomial;secuencia binaria;description systeme;binary sequence;system description;temps polynomial;concepcion sistema;maquina estado finito;keystream generators;indexing terms;securite donnee;asymptotic behavior;comportement asymptotique;algorithme;modelisation;algorithm;comportamiento asintotico;stream cipher;retroaccion;proteccion informacion;retroaction;polynomial method;criptografia;system design;cryptography;information protection;polynomial time;feedback regulation;registro dispersion;cryptographie;descripcion sistema;berlekamp massey;stream ciphers;sequence binaire;methode polynomiale;machine etat fini;security;modeling;registre decalage;security of data;shift register;finite state machine;conception systeme;key words binary sequences;algoritmo;tiempo polinomial	Designers of stream ciphers have generally used ad hoc methods to build systems that are secure against known attacks. There is often a sense that this is the best that can be done, that any system will eventually fall to a practical attack. In this paper we show that there are families of keystream generators that resist all possible attacks of a very general type in which a small number of known bits of a keystream are used to synthesize a generator of the keystream (called a synthesizing algorithm). Such attacks are exemplified by the Berlekamp—Massey attack. We first formalize the notions of a family of finite keystream generators and of a synthesizing algorithm. We then show that for any function h(n) that is in \cal O (2 n/d ) for every d>0 , there is a family \cal B of periodic sequences such that any efficient synthesizing algorithm outputs a generator of size h(log (\mathop \rm per \nolimits(B))) given the required number of bits of a sequence B∈ \cal B of large enough period. This result is tight in the sense that it fails for any faster growing function h(n) . We also consider several variations on this scenario.	algorithm;hoc (programming language);stream cipher	Andrew Klapper	2001	Journal of Cryptology	10.1007/s001450010014	asymptotic analysis;telecommunications;computer science;information security;theoretical computer science;mathematics;stream cipher;finite-state machine;computer security;algorithm	Crypto	-40.12217162644186	83.02054397348671	186182
52e1e7d73b537f5c96b1434f0c9b643494953409	new results on solving linear equations modulo unknown divisors and its applications		We revisit the problem of finding small solutions to a collection of linear equations modulo an unknown divisor p for a known composite integer N . In Asiacrypt’08, Herrmann and May introduced a heuristic algorithm for this problem, and their algorithm has many interesting applications, such as factoring with known bits problem, fault attacks on RSA signatures, etc. In this paper, we consider two variants of Herrmann-May’s equations, and propose some new techniques to solve them. Applying our algorithms, we obtain a few by far the best analytical/experimental results for RSA and its variants. Specifically, – We improve May’s results (PKC’04) on small secret exponent attack on RSA variant with moduli N = pq (r ≥ 2). – We extend Nitaj’s result (Africacrypt’12) on weak encryption exponents of RSA and CRT-RSA.	algorithm;antivirus software;cathode ray tube;differential fault analysis;encryption;heuristic (computer science);integer factorization;linear equation;modulo operation;rsa (cryptosystem)	Yao Lu;Rui Zhang;Dongdai Lin	2014	IACR Cryptology ePrint Archive			Crypto	-38.99773738306532	80.31765954313819	186249
5031d11ba3a4453ddf7f1e300566ba73a3e31eb4	new s/key system against dictionary attack: a case study in casper and csp/fdr	eke;s/key;casper;fdr;csp;dictionary attack;man in the middle attack;one time password	S/Key(One-Time Password) system has vulnerabilities such as dictionary attack. In this paper, we propose a corrected S/Key system mixed with EKE to solve the man-in-the-middle attack. In addition, we specify a new S/Key system with Casper, verify its secrecy and authentication properties using CSP/FDR.	authentication;dictionary attack;man-in-the-middle attack;password;s/key	Il-Gon Kim;Jin-Young Choi	2004			s/key;man-in-the-middle attack;dictionary attack;computer security;internet privacy;computer science;one-time password	Security	-44.4141786232319	74.6451947856655	186486
abc76a71800b5bee0dba0ee0b2006f1a25a79224	security of the pseudorandom number generators and implementations of public key signature schemes. (sécurité des générateurs pseudo-aléatoires et des implémentations de schémas de signature à clé publique)		In this thesis, we are interested in the security of pseudorandom number generators and of implementations of signature schemes. Regarding the signature schemes, we propose, in the case of a widespread implementation of RSA, various fault attacks which apply to any padding function. In addition we present a proven secure infective countermeasure to protect the RSA–PSS scheme against some non-random faults. Furthermore we study the ECDSA scheme coupled with the GLV/GLS speed-up techniques. Depending on the implementations, we prove either the good distribution of the used nonce, or that it has a bias, thereby enabling an attack. Finally we develop a tool for automatically finding fault attacks given an implementation and a fault policy, which is successfully applied to some RSA and ECDSA implementations. Regarding pseudorandom number generators, we study the nonlinear ones and improve some attacks by reducing the information available to the adversary. We also are interested in the security of the Micali-Schnorr generator through various attacks and a statistical study of its security assumption. Finally we propose a cryptanalysis of any public-key scheme based on the factorization or the discrete logarithm when the secret key is generated using a linear generator.		Jean-Christophe Zapalowicz	2014				Security	-39.647522571277	78.95188836571181	186527
6eefde435d01f835890d5de9f2508abf3e1d85c6	synchronous byzantine agreement with expected o(1) rounds, expected o(n2) communication, and optimal resilience		We present new protocols for Byzantine agreement in the synchronous and authenticated setting, tolerating the optimal number of f faults among n = 2f + 1 parties. Our protocols achieve an expected O(1) round complexity and an expected O(n) communication complexity. The exact round complexity in expectation is 10 for a static adversary and 16 for a strongly rushing adaptive adversary. For comparison, previous protocols in the same setting require expected 29 rounds and expected Ω(n) communication. We also give a lower bound showing that expected Ω(n) communication is necessary against a strongly rushing adaptive adversary.	adversary (cryptography);authentication;byzantine fault tolerance;communication complexity	Ittai Abraham;Srinivas Devadas;Danny Dolev;Kartik Nayak;Ling Ren	2018	IACR Cryptology ePrint Archive			Theory	-34.44909131616596	75.11781527128072	186550
e4acb11f3b20869ebbe21adce6dfe58eea3a75dc	short generators without quantum computers: the case of multiquadratics		Finding a short element g of a number field, given the ideal generated by g, is a classic problem in computational algebraic number theory. Solving this problem recovers the private key in cryptosystems introduced by Gentry, Smart–Vercauteren, Gentry–Halevi, Garg–Gentry– Halevi, et al. Work over the last few years has shown that for some number fields this problem has a surprisingly low post-quantum security level. This paper shows, and experimentally verifies, that for some number fields this problem has a surprisingly low pre-quantum security level.	computer;cryptosystem;experiment;linear algebra;post-quantum cryptography;public-key cryptography;quantum computing	Jens Bauch;Daniel J. Bernstein;Henry de Valence;Tanja Lange;Christine van Vredendaal	2017		10.1007/978-3-319-56620-7_2	computer science;theoretical computer science;pure mathematics;algorithm	Crypto	-38.69280639943729	79.89444020452264	186941
54e51f76b50d42a77e773fc9eb8be8caeaf75e3c	which new rsa-signatures can be computed from certain given rsa-signatures?	cryptographic protocol;criptografia;cryptography;necessary and sufficient condition;signature;cryptographie;signing;firma	We consider the following problem. A signature authority issues RSA-signatures of certain types to an individual, and the individual tries, by using the signatures he received, to compute an RSA-signature of a type not issued by the authority. Is the individual able to do this? The RSA-signatures are products of rational powers of residue classes modulo the composite number N of the underlying RSA-system, and the residue classes are chosen at random by the signature authority. The rational exponents in the product determine the type of the signature. We prove that computing an RSA-signature of a particular type, from given RSA-signatures of other types, is polynomial time reducible to computing RSA-roots x 1/d (mod N) for random x and some positive integer d. This extends results of Akl and Taylor [1] and Shamir [11] from one variable to arbitrarily many variables. As an application of this, under the assumption that for the individual it is infeasible to compute RSA-roots, we give necessary and sufficient conditions describing whether it is feasible for that individual to compute RSA-signatures of a prescribed type from signatures of other types that he received before from the authority.	antivirus software;modulo operation;polynomial;rsa (cryptosystem);type signature	Jan-Hendrik Evertse;Eugène van Heyst	1992	Journal of Cryptology	10.1007/BF00191320	ring signature;arithmetic;discrete mathematics;computer science;cryptography;cryptographic protocol;mathematics;signature;blind signature;schnorr signature;computer security;algorithm;algebra	Theory	-39.91573399154619	79.46968628822104	187078
4dad0396c92746c0444739c5e939a030b0c32dff	elliptic curves of prime order over optimal extension fields for use in cryptography	elliptic curve;complex multiplication;corps fini;courbe elliptique;finite field;curva eliptica;criptografia;cryptography;campo finito;cryptographie;extension;optimal extension field	We present an algorithm for generating elliptic curves of prime order over Optimal Extension Fields suitable for use in cryptography. The algorithm is based on the theory of Complex Multiplication. Furthermore, we demonstrate the efficiency of the algorithm in practice by giving practical running times. In addition, we present statistics on the number of cryptographically strong elliptic curves of prime order for Optimal Extension Fields of cardinality (2 + c) with c < 0. We conclude that there are sufficiently many curves in this case.	algorithm;strong cryptography	Harald Baier	2001		10.1007/3-540-45311-3_10	supersingular elliptic curve;discrete mathematics;sato–tate conjecture;twists of curves;complex multiplication;schoof–elkies–atkin algorithm;cryptography;counting points on elliptic curves;edwards curve;mathematics;elliptic curve cryptography;elliptic curve;elliptic curve point multiplication;finite field;schoof's algorithm;algebra	Crypto	-39.528019085992185	80.59437865312763	187366
021d80a3374498f62c07ec23c7f53bdaf0705124	polynomial time attack on wild mceliece over quadratic extensions	public key cryptography;complexity theory;decoding;encryption;goppa code distinguishing problem mceliece cryptosystem wild goppa code cryptanalysis;encryption complexity theory public key cryptography decoding	We present a polynomial-time structural attack against the McEliece system based on Wild Goppa codes defined over a quadratic finite field extension. We show that such codes can be efficiently distinguished from random codes. The attack uses this property to compute a filtration, that is to say, a family of nested subcodes which will reveal their secret algebraic description.	binary goppa code;cryptanalysis;dual code;linear algebra;mceliece cryptosystem;p (complexity);polynomial;protein family;route distinguisher;time complexity	Alain Couvreur;Ayoub Otmani;Jean-Pierre Tillich	2017	IEEE Transactions on Information Theory	10.1109/TIT.2016.2574841	discrete mathematics;mceliece cryptosystem;computer science;theoretical computer science;mathematics;goppa code;public-key cryptography;encryption;algebra	Crypto	-39.33797421308726	80.89375175828822	187974
e63660121fe521432d61c6ec6fcd72ccdef5e2ec	automated analysis and synthesis of padding-based encryption schemes		Verifiable security is an emerging approach in cryptography that advocates the use of principled tools for building machine-checked security proofs of cryptographic constructions. Existing tools following this approach, such as EasyCrypt or CryptoVerif, fall short of finding proofs automatically for many interesting constructions. In fact, devising automated methods for analyzing the security of large classes of cryptographic constructions is a long-standing problem which precludes a systematic exploration of the space of possible designs. This paper addresses this issue for padding-based encryption schemes, a class of public-key encryption schemes built from hash functions and trapdoor permutations, which includes widely used constructions such as RSA-OAEP. Firstly, we provide algorithms to search for proofs of security against chosen-plaintext and chosenciphertext attacks in the random oracle model. These algorithms are based on domain-specific logics with a computational interpretation and yield quantitative security guarantees; for proofs of chosenplaintext security, we output machine-checked proofs in EasyCrypt. Secondly, we provide a crawler for exhaustively exploring the space of padding-based encryption schemes under user-specified restrictions (e.g. on the size of their description), using filters to prune the search space. Lastly, we provide a calculator that computes the security level and efficiency of provably secure schemes that use RSA as trapdoor permutation. Using these three tools, we explore over 1.3 million encryption schemes, including more than 100 variants of OAEP studied in the literature, and prove chosen-plaintext and chosen-ciphertext security for more than 250,000 and 17,000 schemes, respectively. IMDEA Software Institute, Spain. E-mail: {gilles.barthe,juanmanuel.crespo,cesar.kunz}@imdea.org INRIA Sophia Antipolis – Méditerranée, France. E-mail: benjamin.gregoire@inria.fr Université de Grenoble, VERIMAG, France. E-mail: yassine.lakhnech@imag.fr Microsoft Research, UK. E-mail: santiago@microsoft.com	algorithm;chosen-ciphertext attack;ciphertext;cryptoverif;domain-specific language;encryption;hash function;microsoft research;plaintext;provable security;public-key cryptography;random oracle;trapdoor function;web crawler	Gilles Barthe;Juan Manuel Crespo;Benjamin Grégoire;César Kunz;Yassine Lakhnech;Santiago Zanella Béguelin	2012	IACR Cryptology ePrint Archive		random oracle;encryption;cryptography;verifiable secret sharing;theoretical computer science;padding;trapdoor function;hash function;computer science;optimal asymmetric encryption padding	Crypto	-35.99950951787544	77.99494106984636	188013
8b4c8a1b46ea2c7cadaab647697552255af8b443	gcm-siv: full nonce misuse-resistant authenticated encryption at under one cycle per byte	block cipher modes of operation;gcm;nonce misuse resistance	Authenticated encryption schemes guarantee both privacy and integrity, and have become the default level of encryption in modern protocols. One of the most popular authenticated encryption schemes today is AES-GCM due to its impressive speed. The current CAESAR competition is considering new modes for authenticated encryption that will improve on existing methods. One property of importance that is being considered more today -- due to multiple real-life cases of faulty sources of randomness -- is that repeating nonces and IVs can have disastrous effects on security. A (full) nonce misuse-resistant authenticated encryption scheme has the property that if the same nonce is used to encrypt the same message twice, then the same ciphertext is obtained and so the fact that the same message was encrypted is detected. Otherwise, full security is obtained -- even if the same nonce is used for different messages. In this paper, we present a new fully nonce misuse-resistant authenticated encryption scheme that is based on carefully combining the GCM building blocks into the SIV paradigm of Rogaway and Shrimpton. We provide a full proof of security of our scheme, and an optimized implementation using the AES-NI and PCLMULQDQ instruction sets. We compare our performance to the highly optimized OpenSSL 1.0.2 implementation of GCM and show that our nonce misuse-resistant scheme is only 14% slower on Haswell architecture and 19% slower on Broadwell architecture. On Broadwell, GCM-SIV encryption takes only 0.92 cycles per byte, and GCM-SIV decryption is exactly the same as GCM decryption taking only 0.77 cycles per byte. In addition, we compare to other optimized authenticated-encryption implementations carried out by Bogdanov et al., and conclude that our mode is very competitive. Beyond being very fast, our new mode of operation uses the same building blocks as GCM and so existing hardware and software can be utilized to easily deploy GCM-SIV. We conclude that GCM-SIV is a viable alternative to GCM, providing full nonce misuse-resistance at little cost.	aes instruction set;authenticated encryption;authentication;block cipher mode of operation;broadwell (microarchitecture);clmul instruction set;ciphertext;cryptographic nonce;cycles per byte;galois/counter mode;google cloud messaging;haswell (microarchitecture);openssl;programming paradigm;randomness;real life	Shay Gueron;Yehuda Lindell	2015		10.1145/2810103.2813613	block cipher mode of operation;computer science;theoretical computer science;cryptographic nonce;gcm transcription factors;distributed computing;on-the-fly encryption;computer security;encryption	Security	-35.83339418099749	78.81449537891355	188091
568e4e92b64d20b711aa68e08bd7eba02a95b36c	sequential bitwise sanitizable signature schemes	pseudorandom generator	A sanitizable signature scheme is a signature scheme which, after the signer generates a valid signature of a message, allows a specific entity (sanitizer) to modify the message for hiding several parts. Existing sanitizable signature schemes require the message to be divided into pre-defined blocks before signing so that each block can be sanitized independently. However, there are cases where the parts of the message which are needed to be sanitized can not be determined in the time of signing. Thus, it is difficult to decide the partition of the blocks in such cases. Since the length of the signature is usually proportional to the number of blocks, signing every bit independently will make the signature too long. In this paper, we propose a solution by introducing a new concept called sequential bitwise sanitizable signature schemes, where any sequence of bits of the signed document can be made sanitizable without pre-defining them, and without increasing the length of signature. We also show that a one-way permutation suffices to get a secure construction, which is theoretically interesting in its own right, since all the other existing schemes are constructed using stronger assumptions. key words: sanitizable signature, bitwise control, one-way permutation, pseudorandom generator	bitwise operation;digital signature;one-way function;pseudorandom generator;pseudorandomness	Goichiro Hanaoka;Shoichi Hirose;Atsuko Miyaji;Kunihiko Miyazaki;Bagus Santoso;Peng Yang	2011	IEICE Transactions		ring signature;discrete mathematics;merkle signature scheme;computer science;theoretical computer science;mathematics;pseudorandom generator;blind signature;schnorr signature;algorithm	Crypto	-37.24664533867687	79.03844147392994	188340
ecc165cb7bc1d01230f01b2effa051850ffb732b	secure and self-stabilizing clock synchronization in sensor networks	self stabilizing algorithm;resilient computer systems;stabilization;random media;secure clock synchronization;sensor network;self stabilization;sensor networks;secure and resilient computer systems;message passing;clock synchronization;algorithms;sensor network systems;security;article in monograph or in proceedings	In sensor networks, correct clocks have arbitrary starting offsets and nondeterministic fluctuating skews. We consider an adversary that aims at tampering with the clock synchronization by intercepting messages, replaying intercepted messages (after the adversary’s choice of delay), and capturing nodes (i.e., revealing their secret keys and impersonating them). We present the first self-stabilizing algorithm for secure clock synchronization in sensor networks that is resilient to such an adversary’s attacks. Our algorithm tolerates random media noise, guarantees with high probability efficient communication overheads, and facilitates a variety of masking techniques against pulse-delay attacks in the presence of captured nodes.	adversary (cryptography);algorithm;clock synchronization;self-stabilization;with high probability	Jaap-Henk Hoepman;Andreas Larsson;Elad Michael Schiller;Philippas Tsigas	2007		10.1007/978-3-540-76627-8_26	clock synchronization;computer science;distributed computing;computer security;computer network	Theory	-34.08793677738536	74.82896066150784	188553
046cd9bcecd662abad5e7e7707c043b8e2578cc8	faster lego-based secure computation without homomorphic commitments		LEGO-style cut-and-choose is known for its asymptotic efficiency in realizing actively-secure computations. The dominant cost of LEGO protocols is due to wire-soldering — the key technique enabling to put independently generated garbled gates together in a bucket to realize a logical gate. Existing wire-soldering constructions rely on homomorphic commitments and their security requires the majority of the garbled gates in every bucket to be correct. In this paper, we propose an efficient construction of LEGO protocols that does not use homomorphic commitments but is able to guarantee security as long as at least one of the garbled gate in each bucket is correct. Additionally, the faulty gate detection rate in our protocol doubles that of the state-of-the-art LEGO constructions. We have implemented our protocol and our experiments on several benchmark applications show that the performance of our approach is highly competitive in comparison with existing implementations.	benchmark (computing);experiment;logic gate;secure multi-party computation;soldering	Ruiyu Zhu;Yan Huang	2017	IACR Cryptology ePrint Archive		theoretical computer science;secure two-party computation;homomorphic encryption;secure multi-party computation;distributed computing;computer science	Security	-38.55729581588675	75.02871668873881	188609
af0d88dc248457d32ba9d99ae18260db26c3ed2f	block ciphers : security proofs, cryptanalysis, design, and fault attacks/	institutional repositories;fedora;vital;vtls;ils	Block ciphers are widely used building blocks for secure communication systems; their purpose is to ensure confidentiality of the data exchanged through such systems, while achieving high performance. In this context, a variety of aspects must be taken into account. Primarily, they must be secure. The security of a block cipher is usually assessed by testing its resistance against known attacks. However as attacks may exist that are currently unknown, generic security proofs are also tried to be obtained. On the other hand, another attack methodology is also worth considering. Contrary to the others, it aims at the implementation of the algorithm rather than the cipher itself. It is known as side-channel analysis. Finally, performance of a block cipher in terms of throughput is very important as well. More than any other cryptographic primitive, block ciphers allow a tradeoff to be made between security and performance. In this thesis, contributions are given regarding these various topics. In the first part of the thesis, we deal with two particular types of attacks, namely the square attack and key schedule cryptanalysis. We also consider security proofs in the so-called Luby-Rackoff model, which deals with adversaries having unbounded computation capabilities. More precisely, we are interested in the Misty structure, when the round functions are assumed to be involutions. The second part of the thesis is devoted to design and implementation aspects. First, we present a fault attack on substitution-permutation networks, which requires as few as two faulty ciphertexts to retrieve the key. We also study the security of DeKaRT , which is an algorithm intended to protect smart cards against probing attacks. Finally we present the design of ICEBERG, a block cipher deliberately oriented towards good performance in hardware, and give an adequate analysis of its security.	algorithm;block cipher;computation;confidentiality;cryptographic primitive;cryptography;differential cryptanalysis;differential fault analysis;encryption;feistel cipher;integral cryptanalysis;key schedule;michael luby;secure communication;side-channel attack;smart card;substitution-permutation network;throughput;vii	Gilles-François Piret	2005			block cipher;differential cryptanalysis;computer science;cryptography;theoretical computer science;key schedule;correlation attack;stream cipher attack;internet privacy;slide attack;computer security	Crypto	-39.75533690893608	78.58276483650123	189020
bbe8258f38a3c72d6c068727f5f879d3b30aa4cb	forward secure password-enabled pki with instant revocation	public key cryptography;user mobility;carte a puce;secrecy;controle acces;besoin de l utilisateur;smart card;interfase usuario;cryptographie cle publique;movilidad;confiance;keyword;forward secrecy;cle privee;user interface;mobility;securite informatique;trust authority;cle publique;necesidad usuario;palabra clave;mobilite;mot cle;long terme;remote operation;specification language;secret;long term;computer security;confidence;public key;smartcard;largo plazo;mot de passe;clave privada;private key;confianza;smart cards;user need;teleaccion;seguridad informatica;password;signature;llave publica;pki;interface utilisateur;lenguaje especificacion;access control;forward security;unidad aritmetica;signing;unite arithmetique;langage specification;firma;secreto;contrasena;arithmetic unit;teleoperation	Recently the concept of password-enabled PKI is an emerging issue to support user mobility. Virtual soft token and virtual smartcard were proposed as the password-enabled PKI. However, the virtual soft token does not support key disabling. In the virtual smartcard, the user must interact with remote entity per signing operation. In addition, both schemes do not support forward secrecy and instant revocation.#R##N##R##N#In this paper, we propose a new approach that supports user mobility. The proposed approach supports key disabling and the user does not need interaction with the remote entity for each signature. Moreover, the proposed scheme allows instant key revocation. Thereby, the distribution of CRL is not required. Furthermore, the proposed scheme supports forward secrecy. In this sense, our scheme, implemented only software, is stronger than a long-term private key with physical smart cards. By forward secrecy and instant revocation, signing documents using a time-stamp provided by a trusted authority is not required to protect from modifying signed document by the adversary who knows private key.	password;public key infrastructure	Seung Wook Jung;Souhwan Jung	2006		10.1007/11774716_5	smart card;telecommunications;computer science;operating system;database;public-key cryptography;mobile computing;world wide web;computer security	Crypto	-44.87884583760352	77.20760741172435	189112
151980aa92ede631e91b1ced7d275376b8e528db	extended substitution cipher chaining mode (escc)		In this paper, we present a new tweakable narrow-block mode of operation, the Extended Substitution Cipher Chaining mode (ESCC), that can be efficiently deployed in disk encryption applications. ESCC is an extension of Substitution Cipher Chaining mode (SCC) [5]. Unlike SCC, ESCC is resistant to the attacks in [6, 7, 8].	bit-flipping attack;block cipher mode of operation;disk encryption;stream cipher;throughput	Mohamed Abo El-Fotouh;Klaus Diepold	2009	IACR Cryptology ePrint Archive		disk encryption;parallel computing;theoretical computer science;block cipher mode of operation;substitution cipher;chaining;computer science	Crypto	-36.01700544587642	79.84387099160524	189216
0027363af300a4a6b67d986eb9c72e2ed04ccc2e	a novel multilayered rfid tagged cargo integrity assurance scheme	anonymity;concurrency attacks;multi session attacks;radio frequency identification;supply chain management;multilayered grouping proof	To minimize cargo theft during transport, mobile radio frequency identification (RFID) grouping proof methods are generally employed to ensure the integrity of entire cargo loads. However, conventional grouping proofs cannot simultaneously generate grouping proofs for a specific group of RFID tags. The most serious problem of these methods is that nonexistent tags are included in the grouping proofs because of the considerable amount of time it takes to scan a high number of tags. Thus, applying grouping proof methods in the current logistics industry is difficult. To solve this problem, this paper proposes a method for generating multilayered offline grouping proofs. The proposed method provides tag anonymity; moreover, resolving disputes between recipients and transporters over the integrity of cargo deliveries can be expedited by generating grouping proofs and automatically authenticating the consistency between the receipt proof and pick proof. The proposed method can also protect against replay attacks, multi-session attacks, and concurrency attacks. Finally, experimental results verify that, compared with other methods for generating grouping proofs, the proposed method can efficiently generate offline grouping proofs involving several parties in a supply chain using mobile RFID.	ampersand;authentication;computation;concurrency (computer science);denial (psychology);expedited report;information security;logistics;membrane transport proteins;mobile rfid;numerous;online and offline;page hijacking;protocols documentation;radio frequency identification device;radio-frequency identification;replay attack;spectinomycin;tags (device);theft;tracer;anatomical layer;standards characteristics	Ming-Hour Yang;Jia-Ning Luo;Shao-Yong Lu	2015		10.3390/s151027087	radio-frequency identification;supply chain management;anonymity;telecommunications;computer science;internet privacy;world wide web;computer security	Security	-43.715773687498285	74.54903561453462	189220
177356fbef0b6cba5882549720a2af6753690507	improvement of treeless signature schemes implementation by random oracle buffering	lattice algorithms;digital signature;post quantum cryptography	This study is devoted to the optimization of implementation of a recent treeless signature scheme called TSS12. It was shown earlier that the most computational complexity of TSS12 signing algorithm is provided by numerous calls to a Gaussian random oracle in undefined number of attempts to find a suitable masking vector. It is shown in this paper that a several hundred byte buffer of pre-generated random data is capable of providing significant acceleration of TSS12 signing algorithm. This fact is believed to be important for digital signature implementation on devices with limited computational capacities, such as wireless sensors.		Maxim Anikeev	2015		10.1145/2799979.2800045	digital signature;computer science;theoretical computer science;post-quantum cryptography;distributed computing;schnorr signature;computer security;algorithm	Security	-36.57094303644093	78.71003985714042	189456
459151d2cb7395c5d939d2aee9dade8c1e647859	a secure and efficient mix network especially suitable for e-voting		A mix network is proposed in this paper. Its most operations are carried out in an off-line one-time initialization phase so that its on-line efficiency is very high. Although this two-phase mechanism has a limitation to parameter setting, we show that the limitation does not prevent the mix network from being employed in its main application, e-voting, with the help of a grouped shuffling mechanism. Its achievement of desired security properties is formally proved.	mix network	Kun Peng	2012		10.1007/978-3-642-34679-8_16	data mining;mix network;shuffling;initialization;provable security;computer science;voting	Security	-43.441255321427164	74.98841059415724	189595
482473321965f86caeea3a3abb33f51da1aab169	a distributed cross-realm identification scheme based on hyperchaos system	distributed;encryption;hyperchaos;identity authentication	Aiming at the existing the system closed limitations in centralized authentication, was proposed a distributed cross-realm authentication anonymously mechanism suit for network parallel. And systematically analyzed the security system, based on 3d generalized Hénon mapping and Rijndael algorithm, designed and implemented hyperchaotic data encryption. Made the system has credibility, safety, efficiency, etc. © 2011 Springer-Verlag Berlin Heidelberg.	identification scheme	Jinqing Li;Fengming Bai	2011		10.1007/978-3-642-23756-0_24	realm;identification scheme;encryption;credibility;advanced encryption standard;distributed computing;computer science;authentication	Crypto	-45.5785728379731	75.80300689419512	190036
b63f00cc420d741c04a728fb20f260a0ba6f7339	gevosh: using grammatical evolution to generate hashing functions	hash function;grammatical evolution		grammatical evolution;hash function	Patrick Berarducci;Demetrius Jordan;David Martin;Jennifer Seitzer	2004			theoretical computer science;machine learning;artificial intelligence;computer science;grammatical evolution;hash function;feature hashing;universal hashing	NLP	-36.847749732068884	82.06995919334857	190055
d04415bcac748c999283bd69a8e0c9605fbc96f8	certificate-based smooth projective hashing and its applications		Smooth projective hashing was firstly introduced by Cramer and Shoup (EuroCrypt’02) as a tool to construct efficient chosen-ciphertext-secure public key encryption schemes. Since then, they have found many other applications, such as password-based authenticated key exchange, oblivious transfer, zero-knowledge arguments et al. Certificate-based encryption (CBE) not only eliminates third-party queries and heavy certificate management problem in traditional public-key encryption, but also solves key escrow problem for identity-based encryption. We introduce the new concept of certificate-based smooth projective hashing (CB-SPH). Under the security model for the leakage-resilient certificate-based encryption (LR-CBE), we show how to construct a general leakage-resilient certificate-based encryption scheme using the certificate-based smooth projective hashing. Based on these theoretical constructions, we present two concrete CB-SPH instantiations under the DBDH assumption and the DLWE assumption respectively. Based on these CB-SPH instantiations, we can construct leakage resilient CBE schemes.	adaptive chosen-ciphertext attack;authenticated key exchange;authentication;certificate-based encryption;ciphertext;hash function;id-based encryption;key escrow;lr parser;oblivious transfer;password;public-key cryptography;smoothed-particle hydrodynamics;spectral leakage	Sujuan Li;Yi Mu;Mingwu Zhang	2018	I. J. Network Security		certificate;computer network;projective test;theoretical computer science;hash function;computer science	Crypto	-39.905224588062396	76.33521784381836	190367
e3adad90eae6f451675bd4590076269fe4174327	fast multiparty multiplications from shared bits		We study the question of securely multiplying N -bit integers that are stored in binary representation, in the context of protocols for dishonest majority with preprocessing. We achieve communication complexity O(N) using only secure operations over small fields F2 and Fp with log(p) ≈ log(N). For semi-honest security we achieve communication O(N)2 ∗(N)) using only secure operations over F2. This improves over the straightforward solution of simulating a Boolean multiplication circuit, both asymptotically and in practice.	algorithm;binary number;communication complexity;preprocessor;semiconductor industry;simulation;toom–cook multiplication;whole earth 'lectronic link	Ivan Damgård;Tomas Toft;Rasmus Winther Zakarias	2016	IACR Cryptology ePrint Archive			Crypto	-37.616282708117254	76.57049347594096	190432
119bb86ccd167962d377d31deeb04de7e1c13ba7	accelerating the scalar multiplication on genus 2 hyperelliptic curve cryptosystems	hyperelliptic curve cryptosystem;scalar multiplication	viii	32-bit;64-bit computing;adversary (cryptography);algorithmic number theory symposium;alternating direction implicit method;andrew donald booth;atomic formula;automata theory;bibliothèque de l'école des chartes;binary number;bézier curve;cantor;catherine;centre for applied cryptographic research;christof ebert;coefficient;communications of the acm;computer science;cryptology eprint archive;cryptosystem;danny lange;database normalization;digital signature;directed graph;ecrypt;elliptic curve cryptography;genera;genus (mathematics);gerhard ringel;graph (discrete mathematics);graph traversal;harley's humongous adventure;hyperelliptic curve cryptography;ieee transactions on computers;informatics;information theory;jacobian matrix and determinant;jan bergstra;jorge urrutia galicia;journal of cryptology;journal of symbolic computation;karatsuba algorithm;linear algebra;magma;matrix multiplication;modulus of continuity;montgomery modular multiplication;pkc (conference);period-doubling bifurcation;polynomial;precomputation;public-key cryptography;requirement;scalar processor;search algorithm;selected areas in cryptography;semiconductor industry;side-channel attack;springer (tank);time complexity;tree traversal;type signature;victor s. miller;wilfried brauer	Balasingham Balamohan	2011	IACR Cryptology ePrint Archive		arithmetic;discrete mathematics;hyperelliptic curve cryptography;mathematics;hyperelliptic curve;elliptic curve point multiplication;algebra	Crypto	-40.97625663882553	80.76721497471506	190491
7ecc1d1894847adaae53b1436d19287b6d9c8d85	cryptanalysis on aw digital signature scheme based on error-correcting codes	error correcting code;digital signature error correcting code cryptanalysis;cryptanalysis digital signature error correcting code;cryptanalysis;public key;error correction code;digital signature;digital signature scheme	In 1993, Alabhadi and Wicker gave a modification to Xinmei Digital Signature Scheme based on error-correcting codes, which is usually denoted by AW Scheme. In this paper we show that the AW Scheme is actually not secure: anyone holding public keys of the signatory can obtain the equivalent private keys, and then forge digital signatures for arbitrary messages successfully. We also point out that one can hardly construct a digital signature scheme with high-level security due to the difficulty of decomposing large matrixes.	adjusted winner procedure;antivirus software;code;cryptanalysis;digital signature;error detection and correction;forge;forward error correction;high- and low-level	Zhenfeng Zhang;Dengguo Feng;Zongduo Dai	2002	Science in China Series F Information Sciences	10.1007/BF02714096	ring signature;error detection and correction;merkle signature scheme;eddsa;computer science;theoretical computer science;digital signature algorithm;mathematics;internet privacy;blind signature;schnorr signature;elgamal signature scheme;computer security;statistics	Crypto	-37.377461742095875	79.24946097351038	190558
a9487876c176a6a5e76dcc3e93c05d6868dd9a70	current state of multivariate cryptography		A review of the current state of multivariate public-key cryptosystems compares and contrasts the most promising multivariate schemes in digital signatures and public-key encryption as well as their security.	antivirus software;cryptosystem;digital signature;encryption;multivariate cryptography;public-key cryptography	Jintai Ding;Albrecht Petzoldt	2017	IEEE Security & Privacy	10.1109/MSP.2017.3151328	computer security;internet privacy;computer science;neural cryptography;id-based cryptography;theoretical computer science;multivariate statistics;signcryption;pkcs #1;financial cryptography;multivariate cryptography;cryptography law	Security	-41.35149731929114	78.2435960288929	190806
d1ade8c7bbb415482ee6d694b06c1655c8e156a9	a fully-secure rfid authentication protocol from exact lpn assumption	pseudo inverse matrix;hill cipher;privacy analysis fully secure rfid authentication protocol exact lpn assumption light weight cryptographic solution rfid system hb family learning parity noise problem lpn problem mobile wireless reader application channel assumption security fully secure collaborative mutual authentication protocol channel tag reader channel reader server lpn based commitment scheme perfect computational hiding commitment scheme pseudoinverse matrix randomized hill cipher security analysis;telecommunication security cryptographic protocols data privacy radiofrequency identification;cryptographic protocols;exact lpn problem;servers protocols silicon authentication radiofrequency identification vectors;data privacy;mutual authentication;telecommunication security;hill cipher mutual authentication exact lpn problem pseudo inverse matrix;radiofrequency identification	In the recent years, several light-weight cryptographic solutions have been proposed for RFID system. HB-family is one of promising protocol series, based on the hardness of the Learning Parity with Noise (LPN) problem. Most protocols in HB-family are not suited for mobile/wireless reader applications due to secure channel assumptions. In this paper, we present a fully secure collaborative mutual authentication protocol for an RFID system where both channels tag-reader and reader-server are considered to be insecure. More precisely, we introduce a new variant of an HB-like protocol where the complete RFID system is authenticated under LPN-based commitment scheme by taking advantages of properties of perfect computational hiding commitment scheme, pseudo inverse matrix, and randomized Hill cipher. In addition, through detailed security and privacy analysis, we show that our scheme achieves required security and privacy properties, under not the random oracle model, but the standard model.	authentication protocol;cipher;commitment scheme;cryptography;electronic product code;mutual authentication;parity learning;radio-frequency identification;random oracle;randomized algorithm;secure channel;server (computing)	Mohammad Saiful Islam Mamun;Atsuko Miyaji	2013	2013 12th IEEE International Conference on Trust, Security and Privacy in Computing and Communications	10.1109/TrustCom.2013.17	computer science;theoretical computer science;internet privacy;computer security	Security	-41.26864182070283	75.9204065208202	190896
f6b26d8f6b9d8757e1f80645b62ebd3538a07bc4	a novel generic session based bit level encryption technique to enhance information security	information security	In this paper a session based symmetric key encryption system has been proposed and is termed as Permutated Cipher Technique (PCT). This technique is more fast, suitable and secure for larger files. In this technique the input file is broken down into blocks of various sizes (of 2^n order) and encrypted by shifting the position of each bit by a certain value for a certain number of times. A key is generated randomly wherein the length of each block is determined. Each block length generates a unique value of “number of bits to be skipped”. This value determines the new position of the bits within the block that are to be shifted. After the shifting and inverting each block is XOR’ed with SHA-512 digest of the key. The resultant blocks from the cipher text. The key is generated according to the binary value of the input file size. Decryption is done following the same process as the technique is symmetric. KeywordsPermutated Cipher Technique (PCT); Session Based; Number of Bits to Skip (NBSk); Maximum Iterations (MaxIter); Iterations done for encrypting (eIter); Iterations done for decrypting (dIter); Symmetric Key.	binary number;block code;ciphertext;cryptanalysis;cryptographic hash function;encryption;feistel cipher;information security;iteration;key (cryptography);randomness;resultant;sha-2;symmetric-key algorithm	Manas Paul;Tanmay Bhattacharya;Suvajit Pal;Ranit Saha	2009	CoRR		block cipher mode of operation;computer science;information security;theoretical computer science;distributed computing;computer security;cbc-mac	Crypto	-36.58022598955138	80.57620025076388	191122
5c3910efee4fa025b0cd9ca3da7a29d59ee76a3a	a new multivariate based threshold ring signature scheme		In CRYPTO 2011, Sakumoto et al. presented a 3-pass identification protocol whose security is solely based on the MQ problem. This identification protocol was extended to a threshold ring signature scheme by Petzoldt et al. via Fiat-Shamir transformation in AAECC 2013. In this paper, we present a multivariate based Γ-protocol based on Sakumoto et al.’s work, and extend it to a threshold ring signature scheme by applying Γ-transformation (TIFS 2013). Compared with Petzoldt et al.’s work, our scheme reduces signature length and rounds by 21% and 29% respectively to achieve 80-bit security. What’s more, our scheme has higher level provable security, enjoys much better performance on power limited devices, and can be flexible deployed in interactive protocols. To the best of our knowledge, it is the first application of Γ-transformation in post-quantum cryptography.	ring signature;scheme	Jingwan Zhang;Yiming Zhao	2014		10.1007/978-3-319-11698-3_42	ring signature;theoretical computer science;computer science;computer network;cryptography;multivariate statistics;multivariate cryptography;provable security	Crypto	-40.5088421741567	76.41237184424996	191265
29be7e4e54e25599e9f8895e94c88b1b4d5f86c9	attribute-based ring signcryption scheme and its application in wireless body area networks	identity based ring signcryption;wireless body area networks;key policy attribute based ring signcryption;会议论文;identity based ring signature;key policy attribute based encryption	Wireless body area network (WBAN) technology has attracted intensive attention from the academic and industrial research communities in recent years. For widespread deployment of WBANs, security and privacy must be addressed properly. In this paper, we introduce a new cryptographic primitive named key-policy attributebased ring signcryption (KP-ABRSC) scheme, which is a combination of identity-based ring signature scheme and key-policy attribute-based encryption scheme. In KP-ABRSC, each signcrypted message is labeled by the sender with a set of descriptive attributes and a list of identities of potential senders, while an access structure is embedded in each user’s private key by a trusted authority. We give formal syntax and security definitions for KP-ABRSC scheme and construct a KP-ABRSC scheme from bilinear pairings. The proposed KP-ABRSC scheme is proven to be indistinguishable against adaptive chosen plaintext attacks under the DBDH assumption and existentially unforgeable against adaptive chosen message and identity attacks under the CDH assumption. Finally, we present a cloud-based healthcare framework by exploiting our proposed KP-ABRSC scheme and WBANs, which can ensure data authenticity, confidentiality and non-repudiation, but also can offer participants privacy and fine-grained access control on encrypted medical data.	access control;access structure;attribute-based encryption;bilinear filtering;cloud computing;computational diffie–hellman assumption;confidentiality;cryptographic primitive;digital signature forgery;embedded system;formal grammar;message authentication;non-repudiation;plaintext;public-key cryptography;ring signature;signcryption;software deployment	Changji Wang;Jing Liu	2015		10.1007/978-3-319-27161-3_47	signcryption;internet privacy;computer security;computer network	Security	-41.84433922309706	75.27328644386736	191294
714505513827e8482c354ff7aa1f3ea43381562a	2-source extractors under computational assumptions and cryptography with defective randomness	linear min entropy;protocols;probability;network weak random source extractor cryptography;imperfect randomness;weak random source;cryptographic protocols;computable permutation;distributed computing;polynomials;computer network;nonnegligible probability;probability cryptographic protocols entropy;cryptography entropy access protocols computer science circuits polynomials distributed computing computer networks algorithm design and analysis cryptographic protocols;cryptography;lossless computational network extractor protocol;2 source extractors;computational assumptions;extractor;entropy;defective randomness;program processors;imperfect randomness 2 source extractors computational assumptions cryptography defective randomness linear min entropy computable permutation nonnegligible probability lossless computational network extractor protocol;secure multiparty computation;network	We show how to efficiently extract truly random bits from two independent sources of linear min-entropy, under a computational assumption. The assumption we rely on is the existence of an efficiently computable permutation $f$, such that for any source $X\in\{0,1\}^n$ with linear min-entropy, any circuit of size $\poly(n)$ cannot invert $f(X)$ with non-negligible probability. Under the stronger assumption that $f(X)$ cannot be inverted even by circuits of size $\poly(n^{log n})$ with non-negligible probability, we design a lossless computational network extractor protocol. Namely, we design a protocol for a set of players, each with access to an independent source of linear min-entropy, with the guarantee that at the end of the protocol, each honest player is left with bits that are computationally indistinguishable from being uniform and private. Our protocol succeeds as long as there are at least two honest players. Our results imply that if such one-way permutations exist, and enhanced trapdoor permutations exist, then secure multiparty computation with imperfect randomness {\em is possible} for any number of players, as long as at least two of them are honest. We also construct a network extractor protocol for the case where each source has only {\em polynomially-small} min-entropy($n^\delta$ for some constant $\delta≫0$). For this we need at least a constant $u(\delta)$ (which depends on $\delta$) number of honest players, and we need that the one-way permutation is hard to invert even on polynomially small min-entropy sources.	artificial neural network;computable function;computational hardness assumption;computational indistinguishability;cryptography;lossless compression;maxima and minima;one-way function;randomness extractor;secure multi-party computation;trapdoor function	Yael Tauman Kalai;Xin Li;Anup Rao	2009	2009 50th Annual IEEE Symposium on Foundations of Computer Science	10.1109/FOCS.2009.61	extractor;entropy;combinatorics;discrete mathematics;computer science;cryptography;theoretical computer science;probability;mathematics;algorithm;statistics	Theory	-36.87356700417544	76.39513216355427	191329
4ae8c45c565894a2ee84be81c82f947dfd3c5e59	determining the optimal random-padding size for rabin cryptosystems		Rabin encryption and a secure ownership transfer protocol based on the difficulty of factorization of a public key use a small public exponent. Such encryption requires random number padding. The Coppersmith’s shortpad attack works effectively on short padding, thereby allowing an adversary to extract the secret message. However, the criteria for determining the appropriate padding size remains unclear. In this paper, we derived the processing-time formula for the shortpad attack and determined the optimal random-padding size in order to achieve the desired security.	adversary (cryptography);cryptosystem;encryption;public-key cryptography;random number generation	Masahiro Kaminaga;Toshinori Suzuki;Masaharu Fukase	2018	CoRR		artificial intelligence;encryption;padding;pattern recognition;public-key cryptography;computer science;coppersmith;adversary;theoretical computer science;cryptosystem;factorization;exponent	Crypto	-38.34778453271245	78.83600921937511	191436
4344a5ee979f8b143c0d76891aab7d14b505f1da	new efficient batch verification for an identity-based signature scheme	identity based system;authenticated key agreement;digital signature;batch verification	Batch verification is a method to verify multiple digital signatures at a batch in time less than total individual verification time. Batch verification for an identity-based signature scheme IBS is attractive because a short public identity such as an e-mail address can be used as a verification key.	digital signature	Jung Yeon Hwang;Dooho Choi;Hyun Sook Cho;Boyeon Song	2015	Security and Communication Networks	10.1002/sec.1194	digital signature;computer science;database;distributed computing;computer security	Crypto	-42.62063297790246	76.22489904701422	191703
6db5d98bc0860af220ebbbc7d3e4288c1ee00dea	helen: a public-key cryptosystem based on the lpn and the decisional minimal distance problems	learning from parity with noise problem;random linear code;public key cryptosystem;lpn;minimum distance problem;code based cryptosystem	We propose HELEN, a code-based public-key cryptosystem whose security is based on the hardness of the Learning from Parity with Noise problem (LPN) and the decisional minimum distance problem. We show that the resulting cryptosystem achieves indistinguishability under chosen plaintext attacks (IND-CPA security). Using the FujisakiOkamoto generic construction, HELEN achieves IND-CCA security in the random oracle model. Our cryptosystem looks like the Alekhnovich cryptosystem. However, we carefully study its complexity and we further propose concrete optimized parameters.	adversary (cryptography);ciphertext indistinguishability;code;color gradient;cryptosystem;encryption;learning with errors;overhead (computing);plaintext;public-key cryptography;random oracle;return statement	Alexandre Duc;Serge Vaudenay	2013		10.1007/978-3-642-38553-7_6	benaloh cryptosystem;paillier cryptosystem;goldwasser–micali cryptosystem;plaintext-aware encryption;theoretical computer science;threshold cryptosystem;cryptosystem;mathematics;hybrid cryptosystem;computer security;cramer–shoup cryptosystem;algorithm	Crypto	-37.910224467848465	79.57860071710769	192263
c18c4d8a6c7a84bc6eda67ce9fe31d7830fbfb0b	steganography: a class of algorithms having secure properties	watermarking;mathematical theory of chaos;stego security;chaos;steganography chaos iterative methods security of data;iterative methods;media;steganography;vectors;chaos media signal processing algorithms watermarking vectors robustness;robustness;mathematical theory of chaos steganography watermarking stego security;signal processing algorithms;chaos security steganography secure properties chaos based approaches nonblind information hiding algorithms finite domains iterations devaney topologically chaotic chaos mathematical theory stego security;security of data	Chaos-based approaches are frequently proposed in information hiding, but without obvious justification. Indeed, the reason why chaos is useful to tackle with discretion, robustness, or security, is rarely elucidated. This research work presents a new class of non-blind information hiding algorithms based on some finite domains iterations that are Devaney's topologically chaotic. The approach is entirely formalized and reasons to take place into the mathematical theory of chaos are explained. Finally, stego-security and chaos security are consequently proven for a large class of algorithms.	algorithm;chaos theory;coefficient;iteration;simulation;steganography	Jacques M. Bahi;Jean-François Couchot;Christophe Guyeux	2011	2011 Seventh International Conference on Intelligent Information Hiding and Multimedia Signal Processing	10.1109/IIHMSP.2011.87	media;digital watermarking;computer science;theoretical computer science;mathematics;iterative method;steganography;programming language;computer security;algorithm;statistics;robustness	Robotics	-40.89901904546346	84.29559234035098	192310
8535e89fa250a8e5fca5ce2d35edfdb4d4963941	cryptographic figures of merit	cryptography;figure of merit;security	This paper endeavours to find a basis for the assignment of a figure of merit to cryptographic algorithms. Such a figure can then be used to evaluate the effectiveness of a particular algorithm. Figures of merit based upon theoretical information principles and complexity theory are first discussed. It is then shown how cydomatic complexity can be used in assigning a figure of merit to an algorithm. Finally, figures of merit for a number of algorithms, obtained by using different evaluation techniques, are compared.	algorithm;computational complexity theory;cryptography;evaluation function	Dirk Van der Bank;Edwin Anderssen	1988	Computers & Security	10.1016/0167-4048(88)90036-3	figure of merit;computer science;cryptography;information security;theoretical computer science;computer security;algorithm	Crypto	-37.76309480368258	82.13128989014118	192511
70696cf7ad9722bbc000afab41fe1e4912d3c6d5	a fair anonymous submission and review system	anonymity;distributed system;confiance;systeme reparti;confidencialidad;multimedia;authentication;securite informatique;confidentiality;authentification;anonymat;computer security;vida privada;confidentialite;reputation system;confidence;sistema repartido;autenticacion;internet;private life;confianza;seguridad informatica;vie privee;anonymous credentials;review;privacy;anonimato	Reputation systems play an important role in many Internet communities. They allow individuals to estimate other individual?s behavior during interactions. However, a more privacy-friendly reputation system is desirable while maintaining its trustworthiness. This paper presents a fair anonymous submission and review system. The review process is reputation-based and provides better anonymity properties than existing reputation systems. Moreover, the system allows for accountability measures. Anonymous credentials are used as basic blocks. A Fair Anonymous Submission and Review	application domain;basic block;digital credential;e-commerce;fairness measure;ibm research;interaction;internet;jan bergstra;peer-to-peer;reputation system;trust (emotion)	Vincent Naessens;Liesje Demuynck;Bart De Decker	2006		10.1007/11909033_5	computer science;authentication;database;internet privacy;world wide web;computer security	Security	-45.16134955683185	77.99305464861423	192555
a854d9aebee23f9129ad08deb4331a409ffc9513	security of the gpt cryptosystem and its applications to cryptography	code based cryptography;public key cryptosystem;gabidulin code;rank distance codes	The public key cryptosystem (PKC) based on rank error correcting codes (the GPT cryptosystem) was proposed in 1991. Use of rank codes in cryptographic applications is advantageous since it is practically impossible to utilize combinatoric decoding. This enabled using public keys of a smaller size. Several attacks against this system were published, including Gibson’s attacks and more recently Overbeck’s attacks. A few modifications were proposed withstanding Gibson’s attack but at least one of them was broken by the stronger attacks by Overbeck. A tool to prevent Overbeck’s attack is presented by Gabidulin, which makes the cryptographer define a proper column scrambler matrix over the extension field without violating the standard mode of GPT cryptosystem. In this paper, we apply this tool to another variant of the GPT cryptosystem. Furthermore we increase the security of the proposed system against all known attacks and reduce the public key size to 4 Kbits instead of 10 Kbits. Copyright © 2010 John Wiley & Sons, Ltd.	authorization;complexity;copy protection;existential quantification;forward error correction;guid partition table;information theory;john d. wiley;key size;matrix multiplication;mceliece cryptosystem;pkc (conference);public-key cryptography;qr code;scrambler	Haitham Rashwan;Ernst M. Gabidulin;Bahram Honary	2011	Security and Communication Networks	10.1002/sec.228	telecommunications;theoretical computer science;threshold cryptosystem;cryptosystem;hybrid cryptosystem;computer security	Crypto	-37.31253195679021	79.42128776684696	192732
63361afa2423bd4de6543fdd9b99e4460a9dc9fe	practical security against differential and linear cryptanalysis for sms4-like cipher	block cipher;sms4 like cipher;linear cryptanalysis;practical security;differential cryptanalysis	SMS4, a block cipher which employs a special kind of unbalanced Feistel structure, has been accepted as the Chinese National Standard for securing Wireless LANs. This paper investigates the upper bounds of the maximum differential and linear characteristic probabilities of SMS4like cipher, in order to evaluate the practical security against differential and linear cryptanalysis. In the same way as for SPN ciphers, if F-function is bijective, we give a simple formula to calculate the minimum number of active F-functions (s-boxes) with regard to the number of rounds and the number of input words in each round. This result provides a convenient tool for the practical security threshold analysis of the SMS4-like cipher against differential and linear attacks.	block cipher;feistel cipher;linear cryptanalysis;s-box;substitution-permutation network;unbalanced circuit	Qiu-Yan Wang;Bin Zhang;Chen-Hui Jin	2013	JNW	10.4304/jnw.8.8.1689-1693	block cipher;transposition cipher;differential cryptanalysis;two-square cipher;running key cipher;piling-up lemma;computer science;theoretical computer science;key schedule;boomerang attack;higher-order differential cryptanalysis;distributed computing;stream cipher;impossible differential cryptanalysis;affine cipher;slide attack;computer security;cbc-mac;3-way;statistics;linear cryptanalysis	Crypto	-38.833028238937985	81.15362757129884	192845
40558771b0c438bdecdc37db9a930115975803f1	a medium field multivariate public key signature scheme with external perturbation	grobner basis attack;public key cryptography;medium field equation mfe;differential attacks;rank attack multivariate public key cryptography quantum computation medium field equation mfe high order linearization equation hole;differential attacks medium field multivariate public key signature external perturbation mfe central map high order linear equation attack rank attacks grobner basis attack;grobner basis;high order linearization equation hole;external perturbation;perturbation techniques;polynomials;rank attacks;quantum computation;signature scheme;public key;mfe central map;quantum computer;rank attack;mathematical model;public key public key cryptography polynomials equations quantum computing galois fields security information science resists information technology;multivariate public key cryptography;linear equations;public key cryptography perturbation techniques;high order linear equation attack;medium field multivariate public key signature	In this paper, we redesign the MFE central map, and then present a signature scheme. The new scheme can resist high order linear equation attack, rank attacks, Gröbner basis attack, differential attacks etc, and also keep advantages in efficiency and implementation as the original version.	differential cryptanalysis;digital signature;encryption;gröbner basis;linear equation;public-key cryptography	Li Tian;Wansu Bao	2010	2010 Third International Symposium on Intelligent Information Technology and Security Informatics	10.1109/IITSI.2010.149	combinatorics;discrete mathematics;theoretical computer science;mathematics	Crypto	-39.929742026731226	80.89744023269503	192912
60df56265b2a38b407f2f446054e6db8f061c12d	survey on lightweight primitives and protocols for rfid in wireless sensor networks		The use of radio frequency identification (RFID) technologies is becoming widespread in all kind of wireless network-based applications. As expected, applicatio ns based on sensor networks, ad-hoc or mobile ad hoc networks ( MANETs) can be highly benefited from the adoption of RFID soluti ons. There is a strong need to employ lightweight cryptographic pri mitives for many security applications because of the tight cos and constrained resource requirement of sensor based networks. This paper mainly focuses on the security analysis of lightweight pro toc ls and algorithms proposed for the security of RFID systems . A large number of research solutions have been proposed to implement lightweight cryptographic primitives and protocols in sensor and RFID integration based resource constraint networks. In this work, an overview of the currently discussed lightweight primitives and their attributes has been done. These primitives an d protocols have been compared based on gate equivalents (GEs), powe r, technology, strengths, weaknesses and attacks. Furt her, an integration of primitives and protocols is compared with the possibilities of their applications in practical sc enarios.	algorithm;authentication;computer;confidentiality;cryptosystem;error detection and correction;gate equivalent;hoc (programming language);identity document forgery;information security;non-repudiation;packet delay variation;post-quantum cryptography;quality of service;quantum computing;radio frequency;radio-frequency identification;routing;throughput	Manju Lata;Adarsh Kumar	2014	IJCNIS		distributed computing;computer security;computer network	Mobile	-47.859379328777194	75.51705580456829	193140
1ad4ad05ac08849e0198c7abedaeba1c1e42a739	pseudorandom function tribe ensembles based on one-way permutations: improvements and applications	informatica;cle privee;encryption;via unica;poids hamming;improvement;generateur fonction;funcion aleatoria;voie unique;pseudo random function;permutation;sucesion seudo aleatoria;suite pseudoaleatoire;cryptage;private key;criptografia;cryptography;random function;amelioration;permutacion;mejoria;generador funcion;pseudorandom sequence;cryptographie;informatique;computer science;one way;function generator;fonction aleatoire	Pseudorandom function tribe ensembles are pseudorandom function ensembles that have an additional collision resistance property: almost all functions have disjoint ranges. We present an alternative to the construction of pseudorandom function tribe ensembles based on oneway permutations given by Canetti, Micciancio and Reingold [7]. Our approach yields two different but related solutions: One construction is somewhat theoretic, but conceptually simple and therefore gives an easier proof that one-way permutations suffice to construct pseudorandom function tribe ensembles. The other, slightly more complicated solution provides a practical construction; it starts with an arbitrary pseudorandom function ensemble and assimilates the one-way permutation to this ensemble. Therefore, the second solution inherits important characteristics of the underlying pseudorandom function ensemble: it is almost as efficient and if the starting pseudorandom function ensemble is invertible then so is the derived tribe ensemble. We also show that the latter solution yields so-called committing private-key encryption schemes. i.e., where each ciphertext corresponds to exactly one plaintext — independently of the choice of the secret key or the random bits used in the encryption process.	ciphertext;collision resistance;encryption;key (cryptography);one-way function;permutation pattern;plaintext;pseudorandom function family;pseudorandom number generator;pseudorandomness;public-key cryptography;symmetric-key algorithm;theory	Marc Fischlin	1999		10.1007/3-540-48910-X_30	pseudorandom generators for polynomials;combinatorics;function generator;computer science;cryptography;theoretical computer science;pseudorandom function family;random function;pseudorandom permutation;mathematics;permutation;pseudorandom generator;computer security;pseudorandomness;encryption;pseudorandom generator theorem;algorithm;statistics	Crypto	-38.66428092924606	78.7381375542755	193237
6489f284ae82e0b147e3b6b7bb48a66243aac44d	towards the development of a cyber analysis & advisement tool (caat) for mitigating de-anonymization attacks		We are seeing a rise in the number of Anonymous Social Networks (ASN) that claim to provide a sense of user anonymity. However, what many users of ASNs do not know that a person can be identified by their writing style. In this paper, we provide an overview of a number of author concealment techniques, their impact on the semantic meaning of an author's original text, and introduce AuthorCAAT, an application for mitigating de-anonymization attacks. Our results show that iterative paraphrasing performs the best in terms of author concealment and performs well with respect to Latent Semantic Analysis.	computer-aided audit tools;data anonymization;de-anonymization;fingerprint (computing);iteration;iterative method;latent semantic analysis;principle of good enough;printing	Siobahn C. Day;Henry Williams;Joseph Shelton;Gerry V. Dozier	2016			computer science;internet privacy;world wide web;computer security	Security	-46.217275526534806	75.33347165415138	193248
b495f163e8d513a5611e97b1e84687ac46550a54	ubapv2g: a unique batch authentication protocol for vehicle-to-grid communications	demand response;protocols;security analysis;real time;vehicles communication power control protocols security;authentication;cryptographic protocols;intelligent vehicles authentication batteries real time systems wireless communication computer security network security;hybrid vehicle;telecommunication traffic cryptographic protocols hybrid electric vehicles message authentication mobile communication power system security smart power grids telecommunication security;wireless communication;telecommunication traffic;smart power grids;batteries;mobile communication;telecommunication security;performance analysis;electricity;vehicles;message authentication;ubapv2g protocol unique batch authentication protocol vehicle to grid communications green energy scheme plug in hybrid vehicles electric hybrid vehicles smart grid demand response services v2g communications encryption decryption authentication delay communication traffic security analysis security attacks;hybrid electric vehicles;security;communication;power system security;authentication protocol;real time systems;power control	“Vehicle-to-grid” (V2G) power will be a new green energy scheme in which electric or plug-in hybrid vehicles communicate with the smart grid to sell demand response services by either delivering electricity into the grid or by throttling their charging rate. Due to high vehicular speed, sporadic connection, limited communication range, and large volume of data that need to be transmitted, V2G communications have the crucial requirements of fast authentication and encryption/decryption. This paper proposes a unique batch authentication protocol UBAPV2G that takes into account the characteristics of vehicle communication. The performance analysis shows that UBAPV2G can achieve less authentication delay, less computational cost, and less communication traffic, and security analysis shows that UBAPV2G is strong enough to defend against security attacks. The experimental results also demonstrate that UBAPV2G can achieve less authentication delay for large number of packets. Thus, UBAPV2G protocol is suitable for the stringent requirement of real time V2G communications.	algorithmic efficiency;authentication protocol;computation;encryption;network packet;plug-in (computing);requirement;verification and validation	Huaqun Guo;Yongdong Wu;Feng Bao;Hongmei Chen;Maode Ma	2011	IEEE Transactions on Smart Grid	10.1109/TSG.2011.2168243	embedded system;hybrid vehicle;power control;computer science;engineering;information security;authentication protocol;lightweight extensible authentication protocol;authentication;electricity;security analysis;computer security;computer network	Mobile	-47.67939470759173	75.55133477698851	193335
ea834f5ac9c112a827386ea755610722f5b215e4	introduction to electromagnetic information security			information security	Yu-ichi Hayashi;Naofumi Homma	2019	IEICE Transactions		information security;computer science;distributed computing	Crypto	-43.56147093952743	82.6096420002847	193410
bf9e4f1c0fc1ae73f1f438b10ceaa41e0d0bb6a4	g-merkle: a hash-based group signature scheme from standard assumptions		Hash-based signature schemes are the most promising cryptosystem candidates in a post-quantum world, but offer little structure to enable more sophisticated constructions such as group signatures. Group signatures allow a group member to anonymously sign messages on behalf of the whole group (as needed for anonymous remote attestation). In this work, we introduce G-Merkle, the first (stateful) hash-based group signature scheme. Our proposal relies on minimal assumptions, namely the existence of one-way functions, and offers performance equivalent to the Merkle single-signer setting. The public key size (as small as in the single-signer setting) outperforms all other post-quantum group signatures. Moreover, for N group members issuing at most B signatures each, the size of a hash-based group signature is just as large as a Merkle signature with a tree composed by N ·B leaf nodes. This directly translates into fast signing and verification engines. Different from lattice-based counterparts, our construction does not require any random oracle. Note that due to the randomized structure of our Merkle tree, the signature authentication paths are pre-stored or deduced from a public tree, which seems a requirement hard to circumvent. To conclude, we present implementation results to demonstrate the practicality of our proposal.	antivirus software;authentication;cryptosystem;digital signature;group signature;key size;merkle tree;merkle–damgård construction;one-way function;post-quantum cryptography;public-key cryptography;random oracle;randomized algorithm;stateful firewall;tree (data structure);trusted computing	Rachid El Bansarkhani;Rafael Misoczki	2018		10.1007/978-3-319-79063-3_21	group signature;hash function;n-group (finite group theory);public-key cryptography;random oracle;distributed computing;cryptosystem;mathematics;merkle tree;post-quantum cryptography	Crypto	-39.082488628084434	76.1519625447797	193441
c59e69818d0329017bc5ae61f32268d4a9b4e16c	unconditional secure communication: a russian cards protocol	unconditional security;protocole transmission;deleting rule;securite informatique;picking rule;journal;optimisation combinatoire;computer security;russian cards problem;protocolo transmision;seguridad informatica;combinatorial optimization;optimizacion combinatoria;russian cards problems;transmission protocol	This paper investigates Russian Cards problem for the purpose of unconditional secure communication. First, a picking rule and deleting rule as well as safe communication condition are given to deal with the problem with 3 players and 7 cards. Further, the problem is generalized to tackle n players and n(n−1)+1 cards. A new picking rule for constructing the announcement is presented, and a new deleting rule for players to determine each other’s cards is formalized. Moreover, the safe communication condition is proved. In addition, to illustrate the approach, an example for 5 players and 21 cards is presented in detail.	secure communication	Zhenhua Duan;Chen Yang	2010	J. Comb. Optim.	10.1007/s10878-009-9252-7	mathematical optimization;combinatorial optimization;computer science;artificial intelligence;mathematics;computer security;algorithm	Crypto	-44.30413357107003	78.89542941126834	193580
6af08faa0c84e44aef4b480c406bd429432ce5f9	survey on location authentication protocols and spatial-temporal attestation services	modelizacion;distributed system;security properties;systeme reparti;calculateur embarque;pervasive computing;localization;cosic;authentication;localizacion;authentification;informatica difusa;modelisation;sistema repartido;autenticacion;localisation;informatique diffuse;boarded computer;modeling;calculador embarque;authentication protocol	A survey on location authentication protocols and spatialtemporal attestation services is presented. Several protocols and services with these objectives have been proposed during the last decade, but still there is a lack of understanding of the security properties they should provide and which security mechanisms are appropriate. We first define the goals and threat model of location authentication protocols, next they are described and analyzed against this model. Also, spatial-temporal attestation services are described and classified depending on their goal and kind of issued evidence.	authentication protocol;denial-of-service attack;mobile phone;privacy;threat model	Ana Isabel González-Tablas Ferreres;Klaus Kursawe;Benjamín Ramos;Arturo Ribagorda	2005		10.1007/11596042_82	computer science;authentication;internet privacy;world wide web;computer security;ubiquitous computing	Security	-46.166424251336515	78.80608323392916	193672
6b5cd2f315d74b0f96445e96cd42984680f5f862	bounded wait-free implementation of optimally resilient byzantine storage without (unproven) cryptographic assumptions	wait-free;byzantine;replication;bounded;information theoretic;fault tolerance;atomic	We present the first optimally resilient, bounded, wait-free implementation of a distributed atomic register, tolerating Byzantine readers and (up to one-third of) Byzantine servers, without the use of unproven cryptographic primitives or requiring communication among servers. Unlike previous (non-optimal) solutions, the sizes of messages sent to writers depend only on the actual number of active readers and not on the total number of readers in the system. With a novel use of secret sharing techniques combined with write back throttling we present the first solution to tolerate Byzantine readers information theoretically, without the use of cryptographic techniques based on unproven numbertheoretic assumptions.	cryptography	Amitanand S. Aiyer;Lorenzo Alvisi;Rida A. Bazzi	2007		10.1007/978-3-540-75142-7_4	computer science;quantum byzantine agreement;theoretical computer science;distributed computing;algorithm	Crypto	-34.26827628088781	74.97956572799403	193929
d0771be3c8f1ed8431a919e06b35d200cb1bef08	blind signature and ring signature schemes: rehabilitation and attack	provable security;information security;network security;computational intelligence;unlinkability;cryptanalysis;signature scheme;ny;blind signature;applied cryptography;partially blind signature;new zealand;ring signature;identity based signature	Blind signature and ring signature are two signature schemes with privacy concern. Zhang [Jianhong Zhang, Linkability analysis of some blind signature schemes, In International Conference on Computational Intelligence and Security 2006, IEEE, vol. 2, 2006, pp. 1367-1370, (Available at http://dx.doi.org/10.1109/ICCIAS.2006.295283.)] analyzed the unlinkability of Zhang and Kim [Fangguo Zhang, Kwangjo Kim, ID-based blind signature and ring signature from pairings, in: Yuliang Zheng (Ed.), Advances in Cryptology - ASIACRYPT 2002, 8th International Conference on the Theory and Application of Cryptology and Information Security, Queenstown, New Zealand, December 1-5, 2002, Proceedings, Lecture Notes in Computer Science, vol. 2501, Springer, 2002, pp. 533-547], Huang et al. [Zhenjie Huang, Kefei Chen, Yumin Wang, Efficient identity-based signatures and blind signatures, in: Yvo Desmedt, Huaxiong Wang, Yi Mu, Yongqing Li (Eds.), Cryptology and Network Security, 4th International Conference, CANS 2005, Xiamen, China, December 14-16, 2005, Proceedings, Lecture Notes in Computer Science, vol. 3810, Springer, 2005, pp. 120-133] and Wu et al. [Qianhong Wu, Willy Susilo, Yi Mu, Fangguo Zhang, Efficient partially blind signatures with provable security, in: Osvaldo Gervasi, Marina L. Gavrilova, (Eds.), Computational Science and Its Applications - ICCSA 2007, International Conference, Kuala Lumpur, Malaysia, August 26-29, 2007. Proceedings. Part III, Lecture Notes in Computer Science, vol. 4707, Springer, 2007, pp. 1096-1105] and claimed that they are indeed linkable. On the other hand, Gamage et al. [Chandana Gamage, Ben Gras, Bruno Crispo, Andrew S. Tanenbaum, An identity-based ring signature scheme with enhanced privacy, Securecomm and Workshops 2006, IEEE, 2006, pp. 1-5, (Available at http://dx.doi.org/10.1109/SECCOMW.2006.359554)] claimed that the scheme of Chow et al. [Sherman S.M. Chow, Siu-Ming Yiu, Lucas Chi Kwong Hui, Efficient identity based ring signature, in: John Ioannidis, Angelos D. Keromytis, Moti Yung (Eds.), Applied Cryptography and Network Security, Third International Conference, ACNS 2005, New York, NY, USA, June 7-10, 2005, Proceedings, Lecture Notes in Computer Science, vol. 3531, 2005, pp. 499-512] is vulnerable to key exposure attack. This paper shows that all these claims are incorrect. Furthermore, we show that the scheme proposed by Gamage et al. [Chandana Gamage, Ben Gras, Bruno Crispo, Andrew S. Tanenbaum, An identity-based ring signature scheme with enhanced privacy, Securecomm and Workshops 2006, IEEE, 2006, pp. 1-5, (Available at http://dx.doi.org/10.1109/SECCOMW.2006.359554)] which aimed to provide enhanced privacy actually has privacy level reduced. We hope this work can pinpoint the standard one should use when analyzing the unlinkability of blind signatures and the anonymity of ring signatures.	blind signature;ring signature;signature block	Sherman S. M. Chow	2009	Computer Standards & Interfaces	10.1016/j.csi.2008.09.002	ring signature;cryptanalysis;telecommunications;computer science;information security;network security;computational intelligence;provable security;blind signature;computer security	Security	-44.876235236944	75.05566294327716	194133
a5ddaa17f1ff0e0d9d5dfd84b5c937c777ade9a3	fpga implementation and comparison of aes-gcm and deoxys authenticated encryption schemes		Authenticated Encryption (AE) schemes are key-based cryptographic algorithms that provide both goals of confidentiality of message and authenticity of the sender, simultaneously. Traditionally, Advanced Encryption Standard (AES) in Galois Counter Mode (AES-GCM), among several other approaches, has been employed for Authenticated Encryption. However, several lightweight cryptographic applications such as those used in sensor networks or RFID security can benefit from new AE schemes which can be constructed more efficiently. In this paper we provide evaluations for Deoxys, a third round candidate from the ongoing Competition for Authenticated Encryption: Security, Applicability, and Robustness (CAESAR). We describe simplified flow diagrams and a detailed summary on the timing performance, area, memory and energy requirements of AES-GCM and Deoxys, using our own implementations on Altera Cyclone V FPGAs. Our analysis shows that Deoxys requires 10% less energy per bit and 25% less LUTs as compared to AES-GCM.	aes instruction set;algorithm;authenticated encryption;authentication;confidentiality;cryptography;cyclone;diagram;field-programmable gate array;galois/counter mode;google cloud messaging;radio-frequency identification;requirement	Sandhya Koteshwara;Amitabh Das;Keshab K. Parhi	2017	2017 IEEE International Symposium on Circuits and Systems (ISCAS)	10.1109/ISCAS.2017.8050315	key wrap;sponge function;40-bit encryption;56-bit encryption;computer science;disk encryption theory;authenticated encryption;theoretical computer science;client-side encryption;link encryption	Arch	-46.74188684404369	75.31535342134188	194216
1777006a66677758975eb55fa3ffbcbcbca45af4	security notions and generic constructions for client puzzles	one way function;formal model;random oracle model;denial of service;hash function;dos attack	Computational puzzles are mildly difficult computational problems that require resources (processor cycles, memory, or both) to solve. Puzzles have found a variety of uses in security. In this paper we are concerned with client puzzles: a type of puzzle used as a defense against Denial of Service (DoS) attacks. Before engaging in a resource consuming protocol with a client, a server demands that the client solves a freshly generated client puzzle. Despite their widespread use, the lack of formal models for security of client puzzles prevents a full analysis of proposed puzzles and, more importantly, prevents rigorous proofs for the effectiveness of puzzles as a DoS defense. The main contribution of this paper is a formal model for the security of client puzzles as a stepping stone towards solving the above problems. We clarify the interface that client puzzles should offer and give two security notions for puzzles. Both functionality and security are inspired by, and tailored to, the use of puzzles as a defense against DoS attacks. The first notion – puzzle unforgeability – requires that an adversary is unable to produce valid looking puzzles on its own. The second notion – puzzle-difficulty – requires that an adversary spends at least an appropriate amount of resources solving puzzles. Our definitions fill an important gap: breaking either of the two properties immediately leads to successful DoS attacks. We illustrate this point with an attack against a previously proposed puzzle construction. We show that a subtle flaw renders the construction forgeable and we explain how to exploit this flaw to mount a DoS attack on certain protocols that use this puzzle. We also provide a generic construction of a client puzzle. Our construction uses a pseudorandom function family to provide unforgeability and a one way function for the difficulty. We prove our generic construction meets our definitions of unforgeability and difficulty for client puzzles. Finally, we discuss and analyze (in the random oracle model) a practical instantiation of our construction based on hash functions.	adversary (cryptography);client puzzle protocol;computation;computational problem;denial-of-service attack;flaw hypothesis methodology;formal language;hash function;one-way function;pseudorandom function family;random oracle;rendering (computer graphics);server (computing);stepping level;universal instantiation	Liqun Chen;Paul Morrissey;Nigel P. Smart;Bogdan Warinschi	2009	IACR Cryptology ePrint Archive	10.1007/978-3-642-10366-7_30	mathematical puzzle;computer science;world wide web;computer security;denial-of-service attack;algorithm	Security	-38.96829868044891	75.22629392594125	194373
afb91cb334aa5892e1ae567e016ba9de63738575	certifying assembly with formal security proofs: the case of bbs	provable security;prng;coq;hoare logic;assembly language	With today’s dissemination of embedded systems manipulating sensitive data, it has become important to equip low-level programs with strong security guarantees. Unfortunately, security proofs as done by cryptographers are about algorithms, not about concrete implementations running on hardware. In this article, we show how to perform security proofs to guarantee the security of assembly language implementations of cryptographic primitives. Our approach is based on a framework in the Coq proof assistant that integrates correctness proofs of assembly programs with game-playing proofs of provable security. We demonstrate the usability of our approach using the Blum-Blum-Shub pseudorandom number generator, for which a MIPS implementation for smartcards is shown cryptographically secure.	assembly language;blum blum shub;blum axioms;concrete security;correctness (computer science);cryptographic primitive;cryptography;embedded system;formal verification;high- and low-level;list of cryptographers;nondeterministic algorithm;proof assistant;provable security;pseudorandom number generator;pseudorandomness;security parameter;semantic security;smart card;standard-definition television;usability	Reynald Affeldt;David Nowak;Kiyoshi Yamada	2012	Sci. Comput. Program.	10.1016/j.scico.2011.07.003	computer security model;computer science;theoretical computer science;concrete security;provable security;distributed computing;hoare logic;programming language;computational hardness assumption;pseudorandom number generator;assembly language	Security	-35.745588865561906	74.71064089352062	194378
15708f1a7d1198c65d91f7ad4b8622dd5c81063c	the wrestlers protocol: a simple, practical, secure, deniable protocol for key-exchange		We describe and prove (in the random-oracle model) the security of a simple but efficient zero-knowledge identification scheme, whose security is based on the computational Diffie-Hellman problem. Unlike other recent proposals for efficient identification protocols, we don’t need any additional assumptions, such as the Knowledge of Exponent assumption. From this beginning, we build a simple key-exchange protocol, and prove that it achieves ‘SK-security’ – and hence security in Canetti’s Universal Composability framework. Finally, we show how to turn the simple key-exchange protocol into a slightly more complex one which provides a number of valuable ‘real-life’ properties, without damaging its security.	computational diffie–hellman assumption;diffie–hellman problem;identification scheme;key exchange;random oracle;ski combinator calculus;universal composability	Mark Wooding	2006	IACR Cryptology ePrint Archive		universal composability;identification scheme;key exchange;exponent;distributed computing;computer science	Crypto	-41.41976811042891	75.99633532209292	195007
f2bf0e116f90c96bfbc008db6e95fb1bbb58187a	new compact cca secure elgamal scheme in the random oracle model	public key cryptography;encryption games public key standards presses;standards;encryption;decryption compact cca secure elgamal scheme chosen ciphertext security scheme random oracle model public key encryption pke kem key encapsulation mechanism;compact ciphertext;presses;public key;cca security;games;elgmal encryption;compact ciphertext cca security elgmal encryption	Chosen ciphertext security (CCA security) is a very important security notion for public key encryption. Until now, there are numerous ways to construct CCA secure public key encryption (PKE) or key encapsulation mechanism (KEM) schemes. In this paper, we propose a new CCA secure Elgmal scheme, which is proved secure in the random oracle based on the CDH assumption, has almost no additional overhead compared with the traditional IND-CPA secure Elgamal scheme, except one more modular exponentiation for the decryption. To the best of our knowledge, this is the first scheme which runs almost like the basic Elgsmal scheme but with CCA security.	ciphertext indistinguishability;computational diffie–hellman assumption;encapsulation (networking);encryption;key (cryptography);key encapsulation;modular exponentiation;overhead (computing);public-key cryptography;random oracle	Xu An Wang;Jianfeng Ma;Xiaoyuan Yang	2015	2015 International Conference on Intelligent Networking and Collaborative Systems	10.1109/INCoS.2015.41	40-bit encryption;plaintext-aware encryption;computer science;ciphertext indistinguishability;internet privacy;malleability;public-key cryptography;deterministic encryption;elgamal encryption;world wide web;computer security;cramer–shoup cryptosystem;encryption;probabilistic encryption;56-bit encryption;attribute-based encryption	Crypto	-40.798270819487286	76.22824526436058	195385
08a868c8570af1db23adbc56e901d888491ec317	bootstrapping the blockchain, with applications to consensus and fast pki setup		The Bitcoin backbone protocol [Eurocrypt 2015] extracts basic properties of Bitcoin's underlying blockchain data structure, such as common pre x and chain quality, and shows how fundamental applications including consensus and a robust public transaction ledger can be built on top of them. The underlying assumptions are proofs of work (POWs), adversarial hashing power strictly less than 1/2 and no adversarial pre-computation or, alternatively, the existence of an unpredictable genesis block. In this paper we rst show how to remove the latter assumption, presenting a bootstrapped Bitcoin-like blockchain protocol relying on POWs that builds genesis blocks from scratch in the presence of adversarial pre-computation. Importantly, the round complexity of the genesis block generation process is independent of the number of participants. Next, we consider applications of our construction, including a PKI generation protocol and a consensus protocol without trusted setup assuming an honest majority (in terms of computational power). Previous results in the same setting (unauthenticated parties, no trusted setup, POWs) required a round complexity linear in the number of participants.		Juan A. Garay;Aggelos Kiayias;Nikos Leonardos;Giorgos Panagiotakos	2018		10.1007/978-3-319-76581-5_16	theoretical computer science;public key infrastructure;ledger;computer science;mathematical proof;hash function;data structure;bootstrapping;prefix;database transaction	Crypto	-38.54276134976518	74.72855796382112	195647
6d08125d2dd5c312df9927474bfe3adc6fb2c278	generating signatures with optimal overhead: practical paddings for signature schemes	short signature;tight security;optimal signature;random oracle model;ideal cipher model	ABSTRACT#R##N##R##N#Optimal signatures (generating signatures as short as possible), which achieve the optimal bandwidth for communication, are extremely useful in bandwidth-critical networks. Previous approaches use the random permutations with large block size as building blocks, which incurs less efficient implementations in the real world. Meanwhile, all the practical signature schemes are not optimal in bandwidth including PSS-R (probabilistic signature scheme with message recovery ), FDH ( Full Domain Hash), and DSA (Digital Signature Algorithm). This paper presents three constructions for optimal signature schemes. All the proposals use both the random oracles and the ideal ciphers with smaller block sizes as building blocks to obtain optimal paddings for signature schemes. The ideal ciphers in our schemes can be implemented by real block ciphers (e.g., AES (Advanced Encryption Standard)-256). Concrete implementations of these signature schemes can utilize the trapdoor permutations of Rabin and RSA, respectively. Surprisingly, RSA and Rabin (trapdoor permutations) lead to not only optimality in bandwidth but also a tight security. Therefore, besides yielding secure signatures with high efficiency, our proposals can also be flexibly applied to the bandwidth-limited networks that reduces the communication cost as less as possible. Copyright © 2014 John Wiley & Sons, Ltd.	overhead (computing);type signature	Haifeng Qian;Yuan Zhou;Zhibin Li;Zhijie Chen	2014	Security and Communication Networks	10.1002/sec.945	random oracle;merkle signature scheme;computer science;theoretical computer science;distributed computing;blind signature;schnorr signature;computer security	Crypto	-38.208228014519214	77.83348676748797	195754
41dee37d4766628a43345d341b3aa4abb4cc7061	the effectiveness of lattice attacks against low-exponent rsa	coppersmith method;cle publique;equation polynomiale;polynomial equation;public key;lattice reduction;ecuacion polinomial;resolucion ecuacion;criptografia;cryptography;llave publica;cryptographie;resolution equation;equation resolution	At Eurocrypt ’96, Coppersmith presented a novel application of lattice reduction to find small roots of a univariate modular polynomial equation. This led to rigorous polynomial attacks against RSA with low public exponent, in some particular settings such as encryption of stereotyped messages, random padding, or broadcast applications à la Hast̊ad. Theoretically, these are the most powerful known attacks against low-exponent RSA. However, the practical behavior of Coppersmith’s method was unclear. On the one hand, the method requires reductions of high-dimensional lattices with huge entries, which could be out of reach. On the other hand, it is well-known that lattice reduction algorithms output better results than theoretically expected, which might allow better bounds than those given by Coppersmith’s theorems. In this paper, we present extensive experiments with Coppersmith’s method, and discuss various trade-offs together with practical improvements. Overall, practice meets theory. The warning is clear: one should be very cautious when using the low-exponent RSA encryption scheme, or one should use larger exponents.	algebraic equation;coppersmith–winograd algorithm;digital signature;encryption;eurocrypt;experiment;lattice reduction;linear algebra;modulus robot;polynomial;rsa (cryptosystem)	Christophe Coupé;Phong Q. Nguyen;Jacques Stern	1999		10.1007/3-540-49162-7_16	combinatorics;discrete mathematics;lattice reduction;computer science;cryptography;artificial intelligence;theoretical computer science;mathematics;distributed computing;computer security;algorithm;statistics	Crypto	-38.39901182400703	79.13342361706425	195765
5e919d738bb5a65de94f6f952bd06a1061985843	boolean circuit camouflage: cryptographic models, limitations, provable results and a random oracle realization		Recent hardware advances, called gate camouflaging, have opened the possibility of protecting integrated circuits against reverse-engineering attacks. In this paper, we investigate the possibility of provably boosting the capability of physical camouflaging of a single Boolean gate into physical camouflaging of a larger Boolean circuit. We first propose rigorous definitions, borrowing approaches from modern cryptography and program obfuscation areas, for circuit camouflage. Informally speaking, gate camouflaging is defined as a transformation of a physical gate that appears to mask the gate to an attacker evaluating the circuit containing this gate. Under this assumption, we formally prove two results: a limitation and a construction. Our limitation result says that there are circuits for which, no matter how many gates we camouflaged, an adversary capable of evaluating the circuit will correctly guess all the camouflaged gates. Our construction result says that if pseudo-random functions exist (a common assumptions in cryptography), a small number of camouflaged gates suffices to: (a) leak no additional information about the camouflaged gates to an adversary evaluating the pseudo-random function circuit; and (b) turn these functions into random oracles. These latter results are the first results on circuit camouflaging provable in a cryptographic model (previously, construction were given under no formal model, and were eventually reverse-engineered, or were argued secure under specific classes of attacks). Our results imply a concrete and provable realization of random oracles, which, even if under a hardware-based assumption, is applicable in many scenarios, including public-key infrastructures. Finding special conditions under which provable realizations of random oracles has been an open problem for many years, since a software only provable implementation of random oracles was proved to be (almost certainly) impossible.	adversary (cryptography);attack model;boolean circuit;emoticon;formal language;integrated circuit;mathematical model;provable security;pseudorandom function family;pseudorandomness;public-key cryptography;random oracle;reverse engineering	Giovanni Di Crescenzo;Jeyavijayan Rajendran;Ramesh Karri;Nasir D. Memon	2017		10.1145/3139324.3139331	open problem;hardware security module;random oracle;theoretical computer science;cryptography;adversary;electronic circuit;boolean circuit;small number;mathematics	Crypto	-36.303116043729055	75.79824222866284	195890
914c8cc43aa0442e22fbb0a894b6f29aa220dff9	secure transactions with mobile agents in hostile environments	public key cryptography;protection information;developpement logiciel;protection secret;cryptographie cle publique;securite informatique;computer security;proteccion informacion;digital signature;desarrollo logicial;information protection;software development;authentification message;secrecy protection;signature numerique;message authentication;mobile agent	A major problem of mobile agents is their apparent inability to authenticate transactions in hostile environments. In this paper, we consider a framework for the prevention of agent tampering without compromising the mobility or autonomy of the agent. Our approach uses encrypted functions. We present an RSA implementation which answers affirmatively the open problem on undetachable signatures of Sander and Tschudin.	algorithm;antivirus software;authentication;code mobility;cryptographic primitive;cryptography;digital signature;encrypted function;mobile agent;provable security	Panayiotis Kotzanikolaou;Mike Burmester;Vassilios Chrissikopoulos	2000		10.1007/10718964_24	message authentication code;digital signature;telecommunications;computer science;software development;mobile agent;internet privacy;public-key cryptography;computer security;information protection policy	Security	-44.68301855219969	77.69922820669049	195982
5787ed51fab1a16ca62c45acad3d7b509aa964d3	a smart approach for gpt cryptosystem based on rank codes	public key cryptography;gpt cryptosystem smart approach;gabidulin paramonov trejtakov cryptosystem;rank codes;respective structural attacks;generators;public key cryptography decoding matrix algebra;decoding;column scrambler matrix gpt cryptosystem smart approach rank codes public key cryptosystem mceliece cryptosystem gabidulin paramonov trejtakov cryptosystem combinatoric decoding respective structural attacks distortion matrix;distortion matrix;mceliece cryptosystem;combinatoric decoding;public key cryptosystem;matrix algebra;public key;column scrambler matrix;proposals;information theory;public key cryptography public key proposals decoding physics combinatorial mathematics polynomials reed solomon codes error correction codes robustness	The concept of Public- key cryptosystem was innovated by McEliece's cryptosystem. The public key cryptosystem based on rank codes was presented in 1991 by Gabidulin -Paramonov-Trejtakov (GPT). The use of rank codes in cryptographic applications is advantageous since it is practically impossible to utilize combinatoric decoding. This has enabled using public keys of a smaller size. Respective structural attacks against this system were proposed by Gibson and recently by Overbeck. Overbeck's attacks break many versions of the GPT cryptosystem and are turned out to be either polynomial or exponential depending on parameters of the cryptosystem. In this paper, we introduce a new approach, called the Smart approach, which is based on a proper choice of the distortion matrix X. The Smart approach allows for withstanding all known attacks even if the column scrambler matrix P over the base field Fq.	code;cryptosystem;distortion;guid partition table;polynomial;public-key cryptography;scrambler;time complexity	Haitham Rashwan;Ernst M. Gabidulin;Bahram Honary	2010	2010 IEEE International Symposium on Information Theory	10.1109/ISIT.2010.5513549	benaloh cryptosystem;arithmetic;paillier cryptosystem;information theory;theoretical computer science;threshold cryptosystem;cryptosystem;mathematics;hybrid cryptosystem;public-key cryptography;computer security;statistics	Crypto	-37.33735428831373	79.5029015539023	196135
adf7c51d3b98aee31455e3fc73c0cd4aa1ce0666	short solutions to nonlinear systems of equations		This paper presents a new hard problem for use in cryptography, called Short Solutions to Nonlinear Equations (SSNE). This problem generalizes the Multivariate Quadratic (MQ) problem by requiring the solution be short; as well as the Short Integer Solutions (SIS) problem by requiring the underlying system of equations be nonlinear. The joint requirement causes common solving strategies such as lattice reduction or Gröbner basis algorithms to fail, and as a result SSNE admits shorter representations of equally hard problems. We show that SSNE can be used as the basis for a provably secure hash function. Despite failing to find public key cryptosystems relying on SSNE, we remain hopeful about that possibility.	ab initio quantum chemistry methods;algorithm;antivirus software;cryptographic hash function;cryptosystem;cubic function;encryption;failure;gröbner basis;image scaling;integer (computer science);lattice reduction;modulus of continuity;nonlinear system;post-quantum cryptography;provable security;public-key cryptography;security of cryptographic hash functions;the superficial	Alan Szepieniec;Bart Preneel	2017		10.1007/978-3-319-76620-1_5	discrete mathematics;cryptography;public-key cryptography;hash function;cryptosystem;system of linear equations;nonlinear system;mathematics;gröbner basis;lattice reduction	Crypto	-39.35313106734063	80.84609172536878	196231
1ffb51b130157b073cce4aee2d6bd287d8f7fcb3	revised quantum resistant public key encryption scheme rlce and ind-cca2 security for mceliece schemes		Recently, Wang (2016) introduced a random linear code based quantum resistant public encryption scheme RLCE which is a variant of McEliece encryption scheme. In this paper, we introduce a revised version of the RLCE encryption scheme. The revised RLCE schemes are more efficient than the original RLCE scheme. Specifically, it is shown that RLCE schemes have smaller public key sizes compared to binary Goppa code based McEliece encryption schemes for corresponding security levels. The paper further investigates message padding schemes for RLCE to achieve IND-CCA2 security. Practical RLCE parameters for the classical security levels of 128, 192, and 256 and for the quantum security levels of 85, 100, 120, and 150 are recommended. Software packages available at http://quantumca.org/	binary goppa code;ciphertext indistinguishability;encryption;experiment;heuristic (computer science);key size;linear algebra;linear code;low-density parity-check code;polar code (coding theory);post-quantum cryptography;public-key cryptography;quantum;turbo code	Yongge Wang	2017	IACR Cryptology ePrint Archive		theoretical computer science;public-key cryptography;quantum;adaptive chosen-ciphertext attack;computer security;probabilistic encryption;mceliece cryptosystem;computer science	Crypto	-37.73542692302057	79.78060635857751	196252
6e77caeabde0e5825e5fd02c43b7f75cab67b689	i-hop homomorphic encryption and rerandomizable yao circuits	homomorphic encryption	Homomorphic encryption (HE) schemes enable computing functions on encrypted data, by means of a public Eval procedure that can be applied to ciphertexts. But the evaluated ciphertexts so generated may differ from freshly encrypted ones. This brings up the question of whether one can keep computing on evaluated ciphertexts. An i-hop homomorphic encryption scheme is one where Eval can be called on its own output up to i times, while still being able to decrypt the result. A multi-hop homomorphic encryption is a scheme which is i-hop for all i. In this work we study i-hop and multi-hop schemes in conjunction with the properties of function-privacy (i.e., Eval’s output hides the function) and compactness (i.e., the output of Eval is short). We provide formal definitions and describe several constructions. First, we observe that “bootstrapping” techniques can be used to convert any (1-hop) homomorphic encryption scheme into an i-hop scheme for any i, and the result inherits the function-privacy and/or compactness of the underlying scheme. However, if the underlying scheme is not compact (such as schemes derived from Yao circuits) then the complexity of the resulting i-hop scheme can be as high as n. We then describe a specific DDH-based multi-hop homomorphic encryption scheme that does not suffer from this exponential blowup. Although not compact, this scheme has complexity linear in the size of the composed function, independently of the number of hops. The main technical ingredient in this solution is a re-randomizable variant of the Yao circuits. Namely, given a garbled circuit, anyone can re-garble it in such a way that even the party that generated the original garbled circuit cannot recognize it. This construction may be of independent interest.	decisional diffie–hellman assumption;eval;formal grammar;garbled circuit;homomorphic encryption;hop;time complexity;yao graph	Craig Gentry;Shai Halevi;Vinod Vaikuntanathan	2010	IACR Cryptology ePrint Archive	10.1007/978-3-642-14623-7_9	discrete mathematics;homomorphic encryption;computer science;theoretical computer science;mathematics;homomorphic secret sharing;on-the-fly encryption;computer security;encryption;probabilistic encryption;algorithm	Crypto	-38.50299740048439	77.24939013764352	196274
04578f5335ce5d052239c027d4b4c1860d32e280	forward-secure authenticated symmetric key exchange protocol: new security model and secure construction	input swapping;weak almost universal hash functions;authenticated key exchange;key evolving;perfect forward secrecy;weak pseudo random functions;random oracle	While a lot of work has been done on the design and security analysis of PKI-based authenticated key exchange AKE protocols, very few exist in the symmetric key setting. The first provably secure symmetric AKE was proposed by Bellare and Rogaway BR in CRYPTO 1994 and so far this stands out as the most prominent one for symmetric key setting. In line with the significant progress done for PKI based system, we propose a stronger model than the BR model for symmetric key based system. We assume that the adversary can launch active attacks. In addition, the adversary can also obtain long term secret keys of the parties and the internal states of parties by getting access to their ephemeral secrets or internal randomness by means of appropriate oracle queries. The salient feature of our model is the way we handle active adversaries even in the test session.#R##N##R##N#We also design a symmetric key AKE construction that is provably secure against active adversaries in our new model using weak primitives. Dodis et al. EUROCRYPT 2012 used weak Pseudo Random Functions wPRF and weak Almost-XOR Universal hash function family wAXU to design a three-pass one-sided authentication protocol in the symmetric key paradigm. A direct application of their techniques yields a four-pass two-round symmetric key AKE protocol with mutual authentication. Our construction uses particular instances of these weak primitives and introduces a novel technique called input-swapping to achieve a three-pass symmetric key AKE protocol with mutual authentication resisting active attacks even in the test session. Our construction is proven secure in the Random oracle Model under the DDH assumption.	authentication;key exchange;symmetric-key algorithm	Suvradip Chakraborty;Goutam Paul;C. Pandu Rangan	2015		10.1007/978-3-319-26059-4_8	random oracle;forward secrecy;computer science;distributed computing;cryptographic key types;internet privacy;pre-shared key;key distribution;computer security;algorithm;key encapsulation	Crypto	-39.456471569984714	75.67934167538182	196399
c6d880fa6c692b67d4927e8eb043e9680ab99cb3	matlab-based software tool for implementation of bifid ciphers		"""The paper presents one of the classical ciphers in cryptography, the bifid cipher, a type of cipher that was used historically but now has fallen into disuse. Most classical ciphers can be practically computed and solved by hand. They are also usually very simple to break with modern technologies. In classical cryptography, the bifid cipher is a cipher which combines the Polybius square with transposition, and uses fractionation to achieve diffusion. It was invented around 1901 by Felix Delastelle. The paper presents MATLAB-based software tool implementing encryption and decryption of English texts using the bifid cipher and 3 options for creating the Polybius square: 5x5, 6x6 and 8x8. The tool will be used in the course """"Telecommunication Security"""" by students of the specialty """"Telecommunication Systems"""" for the Bachelor degree at the University of Ruse."""	cipher;cryptography;encryption;matlab;polybius square;programming tool	Adriana Borodzhieva	2017		10.1145/3134302.3134333	cipher;theoretical computer science;matlab;encryption;computer science;software;bifid cipher;cryptography;transposition (music);polybius square	Crypto	-37.90705214380844	81.80972610898996	196419
cfefe96076ccf5cf20c4e17f3992ff603d20b1a0	the security of the fdh variant of chaum's undeniable signature scheme	public key cryptography;fdh;protocols;cryptographie cle publique;digital signatures cryptography telecommunication security protocols;security analysis;modelo 3 dimensiones;three dimensions;information science;application software;helium;modele 3 dimensions;disavowal protocol;noninteractive zero knowledge protocol confirmation;digital signatures;nizk;three dimensional model;securite donnee;cdh security full domain hash variant fdh chaum undeniable signature scheme disavowal protocol noninteractive zero knowledge protocol confirmation nizk computational diffie hellman problem;chaum undeniable signature scheme;zero knowledge zk invisibility security analysis undeniable signature unforgeability;computational diffie hellman problem;cryptography;licenses;telecommunication security;full domain hash variant;computer science;invisibility;zero knowledge;cdh;security;protocols security public key cryptography application software licenses digital signatures electronic voting computer science information science;electronic voting;security of data;zero knowledge zk;undeniable signature;qa75 5 76 95 electronic computers computer science;unforgeability	In this paper, a new kind of adversarial goal called forge-and-impersonate in undeniable signature schemes is introduced. Note that forgeability does not necessarily imply impersonation ability. The security of the full-domain hash (FDH) variant of Chaum's undeniable signature scheme is then classified according to three dimensions, the goal of adversaries, the attacks, and the zero-knowledge (ZK) level of confirmation and disavowal protocols. Each security is then related to some well-known computational problem. In particular, the security of the FDH variant of Chaum's scheme with noninteractive zero-knowledge (NIZK) protocol confirmation and disavowal protocols is proven to be equivalent to the computational Diffie-Hellman (CDH) problem, as opposed to the gap Diffie-Hellman (GDH) problem as claimed by Okamoto and Pointcheval.	digital signature;full domain hash;undeniable signature	Wakaha Ogata;Kaoru Kurosawa;Swee-Huay Heng	2006	IEEE Trans. Information Theory	10.1109/TIT.2006.872853	application software;information science;computer science;cryptography;theoretical computer science;mathematics;internet privacy;helium;security analysis;computer security;undeniable signature;invisibility	Crypto	-41.163540806729	76.50599405501076	196502
99df3f69ef3de9fe5b9baf0549862ccce315f776	new (two-track-)mac based on the two trails of ripemd	long message;short message;unkeyed hash function ripemd-160;positive fact;new message authentication code;trail construction	We present a new message authentication code. It is based on a two trail construction, which underlies the unkeyed hash function RIPEMD-160. It is in comparison with the MDx-MAC based on RIPEMD-160, much more efficient on short messages (that is on messages of 512 or 1024 bits) and percentage-wise a little bit more efficient on long messages. Moreover, it handles key-changes very efficiently. This positive fact remains if we compare our Two-Track-MAC with HMAC based on RIPEMD-160.	hash function;hash-based message authentication code;ripemd	Bert den Boer;Bart Van Rompay;Bart Preneel;Joos Vandewalle	2001		10.1007/3-540-45537-X_25	computer science;distributed computing;internet privacy;computer security	Crypto	-37.19019180921453	79.99103981329476	196644
a8fa80d5897c4a08df1df290c74c436a21972d15	optimistic asynchronous multi-party contract signing with reduced number of rounds	commerce electronique;comercio electronico;protocole transmission;contract signing protocol;protocolo transmision;protocole signature contrat;electronic trade;transmission protocol	Optimistic asynchronous multi-party contract signing pro tocols have received attention in recent years as a compromise between e fficient protocols and protocols avoiding a third party as a bottleneck of security . “Optimistic” roughly means: in case all participants are honest and receive the me ssag s from the other participants as expected, the third party is not involved at all. The best solutions known so far terminate withint + 2 rounds in the optimistic case, for any fixed set ofn signatories and allowing up to< n dishonest signatories. The protocols presented here achieve a major improvement compared to the s tate of the art: The number of roundsR is reduced fromO(t) to O(1) for all n 2t + 1, and for n < 2t + 1, R grows remarkably slowly compared with numbers of rounds in O(t): If t k k+1n thenR 2k.1	asynchronous i/o;optimistic concurrency control;signature;terminate (software)	Birgit Baum-Waidner	2001	IACR Cryptology ePrint Archive	10.1007/3-540-48224-5_73	telecommunications;computer science;distributed computing;computer security;algorithm	Crypto	-44.65294560744493	78.82734346089212	196837
86749cc4849ea8af49a5cfc8f142dd76891b5570	normalized unconditional ϵ-security of private-key encryption	unconditional security;kolmogorov complexity;private key encryption;entropy	In this paper we introduce two normalized versions of non-perfect security for private-key encryption: one version in the framework of Shannon entropy, another version in the framework of Kolmogorov complexity. We prove the lower bound on either key entropy or key size for these models and study the relations between these normalized security notions.	communication theory of secrecy systems;encryption;entropy (information theory);information-theoretic security;key size;kolmogorov complexity;public-key cryptography;shannon (unit);symmetric-key algorithm	Lvqing Bi;Songsong Dai;Bo Hu	2017	Entropy	10.3390/e19030100	kolmogorov structure function;entropy;combinatorics;discrete mathematics;theoretical computer science;mathematics;public-key cryptography;thermodynamics;chain rule for kolmogorov complexity;probabilistic encryption;physics;quantum mechanics	Crypto	-39.04550473447441	79.17126023985969	197146
1f4ee3cd0c00842cf65c12156344a163404825bf	private itemset support counting	extraction information;distributed system;private subset inclusion test;base donnee;systeme reparti;protocole transmission;oblivious transfer;information extraction;building block;random sampling;securite informatique;serveur informatique;database;base dato;data mining;transfert oublieux;computer security;vida privada;private itemset support counting;protocolo transmision;sistema repartido;private life;data privacy;fouille donnee;seguridad informatica;muestreo aleatorio;private frequent itemset mining;frequent itemset mining;servidor informatico;vie privee;echantillonnage aleatoire;busca dato;confidentialite donnee;extraccion informacion;transferencia olvidadiza;computer server;privacy preserving data mining;transmission protocol	Private itemset support counting (PISC) is a basic building block of various privacy-preserving data mining algorithms. Briefly, in PISC, Client wants to know the support of her itemset in Server’s database with the usual privacy guarantees. First, we show that if the number of attributes is small, then a communication-efficient PISC protocol can be constructed from a communication-efficient oblivious transfer protocol. The converse is also true: any communication-efficient PISC protocol gives rise to a communicationefficient oblivious transfer protocol. Second, for the general case, we propose a computationally efficient PISC protocol with linear communication in the size of the database. Third, we show how to further reduce the communication by using various tradeoffs and random sampling techniques.	algorithm;algorithmic efficiency;data mining;monte carlo method;oblivious transfer;sampling (signal processing)	Sven Laur;Helger Lipmaa;Taneli Mielikäinen	2005		10.1007/11602897_9	sampling;computer science;operating system;oblivious transfer;data mining;database;computer security;information extraction;server	Security	-43.124602027716314	78.70845836662635	197315
5dde18b1a3069a08b20c3460588fe7191d3ffa40	multi-exponentiation algorithm based on binary gcd computation and its application to side-channel countermeasure	drntu science mathematics discrete mathematics algorithms;journal article	A series of algorithms for evaluation of multi-exponentiation are proposed based on the binary greatest common divisor algorithm. The proposed algorithms are inversion free and have the capability to evaluate double or multi-exponentiation with non-fixed base numbers and exponents. They can also be employed in developing side-channel countermeasures. For n-bit double and triple exponentiation, they achieve the average complexity of 1.53n and 1.75n multiplications (including squarings), respectively. The proposed algorithms can be very useful for the implementation of many public-key cryptosystems on small devices with limited memory space, e.g., smart cards.	binary gcd algorithm;computation;cryptosystem;dspace;public-key cryptography;side-channel attack;smart card;triple des	Sung-Ming Yen;Chien-Ning Chen;Sang-Jae Moon	2012	Journal of Cryptographic Engineering	10.1007/s13389-012-0032-4	theoretical computer science;mathematics;algorithm	Security	-39.1747475033133	81.23810107058127	197320
e2f875e136de7c55f6cc17cc1f190363a44b0b7b	multi-key authenticated encryption with corruptions: reductions are lossy		We study the security of symmetric encryption schemes in settings with multiple users and realistic adversaries who can adaptively corrupt encryption keys. To avoid confinement to any particular definitional paradigm, we propose a general framework for multi-key security definitions. By appropriate settings of the parameters of the framework, we obtain multi-key variants of many of the existing single-key security notions. This framework is instrumental in establishing our main results. We show that for all single-key secure encryption schemes satisfying a minimal key uniqueness assumption and almost any instantiation of our general multi-key security notion, any reasonable reduction from the multi-key game to a standard single-key game necessarily incurs a linear loss in the number of keys. We prove this result for all three classical single-key security notions capturing confidentiality, authenticity and the combined authenticated encryption notion.	authenticated encryption;authentication;confidentiality;definition;key (cryptography);lossy compression;multi-user;programming paradigm;symmetric-key algorithm;universal instantiation	Tibor Jager;Martijn Stam;Ryan Stanley-Oakes;Bogdan Warinschi	2017	IACR Cryptology ePrint Archive	10.1007/978-3-319-70500-2_14	lossy compression;encryption;theoretical computer science;symmetric-key algorithm;computer science;key (lock);authenticated encryption	Crypto	-38.004733921271416	75.45025358944174	197335
87c779959312e145a941d29e71f7d6a920cd1836	information security and cryptology --- icisc 2008: 11th international conference, seoul, korea, december 3-5, 2008, revised selected papers	computer communication networks;algorithm analysis;information security;discrete mathematics;data encryption;problem complexity;information system;data security	General Bounds for Small Inverse Problems and Its Applications to Multi-Prime RSA.- On the Security of Distributed Multiprime RSA.- Formal Modeling of Random Oracle Programmability and Verification of Signature Unforgeability Using Task-PIOAs.- Algebraic Cryptanalysis of Yasuda, Takagi and Sakuraiu0027s Signature Scheme.- Discrete Logarithms for Torsion Points on Elliptic Curve of Embedding Degree 1.- Efficient Key Dependent Message Security Amplification Against Chosen Ciphertext Attacks.- A Fast Phase-Based Enumeration Algorithm for SVP Challenge Through y-Sparse Representations of Short Lattice Vectors.- How Much Can Complexity of Linear Cryptanalysis Be Reduced?.- Format-Preserving Encryption Algorithms Using Families of Tweakable Blockciphers.- Bicliques with Minimal Data and Time Complexity for AES.- Fault Analysis on SIMON Family of Lightweight Block Ciphers.- A Clustering Approach for Privacy-Preserving in Social Networks.- Securely Solving Classical Network Flow Problems.- Remote IP Protection Using Timing Channels.- Detecting Camouflaged Applications on Mobile Application Markets.- WrapDroid: Flexible and Fine-Grained Scheme Towards Regulating Behaviors of Android Apps.- A Collision Attack on a Double-Block-Length Compression Function Instantiated with Round-Reduced AES-256.- LSH: A New Fast Secure Hash Function Family.- Lossless Data Hiding for Binary Document Images Using n-Pairs Pattern.- Montgomery Modular Multiplication on ARM-NEON Revisited.- A Fair and Efficient Mutual Private Set Intersection Protocol from a Two-Way Oblivious Pseudorandom Function.- Security Analysis of Polynomial Interpolation-Based Distributed Oblivious Transfer Protocols.- Compact and Efficient UC Commitments Under Atomic-Exchanges.- Issuer-Free Adaptive Oblivious Transfer with Access Policy.- Memory Address Side-Channel Analysis on Exponentiation.- Mutant Differential Fault Analysis of Trivium MDFA.		Pil Joong Lee;Jung Hee Cheon	2009		10.1007/978-3-642-00730-9	computer security model;h.235;computer science;theoretical computer science;distributed computing;computer security	EDA	-44.88212017473126	81.71950179395338	197364
2642738e9977c08d4085ce1c6530d63545383d30	efficient signature generation by smart cards	signature analysis;smart card;signatures with preprocessing;one way function;analyse signature;efficient algorithm;public key signatures;digital signatures;cle publique;discrete logarithm;signature scheme;public key;elgamal signatures;random exponentiated residues;digital signature;criptografia;cryptography;discrete logarithm one way function;llave publica;cryptographie;public key authentification;public key authentication;analisis firma	We present a new public-key signature scheme and a corresponding authentication scheme that are based on discrete logarithms in a subgroup of units in ℤ p where p is a sufficiently large prime, e.g., p ≥ 2512. A key idea is to use for the base of the discrete logarithm an integer α in ℤ p such that the order of α is a sufficiently large prime q, e.g., q ≥ 2140. In this way we improve the ElGamal signature scheme in the speed of the procedures for the generation and the verification of signatures and also in the bit length of signatures. We present an efficient algorithm that preprocesses the exponentiation of a random residue modulo p.	algorithm;authentication;bit-length;digital signature;discrete logarithm;modulo operation;public-key cryptography;smart card;type signature	Claus-Peter Schnorr	1991	Journal of Cryptology	10.1007/BF00196725	digital signature;discrete mathematics;computer science;theoretical computer science;mathematics;elgamal signature scheme;computer security	Crypto	-40.333776439903716	79.81677707406173	197415
311d277eb662486aa605b5fd681c419b77443627	the hunting of the snark	lewis carroll;null entity;original finding;null expression;local variable;empty vector;century terminology;empty array;empty string;formal semantics	The existence of succinct non-interactive arguments for NP (i.e., non-interactive computationally sound proofs where the verifier’s work is essentially independent of the complexity of the NP non-deterministic verifier) has been an intriguing question for the past two decades. Other than CS proofs in the random oracle model (Micali in SIAM J Comput 30(4):1253–1298, 2000), prior to our work the only existing candidate construction is based on an elaborate assumption that is tailored to a specific protocol (Di Crescenzo and Lipmaa in Proceedings of the 4th conference on computability in Europe, 2008). We formulate a general and relatively natural notion of an extractable collision-resistant hash function (ECRH) and show that, if ECRHs exist, then a modified version of Di Crescenzo and Lipmaa’s protocol is a succinct non-interactive argument for NP. Furthermore, the modified protocol is actually a succinct non-interactive adaptive argument of knowledge (SNARK). We then propose several candidate constructions for ECRHs and relaxations thereof. We demonstrate the applicability of SNARKs to various forms of delegation of computation, to succinct non-interactive zero-knowledge arguments, and to succinct two-party secure computation. Finally, we show that SNARKs essentially imply the existence of ECRHs, thus demonstrating the necessity of the assumption. Going beyond $$\hbox {ECRH}$$ ECRH s, we formulate the notion of extractable one-way functions ( $$\hbox {EOWF}$$ EOWF s). Assuming the existence of a natural variant of $$\hbox {EOWF}$$ EOWF s, we construct a two-message selective-opening-attack-secure commitment scheme and a three-round zero-knowledge argument of knowledge. Furthermore, if the $$\hbox {EOWF}$$ EOWF s are concurrently extractable, the three-round zero-knowledge protocol is also concurrent zero knowledge. Our constructions circumvent previous black-box impossibility results regarding these protocols by relying on $$\hbox {EOWF}$$ EOWF s as the non-black-box component in the security reductions.	black box;collision resistance;commitment scheme;computability in europe;hash function;interactivity;np (complexity);one-way function;random oracle;secure multi-party computation;snark (graph theory);zero-knowledge proof	Nir Bitansky;Ran Canetti;Alessandro Chiesa;Shafi Goldwasser;Huijia Lin;Aviad Rubinstein;Eran Tromer	2014	Journal of Cryptology	10.1007/s00145-016-9241-9		Crypto	-38.27314275641623	75.63762552832591	197435
361b837964667c7497007b5705be86af2a1ffb57	on the exact decryption range for gentry-halevi's implementation of fully homomorphic encryption		In this paper, we revisit the fully homomorphic encryption (FHE) scheme implemented by Gentry and Halevi, which is just an instantiation of Gentry’s original scheme based on ideal lattices. Their FHE scheme starts from a somewhat homomorphic encryption (SHE) scheme, and its decryption range is deeply related with the FHE construction. Gentry and Halevi gave an experimental evaluation of the decryption range, but theoretical evaluations have not been given so far. Moreover, we give a theoretical upper bound, and reconsider suitable parameters for theoretically obtaining an FHE scheme. In particular, while Gentry and Halevi use the Euclidean norm evaluation in the noise management of ciphertexts, our theoretical bound enables us to use the1-norm evaluation, and hence it helps to lower the difficulty of controlling the noise density of ciphertexts.	homomorphic encryption;ideal lattice cryptography;universal instantiation	Masaya Yasuda;Kazuhiro Yokoyama;Takeshi Shimoyama;Jun Kogure;Takeshi Koshiba	2014	J. Mathematical Cryptology	10.1515/jmc-2013-0024	theoretical computer science;homomorphic secret sharing;internet privacy;computer security;encryption;attribute-based encryption	Crypto	-37.59932620960088	76.92220187821682	197453
271d0ea90ca72cbad0c74db1256ea143d12d117e	intrinsic information of wideband channels	computer network security;uncertainty standards wideband cryptography wireless networks noise;intrinsic information nonbayesian perspective mobile wireless network wideband propagation media unknown deterministic source secret key generation mathematical framework shared secret key secret message exchange wideband channel;cryptography;non bayesian inference secret key generation physical layer security wideband channels;mobile computing computer network security cryptography;mobile computing	The ability to exchange secret messages and protect against security attacks becomes increasingly important for providing information superiority and confidentiality in modern information systems. These systems require shared secret keys, which can be generated from common random sources with known distributions. However, the assumption on the distribution of the sources may not hold in many realistic scenarios. In this paper, we establish a mathematical framework for secret-key generation using common unknown deterministic sources (UDSs). In particular, we propose a new information measure called intrinsic information to characterize the achievable length of the secret key that can be generated from a UDS. As a case study, we consider a wideband propagation medium in mobile wireless networks as a UDS and derive its intrinsic information as a function of various network parameters. Our results provide a non-Bayesian perspective for secret-key generation as well as practical implications of this new perspective.	confidentiality;information system;key (cryptography);key generation;mobile phone;public-key cryptography;shared secret;software propagation;unified diagnostic services;unix domain socket	Yuan Shen;Moe Z. Win	2013	IEEE Journal on Selected Areas in Communications	10.1109/JSAC.2013.130919	shared secret;telecommunications;computer science;cryptography;operating system;internet privacy;pre-shared key;mobile computing;key distribution;computer security;computer network	Security	-44.88637623995258	80.58002168152278	197652
243a4af2992bee825ef5a32f173765915428236d	secure biometric authentication for weak computational devices	carte a puce;cryptographic hash functions;smart card;interfase usuario;cle secrete;finance;encryption;biometric authentication;cryptographic hash function;user interface;biometrie;authentication;securite informatique;biometrics;biometria;cle publique;public key encryption;signature electronique;cifrado;computer security;feature vector;captador medida;measurement sensor;capteur mesure;public key;smartcard;institucion financiera;cryptage;smart cards;financial institutions;digital signature;secret key;criptografia;clave secreta;cryptography;seguridad informatica;llave publica;institution financiere;cryptographie;interface utilisateur;financial institution;firma numerica;finanzas	This paper presents computationally “lightweight” schemes for performing biometric authentication that carry out the comparison stage without revealing any information that can later be used to impersonate the user (or reveal personal biometric information). Unlike some previous computationally expensive schemes — which make use of slower cryptographic primitives — this paper presents methods that are particularly suited to financial institutions that authenticate users with biometric smartcards, sensors, and other computationally limited devices. In our schemes, the client and server need only perform cryptographic hash computations on the feature vectors, and do not perform any expensive digital signatures or public-key encryption operations. In fact, the schemes we present have properties that make them appealing even in a framework of powerful devices capable of public-key signatures and encryptions. Our schemes make it computationally infeasible for an attacker to impersonate a user even if the attacker completely compromises the information stored at the server, including all the server’s secret keys. Likewise, our schemes make it computationally infeasible for an attacker to impersonate a user even if the attacker completely compromises the information stored at the client device (but not the biometric itself, which is assumed to remain attached to the user and is not stored on the client device in any form).	access control;adversary (cryptography);algorithm;analysis of algorithms;antivirus software;authentication;biometrics;channel (communications);commitment scheme;communications security;computation;computational complexity theory;cryptographic hash function;cryptographic primitive;digital credential;digital signature;encryption;error detection and correction;eurocrypt;feature vector;fingerprint;ieee transactions on pattern analysis and machine intelligence;identification scheme;information theory;john d. wiley;lecture notes in computer science;malware;online and offline;public-key cryptography;replay attack;sensor;server (computing);signal-to-noise ratio;smart card;springer (tank);stan frankel;strong key;thread-local storage;type signature	Mikhail J. Atallah;Keith B. Frikken;Michael T. Goodrich;Roberto Tamassia	2005		10.1007/11507840_32	smart card;computer science;operating system;database;distributed computing;internet privacy;world wide web;computer security;algorithm	Security	-43.6251893455472	78.00586969634277	197725
1ddb640116b1dffba839c4f868176a69de768187	merkle-damgård revisited: how to construct a hash function	block ciphering;hachage;cryptage bloc;design principle;building block;block cipher;probabilistic approach;satisfiability;hashing;criptografia;enfoque probabilista;cryptography;approche probabiliste;cifrado en bloque;random oracle;cryptographie;hash function;oracle	The most common way of constructing a hash function (e.g., SHA-1) is to iterate a compression function on the input message. The compression function is usually designed from scratch or made out of a blockcipher. In this paper, we introduce a new security notion for hash-functions, stronger than collisionresistance. Under this notion, the arbitrary length hash function H must behave as a random oracle when the fixed-length building block is viewed as a random oracle or an ideal block-cipher. The key property is that if a particular construction meets this definition, then any cryptosystem proven secure assuming H is a random oracle remains secure if one plugs in this construction (still assuming that the underlying fixedlength primitive is ideal). In this paper, we show that the current design principle behind hash functions such as SHA-1 and MD5 — the (strengthened) Merkle-Damg̊ard transformation — does not satisfy this security notion. We provide several constructions that provably satisfy this notion; those new constructions introduce minimal changes to the plain Merkle-Damg̊ard construction and are easily implementable in practice. University of Luxembourg, Email: coron@clipper.ens.fr New York University, Email: dodis@cs.nyu.edu Gemplus Card International, Email: cecile.malinaud@normalesup.org New York University, Email: puniya@cs.nyu.edu	block cipher;cryptosystem;email;hash function;iteration;md5;merkle–damgård construction;one-way compression function;random oracle;sha-1	Jean-Sébastien Coron;Yevgeniy Dodis;Cécile Malinaud;Prashant Puniya	2005		10.1007/11535218_26	random oracle;security of cryptographic hash functions;discrete mathematics;hash function;perfect hash function;collision resistance;computer science;theoretical computer science;database;mathematics;distributed computing;computer security;algorithm;cryptographic hash function;swifft	Crypto	-38.06669127349941	77.36149295642555	197858
30fafd249a3cad623fd24ff7a92c388d9da8cd6e	on chosen ciphertext security of multiple encryptions		We consider the security of multiple and possibly related plaintexts in the context of a chosen ciphertext attack. That is the attacker in addition and concurrently to obtaining encryptions of multiple plaintexts under the same key, may issue encryption and decryption queries and partial information queries. Loosely speaking, an encryption scheme is considered secure under such attacks if all that the adversary can learn from such attacks about the selected plaintexts can be obtained from the corresponding partial information queries. The above deenition extends the deenition of semantic security under chosen ciphertext attacks (CCAs) which is also formulated in this work. The extension is in considering the security of multiple plaintexts rather than the security of a single plaintext. We prove that both these formulations are equivalent to the standard formulation of CCA, which refers to indistinguishability of encryptions. The good news is that any encryption scheme that is secure in the standard CCA sense is in fact secure in the extended model. The treatment holds both for public-key and private-key encryption schemes.	adversary (cryptography);chosen-ciphertext attack;ciphertext;encryption;plaintext;public-key cryptography;semantic security;symmetric-key algorithm	Oded Goldreich;Yoad Lustig;Moni Naor	2002	IACR Cryptology ePrint Archive		ciphertext;semantic security;theoretical computer science;ciphertext stealing;cramer–shoup cryptosystem;ciphertext indistinguishability;malleability;key clustering;computer science	Crypto	-39.44051334794305	75.0874060223192	198184
10794dc2f6039abed5a38792f7916b9737d49bb4	a method for rapid rsa key generation	algorithme rapide;generation;keyword;securite;generacion;sistema informatico;computer system;palabra clave;mot cle;criptografia;cryptography;fast algorithm;safety;cryptographie;systeme informatique;methode gordon;seguridad;algoritmo rapido	Abstract#R##N##R##N#The RSA public key cryptosystem is one of the cryptosystems which can be applied not only to the security protection but also to the verifications of other users and messages. It is one of the most important techniques in ensuring the security of information. To construct a secure RSA public key cryptosystem, the key must be generated using primes which are robust against a “(p + 1) factorizing attack.” For this purpose, Gordon proposed a method of generating the key by sieving using known primes less than 8 bit and by employing the higher-order exponential calculation. This paper is an extension of Gordon's approach. The range of known primes is defined optimally through an evaluation for the sieving primes less than 32 bit. The exponential calculation is simplified. The method is implemented on a program. Numerical experiment is made on a 32-bit workstation, and the practical usefulness of the method is verified.	key generation	Yasuko Gotoh;Kazuo Takaragi;Ryôichi Sasaki	1990	Systems and Computers in Japan	10.1002/scj.4690210802	generation;cryptography;theoretical computer science;cryptosystem;mathematics;computer security;algorithm;statistics	Crypto	-41.53079984365651	79.86748540973399	198221
f09e7fe900748afb9be7b3148b2a5f1d2a140093	can we access a database both locally and privately?		We consider the following strong variant of private information retrieval (PIR). There is a large database x that we want to make publicly available. To this end, we post an encoding X of x together with a short public key pk in a publicly accessible repository. The goal is to allow any client who comes along to retrieve a chosen bit xi by reading a small number of bits from X, whose positions may be randomly chosen based on i and pk, such that even an adversary who can fully observe the access to X does not learn information about i. Towards solving the above problem, we study a weaker secret key variant where the data is encoded and accessed by the same party. This primitive, that we call an oblivious locally decodable code (OLDC), is independently motivated by applications such as searchable symmetric encryption. We reduce the public-key variant of PIR to OLDC using an ideal form of obfuscation that can be instantiated heuristically with existing indistinguishability obfuscation candidates, or alternatively implemented with small and stateless tamper-proof hardware. Finally, a central contribution of our work is the first proposal of an OLDC candidate. Our candidate is based on a secretly permuted Reed-Muller code. We analyze the security of this candidate against several natural attacks and leave its further study to future work. ∗Email: eboyle@alum.mit.edu †Email: yuvali@cs.technion.ac.il ‡Email: rafael@cs.cornell.edu §Email: marykw@stanford.edu	adversary (cryptography);cryptographic primitive;database;email;encryption;heuristic;key (cryptography);locally decodable code;obfuscation (software);overhead (computing);personally identifiable information;preprocessor;private information retrieval;public-key cryptography;randomness;reed–muller code;server (computing);stateless protocol;symmetric-key algorithm;tamper resistance	Elette Boyle;Yuval Ishai;Rafael Pass;Mary Wootters	2017		10.1007/978-3-319-70503-3_22	computer science;adversary;private information retrieval;encoding (memory);public-key cryptography;database;small number	Crypto	-38.0877370189822	75.92517692495183	198327
492742e8b9ecb2a10817e8a30dd86786a92351f8	primeless factoring-based cryptography - -solving the complexity bottleneck of public-key generation-	primeless factoring-based cryptography;consideration different possibility;fundamental operation;correct choice;key-production algorithm;denoted sis;asymptotic complexity;well-known public-key cryptosystems;overall complexity;factoring-based public-key cryptosystems;well-known factoring-based cryptosystems	Factoring-based public-key cryptosystems have an overall complexity which is dominated by the key-production algorithm, which requires the generation of prime numbers. This is most inconvenient in settings where the key-generation is not an one-off process, e.g., for forwards secrecy. To this end, we extend the Goldwasser-Micali (GM) cryptosystem to a provably secure system, denoted SIS, where the generation of primes is bypassed. By developing on the correct choice of the parameters of SIS, we align SIS’s security guarantees (i.e., resistance to factoring of moduli, etc.) to those of other well-known factoring-based cryptosystems. Taking into consideration different possibilities to implement the fundamental operations, we explicitly compare and contrast the asymptotic complexity of well-known public-key cryptosystems (e.g., GM and/or RSA) with that of SIS’s. The latter shows that once we are ready to accept an increase in the size of the moduli, SIS offers a generally lower asymptotic complexity than, e.g., GM or even RSA.		Sonia Bogos;Ioana Boureanu;Serge Vaudenay	2013		10.1007/978-3-642-38980-1_35	theoretical computer science;mathematics;computer security;algorithm	Security	-37.938289068143	78.34339542659181	198440
c0ccafc8af9c05b8fa83f26976c631dd5ad4828a	on locally decodable codes, self-correctable codes, and t-private pir	error correcting code;confidencialidad;code reed muller;combinatorial designs;base donnee reproduite;codigo corrector error;private information retrieval;reed muller code;locally decodable code;satisfiability;codigo reed muller;confidentiality;vida privada;hamada s conjecture;confidentialite;similarity transformation;locally decodable codes;private life;criptografia;cryptography;combinatorial design;analyse combinatoire;cryptographie;vie privee;t privacy;code correcteur erreur;self correctable codes;replicated databases;reed muller codes;analisis combinatorio;combinatorial analysis	A k-query locally decodable code (LDC) allows to probabilistically decode any bit of an encoded message by probing only k bits of its corrupted encoding. A stronger and desirable property is that of self-correction, allowing to efficiently recover not only bits of the message but also arbitrary bits of its encoding. In contrast to the initial constructions of LDCs, the recent and most efficient constructions are not known to be self-correctable. The existence of self-correctable codes of comparable efficiency remains open. A closely related problem with a very different motivation is that of private information retrieval (PIR). A k-server PIR protocol allows a user to retrieve the i-th bit of a database, which is replicated among k servers, without revealing information about i to any individual server. A natural generalization is t -private PIR, which keeps i hidden from any t colluding servers. In contrast to the initial PIR protocols, it is not known how to generalize the recent and most efficient protocols to yield t-private protocols of comparable efficiency. In this work we study both of the above questions, showing that they are in fact related. We start by presenting a general transformation of any 1-private PIR protocol (equivalently, LDC) into a t-private protocol with a similar amount of communication per server. Combined with the recent result of Yekhanin (STOC 2007), this yields an improvement over previous t-private PIR protocols. A major weakness of our transformation is that the number of servers grows exponentially with t. We show that if the underlying LDC satisfies the stronger self-correction property, then there is a similar transformation in which the number of servers grows only linearly with t, which is the best one can hope for. Finally, we explore the possibility of improving current constructions of self-correctable codes and relate this question to a conjecture of Hamada concerning the algebraic rank of combinatorial designs.	code (cryptography);linear algebra;linguistic data consortium;locally decodable code;personally identifiable information;private information retrieval;server (computing);symposium on theory of computing	Omer Barkol;Yuval Ishai;Enav Weinreb	2008	Algorithmica	10.1007/s00453-008-9272-1	arithmetic;reed–muller code;combinatorial design;combinatorics;theoretical computer science;mathematics;algorithm;statistics	Theory	-36.87718155029356	76.8187659510267	198894
b6bad3bf237024e8aee37c1d13fe81f51c599e1d	the bit security of paillier's encryption scheme and its applications	semantic security;encryption;securite;cryptage;criptografia;cryptography;safety;cryptographie;seguridad	At EuroCrypt’99, Paillier proposed a new encryption scheme based on higher residuosity classes. The new scheme was proven to be one-way under the assumption that computing N -residuosity classes in Z N2 is hard. Similarly the scheme can be proven to be semantically secure under a much stronger decisional assumption: given w ∈ Z N2 it is hard to decide if w is an N -residue or not. In this paper we examine the bit security of Paillier’s scheme. We prove that, if computing residuosity classes is hard, then given a random w it is impossible to predict the least significant bit of its class significantly better than at random. This immediately yields a way to obtain semantic security without relying on the decisional assumption (at the cost of several invocations of Paillier’s original function). In order to improve efficiency we then turn to the problem of simultaneous security of many bits. We prove that Paillier’s scheme hides n− b (up to O(n)) bits if one assumes that computing the class c of a random w remains hard even when we are told that c < 2. We thoroughly examine the security of this stronger version of the intractability of the class problem. An important theoretical implication of our result is the construction of the first trapdoor function that hides super-logarithmically (up to O(n)) many bits. We generalize our techniques to provide sufficient conditions for a trapdoor function to have this property.	algorithm;computation;decisional diffie–hellman assumption;encryption;least significant bit;most significant bit;one-way function;semantic security;trapdoor function	Dario Catalano;Rosario Gennaro;Nick Howgrave-Graham	2001		10.1007/3-540-44987-6_15	paillier cryptosystem;semantic security;computer science;cryptography;artificial intelligence;theoretical computer science;database;mathematics;distributed computing;computer security;encryption;algorithm;statistics	Crypto	-38.806765811529104	77.55137957767616	198904
a7c02afcd7db309de09b66761a271928666eed62	efficient primitives from exponentiation in zp	hachage;provable security;expositoracion;confidencialidad;decisional diffie hellman;securite informatique;random number generation;exponentiation;numero seudo aleatorio;probabilistic approach;logarithme discret;discrete logarithm;confidentiality;computer security;confidentialite;hashing;it security;nombre pseudoaleatoire;enfoque probabilista;approche probabiliste;seguridad informatica;generation nombre aleatoire;secure system;random oracle;pseudorandom number;problema diffie hellman;logaritmo discreto;hash function;information system;systeme information;generacion numero aleatorio;modular multiplication;diffie hellman;oracle;probleme diffie hellman;diffie hellman problem;sistema informacion	Since Diffie-Hellman [14], many secure systems, based on discrete logarithm or Diffie-Hellman assumption in Zp, were introduced in the literature. In this work, we investigate the possibility to construct efficient primitives from exponentiation techniques over Zp. Consequently, we propose a new pseudorandom generator, where its security is proven under the decisional Diffie-Hellman assumption. Our generator is the most efficient among all generators from Zp that are provably secure under standard assumptions. If an appropriate precomputation is allowed, our generator can produce O(log log p) bits per modular multiplication. This is the best possible result in the literature (even improved by such a precomputation as well). Interestingly, our generator is the first provably secure under a decisional assumption and might be instructive for discovering potentially more efficient generators in the future. Our second result is a new family of universally collision resistant hash family (CRHF). Our CRHF is provably secure under the discrete log assumption and is more efficient than all previous CRHFs that are provably secure under standard assumptions (especially without a random oracle). This result is important, especially when the unproven hash functions (e.g., MD4, MD5, SHA-1) were broken by Wang et al. [41–43].	collision resistance;computational diffie–hellman assumption;cryptographic hash function;decisional diffie–hellman assumption;diffie–hellman key exchange;discrete logarithm;md4;md5;precomputation;provable security;pseudorandom generator;pseudorandomness;random oracle;sha-1	Shaoquan Jiang	2006		10.1007/11780656_22	hash function;computer science;theoretical computer science;mathematics;computer security;algorithm	Crypto	-41.56028717840351	78.41494900674198	199086
e209226c22b852e66fb1d91a5c541a7a35020693	euf-cma-secure structure-preserving signatures on equivalence classes		At ASIACRYPT’14 Hanser and Slamanig proposed a new primitive called structure-preserving signatures on equivalence classes (SPS-EQ) and used it to construct very efficient attribute-based anonymous credentials. They also presented a candidate construction of an SPS-EQ scheme and claimed that the scheme was existentially unforgeable under adaptive chosen message attacks (EUF-CMA). Fuchsbauer has however recently shown that the construction is insecure under adaptive queries and consequently the security claim is invalid. We fix this issue by providing an EUF-CMA-secure construction of an SPS-EQ, which is also more efficient than the original construction in every respect. We prove our scheme secure in the generic group model for Type-3 bilinear groups.	antivirus software;bilinear filtering;cma-es;digital credential;digital signature forgery;electronic signature;generic group model;ibm 1401 symbolic programming system;relational operator;turing completeness	Georg Fuchsbauer;Christian Hanser;Daniel Slamanig	2014	IACR Cryptology ePrint Archive		discrete mathematics;mathematics;equivalence class	Crypto	-40.146891258920895	76.31952429896272	199093
e36e67139bf9c566de7e6dd6e8f9eb29d5f51047	boomerang attack on step-reduced sha-512	会议论文	SHA-2 (SHA-224, SHA-256, SHA-384 and SHA-512) is hash function family issued by the National Institute of Standards and Technology (NIST) in 2002 and is widely used all over the world. In this work, we analyze the security of SHA-512 with respect to boomerang attack. Boomerang distinguisher on SHA-512 compression function reduced to 48 steps is proposed, with a practical complexity of 2. A practical example of the distinguisher for 48-step SHA-512 is also given. As far as we know, it is the best practical attack on step-reduced SHA-512.	boomerang attack;hash function;one-way compression function;route distinguisher;sha-2	Hongbo Yu;Dongxia Bai	2014		10.1007/978-3-319-16745-9_18	computer science	Crypto	-37.991276213648746	79.02344837228962	199436
a8d237f048eaf9c389bc0cd0b3d9bb0cbcb78bdf	how to construct secure cryptographic location-based services	sensibilidad contexto;key management;distributed system;valor elevado;systeme reparti;context aware;informatique mobile;calculateur embarque;location based service;location management;pervasive computing;localization;distributed computing;localizacion;valeur elevee;informatica difusa;sistema repartido;localisation;informatique diffuse;criptografia;cryptography;boarded computer;calculo repartido;high value;cryptographie;ubiquitous computing;mobile node;sensibilite contexte;mobile computing;calcul reparti;calculador embarque	Recently, ubiquitous computing / networks have been studied actively. These networks provide services depending on real environments of mobile nodes. Especially, we expect location-based services (LBSs), which rely on location of mobile nodes, are anticipated to come into wide use in the future. High-value LBSs require cryptography to ensure security. Here, cryptographic LBSs comprise a key management function (e.g. key sharing with nodes) and a location management function (e.g. location verification of nodes). Cooperation between key and location management functions realizes cryptographic LBSs. However, these functions have mostly been studied individually. This study indicates that cryptographic LBSs are insecure if the cooperation is incomplete, and proposes a method of constructing secure cryptographic LBSs.	cryptography;location-based service	Jun Anzai;Tsutomu Matsumoto	2005		10.1007/11596042_92	human–computer interaction;telecommunications;computer science;cryptography;operating system;key management;distributed computing;computer security;ubiquitous computing	Crypto	-46.1326966650483	78.74955839284912	199498
5d2be5d046324fd9f1a1b22fd02c3839e5d559f5	dependence in iv-related bytes of rc4 key enhances vulnerabilities in wpa		The first three bytes of the RC4 key in WPA are public as they are derived from the public parameter IV, and this derivation leads to a strong mutual dependence between the first two bytes of the RC4 key. In this paper, we provide a disciplined study of RC4 biases resulting specifically in such a scenario. Motivated by the work of AlFardan et al. (2013), we first prove the interesting sawtooth distribution of the first byte in WPA and the similar nature for the biases in the initial keystream bytes towards zero. As we note, this sawtooth characteristics of these biases surface due to the dependence of the first two bytes of the RC4 key in WPA, both derived from the same byte of the IV. Our result on the nature of the first keystream byte provides a significantly improved distinguisher for RC4 used in WPA than what had been presented by Sepehrdad et al. (2011-12). Further, we revisit the correlation of initial keystream bytes in WPA to the first three bytes of the RC4 key. As these bytes are known from the IV, one can obtain new as well as significantly improved biases in WPA than the absolute biases exploited earlier by AlFardan et al. or Isobe et al. We notice that the correlations of the keystream bytes with publicly known IV values of WPA potentially strengthen the practical plaintext recovery attack on the protocol.	byte;plaintext;rc4;route distinguisher;sawtooth (cellular automaton);wi-fi protected access	Sourav Sengupta;Subhamoy Maitra;Willi Meier;Goutam Paul;Santanu Sarkar	2014		10.1007/978-3-662-46706-0_18	computer security;computer network	Crypto	-43.480667247892136	80.0166872327722	199549
4ddd57fb26739ab50324ec917ca94e32af63e09e	on formal models for secure key exchange	public key;security model;key exchange	A new formal security model for session key exchange protocols in the public key setting is proposed, and several eecient protocols are analyzed in this model. The relationship between this new model and previously proposed models is explored, and several interesting, subtle distinctions between static and adaptive adversaries are explored. We also give a brief account of anonymous users.	algorithm;encryption;key exchange;norm (social);public-key cryptography;session key	Victor Shoup	1999	IACR Cryptology ePrint Archive		mqv;computer security model;computer security;key distribution;public-key cryptography;key exchange;business;security association;authenticated key exchange	Crypto	-41.244211434115094	75.2903554528262	199620
2f28e3b52666d762519fa64ed8689dc66ce10181	study and performance evaluation of security-throughput tradeoff with link adaptive encryption scheme		With the ever increasing volume of information over wireless medium, security has assumed an important dimension. The security of transmitted data over a wireless channel aims at protecting the data from unauthorized intrusion. Wireless network security is achieved using cryptographic primitives. Some properties that give encryption mechanism their cryptographic strength also make them very sensitive to channel error as well. Therefore, security for data transmission over wireless channel results in throughput loss. Trade-off between security and throughput is always a major concern in wireless networks. In this paper, a Link Adaptive Encryption scheme is evaluated that adapts to channel variations and enhances the security level of WLANs without making any compromise with the network performance. Numerical results obtained through simulation are compared with the fixed block length encryption technique in two different modes of operationElectronic Code Book (ECB) & Cipher Block Chaining (CBC). Optimal block length is also computed, which is assumed to be the effective strength of the cipher. It has been observed that security attained with link adaptive scheme operating in ECB mode of cipher is a better solution for security and throughput trade-off. However, it is found that if computational security is a major concern, link adaptive scheme in CBC mode should be preferred.	authorization;block cipher mode of operation;block code;computational hardness assumption;cryptographic primitive;download;encryption;europe card bus;network performance;network security;performance evaluation;semantic security;simulation;strong cryptography;throughput	Poonam Jindal;Brahmjit Singh	2012	CoRR		telecommunications;computer science;link encryption;computer security;cbc-mac;encryption;computer network	Security	-46.8997396108848	75.70286673844973	199631
262411e495eee6c8ae6c6a4b4545cbf96c780312	evaluation of the security of rc6 against the χ2-attack*a preliminary version was presented at acisp'05.	tecnologia electronica telecomunicaciones;rc6;block cipher;967;2 attacks;tecnologias;grupo a;χ 2 attacks	Knudsen and Meier applied the χ2-attack to RC6. The χ2-attack recovers a key by using high correlations measured by χ2-value. Up to the present, the success probability of any χ2-attack has not been evaluated theoretically without using experimental results. In this paper, we discuss the success probability of χ2-attack and give the theorem that evaluates the success probability without using any experimental result, for the first time. We make sure the accuracy of our theorem by demonstrating it on both 4-round RC6 without post-whitening and 4-round RC6-8. We also evaluate the security of RC6 theoretically and show that a variant of the χ2-attack is faster than an exhaustive key search for the 192-bit-key and 256-bit-key RC6 with up to 16 rounds. As a result, we succeed in answering such an open question that a variant of the χ2-attack can be used to attack RC6 with 16 or more rounds.		Atsuko Miyaji;Yuuki Takano	2007	IEICE Transactions	10.1093/ietfec/e90-a.1.22	block cipher;telecommunications;computer science;theoretical computer science;mathematics;computer security;algorithm;statistics	Theory	-37.831188019773194	79.54900270214571	199676
