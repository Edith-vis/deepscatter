id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
ac0023f705c8081c92477d2a9ff8fa2ce9f1b38e	optimal quality and quantity provisions for centralized vs. decentralized distribution: market size uncertainty effects		We provide insights on how market size uncertainty affects the optimal quality (quantity) provision in distribution channels when consumers are heterogeneous in their willingness to pay for product quality. In this context, we denote the difference between the manufacturer’s optimal quality (quantity) provision for a centralized channel and its optimal analog for a decentralized channel as the quality (quantity) differential. We find that market size uncertainty creates or increases the quantity differential, but it does not affect the differential’s polarity. In contrast, market size uncertainty decreases the quality differential and it does so to the extent that, depending on the level of consumer heterogeneity, it reverses the differential’s polarity. Moreover, we find that the higher the inherent uncertainty level, the more pronounced are the effects. We likewise find that the effects of market size uncertainty are amplified if the notion of consumer heterogeneity is replaced with retail-level competition. © 2017 Elsevier B.V. All rights reserved.	centralized computing;fear, uncertainty and doubt	Yan Liu;Hongyan Shi;Nicholas C. Petruzzi	2018	European Journal of Operational Research	10.1016/j.ejor.2017.08.030	mathematics;willingness to pay;newsvendor model;microeconomics;communication channel	ECom	-2.1203354100302834	-6.754365558715866	43608
6f31ab5f44e754eed99cedc956fd6a42077bbaff	simple versus optimal mechanisms	networks;independent private values;commerce;satisfiability;agents;vickrey auction;revenue maximization;economics;review;regularity condition	The monopolist's theory of optimal single-item auctions for agents with independent private values can be summarized by two statements. The first is from Myerson [8]: the optimal auction is Vickrey with a reserve price. The second is from Bulow and Klemperer [1]: it is better to recruit one more bidder and run the Vickrey auction than to run the optimal auction. These results hold for single-item auctions under the assumption that the agents' valuations are independently and identically drawn from a distribution that satisfies a natural (and prevalent) regularity condition. These fundamental guarantees for the Vickrey auction fail to hold in general single-parameter agent mechanism design problems. We give precise (and weak) conditions under which approximate analogs of these two results hold, thereby demonstrating that simple mechanisms remain almost optimal in quite general single-parameter agent settings.		Jason D. Hartline;Tim Roughgarden	2009	SIGecom Exchanges	10.1145/1598780.1598785	vickrey auction;generalized second-price auction;economics;computer science;vickrey–clarke–groves auction;software agent;revenue equivalence;microeconomics;welfare economics;auction theory;commerce;satisfiability	ECom	-3.489312625699735	-2.248993906916234	43631
aafcfffad7f4e8d258cacdd98aacae0a4c73953a	online auctions and multichannel retailing	seller activity;online auction;online auctions;online auction channel;lower percentage;online channel;retail location;multichannel retailing;auction sale price;reserve price;auction outcome;online auction outcome;pricing;retailing;electronic commerce;cost accounting;internet;data collection	An advantage of online auctions is the ability to offer an item at auction while simultaneously using other offline and online channels. Despite the potential of interactions between channels, little is known regarding how multichannel-retailing strategies may influence outcomes for online auctions. Using data collected from eBay Motors and dealer websites, this paper examines how resources and capabilities of sellers related to multichannel retailing influences online auction outcomes--with findings indicating that auction outcomes are influenced by seller activities in other channels. In particular, this paper finds that the quality of the retail location (accessed through the total household income for the surrounding 30 miles of the seller's location) and the seller's electronic commerce capabilities (accessed through the seller's website and use of other online channels) are each associated with increases in auction sale price, a lower percentage of auctions in which the reserve price is met (closing ratio), and a lower percentage of vehicles which sell through the online auction channel (sell-through ratio).	closing (morphology);e-commerce;interaction;omnichannel;online and offline;online shopping	Jason Kuruzovich	2012	2012 45th Hawaii International Conference on System Sciences	10.1109/HICSS.2012.457	e-commerce;pricing;eauction;the internet;combinatorial auction;generalized second-price auction;computer science;auto auction;marketing;reverse auction;common value auction;revenue equivalence;multiunit auction;english auction;advertising;auction theory;commerce;cost accounting;forward auction;data collection;dutch auction	HCI	-2.41464849796884	-8.1917406218656	43678
d2082ce38813e1c5a50521fe81e191fcf04e29c1	dynamic portfolio selection with market impact costs	multiple time scale asymptotic expansion;liquidity;dynamic portfolio choice;trading costs	This paper concerns optimal dynamic portfolio choice with quadratic utility when there are market impact costs. The optimal policy is difficult to characterize, so we look instead for sub-optimal policies. Our proposed suboptimal policy solves a tractable dynamic portfolio choice problem where the cost of trading is captured in the objective instead of the price dynamics. A multiple time scale asymptotic expansion shows that our proposed policy has sensible structural properties, while numerical experiments show promising performance and robustness properties.		Andrew E. B. Lim;Poomyos Wimonkittiwat	2014	Oper. Res. Lett.	10.1016/j.orl.2014.04.008	replicating portfolio;portfolio optimization;market liquidity	ECom	1.9230052915692963	-2.339030375743051	43699
934094a58835bd3646de6e04a15c7d0a38b81f7d	inventory management of spare parts in an energy company	duplicates;inventory management;service level;operant conditioning;or in the oil and gas sector;journal of the operational research society;inventory of spare parts;oil and gas;computer experiment;cost efficiency;lot sizing;ownership structure;inventory inaccuracy;expert judgment;inventory control;working paper;spare parts;risk pooling	We address a problem of inventory management of spare parts in the context of a large energy company, producer of oil and gas. Spare parts are critical for assuring operational conditions in offshore platforms. About 200,000 different items are held in several inventory plants. The inventory system implemented at the company corresponds to a min-max system. The control parameters are decided based mainly on the expert judgment of the planners. Also, though the inventory plants can in practice be supplied from each other, the inventory planning is performed separately by the plant planners. This is because of different ownership structures where the studied company has the operative responsibility. The company is pursuing a system in which all planners conform to the same inventory management approach and evaluation, as well as being more cost efficient. Our work focuses on supporting this goal. We apply methods to decide the inventory control parameters for this system under a service level constraint. The methodology we use distinguishes unit-size and lot-size demand cases. We perform computational experiments to find control parameters for a sample of items. After the control parameters are found, we use them to explore the impact of risk pooling among the plants and inaccuracy arising from duplicate item codes.	code;computation;cost efficiency;experiment;inventory control;multistage interconnection networks	Mario Guajardo;Mikael Rönnqvist;Ann Mari Halvorsen;Svein Inge Kallevik	2015	JORS	10.1057/jors.2014.8	inventory control;computer experiment;service level;economics;marketing;operations management;spare part;operant conditioning;risk pool;management;operations research;cost efficiency	AI	9.39939125773391	-3.023577401553018	43765
56e493709f8b11a91ce2af93a5cf3995da34c378	redagent: winner of tac scm 2003	high dimensionality;international marketing;supply chain management;international trade	The Supply Chain Management track of the international trading Agents Competition (TAC ACM) provides a challenging scenario for existing AI decision-making algorithms, due to the high dimensionality and the non-determinism of the environment. Our entry in this competition, RedAgent, is centered around the idea of using an internal market in order to determine what products to focus on and how to allocate the existing resources. This simple design provided a very efficient search mechanism, while at the same time producing price estimates for components, as well as bidding estimates on customer orders.	algorithm	Philipp W. Keller;Felix-Olivier Duguay;Doina Precup	2004	SIGecom Exchanges	10.1145/1120701.1120703	supply chain management;economics;marketing;operations management;microeconomics;management;commerce	AI	0.5749421313798835	-7.391134077184267	43776
ce05a154d1a85f8eed826b2c7b5a2ab394e21d19	modeling crime diffusion and crime suppression on transportation networks: an initial report.		In urban transportation networks, crime diffuses as criminals travel through the networks and look for illicit opportunities. It is important to first model this diffusion in order to recommend actions or patrol policies to control the diffusion of such crime. Previously, game theory has been used for such patrol policy recommendations, but these applications of game theory for security have not modeled the diffusion of crime that comes about due to criminals seeking opportunities; instead the focus has been on highly strategic adversaries that plan attacks in advance. To overcome this limitation of previous work, this paper provides the following key contributions. First, we provide a model of crime diffusion based on a quantal biased random movement (QBRM) of criminals opportunistically and repeatedly seeking targets. Within this model, criminals react to real-time information, rather than strategically planning their attack in advance. Second, we provide a gametheoretic approach to generate randomized patrol policies for controlling such diffusion.	approximation algorithm;cobham's thesis;cybercrime;game theory;markov chain;mathematical optimization;nonlinear programming;nonlinear system;optimization problem;quantum;randomized algorithm;real-time data;scalability;scheduling (computing);zero suppression	Chao Zhang;Albert Xin Jiang;Martin B. Short;P. Jeffrey Brantingham;Milind Tambe	2013				AI	-2.301656912807874	2.571202216342442	43913
e6e7d653c22c62be5068d018a6a434abcda0f39f	shield versus sword resource distribution in k-round duels	defense;game theory;journal article;contest intensity;protection;peer reviewed;attack;survivability;duel	The paper considers optimal resource distribution between offense and defense in a duel. In each round of the duel two actors exchange attacks distributing the offense resources equally across K rounds. The offense resources are expendable (e.g. missiles), whereas the defense resources are not expendable (e.g. bunkers). The outcomes of each round are determined by a contest success functions which depend on the offensive and defensive resources. The game ends when at least one target is destroyed or after K rounds. We show that when each actor maximizes its own survivability, then both actors allocate all their resources defensively. Conversely, when each actor minimizes the survivability of the other actor, then both actors allocate all their resources offensively. We then consider two cases of battle for a single target in which one of the actors minimizes the survivability of its counterpart whereas the counterpart maximizes its own survivability. It is shown that in these two cases the minmax survivabilities of the two actors are the same, and the sum of their resource fractions allocated to offense is equal to 1. However, their resource distributions are different. In the symmetric situation when the actors are equally resourceful and the two contest intensities are equal, then the actor that fights for the destruction of its counterpart allocates more resources to offense. We demonstrate a methodology of game analysis by illustrating how the resources, contest intensities and number of rounds in the duels impact the survivabilities and resource distributions.	minimax;the duel: test drive ii	Kjell Hausken;Gregory Levitin	2011	CEJOR	10.1007/s10100-010-0148-5	game theory;attack;peer review;economics;operations management;operations research;computer security	ECom	-3.6594753464426053	-4.028548247051851	44086
54f0a0ef656cecdb7eae559f0e2a2940b80a3452	hybrid modeling for vineyard harvesting operations		Hiring workers under seasonal recruiting contracts causes significant variation of workers skills in the vineyards. This leads to inconsistent workers performance, reduction in harvesting efficiency, and increasing in grape losses rates. The objective of this research is to investigate how the variation in workers experience could impact vineyard harvesting productivity and operational cost. The complexity of the problem means that it is difficult to analyze the system parameters and their relationships using individual analytical model. Hence, a hybrid model integrating discrete event simulation (DES) and agent based modeling (ABM) is developed and applied on a vineyard to achieve research objective. DES models harvesting operation and simulates process performance, while ABM addresses the seasonal workers heterogeneous characteristics, particularly experience variations and disparity of working days in the vineyard. The model is used to evaluate two seasonal recruiting policies against vineyard productivity, grape losses quantities, and total operational cost.	agent-based model;binocular disparity;information harvesting;simulation	Mohammed Mesabbah;Amr Mahfouz;Mohamed A. F. Ragab;Amr Arisha	2016	2016 Winter Simulation Conference (WSC)		agriculture;productivity;simulation;environmental engineering;engineering;mathematical model;measurement;statistics	AI	5.180636312222511	-8.301587191423236	44352
285d68de8a6fa415d1d471f3a5417033c263f29b	for-profit mediators in sponsored search advertising	game theory;incentive compatibility;sponsored search;ny;for profit	A mediator is a well-known construct in game theory, and is an entity that plays on behalf of some of the agents who choose to use its services, while the rest of th e agents participate in the game directly. We initiate a game theoretic study of sponsored search auctions, such as t hose used by Google and Yahoo!, involving i centive driven mediators. We refer to such mediators as for-profit mediators, so as to distinguish them from mediators introduced in prior work, who have no monetary incentives, a nd re driven by the altruistic goal of implementing certain desired outcomes. We show that in our model, (i) play ers/advertisers can improve their payoffs by choosing to use the services of the mediator, compared to directly par ticipating in the auction; (ii) the mediator can obtain monetary benefit by managing the advertising burden of its gr oup of advertisers; and (iii) the payoffs of the mediator and the advertisers it plays for are compatible with the ince ntiv constraints from the advertisers who do dot use its services. A simple intuition behind the above result com es from the observation that the mediator has more information about and more control over the bid profile than a ny individual advertiser, allowing her to reduce the payments made to the auctioneer, while still maintaining in centive constraints. Further, our results indicate that there are significant opportunities for diversification in t he internet economy and we should expect it to continue to develop richer structure, with room for different types of a gents to coexist.	coexist (image);diversification (finance);expect;game theory;matchware mediator;search advertising;search engine marketing	Sudhir Kumar Singh;Vwani P. Roychowdhury;Himawan Gunadhi;Behnam Attaran Rezaei	2007	CoRR		public relations;game theory;economics;incentive compatibility;marketing;microeconomics;advertising;mathematical economics	ML	-3.3291518923935617	-6.166990530413571	44479
d10ab5e927972a73152ae90c62017cb13229ca35	asset pricing in a monetary economy with heterogeneous beliefs	finance;continuous time finance;monetary economics;grupo de excelencia;market volatility;monetary policy;administracion de empresas;economia y empresa;heterogeneous beliefs;grupo a;asset pricing	In this paper, we shed new light on the role of monetary policy in asset pricing by focusing on the case where investors have heterogeneous expectations about future monetary policy. This case is realistic, because central banks are typically less than perfectly open on their intentions. Accordingly, surveys of economists in the press reveal that they frequently disagree in their expectations. Under heterogeneity in beliefs, investors place bets against each other on the evolution of the money supply, and as a result, the sharing of wealth in the economy evolves stochastically over time, making money non-neutral. Employing a continuous-time, general equilibrium model, we establish these fluctuations to be rich in implications, in that they majorly affect the equilibrium prices of all assets, as well as inflation. In some specific cases, we are able to derive explicit formulas for important economic quantities. In particular, we find that the stock market volatility may be significantly increased by the heterogeneity in beliefs. In addition to generating interesting behavior on the part of asset prices, our model provides a natural framework in which to assess the impact of the transparency of monetary policy, a topical and controversial issue. Our model is particularly appropriate for the study of the effects of transparency, because it is intuitive that one of the key effects of increased transparency should be a drop in the amount of heterogeneity in beliefs.	aggregate data;c date and time functions;cobham's thesis;coefficient;envelope theorem;filter bank;first-order predicate;linear algebra;mathematical optimization;money;numerical analysis;optimization problem;volatile memory;volatility	Benjamin Croitoru;Lei Lu	2015	Management Science	10.1287/mnsc.2014.1968	financial economics;monetary policy;economics;marketing;finance;microeconomics;management;monetary economics	ECom	-0.31559668383460454	-3.4579868442228574	45042
08eed85ad01eccdfed4330b31276e8177a8a63b6	increasing long belt-conveyors availability by using fault-resilient medium voltage ac drives: part ii — reliability and maintenance assessment	medium voltage;reliability;circuit faults;profitability long belt conveyors availability fault resilient medium voltage ac drives reliability assessment maintenance assessment mining industry medium voltage variable frequency drives mv vfd drive system availability drive solution three level igct based converter 3l igct based converter neutral point clamped converters fault resilient 3l npc igct based converter stock forecasting spare parts multidrive common dc bus downhill conveyor catastrophic protection failure;availability;convertors;maintenance engineering;spare parts forecasting availability belt conveyors igct medium voltage drives npc converters protection reliability;medium voltage drives;reliability ac motor drives belts convertors conveyors failure mechanical maintenance engineering mining industry profitability;belts;mining industry;protection;redundancy;conveyors;npc converters;failure mechanical;spare parts forecasting;mining industry maintenance engineering circuit breakers medium voltage redundancy circuit faults;profitability;circuit breakers;belt conveyors;igct;ac motor drives	In the mining industry the profitability goals are often linked to the long belt-conveyors availability. Since the use of the medium voltage variable frequency drives (MV-VFD) in conveying applications is essential to meet various technical requirements, the conveyor service continuity depends on the drive system availability. Although there are at least three established technologies commercially available, the drive solution using three-level (3L) IGCT-based, neutral point clamped (NPC) converters is clearly the most popular for higher powers. In the early parts of this work [1] and [2], it was shown how to design a fault-resilient 3L-NPC IGCT-based converter, in this second part, the reliability, availability and maintenance aspects of MV-VFD are discussed with focus on the benefits provided by the fault-resilient design. The stock forecasting for spare parts considering a multidrive common dc bus used in a real downhill conveyor is performed and analyzed under catastrophic protection failure standpoint.	belt machine;diode;downtime;mv-algebra;np-completeness;requirement;scott continuity;simulation;switched-mode power supply;uptime;vacuum fluorescent display	Anderson V. Rocha;Helder de Paula;Manoel E. dos Santos;Braz de Jesus Cardoso Filho	2012	2012 IEEE Industry Applications Society Annual Meeting	10.1109/IAS.2012.6374079	control engineering;electronic engineering;engineering;operations management	Embedded	6.130098951546792	1.2274381270102954	45305
b9d401f6431f06d8e278563cc1b0fed28e9ddd4b	attention allocation for decision making queues	computacion informatica;policies;grupo de excelencia;human robot interaction;sigmoid utility;ciencias basicas y experimentales;control of queues;optimization;markov processes;human decision making	We consider the optimal servicing of a queue with sigmoid server performance. There are various systems with sigmoid server performance including systems involving human decision making, visual perception, human-machine communication and advertising response. The tasks arrive at the server according to a Poisson process. Each task has a deadline that is incorporated as a latency penalty. We investigate the trade-off between the reward obtained by processing the current task and the penalty incurred due to the tasks waiting in the queue. We study this optimization problem in a Markov decision process (MDP) framework. We characterize the properties of the optimal policy for the MDP and show that the optimal policy may drop some tasks, that is, may not process a task at all. We determine an approximate solution to the MDP using certainty-equivalent receding horizon optimization framework and determine performance bounds on the proposed receding horizon policy. We also suggest guidelines for the design of such queues.	approximation algorithm;automata theory;automaton;closed-loop transfer function;decision support system;human factors and ergonomics;human reliability;interaction;loop optimization;markov chain;markov decision process;mathematical optimization;optimization problem;preemption (computing);queueing theory;server (computing);sigmoid function	Vaibhav Srivastava;Ruggero Carli;Cédric Langbort;Francesco Bullo	2014	Automatica	10.1016/j.automatica.2013.11.028	human–robot interaction;real-time computing;simulation;partially observable markov decision process;computer science;mathematics;markov process;statistics	Metrics	1.870332419612092	-0.2903381074705043	45311
c23a84e49c4b6a90ccec80eaba18dfa4aaf1d8e8	scenario-based resilience assessment framework for critical infrastructure systems: case study for seismic resilience of seaports		A number of metrics in the past have been proposed and numerically implemented to assess the overall performance of large systems during natural disasters and their recovery in the aftermath of the events. Among such performance measures, resilience is a reliable metric. This paper proposes a probabilistic framework for scenario-based resilience assessment of infrastructure systems. The method accounts for uncertainties in the process including the correlation of the earthquake intensity measures, fragility assessment of structural components, estimation of repair requirements, the repair process, and finally the service demands. The proposed method is applied to a hypothetical seaport terminal and the system level performance of the seaport is assessed using various performance metrics. Results of this analysis have shown that medium to large seismic events may significantly disrupt the operation of seaports right after the event and the recovery process may take months. The proposed framework will enable port stakeholders to systematically assess the most-likely performance of the system during expected future earthquake events. & 2014 Elsevier Ltd. All rights reserved.	cladistics;computer simulation;disaster recovery plan;emoticon;half-life 2: episode one;hardening (computing);nonlinear system;numerical analysis;pushover;requirement;uncertainty quantification	Abdollah Shafieezadeh;Lindsay Ivey Burden	2014	Rel. Eng. & Sys. Safety	10.1016/j.ress.2014.07.021	reliability engineering;systems engineering;engineering;civil engineering	HPC	7.576316182314228	-9.562861801150433	45340
a1c8f9c115080c6387e53498a9a1d17bfd21dd2d	a survey of uniqueness results for selfish routing	nash equilibrium;cost function;selfish routing;network topology	We consider the problem of selfish or competitive routing over a network with flow-dependent costs which is shared by a finite number of users, each wishing to minimize the total cost of its own flow. The Nash Equilibrium is well known to exist for this problem under mild convexity assumptions on the cost function of each user. However, uniqueness requires further conditions, either on the user cost functions or on the network topology. We briefly survey here existing results that pertain to the uniqueness issue. We further consider the mixed NashWardrop problem and propose a common framework that allows a unified treatment of this problem.	loss function;nash equilibrium;network topology;routing	Nahum Shimkin	2007		10.1007/978-3-540-72709-5_4	mathematical optimization;economics;mathematical economics;welfare economics	ECom	-2.4596985287939916	2.1037670057683995	45603
2c720120f57a8b5cb577d6f4e5da4600328d0eff	multi agent based networking satellite tasks scheduling with department collaborative mechanism		Satellite network, multiply satellites cooperated, can perform the complicated observation tasks. Also, how to schedule the task is critical in the whole satellite system. As a kind of NP Hard problem, it is defined as a combinatorial optimization problem with a number of resources, requests, and constraints. The existing researches mainly focus on a satellite or a type of satellite. Furthermore, this paper proposed an approach of tasks scheduling with the department collaborative mechanism. It contains three respects of work: First, adopting the department collaborative mechanism makes it possible for delicacy management and planning as a whole. Then, we built a multi-agent based tasks scheduling model to solve the interaction problem among the cooperative departments and satellites. Finally, a contract net algorithm with allowing reschedule is presented for solving the dynamic task scheme. Simulation experiments verified the models and algorithms above.	agent-based model;scheduling (computing)	Wei Jiang;Xiu-Li Pang;Zi-qing Yuan	2017		10.1109/FSKD.2017.8393413	satellite system;task analysis;artificial intelligence;machine learning;combinatorial optimization;scheduling (computing);satellite;computer science;distributed computing	ML	-0.638912274619889	2.6614958213695226	45897
104c62145a7e9b88b787cfcca42e0230ee72dbf8	auctions with private uncertainty and resale opportunities	secondary market;revenue equivalence;resale markets;common value;market structure;signaling;winner s curse;profitability;endogenous valuations;loser s curse;auctions	This paper studies auctions held before bidders are sure of the values they place on the object for sale, leaving potential gains to subsequent resale trade. While important insights from models of auctions without resale carry over, equilibrium bidding can be fundamentally altered by the endogeneity of valuations and the informational linkages between primary and secondary markets. As a result, models ignoring resale may often misguide policy and interpretation of bidding data. Furthermore, results regarding players' incentives to signal through their bids, the e ects of resale on auction revenues, and revenue comparisons between standard auctions depend on the structure of the secondary market. JEL Class: D44, D89	endogeneity (econometrics)	Philip A. Haile	2003	J. Economic Theory	10.1016/S0022-0531(02)00010-8	industrial organization;signalling;secondary market;economics;winner's curse;common value auction;revenue equivalence;market structure;microeconomics;commerce;profitability index	ECom	-2.0489862372966328	-6.661020161431444	45900
85226738a0f4f575c6debc02d60ee5ef840215ff	a multinomial probit model of stochastic evolution	idiosyncrasy;dominated strategies;equilibrium selection;normal distribution;stochastic evolution;probit model;rooted tree;multinational probit;normal form game	A strategy revision process in symmetric normal form games is proposed. Following Kandori et al. (Econometrica 61 (1993) 29), members of a population periodically revise their strategy choice, and choose a myopic best response to currently observed play. Their payoffs are perturbed by normally distributed Harsanyian trembles, so that strategies are chosen according to multinomial probit probabilities. As the variance of payoffs is allowed to vanish, the graph theoretic methods of the earlier literature continue to apply. The distributional assumption enables a convenient closed form characterisation for the weights of the rooted trees. An illustration of the approach is offered, via a consideration of the role of dominated strategies in equilibrium selection. r 2003 Elsevier Science (USA). All rights reserved. JEL classification: C72; C73	belief revision;best practice;ergodicity;evolutionary algorithm;graph theory;multinomial logistic regression;nash equilibrium;path dependence;probit model;vanish (computer science)	David P. Myatt;Chris C. Wallace	2003	J. Economic Theory	10.1016/S0022-0531(03)00069-3	normal distribution;probit model;econometrics;economics;mathematics;normal-form game;mathematical economics;multivariate probit model;welfare economics;equilibrium selection;multinomial probit;statistics	AI	-0.04555239281914327	-2.3904687334062458	45988
719d8bd77fdf582d9fd9ea37f62e892181fcdd18	a simulation framework for uneconomic virtual bidding in day-ahead electricity markets		Virtual bids were introduced in U.S. wholesale electricity markets to exploit arbitrage opportunities arising from expected price differences between day-ahead and real-time energy markets. These financial instruments have interactions with other elements of the electricity market design. For instance, virtual bids may be intended to move day-ahead electricity prices in a direction that enhances the value of Financial Transmission Rights (FTRs) settling at those energy prices. We consider a model of the day-ahead electricity market at one node in the network, under the assumption that virtual bidding does not affect the real-time dispatch of generators. Theoretical results on interior Nash equilibria are presented, assuming virtual bidders can perfectly predict real-time prices and hold no FTRs. We then adopt a kind of hypergame framework to model the day-ahead market, assuming imperfect prediction of real-time prices by different virtual bidders, and present simulation results with and without FTRs. Finally, we discuss two detection mechanisms that may be used by regulators to distinguish between competitive and manipulative market outcomes, as well as trade-offs between specificity and sensitivity.	dynamic dispatch;interaction;nash equilibrium;real-time clock;real-time transcription;sensitivity and specificity;simulation;terminator 2: judgment day	Yuquan Shan;Chiara Lo Prete;George Kesidis;David J. Miller	2017	2017 American Control Conference (ACC)	10.23919/ACC.2017.7963361	control engineering;computer science;electricity market;financial instrument;exploit;bidding;arbitrage;microeconomics;electricity;nash equilibrium;supply and demand	ECom	1.724209959530926	2.9020936027283764	46147
8fce821694f4ecc939ffae101b6dfd2e5b1b7f4f	aggregate instability under balanced-budget consumption taxes: a re-examination	infinite horizon model;endogenous business cycles;income effect;indeterminacy;balanced budget rule;consumption taxes	We re-examine the destabilizing role of balanced-budget fiscal policy rules based on consumption taxation. Using a one-sector model with infinitely-lived households, and assuming that preferences are of the Greenwood-Hercovitz-Huffman [8] (GHH) type, we show that non-linear consumption taxation may destabilize the economy, promoting expectation-driven fluctuations, if the tax rate is countercyclical. We also exhibit a Laffer curve, which explains the multiplicity of steady states when the tax rate is counter-cyclical. All these results are mainly driven by the absence of income effect. Finally, a numerical illustration shows that consumption taxation may be a source of instability for most OECD countries.	aggregate function;huffman coding;instability;larry laffer;nonlinear system;numerical analysis	Carine Nourry;Thomas Seegmuller;Alain Venditti	2013	J. Economic Theory	10.1016/j.jet.2013.07.010	consumption function;autonomous consumption;economics;finance;macroeconomics;microeconomics;mathematical economics	AI	-0.5014910703176575	-8.479997496183532	46152
8f4dac8885befdbdbb6c71e66333684674f6ff19	analysis of base-stock controlled production-inventory system using discrete-time queueing models	stock control;poisson process;optimisation;service level;control system analysis control system synthesis queueing analysis cost function supply chains batch production systems pulp manufacturing random variables material storage inventory control;queueing theory;discrete time systems;discrete time;serving orders discrete time queueing models base stock controlled production inventory system customer orders discrete random variables optimization model poisson process;stochastic processes stock control discrete time systems queueing theory optimisation warehousing;stochastic processes;queueing model;warehousing;random variable;optimization model	In this paper, we concern ourselves with a production-inventory (PI) system consisting of a manufacturing plant and one warehouse which faces a stream of demands from customers. We present discrete-time queueing models which can be used for evaluating the performance of a given production-inventory system which processes customer orders with service times that are discrete random variables. This analysis can be embedded in an optimization model which can be used for designing efficient inventory policies. In particular we determine the optimal base-stock level at the warehouse that minimizes the long term total expected cost per unit time of carrying inventory, backorder cost associated with serving orders in the backlog queue. In an alternate model, we impose stock out as a service level constraint in terms of probability of stock out at the warehouse. In these models we assume that customers do not balk from the system. In this paper, the customers orders arriving at warehouse are assumed to Poisson process; the service process at the manufacturing plant has the distribution of a discrete random variable. Several examples are presented to validate the model and to illustrate its various features.	embedded system;inventory control;mathematical optimization;queueing theory;verification and validation	Sandeep Jain;N. R. Srinivasa Raghavan	2005	IEEE International Conference on Automation Science and Engineering, 2005.	10.1109/COASE.2005.1506742	simulation;bulk queue;marketing;operations management;layered queueing network;business	Robotics	5.748874940505484	-0.7637649132023023	46250
75f87cf8ebe3119b482dd0d4250c92c1bcc24f36	an integrated vendor-buyer inventory model with order-processing cost reduction and permissible delay in payments	cout variable;gestion integrada;juste a temps;modelizacion;politica optima;gestion integree;capital;variable cost;bank credit;credit bancaire;financing;cost function;diminution cout;pago;adquisicion por suscripcion;compra;credito bancario;trade credit;inversion;information technology;cost reduction;convexite;integrated management;order processing cost;permissible delay in payments;payment;optimal policy;financiacion;funcion coste;investment;inventory model;convexidad;systeme ordre reduit;administracion deposito;purchasing;modelisation;capital investment;paiement;intercambio electronico de datos;tamano lote;taille lot;financement;retard;investissement;gestion stock;lot sizing;fonction cout;achat;just in time;justo en tiempo;echange donnee informatise;information system;convexity;reduccion costes;retraso;politique optimale;modeling;inventory control;cost lowering;systeme information;reduced order systems;inventory model order processing cost permissible delay in payments;electronic data interchange;purchases;acquisition titre onereux;sistema informacion	Trade credit plays an important role in financing for many businesses and industries. For the buyers, purchased inventory can be considered to be financed in whole or in part with permissible delay in payments during the purchasing process. On the other hand, both the vendor and buyer take part in order-processing cost reduction by applying information technologies, such as EDI (electronic data interchange). The order-processing cost can also be reduced by adding certain capital investments, and this will affect the lot size decisions. This article develops an integrated inventory model to determine the optimal inventory policy under conditions of order-processing cost reduction and permissible delay in payments, and shows that the total annual variable cost function possesses some kinds of convexities. A solution procedure is provided to determine the optimal order policy. Finally, a numerical example is presented to illustrate the solution procedure. 2009 Elsevier B.V. All rights reserved.	electronic data interchange;inventory theory;loss function;numerical analysis;purchasing	Chao-Kuei Huang;Deng-Maw Tsai;Ji-Cheng Wu;Kun-Jen Chung	2010	European Journal of Operational Research	10.1016/j.ejor.2009.05.035	inversion;inventory control;variable cost;economics;capital;convexity;investment;public economics;operations management;electronic data interchange;economy;information technology;information system;payment	EDA	3.210602274713971	-5.23317053757272	46308
c6ee8b1dc9ed9f0ea2ffbfeb8bdd69c760ffa979	addressing flexibility during process and infrastructure systems conceptual design: real options perspective	real options analysis;degree of freedom;conceptual systems design infrastructure system energy infrastructure design industrial infrastructure design optimal design decision analysis flexible design infrastructure systems network real option analysis infrastructure systems design conceptual design process infrastructure flexibility;decision analysis;conceptual design;conceptual systems design infrastructure flexibility uncertainty real options;system design;real option;optimal design;uncertainty power generation economics environmental economics cost accounting technology management investments energy management system analysis and design process design bonding;electricity supply industry	In highly complex and dynamic designs such as energy and industrial infrastructure designs, designers may not practically (within the available time limit), be able to assess all the uncertainties with all the needed precision required for optimal design decision analysis that could lead to flexible design outputs. Consequently, practical and realistic approaches are still needed for addressing such residual uncertainties early in the conceptual design phase of these interconnected and interdependent infrastructure systems networks. In this paper, the place of real-option analysis, which incorporates uncertainty in a theoretically consistent manner, in exploitatively handling these uncertainties during the infrastructure systems design, is addressed. We surmise that the adoption of the real options approach early in the conceptual design process can offer to the designer, extra degrees of freedom of systematically considering and designing system elements with the ability of reacting swiftly to the varying technical, economic and institutional dynamics of infrastructure systems.	complexity;decision analysis;interdependence;inventory;mathematical model;optimal design;radiant ai;systems design;value (ethics)	Austine N. Ajah;Paulien M. Herder	2005	2005 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2005.1571723	probabilistic design;decision analysis;optimal design;conceptual design;management science;degrees of freedom;statistics;systems design	EDA	6.94705318910474	-6.289263709697074	46321
be4a127dca7c52c7f8d2e3146c65907055f2174d	multiple-layer network planning with scenario-based traffic forecast	traffic uncertainty;network planning;multi layer	One of the major tendencies in network planning is to take the interactions of multiple network layers into consideration, so that solutions much better than those restricted in single layers can be achieved. This also applies when planning for the extension of the network infrastructure to meet the increment of traffic in the future, in which minimizing the capital expenditure of new devices and the corresponding energy consumptions are among the greatest concerns of network operators. However, the planning relies on the forecast of future traffic demands, where some degree of uncertainty must be counted as a part. A special forecast mechanism currently used by some network operators is to make a series of forecasts, each being a scenario which describes a possible future situation. In this paper, we will introduce this mechanism, analyze its differences to other traffic uncertainty models, and suggest the corresponding planning methods based on the Integer Linear Programming (ILP) models. The performances are shown in the tests at a scale of real problems.		Shu Zhang;Ulrich Killat	2011		10.1007/978-3-642-23541-2_10	traffic generation model;network planning and design;simulation;engineering;operations management;network simulation;operations research	AI	9.413205308710396	-6.329801979151031	46335
d9086bc71900a2e48c4512782e790c5bd9fd9a21	dynamic relational contracts under complete information	relational contracts;risk sharing;limited commitment;self enforcement;working paper	This paper considers a long-term relationship between two agents who both undertake an action or investment that produces a joint benefit. Agents have an opportunity to expropriate some of the joint benefit for their own use. Agents have quasi-linear preferences. Two cases are considered: where agents are risk averse but where limited liability constraints do not bind, and where agents are risk neutral and subject to limited liability constraints. We ask how to structure the investments and division of the surplus over time to avoid expropriation. In the risk-averse case, the dynamics of actions and surplus may or may not be monotonic depending on whether or not a first-best allocation can be sustained. Agents may underinvest but never overinvest. If the first-best allocation is not sustainable, there is a trade-off between risk sharing and surplus maximization; surplus may not be at its constrained maximum even in the long run and the “amnesia” property of pure risk-sharing models fails to hold. In contrast, in the risk-neutral case there may be an initial phase in which one agent overinvests and the other underinvests. Both actions and surplus converge monotonically to a stationary state, where surplus is maximized subject to the self-enforcing constraints. © 2018 Published by Elsevier Inc. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/). JEL classification: C61; C73; D86; D91; L14		Jonathan P. Thomas;Tim Worrall	2018	J. Economic Theory	10.1016/j.jet.2018.02.004	actuarial science;economics;operations management;welfare economics	AI	-4.379168853746176	-4.208435077732397	46373
7dba809792dc5405560c4e9b8b664b85bb3c6512	criteria for a tournament: the world professional snooker championship	torneo;forecasting;reliability;project management;information systems;analisis estadistico;tournament;maintenance;deporte;soft or;information technology;snooker;packing;swinburne;operations research;location;investment;journal;journal of the operational research society;inventory;equite;purchasing;equidad;history of or;equity;sports;logistics;statistical analysis;marketing;scheduling;tournoi;analyse statistique;statistics;production;communications technology;computer science;operational research;sport;applications of operational research;or society;jors;management science;infrastructure	Desirable qualities of a tournament are fairness (the better the player, the better his chance of success), balance (few one-sided matches) and efficiency (long enough to benefit the more skillful yet being completed within schedule). The World Professional Snooker Championship is examined to see how well it meets these criteria.		Stephen R. Clarke;John M. Norman;C. B. Stride	2009	JORS	10.1057/jors.2008.126	project management;logistics;simulation;inventory;economics;forecasting;investment;marketing;operations management;sport;reliability;mathematics;location;management;operations research;information technology;scheduling;equity;tournament;statistics	HCI	6.036255193087175	-3.872749185241104	46456
3d4c7861d31beef9db5f24936b25f4b46966bbae	should business rely on business cycle forecasting?	forecasting;business cycle;planning;strategic management;e32;e37;m21;l21	We investigate the circumstances in which business cycle forecasting is beneficial for business by addressing both the short-run and the long-run aspects. For an assessment of short-run forecasting we make a distinction between using publicly available information of cycle probabilities and the use of resources to sharpen this outlook. A sharpened forecast can pay off because it helps the firm to optimally select its output mix. For a long-run perspective we show that firms whose optimal level of operation varies with varying selling prices gain from an accurate assessment of the likelihood of the states of expansion and recession. Petroleum refining in the U.S. is econometrically studied as an exemplary industry. The results document cyclical regularities that indicate that forecasting is advantageous for firms in this industry.	business logic	Tobias F. Rötheli	2018	CEJOR	10.1007/s10100-017-0477-8		Theory	0.5265345799363367	-9.056756710660606	46474
31f6fb6d62f8e73d6420b400ebfc46d820242406	what's the price now?		Dynamic pricing finds its way into a growing number of industries.		Mark Broderick	2015	Commun. ACM	10.1145/2732421	ask price	Theory	2.08447139053627	-7.806338031999317	46531
b2b6d3b41827d6605d67daa93ac8b0215108b083	slow boom, sudden crash	asset prices;emerging market;asset market;interest rate;journal of economic literature;credit market;public information	Many asset markets exhibit slow booms and sudden crashes. This pattern is explained by an endogenous flow of information. In the model, agents undertake more economic activity in good times than in bad. Economic activity generates public information about the state of the economy. If the economic state changes when times are good and information is abundant, asset prices adjust quickly and a sudden crash occurs. When times are bad, scarce information and high uncertainty slow agents’ reactions as the economy improves; a gradual boom ensues. Data from U.S. and emerging credit markets support the theory. Journal of Economic Literature Classification Numbers: E32, E44, D83.	2010 flash crash;crash (computing);information;lagrangian relaxation;signal-to-noise ratio	Laura L. Veldkamp	2005	J. Economic Theory	10.1016/j.jet.2003.12.008	financial economics;actuarial science;economics;interest rate;finance;macroeconomics;microeconomics;emerging markets	ECom	-0.7231152387235067	-8.58290055853046	46580
d59659270c0b607205919dba9822af2f4c386eee	research report: intrafirm resource allocation with asymmetric information and negative externalities	resource allocation;asymmetric information;negative externalities	We examine the intrafirm resource allocation problem with the following characteristics. The resource exhibits negative externalities, and the benefit of using the resource is known only to the user department and not to top management or other user departments. In addition, the consumption of the resource depends upon the choice of the mechanism for allocating the resource. For this problem, we derive a two-stage mechanism, and show that this proposed mechanism leads to optimal allocation.		Raja Nadiminti;Tridas Mukhopadhyay;Charles H. Kriebel	2002	Information Systems Research	10.1287/isre.13.4.428.70	industrial organization;information asymmetry;externality;economics;resource allocation;public economics;microeconomics;management	ECom	-3.166128135892432	-6.155884077572431	46836
6b10224d8a3b926de1d8d2984801383c8190c059	global positioning systems data for performance evaluation of hov and gp lanes on i-66 and i-395/i-95	performance measure;right of way;high occupancy vehicle lanes;automotive electronics;probes global positioning system time measurement licenses delay road transportation throughput monitoring road vehicles computer errors;performance evaluation;travel time;empirical analysis;traffic engineering computing automotive electronics global positioning system road vehicles;global position system;test bed;i 395 i 95;high occupancy vehicle;global positioning system;i 66;indexation;general purpose lanes;traffic engineering computing;stopping time;i 395 i 95 global positioning systems performance evaluation high occupancy vehicle lanes general purpose lanes i 66;global positioning systems;road vehicles	In this study an empirical analysis is conducted for assessing the performance of high occupancy vehicle (HOV) lanes using Global Positioning System (GPS). Second by second speed, time, and location data were obtained from GPS equipped probe vehicles on HOV lanes with exclusive right of way as well as on HOV lanes that share the right of way with general purpose (GP) lanes. Peak-hour operations of HOV facilities on I-66 and I-395/I-95 corridors in the Washington DC area were used as test beds. Parameters for the performance measures such as travel time, mean journey speed, delay, proportion of stopped time and congestion index were developed and compared for HOV and GP lanes. The data were also used to identify location and the extent of congestion along the study routes. The results of the analysis showed travel times saving, higher journey speeds, less delay, and lower congestion incurred by the probe vehicles on the HOV lanes as compared to the probe vehicles traveling simultaneously on non-HOV lanes	global positioning system;network congestion;performance evaluation	Ali T. Ali;Qiancheng Zhu	2006	2006 IEEE Intelligent Transportation Systems Conference	10.1109/ITSC.2006.1706861	simulation;engineering;automotive engineering;transport engineering	Robotics	9.123592504019685	-7.481239785848455	46843
f4f5c5aba66d9ef30a8e6c473a11ed4ea956d7da	building cooperation in voip network through a reward mechanism	supernode;efficiency wage model;voip;efficiency wage;incentive;satisfiability;market share	In this paper, for solving the moral hazard problem of super nodes in VOIP network and achieving better communication quality, we establish a reward mechanism based on classical efficiency-wage models. In the reward mechanism, the function of reward is to encourage super nodes to contribute their bandwidth and cover their effort costs, whereas the function of fine is to prevent opportunistic super nodes from shirking. We consider that network quality and idle bandwidth are the essential criterions for selecting qualified super nodes. Once all super nodes can satisfy specific conditions, the required reward can be derived so as to improve the VoIP platform’s revenue. Moreover, we also suggest several targets both in technical and economic view that the platform provider can strive in order to boost his/her market share. In addition, the case of Skype is discussed in this study and we also examine its current pricing strategy.	bandwidth (signal processing);moral hazard	Yung-Ming Li;Ding-Yuan Cheng;Jhih-Hua Jhang-Li	2008			supernode;marketing;computer network;market share;idle;efficiency wage;voice over ip;microeconomics;revenue;economics;incentive	ECom	-3.1311414482561353	-5.427891183772743	46910
fe62989eeaa3725f6997c51e26875513e21517cd	an approximation algorithm based on game theory for scheduling simple linear deteriorating jobs	non cooperative game theory;simple linear deterioration;approximation algorithm;price of anarchy	Abstract We consider the scheduling of simple linear deteriorating jobs on parallel machines from a new perspective based on game theory. In scheduling, jobs are often controlled by independent and selfish agents, in which each agent tries to select a machine for processing that optimizes its own payoff while ignoring the others. We formalize this situation as a game in which the players are job owners, the strategies are machines, and a playeru0027s utility is inversely proportional to the total completion time of the machine selected by the agent. The price of anarchy is the ratio between the worst-case equilibrium makespan and the optimal makespan. In this paper, we design a game theoretic approximation algorithm A and prove that it converges to a pure-strategy Nash equilibrium in a linear number of rounds. We also derive the upper bound on the price of anarchy of A and further show that the ratio obtained by A is tight. Finally, we analyze the time complexity of the proposed algorithm.	anarchy;approximation algorithm;game theory;nash equilibrium;nonlinear system;scheduling (computing);time complexity	Keqin Li;Chubo Liu;Keqin Li	2014	Theor. Comput. Sci.	10.1016/j.tcs.2014.05.023	price of stability;implementation theory;mathematical optimization;computer science;repeated game;mathematics;distributed computing;strategy;normal-form game;mathematical economics;algorithmic game theory;approximation algorithm;price of anarchy	AI	-2.264847697810954	0.4504722965398539	47107
11912d84014dcdb2498a449b25c8eb2c1bb2f4b5	optimizing direct response in internet display advertising	negative binomial distribution;internet display advertising;separable programming;direct response marketing;mixed integer programming	Internet display advertising has grown into a multi-billion dollar a year global industry and direct response campaigns account for about three-quarters of all Internet display advertising. In such campaigns, advertisers reach out to a target audience via some form of a visual advertisement (hereinafter also called ‘‘ad’’) to maximize short-term sales revenue. In this study, we formulate an advertiser’s revenue maximization problem in direct response Internet display advertisement campaigns as a mixed integer program via piecewise linear approximation of the revenue function. A novelty of our approach is that ad location and content issues are explicitly incorporated in the optimization model. Computational experiments on a large-scale actual campaign indicate that adopting the optimal media schedule can significantly increase advertising revenues without any budget changes, and reasonably sized instances of the problem can be solved within short execution times. 2011 Elsevier B.V. All rights reserved.	computation;display advertising;entropy maximization;experiment;integer programming;internet;linear approximation;linear programming;mathematical optimization;optimizing compiler;piecewise linear continuation	Vural Aksakalli	2012	Electronic Commerce Research and Applications	10.1016/j.elerap.2011.11.002	advertising campaign;simulation;integer programming;compensation methods;share of voice;marketing;advertising;negative binomial distribution;statistics	ECom	-0.8434997904311915	-2.444772860321644	47253
ac6a6a6345f7e623289ec7b35b26bd529a927873	optimize pricing policy in evolutionary market with multiple proactive competing cloud providers		In the cloud computing market with multiple competing cloud providers, each provider needs to run an optimize pricing policy to determine the price for cloud resources in order to beat other providers and maximize the long-term revenue. In this paper, we intend to design an optimal pricing policy for the cloud provider by taking into account the following two facts: (1) the market is evolutionary in terms of the increased amount of cloud users and the decreased marginal cost of providers; (2) the market is fully competitive since all providers expect to receive more profits while users expect to pay less for their requirements. By considering these realistic situations, we analyze how the cloud provider designs an optimal pricing policy while competing against the other provider. Specifically, we model the pricing issue in the competing environment as a Markov games, and then adopt the Minimax-Q and Q-learning algorithm to find the optimal pricing policy. Finally, we evaluate our algorithms and compare the pricing policy with other existing polices. Numerical simulations demonstrate the effectiveness of our proposed approach.	algorithm;cloud computing;experiment;marginal model;markov chain;minimax;numerical linear algebra;q-learning;requirement;simulation	Bing Shi;Hangxing Zhu;Jinwen Wang;Bin Sun	2017	2017 IEEE 29th International Conference on Tools with Artificial Intelligence (ICTAI)	10.1109/ICTAI.2017.00041	artificial intelligence;machine learning;profit (economics);law enforcement;cloud computing;computer science;microeconomics;marginal cost;revenue;markov chain;markov process	AI	1.753475134833469	-1.3702744308357564	47269
816d7ab55d5c5dff06b7f9a5b16f1799c34c5337	a committed delivery strategy with fixed frequency and quantity	distribution;closed form solution;normal distribution;cost reduction;inventory;finite horizon;supply chain;supply chain management	We analyze a supply chain environment in which a distributor facing price-sensitive demand has the opportunity to contractually commit to a delivery quantity at regular intervals over a finite horizon in exchange for a per-unit cost reduction for units acquired via committed delivery. Supplemental orders needed to meet demand are purchased at an additional unit cost. For normally distributed demand, we use a simulation-based approximation to develop models yielding closed-form solutions for the optimal order quantity and resell price for the distributor. Inventory, ordering and pricing implications for this ‘‘committed delivery strategy’’ are investigated. 2002 Elsevier Science B.V. All rights reserved.	approximation;simulation	Douglas J. Thomas;Steven T. Hackman	2003	European Journal of Operational Research	10.1016/S0377-2217(02)00398-3	normal distribution;distribution;closed-form expression;supply chain management;inventory;economics;marketing;operations management;mathematics;microeconomics;supply chain;commerce	Logic	2.2992026302132396	-4.939213410897716	47283
bd5875cc84ac95a2130fab2fbc78fd50d0e4f94d	exit option for a class of profit functions	exit option;65l10;free boundary problem;optimal stopping time;real options;60g40;49l20	ABSTRACTIn this paper we propose a formula to derive the value of a firm which is currently producing a certain product and faces the option to exit the market, whose demand follows a geometric Brownian motion. The problem of optimal exiting is an optimal stopping problem that can be solved using the dynamic programming principle. This is a free-boundary problem. We propose an approximation for the original model and, using the Implicit Function Theorem, we obtain the solution of the original problem. Finally we show, analytically, that the exit threshold is decreasing with the volatility as well as the drift of the geometric Brownian motion.		Manuel Guerra;Cláudia Nunes;Carlos Augusto Costa Oliveira	2017	Int. J. Comput. Math.	10.1080/00207160.2016.1227435	mathematical optimization;optimal stopping;free boundary problem;control theory;mathematics;mathematical economics;statistics	Theory	1.9772882002834393	-2.646098066724386	47295
d739dabbc781f0cfebb76df9295578ba59cd2dfd	an efficient energy curtailment scheme for outage management in smart grid	variational equilibrium;variational inequality problems;variational techniques cost reduction game theory minimisation power system economics power system management smart power grids;smart grid networks;game theory;variational inequalities;cost reduction;smart grid;conference paper;energy requirements;variati energy curtailment;smart power grids;keywords energy curtailment;variational inequality;power users average total cost reduction energy curtailment game variational equilibrium socially optimum solution variational inequality problem total cost minimization energy requirements noncooperative generalized nash game two way communication infrastructure power outage management energy reduction smart grid network;variational equilibrium smart grid energy curtailment outage management game theory variational inequality;two way communications;outages;communication;outage management	In this paper an efficient energy curtailment scheme is studied, which enables the power users of a smart grid network to decide on the reduction in energy supplied to them in the event of a power outage in the system. Considering the advantages of a two-way communications infrastructure for any future smart grid, a non-cooperative generalized Nash game is proposed where the players are users of power in the network. They adopt a strategy to choose the amount of reduction in energy supplied to them based on their energy requirements so as to minimize the total cost incurred to the system due to the power outage (i.e., social optimality). The game is modeled as a variational inequality problem, and it is shown that the socially optimum solution is obtained at the variational equilibrium of the energy curtailment game. An algorithm that enables the users to efficiently reach this equilibrium is proposed. Simulation results show that the proposed game yields an improvement of about 15% on average, in terms of average total cost reduction, compared to a standard equal power curtailment scheme.	algorithm;calculus of variations;computational complexity theory;denial-of-service attack;downtime;grid network;nash equilibrium;requirement;simulation;social inequality;sun outage;variational inequality;variational principle	Wayes Tushar;Jian Zhang;David B. Smith;H. Vincent Poor;Glenn Platt;Salman Durrani	2012	2012 IEEE Global Communications Conference (GLOBECOM)	10.1109/GLOCOM.2012.6503583	game theory;mathematical optimization;variational inequality;mathematical economics	EDA	2.6266090656789554	3.633119848738085	47318
c1307449801de3a4088fc138d974159f06873f44	managing hospital inpatient bed capacity through partitioning care into focused wings	care partitioning;hospital bed capacity management;focus	We consider the partitioning of care types into wings from the perspective of a hospital administrator who wishes to optimize the use of a fixed number of beds that provide services for heterogeneous care types. The hospital administrator decides on the number of wings to form, the number of beds to allocate to each wing, and the set of care types to assign to each wing to maximize the total utility to the hospital. The administrator faces an inherent trade-off between forming large wings to pool demand and bed capacity, and forming specialized wings to focus on narrow ranges of care types. Specialized wings not only provide advantages from focused care but also allow the protection of beds for high-utility care types. We provide an optimization model for the wing formation decision and address the advantages of focus endogenously in our model. Using data from a large urban teaching hospital in the United States along with a national database, we report on a number of managerial insights. In particular, as the overall demand increases across all care types, wings are formed to reserve more beds for higher-utility types, which leads to higher overall hospital utility but also some disparity across types, such as increased hospital access for some and decreased access for others. Furthermore, overall bed occupancy decreases as the hospital is split into wings. However, if sufficient focus is attained, shorter lengths-of-stay associated with focused care may increase overall patient throughput. We also observe that when patients are willing to wait longer for admission, the hospital tends to form more wings. This implies that hospitals that garner longer waits can form more specialized wings and thereby benefit from focused care, whereas hospitals that cannot will tend to form fewer, if any, wings, choosing to pool demand and bed capacity.		Thomas J. Best;Burhaneddin Sandikçi;Donald D. Eisenstein;David O. Meltzer	2015	Manufacturing & Service Operations Management	10.1287/msom.2014.0516	simulation;operations management;operations research;focus	Robotics	8.410932986861138	-3.934063920113082	47447
971dfb84dc1d6b8f74237c6f797eb95ba82546f0	on predicting the maximum of a semimartingale and the optimal moment to sell a stock		We generalize the results of recent publications on the prediction of an unknown maximum of a process to the case of an exponential semimartingale whose logarithm can be represented as a sum of local martingales and a positive bias. Our results generalize across a wide variety of models, including multifactor models; the results can also be applied to risk reduction problems.		Roman V. Ivanov	2015	Automation and Remote Control	10.1134/S000511791507005X	econometrics;mathematical optimization;mathematics;statistics	Robotics	1.7941651629343942	-2.8950925762730004	47546
e5da5053538fa92efcc3896cf261dde9ec36ef84	a battle of informed traders and the market game foundations for rational expectations equilibrium	rational expectations;noise traders;market game;price manipulation	Potential manipulation of prices and convergence to rational expectations equilibrium is studied in a game without noise traders. Informed players with initially long and short positions (bulls and bears) seek to manipulate consumer expectations in opposite directions. In equilibrium, period 1 prices reveal the state, so manipulation is unsuccessful. Bears and uninformed consumers sell up to their short-sale limits in period 1. Bulls buy in period 1 but receive arbitrage losses. When the number of bulls and bears approaches infinity, the equilibrium converges to the REE. Without short-sale constraints there is a non-revealing equilibrium but no revealing equilibrium. JEL Classification: D43, D53, D84	traders	James Peck	2014	Games and Economic Behavior	10.1016/j.geb.2014.09.004	financial economics;economics;rational expectations;microeconomics	ECom	-4.438440801440167	-6.0431486232011045	47576
0004f531ceb9c9ba5c5ede9e4e7044525c8a6c6e	justifying contingent information technology investments: balancing the need for speed of action with certainty before action	total commitment;justifying contingent information technology;available funding;investment opportunity;strategic commitment;strategic option;strategic uncertainty;subsequent stage investment;common model;high level;investment alternative	Executives need to master different mechanisms for analyzing their firms' investment opportunities in uncertain, difficult times. Rapidly changing business conditions require firms to move quickly, with total commitment and the rapid deployment of capital, resources, and management attention, often in several directions at the same time. However, high levels of strategic uncertainty and environmental risk, combined with limits on available funding, require firms to limit their commitment. In brief, we require high levels of strategic commitment to numerous projects, while simultaneously preserving our flexibility and withholding commitment. Whereas achieving both is clearly impossible, techniques exist that enable executives (1) to identify and to delimit their range of investment alternatives that must be considered, and to do so rapidly and reliably, (2) to divide investments into discrete stages that can be implemented sequentially, (3) to determine which chunks can safely and profitably be developed as strategic options, with value that can be captured when subsequent stage investments are made later; and (4) to quantify and to estimate the value of these strategic options with a significant degree of accuracy, so that selections can be made from a portfolio of investment alternatives. This paper also avoids restrictions of common option valuation models by providing a technique that is general enough to be used when the data required by common models are not available or the assumptions are not satisfied.	contingency (philosophy);the need for speed	Eric K. Clemons;Bin Gu	2003	J. of Management Information Systems		actuarial science;economics;marketing;operations management;valuation of options;management;commerce	AI	0.4912410490012536	-9.027117271241917	47668
8696c98cb8d332ec09bdba85345b76f14aaa4774	scenario relaxation algorithm for finite scenario-based min-max regret and min-max relative regret robust optimization	modelizacion;iterative method;optimal solution;optimisation;solution optimale;decision making under uncertainty;optimizacion;loi probabilite;ley probabilidad;systeme aide decision;metodo minimax;modele lineaire;minimax method;modele mixte;prise de decision;sistema ayuda decision;psychology;modelo lineal;long terme;decision maker;probleme terminaison;iterative algorithm;robust optimization;long term;metodo iterativo;scenario;modelisation;min max regret;systeme incertain;decision support system;programacion lineal;largo plazo;programacion mixta entera;probleme mixte;mixed model;argumento;mathematical programming;methode iterative;solucion optima;min max relative regret;probability distribution;script;linear model;methode minimax;scenario based decision making;linear programming;programmation lineaire;programmation partiellement en nombres entiers;linear program;mixed integer programming;termination problem;ambiguity;problema mixto;psychologie;optimization;modelo mixto;toma decision;sistema incierto;scenarios;ambiguedad;mixed problem;modeling;programmation mathematique;uncertain system;programacion matematica;problema terminacion;psicologia;ambiguite	Most practical decision-making problems are compounded in difficulty by the degree of uncertainty and ambiguity surrounding the key model parameters. Decision makers may be confronted with problems in which no sufficient historical information is available to make estimates of the probability distributions for uncertain parameter values. In these situations, decision makers are not able to search for the long-term decision setting with the best long-run average performance. Instead, decision makers are searching for the robust long-term decision setting that performs relatively well across all possible realizations of uncertainty without attempting to assign an assumed probability distribution to any ambiguous parameter. In this paper, we propose an iterative algorithm for solving min-max regret and min-max relative regret robust optimization problems for two-stage decision-making under uncertainty (ambiguity) where the structure of the first-stage problem is a mixed integer (binary) linear programming model and the structure of the second-stage problem is a linear programming model. The algorithm guarantees termination at an optimal robust solution, if one exists. A number of applications of the proposed algorithm are demonstrated. All results illustrate good performance of the proposed algorithm.	algorithm;linear programming relaxation;mathematical optimization;maxima and minima;regret (decision theory);relaxation (iterative method);robust optimization	Tiravat Assavapokee;Matthew J. Realff;Jane C. Ammons;I-Hsuan Hong	2008	Computers & OR	10.1016/j.cor.2006.10.013	wald's maximin model;mathematical optimization;linear programming;artificial intelligence;mathematics;iterative method;algorithm;regret	ML	6.437129057138535	-3.375977953076455	47718
01e6b3e27fb84735c8878327c631d9560b23f88b	risk measures and their application to staffing nonstationary service systems	healthcare;risk measures;time inhomogeneous markov processes;staffing;queues and service systems	In this paper, we explore the use of static risk measures from the mathematical finance literature to assess the performance of some standard nonstationary queueing systems. To do this we study two important queueing models, namely the infinite server queue and the multi-server queue with abandonment. We derive exact expressions for the value of many standard risk measures for the M t / M / ∞ , M t / G / ∞ , and M t / M t / ∞ queueing models. We also derive Gaussian based approximations for the value of risk measures for the Erlang-A queueing model. Unlike more traditional approaches of performance analysis, risk measures offer the ability to satisfy the unique and specific risk preferences or tolerances of service operations managers. We also show how risk measures can be used for staffing nonstationary systems with different risk preferences and assess the impact of these staffing policies via simulation. © 2016 Elsevier B.V. All rights reserved.	approximation;erlang (programming language);queueing theory;risk measure;server (computing);service-oriented architecture;simulation	Jamol Pender	2016	European Journal of Operational Research	10.1016/j.ejor.2016.03.012	actuarial science;operations management;management science;health care	Metrics	4.966930205083587	-5.892600742534275	47878
bd45db1c38c9021ae7904513ef76a2727eec7991	ruin probabilities in a finite-horizon risk model with investment and reinsurance	60j28	A finite horizon insurance model is studied where the risk/reserve process can be controlled by reinsurance and investment in the financial market. Obtaining explicit optimal solutions for the minimizing ruin probability problem is a difficult task. Therefore, we consider an alternative method commonly used in ruin theory, which consists in deriving inequalities that can be used to obtain upper bounds for the ruin probabilities and then choose the control to minimize the bound. We finally specialize our results to the particular, but relevant, case of exponentially distributed claims and compare for this case our bounds with the classical Lundberg bound		Rosario Romera;Wolfgang J. Runggaldier	2012	J. Applied Probability	10.1017/S0021900200012808	financial economics;actuarial science;operations management;ruin theory;business	Theory	2.5543238852369146	-2.5541277750352056	47890
7e65d27a71ea8da7246a5b01961ee6e2c03a9b78	"""erratum to """"a continuous model for multistore competitive location"""""""	equipment planning;grupo de excelencia;location;ciencias basicas y experimentales;matematicas;facilities;grupo a;continuous	In Dasci and Laporte (2005), we present a model in a multistore competitive location environment. We develop the model by shifting the issue from competition on precise location decisions to competition over location density decisions. The intent of this note is to correct an error in one of the intermediate calculations and its impact on some of the subsequent results. We thank Hans-Peter Ziegler and Stefan Nickel of Saarland University, who discovered the error and brought it to our attention. To describe the error and its correction, we reconsider the leader’s problem and its proposed solution given in Equations (18) and (19) of Dasci and Laporte (2005). The leader’s problem is given as		Abdullah Dasci;Gilbert Laporte	2007	Operations Research	10.1287/opre.1070.0389	continuous function;operations management;mathematics;location	ML	3.30149529794394	-5.815756079477206	47922
f1640cdc3e177e1c57dfcb06b257bc60f2f20cc7	perturbation analysis for investment portfolios under partial information with expert opinions	filtering;hamilton jacobi bellman equation;portfolio optimization;control	We analyze the Merton portfolio optimization problem when the growth rate is an unobserved Gaussian process whose level is estimated by filtering from observations of the stock price. We use the Kalman filter to track the hidden state(s) of expected returns given the history of asset prices, and then use this filter as input to a portfolio problem with an objective to maximize expected terminal utility. Our results apply for general concave utility functions. We incorporate time-scale separation in the fluctuations of the returns process, and utilize singular and regular perturbation analysis on the associated partial information HJB equation, which leads to an intuitive interpretation of the additional risk caused by uncertainty in expected returns. The results are an extension of the partially-informed investment strategies obtained by the Black-Litterman model, wherein investors’ views on upcoming performance are incorporated into the optimization along with any degree of uncertainty that the investor may have in these views.	bellman equation;black–litterman model;black–scholes model;concave function;gaussian process;hamilton–jacobi–bellman equation;kalman filter;mathematical optimization;optimization problem;perturbation theory	Jean-Pierre Fouque;A. Papanicolaou;Ronnie Sircar	2017	SIAM J. Control and Optimization	10.1137/15M1006854	filter;mathematical optimization;hamilton–jacobi–bellman equation;merton's portfolio problem;actuarial science;portfolio optimization;scientific control;statistics	ML	1.7915792422692762	-1.600996838651946	47924
ecee2c7e7295e89c8553ac9082ec2461299481d2	new perspectives on capital, sticky prices, and the taylor principle	sticky prices;new keynesian;interest rate rule;interest rate;monetary policy;price stickiness;interest rate smoothing;point of view;taylor principle	Our main result is that dynamic new-Keynesian (DNK) models with firm-specific capital feature a substantial amount of endogenous price stickiness. We use this insight to assess the desirability of alternative interest rate rules, and make the case for combining active monetary policy with interest rate smoothing and/or some responsiveness of the nominal interest rate to real economic activity. The key mechanism behind our results is also useful from a positive point of view: the feature of firmspecific capital increases the empirical appealingness of DNK models, as documented by a growing body of literature. © 2005 Elsevier Inc. All rights reserved. JEL classification: E22; E31	responsiveness;smoothing;social capital;sticky bit	Tommy Sveen;Lutz Weinke	2005	J. Economic Theory	10.1016/j.jet.2005.02.002	financial economics;monetary policy;economics;real interest rate;credit channel;interest rate;finance;macroeconomics;nominal interest rate;microeconomics;new keynesian economics;mathematical economics;fisher hypothesis	ECom	-1.4807550389118422	-8.644125881117365	48546
315d25f9d7278a04f5592a119f8fb7e02efb8fa1	the neighborhood effects of foreclosure	neighborhood effect;hedonic price;errors;erreur;spatial dependence;qualite;prix;property values;modelo;it value;quality;empirical model;hedonic model;house prices;modele;vente;sales;error;venta;foreclosures;price;models;calidad;precio;local public goods	Neighborhood quality is an important attribute of housing yet its value is rarely known to researchers. We argue that changes in nearby foreclosures reveal changes in neighborhood quality. Thus estimates of the hedonic price of nearby foreclosures provide a glimpse of values that people hold for local neighborhood quality. The empirical models include controls for both spatial dependence in housing prices and in the errors. The estimates indicate that nearby foreclosures produce externalities that are capitalized into home prices-an additional foreclosure within 250 feet of a sale negatively impacts selling price by approximately $1,666, ceteris paribus. 1 We wish to thank Nathan Berg, Magnus Lofstrom and two anonymous reviewers for helpful comments.	berg connector;hedonic regression	Tammy Leonard;James C. Murdoch	2009	Journal of Geographical Systems	10.1007/s10109-009-0088-6	spatial dependence;mathematics;empirical modelling;statistics	HCI	-2.589790603581219	-9.854470246622633	48613
0a5909dcfa84d303eb4b98306bf81cf49ef843af	strategic multiway cut and multicut games	network formation games;approximate nash equilibrium;multiway cut;multi cut;price of stability	We consider cut games where players want to cut themselves off from different parts of a network. These games arise when players want to secure themselves from areas of potential infection. For the game-theoretic version of Multiway Cut, we prove that the price of stability is 1, i.e., there exists a Nash equilibrium as good as the centralized optimum. For the game-theoretic version of Multicut, we show that there exists a 2-approximate equilibrium as good as the centralized optimum. We also give poly-time algorithms for finding exact and approximate equilibria in these games.	approximation algorithm;centralized computing;game theory;nash equilibrium;price of stability	Elliot Anshelevich;Bugra Caskurlu;Ameya Hate	2011	Theory of Computing Systems	10.1007/s00224-011-9380-1	price of stability;mathematical optimization;maximum cut;combinatorics;mathematics;mathematical economics	ECom	-3.372381481993921	0.7630232994405659	48644
4a454281c74bdd471f23c65c154070073d17e6ea	an improved algorithm for computing approximate equilibria in weighted congestion games		We present a polynomial-time algorithm for computing dd+o(d)-approximate (pure) Nash equilibria in weighted congestion games with polynomial cost functions of degree at most d. This is an exponential improvement of the approximation factor with respect to the previously best algorithm. An appealing additional feature of our algorithm is that it uses only best-improvement steps in the actual game, as opposed to earlier approaches that first had to transform the game itself. Our algorithm is an adaptation of the seminal algorithm by Caragiannis et al. [7], but we utilize an approximate potential function directly on the original game instead of an exact one on a modified game. A critical component of our analysis, which is of independent interest, is the derivation of a novel bound of [d/W (d/ρ)]d+1 for the Price of Anarchy (PoA) of ρ-approximate equilibria in weighted congestion games, where W is the Lambert-W function. More specifically, we show that this PoA is exactly equal to Φd+1 d,ρ , where Φd,ρ is the unique positive solution of the equation ρ(x+1) = xd+1. Our upper bound is derived via a smoothness-like argument, and thus holds even for mixed Nash and correlated equilibria, while our lower bound is simple enough to apply even to singleton congestion games.	anarchy;approximation algorithm;nash equilibrium;network congestion;polynomial;potential method;time complexity	Yiannis Giannakopoulos;Georgy Noarov;Andreas S. Schulz	2018	CoRR			ECom	-3.6531018157078607	0.6825527844124563	48675
1a203d5b283c55b122714d0081afd2fce8a13d64	operational supply chain planning method for integrating spare parts supply chains and intelligent maintenance systems		A lack of spare parts and ineffective maintenance lead to low service levels and high production costs. Intelligent maintenance systems (IMS) have been intensively considered for supporting a better performance of maintenance service. For achieving high supply chain performance, it is also necessary that the information provided by IMS is integrated into the operational planning of the spare parts supply chain. Thus, this paper proposes a procedure for the integration of the spare parts supply chain operational decision level and the IMS. A framework comprising a heuristic approach along with a simulation model and a mathematical model is proposed.		Eduardo Israel;Enzo Morosini Frazzon;Ann-Kristin Cordes;Bernd Hellingrath;Andre Lopes	2014		10.1007/978-3-319-23512-7_44	supply chain risk management;supply chain management;service management;systems engineering;operations management;spare part;materials management	Robotics	9.43811304808194	0.778868997903455	48714
76106b9a5b9df937463fe8a3d2de5c03720fe8ee	untangling uncertainty with common random numbers: a simulation study		Cost-effectiveness analysis microsimulation for low- and middle-income countries can guide decision makers in allocating limited health budgets. But in order to compare alternative options, estimates of cost and effect must account for a high level of uncertainty in input parameters (parameter uncertainty) and also include an appropriate amount of stochastic uncertainty. It can be a challenge to incorporate the stochastic uncertainty appropriately, particularly when there is a lot of parameter uncertainty, due to large variance in the quantities of interest (such as incremental cost and health of an intervention scenario as compared to a baseline scenario). We investigated the utility of the common-random-numbers approach to variance reduction in simulation and found it very useful. We found that without variance reduction our intervention erroneously appeared unacceptable at any threshold, but with variance reduced using common random numbers it was cost effective.	simulation	Abraham D. Flaxman;Alec W. Deason;Andrew J. Dolgert;John Everett Mumford;Reed J. D. Sorensen;Erika Eldrenkamp;Theo Vos;Kyle Foreman;Ali H. Mokdad;Marcia R. Weaver	2017			variance reduction;econometrics;microsimulation;uncertainty analysis;marginal cost;sensitivity analysis;economics	Logic	5.868207376943656	-5.54601856615138	48962
d8c33aaa56614f2850d929fae941603364c6d645	dynamic investment strategies with demand-side and cost-side risks	analisis numerico;matematicas aplicadas;mathematiques appliquees;estrategia optima;industrie;cost reduction;market structure and investment policies;market structure;analyse numerique;investment strategies;optimal strategy;industry;numerical analysis;stochastic demand;real option;demand side and cost side risks;systematic risk;dynamic investment strategies;optimal investment;applied mathematics;firm value;strategie optimale;real options and firm value	Investments in cost reductions are critical for the long run success of companies that operate in dynamic and stochastic market environments. This paper studies optimal investment in cost reductions as a real option under the assumption that a single firm faces two different sources of risk, stochastic demand and input prices. We derive optimal investment strategies for a monopoly as well as a firm in a perfectly competitive market and show that in case of high marginal costs, cost reductions take place earlier in competitive than in monopoly markets. While the existence of an option to invest in cost reductions increases firm value it also increases a firm’s systematic risk. Risk can be smaller in a monopolistic than in a competitive industry.	marginal model;monopoly;reduced cost	Engelbert J. Dockner;Andrea Gaunersdorfer	2010	Applied Mathematics and Computation	10.1016/j.amc.2010.04.065	investment strategy;numerical analysis;systematic risk;market structure;enterprise value	ML	1.4250684421907491	-4.429671981593851	49149
d65cdfb66cdcf32652febf54b3637a7ef860c82e	capital rationing problems under uncertainty and risk	risk management;multi dimensional;risk measure;stochastic programming;branch and bound;capital rationing	Capital rationing is a major problem in managerial decision making. The classical mathematical formulation of the problem relies on a multi-dimensional knapsack model with known input parameters. Since capital rationing is carried out in conditions where uncertainty is the rule rather than the exception, the hypothesis of deterministic data limits the applicability of deterministic formulations in real settings. This paper proposes a stochastic version of the capital rationing problem which explicitly accounts for uncertainty. In particular, a mathematical formulation is provided in the framework of stochastic programming with joint probabilistic constraints and a novel solution approach is proposed. The basic model is also extended to include specific risk measures. Preliminary computational results are presented and discussed.		Patrizia Beraldi;Maria Elena Bruni;Antonio Violi	2012	Comp. Opt. and Appl.	10.1007/s10589-010-9390-y	stochastic programming;mathematical optimization;actuarial science;risk management;mathematics;branch and bound	Robotics	4.938347005527958	-4.72654345036034	49150
7f30f66c0c58af3c28a1302a297562777dc24c0f	flow-time estimation by synergistically modeling real and simulation data		The ability to quote a competitive and reliable lead time for a new order is a key competitive advantage for manufacturers and plays a significant role in customer acquisition and satisfaction. Quoting a precise and reliable lead time requires a good prediction for the flow time of a new order. This research focuses on quantifying the dependence of the flow time upon observed job shop status variables, the size of a new order, and the arrival rate of future orders. An iterative fitting procedure based on stochastic kriging with qualitative factors, is developed to synergistically model simulation and real manufacturing data, for the prediction of a new order's flow time.	iterative method;kriging;queueing theory;simulation;synergy	Hoda Sabeti;Feng Yang	2017	2017 Winter Simulation Conference (WSC)	10.1109/WSC.2017.8248041	competitive advantage;simulation;computer science;lead time;data modeling;job shop;real-time computing;kriging;server	Robotics	0.9384870815472625	-7.336640368336432	49226
5083b0cca5fcb3b02b7a96a47de197915f91e8ed	risk-aware revenue maximization in display advertising	pricing experiment;instant messaging;price adjustment;display advertising;web pages;market share;audio video;business model;revenue maximization;world wide web;market segmentation;lagrangian relaxation	Display advertising is the graphical advertising on the World Wide Web (WWW) that appears next to content on web pages, instant messaging (IM) applications, email, etc. Over the past decade, display ads have evolved from simple banner and pop-up ads to include various combinations of text, images, audio, video, and animations. As a market segment, display continues to show substantial growth potential, as evidenced by companies such as Microsoft, Yahoo, and Google actively vying for market share. As a sales process, display ads are typically sold in packages, the result of negotiations between sales and advertising agents. A key component to any successful business model in display advertising is sound pricing. Main objectives for on-line publishers (e.g. Amazon, YouTube, CNN) are maximizing revenue while managing their available inventory appropriately, and pricing must reflect these considerations.  This paper addresses the problem of maximizing revenue by adjusting prices of display inventory. We cast this as an inventory allocation problem. Our formal objective (a) maximizes revenue using (b) iterative price adjustments in the direction of the gradient of an appropriately constructed Lagrangian relaxation. We show that our optimization approach drives the revenue towards local maximum under mild conditions on the properties of the (unknown) demand curve.  The major unknown for optimizing revenue in display environment is how the demand for display ads changes to prices, the classical demand curve. This we address directly, by way of a factorial pricing experiment. This enables us to estimate the gradient of the revenue function with respect to inventory prices. Overall, the result is a principled, risk-aware, and empirically efficient methodology.  This paper is based on research undertaken on behalf of one of Google's clients.	design of experiments;display advertising;elasticity (cloud computing);email;emoticon;expectation–maximization algorithm;experiment;gradient;graphical user interface;instant messaging;iterative method;lagrangian relaxation;linear programming relaxation;mathematical optimization;maxima and minima;norm (social);online and offline;pop-up ad;price point;www;web page;world wide web	Ana Radovanovic;William D. Heavlin	2012		10.1145/2187836.2187850	business model;market share;lagrangian relaxation;revenue model;computer science;web page;database;world wide web;market segmentation	Web+IR	-0.8832512437700064	-2.3787006235450114	49285
2bc75ee25e2ed6f952b2acfec76368cbcf01c5e4	resource reservation with a market-based protocol: what prices to expect?	market power;electronic services;resource reservation;resource pricing;profitability;bilateral protocols;bilateral trade	A reservation protocol and pricing model is proposed for the allocation of electronic services, such as computing and communication resources. Whereas centralised allocation mechanisms are frequently analysed, and therefore better understood, we focus on a decentralised, bilateral market, employing a new protocol to enable application agents to request price quotes and to book resource capacity from resource providers. In contrast to existing protocols we allow for competition between providers. Contracts and prices are confidential; therefore, resource providers can only collect information from their own bilateral trades and from requests for price quotes. They determine the optimal price with a supply function that is extended to continuous trading by updating the optimal price quotes with new information. We implement the protocol in a simulation, show that the equilibrium prices are above competitive levels and demonstrate that simple deviations from the pricing model are not profitable.		Jörg H. Lepler;Karsten Neuhoff	2003	Computer Communications	10.1016/S0140-3664(03)00029-X	profitability index	Networks	-2.9578561789767917	-5.645687474225714	49306
e12707f4cadb5d0b04706bbce6c35a6f6b8856de	the base stock/base backlog control policy for a make-to-stock system with impatient customers	stock control;production en flux pousse;gestion integrada;fila espera m m 1;safety stock;file attente;modelizacion;in process inventory;rentabilidad;gestion integree;deposito en curso;control optimo;produccion flujo empujado;customer impatience;nuevo abastecimiento;queueing analysis admission control customer impatience production inventory control;control systems costs marketing and sales inventory management delay production systems queueing analysis raw materials safety inventory control;tiempo busqueda;materia prima;raw materials;customer relationship management;gestion production;m m 1 queueing model base stock base backlog control policy make to stock system impatient customers single stage production system inventory;competitividad;proceso llegada;matiere premiere;preparacion pedido;queueing theory;production inventory control;stock securite;realimentation;production system;impatient customers;systeme production;queue;integrated management;date echeance;produccion pequena serie;sistema complejo;stock control customer relationship management production control queueing theory;temps recherche;small series production;sistema produccion;refeeding;arrival process;production management;inventory;administracion deposito;processus arrivee;optimal control;modelisation;profit;economic order quantity;rejection;production control;systeme complexe;beneficio;complex system;base stock;commande optimale;gestion produccion;single stage production system;m m 1 queue;stock minimo;due date;gestion stock;realimentacion;competitiveness;base stock base backlog control policy;benefice;production systems;coaccion capacidad;fecha vencimiento;rentabilite;quantite economique a commander;vente;sales;contrainte capacite;profitability;file attente m m 1;stock minimal;preparation commande;markov processes;encours de fabrication;cantidad economica pedida;stock seguridad;replenishment;venta;capacity constraint;order picking;stockout;competitivite;search time;rechazo;modeling;make to stock	We study a single-stage production system that produces one product type. The system employs a base stock policy to maintain an inventory of finished items and cope with random demand. During stockout periods, the system incurs three types of potential customer loss: (a) balking, i.e., arriving customers may be unwilling to place orders and leave immediately; (b) rejection, i.e., the system rejects new customer orders if its backlog has reached a certain limit, called the base backlog; (c) reneging, i.e., outstanding customers waiting in queue may become impatient and withdraw their orders. The objective is to determine the base stock and base backlog that maximize the mean profit rate of the system. This quantity is estimated analytically using a finite capacity M/M/1 queueing model, in which the arrival rate is a decreasing but otherwise arbitrary function of the backlog and customer reneging times have an arbitrary but known distribution. Certain properties are established which ensure that the optimal control parameters can be determined in finite time by exhaustive search. The model is then extended to take into account a fixed order quantity policy for replenishing raw material. Numerical results show that managing inventories and backlog jointly achieves higher profit than other control policies.	algorithm;algorithmic efficiency;brute-force search;distributed computing;emoticon;inventory;inventory control;multistage amplifier;numerical analysis;numerical method;optimal control;product type;production system (computer science);queueing theory;rejection sampling	Angelos A. Economopoulos;Vassilis S. Kouikoglou;Evangelos Grigoroudis	2011	IEEE Transactions on Automation Science and Engineering	10.1109/TASE.2010.2052802	customer relationship management;complex systems;computer science;marketing;production system;operations research	Metrics	5.003431722205499	-2.659629505240129	49308
35b3d4f3cff6b3158aecaa3b0eb674e461fe0b74	on polynomial-time preference elicitation with value queries	electronic commerce;learning;preference elicitation;polynomial time;network flow;combinatorial auctions;computational learning theory;learning preference;combinatorial auction	Preference elicitation --- the process of asking queries to determine parties' preferences --- is a key part of many problems in electronic commerce. For example, a shopping agent needs to know a user's preferences in order to correctly act on her behalf, and preference elicitation can help an auctioneer in a combinatorial auction determine how to best allocate a given set of items to a given set of bidders. Unfortunately, in the worst case, preference elicitation can require an exponential number of queries even to determine an approximately optimal allocation. In this paper we study natural special cases of preferences for which elicitation can be done in polynomial time via value queries. The cases we consider all have the property that the preferences (or approximations to them) can be described in a polynomial number of bits, but the issue here is whether they can be elicited using the natural (limited) language of value queries. We make a connection to computational learning theory where the similar problem of exact learning with membership queries has a long history. In particular, we consider preferences that can be written as read-once formulas over a set of gates motivated by a shopping application, as well as a class of preferences we call Toolbox DNF, motivated by a type of combinatorial auction. We show that in each case, preference elicitation can be done in polynomial time. We also consider the computational problem of allocating items given the parties' preferences, and show that in certain cases it can be done in polynomial time and in other cases it is NP-complete. Given two bidders with Toolbox-DNF preferences, we show that allocation can be solved via network flow. If parties have read-once formula preferences, then allocation is NP-hard even with just two bidders, but if one of the two parties is additive (e.g., a shopping agent purchasing items individually and then bundling them to give to the user), the allocation problem is solvable in polynomial time.	approximation;best, worst and average case;computation;computational learning theory;computational problem;decision problem;e-commerce;flow network;mathematical optimization;np-completeness;polynomial;preference elicitation;purchasing;time complexity;utility functions on indivisible goods	Martin Zinkevich;Avrim Blum;Tuomas Sandholm	2003		10.1145/779928.779949	preference learning;mathematical optimization;combinatorial auction;computer science;machine learning;data mining;mathematics;microeconomics;computational learning theory;welfare economics	ECom	-2.3270229228601185	-0.8576842600974893	49570
30c7cb306f5aa52da73b7697316c18df5e0a942d	on competitive search games for multiple vehicles	game theory;constrained nash equilibrium competitive search games multiple vehicles probability density function nash strategies game reduction auxiliary nash game computation algorithms;games vehicles nash equilibrium heuristic algorithms clocks probability density function random variables;vehicles;vehicles game theory	We investigate the competitive search game where a group of vehicles compete to locate the target on a ring in ℝ2 where the probability density function of the target is known a priori. In order to compute Nash strategies for vehicles, we first perform a game reduction and determine an auxiliary Nash game which, on one hand, has a much smaller dimension, and on the other hand, is equivalent to the competitive search game. For the auxiliary Nash game, we first provide a counter-example where Nash equilibrium does not exist. Then we study computation algorithms to seek a class of constrained Nash equilibrium under certain sufficient conditions.	algorithm;computation;game theory;nash equilibrium;search game	Minghui Zhu;Emilio Frazzoli	2012	2012 IEEE 51st IEEE Conference on Decision and Control (CDC)	10.1109/CDC.2012.6426371	price of stability;implementation theory;game theory;epsilon-equilibrium;minimax;mathematical optimization;simulation;best response;subgame;non-credible threat;folk theorem;repeated game;mathematics;correlated equilibrium;chicken;normal-form game;zero-sum game;mathematical economics;subgame perfect equilibrium;matching pennies;equilibrium selection;symmetric game;solution concept;nash equilibrium	Vision	-4.005079650053395	-1.860328763626698	49590
613a5f54a11935c60505f3ab63dae51e6e9edb1b	a review of competitive facility location in the plane		In this paper, we review competitive location models. Retail facilities operate in a competitive environment with an objective of profit and market share maximization. These facilities are different from each other in their overall attractiveness to consumers. The basic problem is the optimal location of one or more new facilities in a market where competition already exists or will exist in the future. Extensions to the models include an analysis of the optimal allocation of a budget among new facilities and their best locations, modeling location under conditions of uncertainty and future competition, incorporating the concept of a threshold in competitive location, modeling lost demand, and minimizing cannibalization.	competitive programming;entropy maximization;facility location problem;location-based service;mathematical optimization	Tammy Drezner	2014	Logistics Research	10.1007/s12159-014-0114-z	marketing;operations management;microeconomics;business;commerce	AI	0.7393710074889674	-5.177915171737349	49884
5d0e1e3a64feb542ad8b66d017b2b9080ff16e9d	optimal residential demand response in distribution networks	home appliances schedules load modeling power systems aggregates electricity simulation;electricity shedding optimal residential demand response distribution networks electricity usage supply and demand supply demand matching electricity consumption residential dr parameters power distribution network optimal power flow load service entity optimal demand schedule ieee test distribution system;supply and demand demand side management load flow load shedding power consumption power distribution economics	Demand response (DR) enables customers to adjust their electricity usage to balance supply and demand. Most previous works on DR consider the supply-demand matching in an abstract way without taking into account the underlying power distribution network and the associated power flow and system operational constraints. As a result, the schemes proposed by those works may end up with electricity consumption/shedding decisions that violate those constraints and thus are not feasible. In this paper, we study residential DR with consideration of the power distribution network and the associated constraints. We formulate residential DR as an optimal power flow problem and propose a distributed scheme where the load service entity and the households interactively communicate to compute an optimal demand schedule. To complement our theoretical results, we also simulate an IEEE test distribution system. The simulation results demonstrate two interesting effects of DR. One is the location effect, meaning that the households far away from the feeder tend to reduce more demands in DR. The other is the rebound effect, meaning that DR may create a new peak after the DR event ends if the DR parameters are not chosen carefully. The two effects suggest certain rules we should follow when designing a DR program.	algorithm;converge;convex optimization;flow network;goto;heuristic;interactivity;iteration;kerrison predictor;mathematical optimization;maxima and minima;optimization problem;predictor–corrector method;randomness;simulation;strong duality;uninterruptible power supply	Wenbo Shi;Na Li;Xiaorong Xie;Chi-Cheng Peter Chu;Rajit Gadh	2014	IEEE Journal on Selected Areas in Communications	10.1109/JSAC.2014.2332131	peak demand	Metrics	3.6830254609555735	3.870896507573766	49930
1a0221df58525810cbee150958153c101ba5ff53	using simulation optimization as a decision support tool for supply chain coordination with contracts	contracts;decision support systems;retail data processing;supply chain management;buyback contract;channel coordination;competitive price;decision support tool;effort dependent demand;linear demand model;market demand;revenue sharing;simulation optimization;stochastic demand;supply chain coordination	This paper studies the issue of channel coordination for a supply chain consisting of one supplier and two retailers, facing stochastic demand that is sensitive to both sales effort and retail price. We develop a decision support tool using simulation optimization for supply chain coordination with revenue sharing or buyback contract. In order to represent a real competitive price and effort dependent demand, a new linear demand model is proposed. Due to the stochastic nature of the market demand and the interaction between decision variables, simulation could help us modeling and analyzing the problem. Simulation optimization is then used to find the optimum or near optimum set of decision variables in the cases of centralized supply chain and coordinated supply chain with contracts.	centralized computing;decision support system;decision theory;mathematical optimization;optimization problem;revenue sharing;simulation;stochastic process	Hamidreza Eskandari;Mohamad Darayi;Christopher D. Geiger	2010	Proceedings of the 2010 Winter Simulation Conference		stochastic process;demand chain;supply chain management;service management;supply chain	AI	0.8046234531409905	-5.377490757280823	49936
d60deb4ddc893a68cf0d5c33358c6cf240f88e32	systemic risk in financial systems	limited liability;clearing systems;default;fixed point;financial system;systemic risk;credit risk;comparative statics;regularity condition	"""We consider default by firms that are part of a single clearing mechanism. The obligations of all firms within the system are determined simultaneously in a fashion consistent with the priority of debt claims and the limited liability of equity. We first show, via a fixed-point argument, that there always exists a """"clearing payment vector"""" that clears the obligations of the members of the clearing system; under mild regularity conditions, this clearing vector is unique. Next, we develop an algorithm that both clears the financial system in a computationally efficient fashion and provides information on the systemic risk faced by the individual system firms. Finally, we produce qualitative comparative statics for financial systems. These comparative statics imply that, in contrast to single-firm results, even unsystematic, nondissipative shocks to the system will lower the total value of the system and may lower the value of the equity of some of the individual system firms."""		Larry Eisenberg;Thomas H. Noe	2001	Management Science	10.1287/mnsc.47.2.236.9835	financial economics;limited liability;actuarial science;economics;credit risk;comparative statics;finance;fixed point;microeconomics;default;systemic risk	Logic	-3.287738987606095	-4.890343894003039	50079
1cfc3c1d3a3504aa93398156dd21bd4be52ed2ff	public evacuation decisions and hurricane track uncertainty	disaster;paper;person evacuation;localization;analisis decision;false negative;false alarm rate;localizacion;natural systems;probabilistic approach;lead time;decision analysis;imperfect information;systeme incertain;planificacion;localisation;geographic variation;risk;enfoque probabilista;approche probabiliste;sinistre;public evacuations;informacion imperfecta;planning;tiempo puesta en marcha;stochastic model;evacuacion personas;planification;disaster planning;sistema incierto;taux fausse alarme;porcentaje falsa alarma;modelo estocastico;temps mise en oeuvre;uncertain system;analyse decision;modele stochastique;evacuation personne;siniestro;information imparfaite	Public officials with the authority to order hurricane evacuations face a difficult trade-off between risks to life and costly false alarms. Evacuation decisions must be made on the basis of imperfect information, in the form of forecasts. The quality of these decisions can be improved if they are also informed by measures of uncertainty about the forecast, including estimates of the value of waiting for updated, more accurate, forecasts. Using a stochastic model of storm motion derived from historic tracks, this paper explores the relationship between lead time and track uncertainty for Atlantic hurricanes and the implications of this relationship for evacuation decisions. Typical evacuation clearance times and track uncertainty imply that public officials who require no more than a 10% probability of failing to evacuate before a striking hurricane (a false negative) must accept that at least 76%---and for some locations over 90%---of evacuations will be false alarms. Reducing decision lead times from 72 to 48 hours for major population centers could save an average of hundreds of millions of dollars in evacuation costs annually, with substantial geographic variation in savings.		Eva Regnier	2008	Management Science	10.1287/mnsc.1070.0764	planning;disaster;simulation;internationalization and localization;economics;decision analysis;stochastic modelling;perfect information;finance;risk;constant false alarm rate;management;operations research	Robotics	5.720099663606646	-4.203839748943626	50129
a0561773be144952a1e4fc00daa3f44e01f1a77c	reconfiguration of standards data for improved production planning	standards;production control;scheduling;production planning	Increased environmental problems in the form of global warming have reshaped human thinking about the prospects of human survival on this planet. The 1996 IPCC [1] study has confirmed that increased GHG concentrations in the atmosphere will substantially increase global temperatures. South East Asia’s (SEA) particular vulnerabilities to the impacts of climate change need to be explored. The primary production levels, tourism industry, agricultural productivity, energy sector and urban water supply systems are sensitive to potential climate changes. To address these issues and options, the study undertakes an integrated climate change and economic growth modelling study with a comprehensive coverage of the SEA region. The model is based on the work done by Nordhaus [2] (the DICE model) and Islam [3] (the Asia-DICE model), and named the South East Asia Dynamic Integrated Climate and the Economy (SEADICE) model. The results address issues related to global environmental change and sustainable development for SEA. The results suggest the following: (1) GHG abatement costs are justifiable for the region; (2) optimal abatement control rates are significantly higher compared to other models; and (3) this suggests that regional or country specific abatement policies should be implemented in the region.	dvd region code;uninterruptible power supply;vulnerability (computing)	Gary P. Moynihan;Dana S. Gurley;Paul S. Ray;Thomas L. Albright	2002	IJMTM	10.1504/IJMTM.2002.002521	reliability engineering;real-time computing;computer science;engineering;operations management;scheduling	AI	8.258937904248857	-6.101463926044946	50430
898b826b4eeee50f9d20197c50492b53675c70a6	prices, promotions, and channel profitability: was the conventional wisdom mistaken?	rentabilidad;bilateral;trademark;gestion entreprise;marca comercial;marque commerciale;game theory;methode empirique;remise;fournisseur;economic sciences;pricing;metodo empirico;comercializacion;empirical method;firm management;teoria juego;supplier;monopolio;theorie jeu;fijacion precios;espace parametre;detaillant;monopole;commercialisation;marketing channel;empirical evidence;profit;ciencias economicas;instant rebates;beneficio;rebate;marketing;marketing economic power game theory marketing channel instant rebates;espacio par metro;parameter space;benefice;coordinacion;administracion empresa;rentabilite;profitability;sciences economiques;rebaja;economic power;retailers;fixation prix;coordination;proveedor	Because of the lack of empirical evidence supporting the shift of economic power from manufacturers to retailers, it has been claimed that the conventional wisdom that retailers benefit more from the use of consumer promotions was mistaken. This paper assesses this claim and examines how two different pricing approaches during manufacturers' instant price promotions targeted at consumers impact on channel profits in a bilateral monopoly. We found that manufacturers should only offer rebates when they keep their prior-to-promotion wholesale prices unchanged. Consistent with the conventional wisdom, retailers do indeed take the lion's share of the promotion incremental profits. Surprisingly, however, we found that in the largest part of the parameter space, manufacturers still earn more total channel profits than retailers over time. The theoretical and managerial implications of these findings are discussed.		Guiomar Martín-Herrán;Simon Pierre Sigué	2011	European Journal of Operational Research	10.1016/j.ejor.2010.12.022	magnetic monopole;pricing;game theory;profit;empirical evidence;economics;marketing;operations management;economic power;economy;parameter space;empirical research;profitability index	Crypto	-3.78446473216265	-8.55157506965128	50467
962515713828f24ba6623cd6b6a001311c77fe38	nash equilibria in unconstrained stochastic games of resource extraction	nash equilibrium;capital accumulation;capital accumulation problems;nash equilibria;nonzero sum stochastic games;stochastic games;resource extraction games	A class of nonzero-sum symmetric stochastic games of capital accumulation/resource extraction is considered. It is shown that Nash equilibria in the games with some natural constraints are also equilibrium solutions in unconstrained games and dominate in the Pareto sense an equilibrium leading to exhausting the entire resource stock in the first period of the game. One example is given to ilustrate this situation.	nash equilibrium;pareto efficiency;tree accumulation	Lukasz Balbus;Andrzej S. Nowak	2008	IGTR	10.1142/S0219198908001753	price of stability;markov perfect equilibrium;game theory;epsilon-equilibrium;mathematical optimization;best response;trembling hand perfect equilibrium;coordination game;economics;repeated game;correlated equilibrium;microeconomics;risk dominance;mathematical economics;equilibrium selection;nash equilibrium	AI	-3.9397845989996942	-2.2097842607752565	50472
ed8793cd1b591c3fc8150912a1e8e2638087206e	comparative analysis of standby systems with unreliable server and switching failure	availability;switching failure;general repair;unreliable server	The purpose of this paper is to study the steady-state availability of a repairable system with standby switching failure. The repairable system configuration includes the primary and standby components, where an unreliable server is responsible to repair or monitor the failed ones. The time-to-failure and time-to-repair of the components follow exponential and general distribution, respectively. The server subjects to active breakdown when it is repairing. The time-to-breakdown of the server is also assumed to be exponentially distributed. When the primary components fail, the standby components replace the primary components successfully with probability 1−q. The repair time of the failed components and the repair time of the breakdown server are generally distributed. Further, we frame a practical model with three different repairable system configurations. We use supplementary variable method and integro-differential equations to obtain the steady-state availability of these three different repairable system configurations. Finally, we compare the cost/benefit ratio among the three configurations given the distribution parameters, and to the cost of the primary and standby components.	server (computing)	Ching-Chang Kuo;Jau-Chuan Ke	2016	Rel. Eng. & Sys. Safety	10.1016/j.ress.2015.09.001	reliability engineering;availability;real-time computing;engineering	SE	6.985191637114043	-0.8436675355018161	50506
b4848a198eacffa44bbe2769b2a0728085561d35	consistent price systems under model uncertainty	article accepte pour publication ou publie;91b25;93e20;consistent pr ice system;60g42;model uncertainty;transaction costs;consistent price system;arbitrage of the second kind;49l20;arbitrage of second kind	We develop a version of the fundamental theorem of asset pricing for discrete-time markets with proportional transaction costs and model uncertainty. A robust notion of no-arbitrage of the second kind is defined and shown to be equivalent to the existence of a collection of strictly consistent price systems.	price systems	Bruno Bouchard;Marcel Nutz	2016	Finance and Stochastics	10.1007/s00780-015-0286-7	financial economics;transaction cost;arbitrage pricing theory;economics;finance;mathematical economics;welfare economics;arbitrage	DB	0.9786372615192469	-2.435786215309956	50759
0fccc0b4250602bf2532daa0f6c0682e26561f13	bilevel programming approaches to the computation of optimistic and pessimistic single-leader-multi-follower equilibria		We study the problem of computing an equilibrium in leader-follower games with a single leader and multiple followers where, after the leader’s commitment to a mixed strategy, the followers play simultaneously in a noncooperative way, reaching a Nash equilibrium. We tackle the problem from a bilevel programming perspective. Since, given the leader’s strategy, the followers’ subgame may admit multiple Nash equilibria, we consider the cases where the followers play either the best (optimistic) or the worst (pessimistic) Nash equilibrium in terms of the leader’s utility. For the optimistic case, we propose three formulations which cast the problem into a single level mixedinteger nonconvex program. For the pessimistic case, which, as we show, may admit a supremum but not a maximum, we develop an ad hoc branch-and-bound algorithm. Computational results are reported and illustrated. 1998 ACM Subject Classification G.1.6 [Optimization] Nonlinear programming	algorithm;branch and bound;computation;hoc (programming language);mathematical optimization;nash equilibrium;nonlinear programming	Nicola Basilico;Stefano Coniglio;Nicola Gatti;Alberto Marchesi	2017		10.4230/LIPIcs.SEA.2017.31	oceanography;mathematical optimization;theoretical computer science;bilevel optimization;computation;computer science	AI	-3.777030709302256	1.5837895401569646	50900
055e8849f2e4d1d9da42ad0fcd84ba0d3a4fe8b9	multicommodity production planning: qualitative analysis and applications	substitutes and complements;qualitative analysis;convex multicommodity flows;monotonicity;dynamic production planning problem	We develop a qualitative analysis theory for the convex-cost dynamic multicommodity production planning problem, which can be used, without performing any computational work, to provide invaluable insight to managers when faced with the task of deciding how to respond to changes in problem environment. We first formulate the problem as a multicommodity flow problem with parameters associated with each arc–commodity pair. We then reduce the problem to an equivalent single-commodity flow problem and develop a complete characterization of conformality among production, sales, and inventory activities in various instances of the problem. By combining the conformality characterizations with the monotonicity theory of Granot and Veinott [Granot F, Veinott AF Jr (1985) Substitutes, complements and ripples in network flow. Math. Oper. Res. 10:471–497] for single-commodity problems, we study the effects of changes in problem environment on optimal production, sales, and inventory schedules in the multicommodity pr...		Iara Ciurria-Infosino;Daniel Granot;Frieda Granot;Arthur F. Veinott	2015	Manufacturing & Service Operations Management	10.1287/msom.2015.0549	mathematical optimization;monotonic function;qualitative research;operations management;mathematics;mathematical economics	Robotics	2.216293176117581	-1.0220096721723795	50907
c64fe2d6a9d9bb3c25ec39c6051611a5df0b89c3	survivability and business continuity management system according to bs 25999	business continuity plan bcp;performance measure;disaster recovery;key performance indicator;disaster recovery plans business continuity management system bs 25999 business continuity plans;iso standards;disaster recovery plans;business continuity management system;data mining;companies;business continuity;bs 25999;book reviews;disaster recovery dr;disaster recovery dr bs 25999 bcms business continuity plan bcp;economics;business continuity iso standards disaster management companies information security conference management technology management system buses measurement risk analysis;extreme event;bcms;business continuity management;business continuity plans	In this paper, a new model is presented for evaluating the performance of a Business Continuity Management System according to BS 25999. This model is able to calculate the survivability \emph{ex-ante} if the key performance indicator for the effectiveness exists. Performance is based fundamentally on the system's Business Continuity Plans and Disaster Recovery Plans. Typically, the performance of these plans is evaluated by a number of specific exercises at various intervals and, in many cases, with a variety of targets. Furthermore, these specific exercises are rerun after a longer period ($\ge $ a year) and then often only partially. If a company is interested in taking performance measurements over a shorter period, obstacles and financial restrictions are often encountered. Furthermore, it is difficult for companies to give an \emph{ex-ante} statement of their survival in the case of a disaster.Two key performance indicators are presented that allow the performance of a Business Continuity Management System to be evaluated according to BS 25999. Using these key performance indicators, the probability of survival can be estimated before extreme events occur.	business continuity planning;disaster recovery;management system;rare events;scott continuity	Wolfgang Boehmer	2009	2009 Third International Conference on Emerging Security Information, Systems and Technologies	10.1109/SECURWARE.2009.29	computer science;knowledge management;performance indicator;computer security;disaster recovery	DB	4.445021223146789	-8.589121210830829	51122
c16d6dd1418834a9a8cd2b4dd392238ae7bc042a	tacit collusion games in pool-based electricity markets under transmission constraints		Harrington et al. [21] introduced a general framework for modeling tacit collusion in which producing firms collectively maximize the Nash bargaining objective function, subject to incentive compatibility constraints. This work extends that collusion model to the setting of a competitive pool-based electricity market operated by an independent system operator. The extension has two features. First, the locationally distinct markets in which firms compete are connected by transmission lines. Capacity limits of the transmission lines, together with the laws of physics that guide the flow of electricity, may alter firms’ strategic behavior. Second, in addition to electricity power producers, other market participants, including system operators and power marketers, play important roles in a competitive electricity market. The new players are included in the model in order to better represent real-world markets, and this inclusion will impact power producers’ strategic behavior as well. The resulting model is a mathematical program with equilibrium constraints (MPEC). Properties of the specific MPEC are discussed and numerical examples illustrating the impacts of transmission congestion in a collusive game are presented.	loss function;mathematical programming with equilibrium constraints;nash equilibrium;network congestion;numerical analysis;optimization problem;sysop;tacit programming;three utilities problem;transmission line	Andrew L. Liu;Benjamin F. Hobbs	2013	Math. Program.	10.1007/s10107-013-0693-5	electricity market;collusion;operator (computer programming);mathematical optimization;incentive compatibility;mathematics;tacit collusion;electric power transmission;microeconomics;bargaining problem;transmission (mechanics)	AI	-0.7136224860815247	-3.225901174649277	51169
3f145b1ec7e69da26e18e4c81e4faea8748f8764	seeing the forest and the trees: capacity planning for a large number of servers			the forest	Linwood Merritt	2004			capacity planning;water resource management;business;server	ML	2.7409230844291526	-8.730735551834979	51349
e94ea11d34513170cc78c00c25f3fb8e43d08003	restricted coherent risk measures and actuarial solvency		We prove a general dual representation form for restricted coherent risk measures, and we apply it to a minimization problem of the required solvency capital for an insurance company.	coherent	Christos E. Kountzakis	2012	ADS	10.1155/2012/350765	financial economics;actuarial science;economics;welfare economics;coherent risk measure	ML	0.539386241081602	-2.8410475448953876	51354
7a3f8563d470e4a248b2d3d8a63a0d66608a650e	a queueing-game model for making decisions about order penetration point in supply chain in competitive environment	game theory;order penetration point opp;make to order mto;competitive environment;queueing system;matrix geometric method mgm;integrated operations marketing perspective;supply chain;mts mto queue;make to stock mts	This study is dedicated to Order Penetration Point OPP strategic decision making which is the boundary between Make-To-Order MTO and Make-To-Stock MTS policies. This paper considers two competing supply chains in which a manufacturer produces semi-finished items on a MTS basis for a retailer that will customize the items on a MTO basis. The two-echelon supply chain offers multi-product to a market comprised of homogenous customers who have different preferences and willingness to pay. The retailer wishes to determine the optimal OPP, the optimal semi-finished goods buffer size, and the price of the products. Moreover, the authors consider both integrated scenario shared capacity model and competition scenario Stackelberg queueing-game model in this paper. A matrix geometric method is utilized to evaluate various performance measures for this system and then, optimal solutions are obtained by enumeration techniques. The suggested queueing approach is based on a new perspective between the operation and marketing functions which captures the interactions between several factors including inventory level, price, OPP, and delivery lead time. Finally, parameter sensitivity analyses are carried out and the effect of demand on the profit function, the effect of prices ratio on completion rates ratio and buffer sizes ratio and the variations of profit function for different prices, completion percents, and buffer sizes are examined in both scenarios.		Ebrahim Teimoury;Mahdi Fathi	2013	IJSDS	10.4018/ijsds.2013100101	game theory;economics;marketing;operations management;supply chain;management;operations research;commerce	ECom	-0.1483851067693613	-5.911086700259665	51589
52268c5453c0239f5d9ba481a8a9ac8b3b76f216	a review of abc methodology for agricultural sector		This study examines recent advances in cost accounting methods with special reference to the application of Activity Based Costing methodology in primary sector. Large scale agricultural enterprises that depend heavily on capital investments require rational allocation of the available resources and efficient utilization of the existing production technology. The accurate and reliable computation of cost per unit of product is crucial for the evaluation of the economic performance of the enterprises and the investigation of the optimal allocation of the production factors in different activities. The concept of Activity Based Costing methodology, which is of great importance in the system of cost accounting, allows the allocation of indirect costs to specific activities and individual products, overcoming the drawbacks of the traditional method of cost accounting. A synopsis of the Activity Based Costing method is described, followed by a review of recent cost accounting applications to agricultural systems.	computation;mathematical optimization;newton's method;video synopsis	Georgia Koutouzidou;Athanasios Vazakidis;Alexandros Theodoridis;Christos Batzios	2015			finance;cost accounting;activity-based costing;agriculture;business;indirect costs;factors of production;primary sector of the economy	HCI	4.677895178050823	-7.580092772784017	51597
33e1d1daa1bc0fea5bcac2bb9d00166dab8b9261	network effects, market structure and industry performance	netzwerk;monotone comparative statics;network effects;marktmechanismus;equilibrium model;su permodularit;competition;grundlagenforschung;enterprise;industrie;effect;gleichgewichtsmodell;political economy;network effect;market structure;economic model;wirtschaft;oligopol;nonsmooth analysis;markt;supermodularity;market mechanism;management strategy;industry start up;industry;technological progress;industry viability;network externality;demand side externalities;okonomisches modell;unternehmen;cournot oligopoly;industriebetrieb;volkswirtschaftslehre;wettbewerb;economics;market;basic research;network goods;oligopoly;wirkung;network;industrial enterprise	This paper analyzes oligopolistic markets with network externalities. Exploiting a minimal complementarity structure on the model primitives that allows for pure network goods, we prove existence of non-trivial fulfilled-expectations equilibrium. We formalize the concept of industry viability, investigate its determinants, and show that it improves with more firms in the market and/or by technological progress. These results enlighten some well-known conclusions from case studies in the management strategy literature. We also characterize the effects of market structure on industry performance, which depart substantially from ordinary markets. The approach relies on lattice-theoretic methods, supplemented with basic insights from nonsmooth analysis. © 2011 Elsevier Inc. All rights reserved. JEL classification: C72; D43; L13; L14	complementarity theory;subderivative	Rabah Amir;Natalia Lazzati	2011	J. Economic Theory	10.1016/j.jet.2011.10.006	industrial organization;technological change;cournot competition;competition;economics;economic model;network effect;finance;macroeconomics;market structure;microeconomics;mathematical economics;market economy	AI	-3.1955942894532723	-3.8097004470627627	51709
6e4fb876fc552d6d2bbe2c5020b7defbebc4caf2	an existence result of a quasi-variational inequality associated to an equilibrium problem	variational and quasi variational inequality;quasi variational inequalities;utility function;exchange economy;equilibrium problem;mosco s convergence;variational approach;competitive equilibrium;walrasian equilibrium	In this paper we consider a Walrasian pure exchange economy with utility function which is a particular case of a general economic equilibrium problem, without production. We assume that each agent is endowed with at least of a commodity, his preferences are expressed by an utility function and it prevails a competitive behaviour: each agent regards the prices payed and received as independent of his own choices. The Walrasian equilibrium can be characterized as a solution to a quasi-variational inequality. By using this variational approach, our goal is to prove an existence result of equilibrium solutions.	social inequality;variational inequality;variational principle	Maria Bernadette Donato;Monica Milasi;Carmela Vitanza	2008	J. Global Optimization	10.1007/s10898-007-9199-0	mathematical optimization;variational inequality;general equilibrium theory;mathematical economics	Theory	-4.416309190589176	-2.273014799442587	51711
85ff723ad854bfabf4efa5edd214c738a75378fd	kraljicmatrix: an r package for implementing the kraljic matrix to strategically analyze a firm's purchasing portfolio		KraljicMatrix is an R package (R Core Team (2016)) that implements a quantified approach to the Kraljic Matrix (Kraljic (1983)) introduced by Montgomery et al. (Montgomery, Ogden, and Boehmke (2017)). It allows a firm to strategically analyze its purchasing portfolio with singleand multi-attribute value analysis to measure purchasing characteristics. In addition KraljicMatrix also provides useful functions to identify the preferred single utility slope based on subject matter expert inputs, assign and place purchases within the Kraljic Matrix, and perform sensitivity analysis.		Bradley C. Boehmke;Robert Montgomery;Jeffrey A. Ogden;Jason K. Freels	2017	J. Open Source Software	10.21105/joss.00170		AI	-0.547997279987061	-7.147775866353442	51846
b20b769f479731541108c2da73910405324b9f6d	a joint optimization strategy for scale-based product family positioning	product portfolio;joint optimization;product family positioning;scale based product family	With the development of modern technologies and global manufacturing, it becomes more difficult for companies to distinguish themselves from their competitors. In order to keep their competitive advantages, companies must properly position their product families by offering a right product portfolio to each target market. To evaluate competitive advantages for a scale-based product family, this paper takes product family competitive advantage (PFCA) as a measure metric which is consisted of customer choice probability, sales, and profit. Meanwhile, to keep lower manufacturing costs, a commonality index of scale-based product family is proposed based on product design technology parameters in a product family. A multi-objective joint optimization model that balances the competitive advantages and the commonality is proposed. Based on a case study of motor product family positioning, Pareto frontier solutions are generated by genetic algorithm, and the results show that the joint optimization model excels in supporting product family positioning.	genetic algorithm;mathematical optimization;pareto efficiency	Yangjian Ji;Tianyin Tang;Chunyang Yu;Guoning Qi	2014	Int. J. Comput. Intell. Syst.	10.1080/18756891.2014.947087	product design;new product development;product engineering	ML	0.5341491135877392	-8.139149070097158	52046
c8a014173ef514b4bcdfe97391b461622ad07f93	the reliability and economic analysis on system connection mode	reliability;pareto;connection mode	To improve the reliability of the system, the component can be used as parallel or redundant backup. Among them, the parallel connection mode is simple and the cost is low, but the reliability of increasing rate is small.The other one connection mode is complexity and cost is high, but the reliability is improved greatly.The actual system has many components, through the combination of the original component can produce a variety of ways of connection mode,its composition space is exponential. Every connection mode has its reliability and cost, they are a pair of contradictory goals,how to choose the best connection mode to make the reliability and economy to achieve better,in other words, how much of the number of components are choose for parallel and the number of it for redundant are the best choice?This find the optimal number of for parallel and redundant backups in the sense of pareto,and analysis the relation between optical connection mode and time.	backup;parallel computing;pareto efficiency;series and parallel circuits;time complexity	Chao-Fan Xie;Lin Xu;Lu-Xiong Xu	2016		10.1145/2955129.2955192	reliability engineering;mathematical optimization;real-time computing;mathematics	HPC	6.14891582572792	1.087587828285221	52056
03289e92ab3c3ac02a1f48469085da30433d9988	a stochastic model on the profitability of loyalty programs	loyalty program;customer satisfaction;marketing;valuation;stochastic programming	Effectiveness of customers' loyalty programs has been the focal point of some recent studies. While empirical research shows mixed findings, analytical studies on the efficacy of loyalty programs are in their early stages. In this paper, we develop an analytical model on the profitability of loyalty programs in which customers' valuations along with their satisfaction levels are incorporated as stochastic variables. The model consists of a revenue-maximizing firm selling a product through two periods. A loyalty reward is offered to two-period buyers in the form of an absolute-value discount on the price in the second period. The satisfaction level is represented by the difference between a customer's original and post-purchase valuation. The formulation yields a stochastic programming problem with a nonlinear non-convex objective function. The problem is solved in terms of the model parameters. The results reveal that depending on the mean and variance of the satisfaction levels, the firm may be better off not to offer a loyalty reward. Specifically, if the mean of satisfaction levels turns out to be positive with a coefficient of variation less than a certain threshold, not adopting the loyalty program is optimal.		A. Gandomi;Saeed Zolfaghari	2011	Computers & Industrial Engineering	10.1016/j.cie.2011.04.002	stochastic programming;actuarial science;valuation;loyalty business model;marketing;customer satisfaction;commerce	SE	-0.09085857432173629	-6.719971152330388	52163
9c3cf1e9fa25e40c3a2dd09c5d0f75942861c8d1	double-sided parisian option pricing	fourier inversion;fourier transform;brownian motion;60j65;laplace transform;option pricing;parisian options;markov property;62l15;stock price;60g40;stopping time;excursions	In this paper we derive Fourier transforms for double sided Parisian option contracts. The double sided Parisian option contract is triggered by the stock price process spending some time above an upper level or below some lower level. The double sided Parisian knock-in call contract is the general type of Parisian contract from which all the one-sided contract types follow. We also discuss the Fourier inversion in the paper and conclude with a series of numerical examples, explaining the Parisian optionality and the way prices are affected by the local behavior of Brownian motion in detail.	brownian motion;numerical analysis	Jasper H. M. Anderluh;Johannes A. M. van der Weide	2009	Finance and Stochastics	10.1007/s00780-009-0090-3	financial economics;fourier transform;actuarial science;economics;markov property;stopping time;valuation of options;brownian motion;mathematics;economy;laplace transform;statistics	ECom	2.257683111911367	-2.1211951563423623	52233
0c552998a82cf37d7ac597062127ad119ed9eebf	crowdsourcing with tullock contests: a new perspective	players social welfare incentive mechanisms all pay auctions user entry optimal tullock contest design contest prize prize function rapid prototyping distributed web agents smartphone apps players antagonism fixed prize tullock contests optimal benchmark crowdsourcer utility cum profit;crowdsourcing benchmark testing bayes methods computers cost accounting conferences games;smart phones commerce optimal systems	Incentive mechanisms for crowdsourcing have been extensively studied under the framework of all-pay auctions. Along a distinct line, this paper proposes to use Tullock contests as an alternative tool to design incentive mechanisms for crowdsourcing. We are inspired by the conduciveness of Tullock contests to attracting user entry (yet not necessarily a higher revenue) in other domains. In this paper, we explore a new dimension in optimal Tullock contest design, by superseding the contest prize - which is fixed in conventional Tullock contests - with a prize function that is dependent on the (unknown) winner's contribution, in order to maximize the crowdsourcer's utility. We show that this approach leads to attractive practical advantages: (a) it is well-suited for rapid prototyping in fully distributed web agents and smartphone apps; (b) it overcomes the disincentive to participate caused by players' antagonism to an increasing number of rivals. Furthermore, we optimize conventional, fixed-prize Tullock contests to construct the most superior benchmark to compare against our mechanism. Through extensive evaluations, we show that our mechanism significantly outperforms the optimal benchmark, by over three folds on the crowdsourcer's utility cum profit and up to nine folds on the players' social welfare.	bayesian network;benchmark (computing);business process;compaq lte;crowdsourcing;emoticon;expectation–maximization algorithm;futures studies;mathematical model;mobile app;nonlinear system;rapid prototyping;semantic network;smartphone;time complexity;value (ethics);wireless access point	Tie Luo;Salil S. Kanhere;Hwee Pink Tan;Fan Wu;Hongyi Wu	2015	2015 IEEE Conference on Computer Communications (INFOCOM)	10.1109/INFOCOM.2015.7218641	industrial organization;economics;public economics;marketing;microeconomics;mathematical economics	Web+IR	-2.724129466086078	-4.705066628270622	52241
8d317b5e0b6271ca03422a1268dfc51599b330d9	stackelberg game models between two competitive retailers in fuzzy decision environment	collusion;competition;pricing decisions;stackelberg game;fuzzy variable;journal;supply chain	In this paper, we study the pricing problem in a fuzzy supply chain that consists of a manufacturer and two competitive retailers. There is a single product produced by a manufacturer and then sold by two competitive retailers to the consumers. The manufacturer acting as a leader determines the wholesale price, and the retailers acting as the followers set their sale prices independently. Both the manufacturing cost and the demand for product are characterized as fuzzy variables, we analyze how the manufacturer and the retailers make their pricing decisions with the duopolistic retailers’ different behaviors: competition strategy and collusion strategy, and develop the expected value models in this paper. Finally, numerical examples illustrate the effectiveness of the proposed two-echelon models using fuzzy set theory.	futures studies;fuzzy logic;fuzzy set;mathematical optimization;numerical analysis;row echelon form;set theory;yang	Shukuan Liu;Zeshui Xu	2014	FO & DM	10.1007/s10700-013-9165-x	competition;supply chain;stackelberg competition	ML	-1.853054904102653	-5.332335873875261	52449
315875163d8d6ba56829725350e822af328c0874	the impact of three forecasting methods on the value of vendor managed inventory	supply chain management autoregressive processes demand forecasting inventory management least mean squares methods;exponential smoothing method vendor managed inventory demand forecasting replenishment management two echelon supply chain first order autoregressive process inventory savings minimum mean square error method moving average method;forecasting supply chains analytical models predictive models information management lead standards	In a traditional supply chain, where only orders and products transact between partners, demand forecasts are important for a retailer to estimate future sales. But in a Vendor Managed Inventory (VMI) partnership, where the responsibility for replenishment management is transferred to the manufacturer, demand forecasts become essential for this manufacturer to produce the right quantity of products to be sold to the retailer. In this paper, we consider a two-echelon supply chain implementing the Vendor Managed Inventory coordination mechanism, where the manufacturer directly observes customer demand which follows a first order autoregressive process (AR(1)). We use analytical modeling to investigate benefits from VMI for the overall supply chain in terms of inventory savings with a manufacturer using one of the following three forecasting methods: the minimum-mean square error, the simple moving average method, and the exponential smoothing method. The experimentation results allow to identify some managerial guidelines to support managers to select the suitable forecasting method in an AR(1) demand environment.	autoregressive model;inventory;inventory control;mean squared error;numerical analysis;row echelon form;smoothing;time complexity	Zainab Belalia;Fouzia Ghaiti	2016	2016 3rd International Conference on Logistics Operations Management (GOL)	10.1109/GOL.2016.7731670	demand forecasting;marketing;operations management;business;commerce	DB	1.4584352411732235	-9.276337896924323	52483
4bc35dcaf018f9836b1017ee00c720ef94bb0889	robust quadratic programming for price optimization		The goal of price optimization is to maximize total revenue by adjusting the prices of products, on the basis of predicted sales numbers that are functions of pricing strategies. Recent advances in demand modeling using machine learning raise a new challenge in price optimization, i.e., how to manage statistical errors in estimation. In this paper, we show that uncertainty in recently-proposed prescriptive price optimization frameworks can be represented by a matrix normal distribution. For this particular uncertainty, we propose novel robust quadratic programming algorithms for conservative lower-bound maximization. We offer an asymptotic probabilistic guarantee of conservativeness of our formulation. Our experiments on both artificial and actual price data show that our robust price optimization allows users to determine best risk-return trade-offs and to explore safe, profitable price strategies.	converge;expectation–maximization algorithm;experiment;machine learning;mathematical optimization;program optimization;quadratic programming	Akihiro Yabe;Shinji Ito;Ryohei Fujimaki	2017		10.24963/ijcai.2017/648	branch and price;discrete mathematics;robust optimization;active set method;second-order cone programming;quadratic unconstrained binary optimization;quadratic programming;computer science;sequential quadratic programming;mathematical optimization;quadratically constrained quadratic program	DB	2.501873353432078	-0.6977020188732382	52522
7997ddd5d00d791a58ab1fd00079295ace82670d	autonomous coordination technology through community organization for resource utilization	communication system;community organization;resource utilization	The challenge in resource utilization under dynamic environment is how to utilize appropriate resources to the right users at the right time and the right location. In conventional system, centralized management system is applied but it tends to congest when user requests increase or resources rapidly move. Therefore, this paper proposes Autonomous Coordination Technology (ACT) through community organization for resource utilization. In ACT, a node which has surplus resources autonomously constructs community with a surplus-level based size and distributes resources to members which are deficient in resources. ACT consists of autonomous coordination within community and among communities. According to community organization, online property and flexibility can be satisfied. However, it is difficult to achieve service provision timeliness and resource allocation operatability in the mean time. Thus, ACT includes successive transportation method, and autonomous resource allocation which dynamic decision is made by a tradeoff between timeliness and operatability. As a result, the service assurance in terms of timeliness and operatability can be assured. The effectiveness of proposed technology is affirmed through the simulation of taxi dispatching application in terms of response time and standard deviation versus user rates.		Titichaya Thanamitsomboon;Kotaro Hama;Riyako Sakamoto;X J David Lu;Kinji Mori	2011	IEICE Transactions		community organization;in situ resource utilization;systems management;simulation;internationalization and localization;resource allocation;computer science;autonomous system;resource management;standard deviation;operations research;response time;communications system;statistics	HPC	-1.233153913623568	3.4530067773941995	52611
ecb929bd0a365d8349100e3a06c695f1a86190b8	the coordination mechanisms of emergency inventory model under supply disruptions		This paper develops a cooperative emergency inventory model to deal with supply disruptions. To achieve a cooperative state between the two sides in supply chain, the game theory is used and three coordination mechanisms are proposed. With the emergency inventory method which has been established, many tests of numerical experiments are made. The aim is to find the optimal mechanism so that the conditions of three mechanisms need to meet are analyzed. Results show that the total profits of the whole supply chain are unchanged in return mechanism. In cost-sharing mechanism, the manufacturer’s profits are smaller than the profits before coordination, and the supplier’s profits are greater than the former, but total profits of the whole supply chain become larger. The proposed model with the introduction of a second manufacturer mechanism performs best, which can make up the expenses by using the new joined manufacturers. It also can help the manufacturers respond to the supply disruptions effectively and that will not harm the profits of both sides.	inventory theory	Jiaguo Liu;Huan Zhou;Junjin Wang	2018	Soft Comput.	10.1007/s00500-018-3147-4	risk management;operations management;game theory;mathematical optimization;optimal mechanism;profit (economics);supply chain;computer science	ECom	-1.1162787808353993	-5.393746878545296	52620
4060e9c807597f5fbaabc9678516e0317cf4b078	pricing and production lot-size/scheduling with finite capacity for a deteriorating item over a finite horizon	cout variable;dynamic programming;decision models;gestion entreprise;analisis sensibilidad;time varying;variable cost;programacion dinamica;indice produccion;lot size and scheduling;systeme aide decision;producto perecedero;pricing;time varying demand;processus metier;production system;resource management;comercializacion;systeme production;firm management;dynamic program;sistema ayuda decision;fijacion precios;sistema produccion;horizonte finito;capacite stockage;commercialisation;gestion recursos;decision support system;horizon fini;marketing;planification ressource entreprise;sensitivity analysis;capacidad almacenaje;scheduling;perishable item;storage capacity;taux production;enterprise resource planning;comparative study;programmation dynamique;programacion produccion;deterioration;analyse sensibilite;scheduling problem;lot sizing;gestion ressources;finite horizon;production planning;proceso oficio;production rate;administracion empresa;profitability;production cost;numerical experiment;planification production;produit perissable;fixation prix;ordonnancement;periodic pricing;business process;reglamento	Although the lately evolved manufacturing technologies such as enterprise resource planning (ERP) provide a uni&ed platform for managing and integrating core business processes within a &rm, the decision-making between marketing and production planning still remains rather disjoint. It is due in large parts to the inherent weaknesses of ERP such as the &xed and static parameter settings and uncapacitated assumption. To rectify these drawbacks, we propose a decision model that solves optimally the production lot-size/scheduling problem taking into account the dynamic aspects of customer’s demand as well as the restriction of &nite capacity in a plant. More speci&cally, we consider a single product that is subject to continuous decay, faces a price-dependent and time-varying demand, and time-varying deteriorating rate, production rate, and variable production cost, with the objective of maximizing the pro&t stream over multi-period planning horizon. We propose both coordinated and decentralized decision-making policies that drive the solution of the multivariate maximization problem. Both policies are formulated as dynamic programming models and solved by numerical search techniques. In our numerical experiments, the solution procedure is demonstrated, comparative study is conducted, and sensitivity analysis is carried out with respect to major parameters. The numerical result shows that the solution generated by the coordinated policy outperforms that by the decentralized policy in maximizing net pro&t and many other quanti&able measures such as minimizing inventory investment and storage capacity. Scope and purpose We consider a manufacturing &rm who produces and sells a single product that is subjected to continuous decay over a lifetime, faces a price-dependent and time-varying demand function, shortages are allowed and a completely backlogged, and has the objective of determining price and production lot-size/scheduling so as to maximize the total pro&t stream over multi-period planning horizon. We develop a tactical-level decision model that solves the production scheduling problem taking into account the dynamic nature of customer’s demand which is partially controllable through pricing schemes. As analogous to the sales and operations planning, the proposed scheme can be used as a coordination center of the APS system within a generic enterprise resource planning framework which integrates and coordinates distinct functions within a &rm. ∗ Corresponding author. Tel.: +886-03-425-8192; fax: +886-3-425-8197. E-mail address: jmchen@mgt.ncu.edu.tw (J.-M. Chen). 0305-0548/$ see front matter ? 2004 Elsevier Ltd. All rights reserved. doi:10.1016/j.cor.2004.04.005 2802 J.-M. Chen, L.-T. Chen / Computers & Operations Research 32 (2005) 2801–2819 This paper diBers from the existing works in several ways. First, we propose a dynamic version of the joint pricing and lot-size/scheduling problem taking into account the capacitated constraint. Second, several key factors being considered in the model, such as the demand rate, deteriorating rate, production rate, and variable production cost are assumed time-varying that reDect the dynamic nature of the market and the learning eBect of the production system. A third diBerence between the past research and ours is that the price can be adjusted upward or downward in our model, making the proposed pricing policy more responsive to the structural change in demand or supply. ? 2004 Elsevier Ltd. All rights reserved.	business process;dynamic programming;erp;enterprise resource planning;entity–relationship model;expectation–maximization algorithm;experiment;fax;numerical analysis;operations research;production system (computer science);scheduling (computing)	Jen-Ming Chen;Liang-Tu Chen	2005	Computers & OR	10.1016/j.cor.2004.04.005	pricing;job shop scheduling;variable cost;decision model;simulation;decision support system;computer science;resource management;dynamic programming;comparative research;production system;business process;operations research;scheduling;sensitivity analysis;profitability index	AI	1.6390344534274879	-5.394609010779686	52698
b18681f93be777824f774bc70ff15f37d7a71d76	strive to be first or avoid being last: an experiment on relative performance incentives	tournament;learning;loser;contract;winner;experiment	Strive to be First or Avoid Being Last: An Experiment on Relative Performance Incentives We utilize a laboratory experiment to compare effort provision under optimal tournament contracts with different distributions of prizes which motivate agents to compete to be first, avoid being last, or both. We find that the combined tournament contract incorporating both incentives at the top and at the bottom induces the highest effort, especially in larger groups. Avoiding being last produces the lowest variance of effort and is more effective at motivating employees compared to competing for the top. JEL Classification: M52, J33, J24, D24, C90	reinforcement learning	E. Glenn Dutcher;Loukas Balafoutas;Florian Lindner;Dmitry Ryvkin;Matthias Sutter	2015	Games and Economic Behavior	10.1016/j.geb.2015.08.008	contract;experiment;economics;marketing;operations management;tournament;statistics	AI	-4.405863909855713	-6.016844895414457	52746
251de16bca7d29bbbdce987bbb0bd9308b87fe98	a new method for measuring the static complexity in manufacturing	forecasting;reliability;project management;information systems;maintenance;soft or;information technology;packing;operations research;location;investment;journal;journal of the operational research society;inventory;purchasing;history of or;logistics;marketing;scheduling;production;communications technology;computer science;operational research;applications of operational research;or society;jors;management science;infrastructure			Ahmad Makui;Mir-Bahador Aryanezhad	2003	JORS	10.1057/palgrave.jors.2601493	project management;logistics;inventory;economics;forecasting;investment;marketing;operations management;reliability;management science;location;operations research;information technology;scheduling	Robotics	6.637269179923359	-3.825383989203199	53062
aeeee5b9eddaea32249e679f28c20e9ec82337f5	an eoq model for retailers partial permissible delay in payment linked to order quantity with shortages	partial trade credit;eoq model;inventory model;partial backlogging	Living in the business world, maximizing owner's happiness or getting paid by the sales of goods or services on an open account at some reasonable profit is the main purpose of any business. The credit functions play a vital role within the organization. In this paper, we develop an inventory model for retailers partial permissible delay-in-payment linked to order quantity with shortage, which is partial backlogged. Here, we consider two different cases, i.e. in first, the trade-credit period ( M ) is greater than or equal to the time interval t w , that w units are depleted to zero due to demand; and later, the trade-credit period ( M ) is less than the time interval t w . The principle objective of the introduced model is to minimize the total inventory cost by finding an optimal replenishment policy. Required theorems are provided to verify the optimal solutions. Various numerical examples and managerial implications are discussed to check and substantiate the intransigent results.	economic order quantity	Vandana;B. K. Sharma	2016	Mathematics and Computers in Simulation	10.1016/j.matcom.2015.11.008	actuarial science;economic order quantity	ECom	1.4808626233053228	-5.451460407035434	53109
2cdc126a0dfc87f7ce10e036ed736a8a1c64f0b8	proving regularity of the minimal probability of ruin via a game of stopping and control	hamilton jacobi bellman equation;convex duality;boundary value problem;risk management;93e20;classical solution;utility maximization;viscosity solution;hamilton jacobi bellman;probability of ruin;financial market;portfolio management;variational inequality;optimal stopping;60g40;stochastic representation;optimal investment;91b28;probability of lifetime ruin;hjb equation;stochastic games	We will reveal an interesting convex duality relationship between (a) minimizing the probability of lifetime ruin when the rate of consumption is stochastic and when the individual can invest in a Black-Scholes financial market; (b) a controller-and-stopper problem: the controller controls the drift and volatility of a process in order to maximize a running reward based on that process, the stopper chooses the time to stop the running reward and rewards the controller a final amount at that time. Our primary goal is to show that the minimal probability of ruin, whose stochastic representation does not have a classical form as the utility maximization problem (i.e. the objective’s dependence on the initial values of the state variables is implicit), is the unique classical solution of its Hamilton-Jacobi-Bellman (HJB) equation, which is a non-linear boundary-value problem. We establish our goal by exploiting the convex duality relationship between (a) and (b). MSC 2000 Classification: Primary 93E20, 91B28; Secondary 60G40. JEL Classification: Primary G11; Secondary C61.	black–scholes model;control theory;convex function;emoticon;expectation–maximization algorithm;hamilton–jacobi–bellman equation;jacobi method;navier–stokes equations;nonlinear system;optimal control;optimal stopping;viscosity solution;volatility	Erhan Bayraktar;Virginia R. Young	2011	Finance and Stochastics	10.1007/s00780-011-0160-1	financial economics;mathematical optimization;hamilton–jacobi–bellman equation;variational inequality;optimal stopping;economics;risk management;boundary value problem;first-hitting-time model;finance;viscosity solution;mathematics;mathematical economics;financial market	AI	1.5691979251164314	-2.148111235305567	53238
35b26c131a717ff05473b0ce210a160866262f86	analysis of the stochastic cash balance problem using a level crossing technique		The simple cash management problem includes the following considerations: the opportunity cost of holding too much cash versus the penalty cost of not having enough cash to meet current needs; the cost incurred (or profit generated) when making changes to cash levels by increasing or decreasing them when necessary; the uncertainty in timing and magnitude of cash receipts and cash disbursements; and the type of control policy that should be used to minimize the required level of cash balances and related costs. In this paper, we study a version of this problem in which cash receipts and cash disbursements occur according to two independent compound Poisson processes. The cash balance is monitored continuously and an order-point, order-up-to-level, and keep-level ( left( {s, S, M} right) ) policy is used to monitor the content, where ( s le S le M ). That is, (a) if, at any time, the cash level is below s, an order is immediately placed to raise the level to S; (b) if the cash level is between s and M, no action is taken; (c) if the cash level is greater than M, the amount in excess of M is placed into an earning asset. We seek to minimize the expected total costs per unit time of running the cash balance. We use a level-crossing approach to develop a solution procedure for finding the optimal policy parameters and costs. Several numerical examples are given to illustrate the tradeoffs.		Ben A. Chaouch	2018	Annals OR	10.1007/s10479-018-2822-2	cash;mathematical optimization;econometrics;mathematics;cash management;total cost;cash receipts journal;opportunity cost;poisson distribution;level crossing	EDA	2.217611701626037	-4.068624810012963	53702
02d624c8abfab50e8d25c12eb666c25908e0702f	a recursive approach for lot sentencing problem in the presence of inspection errors	dynamic programming;bayesian inference;acceptance sampling plan;65c40;inspection errors;65c50	ABSTRACTIn this paper, a new sequential acceptance sampling plans in the presence of inspection errors is developed. A suitable profit objective function is employed for optimizing the lot sentencing problem. A backward recursive approach is applied for obtaining the profit of different decisions in each stage of sampling. Required probabilities are obtained using Bayesian rule. A case study is solved for illustrating the application of proposed models and sensitivity analysis are carried out on the parameters of the proposed methodologies and the behaviour of models by changing the parameters are investigated.	recursion	Mohammad Saber Fallah Nezhad;Abolghasem Yousefi Babadi;Mohammad Saleh Owlia;Ali Mostafaeipour	2017	Communications in Statistics - Simulation and Computation	10.1080/03610918.2015.1043389	econometrics;dynamic programming;mathematics;bayesian inference;statistics	ECom	7.860161110748855	-0.9312976724982507	53933
b3a2c2b9cc1b1f3b8487f72f3018969be92772e7	the complexity of simplicity in mechanism design	simple mechanisms;approximation;revenue;optimal mechanisms	"""Optimal mechanisms are often prohibitively complicated, leading to serious obstacles both in theory and in bridging theory and practice. Consider the problem of a monopolist seller facing a single additive buyer with independent valuations over n heterogeneous items. Even in this simple setting, it is known that optimal (revenue-maximizing) mechanisms may require randomization [Hart and Reny 2012], use menus of infinite size [Daskalakis et al. 2015], and may be computationally intractable [Daskalakis et al. 2014].  In a letter here last year, Babiaoff et al. [Babaioff et al. 2014a] described their attempt to alleviate the problem by showing that a constant fraction of the optimal revenue can be obtained by a simple mechanism. In this letter we argue in favor of a related research direction: finding the optimal simple mechanism. We survey our recent results in this setting [Rubinstein 2016] and draw attention to the question of what is a """"simple"""" mechanism?"""	bridging (networking);computational complexity theory;utility functions on indivisible goods	Aviad Rubinstein	2015	SIGecom Exchanges	10.1145/2904104.2904110	mathematical optimization;economics;artificial intelligence;operations management;approximation;mathematics;mathematical economics;revenue;algorithm	ECom	-2.574291506304076	-1.412240445323151	53936
86813dcffa2e0a2d3309af52e944af14419ec0fd	the cost of continuity in the collaborative pickup and delivery problem		We assess the potential total profit in collaborative pickup and delivery problems, where carriers are willing to exchange transportation requests. For this, we design an adaptive large neighborhood search method that is used to generate solutions of publicly available but yet unsolved test instances. Our computational study reveals that collaboration profits might go up to 40% of the initial total profit, but typically come with unevenly distributed workloads. Such solution are of course not acceptable in practice. Thus, the aim of this study is to elaborate on the cost of continuity, i.e. the possibility for carriers to not deviate too much from their initial situations. Carriers might, for instance, not be willing to give up on some of their customers or want to stay with minimum profits. The rational behind keeping customers is that carriers might have long-term or particular valuable customer relationships, which they do not want to abandon. We discuss different types of continuity constraints and assess their impact on the total collaboration profit. Our computational study shows that even in the presence of continuity constraints remarkable total collaboration profits can be achieved.	scott continuity	Margaretha Gansterer;Richard F. Hartl;Sarah Wieser	2018		10.1007/978-3-030-00898-7_15	operations research;computer science;theoretical computer science;profit (economics);pickup;delivery problems	ML	3.706101462417198	0.5378292277445902	54141
3c49db3c6b30b2bb68f346b3a507630d805f9f4d	incorporating human factors-related performance variation in optimizing a serial system	work related musculoskeletal disorders;human factors;health state markov chain;performance optimization	Work-related health problems cause an operator to be in different health-states and to have different performance levels in terms of productivity and the number of defective items produced. Human factors studies usually investigate workplace risk factors to reduce the negative effects of occupational health problems. However, they rarely optimize the performance of operation systems. To this end, this paper presents an analytical modeling framework integrating human factor aspects (workplace risk factors) into a serial assembly system performance optimization model. First, a health-state Markov chain is developed to model an employee’s work-related health conditions, which varies due to workplace risk factor exposure levels. Then, the total cost of the assembly system is minimized with respect to incorporating operational and financial consequences of the work-related health-states with other features of the system such as customer demand, inventory capacity and production costs. Ultimately, this study compares the optimum total cost of the system with and without including human factors. The results of numerical analysis show that the total cost increases from 0.1 percent to 32 percent in the presence of different workplace risk factors. This research opens a new window to considering a human factors (ergonomic) intervention not only as an occupational health and safety solution, but also as an operation improvement method leading to the design of safer and more efficient systems. Managers may also take the advantages of this study by having more opportunities to better deal with production variations via improving workplace ergonomic conditions.	human factors and ergonomics	Ahmad Sobhani;M. I. M. Wahab;W. Patrick Neumann	2017	European Journal of Operational Research	10.1016/j.ejor.2016.06.057	simulation;human factors and ergonomics;operations management;management science	Robotics	8.395114412566263	-3.515119582288885	54427
30e45ac05209237ce5a3a07705b6eb139706660c	economic design of an inventory system involving probabilistic deterioration and variable setup cost through mathematical approach	probabilistic deterioration;inventory management;delivery lot sizing;economic design;capital investment;differential calculus optimisation;logarithmic function;inventory modelling;variable setup costs	The purpose of this paper is to present the single-supplier single-buyer integrated production-distribution inventory model with three types of probabilistic deterioration and effectively increase investment to reduce the setup cost. An economic model is designed through mathematical approach to investigate the effects of probabilistic deterioration on the optimal solutions when a capital investment strategy in setup reduction is adopted. We used the differential calculus optimisation technique to optimise the strategies of our setup cost reduction inventory system. An efficient iterative algorithm is designed to obtain the optimal solution of the delivery lot-size, setup cost and total number of deliveries from a supplier to a buyer in one production run simultaneously. Numerical examples are given to demonstrate the application and the performance of the proposed methodology. The results of the numerical examples indicate that if the supplier makes his/her decisions with the capital investment in reduci...		S. Priyan;R. Uthayakumar	2016	IJMOR	10.1504/IJMOR.2016.075519	mathematical optimization;logarithm;economics;operations management;mathematics;welfare economics	EDA	4.5760961200454	-4.801376568754417	54441
a77d48968a6348dcd5a68fcf01597ebadb7cd026	reliability-based optimal planning of electricity and natural gas interconnections for multiple energy hubs	multiple energy hub system reliability based planning electricity and natural gas interconnection;electricity and natural gas interconnection multiple energy hub system reliability based planning;natural gas reliability planning pipelines power transmission lines couplings computer network reliability	This paper presents a reliability-based optimal planning model for an interconnection of energy hubs with multiple energy infrastructures. Energy hub represents a coupling among various energy infrastructures for supplying electricity and natural gas loads. The proposed planning problem determines a least-cost network of transmission lines and natural gas pipelines for interconnecting energy hubs from a given set of candidate paths that satisfy probabilistic reliability criteria. The minimal cut-maximal flow algorithm is applied for network flow analyses and calculating transfer capabilities of a multiple energy system. So, in contrast to a single energy infrastructure, the proposed hub planning model enables a synergetic strategy to design multiple energy networks for optimizing the supply economics and satisfying the reliability criteria. Numerical simulations demonstrate the effectiveness of the proposed reliability-based planning approach to interconnect energy hubs with multiple energy infrastructures.	algorithm;computer simulation;data-flow analysis;energy systems language;energy level;flow network;interconnection;max-flow min-cut theorem;maximal set;maximum flow problem;numerical linear algebra;pipeline (computing);synergetics (haken);synergy;transmission line;usb hub	Xiaping Zhang;Liang Che;Mohammad Shahidehpour;Ahmed Alabdulwahab;Abdullah M. Abusorrah	2017	IEEE Transactions on Smart Grid	10.1109/TSG.2015.2498166	reliability engineering;electronic engineering;engineering;operations management	Robotics	5.906003220709937	3.881330360635622	55076
d8b616a596b275f107f7c77f842f1c40dc27fc5f	input control for serial production lines consisting of processing and assembly operations with random yields	chaine fabrication;control optimo matematicas;multistage;gestion production;variable aleatoire;variable aleatoria;product line;inventory production;yield;production management;production line;issuing policies;yield uncertainty;controle optimal;gestion produccion;random variable;optimal control mathematics;linea fabricacion;rendimiento;rendement	"""This paper deals with a serial production line where each of the stages can be either a processing or an assembly stage. A processing stage processes outputs from an upstream stage and transforms them into inputs for the downstream stage. Each processing stage is subject to yield losses. At an assembly stage, a batch of identical input components is processed and the nondefective components are then combined with the output from the upstream stage. The processing operation for the input component is imperfect. For such a system, we characterize the form of the optimal policy for input quantity at each stage in the production line, when stochastically proportional yield is assumed at each stage, i.e., the distribution of the yield fraction is assumed to be independent of the lot size. The optimal policy exhibits some form of a critical number policy. For production lines consisting of assembly stages only, the critical numbers can be computed easily. When yields are of the """"exponential"""" type, the critical number policy is still optimal, although there are interesting differences in the policies for the different types of yield characterizations."""		Hau L. Lee	1996	Operations Research	10.1287/opre.44.3.464	random variable;yield;simulation;production line;operations management;mathematics;statistics	Robotics	5.477311654178205	-1.7771308171671796	55085
6aa966722929136610949eb110e6c4a3137f195a	parimutuel betting on permutations	multiagent system;game theory;convex programming;decision problem;computational complexity;state space;polynomial time;data structure;maximum entropy	We focus on a permutation betting market under parimutuel call auction model where traders bet on the final ranking of n candidates. We present a Proportional Betting mechanism for this market. Our mechanism allows the traders to bet on any subset of the n ‘candidate-rank’ pairs, and rewards them proportionally to the number of pairs that appear in the final outcome. We show that market organizer’s decision problem for this mechanism can be formulated as a convex program of polynomial size. More importantly, the formulation yields a set of n unique marginal prices that are sufficient to price the bets in this mechanism, and are computable in polynomialtime. The marginal prices reflect the traders’ beliefs about the marginal distributions over outcomes. We also propose techniques to compute the joint distribution over n! permutations from these marginal distributions. We show that using a maximum entropy criterion, we can obtain a concise parametric form (with only n parameters) for the joint distribution which is defined over an exponentially large state space. We then present an approximation algorithm for computing the parameters of this distribution. In fact, the algorithm addresses the generic problem of finding the maximum entropy distribution over permutations that has a given mean, and may be of independent interest.	approximation algorithm;computable function;convex optimization;decision problem;electronic organizer;marginal model;maximum entropy probability distribution;polynomial;principle of maximum entropy;state space;time complexity;traders	Shipra Agrawal;Zizhuo Wang;Yinyu Ye	2008		10.1007/978-3-540-92185-1_21	time complexity;game theory;mathematical optimization;combinatorics;data structure;economics;computer science;state space;principle of maximum entropy;decision problem;mathematics;microeconomics;mathematical economics;computational complexity theory;algorithm;statistics	ECom	-2.4046466060551825	-0.9424989768446403	55196
7440792326ce768abcb7ca51cd8032ef434c45ce	is a unique cournot equilibrium locally stable?	local stability;journal of economic literature	Abstract   We consider a homogeneous product oligopoly, where the Cournot equilibrium is regular and unique. We show that for a duopoly, a unique Cournot equilibrium is always locally stable. For a “ n ” firm asymmetric cost oligopoly a unique Cournot equilibrium is locally stable under very general conditions. The sufficient conditions for local stability of a unique Cournot equilibrium are much less restrictive than what the existing literature suggests. For a symmetric cost oligopoly the unique Cournot equilibrium is almost always locally stable, except for a perverse case.  Journal of Economic Literature  Classification number: L13.		Krishnendu Ghosh Dastidar	2000	Games and Economic Behavior	10.1006/game.1999.0768	partial equilibrium;cournot competition;bertrand competition;economics;microeconomics;mathematical economics;welfare economics	ECom	-4.044522637946861	-3.308020518043516	55224
1cba69ef4e936ab32f71f825c5dcd0d5b4e0fe49	the dynamic economic equilibrium model and uncertainty applied study about forest resources sustainable utilization	dynamic economic modelforest resourcessustainable harvest quantityuncertainty applied study	In this paper, we regarded the forest resources as research objects, and used the dynamic economic model about renewable resources utilization based of the Logistic model to create the forest resources dynamic economic equilibrium model with the many restriction conditions about ecological production supply, taxation, economic composition and so on. Then we used the mathematic method about normal differential equation and maximum theory to obtain the optimal forest accumulation stock quantity and the optimal harvest quantity. After, we selected the North-east of China as the case site of applied research, and used the dynamic economic equilibrium theoretical model and the data from forest resources investigation, forestry statistics yearbook and typical survey to carry the applied analysis to obtain the optimal harvest quantity dynamic function about forest resources in North-east of China. Then we used the function to obtain the development trend of the equilibrium after 2008, and the optimal harvest quantity should be 4.26 million m.	c date and time functions;converge;ecosystem services;the forest;theory;tree accumulation	Wenhui Chen;Junchang Liu;Aili Yao	2011		10.1007/978-3-642-18387-4_5	environmental economics;economics;agricultural economics;environmental resource management	AI	5.850238445303553	-8.143161803465269	55439
3a44527e6252d05e0cfa113d94fcd3395e61132d	selfish unsplittable flows: algorithms for pure equilibria			algorithm	Paul Pavlos Spirakis	2016		10.1007/978-1-4939-2864-4_360		Theory	-4.333554080695106	1.8315957585011504	55525
b289ab07c8fa44488486c301443fef2bd02c1d08	on the competitive ratio of online sampling auctions	digital goods auctions;prior free mechanisms;online algorithms;mechanism design	We study online profit-maximizing auctions for digital goods with adversarial bid selection and uniformly random arrivals; in this sense, our model lies at the intersection of prior-free mechanism design and secretary problems. Our goal is to design auctions that are constant competitive with F(2). We give a generic reduction that transforms any offline auction to an online one with only a loss of a factor of 2 in the competitive ratio. We also present some natural auctions, both randomized and deterministic, and study their competitive ratio. Our analysis reveals some interesting connections of one of these auctions with RSOP.	competitive analysis (online algorithm);online and offline;randomized algorithm;secretary problem	Elias Koutsoupias;George Pierrakos	2013	ACM Trans. Economics and Comput.	10.1145/2465769.2465775	mechanism design;online algorithm;economics;unique bid auction;computer science;marketing;common value auction;microeconomics;advertising;mathematical economics;commerce;forward auction	ECom	-2.563688067258225	-1.1670205499130515	55540
56ef7565f26818ad2a38734af9b46376fa87415d	enterprise behaviour under cap-and-trade conditions: an experimental study with system dynamic models	jos;simulation;conceptual modellling;journal of simulation;output analysis;design and analysis of simulation experimetns;input modelling;applications of simulation and modelling;simulation visualisation;期刊论文;simulation tutorials;parallel and distributed simulation;discrete event simulation	Operating under Cap-and-Trade programme conditions has brought new challenges to industrial organizations pursuing green sustainable development by imposing more constraints on resource/energy acquisition and disposition in order to reduce green-house-gas emissions. New factors due to the conditions interact with each other and system production/service functions, causing complicated dynamic relationships that significantly affect the overall performance of participating enterprises. Managers now have to balance production economy and green improvement. This research shows a proactive approach based on system dynamics modelling to represent such complex systems and analyse the relationship to explore the underlining logic that drives system behaviour under related conditions. The analysis provides useful insights for decision or policymakers to pursue environmentally friendly and economically sound production. Conceptual models were developed and verified for functions, and simulation experiments were designed to implement the models and compare different strategies to analyse their impact on the system’s overall performance, such as long-term over-emission, continuous green investment on emissions reduction, and cost of purchasing emissions allowance or paying penalty (via over-emission tax).	experiment;system dynamics	M. Zhou;Yu Pan;Z. Chen;Bin Li	2016	J. Simulation	10.1057/jos.2014.36	simulation;computer science;discrete event simulation;management science	Robotics	5.179630645709623	-7.910675574963945	55609
7f1531f0659ae2032639ef9e4a5aad579f13d25a	editor's introduction		"""I am very happy to introduce Issue 8.1 of SIGecom Exchanges. This issue starts with a conference announcement and a book review. Rossi and Tsoukias announce the first edition of a new conference on Algorithmic Decision Theory (ADT-09), to be held in Venice, Italy. The conference aims to bring together researchers from decision theory, discrete mathematics, theoretical computer science, and artificial intelligence. Then, Aziz reviews the book """" Social and Economic Networks """" by Matthew O. Jackson, which gives an overview and synthesis of techniques from a variety of fields for the analysis of such networks. The first four letters concern the design of auctions and other mechanisms. Ashlagi, Dobzinski, and Lavi consider the problem of designing mechanisms to schedule jobs on unrelated machines. The goal is to minimize the makespan. They examine the Nisan-Ronen conjecture that no truthful mechanism achieves an approximation ratio better than the number of machines, and prove that the conjecture holds for anonymous mechanisms. Hartline and Roughgarden consider the problem of creating """" optimal """" mechanisms, that is, mechanisms that maximize expected revenue. In particular, they study simple mechanisms such as VCG with reserve prices, VCG with anonymous reserve prices, and VCG without any reserve prices, and they consider how close these come to optimality, in several different senses. Herings, Müller, and Vermeulen give a survey of bisection auctions, which are iterative auctions that aim to minimize the information communicated by bidders by performing a type of binary search on the valuation space. Finally, Vorobeychik engages in simulation-based analyses of strategic behavior in keyword auctions that are difficult to solve analytically. Some of his noteworthy conclusions are that generalized second price mechanisms are far from truthful and that ranking by bid tends to produce higher profit than ranking by revenue. The next four letters concern other game-theoretic topics. Ackermann, Goldberg, Mirrokni, Röglin, and Vöcking consider two-sided matching markets without a central authority, and study whether better-response and best-response dynamics converge to a stable matching, and, if so, whether they do so quickly. Chalkiadakis, Elkind, Markakis, Polukarov, and Jennings consider coalitional games in which an agent can simultaneously be part of multiple (partial) coalitions by devoting only some of her resources to each of these coalitions. They introduce various notions of stability, and also instantiate their framework on some specific games. Chawla, Niu, and Roughgarden consider networks where every seller owns a single edge, and every …"""	ackermann function;approximation algorithm;artificial intelligence;binary search algorithm;converge;decision theory;discrete mathematics;game theory;iteration;jackson;job stream;makespan;simulation;stable marriage problem;theoretical computer science;value (ethics)	Vincent Conitzer	2009	SIGecom Exchanges	10.1145/1598780.1598781		AI	-2.54211131142278	0.3838980586986609	55614
62bf413747d68f499822b7f78ae36ac1c78afd89	a simulation of the product distribution in the newspaper industry	printing;analytical models;paper distribution process;distributed processing;paper printing process;publishing;business communication;probability of failure;companies;printing industry;goods dispatch data processing digital simulation publishing printing industry;product distribution;press schedule;goods dispatch data processing;decision support systems;environmental economics;production;paper packaging process;warehouse assignments on time paper delivery newspaper industry quality of service product distribution sales required delivery times simulation model paper printing process paper packaging process paper distribution process press schedule;sales;on time paper delivery;quality of service;newspaper industry;required delivery times;modeling;simulation model;modeling production printing analytical models companies environmental economics decision support systems discrete event simulation business communication quality of service;warehouse assignments;digital simulation;discrete event simulation	On-time delivery of the paper is critical in the newspa industry since it is directly related to the quality of servic therefore, it enhances or damages sales. This study focused on determining the means to meet requ delivery times, and in identifying ways to improve it, that there is a lower probability of failure. A simulatio model was built to model the paper printing, packagi and distribution processes. The results yielded a p schedule and warehouse assignments that provided a improvement on delivery time. This improvement resu in a 97% on time delivery of the paper.	printing;simulation	Marelys L. García;Martha A. Centeno;Gabriela Peñaloza	1999		10.1145/324898.325058	simulation;systems modeling;quality of service;product distribution;computer science;engineering;discrete event simulation;industrial engineering;simulation modeling;publishing;business communication;statistics	DB	8.223694915237063	1.748333877776921	55699
44290070cfcfb0ca0e5aba9bcd5dda502d33e567	a stock model with varying stock diffusion for uncertain market				Shengguo Li;Jin Peng;Bo Zhang	2018	International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems	10.1142/S0218488518500319	machine learning;artificial intelligence;financial economics;mathematics	Robotics	2.39140225492655	-9.2874752410757	55995
139a3ae512b4b28d835e14550c3c2f3c9c0a35aa	research on congestible government production and welfare expenditure in stochastic endogenous growth model	stochastic fluctuation;congestion;stochastic endogenous growth model;economic growth	Based on the endogenous growth model, a continuous-time stochastic endogenous growth model with congestible government production and welfare expenditure is proposed. The impact of model parameters on the equilibrium economic growth and welfare is discussed and some optimal policy parameters are obtained. Furthermore, production effect of congestible government expenditure is investigated from two cases whether congestion has production utility or not. Finally, macroeconomic effects of government expenditure and its volatility on economic growth are analysed and demonstrated.	population dynamics	Bo Yang;Xueguang Chen;Mehala Zhuran	2014	IJCAT	10.1504/IJCAT.2014.063924	endogenous growth theory	AI	1.1477500224054904	-8.468568637298036	56072
46d9d5e3f011effb4951960affb3c54d0f68b4db	revenue ranking of first-price auctions with resale	auctions resale first price mechanism;first price auction;second price auction	When the price setter in post-auction resale is chosen according to exogenous probabilities, Hafalir and Krishna (2008) [2] showed that the first-price auction brings more expected revenues than the second-price auction with truth-bidding bidders. We complete their revenue ranking by proving that the first-price auction produces higher expected revenues the higher the probability the auction winner sets the resale price. © 2010 Elsevier Inc. All rights reserved. JEL classification: D44; D82		Bernard Lebrun	2010	J. Economic Theory	10.1016/j.jet.2010.04.002	industrial organization;walrasian auction;eauction;vickrey auction;combinatorial auction;generalized second-price auction;economics;unique bid auction;reverse auction;vickrey–clarke–groves auction;proxy bid;revenue equivalence;multiunit auction;english auction;microeconomics;bid shading;auction theory;commerce;forward auction;dutch auction	AI	-2.677498636383007	-4.645824826752049	56194
fc22f7ba1f0057295fb7fa0969279293dd8e24eb	offering rss feeds: does it help to gain competitive advantage?	simple syndication;different parameter combination;free content;offering rss feeds;different equilibrium outcome;gain competitive advantage;online content;competitive market;offering website;competitive setting;competitive disadvantage;competing website	Nowadays, many websites have adopted the Really Simple Syndication (RSS) technology to deliver online content to visitors. In this paper, I build an analytical model to examine how the offering of RSS feeds impact the number of visitors, total traffic load, and profit of websites in a competitive setting. I show that although RSS can always attract more visitors, it may reduce the website's profit. Interestingly, in a competitive market there are cases that the RSS feeds hurt the offering website but benefit the competing website instead. The conditions under which these will happen are derived. I also study the simultaneous RSS-adoption game and show that different equilibrium outcomes will appear under different parameter combinations. Applying my findings to the practice, I suggest that offering RSS feeds could become a competitive disadvantage, and that certain types of websites, such as websites providing free content, should not offer RSS feeds.	rss;web content;web syndication	Daqing Ma	2009	2009 42nd Hawaii International Conference on System Sciences	10.1109/HICSS.2009.842	computer science;marketing;rss;web syndication;advertising;world wide web;competitive advantage;profitability index	HCI	-2.528180253805745	-8.307089549934762	56761
7e8fa85bd963391d3df0fccdf70b8237dfec0d4d	stochastic programming for optimizing bidding strategies of a nordic hydropower producer	modelizacion;mixed integer linear program;hydroelectric power plant;centrale hydroelectrique;optimisation;optimizacion;reseau electrique;estrategia optima;or in energy;power market;electrical network;bidding strategies;red electrica;modele lineaire;programmation stochastique;modelo lineal;electricity market;prix marche;scenario;modelisation;optimal strategy;systeme incertain;market price;central hidroelectrica;programacion mixta entera;argumento;script;linear model;subasta;bidding;electricity markets;programmation partiellement en nombres entiers;mixed integer programming;optimization;modele donnee;enchere;point of view;stochastic programming;sistema incierto;scenarios;modeling;uncertain system;programacion estocastica;strategie optimale;data models	From the point of view of a price-taking hydropower producer participating in the day-ahead power market, market prices are highly uncertain. The present paper provides a model for determining optimal bidding strategies taking this uncertainty into account. In particular, market price scenarios are generated and a stochastic mixed-integer linear programming model that involves both hydropower production and physical trading aspects is developed. The idea is to explore the effects of including uncertainty explicitly into optimization by comparing the stochastic approach to a deterministic approach. The model is illustrated with data from a Norwegian hydropower producer and the Nordic power market at Nord Pool. 2006 Elsevier B.V. All rights reserved.	integer programming;linear programming;mathematical optimization;point of view (computer hardware company);programming model;stochastic programming	Stein-Erik Fleten;Trine Krogh Kristoffersen	2007	European Journal of Operational Research	10.1016/j.ejor.2006.08.023	stochastic programming;data modeling;electrical network;mathematical optimization;simulation;systems modeling;integer programming;market price;economics;bidding;electricity market;scenario;operations management;hydroelectricity;linear model;mathematics;economy	AI	5.268833994728139	-3.567901798820308	57204
ee889aba7f89c12df875744932a728969b999ac3	on the optimization of supply chain networking decisions	core competencies;product distribution;mixed integer program;theory of the firm;mathematical programming;network model;networking;mixed integer programming;extended enterprise;supply chain;value function;supply chain network;production cost;supply chain strategy	Companies strive to position themselves to maximize the value they add to the supply chains in which they are embedded. This raises strategic questions such as: Which durable resources should be developed to enhance current core competencies? Which activities should be externalized and to which potential partner should they be given? Which internal activities should be preserved and developed? How should the resources of the enterprise be allocated to activities? The aim of this paper is to propose a mathematical programming model of the extended enterprise which can be used to investigate this type of strategic networking issues. A number of general network modeling constructs are ®rst proposed. A model to optimize the supply chain structure under speci®c assumptions on the nature of production, cost and value functions in typical production/distribution companies is then derived. A heuristic to obtain solutions from the model is also presented. Finally, an example based on a refrigerator company is used to illustrate the usefulness of the approach. Ó 2001 Elsevier Science B.V. All rights reserved.	embedded system;extended enterprise;heuristic;mathematical optimization;programming model;supply chain network	Salem Y. Lakhal;Alain Martel;Ossama Kettani;Muhittin Oral	2001	European Journal of Operational Research	10.1016/S0377-2217(00)00223-X	mathematical optimization;integer programming;economics;product distribution;service management;computer science;marketing;operations management;network model;mathematics;supply chain;bellman equation;core competency;theory of the firm	AI	1.196577554051682	-4.605861683591936	57504
b1fbee6fc6f16909f1bae647abad2a79b223d98d	burn-in and the performance quality measures in heterogeneous populations	reliability;performance quality measures;burn in;heterogeneous population;stochastic order;failure rate;quality measures;reliability burn in heterogeneous population stochastically ordered subpopulations performance quality measures;stochastically ordered subpopulations	Burn-in is a widely used engineering method of elimination of defective items before they are shipped to customers or put into field operation. Under the assumption that a population is described by the decreasing or bathtub-shaped failure rate functions, various optimal burn-in problems have been intensively studied in the literature. In this paper, we consider a new model and assume that a population is composed of stochastically ordered subpopulations described by their own performance quality measures. It turns out that this setting can justify burn-in even in situations when it is not justified in the framework of conventional approaches. For instance, it is shown that it can be reasonable to perform burn-in even when the failure rate function that describes the heterogeneous population of items increases and this is one of the main and important findings of our study.	burn-in;population	Ji Hwan Cha;Maxim Finkelstein	2011	European Journal of Operational Research	10.1016/j.ejor.2010.09.019	operations management;failure rate;reliability;mathematics;burn-in;welfare economics	Robotics	8.506668037102454	-1.5039287284117793	57656
191fbeaacd5865a5a60d678d91b71e8d551422d4	a discriminated release strategy for parking variable message sign display problem using agent-based simulation	road traffic control intelligent transportation systems multi agent systems;reliability space exploration space vehicles roads sun;agent based simulation parking guidance and information system parking vms guiding reliability discriminated release strategy;waiting time parking variable message sign display problem intelligent transportation systems its parking guidance and information system parking vms pgis space availability information driver response model parking information guiding efficiency driver assistance vacant spaces discriminated release strategy space occupancy indicator soi agent based simulation parking choice model traffic assignment algorithm reliability strategies parking lot	With the development and application of intelligent transportation systems (ITS), parking guidance and information system (PGIS) has become a hot topic for research and applications. Parking variable message sign (parking VMS) is the most common form of PGIS currently in use, particularly in providing the space availability information to en-route drivers. The aim of this study is to model drivers' responses to the parking VMSs under various parking information in a dynamical way. To ensure the guiding efficiency and assist drivers to identify parking lots with vacant spaces, the display strategies of parking VMS were studied. A discriminated release strategy with a space occupancy indicator (SOI) was then proposed to determine the display content on the parking VMS, in which an agent-based simulation was introduced to incorporate both parking choice model and traffic assignment algorithm dynamically. Guiding reliability and display strategies were further analyzed to attain a discriminated release strategy with SOI effectively. The results indicate that the guiding reliability was improved by reducing the SOI value of the corresponding parking lot, and the relatively uniform guiding reliabilities of all parking lots were attained by modifying SOI values iteratively. Additionally, the performance by incorporating the waiting time into the parking choice model was investigated and recommended. The discriminated release strategy presented in this study will assist in designing and operating urban PGIS.	agent-based model;algorithm;choice modelling;information system;simulation	Daniel Jian Sun;Xun-You Ni;Lihui Zhang	2016	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2015.2445929	simulation;engineering;parking guidance and information;transport engineering;computer security	HCI	9.317993899504298	-7.529265217023224	57746
2d232182beb73e32f0cb8211055ae0fbe2c0d2b6	optimal system design with mc2 linear programming: a dual contingency plan approach	design model;optimal solution;optimal systems;metodo simplejo;concepcion sistema;transfer pricing;simplex method;multiple criteria;methode simplexe mc2;multiple constraints;programacion lineal;system design;plan contingence dual optimal;linear programming;programmation lineaire;linear program;resource availability;methode simplexe;conception systeme;systeme optimal	Given a system design problem with multiple criteria and multiple resource availability levels, we use the multiple-criteria and multiple-constraint level (MC*> simplex method to identify a set of potentially good systems as candidates for the optimal system. Each potentially good system is a subset of a given opportunity set and optimizes the design model under some changes of resource availability levels and the unit contribution of selected opportunities. As the contribution of an opportunity can fluctuate and lead to a non-optimal solution, the optimal dual contingency plans must be constructed to cope with the fluctuation. In this paper, we present a method of effectively and systematically constructing optimal dual contingency plans for given potentially good systems by adjusting the unit contribution of the selected opportunities. International transfer pricing is used to exemplify the method.	computation;contingency plan;exemplification;institute for operations research and the management sciences;justin (robot);lecture notes in computer science;linear programming;linear system;prototype;quantum fluctuation;simplex algorithm;slack variable;systems design;time complexity	Yong Shi	1998	European Journal of Operational Research	10.1016/S0377-2217(97)00092-1	mathematical optimization;linear programming;operations management;mathematics;simplex algorithm;algorithm;systems design	Robotics	5.663650433104035	-3.0633057535489465	57852
fd77e4534c8ab266c37f20da58e8533e7bcfa131	general electric uses an integrated framework for product costing, demand forecasting, and capacity planning of new photovoltaic technology products	forecasting;facilities planning;capacity planning;cost analysis;mathematical programming;risk;general electric;production cost;capital budgeting;demand forecasting	General Electric (GE) Energy's nascent solar business has revenues of over $100 million, expects those revenues to grow to over $1 billion in the next three years, and has plans to rapidly grow the business beyond this period. GE Global Research (GEGR), in partnership with GE Energy's solar platform team, is pursuing a number of technological alternatives to bring new low-cost solar products to the market. However, the GE solar business is facing a challenge---making optimal investment decisions to realize its growth objectives in the presence of major uncertainties in technology, costs, demands, and energy policy. We have developed analytical decision support tools with embedded mathematical models to estimate product costs and demands, and to support capacity planning decisions under cost and demand uncertainties. In this paper, we outline our algorithmic approach and system implementation, which help to support strategic decisions at GE.		Bex George Thomas;Srinivas Bollapragada	2010	Interfaces	10.1287/inte.1100.0518	actuarial science;economics;demand forecasting;forecasting;cost–benefit analysis;marketing;operations management;risk;capital budgeting;management;operations research;commerce	Robotics	4.647946579595832	-7.292896701056701	58134
b459707dfdf016ddb45fb2f722e85ca150e85c7a	impact of e-book technology: ownership and market asymmetries in digital transformation	information good;economic analysis;channel competition;game theory;market share;e commerce;e books;ownership;consumer preference;information goods;strategic interaction;product differentiation;digital goods;transformation;book industry	The book industry is undergoing a digital transformation enabled by the Internet and e-book technology, which offers a novel channel for delivering books to consumers who mostly purchase paper books from physical or online bookstores. With a game theory model that introduces the concepts of paper book market asymmetry and e-book market asymmetry, we examine how the entry of an e-book seller affects strategic interaction in the book markets and impacts sellers and consumers. We show that market asymmetries, ownership of the e-book seller, and consumers’ preferences for e-books are important determinants of prices, market shares and total book readership. We find that prices in the book market may increase after the e-book entry. Total readership may decrease after e-book entry, if the e-book seller is owned by one of the paper book sellers. The lowest total readership occurs when the online paper book seller owns the e-book seller. 2010 Elsevier B.V. All rights reserved. ‘‘Like many other parts of the media industry, publishing is being radically reshaped by the growth of the Internet. Online retailers are already among the biggest distributors of books. Now e-books threaten to undermine sales of the old-fashioned kind.” (The Economist 2010)	book;e-book;game theory;internet;online shopping	Yabing Jiang;Evangelos Katsamakas	2010	Electronic Commerce Research and Applications	10.1016/j.elerap.2010.06.003	industrial organization;e-commerce;game theory;economics;marketing;information good;commerce	ECom	-2.663701143023089	-7.504741681450913	58227
80000b6ac5680c096bc86589bade217df0621d58	smart routing in smart grids		Electric vehicles (EVs) are expected to be a major component of the smart grid. The rapid proliferation of EVs will introduce an unprecedented load on the existing electric grid due to the charging/discharging behavior of the EVs, thus motivating the need for novel approaches for routing EVs across the grid. In this paper, a novel game-theoretic framework for smart routing of EVs within the smart grid is proposed. The goal of this framework is to balance the electricity load across the grid while taking into account the traffic congestion and the waiting time at charging stations. The EV routing problem is formulated as a repeated noncooperative game. For this game, it is shown that selfish behavior of EVs will result in a pure-strategy Nash equilibrium with the price of anarchy upper bounded by the “variance” of the ground load induced by the residential, industrial, or commercial users. Moreover, the results are extended to capture the stochastic nature of induced ground load as well as the subjective behavior of the owners of EVs as captured by using notions from the behavioral framework of prospect theory. Simulation results provide new insights on more efficient energy pricing at charging stations and under more realistic grid conditions.	anarchy;extended validation certificate;game theory;nash equilibrium;network congestion;routing;simulation;time complexity	Seyed Rasoul Etesami;Walid Saad;Narayan B. Mandayam;H. Vincent Poor	2017	2017 IEEE 56th Annual Conference on Decision and Control (CDC)	10.1109/CDC.2017.8264036	mathematical optimization;grid;smart grid;efficient energy use;bounded function;distributed computing;prospect theory;computer science;price of anarchy;nash equilibrium;traffic congestion	Robotics	1.7197099783717607	3.6948794220912067	58256
32a509408513975ae6dada5cb34c4eecf5891444	traccs: a framework for trajectory-aware coordinated urban crowd-sourcing	mobile tasking;mobile crowdsourcing;centralized planning;crowdsourcing;orienteering problem	We investigate the problem of large-scale mobile crowd-tasking, where a large pool of citizen crowd-workers are used to perform a variety of location-specific urban logistics tasks. Current approaches to such mobile crowd-tasking are very decentralized: a crowd-tasking platform usually provides each worker a set of available tasks close to the worker's current location; each worker then independently chooses which tasks she wants to accept and perform. In contrast, we propose TRACCS, a more coordinated task assignment approach, where the crowd-tasking platform assigns a sequence of tasks to each worker, taking into account their expected location trajectory over a wider time horizon, as opposed to just instantaneous location. We formulate such task assignment as an optimization problem, that seeks to maximize the total payoff from all assigned tasks, subject to a maximum bound on the detour (from the expected path) that a worker will experience to complete her assigned tasks. We develop credible computationally-efficient heuristics to address this optimization problem (whose exact solution requires solving a complex integer linear program), and show, via simulations with realistic topologies and commuting patterns, that a specific heuristic (called Greedy-ILS) increases the fraction of assigned tasks by more than 20%, and reduces the average detour overhead by more than 60%, compared to the current decentralized approach.	crowdsourcing	Cen Chen;Shih-Fen Cheng;Aldy Gunawan;Archan Misra;Koustuv Dasgupta;Deepthi Chander	2014			real-time computing;simulation;computer science;artificial intelligence;machine learning;crowdsourcing	Vision	3.7562177311730602	0.6906058876572514	58314
1798420271aaa480c6525b3857874c99b926b42c	comparing securitized and balance sheet loans: size matters	structured finance;commercial mortgage backed securities	Do securitized loans differ from loans held on lenders’ balance sheets? If so, why? We assemble a unique dataset of commercial mortgages with information on loan characteristics at origination and subsequent performance. The most significant difference between securitized (CMBS) and balance sheet loans is the loan size. The largest loans are 42 percentage points more likely to be securitized than the smallest loans, which is consistent with diversification being a key motive for securitization. A structural model reveals little evidence that securitized loans carry greater distress risk. However, CMBS defaults are less likely to get resolved, pointing to agency issues.	color balance;diversification (finance);inventory	Andra Ghent;Rossen Valkanov	2016	Management Science	10.1287/mnsc.2015.2260	financial economics;economics;finance;financial system;structured finance;commercial mortgage-backed security	Metrics	-2.4312220491752825	-8.316405462123864	58345
69b3efe05c855c8c5e3f46924a1a7542eff13621	multiperiod optimization for the design and planning of multiproduct batch plants	multiproduct batch plants;raw materials;seasonality;batch process;batch process design;point of view;seasonal effect;multiperiod optimization;optimization model	This paper presents a general multiperiod optimization model, which simultaneously solves the design and planning decisions in multiproduct batch plants. Therefore, the trade-offs between both problems are taken into account as well as variations due to seasonal effects, demand patterns, etc.#R##N##R##N#From the design point of view, the model is formulated considering batch and semicontinuous units, the allocation of intermediate storage, and structural decisions. Following the usual procurement policy, equipment is provided using discrete sizes. From the planning point of view, the formulation takes into account both products and raw materials inventories, product demands and raw materials supplies that vary seasonally in a multiperiod approach.#R##N##R##N#The objective is the maximization of an economic function, which considers incomes, and both investment and operation costs. A plant that produces five oleoresins in seven stages is used to illustrate this approach.	mathematical optimization	Marta Susana Moreno;Jorge Marcelo Montagna;Oscar Alberto Iribarren	2007	Computers & Chemical Engineering	10.1016/j.compchemeng.2006.10.003	mathematical optimization;computer science;industrial engineering;raw material;mathematics;seasonality;statistics;batch processing	AI	9.443224358404406	-3.1443526167916445	58473
ec64d255453f2bf221a990029d7dbce446d174b2	arebic: autonomous reservation-based intersection control for emergency evacuation		Connected vehicle (CV) and autonomous vehicle (AV) technologies are rapidly advancing. Traffic control for future hurricane evacuation can be radically different compared to the current approaches in use. Extensive modeling research and limited field deployments have demonstrated the benefits of CV, AV technologies in achieving higher mobility, safety, and environmentally friendly solutions. One area that has not been explored in prior research is the benefits these technologies may offer to the emergency evacuation performance. Specifically, evacuation traffic control is one area where CV and AV technologies can have a transformative effect. At-grade intersections and grade-separated interchanges on evacuation routes are susceptible to congestion due to the increased demand competing for road usage. Traffic control methods that efficiently route traffic at intersections and interchanges also enhance the overall evacuation performance. This paper proposes an autonomous reservation-based intersection control (AReBIC) system for evacuation traffic control. The AReBIC system receives and processes reservation requests from approaching vehicles in real-time and routes them free of conflict. The results of a case study of Hampton Roads, Virginia, showed that the AReBIC system outperformed the existing traffic control practice in terms of mobility and safety. The average speeds increased by 29% and total delays reduced by 88% when intersection control was changed to the AReBIC system. The number of crossing conflicts decreased by 88% and lane change conflicts decreased by 47%.	algorithm;autonomous robot;centralized computing;control system;freeway;matlab;network congestion;ramp simulation software for modelling reliability, availability and maintainability;real-time clock;software deployment	Yohan Chang;Praveen Edara	2017	2017 IEEE Intelligent Vehicles Symposium (IV)	10.1109/IVS.2017.7995980	simulation;transport engineering;environmentally friendly;emergency evacuation;hurricane evacuation;reservation;business	Embedded	9.64768344510592	-8.990495575804424	58517
4ac5c5ff34d34d8947fedadd1841c9247b5efc4f	online consumer's optimal purchasing decisions under contingent free delay shipping	analytical models;psychology;sensitivity;internet;economics;delays	This paper considers the optimal purchasing decisions of a consumer when online retailers provide contingent free shipping service under delay delivery. A consumption decision model for online consumers is proposed by establishing net consumption surplus function under delay delivery, which comprehensively considering all of the conditions including the product price, delay time, free shipping threshold given by online retailers, as well as the consumer's individual characteristics relate to the preference for the product and sensitivity on delay delivery, which can be used to analyze the best purchasing decisions of an online consumer. Finally, a numerical example proves the reliability of the model, and the result shows that a consumer's optimal purchasing decisions mainly depend on the comparison of free shipping cut off level under delay delivery and consumer's specific parameter about the preference for the product and sensitivity on delay time. Simultaneously, it indicates that free delay shipping service with a reasonable threshold could attract additional consumers with middle consumption desire to enlarge purchasing amount, which can be used as a reference for online retailers to set an effective free delay shipping strategy.	contingency (philosophy);delay-gradient congestion control;numerical analysis;online shopping;purchasing	Qianqian Liu;Wenliang Bian	2016	2016 International Conference on Logistics, Informatics and Service Sciences (LISS)	10.1109/LISS.2016.7854483	marketing;advertising;business;commerce	EDA	0.7774694532490833	-6.0146412360742785	58598
5df5938a804cdf909555eff92bde60ea3c33314b	a budget balanced energy distribution mechanism among consumers and prosumers in microgrid	convergence;resource management;smart grids;games;linear programming;optimization;microgrids	Energy trading is a key feature of the emerging smart grid system. In this paper, we propose an energy allocation mechanism for energy trading among competing consumers and prosumers, i.e. agents, in a microgrid. The proposed mechanism is modeled for rational agents with hidden private information, aiming to optimize self-utility and payoff. We achieve this goal through the presence of a central impartial aggregator whose aim is to accomplish an efficient, price uniform, individually rational, and budget balanced trading among agents.	iteration;microgrid;nash equilibrium;news aggregator;personally identifiable information;rational agent;rationality	M. Nazif Faqiry;Sanjoy Das	2016	2016 IEEE International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData)	10.1109/iThings-GreenCom-CPSCom-SmartData.2016.119	games;convergence;computer science;linear programming;resource management;smart grid	Robotics	0.1368217649492199	3.8683615815893466	58892
19d788716ca64fbcdb80855fa4ae8e58f91182c8	eisenberg-gale markets: rationality, strongly polynomial solvability, and competition monotonicity	directed graph;network coding;binary search;convex programming	We study the structure of EG[2], the class of Eisenberg-Gale markets with two agents. We prove that all markets in this class are rational and they admit strongly polynomial algorithms whenever the polytope containing the set of feasible utilities of the two agents can be described via a combinatorial LP. This helps resolve positively the status of two markets left as open problems by [JV]: the capacity allocation market in a directed graph with two source-sink pairs and the network coding market in a directed network with two sources. Our algorithms for solving the corresponding nonlinear convex programs are fundamentally different from those obtained by [JV]; whereas they use the primal-dual schema, we use a carefully constructed binary search. We also settle a third open problem of [JV], that of determining whether the notion of competition monotonicity characterizes the class of SUA markets within UUA markets. We give a positive resolution of this problem as well.	binary search algorithm;convex optimization;directed graph;linear network coding;nist hash function competition;nonlinear system;polynomial;rationality;time complexity	Deeparnab Chakrabarty;Nikhil R. Devanur;Vijay V. Vazirani	2006	Electronic Colloquium on Computational Complexity (ECCC)		binary search algorithm;combinatorics;discrete mathematics;linear network coding;mathematics;rationality;directed graph;monotonic function;convex optimization;polynomial;square-free polynomial	ECom	-3.6521917896489784	-0.5369145150159365	58949
ec709bc80830cecaf0436026ba7bf691617fe01b	on the range of options prices	martingale measures;incomplete model;option pricing;interest rate;martingale measure;stock price;purely discontinuous process;convex function;contingent claim valuation;equivalent martingale measure;contingent claim	In this paper we consider the valuation of an option with time to expirationT and pay-off functiong which is a convex function (as is a European call option), and constant interest rate r , in the case where the underlying model for stock prices ( St ) is a purely discontinuous process (hence typically the model is incomplete). The main result is that, for “most” such models, the range of the values of the option, using all possible equivalent martingale measures for the valuation, is the interval ( e−rT g(erT S0),S0), this interval being the biggest interval in which the values must lie, whatever model is used.	contingency (philosophy);convex function;kullback–leibler divergence;risk-neutral measure;value (ethics)	Ernst Eberlein;Jean Jacod	1997	Finance and Stochastics	10.1007/s007800050019	financial economics;convex function;actuarial science;economics;martingale pricing;valuation of options;interest rate;martingale difference sequence;welfare economics;local martingale	Theory	1.1756417664462648	-2.6151059009871847	59058
313edd3d23def6bbfd292d72ddd7b7db7c54e62f	effect of strategic grading and early offers in matching markets		Strategic suppression of grades, as well as early offers and contracts, are well-known phenomena in the matching process where graduating students apply to jobs or further education. In this paper, we consider a game theoretic model of these phenomena introduced by Ostrovsky and Schwarz, and study the loss in social welfare resulting from strategic behavior of the schools, employers, and students. We model grading of students as a game where schools suppress grades in order to improve their students’ placements. We also consider the quality loss due to unraveling of the matching market, the strategic behavior of students and employers in offering early contracts with the goal to improve the quality. Our goal is to evaluate if strategic grading or unraveling of the market (or a combination of the two) can cause significant welfare loss compared to the optimal assignment of students to jobs. To measure welfare of the assignment, we assume that welfare resulting from a job – student pair is a separable and monotone function of student ability and the quality of the jobs. Assuming uniform student quality distribution, we show that the quality loss from the above strategic manipulation is bounded by at most a factor of 2, and give improved bounds for some special cases of welfare functions. ∗hedyeh@cs.cornell.edu, Dept of Computer Science, Cornell University. Supported in part by NSF grants CCF0910940. †nishanthd@csail.mit.edu, Dept of Electrical Engineering and Computer Science, Massachusetts Institute of Technology. research was done while visiting Cornell university, supported by NSF grant CCF-0910940. ‡eva@cs.cornell.edu, Dept of Computer Science, Cornell University. Supported in part by NSF grants CCF0910940 and CCR-1215994), ONR grant N00014-08-1-0031, a Yahoo! Research Alliance Grant, and a Google Research Grant. ar X iv :1 50 7. 02 71 8v 1 [ cs .G T ] 9 J ul 2 01 5	computer science;game theory;ibm notes;job stream;langrisser schwarz;zero suppression;monotone	Hedyeh Beyhaghi;Nishanth Dikkala;Éva Tardos	2015		10.1007/978-3-662-48433-3_24	public economics;commerce	Theory	-1.97067320249826	-1.9142849096225827	59075
6b39161e45899b9a8a94dde9a8007b4fdb264839	analysis of the economic benefit of used batteries based on reverse logistics	economic benefit;reverse logistic;smilp;used batteries	Facing the increasing serious environmental problem, it is imminent to carry out the reverse logistics of used batteries. It is a big challenge for government to promote the enterprises to recovery used batteries effectively. Based on the processes of reverse logistics, the paper creates mixed integer liner programming (SMILP) and designs the best reverse logistics network in different recovery rate which can make the enterprises obtain the best economic benefit. Through analyzing the result, the paper provides an effective basis for government to make the recycling policy and punish policy.	logistics	Xianliang Shi;Zhihua Li	2011			process management;marketing;computer science;reverse logistics	Crypto	3.564412159844954	-9.006895353679598	59314
99c56af98b5cc1dee324022b4be82361050c91ad	test duration in choice of helicopter maintenance policy	mean time between failure;sample size;reliability centred maintenance;sequential test;mean time between failures ratio;operating characteristic;sequential testing;failure rate;error probability	In the course of a review of the maintenance policy for a certain type of helicopter, it was found necessary to determine whether the frequency of one of the scheduled tests could be reduced without a shorter mean time between failures (MTBF). A sequential-testing procedure was worked out for an experiment in which hypotheses on the ratio of the respective MTBFs under the new and present maintenance policies are to be verified. In it, two groups of helicopters, subjected to the respective maintenance systems, are observed (Manipulation of two groups in parallel neutralizes the effect of uncontrolled factors, such as variation of the helicopters' operational load and the maintenance-quality level). It is assumed that the failure rates are constant. A decision-making algorithm, and a  matlab  program, were constructed. The program yielded the decision parameters, densities and mean test duration up to the positive/negative decision in dependence on the actual MTBF ratio, the permissible level of the latter, and the given error probability levels. Prediction of the test duration, together with the operating characteristic, permits more rational planning of the experiment, hence of the maintenance policy.		Yefim Haim Michlin;R. Migdali	2004	Rel. Eng. & Sys. Safety	10.1016/j.ress.2004.01.006	sample size determination;reliability engineering;mean time between failures;maintenance-free operating period;engineering;probability of error;sequential analysis;failure rate;mathematics;forensic engineering;statistics	Logic	7.477531448242123	-1.3163788014475806	59527
e5275316c8269545a23b0a724f67545c5d496927	the infinite horizon non-stationary stochastic inventory problem: near myopic policies and weak ergodicity	processus non stationnaire;ergodicite;near myopic policies;dynamic inventory problem;proceso markov;non stationary markov decision processes;infinite horizon inventory problem;decision markov;non stationary demands;infinite horizon inventory problems;demande non stationnaire;processus markov;markov process;ergodicidad;markov decision;infinite horizon;near myopic policy;non stationary process;markov decision process;error bound;numerical experiment;ergodicity;proceso no estacionario	In this paper we consider a periodic review dynamic inventory problem with non-stationary demands. The purpose of this paper is to show that near myopic policies are sufficiently close to optimal decisions for the infinite horizon inventory problem. In order to show this we pay attention to the fact that inventory processes with base-stock policies are weakly ergodic, and we discuss how the weak ergodicity is related to near myopic policies. Then we derive the error bounds of near myopic policies for the optimal decisions and evaluate them with a number of numerical experiments.	ergodicity;stationary process	Tetsuo Iida	1999	European Journal of Operational Research	10.1016/S0377-2217(98)00129-5	markov decision process;mathematical optimization;economics;ergodicity;computer science;operations management;mathematics;markov process;mathematical economics;statistics	AI	3.127867752857867	-2.4841010122606573	59651
df59fa6a7b76d8b323ef64649152e8fc943ec4c8	optimal aviation security screening strategies with dynamic passenger risk updates	security airports feedback monte carlo methods risk analysis;security performance optimal aviation security screening strategy dynamic passenger risk updates aviation security systems multistage sequential passenger screening problem mspsp carry on baggage screening operations passenger screening operation airport terminal screening stages passenger assessed threat value automated passenger prescreening system passenger screening decisions passenger perceived risk levels security device performance parameters optimal policy screening passengers optimal sequential assignment theory monte carlo simulation based heuristic stochastic sequential assignment feedback control algorithms computational analysis two stage security system;aviation security;performance evaluation;risk analysis;airports;simulation;risk management;fixed time;random variables;optimal policy;optimal sequential assignment;feedback;security airports random variables atmospheric modeling monte carlo methods performance evaluation risk management;passenger screening;monte carlo method;perceived risk;baggage screening;secure system;random variable;aviation;optimization;computer analysis;atmospheric modeling;monte carlo simulation;security;feedback control;monte carlo methods;policy modeling aviation security monte carlo simulation optimal sequential assignment;policy modeling	Passenger screening is a critical component of aviation security systems. This paper introduces the multistage sequential passenger screening problem (MSPSP), which models passenger and carry-on baggage screening operations in an aviation security system with the capability of dynamically updating the perceived risk of passengers. The passenger screening operation at an airport terminal is subdivided into multiple screening stages, with decisions made to assign each passenger to one of several available security classes at each such stage. Each passenger's assessed threat value (initially determined by an automated passenger prescreening system) is updated after the passenger proceeds through each screening stage. The objective of MSPSP is to maximize the total security of all passenger screening decisions over a fixed time period, given passenger perceived risk levels and security device performance parameters. An optimal policy for screening passengers in MSPSP is obtained using optimal sequential assignment theory. A Monte Carlo simulation-based heuristic is presented and compared with stochastic sequential assignment and feedback control algorithms. Computational analysis of a two-stage security system provides an assessment of the total security performance.	airport security;algorithm;computation;feedback;heuristic;monte carlo method;multistage amplifier;simulation;virtual screening	Alexander G. Nikolaev;Adrian J. Lee;Sheldon H. Jacobson	2012	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2011.2167230	simulation;risk management;engineering;mathematics;transport engineering;statistics;monte carlo method	ML	8.550961563883272	-0.14384772725272818	59683
5305ded99caa2d58aa6641f954380e38e356f7fc	a margin calculation method for illiquid products		The role of the central counterparties (CCPs) on the market is to take over the counterparty risk during the trading on stock exchanges. CCPs use a multilevel guarantee system to manage this risk. The margin has a key role in this guarantee system, and the paper will focus only on this level. The main motivation of this paper is to introduce a potential margin calculation method which is compliant with the EMIR regulation and also does not put unnecessary burden on the market participants. We will introduce this method for two special type of products: (1) the illiquid products and (2) for the case of initial public offerings (IPOs). The specialty of these two product types, that there is no available historical time series of the securities’ prices, so no risk management models can be used by the CCPs to calculate the margin. REQUIREMENTS OF THE REGULATOR AND	backtesting;counterparty;estimation theory;regulation a;risk management framework;risk measure;statistical relational learning;time series	Marcell Beli;Csilla Szanyi;Kata Váradi	2017		10.7148/2017-0100	financial economics;economics	ML	1.3986272905636654	-9.349694828031787	59813
9a7e301d79c6226349d50275c0a28085d618191d	slam applications in economic modeling of large investment projects	economic evaluation;discount rate;pollution control;risk analysis;standard deviation;economic model;operations research;major element;upper bound;power plant;construction cost;synthetic natural gas;model building;beta distribution;probability distribution;network model;model development;general electric;resource availability;fortran;technical report;cash flow;network structure;oil price;monte carlo simulation;simulation model;operation and maintenance;program development;discrete event;lower bound;monte carlo analysis;industrial engineering;analytical model	SLAM (Simulation Language for Alternative Modeling) is a Fortran-based language with network, discrete event, and continuous modeling capabilities. This simulation language has been widely used in industrial engineering and operations research. Applications of SLAM are also of great value in the economic modeling of large investment projects. The use of SLAM for simulating cash flows facilitates the development of the necessary computer code to test and validate economic risk analysis. The unique process orientation of SLAM employs a network structure comprised of special symbols called nodes and branches in a manner similar to Q-GERT. The modeling task consists of combining these symbols into a network model which pictorially represents the system of interest. Due to the flexibility inherent in SLAM the complexities involved with programming non-deterministic economic models are substantially reduced. As a Fortran-based simulation language SLAM provides the option of processing and analyzing the input data through Fortran subroutines within the program. This paper reviews Monte Carlo simulation models developed for: (a) the economic comparison of oil and coal power plants with emphasis on examining the cost of pollution control; (b) studying the economic feasibility of using coal to produce synthetic natural gas; and (c) an economic evaluation of using synthetic natural gas to produce electricity. An extensive analytical model was developed as a basis for each of these simulation models in which the inflated capital, fuel, and operating and maintenance costs were accounted for to calculate the equivalent annual cost of cash flows over the project life. Major elements of uncertainty were identified and the associated probability distributions were estimated in terms of “optimistic”, “pessimistic”, and “most likely” values. It was assumed that these three estimates correspond to the “upper bound”, “lower bound”, and “mode”, respectively, of a Beta distribution with a standard deviation equal to one-sixth (1/6) of the spread between the lower and the upper bounds. A sufficiently large number of Monte Carlo simulation trials was selected to reduce sampling variation to an acceptable level in view of the accuracy needed and resource availability. The distributions resulting from the Monte Carlo analysis were compared for all alternatives. Then the interrelationship and sensitivity of these alternatives to changes in the input parameters were analyzed. According to the results achieved with 300 observations in a simulation run, the expected equivalent annual cost of the oil power plant was higher than that of the coal power plant. The same conclusion was reached with the standard deviations of costs of the two alternatives, indicating that the risk involved with the oil power plant is higher than the associated risk with the coal power plant. The construction costs, expected escalation rates for fuel, operating and maintenance costs, load factors, and discount rates were identified as the parameters significantly influencing the final results. In the second application, synthetic fuel production was subject to many technological uncertainties, and was found to be economically unattractive. The costs associated with generating electricity by using synthetic natural gas were found to be substantially higher than the respective costs related to oil burning power plants. However, assuming higher oil prices, the economic feasibility of producing synthetic natural gas from coal increases substantially. The selection of SLAM as the simulation language simplified the programming effort. A significant advantage of the program developed for this study is its flexibility and capability of handling various conditions when evaluating the economics of large investment projects. Development of an interactive version of SLAM could put the package at the reach of a wider range of users. The role of the user would be reduced to selecting options offered by the program and to entering the data pertaining to his specific case, without having to master the SLAM simulation language. TESS (The Extended Simulation System) has been developed to complement SLAM capabilities. TESS supports all aspects of SLAM simulation including model building, execution of simulation runs, and statistical output analyses. TESS also provides color graphics for the statistical output analyses.	apple ii graphics;emoticon;fortran;industrial engineering;monte carlo method;network model;operations research;optimistic concurrency control;privilege escalation;sampling (signal processing);sensitivity and specificity;simulation language;simultaneous localization and mapping;subroutine;synthetic intelligence	Mehdi Manesh	1985		10.1145/21850.253925	simulation;computer science;engineering;mathematics;upper and lower bounds;operations research;statistics;monte carlo method	Robotics	6.2439847302457965	-7.134295987359724	60018
73e445523078d0aafe23348a3b1046e14fcc649f	a risk management system for sustainable fleet replacement	risk management;conditional value at risk cvar;decision support systems;sustainable operations;stochastic programming;fleet replacement	This article analyzes the fleet management problem faced by a firm when deciding which vehicles to add to its fleet. Such a decision depends not only on the expected mileage and tasks to be assigned to the vehicle but also on the evolution of fuel and CO2 emission prices and on fuel efficiency. This article contributes to the literature on fleet replacement and sustainable operations by proposing a general decision support system for the fleet replacement problem using stochastic programming and conditional value at risk (CVaR) to account for uncertainty in the decision process. The article analyzes how the CVaR associated with different types of vehicle is affected by the parameters in the model by reporting on the results of a real-world case study.	risk management	Amir H. Ansaripoor;Fernando S. Oliveira;Anne Liret	2014	European Journal of Operational Research	10.1016/j.ejor.2014.02.006	stochastic programming;mathematical optimization;simulation;decision support system;economics;risk management;computer science;operations management;mathematics;operations research	Theory	9.522323448347684	-3.203513186651579	60071
dcf509cf1650f10dd05ee64a7239b469b4fb11fe	long term implications of drug policy shifts: anticipating and non-anticipating consumers		We consider a semi-rational addiction model in which the user has perfect foresight over all things within the user’s control, but not necessarily with respect to exogenous parameter shocks, e.g., those stemming from changes in national policy. We show that addictive substances are more likely to have state-dependent solution trajectories, and that in turn can create path dependence at the macro-policy level; in particular, legalization may be an irreversible experiment. Also, in this model, shifting from a nuanced policy that differentiates between high and low intensity users, to a tougher one where the government makes life hard for every user reduces initiation considerably. However, it also may have perverse effects. In particular, we show that making the policy tougher in this way could drive some people from a ‘‘happy’’ stable saddle point equilibrium with moderate consumption into increasing rather than reducing their consumption and addiction stock. So implementing zero tolerance policies may increase rather than reduce aggregate drug use, depending on the population’s distribution of parameter values and initial consumption stocks. Further, we consider the impact of announcing a policy change. 2013 Elsevier Ltd. All rights reserved.	aggregate data;doppler effect;path dependence;privacy policy;semiconductor industry;steady state;stemming;switching time;unintended consequences	Jonathan P. Caulkins;Gustav Feichtinger;Richard F. Hartl;Peter M. Kort;Andreas J. Novak;Andrea Seidl	2013	Annual Reviews in Control	10.1016/j.arcontrol.2013.03.005	engineering;futures studies;control theory;legalization;government;population;stock (geology);path dependence;zero tolerance;national policy;microeconomics	AI	-0.7984757547066308	-8.378752724263919	60091
7ca3bb70525025bd227f3bf43e4baca9b9660cbc	bayesian and adaptive controls for a newsvendor facing exponential demand	partial observations;bayesian control;adaptive control;newsvendor model;optimal control;incomplete information;censored data;unnormalized probability;consistent estimators;unnormalized probabilities	"""The newsvendor problem is relatively easy to solve when the distribution of demand for newspapers is known. When the demand is unknown, the newsvendor faces a dual problem in the sense of Feldbaum (1960): to choose a decision variable that maximizes profit in the present period, and choose a large enough """"observation window"""" to be able to view the process correctly so that consistent parameter estimation can occur. This is a difficult problem in general. In this paper, we treat a special case when the newsvendor faces exponential demand, independently and identically distributed with unknown mean."""	newsvendor model;time complexity	Alain Bensoussan;Metin Çakanyildirim;Andrew Royal;Suresh P. Sethi	2009	Risk and Decision Analysis	10.3233/RDA-2009-0017	econometrics;mathematical optimization;newsvendor model;extended newsvendor model;economics;welfare economics	ML	1.5948242790388427	-3.9100389966268594	60308
45a4f14fdee891193f16d9ac1b9c9b76670c94b6	max k-armed bandit: on the extremehunter algorithm and beyond		This paper is devoted to the study of the max K-armed bandit problem, which consists in sequentially allocating resources in order to detect extreme values. Our contribution is twofold. We first significantly refine the analysis of the ExtremeHunter algorithm carried out in Carpentier and Valko (2014), and next propose an alternative approach, showing that, remarkably, Extreme Bandits can be reduced to a classical version of the bandit problem to a certain extent. Beyond the formal analysis, these two approaches are compared through numerical experiments.	algorithm;experiment;long tail;multi-armed bandit;numerical analysis;pareto efficiency;regret (decision theory)	Mastane Achab;Stéphan Clémençon;Aurélien Garivier;Anne Sabourin;Claire Vernade	2017		10.1007/978-3-319-71246-8_24		ML	7.155806196261106	1.9897564133062429	60372
610044891844f842a8f00d4449a41d65149b21e6	multi-period decision for hrp of an employee leasing center with one type of employees	dynamic programming;optimal solution;decision models;approximate algorithm;time complexity;approximation algorithms;dynamic programming algorithm;contracts;dynamic program;optimal control;approximation theory;human resource management paper technology contracts stochastic processes optimal control dynamic programming heuristic algorithms robotics and automation intelligent robots sun;employee leasing;stochastic optimization;trajectory;human resource planning;stochastic processes;heuristic algorithms;human resource;multi period decision;stochastic optimal control;time complexity human resource planning employee leasing center contract employee temporary employee manpower market recruitment dismissal factor multiperiod decision model stochastic constraint decision control stochastic optimal control dynamic programming heuristic approximate algorithm;planning;humans;stochastic processes approximation theory dynamic programming labour resources optimal control recruitment;dynamic programming employee leasing human resource planning multi period decision;recruitment;heuristic algorithm;optimal control problem;labour resources	This paper studies the issue of human resource plan in an employee leasing center. The center is engaged in the business of leasing its own contract employees and acting as an agent for flexible employees outside the center. The employees considered in this paper belong to one type of employees that are high-ranked and important for the firms. But this type of employees can be classified into two parts: the contract employees in the employee leasing center and the temporary employees in the manpower market. At first we take into account recruitment/dismissal factors and propose stochastically optimal multi-period decision model of the problem. In the model there are stochastic constraint conditions and the decision (control) in each period is the number of the contract employees that are recruited or dismissed by the center and the objective is to maximize the overall expected net revenue of the center over planning horizon. Then we transform the stochastic optimal control problem into the determined optimal control problem by transforming stochastic constraint conditions into determined constraint conditions. Furthermore we analyze the limits of the states in each period, develop a dynamic programming algorithm to search for an optimal solution to the problem and a heuristic approximate algorithm to find out an approximate optimal solution. Analyzing reveals that the heuristic algorithm is superior to the dynamic programming in time complexity. Finally, we use two algorithms to solve some simulating data case. The results reveal that the error between the two solutions is no more than 5% for each case.	approximation algorithm;dynamic programming;heuristic (computer science);mathematical optimization;optimal control;simulation;time complexity	Mei Han;Junqing Sun	2008	2008 10th International Conference on Control, Automation, Robotics and Vision	10.1109/ICARCV.2008.4795579	mathematical optimization;simulation;stochastic optimization;dynamic programming;mathematics	Robotics	5.473123727864115	0.6509769870903895	60522
c3df893d3439609ef9ae7edd0a7fb744f7e237a7	are all commercial websites created equal? web vendor reputation and security on third party payment use	trust;purchase intention;reputation;purchase decision;third party payment;security	New web vendors emerge daily as business-to-consumer e-commerce grows substantially over the years. However, new web vendors may be regarded with skepticism in an existing marketplace, and may require third party support to reduce uncertainty. This study investigates the effect of consumer’s perceived security and reputation of web vendors on consumer’s purchase intention and third party payment choice. Our study examines under what condition adopting a reputable third party payment system is beneficial to web vendors. Applying trust transference theory, we found that website with high reputation and high security may not benefit from having a third party payment presence, while website with low reputation and low security will benefit the most for having an alternative financial payment mechanism. Our study also found that online consumers tend not to choose to use third party payment system when the website is perceived as high security regardless of the reputation of the website.	e-commerce	Ruth C. King;Richard A. M. Schilhavy	2011			marketing;business;commerce	Security	-3.0586022019343315	-7.848515708289679	60537
91b9a34c802716da85c11b1e205e081516b3d05b	inventory control model for fresh agricultural products on weibull distribution under inflation and delay in payment	fresh agricultural products;inventory model;delay in payment;weibull distribution;food products;inflation;agriculture;inventory control;supply chain management	Purpose – The purpose of this paper is to research the influence of inflation and delay in payment on the inventory model on Weibull distribution and present a new method of inventory control model for fresh agricultural products. Design/methodology/approach – The previous researches deal with the inventory problems. However, these researches are based on deteriorating industrial products, so that the method for inventory model of agricultural products should be employed. According to agricultural products characteristics, the model assumes that deterioration is defined as fixed and demand is taken as Weibull distribution. An optimal order quantity and the minimum inventory total cost are formulated and solved under inflation and delay in payment. Findings – The minimum inventory total cost and the optimal ordering quantity are convex with the length of the period with positive stock. When the delay period is longer than the length of the period with positive stock, the minimum inventory total cost and the optimal ordering quantity increase with permissible delay in payment increase and decrease with inflation rate increase, changing steeply with inflation rate and increasing permissible delay. Research limitations/implications – The market demand of fresh agricultural products is on two-parameter Weibull distribution. Practical implications – The paper gives useful advice for agricultural supply chain managers. Originality/value – The paper presents a new method of inventory control for fresh agricultural products.	convex function;inventory control;inventory theory	Lijuan Wang;Hongwei Wang;Xi-chao Sun	2012	Kybernetes	10.1108/03684921211275306	inventory control;weibull distribution;inflation;agriculture;supply chain management;actuarial science;inventory valuation;inventory turnover	Metrics	2.3389239049806636	-5.1029326245521345	60594
d1644d6052229698a58d135e58c81cbe90892c08	an integrated approach to pricing, inventory, and market segmentation decisions with demand leakage		Differentiated pricing is among the widely practised Revenue Management (RM) tactics in which a firm offers its products/services at differentiated prices to distinct markets. Earlier researches have shown that the benefits from differentiated pricing are evident when the market segmentation is assumed perfect which are regarded as distinct markets with deterministic demands. In perfect market segmentation customers associated with a market segment do not cannibalize (move) between market segments. However, it is not uncommon to notice that the market segmentation a firm exercises is seldom perfect, and due to imperfect segmentation customers cannibalize between market segments which is also referred as demand leakage. In addition to this, the demand is often uncertain, and thus a firm also experiences short sales and leftovers due to uncertain demand. This research addresses the issue of establishing an integrated framework to optimize price differentiation strategy, pricing, and order quantity for a firm that experiences demand leakage. The models to determine the optimal market segmentation strategy, pricing, and order quantities for a firm are developed facing price dependent deterministic demand, stochastic demand, and when the demand is stochastic, yet the distribution is unknown. The models are analyzed to identify the optimal pricing, order quantities, and price differentiation strategy. Numerical experimentation show that optimizing the price differentiation strategy (market segmentation) along with optimizing the joint pricing and order quantity decisions price significantly improve the revenue to a firm although it experiences customer cannibalization. This paper, however, only highlights the deterministic model and its analysis.	spectral leakage	Syed Asif Raza	2012		10.1007/978-3-319-00795-3_58	mathematics;market segmentation;notice;mathematical optimization;leakage (electronics);cannibalization;deterministic system;microeconomics;revenue management;price discrimination;revenue	ECom	1.9292162085678854	-5.641288461205911	60651
ab61d8b7c5767562b9f61f0f5f7d24213cb4a5f4	portfolio management with minimum guarantees: some modeling and optimization issues	transaction cost;portfolio optimization;scenario;dynamic portfolio management;portfolio management;minimum guarantee	In this contribution we consider a dynamic portfolio optimization problem where the manager has to deal with the presence of minimum guarantee requirements on the performance of the portfolio. We briefly discuss different possibilities for the formulation of the problem and present a quite general formulation which includes transaction costs, cardinality constraints and buy-in thresholds. The presence of realistic and operational constraints introduces binary and integer variables greatly increasing the complexity of the problem.	bitwise operation;mathematical optimization;optimization problem;requirement	Diana Barro;Elio Canestrelli	2009		10.3233/978-1-60750-072-8-146	transaction cost;merton's portfolio problem;scenario;portfolio optimization;separation property;application portfolio management;black–litterman model;project portfolio management	EDA	4.440133693780636	-4.539134759939494	60787
f6361513b308a0df7a9ad93da0c4944aca73ccf4	an autonomous electric vehicle based charging system: matching and charging strategy		In this paper, we purpose an autonomous electric vehicle (AEVs) based charging navigation system. It accommodates charging requests by a fleet of AEVs in an integrated manner. We focus on one major problem of implementing such framework: matching between AEVs to electric vehicle charging stations (EVSEs) that minimize total operational cost. The problem is first formulated as a minimum weight perfect matching through creation of a bipartite graph that could be solved by integer programming. We further relax this to linear programming. To demonstrate effectiveness of such formulation, we implement the system with different use cases. We also propose two simple charging strategies that considers various factors, including charging price, current state of charge, and restrictions of power consumption added by utilities. Based on the system, we study their effects on the power grid and AEV owners.	autonomous robot;blossom algorithm;integer programming;linear programming relaxation;matching (graph theory);mathematical optimization;minimum weight;randomness;simulation;state of charge	Zhiyuan Cao;Chi-Cheng Peter Chu;Rajit Gadh	2018	2018 IEEE Power & Energy Society Innovative Smart Grid Technologies Conference (ISGT)	10.1109/ISGT.2018.8403365	grid;mathematical optimization;bipartite graph;matching (graph theory);state of charge;linear programming;integer programming;electric vehicle;navigation system;computer science	EDA	4.272416493516125	3.6933246253798444	60925
06e4ff025e8c0979f715eebb1e0b808857101593	approximate nash equilibria in anonymous games	nash equilibrium;approximation algorithms;anonymous games	We study from an algorithmic viewpoint anonymous games [Mil96, Blo99, Blo05, Kal05]. In these games a large population of players shares the same strategy set and, while players may have different payoff functions, the payoff of each depends on her own choice of strategy and the number of the other players playing each strategy (not the identity of these players). We show that, the intractability results of [DGP09a] and [Das11] for general games notwithstanding, approximate mixed Nash equilibria in anonymous games can be computed in polynomial time, for any desired quality of the approximation, as long as the number of strategies is bounded by some constant. In addition, if the payoff functions have a Lipschitz continuity property, we show that an approximate pure Nash equilibrium exists, whose quality depends on the number of strategies and the Lipschitz constant of the payoff functions; this equilibrium can also be computed in polynomial time. Finally, if the game has two strategies, we establish that there always exists an approximate Nash equilibrium in which either only a small number of players randomize, or of those who do, they all randomize the same way. Our results make extensive use of certain novel Central Limit-type theorems for discrete approximations of the distributions of multinonial sums. JEL Classification: C72 (Noncooperative Games)	approximation algorithm;nash equilibrium;polynomial;scott continuity;time complexity	Constantinos Daskalakis;Christos H. Papadimitriou	2015	J. Economic Theory	10.1016/j.jet.2014.02.002	price of stability;epsilon-equilibrium;mathematical optimization;combinatorics;traveler's dilemma;best response;trembling hand perfect equilibrium;coordination game;economics;folk theorem;repeated game;mathematics;correlated equilibrium;microeconomics;risk dominance;mathematical economics;equilibrium selection;symmetric game;approximation algorithm;nash equilibrium;symmetric equilibrium	ECom	-3.2793854542882075	-0.3325034724752828	61271
c00f9e12543fff8180b307341fa9c1891eabf727	auction algorithms		The auction algorithm is an intuitive method for solving the classical assignment problem. It outperforms substantially its main competitors for important types of problems, both in theory and in practice, and is also naturally well suited for parallel computation. In this article, we will skecth the basic principles of the algorithm, we will explain its computational properties, and we will discuss its extensions to more general network flow problems. For a detailed presentation, we refer to the survey paper [Ber92] and the author’s textbooks [Ber91], [Ber98]. For an extensive computational study, we refer to Castañon [Cas93]. The algorithm was first proposed in a 1979 report by the author [Ber79].	assignment problem;auction algorithm;computation;flow network;parallel computing	Dimitri P. Bertsekas	2009		10.1007/978-0-387-74759-0_22	auction algorithm;vickrey auction;combinatorial auction;generalized second-price auction;revenue equivalence;auction theory	ML	-2.310694475305816	-0.14036616036041255	61296
253cbf9cb2fe6cf369de5ecab7d96b8814b341d6	connections between markets and learning	game theory;utility;journal article;prediction market;matching	We provide an overview of recent research exploring the striking mathematical connections that exist between market maker mechanisms for prediction markets and no-regret learning. We describe how these connections can be used in the design of efficient prediction markets over combinatorial outcome spaces.		Yiling Chen;Jennifer Wortman Vaughan	2010	SIGecom Exchanges	10.1145/1980534.1980540	matching;game theory;economics;management science;microeconomics;mathematical economics;welfare economics;utility	ECom	-3.6929130446480634	-0.7672870657277061	61332
e2f3c4d2a04dca0c4ef7db36ae6cfab51bf5420d	the vl control measure for symmetric networks	cooperative network game;search probabilities;network control;shapley value;proper shapley value;control measure;network game;network;matrix search game	In this paper we measure “control” of nodes in a network by solving an associated optimisation problem. We motivate this so-called VL control measure by giving an interpretation in terms of allocating resources optimally to the nodes in order to maximise some search probability. We determine the VL control meaCooperative network game Proper Shapley value M sure for various classes of networks. Furthermore, we provide two game theoretic interpretations of this measure. First it turns out that the VL control measure is a particular proper Shapley value of the associgam	game theory;mathematical optimization	Ruud Hendrickx;Peter Borm;René van den Brink;Guillermo Owen	2009	Social Networks	10.1016/j.socnet.2008.10.004	bondareva–shapley theorem;mathematical optimization;example of a game without a value;simulation;mathematics;shapley value	ECom	-4.333142932645049	-0.896108179833475	61345
30497ca7eb179eb3073077f57832ad321a713e51	the role of boundary solutions in principal-agent problems of the holmström-milgrom type	continuous time;principal agent problem;brownian motion;discrete time;profitability;incentive scheme	Abstract   The paper extends the Holmstrom–Milgrom [B. Holmstrom, P. Milgrom, Aggregation and linearity in the provision of intertemporal incentives, Econometrica 55 (1987) 303–328] analysis of intertemporal incentive provision to allow for the implementation of actions on the boundary of the feasible set. Boundary actions provide the principal with some freedom in choosing incentive schemes. This can be used to reduce premia. The paper characterizes optimal incentive schemes for the continuous-time Brownian-motion model and its discrete-time approximations. Linearity of incentive schemes in “accounts” is confirmed. However, for models with effort costs depending only on mean returns, the availability of boundary actions destroys the linearity of optimal incentive schemes in profits.		Martin F. Hellwig	2007	J. Economic Theory	10.1016/j.jet.2006.09.004	financial economics;principal–agent problem;discrete time and continuous time;economics;finance;brownian motion;microeconomics;mathematical economics;welfare economics;statistics;profitability index	Theory	-0.21850239226215046	-3.2939561879069053	61453
81596dacf1afc683e04579e3171070e090a604d5	optimal control of information epidemics modeled as maki thompson rumors	maki thompson rumor model;optimal control;pontryagin s minimum principle;social networks	We model the spread of information in a homogeneously mixed p opulation using the Maki Thompson rumor model. We formulate an optimal control problem, from the per s ctive of single campaigner, to maximize the spread of information when the campaign budget is fixed. Control sig nals, such as advertising in the mass media, attempt to convert ignorants and stiflers into spreaders. We show the ex istence of a solution to the optimal control problem when the campaigning incurs non-linear costs under the isoperim et c budget constraint. The solution employs Pontryagin’s Minimum Principle and a modified version of forward bac kward sweep technique for numerical computation to accommodate the isoperimetric budget constraint. The te chniques developed in this paper are general and can be applied to similar optimal control problems in other areas. We have allowed the spreading rate of the information epidem c to vary over the campaign duration to model practical situations when the interest level of the populat ion in the subject of the campaign changes with time. The shape of the optimal control signal is studied for di fferent model parameters and spreading rate profiles. We have a lso studied the variation of the optimal campaigning costs with respect to various model parameters. Results indicate that , for some model parameters, significant improvements can be a chi ved by the optimal strategy compared to the static control strategy. The static strategy respects the same bud get constraint as the optimal strategy and has a constant value throughout the campaign horizon. This work finds appli cation in election and social awareness campaigns, product advertising, movie promotion and crowdfunding cam p igns.	computation;control theory;crowdfunding;isoperimetric inequality;nonlinear system;numerical analysis;optimal control;signature block	Kundan Kandhway;Joy Kuri	2014	CoRR	10.1016/j.cnsns.2014.04.022	pontryagin's minimum principle;simulation;optimal control;control theory;mathematics;mathematical economics;statistics;social network	ML	0.5713054191897643	-1.3595298943556666	61466
a039c50b957b75bd2572a6cec4ae44d77d24f99b	robust design of e/e architecture component platforms	uncertainty minimization e e architecture component platforms monte carlo simulation based method nondominated solutions parameter uncertainty car variant car models;automotive;design space exploration variant management automotive;robustness optimization uncertainty space exploration monte carlo methods uncertain systems automotive engineering;design space exploration;variant management;uncertain systems automotive electronics design engineering minimisation	Already today, car manufacturers are designing E/E architectures using so-called component platforms. Such a platform comprises the superset of all components that are required to build all acquirable variants of a certain or even multiple car models. To find and optimize such component platforms, each candidate platform has to be evaluated by (a) determining a number of design objectives (monetary cost, etc.) of each car variant when derived from the candidate platform and then (b) approximating the platform's design objectives themselves, e. g., by a weighted sum that includes the expected sales of each variant. But typically, since this optimization has to take place in early design stages, important parameters like the number of expected sales numbers per car variant can only be projected and are, thus, uncertain. To investigate the susceptibility of the optimization to such uncertain parameters, this paper proposes a Monte-Carlo simulation-based method that enables to evaluate the uncertainty of a combined multi-variant objective wrt. parameter variations. By treating the minimization of uncertainty as an additional design objective, not only can the robustness of the derived component platforms be improved but also the confidence of the manufacturer. Moreover, we also propose to treat uncertainty not as a conventional design objective, but to use uncertain objectives: Here, not a single (e. g., mean) value but an interval given by observed upper and lower objective values is used. Experimental results show that the design objectives of an E/E architecture component platform are relatively robust wrt. parameter variations (here expected sales numbers of car variants). Moreover, it will be shown that the difference in expected overall costs between different non-dominated solutions is often much higher than the expected variation in cost as a result of parameter uncertainty	emoticon;mathematical optimization;monte carlo method;simulation;weight function	Sebastian Graf;Sebastian Reinhart;Michael Glaß;Jürgen Teich;Daniel Platte	2015	2015 52nd ACM/EDAC/IEEE Design Automation Conference (DAC)	10.1145/2744769.2747941	mathematical optimization;simulation;telecommunications;engineering;automotive industry	EDA	6.072892021378589	-5.164410576975997	61531
0a2064acb4a9cc0f89c9b77b0cbdd5e2fd3d7515	a physical probabilistic model to predict failure rates in buried pvc pipelines	fractografia;polyvinyl chloride;modelizacion;occupation time;europa;cemento;pvc pipe;fiabilidad;reliability;base donnee;durabilite;residual stress;service conditions;temps rupture;metodo monte carlo;failure;fracture mechanics;caracterisation defaut;funcion azar;iniciacion grieta;loi probabilite;piping;operant conditioning;ley probabilidad;porcentaje falla;operating conditions;ciment;canalizacion enterrada;crack initiation;durabilidad;database;methode monte carlo;base dato;break up time;eau;tiempo vida;fracture mechanic;taux defaillance;caracterizacion defecto;modele physique;probabilistic approach;ley weibull;amiante;cast iron;service operation;caneria;conditions service;fonction hasard;fractography;model validation;modelisation;probabilistic model;tiempo ruptura;weibull distribution;fundicion;brittle fracture;systeme incertain;condition operatoire;network failure rate;lifetime;temps occupation;cast metal;durability;cement;royaume uni;model uncertainty;enfoque probabilista;approche probabiliste;mecanique rupture;fiabilite;monte carlo method;probability distribution;condiciones funcionamiento;united kingdom;rupture;defaillance;tiempo ocupacion;reino unido;modele probabiliste;modelo fisico;tuyauterie;metal moldeado;amianto;failure rate;defect characterization;mecanica ruptura;oleoducto;fractographie;canalisation enterree;agua;failures;physical model;europe;duree vie;hazard function;tension residual;buried pipe;monte carlo simulation;sistema incierto;metal moule;condicion operatoria;modeling;loi weibull;fallo;uncertain system;water;contrainte residuelle;ruptura;linear elastic fracture mechanics;amorcage fissure;pipeline;historical data;vinylique chlorure polymere;fonte;modelo probabilista;vinilico cloruro polimero;asbestos	For older water pipeline materials such as cast iron and asbestos cement, future pipe failure rates can be extrapolated from large volumes of existing historical failure data held by water utilities. However, for newer pipeline materials such as polyvinyl chloride (PVC), only limited failure data exists and confident forecasts of future pipe failures cannot be made from historical data alone. To solve this problem, this paper presents a physical probabilistic model, which has been developed to estimate failure rates in buried PVC pipelines as they age. The model assumes that under in-service operating conditions, crack initiation can occur from inherent defects located in the pipe wall. Linear elastic fracture mechanics theory is used to predict the time to brittle fracture for pipes with internal defects subjected to combined internal pressure and soil deflection loading together with through-wall residual stress. To include uncertainty in the failure process, inherent defect size is treated as a stochastic variable, and modelled with an appropriate probability distribution. Microscopic examination of fracture surfaces from field failures in Australian PVC pipes suggests that the 2-parameter Weibull distribution can be applied. Monte Carlo simulation is then used to estimate lifetime probability distributions for pipes with internal defects, subjected to typical operating conditions. As with inherent defect size, the 2-parameter Weibull distribution is shown to be appropriate to model uncertainty in predicted pipe lifetime. The Weibull hazard function for pipe lifetime is then used to estimate the expected failure rate (per pipe length/per year) as a function of pipe age. To validate the model, predicted failure rates are compared to aggregated failure data from 17 UK water utilities obtained from the United Kingdom Water Industry Research (UKWIR) National Mains Failure Database. In the absence of actual operating pressure data in the UKWIR database, typical values from Australian water utilities were assumed to apply. While the physical probabilistic failure model shows good agreement with data recorded by UK water utilities, actual operating pressures from the UK is required to complete the model validation. r 2006 Elsevier Ltd. All rights reserved.	copper(ii) chloride;extrapolation;failure cause;failure rate;monte carlo method;pipeline (computing);pipeline (software);randomness;residual stress;simulation;software bug;statistical model	P. Davis;Stewart Burn;Magnus Moglia;Stephen Gould	2007	Rel. Eng. & Sys. Safety	10.1016/j.ress.2006.08.001	structural engineering;engineering;failure rate;mathematics;forensic engineering;statistics;monte carlo method	AI	6.562744525814929	-2.6937583260942874	61773
2d967cf7faa5e547ab7da06877f68d5a1d5948c8	seismic risk analysis of highway systems using loss estimation methodology with geospatial technologies	seismic risk;emergency response;time dependent;ground motion;travel time;traffic flow;network analysis;spatial distribution;probabilistic analysis;network configuration;economic loss;seismic hazard;knowledge modeling	Effects of earthquake damage to highway components (e.g., bridges, tunnels, roadways, etc.) can go well beyond life-safety risks and costs to repair the damaged components. Such damage can also disrupt traffic flows which, in turn, can impact the region's economic recovery and emergency response. These impacts will depend not only on the seismic performance of the components, but also on the characteristics of the overall highway system such as its network configuration and roadway-link characteristics (e.g., link locations, redundancies, and traffic capacities). Unfortunately, such traffic impacts are usually not considered in seismic risk reduction activities at state transportation departments. One reason for this has been the lack of a technically-sound and practical tool for estimating these impacts. Therefore, since the mid-1990s, the FHWA has sponsored multi-year seismic-research projects at MCEER that have included development and programming of such a tool with geospatial technologies. This has led to new software named REDARS (Risks from Earthquake DAmage to Roadway Systems) that was released for public use in March 2006.  REDARS is a multi-disciplinary tool for seismic risk analysis (SRA) of highway systems nationwide based on geospatial technologies. For any given earthquake, REDARS uses state-of-knowledge models to estimate: (a) the seismic hazards (ground motions, liquefaction, and surface fault rupture) throughout the system; (b) the resulting damage states (damage extent, type, and location) for each component in the system; and (c) how each component's damage will be repaired, including its repair costs, downtimes, and time-dependent traffic states (i.e., its ability to carry traffic as the repairs proceed over time after the earthquake). REDARS incorporates these traffic states into a highway-network link-node model, in order to form a set of system-states that reflect the extent and spatial distribution of roadway closures at various times after the earthquake. Then, REDARS applies network analysis procedures to each system-state, in order to estimate how these closures affect system-wide travel times and traffic flows. Finally, REDARS estimates corresponding economic losses and increases in travel times to/from key locations or along key lifeline routes. These steps can be applied for single earthquakes and no uncertainties (deterministic analysis) or for multiple earthquakes and simulations in which uncertainties in earthquake occurrence and in estimates of seismic hazards and component damage are considered (probabilistic analysis). This presentation will provide the overview of the FHWA seismic risk analysis program, REDARS.	emoticon;knowledge representation and reasoning;probabilistic analysis of algorithms;seismic analysis;sequence read archive;simulation;steam rupture	W. Phillip Yen	2010		10.1145/1823854.1823862	structural engineering;seismic risk;earthquake scenario;engineering;civil engineering;seismic hazard;forensic engineering	Metrics	8.150013492720035	-9.56966826782724	61835
04c826afbadee5ef26d28ff01d257465285bc0ed	activity delay in stochastic project networks	movimiento caja;optimisation;project management;metodo monte carlo;modelo markov;optimizacion;heuristic method;methode monte carlo;metodo heuristico;organizacion proyecto;reseau;prise decision;value analysis;red;analyse valeur;stochastic system;markov model;monte carlo method;retard;analisis valor;gestion projet;optimization;cash flow;methode heuristique;modele markov;sistema estocastico;toma decision;retraso;article;systeme stochastique;network	In this paper we deal with a stochastic project network and consider the impact of activity delay to maximize the expected present value of a project. It is shown that in certain situations, delaying the onset of an activity from its earliest start time can indeed increase the present value of a project due to the postponing of associated negative cash flows. Furthermore, a project that could otherwise be rejected negative expected present value may become profitable positive expected present value due to delay. We demonstrate that even activities on the critical path, as determined by each activity's expected duration, may be profitably delayed. Optimal and approximate procedures are developed to determine the amount of delay of the various activities.		Arnold H. Buss;Meir J. Rosenblatt	1997	Operations Research	10.1287/opre.45.1.126	project management;simulation;economics;artificial intelligence;cash flow;mathematics;markov model;statistics;monte carlo method	EDA	5.02593438945507	-3.05316760079412	61856
b1e9a2bdf7a81fef6088628e4a51a44965b99a2d	the firm as a nexus of strategies	transferable utility;team production;incentive constraints;implicit contracts;contracts;repeated game;theory of the firm;enterprises;repeated games;self enforcement	This paper replaces the standard view of the firm as a nexus of contracts with a repeated game framework where input contributions and side payments are self-enforced. General production technologies and flexible transfers among team members are allowed. When an incentive constraint binds, input demand and output supply are influenced by the discount factor, the probability of exogenous team dissolution, and the aggregate value of outside options. When this incentive constraint does not bind, the firm maximizes profit in the usual way. I discuss examples involving the Cobb-Douglas technology, firms with a single residual claimant, and partnerships.	aggregate data	Gregory K. Dow	2004	IGTR	10.1142/S0219198904000344	industrial organization;economics;repeated game;microeconomics;mathematical economics;labour economics	HCI	-1.1217433070259661	-5.777462295224441	61925
6c983680fef401f2c5cda20f3fdd5374f5cbb35a	benefits of providing amenities to impatient waiting customers	service system;service provider;impatient customers;customer satisfaction;reneging;amenities;waiting lines	This paper proposes an OR modelling approach to study the e ect of managing queue reneging by providing amenities to improve customers’ queueing experience. We evaluate quantitatively the changes in the servers’ utilization and customers’ satisfaction when the size and quality of the amenities are varied. We nd that when the size of the amenities is increased to cover more and more customers, the incremental return in bene ts will eventually diminish. So is the case when the quality of the amenities is improved to higher and higher standards for systems with su ciently heavy workload. However, for systems with light workload, the models show that improving the quality of the amenities has an increasing incremental return in bene ts. Scope and purpose Reneging, the phenomenon of customers leaving a service system before nishing service, represents loss in revenues and goodwill to the service provider. Very often companies provide amenities to alleviate waiting customers’ discomfort so that they would be willing to wait for longer period of time. However, there is the trade-o between investing in amenities and generating more revenue from customers. Our work investigates the optimal balance for this trade-o and the most e ective approach for setting up amenities. ? 2003 Elsevier Ltd. All rights reserved.	experiment;numerical analysis;queue (abstract data type);queueing theory;requirement;social capital	Jihong Ou;B. Madhu Rao	2003	Computers & OR	10.1016/S0305-0548(02)00142-9	service provider;customer satisfaction;service system	Metrics	-0.7425407411429771	-8.54176751646513	62039
053d4f2a06030935a6597fb923e2fc2081c1c73b	technical note - an expectation-maximization algorithm to estimate the parameters of the markov chain choice model		We develop an expectation-maximization algorithm to estimate the parameters of the Markov chain choice model. In this choice model, a customer arrives into the system to purchase a certain product. If this product is available for purchase, then the customer purchases it. Otherwise, the customer transitions between the products according to a transition probability matrix until she reaches an available one and purchases this product. The parameters of the Markov chain choice model are the probability that the customer arrives into the system to purchase each one of the products and the entries of the transition probability matrix. In our expectation-maximization algorithm, we treat the path that a customer follows in the Markov chain as the missing piece of the data. Conditional on the final purchase decision of a customer, we show how to compute the probability that the customer arrives into the system to purchase a certain product and the expected number of times that the customer transitions from a certain product to another one. These results allow us to execute the expectation step of our algorithm. Also, we show how to solve the optimization problem that appears in the maximization step of our algorithm. Our computational experiments show that the Markov chain choice model, coupled with our expectation-maximization algorithm, can yield better predictions of customer choice behavior when compared with other commonly used alternatives.	choice modelling;computation;entropy maximization;expectation–maximization algorithm;experiment;markov chain;mathematical optimization;optimization problem;purchasing;stochastic matrix	A. Serdar Simsek;Huseyin Topaloglu	2018	Operations Research	10.1287/opre.2017.1692		ML	8.008260212747368	-2.66089353340887	62705
0d5d5c7ad1ba111fb33e50c971cde60776ef1551	dedicated refurbishing line optimization by simulation	maintenance engineering;consumer electronics;system performance;supply chains;stochastic processes;probability distribution;manufacturing;simulation remanufacturing reverse logistics;statistical distributions optimisation recycling;manufacturing consumer electronics stochastic processes supply chains probability distribution maintenance engineering system performance;simio line optimization consumer electronics after market service industry ams industry product returns uncertainty stochastic processing times hard to predict product demand remanufacturing systems refurbishing systems simulation optimization resources allocation testing processes refurbishing processes probability distributions	Simulation has gained importance in the consumer electronics After Market Service (AMS) industry, due tofactors such as uncertainty in product returns, stochastic processing times, and unknown or hard-to-predict product demand. Remanufacturing and refurbishing systems may not be analyzed using closed-form expressions due to the complexity caused by above-mentioned factors. In this paper, a detailed simulation optimization study is proposed to better allocate resources within the testing and refurbishing processes. Time studies have been conducted to identify the probability distributions that will be used in the simulation. Also a detailed simulation model using SIMIO® is presented to reflect the complete refurbishing process. We present a framework that can be used in decision-making sequences, allowing us to identify current bottlenecks and evaluate alternate scenarios to improve the system performance.	mathematical optimization;simulation;verilog-ams	K. Calvi;S. Chung;M. Economou;Ritwik Kulkarni;R. Havens	2015	2015 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM)	10.1109/IEEM.2015.7385850	maintenance engineering;probability distribution;simulation;systems engineering;engineering;marketing;operations management;mathematics;supply chain;manufacturing;statistics	Robotics	8.206206702200081	1.4493062925600901	62910
6b8353f1ea0ce75f6b9066f286908fd530982d12	pricing and replenishment policies in a supply chain with competing retailers under different retail behaviors	game theory;replenishment policy;market competition;supply chain management	This paper develops game models for a two-echelon supply chain with one supplier and multiple competing retailers. We study the pricing decision and the replenishment policy for each member under both the decentralized channel and the centralized channel, and examine the impacts of retail behaviors on them. Compared with the centralized operation, the decentralized operation with linear wholesale price obviously inflates the holding cost for each retailer, which results in the inefficiency for the whole channel. For the decentralized system, both retail-competition and retail-cooperation models are considered. The comparative analysis illustrates how the retail pricing and replenishment decisions are affected by the retail behaviors. We find that the retail cooperation is not stable since each self-interested retailer has an incentive to lower his retail price unilaterally. Finally, in order to improve the performance of the channel and each member, a Groves wholesale price contract is designed to achieve the perfect coordination between the supplier and the retailers. Meanwhile, this coordination model can also be used in the case of a supply chain with independent retailers.		Kebing Chen;Tiaojun Xiao	2017	Computers & Industrial Engineering	10.1016/j.cie.2016.11.018	game theory;supply chain management;marketing;microeconomics;commerce	AI	-1.687835263191762	-5.710048606900984	62935
6c1c169e7ac7de2e979bf35a7a3a13615fc41b10	trading higher software piracy for higher profits: the case of phantom piracy	tabla precios;ojo;consumidor;developpement logiciel;modelizacion;rentabilidad;information good;eye;ophthalmology;bien etre economique;produit consommation;intellectual property;droit auteur;welfare;consumer surplus;economic sciences;consommateur;software piracy;pricing;piratage;comercializacion;venta conjunta;bien numerico;vente groupee ou liee;copyright;phantom piracy;bundling;fijacion precios;piracy;scenario;commercialisation;modelisation;profit;ciencias economicas;coste marginal;tariffication;argumento;beneficio;revenu economique;marketing;consumer;tarification;desarrollo logicial;cout marginal;rebajas;propiedad intelectual;bien numerique;software development;script;prices schedule;software industry;marginal cost;benefice;digital goods;rentabilite;simulation analysis;profitability;consumer products;sciences economiques;bareme prix;discount;renta;rabais;surplus;pirateria;modeling;price discrimination;propriete intellectuelle;oeil;fixation prix;bienestar economico;oftalmologia;profit maximization;tarificacion;income;ophtalmologie;derecho autor	This paper analytically explores the effect of software bundling on software piracy. We focus on piracy at individual user level where several individuals illegitimately share a single copy of software. We develop an economic model of software piracy with bundling of two products that are not identically distributed. We derive results for optimal level of piracy and profits for individual products as well as for the bundle. Our results indicate that bundling results in a level of piracy that is always less than the piracy level of one of the products of the bundle. However, it is possible to trade off the piracy level of one product for overall higher profits, i.e., a seller can derive higher profits even with higher levels of piracy for one of the products in the bundle. We derive exact bounds for two cases: (i) where piracy level of the bundle is smaller than the piracy level of both the products in the bundle, and (ii) where the profits from a bundle are always higher even with higher piracy level than one of the products.	dvd region code;imaging phantom;phantom reference;product bundling	Ram D. Gopal;Alok Gupta	2010	Management Science	10.1287/mnsc.1100.1221	marginal cost;pricing;profit;systems modeling;economics;consumer;income;final good;scenario;marketing;software development;welfare;economic surplus;microeconomics;advertising;economy;information good;management;price discrimination;intellectual property;commerce;profitability index	Metrics	-1.1159528689103437	-6.825140251487409	63005
81c027aca57b4207ed3009c0c7230ffe92eecc2b	an analytical approach to bundling in the presence of customer transition effects	criterio optimalidad;methode domaine temps;modelizacion;outil logiciel;commerce electronique;switching;software tool;decision support tool;comercio electronico;systeme aide decision;e commerce;retention;pricing;teoria sistema;comercializacion;venta conjunta;vente groupee ou liee;prise de decision;dynamic system;dynamic systems;bundling;sistema ayuda decision;long terme;metodo dominio tiempo;fijacion precios;suscripcion;monotonie;long term;dynamical system;commercialisation;modelisation;systeme dynamique;condicion optimalidad;decision support system;condition optimalite;tariffication;largo plazo;life time value maximization;systems theory;marketing;tarification;theorie systeme;decision making process;monotonicity;conmutacion;abonnement;time domain;optimality criterion;time domain method;monotonia;sistema dinamico;critere optimalite;toma decision;herramienta software;modeling;subscription;commutation;fixation prix;electronic trade;optimality condition;analytical model;retencion;tarificacion	Service product bundling is a widespread practice in current e-commerce environment. While many studies have examined optimal bundling and pricing in a static time domain, there has been a lack of attention to the dynamic nature of customer transition among bundles and the consequent long-term strategy. This paper considers subscription-based service bundling problem. In this context, an existing customer can choose the same bundle or switch to another bundle, whereas a new customer can adopt any of the bundles that are being offered. An analytical model that explicitly captures the customer transition over multiple time periods is developed using a dynamic systems approach. Using this model, we analyze the effect of adoption, retention, and switching simultaneously on optimal bundle configuration and pricing. We discuss several managerial insights, along with numerical examples and validating simulations, which are relevant to bundling strategy. We provide analytical results which enable an effective and efficient decision support tool to predict future demand stream for different bundles. We present a monotonicity property for the optimality condition which significantly reduces the computational burden.		Seokjoo Andrew Chang;Giri Kumar Tayi	2009	Decision Support Systems	10.1016/j.dss.2009.07.002	simulation;decision support system;computer science;marketing;operations management;dynamical system;operations research	ECom	3.057855840018005	-5.595404478641284	63109
506912af43fb49321ecce4cf740aa772be3afc33	economic order quantity under conditions of a one-time-only extended permissible delay period in payments	inventory;business environment;payment delay;economic order quantity;special order quantity	In today's business environment, a supplier usually offers customers a permissible delay for settling outstanding account balance for the goods supplied. However, a supplier on occasion may allow this permissible delay in payments to be more than the usual during a given specified period. In this paper, we establish an appropriate model for a customer to determine its optimal special order quantity when the supplier offers a special extended permissible delay for one time only during a specified period. We then establish two theorems for a customer to find the optimal special order quantity. Finally, several numerical examples are given to illustrate the theoretical results.	economic order quantity	Suresh Kumar Goyal;Chun-Tao Chang	2008	APJOR	10.1142/S0217595908001675	actuarial science;economic order quantity;inventory;economics;operations management;commerce	EDA	2.1534878133916835	-4.923782646140214	63141
344e683bdb5151973a724054a1394e89b4e29aec	optimal average-cost policy for a queue with start-up and shut-down costs	average cost	"""This paper examines pure stationary policies for starting and stopping service in a single-server queue with respect to the state space consisting of queue length and whether or not the service facility is operating. Almost any such policy is shown to be equivalent to one that depends on two parameters. For a wide class of cost functions, the """"almost any"""" is shown to be without loss of optimality in the sense of average cost per unit time over an infinite horizon. The results are largely distribution-free and are obtained with random-walk arguments. They apply also to certain repair problems and to production smoothing problems in which demand is a renewal process and goods are made sequentially."""		Matthew J. Sobel	1969	Operations Research	10.1287/opre.17.1.145	mathematical optimization;multilevel queue;economics;operations management;mathematics;welfare economics	Crypto	3.9239676051083756	-1.8533085123234072	63299
d133781cf93fccf789f05fe567fdc22ada505b15	co-op advertising analysis within a supply chain based on the product life cycle	spillover effect cooperative advertising analysis supply chain product life cycle game theory model investment national advertising co op expenditures local advertising sales response volume marginal profit;investments;game theory;spillover effect;nash equilibrium;supply chain management advertising game theory investment product life cycle management profitability;product life cycle management;product life cycle;satisfiability;investment;supply chains;advertising investments equations nash equilibrium mathematical model supply chains;mathematical model;supply chain;profitability;supply chain management;advertising	This paper presents two types of game theory model for studying a cooperative advertising problem in one manufacturer and two retailers. Cooperative and noncooperative equilibrium are discussed respectively with three significant conclusions. First, increased investment in national advertising or a greater share taken by the manufacturer in the co-op expenditure can't always lead to the increased investment in local advertising by the retailer, it relevant to the product life cycle. Second, within different stage in product life cycle, the degree of the retailer's local advertising, sales response volume, profit affect by other retailer's marginal profit is relevant to the Spillover effect. Third, when the proportion of two retailer's marginal profit satisfies a certain condition, the profit with cooperation is high than noncooperation.	game theory;knowledge spillover;marginal model	Hong Zhang;Sheng Zhong	2011	2011 Seventh International Conference on Computational Intelligence and Security	10.1109/CIS.2011.325	game theory;supply chain management;investment;marginal profit;supply chain	DB	-1.7814210035991458	-6.012133435227459	63351
62bd46957d29ab00eab45dddc196d48a8a04c2cc	"""matching """"versus"""" mechanism design"""	good property;introductory example;complicated picture;course allocation;social welfare;main example;typical mechanism design paper;good properties approach;incentive constraint;school choice;theory;economics	"""In a typical mechanism design paper the goal is to find a mechanism that maximizes the designer's objective (e.g., social welfare) subject to technology and incentive constraints. In a typical applied matching paper, by contrast, the goal is to find a mechanism that satisfies various """"good properties"""" (e.g., efficiency and fairness). This essay discusses the relationship and tradeoffs between these two approaches. An introductory example, school choice, represents a simple win for the good properties approach. The main example, course allocation, paints a more complicated picture."""	fairness measure	Eric Budish	2012	SIGecom Exchanges	10.1145/2509002.2509005	mathematical optimization;simulation;economics;computer science;artificial intelligence;operations management;mathematics;microeconomics;mathematical economics;management;algorithm	ECom	-1.0212435531488482	-1.6159451865181387	63647
dd958386ee0a2d402d3c83288199953aa02bb9f6	assessing the benefits of remanufacturing option under one-way substitution	steady state probability;markets;modelo markov;mercado;probabilite stationnaire;capacite;rente;substitution;by product;capacidad;inventory;profit;algebraic geometry;markov model;beneficio;sous produit;subproducto;marche;benefice;revenue;geometria algebraica;regime permanent;profitability;remanufacturing;regimen permanente;modele markov;capacity;probabilidad estacionaria;inventaire;inventario;substitucion;geometrie algebrique;one way substitution;steady state	In this study, we consider a segmented market for a product that can either be manufactured or remanufactured. It is assumed that the remanufactured products can be substituted by the new ones. A steady-state profit model is constructed under certain environmental assumptions on capacity requirements of operations, and revenue and cost schemes. Exact steady-state probabilities of the Markovian model constructed are solved via matrix geometric techniques. An extensive computational study is performed to investigate the conditions under which the utilization of remanufacturing option and the use of one-way substitution policy increase the average expected profit.	one-way function	Z. Pelin Bayindir;Nesim K. Erkip;Refik Güllü	2005	JORS	10.1057/palgrave.jors.2601799	profit;inventory;economics;algebraic geometry;marketing;operations management;mathematics;markov model;mathematical economics;revenue;steady state;profitability index	Theory	4.439238454309824	-3.6872068346037903	63663
d6606ecdb76057c0a49292ea7c5f979cdd4b5e45	effects of suboptimal bidding in combinatorial auctions	nash equilibrium;bidding strategies;speed of convergence;satisfiability;computer experiment;linear program;value function;mechanism design;high efficiency;combinatorial auction	Though the VCG auction assumes a central place in the mechanism design literature, there are a number of reasons for favoring iterative combinatorial auction designs. Several promising ascending auction formats have been developed throughout the past few years based on primal-dual and subgradient algorithms and linear programming theory. Prices are interpreted as a feasible dual solution and the provisional allocation is interpreted as a feasible primal solution. iBundle(3) (Parkes and Ungar 2000), dVSV (de Vries et al. 2007) and the Ascending Proxy auction (Ausubel and Milgrom 2002) result in VCG payoffs when the coalitional value function satisfies the buyer submodularity condition and bidders bid straightforward, which is an expost Nash equilibrium in that case. iBEA and CreditDebit auctions (Mishra and Parkes 2007) do not even require the buyer submodularity condition and achieve the same properties for general valuations. In many situations, however, one cannot assume bidders to bid straightforward and it is not clear from the theory how these non-linear personalized price auctions (NLPPAs) perform in this case. Robustness of auctions with respect to different bidding behavior is therefore a critical issue for any application. We have conducted a large number of computational experiments to analyze the performance of NLPPA designs with respect to different bidding strategies and different valuation models. We compare the results of NLPPAs to those of the VCG auction and those of iterative combinatorial auctions with approximate linear prices, such as ALPS (Bichler et al. 2009) and the Combinatorial Clock auction (Porter et al. 2003). While NLPPAs performed very well in case of straightforward bidding, we could observe problems with respect to auctioneer revenue, efficiency, and speed of convergence in case of non-best-response bidding behavior. Under suboptimal bidding strategies, dVSV and CreditDebit auctions have a significantly lower efficiency than iBundle(3). In contrast, linear price combinatorial auctions were robust against all strategies, except collusive behavior which makes it very difficult for any auctioneer to select an efficient solution in general. While our results achieve high efficiency values on average, one can easily construct examples, where linear price CAs cannot be efficient (Bichler et al. 2009). Linear-price designs suffer from the fact that they cannot be 100% efficient, but they have shown to be robust against many strategies and bear a few advantages: S. Das et al. (Eds.): Amma 2009, LNICST 14, pp. 1–2, 2009. c © ICST Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering 2009 2 S. Schneider, P. Shabalin, and M. Bichler – Only a linear number of prices needs to be communicated. – Linear prices, if perceived as a guideline, help bidders to easily find interesting items and bundles and allow for endogenous bidding (Kwon05). – The perceived fairness of anonymous prices might be an issue in some applications. – The number of auction rounds is much lower. Overall, robustness of combinatorial auction formats against different bidding strategies is, aside from efficiency, fairness, and speed of convergence, an important topic auctioneers need to care about.	approximation algorithm;auction algorithm;bellman equation;computation;computer science;david ungar;experiment;fairness measure;institute for computer sciences, social informatics and telecommunications engineering;iteration;iterative method;linear programming;nash equilibrium;nonlinear system;personalization;rate of convergence;real-time bidding;subderivative;subgradient method;value (ethics)	Stefan Schneider;Pasha Shabalin;Martin Bichler	2009		10.1007/978-3-642-03821-1_1	mathematical optimization;combinatorial auction;economics;microeconomics;mathematical economics;auction theory	ECom	-3.482526090106732	-1.8210979967773782	63845
b3587a0c84d255d91dea799b5dcb5372ae189721	optimal loading and protection of multi-state systems considering performance sharing mechanism	protection;universal generating function;genetic algorithms;performance sharing;multi state systems;load dependent failure	Engineering systems are designed to carry the load. The performance of the system largely depends on how much load it carries. On the other hand, the failure rate of the system is strongly affected by its load. Besides internal failures, such as fatigue and aging process, systems may also fail due to external impacts such as nature disasters and terrorism. In this paper, we integrate the effect of loading and protection of external impacts on multi-state systems with performance sharing mechanism. The objective of this research is to determine how to balance the load and protection on system elements. An availability evaluation algorithm of the proposed system is suggested and the corresponding optimization problem is solved utilizing genetic algorithms.		Hui Xiao;Daimin Shi;Yi Ding;Rui Peng	2016	Rel. Eng. & Sys. Safety	10.1016/j.ress.2015.12.001	real-time computing;simulation;genetic algorithm;computer science;engineering	OS	8.566195423807077	-0.4204853564856908	63879
afdeaa4ade155964b519c1ef0ffdbc4e498b5e0c	computing equilibria for a service provider game with (im)perfect information	liverpool;game theory;theoretical framework;service provider;utility function;average case analysis;imperfect information;repository;incomplete information;market equilibria;service provider games;probability distribution;approximation scheme;university;large classes;polynomial approximation;bayesian game	We study fundamental algorithmic questions concerning the complexity of market equilibria under perfect and imperfect information by means of a basic microeconomic game. Suppose a provider offers a service to a set of potential customers. Each customer has a particular demand of service and her behavior is determined by a utility function that is nonincreasing in the sum of demands that are served by the provider.Classical game theory assumes complete information: the provider has full knowledge of the behavior of all customers. We present a complete characterization of the complexity of computing optimal pricing strategies and of computing best/worst equilibria in this model. Basically, we show that most of these problems are inapproximable in the worst case but admit an FPAS in the average case. Our average case analysis covers large classes of distributions for customer utilities. We generalize our analysis to robust equilibria in which players change their strategies only when this promises a significant utility improvement.A more realistic model considers providers with incomplete information. Following the game theoretic framework of Bayesian games introduced by Harsanyi, the provider is aware of probability distributions describing the behavior of the customers and aims at estimating its expected revenue under best/worst equilibria. Somewhat counterintuitively, we obtain an FPRAS for the equilibria problem in the model with imperfect information although the problem with perfect information is inapproximable under the worst-case measures. In particular, the worst-case complexity of the considered problems increases with the precision of the available knowledge.	best, worst and average case;game theory;polynomial-time approximation scheme;utility;worst-case complexity	René Beier;Artur Czumaj;Piotr Krysta;Berthold Vöcking	2006	ACM Trans. Algorithms	10.1145/1198513.1198524	service provider;probability distribution;bayesian game;game theory;mathematical optimization;combinatorics;simulation;perfect information;management science;mathematical economics;complete information	Theory	-1.8533500046155795	-0.9208571020487901	63896
740edd594cf101029ec4b635fe01456414d19c21	logistic modelling of lateness distributions in inventory systems		competitive edge cannot be achieved solely by differentiating themselves through product design or pricing. Instead, in order to attain and maintain a strategic position in the market, well-designed logistic processes are considered a blueprint for enterprises to distinguish themselves and as such are moved to the forefront of business planning. From the market side, one of the highest priorities is that the design, planning and control of logistic processes provide “on-time delivery” [1–3]. A comprehensive study regarding the current state of global supply chains states the high importance of on-time delivery for competitive advantages as well as sustainable economic success [4]. The high importance of on-time delivery is underlined by a study of current orientations from the production perspective in the German mechanical engineering industry, which found that with 65.5%, the key logistic objective was on-time delivery to customers [5]. Despite extensive efforts to improve ontime delivery and in acceptance of increasing logistic costs, enterprises are not completely able to fulfil the logistic side of the market’s demands. Thus, only 23.7% of the enterprises investigated in this study were in a position to attain delivery compliance greater than 95% [5]. A key influencing factor on on-time delivery is the lateness of order completion. Lateness is defined as the difference between the actual and planned order completion time and can either be positive (order is delivered late), zero (order is delivered as planned/promised) or negative (order is delivered early). The lateness behaviour of a supply chain’s process can be analysed based on the lateness of several orders, which are processed at the specific process. Based on the average lateness and the lateness variance the process’s lateness performance can be described. Figure 1 shows how these indicators influence the lateness as well as on-time delivery behaviour in supply chains [2]. Abstract When designing, planning and controlling supply chains schedule reliability is the central objective and is a key performance indicator for assessing the logistic behaviour of a supply chain. The central influencing factor on schedule reliability is the lateness of supply chain processes. In order to comprehend possible interdependencies between logistical objectives and the influencing factor lateness various approaches have been developed for mathematically describing lateness in a supply chain’s primary processes. This paper focuses on the mathematical description of output lateness distributions in inventory systems. The developed logistic model describes the relationships between stock and service levels as well as the resulting inventory system’s output lateness distribution. Within a comprehensive simulation study the quality of the model’s depiction is demonstrated. The paper concludes with an overview of possibilities for applying the developed model for describing the lateness behaviour in supply chains.	axosoft;blueprint;input/output;interdependence;logistics;mathematical optimization;max;microsoft forefront;simulation	Peter Nyhuis;Jonas Mayer	2017	Production Engineering	10.1007/s11740-017-0741-8	simulation;engineering;operations management;operations research	AI	9.377655431857523	1.9846720457942675	64083
f58eacad9ec3a8435d2fca2d7878066efb415e8d	an efficient optimal algorithm for the quantity discount problem in material requirement planning	performance measure;production en flux pousse;experimental design;in process inventory;politica optima;arbre recherche;deposito en curso;evaluation performance;tiempo iniciacion;optimisation;remise quantitative;produccion flujo empujado;all units discount;performance evaluation;optimizacion;adquisicion por suscripcion;compra;metodo mrp;preparacion pedido;concepcion optimal;evaluacion prestacion;demande deterministe;conception optimale;plan experiencia;rebaja cuantitativa;temps mise en route;optimal policy;methode mrp;lead time;inventory;purchasing;material requirements planning;branch and bound method;setup time;material requirement planning;deterministic demand;plan experience;arbol investigacion;tamano lote;metodo branch and bound;taille lot;demanda determinista;rebajas;optimal design;lot sizing;achat;optimization;preparation commande;encours de fabrication;methode separation et evaluation;algoritmo optimo;search tree;discount;order picking;algorithme optimal;politique optimale;rabais;optimal algorithm;branch and bound;make to stock;purchases;acquisition titre onereux;quantity discount	An optimal algorithm based on branch-and-bound approach is presented in this paper to determine lot sizes for a single item in material requirement planning environments with deterministic time-phased demand and constant ordering cost with zero lead time, where all-units discounts are available from vendors and backlog is not permitted. On the basis of the proven properties of optimal order policy, a tree-search procedure is presented to construct the sequence of optimal orders. Some useful fathom rules have been proven, which make the algorithm very efficient. To compare the performance of this algorithm with the other existing optimal algorithms, an experimental design with various environments has been developed. Experimental results show that the performance of our optimal algorithm is much better than the performance of other existing optimal algorithms. Considering computational time as the performance measure, this algorithm is considered the best among the existing optimal algorithms for real problems with large dimensions (i.e. large number of periods and discount levels).	algorithm	S. Hamid Mirmohammadi;Shahram Shadrokh;Fereydoon Kianfar	2009	Computers & OR	10.1016/j.cor.2008.05.003	mathematical optimization;computer science;mathematics;material requirements planning;operations research	AI	5.490696204131175	-3.1351931470649625	64176
f182431a6a0ee26b786b57312a1e56ff077402c8	software agents for learning nash equilibria in non-cooperative games	non cooperative game;software agent;nash equilibria	representing the players act as rational players, i.e. they act to maximise their expected utility in each match of a game, and if such agents play k matches of the game they will converge in playing one of the Nash Equilibria of the game. SALENE can be conceived as a heuristic and efficient method to compute at least one Nash Equilibria in a non-cooperative game represented in its normal form.	converge;expected utility hypothesis;heuristic;nash equilibrium;software agent	Alfredo Garro;Marco Iusi	2006			mathematical optimization;game theory;normal-form game;risk dominance;best response;folk theorem;nash equilibrium;epsilon-equilibrium;computer science;coordination game	ECom	-3.923247059063964	-2.074961486856517	64247
efe62a248726287b27b4d1ec03dc99202c294fe7	pricing index-based catastrophe bonds: part 1: formulation and discretization issues using a numerical pde approach	computadora;tratamiento datos;computers;discretisation;catastrophes;object oriented design;numerical method;bond pricing;ordinateur;low frequency;industrie;huracan;industria;discretization;data processing;estrategia;traitement donnee;object oriented programming;style;prix;catastrophe;interest rate;strategy;agregado;modelo;industry;interest rate models;object oriented;numerical pde;sensitivity analysis;indexation;price index;hurricanes;reinsurance;oriente objet;callable bond;modele;contingent claim;cat bond;interest rate risk;price;strategie;ouragan;high frequency;models;granulat;precio;aggregate	This work is the first installment in a two-part series, and focuses on the development of a numerical PDE approach to price components of a Bermudan-style callable catastrophe (CAT) bond. The bond is based on two underlying stochastic variables; the PCS index which posts quarterly estimates of industry-wide hurricane losses as well as a single-factor CIR interest rate model for the three-month LIBOR. The aggregate PCS index is analogous to losses claimed under traditional reinsurance in that it is used to specify a reinsurance layer. The proposed CAT bond model contains a Bermudan-style call feature designed to allow the reinsurer to minimize their interest rate risk exposure on making substantial fixed coupon payments using capital from the reinsurance premium. Numerical PDE methods are the fundamental strategy for pricing early-exercise constraints, such as the Bermudan-style call feature, into contingent claim models. Therefore, the objective and unique contribution of this first installment in the two-part series is to develop a formulation and discretization strategy for the proposed CAT bond model utilizing a numerical PDE approach. Object-oriented code design is fundamental to the numerical methods used to aggregate the PCS index, and implement the call feature. Therefore, object-oriented design issues that relate specifically to the development of a numerical PDE approach for the component of the proposed CAT bond model that depends on the PCS index and LIBOR are described here. Formulation, numerical methods and code design issues that relate to aggregating the PCS index and introducing the call option are the subject of the companion paper.	catastrophe theory;discretization;numerical analysis	André J. A. Unger	2010	Computers & Geosciences	10.1016/j.cageo.2009.06.010	actuarial science;data processing;computer science;discretization;object-oriented programming;statistics	Robotics	2.001101622661978	-3.4672994862114823	64326
a0cb7d4f186d368be963373707ca51335f2bd974	nonparametric cost and revenue functions under constant economies of scale: an enumeration approach for the single output or input case	enumeration;linear programming;nonparametric cost and revenue functions	This note shows how the linear programs needed to compute cost and revenue functions under constant returns to scale and a single output or input, respectively, can be replaced with a more efficient enumeration algorithm. A numerical example illustrates this algorithm.		Walter Briec;Kristiaan Kerstens;Ignace Van de Woestyne	2014	ITOR	10.1111/itor.12074	mathematical optimization;economics;computer science;linear programming;mathematics;microeconomics;enumeration;welfare economics	ML	1.957144026111545	-2.9824405474812474	64343
ac01ffa4b337bb483f10f5c9ccea12491edea2b1	national-strategic investment in european power transmission capacity	network expansion;generalized nash equilibrium gne;mixed integer equilibrium problem under equilibrium constraints mi epec;electricity transmission	The transformation of the European energy system requires substantial investment in transmission capacity to facilitate cross-border trade and to efficiently integrate renewable energy sources. However, network planning in the EU is still mainly a national prerogative. In contrast to other studies aiming to identify the pan-European (continental) welfare-optimal transmission expansion, we investigate the impact of zonal planners deciding on network investment strategically, with the aim of maximizing the sum of consumer surplus, generator profits and congestion rents in their jurisdiction. This reflects the inadequacy of current mechanisms to compensate for welfare re-allocations across national boundaries arising from network upgrades. We propose a three-stage equilibrium model to describe the Nash game between zonal planners (i.e., national governments, regulators, or system operators), each taking into account the impact of network expansion on the electricity spot market and the resulting welfare effects on the constituents within her jurisdiction. Using a four-node sample network, we identify several Nash equilibria of the game between the zonal planners, and illustrate the failure to reach the first-best welfare expansion in the absence of an effective compensation mechanism.	algorithm;bilinear filtering;complementarity (physics);complementarity theory;disjunctive normal form;energy systems language;first-order reduction;glr parser;iterative method;karush–kuhn–tucker conditions;köppen climate classification;lu decomposition;line level;list of code lyoko episodes;mathematical optimization;mathematical programming with equilibrium constraints;microsoft outlook for mac;nash equilibrium;network congestion;optimization problem;strong duality;supra, inc.;sysop;ti-nspire series;test case;text simplification;time sharing option	Daniel Huppmann;Jonas Egerer	2015	European Journal of Operational Research	10.1016/j.ejor.2015.05.056	economics;public economics;operations management;welfare economics	AI	0.2837261807662585	-2.9307812253859113	64528
fa21061fb31e14b42a91f376fb06179bae8e5ac2	the effect of operational performance and focus on profitability: a longitudinal study of the u.s. airline industry	operations strategy;longitudinal study;focus;quality;profitability;airline industry;operational performance;airlines;capacity utilization;department of transportation	W study the impact of operational performance on profitability in the context of the U.S. domestic airline industry. In addition, we investigate the impact of focus [Skinner, W. 1974. The focused factory. Harvard Bus. Rev. 52(3) 113–121] on profitability in services. We use quarterly data on all major carriers, available since the introduction of required reporting of service indicators to the U.S. Department of Transportation. Our analysis demonstrates two main points. First, the relationship between operational performance and profitability is contingent on a company’s operating model; “focused” airlines show a link between late arrivals and profitability while full-service airlines do not. Also, capacity utilization is a stronger driver of profitability for full-service airlines than for focused airlines. Second, focused airlines outperform the rest of the industry in terms of profitability.	contingency (philosophy);operating model	Nikos Tsikriktsis	2007	Manufacturing & Service Operations Management	10.1287/msom.1060.0133	economics;capacity utilization;marketing;operations management;management;profitability index;focus	DB	7.835500589794037	-8.437298398713287	64583
26a2d62a5e644b4cfec072548c963fe53b074800	social networks and unraveling in labor markets	networks;entry level labor markets;market design;labor market;social network;unraveling;network structure;early;early hiring	This paper studies the phenomenon of early hiring in entry-level labor markets (e.g. the market for gastroenterology fellowships and the market for judicial clerks) in the presence of social networks. We o¤er a two-stage model in which workers in training institutions reveal information on their own ability over time. In the early stage, workers receive a noisy signal about their own ability. The early information is softand non-veriable, and workers can convey the information credibly only to rms that are connected to them (potentially via their mentors). At the second stage, hard veriable (and accurate) information is revealed to the workers and can be credibly transmitted to all rms. We characterize the e¤ects of changes to the network structure on the unraveling of the market towards early hiring. Moreover, we show that an e¢ cient design of the matching procedure can prevent unraveling. (JEL: A14, D85, C78, L14)	social network	Itay P. Fainmesser	2013	J. Economic Theory	10.1016/j.jet.2012.12.016	industrial organization;economics;microeconomics;market economy;social network;labour economics	ECom	-4.352191358373146	-7.680721517287288	64592
9dd2b30919769597bef027bf1e416413516f906c	a tax integrated approach for global supply chain network planning	tax incentive;economie;modelizacion;economia;integrated approach;taxe;global supply chain;tax integrated approach;export;global sourcing;exportation;optimisation;tax;supply chains costs investments trade agreements globalization manufacturing government logistics production outsourcing;outsourcing strategy;outsourcing;investments;entreprise multinationale;entrega;logistique;externalisation;network planning;optimizacion;estrategia optima;globalizacion;industrie fabrication;taxation globalisation integer programming investment microeconomics nonlinear programming outsourcing;nonlinear programming;integrable model;behavioral analysis;foreign direct investment;globalisation;multinational companies;optimal decision;tax aligned supply chain foreign direct investment global sourcing mixed integer nonlinear programming minlp model outsourcing;localization;government;import;modele mixte;tasa;problema np duro;tax aligned supply chain;prise de decision;non linear model;localizacion;modele non lineaire;microeconomics;manufacturing industries;multinational corporation;taxes;fiscalizacion;investment;supply chains;supply chain network planning;distribution cost;scenario;decision problem;modelisation;optimal strategy;decision optimale;joint venture;livraison;importation;np hard problem;gestion ressources humaines;firm cooperation;sous traitance;estrategia empresa;planificacion;modelo no lineal;localisation;inversion extranjero;service industries;importacion;logistics;cout distribution;programacion mixta entera;mixed model;argumento;integer programming;trade agreements;probleme np difficile;ressources humaines;industrie service;developing economies;analyse comportementale;script;fiscalite;manufacturing;gobierno;empresa conjunta;taxation;programmation partiellement en nombres entiers;production;foreign investment;mixed integer programming;human capital;planning;supply chain;analisis conductual;gouvernement;optimization;investissement etranger;cooperation entreprise;economy	Globalization is here to stay. Companies source, manufacture, and sell across borders. There are several destinations available for undertaking these activities offering varying degrees of incentives and at each destination the company incurs a different delivery cost. Multinational companies need to make more realistic decisions about where to make, source, locate, move, and store products to minimize the total cost of delivery keeping in mind the incentives offered by the governments and the logistics costs at and from the location. Current literature on supply chain optimization does not emphasize on tax. To attract foreign investment, many developing economies have included tax-holidays in their export-import (EXIM) policy for companies operating in free trade zones (FTZs). In this paper, we propose a tax integrated mixed integer model, for optimally deciding the foreign direct investment (FDI)-outsourcing (the choice of establishing captive production centers versus complete outsourcing) alternatives at the various stages of a global supply chain. For a general acyclic supply chain, this decision problem is NP-hard and obtaining analytical results on optimal FDI-outsourcing strategy may be difficult. We linearize the tax integrated model by introducing exactly one hub at each stage. In this case, termed hub-based sourcing-single hub case, we prove that the greedy strategy is an optimal FDI-outsourcing strategy. However, by associating multiple hubs at each stage the decision problem remains NP-hard. Finally, we empirically analyze the tax integrated model (for the general case) on a use-case scenario in which some locations in the choice have free trade zones offering tax incentives.	captive portal;decision problem;directed acyclic graph;fault detection and isolation;greedy algorithm;logistics;mathematical optimization;mind;np-hardness;outsourcing;supply chain attack;supply chain network;usb hub	Kannan Balaji;Nukala Viswanadham	2008	IEEE Transactions on Automation Science and Engineering	10.1109/TASE.2008.923823	integer programming;marketing;supply chain	AI	5.376508486808458	-3.7898574565403402	64612
ba36333be78025e87dbda9bea4394bf718336ed2	a four-way-handshake protocol for energy forwarding networks in the smart grid	smart grid communications;queuing theory;distributed mobile energy storage;electric vehicle;four way handshake	Distributed mobile energy storage (DMES) units, which have been recently available in the form of Plug-in Electric Vehicle (PEV) batteries, provide unique opportunities to enhance the efficiency of the smart grid. On the other hand, without communications, uncoordinated supply may risk the stability of the grid, while mobility and variable availability of the batteries make the planning task challenging for the utilities. In this paper, we propose a four-way handshake protocol and a token-based energy forwarding network model for the electricity distribution system that allows energy to be supplied in a store-and-forward fashion similar to packet delivery in delay-tolerant networks. Based on this model, we develop a novel vehicle-to-grid power flow coordination approach, where the power acquired by the delay-tolerant loads is aggregated into tokens which are then matched with the available capacity of the PEV batteries. Energy transactions between delay-tolerant loads and PEVs rely on their communications with the energy management system at the distribution level. Our four-way handshake protocol assures tokens coming from loads and grants coming from storage are matched properly at the distribution level. Our approach provides a convenient supply for loads via PEV batteries while addressing the mobility of vehicles and preserving fairness. We provide a mathematical analysis of the proposed approach and conduct simulations showing that the proposed protocol is able to provide fair access opportunity to PEV owners. Furthermore, by introducing the queuing theory perspective, we enhance the planning capabilities of utilities.		Melike Erol-Kantarci;Jahangir H. Sarker;H. T. Mouftah	2014	Ad Hoc Networks	10.1016/j.adhoc.2014.05.010	embedded system;simulation;telecommunications;computer science;operating system;queueing theory;computer security;statistics;computer network	Mobile	1.4425463945249726	4.150237640169134	64852
81c78256ccc3658c2e203a30ed80d56d651f69ed	optimal construction and rebalancing of index-tracking portfolios	650 management public relations	Index funds aim to track the performance of a financial index, such as, e.g., the Standard & Poor’s 500 index. Index funds have become popular because they offer attractive risk-return profiles at low costs. The index-tracking problem considered in this paper consists of rebalancing the composition of the index fund’s tracking portfolio in response to new market information and cash deposits and withdrawals from investors such that the index fund’s tracking accuracy is maximized. In a frictionless market, maximum tracking accuracy is achieved by investing the index fund’s entire capital in a tracking portfolio that has the same normalized value development as the index. In the presence of transaction costs, which reduce the fund’s capital, one has to manage the trade-off between transaction costs and similarity in terms of normalized value developments. Existing mathematical programming formulations for the index-tracking problem do not optimize this trade-off explicitly, which may result in substantial transaction costs or tracking portfolios that differ considerably from the index in terms of normalized value development. In this paper, we present a mixed-integer linear programming formulation with a novel optimization criterion that directly considers the trade-off between transaction costs and similarity in terms of normalized value developments. In an experiment based on a set of real-world problem instances, the proposed formulation achieves a considerably higher tracking accuracy than state-of-the-art formulations.	computation;emoticon;integer programming;jt (visualization format);linear programming formulation;mathematical optimization;maxima and minima;offset binary;pro tools;purchasing;qt (software);social inequality	Oliver Strub;Philipp Baumann	2018	European Journal of Operational Research	10.1016/j.ejor.2017.06.055	finance;business;market economy	ML	0.38271253551323464	-3.9892677038202926	65277
3241bf5b9d0de10b4162450b30803613b52a43c1	evolving strategies in blackjack	optimisation;blackjack;evolutionary computation;game theory;probability;playing strategies;operations research;probability game theory evolutionary computation optimisation;computational modeling;break even wager;insurance computational modeling evolutionary computation operations research;evolving strategies;card distribution;casino game;insurance;playing strategies evolving strategies blackjack casino game break even wager card distribution	"""Blackjack is a casino game that affords the player an opportunity to have an advantage over the house. The player can play a """"basic strategy"""" that offers an approximately break-even wager. When also taking the distribution of cards played in prior hands into account, the odds can favor the player. Well-known playing strategies have been developed by examining different situations in the game and computing the optimum play for each setting. However, the decisions made at one setting affect the probabilities of being in other settings during the course of play. Simulation provides the basis for optimizing blackjack strategies as a whole, as opposed to in a piecemeal fashion. This work reports on experiments conducted to evolve basic and counting strategies for blackjack."""	blackjack;experiment;optimizing compiler;simulation	David B. Fogel	2004	Proceedings of the 2004 Congress on Evolutionary Computation (IEEE Cat. No.04TH8753)	10.1109/CEC.2004.1331064	game theory;simulation;insurance;computer science;artificial intelligence;probability;operations research;statistics;evolutionary computation	HCI	-1.5081735239580407	0.18870286149099014	65340
1ee7437e6b109f33ced3d8e6b1f8bbb5761aa902	optimal portfolio strategies benchmarking the stock market	stock market;constraint optimization;risk management;martingale method;black scholes model;portfolio optimization;shortfall risk constraints;optimal strategy;stochastic optimal control;financial market;portfolio management;shortfall risk;optimal portfolio	The paper investigates the impact of adding a shortfall risk constraint to the problem of a portfolio manager who wishes to maximize his utility from the portfolios terminal wealth. Since portfolio managers are often evaluated relative to benchmarks which depend on the stock market we capture risk management considerations by allowing a prespecified risk of falling short such a benchmark. This risk is measured by the expected loss in utility. Using the Black–Scholes model of a complete financial market and applying martingale methods, explicit analytic expressions for the optimal terminal wealth and the optimal portfolio strategies are given. Numerical examples illustrate the analytic results. Copyright Springer-Verlag 2006		Abdelali Gabih;Wilfried Grecksch;M. Richter;Ralf Wunderlich	2006	Math. Meth. of OR	10.1007/s00186-006-0091-3	post-modern portfolio theory;capital asset pricing model;merton's portfolio problem;actuarial science;replicating portfolio;risk management;expected shortfall;market neutral;capital market line;modern portfolio theory;black–scholes model;portfolio optimization;spectral risk measure;superhedging price;portfolio insurance;security market line;separation property;application portfolio management;financial market	Theory	2.088559314572148	-3.3376768559697707	65564
3b77a60c7730a124d39174fc06b29ce5920da007	asymmetric spite in auctions	game theory;e commerce	In many auctions, agents bid more aggressively than selfinterest would prescribe. This can be explained by spite, where the agent’s utility not only increases in the agent’s surplus but also decreases as the other bidders’ surpluses increase. Spite can stem from long-term benefits from making competitors worse off and from inherent psychological effects. There have been important recent game-theoretic analyses of spiteful bidding assuming all agents are equally spiteful. We present, to our knowledge, the first auction analysis in the more realistic setting where bidders may be spiteful to different extents. We show that the equilibrium bidding function can still be written in the same form—except that the spite factor is replaced by an ‘expressed’ spite factor. This leads to bidders expressing spites that are higher or lower than their true spite depending on others’ spite. Perhaps surprisingly, in the two-bidder case, the mapping from true spite to expressed spite is the same across all common auction mechanisms. Furthermore, even with two bidders, important properties of symmetric-spite settings cease to hold: the allocation can be inefficient and the revenue ranking may reverse between firstand second-price auctions. We also show that in sealed-bid auctions under asymmetric valuation distributions, there can be a “bargaining problem” in selecting bids. Finally, we study the generalization where agents can have different extents of spite toward different other bidders.	coefficient;emoticon;experiment;game theory;nash equilibrium;real-time bidding;simulation;value (ethics)	Ankit Sharma;Tuomas Sandholm	2010			spite;common value auction	AI	-4.38728418906904	-6.570577452022504	65770
146dce789f16b2e760de7c9e0683d543830dd62b	timed tuplix calculus and the wesseling and van den berg equation	universiteitsbibliotheek;mathematical analysis;logic in computer science;profitability;cumulant	We develop an algebraic framework for the description and analysis of financial behaviours, that is, behaviours that consist of transferring certain amounts of money at planned times. To a large extent, analysis of financial products amounts to analysis of such behaviours. We formalize the cumulative interest compliant conservation requirement for financial products proposed by Wesseling and van den Bergh by an equation in the framework developed and define a notion of financial product behaviour using this formalization. We also present some properties of financial product behaviours. The development of the framework has been influenced by previous work on the process algebra ACP.	airline control program (acp);berg connector;linear algebra;money;process calculus	Jan A. Bergstra;Kees Middelburg	2013	Sci. Ann. Comp. Sci.	10.7561/SACS.2013.2.169	operations management;mathematics;mathematical economics;statistics;profitability index;cumulant	Logic	0.7593083612893242	-2.256129257453282	65842
d5466772747d92ab2fc4df72b4ff32cffc7df8e0	on quadratic cost criteria for option hedging	finanza;dynamic programming;programacion dinamica;marche incomplet;quadratic cost;finance;quadratic cost criteria;discrete time;option pricing;hedging of options;discrete time dynamic programming;incomplete markets;programmation dynamique;portfolio management;portfolio plans;critere quadratique;gestion cartera;option financiere;gestion portefeuille;tiempo discreto;temps discret;financial option;evaluation option;criterio cuadratico	Consider an option with maturity time T corresponding to a contingent claim H in an incomplete market. A fair hedging price for H should take into account an optimal dynamical hedging plan against H. Let Ct be the cumulative cost and ât be the set of events of the history up to time t. You can choose the plan at time t such that you minimize#R##N##R##N#i E[{Ct+1-Ct}2 â£ ât],#R##N##R##N#ii E[{CT-Ct}2 â£ ât], or#R##N##R##N#iii E[{CT-C0}2].#R##N##R##N#Sufficient conditions on the underlying stochastic process in discrete time are provided such that the fair hedging price does not depend on the choice of i, ii, or iii, which fact should increase its acceptability.		Manfred Schäl	1994	Math. Oper. Res.	10.1287/moor.19.1.121	discrete time and continuous time;actuarial science;dynamic programming;valuation of options;incomplete markets;project portfolio management	Theory	3.504776888568631	-2.775018789767124	65848
0652e2c8d04263e0ef09831e506b2882ee231571	job selection in a network of autonomous uavs for delivery of goods	qa mathematics	This article analyzes two classes of job selection policies that control how a network of autonomous aerial vehicles delivers goods from depots to customers. Customer requests (jobs) occur according to a spatio-temporal stochastic process not known by the system. If job selection uses a policy in which the first job (FJ) is served first, the system may collapse to instability by removing just one vehicle. Policies that serve the nearest job (NJ) first show such threshold behavior only in some settings and can be implemented in a distributed manner. The timing of job selection has significant impact on delivery time and stability for NJ while it has no impact for FJ. Based on these findings we introduce a methodological approach for decisionmaking support to set up and operate such a system, taking into account the trade-off between monetary cost and service quality. In particular, we compute a lower bound for the infrastructure expenditure required to achieve a certain expected delivery time. The approach includes three time horizons: long-term decisions on the number of depots to deploy in the service area, midterm decisions on the number of vehicles to use, and short-term decisions on the policy to operate the vehicles.	autonomous robot;autonomous system (internet);data recovery;experience;instability;relevance;stochastic process;television antenna;unmanned aerial vehicle	Pasquale Grippa;Doris A. Behrens;Christian Bettstetter;Friederike Wall	2017	CoRR	10.15607/RSS.2017.XIII.018	simulation;computer science;instability;service quality;stochastic process	Metrics	4.857923771497146	-0.5786122666787603	65906
6680ae4bfd91da7ca15ce19e39ffb175581e6a2a	a large population job search game with discrete time	search problem;modelizacion;equilibrio nash;continuum of players;game theory;tiempo busqueda;nash equilibrium;estrategia optima;equilibrio juego;teoria juego;discrete time;theorie jeu;nash equilibria;temps recherche;problema investigacion;job search;strategie nash;resolucion problema;modelisation;optimal strategy;equilibre nash;equilibrium condition;estrategia nash;condition equilibre;job search problem;nash strategy;equilibre jeu;game equilibrium;tiempo discreto;temps discret;probleme recherche;search time;modeling;strategie optimale;condicion equilibrio;problem solving;resolution probleme	A job search problem is considered, in which there is a large population of jobs initially available and a large population of searchers. The ratio of the number of searchers to the number of jobs is a. Each job has an associated value from a known distribution. At each of N moments the searchers observe a job, whose value comes from the distribution of the values of currently available jobs. If a searcher accepts a job, s/he ceases searching and the job becomes unavailable. Hence, the distribution of the values of available jobs changes over time. Also, the ratio of the number of those still searching to the number of available jobs changes. The model is presented and Nash equilibrium strategies for such problems are considered. By definition, when all the population use a Nash equilibrium strategy, the optimal response of an individual is to use the same strategy. Conditions are given that ensure the existence of a unique Nash equilibrium strategy. Examples are given to illustrate the model and present different approaches to solving such problems. 2007 Elsevier B.V. All rights reserved.	job stream;nash equilibrium;search game;search problem	David M. Ramsey	2008	European Journal of Operational Research	10.1016/j.ejor.2007.05.031	game theory;economics;artificial intelligence;operations management;mathematics;mathematical economics;nash equilibrium	Theory	4.404204802179395	-2.5220435991251913	65990
0199b90509d0961cc1b37dff25bbe6d1e9c33ef1	inventory pooling with environmental constraints using copulas		Pooling is a best practice in inventory management for economic objectives. In this paper we investigate whether pooling stays advantageous if environmental sustainability is considered in addition to the economic performance, i.e. we analyze whether pooling could have a negative impact on the environment and evaluate the resulting trade-off between economic and environmental performance. Within the newsvendor framework we consider three pooling models: pooling via centralized ordering, physical centralization including inventory allocation to the retailers with priority allocation, and transshipments. In addition, we include environmental constraints based on carbon emissions covering all manufacturing and logistics operations of the product. We characterize the optimal policy of the pooling models with emission constraints, make a detailed comparison between the models and compare them to the decentralized (i.e. no pooling) case. Using copulas to model the joint distribution of dependent demands we prove that the profit decreases with increasing demand dependence. Further, if the environmental constraint is binding, optimal inventory level and emissions decrease with increasing demand dependence and pooling harms the environment compared to the case of no pooling. Additionally, we numerically evaluate the impact of copulas and characterize when the economic and environmental performance of pooling can be balanced. © 2017 Elsevier B.V. All rights reserved.	best practice;centralized computing;inventory;logistics;newsvendor model;numerical analysis	Lena Silbermayr;Werner Jammernegg;Peter Kischka	2017	European Journal of Operational Research	10.1016/j.ejor.2017.04.060	operations management;pooling;best practice;newsvendor model;economics;sustainability;joint probability distribution;microeconomics	AI	1.297013184710525	-5.460007251593635	66043
2974930f7678f2dd586710d36ca7ce66096db5b5	myopic solutions of homogeneous sequential decision processes	decision sequentielle;modelizacion;dynamic programming;revenu financier;optimisation;sequential decision;programacion dinamica;probleme statique;juego secuencial;decision secuencial;myopic;recompense;optimizacion;homogeneous process;point equilibre;static problems;inversion;real time;porcentaje ganancia;taux profit;equilibrio juego;processus homogene;grupo de excelencia;dynamic program;homogeneous;sequential game;investment;equilibrium point;modelisation;punto equilibrio;recompensa;reward;proceso homogeneo;tariffication;ingresos;ciencias basicas y experimentales;tarification;matematicas;temps reel;investissement;programmation dynamique;tiempo real;myopic solution;decision process;optimization;equilibre jeu;markov decision process;game equilibrium;grupo a;modeling;return rate;jeu sequentiel;tarificacion;income	An optimum of a Markov decision process (MDP) is myopic if it can be obtained by solving a series of static problems. Myopic optima are desirable because they can be computed relatively easily. We identify new classes of MDPs with myopic optima and sequential games with myopic equilibrium points. In one of the classes, the single-period reward is homogeneous with respect to the state variable. We illustrate the results with models of revenue management and investment.		Matthew J. Sobel;Wei Wei	2010	Operations Research	10.1287/opre.1090.0767	inversion;homogeneous;markov decision process;equilibrium point;mathematical optimization;simulation;economics;income;investment;operations management;dynamic programming;mathematics;mathematical economics;sequential game	EDA	4.671057737493884	-3.0470736286809843	66069
726a639363869cd51d7cec17622a9684d11f8df9	joint pricing and location decisions in a heterogeneous market	pricing;location;heterogeneous customers;non uniform market	In this paper we consider the problem of joint location and pricing optimization for a firm in a heterogeneous market producing a single product. We assume that customers have a different willingness to pay for the product. We consider two classes of customers who are not uniformly distributed in the market and develop an analytical framework to determine the relationship between the optimal price and location of the firm. We demonstrate that the optimal price and location are closely related to each other, and thus there is a need for simultaneous optimization of the price and location. We provide both analytical and numerical results to illustrate the impact of transportation cost and the level of heterogeneity on the firm’s strategic decisions. Our results show that simplifying the analysis of such markets with a uniform demand assumption and a homogeneity of customers may reduce the firm’s profit significantly.		Nafiseh Sedghi;Hassan Shavandi;Hossein Abouee-Mehrizi	2017	European Journal of Operational Research	10.1016/j.ejor.2017.01.055	pricing;economics;marketing;microeconomics;location;commerce	ECom	0.6827419740186452	-5.298712211002035	66114
6e2330b489643aa6ffbdb740c8d3c7cf44656dff	the reasonable range of life cycle utilization rate of distribution network equipment		The utilization rate of power equipment plays a decisive role in the economic operation of power utilities. By determining the reasonable range of life cycle utilization rate of the distribution network equipment, it is of great significance to the management of the distribution network equipment. In this paper, the reasonable range of the life cycle utilization rate of distribution network equipment is determined. The life cycle utilization rate of distribution network equipment depends on the burden rate, load rate, and life expectancy rate, whose reasonable values are analyzed and exemplified, respectively. The optimal model of the burden rate in different conditions is established. The different load characteristic curves are also given by sorting out the load data. The calculation method of the life expectance rate is presented in this paper. The reasonable range of the life cycle utilization rate is finally obtained by defining the boundary condition of its composition. By setting the reasonable range of life cycle utilization rate of the distribution network equipment, power utilities can improve efficiency.	networking hardware;sorting	Linhao Ye;Zhuangli Hu;Canbing Li;Yongjun Zhang;Shiyao Jiang;Zhiqiang Yang;Di Zhang	2018	IEEE Access	10.1109/ACCESS.2018.2803840	computer network;reliability engineering;utilization rate;networking hardware;life expectancy;computer science	Networks	7.6994978455154515	-5.003448187724871	66132
82f81750160a266811a4e892339e33854817b9e8	probabilistic impact assessment of network tariffs in low voltage distribution networks		In this paper, we present a probabilistic framework to assess the impacts of different network tariffs on the consumption pattern of electricity consumers with distributed energy resources such as thermostatically controlled loads and battery storage; and the resultant effects on the distribution network. A mixed integer linear programming-based home energy management system with implicit modeling of peak demand charge is used to schedule the controllable devices of residential customers connected to a low voltage network in order to analyze the impacts of energyand demand-based tariffs on network performance. The simulation results show that flat tariffs with a peak demand component perform best in terms of electricity cost reduction for the customer, as well as in mitigating the level of binding network constraints. This is beneficial for distribution network service providers where there is high PVbattery penetration.	integer programming;linear programming;marginal model;network congestion;network performance;resultant;simulation	Donald Azuatalam;Archie C. Chapman;Gregor Verbic	2018	CoRR		mathematical optimization;network service;peak demand;distributed generation;probabilistic logic;mathematics;cost reduction;low voltage;microeconomics;energy management system;network performance	Metrics	3.849841924647142	2.6793832998289204	66158
fd6a1dfa08686e18a2356074e40099c6a328c013	development of an intelligent decision support system for air pollution control at coal-fired power plants	intelligent decision support system;pollution control;coal fired power plant;fuzzy relation;removal efficiency;decision maker;air pollution control;power plant;decision support system;power plants;air pollution;environment;cost effectiveness;air quality;control strategy;control method;environmental problem;expert decision support system;expert system	Air pollution from power plants is responsible for some of the most pressing environmental problems today. Much research has been done on pollution control for power plants. Contemporary approaches to pollution control often take advantage of computer technology, but research on use of expert systems for power plant management is scarce. In this study an expert system was developed to assist power plant decision makers in selecting an economical and efficient pollution control system that meets new stringent emission standards. The study will also provide the key design parameters for such a system. A fuzzy relation model and a Gaussian dispersion model were integrated into this expert system. Using the fuzzy relation model, the system can quickly select feasible control methods according to the desired removal efficiency. The system will then identify the most cost effective control strategy according to economic considerations provided by users. To assess and ensure effectiveness of the selected method, ambient air quality is simulated using the Gaussian dispersion model and compared with required standards. The developed system was applied to a case study. The results generated show that the system is able to consider the trade-offs between environmental requirement and economic objective, decrease the possibility of pollutant risk, and help the power plant reduce environmental-related capital and operation costs. q 2003 Elsevier Ltd. All rights reserved.	adobe air;computer;control system;control theory;expert system;intelligent decision support system	Qian Zhou;Guo H. Huang;Christine W. Chan	2004	Expert Syst. Appl.	10.1016/j.eswa.2003.09.005	power station;decision support system;intelligent decision support system;computer science;artificial intelligence;expert system	Robotics	8.625501695972755	-5.8479385313173164	66491
ac47fb8b497b2dc20b690788eacb4ea10a99ef0c	personalized pricing and advertising: an asymmetric equilibrium analysis	mixed strategy equilibrium;bertrand equilibrium;consumer targeting;price dispersion;price advertising	We study personalized price competition with costly advertising among n quality-cost differentiated firms. Strategies involve mixing over both prices and whether to advertise. In equilibrium, only the top two firms advertise, earning “Bertrand-like” profits. Social efficiency is U-shaped in the ad cost, with losses due to excessive advertising and sales by the “wrong” firm. Quality or cost improvements at a customer’s best firm make her worse off. When firms are symmetric, the symmetric equilibrium has social surplus decreasing with n. However, we suggest an asymmetric equilibrium, with social surplus increasing in n, is more plausible for stability reasons. JEL Classifications: D43, L13	bertrand (programming language);control theory;information;nash equilibrium;pareto efficiency;personalization;perturbation theory;randomness;relevance;rendering (computer graphics);value (ethics)	Simon Anderson;Alicia Baik;Nathan Larson	2015	Games and Economic Behavior	10.1016/j.geb.2015.05.006	industrial organization;bertrand competition;economics;bertrand paradox;microeconomics;mathematical economics	ECom	-2.670373448937418	-6.857995623640171	66524
a5e4b98336457460c59126a8452132709a366ae8	two-echelon competitive integrated supply chain model with price and credit period dependent demand	competition;credit period;price sensitive demand;wholesale price;multi retailer supply chain;contract;revenue sharing	This study considers a two-echelon competitive supply chain consisting of two rivaling retailers and one common supplier with trade credit policy. The retailers hope that they can enhance their market demand by offering a credit period to the customers and the supplier also offers a credit period to the retailers. We assume that the market demand of the products of one retailer depends not only on their own market price and offering a credit period to the customers, but also on the market price and offering a credit period of the other retailer. The supplier supplies the product with a common wholesale price and offers the same credit period to the retailers. We study the model under a centralised integrated case and a decentralised Vertical Nash case and compare them numerically. Finally, we investigate the model by the collected numerical data.	row echelon form	Brojeswar Pal;Shib Sankar Sana;K. S. Chaudhuri	2016	Int. J. Systems Science	10.1080/00207721.2014.911383	contract;competition	Theory	-0.547703778988774	-5.7757102158684255	66593
1e604e3bfc5dd2cab06316e66e906a16943ed971	using natural gas reserves to mitigate intermittence of renewables in the day ahead market		We formulate and analyze a day-ahead (DA) electricity market in which a thermal power plant and a renewable generator compete with each other in their commitments to the market. The market price of energy is affected by the commitments of the generators. The renewable generator faces a settlement cost if it cannot meet its commitment due to unpredictable generation. As a hedge against this cost, it is equipped with a natural gas reserve that can either be used to compensate generation shortages or be sold in the natural gas market. We model the problem as a Stackelberg game, in which an independent system operator (ISO) sends a price signal to the generators. In response, the generators decide on their commitments to maximize their own profit. The ISO decides on the price such that the total commitment will be equal to the energy demanded by the (estimated) load. We develop sufficient conditions for the uniqueness of Nash equilibrium and obtain a quantitative solution for the Nash equilibrium. It is observed that the market price of energy is lower when the renewable generator is equipped with natural gas reserves. Furthermore, when the renewable generator is equipped with natural gas reserves, the commitments of the generators to the market are less affected by the variance of the renewable energy generation. It is also shown that a larger portion of the natural gas reserves are used for electricity generation when the renewable energy generation has higher uncertainty. Thus, the natural gas reserves act as an effective hedge against the variance in the generation of renewable energy.	cns;data privacy day (data protection day internationally);ibm notes;nash equilibrium;numerical analysis;sysop	Ashkan Zeinalzadeh;Nayara Aguiar;Stefanos Baros;Anuradha M. Annaswamy;Indraneel Chakraborty;Vijay Gupta	2017	2017 IEEE 56th Annual Conference on Decision and Control (CDC)	10.1109/CDC.2017.8264232	electricity generation;mathematical optimization;electricity market;renewable energy;computer science;price signal;stackelberg competition;natural gas;market price;nash equilibrium;microeconomics	ECom	-0.009681626141436066	-4.225948891198422	66704
2a2f3a0f7227c3651782409ac1fe84cf40221dea	first-mover advantage in round-robin tournaments	all pay contests;first mover advantage;round robin tournaments	We study round-robin tournaments with either three or four symmetric players whose values of winning are common knowledge. In the round-robin tournament with three players there are three stages, each of which includes one match between two players. The player who wins in two matches wins the tournament. We characterize the sub-game perfect equilibrium and show that each player maximizes his expected payo¤ and his probability to win if he competes in the rst and the last stages of the tournament. In the round-robin tournament with four players there are three rounds, each of which includes two sequential matches where each player plays against a di¤erent opponent in every round. We characterize the sub-game perfect equilibrium and show that a player who plays in the rst match of each of the rst two rounds has a rst-mover advantage as reected by a signicantly higher winning probability as well as a signicantly higher expected payo¤ than his opponents. JEL Classications: D44, O31 Keywords: All-pay contests, round-robin tournaments, rst-mover advantage. Department of Economics and Business Administration, Ariel University, Ariel 40700, Israel. Email: krumer.alex@gmail.com yDepartment of Managing Human Resources, Department of Practical Economics, Sapir Academic College, M.P. Hof Ashkelon 79165, Israel. zCorresponding author: Department of Economics, Ben-Gurion University of the Negev, BeerSheva 84105, Israel. Tel: 972-86472309. Fax: 972-86472941.	email;fax;higher-order function;round-robin dns;round-robin scheduling;uniform resource identifier	Alex Krumer;Reut Megidish;Aner Sela	2017	Social Choice and Welfare	10.1007/s00355-017-1027-y	economics;operations management;commerce;first-mover advantage	ECom	-2.947365487713015	-4.599192707387756	67016
9c25ab49d960470fef7936ad72d4d8fbfb45871a	stochastic programming approach for the optimal tactical planning of the downstream oil supply chain		This paper develops a multistage stochastic programming to optimally solve the distribution problem of refined products. The stochastic model relies on a time series analysis, as well as on a scenario tree analysis, in order to effectively deal and represent uncertainty in oil price and demand. The ARIMA methodology is explored to study the time series of the random parameters aiming to provide their future outcomes, which are then used in the scenario-based approach. As the designed methodology leads to a large scale optimization problem, a scenario reduction approach is employed to compress the problem size and improve its computational performance. A real-world example motivates the case study, based on the downstream oil supply chain of mainland Portugal, which is used to validate the applicability of the stochastic model. The results explicitly indicate the performance of the designed approach in tackling large and complex problems, where uncertainty is present.	analysis of algorithms;autoregressive integrated moving average;computation;downstream (software development);mathematical optimization;multistage amplifier;optimization problem;robust optimization;stochastic programming;time series	Camilo Lima;Susana Relvas;Ana Paula F. D. Barbosa-Póvoa	2018	Computers & Chemical Engineering	10.1016/j.compchemeng.2017.09.012	control engineering;fold (higher-order function);time series;mathematical optimization;downstream (petroleum industry);stochastic modelling;mathematics;autoregressive integrated moving average;stochastic programming;supply chain;optimization problem	AI	9.624493167587893	-3.157974619464515	67114
c638821afc3adce7debf7f0eda1083db63b3e9ff	using minimal cuts to study the system reliability of electronic transaction in commercial banks				Yi-Kuei Lin;Sheng-Chiang Chen;Hsien-Chang Chou	2014	IJEBM		finance;business;natural resource economics;database transaction	DB	3.247108799119508	-7.537078156757664	67258
9742215c9f6a22ea8f1f85ba948f28cf0052410d	transfer problem in a cloud-based public vehicle system with sustainable discomfort	public vehicle;transfer;multi-hop ridesharing;vehicular networks	The increasing population in urban areas gives rise to a huge traffic pressure. A cloud-based industrial system, public vehicle (PV) system, is promising to mitigate the traffic congestion in smart cities, where passengers can share PVs and transfer among them with scheduling decisions made by the cloud. This paper studies the transfer problem in the PV system due to that transfer can improve the whole traffic efficiency with sacrificing a little comfort with the corporation of all the PVs. The transfer problem is NP-Complete through our analysis. Our work can be separated into three steps. First, we introduce several factors to guarantee the comfort of passengers during transfer. Second, we propose two algorithms through the graph-based scheduling problem aiming at reducing the travel distance of all the PVs with service guarantee. Third, simulations based on the Shanghai (China) urban road network show that, the total travel distance of PVs is reduced under the quality of service for passengers, and the traffic efficiency is improved.	cloud computing	Ming Zhu;Xiao-Yang Liu;Meikang Qiu;Ruimin Shen;Wei Shu;Min-You Wu	2016	MONET	10.1007/s11036-016-0675-y	simulation;computer security	ECom	9.831393074586236	-7.59206466889887	67264
39312f17a36a13d060db029569efcad282b184e7	structural properties of an inventory system with deterioration and trended demand	modelizacion;period;optimisation;optimizacion;periodo;deterioracion;administracion deposito;modelisation;economic order quantity;cout moyen;periode;tamano lote;average cost;taille lot;coste medio;gestion stock;deterioration;lot sizing;quantite economique a commander;optimization;cantidad economica pedida;modeling;inventory control;structural properties	An order-level inventory model for deteriorating items is developed under the conditions of exponential decay, instantaneous replenishment and linear time-dependent demand rate with a positive trend. A number of structural properties of the inventory system is proved analytically. The exact formulae for the optimal average cost and the lot size are derived without carrying out any approximation over the constant deterioration rate. A numerical example is taken to illustrate the procedure of finding the optimal lot size, the average cost and the cycle period. A sensitivity analysis is carried out to demonstrate the effects of changing parameter values on the optimal solution of the system.		A. K. Jalan;K. S. Chaudhuri	1999	Int. J. Systems Science	10.1080/002077299292137	inventory control;systems modeling;economic order quantity;period;mathematical economics;operations research	Logic	4.628625617289542	-2.990017648754375	67365
efb86079f7a650a07bf59e5cf9e8f6c15bd845e8	a near-optimal maintenance policy for automated dr devices	maintenance engineering;meter reading;indexes;standards;clocks;power demand;estimation	Demand-side participation is now widely recognized as being extremely critical for satisfying the growing electricity demand in the U.S. The primary mechanism for demand management in the U.S. is demand response (DR) programs that attempt to reduce or shift demand by giving incentives to participating customers via price discounts or rebate payments. Utilities that offer DR programs rely on automated DR devices (ADRs) to automate the response to DR signals. The ADRs are faulty, but the working state of the ADR is not directly observable; one can, however, attempt to infer it from the power consumption during DR events. The utility loses revenue when a malfunctioning ADR does not respond to a DR signal; however, sending a maintenance crew to check and reset the ADR also incurs costs. In this paper, we show that the problem of maintaining a pool of ADRs using a limited number of maintenance crews can be formulated as a restless bandit problem, and that one can compute a near-optimal policy for this problem using Whittle indices. We show that the Whittle indices can be efficiently computed using a variational Bayes procedure even when the load-shed magnitude is noisy, and when there is a random mismatch between the clocks at the utility and at the meter. The results of our numerical experiments suggest that the Whittle-index-based approximate policy is within 4% of the optimal solution for all reasonably low values of the signal-to-noise ratio in the meter readings.	atx;approximation algorithm;bayesian network;binary search algorithm;emoticon;experiment;flight recorder;heuristic;kullback–leibler divergence;matroid;multi-armed bandit;numerical analysis;optimal maintenance;partially observable system;rewrite (programming);scheduling (computing);signal-to-noise ratio;software publisher;variational principle	Carlos Abad;Garud Iyengar	2016	IEEE Transactions on Smart Grid	10.1109/TSG.2015.2465834	maintenance engineering;database index;mathematical optimization;estimation;actuarial science;economics;telecommunications;computer science;electrical engineering;operations management;dynamic programming;mathematics;welfare economics;automatic meter reading;statistics	Metrics	3.3690191730832484	1.7168893174466064	67944
209b3d3fce2f4c52a25578c8c417e5216beb94a6	on the existence of optimal taxes for network congestion games with heterogeneous users	selfish routing;design optimization;network game;network congestion	We consider network congestion games in which a finite number of non-cooperative users select paths. The aim is to mitigate the inefficiency caused by the selfish users by introducing taxes on the network edges. A tax vector is strongly (weakly)-optimal if all (at least one of) the equilibria in the resulting game minimize(s) the total latency. The issue of designing optimal tax vectors for selfish routing games has been studied extensively in the literature. We study for the first time taxation for networks with atomic users which have unsplittable traffic demands and are heterogeneous, i.e., have different sensitivities to taxes. On the positive side, we show the existence of weakly-optimal taxes for single-source network games. On the negative side, we show that the cases of homogeneous and heterogeneous users differ sharply as far as the existence of strongly-optimal taxes is concerned: there are parallellink games with linear latencies and heterogeneous users that do not admit strongly-optimal taxes.	game theory;network congestion;routing	Dimitris Fotakis;George Karakostas;Stavros G. Kolliopoulos	2010		10.1007/978-3-642-16170-4_15	multidisciplinary design optimization;simulation;economics;microeconomics;mathematical economics;network congestion	ECom	-3.1260910580614434	2.4963307635484355	68054
74c4b5de9147cdda3b94b99fb92829b8272c296e	recurrent neural networks solving a real large scale mid-term scheduling for power plants	reservoirs;quadratic program;augmented lagrange energy function recurrent neural networks scheduling power plants artificial neural network operation planning problem generation systems two phase optimization neural network;power generation planning;wind power;differential equation;lagrange multiplier;satisfiability;energy function;power plant;large scale;artificial neural networks;computer aided software engineering;power engineering computing;operation planning problem;power plants;optimal scheduling;recurrent neural nets power engineering computing power generation planning power generation scheduling;scheduling;augmented lagrange energy function;mathematical model;power generation scheduling;optimization;reservoirs artificial neural networks wind power generation computer aided software engineering optimization mathematical model;generation systems;recurrent neural nets;recurrent neural networks;recurrent neural network;production cost;wind power generation;two phase optimization neural network;artificial neural network;large scale optimization;neural network	This paper deals with an application of artificial neural network (ANN) to solve the operation planning problem of generation systems in the mid-term operation horizon. This problem is related to economic power dispatch that minimizes the overall production cost while satisfies the load demand. These kinds of problem are large scale optimization problems in which the complexity increases with the planning horizon and the accuracy of the system to be modeled. This paper considers the two-phase optimization neural network which solves linear and quadratic programming problems. These networks are based on the solution of a set of differential equations that are obtained from a transformation of an augmented Lagrange energy function. This network also provides the corresponding Lagrange multiplier associated with each constraint which is the marginal price. The results indicate that the developed ANN model provides optimal scheduling of hydro, thermal and wind power plant towards the minimal operation cost.	artificial neural network;dynamic dispatch;lagrange multiplier;marginal model;mathematical optimization;quadratic programming;recurrent neural network;scheduling (computing);two-phase commit protocol	Ronaldo R. B. de Aquino;Manoel A. Carvalho;Otoni Nóbrega Neto;Milde M. S. Lira;Givanildo J. de Almeida;Solange N. N. Tiburcio	2010	The 2010 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2010.5596918	power station;mathematical optimization;computer science;recurrent neural network;machine learning;artificial neural network	AI	5.294356026945256	2.509733550677211	68144
a0a511824c4eecb18994186d1b178aeca7a1729d	graphical methods for robust design of a semiconductor burn-in process	design of experiments;discrete event simulation;integrated circuit manufacture;integrated circuit testing;process control;production engineering computing;production testing;semiconductor process modelling;sensitivity analysis;backend semiconductor manufacturing process;cycle time;discrete-event simulation;experimental design;graphical methods;integer decision variables;metamodeling techniques;product mix;robust design;semiconductor burn-in process;sensitivity analysis;simulation model;specific resource capacities;work in process	Discrete-event simulation is a common tool for the analysis of semiconductor manufacturing systems. With the aid of a simulation model, and in conjunction with sensitivity analysis and metamodeling techniques, robust design can be performed to optimize a system. Robust design problems often include integer decision variables. This paper shows a graphical approach to robust design that is effective in the presence of discrete or qualitative variables. The graphical robust design methodology was applied to a backend semiconductor manufacturing process. Changes in specific resource capacities and product mix were examined to determine their effect on the level and variance of cycle time and work in process.	burn-in;decision theory;graphical user interface;metamodeling;semiconductor device fabrication;simulation	Scott L. Rosen;Chad A. Geist;Daniel A. Finke;Jyotirmaya Nanda;Russell R. Barton	2001			computer science;systems engineering;engineering;process control;mathematics;design of experiments;statistics;manufacturing engineering	EDA	8.5892150412073	1.392330816894664	68146
af54bea910004388e5097e93b8eec43be3cb0832	application of bayesian balance for biding in power projects	bayesian balance;power plants bayes methods game theory marketing;game theory;nash equilibrium;bidding bayesian balance power project;bayes methods;biological system modeling;power project;construction industry;bayesian methods;data mining;power plants;marketing;games;bidding;economics;linear strategy;power projects;bayesian methods costs law game theory databases legal factors power system economics power generation economics power markets qualifications;linear strategy bayesian balance bidding power projects game theory	The method of game theory is applied to study the best offer of power projects and analysis the best linear strategy of our and the other bidders' offer, then the best linear strategy of our offer is obtained. It proofs that the best offer strategy of the bidders is not only relying on its own costs, but also affected by the other bidders' offer. Therefore, in order to win a bid in power projects, we are not only considering our own costs, but also striving to obtain as much information as possible in the tender offer process, and then the other bidders' costs distribution and offer range must be fully understood.	game theory	Wei Li;Yanjiao Ji;Lihong Cai	2009	2009 First International Workshop on Database Technology and Applications	10.1109/DBTA.2009.19	power station;games;game theory;bidding;bayesian probability;nash equilibrium	DB	-1.0747009563187682	-1.1598881236540726	68256
c46afcb9761e0fa04c2218566a6a78cecaeeb454	on the equilibrium personnel structure in the presence of vertical and horizontal mobility via multivariate markov chains	journal of the operational research society	The present paper employs the Multivariate Homogeneous Markov System (MHMS) in the context of Markov manpower planning modelling. The system is regulated by an embedded multivariate Markov process that allows us to distinguish employees’ mobility patterns that take place either within or among the existing divisions (departments) of an organization. The motivation behind this step arises from the generalization of univariate Markov manpower planning models in which the organization is considered a single (probably hierarchical) group and from the fact that departmental mobility is actually common in most realistic establishments. The first part of the paper presents the functional relations of the MHMS governing intra/inter-departmental transitions. Using these functional forms, we proceed by studying the system’s equilibrium behaviour. This asymptotic analysis reveals the inherent tendencies of the system to reach the limiting structures of specific forms and properties under conditions imposed in the long run. Journal of the Operational Research Society (2015) 66(6), 993–1006. doi:10.1057/jors.2014.66 Published online 9 July 2014	embedded system;markov chain	Vasileios A. Dimitriou;Andreas C. Georgiou;Nikolas Tsantas	2015	JORS	10.1057/jors.2014.66	simulation;economics;marketing;operations management;management;operations research;statistics	SE	3.7702690389188573	-6.400159803815933	68322
1ac408b16e11e2fe22c58e8f184912dd5a0447c7	benders decomposition and normal boundary intersection method for multiobjective decision making framework for an electricity retailer in energy markets	forward contracts;stochastic processes;normal boundary intersection nbi method benders decomposition electricity retailer fuzzy decision maker multiobjective mathematical programming mmp;linear programming;stochastic programming contracts decision making fuzzy set theory monte carlo methods planning power markets;electricity;electricity forward contracts optimization linear programming planning stochastic processes;planning;optimization;multiobjective optimization method benders decomposition normal boundary intersection method multiobjective decision making framework electricity retailer energy markets midterm planning portfolio management contracts electricity market framework retailer profit maximization selling price minimization pareto optimal solution generation fuzzy decision maker roulette wheel mechanism lattice monte carlo simulation random scenario generation stochastic optimization problem	In midterm planning, the objective of an electricity retailer is to manage a portfolio of different contracts and determine the selling price offered to its clients. Assuming that, within an electricity market framework, rival retailers compete for prices in order to achieve the largest possible number of clients. In addition, the reasonable criterion for the retailer is to select a solution that attains the minimum selling prices while satisfying the constraints. The proposed framework in this paper is modeled in the form of a multiobjective framework to simultaneously maximize retailers' profit and minimize selling prices to clients. The normal boundary intersection method is implemented to generate Pareto-optimal solutions. The best compromise solution is adopted using a fuzzy decision maker. Roulette wheel mechanism and lattice Monte Carlo simulation are employed for random scenario generation wherein the stochastic optimization problem is converted into its respective deterministic equivalents. Benders decomposition has been employed as a robust algorithm to reach the optimal solution. The efficiency of the presented method is verified by making a comparison of its performance with another multiobjective optimization method through a real case study to show its superiority.	algorithm;benders decomposition;electrical engineering;enterprise resource planning;entropy maximization;ibm power systems;mathematical optimization;monte carlo method;multi-objective optimization;optimization problem;pareto efficiency;plug-in (computing);simulation;stochastic optimization	Mansour Charwand;Abdollah Ahmadi;Ali Reza Heidari;Ali Esmaeel Nezhad	2015	IEEE Systems Journal	10.1109/JSYST.2014.2331322	planning;mathematical optimization;linear programming;electricity	Robotics	8.550122776863395	-2.918725163768918	68375
6bbc42d93a47a299af9f9cd020315d59ad9558e0	on allocation of redundancies in two-component series systems	journal;standby redundancy;reversed hazard rate order;likelihood ratio order;active redundancy;hazard rate order	Allocation of active standby] redundancies in a system is a topic of great interest in reliability engineering and system safety because optimal configurations can significantly increase the reliability of a system. In this paper, we study the problem of allocating two exponentially distributed active standby] redundancies in a two-component series system using the tools of stochastic ordering. We establish two interesting results on likelihood ratio ordering which have no restriction on the parameters.		Peng Zhao;Ping Shing Chan;Long Li;Hon Keung Tony Ng	2013	Oper. Res. Lett.	10.1016/j.orl.2013.09.006	active redundancy;real-time computing	Logic	7.484103187603882	-0.9036425464418345	68413
529e4b6b4454459459d32e98454a6ad289485b1d	massively parallel asset and liability management	dynamic correlation;popular risk measure;interior point methods;high performance computing;parallel processing;multistage stochastic programming;parallel architecture;massively parallel asset;liability management;popular method;enormous size	Multistage Stochastic Programming is a popular method to solve financial planning problems such as Asset and Liability Management (ALM). The desirability to have future scenarios match static and dynamic correlations between assets leads to problems of truly enormous sizes (often reaching tens of millions of unknowns or more). Clearly parallel processing becomes mandatory to deal with such problems. Solution approaches for these problems include nested Decomposition and Interior Point Methods. The latter class in particular is appealing due to its flexibility with regard to model formulation and its amenability to parallelisation on massively parallel architectures. We review some of the results and challenges in this approach, demonstrate how popular risk measures can be integrated into the framework and address the issue of modelling for High Performance Computing.	interior point method;mathematical optimization;multistage amplifier;parallel computing;risk measure;stochastic programming	Andreas Grothey	2010		10.1007/978-3-642-21878-1_52	parallel computing;simulation;computer science;operating system;distributed computing;management science	HPC	4.856140174685168	-6.955725958319483	68752
86c524cc2912c27299daeb4741aabaa49fd26b8b	pricing derivatives with counterparty risk and collateralization: a fixed point approach	collateralization;fixed point method contraction mapping;bilateral counterparty risk;credit valuation adjustment	This paper studies a valuation framework for financial contracts subject to reference and counterparty default risks with collateralization requirement. We propose a fixed point approach to analyze the mark-to-market contract value with counterparty risk provision, and show that it is a unique bounded and continuous fixed point via contraction mapping. This leads us to develop an accurate iterative numerical scheme for valuation. Specifically, we solve a sequence of linear inhomogeneous PDEs, whose solutions converge to the fixed point price function. We apply our methodology to compute the bid and ask prices for both defaultable equity and fixed-income derivatives, and illustrate the non-trivial effects of counterparty risk, collateralization ratio and liquidation convention on the bid-ask spreads.	counterparty;fixed point (mathematics)	Jinbeom Kim;Tim Leung	2016	European Journal of Operational Research	10.1016/j.ejor.2015.06.055	financial economics;actuarial science;economics;finance;credit valuation adjustment	Vision	1.1441380497389935	-2.4152314408625926	68786
16ba79e6ce96d2bdc39e81e7c1affca1c8865e14	a dynamic-material-value-based decomposition method for optimizing a mineral value chain with uncertainty	mineral value chain;decomposition method;or in natural resources;large scale optimization;market uncertainty	A decomposition method is developed to optimize a mineral value chain composed of multiple mines and a material flow circuit. In the proposed decomposition method, the upstream mine production schedule and the downstream material flow plan are optimized simultaneously to maximize the expected NPV of the entire mineral value chain. The proposed approach is tested through a practical-scale case study and the test results show that the proposed method can effectively optimize the production schedule of each mine in consideration of downstream constraints and market uncertainty. Through the observation of the test results, we show that optimizing a mineral value chain in an integrative manner and considering market uncertainty can avoid overinvestment in strategic assets and overestimation of long-term profitability. The proposed decomposition method is not limited to the setting of a specific mineral value chain and can be easily extended to integrate more impacting factors. © 2016 Elsevier B.V. All rights reserved.	downstream (software development);material flow	Jian Zhang;Roussos G. Dimitrakopoulos	2017	European Journal of Operational Research	10.1016/j.ejor.2016.08.071	decomposition method;operations management;mathematics;natural resource economics	AI	9.53212612144785	-2.8883966118864337	68868
5352c842ea7bf6d60a7186b35bdc58a497b213be	interval estimation of the herfindahl-hirschman index under incomplete market information	pareto distribution interval estimation herfindahl hirschman index hhi incomplete market information company size zipf law;market structure;companies;upper bound;indexes;computational modeling;companies upper bound indexes context computational modeling mobile communication;zipf law;settore ing inf 05 sistemi di elaborazione delle informazioni;pareto distribution;mobile communication;market structure herfindahl hirschman index hhi zipf law pareto distribution;hhi;pareto distribution econometrics market research parameter estimation;herfindahl hirschman index;context	An interval estimate is provided for the Herfindahl-Hirschman Index (HHI) when the knowledge about the market is incomplete, and we know just the largest market shares. Two rigorous bounds are provided for the HHI, without any further assumptions. Though the interval gets wider as the sum of the known market shares gets smaller, the estimate proves to be quite tight even when the fraction of the market that we do not know in detail is as high as 30%. This robustness is shown through three examples, considering respectively a set of real data and two sets of synthetic data, with the company sizes (a proxy for market shares) following respectively a Zipf law and a Pareto distribution.	entropic uncertainty;pareto efficiency;synthetic data;zipf's law	Maurizio Naldi;Marta Flamini	2014	2014 UKSim-AMSS 16th International Conference on Computer Modelling and Simulation	10.1109/UKSim.2014.66	financial economics;economics;operations management;mathematical economics	Robotics	1.7463084045967399	-7.6073978637088455	68980
61af9340b29d086c83efa0874ab6a64f22e4bcdc	costs and travel times of cooperative networks in full truck load logistics		Based on the actual situation of full truck load logistics in Germany and the idea of a reorganization of the transport routes using a cooperative network structure with encounter traffics at depots, we model one simple case to underline the expected advantages in costs and productivity. It turns out that the transport costs and unproductive time decreases drastically in the network structure and as positive side effect the job as truck driver may become more attractive.		Sergey Dashkovskiy;Bernd Nieberding	2014		10.1007/978-3-319-23512-7_19	operations management;automotive engineering;transport engineering;business	Robotics	8.87305736573988	-7.42681165814341	69070
119f974045c9e635ec6c611bb840ab5a3f3c5277	dynamic control of a tandem system with abandonments	queueing;dynamic control;health care;90b22;90b36	The goal of this paper is to provide a model that is an extension of classic scheduling problems for a tandem queueing system by including customer impatience. In such scenarios, the server(s)must balance abandonments from each phase of service with the need to prioritize higher reward customers. This presents an interesting challenge since the trade-off between the cost of abandonments and revenue maximization is not at all clear. As a result of customer abandonments, traditional solution techniques are not available. In particular, uniformization is not possible since the transition rates are unbounded. We do our analysis in continuous time, using the continuous-time Markov decision process framework to discern simple relationships of the value functions depending on the starting state. We then use sample path arguments to analyze Electronic supplementary material The online version of this article (doi:10.1007/s11134-016-9489-7) contains supplementary material, which is available to authorized users. B Mark E. Lewis mark.lewis@cornell.edu Gabriel Zayas-Cabán gzayasca@umich.edu Jingui Xie xiej@ustc.edfu.cn Linda V. Green lvg1@columbia.edu 1 Center for Healthcare Engineering and Patient Safety, University of Michigan, Ann Arbor, MI, USA 2 The School of Management, University of Science and Technology of China, Hefei, China 3 Graduate School of Business, Columbia University, New York, NY, USA 4 School of Operations Research and Information Engineering, Cornell University, Ithaca, NY, USA	authorization;columbia (supercomputer);computation;dynamic programming;expectation–maximization algorithm;information engineering;linda (coordination language);little man computer;markov chain;markov decision process;operations research;optimal control;queueing theory;scheduling (computing);two-phase commit protocol;x image extension;monotone	Gabriel Zayas-Cabán;Jingui Xie;Linda V. Green;Mark E. Lewis	2016	Queueing Syst.	10.1007/s11134-016-9489-7	simulation	ML	0.5979263851674455	0.5962308679253432	69089
53d1d1de9a8e0de70a7395d3c4a73e9f87c156da	the bellman equation for power utility maximization with semimartingales	power utility;bellman equation;portfolio constraints;utility maximization;opportunity process;ciencias basicas y experimentales;matematicas;semimartingale characteristics;portfolio management;grupo a;bsde;computational finance;random field	We study utility maximization for power utility random fields with and without intermediate consumption in a general semimartingale model with closed portfolio constraints. We show that any optimal strategy leads to a solution of the corresponding Bellman equation. The optimal strategies are described pointwise in terms of the opportunity process, which is characterized as the minimal solution of the Bellman equation. We also give verification theorems for this equation.	bellman equation;entropy maximization	Marcel Nutz	2009	CoRR	10.1214/11-AAP776	mathematical optimization;random field;computational finance;mathematics;bellman equation;mathematical economics;statistics	Theory	1.520259989474848	-2.216515471151678	69128
09d105daf3e52c2129653c7d9bfb83b5c18f6863	optimization under uncertainty of the integrated oil supply chain using stochastic and robust programming	optimization under uncertainty;scenario analysis;supply chain;stochastic programming;refinery planning;robust programming	Abstract#R##N##R##N#This paper proposes the development of a strategic planning model for an integrated oil chain considering three sources of uncertainty: crude oil production, demand for refined products and market prices. To deal with these uncertainties, three formulations are proposed: (1) a two-stage stochastic model with a finite number of realizations, (2) a robust min–max regret model and (3) a max–min model. These models were applied to Brazil's oil chain, comprising 17 refineries and three main petrochemical plants, 16 groups of crude oils, 50 intermediate products, 10 final products, 13 terminals and a logistic network composed of 278 transportation arcs relative to the road, water, rail and pipeline modes. The time horizon analyzed covers 10 years. The results indicate significant financial differences between the three formulations, depending on the agent's risk profile.	defensive programming;program optimization;stochastic process	Gabriela P. Ribas;Silvio Hamacher;Alexandre Street	2010	ITOR	10.1111/j.1475-3995.2009.00756.x	stochastic programming;mathematical optimization;simulation;computer science;operations management;mathematics;supply chain;scenario analysis	Robotics	9.603738891682324	-3.0636260245549662	69409
46cd4506b4bbfe127dc59d3e0d592f0302243a15	revenue prediction in budget-constrained sequential auctions with complementarities	learning;sequential auctions;revenue maximization;experimentation	When multiple items are auctioned sequentially, the ordering of auctions plays an important role in the total revenue collected by the auctioneer. When historical data are available, it is possible to learn a model in order to predict the outcome of a given sequence. In this work, we show how to construct such a model, and provide methods that finds a good sequence for a new set of items given the learned model. We develop an auction simulator and design several experiment settings to test the performance of the proposed methods.	complementarity theory;simulation	Sicco Verwer;Yingqian Zhang	2012			combinatorial auction;economics;marketing;microeconomics;commerce	ML	-0.17982713465993236	-6.690185059916434	69949
d9fecbd047cfab936e437a4eaf85afdb12ef7cf3	fair resource allocation in a volatile marketplace	fairness;network revenue management;dynamic resource allocation;matching problems;online advertising	We consider the setting where a seller must allocate a collection of goods to budgeted buyers, as exemplified by online advertising systems where platforms decide which impressions to serve to various advertisers. Such resource allocation problems are challenging for two reasons: (a) the seller must strike a balance between optimizing her own revenues and guaranteeing fairness to her (repeat) buyers and (b) the problem is inherently dynamic due to the uncertain, time-varying supply of goods available with the seller.  We propose a stochastic approximation scheme akin to a dynamic market equilibrium. Our scheme relies on frequent re-solves of an Eisenberg-Gale convex program, and does not require the seller to have any knowledge about how goods arrival processes evolve over time. The scheme fully extracts buyer budgets (thus maximizing seller revenues), while at the same time provides a 0.47 approximation of the proportionally fair allocation of goods achievable in the offline case, as long as the supply of goods comes from a wide family of (possibly non-stationary) Gaussian processes.  We then extend our results to a more general family of metrics called \alpha-fairness. Finally, we deal with a multi-objective problem where the seller is concerned with both the proportional fairness and efficiency of the allocation, and propose a hybrid algorithm which achieves a 0.27 bi-criteria guarantee against fairness and efficiency.	convex optimization;emoticon;fairness measure;gaussian process;hybrid algorithm;online advertising;online and offline;proportionally fair;scheme;stationary process;stochastic approximation	MohammadHossein Bateni;Yiwei Chen;Dragos Florin Ciocan;Vahab S. Mirrokni	2016		10.1145/2940716.2940763	mathematical optimization;online advertising;economics;computer science;operations management;microeconomics;commerce	AI	2.90042096904528	-3.182876737605362	70327
e5e8d07a676d77040fa3db8ebdde150dd8ea8b1b	liquidity tail risk and credit default swap spreads		We show that liquidity tail risk in credit default swap (CDS) spreads is time-varying and explains variation in CDS spreads. We capture the liquidity tail risk of a CDS contract written on a firm by estimating the tail dependence, i.e., the asymptotic probability of a joint surge in the bid-ask spread of the firm’s CDS and the illiquidity of a CDS market index. Our results show that protection sellers earn a statistically and economically significant premium for bearing the risk of joint extreme downwards movements in the liquidity of individual CDS contracts and the CDS market. This effect holds in various robustness checks such as instrumental variable regressions and alternative liquidity measures and is particularly pronounced during the financial crisis.	paging;risk aversion	Felix Irresberger;Gregor N. F. Weiß;Janet Gabrysch;Sandra Gabrysch	2018	European Journal of Operational Research	10.1016/j.ejor.2018.02.030	operations management;stock market index;financial economics;financial crisis;tail risk;liquidity risk;credit default swap;instrumental variable;mathematics;tail dependence;market liquidity	Crypto	-2.1122794210369733	-8.554088416584749	70413
c7e2816d6326da1732e34485554e8337d8feaf8a	mathematical model of the occurrence of human error in manufacturing processes	mathematical model;human error;manufacturing system;reliability model	Various types of phenomena contribute to the variability of process results. Their common feature is randomness. Some of them can be described by continuous probability distributions, for example, the performance of machines or the properties of processed material. There are also discretely distributed contributions, such as human errors or machine failures. Six sigma methodology encompasses both continuous and discrete phenomena by expressing measures of variability by the so-called ‘sigma measure’. However, this methodology cannot be used directly to assess the individual impact of a specific class of factors, such as human errors in a continuously distributed production process. This paper describes the development of a probabilistic model of human error. The model makes use of classical reliability concepts, such as a failure rate function, to represent substantial phenomena of various types (continuous and discrete) that play a significant role in the creation of errors in human work. The model includes a mechanism that is inherently associated with human work (i.e. the ‘bathtub curve’ that represents the processes of learning and fatiguing) and mechanisms introduced by the work environment (accumulation of tasks). The hypothesis is formulated that, in industrial processes, special causes of errors are closely related to the assignment of inadequate amounts of time for properly performing the operations. Graphs of error rate functions enable intuitive graphical interpretation of the causes of problems, and they can be used to support some considerations regarding the organization and measurement of workflow during a work shift. Thus, an intuitive graph can be useful for figuring out the potential impact on the risk of errors that will result from certain system events. Such graphs can be applied in a general capability study of a process to assess the variability measures associated with the individual impacts of particular classes of factors, for example, the sigma measure used in the six sigma methodology. It can be used to identify mechanisms of potential failures associated with human error in risk analysis, such as FMEA (Failure Mode and Effect Analysis). Copyright © 2010 John Wiley & Sons, Ltd.	bathtub curve;bit error rate;bus mastering;distributed manufacturing;error message;failure cause;failure mode and effects analysis;failure rate;graphical user interface;heart rate variability;human error;john d. wiley;mathematical model;randomness;schedule (computer science);spatial variability;statistical model;tree accumulation	Jan M. Myszewski	2010	Quality and Reliability Eng. Int.	10.1002/qre.1162	human error assessment and reduction technique;simulation;human error;computer science;engineering;operations management;mathematical model;mathematics;operations research;statistics	SE	7.516470609107027	-2.034972145776478	70503
725db8ae276c477569e75fc4da5d248acb4264c7	dynamic simulation of water resources sustainable utilization of kiamusze based on system dynamics	sustainable utilization;kiamusze;system dynamics;regional water resources;water supply and demands;water resources;会议论文;water utilization;sensitive parameter;dynamic simulation;agricultural productions;policy guidance;fixed numbers;supporting capacities;socio economic development	In order to determine the sustainable supporting capacity of current Kiamusze water utilization situation to future society and economy, a dynamic simulation model of water resources sustainable utilization was built based on system dynamics (SD). The simulation results indicated that current Kiamusze water resources could not satisfy future demand of industrial and agricultural production and also restricted socioeconomic development. In view of the situation, the water resources sustainable utilization schemes were designed and simulated by targeting water supply and demand balance and adjusting sensitive parameters of the model. The analysis showed that the coordinated scheme not only realized water resources sustainable utilization but also enhanced the sustainable supporting capacity of water resources to society and economy within the fixed number of simulating years. Thus, the coordinated scheme is the best one for water resources sustainable utilization of Kiamusze and can provide policy guidance for further exploitation of regional water resources.	dynamic simulation;system dynamics	Qiuxiang Jiang;Zilong Wang;Qiang Fu	2012		10.1007/978-3-642-36137-1_43	water conservation;environmental planning;economics;water resource management;environmental resource management;integrated water resources management	AI	6.949414774403522	-7.335071574189841	70529
798a7e5f10d31ce06b99303b318c53f70cc9e1f7	technical note - price-setting newsvendor problems with uncertain supply and risk aversion	pricing;risk aversion;grupo de excelencia;supply uncertainty;inventory;marketing;ciencias basicas y experimentales;matematicas;production;grupo a	The price-setting newsvendor problem, which models the economic trade-offs associated with uncertain demand of a perishable product, is fundamental to supply chain analysis. However, in settings such as agriculture, there is significant economic risk associated with supply uncertainty. We analyze how risk aversion and the source of uncertainty—demand and/or supply—affect tractability and optimal decisions. We find that concavity of the objective function is preserved under the introduction of risk aversion if the source of uncertainty is demand, but it is not necessarily preserved if the source of uncertainty is supply. We identify a structural difference that explains this result, and show that this difference can lead to opposing directional effects of risk aversion on optimal decisions.	concave function;loss function;newsvendor model;optimization problem;risk aversion	Burak Kazaz;Scott Webster	2015	Operations Research	10.1287/opre.2015.1366	financial economics;pricing;risk aversion;inventory;economics;marketing;risk;microeconomics;commerce	AI	0.7115022897865865	-3.4647685581707024	70611
bbc38b98255309d44a7864a065da527b1157610c	budget management strategies in repeated auctions	repeated auctions;budget constraints;ad auctions;budget management;online advertising;internet advertising	In online advertising, advertisers purchase ad placements by participating in a long sequence of repeated auctions. One of the most important features advertising platforms often provide, and advertisers often use, is budget management, which allows advertisers to control their cumulative expenditures. Advertisers typically declare the maximum daily amount they are willing to pay, and the platform adjusts allocations and payments to guarantee that cumulative expenditures do not exceed budgets. There are multiple ways to achieve this goal, and each one, when applied to all budget-constrained advertisers simultaneously, steers the system toward a different equilibrium. While previous research focused on online stochastic optimization techniques or game-theoretic equilibria of such settings, our goal in this paper is to compare the “system equilibria” of a range of budget management strategies in terms of the seller’s profit and buyers’ utility. In particular, we consider six different budget management strategies including probabilistic throttling, thresholding, bid shading, reserve pricing, and multiplicative boosting. We show these methods admit a system equilibrium in a rather general setting, and prove dominance relations between them in a simplified setting. Our study sheds light on the impact of budget management strategies on the tradeoff between the seller’s profit and buyers’ utility. Finally, we also empirically compare the system equilibria of these strategies using real ad auction data in sponsored search and randomly generated bids. The empirical study confirms our theoretical findings about the relative performances of budget management strategies. ∗We thank Omar Besbes and Gabriel Weintraub for helpful discussions that motivated this research. The full paper version is available at http://ssrn.com/abstract= 2858261. †Part of this work was done when the author was an intern at Google, Inc. c ©2017 International World Wide Web Conference Committee (IW3C2), published under Creative Commons CC BY 4.0 License. WWW 2017, April 3–7, 2017, Perth, Australia. ACM 978-1-4503-4913-0/17/04. http://dx.doi.org/10.1145/3038912.3052682	deferred shading;game theory;mathematical optimization;online advertising;performance;procedural generation;randomness;search engine marketing;shading;stochastic optimization;thresholding (image processing);www;world wide web	Santiago R. Balseiro;Anthony Kim;Mohammad Mahdian;Vahab S. Mirrokni	2017		10.1145/3038912.3052682	budget constraint;online advertising;computer science;world wide web	ECom	-2.223403994916038	-2.0173537132534602	70638
fd4181cad6716621135bbbb24b8df0f344a82251	vertical cooperative advertising and pricing decisions in a manufacturer-retailer supply chain: a game-theoretic approach	game theory;nash equilibrium;pricing;cooperative advertising;stackelberg equilibrium	Manufacturers can increase the advertising expenditures of their retailers by bearing a fraction of the occurring costs within the framework of a vertical cooperative advertising program. We expand the existing research which deals with advertising and pricing decisions in a manufacturer–retailer supply chain contemporaneously. By means of game theory, four different relationships between the channel members are considered: Firstly, three non-cooperative games with either symmetrical distribution of power or asymmetrical distribution with one player being the leader in each case, and one cooperative game where both players tend to maximize the total profit. The latter is complemented by a bargaining model, which proposes a fair split of profit on the basis of the players’ risk attitude and bargaining power. Our main findings are as follows: (a) In contrast to previous analyses, we do not limit the ratio between manufacturer’s and retailer’s margin, which provides more general insights into the effects of the underlying distribution of power within the channel. (b) The highest total profit is gained when both players cooperate. This behavior puts also the customers in a better position, as it produces the lowest retail price as well as the highest advertising expenditures compared to the other configurations.	game theory	Gerhard Aust;Udo Buscher	2012	European Journal of Operational Research	10.1016/j.ejor.2012.06.042	non-cooperative game;pricing;game theory;economics;marketing;microeconomics;stackelberg competition;nash equilibrium;commerce	ECom	-1.6773918626009998	-6.008558881949451	70668
37c89949fd8648a72ede8eb7759b7ce468bdb9c5	the optimal used period of repairable product with leadtime after the warranty expiry	intervalo tiempo;modelizacion;garantie;reliability;replacement;new product;remplacement;producto nuevo;time interval;lead time;modelisation;warranty;guarantee;reparation;produit nouveau;reemplazo;tiempo puesta en marcha;reparacion;modeling;garantia;temps mise en oeuvre;repair;new products;intervalle temps;leadtime	This paper considers the two-phase warranty models for repairable products. It defines the time-interval [0, W] as the first phase (warranty period) and the time interval (W, T + W) as the second phase (buyer survival period). The products have two types of failures: type I failures (minor failures) and type II failures (catastrophic failures). In the model, type I failures are also removed by minimal repairs in the first and the second phases, and type II failures are removed by replacements in the first phase. If type II failures take place in the second phase, then it is supposed the life of products will be ended. To buy a new product is conducted at time T+W or upon the type II failure. Whenever each replacement takes place, the spare unit is ordered and then delivered. Therefore, the lead-time is considered. This thesis considers three warranty and maintenance models for seller, buyer and the society. The objective is to obtain the optimal T *. Finally, a numerical example is provided.		Jhy-Ping Jhang	2005	Int. J. Systems Science	10.1080/00207720500150978	reliability engineering;mean time between failures;systems modeling;engineering;reliability;mathematics;forensic engineering;new product development;statistics	Logic	6.552844045414434	-2.1067676836555957	70715
a0a5213e4343dcd1772a247249400e07e4c2c7ee	composition of markets with conflicting incentives	bob;canonical model;incentive compatibility;information extraction;conflicting incentives;scoring rule;adverse effect;prediction market;prediction markets;perfect bayesian equilibrium;market scoring rule;profitability;information revelation	We study information revelation in scoring rule and prediction market mechanisms in settings in which traders have conflicting incentives due to opportunities to profit from the market operator's subsequent actions. In our canonical model, an agent Alice is offered an incentive-compatible scoring rule to reveal her beliefs about a future event, but can also profit from misleading another trader Bob about her information and then making money off Bob's error in a subsequent market. We show that, in any weak Perfect Bayesian Equilibrium of this sequence of two markets, Alice and Bob earn payoffs that are consistent with a minimax strategy of a related game. We can then characterize the equilibria in terms of an information channel: the outcome of the first scoring rule is as if Alice had only observed a noisy version of her initial signal, with the degree of noise indicating the adverse effect of the second market on the first. We provide a partial constructive characterization of when this channel will be noiseless. We show that our results on the canonical model yield insights into other settings of information extraction with conflicting incentives.	alice and bob;canonical model;information extraction;minimax;quantum channel;regret (decision theory);rule 184;theory;traders	Stanko Dimitrov;Rahul Sami	2010		10.1145/1807342.1807350	scoring rule;bayesian game;actuarial science;economics;incentive compatibility;adverse effect;computer science;artificial intelligence;canonical model;microeconomics;mathematical economics;welfare economics;information extraction;commerce;profitability index	ECom	-4.455745231376185	-3.8961699574904025	70790
159448c591ffd388249d2f4a813b94e5f05bb827	quantifying consumer interest and consumer valuation from buy-it-now offers		An item offered in the buy-it-now offer (BINO) format is sold to the first consumer who is willing to pay the asked price. The “lifetime” of a BINO, therefore, depends on how many consumers are interested in the item and on how much they value it. In this paper, we model this dependency by combining survival analysis and auction theory. Our model enables sellers to quantify consumer interest and consumer valuation for their items from observing BINO lifetimes only. Further, the influence of covariates (e.g., the item condition) can be investigated. To demonstrate this, we apply our model to a dataset that we have collected from eBay. The dataset consists of 1,821 BINOs of a single product, the iPhone 5S. For this example, we find a new item to attract, on average, 1.26 consumers per day, who have a mean valuation of 384.97 EUR.	object lifetime;value (ethics)	Patrick Winter	2015			marketing;microeconomics;commerce	ECom	-2.243941836308115	-9.633266251502018	70800
c1d5a36bca10a51aafa4e2ae8f044143fa62ebcc	an analysis of baseball batting order by monte carlo simulation	monte carlo simulation	A Monte Carlo simulation of over 200,000 baseball games, using a programmed embodiment of the main features of the Sports Illustrated baseball game, shows that batting order exerts only a small influence on the outcomes of baseball games. The effect of using the best batting order rather than the worst is less than three extra wins per 162-game season. The traditional lineup, wherein a team's strongest batters hit in the third through fifth positions, is superior to a lineup in which batters are arranged in decreasing order of productivity.	monte carlo method;simulation	R. Allan Freeze	1974	Operations Research	10.1287/opre.22.4.728	simulation;operations management;mathematics;statistics;monte carlo method;computer graphics (images)	DB	-4.286443122948257	-8.44456190729128	70831
55e7735256d4551dcb91d3fd9d59e668df9325e3	a stock market trading system based on foreign and domestic information		Abstract This paper investigates whether a particular magnitude and direction of inter-regional return signal transmission dominates the performance of domestic trading in American, European and Australasian stock markets. A trading system design, based on fuzzy logic rules, combines direct and indirect channels of foreign information transmission, modelled by stochastic parameter regressions, with domestic momentum information to generate stock market trading signals. Filters that control for magnitude and direction of trading signals are then used to investigate incremental impact on economic performance of the proposed investment system. The results indicate that at reasonable levels of transaction costs very profitable trades that are fewer in number do not increase investment performance as much as trades based on foreign information of a specific low-to-medium daily return magnitude of 0.5% to 0.75%. These information-based strategies are profitable on risk-adjusted bases and relative to a market, but performance declines considerably when tradable instruments are used.		Janusz Brzeszczynski;Boulis Maher Ibrahim	2019	Expert Syst. Appl.	10.1016/j.eswa.2018.08.005	data mining;fuzzy logic;stock market;transaction cost;magnitude (mathematics);transmission (telecommunications);transmission (mechanics);microeconomics;investment performance;computer science;communication channel	NLP	0.6775325919123565	-8.279985305019526	70930
3b5c41b4d948ad105c2f4eef6a4f9d21053d7d7c	optimal vehicle dispatching for ride-sharing platforms via dynamic pricing		"""Dispatching problem, intrinsic differences between: Ride-sharing Traditional Taxi Centralized dispatching Yes No Dynamic pricing Yes No Big data & real-time analysis Yes No Optimal dispatching? Combined with pricing Separated with pricing Contirbutions • Propose a graph model to analyze the vehicle pricing and dispatching problem • Induce a MDP model and reduce it to a convex problem by randomized pricing and """"ironing"""" technique • Characterize the optimal solution via primal-dual analysis • Perform extensive empirical analysis and our algorithm significantly outperforms the other two methods."""	big data;centralized computing;convex optimization;randomized algorithm;real-time clock	Mengjing Chen;Weiran Shen;Pingzhong Tang;Song Zuo	2018		10.1145/3184558.3186924	mathematical optimization;unified model;markov decision process;dynamic pricing;revenue;optimization problem;traffic congestion;economics;economic problem;supply and demand	AI	2.9628928740511538	2.5423591793545337	71040
faea165f24b07f35004607ce65572baf7f6d2c24	opportunities for price manipulation by aggregators in electricity markets	electricity supply industry power measurement energy resources iso real time systems optimization power systems;aggregators renewables optimal curtailment market power locational marginal price lmp	Aggregators are playing an increasingly crucial role for integrating renewable generation into power systems. However, the intermittent nature of renewable generation makes market interactions of aggregators di cult to monitor and regulate, raising concerns about potential market manipulations. In this paper, we address this issue by quantifying the profit an aggregator can obtain through strategic curtailment of generation in an electricity market. We show that, while the problem of maximizing the benefit from curtailment is hard in general, e cient algorithms exist when the topology of the network is radial (acyclic). Further, we highlight that significant increases in profit can be obtained through strategic curtailment in practical settings.		Navid Azizan Ruhi;Krishnamurthy Dvijotham;Niangjun Chen;Adam Wierman	2018	IEEE Trans. Smart Grid	10.1109/TSG.2017.2694043	economics;computer science;microeconomics;economy;market economy	Robotics	2.5605729823108803	3.1714479339526767	71066
2b572c3defa2fbf26be30a39a626f13aadb00da4	online allocation with traffic spikes: mixing adversarial and stochastic models	stochastic analyses;robust algorithm;online allocation;online advertisments;traffic spikes;budgeted allocation;factor revealing lp	Motivated by Internet advertising applications, online allocation problems have been studied extensively in various adversarial and stochastic models. While the adversarial arrival models are too pessimistic, many of the stochastic (such as i.i.d or random-order) arrival models do not realistically capture uncertainty in predictions. A significant cause for such uncertainty is the presence of unpredictable traffic spikes, often due to breaking news or similar events. To address this issue, a simultaneous approximation framework has been proposed to develop algorithms that work well both in the adversarial and stochastic models; however, this framework does not enable algorithms that make good use of partially accurate forecasts when making online decisions. In this paper, we propose a robust online stochastic model that captures the nature of traffic spikes in online advertising. In our model, in addition to the stochastic input for which we have good forecasting, an unknown number of impressions arrive that are adversarially chosen.We design algorithms that combine an stochastic algorithm with an online algorithm that adaptively reacts to inaccurate predictions. We provide provable bounds for our new algorithms in this framework. We accompany our positive results with a set of hardness results showing that that our algorithms are not far from optimal in this framework. As a byproduct of our results, we also present improved online algorithms for a slight variant of the simultaneous approximation framework.	approximation;online advertising;online algorithm;provable security;stochastic process	Hossein Esfandiari;Nitish Korula;Vahab S. Mirrokni	2015		10.1145/2764468.2764536	mathematical optimization;simulation;computer science;artificial intelligence;machine learning;mathematical economics;statistics	ML	-1.032027562920299	0.767467517066561	71268
d3ccef11f29cb8fb94e84cc5f5ef28f8424a4d5f	simulation of lumber processing for improved raw material utilization	analytical models;raw materials milling machines wood industry manufacturing analytical models costs atmospheric modeling strips production solid modeling;raw materials;wood industry;solid modeling;manufacturing;milling machines;production;shift language;technical report;strips;atmospheric modeling;flow simulation;process simulation;general applications;hybrid systems	Lumber processing simulation allows the user an opportunity to examine ways to best utilize the many grades of lumber available to the user. It is most important that the simulation must be able to accurately model the processing plant steps and be capable of obtaining the desired part sizes in the correct quantities. This gives management the ability to increase production and reduce costs associated with lost yield. Flow simulation allows the user to try out different plant layout scenarios as well as engineer a plant prior to construction.	simulation	Timothy Stiess	1997		10.1145/268437.268769	atmospheric model;strips;process simulation;computer science;engineering;technical report;raw material;solid modeling;manufacturing;world wide web;engineering drawing;hybrid system;manufacturing engineering	Arch	9.2296914136825	3.975964787209632	71431
30b2ac248c0c9e8b853c44c9d5f55b27ee63d768	valuation of variable annuity contracts with cliquet options in asia markets	contracts;asia market investment;variable annuity contract valuation;insurance;variable annuity;cliquet option;complicated payoff structure;quanto feature;stock markets;united states;monte carlo method;variable annuity contract;risk management;monte carlo methods;efficient monte carlo method;investment;equity-linked insurance contract;numerical example;asia market;calendar year;mean squared error;simulation	Variable annuities are very appealing to the investor. For example, in United States, sales volume on variable annuities grew to a record 184 billion in calendar year 2006. However, due to their complicated payoff structure, their valuation and risk management are challenges to the insurers. In this paper, we study a variable annuity contract with cliquet options in Asia markets. The contact has quanto feature. We propose an efficient Monte Carlo method to value the contract. Numerical examples suggest our approach is quite efficient.	monte carlo method;numerical method;risk management;value (ethics)	Ming-hua Hsieh	2008	2008 Winter Simulation Conference		actuarial science;risk management;statistics;monte carlo method	AI	1.6464851598041086	-8.58587077633534	71573
c6f10f4ab9fe2e19366bff80497209a4a7c98218	partially informed investors: hedging in an incomplete market with default				Paola Tardelli	2015	J. Applied Probability	10.1017/S0021900200113397	filter;actuarial science;dynamic programming;mathematics	NLP	0.6409301926218254	-2.540477811062352	71608
6905971c15511c0ef8cd435800eba46eca433815	optimal replacement last with continuous and discrete policies	biological system modeling;maintenance engineering radio frequency equations mathematical model optimization educational institutions biological system modeling;maintenance engineering;working cycle replacement minimal repair replacement last maintenance;radio frequency;mathematical model;optimization;statistical analysis reliability theory;replacement first policy optimal replacement last model continuous replacement policy discrete replacement policy comparative method continuous optimization discrete optimization	This paper proposes age and periodic replacement last models with continuous, and discrete policies. That is, an operating unit is replaced preventively at time T of operation as a strategic policy, or at a number N of working cycles to satisfy successive job completion, whichever occurs last. Such policies are named as replacement last, and their expected cost rates and optimal policies are obtained. However, the focus of this paper is to compare replacement last with replacement first policies, which are formulated under the classical assumption of whichever occurs first. From the points of cost and performability, different comparative methods for continuous and discrete optimizations are demonstrated to determine in what cases we should adopt replacement last rather than replacement first. All theoretical discussions in this paper are made analytically, and are computed numerically.	numerical analysis	Xufeng Zhao;Toshio Nakagawa;Ming Jian Zuo	2014	IEEE Transactions on Reliability	10.1109/TR.2014.2337811	maintenance engineering;reliability engineering;simulation;engineering;mathematical model;mathematics;radio frequency;statistics	DB	6.850112618614224	-0.828338132184157	71649
ade06b2c9034f3ecfa9301b9776f512aad07f20d	warranty inventory optimization for hitachi global storage technologies, inc	single location;warranty returns;inventory;stochastic;heuristics;periodic;applications;closed loop supply chains	Warranty inventory management is a challenge that many companies must confront. Customers return allegedly defective units to a company for replacement or credit. The company can then economically recover the unit through either a testing or remanufacturing process; it can use recovered units to fulfill future warranty requests. The company also has the option of purchasing a new product from the production line. In high-volume situations, warranty inventory management involves many complexities such as stochastic demand rates, probabilistic requests for credit instead of replacement, probabilistic repairs, multiple sources of supply, and tight customer-service constraints. Companies may also have to consider the complexities that a batch remanufacturing process causes.#R##N##R##N#In this paper, we formulate several related models of such warranty inventory systems. In these models, we study a periodic, single-location, inventory system that is dedicated to warranty returns. We find near-optimal policies for each system using well-developed heuristics. The models include the following complexities: random warranty claims, random requests for replacement or credit, three sources of supply (testing, remanufacturing, and new product), random flows of returned products into testing and remanufacturing, random yields from testing and remanufacturing, different lead times for each resupply process, remanufacturing lead time variability, and random batching of remanufacturing. The results of the models provide near-optimal inventory-control policies in this complex environment and demonstrate the payoffs that result from reducing production lead times and batching in remanufacturing.#R##N##R##N#Hitachi GST has gained a great deal from this modeling process. In addition to the direct benefit from the model's calculations, additional sensitivity analyses have shed light on the quantitative importance of various factors, including demand volatility, the percentage of credit requests, the percentage of units successfully remanufactured, and batching effects in remanufacturing.		John Khawam;Warren H. Hausman;Dinah W. Cheng	2007	Interfaces	10.1287/inte.1070.0299	inventory;economics;marketing;operations management;heuristics;mathematics;stochastic;operations research;information technology;statistics;commerce	EDA	3.487716110623023	-4.516226732233193	71650
3be511dbe4429e756dd74bed2ce724b38c4060f3	simultaneous design and scheduling of a semicontinuous/batch plant for ethanol and derivatives production	ethanol and yeast productions;batch semicontinuous plant design;mixed integer linear programming;scheduling	The interest on renewable fuels has greatly increased in the last years. Particularly, ethanol production arises as a good solution to many current economic-environmental problems. Yeast production from the ethanol residuals constitutes a sustainable alternative. Usually, this kind of plants is designed using single product campaigns. However, since yeast degradation is fast and a continuous supply must be assured, the mixed product campaign policy is the most appropriate. Besides, a stable context can be assumed to justify this approach that takes advantage of the special structure of the plant. Therefore, in this paper, a mixed integer linear programming model is formulated for simultaneous design and scheduling of a semicontinuous/batch plant for ethanol and derivatives production. The optimal plant configuration, unit sizes, number of batches of each product in the campaign and its sequencing is obtained in order to fulfill the ethanol and yeast demands minimizing the investment cost.	scheduling (computing);semi-continuity	Yanina Fumero;Jorge M. Montagna;Gabriela Corsano	2012	Computers & Chemical Engineering	10.1016/j.compchemeng.2011.08.004	mathematical optimization;computer science;engineering;waste management;scheduling	OS	9.22745132186005	-4.170164793174312	71734
00c1186bbb837fee9f58cc75390c7f90fea76326	"""semiconductor fab layout design analysis with 300-mm fab data: """"is minimum distance-based layout design best for semiconductor fab design?"""""""	semiconductor fab design;amhs;material flow design;factory layout design	The minimum distance based layout is verified.The min-distance based layout is not effective when the product volume is high.The process groups between which the highest flow traffic should be separated.Tips for robust layout design are provided. In this paper, one of the most common layout design approaches in general factory design - minimum flow-weighted distance (min-distance) layout - is verified for semiconductor fabrication facility (FAB) design. In min-distance layout design, machines or workstations with high flow rates are allocated close to each other to minimize the total distance of the material flow. This approach is widely used in various industries including semiconductor manufacturing. However, some research also discusses the drawbacks of this approach due to flow congestions and heavy traffic in material handling systems. We validate the min-distance approach with actual data from a modern 300-mm DRAM FAB. We logically generate 18 different cases with different layouts, overhead hoist transport track configurations, and production scenarios. The effectiveness and drawbacks of the min-distance approach in FAB design is investigated with these cases. From the simulation analysis using the Design of Experiments method, we logically show that the performance of material delivery is sensitive to the production volume in the min-distance layout. Also, the performance of the min-distance layout is significantly degraded when the volume is heavy; however, performance can be improved considerably with a few modifications to the bays. We also provide practical tips for an effective layout design method from the insight gained from the simulation analysis. This paper contributes to the critical analysis of the conventional layout design method and the identification of its effectiveness and limitations by using actual FAB data.	semiconductor fabrication plant	Junghoon Kim;Gwangjae Yu;Young Jae Jang	2016	Computers & Industrial Engineering	10.1016/j.cie.2016.02.012	physical design;simulation;engineering;operations management;engineering drawing;standard cell	EDA	9.776020466179144	3.4057305104857356	72223
67228455eb971643c4426ded63cbb3ba85b4bc34	agent competition double-auction mechanism	taxe;tax;tratamiento transaccion;multiagent system;asymptotic efficiency;systeme aide decision;sintesis mecanismo;tasa;sistema ayuda decision;prise decision;synthese mecanisme;taxes;fiscalizacion;decision support system;eficacia asintotica;fiscalite;subasta;efficacite asymptotique;presupuesto;bidding;strategyproof mechanism;budget;enchere;mechanism synthesis;transaction processing;cout commercialisation;sistema multiagente;mechanism design;toma decision;private information;double auction;costo comercializacion;traitement transaction;systeme multiagent;sales costs	T paper proposes an agent competition double-auction mechanism to simplify decision making and promote transactions for the customer-to-customer marketplaces. Under the proposed double-auction mechanism, bidding one’s true valuation (private information) is the best strategy for each individual buyer and seller even when shipping costs and sales taxes are different across various possible transactions. The proposed mechanism also achieves budget balance and asymptotic efficiency. Furthermore, these results not only hold for an environment where buyers and sellers exchange identical commodities, but also can be extended to an environment with multiple substitutable commodities.	customer to customer;personally identifiable information;value (ethics)	Leon Yang Chu;Zuo-Jun Max Shen	2006	Management Science	10.1287/mnsc.1060.0528	industrial organization;mechanism design;private information retrieval;decision support system;economics;bidding;transaction processing;operations management;double auction;economy	Web+IR	-1.8187478862772755	-4.9157079817953795	72280
38ef9527ca03be3eeb79b02ab741ae19e1b8c858	option pricing for pure jump processes with markov switching compensators	asset prices;european option;hedging;jump process;markov switching;60g44;option pricing;journal article;stock price;characteristic function;60g51;91b28;60g10;european options;compensator;large classes	The paper proposes a model for asset prices which is the exponential of a pure jump process with an N -state Markov switching compensator. This model extends that of Madan and Konikov. Such a process has a good chance of capturing all empirical stylized features of stock price dynamics. A closed form representation of its characteristic function is given. Option pricing is formulated in Fourier transform space. Joint work with Carlton Osakwe (Haskayne School of Business, University of Calgary).	characteristic function (convex analysis);markov chain;time complexity	Robert J. Elliott;Carlton-James U. Osakwe	2006	Finance and Stochastics	10.1007/s00780-006-0004-6	financial economics;hedge;characteristic function;economics;valuation of options;finance;microeconomics;statistics	ML	1.2293038168000043	-1.7525155245822694	72488
31ccb6a68ae5805f0b1faecd6b13f4efd2024ebf	unilateral production restrictions in a dynamic duopoly	nash equilibrium;dynamic game;duopoly;unilateral restriction;profitability	This paper examines a dynamic game of exploitation of a productive asset by a duopoly. A closed-loop Nash equilibrium of the game is constructed and used to analyze the effects of a unilateral production restriction. Surprisingly, such unilateral action may result in a decrease of the long-run asset's stock. We also exhibit production restrictions that can result  simultaneously  in an increase of the asset's stock  and  the long-run profits of the firm that is being imposed the production restriction. Moreover, a unilateral decrease of the production of one firm can induce its rival to also decrease its production.		Hassan Benchekroun	2003	J. Economic Theory	10.1016/S0022-0531(03)00090-5	economics;microeconomics;market economy;sequential game;nash equilibrium;profitability index;duopoly;labour economics	ECom	-2.9675622488025675	-5.275270784981624	72635
2c1c15b1f1424287f613906e0226c22738abcbe3	duopoly market analysis within one-shot decision framework with asymmetric possibilistic information	duopoly market;life cycle;possibilistic cournot equilibrium;decision problem;keywords duopoly market;focus points;possibility theory;one shot decision;market analysis;possibility distribution;new products	In this paper, a newly emerging duopoly market with a short life cycle is analyzed. The partially known information of market is characterized by the possibility distribution of the parameter in the demand function. Since the life cycle of the new product is short, how many products should be produced by two rival firms is a typical one-shot decision problem. Within the one-shot decision framework, the possibilistic Cournot equilibrium is obtained for the optimal production level of each firm in a duopoly market with asymmetrical possibilistic information. The analysis results show that the proposed approaches are reasonable for one-shot decision problems, which are extensively encountered in business and economics.	decision problem;nash equilibrium	Peijun Guo;Ruiliang Yan;John Wang	2010	Int. J. Comput. Intell. Syst.	10.1080/18756891.2010.9727741	biological life cycle;possibility theory;computer science;artificial intelligence;decision problem;market analysis;duopoly	ECom	-0.17130786246684646	-6.135167940301349	72693
ec6becf097f307cc0d6227516baeb0c70558944a	priority pricing with application to time-shared computers	time sharing	Where a commodity cannot be stored, the producer is generally unable to adjust the supply instantaneously to randomly fluctuating demands. When the demand is greater than the supply, some consumers can be put into queues. Since consumers can differ significantly in the urgency of their requests, important social costs may be involved if adequate procedures are not designed to favor the individuals whose requests are the most urgent.	computer;randomness	Maurice Marchand	1968		10.1145/1476589.1476658	operations management;microeconomics;business;commerce	ECom	1.4209168595230874	-5.402232176055854	72731
61dadc1edaf3c5f31078f77de882dea5e66e05d5	using simulation to assess costs of quality	financial data processing;costing;financial data processing quality control digital simulation costing inspection manufacturing data processing;quality improvement;inspection;costs inspection profitability manufacturing systems testing sampling methods assembly appraisal productivity virtual manufacturing;manufacturing data processing;microsoft fortran 5 1 inserts simulation quality cost assessment defective inspection rates defective removal strategies profitability manufacturing system quality improvement justification slamsystem;profitability;fortran;technical report;quality control;manufacturing system;digital simulation;cost of quality	This paper illustrates the impact of defective rates of inspection and defective removal strategies on the profitability of a manufacturing system. The use of simulation to assess the cost of quality for justification of quality improvement is demonstrated. The model is written for the academic version of SLAMSYSTEM with Microsoft FORTRAN 5.1 inserts.	fortran;simulation	L. Leslie Gardner;Mary E. Grant;Laurie J. Rolston	1995		10.1145/224401.224756	reliability engineering;quality costs;quality control;quality management;inspection;systems engineering;engineering;technical report;activity-based costing;profitability index	HPC	8.412886335826803	1.7896333521369316	72760
e71c909933768838559eec0dc6aecfdc7f4118fe	analysis and design for multi-unit online auctions	posted price;online auctions;auctions bidding;lot size	By incorporating platform fees and bidders’ stochastic arrival process into the analysis of the multi-unit Vickrey auctions, we examine the performance of the two popular selling mechanisms (posted price and auction) on the Internet, characterize and derive the closed-form solution for the optimal lot-sizing policies. We show that the seller prefers auctions rather than posted price selling only when the valuation dispersion and the Web traffic are both sufficiently large. The theory also implies that there is no dominant selling mechanism. Since it is not always beneficial for the seller to auction more goods in a single auction, we further derive the optimal number of auction the seller should run and the optimal number of units to be sold in each auction. Moreover, we consider how to reconcile the conflict interests between the seller and the auction platform in single period and multi-period auctions respectively. Our main results indicate that, to decrease the listing fees, increase commission ratio and shorten the auction duration are all helpful for the platform to coordinate its interests with that of the seller.		Hong Wang	2017	European Journal of Operational Research	10.1016/j.ejor.2016.11.031	spectrum auction;auction algorithm;eauction;vickrey auction;combinatorial auction;generalized second-price auction;unique bid auction;auto auction;marketing;reverse auction;vickrey–clarke–groves auction;proxy bid;common value auction;revenue equivalence;multiunit auction;english auction;microeconomics;auction theory;commerce;forward auction;dutch auction	ECom	-1.4041923802953242	-5.666493045632654	72904
0b8ca04391a20f14fa62851c3cf7f6b1eed65e30	an integrated framework for competitive multi-channel marketing of multi-featured products		For any company, multiple channels are available for reaching a population in order to market its products. Some of the most well-known channels are (a) mass media advertisement, (b) recommendations using social advertisement, and (c) viral marketing using social networks. The company would want to maximize its reach while also accounting for simultaneous marketing of competing products, where the product marketings may not be independent. In this direction, we propose and analyze a multi-featured generalization of the classical linear threshold model. We hence develop a framework for integrating the considered marketing channels into the social network, and an approach for allocating budget among these channels.	emoticon;social network;threshold model	Swapnil Dhamal	2018	CoRR		mass media;threshold model;viral marketing;computer science;social network;population;marketing;communication channel	ML	-2.2718862109807616	-6.570529081822621	72991
c667a276e10ac9b39ad6f83ab16b9456e7b178bf	probabilistic selling in quality-differentiated markets	probabilistic selling;quality differentiated markets;welfare;pricing;quality choice;grupo de excelencia;administracion de empresas;product line design;economia y empresa;grupo a;services marketing	"""Probabilistic selling-the sale of synthetic products consisting of a lottery between two distinct goods-has been extensively analyzed in horizontal markets. In this research, we investigate probabilistic selling in quality-differentiated markets. This is an important new dimension of inquiry because of the widespread prevalence of quality-differentiated markets as well as significant differences in the preference structure across these markets. In fact, this latter consideration casts doubt as to whether probabilistic selling will even emerge in quality-differentiated markets. We find that probabilistic selling emerges in quality-differentiated markets as a way to profitably dispose excess capacity; moreover, probabilistic selling remains viable even under endogenous quality choice. In addition, in markets where sellers employ """"strong"""" quality differentiation, the introduction of an intermediate probabilistic good actually causes closer quality levels in a product line and enhances consumer welfare. In contrast, in markets where sellers employ """"weak"""" quality differentiation, the introduction of an intermediate probabilistic good increases quality separation and degrades consumer welfare. Overall, we view our contribution as one of characterizing the optimality, implementation, and policy implications of probabilistic selling in quality-differentiated markets.#R##N##R##N#This paper was accepted by Pradeep Chintagunta, marketing."""		Zelin Zhang;Kissan Joseph;Ramanathan Subramaniam	2015	Management Science	10.1287/mnsc.2014.1974	pricing;actuarial science;economics;marketing;welfare;finance;microeconomics;management;commerce	Theory	-1.5161319121014252	-7.397992979741267	73110
c410b6736971df03fd49954261283154b2951ab7	impact of consumer reviews and ratings on sales, prices, and profits: theory and evidence	data collection;consumer surplus;empirical research;profitability;pricing;economic impact;competitive strategy;ecommerce	We provide a theoretical framework to understand the impacts of consumer reviews and ratings on firms’ prices, sales, profits, and consumer surplus. We show how the economic impacts may differ depending on the informativeness of the reviews, the quantifiability of the product attributes, and the competitive environment. First, even though a monopolist always benefits from an improvement in product rating, a firm in a competitive market can hurt by it. When the low quality firm’s product rating improves, its equilibrium profit will decrease if its quality is above a threshold, and increase if its quality is below that threshold. Second, if the high quality firm’s product rating improves, both the high quality and the low quality firm will benefit. Our empirical findings based on point-and-shoot digital camera and multivitamin data collected from Amazon.com provide strong support for these results.	digital camera;display resolution;online shopping	Bao-Jun Jiang;Bin Wang	2008			competitive advantage;data collection;marketing;empirical research;profitability index;profit (economics);economic impact analysis;economic surplus;perfect competition;economics	Web+IR	-2.954752555210724	-8.50730881362149	73154
b052f3cb661803000b58e5906d1807faafb86776	terminating decision algorithms optimally	bayes estimation;politica optima;mise a jour;arret optimal;prior probability;loi probabilite;ley probabilidad;aumentacion;bayesian updating;temps lineaire;probabilite a priori;temps minimal;ejecucion programa;augmentation;probabilistic approach;tiempo lineal;optimal policy;satisfiability;teoria decision;program execution;devis estimatif;actualizacion;interrupcion optima;estimacion bayes;presupuesto estimativo;increase;theorie decision;distribution temporelle;enfoque probabilista;execution programme;probabilidad a priori;approche probabiliste;probability distribution;linear time;decision theory;decision theoretic;minimum time;optimal stopping;number;estimate;algoritmo optimo;nombre;algorithme optimal;politique optimale;optimal algorithm;tiempo minimo;distribucion temporal;numero;updating;estimation bayes;time distribution	Incomplete decision algorithms can often solve larger problem instances than complete ones. The drawback is that one does not know whether the algorithm will finish soon, later, or never. This paper presents a general decision-theoretic method for optimally terminating such algorithms. The stopping policy is computed based on a prior probability of the answer, a payoff model describing the value that different probability estimates would provide at different times, and the algorithm’s run-time distribution. We present a linear-time algorithm for determining the optimal stopping policy given a finite cap on the number of algorithm steps. To increase accuracy, the initial satisfiability probability and the run-time distribution are conditioned on features of the instance. The expectation of the result at each future time step is computed using Bayesian updating. We then extend the framework to settings where no exogenous cap is given on the number of algorithm steps. The method also provides a normative basis for algorithm selection. Finally, our method can be used to terminate and/or select complete algorithms optimally as well.	algorithm selection;decision theory;divergence (computer science);newman's lemma;optimal stopping;terminate (software);time complexity	Tuomas Sandholm	2003		10.1007/978-3-540-45193-8_85	probability distribution;time complexity;mathematical optimization;prior probability;optimal stopping;numero sign;decision theory;mathematics;bayesian inference;grammatical number;algorithm;statistics;satisfiability	AI	6.248623315831019	-1.814251447556115	73205
40efc3f8f873fb3897aedfbe83c111d84c252ce7	allocating flexible servers in serial systems with switching costs	make to order;queuing system;production system;state dependence;optimal policy;switching costs;server allocation;flexible servers;switching cost	Consider a firm that operates a make-to-order serial production system and employs a cross-trained workforce. We model such a firm as a tandem queuing system in which flexible servers can be allocated across stations, and assume that a switching cost is charged when servers move between stations. We show that even in the two-station two-server case the optimal policy follows a complex state-dependent structure that may be difficult to implement in practice. We propose three alternate heuristic policies and assess their performance. We show that a simpler policy which only moves one server can achieve close to optimal results.	heuristic;production system (computer science);server (computing);tandem computers	Maria E. Mayorga;Kevin M. Taaffe;Ramesh Arumugam	2009	Annals OR	10.1007/s10479-009-0575-7	build to order;real-time computing;simulation;computer science;operations management;queue management system;production system	Metrics	4.684792077545949	-0.2891994915303439	73351
55e6db451acfae502250fe797f259d59dd0621f5	optimal production and rationing policies of a make-to-stock production system with batch demand and backordering	production en flux pousse;politica optima;poisson process;backorder;produccion flujo empujado;exponential distribution;random medium;ley exponencial;gestion production;batch production;loi exponentielle;production system;customization;systeme production;personnalisation;procede discontinu;batch demand;optimal policy;satisfiability;sistema produccion;production management;encargo en retardo;inventory;administracion deposito;produccion por lote;tamano lote;medio aleatorio;taille lot;rationing;gestion produccion;production par lot;batch process;personalizacion;gestion stock;lot sizing;production;procedimiento discontinuo;rationnement;proceso poisson;markov decision process;commande en retard;politique optimale;make to stock;inventory control;milieu aleatoire;processus poisson	In this paper, we consider stock rationing problem of a single-item make-to-stock production/inventory system with multiple demand classes. Demand arrives as a Poisson process with a randomly distributed batch size. It is assumed that the batch demand can be partially satisfied. The facility can produce a batch up to a certain capacity at the same time. Production time follows an exponential distribution. We show that the optimal policy is characterized by multiple rationing levels.	production system (computer science);randomness;scrum (software development);time complexity	Jianjun Xu;Shaoxiang Chen;Bing Lin;Rohit Bhatnagar	2010	Oper. Res. Lett.	10.1016/j.orl.2010.01.006	inventory control;markov decision process;exponential distribution;poisson process;inventory;build to stock;mathematics;production system;mathematical economics;statistics;batch processing;satisfiability	ML	5.48035791350417	-2.198660279870964	73552
ee7c6d8677c638be3583bd258185f18924fd062f	real-time, cooperative enterprises for customised mass production	qa75 electronic computers computer science szamitastechnika;integrated approach;szamitogeptudomany;real time control;integrable system;real time;physical sciences;mass production;product line;planning and scheduling;large scale;scheduling;information fusion;production scheduling;monitoring and control;production network;coordination	1 The paper discusses the main requirements that are posed by customized mass production towards managing production networks. Special emphasis is put on real-time, cooperative behaviour. We present a large-scale national industry-academia R&D project aimed at improving the performance of a production network that produces consumer goods in large quantities and variability. An integrated approach is outlined for planning and scheduling the behaviour of the system at network-, factory-and plant levels, as well as for adapting the various plans and schedules to real execution conditions. Novel, integrated solutions are described for rolling horizon production scheduling of a factory with more than 100 production lines, for real-time control of daily production supported by information fusion and simulation, as well as for cooperative component supply. The industrial deployment of the integrated systems is also presented together with some lessons of their routine application. 1. Introduction Markets are typically served by competing production networks that consist of autonomous enterprises. Hence, as competition and cooperation go on hand in hand, the whole operation of the economy becomes more complex. Nodes and structures of networks are changing, thus making company relations more dynamic and less predictable. Today's greatest pressures are time compression, customization and cost reduction: the market increasingly demands products that are customized, yet available with shorter delivery times. While any network as a whole is driven by the overall objectives to meet customer demand at the possible minimal production and logistic costs, the efficiency of operations and the economical use of material, energy and resources hinges on the local decisions of the autonomous partners. Taking high service level as their main priority, manufacturers can hedge against uncertainties only by capacity and/or material buffers. This however, incurs extra equipment, labor, inventory and organizational costs, as well as – especially under dynamic market conditions – the risk of producing obsolete inventory. Enterprises are independent entities, with their own resources, performance objectives and internal decision mechanisms. They have to find their specific trade-offs between service level and cost that are acceptable for their partners. Hence, an overall solution can only emerge from the interaction of local and asynchronous decisions (Monostori et al., 2006). The key decisions are related at least to three distinct levels: • There is an inevitable need to design both the architecture and behaviour of such network organizations that are able to perceive and respond to market demand by sustaining coordination and, if …	automated planning and scheduling;autonomous robot;entity;inventory;real-time clock;real-time computing;real-time transcription;requirement;scheduling (computing);simulation;software deployment;spatial variability	László Monostori;Tamás Kis;József Váncza;Botond Kádár;Gábor Erdös	2009	Int. J. Computer Integrated Manufacturing	10.1080/09511920802369324	integrable system;mass production;simulation;real-time control system;computer science;engineering;operations management;industrial engineering;operating system;physical science;scheduling;scheduling;mechanical engineering	AI	4.350326630078154	0.36109534539694776	73777
922a3023b0f3a3cf31fe48fe2462929c92611f18	two commodity coordinated inventory system with markovian demand	poisson process;continuous review inventory system;reordering policy;markovian demand;probability distribution;operating characteristic;limiting probability distribution;joint inventory level	This paper considers a two commodity continuous review inventory system. The demand points for each commodity are assumed to form Poisson processes. It is further assumed that the demand for the first commodity require the one unit of second commodity in addition to the first commodity with probability p1. Similarly, the demand for the second commodity require the one unit of first commodity in addition to the second commodity with probability p2. This assumption model the situation in which a buyer who intends to buy one particular commodity may also go for another commodity. The limiting probability distribution for the joint inventory levels is computed. Various operational characteristics, expression for the long run total expected cost rate is derived. The results are illustrated with numerical examples.		V. S. S. Yadavalli;Gunaseelan Arivarignan;N. Anbazhagan	2006	APJOR	10.1142/S0217595906001005	financial economics;probability distribution;poisson process;economics;operations management;mathematics;microeconomics;demand curve;statistics	ML	3.6812058107806362	-1.3980238826022013	73852
8e3750b209536e05918d55ffa296d3649f960f1c	optimal partitioning of groups in selecting the best choice	dynamic programming;sequential decision making;utility function;dynamic program;decision maker;decision analysis;probability distribution;optimal stopping;applied probability;stochastic model;optimal stopping rule;stochastic model applications	"""This article deals with the group interview problem, in which each group contains several alternatives and each group of alternatives is presented and evaluated sequentially over time. We derive the optimal selection strategy for the group interview problem with a general utility function. Among the various types of utility function, we focus on the best choice problem, in which our utility is one if we successfully select the best choice and zero otherwise. We derive a simple selection rule called the optimal partitioning strategy in which the decision-maker divides the entire groups into two disjoint sets and, after evaluating the choices in the """"rst set, chooses the relatively best choice available for the """"rst time in the second set. Because the selected choice is not necessarily the absolutely best choice, we also consider the probability distribution of the actual rank of the choice selected under the partitioning strategy. Scope and purpose In many managerial decision situations such as buying a car, selling a house, or searching for a job, several alternatives are presented sequentially and an accept-or-reject decision is made immediately after evaluating each alternative. The classical secretary problem and its extensions have been successfully applied to such a sequential search and selection problem. This article deals with a more generalized version of the secretary problem, called the group interview problem, in which several groups of alternatives are presented and evaluated sequentially over time. Based on a stochastic dynamic programming approach, we propose the optimal selection strategy for the group interview problem with various types of the decision-maker's utility function. There are many potential applications of the group interview problem, including consumer search and purchase process, job search problem, sequential assignment of batch jobs, and so on. 2001 Elsevier Science Ltd. All rights reserved."""	dynamic programming;job (computing);linear search;search problem;secretary problem;selection algorithm;selection rule;stochastic programming;utility	Young H. Chun	2001	Computers & OR	10.1016/S0305-0548(00)00047-2	probability distribution;decision-making;mathematical optimization;optimal decision;optimal stopping;decision analysis;stochastic modelling;dynamic programming;mathematics;applied probability;operations research;statistics	AI	8.759564548567381	-1.6225024114529019	73890
503880487c7b1132650babb638384593c7311ebd	a new model for selfish routing	it strategy;navio;latencia;metodo caso peor;equilibrio nash;psychologie sociale;nash equilibrium;aumentacion;latence;augmentation;nash equilibria;selfish routing;routage reseau;network routing;strategie nash;equilibre nash;increase;estructura social;psicologia social;methode cas pire;coste;estrategia nash;coordinacion;social psychology;nash strategy;latency;ship;social structure;worst case method;structure sociale;coordination;mixed strategy;cout;navire	In this work, we introduce and study a new, potentially rich model for selfish routing over non-cooperative networks as an interesting hybridization of the two prevailing such models, namely the KP model [26] and the W model [36]. In the hybrid model, each of n users is using a mixed strategy to ship its unsplittable traffic over a network consisting of m parallel links. In a Nash equilibrium, no user can unilaterally improve its Expected Individual Cost. To evaluate Nash equilibria, we introduce Quadratic Social Cost as the sum of the expectations of the latencies incurred by the squares of the accumulated traffics. This modeling is unlike the KP model, where Social Cost [26] is the expectation of the maximum latency incurred by the accumulated traffics; but it is like the W model since Quadratic Social Cost can be expressed as a weighted sum of Expected Individual Costs. We use Quadratic Social Cost to define Quadratic Coordination Ratio. Here are our main findings: • Quadratic Social Cost can be computed in polynomial time. This is unlike the #Pcompleteness [18] of computing Social Cost for the KP model. • For the case of identical users and identical links, the fully mixed Nash equilibrium [29], where each user assigns positive probability to every link, maximizes Quadratic Social Cost. • As our main result, we present a comprehensive collection of tight, constant (that is, independent of m and n), stictly less than 2, lower and upper bounds on Quadratic Coordination Ratio for several, interesting special cases. Some of the bounds stand in contrast to corresponding super-constant bounds on Coordination Ratio previously shown in [13, 25, 26, 29] for the KP model. ∗A preliminary version of this work appeared in the Proceedings of the 21st International Symposium on Theoretical Aspects of Computer Science, V. Diekert and M. Habib eds., pp. 547–558, Vol. 2996, Lecture Notes in Computer Science, Springer-Verlag, Montpellier, France, March 2004. This work has been partially supported by the IST Program of the European Union under projects ALCOM-FT (contract number IST-1999-14186). FLAGS (contract number IST-2001-33116) and DELIS (contract number 001907). †Faculty of Computer Science, Electrical Engineering and Mathematics, University of Paderborn, Fürstenallee 11, 33102 Paderborn, Germany. Email: {luck,bm,rode}@uni-paderborn.de ‡Department of Computer Science, University of Cyprus, P. O. Box 20537, Nicosia CY-1678, Cyprus. Email: mavronic@ucy.ac.cy	electrical engineering;email;lecture notes in computer science;nash equilibrium;pixel;routing;stacs;springer (tank);time complexity;weight function	Thomas Lücking;Marios Mavronicolas;Burkhard Monien;Manuel Rode	2004		10.1007/978-3-540-24749-4_48	simulation;computer science;artificial intelligence;mathematical economics;nash equilibrium	Theory	-4.420318021381496	1.3105809108595705	73895
19841615a1c2669222bce0a2abc5855c8f095050	existence of coordinating transshipment prices in a two-location inventory model	modelizacion;variabilidad;logistique;optimal decision;localization;localizacion;prise decision;decision maker;inventory model;administracion deposito;modelisation;decision optimale;profit;systeme incertain;localisation;logistics;beneficio;transbordo;gestion stock;benefice;transbordement;coordinacion;supply chain;global optimization;profitability;variability;toma decision;sistema incierto;variabilite;modeling;inventory control;uncertain system;coordination;logistica;transhipment;decision optimal;uncertain capacity	We consider a two-location production/inventory model where each location makes production decisions and is subject to uncertain capacity. Each location optimizes its own profits. Transshipment (at a cost) is allowed from one location to another. We focus on the question of whether one can globally set a pair of coordinating transshipment prices, i.e., payments that each party has to make to the other for the transshipped goods, that induce the local decision makers to make inventory and transshipment decisions that are globally optimal. A recent paper suggests, for a special case of our model, that there always exists a unique pair of coordinating transshipment prices. We demonstrate through a counterexample that this statement is not correct and derive sufficient and necessary conditions under which it would hold. We show that in some conditions, coordinating prices may exist for only a narrow range of problem parameters and explore conditions when this can happen. Finally, we study the effects of demand and capacity variability on the magnitude of coordinating transshipment prices.	inventory theory	Xinxin Hu;Izak Duenyas;Roman Kapuscinski	2007	Management Science	10.1287/mnsc.1060.0694	inventory control;logistics;decision-making;transshipment;profit;systems modeling;optimal decision;internationalization and localization;economics;marketing;operations management;supply chain;operations research;welfare economics;profitability index;global optimization	Theory	0.9781437968985838	-4.907382084814432	73914
5694eab80a34a377c064422bb5f1d56b27da892a	revenue management with costly price adjustments	dynamic programming;rentabilidad;politica optima;cost price;gestion entreprise;prix revient;programacion dinamica;price adjustment;revenue management;asymptotic optimality;economic sciences;producto perecedero;pricing;precio costo;real time;heuristic method;porcentaje ganancia;taux profit;accounting;grupo de excelencia;firm management;metodo heuristico;comptabilite;optimal policy;fijacion precios;modelo fluido;fluid model;horizonte finito;administracion deposito;optimalite asymptotique;profit;ciencias economicas;planificacion;tariffication;beneficio;horizon fini;ciencias basicas y experimentales;tarification;perishable item;matematicas;temps reel;programmation dynamique;coste;gestion stock;benefice;tiempo real;finite horizon;coordinacion;administracion empresa;planning;rentabilite;contabilidad;profitability;sciences economiques;modele fluide;methode heuristique;planification;publicidad;grupo a;publicite;politique optimale;inventory control;produit perissable;return rate;fixation prix;price adjustment costs;coordination;tarificacion;advertising;cout	We consider a novel variant of the perishable inventory profit management problem faced by a firm that sells a fixed inventory over a finite horizon in the presence of price-adjustment costs. In economics literature, such price-adjustment costs are widely studied and are typically assumed to include a fixed component (e.g., advertising costs), an inventorydependent component (e.g., inventory relabeling costs), as well as a component that depends on the magnitude of the price adjustment (e.g., cognitive and coordination managerial costs). We formulate the firm’s profit management problem as a finite-horizon dynamic program in which the state of the system is described by the inventory level as well as the current price level. We derive first-order properties of the optimal value function and give a complete characterization of optimal policies for the case of ample inventory. Through a set of examples we demonstrate the complex and counterintuitive nature of optimal price-adjustment policies. Consequently, we focus on developing easily computable and implementable heuristics with demonstrably good performance. To this end, we develop and solve a fluid model based on the original stochastic dynamics and propose three fluid-based heuristic policies. We derive expressions for the expected profit generated by each one of these heuristics when applied to the stochastic problem and derive sufficient conditions for the asymptotic optimality of the policies when the initial inventory levels and planning horizons are proportionally scaled up. We test the performance of the heuristics in a numerical study and demonstrate a robust, near-optimal performance of one of the heuristics (which we call the “Fluid Time” heuristic) for a wide range of problem parameters. Finally, we demonstrate the importance of proper accounting of price-adjustment costs in several alternative business settings.	approximation algorithm;asymptotically optimal algorithm;bellman equation;bundle adjustment;computable function;dynamic programming;first-order predicate;graph labeling;heuristic (computer science);list of code lyoko episodes;mortar methods;numerical analysis;optimization problem;price point;programming model;regular expression;state space;stochastic process	Sabri Çelik;Alp Muharremoglu;Sergei Savin	2009	Operations Research	10.1287/opre.1090.0731	cost price;inventory control;planning;pricing;rate of return;inventory theory;profit;economics;input/output;marketing;operations management;dynamic programming;economy;mathematical economics;profitability index	AI	4.003475322552242	-3.274464378451748	74274
186b281b7dd066239ed04001fff9cfb2e8677691	dominant-strategy auction design for agents with uncertain, private values		We relax a strong assumption of classical auction theory, that bidders have perfect certainty about their own valuations. Instead, we assume that the agents begin uncertain, but can reduce their uncertainty for a cost. (i.e., they are deliberative agents [LS01].) Our contributions are: • characterizing the set of single-good auctions giving rise to dominant strategies for such agents: sequential posted-price auctions; • reformulating the revelation principle to apply to deliberative agents. Motivation Uncertainty about valuations is common among bidding agents: • Thinking hard is costly. • Valuations can be hard to compute (e.g., using the good optimally could require combinatorial optimization). Deliberative agents defy many of the common intuitions based on results from classical auction theory: • Many auctions designs that have dominant strategies in classical models–2 price, Japanese and eBay (ascending proxy)–do not have dominant strategies in deliberative agent models [S00;CJ01;R06]. • Efficient auctions are known [BV02;CP08], but none with dominant strategies. • No dominant strategy mechanism for general quasi-linear settings also satisfies other (modest) requirements [LS05]. Model We require that agents have independent, private values. Deliberative agents can nevertheless be quite complex: • may be able to choose among a wide range of deliberations • available deliberations may depend on the agent’s current belief state • deliberations may be noisy • agents may be unable ever to discover their values perfectly • agents may be able to learn about each other’s valuations as well as their own Intuitively, it is as though each agent gets her private information from a black-box source. [LS05]	black box;combinatorial optimization;deliberative agent;mathematical optimization;personally identifiable information;requirement	David Robert Martin Thompson;Kevin Leyton-Brown	2011			common value auction	AI	-2.7098784312116155	-1.9046131013763976	74422
c7b42b41a8d2d1ee0e5d40dbde404e0c4619aa85	optimal lot-sizing problem with imperfect maintenance and imperfect production	preventive maintenance;integrable model;production process;hazard rate;economic production quantity;lot sizing	In this paper, we develop an integrated model for the joint determination of both economic production quantity and level of preventive maintenance (PM) for an imperfect production process. This process has a general deterioration distribution with increasing hazard rate. The effect of PM activities on the deterioration pattern of the process is modelled using the imperfect maintenance concept. In this concept, it is assumed that after performing PM, the ageing of the system is reduced in proportion to the PM level. After a period of time in production, the process may shift to out-of-control states, either type I or type II. A minimal repair will remove the type I out-of-control state. If a type II out-of-control state occurs, the production process has to stop, and then restoration work is carried out. Examples of Weibull shock models are given to show that the use of PM reduces costs.		Shey-Huei Sheu;Jih-An Chen	2004	Int. J. Systems Science	10.1080/00207720310001657090	reliability engineering;preventive maintenance;engineering;scheduling;hazard ratio;forensic engineering	Logic	6.8627552218370855	-1.322016088411517	74545
7a134e8e6be5d345ce4c495d19509cbc62e4a7f4	a sustainable aggregate production planning model for the chemical process industry		Abstract Process industries typically involve complex manufacturing operations and thus require adequate decision support for aggregate production planning (APP). In this paper, we focus on two relevant features of APP in process industry operations: (i) sustainable operations planning involving multiple alternative production modes/routings with specific production-related carbon emission and the social dimension of varying operating rates, (ii) integrated campaign planning with the operational level in order to anticipate production mix/volume/routing decisions on campaign lead times and WIP inventories as well as the impact of variability originating from a stochastic manufacturing environment. We focus on the issue of multi-level chemical production processes and highlight the mutual trade-offs along the triple bottom line concerning economic, environmental and social factors. To this end, production-related carbon emission and overtime working hours are considered as externalized factors as well as internalized ones in terms of resulting costs. A hierarchical decision support tool is presented that combines a deterministic linear programming model and an aggregate stochastic queuing network model. The approach is exemplified at a case example from the chemical industry to illustrate managerial insights and methodological benefits of our approach.	aggregate data	Gerd J. Hahn;Marcus Brandenburg	2018	Computers & OR	10.1016/j.cor.2017.12.011	triple bottom line;manufacturing operations;management science;network model;real-time computing;mathematics;queueing theory;aggregate planning;decision support system;work in process;abstract process	ML	5.579786911616148	-6.919977019064373	74762
a006886d53f155267272327be7228a0e434f7b77	equilibrium returns with transaction costs		We study how trading costs are reflected in equilibrium returns. To this end, we develop a tractable continuous-time risk-sharing model, where heterogeneous mean-variance investors trade subject to a quadratic transaction cost. The corresponding equilibrium is characterized as the unique solution of a system of coupled but linear forward-backward stochastic differential equations. Explicit solutions are obtained in a number of concrete settings. The sluggishness of the frictional portfolios makes the corresponding equilibrium returns mean-reverting. Compared to the frictionless case, expected returns are higher if the more risk-averse agents are net sellers or if the asset supply expands over time. Mathematics Subject Classification (2010): 91G10, 91G80. JEL Classification: C68, D52, G11, G12.	cobham's thesis;mathematics subject classification;risk aversion	Bruno Bouchard;Masaaki Fukasawa;Martin Herdegen;Johannes Muhle-Karbe	2018	Finance and Stochastics	10.1007/s00780-018-0366-6	financial economics;economics;stochastic differential equation;liquidity premium;transaction cost	ML	0.5992330130564342	-2.6384741967859897	74853
7037152fd7f82e68d778bc0d2d1c676087cfde0c	how to play with a biased coin?	institutional repositories;fedora;biased coin;vital;random variable;vtls;zero sum game;probability measure;ils	We characterize the max min of repeated zero-sum games in which player one plays in pure strategies conditional on the private observation of a fixed sequence of random variables. Meanwhile we introduce a definition of a strategic distance between probability measures, and relate it to the standard Kullback distance.  2002 Elsevier Science (USA). All rights reserved.	kullback–leibler divergence;maxima and minima	Olivier Gossner;Nicolas Vieille	2002	Games and Economic Behavior	10.1016/S0899-8256(02)00507-9	random variable;probability measure;regular conditional probability;data mining;mathematics;zero-sum game;statistics	AI	-4.13288767214536	-0.9417651653921241	75038
92e0f1a2e643daa7cbbc5d9073ef81824955cf51	leaving the tier: an examination of asymmetry in pricing patterns in online high tech shops		We analytically illustrate that maximizing profit in a market with products that quickly degrade in price motivates market leaders to make both aggressive price increases and decreases that exceed that of the market followers, flipping between attempts to capitalize on their brand name and using capturing a large majority of the market. We examine 475,866 prices and 51,260 price changes for 810 high-tech products from 26 vendors over 283 days and show that a price premium does exist for the market leaders, implying a marginal revenue advantage, but aggressive price increases and aggressive price decreases are made by market leaders, and how market followers are unable or unwilling to competitively respond to these price changes. This research adds to the discussion of market friction, tiers, and market leaders by showing how market leaders may be motivated to drastically cut prices cuts, and how such price cuts can be profit maximizing.		Charles A. Wood;Sourav Ray;Paul R. Messinger	2013		10.1007/978-3-642-39808-7_6	marketing;operations management;business;commerce	NLP	-3.4225180341083705	-7.801975547548911	75079
aa278f38f059332210c789ba36d8206c0e09fda6	planning merchandise investments using fuzzy optimization		This article presents a model of retail buyers investing in merchandise for resale to consumers. Given a selection or portfolio of merchandise to buy for a store, the retailer must determine the optimal percentage investment in each item. Depending upon the buyer's investment objectives and tolerance of risk, the profit of the portfolio is maximized while the risk is simultaneously minimized. We first model this investment decision using mean-variance optimization and then reformulate the nonlinear programming model to include a fuzzy objective function and fuzzy constraints. Our results indicate that the fuzzy approach increases the flexibility and profitability of the model, assisting the retailer to build portfolios of merchandise that satisfy consumer demand under conditions of uncertainty.	program optimization	Charles V. Trappey;Amy J. C. Trappey	1993	Journal of Intelligent and Fuzzy Systems	10.3233/IFS-1993-1301	mathematics;fuzzy logic;artificial intelligence;product (business);machine learning;microeconomics;profitability index;nonlinear programming;portfolio	Robotics	1.2519714872424759	-5.759224077469727	75110
09aa1e878a9e873d2f30c6dd17a1ca17c4088535	optimal stockpile problems with stochastic consumption saturation and solution interval	stochastic processes mathematical model equations economics optimal control planning cost function;stochastic processes continuous time systems economics optimal control optimisation;optimal stockpile problems stochastic consumption saturation solution interval economic problems optimal management strategic resource stockpiles optimal control problems continuous time economic systems input saturation effects;finance optimal control uncertain systems	Economic problems in the optimal management of strategic resource stockpiles can be rigorously studied and solved by formulating them as optimal control problems in continuous time. Often, the real economic systems and stockpiling scenarios of interest exhibit both stochastic features and input saturation effects. Building on work to account for saturation effects into basic optimal stockpile problems, the following paper solves a basic optimal stockpile model with a stochastic saturation limit as well as a stochastic solution interval.	best, worst and average case;computer performance;optimal control;pontryagin's maximum principle;stochastic process	Justin Lloyd;Gerard G. L. Meyer	2014	2014 American Control Conference	10.1109/ACC.2014.6858652	mathematical optimization;mathematical economics	Robotics	3.113320090102864	-2.066734771532145	75411
4a37c5da92dbcd2a09c88174e26b22f2d9b93a6c	viability analysis of electric taxis using new york city dataset		This paper examines the viability of electric taxis, namely whether it will be profitable for taxi drivers to adopt electric taxis, in comparison with conventional taxis with internal combustion engines. This paper provides a data analytic investigation using a large dataset of real-world taxi trips in New York City. We model the taxi service strategy by Markov Decision Process. Under this model, we observe that in order to enable an electric taxi driver (using Nissan Leaf) to reach a comparable profit with a conventional taxi driver, the minimum required battery capacity is 45 kWh, more than that of the existing one. We observe that the potential profit of the electric taxi driver can be 3% higher than that of a median conventional taxi driver with sufficient battery capacity, despite nowadays low gas price.	device driver;markov chain;markov decision process;maximal set;the new york times	Chien-Ming Tseng;Chi-Kin Chau	2017		10.1145/3077839.3078463	demography;engineering;operations research;cartography	Web+IR	9.155278927163877	-9.19197473632404	75588
c1692de6043df45e05db05e9a3451bea07babc4e	quality risk prediction at a non-sampling station machine in a multi-product, multi-stage, parallel processing manufacturing system subjected to sequence disorder and multiple stream effects	multi product;sequence disorder effect;multiple stream effect;multi stage parallel manufacturing systems;sampling plan;quality risk;non sampling stations;quality control	Quality risks determined by inspection economies represent a difficult controllable variable in complex manufacturing environments. Planning a quality strategy without being able to predict its effectiveness in all the stations of a system might eventually lead to a loss of time, money and resources. The use of one station to regularly select the samples for a production segment introduces relevant complexities in the analysis of the available quality measurements when they are referred to the other stations in that segment. The multiple streams of product through the parallel machines of the stations and the cycle time randomness, responsible for variation of the item sequence order at each production step, nullify the regularity of the sampling patterns at the machines of the non-sampling stations. This work develops a fundamental model which supports the prediction of the ‘quality risk’, at a given machine in the non-sampling stations, associated with a particular sampling policy for a multi-product, multi-stage, parallel processing manufacturing system subjected to sequence disorder and multiple stream effects. The rationale on which the model is based and successful applications of the model, to scenarios structurally different from those used for its development, give confidence in the general validity of the model here proposed for the quality risk prediction at non-sampling station machines.	parallel computing;sampling (signal processing)	Anna Rotondo;Paul Young;John Geraghty	2013	Annals OR	10.1007/s10479-012-1145-y	sampling;quality control;real-time computing;simulation;operations management;mathematics;statistics	ML	7.975990381515435	-0.1461054717830599	75604
46a67a3d89356cd1725d669124c4768085c68afa	an analytical study of the q	joint replenishment;inventory management;stochastic process;logistics;stochastic processes;policy evaluation;algorithms	We evaluate the performance of a joint replenishment inventory control policy, called the  Q ( s , S ) policy, which was first suggested and characterized by Viswanathan [Manage. Sci. 43 (1997) 1447]. We argue why joint replenishment problems can be seen as one product, multiple location problems, and hence why they should be considered supply chain management problems. The paper uses Markov decision theory to work out an analytical solution procedure to evaluate the costs of a particular  Q ( s , S ) policy, and thereby a method for computing the optimal  Q ( s , S ) policy, under the assumption that demands follow a Poisson process. For a fixed order size  Q , the problem can be decomposed for each item to find an optimal ( s , S ) policy with a stochastic review period. These subproblems can be solved by the algorithm of Zheng and Federgruen [Oper. Res. 39 (4) (1991) 654]. Thereafter it remains to find the optimal value of  Q , which is done by systematic search over all relevant values of  Q . The performance of the  Q ( s , S ) policy is compared with the performance of other known joint ordering policies as in Pantumsinchai [Decis. Sci. 23 (1992) 111] and Viswanathan [Manage. Sci. 43 (1997) 1447]. It is shown that the  Q ( s , S ) performs best among the considered policies.		Christina Nielsen;Christian Larsen	2005	European Journal of Operational Research	10.1016/j.ejor.2004.02.003	stochastic process;logistics;mathematical optimization;operations management;mathematics;operations research;statistics	DB	4.492551310728465	-2.3960819781975298	75890
2eb788d4d7721913cfaabc51b56aff8a31d054ee	profit incentive in trading nonexclusive access on a secondary spectrum market through contract design	telecommunication industry channel capacity contracts optimisation profitability radio spectrum management stochastic processes;incentives;bandwidth licenses ieee transactions uncertainty stochastic processes numerical models;contracts;monotonicity condition secondary spectrum market profit incentive contract design problem primary license holder optimal price profit maximization excess spectrum capacity stochastic process channel uncertainty buyer private information deterministic guarantee channel condition primary user activity secondary user;secondary spectrum market;secondary spectrum market contracts incentives quality of service constraint;quality of service constraint	In this paper, we formulate a contract design problem where a primary license holder wishes to profit from its excess spectrum capacity by selling it to potential secondary users/buyers. It needs to determine how to optimally price the excess spectrum so as to maximize its profit, knowing that this excess capacity is stochastic in nature, does not come with exclusive access, and cannot provide deterministic service guarantees to a buyer. At the same time, buyers are of different types, characterized by different communication needs, tolerance for the channel uncertainty, and so on, all of which are a buyer's private information. The license holder must then try to design different contracts catered to different types of buyers in order to maximize its profit. We address this problem by adopting as a reference a traditional spectrum market where the buyer can purchase exclusive access with fixed/deterministic guarantees. We fully characterize the optimal solution in the cases where there is a single buyer type, and when multiple types of buyers share the same known channel condition as a result of the primary user activity. In the most general case, we construct an algorithm that generates a set of contracts in a computationally efficient manner and show that this set is optimal when the buyer types satisfy a monotonicity condition.	algorithm;algorithmic efficiency;offset binary;personally identifiable information	Shang-Pin Sheng;Mingyan Liu	2014	IEEE/ACM Transactions on Networking	10.1109/TNET.2013.2270954	incentive	ECom	-1.7240429081183704	-3.3336665971627113	76306
d4237ed143f4054e849c956c8aebdbedf6fd16fe	heuristic policies for the stochastic economic lot sizing problem with remanufacturing under service level constraints		In this paper, we address the stochastic economic lot sizing problem with remanufacturing under service level constraints. The problem emerges in hybrid production systems where demand can be met via two alternative sources: manufacturing new products and remanufacturing returned products. The deterministic counterpart of this problem has been considered in the literature and it is shown to be NP-Hard. We focus on the case where period demands and returns are stochastic. The optimal solution to this problem is not a deterministic production schedule but a control policy, yet its structure has not yet been characterized. We propose two heuristic policies for the problem that make use of simple decision rules to control manufacturing and remanufacturing operations and present mathematical models thereof.	heuristic	Onur A. Kilic;Huseyin Tunc;Armagan Tarim	2018	European Journal of Operational Research	10.1016/j.ejor.2017.12.041	operations management;mathematical optimization;decision rule;production schedule;mathematical model;mathematics;sizing;integer programming;remanufacturing;heuristic;service level	Metrics	4.665948476350681	-2.562758062284779	76440
ab526250f74426763f694057cfc3728e27ffe500	hierarchical constraint satisfaction of multilateral trade matching in commodity auction markets	commodity auction market;computational mechanics;constraint logic programs;stable matching;constraint reasoning;electronic markets;trade volume;satisfiability;constraint satisfaction;constraint logic programming;electronic market;short period;hierarchical constraint reasoning	A commodity auction market provides a trading intermediary whose role is to find optimal trade matching between buyers and sellers that satisfies their trading constraints. Some commodity auction markets utilize forms of electronic trading intermediary systems in order to improve the efficiency and effectiveness of trading of huge volumes of transactions during short periods of time. Previous research works on electronic trading intermediary systems focus on the maximization of the trade volume obtained by satisfying mainly price and quantity constraints. The principal restriction of these approaches is that the heterogeneity of the commodity is ignored or at least not significantly considered. The objective of the study in this paper is to propose a computable mechanism of trading inter-mediaries for commodity auction markets, supporting not only ordinary trading constraints of prices and quantities but also other qualitative and quantitative constraints on the commodity properties and trading conditions. Copyright Kluwer Academic Publishers 1997	hierarchical constraint satisfaction	Young U. Ryu	1997	Annals OR	10.1023/A:1018927700552	constraint logic programming;financial economics;mathematical optimization;stable marriage problem;economics;constraint satisfaction;computer science;computational mechanics;trading strategy;mathematics;microeconomics;alternative trading system;commerce;satisfiability;algorithmic trading	AI	-2.055033727739943	-2.9868028275193432	76674
2306db700be36876f402c0c03e38003278999760	optimal replacement policy under a general failure and repair model: minimal versus worse than old repair		We analyze the optimal replacement policy for a system subject to a general failure and repair model. Failures can be of one of two types: catastrophic or minor. The former leads to the replacement of the system, whereas minor failures are followed by repairs. The novelty of the proposed model is that, after repair, the system recovers the operational state but its condition is worse than that just prior to failure (worse than old). Undertrained operators or low quality spare parts explain this deficient maintenance. The corresponding failure process is based on the Generalized PA³lya Process which presents both the minimal repair and the perfect repair as special cases. The system is replaced by a new one after the first catastrophic failure, and also undergoes two sorts of preventive maintenance based on age and after a predetermined number of minor failures whichever comes first. We derive the long-run average cost rate and study the optimal replacement policy. Some numerical examples illustrate the comparison between the as bad-as-old and the worse than old conditions.		Francisco Germán Badía;María Dolores Berrade;Ji Hwan Cha;Hyunju Lee	2018	Rel. Eng. & Sys. Safety	10.1016/j.ress.2018.07.032	engineering;catastrophic failure;reliability engineering;novelty;operator (computer programming);average cost;spare part;preventive maintenance	DB	6.845210876857176	-1.140514575369974	76704
e7dd1c1f4b00fa729e88a9e55c7febf7343753d0	simultaneous optimization of process operations and financial decisions to enhance the integrated planning/scheduling of chemical supply chains	optimisation;computacion informatica;management system;financial management;integrable model;distributed networks;grupo de excelencia;ciencias basicas y experimentales;quimica;supply chain;cash flow;supply chain management	This paper addresses the integrated planning/scheduling of chemical supply chains (SC) with multi-product, multi-echelon distribution networks taking into account financial management issues and suggests a novel approach for enterprise wide management. In order to tackle this problem, it is derived a mathematical formulation combining a scheduling/planning model with a cash flow and budgeting formulation. To motivate the use of such integrated model, a sequential scheme representing traditional enterprise practices is firstly applied. Within this strategy, scheduling and planning decisions are taken firstly, and finances are fitted afterwards considering the cash flows associated to the scheduling/planning decisions previously computed as input parameters. The comparison between the results of the sequential approach and those of the integrated model highlight the advantages of the latter option, in which scheduling/planning and cash management decisions are optimized in unison with a common objective of maximizing the change in equity achieved by the company. The modeling approach developed in this paper and the obtained results suggest that a new conceptual strategy in enterprise management systems consisting of the integration of the financial models of the enterprise with those dealing with the operative area is a must to improve the firm’s performance and its overall earnings and ensuring also healthy cash flow management. © 2005 Elsevier Ltd. All rights reserved.	mathematical optimization;row echelon form;scheduling (computing);unison	Gonzalo Guillén;Mariana Badell;Antonio Espuña Camarasa;Luis Puigjaner	2006	Computers & Chemical Engineering	10.1016/j.compchemeng.2005.10.015	mathematical optimization;supply chain management;simulation;cash flow;management system;management science;supply chain	DB	5.698161123309313	-6.716758978814854	76712
ef5b9e96d9ce88d566fc5980cadbf6e5dabea4bb	fast algorithms for computing interim allocations in single-parameter environments		Myerson’s seminal work characterized optimal auctions; applied naively, however, his approach yields exponential-time algorithms. Using Border’s theorem, in contrast, one can solve mechanism design problems in polynomial time. This latter approach relies on linear programming machinery, the mechanics of which are significantly more complicated than Myerson’s. Motivated by the simplicity and transparency of Myerson’s analysis, we present fast algorithms for computing interim allocations in simple auction settings. These methods apply to both surplus and revenue maximization, and yield ex-ante symmetric solutions.	algorithm	Amy Greenwald;Jasper Lee;Takehiro Oyakawa	2018		10.1007/978-3-030-03098-8_12	time complexity;common value auction;mechanism design;algorithm;interim;simple algorithm;revenue;linear programming;computer science;maximization	HPC	-2.437693675016084	-1.1714788149473319	76805
ed18099a66a40631572caffaa8b38978b43573f1	when customers anticipate liquidation sales: managing operations under financial distress		The presence of strategic customers may force an already financially distressed firm into a death spiral: sensing the firm’s financial difficulty, customers may wait strategically for deep discounts in liquidation sales. In turn, such waiting lowers the firm’s profitability and increases the firm’s bankruptcy risk. Using a two-period model to capture these dynamics, this paper identifies customersu0027 strategic waiting behavior as a source of a firm’s cost of financial distress. We also find that customersu0027 anticipation of bankruptcy can be self-fulfilling: when customers anticipate a high bankruptcy probability, they prefer to delay their purchases, making the firm more likely to go bankrupt than when customers anticipate a low probability of bankruptcy. Such behavior has important operational and financial implications. First, the firm acts more conservatively when facing either more severe financial distress or a large share of strategic customers. As its financial situation deteriorates, the firm lowers ...		John R. Birge;Rodney P. Parker;Michelle Xiao Wu;S. Alex Yang	2017	Manufacturing & Service Operations Management	10.1287/msom.2017.0634	finance;business;commerce	HCI	-1.4909851529316231	-8.093590228386665	76890
148dd203ac2329466c5b8dc732ec691789d59961	a reinforcement learning methodology for a human resource planning problem considering knowledge-based promotion	knowledge intensive;production inventory control;reinforcement learning;human resource planning;stochastic dynamic programming	This paper addresses a combined problem of human resource planning (HRP) and production-inventory control for a high-tech industry, wherein the human resource plays a critical role. The main characteristics of this resource are the levels of “knowledge” and the learning process. The learning occurs during the production process in which a worker can promote to the upper knowledge level. Workers in upper levels have more productivity in the production. The objective is to maximize the expected profit by deciding on the optimal numbers of workers in various knowledge levels to fulfill both production and training requirement. As taking an action affects next periods’ decisions, the main problem is to find the optimal hiring policy of non-skilled workers in long-time horizon. Thus, we develop a reinforcement learning (RL) model to obtain the optimal decision for hiring workers under the demand uncertainty. The proposed interval-based policy of our RL model, in which for each state there are multiple choices, makes it more flexible. We also embed some managerial issues such as layoff and overtime-working hours into the model. To evaluate the proposed methodology, stochastic dynamic programming (SDP) and a conservative method implemented in a real case study are used. We study all these methods in terms of four criteria: average obtained profit, average obtained cost, the number of new-hired workers, and the standard deviation of hiring policies. The numerical results confirm that our developed method end up with satisfactory results compared to two other approaches.	enterprise resource planning;knowledge-based systems;reinforcement learning	Amir-Mohsen Karimi-Majd;Masoud Mahootchi;Amir Zakery	2017	Simulation Modelling Practice and Theory	10.1016/j.simpat.2015.07.004	computer science;knowledge level;optimal decision;strategic human resource planning;reinforcement learning;stochastic programming;layoff;management science;scheduling (production processes);human resources	AI	9.680495784187949	1.199010033955029	77034
aeb1c922b52849555370661a78882ed3720e77f4	analysis of the decision to invest for constructing a nuclear power plant under regulation of electricity price	stochastic process;price regulation;electricity prices;investment decision;net present value;power plant;free market;real option;real options approach;nuclear power plant;regulated price;npv approach	In this study, the effect of the regulation of electricity prices on the decision to invest in power plants is rationally explained using a real-options approach. Conditions under price regulation are described by a simple model in which the variable cost follows a stochastic process; free market conditions are described using Cortazar's model. The resulting comparison could explain the promotion of nuclear power plant construction in Japan from about 1980 until the middle of the 1990s, and the avoidance of such investment in recent years. This difference between economic environments is not confirmed by the traditional net present value (NPV) approaches.		Shin'ichiro Takizawa;Atsuyuki Suzuki	2004	Decision Support Systems	10.1016/S0167-9236(03)00045-9	power station;stochastic process;net present value;economics;free market;microeconomics;market economy;statistics	ECom	1.3442432187359064	-8.408625217812242	77078
cf607a653c8d4c3f8b1e93515bbac2aac8496aa0	optimal reconfiguration-based dynamic tariff for congestion management and line loss reduction in distribution networks	topology;mixed integer programming mip congestion management dynamic tariff dt electric vehicle ev feeder reconfiguration fr line loss reduction;tariffs integer programming losses power distribution economics;case studies;line loss reduction;feeder reconfiguration fr;dynamic tariff dt;niobium;electric losses;optimal reconfigurations;loading;electric vehicle ev;network topology;mixed integer programming mip;line loss;traffic congestion;integer programming;mixed integer programming;switches planning topology optimization loading network topology niobium;planning;optimization;energy cost;switches;reconfiguration based dt method optimal reconfiguration based dynamic tariff congestion management line loss reduction distribution networks feeder reconfiguration mixed integer programming;feeder reconfigurations;congestion management	This paper presents an optimal reconfiguration-based dynamic tariff (DT) method for congestion management and line loss reduction in distribution networks with high penetration of electric vehicles. In the proposed DT concept, feeder reconfiguration (FR) is employed through mixed integer programming when calculating the DT, leading to minimized energy cost and reduced DT as compared with the DT concept without FR. This paper further demonstrates that the line losses can be taken into account during the calculation of DT. As a result, the line loss reduction can be realized in a decentralized manner through the DT framework. Three case studies were conducted to validate the optimal reconfiguration-based DT method for congestion management and line loss reduction in distribution networks.	integer programming;library (computing);linear programming;mathematical optimization;network congestion;network topology;optimization problem;token reconfiguration	Shaojun Huang;Qiuwei Wu;Lin Cheng;Zhaoxi Liu	2016	IEEE Transactions on Smart Grid	10.1109/TSG.2015.2419080	planning;niobium;mathematical optimization;real-time computing;integer programming;network switch;computer science;engineering;operations management;mathematics;network topology	HPC	5.058072378662839	3.927581204976334	77192
34883a17c1998eceb32751f20b9f0d9320caebc4	sole versus dual sourcing under order dependent lead times and prices	modelizacion;order splitting;analisis sensibilidad;tiempo iniciacion;optimisation;nuevo abastecimiento;logistique;optimizacion;adquisicion por suscripcion;compra;ahorro;relacion orden;modele dual;ordering;temps mise en route;dual models;stochastic lead times;lead time;connecting;administracion deposito;purchasing;modelisation;fournisseur multiple;relation ordre;economic order quantity;setup time;dependance du temps;logistics;time dependence;tamano lote;proveedor multiple;sensitivity analysis;taille lot;saving;multiple supplier;gestion stock;analyse sensibilite;lot sizing;achat;quantite economique a commander;optimization;cantidad economica pedida;replenishment;acometida;epargne;branchement;modeling;dual sourcing;inventory control;dependencia del tiempo;supply chain management;purchases;reapprovisionnement;logistica;acquisition titre onereux	In this paper, we consider a dual-sourcing model with constant demand and stochastic lead times. Two suppliers may be different in terms of purchasing prices and lead-time parameters. The ordering takes place when the inventory level depletes to a reorder level, and the order is split among two suppliers. Unlike previous works in the order splitting literature, the supply lead time between vendor and buyer as well as unit purchasing prices is considered to be order quantity dependent. The proposed model finds out the optimal reorder point, order quantity and splitting proportion, using a solution procedure. Numerical results show that neglecting the relationship between ordering batch size and lead times is a shortcoming that hides one of order splitting advantages. Moreover, connecting unit prices to order quantity can decrease the percentage saving from dual sourcing compared to sole sourcing. Furthermore, sensitivity analysis shows some managerial insights.	integer programming;linear programming;nonlinear system;numerical method;purchasing;stochastic process	Mohsen S. Sajadieh;Kourosh Eshghi	2009	Computers & OR	10.1016/j.cor.2009.03.001	inventory control;logistics;supply chain management;systems modeling;economic order quantity;order theory;operations research;sensitivity analysis;saving	ECom	3.251353930041922	-4.930940100470413	77256
f13613071a7602433eab53a487e3eba126b3dde3	optimal risk control for a large corporation in the presence of returns on investments	present value;return on investment;discount rate;singular control;optimal policy;diffusion coefficient;stochastic control theory;geometric brownian motion;dividend pay out;proportional reinsurance;stochastic control;profitability;diffusion models;insurance companies;hjb equation;diffusion model	This paper represents a model for the financial valuation of a firm which has control on the dividend payment stream and its risk, as well as potential profit by choosing different business activities among those available to it. Furthermore the company invests its free reserve in an asset, which may or may not contain an element of risk. The company chooses a dividend payment policy and we associate the value of the company with the expected present value of the net dividend distributions (under the optimal policy). One of the examples could be a large corporation such as an insurance company, whose liquid assets in the absence of control and investments fluctuate as a Brownian motion with a constant positive drift and a constant diffusion coefficient. We interpret the diffusion coefficient as risk exposure, while drift is understood as potential profit. At each moment of time, there is an option to reduce risk exposure, simultaneously reducing the potential profit, like using proportional reinsurance with another carrier for an insurance company. The company invests its reserve in a financial asset, whose price evolve as a geometric Brownian motion, with mean rate $r>0$ and diffusion constant $\sigma_P\geq 0$. Thus $\sigma_P=0$ corresponds to investments in a riskless bank account. The objective is to find a policy, consisting of risk control and dividend payment scheme, which maximizes the expected total discounted dividends paid out until the time of bankruptcy. We apply the theory of controlled diffusions to solve the problem. We show that if the discount rate c is less than r, the optimal return function is infinite. If $r=c$ the return function is finite for all $x		Bjarne Højgaard;Michael I. Taksar	2001	Finance and Stochastics	10.1007/PL00000042	financial economics;dividend policy;actuarial science;stochastic control;economics;finance	HCI	1.6780783265281836	-3.841372977120341	77333
0951858b7b780c7138d65ecc129d83a341eec5bc	optimization and interaction of an economic and sociological model	supply and demand optimization methods electrical equipment industry inventory management production facilities industrial relations constraint optimization microwave integrated circuits calibration;microwave integrated circuits;inventory management;development economics;constraint optimization;helium;dynamic model;resource management;biological system modeling;industries;economic model;electrical equipment industry;production facilities;mathematical model;industrial relations;production;optimization;economics;calibration;dynamic analysis;supply and demand;optimization methods	The use of dynamic economic models based on the work of Leontief has received increased attention due to the current interest in the dynamic analysis of urban and world areas. Stable dynamic models have been developed and consideration of labor in these areas has been proposed. The optimum dynamic allocation of labor has also been considered. The availability of labor as the output of a sociological model has been previously developed. In this paper, an optimum allocation problem is formulated based on the previously developed economic and sociological models. This extension results in an interacting dynamic socioeconomic model.	allocative efficiency;interaction;memory management	Marlin H. Mickle;William G. Vogt;Tobias A. Trygar	1975	IEEE Transactions on Systems, Man, and Cybernetics	10.1109/TSMC.1975.5408470	mathematical optimization;calibration;economic model;resource management;mathematical model;supply and demand;dynamic program analysis;management science;industrial relations;helium	Visualization	2.3929928612012765	1.5910267006198733	77464
97cb700b5068c642c834baa3bab0784fb5ed1b53	optimal policies for production-clearing systems under continuous-review	production clearing systems;inventory systems;continuous review;optimal policies;stochastic demand	In this paper, we consider a production-clearing system with compound Poisson demand under continuous review. The production facility produces one type of item without stopping and at a constant rate, and stores the product into a buffer to meet future demand. To prevent high inventory levels, a clearing operation occasionally removes all or part of the inventory from the buffer. We prove that an (m, q)-policy, i.e., a policy that clears the buffer to level m as soon as the inventory hits a level q, minimizes the long run average holding and clearing cost. We also derive a numerically very efficient approach to compute the optimal parameters of the (m, q)-policy for models with backlogging and models with lost sales. With these numerical methods we show that tuning the clearing levels m and q in concert can lead to substantial cost savings.		Remco Germs;Nicky D. van Foreest;Onur A. Kilic	2016	European Journal of Operational Research	10.1016/j.ejor.2016.05.004	mathematical optimization;economics;operations management;microeconomics;welfare economics	Metrics	2.6146573136148747	-4.339168166684272	77467
4d6b895119c908cf43996739ac11d4f7716833a8	an  $n$ -path logit-based stochastic user equilibrium model		"""This paper proposes a new traffic assignment model, named an <inline-formula> <tex-math notation=""""LaTeX"""">$N$ </tex-math></inline-formula>-path logit-based stochastic user equilibrium (NPSUE), which considers not only road users’ perceptual errors in path choices, but also users’ heterogeneity that allows the numbers of the limited path sets for each user to be different. The property of the <inline-formula> <tex-math notation=""""LaTeX"""">$N$ </tex-math></inline-formula>-path user equilibrium (NPUE) proposed in Dung-Ying Lin (2014) is first reanalyzed, and then the optimization program for the NPSUE models as well as the property of the optimal solution are explicitly discussed. For each type of users, the NPSUE assignment results are consistent with the logit-assignment results in their limited path set. Both the NPUE and NPSUE models are tested in three road networks: an simple grid network, Nguyen and Dupuis’ network and Sioux Falls network. The numerical results show that (1) the NPUE can be equivalent to the UE under certain conditions, although the users don’t have full information on the available paths; (2) the proposed NPSUE may provide an ideal equilibrium state for both system managers and road users; (3) the provision of appropriate path guidance information is beneficial to both system managers and road users; otherwise, the provision of excessive information may decrease the performance of the road network, and (4) under the NPSUE conditions, the provision of excessive information may decrease users’ satisfaction."""	grid network;logistic regression;mathematical optimization;numerical analysis	Jianmei Liu;Zhengbing He;Shuaiqi Ma	2018	IEEE Access	10.1109/ACCESS.2018.2827071	logit;computer science;distributed computing;linear programming;thermodynamic equilibrium;stochastic process;grid network	ML	2.9945947236302946	0.21510697449580263	77564
79c3e78e231f791f09cb148eac0ffa6efc05f15a	a game-theoretic approach for the internet content distribution chain		Currently, commercial CDN providers have become major actors in the Internet content distribution chain. They serve a large portion of the Internet traffic since they allow an efficient user-perceived response time and availability of content. In this paper, we consider an ecosystem that contains content providers CPs as customers of content distribution network providers CDNs. The content distribution network seeks to attract more content providers by offering them prices to save and distribute their contents to end users with better QoS. Thus, the quality and price of the content, which are considered in this study as decision parameters for content providers have an indirect impact on the revenue of the CDN. Once the content of a CP is stored in the CDN content replication servers, the CDN is the delivery manager of this content to all end users’ requests; for this another common parameter is added to our modeling and it determines the share of the CDN that the CP wins requests from users on this content. After formulating non-cooperative games, we have demonstrated the existence and uniqueness of the Nash equilibrium and used the best response dynamic algorithm to make a numerical analysis to the problems. We were able to learn that when the game between the CDNs is socially optimal, the CPs win more and vice versa in the case where the game becomes a monopoly.		Driss Ait Omar;Mohamed El Amrani;Mohamed Baslam;Mohamed Fakir	2018		10.1007/978-3-030-05529-5_18	non-cooperative game;end user;the internet;best response;computer network;quality of service;nash equilibrium;price of anarchy;computer science;server	ECom	-3.2747264466647965	-6.1166748909724715	77839
ba0c65800b18515ca8cc0ef808469fbaa7f48862	coordinating sales and operations management in automobile industry under long procurement lead times		Abstract   The automobile industry is characterized by a very volatile demand and impatient customers. Furthermore, globalization has grown longer procurement lead times of vehicle assembly plants. Therefore a challenge for automotive manufacturers is to cleverly adjust production capacities with customer demands. To satisfy car buyers in a competitive market, sales dealers require short delivery lead time and the possibility to order customized vehicles as late as possible. However, plants need to order parts several weeks beforehand for distant suppliers, when the demand is not known yet. The issue is to find the best trade-off between these sales requirements and industrial constraints while limiting stock levels and emergency supplies due to parts shortages. This study is based on the actual situation of a global automotive manufacturer where a continuous negotiation process is done between sales and supply chain departments to manage this trade-off. During the sales and operations planning, flexibility levels are defined and represent the maximum number of a given vehicle type that sales dealers can order during a week. Since this process is new, supply chain managers lack insights about how this flexibility may impact inventories and delivery lead time. Our objective is to model the dynamics of this sales and operations planning and to study how to improve logistics performance without deteriorating customer satisfaction. We show how flexibility levels impact delivery time and logistic costs by using a simulation approach based on actual industrial data.	procurement	Lâm Laurent Lim;Gülgün Alpan-Gaujal;Bernard Penz	2013		10.3182/20130619-3-RU-3018.00281	sales order;marketing;operations management;sales and operations planning;sales management;business;commerce	Robotics	1.1436555573539922	-6.339432122980589	77944
eaf3e6d39de0a6291423b2cf388bf462976fa964	a virtual age model based on a bathtub shaped initial intensity	reduccion sistema;modelizacion;tribologia;system reliability;fiabilite systeme;analisis estadistico;envejecimiento;wear;maintenance;defecto;system reduction;reliability modeling;tribology;age;sistema complejo;statistical model;imperfect repair;repairable system;fiabilidad sistema;modelisation;failure intensity;tribologie;usure;statistical analysis;systeme complexe;reduction systeme;complex system;repairable systems reliability;defect;rupture;analyse statistique;defaillance;desgaste;ageing;virtual age;modele statistique;bathtub curve;defaut;mantenimiento;reparation;vieillissement;modelo estadistico;failures;sistema reparable;reparacion;modeling;fallo;ruptura;systeme reparable;repair;edad	This paper presents a new reliability model for complex repairable systems, which combines a bathtub shaped ageing and imperfect maintenance. A bathtub shaped initial intensity function allows to take into account the burn-in period, the useful life and wear out of the systems. Repair effect is expressed by a reduction of the system virtual age, which depends on the ageing of the system. The main characteristics of the model are derived. The most important one is that the maintenance efficiency allows an extension of the system useful life duration. A statistical analysis of the model and an application to real failure data are presented. & 2008 Elsevier Ltd. All rights reserved.	applied general equilibrium;bathtub curve;burn-in;point process	Yann Dijoux	2009	Rel. Eng. & Sys. Safety	10.1016/j.ress.2008.11.004	ageing;engineering;tribology;forensic engineering;statistics	AI	6.877747028873893	-2.2290411971145394	77953
037503819aefe29ea6d6e3886db8bb1980b93161	robust dynamic estimation	nonprofit marketing;kalman filter;robust estimation;optimal control;dynamic games;sandwich estimator	Full terms and conditions of use: http://pubsonline.informs.org/page/terms-and-conditions This article may be used only for the purposes of research, teaching, and/or private study. Commercial use or systematic downloading (by robots or other automatic processes) is prohibited without explicit Publisher approval, unless otherwise noted. For more information, contact permissions@informs.org. The Publisher does not warrant or guarantee the article’s accuracy, completeness, merchantability, fitness for a particular purpose, or non-infringement. Descriptions of, or references to, products or publications, or inclusion of an advertisement in this article, neither constitutes nor implies a guarantee, endorsement, or support of claims made of that product, publication, or service. Copyright © 2017, INFORMS		Olivier Rubel;Prasad A. Naik	2017	Marketing Science	10.1287/mksc.2016.1010	kalman filter;minimax estimator;econometrics;mathematical optimization;optimal control;economics;marketing;statistics	Logic	1.4260247272082482	-0.24203163789418974	77999
8a70526e1f3b40d0e29133d157a069e72d81e950	trade determination in multi-attribute exchanges	electronic trading;multiattribute exchange;double sided marketplace;piecewise linear;cost function;mixed integer formulation multiattribute exchange electronic exchange double sided marketplace trade determination pricing one shot exchange mixed integer programming problem bid structure two attribute exchange;piecewise linear techniques;pricing;information technology;two attribute exchange;consumer electronics;pricing piecewise linear techniques consumer electronics linear programming laboratories computer science automation internet information technology cost function;mixed integer programming problem;one shot exchange;demand and supply;mixed integer program;bid structure;internet;computational complexity;electronic exchange;school of automation;linear programming;computer science;trade determination;computer science automation formerly;electronic data interchange;mixed integer formulation;electronic trading electronic data interchange computational complexity;automation	Electronic exchanges are double-sided marketplaces that allow multiple buyers to trade with multiple sellers, with aggregation of demand and supply across the bids to maximize the revenue in the market. Two important issues in the design of exchanges are (1) trade determination (determining the number of goods traded between any buyerseller pair) and (2) pricing. In this paper we address the trade determination issue for one-shot, multi-attribute exchanges that trade multiple units of the same good. The bids are configurable with separable additive price functions over the attributes and each function is continuous and piecewise linear. We model trade determination as mixed integer programming problems for different possible bid structures and show that even in two-attribute exchanges, trade determination is -hard for certain bid structures. We also make some observations on the pricing issues that are closely related to the mixed integer formulations.	algorithm;higher-order function;integer programming;linear programming;max;piecewise linear continuation;telephone exchange;utility functions on indivisible goods	Sampath Kameshwaran;Y. Narahari	2003		10.1109/COEC.2003.1210247	mathematical optimization;computer science;linear programming;electronic trading;information technology	AI	0.32483324595682406	-5.831117994721214	78073
4130c843c47ed5aa64a6163ab6e8c9d37d44f3df	online retailer vs. click and mortar retailer: who performs better?	online retailing;e business;customer satisfaction;business value of is;multichannel	Retail business is characterized by different business models: pure-play model and dual channel approach, which uses both physical and online channels to reach customers. There is conflicting evidence regarding the relative value of these business models to the consumers. We take a market valuation approach to evaluate the relative merits of both business models. We consider a panel of publicly traded US retailers and evaluate how their sales performance impacts their Tobin’s q. We find that the dual channel retailers receive a market premium for their sales revenue as compared to the pure-play retailers. This higher valuation can be associated with higher customer satisfaction with dual channel firms leading to a higher intangible value as compared to the pure-play firms. Our results have important implications for retailers as we demonstrate the value of different channels. Our work also contributes to the existing literature on online consumer retailing and multichannel research.	bricks and clicks;business requirements;customer relationship management;mortar methods;multi-channel memory architecture;online shopping;value (ethics)	Ashish Agarwal;Alvin Chung Man Leung;Prabhudev Konana	2011			marketing;electronic business;advertising;customer satisfaction;management;commerce	Web+IR	-1.7240257654850188	-7.39307813327532	78330
595ec6e58a53695f3a4a25b40a74892afb75872d	yield information and supplier responsiveness in remanufacturing operations	stochastic process;stochastic process yield;supplier responsiveness;lead time;lot sizing;remanufacturing;information system;labor skills;early detection	When making used product disassembly and procurement decisions, managers of remanufacturing facilities usually face limited information on remanufacturing yields or a potentially long supplier lead time. To help making the decision, managers may attempt to identify the reparable parts early in the recovery process, to develop a responsive supplier with reactive capacity, or to implement an information system that helps to identify the wear state of the used machines that are available for remanufacturing. This paper provides optimal lot-size policies for each of these scenarios, which are then used to compare the relative value of the alternatives under a broad range of parameters. We find that: (1) as the yield variance increases, the benefits of developing early detection capability of the process yield at the disassembly stage outweigh the advantage of having suppliers with short lead times; (2) as the shortage cost increases, it is preferable to have a responsive supplier that can deliver with short lead times; and (3) as the purchase, repair or holding cost increase, it is preferable to have the capability to detect process yield early.	responsiveness	Geraldo Ferrer	2003	European Journal of Operational Research	10.1016/S0377-2217(02)00454-X	stochastic process;marketing;operations management;mathematics;information system;statistics;commerce	Crypto	2.775754327829098	-6.075061126670027	78409
81ca0b7576b447618ed200d9a475fa8efc34d3af	cost-sharing contract of supply chain based on carbon emission control		This paper studies the single cycle decision of the two-level supply chain cooperative emission reduction under the carbon emissions trading policy. Designed by Stackelberg game of retailer-led, manufactureru0027s follow-up, the analysis compares changes of the manufactureru0027s emission reductions, the retaileru0027s order quantity, and both profit when whether there is a cost-sharing contract. The study found that after the contract was provided, under certain conditions, the profits of both parties can get a Pareto improvement and the manufactureru0027s product emission reductions and the optimal order quantity of the retailer and the ratio of the optimal cost sharing.	pareto efficiency	Dan Wu;Yuxiang Yang	2017	2017 13th International Conference on Computational Intelligence and Security (CIS)	10.1109/CIS.2017.00080	economic order quantity;computer science;mathematical optimization;pareto principle;stackelberg competition;supply chain;government;profit (economics);cost sharing;microeconomics;greenhouse gas	DB	-0.6458415072317804	-5.089248662300709	78451
e15ec076ec4d8fccb30927db6760c85242759903	customer bill of rights under no-fault service failure: confinement and compensation	advanced selling;targeted compensation;service failure;customer bill of rights	Service providers and their customers are sometimes victims of failures caused by exogenous factors such as unexpected bad weather, power outages, or labor strikes. When such no-fault failures occur in confined zones, service providers may confine customers against their will if making arrangements for them to leave is very costly. Such confinements, however, can result in severe pain and suffering, and customer complaints put regulators under pressure to pass a customer bill of rights that allows captive customers to abort failed services. This paper shows that service providers are better off preempting such laws by voluntarily allowing customers to escape the service under failure. Moreover, service providers can profit by targeting compensation to customers based on whether they use or leave the service under failure.	case-based reasoning;erdős–rényi model;eurographics;marginal model;value (ethics)	Rachel R. Chen;Eitan Gerstner;Yinghui Yang	2012	Marketing Science	10.1287/mksc.1110.0683	consumer bill of rights;actuarial science;marketing;operations management;service guarantee;customer retention	Logic	-1.5619021443430119	-7.9291001436793485	78506
9f2626abf0a7dc46468d9a87a5fea4b768a82c52	computing optimal contracts in series-parallel heterogeneous combinatorial agencies	optimal contract;series parallel	We study an economic setting in which a principal motivates a team of strategic agents to exert costly effort toward the success of a joint project. The action taken by each agent is hidden and affects the (binary) outcome of the agent’s individual task in a stochastic manner. A Boolean function, called technology, maps the individual tasks’ outcomes to the outcome of the whole project. The principal induces a Nash equilibrium on the agents’ actions through payments that are conditioned on the project’s outcome (rather than the agents’ actual actions) and the main challenge is that of determining the Nash equilibrium that maximizes the principal’s net utility, referred to as the optimal contract. Babaioff, Feldman and Nisan suggest and study a basic combinatorial agency model for this setting, and provide a full analysis of the AND technology. Here, we concentrate mainly on OR technologies and on series-parallel (SP) technologies, which are constructed inductively from their building blocks — the AND and OR technologies. We provide a complete analysis of the computational complexity of the optimal contract problem in OR technologies, which resolves an open question and disproves a conjecture raised by Babaioff et al. In particular, we show that while the AND case admits a polynomial time algorithm, computing the optimal contract in an OR technology is NP-hard. On the positive side, we devise an FPTAS for the OR case and establish a scheme that given any SP technology, provides a (1 + )-approximation for all but an ̂-fraction of the relevant instances (for which a failure message is output) in time polynomial in the size of the technology and in the reciprocals of and ̂.	algorithm;binary file;computational complexity theory;map;nash equilibrium;p (complexity);polynomial;polynomial-time approximation scheme;recursive definition;series-parallel graph;stochastic process;universal quantification	Yuval Emek;Michal Feldman	2009		10.1007/978-3-642-10841-9_25	mathematical optimization;combinatorics;series and parallel circuits;simulation;economics;computer science;operations management;mathematics;microeconomics;mathematical economics;computer security;algorithm	ECom	-2.74145613923058	-0.4074220632939812	78541
b095307a3fa5cf2b1c68c9dac72925ef8333d601	statistical models for the analysis of water distribution system pipe break data	modelo lineal generalizado;modelizacion;distributed system;system reliability;salida;rehabilitation;fiabilite systeme;replacement;distribucion agua;remplacement;history;analisis estadistico;piping;modele lineaire generalise;pipe;systeme aide decision;rehabilitacion;mantenimiento sistema;water distribution system reliability;prise de decision;regression model;fuite;sistema ayuda decision;statistical regression;statistical model;caneria;fiabilidad sistema;modelisation;generalized linear models;modelo regresion;planificacion;decision support system;regression;distribution eau;analisis regresion;statistical analysis;capacite limite;canalizacion;regresion estadistica;modele regression;water distribution system;contaminacion;analyse statistique;leak;modele statistique;tuyauterie;capacidad limite;analyse regression;canalisation;general linear model;planning;modelo estadistico;regression analysis;reemplazo;water distribution;generalized linear model;historia;contamination;carrying capacity;planification;regression statistique;toma decision;modeling;system maintenance;histoire;maintenance systeme	The deterioration of pipes leading to pipe breaks and leaks in urban water distribution systems is of concern to water utilities throughout the world. Pipe breaks and leaks may result in reduction in the water-carrying capacity of the pipes and contamination of water in the distribution systems. Water utilities incur large expenses in the replacement and rehabilitation of water mains, making it critical to evaluate the current and future condition of the system for maintenance decision-making. This paper compares different statistical regression models proposed in the literature for estimating the reliability of pipes in a water distribution system on the basis of short time histories. The goals of these models are to estimate the likelihood of pipe breaks in the future and determine the parameters that most affect the likelihood of pipe breaks. The data set used for the analysis comes from a major US city, and these data include approximately 85,000 pipe segments with nearly 2500 breaks from 2000 through 2005. The results show that the set of statistical models previously proposed for this problem do not provide good estimates with the test data set. However, logistic generalized linear models do provide good estimates of pipe reliability and can be useful for water utilities in planning pipe inspection and maintenance.	statistical model	Shridhar Yamijala;Seth D. Guikema;Kelly Brumbelow	2009	Rel. Eng. & Sys. Safety	10.1016/j.ress.2008.03.011	decision support system;mathematics;operations research;regression analysis;statistics	OS	6.212051359799088	-3.970684845296232	78808
7d90de5820cbb370af1b0da2b9da1451c5e4dea7	flexible server allocation and customer routing policies for two parallel queues when service rates are not additive	grupo de excelencia;dynamic programming optimal control;ciencias basicas y experimentales;matematicas;optimization;grupo a;queues;applications	We consider the question of how routing and allocation can be coordinated to meet the challenge of demand variability in a parallel queueing system serving two types of customers. A decision-maker decides whether to keep customers at the station at which they arrived or to reroute them to the other station. At the same time, the decision-maker has two servers and must decide where to allocate their effort. We analyze this joint decision-making scenario, but add two important twists. First, we allow the combined service rate (when the servers work at the same station) to be super-additive or sub-additive. This captures positive or negative externalities that arise during collaboration. Second, routing costs are allowed to be strictly positive. We seek an optimal control policy under the discounted or long-run average cost criteria. Our results show that in the super-additive case jobs should never be routed away from the lower cost queue. When jobs are rerouted from the higher cost queue to the low cost queue the optimal control is monotone in the respective queue lengths. Moreover, we show that the optimal allocation is a non-idling priority rule based on the holding costs. In the sub-additive case we find that the optimal policy need not exhibit such a simple structure. In fact, the optimal allocation need not prioritize one station (it may split the servers), and the optimal routing need not be monotone in the number of customers in each queue. We characterize the optimal policy for a few canonical cases, and discuss why intuitive policies need not be optimal in the general case. An extensive numerical study examines the benefit of dynamically controlling both routing and resource allocation; we discuss when using one of	additive model;heart rate variability;job stream;mathematical optimization;numerical analysis;optimal control;queueing theory;routing;utility functions on indivisible goods;monotone	Hyun-Soo Ahn;Mark E. Lewis	2013	Operations Research	10.1287/opre.1120.1157	mathematical optimization;real-time computing;simulation;computer science;marketing;operations management;fork–join queue;information technology;queue	Metrics	4.1829993440948785	-0.43846871568813617	78817
167aaa727632398f5f0074f1528ad7083a87c510	structural stability implies robustness to bounded rationality	small deviation;bounded rationality;rational agent;journal of economic literature;structural stability	The introduction of a small amount of bounded rationality into a model sometimes has little effect, and sometimes has a dramatic impact on predicted behavior. We call a model robust to bounded rationality if small deviations from rationality result only in small changes in the equilibrium set. We also say that a model is structurally stable if the equilibrium set (given fully rational agents) varies continuously with the parameter values of the model. It is easy to see that when the equilibrium set is discontinuous, bounded rationality can have a very large impact on behavior in the neighborhood of the discontinuity. We go further and show that it is only at such discontinuities that bounded rationality can have large effects. It follows that a model is robust to bounded rationality if and only if it is structurally stable. Thus, we can characterize which models will be robust to bounded rationality and which will not, independently of the exact form that the bounded rationality takes. Journal of Economic Literature Classification Numbers: C69, C79, D51, E19.	rational agent;rationality;reflections of signals on conducting lines;robustness (computer science);stable model semantics	Luca Anderlini;David Canning	2001	J. Economic Theory	10.1006/jeth.2000.2784	rational agent;discrete mathematics;economics;mathematics;structural stability;mathematical economics;bounded function;welfare economics;bounded rationality	ECom	-3.9914823816993206	-3.5665398489692275	78872
21737307996a7da46c5d99a8956aac0afae71984	direct: a scalable approach for route guidance in selfish orienteering problems	decision support;game theory;selfish routing;leisure and entertainment;orienteering;constraint generation;network congestion games	We address the problem of crowd congestion at venues like theme parks, museums and world expos by providing route guidance to multiple selfish users (with budget constraints) moving through the venue simultaneously. To represent these settings, we introduce the Selfish Orienteering Problem (SeOP) that combines two well studied problems from literature, namely Orienteering Problem (OP) and Selfish Routing (SR). OP is a single agent routing problem where the goal is to minimize latency (or maximize reward) in traversing a subset of nodes while respecting budget constraints. SR is a game between selfish agents looking for minimum latency routes from source to destination along edges of a network available to all agents. Thus, SeOP is a multi-agent planning problem where agents have selfish interests and individual budget constraints. As with Selfish Routing, we employ Nash Equilibrium as the solution concept in solving SeOP. A direct mathematical program formulation to find a Nash equilibrium in SeOP cannot scale because the number of constraints is quadratic in the number of paths, which itself is an exponential quantity. To address scalability issues, we make two key contributions. First, we provide a compact non-pairwise formulation with linear number of constraints in the number of paths to enforce the equilibrium condition. Second, we introduce DIRECT, an incremental and iterative master-slave decomposition approach to compute an approximate equilibrium solution. Similar to existing flow based approaches, DIRECT is scale invariant in the number of agents. We also provide a theoretical discussion of our approximation quality and present extensive empirical results on synthetic and real-world graphs demonstrating the scalability of combining DIRECT with our non-pairwise formulation.	approximation algorithm;crowdsourcing;iterative method;multi-agent system;nash equilibrium;network congestion;problem solving;routing;scalability;synthetic intelligence;time complexity;venue (sound system)	Pradeep Varakantham;Hala Mostafa;Na Fu;Hoong Chuin Lau	2015			game theory;mathematical optimization;orienteering;simulation;computer science	AI	-2.6072046564556732	2.913851196778906	79307
5de62aa88fa6081805c7eeb5275fba2ec59bfaf5	tick size and spreads: the case of nasdaq's decimalization	finance;capital market;research design;nasdaq;market microstructure;spreads;tick size;capital market synergetics;securities and exchange commission	Recent studies by the Securities and Exchange Commission (SEC) and by academics have provided empirical evidence that Nasdaq trade execution costs are still higher than, for instance, on the NYSE. Introducing decimal pricing is one concrete plan to enhance Nasdaq s competitiveness. However, effects of tick size changes are difficult to predict. For that reason models have been required for quite a while. Capital market synergetics is appropriate to investigate the effects of market microstructure changes. In this paper, we examine the impact of a variation in Nasdaq s minimum price increment on quoted spreads. First, our findings confirm the numerical value of the decline in the average quoted spread in 1997 as an immediate effect of reducing the tick size from $1/8 to $1/16. This strongly affirms the reliability of our calculation results. Second, by applying the same research design again, we investigate the impact of a further reduction in the tick size to $1/100. No such study is available at the moment. The expected changes in the average quoted spreads due to the reduction in the tick size from $1/16 to $1/100, the change through decimalization, range from an increase of 2.82% to a decrease of 15.51%. Derived by applying the same method again, the figures embody a reliable forecast of the real effects and are therefore of eminent importance to academics and to practitioners as well. 2003 Elsevier B.V. All rights reserved.	computer security;darknet market;numerical analysis;synergetics (haken);while	Otto Loistl;Bernd Schossmann;Alexander Veverka	2004	European Journal of Operational Research	10.1016/S0377-2217(03)00089-4	financial economics;market microstructure;economics;finance;capital market;financial system	Metrics	0.3418652163595334	-9.735202055766754	79349
092e7dadbc3162549ded46eb8edca3b69fc8b5f1	the global warming, sustainability, and environmental tax: dynamic general equilibrium model		A primitive economic model with classical population theory is constructed in order to examine the greenhouse effect on the sustainability of human population as well as the environmental tax when the sustainability is in danger. The conclusion of this paper is that when the negative effect is small, the tax can guarantee the sustainability, where the effective tax rate interval for the sustainability shrinks as the negative effect rises. When the negative effect exceeds the critical level, however, the environmental tax cannot guarantee the sustainability of human population. Thus, the remedial measure to reduce the greenhouse effect other than the environmental tax is needed for the sustainability.	aggregate data;c date and time functions;mathematical model;netware loadable module;population;simulation;utility	Toshitaka Fukiharu	2011		10.1007/978-3-642-22285-6_61	environmental economics;economics;international trade;economic growth	HCI	-0.568798180023622	-8.487352632274211	79541
646b92916a35b759152ecf0d1184d99b63996d7b	joint order and pricing decisions for fresh produce with put option contracts		This paper investigates a newsvendor problem for fresh produce with put option contracts, in which the stochastic demand is price sensitive. The newsvendor can obtain products by ordering from a firm and return unsold products by purchasing and exercising put options. The fresh produce incurs a circulation loss in quantity during its transportation. The optimal joint order and pricing decisions for the newsvendor are analytically derived in the presence of put option contracts and circulation loss. Moreover, combined with numerical analysis, the optimal order quantity and selling price of the newsvendor are found to decrease with option price, but increase with exercise price and circulation loss, whereas the maximum expected profit is found to decrease with option price and circulation loss, but increase with exercise price. Furthermore, the newsvendor with put option contracts can deal with the risks that caused by demand uncertainty and high circulation loss of fresh produce.		Chong Wang;Xu Chen	2018	JORS	10.1057/s41274-017-0228-1	financial economics;newsvendor model;extended newsvendor model;economics;microeconomics;commerce	ECom	0.13779247987482648	-5.920462440005417	79581
14833a00cabbbb9ff00ef938da0226ac7d09fc37	online retailer assortment planning and managing under customer and supplier uncertainty effects using internal and external data		One of the main significant and challenging decisions for online retailers is assortment planning (AP). This decision become even more complex while considering demand and supply uncertainties in the AP planning. However, this lead to more efficient results in today's uncertain markets. Online retailers of late have access to massive amounts of internal and external data which they can leverage their power for tackling the inherent demand uncertainty and supplier uncertainty for assortment planning. This paper propose an AP framework for declaring how to use that data in different stage of decision making. Demand function in the framework is augmented using Google Trends (GT) and Google Correalte (GC) data which improve its accuracy. Using GT and GC increase the power of demand function extrapolability. Feature based modeling has been proposed to this end which allows us to use the GT data more easily. The final assortment decisions are then weighted against the supplier uncertainties to adjust for considering the variety and lead-time supplier effect. Techniques such as operations research methods and web science model will be utilised to develop the required approaches. While assortment planning is the combination of marketing and operations research techniques, in this work for the first time we incorporate web science techniques as the third edge of this important process.	automated planning and scheduling;online shopping;operations research;web science	Zahra Saberi;Omar Khadeer Hussain;Morteza Saberi;Elizabeth Chang	2017	2017 IEEE 14th International Conference on e-Business Engineering (ICEBE)	10.1109/ICEBE.2017.12	management science;leverage (finance);data mining;supplier relationship management;web science;demand curve;marketing;computer science;supply and demand	Robotics	2.142028158819821	-8.49650696870845	79647
10834fd237e0f9d031282f1a8a625236582e1cda	erratum to 'supply chain design for unlocking the value of remanufacturing under uncertainty' [ejor 247 (2015) 804-819]				Wenyi Chen;Beste Kucukyazici;Vedat Verter;María Jesús Sáenz	2016	European Journal of Operational Research	10.1016/j.ejor.2016.02.025	industrial organization;economics;operations management	Robotics	2.7109879502394865	-7.774382052685066	79740
17d2cd72056741eb9c39422b2f24ae5810d4a889	truthful and near-optimal mechanism design via linear programming	optimal solution;social welfare;approximate algorithm;truthful and computationally efficient mechanisms;general techniques;multi unit auction;knapsack problem;probability distribution;linear program;mechanism design;lp relaxation;convex combination;combinatorial auction	We give a general technique to obtain approximation mechanisms that are truthful in expectation. We show that for packing domains, any α-approximation algorithm that also bounds the integrality gap of the LP relaxation of the problem by α can be used to construct an α-approximation mechanism that is truthful in expectation. This immediately yields a variety of new and significantly improved results for various problem domains and furthermore, yields truthful (in expectation) mechanisms with guarantees that match the best-known approximation guarantees when truthfulness is not required. In particular, we obtain the first truthful mechanisms with approximation guarantees for a variety of multiparameter domains. We obtain truthful (in expectation) mechanisms achieving approximation guarantees of O(√m) for combinatorial auctions (CAs), (1 + ε) for multiunit CAs with B = Ω(log m) copies of each item, and 2 for multiparameter knapsack problems (multi-unit auctions).  Our construction is based on considering an LP relaxation of the problem and using the classic VCG mechanism to obtain a truthful mechanism in this fractional domain. We argue that the (fractional) optimal solution scaled down by α, where α is the integrality gap of the problem, can be represented as a convex combination of integer solutions, and by viewing this convex combination as specifying a probability distribution over integer solutions, we get a randomized, truthful in expectation mechanism. Our construction can be seen as a way of exploiting VCG in a computational tractable way even when the underlying social-welfare maximization problem is NP-hard.	approximation;cobham's thesis;entropy maximization;lp-type problem;linear programming relaxation;np-hardness;problem domain;randomized algorithm;set packing	Ron Lavi;Chaitanya Swamy	2005	46th Annual IEEE Symposium on Foundations of Computer Science (FOCS'05)	10.1145/2049697.2049699	probability distribution;mechanism design;mathematical optimization;combinatorics;combinatorial auction;convex combination;linear programming;linear programming relaxation;social welfare;mathematics;mathematical economics;knapsack problem	Theory	-2.3408165157988448	-0.6457094174432573	79758
a9b01bbc220031967406076c40c38702833be273	quasi-robust multiagent contracts	bayes estimation;modelizacion;correlacion;optimisation;multiagent system;belief;optimizacion;sintesis mecanismo;concepcion optimal;expected utility;conception optimale;prior information;contrato;synthese mecanisme;strategie nash;modelisation;estimacion bayes;robust mechanisms;informacion a priori;croyance;contract;subasta;estrategia nash;bidding;optimal design;optimization;nash strategy;utilite attendue;enchere;contrat;mechanism synthesis;optimal contract;correlation;creencia;sistema multiagente;mechanism design;utilidad espera;modeling;multiagent contracts;information a priori;trading rule;systeme multiagent;estimation bayes;second price auction;auctions	"""criticism of mechanism design theory is that the optimal mechanism designed for one environment can produce drastically different actions, outcomes, and payoffs in a second, even slightly different, environment. In this sense, the theoretically optimal mechanisms usually studied are not """"robust."""" To study robust mechanisms while maintaining an expected utility maximization approach, we study a multiagent model in which the mechanism must be designed before the environment is as well understood as is usually assumed. The particular model is of an auction setting with binary private values. Our main result is that if the prior belief about the correlation in the agents' values is diffuse enough, the optimal Bayesian-Nash auction must also satisfy dominant strategy incentive constraints. Furthermore, when the optimal auction does provide dominant strategy incentives, it takes one of two forms: (i) if perfect correlation and negative correlation are excluded as possibilities, the auction incorporates all information about the prior belief over the possible correlations, and (ii) if either perfect correlation or negative correlation is a possibility, the auction does not incorporate any correlation information and can be described as a modified Vickrey auction."""	agent-based model;bayesian network;expectation–maximization algorithm;expected utility hypothesis;nash equilibrium;robustness (computer science)	Anil Arya;Joel Demski;Jonathan Glover;Pierre Liang	2009	Management Science	10.1287/mnsc.1080.0967	contract;mechanism design;mathematical optimization;economics;bidding;artificial intelligence;optimal design;vickrey–clarke–groves auction;belief;mathematics;microeconomics;mathematical economics;welfare economics;correlation;auction theory	AI	-4.184252021835953	-4.384802101456064	80034
30080188cfd81fb2c8d792734e9c04e7c33a9143	eco-optimization of pre-treatment processes in metal finishing	environmental impact sensitivity;computacion informatica;environmental impact;multi objective optimization;grupo de excelencia;lca indicator results;ciencias basicas y experimentales;zinc phosphating;quimica;zinc	8 Saving of bath chemicals and freshwater consumed within metal finishing systems and the reduction of wastewater produced can be important steps towards more sustainable processes. Furthermore, the application of regenerators is usually energy intensive. Accordingly, in an “eco–eco” (ECO) trade-off, importance should be given to both economic benefits as well as to several ecological measures. The approach presented here is the synthesis of an ECO-optimal reuse and recovery network (RRN) based on a simultaneous multi-objective system optimization model with dynamically chosen environmental objective. It includes a conventional cost objective and the potential environmental impact of the system. This second objective is represented by the maximal relative increase of indicator results. This, in turn, derives from a sensitivity analysis of lif e cycle inventory analysis (LCIA) integrated into mixed integer nonlinear programming (MINLP). This means, the LCA-rule, which claims that e al design is a ve function, P in dilemma b l indicators c 9	enterprise core objects;inventory analysis;mathematical optimization;maximal set;nonlinear programming;program optimization;relative record data set	Pinar Erol;Jorg Thming	2006	Computers & Chemical Engineering	10.1016/j.compchemeng.2005.10.010	mathematical optimization;environmental engineering;engineering;zinc;mathematics	PL	9.517748331122663	-4.883182369124303	80042
e0c8ffb4c24708ed5477e9cb6ddc1029e66b15aa	(s, s) policies for a dynamic inventory model with stochastic lead times	inventory analysis;dynamic programming;policies;lead time;inventory model;stockpiles;stochastic control;replenishment;362 stochastic inventory lead times;354 s;inventory control;s policies for stochastic lead time;models;354 s s policies for stochastic lead time;model theory	This study analyzes a stochastic lead time inventory model under the assumptions that (a) replenishment orders do not cross in time and (b) the lead time distribution for a given order is independent of the number and sizes of outstanding orders. The study extends the existing literature on the finitehorizon version of the model and yields an intuitively appealing dynamic program that is nearly identical to one that would apply in a transformed model with all lead times fixed at zero. Hence, many results that have been derived for fixed lead time models generalize easily. Conditions for the optimality of myopic basestock policies, and for the optimality of (s, S) policies are established for both finite and infinite planning horizons. The infinite-horizon model analysis is extended by adapting the fixed lead time results for the efficient computation of optimal and approximately optimal (s, S) policies.	computation;emoticon;inventory theory	Richard Ehrhardt	1984	Operations Research	10.1287/opre.32.1.121	inventory control;mathematical optimization;simulation;stochastic control;economics;operations management;dynamic programming;mathematics;model theory	ML	3.1810065500777984	-2.5132073444241176	80105
b093245a06f4c40f218181e9c4dff2d3a481fb75	capacity improvement of an unreliable production line - an analytical approach	buffer size;chaine fabrication;cycle time;fiabilidad;reliability;modelo markov;machine unique;batch production;amelioration capacite;approximation method;capacity improvement;product line;production process;production line;single machine;maquina unica;markov model;programacion lineal;produccion por lote;fiabilite;production par lot;processus fabrication;linear programming;programmation lineaire;linear program;estructura producto;linea fabricacion;modele markov;structure produit;product structure;proceso fabricacion	This paper addresses the problem of capacity estimation and improvement of a multi-stage, multi-product production line where workstations are subject to random failure and repair. The production line can process a variety of products in a batch production environment. Products are processed according to a predefined sequence. A linear programming model is used and modified by taking into account the random behaviour of unreliable stations. Station’s downtime is modelled as a fictive product added to the production sequence at appropriate positions. A general procedure for the insertion of fictive products is presented. The procedure considers the states up and down that a station may experience while processing the product mix. It consists of two main steps. Firstly, enumerate the station’s states and insert fictive products where appropriate. Secondly, find the best buffer size that minimizes the cycle time. The proposed approach considers more parameters than the Markovian models and the approximation methods where multi-product production lines longer than 2-station 1-buffer can be studied. Numerical examples are presented to show all the steps involved to compute the expected cycle time. Buffer contribution to minimize the cycle time of the production line is also addressed. Simulation is used to validate the results obtained. 2004 Elsevier Ltd. All rights reserved.	approximation;complex systems;computation;computer program;deployment environment;downtime;enumerated type;linear programming;mathematical optimization;mean time to repair;memory-level parallelism;numerical analysis;numerical method;product type;programming model;protocol buffers;randomness;simulation;time complexity;workstation	Walid Abdul-Kader	2006	Computers & OR	10.1016/j.cor.2004.11.015	mathematical optimization;cycle time variation;production line;linear programming;reliability;mathematics;scheduling;markov model;operations research	DB	9.081673387520988	3.1721071188852004	80144
8c84c036a0a641bbde46a0d455efad9ddf25d25e	design for the pricing strategy of return-freight insurance based on online product reviews	return freight insurance;online product review;return policy;product fit uncertainty	To resolve online shopping disputes with product return, some insurance companies have developed a new type of insurance called return-freight insurance to compensate consumers’ loss of return-freight fees. Traditional insurance-premium determination (such as support vector machines) has not fully merged all e-commerce factors, such as the product-fit uncertainty of online shopping, that could affect both insurance demand and return quantity. Based on these traits, we develop a profit-maximization model in terms of certain market-reaction parameters, especially product-fit uncertainty, and calculate the optimal pricing strategy, including both the insurance premium and the compensation. Using prospect theory, we explain why online product review could influence insurance applicants’ risk-averse behavior in the e-commerce situation. Then we solve for the reasonable premium and compensation given online product reviews from the insurance company’s perspective and obtain a number of managerial guidelines for using marketing and operational-strategy variables to influence those reaction parameters so as to obtain the maximum benefit from the market. Interestingly, when consumers’ sensitivity to product-fit uncertainty is moderate, an increase in product-fit uncertainty moves insurance premium and compensation in the opposite direction.		Shidao Geng;Wenli Li;Xiaofei Qu;Lirong Chen	2017	Electronic Commerce Research and Applications	10.1016/j.elerap.2017.05.001	actuarial science;economics;marketing;key person insurance;risk pool;auto insurance risk selection;commerce;deferred acquisition costs	DB	-2.486928341570904	-8.220409689487518	80193
0ed29af9c5e9f562dcd2e35304990242def0688c	the effect of subscription video-on-demand on piracy: evidence from a household-level randomized experiment		We partner with a major multinational telecommunications provider to analyze the effect of subscription video-on-demand (SVoD) services on digital piracy. For a period of 45 consecutive days, a group of randomly selected households who used BitTorrent in the past were gifted with a bundle of TV channels with movies and TV shows that could be streamed as in SVoD. We find that, on average, households that received the gift increased overall TV consumption by 4.6% and reduced Internet downloads and uploads by 4.2% and 4.5%, respectively. However, and also on average, treated households did not change their likelihood of using BitTorrent during the experiment. Our findings are heterogeneous across households and are mediated by the fit between the preferences of households in our sample for movies and the content available as part of the gifted channels. Households with preferences aligned with the gifted content reduced their probability of using BitTorrent during the experiment by 18% and decreased their am...		Miguel Godinho de Matos;Pedro Ferreira;Michael D. Smith	2018	Management Science	10.1287/mnsc.2017.2875	economics;the internet;internet privacy;marketing;upload;randomized experiment;bittorrent	NLP	-3.002836013222868	-7.279969869181118	80315
7eac387b623f2b7ef08656e855146f3070ba492e	generalized quantity competition for multiple products and loss of efficiency	grupo de excelencia;noncooperative games;ciencias basicas y experimentales;matematicas;bidding;cournot competition;grupo a	In this paper we study a generalized model for quantity (Cournot) oligopolistic competition. The main goal in this paper is to understand Cournot competition when firms are producing multiple differentiated products and are faced with a variety of constraints. We first study existence and uniqueness of Cournot equilibria under general constraints. The main focus of the paper is to compare the total society surplus and the total firms' profit under Cournot competition to the corresponding total surplus and total profit of the firms under a centralized setting, (i.e., when a single firm controls all the products in the market maximizing total surplus or total profit respectively). Our goal is to understand how the presence of competition affects the overall society (that includes firms and consumers) as well as the overall firms' profit in the system, but also determine what the key drivers of the inefficiencies that arise due to competition are.	centralized computing;nist hash function competition;nash equilibrium	L. Jonathan Kluberg;Georgia Perakis	2008	2008 46th Annual Allerton Conference on Communication, Control, and Computing	10.1287/opre.1110.1017	industrial organization;cournot competition;economics;bidding;marketing;microeconomics;commerce	Theory	-1.504811841960179	-5.508158918728584	80368
5f5a4dbf63b9bd9b146fb1bf4b38722e42d3bc4a	pricing and capacity decisions for non-profit internet service providers	non profit organization;value added services;capacity planning;pricing;cost recovery;internet service provider;lead time;data center;profitability;quality of service;economies of scale;cost recovery pricing	Many universities and other non-profit organizations started dial-up Internet access as a valueadded service to their respective communities. The implementation and maintenance of these services becomes a nontrivial task, requiring large annual budgets to keep these systems up and running. The mandate for these non-profit entities is to recover the costs of providing their value added services in the long run while maintaining a guaranteed quality of service (QoS) level. Their pricing and capacity planning problem has three distinct aspects. First, pricing based on cost recovery has inherent challenges. Second, the non-profit ISPs have to tackle the growth of very unpredictable demand that calls for a continuous capacity expansion. Third, capacity expansion in terms of Internet dial-up lines comes only in multiple or bulk units which typically exhibit economy of scale characteristics. Another critical issue of capacity expansion is the timing of the expansion since the installation of capacity requires a lead-time for testing. This paper proposes a Busiest-Minute Planning Model (BMPM) for the non-profit ISPs to effectively solve the aforementioned issues. The BMPM model provides non-profit ISPs a mechanism to determine the optimum capacity for a given QoS level. The mechanism can predict when existing capacity becomes saturated by taking into account the desired QoS and future demand growth. The BMPM model proposed in this paper is tested using data from a non-profit ISP The Northeast Regional Data Center (NERDC) of the State of Florida. The results suggest that our BMPM model is very effective in solving the pricing and capacity expansion decisions of NERDC and can be applied to other non-profit ISPs.	data center;dial-up internet access;entity;quality of service	Hsing Kenneth Cheng;Kutsal Dogan;Richard Elnicki	2006	Information Technology and Management	10.1007/s10799-006-8102-x	pricing;data center;actuarial science;quality of service;economics;economies of scale;marketing;operations management;management;law;commerce;profitability index	Metrics	1.0057057392173472	-8.122433980354117	80404
5ab573319970d4a20232ca66427c54044a24ac31	a simulation aided solution to an mcdm problem	forestry;management costs;uncertainty;uncertain payoff values;stochastic simulation;resource management;water supply;random processes digital simulation forestry decision theory water supply ecology;random variables;northern arizona region;wild life;ecology;water quality;delta modulation;wood products;aesthetics;stochastic processes;decision theory;random processes;random variable;production;forest treatment problem;uncertainty resource management random variables land use planning delta modulation industrial engineering stochastic processes production quality management costs;wood production;randomization;water quantity;land use planning;industrial engineering;discrete multiple criterion decision making problem;digital simulation;quality management;uncertainty modelling;management costs forest treatment problem northern arizona region discrete multiple criterion decision making problem uncertain payoff values randomization random variables uncertainty modelling stochastic simulation water quantity water quality wild life wood production aesthetics	A forest treatment problem arising in a Northern Arizon region is first formulated as a discrete MCDM problem, which the payoff values are uncertain. This uncertainty modeled by randomization considering the uncerta values as random variables with assumed types distribution depending on the levels of uncertainty. combination of discrete MCDM methodology and stochastic simulation is used to find the best treatme strategy with respect to criteria including water quanti and quality, wild life, wood production, aesthetics an management costs.	simulation	Ferenc Szidarovszky;Abdollah Eskandari	1999		10.1145/324138.324437	random variable;stochastic process;simulation;engineering;mathematics;management science;statistics	AI	6.364214318865233	-5.745615066429814	80425
7869da224d87a65f8649ffbf1f698b138038df00	a novel bi-vector encoding genetic algorithm for the simultaneous multiple resources scheduling problem	manufacturing management;total resource management;flexible manufacturing systems;scheduling;genetic algorithm	To improve capital effectiveness in light of demand fluctuation, it is increasingly important for high-tech companies to develop effective solutions for managing multiple resources involved in the production. To model and solve the simultaneous multiple resources scheduling problem in general, this study aims to develop a genetic algorithm (bvGA) incorporating with a novel bi-vector encoding method representing the chromosomes of operation sequence and seizing rules for resource assignment in tandem. The proposed model captured the crucial characteristics that the machines were dynamic configuration among multiple resources with limited availability and sequence-dependent setup times of machine configurations between operations would eventually affect performance of a scheduling plan. With the flexibility and computational intelligence that GA empowers, schedule planners can make advanced decisions on integrated machine configuration and job scheduling. According to a number of experiments with simulated data on the basis of a real semiconductor final testing facility, the proposed bvGA has shown practical viability in terms of solution quality as well as computation time. Jei-Zheng Wu Department of Business Administration, Soochow University, Taipei, Taiwan e-mail: jzwu@scu.edu.tw Xin-Chang Hao Graduate School of Information, Production and Systems, Waseda University, Kitakyushu-shi, Fukuoka, Japan. e-mail: haoxc@ruri.waseda.jp	bang file;bang–bang control;causality;computation;computational intelligence;crossover (genetic algorithm);decoding methods;email;entity–relationship model;experiment;fred (chatterbot);genetic algorithm;goto;job scheduler;lu decomposition;limited availability;mutation (genetic algorithm);petri net;quantum fluctuation;scheduling (computing);semiconductor;software release life cycle;time complexity	Jei-Zheng Wu;Xin-Chang Hao;Chen-Fu Chien;Mitsuo Gen	2012	J. Intelligent Manufacturing	10.1007/s10845-011-0570-0	fair-share scheduling;mathematical optimization;simulation;genetic algorithm;dynamic priority scheduling;computer science;engineering;rate-monotonic scheduling;genetic algorithm scheduling;scheduling;management science;scheduling	AI	9.823814798182637	0.38312396341865324	80439
1383d618c49d9a8a146ead8e5cf91f1b1e94a5d9	worst-case demand distributions in vehicle routing		A recent focal point in research on the vehicle routing problem (VRP) is the issue of robustness in which customer demand is uncertain. In this paper, we conduct a theoretical analysis of the demand distributions whose induced workloads are as undesirable as possible. We study two common variations of VRP in a continuous approximation setting: the first is the VRP with time windows, and the second is the capacitated VRP, in which regular returns to the vehicle’s point of origin are required.	approximation;best, worst and average case;cobham's thesis;decision support system;focal (programming language);gravity model of trade;kullback–leibler divergence;mathematical optimization;microsoft windows;robust optimization;scheme;vehicle routing problem	John Gunnar Carlsson;Mehdi Behroozi	2017	European Journal of Operational Research	10.1016/j.ejor.2016.03.047	mathematical optimization;simulation;economics;operations management	Theory	4.177192453305564	-3.798008602382655	80569
f181166ae39e033b7e267b420b46990f5fc9337c	computer graphics in distribution system planning	distributed system;distribution network;reseau distribution;reseau electrique;exploitation;electrical network;logiciel graphique;red electrica;computer graphic;red distribucion;planificacion;planning;planification;explotacion	-This paper describes the general approach and the characteristic of methodology developed for the Instituto de Investigaciones El6ctricas of Mexico (IIE). Recent developments in new technologies and equipment, the advancements made in tools and techniques for mathematical analysis, and the availability of computer equipment for information acquisition, storage and processing have all accelerated progress in the application of computers to the design of distribution networks. Computers cannot yet substitute for the engineer's judgement during the planning process, but their use does provide the engineer with better information and more time to think. Computer models help achieve better and faster decisions, and help explore more alternatives with less resources. THE ELECFRICAL DISTRIBUTION SYSTEM AND THE PLANNING FUNCTION Distribution systems are those networks which transport electric energy from the transmission system to the customer. The distribution system can be divided into the following components: Subtransmission Primary feeders Distribution substations Distribution transformers Secondary feeder Customer The principal objective of distribution system planning is to solve the complex problem of selecting the best design and the best investment strategy to be implemented, subject to service quality specifications and other external constraints. Distribution planning is not technically the same as transmission system planning. Whereas transmission systems are relatively static, distribution systems are by nature dynamic. The distribution system is in continuous change, making it necessary to use computers to update the continuous transformation of the system. In summary, the planning process of a distribution system is numerically more complex. As a result of the large number and the complexity of the interrelationships among the variables that play a role in the planning process of a distribution system, it becomes very difficult to make an exhaustive evaluation of the many alternatives available. However, the automation of the planning process and the consequent possibility of using computers in designing the networks are now a reality. Recent developments in new technologies and equipment, the advancement made in mathematical analysis tools and techniques, as well as the availability of computerized equipment for data acquisition, storage and processing of information have all accelerated progress in this field. The application of computers will not substitute for the engineer's judgement during the planning process, but its use does provide the engineer more and better information and free time to think. The models implemented on the computer aid in making better and faster decisions, and in exploring more alternatives with less resources. Distribution System Planning using modeling and optimisation techniques has been studied for the last two decades. The problem is considered numerically very complex because of the high dimensionality of the network representation. This is the principal variable involved in the different models and methods published in the literature. Furthermore, other important characteristics are the high investment cost and the existence of variables with nonlinear behaviour, such as the losses cost. liEs METHOD In Mexico, the Instituto de Investigaciones El6ctricas (IIE) has been working in this area since 1978 and has developed a computerized system for distribution network planning. The conceptual model is described in Ref. [8] and considers the following three subsystems: 1. Optimisation. 2. Load Forecasting. 3. Information. Based on a methodology approach, the software was developed with the following functions: 1. Data collection and management. 2. Network compaction. 3. Aggregate demand forecasting. 4. Long-range forecasting of spatial load. 5. Short-range forecasting of spatial load. 6. Distribution substation expansion. 7. Primary feeders expansion. 8. Operational analysis. NETWORK OPTIMIZATION PROGRAMS Using the load forecasts, the network optimization programs solve three basic problems: --Distr ibution substation location and sizing. -Pr imary feeder synthesis. -Secondary network. In the three problems the system is represented by a set of nodes and segments. The nodes can be supply, demand, or connection nodes. The segments axe the links between nodes. The supply nodes as well as the	aggregate function;computer graphics;computer simulation;data acquisition;data compaction;inline expansion;mathematical optimization;nonlinear system;numerical analysis;traction substation;transformers	A. Afuso Higa;M. Vega Ortíz	1988	Computers & Graphics	10.1016/0097-8493(88)90058-1	planning;electrical network;simulation;computer science;artificial intelligence;operations research	Robotics	7.962521625898003	-4.799157938780942	80576
6676ca80011b683531304967f1a5e707f44bef48	the influence of developer multi-homing on competition between software ecosystems	two sided markets;multi homing;software ecosystem	Having a large number of applications in the marketplace is considered a critical success factor for software ecosystems. The number of applications has been claimed to determine which ecosystems holds the greatest competitive advantage and will eventually dominate the market. This paper investigates the influence of developer multi-homing (i.e., participating in more than one ecosystem) in three leading mobile application ecosystems. Our results show that when regarded as a whole, mobile application ecosystems are singlehoming markets. The results further show that 3% of all developers generate more than 80% of installed applications and that multi-homing is common among these developers. Finally, we demonstrate that the most installed content actually comprises only a small number of the potential value propositions. The results thus imply that attracting and maintaining developers of superstar applications is more critical for the survival of a mobile application ecosystem than the overall number of developers and applications. Hence, the mobile ecosystem is unlikely to become a monopoly. Since exclusive contracts between application developers and mobile application ecosystems are rare, multi-homing is a viable component of risk management and a publishing strategy. The study advances the theoretical understanding of the influence of multi-homing on competition in software ecosystems. © 2015 The Authors. Published by Elsevier Inc. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).	mobile app;monopoly;multihoming;multiple homing;risk management;software ecosystem	Sami Hyrynsalmi;Arho Suominen;Matti Mäntymäki	2016	Journal of Systems and Software	10.1016/j.jss.2015.08.053	simulation;computer science;engineering;multihoming;management	SE	-3.937454386559555	-6.732780144194885	80699
2cadf2cc652501e0ff2f63631e5cc48339e933f9	mean-variance portfolio and contribution selection in stochastic pension funding	minimisation;dynamic programming;minimization;programacion dinamica;finance;bolsa valores;portfolio selection;seleccion cartera;minimizacion;dynamic program;probabilistic approach;mean variance;bourse valeurs;selection portefeuille;stock exchange;commande stochastique;efficient frontier;portfolio theory;enfoque probabilista;approche probabiliste;pension fund;programmation dynamique;pension funding;portfolio management;stochastic control;control estocastico;defined benefit;pension plan;gestion cartera;risk measure;gestion portefeuille;optimal portfolio;finanzas	In this paper we study the problem of simultaneous minimization of risks, and maximization of the terminal value of expected funds assets in a stochastic defined benefit aggregated pension plan. The risks considered are the solvency risk, measured as the variance of the terminal fund’s level, and the contribution risk, in the form of a running cost associated to deviations from the evolution of the stochastic normal cost. The problem is formulated as a bi-objective stochastic problem of mean variance and it is solved with dynamic programming techniques. We find the efficient frontier and we show that the optimal portfolio depends linearly on the supplementary cost of the fund, plus an additional term due to the random evolution of benefits.	dynamic programming;entropy maximization;risk management	Ricardo Josa-Fombellida;Juan Pablo Rincón-Zapatero	2008	European Journal of Operational Research	10.1016/j.ejor.2007.03.002	financial economics;efficient frontier;minimisation;stock exchange;actuarial science;stochastic control;economics;modern portfolio theory;dynamic programming;welfare economics;project portfolio management	ML	3.770046428132393	-2.8617295841439754	80717
783e4016bbb3b0eea7b39d60aec6b839c11aa48b	coupling optimization and statistical analysis with simulation models		Simulation optimization has become commonplace in commercial simulation tools, but automated statistical analysis of the impacts of varying input parameters is much less common. In this paper we explore how both optimization and statistical analysis can be coupled with simulation models to provide key insights for decision makers. A manufacturing example is provided to illustrate the results of multi-objective optimization and post-optimization statistical analysis of the simulation runs. We demonstrate how automated statistical analysis can provide analysts with valuable information on variable sensitivities and good and bad regions of the decision trade space.	coupling (computer programming);mathematical optimization;multi-objective optimization;optimization problem;simulation	Benjamin G. Thengvall;Fred Glover;Dave Davino	2016	2016 Winter Simulation Conference (WSC)		data modeling;econometrics;statistical theory;sensitivity;computer science;mathematics;management science;manufacturing;statistics	EDA	9.8645612825162	-4.938307152888291	80914
d049fd2cc7c2a3baa352f1575f632c0c145075ba	expected utility for nonstochastic risk	nonstochastic randomness;expected utility;mass phenomena;c10 general;risk;d81 criteria for decision making under risk and uncertainty;multiple prior;statistical regularity	The world of random phenomena exceeds the domain of the classical probability theory. In the general case the description of randomness requires a specific set of probability distributions (which is called statistical regularity) rather than a singe distribution. Such statistical regularity arises as a limit of relative frequencies. This approach to randomness allows to generalize the expected utility theory in order to cover the decision problems under nonstochastic random events. Applying the von Neumann – Morgenstern utility theorem, we derive the maxmin expected utility representation for statistical regularities. The derivation is based on the axiom of the preference for stochastic risk, i.e. the decision maker wishes to reduce the set of probability distributions to a single one.	decision problem;expected utility hypothesis;minimax;randomness	Victor Ivanenko;Illia Pasichnichenko	2017	Mathematical Social Sciences	10.1016/j.mathsocsci.2016.12.005	mathematical optimization;combinatorics;optimal decision;economics;two-moment decision model;expected utility hypothesis;finance;risk;mathematics;subjective expected utility;mathematical economics;von neumann–morgenstern utility theorem;statistics	ML	0.07125515303314334	-2.25716670667894	81068
ad72fbc56f27936df4fcaf7c296f7f656750d6f7	an inventory model with limited production capacity and uncertain demands i. the average-cost criterion	limited production capacity;inventory model;average-cost criterion;uncertain demand		inventory theory	Awi Federgruen;Paul H. Zipkin	1986	Math. Oper. Res.	10.1287/moor.11.2.193		Theory	3.851650969979803	-3.925442835820167	81223
cf047932a00de0aa4a3d4014626efc5bceea29b6	cooling-aware energy and workload management in data centers via stochastic optimization	distributed storage;cooling aware;i i d processes cooling aware energy data centers end users internet services global warming climate change energy efficient cooling facilities distributed storage units system wide energy workload management policy offline management policies real time management schemes stochastic optimization tools unified management approach information technology it workload shift energy price fluctuations long term quality of service requirements qos requirements storage devices near optimal management strategy independently and identically distributed workload electricity price processes real data scenarios;data center;stochastic optimization;cooling optimization quality of service signal processing algorithms batteries power demand;cost minimization;stochastic optimization cooling aware cost minimization data center distributed storage renewable generation;renewable generation;batteries;optimization;quality of service;signal processing algorithms;power demand;stochastic programming computer centres quality of service real time systems;cooling	While the quest of end users for fast and convenient Internet services grows steadily, energy-hungry data centers correspondingly expand in both numbers and scale - a fact that raises global warming and climate change concerns. In addition, high penetration of renewables, development of energy-efficient cooling facilities, and flexibility of distributed storage units, all call for a system-wide energy and workload management policy for future sustainable data centers. As implementing offline management policies is practically infeasible due to complexity and the lack of future information, real-time management schemes are considered here under a systematic framework. Leveraging stochastic optimization tools, a unified management approach is proposed allowing data centers to adaptively respond to intermittent availability of renewables, variability of cooling efficiency, information technology (IT) workload shift, and energy price fluctuations under long-term quality-of-service (QoS) requirements. Meanwhile, it is rigorously established that when storage devices have sufficiently high capacity, or, the difference between electricity purchase and selling prices is small, the proposed algorithm yields a feasible and near-optimal management strategy without knowing the distributions of the independently and identically distributed (i.i.d.) workload, renewable, and electricity price processes. Numerical results further demonstrate that the proposed algorithm works well not only for i.i.d. processes, but also in real-data scenarios, where the underlying randomness is highly correlated over time.	clustered file system;computer cooling;data center;heart rate variability;internet;iteration;mathematical optimization;numerical analysis;numerical method;online algorithm;online and offline;optimization problem;power supply;program optimization;quality of service;randomness;real-time clock;real-time transcription;requirement;schedule (computer science);spectral leakage;stochastic optimization;stochastic process;subgradient method	Tianyi Chen;Xin Wang;Georgios B. Giannakis	2016	IEEE Journal of Selected Topics in Signal Processing	10.1109/JSTSP.2015.2500189	data center;real-time computing;simulation;quality of service;computer science;stochastic optimization	Metrics	2.4892339154632572	3.8365921172626916	81310
3473dfd271c9739bf166db5e1d2d8bdc04ef0bb3	time horizons, lattice structures, and welfare in multi-period matching markets		We analyze a T -period, bilateral matching economy without monetary transfers. Under natural restrictions on agents’ preferences, which accommodate switching costs, status-quo bias, and other forms of inter-temporal complementarity, dynamically stable matchings exist. We propose an ordering of the set of dynamically stable matchings ensuring this set forms a lattice. We investigate the robustness of dynamically stable matchings with respect to the market’s time horizon. We relate our analysis to marketdesign applications, including student-school assignment and labor markets.		Sangram Vilasrao Kadam;Maciej H. Kotowski	2018	Games and Economic Behavior	10.1016/j.geb.2018.07.005	mathematical optimization;economics;mathematical economics;welfare economics	ECom	-4.177451603762433	-3.413854437588477	81502
f8168161a1c99fd38631edc9da46af53fc6bce28	an mpc-based privacy-preserving protocol for a local electricity trading market		This paper proposes a decentralised and privacy-preserving local electricity trading market. The proposed market employs a bidding protocol based upon secure multiparty computations and allows users to trade their excess electricity among themselves. The bid selection and calculation of the clearance price at which the electricity is traded are performed by the market in a decentralised and privacy-preserving manner. We implemented the market in C++ and tested its performance with realistic data sets. Our simulation results show that the market tasks can be performed for 2500 bids in less than five minutes in the online phase, showing its feasibility for a typical electricity trading period of, for example, 30 minutes.	c++;computation;mathematical optimization;offset binary;privacy;simulation	Aysajan Abidin;Abdelrahaman Aly;Sara Cleemput;Mustafa A. Mustafa	2016	IACR Cryptology ePrint Archive	10.1007/978-3-319-48965-0_40	open outcry;electricity market;order;electricity retailing;electronic trading;domestic market;trading turret;alternative trading system;algorithmic trading	ECom	0.5933480070761402	3.408113109681955	81511
d8afbd68f9330d6eecdad5982bb31c72c84858fb	universal service obligations: the role of subsidization schemes	universal service;universal service obligation;universal service obligations regulation	0167-6245/$ see front matter 2008 Elsevier B.V doi:10.1016/j.infoecopol.2008.07.003 q The authors thank J.-T. Bernard, J.A. Doucet, A. G Mougeot, L. Thomas and two anonymous referees f All errors are ours. * Corresponding author. Tel.: +1 418 656 2337; fa E-mail addresses: francois.mirabel@univ-montp1 christophe.poudou@univ-montp1.fr (J.-C. Poudou), M laval.ca (M. Roland). A universal service obligation (USO) that imposes ubiquity and uniform pricing constraints generally creates strategic links among markets served by the universal service provider (USP). In this paper, we show that adding a unit subsidy in the compensation scheme of a USO helps to counteract the inefficiencies that result from these strategic links. Welfare obtained under different implementations of the USO depends on whether use of the unit subsidy is limited or not. In this respect, franchise bidding for the USO, where firms submit bids for lump-sum subsidies, is welfare-dominated by the exogenous choice of the USP and by pay-or-play regulation. Similarly, the second-best allocation can be attained through the endogenous choice of the USP’s geographic area of monopoly, provided the unit subsidy instrument is available. 2008 Elsevier B.V. All rights reserved.	like button;lumped element model;maniac mansion;monopoly;universal storage platform	F. Mirabel;J.-C. Poudou;M. Roland	2009	Information Economics and Policy	10.1016/j.infoecopol.2008.07.003	industrial organization;actuarial science;economics;marketing;microeconomics;economic growth;commerce	ECom	-1.8079433344780207	-7.314986141951231	81794
738cd056b88edc6d77c1201ab22b94a7e3fa8b13	multicriteria and multiperiod programming for scenario analysis in guadalquivir river irrigated farming	agriculture durable;forecasting;reliability;project management;information systems;irrigation;maintenance;hydrologie;desarrollo sostenible;multiperiod programming;soft or;information technology;developpement durable;packing;irrigacion;operations research;location;multicriteria programming;investment;journal;fonction objectif;journal of the operational research society;agricultura sostenible;programmation multiperiode;inventory;purchasing;objective function;hidrologia;history of or;logistics;scenario analysis;marketing;scheduling;explotacion agricola;hydrology;production;programmation multicritere;communications technology;funcion objetivo;sustainable agriculture;farming;computer science;operational research;exploitation agricole;applications of operational research;sustainable development;or society;jors;management science;infrastructure	A multiperiod model based upon a multicriteria objective function has been developed for a representative area of the Guadalquivir Valley, dividing the irrigated area into homogeneous types of farming as identified by cluster analysis. The model was applied to different future scenarios with a time horizon of 10 years and several different farming environments. A set of eight sustainability indicators has been evaluated for the model. The results show that the evolution of crops over time is closely related to the political environment regarding the Common Agricultural Policy and the application of the Water Framework Directive. Methodological innovation has included the successful simultaneous introduction of MCDM and multiperiod programming techniques applied to agriculture and scenario development.	cluster analysis;directive (programming);loss function;optimization problem;proposed directive on the patentability of computer-implemented inventions;scenario analysis;uncanny valley	M. J. López-Baldovin;C. Gutiérrez-Martín;J. Berbel	2006	JORS	10.1057/palgrave.jors.2602029	project management;logistics;inventory;economics;forecasting;investment;computer science;environmental resource management;marketing;operations management;reliability;irrigation;scenario analysis;location;management;operations research;information technology;scheduling;sustainable development;sustainable agriculture	AI	7.168265922290509	-4.291838516457879	81844
2b83f4afeb519e3706b4f2f822623fae33a571ce	the complete proof on the optimal ordering policy under cash discount and trade credit	modelizacion;optimal solution;politica optima;fournisseur;trade credit;relacion orden;ordering;supplier;optimal policy;methode algebrique;inventory model;inventory;modelisation;relation ordre;rebajas;algebraic method;eoq models;cash discount;metodo algebraico;discount;politique optimale;rabais;modeling;proveedor	Huang ((2005), ‘Buyer’s Optimal Ordering Policy and Payment Policy under Supplier Credit’, International Journal of Systems Science, 36, 801–807) investigates the buyer’s optimal ordering policy and payment policy under supplier credit. His inventory model is correct and interesting. Basically, he uses an algebraic method to locate the optimal solution of the annual total relevant cost TRC(T ) and ignores the role of the functional behaviour of TRC(T ) in locating the optimal solution of it. However, as argued in this article, Huang needs to explore the functional behaviour of TRC(T ) to justify his solution. So, from the viewpoint of logic, the proof about Theorem 1 in Huang has some shortcomings such that the validity of Theorem 1 in Huang is questionable. The main purpose of this article is to remove and correct those shortcomings in Huang and present the complete proofs for Huang.	cash;chart;computer;huang's algorithm;industrial engineering;inventory control;inventory theory;markov chain;markov decision process;mathematical model;mathematical optimization;operations research;renegade;shadow volume;systems science	Kun-Jen Chung	2010	Int. J. Systems Science	10.1080/00207720903045866	mathematical optimization;systems modeling;inventory;order theory;mathematics;mathematical economics	Logic	2.841634677088506	-4.290921301508201	81902
a87fee26f5d5b39f2704a2710bd41cd073d19583	advanced methods for the risk, vulnerability and resilience assessment of safety-critical engineering components, systems and infrastructures, in the presence of uncertainties	systemes et infrastructures critiques;simulation;risque;vulnerability;vulnerabilite;advanced computational methods;uncertainties;resilience;risk;surete;methodes computationnelles avancees;mathematical model;infrastructures;incertitude;safety critical systems	cascading models in network optimization tasks. As a further step in the comparison between topological and flow-based models, in [Fang et al., 2015b] we have tackled the problem of searching for the most favorable pattern of link capacity allocation for a CI power network with the objective of resisting to cascading failures with limited investment costs. As before, low vulnerability and low cost are conflicting objectives: for instance, a network whose components have high capacity can be highly resistant to failures; however, this type of components is often characterized by high costs. The problem has been formulated within a multi-objective optimization framework and has been solved by an evolutionary algorithm, namely	accessibility;apple a5;apple a7;backup;best, worst and average case;bootstrapping (statistics);cascading failure;control table;critical system;cross-validation (statistics);database normalization;evolutionary algorithm;exemplification;flow network;hash table;hierarchical database model;image scaling;mathematical optimization;minimal working example;multi-objective optimization;nominal power (radio broadcasting);numerical analysis;optimization problem;physical symbol system;point of view (computer hardware company);self-organized criticality;slack variable;test set;weight function	Nicola Pedroni	2016			reliability engineering;systems engineering;engineering;vulnerability assessment;computer security	AI	7.544222791808723	-4.148772614655116	81990
29df0ec6d7ca7fef2385d2a6d065c9d795667838	a simple algorithm for the nucleolus of airport profit games	airport cost profit games;nucleolus;profitability	In this paper we present a procedure for calculating the nucleolus for airport profit games which are a generalization of the airport cost games.	algorithm	Rodica Branzei;María Elena Iñarra García;Stef Tijs;José Manuel Zarzuelo	2006	Int. J. Game Theory	10.1007/s00182-006-0019-4	economics;operations management;microeconomics;nucleolus;commerce;profitability index;airport problem	Logic	-1.8899231859324466	-3.55577011167417	82036
ff66aab4cf6782af35293cc9c8b939259ec872f2	postponement and international transfer in global supply chains		In this paper, we develop an analytical model for form postponement in global supply chain subject to variations in international transfers and tariffs, in service levels and in deviation from a su...		Thomas Ngniatedema;Romuald Thierry Dzati Kamga;Louis Aimé Fono;Georges Dieudonné Mbondo;Suhong Li	2018	IJBPSCM	10.1504/IJBPSCM.2018.10014520	industrial organization;business;operations management;delivery performance;supply chain;postponement;service level	Robotics	1.3730239352735751	-7.039752340048801	82096
f00747800f27000ffc4a85318a002b44069dd80e	mechanism design for capacity allocation with price competition	business to business;capacity allocation;allocation mechanism design;price competition;mechanism design;supply chain management;oligopoly	Studies on mechanism design mostly focus on a single market where sellers and buyers trade. This paper examines the problem of mechanism design for capacity allocation in two connected markets where a supplier allocates products to a set of retailers and the retailers resale the products to end-users in price competition. We consider the problems of how allocation mechanisms in the upstream market determine the behaviors of markets in the downstream market and how pricing policy in the downstream market influences the properties of allocation mechanisms. We classify an effective range of capacity that influences pricing strategies in the downstream market according to allocated quantities. Within the effective capacity range, we show that the retailers tend to inflate orders under proportional allocation, but submit truthful orders under uniform allocation. We observe that heterogeneous allocations results in greater total retailer profit which is a unique phenomenon in our model. The results would be applied to the design and analysis of Business-to-Business (B2B) marketplaces and supply chain management.	downstream (software development);upstream (software development)	Masabumi Furuhata;Laurent Perrussel;Dongmo Zhang	2008		10.1145/1409540.1409598	industrial organization;microeconomics;business;price mechanism;commerce	ECom	-1.2484648679797803	-5.81437193983806	82370
4f30961c5881647a7c67a69545d0739eb6425de8	do stock returns really decrease with default risk? new international evidence	bankruptcy	This study constructs a unique dataset of bankruptcy filings for a large sample of nonU.S. firms in 14 developed markets and sheds new light on the cross-sectional relation between default risk and stock returns. Using the flexible approach of Campbell et al. (2008) to estimate default risk probabilities, this is the first study to offer conclusive evidence supporting the existence of an economically and statistically significant positive default risk premium in international markets. This finding is robust to different portfolio weighting schemes, data filters, sample periods, and holding period definitions, and it holds using both in-sample estimates of default probabilities during the 1992-2010 period and out-of-sample estimates during the 2000-2010 period. We also show that the magnitude of the default risk premium is contingent upon several firm characteristics.	cross-sectional data;risk aversion;risk measure	Kevin Aretz;Chris Florackis;Alexandros Kostakis	2018	Management Science	10.1287/mnsc.2016.2712	financial economics;bankruptcy;non-performing loan;economics;financial risk;finance;financial system;microeconomics;default;law	Security	-1.746135049846067	-8.885182960834117	82438
0bc74516d0fd53a76586543e816a5bc8cb21548b	co-op advertising models in one manufacturer-two retailers supply chains with spillover effect		In the literature of cooperative advertising co-op, many researchers paid their attentions on the situation of one manufacturer and one retailer. This paper expands the research to one manufacturer and two retailers. The effect of co-op advertising mechanism is discussed here through national advertising investment, local advertising expenditure, and spillover effect which reveals the influence that one retaileru0027s local advertising effort exerts on the othersu0027 sales. For this purpose, three co-op advertising models are discussed: one non-cooperation game, one horizontal cooperation game and one vertical cooperation game. Comparing the three models, we can draw three significant conclusions as follows. First, under the condition of the manufacturer taking a non-cooperative attitude, retailers who cooperate with each other are willing to make more local advertising effort than the non-cooperative ones in the growth period of the product, but in the maturity period, the opposite is the case. In the second, the manufactureru0027s national advertising investment and the spillover effect are uncorrelated. Also, it can be guaranteed that the national advertising investment is greater than the other two models in vertical model. In the third vertical model, the higher the co-op advertising reimbursement portion is, the more the retailersu0027 profit, and the less the manufactureru0027s profit. The systemu0027s profit and the reimbursement policy are uncorrelated	knowledge spillover	Hong Zhang;Quan-ju Zhang	2016	IJCSE	10.1504/IJCSE.2016.10000105	supply chain management;profit;advertising account executive	ECom	-1.8556057926446712	-6.204323574959292	82499
00070265637d52eb4d938deb14bf876f756e4ea9	optimisation of resources deployment in a call centre by using stochastic data in simulation models	mechanical aeronautical and manufacturing engineering;business and management studies;aeronautical and manufacturing engineering;mechanical;computer science and informatics	In recent years, call centres have been considered as an integral part of the modern businesses,#R##N#since they play an important role in providing service delivery functions to their customers. A#R##N#well-managed call centre, therefore, is crucial to ensure high level of customer satisfaction in#R##N#today’s competitive market. In order to achieve a high standard, managers of call centres face#R##N#a very difficult set of challenges. At the top level, they must strike a balance between two#R##N#powerful competing interests: low operating costs and high service quality. On a day-to-day#R##N#basis, while simultaneously keeping low costs and high service quality, those managers must#R##N#also employ appropriate techniques and tools in order to evaluate the true performance of#R##N#their operations accurately. Such tools play a vital role in understanding the current system#R##N#performance, evaluation of any proposed enhancement scenarios, and optimising operations#R##N#management decisions under any unexpected operating conditions.#R##N#One of traditional operations management challenges for call centre managers is to tackle the#R##N#multi-period human resources allocation problem. In this thesis, the staffing and staff#R##N#scheduling decisions in single-skill inbound call centres were studied. These decisions are#R##N#normally made under strict service level constrain in the presence of highly uncertain#R##N#operations and demand of call centre services. Neglecting such uncertainty may lead to#R##N#unrealistic decisions. The objective of this research thesis was to propose a framework to#R##N#enhance the call centre performance through taking realistic optimal staffing and scheduling#R##N#decisions. Realistic optimisation requires realistic modeling (evaluation) of call centre#R##N#operations which is the main focus and contribution of this research.#R##N#The proposed framework has combined statistical, simulation, and Integer Programming (IP)#R##N#techniques in achieving realistic optimisation. The framework begins by developing stochastic#R##N#statistical data models for call centre operations parameters which are divided into service#R##N#demand (arrival volumes) and service quality (service times, abandonment volumes, and#R##N#patience time) parameters. These data models are then fed into a simulation model which was#R##N#developed to determine the minimum staffing levels in daily an-hour periods. Finally, these#R##N#staffing levels are considered as input to an IP model that optimally allocates the service#R##N#agents to the different operating shifts of a typical working day. Application of the proposed#R##N#framework to a call centre in Libya will also be presented to illustrate how its staffing and#R##N#scheduling decisions could be improved by using the model.	mathematical optimization;simulation;software deployment	Ahmed A. Elfituri	2014			simulation;engineering;operations management;management science	Metrics	9.402113674071916	1.8238470594605525	82638
a7334dcc567c01b0e2510f8e6472a5343b064698	optimal incentives for participation with type-dependent externalities	nash equilibrium	We study a “principal-agent” setting in which a principal motivates a team of agents to participate in her project (e.g., friends in a social event or store owners in a shopping mall). A key element in our model is the externalities among the agents; i.e., the benefits that the agents gain from each others’ participation. Bernstein and Winter [6] devised a basic model for this setting and characterized the optimal incentive mechanism inducing full participation as a unique Nash equilibrium. Here we suggest and embark on several generalizations and extensions to the basic model, which are grounded in real-life scenarios. First, we study the effect of side payments among the agents on the structure of the optimal mechanism and the principal’s utility. Second, we study the optimal partition problem in settings where the principal operates multiple parallel projects.	nash equilibrium;partition problem;phil bernstein;real life	Michal Feldman;Ran Tessler;Yoav Wilf	2009		10.1007/978-3-642-10841-9_32	mathematical optimization;economics;computer science;public economics;mathematics;microeconomics;mathematical economics;welfare economics;nash equilibrium	ECom	-3.3045267425297413	-0.9114728791185975	82716
17422d8d3a3e3b50ac77ecbd18e3449f695b11bf	bounds for the approximation of dynamic programs	dynamic program;optimal policy;inventory model	We consider a finite stage dynamic programming model. The minimum expected total cost and the optimal policy are often approximated by expressions, which can be easily computed and handled. In Section 3 we give bounds for the approximation error by taking into account the structure of the transition law (and of the polices). The bounds depend on the state for which the approximation error is considered. As a consequence the bounds also apply to dynamic programming models with unbounded costs and we generalise results of Hinderer (1976), where uniform (i.e. state independent) bounds are given for models with bounded costs. As an example we consider a discrete review single product inventory model with set up cost. Conditions given by Veinott (1966, Theorem 1) imply the optimality o f so-called (s, S)-policies. We first deal with the dependence of the minimum expected total cost and of the optimal policy on the set up cost. Then we suggest four approximation methods and apply the results o f Section 3 to give bounds for the approximation error. Finally we report on numerical results.	approximation algorithm;approximation error;dynamic programming;inventory theory;numerical analysis;programming model	Harald Benzing	1986	Zeitschr. für OR	10.1007/BF01918632	mathematical optimization;dynamic lot-size model;mathematical economics;no-arbitrage bounds	ML	3.211616121899759	-1.785774088669026	82751
20269b975a6a1c5d58549708cfbe783f8925183f	extreme-value theorems for optimal multidimensional pricing	optimal solution;probability approximation theory computational complexity pricing;revenue distributions polynomial time approximation scheme extreme value theorems optimal multidimensional pricing monotone hazard rate distributions probabilistic techniques ptas;game theory;probability;approximation algorithms;search space;pricing;vectors approximation methods random variables polynomials approximation algorithms pricing hazards;hazards;random variables;polynomials;linear functionals;statistical properties;approximation theory;multi dimensional;vectors;extreme value;computational complexity;hazard rate;approximation methods;data structure;article;polynomial time approximation scheme;structural properties	We provide a Polynomial Time Approximation Scheme for the multi-dimensional unit-demand pricing problem, when the buyer's values are independent (but not necessarily identically distributed.) For all epsilon>0, we obtain a (1+epsilon)-factor approximation to the optimal revenue in time polynomial, when the values are sampled from Monotone Hazard Rate (MHR) distributions, quasi-polynomial, when sampled from regular distributions, and polynomial in n^{poly(log r)}, when sampled from general distributions supported on a set [u_min, r u_min]. We also provide an additive PTAS for all bounded distributions. Our algorithms are based on novel extreme value theorems for MHR and regular distributions, and apply probabilistic techniques to understand the statistical properties of revenue distributions, as well as to reduce the size of the search space of the algorithm. As a byproduct of our techniques, we establish structural properties of optimal solutions. We show that, for all epsilon >0, g(1/epsilon) distinct prices suffice to obtain a (1+epsilon)-factor approximation to the optimal revenue for MHR distributions, where g(1/epsilon) is a quasi-linear function of 1/epsilon that does not depend on the number of items. Similarly, for all epsilon>0 and n>0, g(1/epsilon \cdot log n) distinct prices suffice for regular distributions, where n is the number of items and g() is a polynomial function. Finally, in the i.i.d. MHR case, we show that, as long as the number of items is a sufficiently large function of 1/epsilon, a single price suffices to achieve a (1+epsilon)-factor approximation. Our results represent significant progress to the single-bidder case of the multidimensional optimal mechanism design problem, following Myerson's celebrated work on optimal mechanism design [Myerson 1981].	algorithm;linear function;maxima and minima;ptas reduction;polynomial;polynomial-time approximation scheme;quasi-polynomial;utility functions on indivisible goods;monotone	Yang Cai;Constantinos Daskalakis	2011	2011 IEEE 52nd Annual Symposium on Foundations of Computer Science	10.1109/FOCS.2011.76	pricing;random variable;game theory;mathematical optimization;combinatorics;discrete mathematics;polynomial-time approximation scheme;data structure;hazard;extreme value theory;probability;mathematics;mathematical economics;hazard ratio;computational complexity theory;approximation algorithm;statistics;polynomial;approximation theory	Theory	-2.3145872311387863	-0.490936928267847	82794
cdeeadcbcdf0f47902ca262477a32b60b3a1e1de	a stochastic dynamic programming approach-based yield management with substitution and uncertainty in semiconductor manufacturing	multi product;periodic depreciation;raw materials;satisfiability;iterative algorithm;journal;inventory;objective function;profitability;numerical experiment;technical progress;make to stock;stochastic dynamic programming;upward substitution;yield managementinventorymulti productupward substitutionperiodic depreciatio;semiconductor manufacturing;yield management	Yield management is important and challengeable in semiconductor industry for the quality uncertainty of the final products. The total yield rate of the semiconductor manufacturing process is uncertain, each product is graded into one of several quality levels according to performance before being shipped. A product originally targeted to satisfy the demand of one product may be used to satisfy the demand of other products when it conforms to their specifications. At the same time, the products depreciate in allocation periods, which mainly results from technical progresses. This paper studies the semiconductor yield management issue of a make-to-stock system with single input, multi-products, multi-demand periods, upward substitution and periodic depreciation. Thewhole time horizon of the system operation process can be divided into two stages: the production stage and the allocation stage. At the first stage, the firm invests in rawmaterials before any actual demand is known and produces multiple types of products with random yield rates. At the second stage, products are classified into different classes by quality and allocated in numbers of periods. The production and allocation problem are modeled as a stochastic dynamic program inwhich the objective is tomaximize the profit of the firm.We show that the PRA (parallel allocation first, then upgrade) allocation policy is the optimal allocation policy and the objective function is concave in production input. An iterative algorithm is designed to find the optimal production input and numerical experiments are used to illustrate its effectiveness. © 2011 Elsevier Ltd. All rights reserved.	algorithm;computation;concave function;dynamic programming;experiment;iterative method;loss function;mathematical model;mathematical optimization;numerical analysis;nv network;optimization problem;performance;physical review a;qualitative comparative analysis;search algorithm;semiconductor device fabrication;semiconductor industry;spatial variability;stochastic programming	Guanghua Han;Ming Dong;Xiaofeng Shao	2011	Computers & Mathematics with Applications	10.1016/j.camwa.2011.01.003	stochastic programming;mathematical optimization;yield management;inventory;build to stock;raw material;mathematics;iterative method;semiconductor device fabrication;profitability index;satisfiability	AI	5.247640260947585	-2.7457523880455006	82907
b9d04049cef5c9777c4d022d6a89c3432dec2ea9	on participation games with complete information	non linear programming;critical point;nash equilibria;turnout;objective function;incomplete information;degeneration;public good provision;regular equilibrium;public goods;public good;monotone equilibrium;morse function	We analyze a class of two-candidate voter participation games under complete information that encompasses as special cases certain public good provision games. We characterize the Nash equilibria of these games as stationary points of a non-linear programming problem, the objective function of which is a Morse function (one that does not admit degenerate critical points) for almost all costs of participation. We use this fact to establish that, outside a closed set of measure zero of participation costs, all equilibria of these games are regular (an alternative to the result of De Sinopoli and Iannantuoni in Econ Theory 25(2):477–486, 2005). One consequence of regularity is that the equilibria of these games are robust to the introduction of (mild) incomplete information. Finally, we establish the existence of monotone Nash equilibria, such that players with higher participation cost abstain with (weakly) higher probability.	linear programming;loss function;nash equilibrium;nonlinear programming;nonlinear system;optimization problem;stationary process;monotone	Tasos Kalandrakis	2007	Int. J. Game Theory	10.1007/s00182-006-0049-y	best response;public good;economics;nonlinear programming;public economics;microeconomics;mathematical economics;welfare economics	ECom	-2.5508801616854333	2.0203123922882837	83052
0f3f26778caa2e960b76e7e5d13cdea76d6a077d	stochastic budget optimization in internet advertising	scenario model;quadratic program;optimization problem;stochastic budget optimization;internet auction;probability distribution;polynomial time;internet advertising	Internet advertising is a sophisticated game in which the many advertisers “play” to optimize their return on investment. There are many “targets” for the advertisements, and each “target” has a collection of games with a potentially different set of players involved. In this paper, we study the problem of how advertisers allocate their budget across these “targets”. In particular, we focus on formulating their best response strategy as an optimization problem. Advertisers have a set of keywords (“targets”) and some stochastic information about the future, namely a probability distribution over scenarios of cost vs click combinations. This summarizes the potential states of the world assuming that the strategies of other players are fixed. Then, the best response can be abstracted as stochastic budget optimization problems to figure out how to spread a given budget across these keywords to maximize the expected number of clicks. We present the first known non-trivial poly-logarithmic approximation for these problems as well as the first known hardness results of getting better than logarithmic approximation ratios in the various parameters involved. We also identify several special cases of these problems of practical interest, such as with fixed number of scenarios or with polynomial-sized parameters related to cost, which are solvable either in polynomial time or with improved approximation ratios. Stochastic budget optimization with scenarios has sophisticated technical structure. Our approximation and hardness results come from relating these problems to a special type of (0/1, bipartite) quadratic programs inherent in them. Our research answers some open problems raised by the authors (in Algorithmica, 58(4):1022–1044, 2010).	algorithmica;approximation algorithm;computational resource;decision problem;hardness of approximation;mathematical optimization;online advertising;optimization problem;polynomial;search engine marketing;time complexity	Bhaskar DasGupta;S. Muthukrishnan	2012	Algorithmica	10.1007/s00453-012-9614-x	probability distribution;time complexity;optimization problem;mathematical optimization;simulation;mathematics;quadratic programming;algorithm	Theory	-1.4851064337867204	-0.5667439591051778	83257
4c463b31926a594a896de2a2ac2dbd61a361a48a	stochastic maximum flow interdiction problems under heterogeneous risk preferences		We consider a generic maximum flow interdiction problem that involves a leader and a follower who take actions in sequence. Given an interdiction budget, the leader destroys a subset of arcs to minimize the follower’s maximum flows from a source to a sink node. The effect from an interdiction action taken on each arc is random, following a given success rate of decreasing the arc’s capacity to zero. The follower can add additional arc capacities for mitigating flow losses, after knowing the leader’s interdiction plan but before realizing the uncertainty. We consider risk-neutral and risk-averse behaviors of the two players and investigate five bi-level/tri-level programming models for different risk-pref erence combinations. The models incorporate the expectation, left-tail, and right-tail Conditional Value-at-Risk (CVaR) as commonly used convex risk measures for evaluating random maximum flows in the leader’s and follower’s objectives. We reformulate each model as an equivalent mixed-integer linear program and test them on real-world network instances to demonstrate interactions between the leader and the follower under various risk-preference settings. © 2017 Elsevier Ltd. All rights reserved.	black and burst;cvar;interaction;linear programming;maximum flow problem;risk aversion;risk measure;triangular function;value at risk	Xiao Lei;Siqian Shen;Yongjia Song	2018	Computers & OR	10.1016/j.cor.2017.09.004	mathematical economics;mathematical optimization;mathematics;maximum flow problem;sink (computing);arc (geometry);stochastic programming;interdiction;cvar;linear programming;programming paradigm	AI	2.8056184365762893	-0.20236314725294918	83362
c849fbd279b96d1c516b9ab37af1a6f8222f014c	reliability-based network flow estimation with day-to-day variation: a model validation on real large-scale urban networks		ABSTRACTDay-to-day variation in the travel times of congested urban transportation networks is a frustrating phenomenon to the users of these networks. These users look pessimistically at the path travel times, and learn to spend additional time to safeguard against serious penalties that await late arrivals at the destinations. These additional expenses are charges similar to the tolls in system equilibrium flow problem, but may not be collected. With this conjecture, the user equilibrium (UE) formulation of congested network flow problem would lack some necessary factors in addressing appropriate path choices. This study, following a previous work proposing pessimistic UE (PUE) flow, aims to show how to measure this additional travel cost for a link, and investigates how different is PUE from UE, and when such differences are pronounced. Data are collected from the peak-hour travel times for the links of paths in the city of Tehran, to estimate the variance of travel times for typical links. Determinist...	flow network	Mohammad Torkjazi;Parisa Sadat Mirjafari;Hossain Poorzahedy	2018	J. Intellig. Transport. Systems	10.1080/15472450.2017.1413555	engineering;flow network;simulation;safeguard;real-time computing;travel time reliability;phenomenon	Vision	9.66469800218325	-9.017804034973498	83368
5a6b7a4e68770f9b786788b00a9e22a3f22ba1c5	a fuzzy decision maker for portfolio problems	optimisation;cost function;pricing;stock markets decision making fuzzy set theory investment optimisation pricing share prices;utility function;black scholes model;portfolios;decision maker;investment;fuzzy set theory;stock markets;optimization problem;stock price;portfolio dynamics markowitz portfolio theory black scholes model implied volatility;portfolio theory;expected returns;implied volatility;stock prices fuzzy decision maker portfolio problems decision making problem optimization problem portfolio adjustments portfolio composition black scholes pricing formula option market spot market;profitability;share prices;markowitz portfolio theory;asset allocation;portfolio dynamics	In this paper, we investigate the decision making problem which maximizes a cost function for a system with unknown dynamics. Only implicit message coming from future trend of the system can be obtained. After set up the framework of such an optimization problem, we focus on how to determine an optimal sequence of portfolio adjustments, and the purpose is to maximize a utility function at the end of some periods. At the portfolio application, it is crucial to identify the future evolution of the portfolio composition. To this end, the well-known Black-Scholes pricing formula for option market is used to modify the parametric dynamic series. This is because the option market and the spot market are closely related and are affected by each other. Many implicit messages of stocks can be obtained through examining their options. From the implied volatility and the open interest, the investors' viewpoints on the stock prices in the future can be extracted. Then, it can improve the conventional Markowitz portfolio to establish a one-period and a multi-period fuzzy decision maker. These efficient decision makers lie on the more reliable dynamic series of the portfolio composition, and can avoid overestimating and/or underestimating expected return and expected risk. Numerical case study on many scenarios also shows the proposed decision-making scheme exhibits the highest profit for asset allocation among several portfolio models.	black–scholes model;futures studies;loss function;mathematical optimization;optimization problem;utility;volatility;whole earth 'lectronic link	Kuang-Yow Lian;Chien-Chi Li	2010	2010 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2010.5642345	post-modern portfolio theory;efficient frontier;merton's portfolio problem;replicating portfolio;capital market line;modern portfolio theory;portfolio optimization;separation property;application portfolio management;black–litterman model	Robotics	2.0931797561985426	-6.682810824830769	83515
22ef575b0f24b8d25bfc384ef50e7ba5dfdafb5a	the complexity of optimal mechanism design	electrical engineering and computer science;thesis;article	Myerson’s seminal work provides a computationally efficient revenue-optimal auction for selling one item to multiple bidders [17]. Generalizing this work to selling multiple items at once has been a central question in economics and algorithmic game theory, but its complexity has remained poorly understood. We answer this question by showing that a revenue-optimal auction in multi-item settings cannot be found and implemented computationally efficiently, unless ZPP ⊇ P. This is true even for a single additive bidder whose values for the items are independently distributed on two rational numbers with rational probabilities. Our result is very general: we show that it is hard to compute any encoding of an optimal auction of any format (direct or indirect, truthful or non-truthful) that can be implemented in expected polynomial time. In particular, under well-believed complexity-theoretic assumptions, revenue-optimization in very simple multi-item settings can only be tractably approximated. We note that our hardness result applies to randomized mechanisms in a very simple setting, and is not an artifact of introducing combinatorial structure to the problem by allowing correlation among item values, introducing combinatorial valuations, or requiring the mechanism to be deterministic (whose structure is readily combinatorial). Our proof is enabled by a flowinterpretation of the solutions of an exponential-size linear program for revenue maximization with an additional supermodularity constraint. Supported by a Sloan Foundation Fellowship, a Microsoft Research Faculty Fellowship, and NSF Award CCF0953960 (CAREER) and CCF-1101491. Supported by Fannie and John Hertz Foundation Daniel Stroock Fellowship and NSF Award CCF-1101491. Supported by NSF Award CCF1101491.	algorithmic efficiency;algorithmic game theory;approximation algorithm;computation;computational model;encode;expectation–maximization algorithm;linear programming;mathematical optimization;p (complexity);polynomial;polynomial-time approximation scheme;randomized algorithm;supermodular function;time complexity;utility functions on indivisible goods;zpp (complexity)	Constantinos Daskalakis;Alan Deckelbaum;Christos Tzamos	2014		10.1137/1.9781611973402.96	mathematical optimization;economics;computer science;mathematics;microeconomics;mathematical economics;welfare economics;algorithm;statistics	Theory	-2.4300969322094965	-1.1030543868174827	83738
724556f4a407432c07b4982dedef7b215a669503	study on scope of customization customers' perspective based	analytical models;game theory;flexible manufacturing systems;customer services;mass customization;product customisation;pricing;data processing technology;data processing;mass production;heterogeneous preferences;data mining;companies;costs conference management technology management engineering management companies manufacturing systems mass customization investments production data engineering;investment;flexible manufacturing system;product pricing;games;customer perspectives;hoetlling model;production;product pricing flexible manufacturing system mass customization customer perspectives investment information collection technology data processing technology;customization cost;manufactured products;information collection technology;product customisation customer services flexible manufacturing systems investment manufactured products mass production pricing;manufacturing system;hoetlling model customization cost scope of customization customization strategy;customization strategy;scope of customization	The flexibility of manufacturing system in mass customization (MC) requires high initial investments, as well as the technologies of information collection and data processing does. To some extent, the bigger scope of customization induces the higher customization cost. We build a game theory model to test the below variables: customers’ heterogeneous preference, scope of customization, customization cost and custom product price. We highlight the relationships that customization cost is determined by the scope of customization. Then we find customization strategy in a firm will generate some interesting changes. Lastly some novel viewpoints about customization strategy are also provided.	game theory	Yin Zhang;Rongqiu Chen;Li Li	2009	2009 IITA International Conference on Services Science, Management and Engineering	10.1109/SSME.2009.82	pricing;games;game theory;mass production;economics;data processing;investment;mass customization;computer science;marketing;operations management;commerce	Robotics	0.538155359500143	-6.61995680115311	83743
39bb310c7f3712c60bc1fdaad9ae470bb3ceb5e0	a nonlinear dynamic model of female labor supply: iran case study	analytical models;unemployment economics mathematical analysis salaries;economic problems;real wages;labor resources;dynamic model;biological system modeling;education level nonlinear dynamic model female labor supply economic problems average unemployment rates mathematical model;unemployment;unemployment rate;mathematical analysis;force;labor market;female labor supply;labor supply;nonlinear dynamics;mathematical model;developing country;average unemployment rates;reservation wages;education level;economics;salaries;labor resources biological system modeling mathematical model force economics unemployment analytical models;age groups;economic growth;nonlinear dynamic model	In developing countries, one of the most essential economic problems is the high unemployment rate along with the low economic growth. In these cases, female unemployment rate is higher than average unemployment rates. In order to analyze the situation and then take it under control, a mathematical model for both sides of female labor market is required. In this paper, an analytical dynamical model is developed for the Iranian female labor supply. The lifecycle theory is used to divide it into three age groups. Then the static theory is used as a basis to construct each model analytically. It has been presented that some criteria such as the education level, marriage and history of unemployment rate can strongly affect the labor supply as well as the rate of real wage and real non-labor income has both the substitution and income effects. Moreover, a reservation wage is estimated for each model.	iranian.com;mathematical model;nonlinear programming;resource reservation protocol	S. A. Aghaei;G. Shakouri H.Shakouri	2008	2008 Second UKSIM European Symposium on Computer Modeling and Simulation	10.1109/EMS.2008.88	economics;market economy;efficiency wage;labour economics	ECom	1.3361310411646063	-8.642838996554744	83863
5f99b27d016255dc26767e887e3337353377ca49	discrete time hedging errors for options with irregular payoffs	rate of convergence;discrete time;interest rate;approximation of stochastic integral;stochastic integral;diffusion process;discrete time hedging;complete market	In a complete market with a constant interest rate and a risky asset, which is a linear diffusion process, we are interested in the discrete time hedging of a European vanilla option with payoff function f. As regards the perfect continuous hedging, this discrete time strategy induces, for the trader, a risk which we analyze w.r.t. n, the number of discrete times of rebalancing. We prove that the rate of convergence of this risk (when $n \rightarrow + \infty$) strongly depends on the regularity properties of f: the results cover the cases of standard options.		Emmanuel Gobet;Emmanuel Temam	2001	Finance and Stochastics	10.1007/PL00013539	financial economics;mathematical optimization;discrete time and continuous time;economics;diffusion process;interest rate;discrete-time stochastic process;mathematics;mathematical economics;rate of convergence;complete market;statistics	HCI	1.6271669173249421	-2.444805306490879	83956
3c86c58bf7e7cf9cc3aa108142f3bcc09e329df8	noncooperative and cooperative optimization of distributed energy generation and storage in the demand-side of the smart grid	variational inequality demand side management distributed pricing algorithm game theory proximal decomposition algorithm smart grid;game theory;proximal decomposition algorithm;demand side management;pricing;smart grids optimization energy consumption energy storage games production pricing;smart grid;smart grids;energy consumption;games;energy storage;distributed pricing algorithm;variational inequality;production;optimization;article	The electric energy distribution infrastructure is undergoing a startling technological evolution with the development of the smart grid concept, which allows more interaction between the supply- and the demand-side of the network and results in a great optimization potential. In this paper, we focus on a smart grid in which the demand-side comprises traditional users as well as users owning some kind of distributed energy source and/or energy storage device. By means of a day-ahead demand-side management mechanism regulated through an independent central unit, the latter users are interested in reducing their monetary expense by producing or storing energy rather than just purchasing their energy needs from the grid. Using a general energy pricing model, we tackle the grid optimization design from two different perspectives: a user-oriented optimization and an holistic-based design. In the former case, we optimize each user individually by formulating the grid optimization problem as a noncooperative game, whose solution analysis is addressed building on the theory of variational inequalities. In the latter case, we focus instead on the joint optimization of the whole system, allowing some cooperation among the users. For both formulations, we devise distributed and iterative algorithms providing the optimal production/storage strategies of the users, along with their convergence properties. Among all, the proposed algorithms preserve the users' privacy and require very limited signaling with the central unit.	algorithm;calculus of variations;holism;iteration;mathematical optimization;optimization problem;portable storage device;program optimization;purchasing;variational inequality	Italo Atzeni;Luis Garcia Ordóñez;Gesualdo Scutari;Daniel Pérez Palomar;Javier Rodríguez Fonollosa	2013	IEEE Transactions on Signal Processing	10.1109/TSP.2013.2248002	game theory;mathematical optimization;simulation;computer science;electrical engineering;mathematics;smart grid	HPC	2.508278238839525	3.53086753035658	83979
fca50224561932709b3890e6927cf4e65bedfb2c	the role of quantity discounts in the presence of heterogeneous buyers	distribution;inventory;synchronization;model development;profitability;supply chain management	In this paper we develop a model to examine the role of quantity discounts in synchronizing production and order cycles for a system consisting of one manufacturer and two heterogeneous buyers. The model developed can serve as a guideline for the manufacturer and the buyers as how to integrate their decisions to achieve higher benefits. The numerical examples indicate that the benefit of synchronization decreases with the degree of heterogeneity of the buyers. The conditions under which it is profitable for the manufacturer to synchronize with the heterogeneous buyers are demonstrated through numerical examples. Copyright Kluwer Academic Publishers 2001		Z. Kevin Weng;Amy Z. Zeng	2001	Annals OR	10.1023/A:1014979822085	distribution;synchronization;supply chain management;inventory;economics;marketing;operations management;mathematics;commerce;profitability index	EDA	-0.276969479556672	-5.791845529329095	84058
0970f1a6d74b2be6a46c213e8b5c398a08bd14a8	the effectiveness of manufacturer vs. retailer rebates within a newsvendor framework	cross functional interfaces;conceptual modeling;marketing;operations;supply chain management	0377-2217/$ see front matter 2011 Elsevier B.V. A doi:10.1016/j.ejor.2011.06.044 ⇑ Corresponding author. Tel.: +1 506 458 7333; fax E-mail addresses: arcelusf@yahoo.com (F.J. Arcelus) 1 Tel.: +1 506 458 7316; fax: +1 506 453 3561. This paper studies the impact of direct rebates to the end customer from the manufacturer and/or from the retailer upon the profitability and effectiveness of the policies of both channels. Effectiveness is measured by the ratio of the retailer’s to the manufacturer’s profits and by the sum of the profits for the two parties across scenarios wherein at least one of the parties offers a rebate. The main result is to prove analytically the conditions under which either all three scenarios are equally profitable or the retailer-only rebate policy is dominant. Another important result is to illustrate the likelihood that the manufacturer is able to coordinate the supply chain, by the appropriate choice of its pricing and rebate policies, thereby inducing the retailer to do likewise with its associated best pricing, ordering and rebate policies. Finally, numerical examples highlight the main features of the paper. 2011 Elsevier B.V. All rights reserved.	fax;like button;newsvendor model;numerical analysis	Francisco J. Arcelus;Satyendra Kumar;Gopalan Srinivasan	2012	European Journal of Operational Research	10.1016/j.ejor.2011.06.044	supply chain management;economics;conceptual model;marketing;operations management;commerce	AI	-0.5774228393584886	-5.836411552746166	84211
4ee734351a539626db10da020160a1c27dc3fca3	dual-channel supply chain competition with channel preference and sales effort under uncertain environment		Nowadays, a host of suppliers, such as IBM, Apple and Nike, sell products directly online while simultaneously sell via traditional distribution channels. The existence of two channels makes consumers choose purchase channel according to their own preferences and demands, increases suppliers’ potential market demands and improves supply chain efficiency. Furthermore, suppliers can make higher profits by controlling distribution and pricing directly. Spontaneously, studies on dual-channel supply chain have become increasingly prevailing in supply chain management. Customers choose to buy products from a retailer or a direct channel based on price and service quality when suppliers hold two channels (Joseph et al. 1997; Girard et al. 2003). It is well known that customers tend to buy products with high quality and low price. Notably, market demands in the direct channel and retail channel depend on the customers’ choices. Consequently, the managers must pour attention to customers’ channel preference when making decisions. In this paper, channel preference is taken into account to investigate its effect on dual-channel supply chain with multiple retailers. Besides, supply chain members’ sales efforts are crucial for winning market share. For instance, participators can stimulate demand by advertising products’ features, providing attractive shelf space, and adding point-of-sale demonstrations by salespeople. Generally speaking, supply chain members’ own sales efforts have positive influence on their own profits. Therefore, the impact of sales effort on dual-channel supply chain cannot be ignored. Previous studies have examined the influence of sales effort on supply chain (Lau et al. 2012; Hu and Wang 2010; Chernonog et al. 2015). However, only limited literature focuses on sales effort in dual-channel supply Abstract In this paper, we investigate a dual-channel supply chain under uncertain environment. Channel preference and sales effort are taken into account to explore their effects on supply chain members’ profits with uncertain information. Then we analyze the dual-channel supply chain in centralized and decentralized cases, and give closed-form expressions for equilibriums in the two cases. A series of numerical experiments are implemented to examine the impacts of uncertainty distributions of parameters on supply chain profits. We conclude that the total profit of the supply chain in the centralized case is invariably higher than that in the decentralized case under different uncertainty degrees of these parameters. It is shown that the supplier’s profit first decreases then increases as the expected value of customers’ preference to the direct channel increases, and the retailer’s profit decreases with the increase of the expected value of customers’ preference to the direct channel. In addition, the results indicate that the total profits in the centralized and decentralized cases, the supplier’s profit and the retailer’s profit all increase when the expected value of the retailer’s sales effort elasticity increases.	centralized computing;display resolution;elasticity (data store);experiment;holographic principle;multi-channel memory architecture;numerical analysis;point of sale;supply chain attack;word lists by frequency	Hua Ke;Jinjin Liu	2017	J. Ambient Intelligence and Humanized Computing	10.1007/s12652-017-0502-8	simulation;computer science;uncertainty theory;profit (economics);elasticity (economics);service management;supply chain;demand chain;expected value;microeconomics;communication channel	AI	-1.3190132458914408	-5.631908388014122	84510
1b5dedc4cb589bb95b1cd0b808a0f10674369efe	the value of knowing your enemy		Many auction settings implicitly or explicitly require that bidders are treated equally exante. This may be because discrimination is philosophically or legally impermissible, or because it is practically difficult to implement or impossible to enforce. We study so-called anonymous auctions to understand the revenue tradeoffs and to develop simple anonymous auctions that are approximately optimal. We consider digital goods settings and show that the optimal anonymous, dominant strategy incentive compatible auction has an intuitive structure — imagine that bidders are randomly permuted before the auction, then infer a posterior belief about bidder i’s valuation from the values of other bidders and set a posted price that maximizes revenue given this posterior. We prove that no anonymous mechanism can guarantee an approximation better than Θ(n) to the optimal revenue in the worst case (or Θ(logn) for regular distributions) and that even posted price mechanisms match those guarantees. Understanding that the real power of anonymous mechanisms comes when the auctioneer can infer the bidder identities accurately, we show a tight Θ(k) approximation guarantee when each bidder can be confused with at most k “higher types”. Moreover, we introduce a simple mechanism based on n target prices that is asymptotically optimal and build on this mechanism to extend our results to m-unit auctions and sponsored search. Massachusetts Institute of Technology, Cambridge, Massachusetts, USA; tzamos@mit.edu. Supported by NSF Award CCF-1101491. Parts of this work were done while the author was an intern at Yahoo Labs. Yahoo Labs, Sunnyvale, California, USA; cwilkens@yahoo-inc.com.	approximation;asymptotically optimal algorithm;auction algorithm;best, worst and average case;computational complexity theory;differential entropy;ibm notes;kleene's recursion theorem;mathematical optimization;random permutation;randomness;rename (relational algebra);search engine marketing;value (ethics);monotone	Christos Tzamos;Christopher A. Wilkens	2014	CoRR		economics;common value auction;english auction;microeconomics;mathematical economics;welfare economics;commerce	ECom	-2.467017174572747	-1.7041270424790929	84590
29ef6fbc1bbbe7b3c9af9ec4f403221decca9274	on the one-dimensional optimal switching problem	optimal stopping problems;dynamic programming principle;optimal stopping problem;holder continuity;optimal switching problems;ito diffusions;viscosity solution;stochastic optimization;natural resource;real option;geometric brownian motion;variational inequality;value function	We characterize the optimal switching problem as coupled op timal stoping problems. We then use the optimal stopping theory to provide a solution. As oppose d to the methods using quasi-variational inequalities and verification theorem we directly work with the value function.	bellman equation;optimal stopping;variational inequality;variational principle	Erhan Bayraktar;Masahiko Egami	2010	Math. Oper. Res.	10.1287/moor.1090.0432	mathematical optimization;mathematical analysis;variational inequality;optimal stopping;optimal substructure;stochastic optimization;viscosity solution;natural resource;mathematics;bellman equation;mathematical economics;geometric brownian motion;hölder condition	Theory	1.4765722063781803	-1.8896295924431117	84659
fe8345ba62bd29b6017035c92314e5d63f9e7af7	budgeted competitive influence maximization on online social networks		Influence Maximization ((mathsf {IM})) is one of the key problems in viral marketing which has been paid much attention recently. Basically, (mathsf {IM}) focuses on finding a set of k seed users on a social network to maximize the expected number of influenced nodes. However, most of related works consider only one player without competitors. In this paper, we investigate the Budgeted Competitive Influence Maximization (({mathsf {BCIM}})) problem within limited budget and time constraints which seeks a seed set nodes of a player or a company to propagate their products’s information while at the same time their competitors are conducting a similar strategy. We first analyze the complexity of this problem and show that the objective function is neither submodular nor suppermodular. We then apply Sandwich framework to design ({mathsf {SPBA}}), a randomized algorithm that guarantees a data dependent approximation factor.		Canh V. Pham;Hieu V. Duong;Bao Q. Bui;My T. Thai	2018		10.1007/978-3-030-04648-4_2	competitor analysis;submodular set function;expected value;viral marketing;approximation algorithm;randomized algorithm;social network;mathematical optimization;computer science;maximization	ML	-1.1496543425047534	-0.31471747085837143	84663
58032f346cb5784958e538616545f7c156bf61b4	an order control policy in crowdsourced parcel pickup and delivery service		Crowdsourced parcel delivery service has progressed dramatically by actively incorporating innovative technologies and ideas. Yet, maximizing profitability of this new type of delivery service becomes another challenge for service providers as market grows. In this paper we study a service order control policy to maximize profitability from a service provider perspective. Specifically, we suggest an order admission control approach that determines acceptance or rejection of an incoming order according to its profitability characteristics. For this, we model the problem as an average reward Semi-Markov Decision Process and utilize reinforcement learning to obtain an optimal order control policy that maximizes overall profitability of a service provider. Through numerical illustrations, we show that our suggested approach outperforms traditional methods, especially when the order arrival rate is high. Thus, smart order management is an important component of parcel pickup and delivery services.	crowdsourcing	Yuncheol Kang	2018		10.1007/978-3-319-99707-0_21	service provider;operations research;admission control;profitability index;reinforcement learning;order control;pickup;computer science	Robotics	2.083550720787541	-6.885013610592779	84773
61a08c85d48c66bbbc1ff341992545f8f513c742	bundling decisions in supply chains	manufacturer retailer relationship;bundling;supply chain contract;price discrimination;supply chain management	Firms often sell products in bundles to extract consumer surplus. While most bundling decisions studied in the literature are geared to integrated firms, we examine a decentralized supply chain where the suppliers retain decision rights. Using a generic distribution of customers’ reservation price we establish equilibrium solutions for three different bundling scenarios in a supply chain, and generate interesting insights for distributions with specific forms. We find that (i) in supply chain bundling the retailer’s margin equals the margin of each independent supplier, and it equals the combined margin when the suppliers are in a coalition, (ii) when the suppliers form a coalition to bundle their products the bundling gain in the supply chain is higher and retail price is lower than when the retailer bundles the products, (iii) the supply chain has more to gain from bundling relative to an integrated firm, (iv) the first-best supply chain bundling remains viable over a larger set of parameter values than those in the case of the integrated firm, (v) supplier led bundling is preferable to separate sales over a wider range of parameter values than if the retailer led the bundling, and (vi) if the reservation prices are uniformly distributed bundling can be profitable when the variable costs are low and valuations of the products are not significantly different from one another. For normally distributed reservation prices, we show that the bundling set is larger and the bundling gain is higher than that for a uniform distribution.		A. Chakravarty;Andreas Mild;Alfred Taudes	2013	European Journal of Operational Research	10.1016/j.ejor.2013.06.026	supply chain management;economics;marketing;microeconomics;price discrimination;commerce	ECom	-1.0468799707795857	-6.289642081318125	84785
ed93049fe4ffd25fa03b6ea0d29086dcbf528e1c	assessing climate change and asset deterioration impacts on water distribution networks: demand-driven or pressure-driven network modeling?	joomla;peaking factor;background leakages;climate change;asset deterioration;hydraulic system capacity;water distribution networks	This manuscript compares demand-driven and pressure-driven hydraulic network simulation models for assessing hydraulic capacity under uncertain scenarios. A stochastic approach is implemented assuming possible alteration of boundary conditions due to climate and socio-economic changes (i.e., the increase of peaks of customers demands), and system deterioration (i.e., the increase of pipe internal hydraulic resistances and background leakages). Two real water distribution networks located in Southern Italy are used for analyses. Results show that demand-driven analysis underestimates the hydraulic network capacity with respect to pressure-driven analysis. In fact, pressure-driven analysis assumes the components of model demands (human-based and leakage-based) as dependent on pressure status of the system, and thus returns a more reasonable number and location of critical nodes than demand-driven analysis. Furthermore, demand-driven analysis does not predict the water demand that can be realistically supplied to customers under pressure-deficient system functioning. Therefore, the use of pressure-driven analysis is advisable to support water managers to allocate budgets for planning rehabilitation works aimed at increasing the hydraulic capacity of the networks.		Daniele Laucelli;Luigi Berardi;Orazio Giustolisi	2012	Environmental Modelling and Software	10.1016/j.envsoft.2012.04.004	environmental engineering;geology;hydrology;engineering;operations management;climate change;ecology	Metrics	8.183894291601906	-6.0696535992711595	84950
ea1758012bc777dc4edd351cdfddad164c93f215	safety first portfolio choice based on financial and sustainability returns	sustainability value;finance;safety first investor;socially responsible investing;portfolio selection;330 wirtschaft;ddc 330;timing analysis;portfolio choice;convex combination	This paper lays the mathematical foundations of the notion of an investment’s sustainability return and investigates three different models of portfolio selection with probabilistic constraints for safety first investors caring about the financial and the sustainability consequences of their investments. The discussion of these chance-constrained programming problems for stochastic and deterministic sustainability returns includes theoretical results especially on the existence of a unique solution under certain conditions, an illustrating example, and a computational time analysis. Furthermore, we conclude that a simple convex combination of financial and sustainability returns – yielding a new univariate decision variable – is not sufficiently general.	computable function;computational resource;convolution;information and computation;marginal model;optimization problem;quantum correlation;time complexity	Gregor Dorfleitner;Sebastian Utz	2012	European Journal of Operational Research	10.1016/j.ejor.2012.02.034	financial economics;post-modern portfolio theory;actuarial science;convex combination;economics;replicating portfolio;marketing;finance;portfolio optimization;mathematics;separation property;application portfolio management;static timing analysis	ML	1.3380717547525796	-2.361397939175589	85005
bd60bbd6d49c919661df406be89955d9d0312f73	randomized strategy equilibrium in the action commitment game with costs of leading	strategic complements;modelizacion;discontinuity;discontinuite;cost of leading;endogenous timing;game theory;strategie mixte;competitividad;teoria juego;theorie jeu;jeu 2 personnes;modelisation;price competition;aleatorizacion;endogenous;juego 2 personas;estrategia mixta;two person game;coste;competitiveness;randomisation;endogeno;discontinuidad;randomization;competitivite;modeling;endogene;mixed strategy;cout;mixed strategy equilibria;timing	We investigate a two-player action commitment game where one simultaneous-move and two sequential-move pure strategy equilibria exist when the cost of leading is zero, while the simultaneous-move outcome is not an equilibrium when the leading cost is small positive. We show that this discontinuity disappears if we consider randomized strategy equilibria. We investigate a price competition model and show that randomized strategy equilibria exist and any of them converges to the Bertrand equilibrium when the leading cost converges to zero.	randomized algorithm	Toshihiro Matsumura;Takeshi Murooka;Akira Ogawa	2011	Oper. Res. Lett.	10.1016/j.orl.2011.02.004	strategic complements;randomization;game theory;endogeny;simulation;systems modeling;input/output;discontinuity;strategy;correlated equilibrium;mathematical economics;equilibrium selection	AI	-3.369711471572341	-4.833194893053227	85382
0d8c853b4eb9ccbd2294d20ed7a426d82995c143	optimal pricing with positive network effects: the big benefits of just a little discrimination	network effect;network externalities;05 economics and value of is;social networks;03 digital and social networks;economics of information systems;price analysis	We study the revenue-optimal pricing strategies of a monopolist selling a divisible good (service) that exhibits positive externalities to consumers embedded in a social network. The positive externalities in our model mean that a consumer's usage level depends directly on the usage of his neighbors in the network. Optimal pricing may therefore involve offering different prices based on consumers' position. We first consider a setting where the monopolist can offer individualized prices and derive an explicit characterization of the optimal price for each consumer as a function of his network position. We show that such a policy amounts to the solution to a quadratic program and that it is optimal for the seller to charge consumers a price that is proportional to a measure of social network importance called Bonacich centrality. We next study a constrained policy whereby the seller can choose no more than k distinct prices. While the problem is tractable for uniform pricing, i.e. k=1, we show that the problem is generally NP-complete and that there is no polynomial-time approximation scheme of the optimal solution. Next, we consider a relaxation of the k-price problem that is polynomial-time solvable and provide lower bounds on the revenue to the fully discriminatory policy. We show that the latter revenue gap is naturally decreasing in k and is proportional to the Bonacich centrality and to the variance of the network’s degree distribution. The results suggest that knowledge of the externalities is more important to optimal pricing as a network's density and the variance of its degree distribution increases. Put another way, a seller's capability to discriminate between consumers is more important for settings in which consumers' relative influence on each other (or, equally, consumers' susceptibility to influence) from externalities varies greatly. Significantly, we also show that allowing for even a modest number of prices provides a good approximation to the fully discriminatory policy. Finally, we consider seeding strategies as a special case of k-pricing where the good is given to a subset of consumers for free. Seeding always represents a large improvement over uniform pricing, is a good approximation of the unconstrained k-price policy, and the benefits of seeding are greatest for high-variance networks. While the number of seeds varies substantively depending on whether influence is unilateral or bilateral, the revenue extracted remains largely unaffected by the degree of reciprocity of influence.	bilateral filter;centrality;cobham's thesis;decision problem;degree distribution;embedded system;linear programming relaxation;monopoly;np-completeness;polynomial;polynomial-time approximation scheme;quadratic programming;social network;time complexity	Jacomo Corbo;Di Lin	2012			economics;marketing;network effect;microeconomics;welfare economics;commerce;social network	ECom	-2.574836347983235	-3.1854322996648365	85401
2d4b73d81a5af23e92aef608f6669bdc0f7fefbb	the use of data envelopment analysis in the regulation of uk water utilities: water distribution	performance measure;public interest;data envelopment analysis;england and wales;linear program;regulation;water distribution;performance measurement;data envelope analysis;production efficiency	Regulation is increasingly playing a major role in defence of the public interest in the UK and other economies, in the aftermath of the privatisation of utilities operating in near monopoly environments. This paper gives an account of the use of data envelopment analysis (DEA) by the regulator of water companies in England and Wales in 1994 in the context of setting price limits. DEA is a general purpose linear programming-based method for assessing the productive efficiencies of operating units such as bank branches or schools. The paper details the use of DEA to estimate potential savings in the specific context of water distribution and discusses the use of the results obtained. It also highlights certain generic issues arising in the use of DEA and more generally performance measurement methods in the regulatory context.	data envelopment analysis	Emmanuel Thanassoulis	2000	European Journal of Operational Research	10.1016/S0377-2217(99)00303-3	economics;computer science;linear programming;operations management;data envelopment analysis;mathematics;economy;operations research	ECom	4.92916568787825	-7.466365068832185	85516
dc61431c17f6316f3fa5162416d6abb81722aaad	performance evaluation of multi-object auctions	performance measure;performance evaluation;bidding strategies;multi object auction;auction efficiency and revenue;sequential auction;simultaneous auction	The paper evaluates the performance of two multi-object auction models: sequential and simultaneous, using different performance measures. The objects put up for auction have different synergies for different bidders. We define different types of bidders who can exist in these multi-object auction models. The classification of bidders is based on the bidding strategies they use. We then study the effects of different parameters in auction and bidding strategies, on the performance of these auction models by simulating them using a JAVA based framework.		Debasis Mishra;Sunil S. Reddy;Dharmaraj Veeramani	2005	Electronic Commerce Research	10.1007/s10660-005-6160-5	financial economics;auction algorithm;eauction;vickrey auction;combinatorial auction;generalized second-price auction;unique bid auction;reverse auction;vickrey–clarke–groves auction;proxy bid;revenue equivalence;multiunit auction;microeconomics;bid shading;auction theory;commerce;forward auction	AI	-0.5263660354406529	-5.352985969834249	85556
c4df41a423175f8f02da0f8e31d74a1327cfdfd2	on the role of heterogeneous and imperfect information in a laboratory financial market	information support;information structure;asset market;imperfect information;asymmetric information;heterogeneous information;information market;financial market;cumulant	In this paper, we analyze the behavior of a group of heterogeneously informed investors in an laboratory asset market. Our experimental setting is inspired by Huber et al. (On the benefit of information in markets with heterogeneously informed traders: an experimental study, 2004). However, instead of their system of cumulative and exogenously given information structure, we introduce an information market where the traders can buy an imperfect prediction of the future value of the dividend with a maximum anticipation of four periods. The accuracy of the prediction decreases with the chosen time horizon, whereas its price remains constant. Our results confirm a non-strictly monotonic increasing value of the information. Copyright Springer-Verlag 2006		Simone Alfarano;Iván Barreda-Tarrazona;Eva Camacho-Cuena	2006	CEJOR	10.1007/s10100-006-0014-7	financial economics;information asymmetry;actuarial science;economics;perfect information;finance;financial market;statistics;commerce;cumulant	Theory	-3.7679596972046476	-6.37183304916934	85571
69a49048f5ae24f3ef62ce052643f656cc01e520	too risky to hold? the effect of downside risk, accumulated equity wealth, and firm performance on ceo equity reduction	prospect theory;ceo;behavioral theory of the firm;downside risk;equity ownership;agency theory;firm performance	Although the alignment effect of equity ownership is often studied with emphasis on changes in firm strategy, the exposure of CEOs' firm-specific wealth to firm risk is more easily controlled by changing their level of equity holdings than by changing firm strategic risk. We rely on prospect theory and the behavioral theory of the firm to examine the antecedents of CEO equity reduction and investigate whether it serves to decouple CEO wealth from firm risk. Given its central role in loss avoidance, we underline the effect of the firm's downside risk and distinguish the total loss potential on equity holdings from the loss potential due to firm-specific factors. Allowing for own-performance referents, we also consider firm performance and the value of a CEO's equity holdings in the analysis. Based on a sample of 208 U.S. CEOs for the years 1997--1999, we find empirical support for the role of downside risk and firm performance in CEO equity reductions. Implications on incentive alignment through equity ownership are presented.	downside risk	Elie Matta;Jean McGuire	2008	Organization Science	10.1287/orsc.1070.0334	financial economics;prospect theory;principal–agent problem;equity risk;economics;private equity fund;firm offer;private equity firm;finance;return on equity;equity capital markets;equity theory;equity ratio	NLP	-1.8972604937549966	-7.9451117008282655	85595
e8c8add6f54c6814fdbad474ff63d0966caeb665	when less is more: rationing and rent dissipation in stochastic contests	laboratory experiments;stochastic contests;settore secs p 01 economia politica;laboratory experiment;rent seeking	This paper shows how to maximize revenue when a contest is noisy. We consider a case where two or more contestants bid for a prize in a stochastic contest with proportional probabilities, where all bidders value the prize equally. We show that by fixing the number of tickets, thus setting a limit to total expenditures, it is possible to maximize the auctioneer’s revenue and obtain (almost) full rent dissipation. We test this hypothesis with a laboratory experiment. The results indicate that, as predicted, revenue is significantly higher in a lottery with rationing than in a standard lottery. On the other hand, an alternative rationing mechanism that does not limit total expenditures fails to increase revenue relative to a standard lottery.	cpu power dissipation	Marco Faravelli;Luca Stanca	2012	Games and Economic Behavior	10.1016/j.geb.2011.05.008	rent-seeking;economics;public economics;microeconomics;mathematical economics	AI	-1.1381380593691772	-6.769272144512564	85799
b9c7a31109f217d462e08dedc2437f50fab18efe	agent based modelling and simulation of an auction market for airport slots allocation		Airport slot allocation is a combinatorial allocation problem involving different complex and autonomous systems. Nowadays, airport slots are allocated in a two-stage process: primary allocation is performed according to a set of administrative rules and for each airport independently, while secondary allocation is based on trading mechanisms. Several studies have raised inefficiencies in these processes. To enhance the airport slot allocation process we use an auction-based market. More specifically, we present an airport slot allocation mechanism based on a price-setting auction that has been implemented and evaluated by means of Agent-Based Modelling (ABM) and simulation techniques. The solutions obtained using our approach are compared and assessed with the ones obtained using linear programing, showing that market mechanisms can be an efficient alternative to the current administrative procedure.	simulation	José Alberto Araúzo Araúzo;Félix Antonio Villafáñez;David Poza García;Javier Pajares;Juan Pavón	2018		10.1007/978-3-319-94779-2_39	linear programming;autonomous system (internet);combinatorial auction;distributed computing;computer science	AI	0.12428854419328135	1.8985293281399505	85877
732ed1b749d9b216d026ceed46b05479c8c524bb	challenges in modeling demand for inventory optimization of slow-moving items	digital simulation;stock control data processing;expertfit;data-fitting;demand distributions;discrete distributions;inventory optimization;probability modeling;slow-moving item demand	This paper presents the concept of inventory optimiza and the role of demand distributions. Slow-moving it demand receives special emphasis. Simulations of se popular discrete distributions illustrate the difficulties probability modeling with the quantity and quality demand history typically available. Results of experime with a state-of-the-art probability modeling to (ExpertFitTM) highlight the practical difficulties of dat fitting. Finally, inventory optimization over a simulate data set with the “wrong” assumed demand distribu suggests a business case for accurately identifying de distributions.	computer simulation;mathematical optimization;program optimization	Frank Grange	1998			probability distribution;financial management;constrained optimization;simulation;demand forecasting;mathematics;statistics	Vision	7.744920924975631	-3.2245499224869434	85889
ec384f6aef38853a28b1532f8b9d3a05fb609930	the willingness to pay for broadband of non-adopters in the u.s.: estimates from a multi-state survey	telecommunications;survey data;reporting bias;broadband	We use data from a large-scale survey of non-adopting households to provide estimates of their willingness to pay for broadband. A large fraction – approximately 2/3 – of the reporting households indicated that they would not consider subscribing to broadband at any price. For the remaining households who indicated that they would consider subscribing, we find strong evidence in the data of over-reporting at high values of the willingness to pay for broadband. We correct for reporting bias using a semi-parametric procedure. Our estimate of the price elasticity of demand for broadband using the bias-corrected willingness to pay values is equal to −0.62, markedly different from the estimate of −0.95 obtained with the values reported by the survey respondents. Our estimates indicate that, on average, to achieve a 10% increase in subscribership, a price reduction of about 15% is needed. In addition, we estimate the impact of several household characteristics on the likelihood of broadband adoption.		Octavian Carare;Chris McGovern;Raquel Noriega;Jay Schwarz	2015	Information Economics and Policy	10.1016/j.infoecopol.2014.12.001	broadband;actuarial science;telecommunications;public economics;survey data collection;reporting bias;welfare economics	ECom	-2.2106258497615854	-9.165378036881888	85923
ac7bb827d78c4be81bdb5efb9a0be12aa9bb610d	effects of prolonged media usage and long-term planning on archival systems	reliability;performance evaluation;hard disks;media;planning;economics;data models	In archival systems, storage media are often replaced much earlier than their expected service life in exchange for other benefits of new media, such as higher capacity, bandwidth, and I/O operations per second, or lower costs. In an era of decreasing media density growth rates, retiring media early by considering only short-term benefits while discarding potential long-term cost benefits could have a negative long-term impact on an archival system's economics. To extend an archival system's life, at low cost, while limiting performance degradation, we suggest extending media lifetime past manufacturer recommendations as well as increasing the horizon for planning and provisioning future media purchases. We present a cost-benefit analysis of the impact of prolonged media usage and long-term planning. Through Monte Carlo simulation, we simulate the behavior of an archival system using tapes, hard disk drives (HDDs), solid state devices (SSDs), and Blu-ray discs. We show that leaving older media in the archival system makes economic sense for SSDs without significantly affecting reliability; we show cost improvements of approximately 10% for SSDs for a low annual media density growth rate, such as 5%, which would have been a loss of 35%, for a high annual media density rate, such as 20%. We show that, for SSDs and hard disks, the optimal planning time of an archival system is at least as long as the media service life. Combining prolonged media usage with an extended planning horizon reduced costs by 15% for a system using SSDs.	archive;blu-ray;elegant degradation;flops;hard disk drive;input/output;monte carlo method;new media;provisioning;simulation;solid-state electronics	Preeti Gupta;Avani Wildani;Ethan L. Miller;David S. H. Rosenthal;Darrell D. E. Long	2016	2016 32nd Symposium on Mass Storage Systems and Technologies (MSST)	10.1109/MSST.2016.7897083	real-time computing;simulation;engineering;operations management	OS	4.606560457876978	1.430883622610544	85996
c6958dd3ceb0998d42e713ef1baa2ed9d2e29de3	optimal scheduling of electrolyzer in power market with dynamic prices		Optimal scheduling of hydrogen production in dynamic pricing power market can maximize the profit of hydrogen producer; however, it highly depends on the accurate forecast of hydrogen consumption. In this paper, we propose a deep leaning based forecasting approach for predicting hydrogen consumption of fuel cell vehicles in future taxi industry. The cost of hydrogen production is minimized by utilizing the proposed forecasting tool to reduce the hydrogen produced during high cost on-peak hours and guide hydrogen producer to store sufficient hydrogen during low cost off-peak hours.	data pre-processing;hydrogen;preprocessor;random neural network;real-time clock;scheduling (computing)	Yusheng Luo;Min Xian;Manish Mohanpurkar;Bishnu P. Bhattarai;Anudeep Medam;Rahul Kadavil;Rob Hovsapian	2018	2018 IEEE International Conference on Probabilistic Methods Applied to Power Systems (PMAPS)	10.1109/PMAPS.2018.8440508	mathematical optimization;scheduling (computing);electrolysis;hydrogen;dynamic pricing;mathematics;microeconomics;hydrogen production	Robotics	4.803872414925671	3.1743010367255096	86231
f67abc682e3e52e6faf4d4810257c480b27c441d	analysis of inventory systems with (r, q)-policies and backordering	stock control;performance measure;poisson process;exponential distribution;state space methods;inventory systems;customer service;lead time;production control;current measurement;backordering;stochastic processes;markov processes production control stock control exponential distribution;markov process;state probability;production;balance equations;markov processes;state probability inventory systems backordering markov process poisson process lead time exponential distribution balance equations markov chain;customer service stochastic processes industrial engineering steady state poisson equations current measurement production delay state space methods;industrial engineering;poisson equations;steady state;markov chain	This paper describes a Markovian approach for the evaluation of inventory systems with (r,Q) policy and backordering. Demand per unit time is assumed to be Poisson, and the order lead time is exponentially distributed. An order of size Q is placed when the inventory on-hand plus on-order minus backorder downcrosses the re-order level r. Thus, we allow multiple outstanding orders. We have developed a direct approach to solve the steady-state balance equations of the underlying Markov chain to obtain the system state probabilities and performance measures.	scrum (software development)	Lars Nordmann;Tayfur Altiok	1998		10.1109/ICSMC.1998.726478	stochastic process;mathematical optimization;markov process;statistics	Robotics	6.123480287599484	-0.07515461964945216	86329
8d535a59cb0828759c0f62339dcf525a2e89a833	real-time multiobjective microgrid power management using distributed optimization in an agent-based bargaining framework		In this paper, we propose a multi-objective power management procedure for microgrids (MGs). Through this procedure the power management problem is modeled as a bargaining game among different agents with different sets of objective functions. Nash bargaining solution (NBS) is employed to find the solution of the bargaining game. NBS lies on the Pareto-front of the power management problem. Moreover, it introduces a unique and fair balance among the objective functions of different agents and removes the need to track the whole Pareto-front in real-time. Distributed gradient algorithm is applied to find the NBS through a modular distributed decision framework without using a central control unit. In this way, the problem of data privacy of different parties within the MG is addressed. The proposed methodology has been tested through simulations on islanded and grid-connected MGs under different pricing scenarios (fixed versus time-of-use pricing).	agent-based model;algorithm;control unit;gradient;information privacy;mathematical optimization;mg (editor);microgrid;nash equilibrium;netbeans ide;optimization problem;pareto efficiency;power management;real-time clock;real-time transcription;simulation	Kaveh Dehghanpour;M. Hashem Nehrir	2018	IEEE Transactions on Smart Grid	10.1109/TSG.2017.2708686	simulation;operations management;microeconomics	EDA	1.8824174003970076	3.1335980281900557	86473
20748e9e893898e068e489d669db7b542358e6a2	optimal ordering policy for a perishable commodity with fixed lifetime		This paper extends the classical single-item, multiperiod inventory model of Arrow, Karlin, and Scarf to the case where a good in storage perishes exactly l periods after its receipt on order. Units are followed from the time they are purchased and enter the inventory until they are either issued or perish. For general l the paper obtains the optimal policy recursively and derives several properties of the solution.		Brant E. Fries	1975	Operations Research	10.1287/opre.23.1.46	economics;operations management;economy;welfare economics	Crypto	2.7407737791828843	-3.6282854809294207	86611
c20a7c543b0c72007ec0c4159364361ba79518f7	a framework for estimating benefits of using auctions in revenue management	revenue management;pricing;service operations	ABSTRACT#R##N##R##N#We develop a stochastic model to explore the benefits of incorporating auctions in revenue management. To the best of our knowledge the extant literature on modeling in revenue management has not considered auctions. We consider three models, namely, a traditional fixed price (non-auction) model, a pure auction model, and a hybrid auction model and evaluate their revenue performance under a variety of conditions. The hybrid approach outperforms the other two in all 24 scenarios and yields an average revenue increase of 16.1% over the next best. A surprise finding is that there is no significant difference between the performance of the fixed price and pure auction approaches. A sensitivity analysis reveals that the relative superiority of the hybrid revenue management strategy is reasonably robust.		Tim Baker;Nagesh N. Murthy	2002	Decision Sciences	10.1111/j.1540-5915.2002.tb01649.x	financial economics;pricing;yield management;economics;revenue model;marketing;revenue equivalence;microeconomics;auction theory;commerce;service system	ECom	-0.10022203650110098	-7.007718422684889	86777
671f2cebc2d19928e7f0cbb40b01473d606b3167	expansion development planning of thermocracking-based bitumen upgrading plant under uncertainty		Expansion development of upgrading plants is an important decision to make for the oil sands industry. In this paper, we propose a multistage stochastic expansion development method to tackle uncertain synthetic crude oil ( SCO ) and CO 2 tax prices. The linear decision rule based technique is applied to solve the proposed stochastic optimization model. Various analyses are conducted based on optimization results: (i) effects of the uncertainty set size, (ii) comparison of solutions for selected pessimistic, realistic, and optimistic scenarios, (iii) effects of different operating modes for an upgrading plant, and (iv) cost distribution. Results of this work demonstrate that the stochastic model provides a more flexible, economical, and robust solution compared to the deterministic solution. In addition, the CO 2 tax price affects the optimal solution negligibly compared to the SCO price. Finally, expansion development of the studied upgrading plant is economically beneficial even at the current market state. © 2018 Elsevier Ltd. All rights reserved.		Hossein Shahandeh;Farough Motamed Nasab;Zukui Li	2018	Computers & Chemical Engineering	10.1016/j.compchemeng.2018.01.007	stochastic modelling;stochastic optimization;mathematical optimization;synthetic crude;decision rule;oil sands;mathematics;asphalt	AI	8.617685056181777	-4.603629748970387	86853
343f29c41328246ede79a21ebef299ad2f0de991	optimal auction design under non-commitment	limited commitment;mechanism design;optimal auctions	This paper characterizes revenue maximizing auctions for a nite horizon version of the standard IV P model of Myerson (1981) for a seller who cannot commit not to propose a new mechanism, if previously chosen ones fail to allocate the object. We show that a revenue maximizing mechanism in the rst period assigns the good to the buyer with the highest virtual valuation, provided that it is above a buyer-specic reserve price. If no buyer obtains the good in the rst period, the same procedure is repeated in the second period, where virtual valuations are calculated using the posterior distributions and the reserves prices are lower, and so forth, until we reach the last period of the game. This is the rst paper that characterizes optimal mechanisms in a multi-agent environment where the designer behaves sequentially rationally. The characterization procedure can be applicable to other multi-agent mechanism design problems with limited commitment.Keywords: mechanism design, optimal auctions, limited commitment. JEL Classication Codes: C72, D44, D82.	code;horizon effect;multi-agent system;value (ethics)	Vasiliki Skreta	2015	J. Economic Theory	10.1016/j.jet.2015.04.007	mechanism design;economics;operations management;microeconomics;mathematical economics;commerce	AI	-4.403778369640578	-4.243192186427449	86856
84abe708c386a9ed85923c3d1a4b05eab63faef2	research on closed loop supply chain with reference price effect	game theory;reverse channel;clsc;remanufacturing;reference price effect	This paper considers a closed loop supply chain with the manufacturer as the Stackelberg leader. The manufacturer faces three different reverse channels, i.e., (1) manufacturer-managed, (2) retailer-managed, or (3) third party-managed channels. The reference price affects the purchase decision of consumers. Based on game theory, we discuss the reference price effect on the performances across three decentralized reverse channels, and examine the impact of reference price parameter (i.e., reference price coefficient in this paper) on optimal strategies. We conclude that higher reference price coefficient results in lower manufacturer and retailer profits. However, the profit of the third party increases in the reference price coefficient. In addition, some meaningful insights can be derived by comparison without the reference price effect in our models. We found that the scenario without reference price effect is generally superior to that with reference price effect.	closed-loop transfer function	Jie Xu;Nan Liu	2017	J. Intelligent Manufacturing	10.1007/s10845-014-0961-0	game theory;price elasticity of supply;limit price;reservation price;return channel	Robotics	-1.6265358987004068	-6.3217652864593	86900
66ece7860128c15bee2bf545f622c6bf08918492	pre-dispatch of load in thermoelectric power plants considering maintenance management using fuzzy logic		This paper presents a new method for load pre-dispatch considering the technical conditions of engines in thermoelectric power plants by combining several maintenance and diagnostic techniques and using computational intelligence. A diagnosis of the technical conditions of the engines is performed using a lubricant analysis, vibration analysis, and thermography. With these data from a statistical analysis, it is possible to predict when an engine will fail and to consider this phenomenon in the load pre-dispatch. To increase the engine reliability and power supply, a maintenance management program is developed using MANAGEMENT tools, applying only 4 total productive maintenance pillars and combining them with predictive maintenance and diagnostics, thus reducing failures in plant equipment. Some results achieved after this implementation are as follows: a reduction in the annual cost of maintenance, a reduction in the corrective maintenance, an increase in the mean time between failures, and a decrease in the mean time to repair in all areas. In addition, the pre-dispatch ensures that the demanded power is met with a high degree of reliability and quality, and at minimal cost.	computational intelligence;dynamic dispatch;fuzzy logic;mean time between failures;mean time to repair;power supply	Miltonx Fonseca;Ubiratan H. Bezerra;Jorge De Almeida Brito;Jandecy Cabral Leite;Manoel Henrique Reis Nascimento	2018	IEEE Access	10.1109/ACCESS.2018.2854612	reliability engineering;electricity generation;distributed computing;predictive maintenance;total productive maintenance;fuzzy logic;computer science;mean time between failures;corrective maintenance;mean time to repair;computational intelligence	EDA	6.11400512539408	1.3698494150928715	86931
7ad3f3589111dec9e71d71db5b3bfe58decb2dd1	optimal bidding in auctions of mixed populations of bidders	irrationality;asymmetric auctions;optimal bidding;game theoretic model;decision theoretic model;mixed bidder population	A mixed population of bidders consists of two asymmetric groups. Members of the first group are game-theoretic players, who maximize their expected profit and incorrectly believe that their opponents act similarly. The second group of bidders adopts an irrational strategy: they either choose their bids randomly following a given probability distribution, in a “naive” form of bidding, or follow a decision-theoretic approach, maximizing their expected profit under the assumption that all other bids are random. In a sealed bid private-value procurement auction we examine the optimal strategy of a new player, who has perfect knowledge of the structure of the mixed bidder population and enters the auction. The optimal bid of the new bidder is derived when the cost and mark-up follow a uniform distribution in [0,1]. The effect of the relative size of the group of game-theoretic bidders and the population size on the optimal bid price is established.	population	Panos L. Lorentziadis	2012	European Journal of Operational Research	10.1016/j.ejor.2011.07.047	financial economics;vickrey auction;generalized second-price auction;economics;unique bid auction;vickrey–clarke–groves auction;proxy bid;common value auction;english auction;microeconomics;bid shading;commerce	ECom	-4.483170283227863	-4.515667417809845	87023
cdabdced7364f8102ecca43dcf3b59ea6876bddf	the value of capacity sizing under risk aversion and operational flexibility	engineering;computer and systems sciences;project management;systemvetenskap informationssystem och informatik;information systems;optimal project capacity capacity sizing value risk aversion operational flexibility investment opportunity decision maker real option approach resumption options suspension options;risk analysis;uncertainty;technology;social sciences;risk aversion;capacity sizing;industrial;investment;investments uncertainty timing standards renewable energy resources suspensions biological system modeling;real options;science technology;data och systemvetenskap;business economics;business;risk aversion capacity sizing energy sector real options;energy sector;risk analysis capacity planning manufacturing decision making investment project management;projects;management;capacity planning manufacturing;choice;irreversible investment	Risk aversion typically erodes the value of an investment opportunity, often increasing the incentive to delay investment. Although this may be true when the decision maker has discretion only over the timing of investment, any additional discretion over the capacity of a project may lead to different results. In this paper, we extend the traditional real options approach by allowing for discretion over capacity while incorporating risk aversion and operational flexibility in the form of suspension and resumption options. In contrast to a project without scalable capacity, we find that increased risk aversion may actually facilitate investment because it decreases the optimal capacity of the project. Finally, we illustrate how the relative loss in the value of the investment opportunity due to an incorrect capacity choice may become less pronounced with increasing risk aversion and uncertainty.	decision theory;risk aversion;scalability	Michail Chronopoulos;Bert De Reyck;Afzal Siddiqui	2013	IEEE Transactions on Engineering Management	10.1109/TEM.2012.2211363	project management;actuarial science;risk analysis;risk aversion;uncertainty;economics;investment;operations management;microeconomics;management;technology	Metrics	0.555630151326323	-8.871596840462916	87067
61fffc1ec0d2cc0c96a327e15ca2ae194e189353	periodic review for a perishable item under non stationary stochastic demand		We consider the periodic-review, single-location, single-product, production/inventory control problem under non stationary demand and service-level constraints. The product is perishable and has a fixed shelf life. Costs comprise fixed ordering costs and inventory holding costs. For this inventory system we discuss a number of control policies that may be adopted. For one of these policies, we assess the quality of an approximate Constraint Programming (CP) model for computing near optimum policy parameters.	approximation algorithm;constraint programming;inventory control;inventory theory;stationary process	Roberto Rossi	2013		10.3182/20130619-3-RU-3018.00569	inventory theory;economics;operations management;microeconomics;welfare economics	AI	3.7103253139086845	-2.8870594670329273	87180
3bd2e4593504d2b07be36b8fe02a74f6c54dbc8b	setting production capacities for production agents making selfish routing decisions		Traditionally, the capacity dimensioning step within the manufacturing system design process takes a known and fixed distribution of production flow across path alternatives to derive capacity demand based on a desired target utilization level. Setting target levels for machine utilization provides limits on throughput-times and allows to provide capacity bu↵ers against changes in the production mix. In this contribution, we transfer this rationale into the world of Industry 4.0, where Cyber-Physical Systems can make autonomous and selfish routing decisions. Under this new framework, non-cooperative agents make decisions based on the capacity allocation and the decisions of all other agents, thus creating a feedback between flow and capacity distribution that makes existing methods for capacity dimensioning inapplicable. We use methods and insight from algorithmic game theory and operations research to investigate the capacity dimensioning process in this context. We proof properties of the throughput-time optimal allocation of production capacity under fixed target utilization for important queue classes. Our findings not only provide a quantitative, easy to operationalize tool for production system designers, but explore a trade-o↵ between cost and flexibility that arises naturally in this regime.	algorithmic game theory;anarchy;autonomous robot;cyber-physical system;design rationale;industry 4.0;kelly criterion;loss function;mathematical optimization;nash equilibrium;operations research;production system (computer science);routing;stigmergy;systems design;throughput;word lists by frequency	Henning Blunck;Dieter Armbruster;Julia C. Bendul	2018	Int. J. Computer Integrated Manufacturing	10.1080/0951192X.2017.1379097	systems engineering;engineering;cyber-physical system;algorithmic game theory;throughput;management science;industry 4.0;systems design;dimensioning	ECom	6.024860313768827	-5.783202922925879	87224
377da8314112ec58911582014f368a054f723eb1	pricing real abandonment options on several r&d investment projects	closed form solution;r d investment;research and development;real abandonment options;managerial flexibility;capital budgeting	Much previous research has shown that the R&D investments can be evaluated by real growth options approach. But few studies have been done on real abandonment options for R&D projects which may not succeed. The contribution of this paper is not only to derive a more general closed-form solution for evaluating real abandonment options, but to put backup project consideration into our model for reality. We show that both Black-Scholes’s and Stulz’s models are special cases of our model under some specifications of parameters. From the simulation results, we explore that the higher the percentage of recovering salvage value, the more investment projects should be carried out. We hope that the results in this study could provide a useful reference for the manager, to make better decisions regarding backup projects.	backup;black–scholes model;capability maturity model;data recovery;numerical analysis;simulation	Ming-Cheng Wu;Simon H. Yen;Kuo-Ren Lou	2007	Soft Comput.	10.1007/s00500-007-0162-2	closed-form expression;actuarial science;capital budgeting	AI	4.082650764882491	-7.046031582601516	87238
def65176014e668c97583d192b0050bf5dfd29ad	on the performance of mildly greedy players in cut games	cut games;(approximate) nash equilibria;price of anarchy	We continue the study of the performance of mildly greedy players in cut games initiated by Christodoulou et al. (Theoret Comput Sci 438:13---27, 2012), where a mildly greedy player is a selfish agent who is willing to deviate from a certain strategy profile only if her payoff improves by a factor of more than $$1+epsilon $$1+∈, for some given $$epsilon ge 0$$∈ź0. Hence, in presence of mildly greedy players, the classical concepts of pure Nash equilibria and best-responses generalize to those of $$(1+epsilon )$$(1+∈)-approximate pure Nash equilibria and $$(1+epsilon )$$(1+∈)-approximate best-responses, respectively. We first show that the $$epsilon $$∈-approximate price of anarchy, that is the price of anarchy of $$(1+epsilon )$$(1+∈)-approximate pure Nash equilibria, is at least $$frac{1}{2+epsilon }$$12+∈ and that this bound is tight for any $$epsilon ge 0$$∈ź0. Then, we evaluate the approximation ratio of the solutions achieved after a $$(1+epsilon )$$(1+∈)-approximate one-round walk starting from any initial strategy profile, where a $$(1+epsilon )$$(1+∈)-approximate one-round walk is a sequence of $$(1+epsilon )$$(1+∈)-approximate best-responses, one for each player. We improve the currently known lower bound on this ratio from $$min left{ frac{1}{4+2epsilon },frac{epsilon }{4+2epsilon }right} $$min14+2∈,∈4+2∈ up to $$min left{ frac{1}{2+epsilon },frac{2epsilon }{(1+epsilon )(2+epsilon )}right} $$min12+∈,2∈(1+∈)(2+∈) and show that this is again tight for any $$epsilon ge 0$$∈ź0. An interesting and quite surprising consequence of our results is that the worst-case performance guarantee of the very simple solutions generated after a $$(1+epsilon )$$(1+∈)-approximate one-round walk is the same as that of $$(1+epsilon )$$(1+∈)-approximate pure Nash equilibria when $$epsilon ge 1$$∈ź1 and of that of subgame perfect equilibria (i.e., Nash equilibria for greedy players with farsighted, rather than myopic, rationality) when $$epsilon =1$$∈=1.	greedy algorithm	Vittorio Bilò;Mauro Paladini	2014		10.1007/978-3-319-08783-2_44	mathematical optimization;combinatorics;simulation;mathematics	ECom	-3.8280801280677372	0.4298718696473093	87292
87ee73fec819aa2e3e6c8c39f02156bc2ca5822c	pricing, frills, and customer ratings	it strategy;game theory;forward looking behavior;uncertainty;pricing;product augmentation;customer satisfaction;growth rate;customer ratings;profit maximization	This paper explores whether and how a firm should adapt its strategy in view of consumer use of prior customer ratings. Specifically, we consider optimal pricing and whether the firm should offer an unexpected frill to early customers to enhance their product experiences. We show that if price history is unobserved by consumers, a forward-looking firm should always modify its strategy from single-period optimal one, but it may be optimal to do so by lowering price, by lowering price and offering frills, or by raising price and offering frills, depending on the market growth rate. Specifically, the last strategy becomes optimal when market growth rate is high enough. The results are similar when the price history is observed by consumers, except that no deviation from single-period profit maximization choices is optimal when market growth is low enough. We also analyze whether the firm should prefer that the price information be stated in or left out of consumer reviews. In addition, in considering the effects of consumer heterogeneity, we conclude that the optimal firm’s effort to affect ratings is higher when the idiosyncratic part of consumer uncertainty is larger.	consumer-generated advertising;digital history;expectation–maximization algorithm;experience	Dmitri Kuksov;Ying Xie	2010	Marketing Science	10.1287/mksc.1100.0571	pricing;game theory;uncertainty;economics;limit price;marketing;microeconomics;customer satisfaction;commerce	ECom	-2.8113297161995647	-7.596616217871102	87551
6541dc798a55b218fadf318548cc9a6f6d72f264	automation-assisted capture-the-flag: a differential game approach	game theory;trajectory;games;robots;robots decision making differential games numerical analysis;mixed human robot teams automation assisted capture the flag two player capture the flag game zero sum differential game player positions movement speeds numerical solutions hamilton jacobi isaacs equations winning regions joint configuration space computational method human agents berkeley autonomy automation aided decision making;mathematical model;games equations game theory mathematical model trajectory robots approximation methods;approximation methods;reachability analysis capture the flag differential game human robot teams	Capture-the-flag is a complex, challenging game that is a useful proxy for many problems in robotics and other application areas. The game is adversarial, with multiple, potentially competing, objectives. This interplay among different factors makes the problem complex, even in the case of only two players. To make analysis tractable, previous approaches often make various limiting assumptions upon player actions. In this paper, we present a framework for analyzing and solving a two-player capture-the-flag game as a zero-sum differential game. Our problem formulation allows each player to make decisions rationally according to the current player positions, assuming only an upper bound on the movement speeds. Using numerical solutions to Hamilton-Jacobi-Isaacs equations, we compute winning regions for each player as subsets of the joint configuration space and derive the corresponding winning strategies. The computational method and simulations are presented, along with experiments with human agents in the Berkeley autonomy and robotics in capture-the-flag testbed. These experiments demonstrate the use of the solutions in realistic conditions and highlight their potential applications in automation-aided decision making for humans and mixed human-robot teams.	adversary (cryptography);agent-based model;approximation;automation;bellman equation;capture the flag;cobham's thesis;computation;computational complexity theory;experiment;hamilton–jacobi–bellman equation;initial condition;jacobi method;multistage amplifier;numerical analysis;robotics;simulation;state space;testbed	Haomiao Huang;Jerry Ding;Wei Zhang;Claire J. Tomlin	2015	IEEE Transactions on Control Systems Technology	10.1109/TCST.2014.2360502	non-cooperative game;combinatorial game theory;robot;bayesian game;games;game theory;mathematical optimization;simulation;game tree;extensive-form game;simultaneous game;computer science;artificial intelligence;trajectory;game mechanics;repeated game;mathematical model;control theory;mathematical game;mathematics;strategy;screening game;normal-form game;simulations and games in economics education;algorithmic game theory;sequential game	Robotics	-0.2831386158343476	0.13791240119984594	87725
b29f496d1e9ab9ea3e9aee86cded99ad7206d9f7	a rule-based approach to prioritization of it work requests maximizing net benefit to the business	decision support;rule based;cost reduction;it oursourcing;it outsourcing;economies of scale;work request prioritization;it service management	With the growth of IT outsourcing opportunities, providers of managed IT services, such as HP, are compelled to exploit any possible economy of scale in dealing with emerging requirements of their customers. In this paper we present a methodology and a set of tools for enhanced executive decision support capability for the best allocation of scarce development resources through timelier and more accurate delivery of forecast indicators relative to the net benefit. Examples of such indicators are total forecast revenue for a bundle of work requests and total forecast cost reductions for a bundle of work requests. The tools deliver on reduced development cost and shorter time to value through the identification of synergies, duplication and commonality in work requests. For example, our approach will be able to identify in a reliable manner work that falls into these discrete categories pertaining to potential duplication thereby highlighting areas of potential cost reduction. Moreover they guarantee a reduced turn around time of delivery to trade customers through prioritization driven by net benefit and optimized release.	requests	Maher Rahmouni;Claudio Bartolini;Abdel Boulmakoul	2007		10.1007/978-3-540-75975-1_5	rule-based system;decision support system;computer science;artificial intelligence;economies of scale;management science	Vision	1.8226757451949542	-7.3314407861806465	87888
25c2da72b69ccd1916fca8eb2c95a42be755c6f7	online auction effectiveness: optimal selling strategies for online auction market	electronic commerce;online auction;auction;internet auction;auction effectiveness;supply and demand;empirical research	The introduction of internet auction has significantly widened the pool of consumers who participate in auctions and increased the number of companies attempting to sell their products in an auction format. Previous empirical research on auctions has focused almost exclusively on the behavior of professional bidders. In this study, we collect data on a large number of internet auctions to explore the outcome of the auction in a real marketplace. In particular, we focus on the characteristic of sellers, auction parameters, the effect of supply and demand, and examine these impacts on auction effectiveness.	auction algorithm;competitive programming;focal (programming language);internet;mortar methods	Pui-Lai To;Chechen Liao;Yu-Ping Liu;Chiao-Ying Chen	2008			spectrum auction;auction sniping;e-commerce;eauction;social science;vickrey auction;combinatorial auction;generalized second-price auction;economics;unique bid auction;computer science;reverse auction;vickrey–clarke–groves auction;proxy bid;revenue equivalence;multiunit auction;supply and demand;microeconomics;empirical research;world wide web;auction theory;commerce;forward auction;dutch auction	ECom	-4.169611438407188	-7.541425641946719	87992
6c2145c532cdcbebf6b041a29d991f5e24f09cf7	optimal bi-valued auctions	polynomial time;data structure;lower bound	We investigate bi-valued auctions in the digital good setting and construct an explicit polynomial time deterministic auction. We prove an unconditional tight lower bound which holds even for random superpolynomial auctions. The analysis of the construction uses the adoption of the finer lens of general competitiveness which considers additive losses on top of multiplicative ones. The result implies that general competitiveness is the right notion to use in this setting, as this optimal auction is uncompetitive with respect to competitive measures which do not consider additive losses.	competitive analysis (online algorithm);time complexity;utility functions on indivisible goods	Oren Ben-Zwi;Ilan Newman	2011	CoRR		time complexity;mathematical optimization;combinatorics;data structure;computer science;mathematics;mathematical economics;upper and lower bounds;programming language;algorithm	Theory	-2.840416066939585	-0.47099536016306576	88003
090d86ac8397c4d084c4925b2ac774eabedc85e1	online and offline demand and price elasticities: evidence from the air travel industry	market transparency;electronic markets;multichannel strategy;self selection;price elasticity;air travel industry;online travel agencies;mechanism design;economics of information systems	The Internet has brought consumers increased access to information to make purchase decisions. As markets come closer to perfect information, one of the expected outcomes is an increase in competition. One of the consequences is an increase in the price elasticity of demand, or the percent change in demand due to a percent change in price, because consumers are better able to compare offerings from multiple suppliers. In this paper, we analyze the impact of the Internet on demand, by comparing the demand functions in the Internet and traditional air travel channels. We use a data set that contains information for millions of records or airline ticket sales in both offline and online channels. To our knowledge, this is the first study that uses massive sales data to compare consumer demand functions in the two channels. The results suggest that consumer demand in the Internet channel is more price-elastic for both transparent and opaque online travel agencies. We also find that the opaque OTAs are more price-elastic than the transparent OTAs. These results are after controlling for the different mix of business and leisure travelers across these travel agency types. We discuss the broader implications for multi-channel pricing strategy and for the transparency-based design of online selling mechanisms.	elasticity (cloud computing);freedom of information laws by country;internet;online and offline;online shopping;price systems;relative change and difference	Nelson F. Granados;Alok Gupta;Robert J. Kauffman	2012	Information Systems Research	10.1287/isre.1100.0312	price elasticity of demand;mechanism design;economics;limit price;marketing;mid price;self-selection bias;microeconomics;advertising;reservation price;demand curve;commerce	Metrics	-2.2742144753809352	-8.317127451087137	88280
114587ffb72dd1ae629b12d5514be69ff837f661	the equity tax and shelter	income tax;tax avoidance;capital gain;capital gains tax;profitability	Taxes have major costs beyond the collected revenue: deadweight from distorted incentives, compliance and enforcement costs, etc. A simple market mechanism, the Equity Tax, avoids these problems for the trickiest cases: corporate, dividend, and capital gains taxes. It exploits the ability of the share prices to reflect the expected true annual return (as perceived by investors, not as defined by law) and works only for publicly held corporations. Since going or staying public cannot be forced, and for some constitutional reasons too, the conversion to equity tax must be a voluntary contract. Repeated reconversions would be costly (all capital gains are realized) and thus rare. The converts and their shareholders pay no income, dividend, or capital gain taxes. Instead, they give the IRS, say, 2% of stock per year to auction promptly. Debts are the lender’s assets: its status, not the debtor’s, determines their equity-tax or income-tax treatment. The system looks too simple to be right. However, it does have no loopholes (thus lowering the revenue-neutral tax rate), no compliance costs, requires little regulation, and leaves all business decisions tax neutral. The total capital the equity taxed sector absorbs is the only thing the tax could possibly distort. The rates should match so as to minimize this distortion. The equity tax enlarges the pre-tax profit since this is what the taxpayers maximize, not a different after-tax net. The wealth shelter is paid for by efficiency, not by lost tax.	distortion;loopholes in bell test experiments	Leonid A. Levin	2000	CoRR		ad valorem tax;tax revenue;double taxation;state income tax;income tax;tax avoidance;tax credit;direct tax;value-added tax;deferred tax;tax basis;dividend tax;tax deferral;finance;tax deduction;gross income;cost basis;tax shield;indirect tax;tax reform;profitability index;international taxation	ECom	-1.6826400791869158	-7.9302136941039825	88285
e0826f57b073753e91755cb30909942646c352ac	inventory control with an exponential utility criterion	news vendor model;politica optima;funcion utilidad;funcion exponencial;uncertainty;fonction exponentielle;fonction utilite;stochastic exponential utility;exponential function;horizonte acabado;utility function;inventory production;optimal policy;risk sensitivite;administracion deposito;horizonte infinito;horizon infini;horizon fini;gestion stock;exponential utility;finite horizon;utility preference exponential utility in inventory model;infinite horizon;politique optimale;inventory control;dynamic programming optimal control risk sensitive inventory model	A base-stock policy is shown to be optimal when a dynamic version of the “news vendor” model is optimized with respect to an exponential utility criterion.	exponential utility;inventory control	Mokrane Bouakiz;Matthew J. Sobel	1992	Operations Research	10.1287/opre.40.3.603	inventory control;uncertainty;economics;operations management;exponential function;mathematics;mathematical economics;welfare economics;statistics	Robotics	3.5501722559268525	-2.9170992691230238	88483
f4ca6f8634cf2b493d2f0a9849f4b3827b1cc28d	a predictive continuum dynamic user-optimal model for the simultaneous departure time and route choice problem in a polycentric city		This study develops a predictive continuum dynamic user-optimal model for the simultaneous departure time and route choice problem through a variational inequality (VI) approach. A polycentric urban city with multiple central business districts (CBDs) is considered, and travelers are classified into different classes according to their destinations (i.e., CBDs). The road network within the modeling city is assumed to be sufficiently dense and can be viewed as a continuum. A predictive dynamic user-optimal (PDUO) model has been previously used to model traffic flow with a given traffic demand distribution, in which travelers choose the routes that minimize the actual travel cost to the CBD. In this work, we combine the departure time choice with the PDUO model to study the simultaneous departure time and route choice problem. The user-optimal departure time principle is satisfied, which states that for each origin–destination pair, the total costs incurred by travelers departing at any time are equal and m...		Zhi-Yang Lin;Sze Chun Wong;Peng Zhang;Keechoo Choi	2018	Transportation Science	10.1287/trsc.2017.0785	mathematical optimization;variational inequality;mathematics;total cost;continuum (design consultancy);traffic flow	Theory	9.198127794377848	-6.783322431814971	88499
212fd3b6bae396e4273181167ce0de201a2deaa9	a two-stage market model for microgrid power transactions via aggregators		In this paper, we propose a market model where microgrids sell their surplus power to a utility via aggregators. This is a scalable model where a utility does not directly interact with a large number of microgrids. Thus, aggregators collect power from microgrids and resell it to the utility. From the microgrids' perspective, aggregators are buyers. From the utility's perspective, aggregators are sellers. In this context, based on the two-stage Stackelberg game, we show how to achieve efficient market equilibrium using the tatonnement process and supply function bidding. We also show that the participation of aggregators may significantly affect the market depending on the supply elasticity of microgrids, which in turn depends on the cost structure of microgrids. For example, when the cost function of microgrids is roughly linear, the aggregators may not make a profit. However, if the cost function of microgrids has a higher order term, aggregators may accumulate a large profit, which potentially raises the issue of the regulator's role in the market.	elasticity (data store);entropy maximization;loss function;marginal model;microgrid;news aggregator;scalability;walrasian auction	Hongseok Kim;Marina Thottan	2011	Bell Labs Technical Journal	10.1002/bltj.20524	walrasian auction;supply;stackelberg competition;engineering;scalability;real-time computing;price elasticity of supply;bidding;regulator;microeconomics;microgrid	ECom	-1.0896811072154955	-4.093574294153829	88646
a839c9e7c1f128844f9c1213b1ce56ba92ff4deb	consumer product search and the decision between intermediary and supplier online shops	experimental economics;electronic commerce;intermediaries;consumer behavior;transaction costs	When shopping online, consumers have to decide between two vendor types – suppliers and intermediaries. The existing body of research on intermediation usually adopts a market-centric perspective, and subsequently neglects the consumer when making this focal decision. Therefore, using the example of digital music, we offer a consumercentric view on this problem. We use experimental and simulation techniques to analyze how consumers decide between intermediaries and suppliers and what kind of search strategies they apply. Furthermore, we evaluate the efficiency of consumers’ decisions and find significant differences between strategies. Given that in practice, consumers usually possess less information on products and prices prior to search and that market structures are more complex, our study demonstrates that consumers may suffer from efficiency losses when having to make such decisions. This highlights the importance of consumer decision support systems that operate on a market-spanning basis and provides new insights for practical applications.	decision support system;focal (programming language);file spanning;online shopping;simulation	Christian Matt	2012			transaction cost;computer science;marketing;intermediary;experimental economics;world wide web;commerce	Web+IR	-3.658579293623976	-9.300389617552126	88831
b65f4e5166d30b615c95027b1a6538883997709e	queueing models of case managers	networks;healthcare;hospitals;queues;applications;approximations	Many service systems use case managers, servers who are assigned multiple customers and have frequent, repeated interactions with each customer until the customer’s service is completed. Examples may be found in health care (emergency department physicians), contact centers (agents handling multiple on-line chats simultaneously) and social welfare agencies (social workers with multiple clients). We propose a stochastic model of a baseline case manager system, formulate models that provide performance bounds and stability conditions for the baseline system, and formulate a birth-death process that approximates the baseline system’s performance. Many systems place an upper limit on the number of customers simultaneously handled by each case manager. We examine the impact of these case-load limits on waiting time and describe effective, heuristic methods for setting these limits.	baseline (configuration management);heuristic;interaction;online and offline;queueing theory;server (computing)	Fernanda Campello;Armann Ingolfsson;Robert A. Shumsky	2017	Management Science	10.1287/mnsc.2015.2368	simulation;marketing;operations management;management;information technology;queue	AI	4.422061432967346	-0.23195898604156887	88850
088a76559e37cebae9caabcdd2e18f71be68330e	matching and price competition: would personalized prices help?	national resident matching program;wage competition;market design;price competition;matching	We analyze the generalized deferred-acceptance algorithm when preferences are known with an error. This algorithm incorporates personalized salaries and is considered as a replacement for the current algorithm for National Resident Matching Program (NRMP). Maintaining Bulow and Levin’s (2006) assumption on preferences, we show that an error in preferences of a worker propagates through the algorithm, leading to a change in the salary of every more productive worker. Thus, relatively small individual errors accumulate toward the top and may lead to highly distorted salaries for top workers the same way as mild compression translates into highly compressed salaries on the top in the Bulow and Levin study of the current NRMP algorithm. JEL classification: C78, D43, J41.	algorithm;national resident matching program;personalization	Georgy Artemov	2008	Int. J. Game Theory	10.1007/s00182-007-0087-0	matching;economics;marketing;operations management;microeconomics;mathematical economics	AI	-1.247842681242684	-9.645330146033189	88866
6b1c1b7792d506133843516c8df73692f1fd7ccb	performance comparison of enhanced pso and de variants for dynamic energy/reserve scheduling in multi-zone electricity market	nonconvex block price curve;meta heuristic optimization;joint static dynamic dispatch jsd jdd;energy and reserve dispatch;multi zone electricity market;transmission constraints	During the last decade, energy regulatory policies all over the globe have been influenced by the introduction of competition. In a multi-area deregulated power market, competitive bidding and allocation of energy and reserve is crucial for maintaining performance and reliability. The increased penetration of intermittent renewable generation requires for sufficient allocation of reserve services to maintain security and reliability. As a result the market operators and generating companies are opting for market models for joint energy and reserve dispatch with a cost minimization/profit maximization goal. The joint dispatch (JD) problem is more complex than the traditional economic dispatch (ED) due to the additional constraints like the reserve limits, transmission limits, area power balance, energy-reserve coupling constraints and separate sectional price offer curves for both, energy and reserve. The present work proposes a model for the joint static/dynamic dispatch of energy and reserve in deregulated market for multi-area operation using enhanced versions of particle swarm optimization (PSO) and differential evolution (DE). A parameter automation strategy is employed in the classical PSO and DE algorithms (i) to enhance their search capability; (ii) to avoid premature convergence; and (iii) to maintain a balance between global and local search. The performance of enhanced PSO and DE variants is compared for single/multi-area power systems for static/dynamic operation, taking both linear and nonsmooth cost functions. The proposed approach is validated on two test systems for different demands, reserve requirements, tie-line capacities and generator outages. © 2015 Elsevier B.V. All rights reserved.	algorithm;coefficient;differential evolution;downtime;dynamic dispatch;entropy maximization;heuristic;ibm power systems;jd - java decompiler;local search (optimization);loss function;mathematical optimization;maxima and minima;media redundancy protocol;metaheuristic;microwave;optimization problem;pm2;particle swarm optimization;phase-shift oscillator;premature convergence;procurement;qualitative comparative analysis;ramp simulation software for modelling reliability, availability and maintainability;requirement;scheduling (computing);social inequality;tie line;user-generated content	Manjaree Pandit;Laxmi Srivastava;Manisha Sharma	2015	Appl. Soft Comput.	10.1016/j.asoc.2015.09.004	mathematical optimization;simulation;economic dispatch	AI	5.484264829023065	3.3071354587774047	88981
0d3a790d6e0bddf2a492e0e06143b45228a6af94	analytic and experimentally derived estimates of market power in deregulated electricity systems: policy implications for the management and institutional evolution of the industry	market power;market share;electricity supply evolution;electricity market;prediction market;electricity deregulation;energy price;profitability;distributed generators;predicting market power;transmission line	Previous experimental and game-theoretic analyses of deregulated electricity markets suggest that communities having four or less effective suppliers, either because of transmission constraints or load characteristics, or retail customers facing suppliers or marketing agents having more than seventy percent of the region’s market, are likely to experience prices well above competitive levels. While state regulatory bodies may be able to forestall the onset of retail wheeling and non-regulated retail energy pricing until a single supplier does not dominate initial market shares, it is more difficult to mute the exercise of market power by generators serving electrically isolated load pockets. And in both instances, if the accrual of some excess profits by initial, non-regulated suppliers are not tolerated, then little incentive will have been provided for competitors to enter the market and for more efficient technologies to evolve. Estimates are provided in this analysis of the circumstances for and the extent and duration of the exercise of market power. When combined with the present absence of incentives to build transmission lines that would reduce bottlenecks and the existing utilities’ insistence upon full recovery of stranded costs through line charges and access fees, the powerful incentives to develop distributed generation are highlighted.	bottleneck (software);experiment;game theory;mute;offset binary;onset (audio);transmission line	Richard E. Schuler	2001	Decision Support Systems	10.1016/S0167-9236(00)00110-X	market share;market rate;market microstructure;market saturation;market price;economics;electricity market;market impact;order;capital market line;marketing;transmission line;electricity retailing;microeconomics;domestic market;factor market;market share analysis;commerce;profitability index	ECom	-3.786973320724147	-7.3570794951902645	89169
b1b9635f6d263a91f851a868ee4cda0bb3eea809	assessing the quality of convex approximations for two-stage totally unimodular integer recourse models	convex approximations;integer recourse;sampling methods;stochastic programming	We consider two types of convex approximations of two-stage totally unimodular integer recourse models. Although worst-case error bounds are available for these approximations, their actual performance has not yet been investigated, mainly because this requires solving the original recourse model. In this paper we assess the quality of the approximating solutions using Monte Carlo sampling, or more specifically, using the so-called multiple replications procedure. Based on numerical experiments for an integer newsvendor problem, a fleet allocation and routing problem, and a stochastic activity network investment problem, we conclude that the error bounds are reasonably sharp if the variability of the random parameters in the model is either small or large; otherwise, the actual error of using the convex approximations is much smaller than the error bounds suggest. Moreover, we conclude that the solutions obtained using the convex approximations are good only if the variability of the random parameters is ...	approximation algorithm;experiment;fo (complexity);lagrangian relaxation;linear programming relaxation;nl (complexity);newsvendor model;numerical analysis;regular expression;routing;sampling (signal processing);spatial variability;stochastic process;stochastic programming;unimodular polynomial matrix	Ward Romeijnders;David P. Morton;Maarten H. van der Vlerk	2017	INFORMS Journal on Computing	10.1287/ijoc.2016.0725	stochastic programming;sampling;mathematical optimization;combinatorics;discrete mathematics;mathematics	Vision	3.981258888611458	-2.9149089019179293	89266
ef9f2d77ff117014a1072b602ab7668e75e39099	congestion in commodity trading advisors	dea;leverage;congestion	Abstract Congestion is often used in the operations area to investigate the excessive effect of inputs on outputs. In finance, and more specifically in the derivatives area, leverage is embedded in options and futures contracts. Commodity Trading Advisors (CTAs) use leverage (margin-to-equity ratio) to magnify returns through the use of these futures contracts. However, excessive leverage may hamper performance. This paper aims to show that a related data envelopment analysis (DEA) called the “congestion model” can offer a more precise picture of identifying CTAs suffering from congestion. In other words, if congestion is present then a reduction in input(s) may generate an increase in output. However, the opposite effect can arise. Although traditional DEA does an excellent job at ranking efficient CTAs, congestion on the other hand sizes up which CTAs are using too much (overuse) of each input, thereby reducing their performance/compound return (output). We measure the congestion of the largest (in term...	know-how trading;network congestion	Greg N. Gregoriou;Razvan Pascalau;Yao Chen	2011	INFOR	10.3138/infor.49.1.063	financial economics;economics;microeconomics;leverage;commerce	Crypto	-1.1367619427490798	-8.600729253457935	89322
4de0834a323f0ac64a8be409d04281e3f5fb5785	robust decision making using a general utility set		Elicitation of an exact utility function of a decision maker is challenging. In this paper, we address the problem of ambiguity and inconsistency in utility assessments by studying a robust utility-based decision making model where the utility function belongs to a set of general increasing utility functions. We build a robust framework in which the utility function belongs to a set. This set on the utility function is described by boundary and auxiliary conditions. We consider a maximin problem that maximizes the worst-case expected utility of random outcome over the set, thereby hedging the risk arising from uncertainty of the utility function. We study the implications of the uncertain utility on the objective function value of this robust decision model and show that under suitable conditions the Sample Average Approximation (SAA) of a Lagrangian function associated with this model can be solved using a mixed integer linear program. We show that the optimum objective value of the SAA converges to its true counterpart at an exponential rate and we harness this convergence property to present a heuristic which provides a feasible solution for the SAA problem. We illustrate model properties using a portfolio investment problem where investment gains and losses are valued using different uncertain decision (dis)utilities. We also provide computational insights by solving the SAA of this problem as a mixed integer linear program and using our heuristic.	approximation algorithm;best, worst and average case;decision theory;expected utility hypothesis;heuristic;linear programming;loss function;minimax;optimization problem;robustness (computer science);time complexity	Jian Hu;Manish Bansal;Sanjay Mehrotra	2018	European Journal of Operational Research	10.1016/j.ejor.2018.02.018	mathematical optimization;optimal decision;decision tree;mathematics;mathematical economics;welfare economics	AI	4.678837692666153	-4.531201296298449	89554
ad1c335ced38a33722d98b278a23e031bf76d09c	learn to apologize for fun and profit	profitability			Lisa Gualtieri	2007	eLearn Magazine	10.1145/1361059.1361062	economics;computer science;microeconomics;commerce;profitability index;labour economics	ML	-1.6121971397420123	-4.708007871281202	89684
f344e74a2f23ab76b1e85d069ca438dfd1723e39	modelling, simulation and analysis of control mechanism of a dynamic supply chain system considering supply-price trade-off, using control theory	z transform;frequency domain analysis;transfer function;supply chain	Purpose – The objective of this work is to develop a model that can be used for simulation of different parameters including price, subjected to different control strategies. Design/methodology/approach – The entire supply chain can be modelled by combining the transfer function into a closed loop system. The transfer function of each entity in the supply chain can be obtained by using the control theory tools. The model can be approximated as a linear discrete system with various operating constants, like lead time, price, order policy and supply. Findings – The continuous replenishment ordering policy for a distribution node in a supply chain was analyzed using the z-transform. Characteristic equations of the closed loop transfer function are obtained. The bullwhip (BW) effect is analyzed. Study proves that the BW effect is in evitable if the standard heuristic ordering policy is employed with demand forecasting; also the paper analysed price supply trade-off for dynamic demand and supply. Simulation re...	control theory;simulation	Anup Kumar;Kampan Mukherjee;Narendra Kumar	2013	Business Proc. Manag. Journal	10.1108/BPMJ-05-2012-0044	z-transform;simulation;economics;operations management;supply chain;transfer function;mathematical economics;frequency domain	ML	2.159297266843294	-3.576313362398338	89697
52e1a560ad5f2b383c4dd32f2a32550acc7974a1	a joint optimization of product variety and ordering approach	optimal solution;optimisation;non linear programming;optimizacion;non linear optimization;preparacion pedido;programacion no lineal;inventory planning and control;comercializacion;programmation non lineaire;product line;prise decision;consumer preference;production management;administracion deposito;commercialisation;profit;economic order quantity;beneficio;marketing;gestion stock;benefice;planning and control;quantite economique a commander;optimization;product variety;profitability;preparation commande;cantidad economica pedida;order picking;toma decision;inventory control	The OPROVAR model is a non-linear optimization model that determines the optimal product line that would maximize profits while considering costs of ordering and carrying inventory, subject to given system constraints. The model has been formulated with the assumption that consumer preferences for products are known and are ordinally scaled for the subset of products in the product line. Further, products can be added and deleted according to the profitability criterion. The problem of jointly determining the product variety decision with the ordering decision for the different variations of a brand of a certain product that comprises a product line is considered. We determine optimal solutions to the OPROVAR model that not only considers the order quantity decision of a product but also makes stocking decision of a product line to maximize total profits.#R##N##R##N#It has been generally recognized that the product variety or product line decision is one of critical importance to marketing and product managers. Product line composition is one of the most pervasive problems that includes analysis of product additions as well deletions and the degree of complementarity and substitutability among the different items within the product line. Equally important is the ordering decision which determines the order size and timing of the order for replenishing the stock of each of the products that constitute the given product line. We develop a model, OPROVAR (optimization of product variety and ordering strategy) that considers simultaneously the order quantity decision of a product and the stocking decision of a product line to maximize total profits.	mathematical optimization	Vaidyanathan Jayaraman;Rajesh Srivastava;W. C. Benton	1998	Computers & OR	10.1016/S0305-0548(98)00010-0	inventory control;mathematical optimization;product proliferation;profit;economic order quantity;nonlinear programming;operations research;profitability index	EDA	0.8602769631033492	-5.586406666274893	89802
b3985099f81887156f7aa3fe817db58dd1c1b45c	service performance improvement by using rfid-enabled goods traceability data: a case study	distribution;takashimaya;menswear;service productivity;substitute indicators;intellectual capital;retailing;sold items;retail industry;performance improvement;scm;rfid;business shirts;correlation coefficients;shops;radio frequency identification;service performance measurement;services management;clothing;automated data capture;department stores;inventories;goods traceability;sales floors;retailers;japan;supply chain management	This paper presents a case study where service performance of a retailer can be improved not by directly measuring the service performance and solving problem; but by measuring a substitute performance indicator that corresponds to the service performance and solving the problem. As a substitute indicator, we choose a correlation coefficient between sold item distribution and sales floor inventory distribution. Since measuring service performance continuously in stores has lots of difficulties because of the nature of services, the services of the retailer have been difficult to improve. However, since the move of goods inside a store is captured easily by using automated data capturing (ADC) technologies, the service performance could be continuously improved if the goods traceability data is used for this purpose. In this study, we show the effectiveness of our approach with a radio frequency identification (RFID) application in a men's business shirt store of a department store.	radio-frequency identification;requirements traceability	T. Inaba;S. Miyazaki	2010	IJSTM	10.1504/IJSTM.2010.035781	radio-frequency identification;supply chain management;economics;marketing;operations management;retail;management;commerce	NLP	3.8190032010051116	-8.266922281435306	89825
306069156b9edafaaa85e172dd98f2174b442fbf	maintenance strategy for stochastic selective maintenance of a two-state system	system reliability;maintenance time;simulation;mission time;parallel systems;intelligent optimisation;stochastic modelling;maintenance strategy;stochastic selective maintenance;two state systems	Selective maintenance is often applied in many industrial environments where maintenance is performed between sequence missions. When the length of maintenance or work mission time is stochastic, previous research based on deterministic mission times is unsuitable. Assume that the time of work mission is random and maintenance time is determined in a two-state and parallel system, to maximise system reliability of next work mission in this paper a stochastic model is proposed under the maintenance time limit. The optimal maintenance plan is obtained with a hybrid intelligent optimisation algorithm. A simulation was performed to verify the validity and feasibility of the proposed model.		Jing Zhao;Jianchao Zeng	2016	IJWMC	10.1504/IJWMC.2016.10003272	simulation;computer science;stochastic modelling	Robotics	7.96659802580116	-0.19583415914365468	89875
9bff66b08e0c4b7afade7ad2a1a7e4520bcbfe27	international carbon trade with constrained allowance choices: results from the staco model		International carbon markets are advocated in order to involve more countries in an agreement for the mitigation of greenhouse gas emissions and to reduce the costs of mitigation. In this paper we develop a model where allowances are endogenously determined by each member of a carbon trade agreement, but with an exogenous constraint on the number of allowances per member. We use a global model to explore the incentives for regions to participate in such a carbon market and we examine its performance. To gain practical policy insights, we employ the STACO model, a numerically calibrated model with twelve world regions. Our results show that the stability and effectiveness of an international carbon market can be improved by imposing constraints on individual allowance choices compared to a carbon market without such constraints. Constraints on allowance choices reduce ‘hot air’ and increase global welfare and mitigation. When tightening the constraint ‘broad but shallow’ agreements are replaced by ‘narrow but deep’ ones. If the constraint is too tight, however, no stable carbon market exists.		Shuangyue Yu;Hans-Peter Weikard;X. Zhu;E. C. van Ierland	2017	Annals OR	10.1007/s10479-016-2126-3	economics;public economics;economy;welfare economics	Vision	-1.3091601071257937	-7.91900417541729	89929
4e1c2e5b204f1608c11c1d4f9f9a8f6a4d731a9a	repeated games over networks with vector payoffs: the notion of attainability	stock control;continuous time;electronic mail;game theory;vectors games trajectory educational institutions game theory electronic mail monte carlo methods;repeated game;trajectory;vectors;vectors game theory stock control;monte carlo method;games;multi inventory application repeated games over networks vector payoffs attainability;cumulant;monte carlo methods	We introduce the concept of strongly attainable sets of payoffs in two-player repeated games with vector payoffs in continuous time. A set of payoffs is called strongly attainable if player 1 has a strategy guaranteeing, even in the worst case, that the distance between the set and the cumulative payoff shrinks with time to zero. We characterize when any vector is strongly attainable and illustrate the motivation of our study on a multi-inventory application.	best, worst and average case	Ehud Lehrer;Eilon Solan;Dario Bauso	2011	International Conference on NETwork Games, Control and Optimization (NetGCooP 2011)		mathematical optimization;simulation;repeated game;mathematics;stochastic game;mathematical economics;symmetric game	Robotics	-0.18314616730663122	-0.9508597525466619	90294
6eeb1d05db7b57266dd124e8dd25c8ec88e30aa3	auctions with a profit sharing contract	spectrum auction;game theory;profit sharing;interdependent values;risk aversion;spectrum;principal agent relationship;auction;english auction;profitability;profit sharing contracts;selling a resource;second price auction	We study the problem of selling a resource through an auction mechanism. The winning buyer in turn develops this resource to generate profit. Two forms of payment are considered: charging the winning buyer a one-time payment, or an initial payment plus a profit sharing contract (PSC). We consider a symmetric interdependent values model with risk averse or risk neutral buyers and a risk neutral seller. For the second price auction and the English auction, we show that the seller’s expected total revenue from the auction where he also takes a fraction of the positive profit is higher than the expected revenue from the auction with only a one-time payment. Moreover, the seller can generate an even higher expected total revenue if, in addition to taking a fraction of the positive profit, he also takes the same fraction of any loss incurred from developing the resource. Moving beyond simple PSCs, we show that the auction with a PSC from a very general class generates higher expected total revenue than the auction with only a one-time payment. Finally, we show that suitable PSCs provide higher expected total revenue than a one-time payment even when the incentives of the winning buyer to develop the resource must be addressed by the seller.	interdependence;multi-function printer;risk aversion	Vineet Abhishek;Bruce E. Hajek;Steven R. Williams	2013	Games and Economic Behavior	10.1016/j.geb.2012.10.007	spectrum auction;game theory;spectrum;eauction;vickrey auction;profit;generalized second-price auction;risk aversion;economics;reverse auction;revenue equivalence;multiunit auction;english auction;microeconomics;auction theory;commerce;profitability index;forward auction;dutch auction	ECom	-2.7197410572403267	-4.3802107947138404	90324
2b253ab281d8c43251108ee89970856e4ea4d6d0	study on the optimal dynamic programming method and its application based on long-term average annual energy output	dynamic programming;reservoirs;economic benefit;dynamic programming method;application study;chengbihe reservoir hydropower station optimal dynamic programming method long term average annual energy output dynamic reservoir programming model optimization discharge process;dynamic program;optimization discharge process;programming model;long term average annual energy output;optimal operation of reservoir;chengbihe reservoir hydropower station;long term annual average energy output;application study dynamic programming method long term annual average energy output optimal operation of reservoir;reservoirs electricity power generation dynamic programming water conservation discharges;power generation;electricity;reservoirs dynamic programming;optimal dynamic programming method;discharges;water conservation;dynamic reservoir programming model	On the basis of dynamic programming theory, taking the optimization of long-term average annual energy output as its criterion, the dynamic reservoir programming model was set up and the calculation on the optimization discharge process of reservoir was described in detail. The method was applied to the Chengbihe reservoir hydropower station in Guangxi of China and it made the long-term average annual energy output increased by 8.5%, which brought a sound economic benefit. The method is very practical and easy to operate and it can provide reference for operations of the built reservoirs.	discharger;dynamic programming;mathematical optimization;programming model	Chongxun Mo;Qunchao Du;Xinyi Fan;Fanggui Liu	2010	2010 Sixth International Conference on Natural Computation	10.1109/ICNC.2010.5584251	control engineering;mathematical optimization;engineering;operations management	EDA	8.97569370899999	-5.364781972542726	90495
b1cc004db21c93a02d20d74282fcc0bc2a5a715b	a stabilised scenario decomposition algorithm applied to stochastic unit commitment problems	heuristics;mixed integer column generation;stochastic programming;dantzig wolfe decomposition;lagrangian relaxation	In recent years the expansion of energy supplies from volatile renewable sources has triggered an increased interest in stochastic optimization models for hydro-thermal unit commitment. Several studies have modelled this as a two-stage or multi-stage stochastic mixed-integer optimization problem. Solving such problems directly is computationally intractable for large instances, and alternative approaches are required. In this paper we use a Dantzig-Wolfe reformulation to decompose the stochastic problem by scenarios. We derive and implement a column generation method with dual stabilisation and novel primal and dual initialisation techniques. A fast, novel schedule combination heuristic is used to construct very good primal solutions, and numerical results show that knowing these from the start improves the convergence of the column generation method significantly. We test our method on a central scheduling model based on the British National Grid and illustrate that convergence to within 0.1% of optimality can be achieved quickly.	algorithm;analysis of algorithms;approximation algorithm;cplex;central processing unit;column generation;computational complexity theory;computer cluster;dantzig–wolfe decomposition;dreamwidth;duality (optimization);feasible region;heuristic;heuristic (computer science);iteration;lp-type problem;lagrangian relaxation;linear programming relaxation;mathematical optimization;numerical analysis;optimization problem;parallel computing;population;scalability;scheduling (computing);solver;stochastic optimization;stochastic process	Tim Schulze;Andreas Grothey;K. I. M. McKinnon	2017	European Journal of Operational Research	10.1016/j.ejor.2017.02.005	column generation;stochastic programming;mathematical optimization;lagrangian relaxation;dantzig–wolfe decomposition;operations management;heuristics;mathematics;mathematical economics	ML	5.3910062191633354	3.6293771104977837	90504
770f436d9a0ae4e35e74fd7949897f171def79bb	effect of coordinated replenishment policies on quality	nuevo abastecimiento;logistique;costing;costo;administracion deposito;logistics;gestion stock;controle qualite;replenishment;quality control;inventory control;supply chain management;control calidad;reapprovisionnement;logistica;cout	Coordinated replenishment is a supply chain policy that affects many operational performance measures, including cost, lead time, and quality. In this paper, we develop a mathematical model of a simplified supply chain in which conformance quality is one of the supplier's decision variables and both the supplier and its customer are trying to minimize expected annual cost. Our expected cost model includes the important quality costs (appraisal, prevention, internal failure, and external failure) as well as holding, set-up, and ordering costs. Our results indicate that coordination leads to a decline in total cost but that coordination does not necessarily lead to an improvement in quality. In other words, buyers who are using coordinated replenishment may be trading higher quality for lower cost.		S. A. Starbird	2003	JORS	10.1057/palgrave.jors.2601476	inventory control;logistics;quality control;supply chain management;economics;input/output;total cost;marketing;operations management;activity-based costing;commerce	EDA	2.482702163421718	-6.075887538721912	90517
6c3a7a7ee80282030ce14dc9449f392dd24ea414	valuing the switching flexibility of the ethanol-gas flex fuel car	finance;renewable energy sources;fuel consumption;environmental concern;real options;real option;geometric brownian motion;flex fuel car;option value;fossil fuels;diffusion process	Renewable energy sources are becoming more important as the world’s supply of fossil fuels decrease and also due to environmental concerns. Since 2003, when the ethanolgasoline flex fuel car became commercially available in Brazil, the growth of this market has been significant, to the point where currently more than 50% of the fuel consumption of cars in Brazil is from renewable biofuels (ethanol). This has been made possible due to the success of the flex fuel car, which can run on ethanol, gasoline, or any mix of these in the same fuel tank, and which is sold at a premium over the non-flex models. Flex fuel cars, on the other hand, provide the owner with the flexibility to choose fuels at each refueling stop. Given the uncertainty on future prices of ethanol and gas, this option adds value to the owner since he can always opt for the cheaper fuel whenever he fills up his car. We use the Real Options method to analyze the value of the flex fuel option assuming both a Geometric Brownian Motion and Mean Reverting diffusion processes for the prices of gasoline and ethanol and compare the results arising from both methods. We conclude that the flex option value is significant using either method and twice as high as flex premium charged by the car manufacturers, which helps explain the success that this type of automobiles have gained in Brazil since 2003. Our results also indicate that consumers should be willing to purchase flex fuel cars even if manufacturers increase the flex premium.		Carlos Bastian-Pinto;Luiz E. Brandão;Mariana de Lemos Alves	2010	Annals OR	10.1007/s10479-009-0514-7	renewable energy;fossil fuel;operations management;diffusion process;mathematics;fuel efficiency;geometric brownian motion;statistics	ML	1.3631531520036138	-8.171959552093272	90543
62fa1ad2c3c3054efcf0caf1ef21cbf26d920ea1	the complexity of mixed multi-unit combinatorial auctions: tractability under structural and qualitative restrictions	mixed multi unit combinatorial auctions;structural decomposition methods;computational complexity	Mixed multi-unit combinatorial auctions (MMUCAs) are extensions of classical combinatorial auctions (CAs) where bidders trade transformations of goods rather than just sets of goods. Solving MMUCAs, i.e., determining the sequences of bids to be accepted by the auctioneer, is computationally intractable in general. However, differently from classical combinatorial auctions, little was known about whether polynomial-time solvable classes of MMUCAs can be singled out on the basis of their characteristics. The paper fills this gap, by studying the computational complexity of MMUCA instances under structural and qualitative restrictions, which characterize interactions among bidders and types of bids involved in the various transformations, respectively.		Valeria Fionda;Gianluigi Greco	2013	Artif. Intell.	10.1016/j.artint.2012.12.002	mathematical optimization;combinatorial auction;computer science;mathematics;mathematical economics;computational complexity theory	AI	-2.51773182685183	-0.6778506604132899	90569
20f94a6efefda03677cd90f755e74f120b32bcff	environmental policy regulation and corporate compliance in a spatial evolutionary game model		We use an evolutionary game model to study the interplay between corporate environmental compliance and enforcement promoted by the policy maker in a country facing a pollution trap, i.e., a scenario in which the vast majority of firms do not internalize their pollution negative externality and auditors do not inspect firms. The game conflict is due to the trade-off in which firms are better-off when they pollute and are not inspected, while social welfare is maximized when auditors do not need to inspect socially responsible corporations that account for pollution in their production decisions regarding technology used and emission level. Starting with a well-mixed two-population game model, there is no long-run equilibrium and the shares of polluters and shirking auditors keep oscillating over time. In contrast, when firms and auditors are allocated in a spatial network, the game displays a rich dynamics depending on the inspecting cost. While the oscillatory behaviour is still possible, there is a set of parameters for which a long run robust equilibrium is achieved with the country leaving the pollution trap. On the other hand, an excessively high inspection cost leads to an ineffective auditing process where the few compliant firms are driven out of the country.	spatial network	Gabriel Meyer Salomão;André Barreira da Silva Rocha	2018	CoRR		social responsibility;machine learning;industrial organization;externality;artificial intelligence;environmental compliance;enforcement;mathematics;pollution;audit;spatial network;social welfare	AI	-1.265197323641625	-8.082832117231884	90641
f45e546f63805c6941dcb96bc47ef475205a1b50	energy storage and regulation: an analysis	generators;contracts mathematical model batteries discharges electric planning generators;contracts;energy storage frequency regulation;batteries;mathematical model;secondary cells flywheels;discharges electric;multiple contract setting energy storage energy regulation electric system operator total system supply total system load regulation contractual framework regulation unit regulation signal charge evolution equations upward regulation parameters downward regulation parameters battery flywheel;planning	Electric system operators rely on regulation services to match the total system supply to the total system load in quasi real-time. The regulation contractual framework requires that a regulation unit declares its regulation parameters at the beginning of the contract, the operator guarantees that the regulation signals will be within the range of these parameters, and the regulation unit is rewarded proportionally to what it declares and what it supplies. We study how this service can be provided by a unit with a non-ideal storage. We consider two broad classes of storage technologies characterized by different state of charge evolution equations, namely batteries and flywheels. We first focus on a single contract, and obtain formulas for the upward and downward regulation parameters that a unit with either a battery or a flywheel should declare to the operator to maximize its reward. We then focus on a multiple contract setting and show how to analytically quantify the reward that such a unit could obtain in successive contracts. We quantify this reward using bounds and expectation, and compare our analytical results with those obtained from a dataset of real-world regulation signals. Finally, we provide engineering insights by comparing different storage technologies in terms of potential rewards for different contract durations and parameters.	load (computing);real-time transcription;state of charge;sysop	Dariush Fooladivanda;Catherine Rosenberg;Siddharth Garg	2016	IEEE Transactions on Smart Grid	10.1109/TSG.2015.2494841	planning;control engineering;mathematical optimization;simulation;engineering;electrical engineering;operations management;mathematical model;mathematics	AI	2.919617464358379	3.906547310397919	90781
a90efc0f825b6c5e247e3b4d15c2771485fc0a8f	"""modeling the """"pseudodeductible"""" in insurance claims decisions"""	bayes estimation;dirichlet process priors;duration model;owner;seguro;problema valor limite;dirichlet process prior;durabilite;dirichlet process;underreporting;customer lifetime value;stochastic process;analisis estadistico;bayesian statistics;boundary value problem;durabilidad;dirichlet problem;tiempo vida;market structure;inference mechanisms;segmentation;probabilistic approach;probleme dirichlet;estimacion bayes;lifetime;assurance;statistical analysis;durability;heterogeneidad;enfoque probabilista;approche probabiliste;propietario;problema dirichlet;analyse statistique;reclamation;inferencia;processus stochastique;protest;estructura mercado;proprietaire;duree vie;proceso estocastico;structure marche;reclamacion;market segmentation;probleme valeur limite;segmentacion;duration models;insurance;inference;insurance claims;heterogeneity;heterogeneite;semiparametric bayesian statistics;mecanisme inferentiel;estimation bayes	In many different managerial contexts, consumers “leave money on the table” by, for example, their failure to claim rebates, use available coupons, and so on. This project focuses on a related problem faced by homeowners who may be reluctant to file insurance claims despite the fact their losses are covered. We model this consumer decision by introducing the concept of the “pseudodeductible,” a latent threshold above the policy deductible that governs the homeowner’s claim behavior. In addition, we show how the observed number of claims can be modeled as the output of three stochastic processes that are separately, and in conjunction, managerially relevant: the rate at which losses occur, the size of each loss, and the choice of the individual to file or not file a claim. By allowing for the possibility of pseudodeductibles, one can sort out (and make accurate inferences about) these three processes. We test this model using a proprietary data set provided by State Farm, the largest underwriter of personal lines insurance in the United States. Using mixtures of Dirichlet processes to capture heterogeneity and the interplay among the three processes, we uncover several relevant “stories” that underlie the frequency and severity of claims. For instance, some customers have a small number of losses, but all are filed as claims, whereas others may experience many more losses, but are more selective about which claims they file. These stories explain several observed phenomena regarding the claims decisions that insurance customers make, and have broad implications for customer lifetime value and market segmentation.	money;stochastic process	Michael Braun;Peter S. Fader;Eric T. Bradlow;Howard Kunreuther	2006	Management Science	10.1287/mnsc.1060.0517	stochastic process;econometrics;customer lifetime value;economics;insurance;boundary value problem;marketing;operations management;heterogeneity;durability;market structure;bayesian statistics;segmentation;market segmentation;statistics	ML	4.6485142733945155	-9.37620517767331	90783
6de7e520e00c73266e21684a19360ad1ab66d052	distributed demand side management among foresighted decision makers in power networks	generators;cost function;iso;renewable energy sources;uncertainty;energy storage;iso energy storage generators uncertainty renewable energy sources cost function	We consider a power network with an independent system operator (ISO), and geographically distributed aggregators who have energy storage and purchase energy from the ISO to serve its customers. All the entities in the system are foresighted: each aggregator minimizes its own long-term payments for energy purchase and operational costs of energy storage by deciding how much energy to buy from the ISO, and the ISO minimizes the long-term total cost of the network (i.e. energy generation costs and aggregators' costs) by dispatching energy generation among the generators. The decision making of the foresighted entities is complicated because 1) the information required to make optimal decisions is decentralized among the entities, and 2) the coupling (through the prices) among the aggregators is complicated. We propose a design framework in which the ISO provides each aggregator with a conjectured future price, and each aggregator distributively minimizes its own long-term cost based on its conjectured price as well as its local information. The proposed framework can achieve the social optimum despite the decentralized information and complex coupling among the entities. Simulation results demonstrate significant reduction in the total cost by the proposed foresighted demand side management (DSM), compared to the optimal myopic DSM (up to 60% reduction), and the foresighted DSM based on the Lyapunov optimization framework (up to 30% reduction).	converge;coupling (computer programming);decision problem;entity;lyapunov fractal;lyapunov optimization;mathematical optimization;online algorithm;simulation;sysop	Yuanzhang Xiao;Mihaela van der Schaar	2013	2013 Asilomar Conference on Signals, Systems and Computers	10.1109/ACSSC.2013.6810521	operations management;microeconomics;business;commerce	Metrics	2.6732604469207932	4.131333478035116	90838
feb04180eeb2158d8fd3c3318e599bd2183740b0	optimal compensation and pay-performance sensitivity in a continuous-time principal-agent model	continuous time principal agent models;pay performance sensitivity;optimal concave contract;stochastic optimal effort	T paper studies the optimal contract between risk-neutral shareholders and a constant relative risk-aversion manager in a continuous-time model. Several interesting results are obtained. First, the optimal compensation is increasing but concave in output value if the manager is more risk averse than a log-utility manager. Second, when the manager has a log utility, a linear contract is optimal when there is no explicit lower bound on the compensation, and an option contract is optimal when there is an explicit lower bound. Third, optimal effort is stochastic (state dependent). Fourth, consistent with empirical findings and contrary to standard agency theory predictions, the relationship between pay-performance sensitivity and firm performance and that between pay-performance sensitivity and firm risk can be nonmonotonic.	concave function;isoelastic utility;parameter (computer programming);risk aversion	Nengjiu Ju;Xuhu Wan	2012	Management Science	10.1287/mnsc.1110.1417	financial economics;mathematical optimization;economics;operations management;microeconomics;welfare economics	Theory	-0.809481957378804	-6.975255238508961	90924
40b8dfa18902159127153416f12024a9940b908a	systematic integration of lca in process systems design: application to combined fuel and electricity production from lignocellulosic biomass	synthesis gas;economic optimization;energy conversion;multiobjective programming;programmation multiobjectif;proceso concepcion;gas;concepcion ingenieria;lignocellulosics;engineering design;ciclo desarrollo;rendement echelle;design process;biocarburant;life cycle;retorno de escala;conception ingenierie;termodinamica;concepcion optimal;fuel;conceptual analysis;conception optimale;lignocellulose;biomasse;prise de decision;economic model;impact environnement;plant;biofuels;analisis conceptual;return to scale;integration;superestructura;poligeneracion;preparacion serie fabricacion;gaz synthese;biofuel;process systems design;modelo economico;optimisation economique;natural gas;modele economique;combustible;synthetic natural gas;gas sintesis;integracion;system design;polygeneration;gas natural;biomass;cycle developpement;thermodynamique;optimal design;thermodynamics;optimization;process planning;optimizacion economica;biocarburante;conversion energie;analyse conceptuelle;biomasa;surstructure;conversion energetica;toma decision;superstructure;preparation gamme fabrication;life cycle assessment;impacto medio ambiente;gaz naturel;lignocelulosa;environment impact;processus conception;programacion multiobjetivo	This paper presents a methodology to integrate life cycle assessment (LCA)in thermoeconomic models used for the optimal conceptual design of energy conversion systems. It is illustrated by an application to a thermo-economic model developed for the multi-objective optimization of combined synthetic natural gas (SNG) and electricity production from lignocellulosic biomass. The life cycle inventory (LCI) is written as a function of the parameters of the thermo-economic model. In this way, the obtained environmental indicators from the life cycle impact assessment (LCIA) are calculated as a function of the decision variables of process design. The LCIA results obtained with the developed methodology are compared with the results obtained by a conventional LCA of the same process. Then, a multi-objective environomic (i.e. thermodynamic, economic, environmental) optimization of the process superstructure is performed. The results highlight the important effects of process configuration, integration, efficiency and scale on the environmental impacts.	liquid contact indicator;mathematical optimization;multi-objective optimization;process architecture;social network game;synthetic intelligence;systems design	Léda Gerber;Martin Gassner;François Maréchal	2011	Computers & Chemical Engineering	10.1016/j.compchemeng.2010.11.012	engineering;biofuel;thermodynamics;waste management;engineering design process	HCI	8.620835886199998	-4.437773288978973	90942
70abb971a3983b0d019fc841bbfda0c95ba13214	e-fair: aggregation in e-commerce for exploiting economies of scale		In recent years, many new and interesting models of successful online business have been developed, including competitive models such as auctions, where the product price tends to rise, and group-buying, where users cooperate obtaining a dynamic price that tends to go down. We propose the e-fair as a business model for social commerce, where both sellers and buyers are grouped to maximize benefits. e-Fairs extend the group-buying model aggregating demand and supply for price optimization as well as consolidating shipments and optimize withdrawals for guaranteeing additional savings. e-Fairs work upon multiple dimensions: time to aggregate buyers, their geographical distribution, price/quantity curves provided by sellers, and location of withdrawal points. We provide an analytical model for time and spatial optimization and simulate realistic scenarios using both real purchase data from an Italian marketplace and simulated ones. Experimental results demonstrate the potentials offered by e-fairs and show benefits for all the involved actors. Keywords—e-fair, assignment, transshipment, aggregation, optimization	aggregate data;e-commerce;electronic business;emoticon;ftc fair information practice;mathematical optimization;numerical analysis;preprocessor;programming paradigm;purchasing;requirement;simulation;social commerce	Pierluigi Gallo;Francesco Randazzo;Ignazio Gallo	2017	CoRR		common value auction;economies of scale;e-commerce;multiple time dimensions;price optimization;microeconomics;business model;supply and demand;economics	AI	-1.101195759978089	-4.654885768678684	91066
77b65a430dfc6264d9b995e208a9b4e2ea0146d6	explicit shading strategies for repeated truthful auctions		With the increasing use of auctions in online advertising, there has been a large eort to study seller revenue maximization, following Myerson’s seminal work, both theoretically and practically. We take the point of view of the buyer in classical auctions and ask the question of whether she has an incentive to shade her bid even in auctions that are reputed to be truthful, when aware of the revenue optimization mechanism. We show that in auctions such as the Myerson auction or a VCG with reserve price set as the monopoly price, the buyer who is aware of this information has indeed an incentive to shade. Intuitively, by selecting the revenue maximizing auction, the seller introduces a dependency on the buyers’ distributions in the choice of the auction. We study in depth the case of the Myerson auction and show that a symmetric equilibrium exists in which buyers shade non-linearly what would be their rst price bid. ey then end up with an expected payo that is equal to what they would get in a rst price auction with no reserve price. We also perform an extensive study of second price auctions and arrive at the same conclusion. We also propose a novel method to increase the welfare of the system at no cost to the seller, which does not require the buyer to know the distribution of values of the competition. We conclude that a return to simple rst or second price auctions with no reserve price or at least nondynamic anonymous ones is desirable from the point of view of both buyers, sellers, increasing transparency and social welfare.	entropy maximization;expectation–maximization algorithm;mathematical optimization;monopoly;online advertising;optimization mechanism;shading	Marc Abeille;Clément Calauzènes;Noureddine El Karoui;Thomas Nedelec;Vianney Perchet	2018	CoRR		common value auction;ask price;symmetric equilibrium;mathematics;mathematical economics;reservation price;stochastic game;revenue;incentive;microeconomics;monopoly price	ECom	-2.7444776017720476	-2.1837516752100825	91090
95471f37df3d5688b29108ebb4ea9294340319bd	optimal scheduling policies for a production service system with two items	capacity allocation;markov decision process;optimal control;production service system	In this paper, we address the capacity allocation rules for a flexible production service system consisting of one flexible manufacturing facility and one service centre. The manufacturing facility produces two items in the first stage and the service centre serves two customers in the second stage. Each order served by the service centre depletes one unit of dedicated item produced by the manufacturing facility. The manager must make production and service capacity allocation decisions. The objective is to find an effective production and service scheduling rule to minimize the expected total cost over an infinite horizon. The service capacity allocation problem is formulated as a Markov decision process and use this formulation to characterize the structure of the optimal service allocation policy. We show that the optimal service scheduling policy is an extension of the well-known optimal service scheduling policy for classical service system. Then the characteristics of the optimal production policy are studied numerically since the analytic characteristics are not available.	heuristic (computer science);markov chain;markov decision process;memory management;numerical analysis;numerical method;row echelon form;schedule (project management);scheduling (computing);whole earth 'lectronic link	Kangzhou Wang;Zhibin Jiang;Wenming Xie	2013		10.3182/20130619-3-RU-3018.00071	service level requirement;simulation;service product management;operations management;business;commerce	Metrics	4.610651189387095	-0.30086667771085385	91109
d9fd0300bf59406078cbde6b3f62fba391af3ce4	activity-based life cycle cost analysis as an alternative to conventional lcc in engineering design		Petroleum exploration and production in the Arctic region is becoming of increasing interest as the world needs more energy. However, since there is little experience and data on Arctic oil and gas production, the design of production facilities and equipment to be used in the Arctic region is fraught with high cost and risk. Conventional life cycle costing (LCC) approaches have been discussed in literature for many years, but it is difficult to perform such analysis due to the need for a large amount of data and the inherent uncertainty in the results. There is also little evidence in the literature on the practical usage of LCC. In this paper we discuss the differences between conventional LCC and activity-based LCC (AB-LCC) cost systems. Moreover, based on an analytical comparison between the two methodologies we find that the AB-LCC methodology may be a better alternative to use for cost analysis in the design of production facilities to be used in unfamiliar environments such as the Arctic. A simple example is used to demonstrate the differences between conventional LCC and AB-LCC analysis.	causality;engineering design process;overhead (computing)	Dina Kayrbekova;Tore Markeset;Behzad Ghodrati	2011	Int. J. Systems Assurance Engineering and Management	10.1007/s13198-011-0064-7	engineering;operations management;operations research	HCI	7.433488478974531	-6.574110124592093	91186
a48a8dfc3e1286ba9ac1a8456917965c89f63cb6	a dollar for your thoughts: feedback-conditional rebates on ebay	grupo de excelencia;rebates;field experiment;feedback;administracion de empresas;期刊论文;feedback rebates experiment;experiment;economia y empresa;grupo a;working paper	We run a series of controlled field experiments on eBay where buyers are rewarded for providing feedback. Our results suggest that the feedback rate increases when a rebate is given, though the effect is small. Moreover, the nature of buyer feedback is influenced by rewards: buyers are more likely to give positive feedback following a high-quality transaction (fast shipping) and less likely to give negative feedback following a lowquality transaction (slow shipping). In sum, you can buy feedback but you cannot buy unbiased feedback.	experiment;negative feedback;positive feedback	Luís Cabral;Lingfang Li	2015	Management Science	10.1287/mnsc.2014.2074	experiment;field experiment;economics;marketing;operations management;feedback;microeconomics;advertising;management;statistics	Web+IR	-3.270198480010415	-7.60846113075547	91565
ba7218223f7854116cbc63a26c9172cbee621a9c	wholesale-retail pricing strategies under market risk and uncertain demand in supply chain using evolutionary game theory		PurposernrnrnrnrnNowadays, uncertainty in market demand poses considerable risk to the retailers that supply the market. On the other hand, the risk-averse behaviors of retailers toward risk may have evolved over time. Considering a supply chain including a manufacturer and a population of retailers, the authors intend to investigate how the population of retailers tends to evolve toward risk-averse behavior. Moreover, this study aims to evaluate the effects of wholesale-retail price of manufacturer on evolutionary stable strategy (ESS) of the retailers.rnrnrnrnrnDesign/methodology/approachrnrnrnrnrnDue to market uncertainty, a supply chain with a population of risk-averse and risk-neutral retailers was investigated. The wholesale pricing strategy is determined by a manufacturer acting as a leader, while retailers who make order quantity decisions act as followers. An integrated Cournot duopoly equilibrium and evolutionary game theory (EGT) approach has been used to model this situation.rnrnrnrnrnFindingsrnrnrnrnrnA numerical real-world case study using Iran Khodro Company is analyzed by applying the proposed EGT approach. The study provides managerial insights to the manufacturer as well as retailers in developing their strategies. Results showed that risk behavior of retailers significantly affects optimal wholesale/retail price, profits and ESS. In the long term, the retailers tend to have a risk-neutral behavior to gain more profit. In the short term, if a retailer choses risk-averse strategy, in the long term, it will change its strategy to obtain more profit and remain in the competitive market.rnrnrnrnrnOriginality/valuernrnrnrnrnThe contributions in this research are fourfold. First, ESS concept to investigate the risk-averse or risk-neutral attitudes of the retailers was used. Second, the uncertain risk behavior of the competing retailers was considered. Third, the effect of varying wholesale pricing was investigated. Fourth, the equilibrium wholesale and retail prices have been obtained by considering uncertainty demand and risk.	game theory	Ashkan Hafezalkotob;Reza Mahmoudi;Elham Hajisami;Hui-Ming Wee	2018	Kybernetes	10.1108/K-02-2017-0053	mathematical optimization;cournot competition;supply chain;market risk;computer science;pricing strategies;perfect competition;microeconomics;supply and demand;population;risk neutral	ECom	-2.090109973334269	-6.012378946964713	91909
1cbe7bc2607c99c4fccff0719ecd2e2fb7eb963c	improving project cost estimation by taking into account managerial flexibility	project management;project manager;time cost trade off;stochastic dynamics;cost estimation;stochastic dynamic scheduling	Project costs tend to be higher than depicted by budgets. Irrespective of the quality of the project management, this indicates that the budgets are not established in a way which is consistent with how projects are run. Good budgets should on average lead to zero cost overruns. The purpose of this paper is to discuss how project costs (if they are based on models) can be better estimated by taking into account how projects are actually run, in particular, how managerial flexibility adds value to a project. The purpose is not to advocate better ways of running a project, but to obtain better estimates of what projects cost, given the way they are run.		Trond Jørgensen;Stein W. Wallace	2000	European Journal of Operational Research	10.1016/S0377-2217(99)00484-1	level of effort;basis of estimate;project management;cost contingency;simulation;actuarial science;economics;operations management;cost engineering;project management triangle;cost estimate;project portfolio management	Robotics	4.139750416146336	-7.120386712145778	91954
adfb35291814ae91d66cf13b1de1acfd8ffd9d8f	towards scalable optimal traffic control	measurement;trajectory;roads;roads vehicles optimization mathematical model measurement trajectory vehicle dynamics;mathematical model;optimization;vehicles;vehicle dynamics;decentralized suboptimal algorithm scalable optimal traffic light control urban traffic networks traffic demands duty cycle phase shifts global optimization problem mixed integer linear program centralized approach;suboptimal control centralised control integer programming linear programming road traffic control	This paper deals with scalable control of traffic lights in urban traffic networks. Optimization is done in real time, so as to take into account variable traffic demands. At each cycle of the traffic lights, the optimization concerns time instants where each traffic light starts and ends its green phase: this allows to describe both the duty-cycle and the phase shifts. First, we formulate a global optimization problem, which can be cast as a mixed-integer linear program. To overcome the complexity of this centralized approach, we also propose a decentralized suboptimal algorithm, whose simplicity allows online implementation. Simulations show the effectiveness of the proposed strategies.		Pietro Grandinetti;Federica Garin;Carlos Canudas de Wit	2015	2015 54th IEEE Conference on Decision and Control (CDC)	10.1109/CDC.2015.7402529	control engineering;vehicle dynamics;simulation;engineering;trajectory;mathematical model;mathematics;transport engineering;measurement;statistics	Vision	7.141639288588182	3.4468453279216	92255
70261007d0b299bfde1d1accbf028c1a1fbe80e2	rank-dependent utility and risk taking in complete markets		We analyze the portfolio choice problem of investors who maximize rankdependent utility in a single-period complete market. We propose a new notion of less risk taking: choosing optimal terminal wealth that pays off more in bad states and less in good states of the economy. We prove that investors with a less risk averse preference relation in general choose more risky terminal wealth, receiving a risk premium in return for accepting conditional-zero-mean We thank Shigeo Kusuoka, Christoph Kuzmics, Peter Wakker, seminar participants at Oxford, as well as conference participants at the 2014 Econometric Society European Meeting in Toulouse, the 2014 INFORMS Annual Meeting in San Francisco, the 2014 SIAM Conference on Financial Mathematics and Engineering in Chicago, the Fourth IMS Finance, Probability and Statistics Workshop in Sydney, the Seventh International Symposium on Backward Stochastic Differential Equations in Weihai, the 2014 International Conference on Portfolio Selection and Asset Pricing in Kyoto, the 2014 CUHK Symposium in Financial Risk Management in Hong Kong, the 2014 Big Data and Quantitative Behavioral Finance Conference in Nanjing. He acknowledges financial support from a start-up fund at Columbia University. Zhou acknowledges financial support from a start-up fund at the University of Oxford, a research fund from the Oxford-Man Institute of Quantitative Finance, and a research fund from East China Normal University. Corresponding Author. Department of Industrial Engineering and Operations Research, Columbia University, Room 315, Mudd Building, 500 W. 120th Street, New York, NY 10027, US. Email: xh2140@columbia.edu. Telephone: +1-212-854-2936. Mahidol University, College of Management, Bangkok, Thailand; Erasmus University Rotterdam, Erasmus School of Economics, Rotterdam, The Netherlands; Email: roy.kou@mahidol.ac.th. Mathematical Institute, The University of Oxford, Woodstock Road, OX2 6GG Oxford, UK, and Oxford–Man Institute of Quantitative Finance, The University of Oxford; Email: zhouxy@maths.ox.ac.uk.	big data;columbia (supercomputer);email;industrial engineering;institute for operations research and the management sciences;like button;risk aversion;risk management	Xue Dong He;Roy Kouwenberg;Xun Yu Zhou	2017	SIAM J. Financial Math.	10.1137/16M1072516	financial economics;actuarial science;risk aversion;economics;finance;risk premium;spectral risk measure;complete market;time consistency;financial risk management	Embedded	0.5017366170022289	0.5003464892632521	92299
2b9e979585cfffc4422a99b5f860da707e57db1b	toward a large scale e-market: a greedy and local search based winner determination	approximate algorithm;multi agent system;e commerce;electronic markets;large scale;e commerce and multi agent systems;local search;combinatorial auction	Combinatorial auction is one of the most popular market mechanisms and it has a huge effect on electronic markets and political strategies. On large scale e-markets, we need a good approximation algorithm for winner determination that is robust for changing the distribution and the number of bids in an auction. We proposed approximate algorithms for combinatorial auctions with massively large number of (more than 100,000) bids. In this paper, we show the robustness of our winner determination algorithms for combinatorial auctions with large number of bids. Experimental results demonstrate that our proposed algorithms are robust on changing the distribution and the number of bids in an auction. Finally, we shortly describe a theoretical limitation about our algorithms that concerns with giving truthfulness of the auction mechanism.	greedy algorithm;local search (optimization)	Naoki Fukuta;Takayuki Ito	2007		10.1007/978-3-540-73325-6_35	e-commerce;auction algorithm;mathematical optimization;combinatorial auction;computer science;local search;multi-agent system;revenue equivalence;auction theory	AI	-0.588246755256105	1.1796927207974341	92376
33c8f997b9c20d8e84f83e4a4cbdb349611f0b7d	estimating conjectural variations for electricity market models	modelizacion;mercado oligopolistico;ajustamiento modelo;equilibre marche;game theory;market equilibrium;reseau electrique;generation scheduling;electrical network;red electrica;variation parametre;marche oligopolistique;teoria juego;equilibrio mercado;inference mechanisms;theorie jeu;equilibrium models;time series;variacion parametro;electricity market;statistical model;scenario;ajustement modele;modelisation;ciencias economicas;argumento;scheduling;model matching;parameter variation;script;serie temporelle;inferencia;modele statistique;serie temporal;modelo estadistico;sciences economiques;electric power;economics;modeling;ordonnancement;inference;oligopolistic market;reglamento;mecanisme inferentiel;time series model	Agents’ behavior in oligopolistic markets has traditionally been represented by equilibrium models. Recently, several approaches based on conjectural variations equilibrium models have been proposed for representing agents’ behavior in electrical power markets. These models provide insight of market equilibrium sensitivity to agents’ strategies and external variables, and therefore, they are widely applied. Unfortunately, not enough analysis has been done in how these user-supplied parameters, the conjectural variations, should be estimated. This paper proposes a parameter inference procedure based on two stages. The first stage infers historical values of the parameter by fitting the models’ results to historical market data. The second stage is based on a statistical time-series model whose objective is to forecast parameter values in future scenarios. Additionally, results of this procedure’s application to a real-size case are presented.		S. López de Haro;P. Sánchez Martín;J. E. de la Hoz Ardiz;J. Fernández Caro	2007	European Journal of Operational Research	10.1016/j.ejor.2005.12.039	game theory;economics;artificial intelligence;time series;mathematics;operations research;statistics	Vision	5.213967881006313	-9.380159366398146	92411
989b282170782c401a0da60fc87955b6b10ab799	integrated controlling technology on regional agriculture water resources	regional agriculture water resources;economic benefit;water resource;optimisation;crop subsystem;irrigation;agriculture water resources irrigation resource management water storage reservoirs humans crops water conservation sea surface;water resources;resource management;biological system modeling;water resources irrigation optimisation;water allocation;allocation optimization regional agriculture water resources integrated controlling technology crop subsystem dynamic planning model water irrigation linear planning model water allocation chinese national programs;research and development;optimization of allocation;surface water;chinese national programs;allocation optimization;linear planning model;mathematical model;water irrigation;application agriculture water resource optimization of allocation;agriculture water resource;economics;application;ground water;dynamic planning model;integrated controlling technology	With the severe shortage of agricultural water resources, the model of integrated controlling surface water and ground water has been designed based on the greatest economic benefit. In terms of the crop subsystem, the dynamic planning model was designed in the condition of single crop irrigated inadequately, based on the function between crops and water irrigation. As for the whole region, linear planning model was designed between different kinds of crops on the water allocation. This model was verified by Chinese national programs for high technology research and development (national 863 project) demonstration area in Weihai, Shandong province.		Zhenghe Xu;Xiuru Wang	2009		10.1109/ESIAT.2009.140	water conservation;water resources;surface water;groundwater;water resource management;hydrology;resource management;mathematical model;irrigation;agronomy	HCI	6.416778329138171	-8.421356381937986	92519
b6d2b46e590931bb380a72b663866c01869e1f11	optimal periodic run quantities for a set of cells under joint setup	group technology;efficient algorithm;point process;random variables;production process;production group technology manufacturing stochastic processes costs random variables;setup time;stochastic processes;manufacturing;production;structural properties	"""cell is capable of producing a specific type of part family and periodically a joint setup is Considered is a sct of manufacturing cells that are jointly setup for production. Each performed at each of these cells for production. We model the production process of each cell by a selkxciting point process. Using some structural properties of th is process, an ellicient algorithm is developed to obtain the optimal run quantity and the inter-setup time. I . IN'I'ROI>UCTION we consider a set of manufacturing cells which undergoes a periodic (say. every T units of time) joint setup for production. Each cell is capable of producing a specific type of Part family. The purpose of this paper is to obtain optimal run quantity for each cell and the optimal inter-setup time T. The above problem with a given inter-setup time T is studied in Yao and Shanthikumar (1986). where the production process of each cell is modelled as a birth process with statedependent (but time-independent or stationary) birth rates. A stochastic convexity property of the production process is identified, thereby it is shown that he marginal allocation procedure (which is a greedy type of algorithm) will generate the optimal run quantities. In this paper we extend the above results in two way: (i) in addition to the run quantities, the inter-setup time T is also treated as a decision variable and (ii) the production proeess is modelled as a sel6exciting point process, Under very reasonable conditions it is shown that the stochastic convexity property of the birth process is inherited by the self-exciting point process. Therefore. even in this general case, the marginal allocation will generate the optimal run quantities, given the inter-setup time. It is also shown that these optimal run quantities are increasing in the given inter-setup time, due to a supermodularity property of the objective function. This and other structural properties of the objective function lead to an ellicient iterative procedurc for solving this optimal periodic allocation problem. The organization of the paper is as follows: Section 2 gives a precise formulation of the allocation problem. Section 3 elaborates on modelling the production process of each cell as a point process. Key properties of this process are identified in Section 4 ( p o r e m s I and 2). Based on thcse, properties of the objective function are established (Proposition I through 4). and an iterative procedure is developed to generate the optimal solution (Section S). 2. PROBI.EM PORWUIATION Consider a set (1, ._. , M) of M cells. Every T units of time a joint setup is performed for these M cells: xi parts are then allocated to cell i ( i = I , .-, M) to be processed: xi will be refcrred to as the """"run quantity"""" for cell i. Without loss of generality we assume that each cell starts empty (a positive initial quantity can be accommodated by a simple shifi J. George Shanthikumar School of Business Administration University of California Berkeley, CA 94720 of the variable x i ) . The numbcr of part completions (departures) from cell i over the time period IO, 11 , given the allocated run quantity 4, is a random variable, denoted by &(xi, r ) . The production process of each cell will be modelled as a point process (we defer discussion on this modelling approach until the next section). For each completed part from cell i. thcre is a profit (value added) ui . The setup cost for cell i is ci(x,), where ci(x,) is supposed to be increasing and convex in x,. (In this paper we use 'increasingjdecreasing', """"convexl concave"""" in the non-strict sense.) In addition we assume that there is also a cost bi for holding one unit of work-in-process (WIP) inventory in cell i for one unit of time. The optimization problem is to maximize the total expected net profit per unit time. That is (PI) Max F(z. 7) = $ ,$ { a i E [ D i ( q , V I 41: E [ ~ ( x i , 7)Idt) , 1 1 where iV,(xi, T) =xi Di(xi, r) is the WIP inventory in cell i at time -. and the decision variahlcs arc: the inter-setup time 7' and the N n quantities _x = ( x i ) s l . Various constraints can also bc added to (PI). For instance production requirement (upper and lower bounds on E[Di(xi. T)]). capacity constraint (upper bound on xi ) . constraint on the inter-retup time, and so forth. In order not to distract from the major theme of the paper, we focus on (PI) without constraints, and refer the interested reader to Yao and Shanthikumar (1986) for models that incorporate some of these constraints. 3. MOI>EI.LING TlIE PRODUCTION PROCESS llere we focus on a specific cell and omit the cell index (Le.. subscript i ) . Following standard notations. we rewrite the stochastic process o(x, I) (i.c. the number of pan completions from a cell during [O, I ] , given the run quantity at time zem is x ) as ( 4 ) . The production proccss of the cell will be modelled as a general self-exciting point process (Snyder 1975. Chaptcr 5). whose intensity process ( y I ) can depend on both the counting process (Dl) and the occurrence times (i.e., completion times of the parts) of the history up to time r : r, = y,(D1 ; q. ... I '4) . (1) Note that the above model is completely general for any practical purposes, For instance, thcre arc no '""""Markovian' or """"steady-state"""" assumptions involved. Let I , = E l y , 1 Dl] he the conditional intensity and A,@) E[Y , ID, = nl *Supported in part by an NSF grant DMC-8503896 and an ONR grant N00014-84-K-0465 71 I CH2413-3/87/0000/0711$01.00"""	artificial intelligence;concave function;convex function;database transaction;flip-flop (electronics);greedy algorithm;ibm notes;iterative method;marginal model;mathematical optimization;optimization problem;point process;rewrite (programming);stationary process;steady state;stochastic process;strict function;supermodular function;yao graph	David D. Yao;J. George Shanthikumar	1987		10.1109/ROBOT.1987.1087948	random variable;stochastic process;mathematical optimization;engineering;point process;scheduling;manufacturing;statistics;manufacturing engineering	ML	4.520480476640702	-1.0763559288709688	92562
fc47efba6d0d77579c0c8251dcf43a64841bffe7	fault diagnosis of manufacturing systems using continuous petri nets	manufacturing systems;discrete event system;fault detection;fault detection fault diagnosis manufacturing system petri nets;discrete event systems;manufacturing systems discrete event systems petri nets fault diagnosis;petri nets;copper;petri net;manufacturing system;petri nets fault diagnosis manufacturing systems;fault diagnosis	This paper deals with fault detection of manufacturing systems modeled by Petri nets. We show that the theoretical results obtained for continuous Petri nets allow us to treat with systems that are intractable using the theory developed for discrete Petri nets. In particular systems in which the unobservable part contains cycles can be studied. On the other hand, only three diagnosis states can be defined making impossible the splitting of the uncertain state into two different states, to obtain different degrees alarm for the uncertainty.	fault detection and isolation;petri net	Maria Paola Cabasino;Carla Seatzu;Cristian Mahulea;Manuel Silva Suárez	2010	2010 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2010.5642021	real-time computing;stochastic petri net;computer science;process architecture;petri net	Robotics	6.757142523015867	0.45447344632520076	92650
a5f86dfab72b9a996a9d08c44ca638f96c63851e	analytical model of adoption of item level rfid in a two-echelon supply chain with shelf-space and price-dependent demand	economic benefit;supply chain contracts;item level rfid;shelf space management;decision maker;supply chain;profitability;analytical model	We investigate whether it is possible for the manufacturer as well as the retailer to derive economic benefits from item-level RFID. We consider a particular model of shelf-space and price-dependent retail demand and two configurations of the supply chain. In both instances the interaction between the supplier and the retailer is via a wholesale price contract. In one case it is the supplier who sets a linear wholesale tariff on the finished goods. In another case both retail and wholesale prices are set exogenously, and the supplier must pay the retailer for shelf-space so that the retailer will carry the supplier's product. We find that in both cases when the supplier benefits from item-level RFID so does the retailer. However when the supplier sets the wholesale price the interests of the supplier and the retailer are aligned if the retailer benefits from item-level RFID then so does the supplier and vice versa. On the other hand if wholesale prices are set exogenously, and the supplier is able to command payment for shelf-space it is possible for the interests not to be aligned: the retailer may be benefiting from RFID technology as the supplier is losing money.	radio-frequency identification;row echelon form	Joseph G. Szmerekovsky;Vera Tilson;Jiang Zhang	2010	2010 43rd Hawaii International Conference on System Sciences	10.1016/j.dss.2011.02.002	decision-making;marketing;operations management;supply chain;commerce;profitability index	DB	-0.017626778866133834	-6.424627239059372	92773
c275fff67509f078155b8bb1e9631cc33041fc87	integrated inventory routing and freight consolidation for perishable goods		Abstract We propose a model that integrates inventory routing and freight consolidation for perishable goods with a fixed lifetime. The problem is motivated by the status quo of logistics in some U.S. agriculture markets, but adapts to other relevant two-echelon supply chains, e.g. combined production planning and distribution. We first identify special cases where solving single-echelon subproblems sequentially yields an asymptotically optimal solution. For the general case, we propose an iterative framework that consists of a decomposition procedure and a local search scheme. In the decomposition, a freight consolidation subproblem is first solved to obtain crucial shipping decisions, and after fixing these a restrictive model generates the other decisions for the integrated problem. The local search aims at fast identification of good neighborhoods by solving an assignment-style mixed-integer program that matches the consolidation decision with an inventory routing subproblem, and gradually strengthens the incumbent solution pool when executed in an iterative fashion. Experiments based on empirical demand distributions demonstrate that our proposed iterative framework is quite efficient compared to a sequential approach, and that it effectively solves challenging instances.	routing;semiconductor consolidation	Weihong Hu;Alejandro Toriello;Maged Dessouky	2018	European Journal of Operational Research	10.1016/j.ejor.2018.05.034	mathematical optimization;asymptotically optimal algorithm;operations management;production planning;mathematics;local search (optimization);consolidation (soil);supply chain	Theory	9.895852848968884	-2.8505119618647377	92838
862a5736a8a225c502525d3b4d68d68e0ba53366	optimal performance-based building facility management	modelizacion;evaluation performance;probability;performance evaluation;gestion optima;equipo edificio;hierarchized structure;evaluacion prestacion;decision markov;structure hierarchisee;modelisation;programacion lineal;probabilidad;probabilite;linear programming;programmation lineaire;managerial optimization;building equipment;ejemplo;markov decision;equipement bâtiment;gestion optimale;modeling;example;facility management;estructura jerarquizada;exemple	It is a great challenge to efficiently manage and operate the facilities of a set of buildings, which are of different structural types, ages, and locations and serve for different functions required by different users, over a long-term planning horizon using limited resources to achieve multiple and often conflicting objectives. This article proposes an optimization system for the management of facilities in a set of buildings. First, a systemic approach is taken to standardize the various kinds of facilities in the set of buildings into a hierarchical structure, the condition states of these facilities into a state space, and the alternative management actions on different facilities in different condition states into an action set. Second, infinite- and finite-time linear programming models are formulated to maximize the long-term performance of the set of buildings subject to a number of technical and economic constraints. Third, life-cycle management policies are established for both infinite- and finite-time planning horizons. Finally, an illustrative example is provided to discuss the application and usefulness of the proposed optimization system for facility management in a set of buildings.		Xueqing Zhang;Hui Gao	2010	Comp.-Aided Civil and Infrastruct. Engineering	10.1111/j.1467-8667.2009.00633.x	mathematical optimization;simulation;systems modeling;engineering;linear programming;probability;mathematics;facility management;management;operations research;statistics	DB	6.167844935938597	-3.6048771318271977	92954
022deda57c17f010b2532230c25176727f07bcdc	an inventory model for imperfect items under inflationary conditions with considering inspection errors	inspection error;inventory;inflation;imperfect items	This paper represents a discounted cash-flow approach for an inventory model for imperfect items under inflationary conditions with considering inspection errors. The previous imperfect quality inventory studies, however, have mostly had the emphasis on developing cost-minimizing models that do not consider imperfect inspection processes and related defect sales return issues despite their practical significance. In this paper, we assume that some produced items might not be perfect and the first stage inspector of product quality control might make some inspection errors during the separation of defective and perfect items. Thus, this study proposes a profit maximizing inventory model with incorporating both imperfect production quality and two-way imperfect inspection, i.e., Type-one inspection error of falsely screening out a proportion of no defects and disposing of them like defects and Type-two inspection error of falsely not screening out a proportion of defects, thereby passing them on to customers, resulting in defect sales returns. In addition, this model includes one more stage of inspection that is after the rework process and there is no inspection error in this stage. The purpose of this model is to determine the important factors of an inventory system to optimize the present value of the total profit in the finite time horizon. Finally, a numerical example is provided to solve the presented inventory model using our proposed innovative approach, which is further clarified through a sensitivity analysis.	inventory theory	Javad Taheri-Tolgari;Abolfazl Mirzazadeh;Fariborz Jolai	2012	Computers & Mathematics with Applications	10.1016/j.camwa.2011.09.050	inflation;actuarial science;inventory;cycle count	NLP	2.6701008132857535	-5.5252733835118955	93070
053b77f5faf3c9ee2d0acd0cd35fbcb3146538c9	frugal path mechanisms	truthful mechanism design;game theory;overpayment;vickrey clarke groves;satisfiability;dominant strategies;vickrey clarke groves mechanism;mechanism design;large classes	We consider the problem of selecting a low cost s --- t path in a graph, where the edge costs are a secret known only to the various economic agents who own them. To solve this problem, Nisan and Ronen applied the celebrated Vickrey-Clarke-Groves (VCG) mechanism, which pays a premium to induce edges to reveal their costs truthfully. We observe that this premium can be unacceptably high. There are simple instances where the mechanism pays Θ(k) times the actual cost of the path, even if there is alternate path available that costs only (1 + ε) times as much. This inspires the frugal path problem, which is to design a mechanism that selects a path and induces truthful cost revelation without paying such a high premium.This paper contributes negative results on the frugal path problem. On two large classes of graphs, including ones having three node-disjoint s - t paths, we prove that no reasonable mechanism can always avoid paying a high premium to induce truthtelling. In particular, we introduce a general class of min function mechanisms, and show that all min function mechanisms can be forced to overpay just as badly VCG. On the other hand, we prove that (on two large classes of graphs) every truthful mechanism satisfying some reasonable properties is a min function mechanism.	edmund m. clarke;emoticon;graph (discrete mathematics);maxima and minima;selection algorithm	Aaron Archer;Éva Tardos	2002		10.1145/1186810.1186813	mechanism design;game theory;mathematical optimization;combinatorics;mathematics;mathematical economics;algorithm;satisfiability	ECom	-3.8655092858951425	0.4532246125818175	93107
980ab5deee15a90bd3b341bba0ae02044236c7f8	price competition in spectrum markets: how accurate is the continuous prices approximation?	nash equilibrium;pricing;resource management;wireless communication;games;bandwidth;dynamic spectrum access	Dynamic Spectrum Access technology enables two types of users to operate on a channel- primary users, which have prioritized access to the channel and secondary users, which can use the channel when it is not in use by the primaries. We consider a scenario in which multiple primaries own bandwidth in a large region (e.g., a state), which is divided into smaller locations (e.g., towns). A primary that has unused bandwidth in a time slot would like to lease it out to secondaries at a set of mutually non-interfering locations in return for a fee. This results in price competition among the primaries. In prior work, this price competition has only been studied under the approximation, made for analytical tractability, that the price of each primary takes values from a continuous set. However, in practice, the set of available prices is discrete. In this paper, we investigate the fundamental question of how the behaviour of the players involved in the price competition changes when this continuity assumption is removed. Our analysis reveals several important differences between the games with continuous and discrete price sets. For example, in the game at a single location, no pure strategy Nash equilibrium (NE) exists in the game with continuous price sets, whereas a pure strategy NE may exist in the game with discrete price sets. Also, multiple symmetric NE exist in the game with discrete price sets in contrast to the game with continuous price sets, where a unique NE exists. However, we show that as the number of available prices becomes large in the discrete prices game, the strategies of the primaries under every symmetric NE converge to the unique NE strategy of the game with continuous price sets.	approximation;bandwidth (signal processing);converge;nash equilibrium;scott continuity;towns	Aditya Mvs;Abhishek Raghuvanshi;Gaurav S. Kasbekar	2016	2016 IEEE 84th Vehicular Technology Conference (VTC-Fall)	10.1109/VTCFall.2016.7881175	price of stability;pricing;games;limit price;computer science;resource management;repeated game;mathematical economics;bandwidth;reservation price;price of anarchy;nash equilibrium;wireless	Theory	-1.5820313469953988	-3.0176963022314216	93475
666686df4b7b49071eca65bf9a8d67e850cb5a06	optimal control for congestion pricing: theory, simulation, and evaluation	pricing;saturation function;optimal control;logit;roads;saturation function optimal control congestion pricing logit chattering;chattering;mathematical model;pricing roads optimal control mathematical model vehicle dynamics vehicles;vehicles;vehicle dynamics;congestion pricing	This paper presents a mathematical framework for dynamic congestion pricing. The objective is to calculate an optimal toll using the optimal control theory. The problem consists of tolled lanes or routes and alternate non-tolled lanes or routes. The model is developed using a traffic conservation law, the queuing theory, and fundamental macroscopic relationships. A logit model is used for establishing the relationship between the price and the driver's choice behavior. We design a cost function and then use Hamilton–Jacobi–Bellman equation to derive an optimal control law that uses real-time information to determine an optimal tolling price. Simulations are performed to demonstrate the performance of this optimal control congestion-pricing algorithm.	algorithm;bellman equation;computer simulation;control theory;hamilton–jacobi–bellman equation;jacobi method;logistic regression;loss function;network congestion;optimal control;queueing theory;real-time clock;real-time data	Pushkin Kachroo;Saumya Gupta;Shaurya Agarwal;Kaan Ozbay	2017	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2016.2601245	congestion pricing;pricing;vehicle dynamics;simulation;optimal control;mathematical model;mathematics;mathematical economics;logit;statistics	Metrics	8.721865091401787	-9.150871739129041	93479
ae9102788744590937f050cd0d1d606e6ec0b5f6	cutting in line: social norms in queues	social norms;group decisions;games;queues	While the norm in many retail banks is to serve customers on a first-come-first-served basis, some customers try to cut the line, usually by providing an excuse for their urgency. In other queues, however, this behavior is considered unacceptable and is aggressively banned. In all of these cases, customer exhibit strategies that have not yet been explored in the operations literature: they choose whether or not to cut the line and must also decide whether to accept or reject such intrusions by others. This paper derives conditions for the emergence of such behavior in equilibrium among the customers themselves, i.e. when the queue manager is not involved in granting priorities and the customers have to use community enforcement to sustain such equilibria.	emergence;norm (social);schedule	Gad Allon;Eran Hanany	2012	Management Science	10.1287/mnsc.1110.1438	games;marketing;operations management;advertising;management;operations research;queue;norm	ECom	-3.915499991784701	-6.180152533478165	93512
c94f0fbf3e13989df805591840bcc5cbb812a5ff	it portfolio management: a case study	it portfolio management	IT Portfolio Management is increasingly becoming an important topic of research in IS/IT. The number of IT projects in a company can number in the hundreds, and it is difficult for upper level executives to manage this portfolio effectively without using some guiding methodology. This paper focuses on one such methodology that is being developed by a Fortune 100 company. Although many excellent papers have discussed using Real Options in the valuation of IT, there has been relatively little work in using Real Options in the IT Portfolio management context. Furthermore, most of the papers in the main IS journals have used relatively simple option models to evaluate (1) a single investment decision (2) assuming independence between projects. The focus of this paper is on a company that is actually managing IT portfolios of projects, and on some issues that may make exotic option models and more appropriate valuation tools.		John C. Burke;Michael J. Shaw	2008			application portfolio management;post-modern portfolio theory;management science;computer science;exotic option;replicating portfolio;portfolio optimization;finance;it portfolio management;black–litterman model;portfolio	AI	4.4132961701459354	-7.1732965808860465	93530
ffa3d2d78465ad066a82e4a9a2ed480d3faec2e0	spatial-temporal analysis of recent air passenger flows		Airline mergers and acquisitions (MAs) are on the rise across the globe and have been a growing trend in the U.S. aviation industry in the last few years. MAs are taking several factors into consideration, such as cost efficiency, competition, and geographic coverage. For airlines, these transactions can eliminate overlapping routes and help reduce competition, leading airlines to achieve higher operating margins. For travelers, MAs often lead to lesser flight frequency, higher airfares or longer travel miles. To explore spatial-temporal variations from airline and passenger perspectives, this paper focuses on 55 major airports in the 50 largest cities between 2000 and 2010. The detailed results of passenger flow patterns suggest that some airports have more spatial imbalance than others in terms of passenger travel distances. Further, the findings indicate that the MAs have different effects on passenger flows and traveled distances, and the effect is complexly related to the airport’s spatial status. Spatial-Temporal Analysis of Recent Air Passenger Flows Changjoo Kim, University of Cincinnati, Cincinnati, OH, USA Hyun Kim, University of Tennessee, Knoxville, TN, USA	cost efficiency;mike lesser;operating system;twisted nematic field effect	Changjoo Kim;Hyun Jin Kim	2013	IJAGR	10.4018/jagr.2013100103	engineering;operations management;transport engineering;advertising	ML	8.425076719039307	-8.513378082214656	93552
72e3b9aa02f3f7523d64f635871f94009581fc9a	optimal auditing with scoring: theory and application to insurance fraud	cheating;modelizacion;actuarial studies;seguro;red flags strategy;suspicion index;estrategia optima;asymmetry;d0 general;bridges;deterrence effect;probabilistic approach;asymetrie;imperfect information;scoring;asymmetric information;modelisation;optimal strategy;compania seguro;insurance fraud;assurance;moral cost of fraud;enfoque probabilista;approche probabiliste;tricherie;puente;indexation;reclamation;c4 econometric and statistical methods special topics;pont;insurance company;informacion imperfecta;asimetria;signal manipulation;protest;compagnie assurance;audicion;g22 insurance;reclamacion;modeling;strategie optimale;audit;insurance companies;insurance;trampa;fraud indicators;information imparfaite	"""This article makes a bridge between the theory of optimal auditing and the scoring methodology in an asymmetric information setting. Our application is meant for asurance claims fraud, but it can be applied to many other activities that use the scoring approach. We show that the optimal auditing strategy takes the form of a """"Red Flags Strategy"""" which consists in referring claims to a Special Investigative unit (SIU) when certain fraud indicators are observed. Fraud indicators are classified based on the degree to which they reveal an increasing probability of fraud. This strategy remains optimal even when the investigation policy is budget constrained. Moreover, the auditing policy acts as a deterrence device and we explain why it requires the commitment of the insurer and how it should affect the incentives of SIU staffs. the models is calibrated with data from a large European insurance company. We compute a critical suspicion index for fraud, providing a threshold above which all claims must be audited and we estimate the potential gain that could be derived from the optimal auditing policy. We show that it is possible to improve these results by separating different groups of insureds with different moral costs of fraud. Finally, our results indicate how the deterrence effect of the audit scheme can be taken into account and how it affects the optimal auditing strategy. Mots clés : Audit, scoring, Fraude à l'assurance, Stratégie d'indicateurs, Indicateurs de fraude, Indice de suspicion, Coût moral de la fraude, Effet de dissasion."""	calibration (statistics);linear algebra	Georges Dionne;Florence Giuliano;Pierre Picard	2009	Management Science	10.1287/mnsc.1080.0905	actuarial science;economics;insurance;marketing;finance;microeconomics;management;computer security	ML	4.539569682564444	-9.189864767870485	93767
1ecdc9d233c001b45e8cba4db2a24963d8489ece	a fully polynomial approximation scheme for single-product scheduling in a finite capacity facility	produccion;calculating time;gestion production;horizonte acabado;limit;algorithme;algorithm;temps calcul;aproximacion polinomial;planificacion;production control;horizon fini;production scheduling lot sizing approximations and production planning;taille lot;gestion produccion;approximation polynomiale;lot sizing;production;finite horizon;planning;production scheduling;planification;tiempo calculo;limite;polynomial approximation;algoritmo	This paper considers a version of the economic lot sizing problem for a single product produced in a facility of finite capacity over a finite time horizon with specifiable start and end conditions. A set of algorithms is presented that will approximate the optimal production schedule to a given allowable error e. Algorithms with computation time bounds of O1/e2 are presented which allow for setups of finite length, setups with or without direct cash flow, quite general cost and demand functions, and a wide variety of production policy constraints. The procedures make no a priori assumptions about the form of the optimal solution. Numerical results are included.	polynomial;polynomial-time approximation scheme	Bezalel Gavish;Robert E. Johnson	1990	Operations Research	10.1287/opre.38.1.70	planning;mathematical optimization;operations management;limit;mathematics;scheduling;mathematical economics;management;algorithm	Theory	5.3280633562321	-2.6201354812546276	93938
9ccde0859f1ae3bba095346d2a94bcc6fae92126	a scenario-based stochastic programming approach for technology and capacity planning	capacity planning;generic model;new product introduction;product life cycle;capacity and technology planning;large scale stochastic programming;augmented lagrangian method;information and communication technology;stochastic dynamic demands;evaluation methodology;mathematical programming;software package;stochastic dynamics;stochastic programming;scenario based approach;working paper;flexible technology;technology choice	In response to market pressures resulting in increased competition, product proliferation and greater customization, rms in many industries have adopted modern technologies to provide operational exibility on several dimensions. In this paper, we consider the role of product mix exibility, de ned as the ability to produce a variety of products, in an environment characterized by multiple products, uncertainty in product life cycles and dynamic demands. Using a scenario based approach for capturing the evolution of demand, we develop a stochastic programming model for determining technology choices and capacity plans. Since the resulting model is likely to be large and may not be easy to solve with standard software packages, we develop a solution procedure based on augmented Lagrangian method and restricted simplicial decomposition. The scope of our approach for deriving context speci c managerial insights is illustrated by the results of limited computations. Finally, we demonstrate the versatility of our approach by deriving a special case of the general model to address some tactical issues related to new product introduction.	augmented lagrangian method;computation;new product development;programming model;qr decomposition;simplicial complex;stochastic programming	Zhi-Long Chen;Shanling Li;Devanath Tirupati	2002	Computers & OR	10.1016/S0305-0548(00)00076-9	stochastic programming;mathematical optimization;information and communications technology;simulation;augmented lagrangian method;computer science;product lifecycle;mathematics;new product development	AI	4.20665543269389	-6.30783756657792	93976
f2b80f9023838b4917ecaf64085665e6cd8a9e9d	dynamic efficiency of conservation of renewable resources under uncertainty	social welfare;discount rate;environmental conditions;renewable resources;natural product;journal of economic literature	We examine the efficiency of conservation of a renewable resource whose natural productivity is influenced by random environmental disturbances. We allow for non-concave biological production and stock-dependent social welfare. Unlike deterministic models, conservation may be inefficient no matter how productive the resource growth function is. In addition, improvements in the natural productivity of the resource might increase the possibility of extinction. We characterize the conditions on social welfare, resource growth, the discount rate, and the distribution of environmental disturbances that are sufficient for conservation to be efficient. The productivity of the resource under the worst possible environmental conditions, the discount rate, and the welfare function are all crucial factors in determining the efficiency of conservation. Journal of Economic Literature Classification Numbers: Q20, O41, D90. 2000 Academic Press	benchmark (computing);complementarity (physics);concave function;convex set;emoticon;expanded memory;fo (complexity);field electron emission;foreign function interface;marginal model;microsoft kin;serial ata	Lars J. Olson;Santanu Roy	2000	J. Economic Theory	10.1006/jeth.2000.2685	resource productivity;environmental economics;economics;renewable resource;social welfare;microeconomics;welfare economics;resource	AI	-3.721268183696747	-5.7697308588464455	94117
44703e0f2b73a93e998ce9a5f0b485912a69a454	the unique informational efficiency of the competitive mechanism in economies with production	pareto efficiency;resource allocation;informational efficiency;individual rationality;pareto optimality;lower bound	The purpose of this paper is to investigate the informational requirements of resource allocation processes for convex production economies. First, we establish a lower bound of the message space of an informationally decentralized mechanism that realizes Pareto efficient allocations over the class of classical production economies. Then, it is shown that this lower bound is exactly the size of the message space of the competitive (Walrasian) mechanism, and thus the competitive mechanism is informationally efficient for general neoclassical production economies in the sense that it uses the smallest message space among the class of resource allocation processes that are informationally decentralized and realize Pareto optimal allocations. Further, it is shown that the competitive mechanism is the unique informationally efficient decentralized mechanism that realizes Pareto efficient and individually rational allocations. The results obtained in the paper may shed light on the socialist controversy between Mises-Hayek and Lange-Lerner.	complexity;hoc (programming language);nash equilibrium;pareto efficiency;requirement;stationary process	Guoqiang Tian	2006	Social Choice and Welfare	10.1007/s00355-005-0056-0	bayesian efficiency;economics;resource allocation;microeconomics;mathematical economics;upper and lower bounds;welfare economics	Theory	-3.8887952664263707	-0.6110365367082433	94191
25dbfab3439fa79c6b1d5cd7dac08f2488353372	a pareto improving strategy for the time-dependent morning commute problem	ley pareto;traffic equilibrium;commuters;tiempo espera;traffic mitigation;matin;time dependent;congestion trafic;longitud hilera;travel time;congestion trafico;gollete estrangulamiento;social and behavioral sciences;queue length;gestion trafic;commuting;time window;peage;cost control;transport en commun;transporte colectivo;time periods;traffic management;collective transport system;peaje;temps attente;loi pareto;goulot etranglement;dependance du temps;time dependence;traffic congestion;rush hour;pareto distribution;waiting time;morning;gestion trafico;longueur file;manana;tolls;time dependent morning commute problem;architecture;bottleneck;heure de pointe;dependencia del tiempo;control strategy;toll;hora punta;time windows;peak hour traffic	This research shows that certain time-dependent congestion reduction schemes involving tolls have the potential for benefiting every driver even if the collected revenues are not returned to the payers. The paper considers a population of commuters who use a single bottleneck during the morning rush hour and try to arrive at work on time. It is assumed that the number of commuters is fixed (independent of the control strategy) and that each commuter wishes to pass through the bottleneck at a given time, which may differ across commuters. Commuters are otherwise identical. Each of them chooses his/her arrival time at the bottleneck so as to minimize a linear combination of monetary cost (tolls), queuing time and deviation from the desired passage time. A time-dependent toll is applied during a time window, but some commuters are exempted from paying it. Every day each commuter is classified as either “free” or “paying.” The classification method is such that: (i) in the long-run the fraction of days, f, that a commuter is free is the same for all commuters, and (ii) the fraction of “free” commuters is f every day. “Free” commuters are allowed to use the bottleneck without paying the toll, while “paying” commuters can avoid the toll only if they pass through the bottleneck outside the time window. It is shown that if commuters wish to pass through the bottleneck close together then the toll, the window and the fraction of free commuters can be chosen -1in a way that will benefit everyone by inducing an equilibrium where the “peak is smoothed out” in a particular way. Up to 25% of the total user cost can be eliminated in this way. INTRODUCTION This paper proposes and evaluates an unconventional pricing scheme for the time-dependent “morning commute problem” that has the potential for being Pareto improving. Interest in congestion pricing is currently high because both the public and government officials are increasingly aware of the high costs of urban congestion and the limitations of more conventional congestion reduction remedies. [Even though congestion cost estimates must be treated with caution, recent analyses leave no doubt that congestion is a pressing problem: the annual cost of delays in the 10 most snarled city and suburban road systems in the US has been estimated to be on the order of $34 billion (SCHRANK and LOMAX, 1997.)] The paper is motivated by the recognition that conventional congestion pricing strategies involve transfer payments that hurt (or at least do not benefit) the majority of users, and the belief that reducing these inequities can go a long way toward eliminating the public’s reluctance to accept tolls. Some of these issues have already been explored in the context of a steady state (static) system. It has been suggested in DAGANZO (1995) that if certain procedures were implemented (citywide) in a perennially congested city, then a Pareto improvement could be achieved. The assumptions about user behavior made in this reference were rather general, but the traffic model (being steady state) ruled out surgical application of the procedure to “hot spots” that are only congested part of the day. In view of this, some modifications that would be appropriate for these cases are outlined in this paper. They will be illustrated below with the simplest possible “hot spot” scenario; i.e., the so-called “morning commute problem with homogeneous drivers,” introduced in VICKREY (1969) and also examined in HENDRICKSON et al. (1983), SMITH (1984), DAGANZO (1985) and ARNOTT et al. (1990), among others. (A thorough understanding of this simple case is a prerequisite to the investigation of more realistic scenarios; e.g., with heterogeneous drivers, different vehicle types and some cheating.) Section 1 below summarizes the necessary background from these references. Section 2 describes the proposed strategy, and Sec. 3 examines the equilibrium state obtained	control theory;hotspot (wi-fi);network congestion;pareto efficiency;smoothing;steady state;time of arrival	Carlos F. Daganzo;Reinaldo C. Garcia	2000	Transportation Science	10.1287/trsc.34.3.303.12296	morning;simulation;pareto distribution;operations management;architecture;mathematics;transport engineering;statistics	ECom	9.464523536425075	-8.657684876144561	94228
7d1cd2e5ea0e25eba49b23edc36c6a8695d339f7	on fair price discrimination in multi-unit markets		Discriminatory pricing policies, even if at first glance can be perceived as unfair, are widespread. In fact, pricing differences for the same item among different national markets are common, or forms of discrimination based on the time of purchase, like in tickets’ sales. In this work we propose a framework for capturing the setting of “fair” discriminatory pricing and study its application to multiunit markets, in which many copies of the same item are on sale. Our model is able to incorporate the fundamental discrimination settings proposed in the literature, by expressing individual buyers constraints for assigning prices by means of a social relationship graph, modeling the information that each buyer can acquire about the prices assigned to the other buyers. After pointing out the positive effects of fair price discrimination, we investigate the computational complexity of maximizing the social welfare and the revenue in these markets, providing hardness and approximation results under various assumptions on the buyers valuations and on the social graph topology.		Michele Flammini;Manuel Mauro;Matteo Tonelli	2018		10.24963/ijcai.2018/34	fair value;financial economics;machine learning;artificial intelligence;computer science	ECom	-3.2473962461559833	-3.126137514906861	94253
23b09d66d6474b166aae7606d4a5429a25ab03ea	asset allocation and liquidity breakdowns: what if your broker does not answer the phone?	continuous time;portfolio decision;utility function;rare disasters;93e20;rare;blackout period;value function;efficiency loss;91b28;asset allocation;effciency loss;illiquidity	This paper analyzes the portfolio decision of an investor facing the threat of illiquidity. In a continuous-time setting, the efficiency loss due to illiquidity is addressed and quantified. For a logarithmic investor, we solve the portfolio problem explicitly. We show that the efficiency loss for a logarithmic investor with 30 years until the investment horizon is a significant 22.7% of current wealth if the illiquidity part of the model is calibrated to the Japanese data of the aftermath of WW II. For general utility functions, an explicit solution does not seem to be available. However, under a mild growth condition on the utility function, we show that the value function of a model in which only finitely many liquidity breakdowns can occur converges uniformly to the value function of a model with infinitely many breakdowns if the number of possible breakdowns goes to infinity. Furthermore, we show how the optimal security demands of the model with finitely many breakdowns can be used to approximate the optimal solution of the model with infinitely many breakdowns. These results are illustrated for an investor with a power utility function.	half-life 2: episode one;nervous breakdown;sensorineural hearing loss (disorder)	Peter Diesinger;Holger Kraft;Frank Thomas Seifried	2010	Finance and Stochastics	10.1007/s00780-008-0085-5	financial economics;actuarial science;deadweight loss;economics;finance;asset allocation;bellman equation;commerce	Theory	1.2658613158506373	-4.46551926829185	94289
389f4b5330d8d77ef370baf972b70bd5ccd71fbc	simulation, a support for sustainable logistical decision-making in complex supply chains	environmental;freight transport;simulation;ireland;sustainability;sustainable logistics;dss;scm;decision support systems;greenhouse gases;road freight;supply chain inefficiencies;ghg emissions;supply chain management	Across the European economic area (EEA), greenhouse gas (GHG) emissions from most sectors decreased between 1990 and 2004, with the transport sector being one major exception to this. In fact, GHG emissions from the transport sector increased by 23% between 1990 and 2003 for the EEA-32 countries. In Ireland, there has been a 160% increase in GHG emissions from the transport sector in the period 1990 to 2005. The objective of this paper is to highlight the current situation for freight transport by road, with a focus on Ireland and proposes a more general simulation-based tool to assist more environmental sustainable supply chain decision-making. The paper will focus on inefficiencies in modern supply chain design and show how using simulation can aid decision-makers in choosing more environmentally friendly solutions. A simulation tool to aid decision-makers to choose more sustainable options will be proposed, and preliminary results discussed.	extended euclidean algorithm;heart rate variability;logistics;simulation	Peter J. Byrne;Paul Ryan;Cathal Heavey	2010	IJCAET	10.1504/IJCAET.2010.035391	greenhouse gas;supply chain management;decision support system;environmental engineering;computer science;engineering;marketing	AI	7.487457061246284	-7.056234781899116	94388
e2501d503581992e017ac0632bf224436818f194	robust newsvendor problem with autoregressive demand	forecasting;minimax;autoregressive process;uncertainty set;robust optimization;distribution free newsboy problem	This paper explores the classic single-item newsvendor problem under a novel setting which combines temporal dependence and tractable robust optimization. First, the demand is modeled as a time series which follows an autoregressive process AR(p), p ≥ 1. Second, a robust approach to maximize the worst-case revenue is proposed: a robust distribution-free autoregressive forecasting method, which copes with non-stationary time series, is formulated. A closed-form expression for the optimal solution is found for the problem for p = 1; for the remaining values of p, the problem is expressed as a nonlinear convex optimization program, to be solved numerically. The optimal solution under the robust method is compared with those obtained under two versions of the classic approach, in which either the demand distribution is unknown, and assumed to have no autocorrelation, or it is assumed to follow an AR(p) process with normal error terms. Numerical experiments show that our proposal usually outperforms the previous benchmarks, not only with regard to robustness, but also in terms of the average revenue.	autocorrelation;autoregressive model;benchmark (computing);best, worst and average case;cobham's thesis;convex optimization;experiment;mathematical optimization;newsvendor model;nonlinear system;numerical analysis;numerical method;optimization problem;robust optimization;stationary process;time series	Emilio Carrizosa;Alba V. Olivares-Nadal;Pepa Ramírez-Cobo	2016	Computers & OR	10.1016/j.cor.2015.11.002	minimax;econometrics;mathematical optimization;newsvendor model;robust optimization;extended newsvendor model;forecasting;mathematics;autoregressive model;mathematical economics;statistics	ML	3.5068984081252577	-3.335216980115406	94422
0d156f36aebd6e23d2408feae4a5cdc633263964	erratum to: asset price bubbles from heterogeneous beliefs about mean reversion rates		Harrison and Kreps showed in 1978 how the heterogeneity of investor beliefs can drive speculation, leading the price of an asset to exceed its intrinsic value. By focusing on an extremely simple market model—a finite-state Markov chain— the analysis of Harrison and Kreps achieved great clarity but limited realism. Here we achieve similar clarity with greater realism, by considering an asset whose dividend rate is a mean-reverting stochastic process. Our investors agree on the volatility, but have different beliefs about the mean reversion rate. We determine the minimum equilibrium price explicitly; in addition, we characterize it as the unique classical solution of a certain linear differential equation. Our example shows, in a simple and transparent manner, how heterogeneous beliefs about the mean reversion rate can lead to everlasting speculation and a permanent “price bubble.”	markov chain;reversion (software development);stochastic process;volatility	Xi Chen;Robert V. Kohn	2013	Finance and Stochastics	10.1007/s00780-012-0191-2	financial economics;economics;macroeconomics;monetary economics	ML	-0.09264031833446315	-3.351537422411052	94551
a476736b7d79e235a8775be22d2ec081c71c37bf	competitive difference analysis of the one-way trading problem with limited information	one way trading;competitive analysis;online algorithms;robustness and sensitivity analysis	We consider robust one-way trading with limited information on price fluctuations. Our analysis finds the best guarantee of difference from the optimal offline performance. We provide closed-form solution, and reveal for the first time all possible worst-case scenarios. Numerical experiments show that our policy is more tolerant of information inaccuracy than Bayesian policies, and can earn higher average revenue than other robust policies while keeping a lower standard deviation. © 2016 Elsevier B.V. All rights reserved.	best, worst and average case;experiment;one-way function;online and offline	Wei Wang;Liying Wang;Yingjie Lan;Jean X. Zhang	2016	European Journal of Operational Research	10.1016/j.ejor.2016.01.031	financial economics;competitive analysis;online algorithm;mathematical optimization;economics;computer science;trading strategy;microeconomics;welfare economics	AI	1.9433298801815977	-4.19276897223921	94568
0224c57553b4d9bff8fdcea1cf2f079aa3cc9649	can early joining participants contribute more? - timeliness sensitive incentivization for crowdsensing		This paper investigates the incentive mechanism design from a novel and practically important perspective in which mobile users as contributors do not join simultaneously and a requester desires large efforts from early contributors. A two-stage Tullock contest framework is constructed: at the second stage the potential contributors compete for splittable reward by exerting efforts, and at the first stage the requester can orchestrate the incentive mechanism to maximize his crowdsensing efficiency given the rewarding budget. A general reward discrimination mechanism is developed for timeliness sensitive crowdsensing where an earlier contributor usually has a larger maximum achievable reward and thus allocates more efforts. Owning to the lack of joining time information, two practical implementations, namely earliest-n and termination time, are announced to the contributors. For each of them, we formulate a Stackelberg Bayesian game in which the joining time of a contributor is his type and not available to his opponents. The uniqueness of Bayesian Nash equilibrium (BNE) is proved in each strategy. To maximize the requester’s efficiency, we compute the optimal number of rewarded contributors in the earliestn scheme and the optimal deadline in the termination time scheme. Our contest framework is applicable not only to the closed crowdsensing with fixed number of contributors, but also to the open crowdsensing that the arrival of contributors is governed by a stochastic process. Extensive simulations manifest that with appropriate reward discriminations, the requester is able to achieve a much higher efficiency with the optimal selection of the number of rewarded contributiors and the termination time.		Yuedong Xu;Yifan Zhou;Yifan Mao;Xu Chen;Xiang Li	2017	CoRR		mathematics;implementation;uniqueness;mathematical optimization;bayesian game;stackelberg competition;stochastic process;mechanism design;contest;incentive	Web+IR	-1.7371030614821203	-2.580620344702421	95097
80cd48e94a583cf226ec8adf5678c2cd78ccdabe	data-driven bottleneck detection in manufacturing systems: a statistical approach	analytical models;manufacturing systems;production lines data driven bottleneck detection manufacturing systems statistical approach machine performance metrics statistical framework data driven detection inaccuracy system variability;reliability;measurement;throughput reliability measurement analytical models manufacturing systems turning;turning;statistical analysis manufacturing systems;throughput	Data-driven bottleneck detection has received an increasing interest during the recent years. This approach locates the throughput bottleneck of manufacturing systems based on indicators derived from measured machine performance metrics. However, the variability in manufacturing systems may affect the quality of bottleneck indicators, leading to possible inaccurate detection results. This paper presents a statistical framework to decrease the data-driven detection inaccuracy caused by system variability. The proposed statistical framework is numerically verified to be spectacularly effective in decreasing the wrong bottleneck identifications in production lines.	heart rate variability;numerical analysis;statistical model;throughput	Chunlong Yu;Andrea Matta	2014	2014 IEEE International Conference on Automation Science and Engineering (CASE)	10.1109/CoASE.2014.6899406	reliability engineering;simulation;engineering;operations management	Robotics	8.891038704533754	2.4301198443288623	95119
dbbe7b960293aeb811cd7d33e4346e6f4c24deb7	what competition? myopic self-focus in market-entry decisions	market entry;egocentrism;entrepreneurship;underconfidence;overconfidence;focalism;entrepreneurial entry;article	This paper documents egocentric biases in market-entry decisions. We demonstrate self-focused explanations for entry decisions made by three groups of participants: actual entrepreneurs (founders), working professionals who considered starting their own firms but did not (nonfounders), and participants in a market-entry experiment. Potential entrants based their decision to enter primarily on evaluations of their own competence (or incompetence) and paid relatively little attention to the strength of the competition. Our results suggest that excess entrepreneurial entry is more complicated than simple overconfidence, and can help explain notable patterns in entrepreneurial entry.		Don A. Moore;John M. Oesch;Charlene Zietsma	2007	Organization Science	10.1287/orsc.1060.0243	overconfidence effect;entrepreneurship;egocentrism;anchoring;management;social psychology;commerce	HCI	-4.161821723887698	-7.834268555629734	95259
f870a5e30a8ec8755e0b7a4fc2a7ea1abb0fa17d	quantitative assessment of economic, social and environmental impacts of critical infrastructure disruptions		Metrics for critical infrastructure resilience quantification and performability assessment are proposed to help in understanding the infrastructure resilience and identifying its weak spots. Analysis of critical infrastructure performance and its behavior during and after the occurrence of malfunctions and negative impacts of disruptive event of infrastructure functioning is performed through quantitative assessment. Interactions between infrastructures using indices of impact of malfunctions in them are analyzed. Proposed metrics are also concerned with demands ranging and operating and environmental conditions having influence on unrealized tasks.		Agnieszka Blokus	2018	2018 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM)	10.1109/IEEM.2018.8607524		SE	7.399022668941308	-9.684755997854536	95346
91707728f0f4214b82ae4a4e2eec884a8dc4aa21	a warehouse imperfect fuzzified production model with shortages under inflationary conditions		We develop a two-warehouse production model with imperfect items. Production rate is taken as the linear combination of on-hand inventory and demand, while demand rate is taken as function of time. Most of the researchers consider that the production rate is independent from the demand rate. In this paper we assume production rate as being dependent on the demand rate, and this assumption is more realistic. Shortages are allowed and partially backlogged with time-dependent backlogging rate. Due to different preservation facilities we consider that the deterioration rate is time dependent in own warehouse OW and Weibull distribution deterioration in rented warehouse RW . Holding cost in RW is greater than in OW. We developed a fuzzy model with fuzzifying all the costs of the model as triangular fuzzy numbers. The present model is developed in both crisp and fuzzy senses. Finally, numerical example is shown, and sensitivity is also illustrated.	numerical analysis;read-write memory;sketchup 3d warehouse	Shivraj R. Singh;Shalini Jain;Sarla Pareek	2012	ADS	10.1155/2012/638060	economics;operations management;welfare economics;commerce	Networks	4.33101341250304	-5.332812725249272	95350
863abdd14e01e82fb3e9d84029cf30f748e241fa	a two-stage stochastic program for scheduling and allocating cross-trained workers	modelizacion;gestion personnel;forecasting;staff management;reliability;project management;information systems;mano de obra;occupational training;gestion production;maintenance;bepress selected works;soft or;information technology;packing;programmation stochastique;supply demand balance;operations research;location;labour scheduling;investment;journal;gestion personal;production management;journal of the operational research society;inventory;purchasing;modelisation;history of or;manpower planning;logistics;formacion profesional;marketing;scheduling;gestion produccion;cross training;production;communications technology;offre et demande;manpower planning labour scheduling stochastic programming cross training;computer science;operational research;oferta y demanda;stochastic programming;main d oeuvre;modeling;programacion estocastica;ordonnancement;demand uncertainty;applications of operational research;or society;reglamento;formation professionnelle;jors;management science;manpower;infrastructure	A two-stage stochastic program is developed for scheduling and allocating crosstrained workers in a multi-department service environment with random demands. The first stage corresponds to scheduling days-off over a time horizon such as a week or month. The second stage is the recourse action that deals with allocating available workers at the beginning of a day to accommodate realized demands. After the general two-stage model is formulated, a special case is introduced for computational testing. The testing helps quantify the value of cross-training as a function of problem characteristics. Results show that crosstraining can be more valuable than perfect information, especially when demand uncertainty is high.	computation;scheduling (computing);stochastic programming	G. M. Campbell	2011	JORS	10.1057/jors.2010.16	stochastic programming;project management;logistics;simulation;inventory;economics;forecasting;investment;marketing;operations management;reliability;mathematics;location;management;operations research;information technology;scheduling	Metrics	6.014222733168971	-3.634362708301751	95385
204d5b10fa718927dfa29bfa7e92de4a50bab609	pharmaceutical supply chain networks with outsourcing under price and quality competition	outsourcing;pharmaceutical products;game theory;competition;healthcare;variational inequalities;supply chains;quality;supply chain networks;dynamical systems	In this paper, we present a pharmaceutical supply chain network model with outsourcing under price and quality competition, in both equilibrium and dynamic versions. We consider a pharmaceutical firm that is engaged in determining the optimal pharmaceutical flows associated with its supply chain network activities in the form of manufacturing and distribution. In addition to multimarket demand satisfaction, the pharmaceutical firm seeks to minimize its total cost, with the associated function also capturing the firm’s weighted disrepute cost caused by possible quality issues associated with the contractors. Simultaneously, the contractors, who compete with one another in a noncooperative manner in prices a la Bertrand, and in quality, seek to secure manufacturing and distribution of the pharmaceutical product from the pharmaceutical firm. This game theory model allows for the determination of the optimal pharmaceutical product flows associated with the supply chain in-house and outsourcing network activities and provides the pharmaceutical firm with its optimal make-or-buy decisions and the optimal contractor-selections. We state the governing equilibrium conditions and derive the equivalent variational inequality formulation. We then propose dynamic adjustment processes for the evolution of the product flows, the quality levels, and the prices, along with stability analysis results. The algorithm yields a discretization of the continuous-time adjustment processes. We present convergence results and compute solutions to numerical examples to illustrate the generality and applicability of the framework.	algorithm;bertrand (programming language);denial-of-service attack;discretization;game theory;input/output;linear algebra;nash equilibrium;network model;numerical analysis;outsourcing;social inequality;supply chain network;variational inequality;variational principle	Anna Nagurney;Dong Li;Ladimer S. Nagurney	2013	ITOR	10.1111/itor.12031	game theory;dynamical systems theory;competition;economics;operations management;microeconomics;supply chain;commerce;outsourcing	AI	0.04257009502759436	-3.0380117228877728	95451
01469f1c10a20dc21857fcb5505778dc98e2af81	replenishment planning for stochastic inventory systems with shortage cost	institutional repositories;optimal solution;piecewise linear approximation;fedora;cost function;vital;stochastic demand;vtls;inventory control;demand uncertainty;ils	One of the most important policies adopted in inventory control is the (R,S) policy (also known as the “replenishment cycle” policy). Under the non-stationary demand assumption the (R,S) policy takes the form (Rn,Sn) where Rn denotes the length of the n th replenishment cycle, and Sn the corresponding order-up-to-level. Such a policy provides an effective means of damping planning instability and coping with demand uncertainty. In this paper we develop a CP approach able to compute optimal (Rn,Sn) policy parameters under stochastic demand, ordering, holding and shortage costs. The convexity of the cost-function is exploited during the search to compute bounds. We use the optimal solutions to analyze the quality of the solutions provided by an approximate MIP approach that exploits a piecewise linear approximation for the cost function.	approximation algorithm;instability;inventory control;linear approximation;loss function;piecewise linear continuation;stationary process;stochastic process	Roberto Rossi;Armagan Tarim;Brahim Hnich;Steven David Prestwich	2007		10.1007/978-3-540-72397-4_17	inventory control;mathematical optimization	AI	3.17286636585986	-2.6360869506444904	95579
31d920238ee6a51d38e05b06ab1ebc0e6d9b83ea	should americans invest internationally? mean-variance portfolios optimization and stochastic dominance approaches	mean variance portfolio optimization;international diversification;stochastic dominance;monte carlo and bootstrap p values;home bias		mathematical optimization;stochastic gradient descent	Fathi Abid;Mourad Mroua;Wing-Keung Wong	2013	Risk and Decision Analysis	10.3233/RDA-2012-0084	financial economics;actuarial science;economics;welfare economics	ML	2.7459532895414904	-8.854833344358324	95589
69c07dee77c10f910f79b21b4a3982abe62ab447	a queueing network approach to the analysis and control of mobility-on-demand systems	measurement;routing;public transportation;computational modeling;system loads queueing network approach mobility on demand systems mod systems urban personal transportation vehicles fleet one way car sharing service drivers rebalance taxi service two coupled closed jackson networks passenger loss decoupled linear programs nonlinear optimization rebalancing techniques manhattan neighborhoods optimal vehicle to driver ratio real time closed loop rebalancing policy stability customer wait times;optimization;approximation methods;vehicles;vehicles public transportation routing optimization measurement computational modeling approximation methods;queueing theory automobiles closed loop systems linear programming nonlinear programming	This paper presents a queueing network approach to the analysis and control of mobility-on-demand (MoD) systems for urban personal transportation. A MoD system consists of a fleet of vehicles providing one-way car sharing service and a team of drivers to rebalance such vehicles. The drivers then rebalance themselves by driving select customers similar to a taxi service. We model the MoD system as two coupled closed Jackson networks with passenger loss. We show that the system can be approximately balanced by solving two decoupled linear programs and exactly balanced through nonlinear optimization. The rebalancing techniques are applied to a system sizing example using taxi data in three neighborhoods of Manhattan, which suggests that the optimal vehicle-to-driver ratio in a MoD system is between 3 and 5. Lastly, we formulate a real-time closed-loop rebalancing policy for drivers and demonstrate its stability (in terms of customer wait times) for typical system loads.	device driver;jackson;linear programming;mathematical optimization;mesoscopic physics;network congestion;network model;nonlinear programming;nonlinear system;offset binary;one-way function;queueing theory;real-time clock;real-time locating system;self-balancing binary search tree;server (computing);side effect (computer science)	Rick Zhang;Marco Pavone	2015	2015 American Control Conference (ACC)	10.1109/ACC.2015.7172070	routing;simulation;computer science;mathematics;computational model;measurement;computer network	Robotics	7.495791321056403	3.3993527155471597	96134
df12a92602afa7b722fbe43d8a3f3c0da45e8a6e	do hedge funds outperform stocks and bonds?	speculation;stocks;capital formation;hedge funds;bonds	H funds’ extensive use of derivatives, short selling, and leverage and their dynamic trading strategies create significant nonnormalities in their return distributions. Hence, the traditional performance measures fail to provide an accurate characterization of the relative strength of hedge fund portfolios. This paper uses the utility-based nonparametric and parametric performance measures to determine which hedge fund strategies outperform the U.S. equity and/or bond markets. The results from the realized and simulated return distributions indicate that the long/short equity hedge and emerging markets hedge fund strategies outperform the U.S. equity market, and the long/short equity hedge, multistrategy, managed futures, and global macro hedge fund strategies dominate the U.S. Treasury market.	futures and promises	Turan G. Bali;Stephen J. Brown;K. Ozgur Demirtas	2013	Management Science	10.1287/mnsc.1120.1689		ML	-0.1379327794090462	-7.850245476509998	96235
e38c8e6206013fb2c48142aad7b6203c9e2db376	stochastic dynamic pricing: utilizing demand response in an adaptive manner	pricing stochastic processes vehicle dynamics distributed algorithms heuristic algorithms resource management modeling;stochastic processes distributed algorithms network theory graphs optimisation pricing;deterministic dynamic pricing stochastic dynamic pricing framework demand response residential customers static network utility maximization distributed algorithm stochastic process	Dynamic pricing to residential customers has been proposed recently, as extensions of static network utility maximization problems. Those deterministic models do not exploit the refined information as time advances. To address this issue, we formulate a stochastic dynamic pricing framework, in which we show the existence of an optimal price process that incentives the agents to choose the socially optimal decisions. We develop a distributed algorithm and investigate the information structure of the involved stochastic processes via a numerical example, which also illustrates the advantage of stochastic dynamic pricing over deterministic dynamic pricing.	distributed algorithm;embedded system;expectation–maximization algorithm;lagrangian relaxation;multi-user;network utility;numerical analysis;stochastic process;volatility	Wenyuan Tang;Rahul Jain;Ram Rajagopal	2014	53rd IEEE Conference on Decision and Control	10.1109/CDC.2014.7040400	mathematical optimization;stochastic modelling;stochastic optimization	Metrics	1.948645560542421	2.523234643623026	96286
eb22e6da8662a7961ebb3c4d34db81c59a05fc24	erratum to: an economic calibration method for fuel consumption model in hdm4				Kwang-Ho Ko;Byung-Koo Moon;Tong-Won Lee;Won-Ho Lee;In-Kyoon Yoo;Soo-Hyung Lee;Dae-Seok Han;Seung-Hyun Jeong	2016	Wireless Personal Communications	10.1007/s11277-016-3541-0	econometrics;mathematical economics	Robotics	2.894451219119331	-8.259604003574395	96328
a17b72ed776d9ef02ec592a2b06d65103e1497f9	cost analysis of two-dimensional warranty for products with periodic preventive maintenance	two dimensional warranty;preventive maintenance;non homogeneous poisson process	This study uses a bivariate approach, which simultaneously considers the time and usage of a repairable product, and takes into account periodic preventive maintenance to develop a two-dimensional warranty policy for the repairable product. The proposed model is based on the bivariate Weibull process to analyze the breakdown process of a repairable product simultaneously in terms of time and usage. A repairable product may be differently utilized by various customers. We consider two types of customers: (1) customers whose product warranty is terminated because the warranty time limit has reached first; (2) customers whose product warranty is terminated because the warranty usage limit has reached first, to perform cost analyses for determining an appropriate warranty policy. However, since it is often the case that the repairable product may be equally likely purchased by the two types of customers who are equivalently important to the product manufacturer; the optimal warranty policy would thus be the equilibrium solution of the cost analyses which pay the same attention to both types of customers in order to maximize the total profit of the manufacturer.		Yeu-Shiang Huang;Wei-Yo Gau;Jyh-Wen Ho	2015	Rel. Eng. & Sys. Safety	10.1016/j.ress.2014.10.014	reliability engineering;preventive maintenance;engineering;mathematics;inhomogeneous poisson process	DB	2.1341731516046774	-5.098699624014808	96380
40d5d6ae92a3d56671f493298824c96b40ed6634	development and implementation of an operation efficiency management system using the uph according to operation start time	automatic control;operation efficiency management system;control systems;optimisation;efficiency maximization;management system;efficiency measurements;maximum production improvement;automation automatic control control systems production systems graphical user interfaces user interfaces computer science education educational products systems engineering education hardware;production engineering computing;production engineering computing factory automation optimisation;stability;efficiency measurements operation efficiency management system operation start time automation system optimization system efficiency maximization stability maximum production improvement unit per hour;computer science education;graphical user interfaces;unit per hour;software development;optimization system;operation start time;systems engineering education;production systems;factory automation;automation system;efficiency measurement;user interfaces;educational products;hardware;automation	The automation system which depended solely on the production improvements has been developed recently focusing on the optimization of the system, maximization of the efficiency, stability of the system, convenience of the operation and the compatibility. Various studies on the enhancement of the automation system efficiency are on the way by many researchers and software developers n order to achieve the maximum production improvements and optimization of operations in the effort to maximize the effectiveness of the automation system. The production measurement UPH(unit per hour) has been used to determine the automation system efficiency but the efficiency on each operation is calculated manually on the basis of the accumulated UPH in the conventional system. Therefore, more accurate efficiency measurements are required. In this paper, the operational efficiency of the automation system has been measured using UPH to provide the users more quantified and objective evaluation of the system. The user should provide the initiating time to operate the process so that the operation efficiency is obtained as results sorted by date of the operations.	entropy maximization;management system;mathematical optimization;software developer	Hwa-Young Jeong;Jong-Hoon Kim;Kumhee Han	2001		10.1109/ICPADS.2001.934819	computer science;operating system;automation;automatic control	DB	4.0618458157928945	2.4659443268603987	96926
5535c24e58c8c4af265f70dba38ba134f0a03ed4	optimal retailer's replenishment decisions in the epq model under two levels of trade credit policy	politica optima;cycle time;two levels of trade credit;nuevo abastecimiento;quantity production;epq;bank credit;credit bancaire;financing;pago;gestion production;credito bancario;trade credit;numerical method;optimal decision;realimentation;temps minimal;fabrication serie;politica economica;permissible delay in payments;payment;operations research;optimal policy;financiacion;inventory model;refeeding;production management;politique economique;inventory;administracion deposito;detaillant;decision optimale;minimizacion costo;paiement;economic order quantity;minimisation cout;metodo numerico;cost minimization;financement;gestion produccion;retard;economic production quantity;gestion stock;realimentacion;minimum time;fabricacion seria;quantite economique a commander;cantidad economica pedida;replenishment;retraso;politique optimale;tiempo minimo;retailers;inventory control;economic policy;methode numerique;reapprovisionnement;decision optimal	The main purpose of this paper is to investigate the optimal retailer’s replenishment decisions under two levels of trade credit policy within the economic production quantity (EPQ) framework. We assume that the supplier would offer the retailer a delay period and the retailer also adopts the trade credit policy to stimulate his/her customer demand to develop the retailer’s replenishment model under the replenishment rate is finite. Furthermore, we assume that the retailer’s trade credit period offered by supplier M is not shorter than the customer’s trade credit period offered by retailer N (M ≥ N). Since the retailer cannot earn any interest in this situation, M<N. Based upon the above arguments, this paper incorporates both Chung and Huang [14] and Huang [17] under above conditions. In addition, we model the retailer’s inventory system as a cost minimization problem to determine the retailer’s optimal replenishment decisions. Then three theorems are developed to efficiently determine the optimal replenishment decisions for the retailer. We deduce some previously published results of other authors as special cases. Finally, numerical examples are given to illustrate the theorems obtained in this paper. Then, as well as, we obtain a lot of managerial insights from numerical examples.	economic production quantity;numerical analysis;numerical method	Yung-Fu Huang	2007	European Journal of Operational Research	10.1016/j.ejor.2005.10.035	inventory control;optimal decision;economic order quantity;inventory;economics;numerical analysis;cycle time variation;marketing;operations management;eysenck personality questionnaire;economy;payment	ML	2.8251912720540657	-5.2768348387914035	96950
9eb7159c98a4c9ceb1967338b9f22281a83f0cb7	"""a note on """"a multiple-vendor single-buyer integrated inventory model with a variable number of vendors"""""""	inventory management;suppliers selection;logistic approximation;joint economic lot size;supply chain management	In this technical note, an alternative solution procedure to the model that Glock (2011) developed is presented. In particular, we take into account the same assumptions, but the total cost function is reformulated, i.e., the step-type discontinuity is replaced by a logistic approximation and the total costs of the system are computed on the whole set of preselected suppliers. Subsequently, we show that the total cost function possesses some properties in terms of convexity and continuity that allow the exploitation of standard constrained nonlinear minimization algorithms. Finally, tests conducted on the same set of problems that Glock (2011) originally considered illustrate the good performances of the solution procedure developed in this note. 2014 Elsevier Ltd. All rights reserved.	algorithm;approximation;convex function;inventory theory;loss function;nonlinear system;performance;reflections of signals on conducting lines;scott continuity	Marcello Braglia;Davide Castellano;Marco Frosolini	2014	Computers & Industrial Engineering	10.1016/j.cie.2014.05.007	mathematical optimization;supply chain management;economics;marketing;operations management;mathematical economics;welfare economics	AI	3.3643749176485915	-4.692638958544078	96961
9975f8d016b0c5d2175de2f53c1181fa25ae8c73	flow equilibria via online surge pricing		We explore issues of dynamic supply and demand in ride sharing services such as Lyft and Uber, where demand fluctuates over time and geographic location. We seek to maximize social welfare which depends on taxicab locations, passenger locations, passenger valuations for service, and the distances between taxicabs and passengers. Our only means of control is to set surge prices, then taxicabs and passengers maximize their utilities subject to these prices. We study two related models: a continuous passenger-taxicab setting, similar to the Wardrop model, and a discrete (atomic) passenger-taxicab setting. In the continuous setting, every location is occupied by a set of infinitesimal strategic taxicabs and a set of infinitesimal non-strategic passengers. In the discrete setting every location is occupied by a set of strategic agents, taxicabs and passengers, passengers have differing values for service. Afterwards we expand the continuous model to a time-dependent setting and study the corresponding online environment. The utility for a strategic taxicab that drives from u to v and picks up a passenger at v is the surge price at v minus the distance from u to v. The utility for a strategic passenger at v that gets service is the value of the service to the passenger minus the surge price at v. Surge prices are in passenger-taxicab equilibrium if there exists a min cost flow that moves taxicabs about such that (a) every taxicab follows a best response, (b) all strategic passengers at v with value above the surge price rv for v, are served and (c) no strategic passengers with value below rv are served (non-strategic infinitesimal passengers are always served). This thesis computes surge prices such that resulting passenger-taxicab equilibrium maximizes social welfare, and the computation of such surge prices is in poly time. Moreover, it is a dominant strategy for passengers to reveal their true values. We seek to maximize social welfare in the online environment, and derive tight competitive ratio bounds to this end. Our online algorithms make use of the surge prices computed over time and geographic location, inducing successive passengertaxicab equilibria.	competitive analysis (online algorithm);computation;emoticon;geographic coordinate system;minimum-cost flow problem;multistage interconnection networks;nash equilibrium;online algorithm	Amos Fiat;Yishay Mansour;Lior Shultz	2018	CoRR		online algorithm;mathematical optimization;mathematics;competitive analysis;valuation (finance);best response;strategic dominance;location;microeconomics;supply and demand;minimum-cost flow problem	ECom	-1.441764422592987	-3.253370751455984	96990
5a8b948ecebebbd1f7d4a2e7864bd4146dd195bd	simulation in criminal justice: a case study of the juvenile court system	juvenile offender;new jersey;maintenance cost;criminal justice;flow rate;sensitivity analysis;waiting time;field data;technical report;simulation model	A simulation model using GPSS-V has been developed for determining flow rates through a juvenile court system linking four serial queues beginning with arrest, through a court review, court carry-order, and court probation. Observations of distributions of waiting times and processing times provide a basis for sensitivity analysis to consider trade-offs between court resources and gains in over-all flow time. The simulation runs with induced variations in court resources show the gains in over-all flow time expressed as reduced average waiting and processing times. The field data (1975) were collected from the juvenile court system of Morris County, New Jersey.  The purpose of this paper is to study the flow of delinquents through the juvenile court system in order to examine those elements which control the rate of flow. Many courts throughout the country are back-logged and according to expert criminal justice opinion the courts need to deal with juvenile offenders swiftly and justly in order to avoid the negative consequences of higher maintenance costs to the community and the anxiety-oriented pressures on delinquents stemming from slow developing court action. (5)(6)(9)(10)  In addition to describing the entire flow process, the study permits an analysis of those resources needed to bring about changes in flow rates. Hence, trade-offs between allocated court resources and gains in flow time can be evaluated. (2)	gpss;simulation;stemming	Thomas Moranian;Nachum Finger;Nelson M. Fraiman	1977			criminal justice;actuarial science;computer science;technical report;simulation modeling;forensic engineering;world wide web;volumetric flow rate;sensitivity analysis	Networks	8.445559617194716	-7.661152742742215	97096
108ed1097cc1e4a83fb036f1de4fe505f86ef25c	periodicity of pricing and marketing efforts in a distribution channel	pricing;sequence of move;marketing efforts;distribution channel;cooperative advertising	0377-2217/$ see front matter 2013 Elsevier B.V. A http://dx.doi.org/10.1016/j.ejor.2013.02.012 ⇑ Tel.: +1 905 721 8668. E-mail address: salma.karray@uoit.ca Most research about cooperative (coop) advertising programs in channels relies on the assumption that manufacturers and retailers decide of pricing and marketing efforts simultaneously. This paper evaluates this central assumption and investigates the optimal periodicity (sequence of move) of pricing and marketing efforts (ME) decisions for a distribution channel. We develop a game theoretic model that accounts for pricing at each level of the channel, for the manufacturer’s ME mix strategies (a direct ME to consumers and coop advertising program offered to the retailer) and the retailer’s ME as well. We obtain solutions for a bilateral channel under different vertical interaction scenarios; when the channel is led by the manufacturer, the retailer or when channel members decide simultaneously of each of their marketing mix decisions (vertical Nash). We compare the effect of pricing and ME decision periodicity on outputs for each channel member. The main findings suggest that simultaneous decision-making of pricing and ME is optimal only for high enough levels of the manufacturer’s ME effects. For very highly effective marketing efforts, sequential play of pricing and ME allows channel members to implement equilibrium strategies and achieve maximum profits that would not be achieved with simultaneous decision-making. This highlights the importance of relaxing the simultaneous play assumption of pricing and ME in a distribution channel. 2013 Elsevier B.V. All rights reserved.	bilateral filter;game theory;like button;nash equilibrium;quasiperiodicity	Salma Karray	2013	European Journal of Operational Research	10.1016/j.ejor.2013.02.012	pricing;economics;marketing;operations management;advertising	ECom	-1.255927351544256	-6.112352547841355	97099
5cf0872782bec07ccc241dd3c0e87b91b0a8da9b	sequential discrete p-facility models for competitive location planning	competitive location;spatial price discrimination;discrete location models;price adjustment;nash equilibrium;for profit;bilevel programming;price discrimination;location model;oligopoly	Two new models for duopolistic competitive discrete location planning with sequential acting and variable delivered prices are introduced. If locations and prices are assumed to be set “once and for all” by the players, the resulting bilevel program is nonlinear. Under the assumption that further price adjustments are possible, i.e., that a Nash equilibrium in prices is reached, the model can be simplified to a linear discrete bilevel formulation. It is shown that in either situation players should not share any locations or markets if they strive for profit-maximization.		Kathrin Fischer	2002	Annals OR	10.1023/A:1020914122189	financial economics;mathematical optimization;economics;microeconomics;mathematical economics;price discrimination;oligopoly;nash equilibrium	AI	0.6113085174729587	-4.1848719747602905	97152
6d2dff94f53a5095e6cf20655aa003193798a0c7	optimized maintenance design for manufacturing performance improvement using simulation	performance improvement;maintenance scheduling scheme;simulation modeling;optimal system design;optimized maintenance design;auto part manufacturing production;proposed simulation;maintenance availability;overall system performance;maintenance design;product design;mean squared error;system performance;system design;production system;computer aided manufacturing;design for manufacture;maintenance engineering;simulation model;simulation	This research presents optimized maintenance design using simulation to analyze the capability of auto part manufacturing production system. The integration of simulation and optimization is used to identify critical stations, an optimal system design and maintenance scheduling schemes and evaluates their effects on the overall system performance. Most emphasis is focused on the impact on system by individual station reliability and the fluctuation of maintenance availability. The proposed simulation and optimization for maintenance design is validated through real-life application. This simulation modeling and optimization could help for manufacturing performance improvement.	design for manufacturability;mathematical optimization;production system (computer science);quantum fluctuation;real life;scheduling (computing);simulation;systems design	Ahad Ali;Xiaohui Chen;Zimin Yang;Jay Lee;Jun Ni	2008	2008 Winter Simulation Conference		maintenance engineering;computer science;systems engineering;engineering;simulation modeling;mean squared error;production system;product design;design for manufacturability;manufacturing engineering;systems design	EDA	9.002268244849951	2.2547747696141163	97285
b7e9b2cec177b3436285b7ffb2361abbdbc9a47c	on measuring supplier performance under vendor-managed-inventory programs in capacitated supply chains	performance measure;service level guarantees;service level;cost function;coordination mechanisms;customer service;system performance;linear functionals;supplier performance measures;operating characteristic;supply contracts;supply chain;vendor managed inventory;supply chain management	A widely accepted performance measures in supply chain management practice, frequency-based service levels such as fill rate and stockout rate are often considered in supply contracts under vendor-managedinventory (VMI) programs. Using a decentralized two-party capacitated supply chain model consisting of one manufacturer and one supplier in a VMI environment, we demonstrate that supplier’s service level is in general insufficient for the manufacturer to warrant the desired service level at the customer end. The method by which the supplier achieves her service level to the manufacturer also affects customer service level. By developing bounds on the customer service level, we show that the expected backorders at the supplier should also be taken into account. We suggest a supply contract that offers a menu of different combinations of supplier’s service level and expected backorders according to a linear function. Under this contract, the manufacturer can control the end customer service regardless of how the supplier manages her inventory. The supplier has complete flexibility on which combination of the two quantities on the menu to choose according to her own cost functions. Because it does not require any detailed information on supplier’s operational characteristics nor her costs, this kind of contract is expected to be easily implementable. In addition, we derive an estimate of the customer service level in terms of the new measures. Our findings have direct implications to supply chain metrics in general: The local service levels are insufficient measures to guarantee the system wide performance. Alternative local measures and/or coordination mechanisms should be employed to achieve desired system performance. Our analysis illustrates a possible way to explore such alternative measures.		Ki-Seok Choi;J. G. Dai;Jing-Sheng Song	2004	Manufacturing & Service Operations Management	10.1287/msom.1030.0029	service level requirement;service level objective;supply chain management;service level;economics;service management;marketing;operations management;supply chain;supplier relationship management;commerce	Metrics	0.026940045594883246	-6.490161435013742	97308
4d635fd329493043d40833553cc7d7f13110f1a0	bayes-nash equilibria of the generalized second-price auction	sponsored search;click through rates;generalized second price auction;bayes nash equilibrium;position auctions	We develop a Bayes–Nash analysis of the generalized second-price (GSP) auction, the multi-unit auction used by search engines to sell sponsored advertising positions. Our main result characterizes the efficient Bayes–Nash equilibrium of the GSP and provides a necessary and sufficient condition that guarantees existence of such an equilibrium. With only two positions, this condition requires that the click–through rate of the second position is sufficiently smaller than that of the first. When an efficient equilibrium exists, we provide a necessary and sufficient condition for the auction revenue to decrease as click–through rates increase. Interestingly, under optimal reserve prices, revenue increases with the click–through rates of all positions. Further, we prove that no inefficient equilibrium of the GSP can be symmetric. Our results are in sharp contrast with the previous literature that studied the GSP under complete information.	nash equilibrium	Renato Gomes;Kane S. Sweeney	2014	Games and Economic Behavior	10.1016/j.geb.2012.09.001	walrasian auction;financial economics;auction algorithm;generalized second-price auction;click-through rate;economics;vickrey–clarke–groves auction;revenue equivalence;english auction;double auction;microeconomics;mathematical economics;auction theory	ECom	-2.8149903140522965	-4.088035491770662	97440
7216af87c441c6d7e75cbbcc1616dc0a7c7bbaa8	truthful approximation mechanisms for restricted combinatorial auctions.	mechanism design combinatorial auctions multi unit auctions multi unit combinatorial auctions approximation algorithms;approximate algorithm;greedy heuristic;multi unit auction;mechanism design;lp relaxation;combinatorial auction	When attempting to design a truthful mechanism for a computationally hard problem such as combinatorial auctions, one is faced with the problem that most efficiently computable heuristics can not be embedded in any truthful mechanism (e.g. VCG-like payment rules will not ensure truthfulness). We develop a set of techniques that allow constructing efficiently computable truthful mechanisms for combinatorial auctions in the special case where each bidder desires a specific known subset of items and only the valuation is unknown by the mechanism (the single parameter case). For this case we extend the work of Lehmann O’Callaghan, and Shoham, who presented greedy heuristics. We show how to use IF-THEN-ELSE constructs, perform a partial search, and use the LP relaxation. We apply these techniques for several canonical types of combinatorial auctions, obtaining truthful mechanisms with provable approximation ratios.	approximation;computable function;embedded system;greedy algorithm;heuristic (computer science);lagrangian relaxation;linear programming relaxation;provable security;referring expression generation;value (ethics)	Ahuva Mu'alem;Noam Nisan	2002		10.1016/j.geb.2007.12.009	mechanism design;mathematical optimization;greedy algorithm;combinatorial auction;economics;linear programming relaxation;microeconomics;mathematical economics	ECom	-2.4017808878006073	-0.904128116051362	97510
2132c9c22a9c44e997542a3f73339e096becbfb8	truthfulness with value-maximizing bidders: on the limits of approximation in combinatorial markets	approximation mechanisms;game theory;auctions bidding	In some markets bidders want to maximize value subject to a budget constraint rather than payoff. This is different to the quasilinear utility functions typically assumed in auction theory and leads to different strategies and outcomes. We refer to bidders who maximize value as value bidders. While simple single-object auction formats are truthful, standard multi-object auction formats allow for manipulation. It is straightforward to show that there cannot be a truthful and revenue-maximizing deterministic auction mechanism with value bidders and general valuations. Approximation has been used as remedy to achieve truthfulness on other mechanism design problems, and we study which approximation ratios we can get from truthful mechanisms. We show that the approximation ratio that can be achieved with a deterministic and truthful approximation mechanism with n bidders cannot be higher than 1/n for general valuations. For randomized approximation mechanisms there is a framework with a ratio that is tight.	approximation algorithm;auction algorithm;deterministic algorithm;randomized algorithm	Salman Fadaei;Martin Bichler	2017	European Journal of Operational Research	10.1016/j.ejor.2016.12.031	financial economics;game theory;economics;vickrey–clarke–groves auction;english auction;microeconomics;welfare economics;auction theory	ECom	-2.544446429120092	-1.7156563693618891	97542
6196b2e62b2b94196e4ce3ebd6f70c09f910655d	multiagent resource allocation in k -additive domains: preference representation and complexity	article accepte pour publication ou publie;multiagent system;multiagent resource allocation;negociation;resource allocation;software agent;utility function;universiteitsbibliotheek;computational complexity;winner determination problem;preference representation;combinatorial optimisation;negotiation;multiagent systems;combinatorial auction	We study a framework for multiagent resource allocation where autonomous software agents negotiate over the allocation of bundles of indivisible resources. Connections to well-known combinatorial optimisation problems, including the winner determination problem in combinatorial auctions, shed light on the computational complexity of the framework. We give particular consideration to scenarios where the preferences of agents are modelled in terms of k-additive utility functions, i.e. scenarios where synergies between different resources are restricted to bundles of at most k items.	agent-based model;autonomous robot;combinatorial optimization;computational complexity theory;mathematical optimization;software agent;synergy;utility functions on indivisible goods	Yann Chevaleyre;Ulrich Endriss;Sylvia Estivie;Nicolas Maudet	2008	Annals OR	10.1007/s10479-008-0335-0	mathematical optimization;simulation;economics;computer science;knowledge management;multi-agent system;management science;negotiation	AI	-3.613991110114518	-0.8903305834696869	97598
42ff4ae651bc5cf80bc952fa5b4b8c39cbb8a2e8	optimal production plans and shipment schedules in a supply-chain system with multiple suppliers and multiple buyers	intervalo tiempo;navio;optimal solution;politica optima;completion time;logistique;materia prima;raw materials;gestion production;matiere premiere;procurement;efficiency;produit fini;temps achevement;by product;contrato;optimal policy;time interval;horizonte finito;production management;supply chains;network representation;fournisseur multiple;eficacia;planificacion;product cycle;logistics;horizon fini;marche contrat;sous produit;proveedor multiple;multiple suppliers and buyers;scheduling;gestion produccion;subproducto;finished product;multiple supplier;efficacite;finite horizon;planning;supply chain;cout production;producto preterminado;ship;production cost;planification;tiempo acabado;politique optimale;fixed interval;ordonnancement;reglamento;supply chains multiple suppliers and buyers network representation;coste produccion;logistica;intervalle temps;navire	This research addresses an optimal policy for production and procurement in a supply-chain system with multiple non-competing suppliers, a manufacturer and multiple non-identical buyers. The manufacturer procures raw materials from suppliers, converts them to finished products and ships the products to each buyer at a fixed-interval of time over a finite planning horizon. The demand of finished product is given by buyers and the shipment size to each buyer is fixed. The problem is to determine the production start time, the initial and ending inventory, the cycle beginning and ending time, the number of orders of raw materials in each cycle, and the number of cycles for a finite planning horizon so as to minimize the system cost. A surrogate network representation of the problem developed to obtain an efficient, optimal solution to determine the production cycle and cycle costs with predetermined shipment schedules in the planning horizon. This research prescribes optimal policies for a multi-stage production and procurements for all shipments scheduled over the planning horizon. Numerical examples are also provided to illustrate the system.		Bhaba R. Sarker;Ahmad Diponegoro	2009	European Journal of Operational Research	10.1016/j.ejor.2008.01.025	economics;marketing;operations management;supply chain;operations research	Robotics	5.327882862406159	-2.8904328395876187	97946
1b59bc477736d572c5312e0f40ba7b72eeb30264	a qualitative vickrey auction	metric space;utility function;vickrey auction;vickrey clarke groves mechanism;mechanism design;individual rationality;mechanism design without money;auctions;open source	Restricting the preferences of the agents by assuming that their utility functions linearly depend on a payment allows for the positive results of the Vickrey auction and the Vickrey-Clarke-Groves mechanism. These results, however, are limited to settings where there is some commonly desired commodity or numeraire--money, shells, beads, etcetera--which is commensurable with utility. We propose a generalization of the Vickrey auction that does not assume that the agents' preferences are quasilinear, but nevertheless retains some of the Vickrey auction's desirable properties. In this auction, a bid can be any alternative, rather than just a monetary offer. As a consequence, the auction is also applicable to situations where there is a fixed budget, or no numeraire is available at all (or it is undesirable to use payments for other reasons)--such as, for example, in the allocation of the task of contributing a module to an open-source project. We show that in two general settings, this qualitative Vickrey auction has a dominant-strategy equilibrium, invariably yields a weakly Pareto efficient outcome in this equilibrium, and is individually rational. In the first setting, the center has a linear preference order over a finite set of alternatives, and in the second setting, the bidders' preferences can be represented by continuous utility functions over a closed metric space of alternatives and the center's utility is equipeaked. The traditional Vickrey auction turns out to be a special case of the qualitative Vickrey auction in this second setting.	auction algorithm;edmund m. clarke;open-source software;pareto efficiency	Paul Harrenstein;Mathijs de Weerdt;Vincent Conitzer	2008		10.1145/1566374.1566403	walrasian auction;auction algorithm;mechanism design;vickrey auction;generalized second-price auction;economics;unique bid auction;metric space;vickrey–clarke–groves auction;proxy bid;revenue equivalence;english auction;microeconomics;mathematical economics;welfare economics;auction theory	ECom	-3.027537392833881	-2.4121125425853243	97999
e2660aef44dc47eb9258b6d1590ff10d8e8aa923	lot sizing with carbon emission constraints	dynamic programming;complexity;lot sizing;carbon emission	This paper introduces new environmental constraints, namely carbon emission constraints, in multi-sourcing lot-sizing problems. These constraints aim at limiting the carbon emission per unit of product supplied with different modes. A mode corresponds to the combination of a production facility and a transportation mode and is characterized by its economical costs and its unitary carbon emission. Four types of constraints are proposed and analyzed in the single-item uncapacitated lot-sizing problem. The periodic case is shown to be polynomially solvable, while the cumulative, global and rolling cases are NP-hard. Perspectives to extend this work are discussed.		Nabil Absi;Stéphane Dauzère-Pérès;Safia Kedad-Sidhoum;Bernard Penz;Christophe Rapine	2013	European Journal of Operational Research	10.1016/j.ejor.2012.11.044	mathematical optimization;complexity;computer science;operations management;dynamic programming;mathematics;natural resource economics	Vision	9.563329792899943	-2.7304201247493958	98170
e443206a84364beb89e612d12ef81c710c00bd50	approximate portfolio analysis	risk attitudes;portfolio selection;risk aversion;mean variance;coarse utility;mean variance analysis;measure of risk;risk attitude;value function;weight function;portfolio analysis;optimal portfolio	This paper presents a portfolio selection model based on the idea of approximation. The model describes a portfolio by its decumulative distribution curve and a preference structure by a family of convex indierence curves. It prescribes the optimal portfolio as the one whose decumulative curve has the highest tangent indierence curve. The model extends the mean±variance model in the sense that it does not restrict the return distributions of assets to be normal. While under the assumption of normality, the model simpli®es to the mean±variance model. The model has a measure of risk attitudes that resembles the Arrow±Pratt measure while combining both wealth and probability attitudes. Using this measure, we show that the smaller the curvature of a value function and the larger the curvature of a weighting function, the more risk averse an agent. Ó 1999 Elsevier Science B.V. All rights reserved.	approximation;bellman equation;concave function;expected utility hypothesis;graphical model;koch snowflake;lunar lander (video game series);lunar lander challenge;modern portfolio theory;risk aversion;weight function	Liping Liu	1999	European Journal of Operational Research	10.1016/S0377-2217(98)00363-4	financial economics;post-modern portfolio theory;mathematical optimization;weight function;actuarial science;risk aversion;economics;expected shortfall;modern portfolio theory;portfolio optimization;spectral risk measure;mathematics;distortion risk measure;bellman equation;welfare economics;time consistency;statistics	AI	0.24083997370033064	-2.1362927585387994	98428
b6160a17ad762336210b1768f02ce1e0c0d71b5c	a stochastic programming model for asset liability management of a finnish pension company	numerical solution;econometric model;discretization;econometric modeling;optimization problem;stochastic optimization;asset liability management;portfolio insurance;stochastic programming;insurance companies	This paper describes a stochastic programming model that was developed for asset liability management of a Finnish pension insurance company. In many respects the model resembles those presented in the literature, but it has some unique features stemming from the statutory restrictions for Finnish pension insurance companies. Particular attention is paid to modeling the stochastic factors, numerical solution of the resulting optimization problem and evaluation of the solution. Out-of-sample tests clearly favor the strategies suggested by our model over static fixed-mix and dynamic portfolio insurance strategies.	algebraic modeling language;application lifecycle management;approximation algorithm;convex optimization;decision problem;discretization;linear algebra;mathematical optimization;nonlinear system;numerical method;numerical partial differential equations;optimization problem;programming model;solver;stemming;stochastic optimization;stochastic programming;time series	Petri Hilli;Matti Koivu;Teemu Pennanen;Antero Ranne	2007	Annals OR	10.1007/s10479-006-0135-3	financial economics;mathematical optimization;actuarial science;economics;stochastic modelling;stochastic optimization;finance;mathematics;wilkie investment model;econometric model	AI	1.8415308354234012	-2.715945102803996	98462
9331d2831cb67632dbff55026823dd1e3b6c5a95	effects of contrarian investor type in asset price dynamics	asset prices;bifurcation;chaotic dynamics;noninvertible maps;heterogeneous beliefs;asset pricing;interacting agents	We develop an asset pricing model based on the interaction of heterogeneous trading groups. In addition to the two main trader groups, fundamentalists and trend-chasing chartists, we include a third significant group known as contrarian chartists. We model the case of opportunistic contrarian behavior, where the contrarian group disagrees with the trend-chasing chartists only when the return differential is high. We also consider absolute contrarian behavior, in which the contrarians consistently disagree with trend-chasers. The models are nonlinear planar maps, exhibiting period doubling, Neimark–Sacker and global bifurcations leading to local chaotic behavior. Absolute contrarian behavior is found to have a moderating effect on price change, while opportunistic contrarian behavior is found to further complicate the price cycles present in other models.	benchmark (computing);bifurcation theory;capital asset pricing model;chaos theory;dynamical system;map;nonlinear system;opportunistic reasoning;period-doubling bifurcation;traders;volatility;word lists by frequency	Natasha Kirby;Andrew Foster	2009	I. J. Bifurcation and Chaos	10.1142/S0218127409024244	capital asset pricing model	ECom	-4.116825269441011	-4.6793256436831046	98772
3489aaeb5b9484a91d06f39966fd65352a51ad40	collaboration among small shippers in a transportation market	saving allocation mechanisms;satisfiability;stochastic system;shipper collaboration;logistics;stochastic demand;control of stochastic systems	Intense competition in markets is pushing companies to increase their operational efficiency. One possible way to achieve increased efficiency is through cooperation with other companies. We study the coalition formation among small shippers in a transportation market characterized by uncertain demand. We analyze the decisions taken by the coalition and study the effect of shipper characteristics on the benefit of collaboration. Analysis shows that the shippers always benefit from the coalition, but when the benefits are to be allocated, the coalition may not always guarantee the budget balance, which is elementary for sustainability of any coalition. Using a game theoretical approach this study proposes saving allocation mechanisms and discusses the conditions that lead to a balanced budget. 2011 Elsevier B.V. All rights reserved.		Ozhan Yilmaz;Seçil Savasaneril	2012	European Journal of Operational Research	10.1016/j.ejor.2011.11.018	logistics;economics;marketing;operations management;microeconomics;commerce;satisfiability	AI	-1.3103647923395918	-5.5618741723341465	98823
33e126bb4a27718e1aa44115479e06beaecd90c8	asymptotic optimal strategy for portfolio optimization in a slowly varying stochastic environment		In this paper, we study the portfolio optimization problem with general utility functions and when the return and volatility of underlying asset are slowly varying. An asymptotic optimal strategy is provided within a specific class of admissible controls under this problem setup. Specifically, we first establish a rigorous first order approximation of the value function associated to a fixed zeroth order suboptimal trading strategy, which is given by the heuristic argument in [J.-P. Fouque, R. Sircar and T. Zariphopoulou, Mathematical Finance, 2016]. Then, we show that this zeroth order suboptimal strategy is asymptotically optimal in a specific family of admissible trading strategies. Finally, we show that our assumptions are satisfied by a particular fully solvable model.	algorithmic trading;asymptote;asymptotically optimal algorithm;bellman equation;decision problem;heuristic;mathematical optimization;optimization problem;order of approximation;volatility	Jean-Pierre Fouque;Ruimeng Hu	2017	SIAM J. Control and Optimization	10.1137/16M1066762	financial economics;mathematical optimization;economics;mathematical economics;welfare economics	AI	0.933007805929644	-1.9479796190666336	99072
616ad83f49c613775e18a2399b40738a933f18ab	a multi-component and multi-failure mode inspection model based on the delay time concept	optimal inspection interval;maintenance;point process;failure mode;inspection;asymptotic solution;delay time	The delay time concept and the techniques developed for modelling and optimising plant inspection practices have been reported in many papers and case studies. For a system comprised of many components and subject to many different failure modes, one of the most convenient ways to model the inspection and failure processes is to use a stochastic point process for defect arrivals and a common delay time distribution for the duration between defect the arrival and failure of all defects. This is an approximation, but has been proven to be valid when the number of components is large. However, for a system with just a few key components and subject to few major failure modes, the approximation may be poor. In this paper, a model is developed to address this situation, where each component and failure mode is modelled individually and then pooled together to form the system inspection model. Since inspections are usually scheduled for the whole system rather than individual components, we then formulate the inspection model when the time to the next inspection from the point of a component failure renewal is random. This imposes some complication to the model, and an asymptotic solution was found. Simulation algorithms have also been proposed as a comparison to the analytical results. A numerical example is presented to demonstrate the model. & 2010 Elsevier Ltd. All rights reserved.	algorithm;approximation;approximation algorithm;carr–benkler wager;correctness (computer science);ergodicity;estimation theory;expectation propagation;failure cause;markov chain;numerical analysis;opportunistic reasoning;point process;randomness;recursion;simulation;software bug;software inspection	Wenbin Wang;Dragan Banjevic;Michael G. Pecht	2010	Rel. Eng. & Sys. Safety	10.1016/j.ress.2010.04.004	reliability engineering;inspection;engineering;point process;mathematics;forensic engineering;failure mode and effects analysis;statistics	Embedded	6.961175568316169	-0.49875978427817164	99112
e00b33c7f29390b72fcbf3d2985733703658e999	on a stochastic, irreversible investment problem	intervalo tiempo;economie;modelizacion;economia;continuous time;control optimo;employment;capital;consumption;optimisation;replacement;integral equation;singularite;ombre;empleo;arret optimal;cout capital;remplacement;optimizacion;ito equation;inversion;proceso irreversible;frontera movil;moving boundary;temps continu;91b70;econometria;tiempo continuo;93e20;singular control;lagrange multiplier;time interval;investment;capital cost;consumo;integrale stochastique;optimal control;modelisation;interrupcion optima;integral estocastica;sombra;coste capital;commande stochastique;shadow;option reelle;option americaine;commande optimale;consommation;processus irreversible;frontiere mobile;equation ito;multiplicateur lagrange;real option;investissement;equation integrale;singularidad;stochastic integral;multiplicador lagrange;stochastic control;optimal stopping;control estocastico;60g40;ecuacion integral;reemplazo;optimization;american option;economy;econometrics;singular stochastic control;stochastic model;moving free boundary;91b28;instantaneous stopping equation;modeling;opcion americana;modelo estocastico;modele stochastique;econometrie;opcion real;irreversible investment;commande singuliere;control singular;irreversible process;singularity;emploi;intervalle temps;ecuacion ito	The productive sector of the economy, represented by a single firm employing labour to produce the consumption good, is studied in a stochastic continuous time model on a finite time interval. The firm must choose the optimal level of employment and capital investment in order to maximize its expected total profits. In this stochastic control problem the firm’s capacity is modelled as an Itô process controlled by a monotone process, possibly singular, that represents the cumulative real investment. It is optimal to invest when the shadow value of installed capital exceeds the capital’s replacement cost; this threshold is the free boundary of a related optimal stopping problem which we recast as a stopping problem without integral cost, similar to the American Option Problem. Then, under a regularity condition, we characterize the free boundary as the unique solution of a nonlinear integral equation.	nonlinear system;optimal stopping;stochastic control;monotone	Maria B. Chiarolla;Ulrich G. Haussmann	2009	SIAM J. Control and Optimization	10.1137/070703880	capital cost;inversion;singularity;mathematical optimization;shadow;irreversible process;optimal stopping;optimal control;stochastic control;consumption;capital;investment;calculus;mathematics;mathematical economics;lagrange multiplier;integral equation	Theory	2.5782356888955964	-2.7262024167032273	99115
a2003c8afd978bef0954d451b4b267ffcabbcde2	minimization of network losses with financial incentives in voluntary demand response		This paper delivers a customer voluntary demand response (CVDR) program to help the load serving entity (LSE) curtail peak demand and cutoff carbon emission. LSE provides financial incentives to customers who are willing to curtail energy consumption during peak demand hours. A bilevel problem is proposed to determine the optimal power curtailment and financial incentives to achieve equivalent minimal cost for LSE and maximal utility function for customers simultaneously. The effects of the CVDR program are examined with two benchmark radial systems: 3-bus and the IEEE 8500-Node networks. All simulations are carried out with General Algebraic Modeling System and MATLAB. Numerical studies unveil that CVDR enhances customer’s willingness in demand response program and achieve economic savings and peak shaving for LSE.	benchmark (computing);load management;matlab;maximal set;radial (radio);simulation;utility	Jun Wang;Qi Huang	2018	IEEE Access	10.1109/ACCESS.2018.2797272	computer science;energy consumption;peak demand;finance;demand response;load management;turnover;incentive;peaking power plant	Metrics	3.64934163053627	4.120635191906082	99158
caa4b2b21de6043963de13cd3a7fc5db18193626	assessment of a multi-agent mixed-integer optimization algorithm for battery scheduling		In the present paper, the problem of scheduling populations of energy storage systems including asymmetric charging and discharging efficiencies is formulated as a mixed integer program. The problem is solved using both a novel distributed local mixed integer solution scheme and a global mixed integer solver. We draw upon a detailed numerical comparison of both methods via a simulation example built using real PV generation data consisting of 54 energy storage systems over a horizon of 48 time steps leading to 2640 integer variables. Our results indicate that the distributed local solution method delivers values comparable to the centralized global solver but in significantly reduced time.	algorithm;centralized computing;integer programming;linear programming;mathematical optimization;multi-agent system;numerical analysis;population;scheduling (computing);simulation;solver	Alexander Murray;Timm Faulwasser;Veit Hagenmeyer	2018		10.1145/3208903.3212058	battery (electricity);scheduling (computing);mathematical optimization;computer science;solver;integer;energy storage	EDA	4.991635095491158	3.949085133876381	99308
a756c94e32b085fe234a766bf6652bc0f56cce6a	an asymptotic solution of inventory lot-size models with homogeneous time-dependent demand functions	time dependent;asymptotic solution;lot sizing	This paper considers a deterministic inventory lot-size model without backlogs with a continuous, time-dependent demand function of the form kt with k(>0) and r(> 2) known parameters and t(>--to O) for time. Near closed-form expressions are developed for the asymptotic optimal replenishment times and lot sizes as the time horizon tends to infinity. These expressions are easy to calculate and give good approximations to the finite horizon problem. The results extend those of Barbosa and Friedman (Management Sci., 24 (1980), pp. 819-826), where the considerably restrictive condition to 0 is required. An important special case of the present work is when the demand function is affine (r 1).	approximation;horizon effect	Moshe Friedman;Jeffrey L. Winter	1980	SIAM J. Matrix Analysis Applications	10.1137/0601035	mathematical optimization;mathematics;mathematical economics	Theory	3.311361310259644	-2.4134456195865517	99415
1fbef0b86933cb87909e1e52c2f61338f736b9a2	game theory applied to dynamic duopoly problems with production constraints	dynamic duopoly;game theory;nash solutions;decision theory;differential games;economics	In this paper an application of differential game theory in the area of microeconomics is presented. The problem considered is that of a dynamic duopoly where two firms each limited by a maximum capacity of production, share the same market, and try simultaneously but independently to maximize their profits over a certain planning horizon. While the static duopoly theory does not address itself to the question of the process by which changes in the price are brought about, but only compares the prices before and after the change takes place, the dynamic market theory, considered in this paper, allows for an analysis of how the price changes with time and what trajectory it follows. Necessary conditions for the existence of a Nash equilibrium solution in the general case are discussed and more specific results for the special case of linear demand and quadratic cost functions are developed.	game theory	Marwan A. Simaan;Takashi Takayama	1978	Automatica	10.1016/0005-1098(78)90022-5	price of stability;implementation theory;game theory;minimax;positive political theory;decision theory;repeated game;mathematical economics;statistics;duopoly	NLP	-0.22596747047305762	-1.8892203234810017	99537
a72c3852b1fab16d2bc69786618fad7bcbcef305	optimization problems of replacement first or last in reliability theory	replacement last;age replacement;working cycle;periodic replacement;minimal repair;cumulative damage model	This paper takes up age and periodic replacement last models with working cycles, where the unit is replaced before failure at a total operating time T or at a random working cycle Y, whichever occurs last, which is called replacement last. Expected cost rates are formulated, and optimal replacement policies which minimize them are discussed analytically. Comparisons between such a replacement last and the conventional replacement first are made in detail. It is determined theoretically and numerically which policy is better than the other according to the ratios of replacement costs and how the mean time of working cycles affects the comparison results. It is also shown that the unit can be operating for a longer time and avoid unnecessary replacements when replacement last is done. For further studies, expected cost rates of modified models and their applications in a standard cumulative damage model with working cycles are obtained and computed numerically. Finally, case studies on replacement last and first in maintaining electronic systems of naval ships under battle and non-battle statuses are given.	reliability engineering	Xufeng Zhao;Toshio Nakagawa	2012	European Journal of Operational Research	10.1016/j.ejor.2012.05.035	operations management	Theory	7.0512576732098555	-1.061641150093543	99833
1a0396b9b887141352cd594a6384bea7610c70a2	the merger of discrete event simulation with activity based costing for cost estimation in manufacturing environments	discrete event simulation;numerous point cost estimate;abc model;physical system;discrete-event simulation;improved cost estimate;cost estimation;confidence interval estimate;various cost estimate;underlying cost structure;discrete-event simulation modeling;process condition;statistical inference;manufacturing;decision support systems;scheduling;urban planning;costing;point estimation;confidence interval;information operations;industrial engineering;planning;stochastic processes;activity based costing	"""Activity based costing (ABC) has revolutionized product costing, planning, and forecasting in the last decade. It is based on a philosophy of estimation that: """"it is better to be approximately right, than precisely wrong."""" The philosophy of discrete-event simulation modeling follows a similar tack, where statistical inference and the stochastic nature of processes are used to replicate the behavior of a physical system. In this work, ABC and discrete-event simulation are linked to provide an improved costing, planning, and forecasting tool. Numerous point cost estimates are generated by the ABC model, using driver values obtained from a discrete-event simulation of the process. The various cost estimates can be used to produce confidence interval estimates of both the physical system and underlying cost structure. Rather than having a single point estimate of a product's cost, it is now possible to produce the range of costs to be expected as process conditions vary. This improved cost estimate will support more informed operational and strategic decisions."""	self-replicating machine;simulation	Ulrich von Beck;John W. Nowak	2000			stochastic process;process costing;simulation;computer science;engineering;urban planning;management science;target costing;activity-based costing;cost estimate;statistics	Robotics	7.224040338194192	-5.168324608840562	99841
b11c7580cb6e6173a3d6aef70b06fb8424074649	forward rate dependent markovian transformations of the heath-jarrow-morton term structure model	term structure models;markovian transformations;bond pricing;dierential equation;ordinary differential equation;journal article;interest rate;heath jarrow morton;bond price;term structure of interest rates;heath jarrow morton model;forward rates	In this paper, a class of forward rate dependent Markovian transformations of the Heath-Jarrow-Morton [HJM92] term structure model are obtained by considering volatility processes that are solutions of linear ordinary differential equations. These transformations generalise the Markovian systems obtained by Carverhill [Car94], Ritchken and Sankarasubramanian [RS95], Bhar and Chiarella [BC97], and Inui and Kijima [IK98], and also generalise the bond price formulae obtained therein. Introduction In the risk neutral Heath-Jarrow-Morton [HJM92] term structure model, evolution of the forward rate process is completely determined by the forward rate volatilities. The HJM framework is very general and contains many of the earlier interest rate models as special cases, including [Vas77], [CIR85], [HW90], and [BK91], among others. One drawback of the generality, from a practical perspective, is that the model is non-Markovian in general and consequently does not readily lend itself to efficient solution techniques. Suitable restrictions on volatility processes led Carverhill [Car94], Ritchken and Sankarasubramanian [RS95], Bhar and Chiarella [BC97], and Inui and Kijima [IK98] to transform the HJM model to finite dimensional Markovian systems. In [RS95] and [BC97] only the one-factor HJM models are considered, while, under a more transparent framework, [IK98] generalise the [RS95] models to the multifactor case. In [BG99] and [BS99], a theoretical framework is introduced for obtaining necessary and sufficient conditions under which HJM models are Markovian, and for constructing minimal realisation in such cases. The [BC97] model has the feature that spot rate volatility may be an arbitrary function of the spot rate, and although the Markovian systems of [RS95] and [IK98] have the same feature, the bond price formulae obtained therein applies to a more general class of volatility processes, such as those which depend on a finite number of fixed tenor forward rates. In each case, the forward rate volatility processes are expressible as a product of the spot rate volatility and a path-independent function. It should be noted that although [RS95] and [BC97] both consider the one-factor HJM model, they overlap only for a small set of volatility processes. Date: First version January 6, 1998. Current revision March 30, 1999. Printed April 23, 1999. 1This fact does not appear to have been noted by the authors however. 1 2 CARL CHIARELLA AND OH KANG KWON In this paper, a common generalisation of the above models is obtained, in which the multifactor HJM model is transformed to a finite dimensional Markovian system, and in particular, a multifactor generalisation of the [BC97] model is obtained. Further, the volatility processes in the generalised models are allowed to be arbitrary functions of a finite number of fixed tenor forward rates. Consequently, they include finite dimensional forward rate dependent Markovian transformations of the multifactor HJM model. The key observation in [IK98] was that when volatility processes σi(t, T, ω), 1 ≤ i ≤ n, satisfy the condition ∂Tσi(t, T, ω) ∂T = κi(T )σi(t, T, ω), (1) and κi(T ) are path independent functions of T , then the n-factor HJM model can be transformed to a 2n-dimensional Markovian system, and the bond price can be obtained in terms of the 2n state variables. The condition (1) arises naturally from the desire to replace path dependent terms in the differential of the spot rate by an expression involving the spot rate itself, and is in fact sufficient to reduce the HJM model to a finite dimensional Markovian system, as described in [RS95] and [IK98]. Let Li = ∂/∂T − κi(T ). Then (1) can be rewritten Liσi(t, T, ω) = 0. That is, the [IK98] condition requires that, for each t, the volatility processes σi(t, T, ω) satisfy a first order, linear, homogeneous, ordinary differential equation in T . The essentially arbitrary initial condition for the differential equation then allows the spot volatility σi(t, t, ω) to be unrestricted. However, in order for the corresponding model to transform to a Markovian system with respect to state variables introduced in [RS95] and [IK98], the initial condition must be of the form σi(t, t, ω) = σi(t, t, r(t, ω)). (2) That is, the spot volatility must be a function of the time variable t, and the spot rate r(t, ω). As mentioned earlier, although (2) is required to transform to a Markovian system, the bond price formula obtained in [IK98] applies to a larger class of volatility processes. In this paper, the approach of [IK98] is generalised by requiring that each σi(t, T, ω) is a function of t, T , and m forward rates f(t, t+ς1, ω), . . . , f(t, t+ςm, ω), so that σi(t, T, ω) = σi(t, T, f(t, t+ ς1, ω), . . . , f(t, t+ ςm, ω)), (3) and satisfies a differential equation of the form Liσi(t, T, ω) = 0, where Li = ∂i ∂Tmi − mi−1 ∑ j=0 κi,j(T ) ∂ ∂T j (4) is an mi-th order linear differential operator and the coefficients κi,j(T ) are path independent functions of T . The corresponding n-factor HJM model can then be transformed to a finite dimensional Markovian system of dimension at most m ∑n i=1m 2 i (mi + 3)/2. Further, for each i, the mi arbitrary boundary conditions for the differential equation, Liσi(t, T, ω) = 0, allow σi(t, t + T, ω) to be arbitrary functions of the forward rates f(t, t+ ς1, ω), . . . , f(t, t+ ςm, ω). As in [RS95] and [IK98], although the bond price formulae given in §4 remains valid for a more general class of volatility processes, the restriction (3) is required to obtain a Markovian system. 2The ω in σi(t, T, ω) represents the dependence of the volatility process on the path followed by the underlying Wiener process. See §1. 3With respect to the state variables introduced in [IK98]. FORWARD RATE DEPENDENT MARKOVIAN HJM MODELS 3 The outline of the paper is as follows. It begins with a brief review of the HJM term structure model and the parametrisation, T = t+ ς, due to Brace and Musiela [BM94] in §1. The main results of this paper are then presented in §2, in which the transformation of the multifactor HJM model to finite dimensional Markovian systems is outlined. Natural extensions of the [IK98] model are considered in §4, and explicit expressions for the bond price as a function of the state variables are obtained for these models. Finally, the paper concludes in §5. 1. Risk Neutral Heath-Jarrow-Morton Model and the Brace-Musiela Parametrisation This section reviews in brief the HJM model and the parametrisation, T = t+ ς, introduced by Brace and Musiela [BM94]. For details, refer to [HJM92], [BM94], [MR97], or [Bjö96]. 1.1. Risk Neutral Heath-Jarrow-Morton Model. Fix a trading interval [0, τ ], τ > 0, and let (Ω,F ,P) be a probability space, where Ω is the set of states of the economy, F is the σ-algebra of measurable events, and P is a probability measure on (Ω,F). It is assumed that there are n independent standard P-Brownian motions W i t , 1 ≤ i ≤ n, that generate a complete right continuous filtration {Ft}0≤t≤τ on (Ω,F). For each maturity T ∈ [0, τ ], the time t instantaneous forward rate f(t, T, ω) in the risk-neutral n-factor HJM model is a stochastic process determined by suitably well-behaved volatility processes σi(t, T, ω), 1 ≤ i ≤ n, and evolves according to the stochastic integral equation f(t, T, ω) = f(0, T, ω) + n ∑	brownian motion;c date and time functions;capability maturity model;coefficient;initial condition;kyoichi kijima;path dependence;stochastic process;volatility	Carl Chiarella;Oh Kang Kwon	2001	Finance and Stochastics	10.1007/PL00013533	financial economics;econometrics;economics;bond valuation;finance;mathematical economics	ML	2.2029880221676765	-1.7178632305295998	100044
8e402551d94d17613a21dab0897c25f8d38e91ae	demand learning and dynamic pricing under competition in a state-space framework	demand learning;optimisation;learning algorithm;game theory;competition;revenue management;nonparametric statistics;pricing;differential variational inequality;nonlinear time series competition demand learning differential variational inequality dynamic pricing markov chain monte carlo;strategic planning;nonlinear time series;monopoly;sensitivity;dynamic pricing;estimation;markov chain monte carlo;markov chain monte carlo methods;marketing;state space;markov process;revenue maximization;taxation;mathematical model;variational inequality;simulation study;predictive models;prediction model;mathematical model equations sensitivity pricing estimation markov processes predictive models;markov processes;state space model;learning strategies;taxation game theory marketing markov processes monopoly monte carlo methods nonparametric statistics oligopoly optimisation pricing strategic planning;monte carlo methods;oligopoly;differential variational inequality revenue optimization framework dynamic pricing oligopoly market monopoly market state space model revenue management problem game theoretic demand dynamics nonparametric technique demand learning algorithm markov chain monte carlo method model parameter estimation unobserved state variable functional coefficients future price sensitivities optimal pricing policy planning period revenue maximizing problem	In this paper, we propose a revenue optimization framework integrating demand learning and dynamic pricing for firms in monopoly or oligopoly markets. We introduce a state-space model for this revenue management problem, which incorporates game-theoretic demand dynamics and nonparametric techniques for estimating the evolution of underlying state variables. Under this framework, stringent model assumptions are removed. We develop a new demand learning algorithm using Markov chain Monte Carlo methods to estimate model parameters, unobserved state variables, and functional coefficients in the nonparametric part. Based on these estimates, future price sensitivities can be predicted, and the optimal pricing policy for the next planning period is obtained. To test the performance of demand learning strategies, we solve a monopoly firm's revenue maximizing problem in simulation studies. We then extend this paradigm to dynamic competition, where the problem is formulated as a differential variational inequality. Numerical examples show that our demand learning algorithm is efficient and robust.	algorithm;coefficient;game theory;markov chain monte carlo;mathematical optimization;monopoly;monte carlo method;numerical method;programming paradigm;simulation;social inequality;state space;variational inequality;variational principle	Byung Do Chung;Jiahan Li;Tao Yao;Changhyun Kwon;Terry L. Friesz	2012	IEEE Transactions on Engineering Management	10.1109/TEM.2011.2140323	financial economics;game theory;strategic planning;economics;predictive modelling;microeconomics;markov process;mathematical economics;oligopoly;statistics	ML	1.506057244536898	-3.3126928176878367	100355
886fe32f2846897b1ee6d2057dbf72f162cfb7df	reverse auction and the solution of inequality constrained assignment problems	assignment problem;reverse auction;inequality constraint;90c47;auction;linear programming;network optimization;90c05	In this paper we propose auction algorithms for solving several types of assignment problems with inequality constraints. Included are asymmetric problems with different numbers of persons and objects, and multiassignment problems, where persons may be assigned to several objects and reversely. A central new idea in all these algorithms is to combine regular auction, where persons bid for objects by raising their prices, with reverse auction, where objects compete for persons by essentially offering discounts. Reverse auction can also be used to accelerate substantially (and sometimes dramatically) the convergence of regular auction for symmetric assignment problems. 1 This work was supported in part by the BM/C3 Technology branch of the United States Army Strategic Defense Command. 2 Department of Electrical Engineering and Computer Science, M. I. T., Cambridge, Mass., 02139. 3 Department of Electrical Engineering, Boston University, and ALPHATECH, Inc., Burlington, Mass., 01803. 4 ALPHATECH, Inc., Burlington, Mass., 01803. 1	assignment problem;auction algorithm;computer science;electrical engineering;social inequality	Dimitri P. Bertsekas;David A. Castañón;Haralampos Tsaknakis	1993	SIAM Journal on Optimization	10.1137/0803013	auction algorithm;mathematical optimization;combinatorial auction;generalized second-price auction;unique bid auction;linear programming;reverse auction;vickrey–clarke–groves auction;revenue equivalence;mathematics;assignment problem;mathematical economics;auction theory	Theory	-1.7220317303579733	-1.8241940308911202	100356
9dab33d03377359a4a7d3b3ea87ddd26a6c72e43	match your own price? self-matching as a retailer's multichannel pricing strategy	multichannel retailing;distribution channels;pricing strategymarketing strategy;supply and industryretail industry;price self matching;price	Multichannel retailing has led to the emergence of a new form of price-matching policy. A “self-matching policy” allows a multichannel retailer to offer the lowest of its online and instore prices to consumers with appropriate evidence of the pricing discrepancy. In contrast to competitive price-matching, a retailer matching its own price is likely to result in consumers obtaining the lower price, making it seem like an unprofitable strategy. However, we observe a variety of self-matching policies across several industries, with some retailers offering selfmatching for all products while others choosing not to. Using a game-theoretic model of pricing strategy, we examine whether firms are compelled by competitive pressure to offer self-matching even though it might result in a prisoners’ dilemma. We uncover distinct and novel mechanisms that underpin the effectiveness of self-matching, and find it to be profitable across a variety of competitive scenarios. We examine multiple competitive landscapes, including as a monopolist, a mixed duopoly of a multichannel retailer competing with an e-tailer as well as two competing multichannel retailers. We find that the effectiveness of self-matching depends on the decisionmaking stage of consumers and the heterogeneity of their preference for channels. Self-matching strategies can also be profitably used as stores face more consumers using smartphones to discover online prices. Our findings provide insights and recommendations to managers on how and when to derive profit from self-matching pricing strategies. ∗Pavel Kireyev is Doctoral Candidate (pkireyev@hbs.edu), Vineet Kumar (vkumar@hbs.edu) is Asistant Professor of Business Administration and Elie Ofek (eofek@hbs.edu) is the T.J. Dermot Dunphy Professor of Business Administration at Harvard Business School.	discrepancy function;emergence;game theory;omnichannel;online shopping;smartphone	Pavel Kireyev;Vineet Kumar;Elie Ofek	2017	Marketing Science	10.1287/mksc.2017.1035	ask price;forward price;pricing;limit price;marketing;mid price;microeconomics;business;pricing schedule;commerce	Web+IR	-2.3655273118024227	-6.594340126451817	100390
887168ecf032e51ed0c10c734d82cf5d04458660	the communication complexity of coalition formation among autonomous agents	multiagent system;game theory;software agent;communication complexity;utility function;analysis of algorithm;artificial intelligent;coalition formation;theory of computing;autonomous agent;shapley value;computational complexity;problem complexity;solution concept;stable distribution	It is self-evident that in numerous Multiagent settings, selfish agents stand to benefit from cooperating by forming coalitions. Nevertheless, negotiating a stable distribution of the payoff among agents may prove challenging. The issue of coalition formation has been investigated extensively in the field of cooperative n-person game theory, but until recently little attention has been given to the complications that arise when the players are software agents. The bounded rationality of such agents has motivated researchers to study the computational complexity of the aforementioned problems.In this paper, we examine the communication complexity of coalition formation, in an environment whore each of the n agents knows only its own initial resources and utility function. Specifically, we give a tight Θ(n) bound on the communication complexity of the following solution concepts in unrestricted games: Shapley value, the nucleolus and the modified nucleolus, equal excess theory, and the core. Moreover, we show that in some intuitively appealing restricted games the communication complexity is constant, suggesting that it is possible to achieve sublinear complexity by constraining the environment or choosing a suitable solution concept.	agent-based model;autonomous robot;communication complexity;computational complexity theory;game theory;offset binary;rationality;software agent;utility	Ariel D. Procaccia;Jeffrey S. Rosenschein	2005		10.1145/1160633.1160727	game theory;complexity;simulation;computer science;stable distribution;artificial intelligence;autonomous agent;software agent;communication complexity;shapley value;computational complexity theory;solution concept;game complexity	AI	-3.3962447478815014	0.08209670441451847	100396
511bb81aeb18fb1f6d070ca2c3cfa65d400f29c0	bidding strategy for periodic double auctions using monte carlo tree search		Bidding strategies for Periodic Double Auctions (PDAs) are complicated because they need to predict and plan for future auctions, which may affect the bidding strategy in the current auction. We present a general bidding strategy for PDAs based on forecasting clearing prices and using Monte Carlos Tree Search (MCTS) to plan a bidding strategy across multiple time periods. We developed a controlled simulator by isolating Power Trading Agent Competitionu0027s wholesale market to evaluate bidding strategies in a realistic PDA energy market. We show that our MCTS bidding strategy is cost effective in buying energy compared to other baseline and state-of-the-art strategies and itu0027s performance improves with increasing number of MCTS simulations.	baseline (configuration management);monte carlo method;monte carlo tree search;personal digital assistant;simulation	Moinul Morshed Porag Chowdhury;Christopher Kiekintveld;Tran Cao Son;William Yeoh	2018			periodic graph (geometry);simulation;common value auction;computer science;distributed computing;monte carlo tree search;bidding;energy market;multi-agent system	AI	1.5408929385720032	1.48190017692522	100431
b3d2d369e80b36fc7ac966d83abcaffe61579765	an agent-based model of the risk-based spectrum auction in the cognitive radio networks	cognitive radio;commerce;cooperative communication;learning (artificial intelligence);multi-agent systems;radio spectrum management;risk management;telecommunication computing;agent-based model;bidding strategies;cognitive radio networks;cooperative energy-based spectrum sensing mechanism;dynamic spectrum access;imperfect spectrum sensing;reinforcement learning algorithm;risk-based spectrum auction;shared use model;single-unit sealed-bid first-price auction;spectrum trading;total payoff maximization;total revenue maximization;spectrum trading;agent-based modeling;imperfect sensing	In this paper, we propose an agent-based model for spectrum trading in the shared use model of dynamic spectrum access. Spectrum trading is employed using the single-unit sealed-bid first-price auction, which takes into the account risk due to the imperfect spectrum sensing. Bidding strategies of the bidder are controlled by the reinforcement learning algorithm. We consider cooperative energy-based spectrum sensing as a spectrum sensing mechanism. Two different decision fusion strategies, which provide different levels of risk are discussed. The results demonstrate that in risky environment, total revenue and total payoff of the auctioneer and bidder respectively is higher, than in the case of system with lower level of risk. On the other hand, normalized revenue and payoff per a single auction round is higher in the case with lower level of risk. Moreover, the results have shown that the optimum sensing time for maximizing revenue and payoff is different.	agent-based model;algorithm;broadcast television systems inc.;cognitive radio;haven (graph theory);ibm systems network architecture;reinforcement learning	Ján Pastircák;Lukás Sendrei;Stanislav Marchevsky;Juraj Gazda	2014	1st International Conference on 5G for Ubiquitous Connectivity		financial economics;revenue equivalence;microeconomics;business;commerce	Robotics	-3.3782028514389855	-4.5048815476851445	100603
b6665f2b989ad99dd3a2d49266864f0f941a643e	model based systems engineering high level design of a sustainable electric vehicle charging and swapping station using discrete event simulation		"""In line with the spate of technological advances, the transportation industry has also witnessed an increase in the adoption of Electric Vehicles (E.Vs). However, there has been and are still some underlying negating factors to the wide spread acceptance of these electric vehicles; one of note is the unavailability and inaccessibility of adequate charging infrastructure, long charging times, limited driving ranges, costs of the vehicles etc. These and many more characteristics lead to a trend popularly known as """"range anxiety"""". One of the major strengths of electric vehicles are their ability to be powered by electric energy via stored chemical energy in rechargeable batteries. Some electric vehicles run solely on batteries (Battery Electric Vehicle — BEVs), while others are a hybrid of the electric vehicles and the internal combustion engines (Plug-in Hybrid Electric Vehicles — PHEVs, and Hybrid Electric Vehicles — HEVs). However, since these electric vehicles lean towards reducing atmospheric pollution (Carbon monoxide, hydrocarbons etc.) caused by internal combustion engines, it also follows that the means of recharging these electric vehicles should also be geared towards reducing pollution to some degree. Hence, the concept of renewable energy sources powered recharging stations. However, before a lot of resources are committed into building such an infrastructure, a model should be developed which will take into account certain key factors such as storage capacity, type and size of the renewable sources, facility layout, policies and other identified stakeholders requirements which are evaluated and used in trade-off and decision analysis. However, the status-quo involves around a document-centric methodology of system development. This methodology carries with it challenging characteristics such as poor communication of data between and within interested parties, inability to contain complexities inherent in today's projects, stored data becoming prone to damage as a result of storage or usage and sometimes, inaccessibility of data. In line with current systems engineering practice, we propose a model-centric approach of the system development life-cycle, which will negate some of the drawbacks of the document-centric approach. In this work, a two-level approach is proposed: First, the model based systems engineering (MBSE) framework approach is implemented utilizing the systems modeling language (SysML) to formulate and show different views and architecture of the system in question. The objectives of this MBSE approach in addition to offering different views of the model are also to aid in real-time communication and collaboration of designs which links to understanding change configurations and impact, requirements verification, and traceability. In the second approach, a discrete-event simulation (Arena) tool is used as the reference simulation optimization tool for the model's architectural analysis. The discrete-event simulation (DES) models a hypothetical renewable-energy powered charging and swapping station with the objective of maximizing the electric vehicle's throughput (amount of EVs successfully recharging and swapping batteries in the facility). Certain constraints such as the allowable area for the solar panels, operating budget, amount of energy to purchase from the main grid etc., are included to account for a realistic adaptation of the facility, which is in line with the concept of the renewable energy sources powered recharging stations previously mentioned. Statistical analysis are performed on the optimized architectures to evaluate and compare the design configurations based on the stakeholder's requirements. The optimized parameters are then used to verify and validate the requirements. These categorization of events support the application of MBSE and simulation to the early stages of the system life cycle development of the high level design of an electric vehicle charging and swapping station"""		Obinna Ginigeme;Aldo Fabregas	2018	2018 Annual IEEE International Systems Conference (SysCon)	10.1109/SYSCON.2018.8369606	system lifecycle;renewable energy;architecture;automotive engineering;electric vehicle;high-level design;battery electric vehicle;model-based systems engineering;engineering;range anxiety	SE	7.653056979861006	-7.562448378778636	100658
9bb0e5f9a7040ad61d1e3c8aca38722760c6f020	soft risk maps of natural disasters and their applications to decision-making	nuclear power;water resource;risk map;fuzzy probability;natural disaster;profitability;flood risk	A soft risk map of natural disaster is aimed at the visualization of risk levels of natural disasters defined by the fuzzy probabilities. In this paper, we discuss three soft risk maps and show their applications. A soft risk map of flood is applied to help choose zones for investment in projects whose profits depend on water resources, cost and flood risk. A soft risk map of drought can help an investor to choose an appropriate city to invest in a flower shop whose profits depend on drought risk and the number of customers. With a soft risk map of earthquake, a licensee designing a nuclear power station can reasonably adjust the earthquake-resistant parameters to avoid underestimating earthquake. 2006 Published by Elsevier Inc.	coefficient;computer program;computer simulation;map;population;procedural generation;shutdown (computing)	Chongfu Huang;Hiroshi Inoue	2007	Inf. Sci.	10.1016/j.ins.2006.07.033	nuclear power;actuarial science;natural disaster;profitability index	ML	8.750084622121621	-5.818433831474622	100729
c986e1aea7560434af7df74791c6da4f693227cf	a general modeling method for opportunistic maintenance modeling of multi-unit systems	multi unit systems;maintenance group;joint stationary probability density;maintenance probability;opportunistic maintenance;deterioration state space partition method	This paper presents a deterioration state space partition method for opportunistic maintenance modeling of multi-unit systems. The method represents common characteristics of opportunistic maintenance models based on different maintenance strategies. All possible maintenance groups of general multi-unit systems with a known number of non-identical units at each maintenance decision time and their corresponding probabilities are deduced using the presented approach. Further, a general representation of the stationary law of the system deterioration and its numerical solution is developed. Numerical experiments verify the correctness and validity of the state space partition method and the numerical solution of the stationary probability density. The proposed method is applicable to both single-unit and multi-unit systems, and it provides a new generalized modeling method for maintenance optimization of multi-unit systems.		Xiaohong Zhang;Jianchao Zeng	2015	Rel. Eng. & Sys. Safety	10.1016/j.ress.2015.03.030	reliability engineering;mathematical optimization;mathematics	SE	6.7163685516364415	-0.1706402984131562	100764
382b64c12175eded316a13d983705ec822e871f0	a logarithmic safety staffing rule for contact centers with call blending	threshold controls;safety staffing;grupo de excelencia;call blending;contact centers;administracion de empresas;many server queues;economia y empresa;grupo a	W consider large contact centers that handle two types of jobs—inbound and outbound—simultaneously, a process commonly referred to as call blending. Inbound work arrives to the system according to an exogenous arrival process, whereas outbound work is generated by the contact center. We assume that there is an infinite supply of outbound work to process, and that inbound calls are prioritized over the outbound calls. We propose a logarithmic safety staffing rule, combined with a threshold control policy, ensuring that agents’ utilization is very close to one at all times, but that there are practically always idle agents present. Specifically, we prove that it is possible to have almost all inbound calls answered immediately upon their arrival, in addition to satisfying a target long-run throughput rate of outbound calls, with at most a negligible proportion of those calls dropped. Simulation experiments demonstrate the effectiveness and accuracy of our analysis.	alpha compositing;experiment;inbound marketing;simulation;throughput	Guodong Pang;Ohad Perry	2015	Management Science	10.1287/mnsc.2014.2019	real-time computing;simulation;marketing;operations management;management	Security	2.372657006375299	0.24803134303489077	100922
336dd331405af62ebe31f7b10b81eed8295f4ab5	two-instant reallocation in two-echelon spare parts inventory systems	inventory management;multiechelon reparable item inventory system;replenishment cycle two echelon spare parts inventory systems spare parts reallocation multiechelon reparable item inventory system;logistics silver availability automation asia mathematical model stochastic processes management information systems information management risk analysis;maintenance engineering;spare parts reallocation;two echelon spare parts inventory systems;maintenance engineering inventory management;mathematical model;replenishment cycle;spare parts	In this paper, we study the problem of deciding when and how to perform reallocation of existing spare parts in a multi-echelon reparable item inventory system. We present a mathematical model that solves the problem when there are two reallocation instants, in response to the open challenge post by Cao and Silver(2005) to consider two or more possible reallocations within a replenishment cycle	lagrange multiplier;lateral thinking;mathematical model;row echelon form	Huawei Song;Hoong Chuin Lau	2006	2006 IEEE International Conference on Automation Science and Engineering	10.1109/COASE.2006.326905	reliability engineering;inventory theory;engineering;operations management;industrial engineering;spare part	Robotics	6.635705206303321	-3.3283606134103225	100958
1a82a4cf0c2479efbb82a241dd970c6870612b63	a model for portfolio management with mortgage-backed securities	mortgage backed securities;interest rate;large scale;massively parallel computer;portfolio management;stochastic programming	We present a stochastic programming model for the management of large portfolios of mortgage-backed securities (abbreviated: MBS). It is a two-stage, multiperiod model, whereby portfolio decisions made here-and-now are influenced by uncertain information about the future. In particular, we consider uncertainty in both the prepayment activity of the MBSs in the portfolio, as well as uncertainty about the future reinvestment rates. A simulation procedure is used to generate interest rate paths and prepayment behavior, and the stochastic program can be extremely large. Solution of the resulting large-scale programs is particularly challenging. We show that with massively parallel computing technology, the proposed models are indeed solvable. Empirical results on a Connection Machine CM-2 are reported.		Stavros A. Zenios	1993	Annals OR	10.1007/BF02025090	financial economics;stochastic programming;mathematical optimization;actuarial science;economics;interest rate;finance;portfolio optimization;mathematics;application portfolio management;project portfolio management	DB	4.704155741138291	-6.778747913323256	100964
07ec586de782fa96336b90c60d2bce8e5a9b4882	optimization of supply portfolio in context of supply chain risk management: literature review	optimisation;risk management;supply chain management;scrm;optimization;selection supplier;supply chain risk management;supply portfolio;optimisation of supply portfolio;risk management supply chain;qualitative approaches;quantitaive approaches;risk supplier;transportation;stochastic processes;resource management;uncertainty;reliability;supply chains	Selection supplier in context of risk management supply chain has increasingly becoming a more popular research area recently. This repercussion is return to the high level of complexity of supply chains and the inherent risks that exist at any link of supply chain. Various papers, with different focus and approaches, have been published since a few years ago. This paper aimed to survey selection supplier in context of supply chain risk management (SCRM) literature. Papers collected will be analyzed and classified into two categories: the first is relatives to qualitative approach, while the second is oriented to regrouped the quantitative approach for selection supplier based on supply chain risk management.	common criteria;denial-of-service attack;expected shortfall;futures studies;geographic coordinate system;high-level programming language;location (geography);maxima and minima;mcgurk effect;program optimization;quantum fluctuation;risk management;semiconductor industry;stress testing;value at risk	Faiza Hamdi;Ahmed Ghorbel;Faouzi Masmoudi	2014	2014 International Conference on Advanced Logistics and Transport (ICALT)	10.1109/ICAdLT.2014.6866341		EDA	6.3963367674325236	-9.328376052372239	101016
1a96faa72e9f4d502677c10ed41564a880205a19	optimal reinsurance under the general mixture risk measures	lagrangien;analisis numerico;matematicas aplicadas;mathematiques appliquees;lagrangian function;standard deviation;analyse numerique;condition suffisante;condicion optimalidad;expected value;condition optimalite;numerical analysis;condicion suficiente;variance risk measure;expected value principle;reinsurance;lagrangiano;risk measure;sufficient condition;applied mathematics;lagrangian;optimality condition;variance;variancia	This paper concerns the problem of how to purchase the reinsurance in order to make the insurer and the reinsurer’s total risk least under the standard deviation principle. Sufficient conditions for optimality of reinsurance contract are given within the restricted class of admissible contracts. Here, the insurer and reinsurance company can take arbitrary risk measures, respectively. Further, we give the explicit forms of optimal reinsurance contract under special risk measures. We also give the method to decide the parameters.	risk measure	Yusong Cao;Yi Zhang	2007	Applied Mathematics and Computation	10.1016/j.amc.2006.06.120	actuarial science;reinsurance;lagrangian;mathematics;statistics	ML	2.5940719798031764	-2.5868115126849096	101092
a8340a9ed88ad79a6ee7507686f33f4fbda2d920	search algorithms for efficient logistics chains		Logistics networks arise whenever there is a transfer of material substance or objects (such as checked baggage on international flights) as well as energy, information, or finance through links (channels). A general concept of logistics network is suggested and motivated for modeling a service of any kind supplied through links between the nodes of the network. The efficiency of a single link is defined to be the ratio of the volume of useful service at the output node to the volume of expended service at the input node of the link (for a specific period of time). Similarly, the efficiency of a chain is the ratio of the volume of service at the output to the volume of service at the input of the chain. The overall efficiency of the chain is calculated as the product of the efficiencies of its links; the more efficiency of the chain, the less are the losses in the chain. This paper introduces the notion of inadequacy of service in such a way that the overall inadequacy of a chain is equal to the sum of the inadequacies of its links. So the efficiencies are being multiplied, whereas the inadequacies are being added. Thus, the antagonistic pair (efficiency, inadequacy) appears to be analogous to the pair (reliability, entropy) in communication theory. Various possible interpretations of the proposed logistic model are presented: energy, material, information and financial networks. Four algorithms are provided for logistics chain search: two algorithms for finding the most effective chain from a specified origin to a specified destination, and two algorithms for finding the guaranteed minimum level of service between any pair of unspecified nodes in a given network. An example is shown as to how one of the algorithms finds the most efficient energy chain from the electrical substation to a specified user in a concrete energy network.	algorithm;logistics;traction substation	Serge Lawrencenko;Irina A. Duborkina	2015	CoRR	10.12737/11889	mathematical optimization;simulation;telecommunications	Networks	7.698832467922498	-4.434480475080057	101123
4e41f797d1267090ab0d47b3da24af414419e0c2	optimal mechanisms for selling information	partial information;selling information;polynomial time algorithm;revenue maximization;mechanism design;informal learning	The buying and selling of information is taking place at a scale unprecedented in the history of commerce, thanks to the formation of online marketplaces for user data. Data providing agencies sell user information to advertisers to allow them to match ads to viewers more effectively. In this paper we study the design of optimal mechanisms for a monopolistic data provider to sell information to a buyer, in a model where both parties have (possibly correlated) private signals about a state of the world, and the buyer uses information learned from the seller, along with his own signal, to choose an action (e.g., displaying an ad) whose payoff depends on the state of the world.  We provide sufficient conditions under which there is a simple one-round protocol (i.e. a protocol where the buyer and seller each sends a single message, and there is a single money transfer) achieving optimal revenue. In these cases we present a polynomial-time algorithm that computes the optimal mechanism. Intriguingly, we show that multiple rounds of partial information disclosure (interleaved by payment to the seller) are sometimes necessary to achieve optimal revenue if the buyer is allowed to abort his interaction with the seller prematurely. We also prove some negative results about the inability of simple mechanisms for selling information to approximate more complicated ones in the worst case.	approximation algorithm;best, worst and average case;money;online marketplace;time complexity	Moshe Babaioff;Robert D. Kleinberg;Renato Paes Leme	2012		10.1145/2229012.2229024	mechanism design;economics;marketing;microeconomics;advertising;mathematical economics;world wide web;commerce	ECom	-2.478464461877405	-2.6693832474879935	101247
2f8f40096910c44f1bbe7634f11844ba359264aa	"""a game-theoretic model of tv show """"the voice"""""""		Abstract—This paper proposes a game-theoretic model of the two-player best-choice problem with incomplete information. The players (experts) choose between objects by observing their quality in the form of two components forming a sequence of random variables (xi, yi), i = 1, . . . , n. By assumption, the first quality component xi is known to the players and the second one yi is hidden. A player accepts or declines an object based on the first quality component only. A player with the maximal sum of the components becomes the winner in the game. The optimal strategies are derived in the cases of independent and correlated quality components.		Elena N. Konovalchikova;Vladimir V. Mazalov	2016	Automation and Remote Control	10.1134/S0005117916080130	simulation;engineering;statistics	Theory	-4.245574964883231	-3.63408427224475	101268
96f9a5d54734810003e5eb81e5f5ab30ffdbb856	revenue sharing in airline alliances	revenue management;nash equilibrium;capacity control;grupo de excelencia;cooperative game theory;administracion de empresas;economia y empresa;contract design;grupo a	Airline alliances as means of collaboration among independent carriers are a growing trend in the industry. From a revenue management perspective, one of the most significant features of the alliances are codeshare itineraries by which independent airlines can collaboratively market and operate flights. Different from traditional, monopolistic airline revenue management, alliance members control a decentralized network of resources through independent reservation and information systems. To study the revenue management problem of such decentralized network environment, we propose a two-stage hierarchical approach. In the first stage, airlines agree on how to share the revenues generated by these interline products. In the second stage, airlines operate independent inventory control systems in order to maximize their own expected revenues. Through both analytical and numerical studies, we find that the choice of the revenue sharing rule has a great impact on the performance of the alliance. In particular, in the static setting where each airline uses partitioned booking limits, there exists a revenue sharing rule under which the decentralized system can do as well as the centralized system. We further construct an asymptotic regime in which airlines’ capacities and demands grow proportionally large, and prove that under our proposed revenue sharing rule, the performance of the alliance under dynamic inventory control converges to the performance under static booking limit control. The numerical comparisons between several dynamic heuristic policies and the static booking limit control confirm the quality of the approximation. Nevertheless, given that the revenue sharing rule that is provably optimal in our model requires to disclose private demand information, we propose a simple revenue sharing rule that is based on public fares. This simple heuristic performs noticeably well in our numerical experiments, becoming an interesting candidate to be pursued in practice.	approximation;centralized computing;control system;decentralised system;experiment;heuristic;information system;interlaced video;inventory control;numerical analysis;revenue sharing	Xing Hu;René Caldentey;Gustavo J. Vulcano	2013	Management Science	10.1287/mnsc.1120.1591	economics;marketing;operations management;microeconomics;management;nash equilibrium;commerce	ML	-1.6624307126496478	-5.275868269241963	101589
7cfec3b41973f98583ef2846b1e22531af365575	profit-based grassroots design and retrofit of water networks in process plants	water reuse;net present value;grassroots design;interest rate;water systems;profitability;return of investment;retrofit	In this paper, we present a methodology for the grassroots design and/or retrofit of water utilization systems using mathematical optimization to maximize net present value (NPV) and/or return of investment (ROI) instead of minimizing freshwater consumption. The examples show that the solutions where savings and/or profit are maximized can be different from those where freshwater is minimized. They also differ ccepted 1 October 2008 vailable online 21 October 2008 eywords: ater systems ater reuse from each other when ROI or NPV are used. In addition, when the NPV objective is used, the optimum solutions also vary depending on the interest rate used to calculate the discount factor. © 2008 Elsevier Ltd. All rights reserved. r T i h m n m o p c W c i w p w b f i s rassroots design etrofit	cp/m;electronic signatures in global and national commerce act;environmental resource management;european home systems protocol;foobar;freshwater ecosystem;global optimization;han unification;hang (computing);holism;industrial engineering;mathematical optimization;network planning and design;os-tan;optimal design;p (complexity);process modeling;program optimization;region of interest;risk management;wai-aria	Débora C. Faria;Miguel J. Bagajewicz	2009	Computers & Chemical Engineering	10.1016/j.compchemeng.2008.10.005	net present value;return on investment;actuarial science;interest rate;profitability index	AI	9.139457623035677	-4.786630886687514	101607
9371a29e95a64b60435240063079e526c912f486	a model for investments in the natural resource industry with switching costs	qa mathematics;optimal switching;richard reuben lumley;eprints newcastle university;real options;real assets;natural resource;open access;dr mihail zervos;stochastic control;impulse control;switching cost	We consider a model for investment decisions in the natural resource industry with switching costs. This model gives rise to a problem combining features of both absolutely continuous and impulse stochastic control that we explicitly solve. The solution takes qualitatively different forms, depending on parameter values.		Richard R. Lumley;Mihail Zervos	2001	Math. Oper. Res.	10.1287/moor.26.4.637.10008	mathematical optimization;simulation;stochastic control;natural resource;mathematics;operations research	Theory	1.276175895728566	-2.516006247288303	101686
6bb5f52b56ad2768a2b4faff2f9720a9aefd7c43	customer allocation in maximum capture problems	location analysis;maxcap;h social sciences general;h social sciences;maximum capture model;customer allocation	The maximum capture (MAXCAP) model and its variants have been widely used to find the maximum capture that a firm can get as it enters a spatial market where there are already existing (competitor's) facilities. While the model obtains the optimal demand capture, it however allows the customers to be assigned to the non-closest facility which may incur additional operating costs. A two stage method can be used that overcomes the drawback of the original model while requiring a negligible extra computational effort. To make the original model mathematically self contained and more concise two revised formulations of the problem RMAXCAP-1 and RMAXCAP-2 are proposed which assure that the customers patronize only their closest entering facilities. These models are tested on different sizes of datasets and their performances are compared.		Arifusalam Shaikh;Saïd Salhi;Malick M. Ndiaye	2012	J. Math. Model. Algorithms	10.1007/s10852-012-9185-5	mathematical optimization;simulation;computer science;facility location problem;mathematics;operations research	Theory	4.141436835055255	-4.974045438252288	101720
fc225c4b1411615b8186f3547814251fdc903e9e	influence of charging behaviour given charging station placement at existing petrol stations and residential car park locations in singapore		Electric Vehicles (EVs) are set to play a crucial role in making transportation systems more sustainable. However, charging infrastructure needs to be built up before EV adoption can increase. A crucial factor that is ignored in most existing studies of optimal charging station (CS) deployment is the role played by the charging behaviour of drivers. In this study, through an agent-based traffic simulation, we analyse the impact of different driver charging behaviour under the assumption that CSs are placed at existing petrol stations and residential car park locations in Singapore. Three models are implemented: a simple model with a charging threshold and two more sophisticated models where the driver takes the current trip distance and existing CS locations into account. We analyse the performance of these three charging behaviours with respect to a number of different measures. Results suggest that charging behaviours do indeed have a significant impact on the simulation outcome. We also discover that the sensitivity of model parameters in each charging behaviour is an important factor to consider as variations in model parameter can lead to significant different results.	agent-based model;cascading style sheets;charging argument;extended validation certificate;simulation;software deployment	Ran Bi;Jiajian Xiao;T. Viswanathan VaisaghViswanathan;Alois Knoll	2016		10.1016/j.procs.2016.05.347	simulation	AI	9.634651043659842	-7.936192517438891	101732
4fb88bb94074a91f1523427be38b905ce136f017	online trading as a secretary problem		We consider the online problem in which an intermediary trades identical items with a sequence of n buyers and n sellers, each of unit demand. We assume that the values of the traders are selected by an adversary and the sequence is randomly permuted. We give competitive algorithms for two objectives: welfare and gain-from-trade.		Elias Koutsoupias;Philip Lazos	2018		10.1007/978-3-319-99660-8_18	mathematical optimization;secretary problem;mathematical economics;adversary;computer science;welfare	Theory	-2.6372927673794124	-2.2833442327860736	101920
6f50e97fe3b25ecd15a15bfc4c9324b626d3cf83	drone flight scheduling under uncertainty on battery duration and air temperature		Abstract Commercial drones are expected to be widely used in the near future. They are generally powered by batteries to fly aerial areas. Flying time performance is known to change depending on air temperature. Hence, this paper proposes a robust optimization approach to find the optimal flight schedule (i.e., the number of drones and flight paths) in the flight network considering uncertain battery duration. A regression model is first developed to estimate battery duration as a function of air temperature. Three flight duration uncertainty sets (polyhedral, box, and ellipsoidal) are explored based on the regression model, and the robust optimization model is solved for each of the three sets. A decision tool is developed to analyze performance of the sets, and to help a decision maker select an appropriate uncertainty set that is most appropriate for a specific application of interest. The tool considers both minimizing the total operating cost and minimizing the probability of not completing the scheduled flights. Numerical results are presented to illustrate the proposed method.	scheduling (computing);unmanned aerial vehicle	Seon Jin Kim;Gino J. Lim;Jaeyoung Cho	2018	Computers & Industrial Engineering	10.1016/j.cie.2018.02.005	mathematical optimization;engineering;regression analysis;battery (electricity);scheduling (computing);robust optimization;operating cost	Robotics	6.582421368543551	2.509267023413061	102006
9a0870cf6f2ddf1c74b134863cd3cad25535fa0a	discrete-event simulation: from the pioneers to the present, what next?	simulation ordinateur;simulation evenement discret;forecasting;optimisation;reliability;chart;project management;information systems;history;realite virtuelle;red www;optimizacion;realidad virtual;maintenance;soft or;information technology;simulacion numerica;reseau web;packing;virtual reality;operations research;location;investment;journal;journal of the operational research society;computing;inventory;purchasing;history of or;internet;logistics;marketing;scheduling;simulation numerique;production;communications technology;world wide web;carta marina;optimization;historia;simulacion computadora;computer science;operational research;carte marine;precoz;article;computer simulation;early;histoire;applications of operational research;or society;jors;management science;infrastructure;precoce;numerical simulation;discrete event simulation	Discrete-event simulation is one of the most popular modelling techniques. It has developed significantly since the inception of computer simulation in the 1950s, most of this in line with developments in computing. The progress of simulation from its early days is charted with a particular focus on recent history. Specific developments in the past 15 years include visual interactive modelling, simulation optimisation, virtual reality, integration with other software, simulation in the service sector, distributed simulation and the use of the world wide web. The future is then speculated upon. Potential changes in model development, model use, the domain of application for simulation and integration with other simulation approaches are all discussed. The desirability of continuing to follow developments in computing, without significant developments in the wider methodology of simulation, is questioned.		Stewart Robinson	2005	JORS	10.1057/palgrave.jors.2601864	computer simulation;logistics;computing;simulation;inventory;economics;forecasting;investment;computer science;marketing;operations management;discrete event simulation;chart;reliability;location;management;operations research;scheduling;statistics	Metrics	6.922279892424645	-4.242886648063343	102111
59803cf50c28eeb49465f1917b4a50f344fd663e	a column-generation approach for joint mobilization and evacuation planning	evacuation planning;behavioral operations research;journal article;column generation	Large-scale evacuations require authorities to decide and stage evacuation routes, mobilize resources, and issue evacuation orders under strict time constraints. These decisions must consider both the capacity of the road network and the evolution of the threat (e.g., a bushfire or a flood). This paper proposes, for the first time, an optimization model that jointly optimizes the mobilization and evacuation planning, taking into account the behavioral response of evacuees and the allocation of resources for communicating and implementing evacuation orders. From a technical standpoint, the model is solved by a column generation algorithm that jointly decides the evacuation route, evacuation time, and the resource allocation for each evacuated area in order to maximize the number of evacuees reaching safety and minimize the total duration of the evacuation.	algorithm;branch and price;column generation;computation;lagrangian relaxation;linear programming relaxation;long tail;mathematical optimization;scheduling (computing);shortest path problem;time complexity	Victor Pillac;Manuel Cebrián;Pascal Van Hentenryck	2015	Constraints	10.1007/s10601-015-9189-7	column generation;mathematical optimization;simulation;computer science;behavioral operations research;mathematics;operations research	AI	7.62129529249417	2.389886722024797	102211
246fe0f0521818da0d1c502d9868c18790ea74ae	optimal portfolio policies under bounded expected loss and partial information	stochastic differential equation;partial information;satisfiability;trading strategy;continuous time markov chain;utility maximization;malliavin calculus;portfolio optimization;expected shortfall;stock returns;tracking error;shortfall risk;risk constraint;time discretization;optimal portfolio	In a market with partial information we consider the optimal selection of portfolios for utility maximizing investors under joint budget and shortfall risk constraints. The shortfall risk is measured in terms of expected loss. Stock returns satisfy a stochastic differential equation. Under general conditions on the corresponding drift process we provide the optimal trading strategy using Malliavin calculus. We give extensive numerical results in case of a model for the drift as a Markov process with finitely many states. To deal with the problem of time-discretization when applying the results to market data, we propose a method to detect and correct possible tracking errors.	discretization;malliavin calculus;numerical analysis;risk aversion	Jörn Sass;Ralf Wunderlich	2010	Math. Meth. of OR	10.1007/s00186-010-0300-y	mathematical optimization;stochastic differential equation;expected shortfall;continuous-time markov chain;trading strategy;portfolio optimization;mathematics;tracking error;malliavin calculus;satisfiability	ML	1.9341887853220276	-2.565447922565833	102418
2e7def1b92748af9698baa1a0325dc88b813f8e2	dynamic pricing with local interactions: logistic priors and agent technology			interaction	Benoît Leloup	2002			financial economics;prior probability;dynamic pricing;economics	AI	2.349052762091594	-9.007936618071007	102535
f22ee9cf1150364939e3bd95c6beb7ec605617bc	stock optimization for service differentiated demands with fill rate and waiting time requirements		Abstract We develop a computationally efficient optimization procedure to optimize stock and rationing levels for a model consisting of a single product with two priority–demand classes, given by mutually independent, stationary, Poisson demand processes. Each priority class has its own service levels requirements, defined by the class-specific fill rate and expected waiting-time levels. Order lead times are independent and identically distributed random variables. This is the first study in this setting to consider both waiting-time constraints along with fill rate requirements.	mathematical optimization;requirement	Oguzhan Vicil;Peter Jackson	2018	Oper. Res. Lett.	10.1016/j.orl.2018.03.009	independence (probability theory);mathematical optimization;mathematics;independent and identically distributed random variables;poisson distribution;service level	Theory	4.117641393168238	-1.2963298500914422	102568
7cf32d7cb99dfb7e9552f57679ce3c2e9170f140	"""comments on """"optimal policies for a multi-echelon inventory problem"""""""	inventory;multiechelon;optimal	I all came together on a Friday morning in midApril 1959. Just the two of us, in a conference room at Planning Research Corporation in Westwood, CA. The paper was a direct result of this meeting. At the time, we did not think much about what impact the paper would have on future work in this area, but we are pleased and honored that it has been selected as one of the influential papers published in the 50-year history of Management Science. I had been at Planning Research Corporation for just a short time after being in the Logistics Department at the RAND Corporation for five years. During my first couple of years at RAND, I helped in the design and implementation of inventory control procedures based on the Wilson lot size formula and a variable safety level concept to allow for demand uncertainty and differences in unit prices, factors not considered in the stock policies then current in the Air Force. However, I became generally disturbed that each facility (Air Force bases and a depot) was being considered independently, ignoring the fact that they were intimately connected in the real world. In particular, supply performance at the bases was being significantly degraded by lack of proper support from the depot. So, I decided to attack this multiechelon problem from an analytic point of view based on the classical AHM (Arrow-Harris-Marschak) model, particularly in order to accommodate time-dependent factors resulting from the phase-in and phase-out of weapon systems. Starting with the most simplifying assumptions and a single-user activity supported by one higher-level facility (depot), I was able to formulate a procedure by which levels at the user facility could be determined by the AHM model, results of which were then used as inputs to a similar calculation at the depot level. With this basic approach, I was able to then consider nonzero resupply time due to the work of Karlin and Scarf and fixed reorder costs at the depot due to the work of Scarf. Also, the approach was easily		Andrew J. Clark	2004	Management Science	10.1287/mnsc.1040.0292	inventory theory;inventory;economics;marketing	AI	7.64257219036129	-8.352878893335314	102594
91834e069d0c562527fe9984f36efd51879a11f0	the joint determination of price, quality, and capacity: an application to supermarket operations	optimal solution;level of service;service provider;service operation;profitability;service quality;comparative statics	This paper focuses on a service provider who, faced with competition, must determine the optimal price and level of service quality to provide in order to maximize profits. Service quality and price are assumed to impact jointly on demand for services. Both demand and service quality impact on the cost of providing service. While a considerable literature exists on the impact of service quality on demand or cost, less work has focused on the explicit impact of service quality jointly on both demand for and the cost of providing services. A service quality constraint is appended to the formulation in order to guarantee that a declared service standard is met. Conditions are developed which characterize optimal solutions, together with comparative statics. Illustrative results are presented based on empirical data obtained from a supermarket study.	quality of service	Jess S. Boronico;Alexandros Panayides	2001	JAMDS	10.1155/S1173912601000116	service provider;service level requirement;service level objective;service level;economics;service product management;comparative statics;marketing;operations management;service guarantee;microeconomics;level of service;customer service assurance;service quality;profitability index;service system	Metrics	0.45558588773816483	-5.715994524772905	102609
a0324007accb7315e4fab415cd50e49a87d2b041	innovation and price competition in a two-sided market	optimal two-sided pricing strategy;price competition;higher optimal seller-side fee;higher seller-side access fee;infinite innovation race;optimal seller-side access fee;two-sided market;innovation race;optimal buyer-side access fee;optimal strategy;innovation rate;optimal buyer-side fee	We examine a platform owner’s optimal two-sided pricing strategy while considering seller-side innovation decisions and price competition. We model the innovation race among sellers in both finite and infinite horizons. In the finite case, we analytically show that the platform’s optimal seller-side access fee fully extracts the sellers’ surplus, and that the optimal buyer-side access fee mitigates price competition among sellers. The platform’s optimal strategy may be to charge or subsidize buyers depending on the degree of variation in the buyers’ willingness-to-pay for quality; this optimal strategy induces full participation on both sides. Furthermore, a wider quality gap among sellers’ products lowers the optimal buyer-side fee but leads to a higher optimal sellerside fee. In the infinite innovation race, we perform computations to find the stationary Markov equilibrium of sellers’ innovation rate. Our results show that when all sellers innovate, there exists a parameterization under which a higher seller-side access fee stimulates innovation.	computation;markov chain;stationary process	Mei Lin;Shaojin Li;Andrew B. Whinston	2011	J. of Management Information Systems		industrial organization;innovation;economics;marketing;microeconomics;management;commerce	Metrics	-1.360416706539018	-5.892802737614032	102800
77573a1924b1a11aa32b7fc33394db728b3a1e93	machine repairing systems with standby switching failure	probabilistic global search lausanne method;supplementary variable technique;sensitivity analysis;optimization	This paper attempts to explore the performance measures and optimization analysis of machine repairing systems with standby switching failure. The time between failures and time-to-repair of failed machines are assumed to be exponential and general distributions, respectively. The standby is switched over to the operating mode when an operating machine fails, and the switch is subject to failure with probability q. A recursive method based on the supplementary variable technique is used to derive the steady-state probabilities of failed machines in the system. We then develop various performance measures of the system and construct the expected cost function per unit time. The probabilistic global search Lausanne method is employed to determine the optimal number of standbys and the optimal repair rate, wherein the expected cost per unit time is minimized. Finally, some numerical examples are provided for illustrative purposes. 2016 Elsevier Ltd. All rights reserved.	analysis of algorithms;loss function;mathematical optimization;numerical analysis;recursion;steady state;time complexity	Jau-Chuan Ke;Tzu-Hsin Liu;Dong-Yuh Yang	2016	Computers & Industrial Engineering	10.1016/j.cie.2016.07.016	mathematical optimization;real-time computing;simulation;computer science;engineering;operations management;mathematics;sensitivity analysis	AI	7.160843458106114	-0.8283265489622392	102837
feea31799cc73b768ce8d1084c6046b415d30275	renegotiation-proof contract in repeated agency	principal agent problem;expected utility;satisfiability;finite horizon;value function;infinite horizon;optimal value function;lower bound	Renegotiation-proof contracts are studied in infinitely repeated principal-agent problem. Contracts satisfying a weaker notion of renegotiation-proofness always exist. The renegotiation-proof value function has a simple characterization: It is the principal’s optimal value function when an appropriate lower bound is placed on the agent’s expected utility. Sufficient conditions are provided for renegotiation-proof value function in finite horizon to converge to renegotiation-proof value function in infinite horizon as time goes to infinity. Journal of Economic Literature Classification Numbers: D8, C7	bellman equation;converge;expected utility hypothesis;optimization problem	Rui R. Zhao	2006	J. Economic Theory	10.1016/j.jet.2005.05.003	principal–agent problem;economics;expected utility hypothesis;operations management;finance;mathematics;bellman equation;mathematical economics;upper and lower bounds;welfare economics;satisfiability	Theory	-4.50505853766921	-1.6310296622211922	102959
207b008ce22e0f613d32b3b592eb68a400c3a00a	an algorithm for a piecewise linear model of trade and production with negative prices and bankruptcy	economic analysis;piecewise linear;market research;fixed point method;simplex method;commerce;operations research;consumers;convex sets;linear programming;production;linear program;algorithms;point of view;general equilibrium model;welfare economics;bankruptcy	The general equilibrium model is approximated as a piecewise linear convex model and solved from the point of view of welfare economics using linear programming and fixed point methods.	algorithm;linear model;piecewise linear continuation	George B. Dantzig;B. Curtis Eaves;David Gale	1979	Math. Program.	10.1007/BF01582108	bankruptcy;fixed-point iteration;mathematical optimization;consumer;piecewise linear function;linear programming;mathematics;mathematical economics;simplex algorithm	NLP	1.1902641762683352	-2.9552047783696564	103320
46ec29afd3e2b4bb6ea9250bfe81f110dfcfce9b	evolutionary dynamics and potential games in non-cooperative routing	noncooperative routing;potential game;network routing problem;evolutionary dynamics;convergence;game theory;nash equilibrium;cost function;routing;replicator dynamic;traffic control;network topology;telecommunication traffic;telecommunication network routing;roads;potential games;cities and towns;non cooperative game;telecommunication network topology game theory telecommunication network routing;routing convergence network topology roads traffic control context modeling cost function telecommunication traffic cities and towns nash equilibrium;telecommunication network topology;noncooperative game;context modeling;stability property evolutionary dynamics potential games noncooperative routing network routing problem network topology nash equilibrium noncooperative game;stability property	We consider a routing problem in a network with a general topology. Considering a link cost which is linear in the link flow, we obtain a unique Nash equilibrium and show that the non-cooperative game can be expressed as a potential game. We establish various convergence and stability properties of of the equilibrium related to the routing problem being a potential game. We then consider the routing problem in the framework of a population game and study the evolution of the size of the populations when the replicator dynamics is used.	nash equilibrium;population;routing	Eitan Altman;Yezekael Hayel;Hisao Kameda	2007	2007 5th International Symposium on Modeling and Optimization in Mobile, Ad Hoc and Wireless Networks and Workshops	10.1109/WIOPT.2007.4480096	price of stability;non-cooperative game;implementation theory;game theory;minimax;mathematical optimization;routing;simulation;best response;convergence;extensive-form game;computer science;chicken;context model;evolutionary dynamics;normal-form game;mathematical economics;equilibrium selection;symmetric game;solution concept;network topology;nash equilibrium;computer network	ECom	-3.443716870606922	3.350653475911351	103385
75c38a77c9b71171ae80a0bdd7742118ae71197d	convex analysis and financial equilibrium	variational inequalities;91b25;91b42;49j40;financial equilibrium;91b55;90c29;91b51;90c33;90c15;91b50;convex analysis;91b24	Convexity has long had an important role in economic theory, but some recent developments have featured it all the more in problems of equilibrium. Here the tools of convex analysis are applied to a basic model of incomplete financial markets in which assets are traded and money can be lent or borrowed between the present and future. The existence of an equilibrium is established with techniques that include bounds derived from the duals to problems of utility maximization. Composite variational inequalities furnish the modeling platform. Models with and without shortselling are handled, moreover in the absence of any requirement that agents must initially have a positive amount of every asset, as is typical in equilibrium work in economics.	convex analysis;expectation–maximization algorithm;variational inequality;variational principle	Alejandro Jofré;R. Tyrrell Rockafellar;Roger J.-B. Wets	2014	Math. Program.	10.1007/s10107-014-0747-3	convex analysis;mathematical optimization;general equilibrium theory;convexity in economics;mathematics;mathematical economics;equilibrium selection	ECom	0.33024681978568476	-2.4805677295192177	103393
f3f0b018d6e9d7a761c3f0066448a20d76431fe8	systematic market control of cryptocurrency inflations		Most cryptocurrency systems mint new coins according to a predetermined rate, which contributes to inflation instead of solely by the actual demand. On the other hand, the blockchain, or whatever distributed consensus protocol underlying the cryptocurrency, can only process a limited number of transactions in a given time interval. To address both of these two issues, we propose a methodology that connects the coin minting with the prosperity of a cryptocurrency. Specifically, when there are fewer transactions, any cryptocurrency adopting our methodology will introduce a greater inflation to motivate transactions. Moreover, this methodology provides deflations and turns the currency towards a reserve of value when the network burden is too heavy.	consensus (computer science);cryptocurrency;mint	Shuyang Tang;Sherman S. M. Chow	2018		10.1145/3205230.3205240	monetary economics;inflation;prosperity;cryptocurrency;currency;economics;blockchain;consensus	Security	-4.033898561032182	-9.557627755549666	103406
2d1124e8186b7f34f136b782f13673146a53d5b8	on optimal dividend, reinvestment, and liquidation policies for the firm		We consider the liquid asset management problem of a firm with a fixed business. Two questions are addressed: How much, if any, of the firm's liquid assets should be paid to the owners as dividends? If the liquid asset level is negative resulting from a net loss in the previous period, should sufficient funds be raised to pay off the corresponding short-term debts, or should the benefit of limited liability be applied by liquidating the firm declaring it bankrupt? These questions are addressed in a multiperiod environment under uncertainty. The owners seek to maximize the present expected value of the after-tax returns from dividends less funds invested over the lifetime of the firm. Since the owners must pay income taxes on dividends they receive but cannot deduct the expenses of paying off short-term debts when needed, they have an incentive to have the firm retain some liquid assets as a hedge against having to raise funds to pay off such short-term debts. The form of the optimal policy in the general case is found to be surprisingly complex. A numerical example is used to illustrate the possible complexities. The main thrust of the paper is the presentation of three sets of conditions that are sufficient to prove that there exists an optimal policy with a certain intuitively pleasing and simple form.		Evan L. Porteus	1977	Operations Research	10.1287/opre.25.5.818	financial economics;actuarial science;economics;marketing;finance;management	HCI	0.8403823263117381	-5.710058967474266	103525
b71c10d8e4fb44139b26b3a4424ada3b17a16aa6	reliability evaluation for demand-based warm standby systems considering degradation process		Warm standby redundancy is a fault-tolerant technique balancing the low economical efficiency of hot standby and the long recovery time of cold standby. In this paper, motivated by practical engineering systems, a general demand-based warm standby system (DB-WSS) considering component degradation process is studied. A series of intermediate states exists between perfect functionality and complete failure because of degradation processes. A lot of existing analytical reliability assessment techniques are focused on conventional binary-state models or exponential state transition distributions for a system or its components. In this paper, a novel reliability evaluation approach based on the multistate decision diagram for DB-WSS is proposed. The proposed technique can handle arbitrary distributions of degradation processes for multistate components or systems. Moreover, considering the imperfect switch of the warm standby component, the start failure probability is taken into account in the warm standby system. Numerical studies are given to illustrate the proposed approach.	elegant degradation;fault tolerance;hot spare;influence diagram;mit engineering systems division;state transition table;time complexity	Heping Jia;Yi Ding;Rui Peng;Yong-Hua Song	2017	IEEE Transactions on Reliability	10.1109/TR.2017.2717928	redundancy (engineering);reliability engineering;mathematics;hot spare;influence diagram	SE	6.8803174595683405	-0.13833703472545056	103807
e0337deb2008ad00568f0401efaa1e95a457a08d	computing economies of vertical integration, economies of scope and economies of scale using partial frontier nonparametric methods	efficiency;d data envelopment analysis;partial frontier nonparametric methods;economies of vertical integration;economies of scale;economies of scope	So far, in the nonparametric literature only full frontier nonparametric methods have been applied to search for economies of scope and scale, particularly the data envelopment analysis method (DEA). However, these methods present some drawbacks that might lead to biased results. This paper proposes a methodology based on more robust partial frontier nonparametric methods to look for scope and scale economies. Through this methodology it is possible to assess the robustness of these economies, and in particular to assess the influence that extreme data or outliers might have on them. The influence of the imposition of convexity on the production set of firms was also investigated. This methodology was applied to the water utilities that operated in Portugal between 2002 and 2008. There is evidence of economies of vertical integration and economies of scale in drinking water supply utilities and in water and wastewater utilities operating mainly in the retail segment. Economies of scale were found in water and wastewater utilities operating exclusively in the wholesale, and in some of these utilities diseconomies of scope were also found. The proposed methodology also allowed us to conclude that the existence of some smaller utilities makes the minimum optimal scales go down. 2013 Elsevier B.V. All rights reserved.	data envelopment analysis	Pedro Carvalho;Rui Cunha Marques	2014	European Journal of Operational Research	10.1016/j.ejor.2013.09.022	economics;economies of scale;operations management;economies of agglomeration;efficiency;microeconomics;welfare economics	AI	-0.11429244086880176	-8.748262679362886	103826
eef1ce4fb85abed40bbb5a38e828031c152f9588	real-time trading strategies of proactive disco with heterogeneous dg owners	mathematical program with equilibrium constraints mpec distributed generation dg proactive distribution company pdisco distributed generation owner dgo bayesian game bilevel model multi period ac power flow;bilevel model;proactive distribution company pdisco;multi period ac power flow;mathematical program with equilibrium constraints mpec;real time systems reactive power indexes partial discharges stochastic processes procurement games;ac power flow;distributed generation dg;distributed generation owner dgo;bayesian game	This paper presents a methodology to obtain the optimal trading strategies between the proactive distribution company (PDISCO), heterogeneous distributed generation owners (DGOs), and wholesale market in a real-time trading framework. In this framework, the PDISCO’s decisions cover the power procurements from DGOs and the transactions within the real-time market. A one-leader multi-follower-type bilevel model is proposed to embody the PDISCO-DGO gaming structure. The upper-level (UL) problem is to maximize the PDISCO’s profit, while the lower-level (LL) problem indicates the profit maximization per DGO. Since the UL problem is non-linear and non-convex and the LL problems are linear and convex, we reformulate the proposed model to a solvable mathematical program with equilibrium constraints by an equivalent primal-dual approach. The numerical results of the case studies show the effectiveness and scalability of the proposed model.		Chunyu Zhang;Qi Wang;Jianhui Wang;Pierre Pinson;Jacob &#x00D8;stergaard	2018	IEEE Transactions on Smart Grid	10.1109/TSG.2016.2597263	bayesian game;mathematical optimization;simulation;economics;operations management	Robotics	2.9508336666452415	3.238827276569945	103883
e850667992cd7aa6cb17f9b9212efe913e754bf1	diverse replenishment frequency model for toc supply chain replenishment systems with capacity constraints	inventory replenishment;replenishment frequency model;qa75 electronic computers computer science;toc supply chain replenishment systems	When the theory of constraints (TOC) supply chain replenishment system (TOC-SCRS) is deployed in a plant or a central warehouse, replenishment frequency (RF) becomes one of the important decision parameters and depends on the sales or replenishment quantity (RQ) in the plant. The higher RF is preferred by TOC for the low inventory and the fast response to different market requirements. However, when sales significantly increase and capacity is not enough, the lower RF is required to save the setup capacity. Some existing RF determination models substantially increased in inventory. This paper proposes a diverse RF model for TOC-SCRS with capacity constraints so that the RF will only moderately increase in inventory. A numeric example is utilised to evaluate the proposed method and a prototype is further provided to demonstrate its feasibility and performance. The proposed model will enable a plant or a central warehouse to successfully implement an effective TOC-SCRS.	optical disc authoring;prototype;radio frequency;requirement	Xiao-Yun Jiang;Horng-Huei Wu;Tai-Ping Tsai;Huosheng Hu	2013	IJMIC	10.1504/IJMIC.2013.055430	real-time computing;engineering	Mobile	0.9559325696384716	-6.353572342333408	103996
f6cbc7c21ddda008d949bf6e3c48b79c6e232cfe	the natural hedge of a gas-fired power plant	computer and systems sciences;systemvetenskap informationssystem och informatik;information systems;ucl;risk management;discovery;theses;conference proceedings;digital web resources;data och systemvetenskap;ucl discovery;open access;electricity markets;ucl library;book chapters;open access repository;stochastic programming;ucl research	Electricity industries worldwide have been restructured in order to introduce competition. As a result, decision makers are exposed to volatile electricity prices, which are positively correlated with those of natural gas in markets with price-setting gas-fired power plants. Consequently, gas-fired plants are said to enjoy a “natural hedge.” We explore the properties of such a built-in hedge for a gas-fired power plant via a stochastic programming approach, which enables characterisation of uncertainty in both electricity and gas prices in deriving optimal hedging and generation decisions. The producer engages in financial hedging by signing forward contracts at the beginning of the month while anticipating uncertainty in spot prices. Using UK energy price data from 2006 to 2011 and daily aggregated dispatch decisions of a typical gasfired power plant, we find that such a producer does, in fact, enjoy a natural hedge, i.e., it is better off facing uncertain spot prices rather than locking in its generation cost. However, the natural hedge is not a perfect hedge, i.e., even modest risk aversion makes it optimal to use gas forwards partially. Furthermore, greater operational flexibility enhances this natural hedge as generation decisions provide a countervailing response to uncertainty. Conversely, higher energy-conversion efficiency reduces the X. Guo · A. Beskos · A. Siddiqui (B) Department of Statistical Science, University College London, London, UK e-mail: afzal.siddiqui@ucl.ac.uk X. Guo e-mail: x.guo.11@ucl.ac.uk A. Beskos e-mail: a.beskos@ucl.ac.uk A. Siddiqui Department of Computer and Systems Sciences, Stockholm University, Stockholm, Sweden	canonical account;code signing;dynamic dispatch;email;linear programming relaxation;lock (computer science);purchasing;relevance;risk aversion;stochastic programming;systems science;unintended consequences;uninterruptible power supply	Xiaojia Guo;Alexandros Beskos;Afzal Siddiqui	2016	Comput. Manag. Science	10.1007/s10287-014-0222-x	basis risk;stochastic programming;mathematical optimization;economics;risk management;operations management;mathematics;economy;information system;commerce	ML	-0.15332429373133089	-4.371494876070085	104097
20346f2aa573efbf9ea18b762a675a08c0fb7f6a	graphical models for economic profit maximization	decision tree;probability;uncertainty;decision analysis;economic decisions;managerial economics;graphical model;influence diagram;profit maximization	Decision trees and influence diagrams are utilized to analyze and solve profit maximization problems from economics. As a complement to traditional analytical methods for solving these problems, use of these graphical representations allows students to learn about the effects of uncertainty on pricing and capacity choices. Decision trees are first used to model a firm's production capacity and pricing decisions when these choices are made simultaneously under certain and uncertain demand. The decision tree approach is next extended to a situation where the firm makes its capacity and price selections under different information constraints. The use of these problems as part of a case assignment in a writing-intensive managerial economics course is discussed. Influence diagrams are also presented as an alternative modeling technique that can easily accommodate more potential values for decision variables when solving these problems. By studying the effects of uncertainty on profit maximization problems, students can also learn to appreciate that dealing with uncertainty is important in many business decisions.	expectation–maximization algorithm;graphical model;job stream;recommender system	Barry R. Cobb	2011	INFORMS Trans. Education	10.1287/ited.1100.0055	mathematical optimization;influence diagram;uncertainty;economics;decision analysis;marketing;decision tree;probability;mathematics;management science;microeconomics;graphical model;operations research;managerial economics;welfare economics;business decision mapping	ECom	4.398611386135762	-5.8758348249970895	104164
287eb137c7c72784c74bffb7e46fd45700a177ea	energy efficient short term spectrum auction using the concept of green payments	energy efficiency;green payments;dynamic spectrum auction;bidding period;dynamic spectrum access	This work seeks to demonstrate the economic importance of short-term spectrum auction and how it can be implemented with fewer overheads. This can be achieved using the proposed market driven sealed bid spectrum auction process with a novel concept called the green payment. The green payment serves as an incentive during the auction process to encourage the users to use the radio spectrum in an efficient manner. The model proposes to tax users that are not power efficient while those that are power efficient pay a subsidy during the auction process. First, the appropriate bidding and auction periods are examined and determined such that the bidding period is dependent on the traffic load in the system. Using the obtained bidding period, the value of the green payments is then examined and the appropriate level of tax and subsidy are also determined. The economic importance of the model in terms of the revenue generation for the service provider and in terms of the tax being adequate to finance the subsidy is also examined. These results show that using the proposed concept of green payment, the energy consumed and the system delay can be reduced when compared to a non-green payment based auction process. The results also show that the proposed model is beneficial to the service provider in terms of increase in profit and that the tax and subsidy system is self-sustaining.	long short-term memory	Abdulkarim Oloyede;David Grace	2016	Wireless Personal Communications	10.1007/s11277-016-3341-6	spectrum auction;walrasian auction;eauction;generalized second-price auction;revenue equivalence;efficient energy use;auction theory;dutch auction	Mobile	-0.31463005721912257	-4.8618735475200126	104300
b47d6c194ac3b4786003cc895c36aa5e69b15a0e	retail competition and the dynamics of demand for tied goods	endogenous consumption;substitution effect;vertical channels;dynamic discrete choice;retail competition;demand systems;durable good;durable good replacement;long run effects;razor blade market;tied goods	We present a demand system for tied goods incorporating dynamics arising from the tied nature of the products and the stockpiling induced by storability and durability. We accommodate competition across tied good systems and competing downstream retail formats by endogenizing the retail format at which consumers choose to stockpile inventory. This facilitates measurement of long-run retail substitution effects and yields estimates of complementarities within, and substitution across, competing systems of tied goods. We present an empirical application to an archetypal tied goods category: razors and blades. We discuss the implications of measured effects for manufacturer pricing when selling the tied products through an oligopolistic downstream retail channel and assess the extent to which retail substitution reduces channel conflict.		Wesley R. Hartmann;Harikesh S. Nair	2010	Marketing Science	10.1287/mksc.1090.0518	industrial organization;economics;marketing;microeconomics;durable good	Theory	-1.4693058380972248	-7.830338283249351	104505
a20e1b064b9acb33f6a2f049f77a681d42b4ce26	dynamic portfolio optimization for power generation assets		Markowitz’s classical mean-variance approach for portfolio selection considers only single-period investments. It has, therefore, received very little attention in the context of long-term investment planning. Nevertheless, considering dynamic aspects, already Markowitz [12] mentioned the attractiveness of multi-period portfolio selection problems for portfolio readjustments during the planning horizon. The direct application of the mean-variance model to multi-stage portfolio problems, however, causes many difficulties. A number of studies have tackled such difficulties, providing suggestions on how the dynamic aspects of portfolio optimization should be considered. One of these suggestions is a reallocation methodology that is based on scenario analysis and a tree approach [14]. In this paper, we apply this methodology to power generation assets, in order to capture the continuously changing values of the economic as well as technical parameters considered when evaluating investments in power plants.	optimizing compiler	Barbara Glensk;Reinhard Madlener	2012		10.1007/978-3-319-00795-3_26	portfolio optimization	EDA	9.282501147822103	-3.033905237476879	104596
b85b226031ac91a2bb91f7cf1adb480775989a66	sustainable production: using simulation modeling to identify the benefits of green information systems		Researchers and practitioners highlight the potential for information systems to promote sustainability in agricultural production, but little is known about the private and social benefits of specific agricultural decision support tools. In this study, we utilize the resource-based view to assess a specific green technology using an agricultural-economics simulation to estimate the quantitative benefits of this technology expressed as dollars saved and reduced greenhouse gas emissions. In particular, we employ a five-step simulation modeling approach within a micro-economic model of crop production to assess the ability of yield monitors to promote liquefied petroleum (LP) gas savings and subsequently reduce production costs, reduce greenhouse gas (GHG) emissions associated with LP gas burning, and generate additional revenue at a market for GHG mitigation credits. We estimate that the total benefits of using the green IS to improve the harvesting decision would have been $82 million in post-harvest cost savings and a significant reduction in greenhouse gas emissions. We present this simulation modeling approach, a common methodology in environmental sciences and economics, as a viable methodology for IS researchers interested in modeling intricate decision-making processes that are impacted by technology.	information system;simulation	Lyubov A. Kurkalova;Lemuria Carter	2017	Decision Support Systems	10.1016/j.dss.2017.02.006	environmental resource management;operations management	OS	7.021213558069045	-7.013466581197104	104625
1841db7191dbedb959d7503aa4b60476de2ca5a5	a stochastic alternating renewal process model for unavailability analysis of standby safety equipment	stochastic process;unavailability;age based replacement;safety systems;inspection;nuclear plants;failure rate;alternating renewal process	The paper presents a stochastic approach to analyze instantaneous unavailability of standby safety equipment caused by latent failures. The problem of unavailability analysis is formulated as a stochastic alternating renewal process without any restrictions on the form of the probability distribution assigned to time to failure and repair duration. An integral equation for point unavailability is derived and numerically solved for a given maintenance policy. The paper also incorporates an age-based preventive maintenance policy with random repair time. In case of aging equipment, the asymptotic limit or average unavailability should be used with a caution, because it cannot model an increasing trend in unavailability as a result of increasing hazard rate (i.e. aging) of the time to failure distribution. & 2015 Elsevier Ltd. All rights reserved.	asymptote;numerical analysis;process modeling;unavailability	Johannes A. M. van der Weide;Mahesh D. Pandey	2015	Rel. Eng. & Sys. Safety	10.1016/j.ress.2015.03.005	reliability engineering;stochastic process;inspection;engineering;failure rate;forensic engineering;system safety	AI	6.879925915653977	-1.0386754002571124	104672
1b547bd0b961786cca5c071c03d80dd13ea24ec7	study of the bullwhip effect in a multistage supply chain with callback structure considering two retailers		With the purpose of researching the bullwhip effect when there is a callback center in the supply chain system, this paper establishes a new supply chainmodel with callback structure, which has a material supplier, a manufacture, and two retailers.Themanufacture and retailers all employ AR(1) demand processes and use order-up-to inventory policy when they make order decisions. Moving average forecasting method is used to measure the bullwhip effect of each retailer and manufacture. We investigate the impact of lead-times of retailers and manufacture, forecasting precision, callback index, and marketing share on the bullwhip effect of both retailers and manufacture. Then we use the method of numerical simulation to indicate the different parameters in this supply chain. Furthermore, this paper puts forward some suggestions to help the enterprises to control the bullwhip effect in the supply chain with callback structure.	autoregressive model;callback (computer programming);multistage amplifier;numerical weather prediction;simulation	Junhai Ma;Liqing Zhu;Ye Yuan;Shunqi Hou	2018	Complexity	10.1155/2018/3650148	machine learning;callback;artificial intelligence;computer simulation;bullwhip effect;operations management;supply chain;mathematics	AI	2.088536351718059	-9.344975588400601	105007
94b3823ded936d79b4c11ec06a90503f01fa96ab	day-ahead market bidding for a nordic hydropower producer: taking the elbas market into account	garch;hydroelectric scheduling;power market;bidding strategies;price uncertainty;mixed integer program;electricity auctions;elbas;mixed integer programming;profitability;stochastic programming;optimization model	In many power markets around the world the energy generation decisions result from two-sided auctions in which producing and consuming agents submit their price-quantity bids. The determination of optimal bids in power markets is a complicated task that has to be undertaken every day. In the present work, we propose an optimization model for a price-taker hydropower producer in Nord Pool that takes into account the uncertainty in market prices and both production and physical trading aspects. The day-ahead bidding takes place a day before the actual operation and energy delivery. After this round of bidding, but before actual operation, some adjustments in the dispatched power (accepted bids) have to be done, due to uncertainty in prices, inflow and load. Such adjustments can be done in the Elbas market, which allows for trading physical electricity up to one hour before the operation hour. This paper uses stochastic programming to determine the optimal bidding strategy and the impact of the possibility to participate in the Elbas. ARMAX and GARCH techniques are used to generate realistic market price scenarios taking into account both day-ahead price and Elbas price uncertainty. The results show that considering Elbas when bidding in the day-ahead market does not significantly impact neither the profit nor the recommended bids of a typical hydro producer.	arma 3;integer programming;klaus samelson;linear programming;mathematical optimization;stochastic programming;terminator 2: judgment day;thermal grease;trine	Eduardo Faria;Stein-Erik Fleten	2011	Comput. Manag. Science	10.1007/s10287-009-0108-5	financial economics;stochastic programming;autoregressive conditional heteroskedasticity;mathematical optimization;integer programming;economics;finance;mathematics;microeconomics;commerce;profitability index	ECom	5.236333428765656	-5.790626596974982	105033
9328d790580353a586a9947ee097ec623dbc77ca	model predictive control, the economy, and the issue of global warming	institutional repositories;fedora;integrated assessment;climate change;economic model;business as usual;optimal policy;vital;model predictive control;optimal control;numerical analysis;environmental economics;point of view;vtls;global warming;free riding;human activity;ils;dynamic optimization	This study is motivated by the evidence of global warming, which is caused by human activity but affects the efficiency of the economy. We employ the integrated assessment Nordhaus DICE-2007 model (Nordhaus, A question of balance: economic modeling of global warming, Yale University Press, New Haven, 2008). Generally speaking, the framework is that of dynamic optimization of the discounted inter-temporal utility of consumption, taking into account the economic and the environmental dynamics. The main novelty is that several reasonable types of behavior (policy) of the economic agents, which may be non-optimal from the point of view of the global performance but are reasonable form an individual point of view and exist in reality, are strictly defined and analyzed. These include the concepts of “business as usual”, in which an economic agent ignores her impact on the climate change (although adapting to it), and of “free riding with a perfect foresight”, where some economic agents optimize in an adaptive way their individual performance expecting that the others would perform in a collectively optimal way. These policies are defined in a formal and unified way modifying ideas from the so-called “model predictive control”. This research was supported by the Belgian Science Policy under the CLIMNEG project (SD/CP/05A). The second author was supported by the PAI grant P6/07 and from the Belgian French speaking community Grant ARC 03/08-302. The third author was partly financed by the Austrian Science Foundation (FWF) under grant No P18161-N13. T. Bréchet ( ) CORE and Louvain School of Management, Chair Lhoist Berghmans in Environmental Economics and Management, Université catholique de Louvain, Voie du Roman Pays, 34, 1348 Louvain-la-Neuve, Belgium e-mail: thierry.brechet@uclouvain.be C. Camacho Belgian National Foundation of Scientific Research and Economics Department, Université catholique de Louvain, Voie du Roman Pays, 34, 1348 Louvain-la-Neuve, Belgium e-mail: carmen.camacho@uclouvain.be V.M. Veliov ORCOS, Institute of Mathematical Methods in Economics, Vienna University of Technology, Argentinierstrasse 8, 1040 Vienna, Austria e-mail: veliov@tuwien.ac.at 26 Ann Oper Res (2014) 220:25–48 The introduced concepts are relevant to many other problems of dynamic optimization, especially in the context of resource economics. However, the numerical analysis in this paper is devoted to the evolution of the world economy and the average temperature in the next 150 years, depending on different scenarios for the behavior of the economic agents. In particular, the results show that the “business as usual”, although adaptive to the change of the atmospheric temperature, may lead within 150 years to increase of temperature by 2°C more than the collectively optimal policy.	data haven;dynamic programming;email;linear algebra;louvain modularity;mathematical optimization;numerical analysis;point of view (computer hardware company);utility	Thierry Bréchet;Carmen Camacho;Vladimir M. Veliov	2014	Annals OR	10.1007/s10479-011-0881-8	mathematical optimization;simulation;optimal control;economics;global warming;numerical analysis;environmental resource management;economic model;mathematics;management science;free riding;climate change;model predictive control	AI	-0.41523211150143763	-1.3518839961715208	105122
1fb0f99079c98ad12e75ceac4be9ab67f316e7f5	profit management of car rental companies	company mean profit;strategic planning;company information;size and utilization;systems dynamics;entropy;property renting	A car rental company consists of a fleet of available rentable vehicles (waiting to be rented and being rented). We model the company as a family of Birth–Death Processes (BDPs) in equilibrium with finite size, indexed by the company utilization parameter. This metric is the ratio of the primary birth and death rates in these BDPs. Relying on the basic concepts of company information and company entropy (i.e., mean information), we promote a procedure for profit management of car rental companies. The company entropy represents the company uncertainty (i.e., risk); moreover, finding optimal values of company utilization and fleet size leads to a unique management of that uncertainty. Introducing the coefficient of proportionality of a company, as ratio of the renting revenue per vehicle per day and costs per vehicle per day, we obtain an expression for the mean profit per day of a company (i.e., profit attained per day from the average number of simultaneously rented vehicles) as a function of company utilization, fleet size and coefficient. Thus, the profit management procedure reduces to finding optimal values of these three metrics, as the key profit drivers of the rental business. Moreover, an expression for the minimal value of the coefficient is introduced (as a function of the other two metrics), determining the zero mean profit per day. Thereby, the efficiency of the company's fleet is determined as a reciprocal of this minimal value. The developed procedure is illustrated on a company which is represented by the Erlang loss system.		Igor Lazov	2017	European Journal of Operational Research	10.1016/j.ejor.2016.08.064	entropy;strategic planning;actuarial science;economics;marketing;operations management;system dynamics	Robotics	4.186153757442186	-8.646677742643536	105127
f061397c1820671e1c572098d6ec23e7f05aa600	a prediction market system for aggregating dispersed tacit knowledge into a continuous forecasted demand distribution	tacit knowledge;utility function;prediction market;simulation model;aggregate demand;demand forecasting	This research proposes a novel demand forecasting method which will work effectively even in such circumstances where extrapolate-able demand patterns are hardly available. The method uses the market mechanism to aggregate tacit knowledge of the firm's sales people on the future demand of a product into a continuous forecasted demand distribution. In order to make it work, the paper introduces a new type of prediction security and an original market maker algorithm suitable for the security, and furnishes them into an intra-firm prediction market system. As a result, sufficient liquidity is secured for the market even when the number of the traders is small, and the market maker can output at any time an aggregated demand forecast of the traders as a continuous distribution. An agent simulation model, where each trader has the log-utility function, is also developed to show how the method works, how quickly the output distribution converges, etc.	agent-based model;aggregate data;algorithm;experiment;extrapolation;global serializability;real life;risk aversion;simulation;traders;utility	Hajime Mizuyama;Eisuke Kamada	2007		10.1007/978-0-387-74157-4_23	financial economics;demand forecasting;marketing;microeconomics;business	ECom	0.4530125193938923	-7.346035952566354	105205
30d6a40752769e96255d5de8d4b0d42cb624c6f1	payoff-based inhomogeneous partially irrational play for potential game theoretic cooperative control: convergence analysis	objective function;nash equilibrium;game theory;multi agent systems;games;markov processes;resistance;algorithm design and analysis;learning artificial intelligence;probability;convergence	This paper investigates learning algorithm design in potential game theoretic cooperative control, where it is in general required for agents' collective action to converge to the most efficient equilibria while standard game theory aims at just computing a Nash equilibrium. In particular, the equilibria maximizing the potential function should be selected in case the utility functions are already aligned to a global objective function. In order to meet the requirement, this paper develops a learning algorithm called Payoff-based Inhomogeneous Partially Irrational Play (PIPIP). The main feature of PIPIP is to allow agents to make irrational decisions with a specified probability, i.e. agents can choose an action with a low utility from the past actions stored in the memory. We then prove convergence in probability of the collective action to the potential function maximizers. Finally, the effectiveness of the present algorithm is demonstrated through simulation on a sensor coverage problem.	algorithm design;consensus dynamics;converge;eigenvector centrality;ergodic theory;ergodicity;expanded memory;game theory;loss function;markov chain;markov property;multi-agent system;nash equilibrium;optimization problem;potential method;simulation;state transition table;stochastic matrix	Tatsuhiko Goto;Takeshi Hatanaka;Masayuki Fujita	2012	2012 American Control Conference (ACC)		price of stability;implementation theory;games;game theory;algorithm design;minimax;mathematical optimization;traveler's dilemma;simulation;best response;convergence;computer science;probability;repeated game;mathematics;strategy;correlated equilibrium;risk dominance;markov process;mathematical economics;resistance;equilibrium selection;nash equilibrium;statistics	ML	0.13683531119006215	-0.19519488762207912	105531
09368ccba6d01b1aa2399c0c04a4cbc6bb5e8f02	manufacturer's revenue-sharing contract and retail competition	prix vente;bayes estimation;probleme vendeur journaux;variabilidad;strategie stackelberg;channel coordination;logistique;profit sharing;systeme aide decision;numerical method;stackelberg strategy;pricing;optimal decision;relacion orden;venta menudeo;vente au detail;ordering;prise de decision;sistema ayuda decision;probabilistic approach;contrato;fijacion precios;journal;retail marketing;strategie nash;detaillant;decision optimale;profit;relation ordre;systeme incertain;estimacion bayes;decision support system;economic order quantity;sharing;revenue sharing contract;particion;logistics;contract;beneficio;retail competition;stochastic demand;seasonality;enfoque probabilista;approche probabiliste;estrategia stackelberg;estrategia nash;benefice;coordinacion;supply chain;quantite economique a commander;nash strategy;profitability;contrat;cantidad economica pedida;partage;variability;revenue sharing;toma decision;sistema incierto;variabilite;retailers;selling price;newsboy problem;uncertain system;problema vendedor diarios;fixation prix;supply chain management;precio venta;coordination;estimation bayes;logistica;decision optimal	This paper investigates a revenue-sharing contract for coordinating a supply chain comprising one manufacturer and two competing retailers. The manufacturer, as a Stackelberg leader, offers a revenue-sharing contract to two competing retailers who face stochastic demand before the selling season. Under the offered contract terms, the competing retailers are to determine the quantities to be ordered from the manufacturer, prior to the season, and the retail price at which to sell the items during the season. The process of pricing and ordering is expected to result in an equilibrium as in the Bayesian Nash game. On the basis of anticipated responses and actions of the retailers, the manufacturer designs the revenuesharing contract. Adopting the classic newsvendor problem model framework and using numerical methods, the study finds that the provision of revenue-sharing in the contract can obtain better performance than a price-only contract. However, the benefits earned under the revenue-sharing contract by different supply chain partners differ because of the impact of demand variability and price-sensitivity factors. The paper also analyses the impact of demand variability on decisions about optimal retail price, order quantity and profit sharing between the manufacturer and the retailers. Lastly, it investigates how the competition (between retailers) factor influences the decision-making of supply chain members in response to uncertain demand and profit variability. 2007 Elsevier B.V. All rights reserved.	game theory;nash equilibrium;newsvendor model;numerical analysis;numerical method;operations research;price point;product bundling;revenue sharing;spatial variability;throughput;yao graph	Zhong Yao;Stephen C. H. Leung;Kin Keung Lai	2008	European Journal of Operational Research	10.1016/j.ejor.2007.01.049	contract;pricing;logistics;contract management;supply chain management;profit;optimal decision;economic order quantity;decision support system;economics;marketing;operations management;supply chain;seasonality;commerce	ECom	-0.3687077895653605	-5.2438864545638895	105552
1bb31a2f870991f67989b4761a8576fc4938abc0	investigating the dynamics of nation-building through a system of differential equations		Nation-building modeling is an important field given the increasing number of candidate nations and the limited resources available. In this paper, we present a modeling methodology and a system of differential equations model to investigate the dynamics of nation-building.The methodology is based on solving inverse problems, much like Lanchester equations, and provides measures of merit to evaluate nation-building operations. An application is derived for Operation Iraqi Freedom to demonstrate the utility as well as effects of various alternate strategies, using differing applications of national power. This modeling approach is data driven and offers a significant, novel capability when analyzing and planning for future nation-building scenarios. Journal of the Operational Research Society (2017). doi:10.1057/s41274-017-0256-x	coefficient;composite index (database);curve fitting;fm broadcasting;nonlinear system;parallels desktop for mac;programming paradigm	Cade M. Saie;Darryl K. Ahner	2018	JORS	10.1057/s41274-017-0256-x	management science;national power;computer science;differential equation;system dynamics;inverse problem;nation-building		6.030237891186335	-8.531207466397486	105559
ca942bda39d2e5a0669bcadb721cdc8e93628f92	league scheduling and game bundling in sports industry	revenue management;ticket bundling;league scheduling;article	Most sport clubs offer season tickets first and they allow purchasing single tickets at a later date. There are several decision problems within this context; the determination of the optimal time at which the switch from bundled tickets to single tickets should occur, the decision of which event tickets to include into the bundle depending on the schedule of the team and the creation of a league schedule enabling revenue enhancements from game bundling. In this paper we have focused on the last decision problem. We analyze league scheduling and game bundling decisions together for a double round robin tournament in order to maximize the total revenue generated by all of the participating teams in the league. A heuristic method is offered which utilizes the approximate expected revenue values obtained by revenue increase and decrease patterns of bundled tickets. We test the offered heuristic's performance and observe significant benefits numerically.	scheduling (computing)	Serhan Duran;Okan Örsan Özener;Ertan Yakici	2014	Computers & Industrial Engineering	10.1016/j.cie.2014.05.005	marketing;operations management;advertising;lottery scheduling	DB	-0.07835246660263544	-5.826649509050771	105723
1083b702f4a89c1f7a0ef6fbe467f68bdc6109c5	macroeconomic dynamics of assets, leverage and trust	trust;assets;regime shifting;leverage;macroeconomics;complex systems;crisis	A macroeconomic model based on the economic variables (i) assets, (ii) leverage (defined as debt over asset) and (iii) trust (defined as the maximum sustainable leverage) is proposed to investigate the role of credit in the dynamics of economic growth, and how credit may be associated with both economic performance and confidence. Our first notable finding is the mechanism of reward/penalty associated with patience, as quantified by the return on assets. In regular economies where the EBITA/Assets ratio is larger than the cost of debt, starting with a trust higher than leverage results in the highest long-term return on assets (which can be seen as a proxy for economic growth). Therefore, patient economies that first build trust and then increase leverage are positively rewarded. Our second main finding concerns a recommendation for the reaction of a central bank to an external shock that affects negatively the economic growth. We find that late policy intervention in the model economy results in the highest longterm return on assets. However, this comes at the cost of suffering longer from the crisis until the intervention occurs. The phenomenon that late intervention is most effective to attain a high long-term return on assets can be ascribed to the fact that postponing intervention allows trust to increase first, and it is most effective to intervene when trust is high. These results are derived from two fundamental assumptions underlying our model: (a) trust tends to increase when it is above leverage; (b) economic agents learn optimally to adjust debt for a given level of trust and amount of assets. Using a Markov Switching Model for the EBITA/Assets ratio, we have successfully calibrated our model to the empirical data of the return on equity of the EURO STOXX 50 for the time period 2000–2013. We find that dynamics of leverage and trust can be highly nonmonotonous with curved trajectories, as a result of the nonlinear coupling between the variables. This has an important implication for policy makers, suggesting that simple linear forecasting can be deceiving in some regimes and may lead to inappropriate policy decisions.	emoticon;markov chain;nonlinear system	Jeroen C. Rozendaal;Yannick Malevergne;Didier Sornette	2016	I. J. Bifurcation and Chaos	10.1142/S0218127416501339	complex systems;actuarial science;return on equity;weighted average return on assets;crisis;trustworthy computing;leverage;asset	AI	-0.7785158708621107	-9.45694801607101	105733
9c196355e2e74f8866e1c1acf0428074dadc2d5d	unbounded probabilistic sophistication	probabilistic sophistication countable additivity monotone continuity tail continuity;risk preference;probability distribution	I extend Machina and Schmeidler’s (1992) model of probabilistic sophistication to unbounded uncertain prospects (acts) and derive risk preferences over the induced probability distributions (lotteries) with unbounded support. For example, risk preferences can be derived over normal, exponential, and Poisson families of probability distributions. My extension uses a version of Arrow’s (1970) Monotone Continuity, which implies countable additivity for subjective beliefs and a novel property of tail-continuity for the revealed risk preferences. On the other hand, I do not assume P6 (Small Event Continuity) that is used both by Savage (1954) and Machina–Schmeidler. © 2010 Elsevier B.V. All rights reserved.	machina (company);p6 (microarchitecture);scott continuity;time complexity;monotone	Igor Kopylov	2010	Mathematical Social Sciences	10.1016/j.mathsocsci.2010.05.003	probability distribution;mathematical optimization;discrete mathematics;mathematics;welfare economics;statistics	AI	0.428301241701359	-2.3238067460551646	106066
598eec61de824446ee9a24b84a6d8a2c186bf3a4	resale price maintenance in supply chains with general multiplicative demand		Abstract We analyze a supply chain with a Resale Price Maintenance (RPM) contract in which the manufacturer sets the retail price with a general multiplicative price–demand function and prove the existence/uniqueness of an equilibrium. We also compare the equilibrium prices and quantities, consumer surplus and total system welfare for the RPM and wholesale price contracts. We conclude that a manufacturer may capture a smaller share of the total supply chain profit despite her ability to set the retail price.		George J. Kyparisis;Christos Koulamas	2018	Oper. Res. Lett.	10.1016/j.orl.2018.04.005	mathematical optimization;uniqueness;multiplicative function;supply chain;economic surplus;mathematics;microeconomics;resale price maintenance	ECom	-1.264891984887781	-5.238043729688297	106125
f2a56ef4088abbdfb1981ed02946cad14c86ac2a	two-stage discrete choice models for scanner panel data: an assessment of process and assumptions	modelizacion;panel data;eleccion;ensemble choix;compra;systeme discret;comercializacion;multinomial logit;comportement consommateur;prise decision;information search;acheteur;commercialisation;modelisation;buyer behavior;choice models;marketing;choice sets;scanner data;clientele;comportamiento consumidor;achat;consumer behavior;choix marque;sistema discreto;modele logit;choix;logit model;toma decision;modeling;choice;purchases;modelo logit;discrete system;discrete choice model	Discrete choice models such as the multinomial logit assume that consumers choose from the full set of alternatives available to them. However, because (i) consumers may not be able to recall or recognize available brands, (ii) consumers may not have the cognitive capacity or mental energy to process information pertaining to all available brands, or (iii) careful consideration of all available brands might be suboptimal from an economic standpoint given the cost of information search, consumers tend to make choices from a relatively small subset of the available brands. This study assesses the process assumptions of existing two-stage models for scanner panel data and their consistency with the actual processes believed to be used by consumers in forming choice sets. After reviewing what is known from two-stage models in scanner data applications, we highlight issues in need of research. Ó 1998 Elsevier Science B.V. All rights reserved. Keywords: Choice sets; Choice models; Buyer behavior 1. Introduction Over the last 15 years, more than a dozen twostage choice models have been described in the marketing, management, econometric, geography, and transportation engineering literatures. These models have been developed in order to relax certain restrictive assumptions inherent in Lucebased discrete choice models such as multinomial logit, namely the IIA assumption relating to the similarity of available brands and the assumption that all consumers choose from the same universal set of brands available in the marketplace when making a choice. Compared to single-stage discrete choice models (which are reviewed by Manrai, 1995), two-stage models may better represent the underlying process which consumers are believed to use in selecting a brand from a set of competing brands (Gensch, 1987; Shocker et al., 1991). Typically, in the ®rst stage of a two-stage choice model, the consumer is assumed to form a set of brands from which the ®nal choice will be made, which is known as the choice set (Shocker et al., European Journal of Operational Research 111 (1998) 193±215 * Corresponding author. Fax: +1-302-831-4196; e-mail: manraia@udel.edu 0377-2217/98/$19.00 Ó 1998 Elsevier Science B.V. All rights reserved. PII S 0 3 7 7 2 2 1 7 ( 9 8 ) 0 0 1 4 5 3 1991). Forming this set may involve (i) building the set ``from scratch'' by recalling or recognizing brands that are capable of meeting the current need, (ii) reducing the full set of available brands by screening brands that are not desirable or capable of meeting the need, or (iii) some combination of these two processes. In the second stage of a two-stage choice model, the consumer is typically assumed to make a choice from this smaller set of brands using a brand-based compensatory analysis, such as that of the standard multinomial logit choice model. Behaviorally, several explanations can be put forth to justify two-stage models of brand choice. First, in memory-based choice situations (such as the choice of a restaurant), consumers may not be able to recall all brands or options that are available to them (Hutchinson et al., 1994). Inability to recall all brands in the awareness set results in an actual choice set that is smaller than the universal set. Likewise, the consumer may be exposed to brand names in a supermarket and fail to recognize some set of them as appropriate for the need at hand, resulting in a reduced set of alternatives from which to make the ®nal choice. Brand primes such as advertisements, point-of-purchase displays, and store features may make a brand's recall more likely (Andrews and Srinivasan, 1995; Bronnenberg and Vanhonacker, 1996; Nedungadi, 1990). Second, given awareness of the relevant brands, consumers may lack the processing capacity or the mental energy to process all information pertinent to these brands. Researchers have suggested ``phased'' decision strategies as characteristic of decision making in contexts where the choice situation is overly complex (Payne, 1982; Shocker et al., 1991; Wright and Barbour, 1977). With phased decision strategies, the consumer is thought to ®rst screen alternatives using relatively simple criteria before making a more thorough analysis and choice from the reduced set of brands. Third, exhaustive search and information processing may not be optimal given the costs associated with these activities. The theory of the economics of information beginning with Stigler (1961) demonstrates that the optimal number of brands to be searched in a choice situation may be smaller than the number of available brands given nonzero search costs. Empirical evidence has supported the theory to some extent (e.g., Andrews, 1992). Roberts and Lattin (1991) and Hauser and Wernerfelt (1990) have formulated cost-bene®t models to describe the formation of the consumer's choice set, and Andrews and Srinivasan (1995) developed an extension of the Roberts and Lattin model which is intended for use with scanner panel data. Perhaps because the research in this area has emerged from dierent disciplines, there has previously been no complete conceptual comparison of available two-stage choice models. Given the rapid proliferation of two-stage models in recent years, the goal of this paper is to take inventory of the available models to determine how they are dierent conceptually, what process assumptions are being made by the models, and what work remains to be done in the area. It is not our intention to review all literature on choice simpli®cation and choice sets ± only two-stage models of choice which may be applied to scanner panel data. See Roberts and Lattin (1997) for a review of other recent choice set research. Section 2 describes various criteria on which two-stage discrete choice models dier and presents an overview of existing models. Section 3 examines the processes, assumptions, and mathematical forms of these models in some detail. Section 4 presents evidence on the explanatory power and forecasting performance of existing two-stage models. Finally, Section 5 provides conclusions and outlines some directions for future research. 2. Criteria for assessing two-stage discrete choice models Manski (1977) provides a general expression for computing the choice probabilities for two-stage models. When consumer n makes a choice from among a set S  f1; 2; . . . ; i; . . . ;mg of feasible brands on some choice occasion t, the probability that the consumer will choose some brand i is computed as 194 A.K. Manrai, R.L. Andrews / European Journal of Operational Research 111 (1998) 193±215 P i j S; b; c;X n t ; Zn  X 2mÿ1 j1 P Cj j c;X n t ; ZnP i j Cj; b;X n t ; Zn; 1 where Cj is one of the 2m ÿ 1 nonempty subsets of S; c and b are vectors of parameters re ̄ecting the eectiveness of explanatory variables at the two stages of the model; X n t is a matrix containing the attributes of all brands in set S, as experienced by consumer n at choice occasion t; and Zn is a matrix containing consumer n's characteristics, which are assumed to be time invariant. Thus, the ®rst stage of a two-stage model is concerned with how the consumer generates the reduced choice set, and this is captured in the ®rst component on the righthand side of Eq. (1). The second stage, represented by the second component on the right-hand side of Eq. (1), describes how the consumer makes a choice from this set. The two sets of parameters c and b describe the eectiveness of explanatory variables in choice set formation and choice, respectively. In Eq. (1), it is not necessary that all variables contained in the matrices X n t and Z n be involved in both stages of the two-stage model; variables determining choice set composition and choice may overlap partially, completely, or not at all. The simulation study by Andrews and Manrai (1998) found no adverse consequences from including the same variables as determinants of both consideration and choice. Eq. (1) is a two-stage model in its most general form. When the universal set is large, Eq. (1) is not a feasible choice set model since the number of possible choice sets 2m ÿ 1 is so large as to become computationally burdensome. Hence, most two-stage brand choice models are special cases of Eq. (1). Though existing models consistently assume that the consumer makes the second-stage choice from the restricted choice set using a compensatory, brand-based evaluation strategy, they posit a variety of speci®cations for the choice set formation component P Cj j c;X n t ; Zn ÿ : Choice set generation can be (i) memory-based or stimulusbased, (ii) naive or based on consumer and/or product characteristics, (iii) attribute-based or brand-based, (iv) static or dynamic, and (v) deterministic or probabilistic. 2.1. Memory-based versus stimulus-based choice set formation Choice set formation is memory-based if the consumer retrieves the contents of the choice set from memory without any cues from the external environment and stimulus-based if the consumer forms the choice set when the universal set of options is physically present in the consumer's environment at the time of choice. Purely memorybased choice set formation may be more common in store-choice decisions (e.g., choosing a restaurant) than in brand-choice decisions (e.g., choosing a brand of orange juice), though some argue that consumers use memory-based choice even in the presence of the alternatives since information overload is common, and consumers are limited information processors (Alba et al., 1991). Choice set formation may also be purely memory-based when the consumer makes the brand choice decision prior to entering the store (Bucklin and Lattin, 1991). In memory-based choice situations, the consumer may generate the choice set by considering only brands which s/he has purchased before (e.g., Siddarth et al., 1995), only brands which are most preferred, or only brands whose advertising the consumer remembers at the time of purchase (Mitra, 199	brute-force search;central processing unit;choice modelling;computer memory;computer program;consistency model;contingency (philosophy);converge;cross-sectional data;discrete choice;email;emoticon;energy (psychological);fax;heuristic (computer science);information overload;information processing;information retrieval;inventory;kerrison predictor;like button;local optimum;maschinen krieger zbv 3000;multinomial logistic regression;operations research;panel data;personally identifiable information;point of sale;relevance;semantic heterogeneity;simulation;time-invariant system;william jolitz;word lists by frequency;wright (adl)	Ajay K. Manrai;Rick L. Andrews	1998	European Journal of Operational Research	10.1016/S0377-2217(98)00145-3	econometrics;systems modeling;economics;computer science;marketing;operations management;discrete system;discrete choice;panel data;mathematics;logistic regression;consumer behaviour;multinomial logistic regression	Logic	3.625382050837355	-6.553606843991709	106163
393f1b6bb53b22897576e4582b42ac4b64fee073	the effects of customer misclassification on cross-training in call centers		The benefits of cross-training in terms of increasing responsiveness to demand fluctuations have been studied extensively in the literature. In this work, we study another important advantage of cross-training due to customer misclassi- fication, i.e. a caller declares to face a certain problem (e.g. a hardware problem) where in fact another problem persists (e.g. a software problem). In call centers that applynocross-training,misclassifiedcallsneedtobereroutedtoagentswhoareable to serve the true problem, whereas cross-training enables agents to serve different problem types which reduces cycle times. We introduce two-type queueing models to study the effects of customer misclassification on cross-training in call centers. We observe that, if only a third of the agents is cross-trained, high increases in model performance can be confirmed, whereas little benefit is added by higher amounts of cross-training. We also study the effects of routing policies on cycle times.		Andreas Schwab;Burak Büke	2013		10.1007/978-3-319-07001-8_58	simulation	ML	4.715102772788733	0.8886398447878091	106165
03d0faf26514828da9786cfb579c67afde0d1822	deem: a tool for the dependability modeling and evaluation of multiple phased systems	unifi;verification;analytical models;phased mission systems;computer aided analysis;deterministic petri nets;reliability;dependability evaluation;performance evaluation;phase behavior;scheduled maintenance systems;deterministic and stochastic petri nets;computer aided analysis reliability petri nets markov processes maintenance engineering modelling;analytical modeling;stochastic petri net;critical applications;maintenance engineering;dependability modeling and evaluation;markov regenerative processes deem dependability modeling dependability evaluation multiple phased systems operational life disjoint periods phased mission systems scheduled maintenance systems critical applications phased behavior analytical modeling deterministic petri nets stochastic petri nets;firenze;dependable systems;bonding;affidabili;operational life;stochastic petri nets;ricerca;resilient computing lab;power system management;dependability;performance analysis;phased behavior;disjoint periods;validation;deem;rcl;markov processes;affidabilita;petri nets;stochastic systems;power system modeling;florence;sistemi;regenerative process;markov regenerative processes;dependability modeling;assessment;multiple phased systems;scheduled maintenance;aircraft;energy management;modeling and analysis;power system modeling petri nets bonding performance analysis analytical models stochastic systems energy management power system management performance evaluation aircraft	Multiple-Phased Systems, whose operational life can be partitioned in a set of disjoint periods, called “phases”, include several classes of systems such as Phased Mission Systems and Scheduled Maintenance Systems. Because of their deployment in critical appli cations, the dependability modeling and analysis of Multiple-Phased Systems is a task of primary rele vance. However, the phased behavior makes the analy sis of Multiple-Phased Systems extremely complex.. This paper is centered on the description and applica tion of DEEM, a dependability modeling and evalua tion tool for Multiple Phased Systems. DEEM supports a powerful and efficient methodology for the analytical dependability modeling and evaluation of Multiple Phased Systems, based on Deterministic and Stochastic Petri Nets and on Markov Regenerative Processes.	dependability;markov chain;petri net;software deployment	Andrea Bondavalli;Ivan Mura;Silvano Chiaradonna;Roberto Filippini;S. Poli;F. Sandrini	2000		10.1109/ICDSN.2000.857541	maintenance engineering;reliability engineering;real-time computing;stochastic petri net;dependability;statistics	Embedded	7.1745477866530685	0.7359184132585104	106171
064f04c8b9a0052fa5a2c00d907038fd7bb79b67	entry, exit, and imperfect competition in the long run	dynamic game;imperfect competition;sunk cost;finite horizon;infinite horizon;stochastic model;subgame perfect nash equilibrium;stochastic games;entry and exit	An infinite-horizon, stochastic model of entry and exit with sunk costs and imperfect competition is constructed. Simple examples provide insights into: (1) the relationship between sunk costs and industry concentration, (2) entry when current profits are negative, and (3) the relationship between entry and the length of the product cycle. A subgame perfect Nash equilibrium for the general dynamic stochastic game is shown to exist as a limit of finite-horizon equilibria. This equilibrium has a relatively simple structure characterized by two numbers per finite history. Under very general conditions, it tends to exhibit excessive entry and insufficient exit relative to a social optimum.	nash equilibrium	Rabah Amir;Val E. Lambson	2003	J. Economic Theory	10.1016/S0022-0531(03)00002-4	industrial organization;markov perfect equilibrium;sunk costs;economics;subgame;stochastic modelling;microeconomics;mathematical economics;sequential game;subgame perfect equilibrium	Web+IR	-3.4193970773063307	-5.725127228491919	106213
298cb1a5b342c3ae711ff5686cc82dd5f0486052	modelling the re-design decision for a warranted product	produit domestique;manufacturer;produit consommation;garantie contre risque;data capture;producto domestico;zona dato;fabricante;decision reconception;fabricant;warranty;model development;field data;garantia contra riesgo;domestic product;consumer products;data field;zone donnee;re design decision	A prototype model is presented for the potential re-design decision once field data becomes available for a product under warranty. Attention is given to possible techniques for estimating warranty returns for both the existing product beyond the data capture period and for the re-designed product for which there is no field data. The roles and influence of the key parameters and decision variables are explored. Numerical examples based upon realistic data pertinent to domestic consumer products are used to illustrate the various models developed. q 2004 Elsevier Ltd. All rights reserved.	decision theory;numerical analysis;prototype;relevance	H. Ward;A. H. Christer	2005	Rel. Eng. & Sys. Safety	10.1016/j.ress.2004.07.005	computer science;engineering;data field;final good;automatic identification and data capture;manufacturing;forensic engineering;operations research	DB	3.018512261270946	-5.705046213552099	106328
e8ff161c82af96e9438155302a0749ec17efc40b	a model to evaluate the impact of headway variation and vehicle size on the reliability of public transit	analytical models;reliability;vehicle sizes headway variability stochastic model;transit planners headway variation vehicle size public transit reliability public transit systems stochastic variations markov chain technique passenger arrival passenger boarding passenger alighting passenger travel time;reliability markov processes public transport;transit buses;passenger handling;vectors;mathematical models;vehicle size;vehicles;markov processes;vectors vehicles reliability numerical models markov processes analytical models;numerical models;on time performance;headways	Reliability of public transit systems is a chronic concern for transit operators, authorities, and users, in terms of system utilization and level of service. This paper develops a theoretical model to evaluate factors that influence the reliability of public transit systems and examines their performance based on stochastic variations in passenger arrival, boarding, alighting, and travel time on the regularity of headway along the route with multiple stops. The model is based on a Markov chain technique to obtain numerical estimates of performance. The predictions of this model are verified based on replicating the well-observed phenomenal relationship between the mean and variance of delay experienced by passengers. The numerical examples offer insights into the factors that affect the reliability of public transit systems. This investigation provides a better understanding of determinants of reliability of public transit systems and it can be used as an analysis tool by transit planners to evaluate the effectiveness of various policies.	algebraic equation;cobham's thesis;computation;control system;dynamic dispatch;markov chain;numerical analysis;performance;theory;whole earth 'lectronic link	Kamrul Islam;Upali Vandebona;Vinayak V. Dixit;Ashish K Sharma	2015	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2014.2377019	simulation;engineering;automotive engineering;mathematical model;reliability;mathematics;transport engineering;markov process;statistics	Metrics	9.846548839539363	-9.470975932059757	106333
fe3e3033225b90d5b97ff9870ab129df2b443d25	the dual optimizer for the growth-optimal portfolio under transaction costs	transaction cost;black scholes model;taylor expansion;dual problem;60h10;optimal growth;growth rate;portfolio management;transaction costs;infinite horizon;proportional transaction costs;91b16;91b28;growth optimal portfolio;shadow price	We consider the maximization of the long-term growth rate in the Black-Scholes model under proportional transaction costs as in Taksar, Klass and Assaf [Math. Oper. Res. 13, 1988]. Similarly as in Kallsen and MuhleKarbe [Ann. Appl. Probab., 20, 2010] for optimal consumption over an infinite horizon, we tackle this problem by determining a shadow price, which is the solution of the dual problem. It can be calculated explicitly up to determining the root of a deterministic function. This in turn allows to explicitly compute fractional Taylor expansions, both for the no-trade region of the optimal strategy and for the optimal growth rate.	black–scholes model;duality (optimization);expectation–maximization algorithm;mathematical optimization;shadow price	Stefan Gerhold;Johannes Muhle-Karbe;Walter Schachermayer	2013	Finance and Stochastics	10.1007/s00780-011-0165-9	financial economics;transaction cost;economics;mathematical economics;welfare economics;project portfolio management	AI	1.698064491362741	-2.32562458068744	106735
e34c86b299ba0296fe2e8c4b3009c507c487fc5c	capacity investment, pricing, and production allocation across international markets with exchange rate uncertainty	global supply chain;capacity allocation;pricing;ito processes;capacity investment;lead time;seasonality;international marketing;exchange rate;production cost;global supply chains	In this paper, we investigate joint optimal capacity investment, pricing and production decisions for a multinational manufacturer who faces exchange rate uncertainties. We consider a manufacturer who sells its product in both domestic and foreign markets over a multiperiod season. Because of long-lead times, the capacity investment must be committed before the selling season begins. The exchange rate between the two countries fluctuates across periods and the demand in both markets are price dependent. Our model considers three scenarios: (1) early commitment to price and quantity with central sourcing, (2) postponement of prices and quantities with central sourcing, and (3) local sourcing. We derive the optimal capacity and the optimal prices for each scenario, and investigate the impact of the exchange rate parameters and the length of the selling season. We observe that while the price and production decisions in the domestic market are independent of the exchange rate under early commitment and local sourcing scenarios, the exchange rate between two countries directly impacts these decisions under the postponement setting. We identify thresholds and gain insights on capacity and production costs, exchange rate movement, and selling season length for the choice of entering a foreign market under all scenarios.		Anas Ahmed;Murat Erkoc;Sohyung Cho	2012	APJOR	10.1142/S0217595912400088	pricing;economics;mathematics;microeconomics;supply chain;market economy;seasonality;commerce	DB	0.977985801540478	-5.426083072009388	106874
88d5553fa897e2eb7b17946b7c0d13f5f1c6a15c	how does adoption of the outlet channel impact customers' spending in the retail stores: conflict or synergy?	grupo de excelencia;retailing;segmentation;channel strategy;outlet stores;administracion de empresas;multichannel marketing;factory outlets;economia y empresa;grupo a	We investigate how adoption of a retailer’s factory outlet channel impacts customers’ spending in the retailer’s traditional retail store channel. In recent years, many retailers have added exclusively sourced factory outlet stores into their channel mix to achieve market expansion and customer segmentation. However, the impact of adoption of this lower-quality, lower-price alternative channel on spending at the retailer’s higher-quality, higher-price retail store channel is not clear. Customers adopting the outlet channel might increase their spending in the retail store channel because of the opportunity to become familiar with the brand at a lower price point or transfer of positive associations formed through patronage of the outlet channel to the store channel. Customers adopting the lower-quality channel might also decrease their spending in the retail store channel because of brand dilution or cannibalization. To investigate this issue, we use a unique individual-level panel data set from a specialty apparel retailer from a period during which the retailer opened many factory outlet stores. This allows us to study how purchase behavior changes after customers adopt the outlet channel while carefully controlling for alternative explanations including customer heterogeneity and selection effects. We find that although customers who adopt the outlet channel spend less with the retailer compared to store-only customers, the difference cannot be attributed to the impact of adoption of the outlet channel. After controlling for heterogeneity and selection effects, we uncover a positive spillover to the retail store channel from adoption of the outlet channel. Customers who adopt the outlet channel not only make incremental purchases at the outlet channel, but also increase their spending in the retail store channel after adoption. The increase in spending is due to more frequent retail store purchases and not to larger per-purchase expenditure. This paper was accepted by J. Miguel Villas-Boas, marketing .	synergy	Gonca P. Soysal;Lakshman Krishnamurthi	2016	Management Science	10.1287/mnsc.2015.2262	marketing;advertising;segmentation;commerce	EDA	-2.1244352666538644	-7.861472259743014	106994
2e27d234c8731032d33af171ae8ea619d581e929	strategic factor market intelligence: an application of information economics to strategy formulation and competitor intelligence	information acquisition;model generation;resource based view;information gathering;strategic factor market;model building;information economics;number of factors;information processing;competitor intelligence;competitive advantage	"""This paper develops a model of information-acquisition decisions by firms that are competing in a """"strategic factor market"""" (Barney 1986) to purchase a scarce resource whose value is unknown and differs across firms. The model builds on the argument that more accurate expectations about the firm-specific value of resources is, other than luck, the only way for firms to obtain the specific resources required for competitive advantage. We address the more specific question of what types of information firms should gather to accomplish this goal. The model generates a series of testable hypotheses about how a firm's optimal mix of different types of information is affected by a number of factors, including the level of uncertainty about the value of the resource being acquired; the rarity, imitability, and nonsubstitutability of that resource; the level of inscrutability of firms' pre-existing stocks of resources; and firms' information-gathering and information-processing capacities."""		Richard Makadok;Jay B. Barney	2001	Management Science	10.1287/mnsc.47.12.1621.10245	model building;economics;information processing;marketing;operations management;information economics;microeconomics;management;competitive advantage;commerce	AI	-0.02288480013722227	-7.822235712639279	107087
a98d31240b5a4263c15e948af98cc4500606a18c	quality-effective repair of multichip module systems	markov chain model;quality assurance;module multipuce;metodo analitico;modelo medio efectivo;niveau defaut;informe tecnico;modelo markov;modulo multipulga;effective medium model;pulga electronica;yield;chip;modele milieu effectif;multichip module;markov model;analytical method;methode analytique;cost effectiveness;technical report;modele markov;defect level;quality model;figure of merit;monte carlo simulation;puce electronique;rapport technique;repair;facteur merite	This paper proposes a new analytical approach for evaluating the effects of a repair process on the defect level of multichip module (MCM) systems during assembly, thereby identifying the optimal number of repair cycles. Repair of complex MCMs is required to improve the yield and quality of these systems, while preserving cost effectiveness. No analytical evaluation has been reported in the current technical literature. In the proposed approach, we employ a novel Markov-chain model, which is solved analytically in O(rN3) (where r is the maximum number of allowed repair cycles and N is the number of chips in the MCM). The proposed model is based on a previously proposed quality model [36] for MCMs which does not incorporate the effect of a repair process on the defect level.The proposed model effectively relates the defect level to different figures of merit of repair, such as the probability of successfully repairing a fault (referred to as repairability) and the maximum allowed number of repair cycles. Parametric results show that the overall defect level decreases as the MCM yield increases due to the repair process; however, there exists a bound in the number of repair cycles, while still permitting an increase in repairability. The bound value provides the optimal number of repair cycles.Using these results, it is possible to predict a more accurate value of the defect level of MCMs by taking into account the different parameters affecting the repair process, while realistically reducing the defect level of the final MCM product. The cost of the repair process is analyzed and an example using industrial data is provided. The validity of the proposed approach is further accomplished through extensive Monte Carlo simulation.	multi-chip module	Nohpill Park;Fred J. Meyer;Fabrizio Lombardi	2002	Journal of Systems Architecture	10.1016/S1383-7621(01)00038-8	chip;quality assurance;markov chain;yield;figure of merit;simulation;cost-effectiveness analysis;computer science;technical report;markov model;statistics;monte carlo method	Logic	8.31139078053707	0.6839992337338509	107105
331b59e8a0ea8d43b388a1073bb03e19c4114360	a dynamic learning model for on-line quality control using the taguchi approach	decision models;fabricacion asistida por computador;sistema experto;architecture systeme;measurement error;learning;on line;learning model;en linea;intelligence artificielle;prise decision;aprendizaje;fabrication assistee;apprentissage;state space;computer aided manufacturing;estimacion parametro;controle qualite;artificial intelligence;arquitectura sistema;en ligne;adjustment cost;inteligencia artificial;systeme expert;parameter estimation;estimation parametre;system architecture;toma decision;quality control;control calidad;expert system	Abstract An important philosophy of quality control due to Taguchi rests on the belief that, once quality is designed into the product and the process, very little inspection is necessary. Taguchi evaluates quality in terms of costs incurred, including inspection and adjustment costs apart from quality loss. Using these costs, he determines an optimal interval for periodic inspection of products. At each inspection, the first item on the process line is checked for defects. If no defects are found, the process is assumed to be under control. On the other hand, if the first item turns out to be defective, the process is immediately stopped and adjusted. The underlying assumption here is that, once a defect is observed, it is construed that the process has drifted and all subsequent items are defective. This article challenges the underlying assumption by recognizing that the observation of one defective item does not necessarily imply that the process is out of control. Noisy signals may occur as a result ...	online and offline	H. Raghav Rao;M. V. Thirumurthy;Ram Ramesh	1992	Applied Artificial Intelligence	10.1080/08839519208949967	quality control;decision model;simulation;computer science;state space;artificial intelligence;estimation theory;expert system;observational error	AI	6.505414053127054	-2.273675320960963	107184
058a62922203e05dc61a8308ac0138a5a438ed11	globalization and labor market outcomes: wage bargaining, search frictions, and firm heterogeneity	real wages;search friction;wage bargaining;labor market outcomes;firm heterogeneity;selection effect;trade cost;search model;trade liberalization;trade liberalization unemployment search model firm heterogeneity;trade openness	Globalization and Labor Market Outcomes: Wage Bargaining, Search Frictions, and Firm Heterogeneity We introduce search unemployment à la Pissarides into Melitz’ (2003) model of trade with heterogeneous firms. We allow wages to be individually or collectively bargained and analytically solve for the equilibrium. We find that the selection effect of trade influences labor market outcomes. Trade liberalization lowers unemployment and raises real wages as long as it improves aggregate productivity net of transport costs. We show that this condition is likely to be met by a reduction in variable trade costs or the entry of new trading countries. On the other hand, the gains from a reduction in fixed market access costs are more elusive. Calibrating the model shows that the positive impact of trade openness on employment is significant when wages are bargained at the individual level but much smaller when wages are bargained at the collective level. JEL Classification: F12, F15, F16	aggregate data;aggregate function;linear algebra;openness;reduction (complexity);selection bias	Gabriel Felbermayr;Julien Prat;Hans-Jörg Schmerer	2011	J. Economic Theory	10.1016/j.jet.2010.07.004	free trade;selection bias;economics;trade barrier;macroeconomics;microeconomics;efficiency wage;economic policy;labour economics	ECom	-2.8446567624282757	-5.480316347642552	107248
15383148af7b409ac5612c090794025af6983a51	online mechanism design for electric vehicle charging	tl motor vehicles aeronautics astronautics;pricing;monograph or book;incentive engineering;algorithms;design;economics;distributed ai;mechanism design;electric vehicle;applications;tk electrical engineering electronics nuclear engineering;multiagent systems	Plug-in hybrid electric vehicles are expected to place a considerable strain on local electricity distribution networks, requiring charging to be coordinated in order to accommodate capacity constraints. We design a novel online auction protocol for this problem, wherein vehicle owners use agents to bid for power and also state time windows in which a vehicle is available for charging. This is a multi-dimensional mechanism design domain, with owners having non-increasing marginal valuations for each subsequent unit of electricity. In our design, we couple a greedy allocation algorithm with the occasional “burning” of allocated power, leaving it unallocated, in order to adjust an allocation and achieve monotonicity and thus truthfulness. We consider two variations: burning at each time step or on-departure. Both mechanisms are evaluated in depth, using data from a real-world trial of electric vehicles in the UK to simulate system dynamics and valuations. The mechanisms provide higher allocative efficiency than a fixed price system, are almost competitive with a standard scheduling heuristic which assumes non-strategic agents, and can sustain a substantially larger number of vehicles at the same per-owner fuel cost saving than a simple random scheme.	allocative efficiency;benchmark (computing);best, worst and average case;computer multitasking;greedy algorithm;heuristic;marginal model;maximal set;microsoft windows;scheduling (computing);simulation;system dynamics	Enrico Gerding;Valentin Robu;Sebastian Stein;David C. Parkes;Alex Rogers;Nicholas R. Jennings	2011			pricing;mechanism design;design;simulation;artificial intelligence;multi-agent system;information technology	AI	2.914043148827774	3.994443488961892	107323
bd0d7f73c421f711b2c749a43fe77a4e4f1205f9	the sustainable energy tax policy decision-making model based on invest willingness constraint	energy conservation;analytical models;investments;sustainable energy saving;transportation sector;system dynamics;decision making transportation finance macroeconomics economic indicators instruments energy resources costs petroleum protection;cost reduction;biological system modeling;energy tax;tax policy;interest rate;tax rates implementation scheme;decision making model;petroleum;crude oil;energy price;energy consumption;energy resources;transportation;environmental economics;taxation;transportation cost reduction decision making energy conservation energy consumption environmental economics socio economic effects sustainable development taxation;co2 emission;energy consumption decision making model tax policy tax rates implementation scheme china transportation sector sustainable energy saving;china;socio economic effects;system dynamics energy resources energy tax willingness to invest;sustainable development;analytical model;energy saving;willingness to invest	To increase the efficiency of exploiting energy resource and confirm the optimum expected energy-saving target and the tax rates implementation scheme of the energy-saving target, an analytical model of tax policy was set up for researching on the sustainable energy for China’s transportation sector. This model which is based on system dynamics, is taken the effects of the energy price, interest rate, energy tax rate and energy-saving marginal cost into account, and focused on investigating the effects of the finance and tax policy for China energy on the energy-saving program. It is found that the energy tax rates for transportation energy consuming will increase from 28% (in 2005) to 40% (in 2011) and then reduce gradually to 33% (in 2020), assuming the optimum energy-saving target to be 5% annually from 2005 to 2020. The gross transportation energy consuming, the relative CO2 emissions and the tax-inclusive price of crude oil will increase to 321.8 MT, 977.78 MT and 1533.99 USD/T, respectively, in 2020 from 120 MT, 364.57 MT and 611.78 USD/T, respectively, in 2005. This work is of importance and possible to be the guidance for the design of future finance and tax policy on sustainable energy.	diesel;embodied cognition;high-level programming language;imperative programming;marginal model;software release life cycle;system dynamics	Y. Tao;H. F. Xue;Lei Huang	2009	2009 WRI World Congress on Computer Science and Information Engineering	10.1109/CSIE.2009.312	energy conservation;tax basis;interest rate;system dynamics;petroleum;sustainable development;china	AI	6.496567978362672	-7.879849607935457	107333
335e702e2670cfd231a6a0156f37cfdfce83c0da	behavior-based pricing in marketing channels		With behavior-based pricing BBP, firms use customersu0027 purchase history data to price discriminate between past and new customers. Prior research has examined BBP in a non-channel setting. In this paper, we investigate BBP in a channel setting in which manufacturers sell to customers through exclusive retailers. We examine how channel membersu0027 adoption of BBP affects wholesale and retail prices, profits, consumer surplus, and social welfare. We find that BBP decreases channel membersu0027 profits when retailers use BBP and manufacturers use uniform pricing. However, BBP increases channel membersu0027 profits when manufacturers and retailers use BBP. In addition, BBP by retailers alone increases consumer surplus, whereas BBP by manufacturers and retailers decreases consumer surplus. When manufacturers also use BBP, BBP decreases social welfare to a greater degree than when only retailers use BBP. Furthermore, when manufacturers cannot use BBP, their profits are higher with long-term wholesale price contracts. When manufacturers can use BBP, short-term wholesale price contracts yield higher profits for manufacturers and retailers.rnrnThe online appendix is available at https://doi.org/10.1287/mksc.2017.1070 .		Krista J. Li	2018	Marketing Science	10.1287/mksc.2017.1070	microeconomics;marketing;economics;profit (economics);commerce;social welfare;economic surplus;dynamic pricing	Logic	-2.176017526964809	-7.105232659379031	107378
f151a7652e19bd6a4c360b689dd2ebb860ad6f8d	the consignment stock of inventories in coordinated model with generalized policy	consignment stock;inventory;two stage supply chain;optimization	More general consignment stock policies for the vendor-buyer model are presented.Delivery schedules and the inventory patterns are described in different scenarios.Optimal solutions are found and illustrated with numerical examples.Solution procedures for optimal generalized CS-policies are given. In this paper, coordination between a single vendor (or manufacturer) and a buyer (or retailer) via the delivery schedule in a production and distribution system is presented. A continuous deterministic model with centralized decision process is developed. To satisfy the buyer's demands, the product is delivered in discrete batches from the vendor's stock to the buyer's stock and all shipments are realized instantaneously. A more general type of consignment stock (CS) policies for the vendor-buyer integrated production-distribution model is analyzed. Our model does not require equal in size shipments. The inventory patterns and the cost structure of production distribution cycles (PDC) are described in different scenarios. A comparative study of the results shows that the generalized CS policies perform better. Considering CS-policies Braglia and Zavanella (2003) ask about a possibility of cost reduction by delaying a number of late deliveries. Unfortunately, a negative answer was given by Zanoni and Grubbstrom (2004). We verify this problem to obtain a positive answer in more general setting. A solution procedure is developed to find optimal generalized CS-policy for the problems with nonequal and equal in size deliveries. Optimal solutions are found and illustrated with numerical examples.	inventory	Stanislaw Bylka;Piotr Górny	2015	Computers & Industrial Engineering	10.1016/j.cie.2015.01.009	mathematical optimization;stock management;inventory;operations management;microeconomics;commerce	SE	1.8053342727387194	-4.792041630087984	107488
7131d4dfb68ff92bbd08e5dfa06fdb5628997742	surf - structural unduplicated reach and frequency: latent class turf and shapley value analyses	marketing strategy;cooperative game theory;shapley value;choquet integral;turf;latent class;latent structure analysis;structure analysis	Lazarsfeld's Latent Structure Analysis (LSA) is applied to problems in marketing involving the choice of products with maximum customer coverage. The LSA is combined with Total Unduplicated Reach and Frequency (TURF) technique, and also with a tool from cooperative game theory, the Shapley Value (SV), also known as the fuzzy Choquet integral. SV is used for ordering the items by their strength in covering the maximum number of consumers, which provides more stable results than TURF. Structural Unduplicated Reach and Frequency (SURF) analysis is introduced as the LSA segmentation of customers with different preferences across the products. The blending of LSA with TURF and SV yields new abilities of the latent structured TURF and SV. The marketing strategy based on using these techniques permits the identification of the preferred combinations in media or product mix for different population segments.	speeded up robust features;stable marriage problem;value (computer science)	Stan Lipovetsky	2008	International Journal of Information Technology and Decision Making	10.1142/S0219622008002909	simulation;economics;artificial intelligence;marketing;operations management;structural analysis;shapley value;marketing strategy;choquet integral;operations research	SE	-1.6530660818831588	-7.106992000527739	107683
7ed44ef344f68a1098cc4c9df97b3e420ed2c27a	wine analytics: fine wine pricing and selection under weather and market uncertainty	wine pricing;weather uncertainty;pricing;risk aversion;wine futures;market uncertainty	Copyright: © 2016 INFORMS Abstract. We examine a risk-averse distributor’s decision in selecting between bottled wine and wine futures under weather and market uncertainty. At the beginning of every summer, a fine wine distributor has to choose between purchasing bottled wine made from the harvest collected two years ago and wine futures of wine still aging in the barrel from the previous year’s harvest. At the end of the summer, after seeing weather and market fluctuations, the distributor can adjust its allocation by trading futures and bottles. This paper makes three contributions. First, we develop an analytical model to determine the optimal selection of bottled wine and wine futures under weather and market uncertainty. Our model is built on an empirical foundation in which the functional forms describing the evolution of futures and bottle prices are derived from comprehensive data associated with the most influential Bordeaux winemakers. Second, we develop structural properties of optimal decisions. We show that a wine distributor should always invest in wine futures because it increases the expected profit in spite of being a riskier asset than bottled wine. We characterize the influence of variation in various uncertainties in the problem. Third, our study empirically demonstrates for a large distributor the financial benefits of using our model. The hypothetical average profit improvement in our numerical analysis is significant, exceeding 21%, and its value becomes higher under risk aversion. The analysis is beneficial for fine wine distributors, as it provides insights into how to improve their selection in order to make financially healthier allocations.	fo (complexity);futures and promises;institute for operations research and the management sciences;modeling perspective;nl (complexity);numerical analysis;purchasing;requirement;risk aversion;time series;value at risk	Mert Hakan Hekimoglu;Burak Kazaz;Scott Webster	2017	Manufacturing & Service Operations Management	10.1287/msom.2016.0602	pricing;risk aversion;economics;marketing;advertising;economy	ML	0.7348223585975109	-7.80487135190644	107811
46bded9c382cd46b91153542fedf28556e4a7a97	collective effects and performance of algorithmic electric vehicle charging strategies		We combine the power flow model with the proportionally fair optimization criterion to study the control of congestion within a distribution electric grid network. The form of the mathematical optimization problem is a convex second order cone that can be solved by modern non-linear interior point methods and constitutes the core of a dynamic simulation of electric vehicles (EV) joining and leaving the charging network. The preferences of EV drivers, represented by simple algorithmic strategies, are conveyed to the optimizing component by realtime adjustments to user-specific weighting parameters that are then directly incorporated into the objective function. The algorithmic strategies utilize a small number of parameters that characterize the user's budgets, expectations on the availability of vehicles and the charging process. We investigate the collective behaviour emerging from individual strategies and evaluate their performance by means of computer simulation.	behavioral pattern;complex systems;computer simulation;dynamic simulation;emergence;expectation propagation;experiment;extended validation certificate;fairness measure;grid network;interior point method;jonas;mathematical model;mathematical optimization;network congestion;nonlinear system;numerical analysis;optimization problem;proportionally fair;smart city;software deployment;sorting;state of charge;turing institute	Miroslav Gardlo;Lubos Buzna;Rui Carvalho;Richard J. Gibbens;Frank Kelly	2018	2018 IEEE Workshop on Complexity in Engineering (COMPENG)	10.1109/CompEng.2018.8536246	mathematical optimization;proportionally fair;mathematics;electric vehicle;small number;dynamic simulation;interior point method;grid network;weighting	Robotics	3.7743529132831846	3.2842273502698087	107892
c8c6a375948c362d4015ad9e4a76a716c868c84f	a joint dynamic pricing and advertising model of perishable products	journal of the operational research society	Advertising and dynamic pricing play key roles in maximizing profit of a firm. In this paper a joint dynamic pricing and advertising problem for perishable products is investigated, where the time-varying demand rate is decreasing in sales price and increasing in goodwill. A dynamic optimization model is proposed to maximize total profit by setting a joint pricing and advertising policy under the constraint of a limited advertising capacity. By solving the dynamic optimization problem on the basis of Pontryagin’s maximum principle, the analytical solutions of the optimal joint dynamic pricing and advertising policy are obtained. Additionally, to highlight the advantage of the joint dynamic strategy, the case of the optimal advertising with static pricing policy is considered. Numerical examples are presented to illustrate the validness of the theoretical results, and some managerial implications for the pricing and advertising of the perishable products are provided.		Lin Feng;Jianxiong Zhang;Wansheng Tang	2015	JORS	10.1057/jors.2014.89	pricing;economics;marketing;microeconomics;commerce	ECom	0.08219733681057946	-4.852106783875532	108007
c2c58cbdaf7dcc27716a8b640cac0abff1be909e	global dual sourcing: tailored base-surge allocation to near- and offshore production	economic optimization;service apres vente;politica optima;approximation asymptotique;evaluation performance;pressure surge;remontee pression;economic system;trafico denso;probability;performance evaluation;asymptotic optimality;globalizacion;availability;trafic dense;disponibilidad;evaluacion prestacion;after sale service;servicio postventa;supply demand balance;elevacion presion;probabilistic approach;inventory production;optimal policy;administracion deposito;instability;optimisation economique;fournisseur multiple;sous traitance;estrategia empresa;racine carree;systeme economique;proveedor multiple;enfoque probabilista;approche probabiliste;heavy traffic;multiple supplier;coste;gestion stock;instabilite;offre et demande;performance bounds;square root;mondialisation;asymptotic approximation;stochastic model;optimizacion economica;inestabilidad;subcontratacion;capital requirement;oferta y demanda;subcontracting;politique optimale;firm strategy;inventory control;disponibilite;strategie entreprise;quick response;modelo estocastico;globalization;heavy trac;modele stochastique;sistema economico;stochastic model applications;applications;validation studies;aproximacion asintotica;cout;stochastic models;raiz cuadrada	When designing a sourcing strategy in practice, a key task is to determine the average order rates placed to each source because that affects costs and supplier management. We consider a firm that has access to a responsive near-shore source (e.g., Mexico) and a low-cost offshore source (e.g., China). The firm must determine an inventory sourcing policy to satisfy random demand over time. Unfortunately, the optimal policy is too complex to allow a direct answer to our key question. Therefore, we analyze a tailored basesurge (TBS) sourcing policy that is simple, used in practice, and captures the classic tradeoff between cost and responsiveness. The TBS policy replenishes at a constant rate from the offshore source and produces at the near shore plant only when inventory is below a target. The constant base allocation allows the offshore facility to focus on cost efficiency while the nearshore’s quick response capability is utilized only dynamically to guarantee high service. The research goals are to i) determine the allocation of random demand into base and surge capacity, ii) estimate corresponding working capital requirements, and iii) identify and value the key drivers of dual sourcing. Given that even this simple TBS policy is not amenable to exact analysis, we investigate a Brownian approximation that yields a simple “square-root” formula that is insightful to answer our questions and sufficiently accurate for practice, as is demonstrated with a validation study.	2.5d;approximation;centralized computing;cost efficiency;distributed control system;feedback;inventory theory;mathematical optimization;nonlinear system;numerical analysis;requirement;responsiveness	Gad Allon;Jan A. Van Mieghem	2010	Management Science	10.1287/mnsc.1090.1099	simulation;economics;stochastic modelling;operations management;finance;operations research;information technology	AI	4.482925690292035	-3.3170492129628637	108042
9cef8257fda9c7aacd5436106f77f67901afb4d9	comparison between the agency and wholesale model under the e-book duopoly market		This paper provides a comprehensive comparison between the agency and wholesale model under the electronic book market duopoly. A model comprised of two retailers and a publisher was established to run the comparison in terms of price, profit, and welfare. We found that although better e-reader offerings may seem favorable in terms of e-book pricing, the actual effect on e-books is limited or even negligible. High wholesale price leads to higher retail prices of e-books and e-readers under the wholesale model than the agency model. Generally speaking, the total profits of e-books returned to the retailers under the wholesale model are lower than those returned under the agency model; conversely, the publisher obtains higher profits under the wholesale model than the agency model despite its power over e-book pricing. We also found that consumers are more likely to derive greater surplus under the wholesale model when the difference in available e-books is relatively narrow. If the wholesale price is low, however, the consumer surplus under the wholesale model is higher than that under the agency model across the board. Further, when the difference in e-books is very small, the total social welfare is minimized under the wholesale model compared to the agency model; low wholesale price but poor substitutability (or high wholesale price with relatively high substitutability) yield favorable social welfare under the wholesale model.	darknet market;e-book	Cungen Zhu;Zhong Yao	2018	Electronic Commerce Research	10.1007/s10660-017-9256-9	economics;producer price index;marketing;microeconomics;wholesale price index;commerce	ECom	-2.4500247917311873	-7.820038452472644	108092
23ca12b98b747c65d2e81c665044289d997b5406	post-tax optimization with stochastic programming	finance;investment strategies;portfolio optimization;integer programming;portfolio management;linear programming;linear program;stochastic model;integer program;post tax optimization;stochastic programming;scenarios;optimal portfolio	In this paper, we consider a stochastic programming approach to multistage post-tax portfolio optimization. Asset performance information is specified as a scenario tree generated by two alternative methods based on simulation and optimization. We assume three tax wrappers involving the same instruments for an efficient investment strategy and determine optimal allocations to different instruments and wrappers. The tax rules are integrated with the linear and mixed integer stochastic models to yield an overall tax and return-efficient multistage portfolio. The computational performance of these models is tested using a case study with different scenario trees. Our experiments show that optimal portfolios obtained by both linear programming and mixed integer stochastic models diversify over wrappers and the original capital is distributed among assets within each wrapper. 2003 Elsevier B.V. All rights reserved.	computation;display resolution;experiment;linear programming;mathematical optimization;multistage amplifier;simulation;stochastic process;stochastic programming;wrapper function	María Auxilio Osorio Lama;Nalan Gülpinar;Berç Rustem;Reuben Settergren	2004	European Journal of Operational Research	10.1016/S0377-2217(03)00240-6	financial economics;stochastic programming;mathematical optimization;robust optimization;investment strategy;integer programming;economics;linear programming;branch and price;stochastic modelling;stochastic optimization;portfolio optimization;mathematics;microeconomics	AI	9.00625470440029	-3.141178931071236	108172
e842e9ca874a6940ff296da11715d583bfb0fc75	selloffs, bailouts, and feedback: can asset markets inform policy?	market microstructure;strategic trade;corrective intervention	We present a model in which a policymaker observes trade in a financial asset before deciding whether to intervene in the economy, for example by offering a bailout or monetary stimulus. Because an intervention erodes the value of private information, informed investors are reluctant to take short positions and selloffs are, therefore, less likely and less informative. The policymaker faces a tradeoff between eliciting information from the asset market and using the information so obtained. In general she can elicit more information if she commits to intervene only infrequently. She thus may benefit from imperfections in the intervention process or from being non-transparent about the costs or benefits of intervention. JEL: C72, D82, E61, G01, G14.	commitment scheme;feedback;personally identifiable information	Raphael Boleslavsky;David L. Kelly;Curtis R. Taylor	2017	J. Economic Theory	10.1016/j.jet.2017.02.009	industrial organization;market microstructure;actuarial science;economics;finance;macroeconomics;microeconomics	AI	-4.002423692205764	-7.114828294570104	108258
71d4012562e26b5fb9813099a4f575bb554a2bce	distributed optimal control of a network of virtual power plants with dynamic price mechanism	contracts artificial neural networks energy storage europe;distributed control virtual power plants vpps bilateral contracts power balance bidding strategy multi agent systems team theory dynamic price mechanism;contracts;pricing distributed control optimal control power distribution control power distribution economics;artificial neural networks;energy storage;europe;discrete time steps distributed optimal control virtual power plants dynamic price mechanism vpp distributed energy management system distributed generations dg storage facilities electric demand bilateral contracts multilevel negotiation schemes team theory framework distributed control strategy control inputs	This paper addresses a distributed control problem faced by a network of virtual power plants (VPPs). The VPP can be represented as a distributed energy management system tasked to aggregate distributed generations (DGs), loads and storage facilities to operate as a unique power plants regardless of their locations. In this framework, the main decisions that need to be established by the VPP decision maker are: 1) to decide how to fulfill its related electric demand including bilateral contracts and 2) to bid in multi-level negotiation schemes to minimize (maximize) in a cooperative way the power bought (sold) from (to) other interconnected VPPs. The proposed approach is based on a team theory framework and on dynamic price mechanism, where all VPPs' agents cooperate on the accomplishment of a common goal which is function of the subsystem state and of some controls which are shared with other subsystems. A distributed control strategy is proposed, and that includes problems in which each agent is able to communicate with other agents. Agents of the VPPs compute the control inputs at discrete time steps based on the information available to them. An example is presented to show the practical use of the method.	aggregate data;bilateral filter;control theory;distributed control system;is functions;optimal control;secure multi-party computation	Hanane Dagdougui;Ahmed Ouammi;Roberto Sacile	2014	2014 IEEE International Systems Conference Proceedings	10.1109/SysCon.2014.6819231	control engineering;simulation;economics;operations management	Robotics	2.324836074614821	3.834906870269138	108616
781fa506ef6a63363981b10cee0d5ddaa4ca61ac	a nonparametric predictive method for queues	statistical approach;queueing;prediction method;nonparametric predictive inference;waiting time;stochastic model;methodology	This paper presents a novel statistical approach to queues. Instead of studying characteristics of an assumed parametric stochastic model, the method uses information in the form of observed service times per queue and, while adding a minimum of additional assumptions, develops predictive probability results for the waiting time for customers in a queue. We show how these results can be used in a multi-queue problem to assign arriving customers to queues, aiming at minimisation of waiting times.		Frank P. A. Coolen;Pauline Coolen-Schrijner	2003	European Journal of Operational Research	10.1016/S0377-2217(02)00179-0	econometrics;economics;computer science;stochastic modelling;operations management;methodology;mathematics;fork–join queue;queueing theory;statistics	Robotics	7.807335833793388	-2.7056012331924197	108994
b173f56c97335aa6e9770944ae76c494c9bc2d5a	design, simulation and techno-economic analysis of two processes for the conversion of shale gas to ethylene	techno economic analysis;shale gas;ethylene;methanol to olefins;oxidative coupling of methane;co 2 emissions	Shale gas is being considered as feedstock for the production of major petrochemicals. One such chemical is ethylene. Although the typical production for ethylene is carried out via thermal cracking, alternative processes have been gaining importance recently. Among such alternatives are the Oxidative Coupling of Methane (OCM) and the Methanol to Olefins (MTO) processes. The first one is a direct conversion process while the second one involves several stages. The aim of this work is to carry out an economic, energy and environmental assessment for these two processes. The results show that the MTO process is more profitable under the economic and technical scenario considered here. A sensitivity analysis was conducted to show the shale gas and ethylene prices under which the OCM process would be economically attractive. An analysis on catalyst improvement needed for the OCM process to be profitable is also reported.	password cracking;simulation;thermal grease	Andrea P. Ortiz-Espinoza;Mohamed M. B. Noureldin;Mahmoud M. El-Halwagi;Arturo Jiménez-Gutiérrez	2017	Computers & Chemical Engineering	10.1016/j.compchemeng.2017.05.023	petroleum engineering;oxidative coupling of methane;engineering;forensic engineering;waste management	SE	6.052903501190201	2.2443469815207897	109093
2331c84737fc5bc47d7afb45626ec66e5e6cddde	a state aggregation approach to manufacturing systems having machine states with weak and strong interactions	modelizacion;dynamic programming;continuous time;agregacion;fiabilidad;reliability;probability;decomposition;hierarchical planning manufacturing with unreliable machines;proceso markov;commande asymptotique;strong interaction;interaccion fuerte;production system;systeme production;hierarchical control;manufacturing with unreliable machines;dynamic systems;optimal control stochastic;aggregation;sistema produccion;weak interaction;interaccion debil;markov processes hierarchical control of markov process driven systems;optimal control;modelisation;hierarchical control of markov process;optimalite asymptotique;interaction forte;near optimization;interaction faible;processus markov;commande optimale;fiabilite;defaillance;markov process;agregation;reparation;markov processes;production scheduling;failures;reparacion;modeling;systems wirh weak and strong interactions;manufacturing system;fallo;repair;control optimal;hierarchical planning	A hierarchical approach to control a manufacturing system, subject to multiple machine states modeled by a Markov process with weak and strong interactions, is suggested. The idea is to aggregate strongly interacting or high transition probability states within a group of states and consider only the transition between these groups for the analysis of the system in the long run. We show that such an aggregation results in a problem of reduced size, whose solution can be modified in a simple way to obtain an asymptotically optimal feedback solution to the original problem. Also, an example is solved to illustrate the results developed in the paper.	interaction	J. Jiang;S. P. Sethi	1991	Operations Research	10.1287/opre.39.6.970	artificial intelligence;operations management;mathematics;markov process;statistics	AI	5.888440246319631	-1.3346993511898624	109152
71cd46ccb0908d09597b1cbe7408f925ada02dec	product differentiation and location decisions under demand uncertainty	spatial competition;optimal location;discrete choice;product differentiation;random utility model;profitability;transport costs;demand uncertainty	We investigate Hotelling’s duopoly game of location-then-price choices with quadratic transportation costs and uniformly distributed consumers under the assumption that firms are uncertain about the exact location of demand. We characterize the unique equilibrium and the socially optimal locations. Contrary to the individual-level random utility models, location uncertainty is a differentiation force. In equilibrium, increases in the variance of the uncertainty lead to greater differentiation, higher expected equilibrium prices and profits, and a greater welfare loss. r 2004 Elsevier Inc. All rights reserved. JEL classification: C72; D43; D81; L10; L13; R30; R39		Kieron J. Meagher;Klaus G. Zauner	2004	J. Economic Theory	10.1016/j.jet.2003.12.006	industrial organization;economics;product differentiation;discrete choice;microeconomics;welfare economics;profitability index	AI	-1.7306615800543743	-5.547675604524685	109391
a1850202ae188b2e11db04a27d18456f5a8a59b2	decoupled net present value - an alternative to the long-term asset value in the evaluation of ship investments?				Philipp Schrader;Jan-Hendrik Piel;Michael H. Breitner	2017		10.1007/978-3-319-89920-6_37		HCI	3.1263320675017394	-7.544563779902454	109477
47d5072de049b2cb98ed0c155faaea0ff7f9a460	customer-centric marketing with internet coupons	tabla precios;jeu mecanique;ciblage;dynamic programming;commerce electronique;multiagent system;programacion dinamica;electronic commerce;comercio electronico;cupon;customer centric information systems;customer relationship management;pricing;comercializacion;internet coupons;intelligence artificielle;fijacion precios;imperfect information;scenario;commercialisation;juego mecanico;blancado;targeting;tariffication;dynamic pricing;internet;argumento;marketing;tarification;script;prices schedule;programmation dynamique;gestion relation client;informacion imperfecta;coupon;artificial intelligence;bon reduction;mechanical clearance;inteligencia artificial;information system;bareme prix;sistema multiagente;customer centric marketing;price discrimination;fixation prix;systeme information;electronic trade;systeme multiagent;tarificacion;information imparfaite;sistema informacion	We develop an analytical framework to examine customer-centric marketing with Internet coupons. We show that mass distribution of Internet coupons without a customer-centric information system to identify customers' profile will have adverse consequences that defeat the price discrimination effect of couponing. We analyze alternative strategies including distributing Internet coupons to targeted customers with perfect and imperfect profile information of customers. The targeted coupons with perfect information case amounts to dynamic pricing, but without customers' backlash. In the targeted customers with imperfect information scenario, we consider Internet coupons with fixed face value as well as changing face value cases. We derive the condition under which the firm should opt for the changing face value Internet coupons. As the firm's customer-centric information system improves in terms of enhanced targeting accuracy at a lower cost, the changing face value Internet coupons will become more prevalent.		Hsing Kenneth Cheng;Kutsal Dogan	2008	Decision Support Systems	10.1016/j.dss.2007.09.001	e-commerce;pricing;targeting;customer relationship management;the internet;computer science;artificial intelligence;scenario;marketing;operations management;perfect information;dynamic programming;advertising;management;world wide web;price discrimination;information system	ECom	4.135175052211445	-3.625793226950799	109649
63c9cc3782cccd6e48e158e71ad24df72c125ec0	managing licensing in a market for technology	strategic organization design;grupo de excelencia;technology licensing;licensing;reward dependence;administracion de empresas;markets for technology;profitability;economia y empresa;organization design;grupo a;centralization	Technology licensing is an important means for comp anies to extract more value from their intellectual assets. We build a model that helps un derstand how licensing activity should be organized within large corporations. More specifica lly, we compare decentralization—where the business unit using the technology makes licensing decisions—to centralized licensing. The business unit has superior information about licens ing opportunities but may not have the appropriate incentives because its rewards depend u pon product market performance. If licensing is decentralized, the business unit forgoes valuable l icensing opportunities since the rewards for licensing are (optimally) weaker than those for pro duct market profits. This distortion is stronger when production-based incentives, especially privat e benefits of business unit managers, are more powerful, making centralization more attractive. Su rprisingly, we find that inter-dependency across business units may result in more, not less, decent ralization. Further, even though centralization results in less information, centralized licensing deals are larger. Our model conforms to the existing evidence that reports heterogeneity across firm in both licensing propensity and organization of licensing.	centralized computing;druid;money	Ashish Arora;Andrea Fosfuri;Thomas Rønde	2013	Management Science	10.1287/mnsc.1120.1628	barriers to entry;industrial organization;economics;marketing;operations management;centralized government;reward dependence;microeconomics;management;organizational architecture;profitability index	AI	-2.2850070886632685	-6.816451228535482	109704
c5812aca224709d67b22b6b526e17ba72c7e9d32	fast solution techniques for energy management in smart homes	dynamic programming;demand response;pv storage systems;smart grid;phd doctorate;approximate dynamic programming;energy management in smart homes	In the future, residential energy users will seize the full potential of demand response schemes by using an automated smart home energy management system (SHEMS) to schedule their distributed energy resources. The underlying optimisation problem facing a SHEMS is a sequential decision making problem under uncertainty because the states of the devices depend on the past state. There are two major challenges to optimisation in this domain; namely, handling uncertainty, and planning over suitably long decision horizons. In more detail, in order to generate high quality schedules, a SHEMS should consider the stochastic nature of the photovoltaic (PV) generation and energy consumption. In addition, the SHEMS should accommodate predictable inter-daily variations over several days. Ideally, the SHEMS should also be able to integrate into an existing smart meter or a similar device with low computational power. However, extending the decision horizon of existing solution techniques for sequential stochastic decision making problems is computationally difficult and moreover, these approaches are only computationally feasible with a limited number of storage devices and a daily decision horizon. Given this, the research investigates, proposes and develops fast solution techniques for implementing efficient SHEMSs. Specifically, three novel methods for overcoming these challenges: a two-stage lookahead stochastic optimisation framework; an approximate dynamic programming (ADP) approach with temporal difference learning; and a policy function approximation (PFA) algorithm using extreme learning machines (ELM) are presented. Throughout the thesis, the performance of these solution techniques are benchmarked against dynamic programming (DP) and stochastic mixed-integer linear programming (MILP) using a range of residential PV-storage (thermal and battery) systems. We use empirical data collected during the Smart Grid Smart City project in New South Wales, Australia, to estimate the parameters of a Markov chain model of PV output and electrical demand using an hierarchical approach, which first cluster empirical data and then learns probability density functions using kernel regression (Chapter 2). The two-stage lookahead method uses deterministic MILP to solve a longer decision horizon, while its end-of-day battery state of charge is used as a constraint for a daily DP approach (Chapter 4). Here DP is used for the daily horizon as it is shown to provide	approximation algorithm;bellman equation;benchmark (computing);computation;display resolution;dynamic programming;home automation;integer programming;linear programming;markov chain;mathematical optimization;parsing;predictive failure analysis;smart city;smart meter;state of charge;stochastic optimization;temporal difference learning;usb on-the-go	Chanaka Keerthisinghe	2016			embedded system;real-time computing;simulation;engineering;smart grid;internet of things	AI	4.869331774934452	2.983649333506348	109784
ead9b8ef786a6f2dc5ee536d7c5d8b199e0bd8d8	coordinating a supply chain with green innovation in a dynamic setting		This paper addresses the channel coordination problem in a green supply chain consisting of a manufacturer and a retailer, in which the manufacturer controls green innovation and wholes price, while the retailer controls sales price. Pricing and green innovation strategies in integrated and decentralized channels are computed and compared, and a two-part tariff contract is designed to coordinate the decentralized supply chain. A Nash bargaining model is further developed to distribute the extra-profit between channel members. A numerical example is conducted to explore the impacts of green effectiveness and operational inefficiency effect on optimal/equilibrium solutions and coordination. The main results show that the green innovation investment, energy efficiency level and channel profit of integrated channel are larger than those of decentralized one, but the relationship of sales prices under two channel structures depends on system parameters. Green effectiveness exerts a positive effect on optimal/equilibrium solutions. The coordinator’s coordination capability is improved by green effectiveness, but weakened by operational inefficiency effect.	nash equilibrium;numerical analysis	Qiao Zhang;Jianxiong Zhang;Wansheng Tang	2017	4OR	10.1007/s10288-016-0327-x	mathematical optimization;differential game;mathematics;efficient energy use;inefficiency;supply chain;channel coordination;microeconomics;bargaining problem;tariff;two-part tariff	HCI	-1.287109124831935	-5.733574161211621	109944
24d39e88dd96bd3bbde6dd345ee4149454404383	a fuzzy multi-item production model with reliability and flexibility under limited storage capacity with deterioration via geometric programming	reliability;epq;fuzzy modelling;inventory costs;triangular fuzzy numbers;deteriorating items;triangular fuzzy number;storage space;economic production quantity;modified geometric programming;mgp;flexibility;multi item production models	A multi-item EPQ model for deteriorating items is built-up with limited storage space and with flexibility and reliability of production process. Here, production rate for the items is depends on the demand and items deteriorate at constant rates. Due to high rent in market place, storage space is considered limited and imprecise in nature. Inventory related costs, storage space and other parameters are imprecise and taken as it triangular fuzzy number. We solve this inventory decision problem using Modified Geometric Programming (MGP) method. Following the theoretical treatment, we provide a numerical example to demonstrate that MGP has potential as a valuable analytical tool for researchers. At the end some sensitivity analysis with different parameters are made.	carrying cost;complexity;computation;decision problem;economic production quantity;electronic component;fuzzy number;geometric programming;inventory theory;modeller;mouse genetics project;numerical analysis;posynomial;reliability engineering	Dharmendra Yadav;Shivraj Pundir;Rachna Kumari	2011	IJMOR	10.1504/IJMOR.2011.037314	mathematical optimization;operations management;reliability;eysenck personality questionnaire;mathematics;welfare economics;statistics	ML	4.903955432841411	-5.6085773796611145	109955
c352fa56dec1fc8c3be2adc93d70ebe7bd3f5f2f	duopoly pricing strategy for information products with premium service: free product or bundling?		AbstractMany software firms, especially mobile app providers, offer perpetually free basic products to users, but premiums are charged for access to the additional features or functionalities. While the free offering helps capture potential customers, it might cannibalize the sales of premium goods or services. This paper adopts a game theoretical approach to examine the impact of free offering on the competition between two firms in the presence of network effects. The firms can either offer a free core product and a paid service or offer them as a bundle. The core product has stand-alone value and can be used separately but the value-added service has no value without the core product. We derive the market equilibria and present conditions under which the free offering strategy outperforms the bundling strategy. We show that when a firm’s core product has a sufficient advantage in product quality, it is better for this firm to sell the bundle but for the other to use free strategy. However, if the core ...		Zan Zhang;Guofang Nan;Minqiang Li;Yong Tan	2016	J. of Management Information Systems		pricing;economics;service product management;computer science;marketing;network effect;freemium;core product;commerce	DB	-1.5434725570963284	-6.842763899302558	109975
b31b7b5a6fc896b72981896b38805c8fb8205328	online low-price guarantees - a real options analysis	libre mercado;confort;comfort;finance asset pricing;finance;automovil;adquisicion por suscripcion;compra;perishable items;availability;real options analysis;bepress selected works;disponibilidad;producto perecedero;pricing;opcion financiera;inventory production;location;fijacion precios;inventory production perishable items;marche concurrentiel;administracion deposito;detaillant;purchasing;service industries;internet;automobile;industrie service;option reelle;perishable item;motor car;motivacion;transportation;rupture;real option;defaillance;gestion stock;motivation;achat;transportation automobile;option financiere;failures;open market;rental;hotel;retailers;comodidad;arrendamiento;inventory control;produit perissable;disponibilite;financial option;fallo;ruptura;asset pricing;fixation prix;purchases;opcion real;finanzas;finance asset pricing inventory production perishable items transportation automobile;acquisition titre onereux	A common practice among large retailers is the low-price guarantee, rebating consumers if they find an identical product cheaper elsewhere. This provides consumers with some level of comfort in their purchase decision. A similar low-price guarantee is provided by numerous service industries that allow reservation of capacity, yet do not penalize the consumer for failure to keep that reservation-examples include hotels and car rental. Given that a consumer is not required to keep the reservation, they may make another reservation, either at a competing firm or the same firm, if future prices decline. The increasing availability of pricing information on the Internet affords consumers the opportunity to be more strategic in their purchasing behavior. As consumers, we are able to quickly and easily check prices from numerous service or goods providers. The ease of price information potentially makes these guarantees very costly to the service or good provider. We analyze the implied costs associated with these guarantees by making analogies to financial options. Motivation for this research comes from a large car rental firm, Dollar Thrifty Automotive Group Inc., that considered offering a low-price guarantee to all consumers that book a reservation though their website.	internet;purchasing	Benjamin Marcus;Chris K. Anderson	2006	Operations Research	10.1287/opre.1060.0333	inventory control;pricing;availability;transport;capital asset pricing model;the internet;motivation;open market operation;economics;marketing;location;management;commerce	Networks	4.623708394420028	-4.306023738205136	110124
6126636bb2537f617751949d9228444d8626b0ea	capacity allocation among suppliers in the presence of spot market		We consider a supply chain with two suppliers and one buyer. The buyer faces uncertain demand decides to reserve some capacity through the two suppliers. The buyer also sources the remaining capacity from the spot market if demand exceeds the reserved capacity. The suppliers have finite capacity and both have access to a third-party client market. We analytically analyze this problem and characterize its solution.		Tarun Jain;Jishnu Hazra	2018	2018 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM)	10.1109/IEEM.2018.8607555		Robotics	-0.457266316843802	-5.018252665821589	110147
d9934161604e29884c3bb63e7a177a592d708d8a	optimal production and procurement decisions in a supply chain with an option contract and partial backordering under uncertainties	uncertainty;optimal ordering policy;supply chain;partial backorders;option contract	This paper considers a decentralized supply chain including one retailer and one manufacturer , where the manufacturer's production yield and the retailer's demand are both sto-chastic. At the beginning of the selling season, the retailer places an order and purchases an option contract with the manufacturer. After the selling season, the excess demand is partially backordered, and the retailer exercises his option order and then place an instant order for the backorders. The optimal ordering policy for the retailer and the corresponding production decision for the manufacturer are studied. Numerical examples are carried out to show the impact of the model parameters on the optimal policies. With the rapid development of science and technology, the lifecycles of products become shorter and shorter, and then more and more products have the attributes of fashion or seasonal goods. Therefore, in the past five decades, both researchers and practitioners have paid much attention to the important issues such as procurement, lot-sizing and inventory in operations management for newsvendor-type products. The earlier studies mainly focused on how to find the buyer's optimal ordering policies such that the buyer's expected profit (cost) is maximized (minimized) (see e. With the globalization of market and competition, supply chain management has become popular and many researchers have focused on coordination issues of the supply chain for newsvendor-type products (Pasternack [6], Emmons and Gilbert [7], Chen et al. [8], Seliaman and Ahmad [9], Zhou and Wang [10]). Our study is related to determining production and procurement with an option contract under uncertainties, so we confine ourselves in reviewing the related works as follows. Since option contracts are an efficient instrument to help hedge against the uncertainties and to reduce double marginalization in supply chains, they have attracted substantial attention in the area of supply chain management. Eppen and Iyer [11] considered a backup agreement between a catalog company and manufacturers, which is essentially an option contract. They showed that backup agreements have substantial effects on expected profit and committed quantity. An option model to quantify and price a flexible supply contract was studied by Cheng et al. [12], where the supplier decides the price of options as well as the exercise price according to the manufacturer's	backup;dfa minimization;entity–relationship model;gilbert cell;newsvendor model;numerical method;offset binary;procurement;purchasing;scrum (software development);smart contract	Fei Hu;Cheng-Chew Lim;Zudi Lu	2014	Applied Mathematics and Computation	10.1016/j.amc.2014.01.149	uncertainty;mathematics;supply chain;statistics	ECom	1.6073706191497084	-5.685068901813665	110207
dc5a6088a0738ead70550d200756b51ca72da143	selling luxury fashion to conspicuous consumers in the presence of discount sensitivity behavior				Jianheng Zhou;Xiaolei Xu;Bin Shen	2018	ITOR	10.1111/itor.12543	operations management;conspicuous consumption;mathematics;commerce	HCI	-2.191106577989992	-7.243795606731893	110258
827f43211f42d4318590f7d61916fd193cbe6b95	decision support for optimal adaptation of product and supply chain systems based on real options theory	silicon;multiechelon product system;manufacturing systems;decision models;decision support;decision tree;optimal product adaptation;manufacturing enterprise;supply chain management decision trees manufacturing industries manufacturing systems profitability;multiproduct system;manufacturing industries;joints;supply chains;supply chain system;assembly;product quality decision support supply chain system real options theory competitive global market manufacturing enterprise optimal product adaptation decision tree based framework design supplier alternatives multiproduct system multiechelon product system;real options theory;supply chains product design uncertainty decision making costs robustness globalization virtual enterprises automation computer applications;decision tree based framework;supply chain;profitability;product design;product quality;switches;decision trees;design supplier alternatives;article;competitive global market;supply chain management	In order to remain profitable in the highly competitive global market, a manufacturing enterprise is expected to proactively adapt itself in anticipation of unplanned, but foreseeable high impact events. This paper presents a decision model for optimal adaptation of product and supply chain systems subject to sudden, severe changes in the operating environment. Extending our previous work [1], decision-tree based framework is developed for optimally choosing design-supplier alternatives in multi-product, multi-echelon product and supply chain systems based on the real options theory. A case study on a two-component, two-echelon supply chain is presented which highlights unique characteristics of product quality as compared to cost and time.	decision tree;event tree;operating environment;row echelon form;specular highlight	Chong Hyun Park;Lalit Patil;Kazuhiro Saitou;H. Edwin Romeijn	2009	2009 IEEE International Conference on Automation Science and Engineering	10.1109/COASE.2009.5234119	supply chain risk management;service management;systems engineering;operations management;business;commerce	Robotics	2.7960690857688495	-6.368586500404555	110363
a034226a5f314b3c52dd632abdb099a08485466c	data-driven distributionally robust energy-reserve-storage dispatch		This paper proposes distributionally robust energy-reserve-storage co-dispatch model and method to facilitate the integration of variable and uncertain renewable energy. The uncertainties of renewable generation forecasting errors are characterized through an ambiguity set, which is a set of probability distributions consistent with observed historical data. The proposed model minimizes the expected operation costs corresponding to the worst case distribution in the ambiguity set. Distributionally robust chance constraints are employed to guarantee reserve and transmission adequacy. The more historical data are available, the smaller the ambiguity set is and the less conservative the solution is. The formulation is finally cast into a mixed integer linear programming whose scale remains unchanged as the number of historical data increases. Inactive constraint identification and convex relaxation techniques are introduced to reduce the computational burden. Numerical results and Monte Carlo simulations on IEEE 118-bus systems demonstrate the effectiveness and efficiency of the proposed method.	best, worst and average case;dynamic dispatch;integer programming;linear programming relaxation;monte carlo method;numerical linear algebra;simulation	Chao Duan;Lin Jiang;Wanliang Fang;Jun Liu;Shiming Liu	2018	IEEE Transactions on Industrial Informatics	10.1109/TII.2017.2771355	electricity generation;renewable energy;probability distribution;real-time computing;robustness (computer science);mathematical optimization;computer science;monte carlo method;ambiguity;integer programming;energy storage	Vision	6.203841648248646	2.9621680875051184	110437
171ce96cc09bfd748efe15ab340954f93c8a5b53	two-period cycles in a three-period overlapping generations model	overlapping generations model	We study the properties of two-period monetary cycles in simple pure exchange overlapping generations economies in which the households live for three periods. We demonstrate that these economies can support cycles under a much broader -- and, arguably, more plausible -- range of assumptions than the analogous two-period economies. We show that economies that fail the well-known Grandmont [1985] condition can have cycles, and that economies that satisfy the condition can fail to have cycles. In addition, we show that economies can have monetary cycles when they do not have conventional monetary steady states, and when aggregate demand for assets is not decreasing in the real return rate at a gross real rate of unity.		Joydeep Bhattacharya;Steven Russell	2003	J. Economic Theory	10.1016/S0022-0531(03)00011-5	economics;macroeconomics;overlapping generations model	ECom	-3.8737722392516023	-6.0779321073475465	110461
734caa4cd83be95af6778c4332ea115cea549252	are r&d subsidies provided optimally? evidence from a simulated agency-firm stochastic dynamic game	rivalry versus cooperation;pareto efficiency;crowding out;r d subsidies;rivalry vs cooperation;stochastic dynamics;dynamic stochastic games;stochastic games	"""By means of a simulated funding-agency/supported-firm stochastic dynamic game, this paper shows that the level of the subsidy provided by a funding (public) agency, normally used to correct for firm R&D shortage, might be severely underprovided. This is due to the """"externalities"""" generated by the agency-firm strategic relationship, as showed by comparing two versions of the model: one assuming """"rival"""" behaviors between companies and agency (i.e., the current setting), and one associated to the """"cooperative"""" strategy (i.e. the optimal Pareto-efficient benchmark). The paper looks also at what """"welfare"""" implications are associated to different degrees of persistency in the funding effect on corporate R&D. Three main conclusions are thus drawn: (i) the relative quota of the subsidy to R&D is undersized in the rival compared to the cooperative model; (ii) the rivalry strategy generates distortions that favor the agency compared to firms; (iii) when passing from less persistent to more persistent R&D additionality/crowding-out effect, the lower the distortion the greater the variance is and vice versa. As for the management of R&D funding policies, we suggest that all the elements favouring greater collaboration between agency and firm objectives may help current R&D support to approach its social optimum."""	benchmark (computing);crowding;distortion;pareto efficiency	Giovanni Cerulli	2012	J. Artificial Societies and Social Simulation		industrial organization;crowding out;simulation;economics;microeconomics;welfare economics	ECom	-2.6057822054739717	-6.368002458349711	111140
247d9e608db739e4e68041f70b8afd47a867f063	solving mdps with skew symmetric bilinear utility functions		In this paper we adopt Skew Symmetric Bilinear (SSB) utility functions to compare policies in Markov Decision Processes (MDPs). By considering pairs of alternatives, SSB utility theory generalizes von Neumann and Morgenstern’s expected utility (EU) theory to encompass rational decision behaviors that EU cannot accommodate. We provide a game-theoretic analysis of the problem of identifying an SSB-optimal policy in finite horizon MDPs and propose an algorithm based on a double oracle approach for computing an optimal (possibly randomized) policy. Finally, we present and discuss experimental results where SSB-optimal policies are computed for a popular TV contest according to several instantiations of SSB utility functions.	bilinear transform;computer data storage;decision problem;expected utility hypothesis;game theory;gurobi;iteration;iterative method;linear programming;list of intel core i5 microprocessors;markov chain;markov decision process;mathematical optimization;nash equilibrium;python;randomized algorithm;rationality;reinforcement learning;super smash bros.	Hugo Gilbert;Olivier Spanjaard;Paolo Viappiani;Paul Weng	2015			mathematical optimization;discrete mathematics;artificial intelligence;machine learning;mathematics;mathematical economics;statistics	AI	-2.0574771201935835	-0.7591690695477435	111422
2fd822ba8dc50739c2d09c7b1cde129e5e875cbe	reliability analysis for new technology-based transmitters	arbre graphe;modelizacion;new technology;fiabilidad;reliability;tree graph;behavioral analysis;incertidumbre;uncertainty;sistema complejo;behaviour uncertainty;failure mode;emetteur;probabilistic approach;smart sensor;intelligent transmitter;modelisation;systeme incertain;feedback;retroaccion;systeme complexe;retroaction;complex system;transmitter;enfoque probabilista;approche probabiliste;fiabilite;analyse comportementale;feedback regulation;reliability analysis;analisis conductual;relationship analysis;incertitude;emisor;sensor inteligente;boucle reaction;infrared;arbol grafo;sistema incierto;retroalimentacion;modeling;uncertain system;intelligent sensors;capteur intelligent	The reliability analysis of new technology-based transmitters has to deal with specific issues: various interactions between both material elements and functions, undefined behaviours under faulty conditions, several transmitted data, and little reliability feedback. To handle these particularities, a “3-step” model is proposed, based on goal tree–success tree (GTST) approaches to represent both the functional and material aspects, and includes the faults and failures as a third part for supporting reliability analyses. The behavioural aspects are provided by relationship matrices, also denoted master logic diagrams (MLD), with stochastic values which represent direct relationships between system elements. Relationship analyses are then proposed to assess the effect of any fault or failure on any material element or function. Taking these relationships into account, the probabilities of malfunction and failure modes are evaluated according to time. Furthermore, uncertainty analyses tend to show that even if the input data and system behaviour are not well known, these previous results can be obtained in a relatively precise way. An illustration is provided by a case study on an infrared gas transmitter. These properties make the proposed model and corresponding reliability analyses especially suitable for intelligent transmitters (or “smart sensors”).	reliability engineering;transmitter	Florent Brissaud;Anne Barros;Christophe Bérenguer;Dominique Charpentier	2011	Rel. Eng. & Sys. Safety	10.1016/j.ress.2010.09.010	transmitter;complex systems;systems modeling;uncertainty;infrared;telecommunications;engineering;artificial intelligence;reliability;feedback;mathematics;operations research;failure mode and effects analysis;tree;statistics;intelligent sensor	SE	7.116042926035577	-8.886077596859149	111482
c3a998a775a1b5a98fa59cd4995deaa31bce9b35	reliability of a k-out-of-n system equipped with a single warm standby component	consecutive system reliability;reliability theory redundancy random variables computational modeling educational institutions computer aided software engineering;reliability theory;standby redundancy mean residual life order statistics;mean residual life functions k out of n system reliability single warm standby component k out of n g system reliability analysis single warm standby unit arbitrary lifetime distributions;reliability theory consecutive system reliability	A k-out-of-n:G system consists of n components, and operates if at least k of its components operate. Its reliability properties have been widely studied in the literature from different perspectives. This paper is concerned with the reliability analysis of a k-out-of-n:G system equipped with a single warm standby unit. We obtain an explicit expression for the reliability function of the system for arbitrary lifetime distributions. Two different mean residual life functions are also studied for the system.	reliability (computer networking)	Serkan Eryilmaz	2013	IEEE Transactions on Reliability	10.1109/TR.2013.2259202	reliability engineering;reliability theory;engineering;engineering drawing	Metrics	6.756590191030155	-0.16405057370658183	111545
640435c9ede5fa0056b184c9f7a0aaf93f34d813	dual sales channel management with service competition	experimental economics;service level;product availability;dual channels;controlled experiment;supply chain contracting;lead time;direct channel;human behavior;human subjects;service competition;choice models;supply chain;hd0028 management industrial management	W study a manufacturer’s problem of managing his direct online sales channel together with an independently owned bricks-and-mortar retail channel, when the channels compete in service. We incorporate a detailed consumer channel choice model in which the demand faced in each channel depends on the service levels of both channels as well as the consumers’ valuation of the product and shopping experience. The direct channel’s service is measured by the delivery lead time for the product; the retail channel’s service is measured by product availability. We identify optimal dual channel strategies that depend on the channel environment described by factors such as the cost of managing a direct channel, retailer inconvenience, and some product characteristics. We also determine when the manufacturer should establish a direct channel or a retail channel if he is already selling through one of these channels. Finally, we conduct a sequence of controlled experiments with human subjects to investigate whether our model makes reasonable predictions of human behavior. We determine that the model accurately predicts the direction of changes in the subjects’ decisions, as well as their channel strategies in response to the changes in the channel environment. These observations suggest that the model can be used in designing channel strategies for an actual dual channel environment.1	choice modelling;experiment;mortar methods;multi-channel memory architecture;value (ethics)	Kay-Yut Chen;Murat Kaya;Özalp Özer	2008	Manufacturing & Service Operations Management	10.1287/msom.1070.0177	service level;economics;marketing;operations management;supply chain;advertising;experimental economics;human behavior	Mobile	-0.8085186989951628	-6.558208631256858	111716
3b6009ffec2b5d1a8bb6869bdc1ba86d889cb9bb	is shapley cost sharing optimal?	shapley value;cost sharing;lower bound	We study the best guarantees of efficiency approximation achievable by cost-sharing mechanisms. Our main result is the first quantitative lower bound that applies to all truthful cost-sharing mechanisms, including randomized mechanisms that are only truthful in expectation, and only β-budget-balanced in expectation. Our lower bound is optimal up to constant factors and applies even to the simple and central special case of the public excludable good problem. We also give a stronger lower bound for a subclass of deterministic cost-sharing mechanisms, which is driven by a new characterization of the Shapley value mechanism. Finally, we show a separation between the best-possible efficiency guarantees achievable by deterministic and randomized cost-sharing mechanisms.	approximation algorithm;randomized algorithm;stable marriage problem	Shahar Dobzinski;Aranyak Mehta;Tim Roughgarden;Mukund Sundararajan	2008		10.1007/978-3-540-79309-0_29	mathematical optimization;economics;shapley value;mathematical economics;upper and lower bounds;welfare economics	Theory	-3.0414384299013504	-0.3992785503545455	111985
9b5b147b040b8db2d530a980cded732e2ea27800	multiple equilibrium overnight rates in a dynamic interbank market game	interest rate;shapley value;interbank market;market game;solution concept	We analyse a two period model of the interbank market, i.e. the market at which banks trade liquidity. We assume that banks do not take the interbank interest rate as given, but multilaterally negotiate on interest rates and transaction volumes. The solution concept applied is the Shapley value. We show that there is a multiplicity of average equilibrium interest rates of the Þrst period so that the average interest rate in this period does not convey any information on the expected liquidity situation at the interbank market.		Jens Tapking	2006	Games and Economic Behavior	10.1016/j.geb.2005.08.006	financial economics;interbank lending market;economics;interest rate;microeconomics;shapley value;mathematical economics;solution concept;economic policy	ECom	-1.4274753150049764	-5.192574039659497	112240
8b112eda26b47a837567c0f683c1a8bda414c6ad	operational efficiency of decentralized internet auction mechanisms	continuous double auction;laboratory experiments;internet auction mechanisms;electronic markets;operational efficiency;human subjects;internet auction;laboratory experiment;profitability;double auction	The recent consumer-to-consumer (C2C) Internet auction boom at eBay, Yahoo, Amazon, and other sites has added new theoretical challenges to the science of auctions. This paper uses experiments with economically-motivated human subjects to measure the operational efficiency of decentralized Internet auction mechanisms as they compare to centralized double auction mechanisms. Subjects are recruited randomly from the undergraduate population of a large urban university to be buyers or sellers in a simulated trading environment. They are randomly assigned costs and values for 10 units of a virtual product. During the experiment subjects trade these units through computer terminals in auctions similar to those held on eBay and generate profits, which subjects receive at the end of the experiment. The paper uses data from this experiment and previous laboratory experiments to compare operational efficiency and convergence pattern of prices to equilibrium levels in continuous double auctions versus online Internet auctions based on two variables: auction size and time. Experimental results suggest that, because of their decentralized nature, Internet auctions require a few more participants and more time to achieve operational efficiency levels than centralized markets which use continuous double auction	algorithmic efficiency;centralized computing;computer terminal;customer to customer;experiment;randomness	Roumen Vragov	2010	Electronic Commerce Research and Applications	10.1016/j.elerap.2009.04.008	spectrum auction;auction sniping;eauction;combinatorial auction;generalized second-price auction;unique bid auction;marketing;reverse auction;vickrey–clarke–groves auction;proxy bid;revenue equivalence;multiunit auction;double auction;microeconomics;auction theory;commerce;profitability index;forward auction	AI	-2.624179211949636	-5.647643578165047	112304
ee3d142afa9a8e167f497c5501839d8ec74e6f00	an epsilon bargaining game-theoretic formulation between carrier and container terminal operators for servicing vessels during unloading operations	bargaining problem;container terminals;game theory;unloading operations in transshipment;terminal operations;loading and unloading;epsilon equilibrium;container terminal;carriers;vessel service	Due to globalization trends and the increasing competition between ports, the maritime policy for container shipments has witnessed a change in operations that resulted in less reliance on direct freight flows and higher transshipment operations. Motivated to investigate a soft intelligent decision-making approach using game theory in the context of servicing vessels during unloading operations in transshipment, we propose an epsilon bargaining approach between the carrier and the container terminal operator (CTO). The objective of the game is to maximize the carrier service level while minimizing operation costs for the CTO. The players' utilities, which depend on the service level and the fees for the carrier, as well as the revenues generated and the cost incurred for the CTO, are uniquely formulated and evaluated in a bargaining scenario using an ordinal ranking approach. The negotiation process is further improved between the two players based on our proposed Epsilon Bargaining Equilibrium, which to ...		Nabil Nehme;Mariette Awad;Isam A. Kaysi	2016	J. Intellig. Transport. Systems	10.1080/15472450.2015.1065740	bargaining problem;game theory;epsilon-equilibrium;engineering;transport engineering;operations research	Robotics	-0.9908539249880747	-4.539986183208865	112338
f3df06f27bafd78220a01c853aa89e61404725e8	to lend is to own: a game theoretic analysis of the e-book lending market		Digital forms of content have provided online retailers new ways of enhancing other business opportunities. E-book vendors such as Amazon introduced a fourteen-day lending program for its Kindle-linked e-books, banking on the e-book lending program to increase sales to consumers who appreciate the added utility from the new lending options. The benefits of such an e-book lending strategy can become significant as the number of e-book owners reaches a critical mass, creating a network effect. However, the strategy may involve risk because there is also the possibility of cannibalization of retailers’ print book. We investigate, in both monopolistic and duopolistic competition settings, whether and how an online retailer can benefit from introducing an e-book lending program and its effect on their pricing strategy and cannibalization. We also examine whether sequential release of print books and e-books in monopolistic settings will affect retailer’s revenue. Our study finds that in a monopoly setting, the retailer should implement the e-book lending strategy when the condition of network effect is satisfied. Our findings also suggest that retailers can use release time to minimize cannibalization in the case of sequential release. In addition, the e-book lending option benefits the retailer in a duopoly setting only when one retailer offers such a program; otherwise, the better-known retailer benefits more. Theoretical and practical implications for the management of different formats of content in various competition markets to sustain and expand business opportunities are discussed.	amazon kindle;book;e-book lending;game theory;monopoly;nist hash function competition;online shopping	Li Chen;Ruth C. King	2017	Int. J. Electronic Commerce	10.1080/10864415.2016.1319214	industrial organization;economics;cannibalization;monopolistic competition;network effect;monopoly;revenue;digital content	ECom	-3.060106817348508	-7.8035616037689355	112620
fee4efeda5076557d6858de83fa17b676dc90904	a stochastic target approach for p&l matching problems	article accepte pour publication ou publie;discontinuous viscosity solutions;quantile hedging;stochastic target problem	Within a Brownian diffusion Markovian framework, we provide a direct PDE characterization of the minimal initial endowment required so that the terminal wealth of a financial agent (possibly diminished by the payoff of a random claim) can match a set of constraints in probability. Such constraints should be interpreted as a rough description of a targeted profit and loss (P&L) distribution. This allows to give a price to options under a P&L constraint, or to provide a description of the discrete P&L profiles that can be achieved given an initial capital. This approach provides an alternative to the standard utility indifference (or marginal) pricing rules which is better adapted to market practices. From the mathematical point of view, this is an extension of the stochastic target problem under controlled loss, studied in Bouchard, Elie and Touzi (2009), to the case of multiple constraints. Although the associated Hamilton-Jacobi-Bellman operator is fully discontinuous, and the terminal condition is irregular, we are able to construct a numerical scheme that converges at any continuity points of the pricing function.	hamilton–jacobi–bellman equation;jacobi method;marginal model;numerical analysis;scott continuity	Bruno Bouchard;Thanh Nam Vu	2012	Math. Oper. Res.	10.1287/moor.1120.0549	mathematical optimization;mathematics;mathematical economics;statistics	AI	1.5227407855381259	-2.352269995332801	112626
6e47498ec76fa53738935385d4925b394ab50c7c	tractable negotiation in tree-structured domains	multiagent resource allocation;utility function;protocol design;universiteitsbibliotheek;communication conference;tree structure;negotiation;structural properties	Multiagent resource allocation is a timely and exciting area of research at the interface of Computer Science and Economics. One of the main challenges in this area is the high complexity of negotiation. In particular, the complexity of the task of identifying rational deals, i.e. deals that are beneficial for all participants, often hinders the successful transfer of theoretical results to practical applications. To address this issue, we propose several protocols designed to tame the complexity of negotiation by exploiting structural properties of the utility functions used by agents to model their preferences over alternative bundles of resources. In particular, we consider domains where utility functions are k-additive (that is, synergies between different resources are restricted to bundles of at most k items) and tree-structured in the sense that the bundles for which there are synergies do not overlap. We show how protocols exploiting these properties can allow for drastically simplified negotiation processes.	computer science;synergy;tame;tree (data structure);utility functions on indivisible goods	Yann Chevaleyre;Ulrich Endriss;Nicolas Maudet	2006		10.1145/1160633.1160698	computer science;knowledge management;artificial intelligence;management science;tree structure;negotiation	AI	-3.216928187622369	0.04183662364185928	112643
83dd4daa35db8e93090a7d265a72110a2ea32cbc	optimisation of material and energy exchange in an eco-park network considering three fuel sources	fuel sources;optimisation;multi objective optimisation;fuel comparison;gams;industrial;operations research;material and energy exchange;operations management;life cycle analysis;eco park	This work represents a quantitative assessment of the eco-park theory and its application to a case involving the export of several chemical products in addition to heat and electricity. The network is assessed in terms of environmental impact and profitability relative to existing facilities. GAMS software was employed to create the optimization problem akin to a typical transportation problem with added complexities associated with chemical processing at each node. Additionally, utilization of three different fuels as the primary source of chemical reagents and energy are considered. These fuels are coal and biomass for gasification or a steam-methane reforming process using natural gas as the fuel. The eco-park is shown to be more profitable than the comparable non-integrated set of facilities and the outputs are produced with a diminished environmental impact in terms of criteria air contaminants.	gams;mathematical optimization;optimization problem;primary source;transportation theory (mathematics)	Ivan Kantor;Ali Elkamel;Michael W. Fowler	2014	IJAOM	10.1504/IJAOM.2014.066828	economics;computer science;engineering;operations management;waste management;operations research	Metrics	9.385663953929052	-4.70244922182835	112653
6c0285eea3ca3637ed9d65ef12285e9692287705	an integrated vendor-buyer inventory model with perfect and monopolistic competitions: an educational note	perfect competition;partial backordering;inventory model;integrated vendor buyer system;monopolistic competition	Abstract#R##N##R##N#Customers encountering shortages will respond differently according to the type of commodity and the market environment. Complete backordering is only likely to occur in a monopolistic competition, whereas a complete lost sale is only likely to occur in a perfect competition. In reality, neither market environment exists. Therefore, in an environment with perfect and monopolistic markets, the consideration of partial backordering is a practical approach. In this study, we develop an integrated vendor–buyer inventory model with perfect and monopolistic competitions. Significant cost reduction can be achieved when partial backordering is considered. The inventory model can therefore be used to study the effect of partial backordering in a competitive market.	inventory theory;monopoly	P. C. Yang;Hui-Ming Wee;K. P. Wee	2006	ITOR	10.1111/j.1475-3995.2006.00534.x	economics;operations management;monopolistic competition;microeconomics;perfect competition;commerce	HCI	0.8257614327840234	-6.287555085932723	112691
0dd6058f2059cd238fff89ccbba5711868c8e531	a model for estimating cash flows in firms backed by venture capital		Venture Capital only backs firms for a short period of time. When the time to exit arrives, the firm must inevitably be valued in order to obtain a basis for negotiating the exit price. Discounted cash flow is precisely one of the valuation methods that are used most by Small and Medium-sized Enterprises (SMEs).		Ivan Arribas;Elisabeth Bustos;Gregorio Labatut	2013		10.1007/978-3-642-38279-6_6	social venture capital;cash management;venture capital;operating cash flow;finance;financial system;business;cash flow statement	Theory	1.553543435650206	-6.070713777342098	113058
0b45a14583e1256a278251710abfa6dee65b4916	actively purchasing data for learning		We design mechanisms for online procurement of data held by strategic agents for machine learning tasks. The challenge is to use past data to actively price future data and give learning guarantees even when an agent’s cost for revealing her data may depend arbitrarily on the data itself. We achieve this goal by showing how to convert a large class of no-regret algorithms into online posted-price and learning mechanisms. Our results in a sense parallel classic sample complexity guarantees, but with the key resource being money rather than quantity of data: With a budget constraint B, we give robust risk (predictive error) bounds on the order of 1/ √ B. Because we use an active approach, we can often guarantee to do significantly better by leveraging correlations between costs and data. Our algorithms and analysis go through a model of no-regret learning with T arriving pairs (cost, data) and a budget constraint of B. Our regret bounds for this model are on the order of T/ √ B and we give lower bounds on the same order.	algorithm;e-procurement;machine learning;procurement;purchasing;regret (decision theory);sample complexity	Jacob D. Abernethy;Yiling Chen;Chien-Ju Ho;Bo Waggoner	2015	CoRR		marketing;advertising;commerce	ECom	-2.0822011695557343	-2.1968543164989867	113069
f9d64a392e969cc23c9a24de6322f503061d030d	using real options theory to a country's environmental policy: considering the economic size and growth	policy implementation;time preference;environmental policy;numerical calculation;real options;emission trading market;real options theory;real option;gdp	The aim of this paper is to consider how the economic size and growth of a country affect its environmental policy under uncertainty in a real options framework. In contrast to the prior literature, this work explicitly takes into account the link between the development of an economy and the pollution state of the environment. Policy implementation is found to be determined by the levels of the economic size and the disutility of the pollution. We illustrate how to apply our method to the implementation of an environmental policy in an actual situation and show with numerical calculations that the optimal threshold is sensitive only to the subjective time preference, while the expected implementation time is affected by other parameters.		Katsumasa Nishide;Atsuyuki Ohyama	2009	Operational Research	10.1007/s12351-009-0056-4	financial economics;gross domestic product;economics;time preference;finance;economic growth;commerce	AI	0.5301131739500886	-9.481013720177058	113086
e5995d4add70f284c025a4d0d2cde00e6421c09d	optimal stopping by means of point process observations with applications in reliability	processus ponctuel;optimal solution;solution optimale;fiabilidad;reliability;stopping rule;informacion incompleta;point process;partial information;cas monotone;semimartingale;regla parada;incomplete information;semimartingale representation;solucion optima;fiabilite;information incomplete;defaillance;proceso puntual;optimal stopping;failures;monotone case;fallo;regle arret	A problem in reliability is considered in which only partial information is available. Some technical system is assumed to work in one of N unobservable states. The changes of the states are driven by a Markov process with known characteristics. The system fails from time to time according to a point process with a failure rate (intensity) which depends on the unobservable state. After failure a minimal repair is carried out immediately which leaves the state of the system unchanged. It is investigated under which conditions there exists an optimal time to stop operating the system with respect to some reward functional. The only available information is given by the failure point process observations. An explicit solution to this optimal stopping problem with partial information is derived. The problem is solved in the martingale framework. Results for monotone stopping problems are used and a generalization of the so-called monotone case is considered. The well-known disruption or disorder or detection ...	optimal stopping;point process	Uwe Jensen;Guang-Hui Hsu	1993	Math. Oper. Res.	10.1287/moor.18.3.645	mathematical optimization;semimartingale;optimal stopping;reliability;point process;mathematics;mathematical economics;complete information;statistics	Theory	6.4235069539589436	-1.4573161382506001	113095
89f2ecdf771d52afbb6ab7a4d21696ec9fabd84d	a model for efficiency-based resource integration in services	dynamic programming;or in manpower planning;service system;coproduction;dynamic program;services;workforce planning;development policy;service operations	Service processes, such as consulting, require coordinated efforts from the service recipient (client) and the service provider in order to deliver the desired output – a process known as resource integration. Client involvement directly affects the efficiency of service processes, thereby affecting capacity decisions. We present a mathematical model of the resource-integration decision for a service process through which the client and the service provider co-produce resource outputs. This workforce planning model is unique because we include the extent of client involvement as a policy variable and introduce to the resource-planning model efficiency and quality performance measures, which are functions of client involvement. The optimization of resource planning for services produces interesting policy prescriptions due to the presence of a client-modulated efficiency function in the capacity constraint and subjective client value placed on participation in the service process. The primary results of this research are optimal decision rules that provide insights into the optimal levels of client involvement and provider commitment in resource integration. 2011 Elsevier B.V. All rights reserved.		Sheneeta W. White;Ralph Badinelli	2012	European Journal of Operational Research	10.1016/j.ejor.2011.09.009	service provider;service level requirement;service level objective;economics;business service provider;differentiated service;knowledge management;service delivery framework;marketing;operations management;service design;service system	AI	0.28848199838507027	-6.765022259992102	113126
afaf722b60a41c7a6961238d50a673e7b2f5adaf	can contracts replace qualification in a sourcing process with competitive suppliers and imperfect information?	supply chain management contracts;sourcing auction mechanisms procurement;procurement production contracts warranties uncertainty process design analytical models;contracts sourcing process competitive suppliers multiple competing suppliers high quality products quality capability mathematical model performance based contracting sourcing method symmetric linear penalty reward function unit warranty cost quality level winning supplier	This paper considers a manufacturer who outsources the production of a product to multiple competing suppliers, who differ in their cost structures and in their capabilities for producing high-quality products. The manufacturer must design the sourcing process to ensure that the selected supplier has sufficient quality capability, while encouraging competition among the suppliers. We develop and analyze a mathematical model of performance-based contracting, a sourcing method that is appropriate when the manufacturer has imperfect information regarding the suppliers' costs and capabilities. We compare the performance of performance-based contracting with that of a two-stage sourcing process, an alternative sourcing method that is more commonly used in practice. The theoretical results and managerial insights derived from this research can enable manufacturing firms to improve the management of their sourcing processes. In particular, we demonstrate that performance-based contracting with a symmetric linear penalty/reward function will always outperform the two-stage sourcing process from the perspective of the buyer and that the optimal penalty/reward rate is less than or equal to the unit warranty cost. In addition, performance-based contracting generally leads to a higher quality level provided by the winning supplier. However, the winning supplier is generally better off under the two-stage sourcing process.	mathematical model;outsourcing;reinforcement learning	Yue Jin;Jennifer K. Ryan	2016	IEEE Transactions on Engineering Management	10.1109/TEM.2016.2569475	operations management;strategic sourcing;commerce	Visualization	0.3165901487023313	-6.195008703851618	113172
3caca6b0689b3437594401c2d2ef7aed0ae16d0c	optimal overlapping and functional interaction in product development	chevauchement;modelizacion;politica optima;concepcion asistida;overlapping;tiempo iniciacion;controle vibration;computer aided design;equilibrado;agua abajo;concepcion ingenieria;engineering design;project management;estrategia optima;conception ingenierie;integrated product development;project manager;concurrent engineering project management integrated product development overlapping;developpement produit;temps mise en route;overlap;optimal policy;imbricacion;integrated design;lead time;concepcion integrada;modelisation;optimal strategy;setup time;vibration control;balancing;coste;conception assistee;gestion projet;aval;downstream;tiempo puesta en marcha;ingenierie simultanee;ingenieria simultanea;politique optimale;modeling;temps mise en oeuvre;strategie optimale;conception integree;equilibrage;desarrollo producto;gestion proyecto;concurrent engineering;control vibracion;cout;product development	Overlapping of development stages and interaction between different functions are regarded as important strategies for reducing development lead time. However, overlapping typically requires additional costs for rework and functional interaction increases communication time. This paper presents an analytical model to improve project performance by balancing the positive and negative effects of overlapping and functional interaction. We first investigate the progress of downstream development, which is essential to derive the optimal overlapping policies. We find that the downstream progress increases over time when the upstream evolution is fast or linear, but it is indefinite when the upstream evolution is slow. Then, we present optimal overlapping policies taking into account the complexity of downstream progress. The impact of different project properties, such as the dependency between development stages and the opportunity cost of time, on overlapping policies is discussed. Finally, we derive the optimal functional interaction strategy when the optimal overlapping is followed. The methodology is illustrated with a case study at a handset design company.	new product development	Jun Lin;Kah-Hin Chai;Aarnout Brombacher;Yoke San Wong	2009	European Journal of Operational Research	10.1016/j.ejor.2008.05.030	project management;downstream;simulation;systems modeling;input/output;operations management;vibration control;operations research;new product development;concurrent engineering	Robotics	8.308347966422238	2.7103267589875033	113490
2fdd38acdc12730c14566262fd32c2d9e63c6725	next-generation strategic business model for the u.s. internet service providers: rate-based internet subscription	internet service provider;business model;next generation	"""The (information digital) network bandwidth and its usage through Internet subscription, by far, is perhaps the only uni-modal commodity provided to today’s consumers at a flat rate. Regardless of his/her actual bandwidth usage, a consumer is charged a uniform subscription fee by the Internet Service Providers (ISP). Meanwhile, the ISPs have a considerable stake in the overall infrastructure which supports the local perimeters of the Internet. This article presents a rigorous statistical analysis with the objective of determining the optimal billing or pricing policy for the ISPs of the U.S. on the basis of the proposed ‘variable subscription-rate’ business model. Two leading global consumer profiles were selected for data comparison on a cardinal scale; NYC, NY, U.S.A. and Seoul, South Korea. introDuction The (information digital) network bandwidth and its usage through Internet subscription, by far, is perhaps the only uni-modal commodity provided to today’s consumers at a flat rate. Regardless of his/her actual bandwidth usage, a consumer is charged a uniform subscription fee by the Internet Service Providers (ISP). Meanwhile, the ISPs have a considerable stake in the overall infrastructure which supports the local perimeters of the Internet. Constant upgrades encompassing but not restricted to network infrastructure, servers, proxies, security, middleware, applications software, fault tolerance, redundancy, contingency plans, and even customer service are expected on a daily basis, as the Internet usage increases geometrically if not exponentially. Moreover, statistics indicate that approximately 10% of 1781 Copyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited. 1782 Next-Generation Strategic Business Model for the U.S. Internet Service Providers the Internet consumers are roughly occupying 90% of the bandwidth at all times (FCC, 2007). In addition, digital convergence of household electronic products comprising the voice-phones, video-phones, Internet Protocol Television (IPTV), digital Hi-Definition TV, home networks and automation, and even IP-based refrigerators or washing machines is rapidly reshaping the Internet usage among consumers across the globe. As a consequence, the network bandwidth shortage and even depletion problem is further aggravated. Early research on ‘rate-based’ variable Internet subscription fees was performed by the British Telecom (BT), a state-owned organization centrally located in London, U.K. This new business model for the ISP has been actively penetrating most areas of Britain, other than Wales and Scotland (KT, 2006). The success of the business model has brought a number of imitators, with such leaders as South Koreans. The U.K and Korea models have close ties in that most ISPs are State-funded and managed and that they are single-state nation, relative to the U.S. Their differences, however, are yet to be explored. The purpose of this article is to investigate the pros and cons of the ‘variable-rate’ business model by conducting an empirical analysis before its introduction to the U. S. The estimated market – after adoption – is approximately $3.0B annually in the U.S. alone, covering 50 continental States other than Hawaii, Puerto Rico, and Virgin Islands (FCC, 2007). Unlike their South Korean counterparts, the U.S. Internet Service Providers (ISP) carry major disadvantages: • Extension of the information network infrastructure which far outsizes that of Korea due to its geographical coverage area. • Network bandwidth bottleneck problem, often characterized as the ‘last-mile problem’. Whereas the population density and congested residential apartments benefit the South Korean ISPs, the reverse is true for the U.S. counterparts. By way of an example, a resolution to a single last-mile problem by using say, fiber optic cable, which may deliver data transfer rate of up to 1.3 Giga bits per second (Gbps) for an apartment complex may enable a Korean ISP to acquire thousands of additional customers. In contrast, as for the U. S. consumers, however, their majority reside in private houses, apart from one another, which eventually may require the ISP to tackle the ‘last-mile’ problem individually on a per household basis. The outlined advantages may justify the world’s highest Internet penetration among consumers in nations such as Korea and Japan (Park, 2001). Thus, the adoption of partly successful ‘variable rate-based’ Internet subscription pricing or utility business model of South Korea may not be adequate for the U. S. ISPs. The purpose of this article, however, is to investigate the effectiveness of such adoption (of business model) to the U. S. through empirical analysis. In order to perform a sound comparative statistical analysis, a sound design of experiments is the prerequisite. Therefore, the cardinal scale of comparative data is sought by restricting the sample to be selected in highly dense metropolitans in both nations; Manhattan, or formally NY, NY against Seoul, Korea. Determination of the optimal pricing policy for such service-oriented commodity as knowledge from the Internet may confound both the consumers and ISP, the business entity. Possible ramifications are: • The consumer does not have sufficiently accurate a priori information as to how s/ he will be charges or billed for the service s/he seeks to receive from the ISP via the Internet, as opposed to other utility services such as power, energy, traditional entertainment, or even commodities such as food. 7 more pages are available in the full version of this document, which may be purchased using the """"Add to Cart"""" button on the product's webpage: www.igi-global.com/chapter/next-generation-strategic-businessmodel/49839?camid=4v1 This title is available in InfoSci-Books, Business-Technology-Solution, InfoSci-Multimedia Technologies, Communications, Social Science, and Healthcare, InfoSci-Select, InfoSci-Media and Communication Science and Technology. Recommend this product to your librarian: www.igi-global.com/e-resources/library-recommendation/?id=1"""	computer security;contingency plan;cuecat;data rate units;depletion region;design of experiments;electronic billing;experiment;flat rate;iptv;information science;internet;kosterlitz–thouless transition;köppen climate classification;last mile;level of measurement;librarian;middleware;modal logic;optical fiber cable;proxy server;rico;server (computing);service-oriented distributed applications;software fault tolerance;washing machine;web page	Charles C. Willow	2009	IJITN	10.4018/jitn.2009070102	business model;bandwidth throttling;the internet;autonomous system;internet transit;bandwidth cap;computer security;computer network	Metrics	0.7897311742960975	-8.461591171012373	113662
248d1d82659f7bd1c5e65453677d5576ae1c582b	modeling disassembly: incorporating divertability into the construction and demolition of buildings	self disassembly;demolition waste	This article identifies the scope and scale of demolition waste, and reflects on the initial results of a first of its kind research project in Calgary, Alberta, aimed at quantifying residential building demolition waste using parametric modeling techniques. This research is framed as a first step toward self-disassembling buildings with a wide variety of building performance benefits including reduced onsite construction times, energy consumption and C&D waste production.	disassembler;parametric model	Joshua M. Taron	2016	2016 IEEE 1st International Workshops on Foundations and Applications of Self* Systems (FAS*W)	10.1109/FAS-W.2016.74	engineering;civil engineering;transport engineering;waste management	Embedded	7.764517532057241	-6.341709058748889	113676
f9d1a7f5e7e57e775136a3cc0e419a1cdf951bd0	approximate equilibria in games with few players	game theory;nash equilibrium;nash equilibria;normal form game	We study the problem of computing approximate Nash equilibria (ǫ-Nash equi-libria) in normal form games, where the number of players is a small constant. We consider the approach of looking for solutions with constant support size. It is known from recent work that in the 2-player case, a 1 2-Nash equilibrium can be easily found, but in general one cannot achieve a smaller value of ǫ than 1 2. In this paper we extend those results to the k-player case, and find that ǫ = 1 − 1 k is feasible, but cannot be improved upon. We show how stronger results for the 2-player case may be used in order to slightly improve upon the ǫ = 1 − 1 k obtained in the k-player case.	approximation algorithm;nash equilibrium	Patrick Briest;Paul W. Goldberg;Heiko Röglin	2008	CoRR		price of stability;game theory;epsilon-equilibrium;mathematical optimization;combinatorics;best response;trembling hand perfect equilibrium;coordination game;economics;non-credible threat;folk theorem;repeated game;mathematics;correlated equilibrium;microeconomics;risk dominance;normal-form game;mathematical economics;equilibrium selection;nash equilibrium	ECom	-3.68080305732267	0.04994416838305804	113767
110a332912d5fad306f765d3334de3358af2f6ef	robust mechanisms under common valuation	robust mechanism;common value;bayes correlated equilibrium;full surplus extraction	We study robust mechanisms to sell a common-value good. We assume the mechanism designer knows the prior distribution of the buyers’ common value but is unsure about the buyers’ information structure. We use linear programming duality to derive mechanisms that guarantee a good revenue among all information structures and all equilibria.	linear programming;value (ethics)	Songzi Du	2016	CoRR		financial economics;economics;common value auction;microeconomics;mathematical economics;welfare economics	ECom	-2.741074136923819	-3.922989251829359	113769
1b6a7f59ddf555684e9827e139b8955a08b5b3d1	detecting traffic anomalies using an equilibrium property	anomaly detection;statistical test;volume change	When many flows are multiplexed on a non-saturated link, their volume changes over short timescales tend to cancel each other out, making the average change across flows close to zero. This equilibrium property holds if the flows are nearly independent, and it is violated by traffic changes caused by several correlated flows. We exploit this empirical property to design a computationally simple anomaly detection method.	anomaly detection;multiplexing;sensor	Fernando Silveira;Christophe Diot;Nina Taft;Ramesh Govindan	2010		10.1145/1811039.1811095	statistical hypothesis testing;anomaly detection;simulation;computer science;computer security;statistics	Networks	-4.010526818987655	3.1715419015131294	113893
b6f0e4901b5469bb31418b368731c8636a616fd3	an agent-based model of the english housing market		Markets for domestic housing in countries like England differ from other markets because the stock is fixed in the short term, buyers need to raise mortgages to finance their purchases and prices tend to be set through intermediaries (‘estate agents’ or realtors). We introduce an agent-based model in which some of the main features of the English market emerge from interactions between buyers, realtors and sellers and use this model to investigate shocks to the market.	agent-based model;darknet market;interaction;purchasing	G. Nigel Gilbert;John C. Hawksworth;Paul A. Swinney	2009			artificial intelligence;machine learning;agent-based model;computer science;finance;estate;intermediary	AI	-1.7323408631683905	-9.766062086608473	113975
9d733650528eed66450365dd2913cfcf97a6ab16	on the efficiency of nash equilibria in aggregative charging games		Several works have recently suggested to model the problem of coordinating the charging needs of a fleet of electric vehicles as a game, and have proposed distributed algorithms to coordinate the vehicles towards a Nash equilibrium of such game. However, Nash equilibria have been shown to posses desirable system-level properties only in simplified cases. In this letter, we use the concept of price of anarchy (PoA) to analyze the inefficiency of Nash equilibria when compared to the social optimum solution. More precisely, we show that: 1) for linear price functions depending on all the charging instants, the PoA converges to one as the population of vehicles grows; 2) for price functions that depend only on the instantaneous demand, the PoA converges to one if the price function takes the form of a positive pure monomial; and 3) for general classes of price functions, the asymptotic PoA can be bounded. For finite populations, we additionally provide a bound on the PoA as a function of the number vehicles in the system. We support the theoretical findings by means of numerical simulations.	anarchy;computer simulation;distributed algorithm;monomial;nash equilibrium;numerical analysis;population	Dario Paccagnan;Francesca Parise;John Lygeros	2018	IEEE Control Systems Letters	10.1109/LCSYS.2018.2845674	monomial;mathematical optimization;distributed algorithm;mathematics;inefficiency;nash equilibrium;population;price of anarchy;bounded function	ECom	-1.4273857282534828	1.8231847571092152	114055
c57a699137b21efd05f5549b7a07ab415a00bc3e	choice behavior of information services when prices are increased and decreased from reference level	reference price;prospect theory;asymmetric price behavior;services	The purpose of this study is to estimate the impact of price increases and decreases for three, at least partly, compensatory services. The existence of a reference effect in pricing has been commonly accepted. However, the observations of consumer choices with prices below and above the reference price have produced mixed results. Both symmetric and asymmetric behavior has been observed. The current study differs from the mainstream in the way that the object is a service and instead of scanner panel data, stated preferences measured by choice based conjoint analysis are used. Moreover, instead of dealing with changes in value caused by price changes, we consider changes in demand on the respondent level. The main outcome of the study was that with the traditional service the respondents reacted more strongly to price increases (loss) than to price decreases (gain), whereas in the two more modern services the reactions were more versatile; with the majority of respondents the reactions were stronger to price decreases (gain). Copyright Springer Science+Business Media New York 2013		Merja Halme;Outi Somervuori	2013	Annals OR	10.1007/s10479-013-1350-3	prospect theory;price elasticity of supply;service;economics;limit price;public economics;mid price;factor price;microeconomics;price level;reservation price	ECom	-2.6114552662989667	-8.134891518711996	114070
cc402842df3b82b4cb7cad5001e51913cc9703be	optimal age-replacement model with minimal repair based on cumulative repair cost limit and random lead time	random lead time;modelizacion;utilisation information;politica optima;tiempo iniciacion;uso informacion;replacement;tiempo diferido;remplacement;information use;maintenance;maintenance cost;temps minimal;age;information policy;temps mise en route;delay system;optimal policy;repair cost limit;delai livraison;inventory;modelisation;minimal repair;cout moyen;setup time;delayed time;systeme a retard;average cost;coste medio;costo manutencion;plazo entrega;minimum time;politique information;mantenimiento;reparation;reemplazo;temps retard;delay time;sistema con retardo;cumulant;reparacion;politique optimale;existence and uniqueness;tiempo minimo;modeling;tiempo retardo;delivery lead time;politica informacion;cost model;temps differe;structural properties;repair;cout entretien;edad	In this study, we consider an age-replacement model with minimal repair based on a cumulative repair cost limit and random lead time for replacement delivery. A cumulative repair cost limit policy uses information about a system's entire repair cost history to decide whether the system is repaired or replaced; a random lead time models delay in delivery of a replacement once it is ordered. A general cost model is developed for the average cost per unit time based on the stochastic behavior of the assumed system, reflecting the costs of both storing a spare and of system downtime. The minimum-cost policy time is derived, its existence and uniqueness is shown, and structural properties are presented.	analysis of algorithms;downtime;stochastic process	Yu-Hung Chien;Shey-Huei Sheu;Chin-Chih Chang	2007	2007 IEEE International Conference on Industrial Engineering and Engineering Management	10.1080/00207720902953144	systems modeling;mean time to repair;inventory;telecommunications;engineering;mathematics;statistics;cumulant	DB	6.155876547023005	-2.2794906205057353	114159
b30599b907539189ea23ecd0fe11df98cee43b70	analysis of market competition and information asymmetry on selling strategies	selling strategy;cournot competition;information asymmetry	In this paper, we consider the seller’s selling strategies in a supply chain consisting of one supplier and multiple retailers, who compete in the same consumer market. The production lead time is relatively long compared to the selling season. Therefore, the supplier can choose to sell the products either before production begins (i.e., advance sale) or after production finishes (i.e. regular sale). Different to existing literature, we analyze the selling strategies in a more realistic environment where each buyer has a private demand signal about the consumer market at the beginning of the selling season. Three different scenarios (i.e., the monopoly retailer, the competing retailers with information sharing, and the competing retailers without information sharing) are analyzed to study the effect of competition and information asymmetry on the supplier’s selling strategy. In each scenario, we establish the equilibrium result and investigate how the competition and information asymmetry affect the supply chain and its each party’s profits with the underlying reason explained. Our main findings include: (1) the supplier is optimal to adopt regular sale when the retailers form as a monopoly retailer, or when the retailers competing with each other with demand information sharing; (2) he prefers advance sale when facing competing retailers with private information; (3) competition and private information also influence the retailers’ and the supply chain’s preferences on the supplier’s sale strategies. Moreover, when the retailers have private information under competition, we find interestingly that (1) the supplier’s profit is increasing in the information precision under advance sale, while it is not affected by information precision under regular sale; and (2) the retailers’ profits may decrease in the information precision under regular sale.		Weili Xue;Jiaojiao Zuo;Xiaolin Xu	2017	Annals OR	10.1007/s10479-015-1809-5	information asymmetry;cournot competition;marketing;microeconomics;commerce	ML	-1.3542561519635572	-6.085813628211887	114261
e8144b0b6973eec7ee1bc3f5a6cba875dc0f1bca	wiretapping a hidden network	virtual networks;liverpool;computer science and information systems;network security;nucleolus;cooperative game;repository;network connectivity;community networks;extreme point;wiretapping;university;zero sum game;partial order	We consider the problem of maximizing the probability of hitting a strategically chosen hidden virtual network by placing a wiretap on a single link of a communication network. This can be seen as a two-player win-lose (zero-sum) game that we call the wiretap game. The value of this game is the greatest probability that the wiretapper can secure for hitting the virtual network. The value is shown to be equal the reciprocal of the strength of the underlying graph. We provide a polynomial-time algorithm that finds a linear-sized description of the maxmin-polytope, and a characterization of its extreme points. It also provides a succint representation of all equilibrium strategies of the wiretapper that minimize the number of pure best responses of the hider. Among these strategies, we efficiently compute the unique strategy that maximizes the least punishment that the hider incurs for playing a pure strategy that is not a best response. Finally, we show that this unique strategy is the nucleolus of the recently studied simple cooperative spanning connectivity game.	directed graph;file spanning;graph (discrete mathematics);hidden surface determination;minimax;telecommunications network;win–loss analytics	Haris Aziz;Oded Lachish;Mike Paterson;Rahul Savani	2009		10.1007/978-3-642-10841-9_40	partially ordered set;extreme point;simulation;game tree;computer science;artificial intelligence;network security;repeated game;mathematics;distributed computing;zero-sum game;mathematical economics;nucleolus;computer security;algorithm	ECom	-3.7382351976026147	1.333093667484313	114292
59fc267bf5c62e955fd93880a7e97b73e8939ca6	tactical logistics and distribution systems (tloads) simulation	distributed system;logistics automotive engineering data engineering design engineering vehicle dynamics fuels testing water storage appropriate technology personnel;data collection;logistics data processing;equipment design parameters tactical logistics and distribution systems simulation tloads simulation us forces opposing forces upgraded delivery equipment ammunition repair parts logistics material delivery equipment trial maneuvers seagoing forces simulated troop landings noncooperative weather operational expense innovative force deployment positioning schemes supply distribution techniques equipment combinations simulation output data distribution schemes vehicle engineering data;distributive data processing;military systems;distributive data processing logistics data processing military systems digital simulation;digital simulation	In response to changing threats from opposing forces often result from use of enhanced technology, U.S. for must adopt new tactics, employing appropriately upgrad delivery equipment to deliver rations, fuel, ammunitio personnel, and repair parts to forces in forward areas the face of sharply reduced R&D budgets, the opportun to explore new tactics and to test and evaluate n logistics material delivery equipment is corresponding diminished. In addition, the evaluation of new tactic through trial maneuvers employing seagoing forces a simulated troop landings is often frustrated by no cooperative weather, the high operational expense mounting a full-blown sea force and the typicall inconclusive nature of the data collected. However, through the use of simulation, inexpensiv innovative force deployment and positioning schemes tested. New supply distribution techniques employing wide variety of equipment combinations both existing a experimental are also tested. The simulation output dat used to grade distribution schemes. This provides range vehicle engineering data which may impact and supp subsequent equipment design parameters.	logistics;norm (social);simulation;software deployment	David J. Parsons;L. C. Krause	1999		10.1145/324898.325030	simulation;engineering;mathematics;transport engineering;statistics;data collection	HCI	7.3367625036748025	-6.8459141017041505	114383
d58bd55645080f8a1680a5f7a3d8c5c117daf407	optimal strategies for manufacturer with strategic customer behavior under carbon emissions-sensitive random demand	green technology investment;production strategy;strategic customer behaviour;low carbon manufacturing;pricing strategy	Purpose – The purpose of this paper is to investigate the manufacturer’s production, pricing and green technology investment decision problem when strategic customer behavior and carbon emissions-sensitive random demand is taken into consideration and discuss the impact of carbon emissions-sensitive demand on the manufacturer’s operation strategies, total carbon emissions and maximum expected profit. Design/methodology/approach – The authors formulate a model to introduce carbon emissions-sensitive demand into the newsvendor framework with strategic customer behavior. The authors characterize the rational expectations equilibrium to derive the optimal solutions to the manufacturer. The authors analyze the effects of carbon emissions-sensitive demand on the manufacturer’s optimal strategies, total carbon emissions and maximum expected profit by comparative analysis. Findings – The authors obtain the manufacturer’s optimal production, pricing and green technology investment strategies under rational expecta...		Wen Jiang;Xu Chen	2016	Industrial Management and Data Systems	10.1108/IMDS-08-2015-0321	economics;marketing;operations management;microeconomics;commerce	Robotics	0.4112322797794513	-6.425783262825344	114411
cca773bcae4ff4a7f4d68eddf85920c123e6bff3	the discretization of continuum strategy spaces	continuum strategy spaces;bepress selected works;discretization;optimization problem;discretization continuum strategy spaces;insurance market;oligopolies	When the strategy set of a game is a continuum, its discretization may not conserve local properties even for arbitrarily fine strategy grids. This paper provides two technical lemmata which are useful to deal with these problems in particular contexts. Four applications are presented, regarding the discretization of Cournot and Bertrand oligopolies, a consumer optimization problem, and an insurance market.	bertrand (programming language);discretization;mathematical optimization;optimization problem;spaces;triune continuum paradigm	Carlos Alós-Ferrer	2006	IGTR	10.1142/S0219198906001053	optimization problem;mathematical optimization;economics;discretization;mathematics;microeconomics;mathematical economics;welfare economics;oligopoly	ECom	-0.1299594186710984	-2.3725203270842044	114413
df7eba5350a36729e16d58881592345632e23775	price-demand modeling - a tool to support inventory and production decisions for competing products	price demand models;market share attraction models;inventory and production management	Aim of this positioning paper is to explore the existing price-demand models that have been applied in inventory and production management so far and to identify new potential structures that may have been applied in marketing research but have not been touched yet in inventory and production research. Our focus will be on dynamic pricing structures for competing products, since our exploration so far revealed that they have not been studied exhaustively in price-demand inventory literature. Specifically, we propose a price-demand-inventory model framework for optimizing joint pricing, production, inventory and transportation decisions in a supply chain with multiple products, multiple factories, and multiple markets operating in multiple periods. The factories operate in a cooperative environment where these decisions are given centrally so as to maximize the total profit. Competition between the various product types is achieved centrally by setting market specific prices for each product type in each market in each period. To support this price setting we introduce several promising price-demand structures for competing products.	inventory theory;product type	P. C. Schuur;Asli Sencer;Bertan Badur	2014		10.5220/0004924403170321	inventory theory;economics;marketing;operations management;commerce	ECom	-0.13289098017190729	-5.996314196164049	114560
a6308d597b6b7eed23114245d1933801cde71480	valuing continuous-installment options	equation derivee partielle;modelizacion;partial differential equation;ecuacion derivada parcial;probleme frontiere libre;transformation laplace;present value;arret optimal;finance;dividende;compra;garantie contre risque;flexibilidad;inversion;representacion integral;continuous installment options;exact solution;laplace transform;representation integrale;option achat europeenne;black scholes model;prise de decision;free boundary problem;opcion financiera;solucion exacta;value analysis;actif eventuel;asymptotic behavior;comportement asymptotique;analyse valeur;greek;modelisation;interrupcion optima;comportamiento asintotico;griego;laplace transforms;contingent asset;finance continuous installment options free boundary problem integral representation laplace transforms;warranty;laplace transformation;path dependence;analisis valor;portfolio management;problema frontera libre;asymptotic properties;modele black scholes;optimal stopping;achat;garantia contra riesgo;option value;flexibilite;gestion cartera;activo contingente;option financiere;european call option;grec;dividend;contingent claim;solution exacte;gestion portefeuille;integral representation;toma decision;modeling;financial option;opcion compra europea;numerical inversion;flexibility;purchases;finanzas;transformacion laplace;modelo black scholes	Installment options are path-dependent contingent claims in which the premium is paid discretely or continuously in installments, instead of paying a lump sum at the time of purchase. This paper deals with valuing European continuous-installment options written on dividend-paying assets in the standard Black-Scholes-Merton framework. The valuation of installment options can be formulated as a free boundary problem, due to the flexibility of continuing or stopping to pay installments. On the basis of a PDE for the initial premium, we derive an integral representation for the initial premium, being expressed as a difference of the corresponding European vanilla value and the expected present value of installment payments along the optimal stopping boundary. Applying the Laplace transform approach to this PDE, we obtain explicit Laplace transforms of the initial premium as well as its Greeks, which include the transformed stopping boundary in a closed form. Abelian theorems of Laplace transforms enable us to characterize asymptotic behaviors of the stopping boundary close and at infinite time to expiry. We show that numerical inversion of these Laplace transforms works well for computing both the option value and the optimal stopping boundary.	black–scholes model;capability maturity model;contingency (philosophy);control theory;exptime;euler method;finite difference method;lattice model (physics);linear canonical transformation;lumped element model;newton's method;numerical analysis;optimal stopping;pde surface;path dependence;software bug;stochastic process;value (ethics);volatility	Toshikazu Kimura	2010	European Journal of Operational Research	10.1016/j.ejor.2009.02.010	financial economics;asymptotic analysis;optimal stopping;calculus;mathematics;mathematical economics;laplace transform;project portfolio management	Theory	2.369831277150011	-2.519773547340396	114574
5427f9e83d66f39fee1b1b4e194b22acf3b58555	wireless sensors network for traffic surveillance and management in smart cities		The efficiency of a city's own transportation system heavily influences its economic growth due to the increasing need to transport labour force, consumers and cargo. The use of the latest technologies to solve traffic problems is the main theme of ITS “Intelligent transportation system”, several solutions are already in use in many cities around the world and it is an indispensable part of the smart cities project. Our research focuses on developping a solution to manage road traffic in a smart city environment by utilizing wireless sensor network as medium to surveille the traffic. In this paper, we propose a set of countermeasures to avoid congestion and improve the flow of the traffic. The proposed countermeasures were simulated, and the results showed that our plan reduced the traffic congestion, minimized gases emission and increased fuel usage efficiency.		A. Elmrini;A. Ghacham Amrani	2018	2018 IEEE 5th International Congress on Information Science and Technology (CiSt)	10.1109/CIST.2018.8596636	wireless;computer network;computer science	Embedded	9.934429726898363	-7.295781378306357	114654
f7f846a31cda32dee3b8af1dc2267e67df62e897	methodology for solar and wind energy chemical storage facilities design under uncertainty: methanol production from co2 and hydrogen	hydrogen;wind power;solar energy;synthetic methanol;design under uncertainty;co2	Production facilities that store solar or wind energy in the form of chemicals present underused capacity. The problem needs to address uncertain and variable operating conditions and prices for complex process models. An MILP formulation is developed including surrogate models based on the detailed NLP steady state models. The model solves the tradeoffs between investment and production capacity. This approach is applied to the case of the production of methanol from CO2 and solar or wind based hydrogen. Two cases are evaluated, Spain and UK. For the Spanish case, if electricity can be sold and there is no area restrictions, the process produces an excess of electricity with the solar panels available during summer time. Otherwise, electricity is only produced when excess capacity is available. In the UK, only wind turbines are used and the excess of electricity is produced during winter time.	hydrogen	Mariano Martín	2016	Computers & Chemical Engineering	10.1016/j.compchemeng.2016.05.001	wind power;hydrogen;environmental engineering;engineering;grid parity;carbon dioxide;stand-alone power system;solar energy;waste management	OS	9.185171974196445	-4.510819961724241	114976
74e42b41d60d765684e5a85758f19f159cb8c330	optimal policy for a two-stage assembly system under random demand	629 two stage production assembly;optimal policy;362 component ordering and product assembly	This paper considers an inventory system in which an end product is assembled from two components, each of which is ordered from an external supplier. Only the end product has final demand, which is assumed to be random. Using the functional equation approach of dynamic programming, we characterize the forms of both the optimal order policy for the components and the optimal assembly policy of the end product for a multiperiod problem of arbitrary, but finite length. We believe that this work represents the only exact analysis of an MRP-type assembly system when demand is stochastic.		Charles P. Schmidt;Steven Nahmias	1985	Operations Research	10.1287/opre.33.5.1130	mathematical optimization;economics;operations management;mathematical economics	Robotics	4.120857192146472	-2.5201988205833366	114983
2591a65d24ea4a7ccba51a16093ec68e6f6597fb	robust optimization of ev charging schedules in unregulated electricity markets	uncertainty;state of charge soc curve charging schedule electric vehicle ev robust optimization ro;indexes;optimization robustness uncertainty system on chip schedules batteries indexes;system on chip;batteries;schedules;robustness;optimization	In this paper, we address the problem of optimal electric vehicle (EV) charging in an unregulated electricity market. This problem is known to be highly nonlinear even in the case of fixed electricity prices due to a nonlinear state-of-charge curve representing physical battery limitations. We design tractable formulations for single and multiple EV charging frameworks. In the first part of this paper, we develop a new efficient cutting plane method, that can be used for solving charging optimization problem for both scenarios of known and uncertain electricity prices. The latter scenario with real-time electricity rates is considered in the second part of this paper. We obtain robust optimization counterparts of the nominal charging problems that are particularly important from an economic perspective when budget constraints are strictly enforced. New robust formulations are proven to be tractable. Moreover, computational experiments illustrate that a decision maker can find solutions that are close to optimal in terms of the corresponding objective values, and robust with respect to uncertain electricity prices.	algorithm;cobham's thesis;computation;concave function;cutting-plane method;decision theory;experiment;extended validation certificate;integer programming;loss function;mathematical optimization;nonlinear system;numerical analysis;optimization problem;program optimization;real-time transcription;robust optimization;schedule (computer science);scheduling (computing);state of charge;terms of service	Nikita Korolko;Zafer Sahinoglu	2017	IEEE Transactions on Smart Grid	10.1109/TSG.2015.2472597	system on a chip;database index;mathematical optimization;simulation;uncertainty;schedule;computer science;engineering;operations management;statistics;robustness	Vision	3.4032218248157564	3.2413301117019104	115139
b6a8a9e788e9df51c63016a7d25d48b10441199d	flight rescheduling responding to large-area flight delays	large area flight delays;programming and algorithm theory;aviation safety;risk management;flight status;polynomial algorithm;mathematic programming model;airlines;operations management;priority;flight rescheduling	Purpose – The purpose of this paper is to focus on disruption management responding to large‐area flight delays (LFD). It is urgent for airways to reschedule the disrupted flights so as to relieve the negative influence and minimize losses. The authors try to reduce the risk of airline company's credit and economic losses by rescheduling flights with mathematic models and algorithm.Design/methodology/approach – Based on flight classifications of real‐time statuses and priority indicators, all flights are prioritized. In this paper, two mathematic programming models of flight rescheduling are proposed. For the second model, an optimum polynomial algorithm is designed.Findings – In practice, when LFD happens, it is very important for the airline company to pay attention to real‐time statuses of all the flights. At the same time, the disruption management should consider not only the economic loss but also other non‐quantitative loss such as passengers' satisfaction, etc.Originality/value – In this paper, tw...		Mingang Gao;Hong Chi;Baoguang Xu;Ruo Ding	2012	Kybernetes	10.1108/03684921211276693	simulation;risk management;aviation safety;operations research	Robotics	8.593115402694263	-3.4385804044773995	115219
93103956db91680a6a401d554abd9bab37eb691b	modeling of product sales promotion and price discounting strategy using fuzzy logic in a retail organization		"""Modeling of Product Sales Promotion and Price Discounting Strategy using Fuzzy Logic in a Retail Organization Anup Kumar Amit Adlakha Kampan Mukherjee Article information: To cite this document: Anup Kumar Amit Adlakha Kampan Mukherjee , (2016),""""Modeling of Product Sales Promotion and Price Discounting Strategy using Fuzzy Logic in a Retail Organization"""", Industrial Management & Data Systems, Vol. 116 Iss 8 pp. Permanent link to this document: http://dx.doi.org/10.1108/IMDS-10-2015-0438"""	adaptive neuro fuzzy inference system;dls format;data system;fuzzy logic;inventory control;linear programming relaxation;nl (complexity);procurement;rationality	Anup Kumar;Amit Adlakha;Kampan Mukherjee	2016	Industrial Management and Data Systems	10.1108/IMDS-10-2015-0438	economics;marketing;operations management;sales management;management;commerce	DB	2.909376697358122	-7.8940540681502975	115491
924cb45b4e5d79b895352e11050cd9b01fe5ab5c	optimality of ramsey-euler policy in the stochastic growth model		For the standard one sector stochastic optimal growth model, we outline a new set of conditions for a policy function that satisfies the Ramsey-Euler equation to be optimal. An interior Ramsey-Euler policy function is optimal if (and only if) it is continuous or alternatively, if both consumption and investment are non-decreasing in output. One does not need to verify the transversality condition to show that the Ramsey-Euler policy function is optimal.	bellman equation;euler;population dynamics;transversality (mathematics)	Tapan Mitra;Santanu Roy	2017	J. Economic Theory	10.1016/j.jet.2017.08.001		ML	1.648620892184013	-2.217337015721696	115514
7a0610eeedf0301504bb5ed0e7180e7a2feae4af	a study on supermarket chains of multi-category inventory management strategy	optimal reorder point;inventory management;service level;sale volume;optimal order quantity;multicategory inventory management strategy;biological system modeling;industries;retailing;operations research;optimal order quantity supermarket chain multicategory inventory management strategy gross profit rate sale volume multicategory good retailer oriented category role optimal reorder point;gross profit rate;biological system modeling inventory management marketing and sales operations research safety face industries;the optimal reorder point;supermarket chain;the optimal order quantity;safety;multicategory good;retailer oriented category role;face;profitability;supply chain management inventory management retailing;the optimal order quantity inventory management service level the optimal reorder point;supply chain management;marketing and sales	Nowadays, the supermarket chains face the multi-category goods of which gross profit rate and sales volume are different. In this paper we study on supermarket chains of multi-category inventory management strategy. Firstly, we carry out classification on the goods by the method of retailer-oriented category roles. Then, we set different service level for different category goods. At last, we discuss the different categories of the optimal reorder point and the optimal order quantity.	inventory	Lu Qing	2010	2010 International Conference on E-Business and E-Government	10.1109/ICEE.2010.802	face;supply chain management;economic order quantity;service level;economics;marketing;operations management;commerce;profitability index	Robotics	3.6408053514546466	-9.35289160582593	115545
1e48cc124460ca1cc0d08de64ea4e717f588ed2f	auction mechanism for optimally trading off revenue and efficiency	social welfare;efficiency;economic efficiency;expected utility;electronic marketplace;tradeoff;vickrey auction;revenue;economics;auctions	We study selling one indivisible object to multiple potential buyers. Depending on the objective of the seller, different selling mechanisms are desirable. The Vickrey auction with a truthful reserve price is optimal when the objective is efficiency (i.e., allocating the object to the party who values it the most). The Myerson auction is optimal when the objective is the seller's expected utility. These two objectives are generally in conflict, and cannot be maximized with one mechanism. In many real-world settings---such as privatization and competing electronic marketplaces---it is not clear that the objective should be either efficiency or seller's expected utility. Typically, one of these objectives should weigh more than the other, but both are important. We account for importance of both objectives by designing a new deterministic auction mechanism that maximizes expected social welfare subject to a minimum constraint on the seller's expected utility. This way the seller can expect to do well enough for himself, while maintaining the attractive properties of the mechanism.	auction algorithm;expected utility hypothesis;indivisible;serializability	Anton Likhodedov;Tuomas Sandholm	2003		10.1145/779928.779964	eauction;vickrey auction;generalized second-price auction;economics;expected utility hypothesis;trade-off;reverse auction;vickrey–clarke–groves auction;proxy bid;revenue equivalence;social welfare;english auction;efficiency;microeconomics;revenue;welfare economics;economic efficiency;auction theory;commerce;forward auction;dutch auction	AI	-2.8371397576854815	-3.1053379831920456	115585
66141dffc68f096d0222e9f92104ea8da7b0c55f	free entry, market size, and the optimistic stability	mode of play;optimistic stable standard of behavior ossb;free entry;jel classification l13;market structure;jel classification c79;elasticity of substitution;free entry long run equilibrium;monopolistic competition;social situation;profit maximization;market size	We examine the long-run outcomes under free entry-exit when each firm not only takes account of the effects of her own entry-exit on the market structure but also takes full account of the effects due to other firms’ simultaneous entry-exit. Adopting the framework of the theory of social situations (TOSS), we derive a unique set of stable outcomes, which is based only on two fundamental assumptions of the “firms-as-profit-maximizers” and the “free entry-exit,” but not on any specific mode of play (i.e., a specification of how the players make their decisions, take actions within the market, and think of the other players’ behavior). We compare the stable outcome with the long-run equilibria under the competitive mode, the Cournot-Nash mode, and the monopolistically competitive mode. We find that (i) each of these equilibria can be compatible with the stable outcome only if the market size is small and (ii) none of them can be compatible with the stable outcome if the market size is sufficiently large; Further, (iii), for almost all market size, the monopolistically competitive equilibrium is compatible with the stable outcome if the elasticity of substitution is sufficiently close to (but, greater than) unity. In a sense, when the market size is sufficiently large, these three modes of play are not consistent with two fundamental assumptions.	elasticity (cloud computing);nash equilibrium	Noritsugu Nakanishi	2007	IGTR	10.1142/S0219198907001382	industrial organization;economics;monopolistic competition;market structure;microeconomics;mathematical economics;welfare economics;elasticity of substitution	ECom	-4.466388507900587	-5.124604929974669	115612
5b63de58558246b292ef971f17326b389ff0cbf6	addressing the computational issues of the shapley value with applications in the smart grid	qa75 electronic computers computer science	We consider the computational issues that arise in using the Shapley value in practical applications. Calculating the Shapley value involves computing the value of an exponential number of coalitions, which poses a significant computational challenge in two cases: (i) when the number of agents (players) is large (e.g., more than 20), and (ii) when the time complexity of the characteristic function is high. However, to date, researchers have aimed to address only the first case, although with limited success.  To address the first issue, we focus on approximating the Shapley value. In more detail, building upon the existing sampling-based approaches, we propose an improved error bound for approximating the Shapley value using simple random sampling (SRS), which can be used in any superadditive game. Moreover, we put forward the use of stratified sampling, which can lead to smaller standard errors. We propose two methods for minimising the standard error in supermodular games and a class of games that have a property that we call order-reflecting. We show that among others, newsvendor games, which have applications in the smart grid, exhibit this property. Furthermore, to evaluate our approach, we apply our stratified sampling methods to an instance of newsvendor games consisting of 100 agents using real data. We find that the standard error of stratified sampling in our experiments is on average 48% lower than that of SRS.  To address the second issue, we propose the characteristic function of the game be approximated. This way, calculating the Shapley value becomes straightforward. However, in order to maintain fairness, we argue that, in distributing the value of the grand coalition, agents' contribution to the complexity of the characteristic function must be taken into account. As such, we propose the bounded rational Shapley value, which, using the additivity axiom of the Shapley value, ensures that the share of each agent reflects its contribution to the difficulty of computing the coalition values. We demonstrate the usefulness of this approach in a demand response scenario where a number of apartments want to fairly divide the discount they receive for coordinating their cooling loads.		Sasan Maleki	2015			mathematical optimization;simulation;mathematics;mathematical economics	HPC	-2.935351887703995	-0.1902839196937808	115878
83457e6ab546ffba083fff179f32dc0071e5d3a8	evaluating significance of inconsistencies	quasi classical	In this paper, we study distributed algorithms for cooperative agents that allow them to exchange their assigned tasks in order to reduce their team cost. We define a new type of contract, called K-swaps, that describes multiple task exchanges among multiple agents at a time, which generalizes the concept of single task exchanges. We design a distributed algorithm that constructs all possible K-swaps that reduce the team cost of a given task allocation and show that each agent typically only needs to communicate a small part of its local computation results to the other agents. We then demonstrate empirically that K-swaps can reduce the team costs of several existing task-allocation algorithms significantly even if K is small.	computation;distributed algorithm;memory management;palette swap	Anthony Hunter	2003			computer science;data mining;mathematics;algorithm	AI	-1.8731930767994	3.090469490717482	115894
ba60fd51a0aec2f319148f3c08bfb96fef4941fb	licensing of a quality-improving innovation	new technology;social welfare;quality improvement;quality improving innovation random utility logit licensing covered market uncovered market;random utility	We study the licensing of a quality-improving innovation in a duopoly model with heterogeneous consumers. Firms compete in prices facing a logit demand framework. The innovator is an outsider to the market and sells licenses via up front fee (determined in an auction), royalty or their combination. We show that if the market is covered then irrespective of the magnitude of the innovation both firms acquire the new technology and pay positive royalty and zero up-front fee. The increase in social welfare due to the innovation is totally extracted by the innovator. For the uncovered market case we show that if the consumer heterogeneity is sufficiently high, then both firms become licensees. The licensees pay positive royalty and zero upfront fee – if the value of an outside alternative option is low – and both positive royalty and positive up-front fee — if the value of the outside alternative option is high. © 2008 Elsevier B.V. All rights reserved.		Giorgos Stamatopoulos;Yair Tauman	2008	Mathematical Social Sciences	10.1016/j.mathsocsci.2008.06.006	quality management;economics;marketing;social welfare;microeconomics;commerce	AI	-2.2514427405068185	-7.536003846092503	115973
9a6c13092c7607d8df4d9d7ba85a6b5609842772	congestion and returns to scale in data envelopment analysis	efficiency;return to scale;increasing returns to scale;data envelopment analysis;necessary and sufficient condition;congestion;constant returns to scale;data envelope analysis;returns to scale	Congestion indicates an economic state where inputs are overly invested. Evidence of congestion occurs whenever reducing some inputs can increase outputs. Return to scale is another related important economic implication of DEA efficiencies. In this research, we discuss together the problems of congestion, constant return to scale, increasing return to scale and decreasing return to scale by output oriented DEA models, CR model, BC model, FG model, ST model, and a modified model. We identify the necessary and sufficient conditions for the evidence of congestion, constant, increasing and decreasing returns to scale. We show the exclusive relationships between the concepts of congestion and returns to scale. Numerical examples are provided for illustration. 2002 Elsevier B.V. All rights reserved.	data envelopment analysis;digital mockup;job control (unix);network congestion	Quanling Wei;Hong Yan	2004	European Journal of Operational Research	10.1016/S0377-2217(02)00799-3	financial economics;returns to scale;economics;operations management;welfare economics	Metrics	-0.8723409769081636	-9.030757739618387	116051
03145432202df7a1f7bdd5f968119bfa867aca65	altruism in congestion games	congestion game	This paper studies the effects of introducing altruistic agents into atomic congestion games. Altruistic behavior is modeled by a trade-off between selfish and social objectives. In particular, we assume agents optimize a linear combination of personal delay of a strategy and the resulting increase in social cost. Our model can be embedded in the framework of congestion games with player-specific latency functions. Stable states are the Nash equilibria of these games, and we examine their existence and the convergence of sequential best-response dynamics. Previous work shows that for symmetric singleton games with convex delays Nash equilibria are guaranteed to exist. For concave delay functions we observe that there are games without Nash equilibria and provide a polynomial time algorithm to decide existence for symmetric singleton games with arbitrary delay functions. Our algorithm can be extended to compute best and worst Nash equilibria if they exist. For more general congestion games existence becomes NP-hard to decide, even for symmetric network games with quadratic delay functions. Perhaps surprisingly, if all delay functions are linear, then there is always a Nash equilibrium in any congestion game with altruists and any better-response dynamics converges. In addition to these results for uncoordinated dynamics, we consider a scenario in which a central altruistic institution can motivate agents to act altruistically. We provide constructive and hardness results for finding the minimum number of altruists to stabilize an optimal congestion profile and more general mechanisms to incentivize agents to adopt favorable behavior. ∗Computer Science Department, Stanford University, USA. Supported by a fellowship within the Postdoc-Program of the German Academic Exchange Service (DAAD). †Dept. of Computer Science, RWTH Aachen University, Germany. Supported in part by the German Israeli Foundation (GIF) under contract 877/05.	algorithm;anarchy;best, worst and average case;computer science;concave function;converge;embedded system;entity–relationship model;gif;kempe chain;nash equilibrium;network congestion;p (complexity);polynomial;routing;time complexity	Martin Hoefer;Alexander Skopalik	2008	CoRR		epsilon-equilibrium;mathematical optimization;simulation;best response;economics;microeconomics;mathematical economics;symmetric game	ECom	-4.392664210861474	0.97876673132736	116087
a86e93dd1a7aad18ae0a3e47cd627d33a4b9be7d	short-term robustness of production management systems: a case study	risk analysis;product line;operations research;satisfiability;production management;production control;uncertainty analysis;sensitivity analysis	Abstract   Whereas Operations Research concentrates on optimization, practitioners find the robustness of a proposed solution more important. Therefore this paper presents a practical methodology that is a stagewise combination of four proven techniques: (1) simulation, (2) optimization, (3) risk or uncertainty analysis, and (4) bootstrapping. This methodology is illustrated through a production-control study. That illustration defines robustness as the capability to maintain short-term service, in a variety of environments (scenarios); that is, the probability of the short-term fill-rate remains within a prespecified range. Besides satisfying this probabilistic constraint, the system minimizes expected long-term work-in-process. Actually, the example compares four systems––namely, Kanban, Conwip, Hybrid, and Generic––for the well-known case of a production line with four stations and a single product. The conclusion is that in this particular example, Hybrid is best when risk is not ignored; otherwise Generic is best; that is, risk considerations do make a difference.		Jack P. C. Kleijnen;E. G. A. Gaury	2003	European Journal of Operational Research	10.1016/S0377-2217(02)00437-X	mathematical optimization;uncertainty analysis;risk analysis;economics;operations management;mathematics;sensitivity analysis;statistics;satisfiability	Robotics	9.211763093136055	-3.8999413045499938	116104
36769e98669ada66e72a6e31157198fec1dbe897	case series - bluesky airlines: single-leg revenue management				Robert A. Shumsky	2009	INFORMS Trans. Education			HCI	2.789061214500441	-7.946226094008089	116175
7a8f080740eef0eeadbc41a044286571620dd221	workflow scheduling using multi-agent systems in a dynamically changing environment	jos;simulation;conceptual modellling;journal of simulation;output analysis;design and analysis of simulation experimetns;input modelling;applications of simulation and modelling;simulation visualisation;simulation tutorials;parallel and distributed simulation;discrete event simulation	The application of intelligent agent technologies is considered a promising approach to improve system performance in complex and changeable environments. Especially, in the case of unforeseen events, for example, machine breakdowns that usually lead to a deviation from the initial production schedule, a multi-agent approach can be used to enhance system flexibility and robustness. In this paper we apply this approach to revise and re-optimize the dynamic system schedule in response to unexpected events. We employ Multi-Agent System simulation to optimize the total system output (eg, number of finished products) for recovery from machine and/or conveyor failure cases. Diverse types of failure classes (conveyor and machine failures), as well as duration of failures are used to test a range of dispatching rules in combination with the All Rerouting re-scheduling policy, which showed supreme performance in our previous studies. In this context, the Critical Ratio rule, which includes the transportation time into the calculation for the selection of the next job, outperformed all other dispatching rules. We also analysed the impact of diverse simulation parameters (such as number of pallets, class of conveyor failure and class of machine failure) on the system effectiveness. Presented research also enlightens the economic interdependencies between the examined parameters and the benefits of using the agent paradigm to minimize the impact of the disrupting events on the dynamic system.	multi-agent system;scheduling (computing)	Munir Merdan;Thomas Moser;Wikan Danar Sunindyo;Stefan Biffl;Pavel Vrba	2013	J. Simulation	10.1057/jos.2012.15	real-time computing;simulation;computer science;discrete event simulation	AI	9.45728995053332	1.5256502080958365	116200
95abb4559939530e9358bd917b038392f00dab95	analytic-numerical investigations of singular problems for survival probability in the dual risk model with simple investment strategies		We study the life annuity insurance model when simple investment strategies (SISs) of the two types are used: risky investments and risk-free ones. According to a SIS of the first type, the insurance company invests a constant positive part of its surplus into a risky asset while the remaining part is invested in a risk-free asset. A risk-free SIS means that the whole surplus is invested in a risk-free asset. We formulate and study some associated singular problems for linear integro-differential equations (IDEs). For the case of exponential distribution of revenue sizes, we state that survival probabilities as the functions of the initial surplus (IS) are unique solutions of the corresponding problems. Using the results of computational experiments, we conclude that in the region of small sizes of IS the risky SIS may be more effective tool for increasing of the survival probability than risk-free one.		T. A. Belkina;N. B. Konyukhova;B. V. Slavko	2017		10.1007/978-3-319-71504-9_21	financial economics;economics;life annuity;exponential distribution;revenue;investment strategy	ML	2.1068794216251874	-2.9022827660472528	116480
8590a33f1f03d04f75b451c6b7f7b0a1e0963228	time horizon and the discount rate	discount rate;risk aversion;utility function;journal of economic literature;random walk;growth rate;relative risk aversion;cash flow;yield curve	We consider an economy à la Lucas [12] with a risk-averse representative agent. The exogenous growth rate of the economy follows a random walk. We characterize the set of utility functions for which it is efficient to discount more distant cash flows at a lower rate. The benchmark result is that, when the growth rate is almost surely nonnegative, the yield curve is decreasing if and only if relative risk aversion is decreasing with wealth. Relaxing the assumption on the absence of recession requires more restrictions on preferences, as increasing relative prudence.	benchmark (computing);i. michael ross;linear algebra;reversion (software development);risk aversion;supermodular function;whole earth 'lectronic link	Christian Gollier	2002	J. Economic Theory	10.1006/jeth.2001.2952	financial economics;risk aversion;economics;finance;macroeconomics;microeconomics;welfare economics	ECom	-4.2788884399329925	-1.4461374174727255	116611
832d4fc2e4343083595864894bac3caf7664a781	nash extremal optimization and large cournot games		Equilibria detection in large games represents an important challenge in computational game theory. A solution based on generative relations defined on the strategy set and the standard Extremal Optimization algorithm is proposed. The Cournot oligopoly model involving up to 1000 players is used to test the proposed methods. Results are compared with those obtained by a Crowding Differential Evolution algorithm.	extremal optimization;nash equilibrium	Rodica Ioana Lung;Tudor Dan Mihoc;Dumitru Dumitrescu	2011		10.1007/978-3-642-24094-2_14	epsilon-equilibrium;simulation;best response;mathematical economics	EDA	-4.372299200622675	-2.1918458516251973	116632
8fa4953445fd73b23266d87073f29a2ac6f8e834	distributed task management in cyber-physical systems: how to cooperate under uncertainty?		We consider the problem of task allocation in a network of cyber-physical systems (CPSs). The network can have different states, and the tasks are of different types. The task arrival is stochastic and state-dependent. Every CPS is capable of performing each type of task with some specific state-dependent efficiency. The CPSs have to agree on task allocation prior to knowing about the realized network’s state and/or the arrived tasks. We model the problem as a multi-state stochastic cooperative game with state uncertainty. We then use the concept of deterministic equivalence and sequential core to solve the problem. We establish the non-emptiness of the strong sequential core in our designed task allocation game and investigate its characteristics including uniqueness and optimality. Moreover, we prove that in the task allocation game, the strong sequential core is equivalent to Walrasian equilibrium under state uncertainty; consequently, it can be implemented by using the Walras’ tatonnement process.		Setareh Maghsudi;Mihaela van der Schaar	2018	CoRR	10.1109/tccn.2018.2888970	resource management;task analysis;equivalence (measure theory);task management;computer network;walrasian auction;mathematical optimization;computer science;general equilibrium theory;cyber-physical system;stochastic process	AI	-1.6713152079119247	1.4299678229948058	116783
6d241678e0b0f194520055d3e75d4b77f7000f41	distribution system voltage control under uncertainties		Voltage control plays an important role in the operation of electricity distribution networks, especially with high penetration of distributed energy resources. These resources introduces significant and fast varying uncertainties. In this paper, we focus on reactive power compensation to control voltage in the presence of uncertainties. We adopt a probabilistic approach that accounts for arbitrary correlations between renewable resources at each of the buses and we use the linearized DistFlow equations to model the distribution network. We then show that this optimization problem is convex for a wide variety of probabilistic distributions. Compared to conventional per-bus chance constraints, our formulation is more robust to uncertainty and more computationally tractable. We illustrate the results using standard IEEE distribution test feeders.	approximation algorithm;cobham's thesis;feasible region;mathematical optimization;monte carlo method;optimization problem;sampling (signal processing);simulation	Pan Li;Baosen Zhang	2017	2017 51st Asilomar Conference on Signals, Systems, and Computers	10.1109/ACSSC.2017.8335424	robustness (computer science);mathematical optimization;voltage;probabilistic logic;computer science;distributed generation;ac power;electric power distribution;optimization problem	EDA	6.458578625079615	3.863250891580169	116919
66ec7d0a14fd3ea37a391d21cf682c88f3db30bc	characterization of facility assignment costs for a location-inventory model under truckload distribution	journal of the operational research society	We consider a two-stage distribution system, where the first stage consists of potential distribution centres (DCs) and the second stage consists of geographically dispersed existing retailers. Our goal is to determine the set of open DCs and assignment of open DCs to retailers simultaneously with inventory decisions of retailers. In addition to the DC-specific fixed facility location costs, we explicitly model the inventory replenishment and holding costs at the retailers and truckload transportation costs between the DCs and the retailers. The transportation costs are subject to truck/cargo capacity, leading to an integrated location-inventory problem with explicit cargo costs. We develop a mixed-integer nonlinear model and analyse its structural properties leading to exact expressions for the so-called implied facility assignment costs and imputed per-unit per-mile transportation costs. These expressions analytically demonstrate the interplay between strategic location and tactical inventory/transportation decisions in terms of resulting operational costs. Although both the theory and practice of integrated logistics have recognized the fact that strategic and tactical decisions are interrelated, to the best of our knowledge, our paper is the first to offer closed-form results demonstrating the relationship explicitly. We propose an efficient solution approach utilizing the implied facility assignment costs and we demonstrate that significant savings are realizable when the inventory decisions and cargo costs are modelled explicitly for facility location purposes.	inventory theory	Sila Çetinkaya;Burcu Baris Keskin;Halit Üster	2014	JORS	10.1057/jors.2013.87	simulation;economics;marketing;operations management;operations research	ECom	9.22221795542365	-2.8908624745017266	117099
31cdc24a73d867e92dad94ec34f90cd27708d4e6	joint privacy-cost optimization in smart electricity metering systems		Joint privacy-cost optimization is studied for a smart grid consumer, whose electricity consumption is monitored in almost real time by the utility provider (UP). It is assumed that an energy storage device, e.g., an electrical battery, is available to the consumer, which can be utilized both to achieve privacy and to reduce the energy cost by modifying the electricity consumption. Privacy is measured via the mean squared distance between the smart meter readings and a target load profile, while time-of-use pricing is considered to compute the electricity cost. The consumer also has the possibility to sell electricity back to the UP to further improve the privacy-cost tradeoff. Two privacy-preserving energy management policies (EMPs) are proposed, which differ in the way the target load profile is characterized. Additionally, a simplified and more practical EMP, which optimizes the energy management less frequently, is considered. Numerical results are presented to compare the performances of these EMPs in terms of the privacy-cost tradeoff they achieve, considering a number of privacy indicators.	constant function;load profile;low-pass filter;mathematical optimization;mean squared error;numerical analysis;numerical method;offset binary;performance;privacy;simulation;smart meter	Giulio Giaconi;Deniz Gündüz;H. Vincent Poor	2018	CoRR		mathematical optimization;electrical battery;automotive engineering;smart grid;metering mode;mathematics;energy management;load profile;electricity;smart meter;energy storage	AI	3.7477129666145537	4.167124532491372	117152
1d91f58b70cc122d1805aa6066d7874d7e8ff6c6	analyzing losses from hazard exposure: a conservative probabilistic estimate using supply chain risk simulation	markov processes;monte carlo methods;risk analysis;supply chain management;monte carlo simulation;business interruption costs;conservative probabilistic estimation;generalized semi-markov process;hazard exposure;insurance coverage limits;probability distribution;risk events;stochastic risk modeling;supply chain losses;supply chain network design;supply chain risk simulation	We present a supply chain risk analysis that is based on a Monte Carlo simulation of a Generalized Semi-Markov Process (G.S.M.P.) model. Specifically, we seek to estimate the probability distribution of supply chain losses caused by disruptions. This distribution is computed conditional on conservative hypotheses which are the following: (1) no additional risk reduction measures are implemented beyond those already in place, (2) all the products whose production has been canceled are counted as losses at their market value. The simulation thus yields conditional probabilities of loss levels that firms may reasonably use in the evaluation of business interruption costs and insurance coverage limits. The model also enables the comparison of supply chain designs based on their resilience in recovering from risk events. The approach is novel for it connects stochastic modeling of risks from an insurance perspective with supply chain network design.	interrupt;monte carlo method;network planning and design;simulation;stochastic modelling (insurance);supply chain network	Léa A. Deleris;Debra A. Elkins;Marie-Elisabeth Paté-Cornell	2004	Proceedings of the 2004 Winter Simulation Conference, 2004.		reliability engineering;supply chain management;mathematics;statistics;monte carlo method	ML	1.9052024326377728	-9.422280974090025	117498
404d3531dbd484f3a79e1a4d2421a0de3ac85c46	r&d investment decision on emerging technology	investment decision;r d investment;22e46;emerging technology;real options;rare event;market driven innovation;r d;hazard rate;real option;growth rate;profitability;57s20;53c35;technology driven innovation	The prosperity of emerging technology may be triggered by the occurrence of rare events, and once emerging technology booms, there may be an enormous market demand for it. This paper explores the firm's commercial and R&D investment decisions on emerging technology in real options framework. We think that, for the fear that a rare event which occurs prior to R&D success would trigger the emerging technology boom, the firm should carry out prospective R&D in the emerging technology innovation. So the impacts of the R&D hazard rate and the intensity of rare event arrival on the prospective R&D investment strategy are mainly addressed. There are two results. First, the firm is most likely to take the strategy at low, rather than high, probability of technological boom in market-driven innovation. Second, in technology-driven innovation, the huge potential profit of emerging technology in booming period can arouse more attention toward the firm. When the growth rate of profit flow in booming period rises to some degree, the firm may take this strategy unconditionally.		Guang-Jun Deng;Yong Zeng	2011	International Journal of Information Technology and Decision Making	10.1142/S0219622011004403	economics;computer science;artificial intelligence;marketing;operations management;finance;economy;hazard ratio;emerging technologies;management;commerce;profitability index	EDA	-0.4704083789108964	-8.544831553134967	117766
37a58f41ce1a0935dfb94b7218929b4bcb676154	super solutions for combinatorial auctions	constraint satisfaction problem;combinatorial auction	Super solutions provide a framework for finding robust solutions to Constraint Satisfaction Problems [5, 3]. We present a novel application of super solutions to combinatorial auctions in which a bid may be disqualified or withdrawn after the winners are announced. We examine the effectiveness of super solutions in different auction scenarios that simulate economically motivated bidding patterns. We also analyze the drawbacks of this approach and motivate an extension to the framework that permits a more flexible and realistic approach for determining robust solutions.	anytime algorithm;auction algorithm;computation;constraint satisfaction;scalability;simulation	Alan Holland;Barry O'Sullivan	2004		10.1007/11402763_14	mathematical optimization;combinatorial auction;economics;microeconomics;mathematical economics	AI	-2.292097594821914	-1.910520223690541	117791
98cfa4e6861d6ca0bf811146d4ceaa698e761efc	lqg dynamic games with a control-sharing information pattern		“Zero-sum” linear-quadratic Gaussian dynamic games (LQGDGs) where the players have partial information are considered. The players’ initial state information and their measurements are private information, but each player is able to observe his antagonist’s past inputs: The protagonists’ past controls are shared information. Although this is a game with partial information, the control-sharing information pattern renders the game amenable to solution by Dynamic Programming. Three Riccati equations and a Lyapunov equation must be solved. The solution of LQGDGs with a control-sharing information pattern is obtained in closed-form.		Meir Pachter	2017	Dynamic Games and Applications	10.1007/s13235-016-0182-6	bayesian game;mathematical optimization;information set;control theory;mathematics;screening game;sequential game;complete information;interaction information	HCI	0.28618548897558216	-0.5045464554955119	117918
10d9f4c2f8e53e659c4924a4e0fd2b6a10e782a4	the option value of returns: theory and empirical evidence	returns;structural model;hierarchical bayes analysis;e commerce;econometric model;costs and benefits;latent variable models;latent variable model;empirical evidence;marketing operations interface;targeting;econometric models;choice models;decision under uncertainty;decisions under uncertainty;option value;consumer behavior;direct marketing;service quality;hierarchical bayes	W a firm allows the return of previously purchased merchandise, it provides customers with an option that has measurable value. Whereas the option to return merchandise leads to an increase in gross revenue, it also creates additional costs. Selecting an optimal return policy requires balancing both demand and cost implications. In this paper, we develop a structural model of a consumer’s decision to purchase and return an item that nests extant choice models as a special case. The model enables a firm to both measure the value to consumers of the return option and balance the costs and benefits of different return policies. We apply the model to a sample of data provided by a mail-order catalog company. We find considerable variation in the value of returns across customers and categories. When the option value is large, there are large increases in demand. For example, the option to return women’s footwear is worth an average of more than $15 per purchase to customers and increases average purchase rates by more than 50%. We illustrate how the model can be used by a retailer to optimize his return policies across categories and customers.	concave function;fo (complexity);incidence matrix;purchasing;return statement	Eric T. Anderson;Karsten Hansen;Duncan Simester	2009	Marketing Science	10.1287/mksc.1080.0430	e-commerce;financial economics;economics;marketing;asian option;internal rate of return;microeconomics;return of capital;investment performance;econometric model;consumer behaviour;statistics	Metrics	-0.5394094845927974	-7.2584153086516405	117931
e00d100ce9ee3194fe40e5e2234f417747efd8f1	notice of retractionsupply chain coordination of emergency event	supply chain profit;game theory;market demand;market demand scale;costing;coordination mechanisms;supply chain management costing game theory macroeconomics profitability purchasing risk management;risk management;stackelberg game;biological system modeling;supply chains;linear functionals;purchasing;cost of production;adaptation model;emergency event;retailer s purchase costs;disruption strategy;lead;macroeconomics;number of factors;supply chain coordination disruption market demand scale retailer s purchase costs;games;disruption;stackelberg game leader;disruption management;retailer purchase costs disruption supply chain coordination emergency event disruption management market demand disruption strategy supply chain profit stackelberg game leader;supply chain;profitability;retailer purchase costs disruption;economics;supply chains economics biological system modeling lead adaptation model games;supply chain coordination;supply chain management	Most of papers of disruption management of supply chain were based on the assumption that only a single factor was disrupted. But in practice, the unexpected event will inevitably lead to a number of factors disruptions in the supply chain system. This paper considers the scale of market demand and retailer's purchase costs disruptions in the disruption management of supply chain. When demand is a linear function of the price, the manufacturer's cost of production is a convex of retailers deviate at the same time, a disruption strategy is proposed to optimize the supply chain profit. When manufacture is the Stackelberg game leader, the coordination mechanism is proposed to coordinate the supply chain so as to realize the maximal profit of supply chain.		Xiao Yong Lei	2010	2010 International Conference on E-Business and E-Government	10.1109/ICEE.2010.864	supply chain risk management;game theory;demand chain;supply chain management;economics;risk management;service management;marketing;bullwhip effect;operations management;microeconomics;supply chain;commerce;supply shock	Robotics	-2.088967614261487	-5.759122332066802	118163
e8487cc744918fcaf96a7cbec6b1e004d8f05893	competitive remanufacturing strategy and take-back decision with oem remanufacturing	game theory;remanufacturing;take back;supply chain management	Consumer desire for environment-friendly and economical products drives original equipment manufacturers (OEMs) to offer remanufactured products. Thus, OEMs compete with independent remanufacturers (IRs) not only in sales but also in collection of used items for remanufacturing. In this paper, we develop a closed-loop supply that consists with an OEM that sells new and remanufactured products and an IR. Each firm is endowed with two remanufacturing strategies that drive economies of remanufacturing by sales or collection. We then elaborate the relation between the firms’ decisions and the remanufacturing strategies, and further derive the equilibrium decisions and strategic schemes. We find that OEM remanufacturing provides the OEM with the variability to respond to changes of competitive scenarios by allocating sales between new and OEM-remanufactured products, compelling the IR to react differently. We further show the conditions for firms to determine their profitable strategies, and characterize the firms’ equilibrium strategic choices and operational decisions. This study provides managerial insights for OEM and IR managers in terms of firms’ equilibrium behavior. 2016 Elsevier Ltd. All rights reserved.	consistency model;entity–relationship model;game theory;heart rate variability;interaction;nash equilibrium;purchasing;scheme;value (ethics)	Chao-Hsin Wayne Wu;Hsin-Huan Wu	2016	Computers & Industrial Engineering	10.1016/j.cie.2016.05.033	game theory;supply chain management;marketing;operations management;commerce	ECom	-0.21203612587755427	-5.856057036608579	118243
ece167759bd12bf7a5f21e1c511e5199007af532	an ldqbd process under degradation, inspection, and two types of repair	systeme avec reserve;optimisation;degradation;ldqbd process;optimizacion;availability;processus naissance mort;disponibilidad;quasi birth and death;sistema con reserva;preventive and corrective repair;inspection;optimization problem;proceso nacimiento muerte;rupture;defaillance;reparation;phase type distribution;optimization;standby system;failures;birth death process;reparacion;disponibilite;fallo;ruptura;repair	A warm standby n-system with operational and repair times following phase-type distributions is considered. The online unit goes through degradating levels, determined by inspections. Two types of repairs are performed, preventive and corrective, depending on the degradation level. The standby units undergo corrective repair. This systems is governed by a level-dependent-quasi-birth-and-death proces (LDQBD process), whose generator is constructed. The availability, rate of occurrence of failures, and other quantities of interest are calculated. A numerical example including an optimization problem and illustrating the calculations is presented. This system extend other previously studied in the literature.	elegant degradation	Delia Montoro-Cazorla;Rafael Pérez-Ocón	2008	European Journal of Operational Research	10.1016/j.ejor.2007.04.056	optimization problem;availability;mathematical optimization;degradation;inspection;operations management;mathematics;phase-type distribution;birth–death process;statistics	Robotics	6.623324621114406	-1.5247622070606315	118316
b70732d689269a31ff20aba87a25ef7154a57c0d	equilibrium dynamics in a two-sector model with taxes	tax competition;dynamic instability;distortionary taxes;journal of economic literature;competitive equilibrium;endogenous growth;non interior equilibrium orbit;steady state	In this paper we are concerned with the equilibrium dynamics of a two-sector model of endogenous growth with distortionary taxes. We show that for certain parameters values and tax schemes every equilibrium orbit--except the steady state solution--is non-interior; i.e., there are times in which one of the sectors is inactive. This analysis confirms that in multisector models the set of easily checkable, universal conditions that can guarantee the interiority of equilibrium solutions is rather limited.		Salvador Ortigueira;Manuel S. Santos	2002	J. Economic Theory	10.1006/jeth.2001.2843	partial equilibrium;economics;public economics;endogenous growth theory;macroeconomics;microeconomics;market economy;steady state	ECom	-3.4396220179777934	-4.87554147242864	118337
bb3fb0167a1a99dbf84c54f3003db1b387f9cb4a	multi-item replenishment and storage problem (mirsp): heuristics and bounds	analysis of algorithms worst case bounds;deterministic models eoq with annual linear cost for storage space;modelo determinista;heuristic method;metodo heuristico;modele deterministe;inventory production;administracion deposito;horizonte infinito;horizon infini;economic order quantity;almacenamiento;entreposage;warehousing;aprovisionamiento;stockage;gestion stock;approvisionnement;quantite economique a commander;infinite horizon;supply;methode heuristique;cantidad economica pedida;deterministic model;inventory control;storage;inventory production storage space requirement in automated warehouses	JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of content in a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org. INFORMS is collaborating with JSTOR to digitize, preserve and extend access to Operations Research.	archive;heuristic;institute for operations research and the management sciences	Shoshana Anily	1991	Operations Research	10.1287/opre.39.2.233	supply;inventory control;mathematical optimization;economic order quantity;economics;marketing;operations management;deterministic system;operations research;welfare economics;warehouse	HCI	5.286427135622217	-3.2578076167133405	118547
0758af8dc9cb5a173ef74fee80385b0c29041059	nash and integrated solutions in a just-in-time seller-buyer supply chain with buyer's ordering cost reductions	integrated solution;order cost reduction;trade credit;inventory;just in time;nash solution	Nash and integrated solutions in a just-in-time seller–buyer supply chain with buyer's ordering cost reductions Kuo-Ren Lou & Lu Wang To cite this article: Kuo-Ren Lou & Lu Wang (2014): Nash and integrated solutions in a just-intime seller–buyer supply chain with buyer's ordering cost reductions, International Journal of Systems Science, DOI: 10.1080/00207721.2014.942243 To link to this article: http://dx.doi.org/10.1080/00207721.2014.942243	lu decomposition;nash equilibrium;systems science;wang tile	Kuo-Ren Lou;Lu Wang	2016	Int. J. Systems Science	10.1080/00207721.2014.942243	inventory;credit note	Embedded	2.8475054950933485	-7.4748783856921595	118756
2118c4e6e1395eb1a03ac091d434d6b6eb3d17a3	cost of ownership model for spare engines purchase for the korean navy acquisition program	modelizacion;forecasting;cost estimation model;fiabilidad;reliability;durabilite;initial cost;project management;temps rupture;information systems;compra;maintenance;porcentaje falla;procurement;estimation cout;soft or;information technology;durabilidad;packing;defense nationale;break up time;maintenance cost;tiempo vida;taux defaillance;weapon;contrato;operations research;location;investment;journal;journal of the operational research society;inventory;purchasing;modelisation;tiempo ruptura;history of or;efecto aleatorio;lifetime;logistics;durability;marche contrat;random effect;marketing;scheduling;fiabilite;national defence;costo manutencion;estimacion costo;presupuesto;arma;reparation;production;communications technology;failure rate;achat;defensa nacional;cost of ownership;budget;random effects model;computer science;operational research;methode domaine temps frequence;cost estimation;duree vie;arme;reparacion;effet aleatoire;cout acquisition;modeling;metodo dominio tiempo frecuencia;weapon system acquisition;applications of operational research;or society;purchases;jors;management science;time frequency domain method;infrastructure;repair;cout entretien;costo adquisicion	Major weapon system acquisition programmes often require high initial purchase cost which can be a burden for the procurement of a highly reliable system. In order to avoid the tendency of acquiring a less expensive weapon system with lower performance, a cost of ownership (COO) model can be applied to assess the lifetime cost of the weapon system. In many existing cost estimation models for weapon systems, the failure rate of the system is assumed to be constant and the functional relationship between the initial purchase cost and maintenance cost is not well defined. In this paper, we propose a revised COO model where random effects models are employed to accommodate the variations of the system failure frequency and repair time. It is expected that our model can contribute to the cost-effective procurement of spare engines for the Korean Navy acquisition programme within the limited national defence budget. Journal of the Operational Research Society (2009) 60, 1674–1682. doi:10.1057/jors.2008.147 Published online 17 June 2009	analysis of algorithms;failure rate;limited availability;money;procurement;random effects model;total cost of ownership	S. Y. Sohn;Y. Kim;B. T. Kim	2009	JORS	10.1057/jors.2008.147	project management;relevant cost;simulation;economics;marketing;operations management;operations research;information technology;statistics;random effects model	AI	6.2077555243246225	-3.8398892194050176	118761
26ae534b6622befae1d87561f597e7be36c8b700	prospect theory and market quality		We study equilibrium trading strategies and market quality in an economy in which speculators display preferences consistent with Prospect Theory (Kahneman and Tversky, [39]; Tversky and Kahneman, [63]), i.e., loss aversion and mild risk seeking in losses. Loss aversion (risk seeking in losses) induces speculators to trade less (more), and less cautiously (more aggressively), with their private information – but also makes them less (more) inclined to purchase private information when it is costly – in order to mitigate (enhance) their perceived risk of a trading loss. We demonstrate that these forces have novel, nontrivial, state-dependent effects on equilibrium market liquidity, price volatility, trading volume, market efficiency, and information production. © 2013 Elsevier Inc. All rights reserved. JEL classification: D82; G14	algorithmic trading;personally identifiable information;price point;risk aversion;volatility	Paolo Pasquariello	2014	J. Economic Theory	10.1016/j.jet.2013.09.010	financial economics;prospect theory;adverse selection;volatility;economics;finance;macroeconomics;efficiency;microeconomics;market liquidity;algorithmic trading	AI	-2.6250512630963474	-7.073251648660497	118793
aae5d562bb5f76c322d070b480feb62a99029324	broadband investment and welfare under functional and ownership separation	vertical integration;vertical separation;access pricing;high speed broadband;quality investment	We study how the vertical industry structure affects investment in network quality and social welfare, with a focus on the prospective deployment of high-speed broadband access networks (the so-called NGA). We model pros and cons of vertical separation, namely, procompetitive effects and loss of some efficiencies of vertical integration, and distinguish functional separation from ownership separation. Our findings challenge the presumption that (compared with vertical integration) vertical separation reduces investment incentives and involves a trade-off between promoting consumer surplus and ensuring investment. While investment is higher under ownership rather than functional separation, the latter may yield the highest social welfare among vertical industry structures. Furthermore, the incumbent may voluntarily opt for functional separation, but in some of these cases, prohibiting separation improves welfare. 2014 Elsevier B.V. All rights reserved.	access network;internet access;next-generation access;prospective search;software deployment	Alessandro Avenali;Giorgio Matteucci;Pierfrancesco Reverberi	2014	Information Economics and Policy	10.1016/j.infoecopol.2014.07.003	industrial organization;vertical integration;economics;marketing;microeconomics;labour economics	PL	-2.2890714557553222	-7.2811801551314135	118807
b446d4bb4e7afcf5c7154fc7bbf3962a5d87a0f9	enhancing graphical simulation output using cluster analysis	cluster algorithm;aerospace;free flight;simulation;traffic flow;federal aviation administration;cluster analysis;clustering;optimal routing;process development;figure of merit;modeling;simulation model;air route structure;air traffic management	Recent work performed for the Federal Aviation Administration to support the development of future concepts of air traffic management has involved simulation modeling of patterns of airspace usage by commercial and business air traffic. 1) The objective of these efforts has been to investigate the impacts of a pattern of airspace usage known as “free flight”, whereby pilots and flight dispatchers have much more freedom to choose, say, direct or wind-optimal routing through airspace. One of the figures of merit investigated is a count of “convergence pairs” as a measure of the complexity of various traffic patterns. These are cases when aircraft in the simulation model fly close to each other. Interestingly, geographic plots of convergence pairs accumulated over time bring out certain features or patterns of congested air traffic flows or flight alignments. However, these plots are also thick with “noise” or extraneous convergence pairs, whose presence detracts from the ability to perceive congested air traffic flows. Cluster analysis has been found to be an effective method of filtering these displays so that the congested flow features are discernible. The process developed for this purpose is based on a two-pass clustering approach. The process has worked well for the simulation modeling performed to date. Classification of the locations of convergence pairs into congested flow corridors is visually appealing, and has helped distinguish differences in contrasting scenarios of airspace usage. The paper presents graphical results and describes the clustering algorithms employed.	adaptive filter;algorithm;artificial neural network;cluster analysis;effective method;formal concept analysis;graphical user interface;routing;simulation	James DeArmon	1997	Annals OR	10.1023/A:1018986808246	free flight;simulation;computer science;operations management;cluster analysis	ML	9.916780128300292	-9.038576540598266	118822
6010d15f3087b1a424d8ce144fa52987119b2b0b	integer programs for margining option portfolios by option spreads with more than four legs	spread;arbitrage;margin;homomorphism;option	Margining is a crucial brokerage operation. In application to option portfolios it becomes exceptionally challenging because margin offsets with options require solving a highly intractable integer program. All these offsets are based on option spreads with a maximum of four legs. Although option spreads with more than four legs can be traced in regulatory literature of 2003, they have not yet been studied and used. Their usage in margin calculations would substantially increase the size of the program and therefore make it practically unsolvable. On the other hand, option spreads with more than four legs would allow the brokers to substantially increase the accuracy of margin calculations for option portfolios. In this paper we develop a theoretical framework for option spreads with any number of legs. We show that these spreads can be naturally described by homomorphisms of free abelian groups associated with option portfolios and option spreads with up to four legs. Using this observation we propose alternative integer programs that use option spreads with any number of legs and whose size does not depend on the number of legs. These programs can be solved in reasonable time and substantially increase the accuracy of margin calculations for option portfolios. Copyright Springer-Verlag Berlin Heidelberg 2013	linear programming	Dmytro Matsypura;Vadim G. Timkovsky	2013	Comput. Manag. Science	10.1007/s10287-012-0159-x	homomorphism;financial economics;margin;spread trade;actuarial science;economics;asian option;machine learning;mathematics;arbitrage;commerce	Theory	-2.679435419977296	-3.2774714648449224	118880
57b1ebbaa8fc2373bba37e742011534586d0ab00	managing wip and cycle time with the help of loop control	integrated circuit manufacture;production management;work in progress;amd dresden fabs;conwip concept;thp-limit;wip-limit;cycle time;dynamic constraints;fab dispatching system;fab simulation study;loop control;managing wip;wafer fabrication facility;work in progress	"""As an adaptation of the CONWIP concept, AMD has developed a heuristic approach to control the WIP in its wafer fabrication facilities (fabs). The so called """"Loop Control"""" concept helps to utilize the installed equipment in an efficient way and reduces the overall cycle time. Two dynamic constraints (the WIP-Limit and the THP-Limit) are defined to limit the WIP (work in progress) per photo layer and to tackle high WIP situations at individual operations inside a photo layer. Loop Control has been evaluated with help of a fab simulation study prior to implementation in the fab dispatching system. Since its development three years ago, this system operates successfully in the AMD Dresden fabs."""	heuristic;semiconductor fabrication plant;simulation;wafer fabrication	Steffen Kalisch;Robert Ringel;Jörg Weigang	2008	2008 Winter Simulation Conference		simulation;cycle time variation;engineering;industrial engineering;work in process;mean squared error;manufacturing engineering	Robotics	10.020379643088642	4.125255469329554	118986
71ca98b44c0b42d6cbfc77964dbc3bcb14cc3898	the value of advance demand information in production/inventory systems	production inventory systems;advance demand information;base stock policies;make to stock queue;make to stock	Advance demand information, when used effectively, improves the performance of production/inventory systems. In this paper, we investigate the value of advance demand information in production/inventory systems. For a single-stage make-to-stock queue, we assess the value of using advance demand information under a variety of assumptions on the cost of obtaining advance demand information, and the delivery timing requirements. This analysis enables us to identify conditions under which advance demand information may bring significant benefits.	load (computing);requirement;schedule (computer science)	Fikri Karaesmen;George Liberopoulos;Yves Dallery	2004	Annals OR	10.1023/B:ANOR.0000012278.41301.24	economics;demand forecasting;build to stock;perpetual inventory;operations management;demand management;microeconomics;commerce	Metrics	1.853342082184291	-6.856191079399681	119058
a38e0059cfd801a7837f889b84ed7a4e5516ce1e	welfare of sequential allocation mechanisms for indivisible goods		Sequential allocation is a simple and attractive mechanism for the allocation of indivisible goods used in a number of real world settings. In sequential allocation, agents pick items according to a policy, the order in which agents take turns. Sequential allocation will return an allocation which is Pareto efficient – no agent can do better without others doing worse. However, sequential allocation may not return the outcome that optimizes the social welfare. We consider therefore the relationship between the welfare and the efficiency of the allocations returned by sequential allocation mechanisms. We then study some simple computational questions about what welfare is possible or necessary depending on the choice of policy. Over half the problems we study turn out to be tractable, and we give polynomial time algorithms to compute them. We also consider a novel control problem in which the Chair chooses a policy to improve social welfare. Again, many of the control problems we study turn out to be tractable, and our results give polynomial time algorithms. In this case, tractability is a good thing so that the Chair can improve the social welfare of the allocation.	algorithm;cobham's thesis;computation;indivisible;multi-armed bandit;pareto efficiency;polynomial;recursion;time complexity	Haris Aziz;Thomas Kalinowski;Toby Walsh;Lirong Xia	2015		10.3233/978-1-61499-672-9-787	computer science;mathematical optimization;welfare economics;social welfare;welfare	AI	-2.176412927113811	0.1774488143921735	119097
dc692b172e16392627b032b73466fbac749732ae	stochastic control in optimal portfolio with regime switching model	stopping time stochastic control optimal portfolio;optimisation;random regime switching model;banking;stock market;brownian motion;regime switching;volatility rate;investment;utility maximization;stock markets;interest rate;markov chain modulated diffusion formulation;optimal control;utility theory banking brownian motion economic indicators investment markov processes optimal control optimisation random processes stochastic systems stock markets;optimal;bank interest rate;random processes;stochastic processes optimal control portfolios economic indicators investments educational institutions information technology finance information analysis switches;stochastic control;value function;stopping time;markov processes;stochastic systems;regime switching model;verification theorem;portfolio;optimal portfolio;martingale optimality principle;portfolio stochastic control theory;optimal portfolio stock market bank interest rate volatility rate random regime switching model brownian motion markov chain modulated diffusion formulation portfolio stochastic control theory martingale optimality principle optimal control verification theorem value function utility maximization;utility theory;economic indicators;markov chain	Portfolio stochastic control problem is proposed and analyzed for a market consisting of one bank account and multiple stocks. The market parameters, including the bank interest rate and the appreciation and volatility rates of the stocks, depend on the market mode that switches among a finite number of states. The random regime switching is assumed to be independent of the underlying Brownian motion. This essentially renders the underlying market incomplete. A Markov chain modulated diffusion formulation is employed to model the problem. Using techniques of stochastic control theory and martingale optimality principle, a general verification theorem is obtained. Applying the verification theorem, the optimal control and value functions for the problems of utility maximization are derived explicitly.	brownian motion;control theory;entropy maximization;formal verification;markov chain;modulation;network switch;optimal control;rendering (computer graphics);stochastic control;volatility	Shuping Wan	2006	2006 9th International Conference on Control, Automation, Robotics and Vision	10.1109/ICARCV.2006.345087	stochastic process;markov chain;optimal control;stochastic control;investment;stopping time;interest rate;brownian motion;mathematics;statistics	Robotics	1.6240304851320695	-1.5001043656732411	119170
458f0676ffe9b5f6c8b00372949790ba51a5e8d9	transient analysis of machining systems with service interruption, mixed standbys and priority	markovian model;priority queues;neural networks;availability;mixed standbys;neuro fuzzy inference;machine repair system;spares;transient analysis;fuzzy logic;priority queue;neuro fuzzy;service interruption;queue size;reliability analysis;machine repair systems;machining systems;transient;runge kutta method	Spare support plays an important role in improving the reliability of multi-component repairable machining systems in many industries as well as in day-to-day real-time embedded systems. This paper is concerned with the reliability analysis of embedded machining system consisting of two types of units along with warm and cold standbys support under the priority concepts. The Markov model is developed by constructing the transient equations using birth death process. Various queueing and reliability performance measures are established in terms of transient probabilities of the system states which are evaluated using numerical technique based on Runge-Kutta method. To illustrate the tractability of the proposed method, a numerical example is worked out. Further neuro-fuzzy inference approach is employed to compare some performance indices which are also obtained numerically.	interrupt	Madhu Jain	2013	IJMOR	10.1504/IJMOR.2013.056117	real-time computing;computer science;operations management;machine learning;priority queue;artificial neural network	HPC	6.7829873743694	0.21052723235760398	119208
6ad7f65981dda1c3d59c22883eca237b92e584a5	credit risky securities valuation under a contagion model with interacting intensities	continuous time;change of measure;common factor;discrete time;credit default swap;counterparty risk;analytic solution;density functional	We study a three-firm contagion model with counterparty risk and apply this model to price defaultable bonds and credit default swap CDS . This model assumes that default intensities are driven by external common factors as well as other defaults in the system. Using the “total hazard” approach, default times can be generated and the joint density function is obtained. We represent the pricing method of defaultable bonds and obtain the closed-form pricing formulas. By the approach of “change of measure,” analytical solutions of CDS swap rate swap premuim are derived in the continuous time framework and the discrete time framework, respectively.		Anjiao Wang;Zhongxing Ye	2011	J. Applied Mathematics	10.1155/2011/158020	closed-form expression;credit default swap index;discrete time and continuous time;actuarial science;credit risk;mathematics;itraxx;credit default swap;credit valuation adjustment	AI	1.6227490723909015	-9.61336502935959	119263
244d4cb8b52db510393462aeb22fe39d12648c1a	dynamic pricing in high-dimensions	revenue management;high dimensional regression;maximum likelihood;dynamic pricing;sparsity;hypothesis testing	We study the pricing problem faced by a firm that sells a large number of products, described via a wide range of features, to customers that arrive over time. This is motivated in part by the prevalence of online marketplaces that allow for real-time pricing. We propose a dynamic policy, called Regularized Maximum Likelihood Pricing (RMLP), that obtains asymptotically optimal revenue. Our policy leverages the structure (sparsity) of a high-dimensional demand space in order to obtain a logarithmic regret compared to the clairvoyant policy that knows the parameters of the demand in advance. More specifically, the regret of our algorithm is of O(s0 logT (log d+ logT )), where d and s0 correspond to the dimension of the demand space and its sparsity. Furthermore, we show that no policy can obtain regret better than O(s0(log d+ logT )).	asymptotically optimal algorithm;online marketplace;real-time transcription;regret (decision theory);sparse matrix;variable pricing	Adel Javanmard;Hamid Nazerzadeh	2016	CoRR		econometrics;mathematical optimization;statistical hypothesis testing;mathematics;maximum likelihood;sparsity-of-effects principle;statistics	ML	1.1304927920741084	-3.546601915626609	119474
0717959471e65cb473e91748bdeeb6d1c0ee8fb4	robust timing of markdowns	pricing under uncertainty;robust optimization;uncertainty arrival rates;dynamic policies;markdowns	We propose an approach to the timing of markdowns over a finite time horizon that does not require the precise knowledge of the underlying probabilities, instead relying on range forecasts for the arrival rates of the demand processes, and that captures the degree of the manager’s risk aversion through intuitive budget of uncertainty functions. These budget functions bound the cumulative deviation of the arrival rates from their nominal values over the lengths of time for which a product is offered at a given price. A key issue is that using lengths of time as decision variables introduces non-convexities when budget functions are strictly concave; concavity is a common assumption in the robust optimization literature and therefore must be incorporated in a tractable manner. In the single-product case, we describe a tractable and intuitive framework to incorporate uncertainty on customers’ arrival rates, formulate the resulting robust optimization model, describe an efficient procedure to compute the optimal sale times, and provide theoretical insights. We then describe how to use the solution of the static robust optimization model to implement a dynamic markdown policy. We also extend the robust optimization approach to multiple products and suggest the idea of constraint aggregation to preserve performance in robust revenue management for this type of problem structure. Numerical results are very encouraging.	aggregate data;approximation;cobham's thesis;computational complexity theory;concave function;convex optimization;mathematical optimization;nonlinear system;numerical method;optimization problem;piecewise linear continuation;price point;risk aversion;robust optimization	Michael Dziecichowicz;Daniela Caro;Aurélie Thiele	2015	Annals OR	10.1007/s10479-015-1913-6	mathematical optimization;robust optimization;economics;operations management;mathematics;welfare economics;statistics	ML	3.2069552094649487	-3.635021772727572	119627
023fcff577e3e2ac9e7f0735b40e1264bd59ac27	a simple and approximately optimal mechanism for an additive buyer	simple mechanisms;approximation;revenue;optimal mechanisms	In this letter we briefly survey our main result from [Babaioff el al. 2014]: a simple and approximately revenue-optimal mechanism for a monopolist who wants to sell a variety of items to a single buyer with an additive valuation.	additive model;utility functions on indivisible goods;value (ethics)	Moshe Babaioff;Nicole Immorlica;Brendan Lucier;S. Matthew Weinberg	2014	2014 IEEE 55th Annual Symposium on Foundations of Computer Science	10.1145/2728732.2728736	financial economics;economics;approximation;microeconomics;mathematical economics;revenue	Theory	-2.6908990503559136	-1.743896726277627	119724
46ea04a4d0f0ef6349fc3cd2efc77336fe8e3a15	optimal choice of health and retirement in a life-cycle model	life cycle model;annuities;moral hazard;optimal control;demand for health;health;retirement;value of life	We examine within a life-cycle set-up the simultaneous choice of health care and retirement (together with consumption), when health care contributes to both a reduction in mortality and in morbidity. Health tends to impact on retirement via morbidity, determining the disutility of work, and through longevity, determining the need to accumulate retirement wealth. In contrast, the age of retirement drives health through changes in the value of survival and the value of morbidity reductions. We apply our ∗This research was financed by the European Commission under grant SSH-2007-3.1.01217275 (Long-Run Economic Perspectives of Ageing Societies.) †Austrian Academy of Sciences, Vienna Institute of Demography / Wittgenstein Centre, Wohllebeng. 12-14, A-1040 Vienna, Austria (michael.kuhn@oeaw.ac.at) ‡Institute of Mathematical Methods in Economics (Research Unit on Operations Research and Control Systems), Vienna University of Technology, Argentinierst. 8, A-1040 Vienna, Austria; and Austrian Academy of Sciences, Vienna Insitute of Demography / Wittgenstein Centre (wrzaczek@server.eos.tuwien.ac.at) §Institute of Mathematical Methods in Economics (Research Unit on Economics), Vienna University of Technology; and Austrian Academy of Sciences, Vienna Institute of Demography / Wittgenstein Centre (afp@econ.tuwien.ac.at) ¶Institute of Mathematical Methods in Economics (Research Unit on Operations Research and Control Systems), Vienna University of Technology; and Austrian Academy of Sciences, Vienna Institute of Demography / Wittgenstein Centre (gustav@eos.tuwien.ac.at)	cobham's thesis;distortion;donald becker;moral hazard;numerical analysis;ps-algol;perf (linux);proxy server;software development process;utility	Michael Kuhn;Stefan Wrzaczek;Alexia Prskawetz;Gustav Feichtinger	2015	J. Economic Theory	10.1016/j.jet.2015.04.006	actuarial science;optimal control;economics;health;welfare economics;labour economics	HCI	0.6476378188313364	0.42576610277625315	119759
473d77b23c4a1469e7c6a0b4d65b6ce355586d73	a flexible model for tree-structured multi-commodity markets	market equilibrium;power market;resource allocation;electronic markets;bandwidth markets;power markets;computational markets;multi commodity markets;computational complexity;single unit;tree structure;polynomial time;datavetenskap datalogi;computer science;winner determination problem;equilibrium markets;combinatorial auction	In this article we study tree-structured multi-commodity markets. The concept is a way to handle dependencies between commodities on the market in a tractable way. The winner determination problem of a general combinatorial market is well known to be NP-hard. It has been shown that on single-unit single-sided auctions with tree-structured bundles the problem can be computed in polynomial time. We show that it is possible to extend this to multi-unit double-sided markets. Further it is possible to handle the commodities of a bundle not only as complements but as perfect substitutes too. Under certain conditions the computation time is still polynomial.	cobham's thesis;complement (complexity);computation;np-hardness;polynomial;time complexity;tree (data structure)	Per Carlsson;Arne Andersson	2007	Electronic Commerce Research	10.1007/s10660-006-0063-Y	financial economics;time complexity;combinatorial auction;economics;resource allocation;computer science;microeconomics;tree structure;computational complexity theory;commerce	ECom	-2.677735586725643	-0.5543959315594883	120005
5b4552e8cbd1d040d3926ab20ac4be70ce0a49c5	forest harvest scheduling with endogenous road costs		The Washington State Department of Natural Resources (DNR) manages over 800,000 hectares of forested state trust lands and 20,000 kilometers of forest roads in Washington State. Forest harvest and road reconstruction decisions greatly impact the agency’s cash flows and its ability to meet its fiduciary obligations. We introduce a mixed-integer programming model that integrates harvest and road scheduling decisions. We show how DNR embedded the new model in its workflows and applied it to the Upper Clearwater River Landscape in the Olympic Experimental State Forest. We find that the forest valuation of the Upper Clearwater increased by $0.5–$1 million (0.4–1.1 percent) because of the new method, which allowed the DNR to concentrate capital expenditures in support of harvest and road operations in both time and space. This led to a 14.5 percent reduction in the size of the active road network. DNR is now in the process of scaling the new approach to the entire forest estate.	ibm 7950 harvest	Kai L. Ross;Sándor F. Tóth;Weikko S. Jaross	2018	Interfaces	10.1287/inte.2017.0926	kilometer;operations management;hectare;engineering;forestry;valuation (finance);capital expenditure;state forest;estate;fiduciary;natural resource	HCI	9.256632092211676	-4.697519294033862	120021
79750ed29c5ee71fc56d6c6292965c01e9a91e02	measuring default risk in a parallel alm software for life insurance portfolios	reduced form models;high performance computing;life insurance policies;asset liability management;credit risk	"""In this paper we investigate the computational issues in the use of a stochastic model - the doubly stochastic intensity default model - to measure default risk in the development of """"internal models"""", according to the new rules of the Solvency II project. We refer to the valuation framework used in DISAR, an asset-liability management system for the monitoring of portfolios of """"Italian style"""" profit sharing life insurance policies with minimum guarantees. The computational complexity of the overall valuation process requires both efficient numerical algorithms and high performance computing methodologies and resources. Then, to improve the performance, we apply to DISAR a parallelisation strategy based on the distribution of Monte Carlo simulations among the processors of a last generation blade server."""		Stefania Corsaro;Zelda Marino;Francesca Perla;Paolo Zanetti	2010		10.1007/978-3-642-21878-1_58	supercomputer;credit risk	SE	5.04745138593608	-8.485155070682872	120235
0b29da9d9e2d0e912e985e4fdb0a2777e0131adb	american option pricing with imprecise risk-neutral probabilities	sistema lineal;modelizacion;probabilidad imprecisa;volatility;non linear programming;computacion informatica;american option pricing;linear system of equations;nonlinear programming;bolsa valores;economic sciences;binomial model;programacion no lineal;prise de decision;fuzzy linear systems;programmation non lineaire;intelligence artificielle;option pricing;value analysis;probabilistic approach;linear system;financial economics;bourse valeurs;analyse valeur;stock exchange;modelisation;uncertain environment;ciencias economicas;systeme incertain;imprecise probability;tariffication;probabilite imprecise;ciencias basicas y experimentales;tarification;enfoque probabilista;option americaine;approche probabiliste;cox model;stochastic volatility;modele cox;analisis valor;model;prices;valuation;artificial intelligence;possibility theory;volatilite;sistema difuso;american option;sciences economiques;inteligencia artificial;systeme flou;systeme lineaire;volatibilidad;grupo a;toma decision;sistema incierto;european options;modeling;opcion americana;american put option;uncertain system;fuzzy system;teoria posibilidad;modelo cox;possibility distribution;tarificacion;theorie possibilite	The aim of this paper is to price an American style option when there is uncertainty on the volatility of the underlying asset. An option contract can be either European or American style depending on whether the exercise is possible only at or also before the expiry date. A European option gives the holder the right to buy or sell the underlying asset only at the expiry date of the option. On the other hand, an American option gives the holder the right to buy or sell the underlying asset at any time up to the expiry date. Therefore, in American option pricing, the likelihood of the early exercise should be carefully taken into account. American option valuation is usually performed, under the risk-neutral valuation paradigm, by using numerical procedures such as the binomial option pricing model of Cox, Ross, Rubinstein (1979). A key input of the multiperiod binomial model is the volatility of the underlying asset, that is an unobservable parameter. The volatility parameter can be estimated either from historical data (historical volatility) or implied from the price of European options (implied volatility). In the first case, the lenght of the time series, the frequency and the estimation methodology may lead to different estimates. In the second case, as options differ in strike price, time to expiration and option type (call or put), which option class yields implied volatilities that are most representative of the markets’ volatility expectations, is still an open debate. Various papers have examined the predictive power of implied volatility extracted from different option classes. Christensen and Prabhala (1998) examine the relation between implied and realized volatility on SP&100 options. They found that at the money calls are good predictors of future realized volatility. Christensen and Strunk (2002) consider the relation between implied and realized volatility on the S&P100 options. They suggest to compute implied volatility as a weighted average of implied volatilities from both in the money and out of the money options and both puts and calls. Ederington and Guan (2005) examine how the information in implied volatility differs by strike price for options on S&P500 futures. They suggest to use implied volatilities obtained from high strike options (out of the money calls and in the money puts) since the information content in implied volatilities varies roughly in a mirror image of the implied volatility smile.	algorithm;coefficient;computation;cox–ingersoll–ross model;fax;futures and promises;fuzzy number;fuzzy set;linear system;money;numerical analysis;option type;programming paradigm;risk-neutral measure;self-information;system of linear equations;time series;value (ethics);volatility	Silvia Muzzioli;Huguette Reynaerts	2008	Int. J. Approx. Reasoning	10.1016/j.ijar.2007.06.011	financial economics;system of linear equations;possibility theory;econometrics;implied volatility;stock exchange;systems modeling;imprecise probability;volatility;valuation;volatility smile;nonlinear programming;binomial distribution;artificial intelligence;asian option;trinomial tree;valuation of options;mathematics;finite difference methods for option pricing;linear system;mathematical economics;stochastic volatility;rational pricing;binomial options pricing model;proportional hazards model	AI	3.397650881709213	-6.379137332056342	120489
319d741802ae14d9ccf2470b9cc31cb88caee105	intertemporal mixed bundling strategy of information products with network externality		This paper proposes a two-period model of intertemporal mixed bundling for two information products with network externality, in which a profit-maximizing monopolist offering two information products in the first period decides the optimal time of bundle release and the adoption of “Complete My Bundle” option. “Complete My Bundle” is an option offered by App Store, with which customers can enjoy the bundle discount even if they purchase all components within the bundle in different time. We demonstrate that the seller should promptly release the bundle in the first period when network externality is moderate-to-high, or the bundle release should be delayed to the second period when network externality is low. The impact of network externality on optimally pricing individual products and bundles depends on the time of bundle release. Offering “Complete My Bundle” option is advantageous in a large number of situations when the seller makes an optimal choice for the time of bundle release. Our analysis provides insightful explanations to real-world practices of intertemporal mixed bundling strategies, and also supports the optimal choices for intertemporally bundling information products.	app store;product bundling	Xiaoxiao Luo;Minqiang Li;Haiyang Feng;Nan Feng	2017	Computers & Industrial Engineering	10.1016/j.cie.2017.09.019	industrial organization;network effect;app store;bundle;economics;microeconomics	Web+IR	-0.9995078066546457	-6.260216275998694	120491
6497d2f760051c76047942285560cbdab99b1b10	broadcast competition and advertising with free entry: subscription vs. free-to-air	free entry;subscription price;market failure;broadcast competition;regulation;advertising	Abstract   This paper develops a model of broadcast competition in the presence of free entry. In particular, it considers two alternative schemes in which broadcast stations are financed: the pay media regime under which broadcast stations are financed through subscription and advertising revenues, and the free-to-air regime under which broadcast stations are financed through advertising revenues only. It addresses the nature of market failure in the industry with respect to the provision of variety of programming and the level of advertising. Policy implications and the optimal regulation are also explored.		Jay Pil Choi	2006	Information Economics and Policy	10.1016/j.infoecopol.2005.12.002	industrial organization;regulation;economics;market failure;marketing;microeconomics;advertising;law	NLP	-0.36335705086696457	-7.285247644282585	120526
b300fb5c6e611cf2f8c6039549b229cc68f0ce4c	simulation as a tool in understanding the concepts of lean manufacturing	lean manufacturing;variabilidad;systeme evenement discret;produccion al mas justo;lean production;production process;administracion deposito;sistema acontecimiento discreto;production au plus juste;control proceso;discrete event system;takt time;process control;processus fabrication;gestion stock;variability;variabilite;inventory control;commande processus;discrete event;proceso fabricacion;kanban	This paper presents the use of discrete event simulation to understand the concepts of lean manufacturing, including line balancing against Takt time, pull versus push manufacturing, Kanban inventory control, and process variability reduction. Several simulation models were used to evaluate the impact of these lean concepts on production, work in process, and station/operator utilization.	simulation	Bernard J. Schroer	2004	Simulation	10.1177/0037549704045049	inventory control;lean project management;takt time;simulation;engineering;scheduling;lean software development;engineering drawing;kanban;lean manufacturing	Robotics	8.569525001176592	2.7688935042120266	120585
3bf2b2b466ec6db9a36487339806cbc8b5725a7d	a new biobjective probabilistic risk-based wind-thermal unit commitment using heuristic techniques	generators;uncertainty;power systems;wind power generation uncertainty informatics power systems spinning probabilistic logic generators;wind power penetration wpp;informatics;wind power penetration backtracking search algorithm bi objective optimization operation risk unit commitment;probabilistic logic;wind power generation;operation risk;unit commitment;backtracking search algorithm bsa;spinning;biobjective optimization	Large penetration of wind generating units in power systems necessitates a flexible unit commitment tool to handle the intermittent nature of these units as well as demand. Moreover, power system operators face not only the risks of wind power curtailments, but also probable unit outages. Therefore, assessing a tradeoff between operational costs and such risks is very important. In the proposed approach, the probability of the residual demand falling within the up-and-down spinning reserve imposed by n – 1 security criterion is converted into a risk index. A new biobjective probabilistic risk/cost-based unit commitment model is proposed to simultaneously minimize both the operational costs and risk. The novel formulation presented provides a new power redispatch process to satisfy up-and-down ramp rate constraints. A new operational-cycles-based unit commitment algorithm is developed. The approach profits from a new nondominated sorting backtracking search optimization algorithm for extracting the Pareto-optimal set. The proposed approach is shown to provide superior results when applied to two test systems: 1) 10-unit and 2) IEEE 118-bus, 54-unit system.	algorithm;backtracking;heuristic;ibm power systems;mathematical optimization;pareto efficiency;ramp simulation software for modelling reliability, availability and maintainability;sorting;sysop	Farhad Bavafa;Taher Niknam;Rasoul Azizipanah-Abarghooee;Vladimir V. Terzija	2017	IEEE Transactions on Industrial Informatics	10.1109/TII.2016.2616109	mathematical optimization;simulation;uncertainty;spinning;engineering;power system simulation;probabilistic logic;electric power system;informatics;statistics	Vision	5.37057005114192	3.6483327945534225	120717
5b5c0ae312d8f5b99a06f3488e4661885658a140	popularity signals in trial-offer markets		This paper considers trial-offer and freemium markets where consumer preferences are modeled by a multinomial logic model with social influence and position bias. The social signal for a product i is of the form φi , i.e., its market share raised to power r. The paper shows that, when 0 < r < 1 and a static position assignment (e.g., a quality ranking) is used, the market converges to a unique equilibrium where the market shares depend only on product quality, not their initial appeals or the early dynamics. When r > 1, the market become unpredictable and goes most likely to a monopoly for some product. Which product becomes a monopoly depends on the initial conditions of the market. These theoretical results are complemented by an agent-based simulation which indicates that convergence is fast when 0 < r < 1 and that the quality ranking dominates the well-known popularity ranking in terms of market efficiency. These results shed a new light on the role of social influence which has been believed to produce unpredictability, inequalities, and inefficiencies in markets. In contrast, this paper shows that, with a proper social signal and a proper position assignment for the products, the market becomes predictable and inequalities and inefficiencies can be controlled.	agent-based model;agent-based social simulation;initial condition;monopoly;multinomial logistic regression;whole earth 'lectronic link	Felipe Maldonado;Pascal Van Hentenryck;Gerardo Berbeglia;Franco Berbeglia	2015	CoRR		data mining;computer science;factor market;microeconomics;monopoly;social influence;freemium;logic model;market share;popularity;ranking	ECom	-4.41969112640316	-5.503498125632187	120730
364123eaefcf4bce8398ea2c306c3c140a3b655f	inventory and credit decisions for time-varying deteriorating items with up-stream and down-stream trade credit financing by discounted cash flow analysis	trade credit;expiration dates;discounted cash flow;supply chain management	In today’s competitive markets, most firms in United Kingdom and United States offer their products on trade credit to stimulate sales and reduce inventory. Trade credit is calculated based on time value of money on the purchase cost (i.e., discounted cash flow analysis). Recently, many researchers use discounted cash flow analysis only on the purchase cost but not on the revenue (which is significantly larger than the purchase cost) and the other costs. For a sound and rigorous analysis, we should use discounted cash flow analysis on revenue and costs. In addition, expiration date for a deteriorating item (e.g., bread, milk, and meat) is an important factor in consumer’s purchase decision. However, little attention has been paid to the effect of expiration date. Hence, in this paper, we establish a supplier–retailer–customer supply chain model in which: (a) the retailer receives an up-stream trade credit from the supplier while grants a down-stream trade credit to customers, (b) the deterioration rate is non-decreasing over time and near 100 percent particularly close to its expiration date, and (c) discounted cash flow analysis is adopted for calculating all relevant factors: revenue and costs. The proposed model is an extension of more than 20 previous papers. We then demonstrate that the retailer’s optimal credit period and cycle time not only exist but also are unique. Thus, the search of the optimal solution reduces to a local one. Finally, we run several numerical examples to illustrate the problem and gain managerial insights. © 2014 Elsevier B.V. All rights reserved.	data-flow analysis;emoticon;numerical analysis;time value of money	Sheng-Chih Chen;Jinn-Tsair Teng	2015	European Journal of Operational Research	10.1016/j.ejor.2014.12.007	supply chain management;actuarial science;economics;cash management;marketing;operating cash flow;forecast period;microeconomics;price/cash flow ratio;commerce;cash on cash return;terminal value	AI	2.1185245265332444	-5.3592446260279925	120776
70ed29d803b7728dbe413bb979c9c7f60dd7cd1b	a two-stage coupled algorithm for an integrated maintenance planning and flowshop scheduling problem with deteriorating machines	machine deterioration;logic based benders decomposition;maintenance planning;production scheduling;integrated decision making	We address a novel integrated maintenance and production scheduling problem in a multi-machine and multi-period production system, considering maintenance as a long-term decision. Deterioration of machines over time decreases production capacity. Since maintenance activities improve machine conditions, increasing production capacity, but also take time that cannot be used for production, the challenge is to assign maintenance to periods and to schedule maintenance and production activities within each period to minimize the combined cost of maintenance and lost production over the planning horizon. Motivated by logic-based Benders decomposition, we design an integrated two-stage algorithm to solve the problem. The first stage assigns maintenance to machines and time periods, abstracting the scheduling problem, while the second stage creates a schedule for the current time period. The first stage is then re-solved using feedback from the schedule. This iteration between maintenance planning and scheduling continues until the solution costs in two stages converge. The integrated approach models the interdependencies between maintenance and scheduling decisions in highly coupled processes such as wafer fabrication in the semiconductor manufacturing. Our results demonstrate that the benefit of integrated decision making increases when maintenance is less expensive relative to lost production cost and that Maliheh Aramon Bajestani Department of Mechanical & Industrial Engineering University of Toronto, Canada E-mail: maramon@mie.utoronto.ca J. Christopher Beck Department of Mechanical & Industrial Engineering University of Toronto, Canada E-mail: jcb@mie.utoronto.ca a longer horizon for maintenance planning is beneficial when maintenance cost increases.	algorithm;automated planning and scheduling;benders decomposition;circuit restoration;computation;converge;coupling (computer programming);feedback;heuristic;industrial engineering;interdependence;iteration;multimachine;open-shop scheduling;production system (computer science);requirement;schedule (computer science);scheduling (computing);scientific literature;semiconductor device fabrication;semiconductor fabrication plant;wafer fabrication;word lists by frequency	Maliheh Aramon Bajestani;J. Christopher Beck	2015	J. Scheduling	10.1007/s10951-015-0416-2	mathematical optimization;real-time computing;scheduling;operations research	AI	9.51102330061132	0.2922274603874101	120845
c9661df83577dfa4a885d49855571af9accfac64	impact of online renting on software piracy	social welfare;software piracy;network effect;comparative modeling;software as a service;profitability	Online rental of software is emerging as a new way of dissemination for several major software firms. Compared to outright selling, the renting scheme delivers the software as a service instead of a physical good. Hence, users cannot privately make copies for resale in the market. We investigate the impact of the renting mechanism on software piracy and pricing in a two-period model whereby a piracy market is present in the second period. We develop and compare models with or without renting. Our analysis shows that renting reduces social welfare but helps to increase a vendor’s profit under certain conditions. We also assess the difference in outcomes in the presence of network effect.	software as a service	Xiaohua Zeng;Sang-Yong Tom Lee;Hock-Hai Teo	2002			homology modeling;economics;computer science;marketing;network effect;software as a service;social welfare;database;commerce;profitability index	Metrics	-3.041868189198579	-7.056761266520924	120865
fa42e9430565672968a4030f4fd7fb0ddad8f175	quanto european option pricing with ambiguous return rates and volatilities	pricing;quanto european option pricing ambiguous return rates quantity adjusting option european option pricing set valued stochastic differential inclusions black scholes quanto model ambiguous volatilities risk neutral martingale measures nonlinear maximal conditional expectations nonlinear minimal conditional expectations backward stochastic differential equations exact upper bound formulas exact lower bound formulas;differential equations pricing set theory stochastic processes;upper bound;mathematical model pricing europe stochastic processes differential equations numerical models upper bound;stochastic processes;ambiguous return rates ambiguous volatilities bounds of option prices maximal minimal conditional expectations quanto european options;mathematical model;differential equations;europe;numerical models;bounds of option prices quanto european options ambiguous return rates ambiguous volatilities maximal minimal conditional expectations	This paper presents a model of quanto (quantity adjusting option) European option pricing when returns and volatilities are ambiguity. First, we use set-valued stochastic differential inclusions to describe the Black–Scholes quanto model with ambiguous return rates and volatilities. The risk neutral martingale measures are not unique but a set in this model. So we consider the upper and lower bounds of contingent claim by using the maximal and minimal conditional expectations, respectively. Since the maximal (minimal) conditional expectations are nonlinear, we provide a computational method for calculating maximal (minimal) conditional expectations by backward stochastic differential equations in the second part of this paper. Third, we give the exact upper bound and lower bound formulas of quanto European options and provide a numerical example to illustrate our model. Finally, we show some conclusions and further work.	black–scholes model;contingency (philosophy);maximal set;nonlinear system;numerical analysis;risk aversion	Junfei Zhang;Shoumei Li	2017	IEEE Transactions on Fuzzy Systems	10.1109/TFUZZ.2016.2598358	pricing;stochastic process;mathematical model;mathematics;mathematical economics;upper and lower bounds;differential equation;statistics	Vision	2.3528882503626445	-2.4316175932543147	120915
45cecac28cd3ac99f913867e7a5d30e5ae58e26f	competing for your attention: negative externalities in digital signage advertising	auctions.;negative externality;advertising;digital signage;attention;transaction cost	In this paper, we propose to model attention consumption of advertisements as a negative externality. We examine the methods of maximum permissible values, fees, and tradable certificates to cope with the negative effects. We propose to integrate auctions for tradable attention certificates with auctions for advertising slots on digital signage. This method allows us to implement tradable certificates with relatively low transaction costs. It enables us to define a maximum amount of attention that is consumed at a certain location at a certain time. It is guaranteed to stay within these limits while causing only minimum costs for advertisers.	digital signage;public key certificate	Jörg Müller;Antonio Krüger	2007			externality;common value auction;transaction cost;advertising;business;digital signage	Web+IR	-1.9222718729586687	-6.983799343019826	120943
7528ce488ebf6f66c31df7acd637d0f430e05dc3	cost-based optimization of buffer size in m/g/1/n systems under different service-time distributions	buffer size;customer loss;optimisation;optimized production technology;servers shape organizations equations queueing analysis optimized production technology cost function;cost function;selected works;queueing systems;queueing theory;queueing theory optimisation;processor speed;servers;shape;processor speed cost based optimization buffer size m g 1 n systems service time distributions queueing systems customer loss customer delays;queueing system;m g 1 n systems;service time distributions;bepress;cost based optimization;organizations;customer delays;cost model;queueing analysis	An analytic cost model is presented for M/G/1/N queueing systems. It considers the cost of customer loss versus customer delays, by varying buffer size and processor speed. We find optimal (and near optimal) configurations for a wide variety of service-time distributions. The model can provide insight into when it is better to invest in increased processor speed than to supply more buffer space. It is seen that different distributions may need very different hardware for optimal performance, and that it may actually be better to reject customers.	analysis of algorithms;clock rate	Derek Doran;Lester Lipsky;Steve Thompson	2010	2010 Ninth IEEE International Symposium on Network Computing and Applications	10.1109/NCA.2010.11	real-time computing;simulation;shape;computer science;organization;operating system;clock rate;queueing theory;server	Arch	3.715585287144416	-1.012792898150861	120954
869be038425777cf60366a48930fadbd1a73c3c0	is shapley cost sharing optimal?	approximate efficiency;shapley value;cost sharing mechanisms	A general approach to the design of budget-balanced cost-sharing mechanisms is to use the Shapley value, applied to the given cost function, to define payments from the players to the mechanism. Is the corresponding Shapley value mechanism “optimal” in some sense? We consider the objective of minimizing worst-case inefficiency subject to a revenue constraint, and prove results in three different regimes. First, for the public excludable good problem, the Shapley value mechanism minimizes the worst-case efficiency loss over all truthful, deterministic, and budget-balanced mechanisms that satisfy equal treatment. Second, even with randomization and approximate budget-balance allowed and dropping equal treatment, the worst-case efficiency loss of the Shapley value mechanism is within a constant factor of the minimum possible. Third, for no-deficit mechanisms, we prove a general positive result: for every monotone cost function, a suitable blend of the VCG and Shapley value mechanisms is no-deficit and enjoys good approximate efficiency guarantees.	stable marriage problem	Shahar Dobzinski;Aranyak Mehta;Tim Roughgarden;Mukund Sundararajan	2018	Games and Economic Behavior	10.1016/j.geb.2017.03.008	mathematical optimization;economics;microeconomics;shapley value;mathematical economics;welfare economics	ECom	-2.944104614449555	-1.320289187026548	121058
a989e1125d35074d702c9e706f1e2e5464de8a25	a comparative analysis of different paperless picking systems	warehouse manual picking;paperless picking;hourly cost function	Purpose – Warehouse picking is often referred to as the most labour-intensive, expensive and time consuming operation in manual warehouses. These factors are becoming even more crucial due to recent trends in manufacturing and warehousing requiring the processing of orders that are always smaller and needed in a shorter time. For this reason, in recent years more efficient and better performing systems have been developed, employing various technological solutions that can support pickers during their work. The purpose of this paper is to introduce a comparison of five paperless picking systems (i.e. barcodes handheld, RFID tags handheld, voice picking, traditional pick-to-light, RFID pick-to-light). Design/methodology/approach – Warehouse picking is often referred to as the most labour-intensive, expensive and time consuming operation in manual warehouses. These factors are becoming even more crucial due to recent trends in manufacturing and warehousing requiring the processing of orders that are always ...	paperless office;qualitative comparative analysis	Daria Battini;Martina Calzavara;Alessandro Persona;Fabio Sgarbossa	2015	Industrial Management and Data Systems	10.1108/IMDS-10-2014-0314	simulation;engineering;operations management;data mining	Embedded	4.519453224242689	-8.55478257618854	121141
b3ded5a543d68a780790391fe6c97e96e66b1e7f	impact of rfid technology on inventory control policy	dynamic programming;inventory control policy;shrinkage;rfid;misplacement	Abstract RFID application can improve operation performance in a supply chain by reducing or eliminating inventory misplacement and shrinkage. In this paper, we present a periodic review inventory model to investigate and characterize the multiperiod inventory control policies in both non-RFID and RFID cases when the firm encounters misplacement and shrinkage. The optimal inventory control policy is proved to be a two-control limit policy. The control limits in both the non-RFID case and the RFID case are analyzed and examined, while considering the impact of shrinkage and misplacement on inventory policies. A critical inventory level is determined to identify the relationship of higher inventory level control limits between the RFID case and the non-RFID case. An intensive numerical study with sensitivity analysis of selling price, misplacement rate, shrinkage rate, inventory recovery rate, and tag price is conducted. We find that when RFID technology is adopted, the inventory control policy in the RFID case is much more stable than that of the non-RFID case, as the misplaced inventory can be recovered perfectly and instantly for sale and the inventory shrinkage can be reduced by RFID technology. In addition, one of our intriguing findings is that when the shrinkage rate is below a threshold value which is independent of parameters, RFID application has no effect on inventory control policy if the misplaced inventory can be recovered in a timely manner by physical audit, which has not been revealed in previous studies.		Feng Tao;Tijun Fan;Kin Keung Lai;Lin Li	2017	JORS	10.1057/s41274-016-0030-5	radio-frequency identification;inventory theory;stock-taking;computer science;marketing;operations management;dynamic programming;shrinkage;commerce;cycle count	HCI	1.7705700813095893	-5.69771033926053	121186
69507d2c71ed22707f564fba2a31954b26fcd958	on-net and off-net pricing on asymmetric telecommunications networks	telecommunications network competition;asymmetry;market share;two part tariffs;call externality;on off net pricing;mobile telephony;telecommunication networks	The differential between on-net and off-net prices, for example on mobile telephony networks, is hotly debated between telecoms operators and regulators. Small operators contend that their competitors’ high off-net prices are anticompetitive. We show that if the utility of receiving calls is taken into account, the equilibrium pricing structures will indeed depend on firms’ market shares. Larger firms will charge higher off-net prices, even without anticompetitive intent, and both under linear and two-part tariffs. We also show that nevertheless high on-net / off-net differentials can be used for anticompetitive purposes.	flat rate;telecommunications network	Steffen Hoernig	2007	Information Economics and Policy	10.1016/j.infoecopol.2007.01.004	industrial organization;market share;mobile telephony;economics;marketing;finance;microeconomics;asymmetry;commerce	ECom	-1.8571921992270348	-5.647860379844414	121368
d2485e1a1ab8111caeef84f5b48204f72d1eb30c	coordination of stocking decisions in an assemble-to-order environment	make to order;capacite production;quantity production;ciclo desarrollo;channel coordination;logistique;life cycle;produccion flujo tirado;exogeno;procurement;exogene;prise de decision;fabrication serie;contrato;production a la commande;assembly;profit;logistics;contract;beneficio;marche contrat;cycle developpement;fabricacion seria;benefice;assembly systems;assemble to order;coordinacion;supply chain;montage;capacidad produccion;contrat;montaje;toma decision;production capacity;supply chain management;exogenous;coordination;logistica	In this paper we study an assemble-to-order environment involving a short-life-cycle product. The product is sold in two different configurations, each requiring a unique component that must be stocked in advance. Both configurations of the product are assembled on the same equipment which has limited capacity. We assume that the assembly capacity is allocated in such a way as to maximize profit for any given product demands and components availability. The main issue is to determine the appropriate stocking quantities for each of the configuration specific components. We first solve for the optimal stocking policy when the components are produced internally, and then consider the case when the components are procured from external suppliers. We investigate how different forms of contract between the assembler and the component suppliers affects coordination of the supply chain as well as each party’s profit. One particularly interesting phenomenon we discover is that it is possible to coordinate the supply chain with a single-price contract between each supplier and the assembler while awarding all parties positive profit. (Supply Chain Management, Channel Coordination, Assembly Systems)	assemble-to-order system;assembly language;block cipher mode of operation;centralized computing;inventory;numerical analysis;phil bernstein;push technology	Xiaohong Zhang;Jihong Ou;Stephen M. Gilbert	2008	European Journal of Operational Research	10.1016/j.ejor.2007.05.047	contract;logistics;supply chain management;profit;economics;procurement;marketing;operations management;assembly;supply chain;management;operations research	Theory	0.012385098986819693	-5.409474760798821	121469
67d3b4d16f4c760b44d9ce9b7bde8b818418ed2b	social connection aware team formation for participatory tasks		Performance of a collaborative task is mostly dependent on the collective effort from participants. To accomplish a participatory task effectively and efficiently, the team formation problem (TFP) outweighs all other considerations. It is even more complicated when social connections among candidates is taken into account. As we can imagine, a large number of tasks require members of the team to be socially close. On the contrary, a portion of tasks, e.g., proposal review, pay more attention to a multidimensional view, and team members should be selected from a variety of cliques. Due to the nature of tasks, it is challenging to find a subset that meets the skill requirement of the task as well as socially diversity demand of team members from a pool of candidates. In this paper, we explore the TFP in a social network. Based on different task objectives, we first formulate the TFP as TFP with strong ties (TFP-ST) and TFP with weak ties (TFP-WT), respectively. Both TFP-ST and TFP-WT are proven to be NP-hard, and we then design corresponding heuristic algorithms to solve the two problems. Through extensive simulations, we show that the solution to TFP-ST can achieve significant improvement in terms of collaboration cost, team size, as well as running time, and the solution to TFP-WT can provide better performance than existing approaches at the same time.	algorithm;clique (graph theory);heuristic;np-hardness;regular expression;simulation;social network;time complexity;total functional programming	Xiaoyan Yin;Chao Qu;Qianqian Wang;Fan Wu;Baoying Liu;Feng Chen;Xiaojiang Chen;Dingyi Fang	2018	IEEE Access	10.1109/ACCESS.2018.2819992	cultural diversity;task analysis;management science;distributed computing;computer science;total factor productivity;citizen journalism;interpersonal ties;heuristic;social network	Web+IR	-1.5102067831446726	3.3191436713599027	121630
9648e7c8ef6752317af2eec09f7469cc6a5a5d6c	game theoretical approach to supply chain microfinance	game theory;supply chain microfinance	This paper considers a supply chain microfinance model in which a manufacturer acts as a lender and a raw material supplier as a borrower. Using a game theoretical analysis, the study investigates how investment levels, raw material prices, and profit margins are influenced by loan interest rates under two types of decentralized channel policies: manufacturer Stackelberg and vertical Nash game. In addition, the study shows how the profits of a manufacturer and a supplier are changed under each supply chain channel structure.	game theory;nash equilibrium;supply chain attack	Jaehun Sim;Vittaldas V. Prabhu	2013		10.1007/978-3-642-41266-0_6	microeconomics;supply chain;business;market economy;commerce	AI	-2.3541349850003552	-5.186609333110663	121640
5cf3a68080cdc5baa40a8b75c16051cae11f6ba9	tractable combinatorial auctions and b-matching	electronic commerce;internet auction;b matching;strategic game;combinatorial auctions;combinatorial auction	Auctions are the most widely used strategic game-theoretic mechanisms in the Internet. Auctions have been mostly studied from a game-theoretic and economic perspective, although recent work in AI and OR has been concerned with computational aspects of auctions as well. When faced from a computational perspective, combinatorial auctions are perhaps the most challenging type of auctions. Combinatorial auctions are auctions where agents may submit bids for bundles of goods. Given that finding an optimal allocation of the goods in a combinatorial auction is in general intractable, researchers have been concerned with exposing tractable instances of combinatorial auctions. In this work we expose the use of b-matching techniques in the context of combinatorial auctions, and apply them in a non-trivial manner in order to introduce polynomial solutions for a variety of combinatorial auctions.	cobham's thesis	Moshe Tennenholtz	2002	Artif. Intell.	10.1016/S0004-3702(02)00229-1	e-commerce;combinatorial auction;unique bid auction;computer science;forward auction	AI	-2.441211179740335	-0.6889288886549263	121725
c9605ac6fbe67e4f91143f132c7ab8325df7ba91	reliable routing in stochastic time-dependent network with the use of actual and forecast information of the traffic flows	vehicle routing forecasting theory optimisation probability road traffic stochastic processes;routing stochastic processes roads reliability shortest path problem probability density function correlation;russia reliable routing problem stochastic time dependent networks actual information forecast information traffic flow parameters optimality criterion departure time time budget computational complexity on time arriving probability maximization large transport network samara	This paper addresses the reliable routing problem in stochastic time-dependent networks using actual and forecast information of the traffic flow parameters. We consider the following optimality criterion: maximization the probability of arriving on time at a destination given a departure time and a time budget. The proposed model is compared with an existing algorithm. Conducted experiments show that the proposed method with a slight increase in computational complexity increases the probability of on-time arriving in a stochastic time-dependent network. The proposed algorithm was implemented and tested using the large transport network of Samara, Russia.	computation;computational complexity theory;expectation–maximization algorithm;experiment;optimality criterion;routing;shroud of the avatar:	Anton Agafonov;Vladislav Myasnikov	2016	2016 IEEE Intelligent Vehicles Symposium (IV)	10.1109/IVS.2016.7535537	mathematical optimization;routing;simulation;geography;operations management	Robotics	9.940803300588787	-8.232006853870441	121740
5ec7532b3ad506eb03095c68c9a4cada9b67a2e4	pricing and benefit of decentralization for competing supply chains with fixed costs		This paper develops two duopoly game models to explore price decisions and the channel benefit of decentralization for two supply chains, and investigates the channel structure decisions in the presence of fixed marketing and manufacturing costs. We give the price decisions and discuss price distortion. Under the downward decentralization model, our analysis reveals that first, symmetric decentralization improves supply chain profit only when the fixed marketing costs are high or product substitutability is high; second, decentralization improves channel profit, and symmetric decentralization (i.e., both manufacturers use decentralization) is an equilibrium if the fixed marketing (or unit production) costs are sufficiently high and the market scales are sufficiently small; and third, the presence of fixed marketing costs and asymmetry of supply chains support the existence of asymmetric equilibrium. Under the upward decentralization model, we find that symmetric outsourcing emerges when the fixed manufacturing cost or the unit production cost is low while both market scale and product substitutability are large in the supplier-led setting, the channel profit under downward decentralization is higher than that under symmetric outsourcing only if product substitutability is high, and the sourcing strategy largely depends on the specific game sequence.	distortion;outsourcing;symmetric multiprocessing	Tiaojun Xiao;Tsan-Ming Choi;T. C. Edwin Cheng	2018	IEEE Transactions on Engineering Management	10.1109/TEM.2017.2773614	management science;duopoly;engineering;fixed cost;outsourcing;supply chain;decentralization;manufacturing cost;strategic sourcing;microeconomics	ECom	-1.5455733669854814	-6.161063293294832	121839
21d42e8bc4962c7a5584059580a201144996cc8e	on pricing complex it service solutions	outsourcing;pricing;contracts;it service solution competitiveness it service solution pricing it service solution price to win;pricing business data processing contracts;servers;outsourcing pricing contracts servers benchmark testing proposals geography;it service solution competitiveness;client decision complex it service solutions pricing case management approach it service contracts market benchmark data unit costs unit prices won deals lost deals ceteris paribus assumption;proposals;benchmark testing;it service solution pricing;it service solution price to win;geography	We present a case management approach to determining the upper and lower bounds on the price at which complex IT service contracts can be won or lost. Our approach is based on mining 'similar' prior deals and market benchmark data modeled as cases, to determine the upper and lower bounds on unit costs and unit prices for each of the service involved in an IT service solution such that the win probability of the deal is maximized. While there is no such a thing as an exact match in complex IT service solutions, as no two deals are alike, our approach offers a practical method for assessing the competitiveness of IT service solutions from unit cost and unit price perspective by leveraging prior won and lost deals. Experiments done on about 177 prior IT strategic outsourcing deals of a large IT service provider organization have resulted in a precision of 72% in determining the price at which one must not lose a deal under ceteris paribus assumption. Another main outcome of our study is the reconfirmation of the belief that price is a weak indicator of win or loss outcome in complex IT services where multiple factors are at play in clients' decision to award contracts.	benchmark (computing);experiment;outsourcing	Rama Akkiraju;Mark Smith;Daniel B. Greenia;Shun Jiang;Taiga Nakamura;Debdoot Mukherjee;Shyam Pusapaty	2014	2014 Annual SRII Global Conference	10.1109/SRII.2014.19	actuarial science;business;commerce	DB	1.7339036182949976	-7.411900152031773	121879
4a9655ad08d2965f565edbb8440f675245f38c3c	on the optimal control of natural resource use in the neoclassical economic framework	optimal control;natural resource;finite horizon;infinite horizon;dynamic optimization problem;economic growth	One considers a class of neoclassical economic growth models where one commodity is a natural resource. Turnpike properties are proved for the finite horizon dynamic optimization problem and conditions are given for the existence of optimal programmes in the infinite horizon case. Some simple examples illustrate these findings.	optimal control	Alain Haurie;N. M. Hung	1975		10.1007/3-540-07622-0_500	mathematical optimization;economics;mathematical economics;welfare economics	Robotics	1.160826085129319	-1.7890083227761	121883
3f37809b51db9a8dee44890084ef8f0486886801	the impact of manufacturer's direct sales and cost information asymmetry in a dual-channel supply chain with a risk-averse retailer	risk aversion;information asymmetry;optimal contracts;online offline channels;dual distribution channel;manufacturer encroachment	ABSTRACTWith the development of electronic commerce, more and more manufacturers choose to distribute their products not only through retail channels but also directly to customers through online channels. This phenomenon is called manufacturer encroachment. We investigate the advantages and drawbacks of manufacturer encroachment in a dual-channel supply chain with a risk-averse retailer and stochastic price-dependent demand. By assuming that the manufacturer’s production cost is private, we build a principal–agent model to explore the optimal contracts the retailer will offer and compare four cases based on the information state and distribution strategy of the manufacturer. Furthermore, we discuss the impact of the key parameters on the optimal contracts and profits using numerical experiments. We find that choosing to encroach can bring the manufacturer much greater profit than information asymmetry.	risk aversion	Ping Chen;Bo Li;Yushan Jiang;Pengwen Hou	2017	Int. J. Electronic Commerce	10.1080/10864415.2016.1204189	information asymmetry;risk aversion;economics;marketing;operations management;commerce	DB	-0.6406144472476182	-5.752783772637055	122051
8b85dadbb5199da3d29b8bd053143610242a2dae	a preventive maintenance policy based on dependent two-stage deterioration and external shocks	competing failures;preventive maintenance;expected cost per unit time;external shock;delay time	This paper proposes a preventive maintenance policy for a single-unit system whose failure has two competing and dependent causes, i.e., internal deterioration and sudden shocks. The internal failure process is divided into two stages, i.e. normal and defective. Shocks arrive according to a non-homogeneous Poisson process (NHPP), leading to the failure of the system immediately. The occurrence rate of a shock is affected by the state of the system. Both an age-based replacement and finite number of periodic inspections are schemed simultaneously to deal with the competing failures. The objective of this study is to determine the optimal preventive replacement interval, inspection interval and number of inspections such that the expected cost per unit time is minimized. A case study on oil pipeline maintenance is presented to illustrate the maintenance policy.		Li Yang;Xiaobing Ma;Rui Peng;Qingqing Zhai;Yu Zhao	2017	Rel. Eng. & Sys. Safety	10.1016/j.ress.2016.12.008	reliability engineering;preventive maintenance;engineering;forensic engineering	SE	6.836776647731888	-1.1799353609547736	122092
3df0fff20b0f0942a9d0f7864eeb51be15d17ef4	price of simplicity under congestion	communication networks;congestion externality;pricing;internet price of simplicity network service provider nsp congestion externality two part tariff flat price revenue loss;congestion externality pricing internet flat price two part tariff price of simplicity;telecommunication congestion control;tariffs;two part tariff;flat price;internet;tariffs internet pricing;network service providers;economics telecommunication services communication networks network service providers telecommunication congestion control;telecommunication services;economics;price of simplicity	"""In this paper, we consider revenues of the NSP (network service provider) when there exists a """"congestion externality."""" In particular, we compare revenues obtained using a flat price and two-part tariff and analyze the effect of congestion on the revenue loss when using a simple entry fee in lieu of the two-part tariff. Previous study has shown that when there is no delay disutility the revenue loss is small, which leads to a low """"Price of Simplicity."""" However, in this study, we show that in an extreme case where all users are identical, the price of simplicity is substantial. Then we consider a more practical scenario where users have different preferences, and show that even in this case, under congestion externality, the price can be extremely high."""	concave function;expanded memory;flat rate;network congestion;network service provider;radio frequency;utility	Dongmyung Lee;Jeonghoon Mo;Guang Jin;Jinwoo Park	2012	IEEE Journal on Selected Areas in Communications	10.1109/JSAC.2012.121208	pricing;the internet;telecommunications;computer science;telecommunications service	Metrics	-1.3088902981974568	-4.734522105891985	122264
3c0b40e8398df9eb2f31323cd6e624186361ff3c	the impact of linear optimization on promotion planning	integer programming	In many important settings, promotions are a key instrument for driving sales and profits. Examples include promotions in supermarkets among others. The Promotion Optimization Problem (POP) is a challenging problem as the retailer needs to decide which products to promote, what is the depth of price discounts and finally, when to schedule the promotions. We introduce and study an optimization formulation that captures several important business requirements as constraints. We propose two general classes of demand functions depending on whether past prices have a multiplicative or an additive effect on current demand. These functions capture the promotion fatigue effect emerging from the stock-piling behavior of consumers and can be easily estimated from data. The objective is nonlinear (neither convex nor concave) and the feasible region has linear constraints with integer variables. Since the exact formulation is “hard”, we propose a linear approximation that allows us to solve the problem efficiently as a linear program (LP) by showing the integrality of the integer program (IP) formulation. We develop analytical results on the accuracy of the approximation relative to the optimal (but intractable) POP solution by showing guarantees relative to the optimal profits. In addition, we show computationally that the formulation solves fast in practice using actual data from a grocery retailer and that the accuracy is high. Together with our industry collaborators from Oracle Retail, our framework allows us to develop a tool which can help supermarket managers to better understand promotions by testing various strategies and business constraints. Finally, we calibrate our models using actual data and determine that they can improve profits by 3% just by optimizing the promotion schedule and up to 5% by slightly modifying some business requirements.	business requirements;concave function;convex function;feasible region;integer programming;linear approximation;linear programming;mathematical optimization;nonlinear system;optimization problem;requirement;utility functions on indivisible goods	Maxime C. Cohen;Ngai-Hang Z. Leung;Kiran Panchamgam;Georgia Perakis;Anthony Smith	2017	Operations Research	10.1287/opre.2016.1573	mathematical optimization;integer programming;marketing;operations management;mathematics;advertising	ML	0.7439072997963813	-3.6839921044840933	122296
b2fe2edf22f6972ef4414e7a8b427ce3df63adc7	cost reduction through operations reversal		In some manufacturing and service processes, several stages must be performed, but there is some freedom in the ordering of stages. Operations reversal means switching the order of two stages. Several authors have studied the benefits of operations reversal, focusing on the reduction of a certain variable’s variance or a related measure. This paper focuses instead on cost. We construct a model with the standard objective of minimizing the long-run average inventory-related cost. First, by using stochastic orders, we identify conditions under which operations reversal reduces cost. We find that in some cases the variability and cost objectives agree on when operations reversal is beneficial, but in other cases they disagree. In particular, when demands are multinomially distributed, variability reduction may be accompanied by cost increase. We show that, to guarantee a lower cost, we need certain properties on the aggregated demand at the choice-level (such as demands for sweaters of the same color). Finally, we examine the effects of cost parameters and lead times on operations reversal under the cost measure.		Ki Ling Cheung;Jing-Sheng Song;Yue Zhang	2017	European Journal of Operational Research	10.1016/j.ejor.2016.09.052	process design;relevant cost;operations management;restructuring;management science;operations research	Crypto	2.446155472413124	-6.340995503473143	122344
60c2347e1cc5241790dd20545574b410a45b1b7d	pricing and replenishment decisions in a continuous review inventory system under (r, q) policy	pricing;r;contract.;replenishment;q policy	This paper discusses a problem of pricing and replenishment decisions for a system consisting of a single vendor and a single  retailer. The retailer faces a stochastic customer demand, and adopts a continuous review (r,Q) policy for replenishing inventory from the vendor. At the beginning of the time horizon, the retailer chooses his expected  sales target, and satisfies customer demands with resultant price that depends on the sales target. Taking the optimal centralized  solution as benchmark, we analyze the system performances with wholesale-price contract and revenue-sharing contract, respectively.  Numerical computations show that the performance of the revenue-sharing contract dominants the wholesale-price contract in  most of the regular cases.  		Ruoxi Guan;Xiaobo Zhao	2009		10.1007/978-3-642-10430-5_100	operations management;microeconomics;business;commerce	AI	-0.03208087010387636	-5.528022026225226	122552
8f99cf30019f4226da0d99f91aa8ad5293119c53	bioenergy systems planning using location-allocation and landscape ecology design principles	design principle;energy demand;landscape ecology;energy flow;location allocation;genetic algorithm;developing world;rural development;bioenergy;sustainable development	Rural energy planning is a nexus of sustainable development issues, particularly the sustainable utilization of biomass resources, on which rural parts of the developing world remain critically dependent. A landscape based rural bioenergy planning framework is presented, which is based on location–allocation and landscape ecology principles and considers both domestic and commercial energy demands and energy flows, as well as the landscape impact of the required bioenergy production zones. p-median modelling principles underly the location–allocation formulation. Optimized bioenergy landscape designs are presented, which illustrate both accessibility and landscape ecology objectives. Copyright Kluwer Academic Publishers 2003	landscape ecology;location-allocation	Henry David Venema;Paul H. Calamai	2003	Annals OR	10.1023/A:1026135632158	genetic algorithm;landscape ecology;developing country;agricultural economics;landscape assessment;energy flow;bioenergy;sustainable development	Robotics	9.542518897039933	-4.974812985707286	122604
5c91c0c45d60fd1ed2d4b72967396828f12212c7	a queuing model on supply chain with the form postponement strategy	ひらめく;研究開発;専門;特許;機関;検索;科学技術;研究者;産学連携;横断検索;mass customization;jst;学術;独立行政法人;検索エンジン;科学技術振興機構;リンクセンター;関連検索;論文;journal;ひろがる;フォームポストポーンメント form postponement 戦略を考慮したサプライチェーンに関する待ち行列モデル;j global;遺伝子;データベース;ｊｇｌｏｂａｌ;研究資源;研究課題;jglobal;国立研究開発法人;jdream;ｊ ｇｌｏｂａｌ;アイディア;資料;技術動向;書誌情報;queuing network;文献;発想;化学物質;customer order decoupling point;統合検索;ｊｓｔ;科学技術用語;つながる;form postponement	The form postponement (FP) strategy is an important strategy for manufacturing firms to utilize to achieve a quick response to customer needs while keeping low inventory levels of finished products. It is an important and difficult task to design a supply chain that uses FP strategy to mitigate the conflict between inventory level and service level. To this end, we develop a two-stage tandem queuing network to model the supply chain. The first stage is the manufacturing process of the undifferentiated semi-finished product, which is produced on a Make-To-Stock basis: the inventory is controlled by base-stock policy. The second stage is the customization process based on customers’ specified requirements. There are two types of order: ordinary order and special order. The former can be met by customizing from semi-finished product, while the latter must be entirely customized beginning from the first stage. The customer orders arrive according to a Poisson process. We first derive the inventory level and fill rate, and then present a total cost model. It turns out that the model is intractable due to the Poisson distribution in the objective function. To analytically solve the problem, we use normal distribution as an approximation of the Poisson distribution, which works well when the parameter of the Poisson distribution is quite large. Finally, some numerical experiments are conducted and managerial insights are offered based on the numerical results. 2013 Elsevier Ltd. All rights reserved.	analysis of algorithms;approximation;experiment;loss function;numerical analysis;optimization problem;queueing theory;requirement;semiconductor industry	Wen-Hui Zhou;Ren-Qian Zhang;Yongwu Zhou	2013	Computers & Industrial Engineering	10.1016/j.cie.2013.09.022	mass customization;engineering;marketing;operations management;commerce	AI	2.942065090156986	-4.886270653777461	122818
15c55a2b37c430b71a0166632ad3b167490f59b5	remaining useful life estimation for repairable multi-state components subjected to multiple maintenance actions		This paper discusses the methodologies for determining the reliability and remaining useful life (RUL) of repairable Multi-State Components (MSCs) subjected to different maintenance actions. By utilizing the degradation rates of the components that depend on the failure and maintenance rates, the transition intensities at the performance states and the Universal Generating Function (UGF), the availability and Mean Time To failure (MTTF) was obtained. The technique developed in this study is used to determine the expected RUL of a Feed Water System (FWS) of a power generating plant that uses three maintenance policies that include â€“ no, minor and major maintenance actions for the components integrity management. The study also shows the influence of repeated maintenance actions on the RUL of the components and the impact on reliability at the lifecycle durations of the components and systems.		Chinedu I. Ossai	2019	Rel. Eng. & Sys. Safety	10.1016/j.ress.2018.10.014	reliability engineering;engineering;mean time between failures;maintenance actions	ML	7.359516416140472	-1.626482292249333	122874
57575ef62bd71d463269a77a7cd728a635c06746	selective maintenance of multi-state systems with structural dependence	multi state system;selective maintenance;assembly sequence;structural dependence;multi component system;directed graph	This paper studies the selective maintenance problem for multi-state systems with structural dependence. Each component can be in one of multiple working levels and several maintenance actions are possible to a component in a maintenance break. The components structurally form multiple hierarchical levels and dependence groups. A directed graph is used to represent the precedence relations of components in the system. A selective maintenance optimization model is developed to maximize the system reliability in the next mission under time and cost constraints. A backward search algorithm is used to determine the assembly sequence for a selective maintenance scenario. The maintenance model helps maintenance managers in determining the best combination of maintenance activities to maximize the probability of successfully completing the next mission. Examples showing the use of the proposed method are presented.		Cuong Duc Dao;Ming Jian Zuo	2017	Rel. Eng. & Sys. Safety	10.1016/j.ress.2016.11.013	reliability engineering;directed graph;engineering;mathematics;engineering drawing	SE	7.909756377077629	-0.12308434604497297	123295
f76173c2fcfb9ece82662f3ede121281442f08ac	periodic imperfect preventive maintenance with two categories of competing failure modes	politica optima;fiabilidad;reliability;preventive maintenance;entretien preventif;porcentaje falla;defecto;mantenimiento sistema;taux defaillance;failure mode;optimal policy;minimal repair;maintainable failure modes;non maintainable failure modes;fiabilite;defect;rupture;defaillance;defaut;reparation;entretenimiento preventivo;failure rate;improvement factor;failures;reparacion;politique optimale;system maintenance;fallo;ruptura;repair;maintenance systeme	A maintenance policy is studied for a system with two types of failure modes: maintainable and non-maintainable. The quality of maintenance actions is modelled by its effect on the system failure rate. Preventive maintenance actions restore the system to a condition between as good as new and as bad as immediately before the maintenance action. The model presented permits to study the equipment condition improvement (improvement factor) as a function of the time of the preventive maintenance action. The determination of the maintenance policy, which minimizes the cost rate for an infinite time span, is examined. Conditions are given under which a unique optimal	failure cause;failure rate	Rómulo I. Zequeira;Christophe Bérenguer	2006	Rel. Eng. & Sys. Safety	10.1016/j.ress.2005.03.009	reliability engineering;preventive maintenance;engineering;failure rate;reliability;forensic engineering;failure mode and effects analysis	AI	6.740010489137036	-1.466677217736597	123309
9d21835578150686701dbae22bf9f8b238332b48	a critical comparison of the various plausible inter-echelon gaming processes in supply chain models	prix vente;forecasting;reliability;project management;strategie stackelberg;two echelon supply chain models;game theory;information systems;logistique;produit consommation;asymmetry;maintenance;on line;stackelberg strategy;en linea;soft or;demande deterministe;information technology;stackelberg game;packing;venta menudeo;vente au detail;teoria juego;theorie jeu;asymetrie;operations research;location;investment;journal;retail marketing;journal of the operational research society;inventory;detaillant;purchasing;history of or;logistics;deterministic demand;marketing;scheduling;demanda determinista;estrategia stackelberg;production;asimetria;communications technology;supply chain;en ligne;consumer products;computer science;operational research;retailers;selling price;article;inventaire;applications of operational research;or society;inventario;jors;management science;infrastructure;precio venta;logistica	An increasing number of supply-chain models are related to the following structure: (i) a manufacturer supplies a product to a retailer—who fixes a retail price and then retails the product to the consumers; (ii) the effect of the retail price on sales volume is dictated by a deterministic demand curve known to both parties. Results from these models depend very much on the ‘gaming process’ that is assumed to govern how the manufacturer and the retailer interact with each other. This paper reviews and compares some basic characteristics of seven seemingly plausible gaming processes; including the two most common ones: the manufacturer-Stackelberg and the fixed-markup-retailer processes. Our results show that: (i) each of the seven processes appear to be no less plausible than the other six; (ii) all seven processes possess some implausible characteristics; (iii) the relationships among the processes are confusing and do not appear to be intuitively logical; (iv) the relationships among these processes are further complicated by the way they are affected by the form of the assumed demand curve. Our results show that in supply-chain modelling more attention should be given to: (i) the proper selection of an appropriate gaming process assumption; (ii) how the model’s results change under different gaming processes; (iii) the incorporation of information asymmetry that will allow these gaming-process assumptions to become more realistic. Journal of the Operational Research Society (2005) 0, 000–000. doi:10.1057/palgrave.jors.2601956	decision theory;deterministic algorithm;markup language;row echelon form	A. H. L. Lau;H.-S. Lau	2005	JORS	10.1057/palgrave.jors.2601956	project management;logistics;game theory;inventory;economics;forecasting;investment;marketing;operations management;reliability;supply chain;location;management;operations research;information technology;scheduling;asymmetry	Metrics	3.421963136936126	-6.3921656770662	123473
0075084412af3baace3aa0148a4d313b721bface	efficient algorithms for learning to play repeated games against computationally bounded adversaries	game theory contracts minimax techniques learning automata computational efficiency particle measurements time measurement computer science;computationally bounded adversaries;learning algorithm;classically studied finite automata repeated games playing computationally bounded adversaries computational efficiency learning algorithm penny matching;game theory;time measurement;particle measurements;efficient algorithm;learning artificial intelligence finite automata game theory;contracts;learning automata;repeated game;minimax techniques;finite automata;polynomial time;computer science;repeated games playing;learning artificial intelligence;penny matching;computational efficiency;classically studied finite automata	In the game theory literature, there is an intriguing line of research on the problem of playing a repeated matrix game against an adversary whose computational resources are limited in some way. Perhaps the main way in which this research differs from classical game theory lies in the fact that when our adversary is not playing the minimax optimal strategy for the game, we may be able to attain payoff that is significantly greater than the minimax optimum. In this situation, the correct measure of our performance is in comparison to the optimum achievable against the particular adversary, not to the minimax optimum. The typical approach is to assume that the adversary’s strategy is a member of some natural class of computationally bounded strategies — most often, a class of finite automata. (For a survey on the area of “bounded rationality”, see the paper of Kalai [4].) Many previous papers examine how various aspects of classical game theory change in this setting; a good example is the question of whether cooperation is a stable solution for prisoner’s dilemma when both players are finite automata [6, 8]. Some authors have examined the further problem of learning to play optimally against an adversary whose precise strategy is unknown, but is constrained to lie in some known class of strategies (for instance, see Gilboa and Samet [3]). It is this research that forms our starting point. The previous work on learning to play optimally usually does not explicitly take into account the computational efficiency of the learning algorithm, and often gives algorithms whose running time is exponential in some natural measure of the adversary’s complexity; a notable recent exception is the work	adversary (cryptography);algorithm;automata theory;computation;computational complexity theory;computational resource;finite-state machine;game theory;minimax;prisoner's dilemma;rationality;time complexity	Yoav Freund;Michael Kearns;Yishay Mansour;Dana Ron;Ronitt Rubinfeld;Robert E. Schapire	1995		10.1109/SFCS.1995.492489	time complexity;game theory;combinatorics;simulation;advantage;computer science;theoretical computer science;machine learning;repeated game;mathematics;algorithm;adversary model;time	Theory	-3.1442368735597257	0.27075488283916954	123548
1340d874ae55247e466f2e3f574635dbfc5330b0	stochastic leadtimes in a one-warehouse, n-retailer inventory system with the warehouse not carrying stock	nuevo abastecimiento;modelo determinista;realimentation;modele deterministe;probabilistic approach;inventory model;refeeding;inventory;administracion deposito;detaillant;stochastic leadtimes;enfoque probabilista;base stock;approche probabiliste;stock minimo;gestion stock;realimentacion;stock minimal;stochastic model;replenishment;deterministic model;retailers;inventory control;modelo estocastico;modele stochastique;fixed replenishment intervals;reapprovisionnement;multi echelon inventory system	This study extends upon a multi-echelon inventory model developed by Graves, introducing in the one-warehouse, N-retailer case—as Graves suggested—stochastic leadtimes between the warehouse and the retail sites in place of the original deterministic leadtimes. Effects of stochastic leadtimes on required base stock levels at the retail sites in the case where the warehouse carries no stock (e.g., serves as a cross-dock point) were investigated analytically. Two alternative treatments of stochastic leadtime distributions were considered. Using as a baseline Graves’ computational study under deterministic leadtimes, results of the current study suggest that it may be better to use the deterministic model with an accurately estimated mean leadtime than a stochastic model with a poorly estimated mean leadtime.		Adriano O. Solis;Charles P. Schmidt	2007	European Journal of Operational Research	10.1016/j.ejor.2006.07.008	inventory control;inventory;economics;stochastic modelling;marketing;operations management;deterministic system;commerce	Robotics	4.700754584246346	-3.617939353998726	123829
9f20e94911ccc20720872ba7f29a3c9e18e0ba38	demand response management in smart grids with heterogeneous consumer preferences	pricing nash equilibrium game theory demand side management power demand renewable energy sources;game theory;nash equilibrium;renewable energy sources;demand side management;pricing;demand response management bayesian nash equilibrium correlated consumption preferences noncooperative game time of use pricing real time pricing consumer demand profiles renewable power generation temporal linear pricing strategy electricity market heterogeneous consumer preferences smart grids;power demand;tariffs bayes methods consumer behaviour demand side management game theory power generation economics power markets smart power grids;renewable energy demand response management drm game theory	Consumer demand profiles and fluctuating renewable power generation are two main sources of uncertainty in matching demand and supply. This paper proposes a model of the electricity market that captures the uncertainties on both the operator and user sides. The system operator (SO) implements a temporal linear pricing strategy that depends on real-time demand and renewable generation in the considered period combining real-time pricing with time-of-use pricing. The announced pricing strategy sets up a noncooperative game of incomplete information among the users with heterogeneous, but correlated consumption preferences. An explicit characterization of the optimal user behavior using the Bayesian Nash equilibrium solution concept is derived. This explicit characterization allows the SO to derive pricing policies that influence demand to serve practical objectives, such as minimizing peak-to-average ratio or attaining a desired rate of return. Numerical experiments show that the pricing policies yield close to optimal welfare values while improving these practical objectives.	experiment;nash equilibrium;numerical method;real-time clock;real-time transcription;sysop;variable pricing	Ceyhun Eksin;Hakan Deliç;Alejandro R. Ribeiro	2015	IEEE Transactions on Smart Grid	10.1109/TSG.2015.2422711	renewable energy;financial economics;pricing;variable pricing;game theory;economics;demand management;microeconomics;demand;nash equilibrium;demand curve;commerce	Metrics	0.008010868849904018	-3.838400990736313	123913
c736a02be71d371ba0ed7aec5d44f9508835ab85	stochastic optimization of grid to vehicle frequency regulation capacity bids	dynamic programming;smart power grids dynamic programming electric vehicles frequency control linear programming markov processes;frequency control;smart power grids;system on chip batteries automatic generation control optimization approximation methods stochastic processes equations;ev charging cost grid to vehicle frequency regulation capacity bid charging optimization electric vehicle smart electric grid markov decision problem markov random price markov random regulation signal discrete stochastic dynamic programming linear programming stochastic process model;electric vehicles;linear programming;markov processes;vehicle to grid v2g approximation algorithms dynamic programming electric vehicles frequency regulation linear programming markov decision problem mdp smart grid stochastic optimization	This paper investigates the application of stochastic dynamic programming to the optimization of charging and frequency regulation capacity bids of an electric vehicle (EV) in a smart electric grid environment. We formulate a Markov decision problem to minimize an EV's expected cost over a fixed charging horizon. We account for both Markov random prices and a Markov random regulation signal. We also propose an enhancement to the classical discrete stochastic dynamic programming method. This enhancement allows optimization over a continuous space of decision variables via linear programming at each state. Simple stochastic process models are built from real data and used to simulate the implementation of the proposed method. The proposed method is shown to outperform deterministic model predictive control in terms of average EV charging cost.	approximation algorithm;decision problem;dynamic programming;extended validation certificate;linear programming;markov chain;mathematical optimization;personal computer;simulation;sockets direct protocol;stochastic optimization;stochastic process;stochastic programming	Jonathan Donadee;Marija D. Ilic	2014	IEEE Transactions on Smart Grid	10.1109/TSG.2013.2290971	markov decision process;stochastic programming;control engineering;mathematical optimization;robust optimization;simulation;computer science;linear programming;stochastic optimization;dynamic programming;automatic frequency control;mathematics;markov process;markov model	ML	4.427722227448965	3.006071538928882	123924
64ef2e56e8341f33c07008befbab79d725c1e123	vehicle interference effects in warehousing systems with autonomous vehicles	analytical models;cycle time;warehousing decomposition interference mobile robots queueing theory vehicles warehouse automation;protocols;decomposition;high density storage;high density;queuing model;autonomous vehicle;warehousing system;queueing theory;decomposition based method;mobile robots;interference;vehicle interference effect;autonomous vehicle based storage and retrieval system;system performance;warehousing;decomposition based method vehicle interference effect warehousing system autonomous vehicle based storage and retrieval system high density storage;vehicles;vehicles interference delay protocols analytical models throughput queueing analysis;warehouse automation;queueing analysis;throughput	Autonomous vehicle based storage and retrieval (AVS/R) systems offer greater flexibility to improve cycle time and throughout capacity in the transfer of unit loads in high density storage areas. AVS/R systems rely on autonomous vehicles to provide horizontal the movement within a tier and use lifts to provide vertical movement between tiers. In these systems, vehicle interference in the aisles and cross aisles could significantly decrease system throughput and increase cycle times. In this research, protocols are developed to address vehicle interference and a queuing model is proposed to analyze system performance. A decomposition-based method is used to solve the model and quantify the effect of interference. The interference effects are studied for systems with varying tier configuration parameters such as depth/width ratio and number of vehicles. These insights are validated against detailed simulations.	autonomous robot;interaction;interference (communication);multitier architecture;queueing theory;simulation;throughput	Debjit Roy;Ananth Krishnamurthy;Sunderesh S. Heragu;Charles J. Malmborg	2010	2010 IEEE International Conference on Automation Science and Engineering	10.1109/COASE.2010.5584777	embedded system;real-time computing;simulation;engineering	Robotics	8.316607529700297	3.910666141835374	124050
1dee4526db7244c65df1dd281d01a41c068262a9	self-confirming price prediction strategies for simultaneous one-shot auctions	self confirming price prediction;simultaneous auctions;empirical game theoretic analysis	Bidding in simultaneous auctions is challenging because an agent’s value for a good in one auction may depend on the outcome of other auctions; that is, bidders face an exposure problem. Given the gap in our understanding (e.g., lack of game-theoretic solutions) of general simultaneous auction games, previous works have tackled the problem of how to bid in these games with heuristic strategies that employ probabilistic price predictions—so-called price-prediction strategies. We introduce a concept of self-confirming prices, and show that within an independent private value model, Bayes-Nash equilibrium can be fully characterized as a profile of optimal price-prediction strategies with self-confirming prices. We exhibit practical procedures to compute near-self-confirming price predictions given a priceprediction strategy, and near-optimal bids given a probabilistic price prediction. We call the output of our procedures self-confirming price-prediction (SCPP) strategies, and produce one such strategy that outperforms all previously studied bidding heuristics for this setting. An extensive empirical gametheoretic analysis demonstrates that SCPP strategies are effective in simultaneous auctions with both complementary and substitutable preference structures.	approximation algorithm;best, worst and average case;computation;emoticon;experiment;game theory;heuristic (computer science);iterative method;local search (optimization);mathematical optimization;nash equilibrium;real-time bidding;simulation;stochastic optimization;value (ethics)	Michael P. Wellman;Eric Sodomka;Amy Greenwald	2012	Games and Economic Behavior	10.1016/j.geb.2017.01.007	economics;common value auction;microeconomics;welfare economics;commerce	AI	-2.5459604839429266	-1.8272200345356502	124190
579d4b40c50a198e6fc004c6fe3a727d4e225420	an analytical approach to the facility location and capacity acquisition problem under demand uncertainty	distribution;forecasting;location problem;metodo analitico;reliability;probleme localisation;localisation installation;project management;information systems;equipement collectif;maintenance;penurie;soft or;information technology;packing;operations research;location;investment;journal;journal of the operational research society;inventory;purchasing;identificacion sistema;equipamiento colectivo;sous traitance;history of or;logistics;system identification;penuria;marketing;scheduling;analytical method;facility;estimacion parametro;production;methode analytique;communications technology;problema localizacion;computer science;operational research;parameter estimation;estimation parametre;subcontratacion;subcontracting;distribucion;shortage;identification systeme;demand uncertainty;applications of operational research;or society;jors;management science;infrastructure;facility location	This article presents an analysis of facility location and capacity acquisition under demand uncertainty. A novel methodology is proposed, in which the focus is shifted from the precise representation of facility locations to the market areas they serve. This is an extension of the optimal market area approach in which market area size and facility capacity are determined to minimize the total cost associated with fixed facility opening, variable capacity acquisition, transportation, and shortage. The problem has two variants depending on whether the firm satisfies shortages by outsourcing or shortages become lost sales. The analytical approach simplifies the problem considerably and leads to intuitive and insightful models. Among several other results, it is shown that fewer facilities are set up under lost sales than under outsourcing. It is also shown that the total cost in both models is relatively insensitive to small deviations in optimal capacity choices and parameter estimations.	facility location problem	Abdullah Dasci;Gilbert Laporte	2005	JORS	10.1057/palgrave.jors.2601826	distribution;project management;logistics;simulation;inventory;economics;system identification;forecasting;investment;marketing;operations management;reliability;mathematics;location;management;operations research;information technology;scheduling;statistics	Robotics	5.567466645693248	-3.959824021162985	124387
2b2b403b99646e91651579919cb00d40bdee6e2c	separating risk and return in the capm: a general utility-based model	functional form;equilibrium asset pricing;utility function;capital asset pricing model;decision theory;downside risk;risk measure;management science	The author proposes a new utility function which captures trade-os between return and a large body of risk measures as de®ned by popular risk±return models in the management science literature while exhibiting desirable properties for a ®nancial investor. This function forms the basis for an extension to the Capital Asset Pricing Model which links general asymmetric risk measures and risk±value models with equilibrium asset pricing. Ó 2000 Elsevier Science B.V. All rights reserved.	capital asset pricing model;management science;risk measure;utility	Christian S. Pedersen	2000	European Journal of Operational Research	10.1016/S0377-2217(99)00114-9	financial economics;basis risk;beta;capital asset pricing model;investment theory;arbitrage pricing theory;actuarial science;economics;decision theory;risk-free interest rate;computer science;diversification;finance;risk premium;mathematics;consumption-based capital asset pricing model;rational pricing;security market line;higher-order function;statistics	AI	-0.25123247938623133	-2.9900836715412713	124637
2855842a952a8e257d77638847f62efc27af5777	joint optimization for inspection and replacement model based on a three-stage failure process	preventive maintenance;inspection;age based replacement policy;three stage failure process	Preventive maintenance (PM) is still a dominant policy in industry and inspections are necessary PM activities. An inspection model based on a three-stage failure process under the age-based preventive replacement policy for a single component system is proposed. The three-stage failure process divides the lifetime of the system into four states: normal, minor defective, severe defective and failure, which is closer to reality. The system is renewed at the time that the severe defective stage is identified and at failure. Moreover, the system is replaced once reaching the certain age T under the age-based replacement policy. However, two different cost models are proposed depending on the different options at the time of identifying the minor defective stage. A numerical example is presented to demonstrate the efficiency of the proposed models.	mathematical optimization	Ruifeng Yang;Jianshe Kang	2017	Int. J. Systems Assurance Engineering and Management	10.1007/s13198-015-0351-9	reliability engineering;preventive maintenance;inspection;engineering;operations management;forensic engineering	DB	7.088590463394211	-1.309319425586192	124641
51f03a5132db88811f520ce6fed44b9b64d3c2f1	combinatorial auctions without money	liverpool;algorithmic mechanism design;repository;mechanisms with verification;greece;university;economics;combinatorial auctions;article;combinatorial analysis;multiagent systems	Algorithmic Mechanism Design attempts to marry computation and incentives, mainly by leveraging monetary transfers between designer and selfish agents involved. This is principally because in absence of money, very little can be done to enforce truthfulness. However, in certain applications, money is unavailable, morally unacceptable or might simply be at odds with the objective of the mechanism. For example, in combinatorial auctions (CAs), the paradigmatic problem of the area, we aim at solutions of maximum social welfare but still charge the society to ensure truthfulness. Additionally, truthfulness of CAs is poorly understood already in the case in which bidders happen to be interested in only two different sets of goods. We focus on the design of incentive-compatible CAs without money in the general setting of k-minded bidders. We trade monetary transfers with the observation that the mechanism can detect certain lies of the bidders: i.e., we study truthful CAs with verification and without money. We prove a characterization of truthful mechanisms, which makes an interesting parallel with the well-understood case of CAs with money for single-minded bidders. We then give a host of upper bounds on the approximation ratio obtained by either deterministic or randomized truthful mechanisms when the sets and valuations are private knowledge of the bidders. (Most of these mechanisms run in polynomial time and return solutions with (nearly) best possible approximation guarantees.) We complement these positive results with a number of lower bounds (some of which are essentially tight) that hold in the easier case of public sets. We thus provide an almost complete picture of truthfully approximating CAs in this general setting with multi-dimensional bidders.	approximation algorithm;computation;deterministic algorithm;money;polynomial;randomized algorithm;resource bounded measure;time complexity;whole earth 'lectronic link	Dimitris Fotakis;Piotr Krysta;Carmine Ventre	2014	Algorithmica	10.1007/s00453-015-0105-8	algorithmic mechanism design;mathematical optimization;combinatorial auction;computer science;artificial intelligence;multi-agent system;mathematical economics;algorithm	ECom	-3.1011637468777153	-0.0828666506639723	124834
7138db7bb0c6c4a2d6c9bd34379b511584c0de9a	addressing imperfect maintenance modelling uncertainty in unavailability and cost based optimization	maintenance equipment;economie;modelizacion;teoria demonstracion;epistemic uncertainty;optimal solution;economia;multicriteria analysis;multiobjective programming;systeme avec reserve;programmation multiobjectif;optimisation;instalaciones manutencion;theorie preuve;optimizacion;proof theory;maintenance;systeme aide decision;defecto;availability;uncertainty;disponibilidad;etude experimentale;multiple criteria decision making;risk aversion;multi objective optimization;safety systems;prise de decision;sistema con reserva;impact test;imperfect maintenance modelling;sistema complejo;sistema ayuda decision;probabilistic approach;decision maker;algoritmo genetico;approche deterministe;imperfect information;deterministic approach;modelisation;systeme incertain;multiple objectives;decision support system;systeme complexe;complex system;enfoque probabilista;approche probabiliste;essai choc;defect;cognition;ensayo choque;enfoque determinista;coste;algorithme genetique;defaut;mantenimiento;informacion imperfecta;systeme securite;cognicion;fabrica;genetic algorithm;nuclear power plant;genetic algorithms;centrale nucleaire;optimization;industrial plant;economy;analisis multicriterio;standby system;analyse multicritere;materiel entretien;toma decision;sistema incierto;aversion riesgo;modeling;disponibilite;estudio experimental;uncertain system;testing and maintenance;central nuclear;aversion risque;usine;cout;information imparfaite;programacion multiobjetivo	Optimization of testing and maintenance activities performed in the different systems of a complex industrial plant is of great interest as the plant availability and economy strongly depend on the maintenance activities planned. Traditionally, two types of models, i.e. deterministic and probabilistic, have been considered to simulate the impact of testing and maintenance activities on equipment unavailability and the cost involved. Both models present uncertainties that are often categorized as either aleatory or epistemic uncertainties. The second group applies when there is limited knowledge on the proper model to represent a problem, and/or the values associated to the model parameters, so the results of the calculation performed with them incorporate uncertainty. This paper addresses the problem of testing and maintenance optimization based on unavailability and cost criteria and considering epistemic uncertainty in the imperfect maintenance modelling. It is framed as a multiple criteria decision making problem where unavailability and cost act as uncertain and conflicting decision criteria. A tolerance interval based approach is used to address uncertainty with regard to effectiveness parameter and imperfect maintenance model embedded within a multiple-objective genetic algorithm. A case of application for a stand-by safety related system of a nuclear power plant is presented. The results obtained in this application show the importance of considering uncertainties in the modelling of imperfect maintenance, as the optimal solutions found are associated with a large uncertainty that influences the final decision making depending on, for example, if the decision maker is risk averse or risk neutral.	mathematical optimization;unavailability	Ana Sánchez;Sofía Carlos;Sebastián Martorell;José F. Villanueva	2009	Rel. Eng. & Sys. Safety	10.1016/j.ress.2007.03.022	genetic algorithm;decision support system;computer science;engineering;artificial intelligence;operations research;statistics	DB	7.579456642869867	-3.611751187923044	124843
cec0715a51ff98db83c739533925424e1695f82e	perspectives of a future-proof primary resource logistics chain		Energy policies and energy prices have increasingly been influencing the demand for wood. For long-lasting profitability and sustainable growth of companies involved in the wood market, logistics for raw material supply is of crucial importance. This article addresses possible measures for supply chains in the wood-processing industry based on a five-year forecast horizon derived from a simulation study. It describes the design and implementation of a simulation model to derive strategic action recommendations for raw material supply logistics for the raw material wood. Decisions concerning the size of storage locations, the number of operators in the system and the system costs can be supported by this analysis.	logistics;mesoscopic physics;simulation	Oliver Meier;Sebastian Trojahn;Henning Strubelt	2017	2017 Winter Simulation Conference (WSC)	10.1109/WSC.2017.8248058	energy policy;operations management;systems engineering;future proof;computer science;sustainable growth rate;supply chain;profitability index;raw material	ECom	5.369163112518869	-6.9787521158311066	124886
f08ea5e76eacf2a6747bfed493387ff3ff479ec2	the machine breakdown paradox: how random shifts in the production rate may increase company profits	variable production rate;rational inefficiency;inventory;machine breakdown;production;deteriorating process	The causes and effects of machine breakdowns have frequently been investigated in the past. One popular stream of research studies technical errors in production and analyzes their impact on the inventory policy of the company. In this paper, we show that random shifts in the production rate of a machine, which may occur, for example, due to technical defects, may lead to a reduction in total cost and therewith to an increase in profit. This obvious paradox may lead to situations where it is economically rational for the company to sustain a technically inefficient situation, or even to take measures to intentionally induce a shift in the production rate, for example by damaging the machine on purpose. In this paper, we illustrate this paradox by referring to an existing inventory model, and trace it back to common assumptions made in the literature.		Christoph H. Glock	2013	Computers & Industrial Engineering	10.1016/j.cie.2013.07.018	inventory;economics;engineering;artificial intelligence;marketing;operations management;management;operations research;commerce	AI	1.7032847990534559	-6.145677687112762	124973
81002325938645db7382fac530301d6f6abd9f3d	effect of information feedback on bidder behavior in continuous combinatorial auctions	experimental economics;information feedback;bidder behavior;eexperimental economics;bbidder behavior;combinatorial auctions;auctions	Combinatorial auctions – in which bidders can bid on combinations of goods – can increase the economic efficiency of a trade when goods have complementarities. Recent theoretical developments have lessened the computational complexity of these auctions, but the issue of cognitive complexity remains an unexplored barrier for the online marketplace. This study uses a data-driven approach to explore how bidders react to the complexity in such auctions using three experimental feedback treatments. Using cluster analyses of the bids and the clicks generated by bidders, we find three stable bidder strategies across the three treatments. Further, these strategies are robust for separate experiments using a different setup. We also benchmark the continuous auctions against an iterative form of combinatorial auction—the Combinatorial Clock auction. The enumeration of the bidding strategies across different types of feedback, along with the analysis of their financial implications, is offered to help practitioners design better combinatorial auction environments.	aggregate data;aggregate function;auction algorithm;benchmark (computing);clickstream;cluster analysis;cognitive complexity;combinatorial optimization;complementarity theory;computational complexity theory;experiment;feedback;heuristic (computer science);hudson;ibm notes;information system;iterative method;online marketplace;relevance;simulation;stepping level;test suite;time complexity;value (ethics);word lists by frequency	Gediminas Adomavicius;Shawn P. Curley;Alok Gupta;Pallab Sanyal	2012	Management Science	10.1287/mnsc.1110.1443	industrial organization;mathematical optimization;combinatorial auction;economics;common value auction;microeconomics;experimental economics;commerce	AI	-2.3977055637064697	-2.0841381328808564	124976
16eeb47290b85927f88ae2d3714003bcb7079620	when does improved targeting increase revenue?	targeting;position auctions;revenue;online auctions;advertising	In second-price auctions, we find that improved targeting via enhanced information disclosure decreases revenue when there are two bidders and increases revenue if there are at least four symmetric bidders with values drawn from a distribution with a monotone hazard rate. With asymmetries, improved targeting increases revenue if the most frequent winner wins less than 30.4% of the time under a model in which shares are well defined, but can decrease revenue otherwise. We derive analogous results for position auctions. Finally, we show that revenue can vary nonmonotonically with the number of bidders who are able to take advantage of improved targeting.	personally identifiable information;monotone	Patrick Hummel;R. Preston McAfee	2015	ACM Trans. Economics and Comput.	10.1145/2956586	targeting;marginal revenue;marketing;common value auction;microeconomics;revenue;commerce	ECom	-2.848598261674148	-5.28830710205403	125037
60c66afb6b4084c10a8a7802a7ce89385ecf643b	a strategy-proof multiunit double auction mechanism	electronic commerce;auction;is strategy;mechanism design;individual rationality;double auction	We envision a future economy where e-markets will play an essential role as exchange hubs for commodities and services. Because of their flexibility, we anticipate multi-unit double auctions (MDAs) to play an important role in future's e-markets. In this paper, we present a multi-unit double auction mechanism which is strategy-proof with respect to reservation price, weakly budget-balanced and individually rational.		Pu Huang;Alan Scheller-Wolf;Katia P. Sycara	2002		10.1145/544741.544780	e-commerce;mechanism design;eauction;combinatorial auction;generalized second-price auction;unique bid auction;computer science;reverse auction;vickrey–clarke–groves auction;revenue equivalence;double auction;auction theory;forward auction	AI	-2.7308189384920194	-4.378936915140552	125075
6b8f9442882d86c309ed606fb46c85b680609b9d	on formation of security portfolio with uniform distribution by logarithmic criterion and priority risk component	priority risk component;criterial function;upper estimate;corresponding strategy;uniform distribution;optimal formation;riskless security;risk security;logarithmic criterion;security portfolio;explicit form	Consideration was given to the optimal formation of the security portfolio by the logarithmic criterion for two uniformly distributed risk securities and one riskless security. For the criterial function, concavity was established and the explicit form was presented, the lower and upper estimates of the criterial function and their corresponding strategies were determined. An example of using the relations obtained was discussed.		Alexei N. Ignatov;Andrey I. Kibzun	2014	Automation and Remote Control	10.1134/S0005117914030060	mathematical optimization;mathematics	EDA	1.9665162859985772	-1.8759700803620034	125135
ce9b54aa7f8416a630b69a40a6f96d4611488751	valuing gm technologies using real options: the case of drought tolerant wheat in australia		ABSTRACTIn this article we seek to estimate the value of a partially-developed crop technology from the perspective of the firm developing the technology. Firms need this value estimation to decide whether their technology will earn a sufficient return in the market to justify investing in it. However, determining the (ex-ante) value of the technology before it is commercialised is challenging as the technology is not yet in the market and hence the demand function has not yet been defined. An alternative valuation method is required. We use risk premiums, Monte Carlo simulation and real options analysis and we demonstrate this combination of valuation tools on wheat that is currently being developed in Australia to be drought tolerant. The results indicate that this drought tolerant wheat variety is likely to be adopted by farmers in most regions and has a pre-commercialisation value that justifies continued investment in its development. We also identified South Australia as a region in which the new va...		Katherine K. Wynn;German C. Spangenberg;Kevin F. Smith;William J Wilson	2018	Techn. Analysis & Strat. Manag.	10.1080/09537325.2018.1474194	finance;marketing;valuation (finance);drought tolerance;risk premium;monte carlo method;economics;demand curve	Robotics	0.4276986590188534	-9.010062039603	125343
2d55cdd04ea272acfd2dc844f3906f7e59b0961c	simulation modelling for a bus maintenance facility	maintenance engineering;mechanical engineering computing;modelling;road vehicles;sensitivity analysis;simulation;greyhound lines dallas maintenance facility;bus maintenance facility;facility sizing decisions;peak operating period;peak traffic accomodation;sensitivity analysis;simulation modelling;stochastic model	The Greyhound Lines Dallas Maintenance Facility was congested during peak operating periods. A stochastic model of this facility was developed to determine the resource requirements needed to provide adequate service during periods of peak demand. The structure of the simulation model is described. A representative sensitivity analysis is presented to discuss how this model was used to support facility sizing decisions. Based on our simulation experiments, we concluded that the existing site, with appropriate modifications, could accommodate peak traffic with some room for growth.	experiment;requirement;simulation	Manivannan Ramadass;Jay M. Rosenberger;Brian Huff;Stephanie Gonterman;Rajesh N. Subramanian	2004	Proceedings of the 2004 Winter Simulation Conference, 2004.		maintenance engineering;simulation;engineering;stochastic modelling;simulation modeling;transport engineering;sensitivity analysis	AI	8.721144628202902	-7.479411390490927	125509
98414550a8d9fa02da345f0b1744c88b17c0efb3	an application of optimization-by-simulation to discrete variable systems	search method;stochastic system;technical report;simulation model;computer simulation	An algorithm is being developed for optimization of discrete variable stochastic systems that are modeled by computer simulation. The algorithm is basically a complex type search method that interacts with the simulation model. The capabilities built in the procedure allows it to take into account the stochastic nature of the responses of the simulation model and arrive at a reasonable solution with a certain level of confidence. This paper reports preliminary results obtained from this procedure which is undergoing its final stages of development. An application of this procedure to optimization of operation of a manufacturing cell is also presented.	algorithm;computer simulation;mathematical optimization;stochastic process	Young Hae Lee;Farhad Azadivar	1985		10.1145/21850.253114	computer simulation;mathematical optimization;simulation;computer science;technical report;systems simulation;simulation modeling;world wide web	ML	8.516263362522395	0.2593869087324727	125612
7084aa8254408c5fdbc29b04782e10c23017d4e4	new cake cutting algorithms: a random assignment approach to cake cutting			algorithm	Haris Aziz;Chun Ye	2013	CoRR		economics;random assignment;mathematical optimization	AI	-1.595077819245383	0.5260380027719129	125642
05a86e4e944c9b9be703b3846e6360e56d4360b4	high frequency trading, liquidity, and execution cost	discrete optimization;liquidity;optimal execution;price impact;article;high frequency trading	We build a model under the framework of discrete optimization to explain how high frequency trading (HFT) can be applied to supply liquidity and reduce execution cost. We derive the analytical properties of our model in finding the optimal solution to minimize the overall execution cost of HFT. We show that the execution cost can be reduced after increasing trading frequency (i.e., the higher the trading frequency, the lower the execution cost) with a simulation study. In addition, we conduct an empirical investigation with tick level data from US equity market through January 2008 to October 2010 to verify our conclusion drawn from the simulation study. Based on the simulation and empirical results we collected, we show that the HFT can reduce the execution cost when supplying liquidity. Our results coincide with the empirical observations documented in literature that automated trading can improve liquidity and reduce trade-related price discovery.	algorithmic trading;discrete optimization;high-frequency trading;mathematical optimization;numerical partial differential equations;simulation;traders;volatility	Edward W. Sun;Timm Kruse;Min-Teh Yu	2014	Annals OR	10.1007/s10479-013-1382-8	financial economics;discrete optimization;high-frequency trading;operations management;market liquidity;commerce	Metrics	1.9325580386827834	-5.57060621345514	125782
87279edd22f6e35b66bdb869a69ba9d1466bc2ab	simulating exogenous shocks in complex supply networks using modular stochastic petri nets	004 informatik;330 wirtschaft;it enabled supply chain management	Almost all major companies are embedded in complex, global supply networks, consisting of multiple nested supply chains, and building up a high level of complexity. Exogenous shocks on these networks (e.g. natural disasters) can directly and indirectly impact companies and even cause their entire supply network to fail. However, today it is extremely difficult for a company to predict the actual impact of an exogenous shock on its supply network. Hence, companies are not able to identify adequate counteractive measures. Therefore safeguarding measures are oftentimes insufficient or even counterproductive. This paper deals with modelling, analyzing and quantifying impacts of exogenous shocks on supply networks using Petri Nets. It provides means to simulate the vulnerability of different network constellations regarding exogenous influences. In order to evaluate the proposed method, we simulate different intensities of an exogenous shock delaying the delivery for an exemplary supply network. We thereby illustrate which results could be yielded from a real-world application. For our exemplary network we find that the marginal effect of a disruption declines with an increasing intensity of shock. Moreover, the impact of shocks can be mitigated by appropriate counteractive measures like in this example by an increased safety margin of stock.	denial-of-service attack;embedded system;high-level programming language;information system;marginal model;simulation;stochastic petri net	Gilbert Fridgen;Christian Stepanek;Thomas Wolf	2012			real-time computing;simulation;economics;operations management	Web+IR	1.2793975758718767	-7.652991689197478	125803
d5e9317857bf33802d66cf1471a14770ce0738c4	prioritizing and scheduling service requests under time constraints	scheduling cloud computing game theory iterative methods;cloud resource optimization iterative bidding saas prioritizing and scheduling;schedules resource management cost accounting computational modeling time factors games optimization;cloud resource optimization;iterative bidding;saas prioritizing and scheduling;multilateral negotiation platform service request prioritizing service request scheduling game theoretic model iterative bidding framework software as a service environments saas environments service provider capacity customer service requests profitable requests economic based models economic social welfare	This paper presents a game theoretic model and an iterative bidding framework for the service request prioritizing and scheduling problem in Software as a Service (SaaS) environments. We focus on a type of settings in which the service provider's existing capacity is over demanded and customers' service requests are constrained with completion times. To gain more profit, the provider needs to prioritize customers' requests based on their profitability and schedule as many profitable requests as possible. The prioritizing and scheduling problem is considered in a strategic setting in which customers' values on the service requests are their private information that is not known to the provider, which calls for economic based models. The key issue here is how to maximize economic social welfare across all customers given the presence of customers' self-interests. We propose an iterative bidding framework as a multilateral negotiation platform for the service provider and its customers to allocate compute capacity among service requests. The proposed bidding framework is evaluated by a computational study. The data from the experiments show that the proposed approach produces near optimal solutions with moderate information revelation. It also scales well to large size problem instances.	auction algorithm;computation;experiment;game theory;high-level programming language;iteration;iterative method;level structure;personally identifiable information;purchasing;requests;schedule (project management);scheduling (computing);software as a service	Farnaz Dargahi;Mohammad Fozlul Haque Bhuiyan;Chun Wang;Chen Ding	2014	2014 IEEE International Conference on Services Computing	10.1109/SCC.2014.10	service level requirement;service level objective;service delivery framework;marketing;operations management;service design;business;commerce	Mobile	-0.529427723202409	1.2183634376715644	125822
de9a3ac4f0e44dbe67696b24e656a1d270986ffa	optimal bidding strategies of wind-thermal power producers		This paper addresses a stochastic mixed-integer linear programming model for solving the self-scheduling problem of a thermal and wind power producer acting in an electricity market. Uncertainty on market prices and on wind power is modelled via a scenarios set. The mathematical formulation of thermal units takes into account variable and start-up costs and operational constraints like: ramp up/down limits and minimum up/down time limits. A mixed-integer linear formulation is used to obtain the offering strategies of the coordinated production of thermal and wind energy generation, aiming the profit maximization. Finally, a case study is presented and results are discussed.		Rui Laia;Hugo M. I. Pousinho;Rui Melício;Victor M. F. Mendes	2016		10.1007/978-3-319-31165-4_46	stochastic optimization;electricity market;wind power;control engineering;market price;engineering;bidding;microeconomics;thermal power station;linear programming;profit maximization	HCI	3.7677123764240994	4.0367052006767175	125901
ef8b3cd5ff6472ac7a36fc6c0824d9a06d6e5887	a robust design of electric vehicle frequency regulation service	iso;frequency control automatic generation control iso robustness bismuth real time systems;frequency control;bismuth;power generation control battery storage plants compensation electric vehicles frequency control government policies optimisation;automatic generation control;robustness;ev frequency regulation revenue electric vehicle frequency regulation service ref algorithm independent system operator iso discharging power automatic generation control signal agc signal federal energy regulatory commission performance based compensation paradigm compensation scheme frequency regulation capacity;real time systems	Electric vehicles (EVs) have the potential to provide frequency regulation service to an independent system operator (ISO) by changing their real-time charging or discharging power according to an automatic generation control (AGC) signal. Recently, the Federal Energy Regulatory Commission has issued an order to ISOs to introduce a performance-based compensation paradigm. In this new compensation scheme, the ISOs make payments to the EVs for providing the frequency regulation capacity and the real-time dispatch when following the AGC signal. In this paper, we propose a robust EV frequency regulation (REF) algorithm to determine the hourly regulation capacity for each EV considering the randomness of the AGC signal. The proposed REF algorithm is based on a robust optimization problem formulation. It enables EVs to follow the random AGC signal reliably and to improve the EV frequency regulation revenue. Simulation results show that the proposed REF algorithm obtains a higher revenue compared with a benchmark algorithm from the literature under a performance-based compensation paradigm.	algorithm;automatic gain control;benchmark (computing);dynamic dispatch;experiment;extended validation certificate;linear programming;mathematical optimization;numerical analysis;optimization problem;programming paradigm;randomness;real-time clock;real-time transcription;robust optimization;simulation;sysop	Enxin Yao;Vincent W. S. Wong;Robert Schober	2014	2014 IEEE International Conference on Smart Grid Communications (SmartGridComm)	10.1109/SmartGridComm.2014.7007729	control engineering;engineering;operations management;control theory	Robotics	3.3144206612801823	3.795931135831193	126103
77828f42dd8683944c238365b3388ab8671f6f73	the optimal pace of product updates	modelizacion;occupation time;entreprise;concepcion ingenieria;engineering design;new product;mise a jour;markets;cost function;mercado;cout developpement;conception ingenierie;new product introduction;development cost;empresa;or in research and development new product introduction diffusion time pacing clockspeed;developpement produit;taux croissance;producto nuevo;coefficient diffusion;imitation;funcion coste;diffusion coefficient;tasa crecimiento;clockspeed;actualizacion;modelisation;imitacion;research and development;innovation;temps occupation;investigacion desarrollo;marche;firm;growth rate;tiempo ocupacion;time pacing;produit nouveau;fonction cout;or in research and development;coeficiente difusion;willingness to pay;innovacion;new product development;modeling;diffusion;working paper;desarrollo producto;updating;recherche et developpement;product development	Some firms (such as Intel and Medtronics) use a time–pacing strategy for new product development, introducing new generations at regular intervals. If the firm adopts a fast pace (introducing frequently) then it prematurely cannibalizes its old generation and incurs high development costs, while if it waits too long, it fails to capitalize on customer willingness–to– pay for more advanced technology. We develop a model to gain insight into which factors drive the pace. We consider the degree to which a new generation stimulates market growth, the rate at which it diffuses (its coefficients of innovation and imitation), the rate of decline in its margin over time, and the cost of new product development. The optimization problem is non–concave; however we are able to solve it numerically for a wide range of parameters because there is a finite number of possible solutions for each case. Somewhat intuitively, we find that a faster pace is associated with a higher market growth rate and faster margin decay. Not so intuitively, we find that relatively minor differences in the new product development cost function can significantly impact the optimal pace. Regarding the Bass coefficients of innovation and imitation, we find that a higher sum of these coefficients leads to a faster pace but with diminishing effects, and that for relatively higher sums the coefficients are effectively	beneath a steel sky;coefficient;concave function;loss function;margin classifier;mathematical optimization;new product development;numerical analysis;optimization problem;waits	Cheryl T. Druehl;Glen M. Schmidt;Gilvan C. Souza	2009	European Journal of Operational Research	10.1016/j.ejor.2007.09.043	simulation;economics;marketing;operations management;engineering design process;new product development	Metrics	2.769778275547755	-5.048888730245407	126108
0985f3cdbaede8c89b00fcdab270021a0080fae0	dynamic cournot duopoly games with nonlinear demand function	multi team duopoly;bifurcation;bounded rationality;stability;discrete duopoly model	In this paper, dynamic duopolistic Cournot models are investigated with discrete time scales under the assumption of unknown inverse demand function and linear cost. With this motivation, we consider different types of models: bounded rational duopoly, Puu's duopoly, bounded rational duopoly with delay, and bounded rational multi-team model. In these models, the firms use two important adjustment mechanism, the bounded rationality and Puu's approach, to update their quantity in each period. The locally asymptotic stability of the fixed point of each model is investigated and complex dynamic characteristics including period doubling bifurcation, strang attractors and chaotic phenomena are also discussed. Numerical simulations are carried out to show such complex behavior of the four models and to point out the impact of the models' parameters on the stability of the fixed points.	nonlinear system	S. S. Askar;Ahmad M. Alshamrani;Khalid Abdulaziz Alnowibet	2015	Applied Mathematics and Computation	10.1016/j.amc.2015.02.072	stability;mathematics;mathematical economics;statistics;bounded rationality	Theory	-3.732276118454929	-4.35489492369799	126171
b15aa62067cf1374c4f242d425889396ad2d7c5d	multi-unit auctions with budget limits	multi unit auctions;incentive compatibility;satisfiability;budget constraints;multi unit auction;auction theory;budget constraint;individual rationality;pareto optimality	We study multi-unit auctions for bidders that have a budget constraint, a situation very common in practice that has received relatively little attention in the auction theory literature. Our main result is an impossibility: there is no deterministic auction that (1) is individually rational and dominant-strategy incentive-compatible, (2) makes no positive transfers, and (3) always produces a Pareto optimal outcome. In contrast, we show that Ausubelʼs “clinching auction” satisfies all these properties when the budgets are public knowledge. Moreover, we prove that the “clinching auction” is the unique auction that satisfies all these properties when there are two players. This uniqueness result is the cornerstone of the impossibility result. Few additional related results are given, including some results on the revenue of the clinching auction and on the case where the items are divisible.		Shahar Dobzinski;Ron Lavi;Noam Nisan	2012	Games and Economic Behavior	10.1016/j.geb.2011.08.003	walrasian auction;auction algorithm;budget constraint;vickrey auction;combinatorial auction;generalized second-price auction;economics;unique bid auction;vickrey–clarke–groves auction;common value auction;revenue equivalence;english auction;microeconomics;mathematical economics;bid shading;welfare economics;auction theory;commerce;forward auction	Theory	-3.5023756958390573	-2.3838321586204048	126335
bcb8769528dc34c7dfe7927f1b6f2ef6d7ad7ca7	eoq model for items with weibull distribution deterioration, shortages and trended demand	modelizacion;optimal solution;analisis sensibilidad;optimisation;optimizacion;penurie;peticion;ley weibull;deterioracion;inventory model;inventory;modelisation;weibull distribution;penuria;sensitivity analysis;demande;aprovisionamiento;approvisionnement;deterioration;analyse sensibilite;sensibilite parametrique;optimization;supply;parametric sensitivity;modeling;demand;shortage;loi weibull;inventaire;sensibilidad parametrica;inventario	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	economic order quantity;francis;primary source	A. K. Jalan;Bibhas Chandra Giri;K. S. Chaudhuri	1996	Int. J. Systems Science	10.1080/00207729608929285	supply;weibull distribution;systems modeling;inventory;economic shortage;forensic engineering;operations research;sensitivity analysis;demand	Robotics	6.222307549268474	-3.268743509857668	126343
a02183b173d819ef418d4edd147ca2505c929a5f	exergoeconomic assessment of solar absorption and absorption-compression hybrid refrigeration in building cooling		The paper mainly deals with the match of solar refrigeration, i.e., solar/natural gas-driven absorption chiller (SNGDAC), solar vapor compression–absorption integrated refrigeration system with parallel configuration (SVCAIRSPC), and solar absorption-subcooled compression hybrid cooling system (SASCHCS), and building cooling based on the exergoeconomics. Three types of building cooling are considered: Type 1 is the single-story building, type 2 includes the two-story and three-story buildings, and type 3 is the multi-story buildings. Besides this, two Chinese cities, Guangzhou and Turpan, are taken into account as well. The product cost flow rate is employed as the primary decision variable. The result exhibits that SNGDAC is considered as a suitable solution for type 1 buildings in Turpan, owing to its negligible natural gas consumption and lowest product cost flow rate. SVCAIRSPC is more applicable for type 2 buildings in Turpan because of its higher actual cooling capacity of absorption subsystem and lower fuel and product cost flow rate. Additionally, SASCHCS shows the most extensive cost-effectiveness, namely, its exergy destruction and product cost flow rate are both the lowest when used in all types of buildings in Guangzhou or type 3 buildings in Turpan. This paper is helpful to promote the application of solar cooling.	chomsky hierarchy;computer cooling;nsa product types	Yue Jing;Zeyu Li;Liming Liu;Shengzi Lu	2018	Entropy	10.3390/e20020130		PL	7.746613887964719	-6.939199689923396	126432
e369f5841fdb28644e661454d89e0157941b992c	efficient formulations for dynamic warehouse location under discrete transportation costs	safety stock;supply chain design;mixed integer linear programming;discrete transportation cost;facility location	A Mixed-integer Linear Programming model is proposed to determine the optimal number, location and capacity of the warehouses required to support a long-term forecast for a business with seasonal demand. Discrete transportation costs, dynamic warehouse contracting, and the handling of safety stock are the three main distinctive features of the problem. Four alternatives for addressing discrete transportation costs are compared. The most efficient formulation is obtained using integer variables to account for the number of units used of each transportation mode. Contracting policies constraints are derived to ensure use of warehouses for continuous periods. Similar constraints are included for the case when a warehouse is closed. Safety stock with risk-pooling effect is considered using a piecewise-linear representation. To solve large-scale problems, tightening constraints, and simplified formulations are proposed. These formulations are based on single-sourcing assumptions and yield near-optimal results with a large reduction in the solution time and a low impact on the optimum cost.	algorithm;decomposition (computer science);facility location problem;flip-flop (electronics);integer factorization;linear approximation;linear programming relaxation;mathematical optimization;network planning and design;optimization problem;outsourcing;piecewise linear continuation;programming model;propositional calculus;safety stock	Braulio Brunaud;Matthew H. Bassett;Anshul Agarwal;John M. Wassick;Ignacio E. Grossmann	2018	Computers & Chemical Engineering	10.1016/j.compchemeng.2017.05.011	mathematical optimization;computer science;facility location problem;mathematics	AI	9.708863698098051	-2.2897340406500564	126691
762e00cafa38bbd06cc17c5617d0d715dd311f2a	the effectiveness of several performance bounds for capacitated production, partial-order-service, assemble-to-order systems	performance measure;performance estimation;setwise lower upper bounds;upper bound;probability distribution;performance measures;assemble to order;performance bounds;manufacturing system;partial order;assemble to order manufacturing systems	We consider an assemble-to-order (ATO) system: Components are made to stock by production facilities with finite capacities, and final products are assembled only in response to customers’ orders. The key performance measures in this system, such as order fill rates, involve evaluation of multivariate probability distributions, which is computationally demanding if not intractable. The purpose of this paper is to develop computationally efficient performance estimates. We examine several ideas scattered in diverse literatures on approximations for multivariate probability distributions, and determine which approach is most effective in the ATO application. To do so, we first tailor different approximation ideas to the ATO setting to derive performance bounds, and then compare these bounds theoretically and numerically. The bounds also allow us to make connections between capacitated and uncapacitated ATO systems and gain various insights. (Assemble-to-Order Manufacturing Systems; Performance Measures; Setwise Lower/Upper Bounds)	algorithmic efficiency;approximation;numerical analysis	Savas Dayanik;Jing-Sheng Song;Susan H. Xu	2003	Manufacturing & Service Operations Management	10.1287/msom.5.3.230.16033	partially ordered set;probability distribution;mathematical optimization;operations management;upper and lower bounds;no-arbitrage bounds;statistics	ML	4.184365756287791	-1.9012993079892742	126716
8e09c2fceac7ac68c6f12700530a2910d1e89f7a	three-phase distribution opf in smart grids: optimality versus computational burden	distributed system;optimal solution;genetic algorithms unbalanced distribution systems real time operation optimal power flow smart grids;unbalanced distribution systems;mixed integer non linear programming;nonlinear programming;distribution networks;optimal power flow;load modeling real time systems capacitors switches computational modeling smart grids;computer model;heuristic method;distribution system operators;distributed optimization;smart grids;distribution feeders three phase distribution opf smart grids computational burden mixed integer nonlinear programming optimal power flow genetic algorithm;computational modeling;smart power grids;integer programming;capacitors;genetic algorithm;genetic algorithms;power flow;switches;computational efficiency;load modeling;real time application;real time operation;smart power grids distribution networks genetic algorithms integer programming nonlinear programming;real time systems	Existing Mixed Integer Non-linear Programming (MINLP) solution methods and commercially available solvers lack computational efficiency and robustness in solving three-phase Distribution Optimal Power Flow (DOPF) programs, given the large number of continuous and integer variables encountered in practical sized systems. A heuristic approach to solve this problem was proposed by the authors, in which a compromise is made on optimality in order to reduce the computational burden. In the present work, a Genetic Algorithm (GA) based method is applied to determine the optimal solution to the three-phase DOPF problem, and is compared with the heuristic solution in terms of both optimality and computational burden. Two distribution feeders, namely, the IEEE 13-node feeder and a practical feeder from Hydro One are used for these comparisons. The results show that the GA-based method yields superior solutions in terms of optimality but at a rather large computational cost, making it unsuitable for practical implementation. The heuristic method is shown to yield solutions reasonably close to the global optima at a significantly reduced computational burden, demonstrating that the heuristic solution method has the potential to improve distribution system operation in practical real-time applications.	algorithmic efficiency;computation;genetic algorithm;heuristic;linear programming;real-time clock;software release life cycle	Sumit Paudyal;Claudio A. Cañizares;Kankar Bhattacharya	2011	2011 2nd IEEE PES International Conference and Exhibition on Innovative Smart Grid Technologies	10.1109/ISGTEurope.2011.6162628	control engineering;mathematical optimization;theoretical computer science;mathematics	Robotics	6.613061346644657	3.727532971304178	126841
9c8c5d1358df58a598eb7962794fa05ad8d94648	on the use of simulation in support of capital utilization	cost reduction;industrial economics;production management;semiconductor industry;capital utilization;full fab simulation;matched cycle time;maximum velocity;production efficiency;semiconductor manufacturing	"""This paper provides a modeling approach for dealing with the challenging question of trade-off between capital utilization and production efficiency in semiconductor manufacturing where the ultimate goal is of maximum output at maximum velocity and minimum cost. Full fab simulation is used iteratively between models of """"horizontal"""" and """"vertical"""" simulations in order to rapidly generate results for different possible states of the fab with varying capital costs, matched cycle time (CT), and fixed throughput rate, so as to determine the most efficient operating condition for the fab with respect to cost, CT, and output."""	magnetic-core memory;semiconductor device fabrication;semiconductor fabrication plant;simulation;throughput;velocity (software development)	Adar Kalir;Dean Grosbard	2014	Proceedings of the Winter Simulation Conference 2014		simulation	EDA	9.68027622030178	4.006668797007817	126971
dc563c7bc86f4dc91df6f1e1af18f89240e516ec	assessing survivability to support power grid investment decisions	active power;optimization;power grids;survivability;reactive power	The reliability of power grids has been subject of study for the past few decades. Traditionally, detailed models are used to assess how the system behaves after failures. Such models, based on power flow analysis and detailed simulations, yield accurate characterizations of the system under study. However, they fall short on scalability. In this paper, we propose an efficient and scalable approach to assess the survivability of power systems. Our approach takes into account the phased-recovery of the system after a failure occurs. The proposed phased-recovery model yields metrics such as the expected accumulated energy not supplied between failure and full recovery. Leveraging the predictive power of the model, we use it as part of an optimization framework to assist in investment decisions. Given a budget and an initial circuit to be upgraded, we propose heuristics to sample the solution space in a principled way accounting for survivability-related metrics. We have evaluated the feasibility of this approach by applying it to the design of a benchmark distribution automation circuit. Our empirical results indicate that the combination of survivability and power flow analysis can provide meaningful investment decision support for power systems engineers. & 2016 Elsevier Ltd. All rights reserved.	benchmark (computing);data-flow analysis;decision support system;feasible region;heuristic (computer science);ibm power systems;mathematical optimization;scalability;simulation;systems engineering	Anne Koziolek;Alberto Avritzer;Sindhu Suresh;Daniel Sadoc Menasché;Morganna C. Diniz;Edmundo de Souza e Silva;Rosa Maria Meri Leão;Kishor S. Trivedi;Lucia Happe	2016	Rel. Eng. & Sys. Safety	10.1016/j.ress.2016.05.015	reliability engineering;simulation;engineering;ac power	EDA	6.053299596403693	3.7588322592482513	127063
7dce13f3bf90ea84ca5fd75f5391cc9f644a371a	contract efficiency for a decentralized supply chain in the presence of quality improvement	quality improvement;contract parameter;contract efficiency;coordination	Abstract#R##N##R##N#In this paper, we study a joint pricing and product quality decision problem in a decentralized supply chain consisting of one manufacturer and one retailer. Although the manufacturer decides the product quality with an associated cost, the retailer decides the retail price. We aim to study and compare different contract formats for this decentralized supply chain. There is a trade-off in the choice of contracts: simpler format contract (with a few parameters) is less complicated, but the contract efficiency is low. We start with the simplest one-parameter contract: a wholesale price contract that serves as the benchmark. We then study how contract efficiency can be improved by adding one more parameter. Specifically, we consider three two-parameter contracts that are commonly used in reality: two-part tariff contract, revenue-sharing contract, and effort cost sharing contract. We find that the contract efficiency is improved under all the three contracts, but in different ways: the improvement in contract efficiency under each of them dominates the other two when manufacturer's quality improvement effectiveness is relatively low, moderate, and high, respectively. Furthermore, through numerical examples, we find that under some cases, a choice from these three two-parameter contracts can achieve a close-to-perfect efficiency (>85%). Finally, we investigate whether a combination of the three two-parameter contracts can achieve coordination. Interestingly, we find that only the combination of effort cost sharing contract and revenue-sharing contract can achieve coordination, whereas combinations of either of them and two-part tariff contract cannot.		Xinghao Yan	2015	ITOR	10.1111/itor.12106	contract management;quality management;operations management;microeconomics;completed-contract method;commerce	Logic	-0.35781774742864525	-6.122628020674117	127205
9ccd9dccc6962a66aca76208e5c89315eabaa158	optmial plans for aggregation	multi party computation;byzantine agreement;broadcast;quantum signatures;independent and identically distributed;public key infrastructure	We consider the following problem, which arises in the context of distributed Web computations. An aggregator aims to combine specific data from n sources. The aggregator contacts all sources at once. The time for each source to return its data to the aggregator is independent and identically distributed according to a known distribution. The aggregator at some point stops waiting for data and returns an answer depending only on the data received so far. If the aggregator returns the aggregated information from k of the n sources at time t it obtains a reward Rk(t) that grows with k and decreases with t. The goal of the aggregator is to maximize its expected reward.We prove that for certain broad families of distributions and broad classes of reward functions, the optimal plan for the aggregator has a simple form and hence can be easily computed.	c date and time functions;computation;news aggregator	Andrei Z. Broder;Michael Mitzenmacher	2002		10.1145/571825.571852	independent and identically distributed random variables;computer science;public key infrastructure;data mining;distributed computing;computer security;statistics	ML	-3.573447507435268	-2.236202474478697	127369
90d58a53df64b3297a11af3672925f7f8fe0fa4f	averaging techniques for competitive auctions		We study digital-goods auctions for items in unlimited supply introduced by Goldberg, Hartline and Wright. Since no deterministic algorithms are competitive for this class of auctions, one of the central research issues is how to obtain a nice probabilistic distribution over truthful algorithms. In this paper, we introduce a rather systematic approach to this goal: Consider for example the Sampling Cost Share (SCS) auction. It is well known that SCS works well if the the current bid vector produces many winners against F , the standard benchmark algorithm for competitive analysis. In fact, its competitive ratio is approaching to 2.0 as k (= the number of F (2) winners) grows. On the other hand, its competitive ratio becomes as bad as 4.0 for k = 2. Our new approach is to develop a sequence of similar cost-share type algorithms, DCSk, which work well for small k. Now we choose a sufficiently large constant N and run DCS1, DCS2, ..., DCSN and SCS with probabilities p1, p2, ..., pN and q, respectively. It should be noted that we can use LP to obtain optimal p1, p2,..., pN and q. By this averaging method, we can improve the competitive ratio of SCS from 4.0 to 3.531 and that of the currently best Aggregated Υ3 algorithm due to Hartline and McGrew from 3.243 to 3.119.	algorithm;benchmark (computing);competitive analysis (online algorithm);wright (adl)	Takayuki Ichiba;Kazuo Iwama	2010		10.1137/1.9781611973006.10	computer science;artificial intelligence;operations management;mathematical economics	Theory	-1.3106199910941783	-1.173556059727459	127384
c305cd89079a5a471354437d0038caab95fb3998	convergence of strategies in simple co-adapting games	change detection;empirical distribution;distributed artificial intelligence multi agent systems;nash equilibrium;fictitious play;iterated normal form games;sequence prediction;opponent modelling;learning in normal form games;change point detection;self play convergence	Simultaneously co-adapting agents in an uncooperative setting can result in a non-stationary environment where optimisation or learning is difficult and where the agents' strategies may not converge to solutions. This work looks at simple simultaneous-move games with two or three actions and two or three players. Fictitious play is an old but popular algorithm that can converge to solutions, albeit slowly, in self-play in games like these. It models its opponents assuming that they use stationary strategies and plays a best-response strategy to these models. We propose two new variants of fictitious play that remove this assumption and explicitly assume that the opponents use dynamic strategies. The opponent's strategy is predicted using a sequence prediction method in the first variant and a change detection method in the second variant. Empirical results show that our variants converge faster than fictitious play. However, they do not always converge exactly to correct solutions. For change detection, this is a very small number of cases, but for sequence prediction there are many. The convergence of sequence prediction is improved by combining it with fictitious play. Also, unlike in fictitious play, our variants converge to solutions in the difficult Shapley's and Jordan's games.	algorithm;converge;mathematical optimization;stationary process	Richard Mealing;Jonathan L. Shapiro	2015		10.1145/2725494.2725503	mathematical optimization;simulation;machine learning;mathematics;mathematical economics;change detection;statistics;fictitious play	AI	-2.772119412485125	1.4887687029899555	127385
8698b47520b7ba0cadc0d56d0f2cb1e3346540d7	oligopoly pricing in congested networks	satisfiability;profitability	In this paper we study the problem of oligopoly pricing in congested markets when the demand faced by every firm is stochastic. In particular, we consider a general network, where every link is owned by a firm which charges prices in order to maximize its profits. In this environment we show the existence of a pure strategy price equilibrium, where the latency functions are assumed to satisfy continuity, monotonicity and convexity. Given this existence result, we show how to compute bounds for the inefficiency and how the result can be adapted to study price and capacity competition.	convex function;scott continuity	Emerson Goncalves Melo	2010		10.1145/1807406.1807409	financial economics;economics;microeconomics;welfare economics	Theory	-0.708523590324332	-3.766530326489371	127399
73e52cea7fe500af02ae78dabe9bee011330c0e3	selling to a no-regret buyer		"""We consider the problem of a single seller repeatedly selling a single item to a single buyer (specifically, the buyer has a value drawn fresh from known distribution D in every round). Prior work assumes that the buyer is fully rational and will perfectly reason about how their bids today affect the seller's decisions tomorrow. In this work we initiate a different direction: the buyer simply runs a no-regret learning algorithm over possible bids. We provide a fairly complete characterization of optimal auctions for the seller in this domain. Specifically: - If the buyer bids according to EXP3 (or any """"mean-based"""" learning algorithm), then the seller can extract expected revenue arbitrarily close to the expected welfare. This auction is independent of the buyer's valuation D , but somewhat unnatural as it is sometimes in the buyer's interest to overbid. - There exists a learning algorithm A such that if the buyer bids according to A then the optimal strategy for the seller is simply to post the Myerson reserve for D every round. - If the buyer bids according to EXP3 (or any """"mean-based"""" learning algorithm), but the seller is restricted to """"natural"""" auction formats where overbidding is dominated (e.g. Generalized First-Price or Generalized Second-Price), then the optimal strategy for the seller is a pay-your-bid format with decreasing reserves over time. Moreover, the seller's optimal achievable revenue is characterized by a linear program, and can be unboundedly better than the best truthful auction yet simultaneously unboundedly worse than the expected welfare."""	algorithm;entropy maximization;linear programming;monopoly;network switch;regret (decision theory);value (ethics)	Mark Braverman;Jieming Mao;Jon Schneider;S. Matthew Weinberg	2018		10.1145/3219166.3219233	microeconomics;common value auction;bond for deed;regret;as is;mathematics;credit note;mechanism design;revenue;buyer's premium	ECom	-2.622310205573462	-2.2067745538987267	127610
d402a4f175ff0a8798741afeaeda80bc5af8b0ac	inventory control and pricing for regret-averse newsvendor		The decision maker’s perception of regret affects a company’s inventory control and pricing decisions. In this paper, we investigate how regret aversion behaviors affect the inventory control and pricing decisions under a newsvendor setting. To capture the regret aversion behaviors of the newsvendor, we provide a regret aversion utility function. Based on the built regret aversion utility function and the classic inventory control and pricing model, we construct utility function by integrating the profit utility and the regret aversion utility, and then analyze the conditions of optimal solution on the inventory and pricing policy under additive and multiplicative demand in details. Further, by the analysis of properties and numerical study, we show that the optimal policy for regret-averse newsvendor deviates from the one for regret-neutral newsvendor and changes with the regret aversion parameters to varying degree. We also show the impact tendency of newsvendor’s regret aversion behaviors on the optimal inventory and pricing policy under the additive and multiplicative demand.	inventory control;newsvendor model;regret (decision theory)	Bing-Bing Cao;Zhi-Ping Fan;Hongyan Li;Tian-Hui You	2017	RAIRO - Operations Research	10.1051/ro/2017005	newsvendor model;extended newsvendor model	Robotics	0.4716096531521306	-6.641040750641535	127614
62a04a10c7d1b38e0307ed56e98bc06ebc838b8e	synthesis of robust water reuse networks for single-component retrofit problems using symmetric fuzzy linear programming	computacion informatica;water reuse;water reuse network;grupo de excelencia;process integration;water consumption;mathematical programming;ciencias basicas y experimentales;quimica;fuzzy linear programming;water pollution;89 60	Water integration techniques can be used to minimize the utility water consumption and effluent generation of process plants through the implementation of reuse or recycle networks. There are a number of graphical and mathematical programming techniques available for the synthesis of such water reuse networks. However, effective use of these methods requires the availability of reliable process data, which in reality might be difficult to acquire. This paper describes a procedure for the synthesis of robust water reuse networks from imprecise data using symmetric fuzzy linear programming (SFLP). Two model variants, one based on mass exchange units and the other on source/sink allocation, are presented. Each variant is illustrated with a numerical example.	linear programming	Raymond R. Tan;Dennis E. Cruz	2004	Computers & Chemical Engineering	10.1016/j.compchemeng.2004.06.016	real-time computing;environmental engineering;engineering;chemical engineering;process integration;water pollution	AI	9.423109605790806	-4.49387951711429	127717
02a6dcaeaab891973b08f5c10b709854d238e5cb	are we really solving the dynamic traffic equilibrium problem with a departure time choice?				Ren-Yong Guo;Hai Yang;Hai-Jun Huang	2018	Transportation Science	10.1287/trsc.2017.0764		AI	1.3985222662987966	0.821245579688037	127835
a61317b745472479281c73f3432d687d874a2944	modeling of control loop in production scheduling for overall inventory cost reduction	control systems;job shop scheduling;processor scheduling;random number generation;production system;simulation;cost reduction;lean production;lead time;production process;promodel production scheduling lean production simulation;computational modeling;production control;computer aided manufacturing;work in process;mathematical model;production systems;costs job shop scheduling production systems processor scheduling lean production random number generation computer aided manufacturing control systems mathematical model computational modeling;production scheduling;promodel	Performance of manufacturing organization depends on production scheduling which is an essential part of the management of production systems. Effective scheduling can lead to performance which results in reducing work in process inventories [1]. According to the lean production principles, excessive production and high inventory level are the biggest waste in production process [2]. Inventory level higher then it is necessary for fulfilling the costumer demands, leads to additional costs in warehouse. Objectives of production control are graphically represented over time in diagrams: inventory, lead time, input orders and output of production process. In this paper, the fact that the input and output amount of work coming from released orders of one product are not equal in every period, results with a technique to balance input against output continuously, to establish a control loop.	control system;diagram;input/output;inventory;production system (computer science);scheduling (computing)	Nikola Gjeldum;Ivica Veza;Drazen Bajic	2008	Tenth International Conference on Computer Modeling and Simulation (uksim 2008)	10.1109/UKSIM.2008.52	backflush accounting;job shop scheduling;inventory theory;simulation;computer science;engineering;artificial intelligence;industrial engineering;scheduling;production system;manufacturing engineering;cycle count	Robotics	10.024660852494026	3.9230055891629285	128016
441f40e6b9e1bd46778623ae026005127d0ba8a5	on the optimality of fixed-up-to tariff for telecommunications service	nonlinear pricing;queuing delays;menu of plans;tariff design	A tariff is the total charge payable by a customer for services provided. We study the design of tariffs for a telecommunications service provider. We develop an economic model that captures the negative externalities of the network and the diversity of customers. The tariff is designed so that it reflects the expected response of different customers and the system congestion it would induce. We study a simple tariff structure in wide use by mobile phone carriers---a menu of “fixed-up-to (FUT)” plans like “fixed access fee $35 up to 300 minutes, and $0.40 per minute beyond the limit.” We derive the optimal menu of FUT plans and show that such a simple FUT menu structure delivers as good performance to the monopolistic carrier as any nonlinear pricing schedule.		Yasushi Masuda;Seungjin Whang	2006	Information Systems Research	10.1287/isre.1060.0097	economics;marketing;microeconomics;commerce	HPC	-1.0879875599714381	-4.714452901943756	128259
57705ea28fd473fbd89c626140d58a2d6a074680	a real options design for quality control charts	monte carlo methods;quality control;statistical process control;monte carlo simulation;assignable cause;financial model;manufacturing process;market dynamics;profitability;quality control charts;quality control decision;real options design;statistical process control chart	We develop a financial model for a manufacturing process where quality can be affected by an assignable cause. We evaluate the options associated with applying a statistical process control chart using pentanomial lattice and Monte Carlo simulation methods. By connecting the aspects of market dynamics with the manufacturing operational aspects, we now have a way to help decision makers address the bottom-line profitability associated with the quality control decision.	chart;financial modeling;monte carlo method;monte carlo methods for option pricing;simulation	Harriet Black Nembhard;Leyuan Shi;Mehmet Aktan	2000			simulation;systems engineering;engineering;mathematics;statistics;monte carlo method	Robotics	7.170080161074444	-5.1174357529049805	128303
e1251fe9059bd7284914f92f4bbf63aeb70825a9	a mutual subsidy mechanism for a seasonal product supply chain channel under double price regulation				Hongjun Peng;Tao Pang;Fuliang Cao;Juan Zhao	2018	APJOR	10.1142/S0217595918500471		ECom	0.09528670874584073	-7.4817092129191645	128311
0724ce3b9e566074c3e28eb4800c824481479722	flexibility analysis on a supply chain contract using a parametric linear programming model	mathematics;contracting multi period quantity flexibility parametric linear programming;optimal solution flexibility analysis supply chain contract parametric linear programming model continuous mathematical model multiperiod quantity flexibility contract qf contract car manufacturer external parts supplying company strategic level optimal nominal order quantity variation rate underpinning actual order quantity contract length convexity;industries;contracts;convex functions;vectors;supply chains contracts linear programming supply chain management;linear programming;mathematical model;optimization;contracts linear programming mathematical model convex functions vectors industries optimization	This research paper builds on existing knowledge in the field of parametric Linear Programming (pLP) and proposes a continuous mathematical model that considers a multi-period Quantity Flexibility (QF) contract between a car manufacturer (buyer) and external parts supplying company. The supplier periodically delivers parts to the car manufacturer as agreed in the contract. Due to the uncertainty of the demand for parts, the car manufacturer -in concert with the supplier-aims to develop a policy -at strategic level, that determines the optimal nominal order quantity (Q) and variation rate (β) underpinning the contract that ensures the actual order quantity satisfies the actual demand and the total cost is minimised over the contract length. The behaviour of the mathematical model has been examined in order to establish its feasibility and convexity, consequently guaranteeing an optimal solution. Simulations have been carried out to evaluate the relationship of the total cost with respect to the variation rate and the nominal quantity ordered.	computer simulation;linear programming;mathematical model;programming model	Chengbin Chu;Eric E. Longomo;Xiang Song;Djamila Ouelhadj	2014	2014 IEEE International Conference on Automation Science and Engineering (CASE)	10.1109/CoASE.2014.6899405	economics;operations management;microeconomics;mathematical economics	Robotics	1.3137237303553728	-4.478372150557565	128335
3e8d16675b5e6fbee3d1243d7bf4f11a1ddb3637	core, equilibria and incentives in large asymmetric information economies	pareto efficiency;incentive compatibility;negligible private information;walrasian allocation;asymmetric information;core;walrasian equilibrium;private information	We consider a perfectly competitive ex ante economy with a continuum of agents and negligible asymmetric information. For such an economy we recast the basic classical results on the existence of Walrasian equilibrium, core equivalence, and the blocking size of coalitions. Moreover, we examine the incentive compatibility of the ex ante Pareto, core and Walrasian allocations. © 2007 Elsevier Inc. All rights reserved. JEL classification: C71; D50; D82	blocking (computing);nash equilibrium;pareto efficiency;triune continuum paradigm;turing completeness	Yeneng Sun;Nicholas C. Yannelis	2007	Games and Economic Behavior	10.1016/j.geb.2006.11.001	industrial organization;walrasian auction;information asymmetry;core;private information retrieval;general equilibrium theory;economics;incentive compatibility;microeconomics;welfare economics	AI	-4.273018565995867	-3.27385639386071	128359
aad56a667df995d7fcf1934a01dc6b0d00e2ef24	collaborative cost reduction and component procurement under information asymmetry	procurement;collaboration;grupo de excelencia;asymmetric information;contracting;administracion de empresas;economia y empresa;grupo a;product development	During development of an innovative product there is often considerable uncertainty about component production cost, and it is of interest for both the manufacturer and the supplier to engage in a collaborative e¤ort to reduce this uncertainty and lower the expected cost. Despite the obvious benets this brings, the supplier may be reluctant to collaborate as he fears revealing his proprietary cost information. We investigate how information asymmetry and procurement contracting strategies interact to inuence the supply chain partiesincentives to collaborate. We consider a number of procurement contracting strategies, and identify a simple strategy, Expected Margin Commitment (EMC), that e¤ectively promotes collaboration. The manufacturer prefers EMC if collaboration leads to a large reduction in unit cost and/or demand variability is low. Otherwise, a screening contract based on price and quantity is preferred. We also nd that, paradoxically, ex-post e¤orts to enhance supply chain e¢ ciency may hinder ex-ante collaboration that precedes production.	commitment ordering;heart rate variability;procurement	Sang-Hyun Kim;Serguei Netessine	2013	Management Science	10.1287/mnsc.1120.1573	information asymmetry;economics;procurement;marketing;operations management;microeconomics;management;new product development;commerce;collaboration	AI	-1.2381535558985728	-6.939728204380273	128366
98c93a86df9b2beeb4b1cad83978ea174fefc0a3	dynamic contract to regulate energy management in microgrids	distributed power generation;power distribution planning;heuristic programming;energy management systems;stochastic programming contracts distributed power generation energy management systems heuristic programming load forecasting power distribution economics power distribution planning power grids purchasing;contracts;load forecasting;purchasing;microgrids contracts energy storage benchmark testing renewable energy sources aggregates;suboptimal purchasing policy energy management regulation unreliable renewable energy source storage capacity local consumer random demand microgrid energy purchasing fluctuation grid energy generation dynamic contract mechanism energy purchasing regulation stochastic dynamic programming load prediction optimal purchase planning heuristic algorithm;power distribution economics;power grids;stochastic programming	Powered by unreliable renewable energy sources, microgrids with limited storage capacities need to purchase supplementary energy from the main grid to support local consumers' random demand. The high variability of renewable energy increases a microgrid's energy purchasing fluctuation over time and makes the main grid's energy generation and supply more unscheduled and risky. This paper proposes a dynamic contract mechanism to regulate microgrids' energy purchasing over time, while the mismatch between renewable supply and local demand in each microgrid is efficiently resolved. The contract sets time-specific purchasing commitments for a microgrid to fulfill, yet still provides the microgrid with flexibility to change future commitments. Under the contract, a stochastic dynamic program is formulated for each microgrid to update commitments according to current storage status and future load prediction. As the microgrid's optimal purchase planning is complex to analyze, we further propose a heuristic algorithm to develop a suboptimal purchasing policy which is threshold-based and easy to implement. Extensive simulations show that the proposed contract can significantly reduce microgrids' purchasing fluctuation even though a large flexibility is allowed to change commitments. The contract smoothes out more purchasing fluctuations when fewer microgrids connect to the main grid or the net load variation in each microgrid increases.	algorithm;heart rate variability;heuristic (computer science);microgrid;purchasing;quantum fluctuation;simulation;smoothing	Lingjie Duan;Rui Zhang	2013	2013 IEEE International Conference on Smart Grid Communications (SmartGridComm)	10.1109/SmartGridComm.2013.6688034	operations management;microeconomics;business;commerce	Robotics	3.135865494409684	3.8842266072488907	128392
92e8a85a475b289e3ee9ca26760e86f086f28a6e	mechanism design via consensus estimates, cross checking, and profit extraction	consensus;game theory;random sampling;envy freedom;profit extraction;prior free mechanism design;profitability;mechanism design;combinatorial auction	There is only one technique for prior-free optimal mechanism design that generalizes beyond the structurally benevolent setting of digital goods. This technique uses random sampling to estimate the distribution of agent values and then employs the Bayesian optimal mechanism for this estimated distribution on the remaining players. Though quite general, even for digital goods, this random sampling auction has a complicated analysis and is known to be suboptimal. To overcome these issues we generalize the consensus and profit extraction techniques from Goldberg and Hartline [2003] to structurally rich environments that include, for example, single-minded combinatorial auctions.	monte carlo method;sampling (signal processing)	Bach Q. Ha;Jason D. Hartline	2012		10.1145/2465769.2465773	mechanism design;game theory;sampling;mathematical optimization;combinatorial auction;consensus;economics;operations management;microeconomics;mathematical economics;welfare economics;profitability index	Theory	-2.5674443375046	-4.01489465367384	128407
f98bf79d89f30d671ecddc023bb0de46d6662400	an interval-parameter fuzzy two-stage stochastic program for water resources management under uncertainty	loi discrete;discrete distribution;ley discreta;water resource;optimisation;water policy;matrice intervalle;fuzzy programming;optimizacion;stochastic method;optimization technique;penurie;uncertainty;ressource eau;water resources;logique floue;analisis decision;eau;logica difusa;programmation stochastique;probabilistic approach;decision analysis;preparacion serie fabricacion;fuzzy logic;systeme incertain;stochastic optimization;planificacion;matriz intervalo;gestion recurso agua;penuria;enfoque probabilista;approche probabiliste;probability distribution;environment;recurso agua;interval matrix;gestion ressource eau;methode stochastique;possibility theory;planning;optimization;aritmetica intervalo;agua;process planning;water resource management;programmation floue;planification;interval arithmetic;arithmetique intervalle;stochastic programming;sistema incierto;preparation gamme fabrication;shortage;programming;uncertain system;programacion estocastica;analyse decision;water;teoria posibilidad;programacion difusa;theorie possibilite;metodo estocastico	This study presents an interval-parameter fuzzy two-stage stochastic programming (IFTSP) method for the planning of water-resources-management systems under uncertainty. The model is derived by incorporating the concepts of interval-parameter and fuzzy programming techniques within a two-stage stochastic optimization framework. The approach has two major advantages in comparison to other optimization techniques. Firstly, the IFTSP method can incorporate pre-defined water policies directly into its optimization process and, secondly, it can readily integrate inherent system uncertainties expressed not only as possibility and probability distributions but also as discrete intervals directly into its solution procedure. The IFTSP process is applied to an earlier case study of regional water resources management and it is demonstrated how the method efficiently produces stable solutions together with different risk levels of violating pre-established allocation criteria. In addition, a variety of decision alternatives are generated under different combinations of water shortage.	stochastic programming	Imran Maqsood;Guo H. Huang;Julian Scott Yeomans	2005	European Journal of Operational Research	10.1016/j.ejor.2003.08.068	stochastic programming;probability distribution;probabilistic-based design optimization;mathematical optimization;decision analysis;artificial intelligence;operations management;stochastic optimization;mathematics;operations research;statistics	Robotics	8.094286847208286	-4.363335229485905	128544
2d8f2a3b089d77b3e3cbae669eb17ed5437c94f4	on the complexity of the core over coalition structures	coalitional game;special case;complexity issue;feasible coalition;related stability concept;polynomial-time computable function;coalition structure viewpoint;relevant core-related question;computational complexity;complete picture	The computational complexity of relevant corerelated questions for coalitional games is addressed from the coalition structure viewpoint, i.e., without assuming that the grand-coalition necessarily forms. In the analysis, games are assumed to be in “compact” form, i.e., their worth functions are implicitly given as polynomial-time computable functions over succinct game encodings provided as input. Within this setting, a complete picture of the complexity issues arising with the core, as well as with the related stability concepts of least core and cost of stability, is depicted. In particular, the special cases of superadditive games and of games whose sets of feasible coalitions are restricted over tree-like interaction graphs are also studied.	computable function;computational complexity theory;time complexity	Gianluigi Greco;Enrico Malizia;Luigi Palopoli;Francesco Scarcello	2011		10.5591/978-1-57735-516-8/IJCAI11-047	combinatorics;discrete mathematics;mathematics;mathematical economics	Theory	-4.262110016661462	1.6892973321283848	128570
05c8fdf30568daef51c12ac08c9097a45ce70d06	"""erratum to """"on returns policies with exogenous price"""" [european journal of operational research 178 (3) (2007) 782-788]"""	operations research		operations research	Indranil Bose;Anand Paul	2008	European Journal of Operational Research	10.1016/j.ejor.2006.12.002	economics;computer science;public economics;mathematics;operations research	Vision	2.826314554365851	-7.782527142201678	128603
2be4c8c7e479f5b599d1c52c9cd90ccab1004b9d	influence of data uncertainty on the optimum inspection period in a multi-unit system maintained according to the block inspection policy		In the presented paper, authors focus on delay-time-based maintenance modelling issues. They present an analytical maintenance model for multi-unit systems. Implemented maintenance policy is the Block-Inspection Policy (BIP) that assumes performing inspection actions at regular time intervals of T. In the next step, the problem of data uncertainty is analysed. There is also investigated the sensitivity analysis of the proposed cost model due to probability distributions of system elements’ initial and delay times parameters change.		Anna Jodejko-Pietruczuk;Sylwia Werbinska-Wojciechowska	2016		10.1007/978-3-319-39639-2_21	reliability engineering;engineering;operations management;engineering drawing	Robotics	6.916614268836636	-1.1979229326306424	128674
2b2ed1e322088a0a48df8e9bf80b24678852d4a7	optimal trading under non-negativity constraints using approximate dynamic programming				Shahin Abbaszadeh;Tri-Dung Nguyen;Yue Wu	2018	JORS	10.1080/01605682.2017.1398201	negativity effect;computer science;mathematical optimization;dynamic programming	HCI	0.773664017831898	-1.1844083059367325	128799
e8be520bf17c72a5056d3fefde5695ee7478faec	application of stochastic programming and probabilistic analyses as key parameters for real decision making regarding implementing or not energy rationing - a case study for the brazilian hydrothermal interconnected system	hydrothermal systems;large scale systems hydrothermal systems probabilistic analysis stochastic programming decision making under uncertainty;decision making under uncertainty;probabilistic analysis;planning reservoirs load modeling mathematical model biological system modeling predictive models stochastic processes;electric power system performance monitoring probabilistic analysis key parameter decision making energy rationing dual stochastic dynamic programming multivariate inflow scenario optimization model cepel brazilian large scale interconnected hydrothermal system electrical sector brazilian monitoring committee;stochastic programming;large scale systems;stochastic programming decision making dynamic programming hydrothermal power systems power system interconnection	During 2014 and 2015, the Brazilian hydrothermal interconnected system faced critical hydrological conditions, such as extremely low multivariate inflow values on February 2014 and January 2015. Therefore, an issue that arose in early 2014 was whether the Brazilian government would have to implement or not an energy rationing. In this sense, this paper summarizes a proposed approach to technically support this decision, based on dual stochastic dynamic programming, multivariate inflows scenarios generation and probabilistic analyses, and that utilized the chain of optimization models developed by CEPEL and real configurations of the Brazilian large scale interconnected hydrothermal system. These studies, inserted in a very comprehensive and detailed technical analyses carried out by the Brazilian Monitoring Committee of the Electrical Sector, led to the decision of not implementing an energy rationing in 2014, and to continue to closely monitoring the electric power system performance.	dynamic programming;electronic data processing;goto;mathematical optimization;stochastic programming;synthetic intelligence;vii	Maria Elvira Piñeiro Maceira;A. C. G. Melo;M. P. Zimmermann	2016	2016 Power Systems Computation Conference (PSCC)	10.1109/PSCC.2016.7541014	engineering;operations management;management science;operations research	AI	5.431485333869914	2.6771837170160624	128873
e82ffe386fa34a150d94978d328dce4fe6656e6e	simulation analysis for evacuation under congested traffic scenarios: a case study	traffic simulation;pedestrian safety;case studies;poison control;injury prevention;safety literature;traffic flow;traffic safety;injury control;disaster preparedness;home safety;injury research;safety abstracts;human factors;traffic congestion;occupational safety;safety;planning and forecasting;transportation and traffic;evacuation;safety research;accident prevention;violence prevention;highway capacity;highway traffic control;bicycle safety;emergency planning and management;poisoning prevention;falls;ergonomics;suicide prevention	In this paper a new simulation modeling approach to support evacuation traffic management is introduced and a case study is presented. Traditional traffic simulation models neglect some real-life factors that need to be considered in an evacuation, such as the effect of road information and active control measures to manage traffic flow while vehicles are competing to find the best or preferred route. A passive equilibrium-seeking modeling approach may not be suitable for evacuation trip analysis due to limited route capacity and likely severe congestion during an evacuation. This paper introduces a new updated cell transmission model using discrete-event simulation, which can review and analyze the preferred path of evacuation traffic from multiple starting locations (or originations) to multiple destinations. Using this approach, case studies are conducted based on the user equilibrium principle, since it represents a natural behavior in an evacuation process. This research also demonstrates that, with the help of the cell transmission simulation model, an active traffic control mechanism can be evaluated. This study found that active traffic control measures are capable of decreasing total travel time during an evacuation by thousands of vehicle hours. Incorporating behavior consideration into the evacuation planning can help form a more accurate and realistic analysis of an evacuation plan.	network congestion;real life;simulation	Jun Duanmu;Kevin M. Taaffe;Mashrur Chowdhury;R. Michael Robinson	2012	Simulation	10.1177/0037549712454688	simulation;engineering;suicide prevention;human factors and ergonomics;injury prevention;traffic flow;transport engineering;computer security	Robotics	9.914138847984255	-9.319928435897538	128937
1b40bab24132e8b8d695ead290a2a19e47ba04ee	communication complexity of discrete fair division		We initiate the study of the communication complexity of fair division with indivisible goods. We focus on some of the most well-studied fairness notions (envy-freeness, proportionality, and approximations thereof) and valuation classes (submodular, subadditive and unrestricted). Within these parameters, our results completely resolve whether the communication complexity of computing a fair allocation (or determining that none exist) is polynomial or exponential (in the number of goods), for every combination of fairness notion, valuation class, and number of players, for both deterministic and randomized protocols.	approximation;communication complexity;fairness measure;indivisible;polynomial;randomized algorithm;submodular set function;time complexity;value (ethics)	Benjamin Plaut;Tim Roughgarden	2019		10.1137/1.9781611975482.122	fair division;subadditivity;discrete mathematics;mathematics;mathematical economics;combinatorics;submodular set function;valuation (finance);proportionality (mathematics);communication complexity;exponential function;polynomial	Theory	-2.8213579970068157	-0.3312760318123233	128943
0c9ca518b65e5fba55d1602b1ae52347303add38	scalable grid resource trading with greedy heuristics	silicon;resource management approximation algorithms grid computing computer industry algorithm design and analysis competitive intelligence software systems business electronic government scalability;markets;optimal resource trading;marketing data processing;scale effect;approximation algorithms;resource allocation;resource management;construction industry;330 wirtschaft;greedy algorithms;commerce;allocation;greedy heuristic;runtime;greedy heuristics;grid;cost accounting;marketing data processing commerce greedy algorithms grid computing;trading;match consumers scalable grid resource trading markets greedy heuristics grid infrastructures resource allocation optimal resource trading nonoptimal resource trading;allocation heuristics grid trading markets;nonoptimal resource trading;heuristics;grid infrastructures;match consumers;institutional repository research archive oaister;grid computing;benchmark testing;scalable grid resource trading markets	As Grid infrastructures become more widely used by the academic and commercial world, the problem of resource allocation increases in complexity. Resource trading markets are one mechanism that allows many resource owners and resource consumers to trade. To perform efficiently trading markets for grids require approaches to match consumers and producers. Solutions for optimal and non-optimal resource trading exist, but fail to scale effectively to meet the challenges of large numbers of traders. This paper first defines the problem of scalable resource trading in grids before describing and evaluating greedy approaches for scalability.	benchmark (computing);greedy algorithm;heuristic (computer science);hill climbing;scalability;simulated annealing;sorting;tabu search;traders;uniform resource identifier	Georg Buss;Kevin Lee;Daniel Veit	2010	2010 International Conference on Complex, Intelligent and Software Intensive Systems	10.1109/CISIS.2010.146	resource allocation;trading strategy;management science;business;commerce	HPC	-0.34337485614907287	1.5251327285878336	129244
98738d78ae353a23191138fd1ad13b2446714fdb	optimal contract period for priority service	dynamic programming;organisation marche;optimisation;optimizacion;organization management;proceso markov;industries;electric priority service of electric power;decision analysis;processus markov;markov process;optimization;applications optimal contract period;optimal contract;gestion organizacion;gestion organisation	In industries with capacity constraints and nonstorable outputs, priority service is a form of market organization in which customers subscribe in advance to the order in which they will be served from scarce supplies. The optimal duration of priority service contracts depends on a tradeoff between transaction costs and efficiency gains that, in turn, depends on the serial correlations of customers' service valuations. Using a stationary Markov process to characterize the distribution of customers' valuations, we present several simple methods that illustrate the principal determinants of the optimal contract period.		Hung-Po Chao;Robert Wilson	1990	Operations Research	10.1287/opre.38.4.598	mathematical optimization;actuarial science;decision analysis;marketing;operations management;dynamic programming;mathematics;markov process;management;operations research;statistics	OS	3.6862939305276137	-5.041047529756153	129398
5acecd59b8fc62b4a0853235064ab372c2896f0e	a distributed auction algorithm for the assignment problem	distributed computing network topology approximation algorithms mobile communication linear programming context linear approximation iterative algorithms robots distributed control;assignment problem;topology;convergence;bepress selected works;linear assignment problem;pricing;linear approximation;commerce;global computing;upper bound;network topology;facility allocation;distributed auction algorithm;local community;facility allocation distributed auction algorithm linear assignment problem linear programming distributed control;heuristic algorithms;linear programming;commerce distributed control facility location linear programming distributed auction algorithm distributed control facility allocation linear assignment problem linear programming;linear program;linear programming commerce distributed control facility location;networked systems;distributed control;algorithm design and analysis;facility location	The assignment problem constitutes one of the fundamental problems in the context of linear programming. Besides its theoretical significance, its frequent appearance in the areas of distributed control and facility allocation, where the problems¿ size and the cost for global computation and information can be highly prohibitive, gives rise to the need for local solutions that dynamically assign distinct agents to distinct tasks, while maximizing the total assignment benefit. In this paper, we consider the linear assignment problem in the context of networked systems, where the main challenge is dealing with the lack of global information due to the limited communication capabilities of the agents. We address this challenge by means of a distributed auction algorithm, where the agents are able to bid for the task to which they wish to be assigned. The desired assignment relies on an appropriate selection of bids that determine the prices of the tasks and render them more or less attractive for the agents to bid for. Up to date pricing information, necessary for accurate bidding, can be obtained in a multi-hop fashion by means of local communication between adjacent agents. Our algorithm is an extension to the parallel auction algorithm proposed by Bertsekas et al to the case where only local information is available and it is shown to always converge to an assignment that maximizes the total assignment benefit within a linear approximation of the optimal one.	assignment (computer science);assignment problem;auction algorithm;computation;converge;distributed control system;linear approximation;linear programming;network topology;shared memory	Michael M. Zavlanos;Leonid Spesivtsev;George J. Pappas	2008	2008 47th IEEE Conference on Decision and Control	10.1109/CDC.2008.4739098	auction algorithm;mathematical optimization;computer science;generalized assignment problem;linear programming;theoretical computer science;mathematics;distributed computing;assignment problem;weapon target assignment problem	AI	-1.3368007068217072	2.13973238914499	129453
a3ded25be3d651ec1f858d99c97b713c73311ec5	limitations of randomized mechanisms for combinatorial auctions	incentive compatibility;submodular valuations;algorithmic mechanism design;combinatorial auctions	We address the following fundamental question in the area of incentive-compatible mechanism design: Are truthful-in-expectation mechanisms compatible with polynomial-time approximation? In particular, can polynomial-time truthful-in-expectation mechanisms achieve a near-optimal approximation ratio for combinatorial auctions with submodular valuations?	randomized algorithm	Shaddin Dughmi;Jan Vondrák	2015	Games and Economic Behavior	10.1016/j.geb.2014.01.007	algorithmic mechanism design;mathematical optimization;combinatorial auction;economics;incentive compatibility;microeconomics;mathematical economics	ECom	-2.8243074159882715	-0.6289895594729964	129512
56551f28089e58bcfb1d5dc9956c1057be252c09	operation analysis of the electronic screening system at a commercial vehicle weigh station	weigh in motion scales;electronic screening;measurement error;travel time;simulation;goods transportation;traffic operations;weight measurement;weigh in motion;commercial vehicles;transponders;large trucks;simulation model;overweight loads;weigh stations	Electronic screening (e-screening) sorts and diverts commercial vehicles that have a high likelihood of being overweight into a weigh station using weigh-in-motion technology. E-screening is known to add significant efficiency in operating weigh stations by allowing eligible trucks to bypass the in-station inspection, hence reducing the congestion at the weigh station. The primary goal of this study was twofold: (a) to develop a simulation model for describing the e-screening operation at truck weigh stations and (b) to analyze and evaluate the weigh station operation with varying values of affecting factors including the transponder penetration rate and the weigh-in-motion weight threshold. This study focuses the e-screening operation at a small weigh station with relatively short queuing area and heavy truck volumes, which is inevitably vulnerable to truck overflows and is sensitive to the prevailing transponder penetration rate and the weigh-in-motion threshold. The simulation results reveal that an e-screening operation can substantially improve the overweight enforcement and can reduce the travel time of legal trucks passing the test weigh station. The simulation results also demonstrate that properly adjusted weigh-in-motion thresholds can effectively enhance the overweight enforcement by preventing overweight trucks from being granted a false green light as a result of the erroneous weigh-in-motion measurement error. The study results also indicate that with the transponder penetration rate equal to or less than 20%, the e-screening benefits are relatively insignificant and adjusting the weigh-in-motion threshold may further deteriorate the enforcement efficiency.	control theory;emoticon;network congestion;penetration test;ramp simulation software for modelling reliability, availability and maintainability;screening effect;simulation;transponder;wap identity module	Jinwoo Brian Lee;Garland Chow	2011	J. Intellig. Transport. Systems	10.1080/15472450.2011.570111	simulation;computer science;engineering;transponder;simulation modeling;transport engineering;forensic engineering;observational error	Mobile	8.982360493015564	-7.779177463542231	129577
ae5af254a707f03d19cb96172640b30d7984bf74	optimal pension fund composition for an italian private pension plan sponsor	secs s 06 metodi mat dell economia e scienze attuariali e finanziarie;multistage stochastic programming;optimal policy;cluster analysis;pension fund;secs p 11 economia degli intermediari finanziari	We address the problem of a private pension plan sponsor who has to find the best pension funds for its members. Starting from a descriptive analysis of the pension plan members we identify a set of representative subscribers. Then, the optimal allocation for each representative will become a pension fund of the pension plan. For each representative, we propose a multistage stochastic program (MSP) which includes a multi-criteria objective function. The optimal choice is the portfolio allocation that minimizes the average value at risk deviation of the final wealth and satisfies a wealth target in the final stage and other constraints regarding pension plan regulations. Stochasticity arises from the investor’s salary process and from asset returns. Numerical results show the optimal dynamic portfolios with respect to the investor’s preferences and then the best pension funds the sponsor might offer.		Sebastiano Vitali;Vittorio Moriggia;Milos Kopa	2017	Comput. Manag. Science	10.1007/s10287-016-0263-4	financial economics;actuarial science;economics;computer science;machine learning;finance;cluster analysis	Theory	8.766967924620097	-3.1681703545100017	129749
435d2fe4c591d1710ccee7bd85d4cee09ecf1aaa	practice summary: chemstation embarks on a new approach to customer delivery	safety stock;heuristic;selected works;vehicle routing;bepress;distribution center;telemetry;delivery scheduling	ChemStation, a cleaning-solutions company, recently embarked on a new delivery approach using telemetry to improve its customer inventory information. However, without a change in philosophy within ChemStation, the technology did not deliver the benefits anticipated. We developed a simple heuristic that allows the company to defer deliveries, effectively eliminating many deliveries and improving its economics. The improvement has led to a justification for a more sophisticated programmatic solution method.	agilent chemstation	Michael F. Gorman;Tony Ball	2015	Interfaces	10.1287/inte.2015.0813	heuristic;computer science;engineering;artificial intelligence;marketing;operations management;telemetry;management;operations research	Robotics	8.966153500706048	-2.458158363185329	129816
4c0ba2466a632ed03535233143925a470c8c8d69	simulation-based performance analysis in robotic mobile fulfilment systems - analyzing the throughput of different layout configurations		A robotic mobile fulfilment system for automated storage and retrieval of goods is investigated to determine reachable throughput as a function of the number of vehicles. The simulation model considers connected zones for manual order picking and replenishment of empty storage units. The results show a strong increase of blocking effects between vehicles if the number of vehicles within the system increases. This leads to a maximal throughput, which further vehicles cannot increase. We will show that changing the storage layout increases throughput. The results also show a linear correlation between the number of vehicles and the throughput for small numbers of vehicles. Here, analytical calculations are admissible since minor blocking effects do occur. However, the end of the linear correlation can only be found by simulation.	admissible heuristic;blocking (computing);experiment;linear function;maximal set;maximum throughput scheduling;performance;profiling (computer programming);robot;simulation	Thomas Lienert;Tobias Staab;Christopher Ludwig;Johannes Fottner	2018		10.5220/0006827103830390	real-time computing;throughput;theoretical computer science;computer science	Robotics	8.345468431342756	3.8895196944447297	129862
74b127c5c82a76aff9242bac69f2a389f7a7cf35	3d printing as an alternative supply option in spare parts inventory management		We study a spare parts stochastic production/inventory problem of a manufacturer, where he has an option to source parts from a relatively inflexible conventional regular supplier ordering in large batches with long replenishment lead time, or alternatively from a flexible in-house or outsourced 3D printing facility. We derive the dynamic programming formulation for cost associated with utilizing the 3D printing supply option and give some insights into the structure of the optimal policy. In a numerical experiment, we compare the performance of this hybrid sourcing strategy with the regular sourcing option, and provide some managerial insights.	3d printing;dynamic programming;inventory;inventory theory;numerical analysis	Marko Jaksic;Peter Trkman	2016		10.1007/978-3-319-55702-1_81	mathematics;lead time;spare part;mathematical optimization;dynamic programming;operations management;3d printing;strategic sourcing	ML	3.074964388505218	-4.546665657754191	129877
330f2a6248605a77ac6848e84329c929e4e5242b	competitive equilibria in matching markets with budgets	transferable utility;willing to pay;game theory;utility;return on investment;stable matching;utility function;strong stability;polynomial time algorithm;matching;competitive equilibrium;indivisible good;data structure;budget constraint	Consider a market with <i>n</i> unit demand buyers and <i>m</i> sellers, each selling one unit of an indivisible good. The buyers specify their preferences over items via utility functions <i>u</i><sub><i>ij</i></sub>(<i>p</i><sub><i>j</i></sub>), which is the utility of buyer <i>i</i> for item <i>j</i> when its price is <i>p</i><sub><i>j</i></sub>. So far, this is the classic Shapley-Shubik assignment model [Shapley and Shubik 1971] which captures a variety of matching markets including housing markets and ad auctions [Edelman et al. 2007], except for the extension to general utility functions instead of the quasi-linear utilities in the original model. Shapley and Shubik show that a <i>competitive equilibrium</i> always exists in their model, and later work [Crawford and Knoer 1981, Quinnzi 1984, Gale 1984] shows that a competitive equilibrium must also exist for the model with general utility functions <i>u</i><sub><i>ij</i></sub>(·), provided these <i>u</i><sub><i>ij</i></sub>(·) are strictly decreasing and continuous everywhere.	competitive programming;indivisible;stable marriage problem	Ning Chen;Xiaotie Deng;Arpita Ghosh	2010	SIGecom Exchanges	10.1145/1980534.1980539	matching;game theory;mathematical optimization;budget constraint;return on investment;stable marriage problem;data structure;economics;microeconomics;transferable utility;mathematical economics;welfare economics;utility	ECom	-2.2324175097599426	-2.174894725495486	130022
12e4c82a2efc85e3e6983680025db807b272856d	dynamics of rate-of-return regulation	accounting;depreciation;rate of return;marginal cost;dynamic properties;rate of return regulation	It is commonly accepted in the industrial organization literature that rate of return regulation leads to inefficient outcomes. Since prices are calculated so as to cover the regulated firm’s average cost, which includes the periodic fixed costs associated with plant property and equipment, the conventional argument is that prices must exceed the marginal cost of production. This paper examines the dynamic properties of the rate of return regulation process when the regulated firm periodically undertakes new capacity investments. Our analysis identifies prices which can potentially emerge as equilibria of the regulation process. It is shown that the underlying accounting (depreciation) rules determine whether these equilibrium prices will be above, equal to, or below the long run marginal cost. We provide conditions under which the rate of return regulation process is dynamically stable so that prices indeed converge to their equilibrium values.	converge;marginal model	Alexander Nezlobin;Madhav V. Rajan;Stefan Reichelstein	2012	Management Science	10.1287/mnsc.1110.1464	marginal cost;rate of return;economics;marketing;finance;microeconomics;market economy;management;depreciation;labour economics	Networks	1.3334935734364897	-5.275449819017206	130164
8c1fa53752209d9a9f1421f90e8cda357de82a32	legal determinants of the global spread of e-commerce	consumidor;commerce electronique;model specification;comercio electronico;new information communication technology;aplicacion;organismo internacional;customer governance;consommateur;e commerce;qualite;creditor rights in each country;economic model;integration;aspecto juridico;e commerce revenues and global spread of e commerce;modelo economico;droit international;derecho internacional;modele economique;person protection;international law;proteccion persona;revenu economique;quality legal rules and enforcement;consumer;international institution;integracion;quality;organisme international;legal aspect;technology integration;internacional;nouvelle technologie information communication;aspect juridique;renta;application;protection personne;international;electronic trade;calidad;nueva tecnologia informacion comunicacion;income	This paper examines the effects of quality of legal rules and enforcement, creditor rights, shareholder rights and the level of technology integration in the market on the global spread of e-commerce. We report three primary results. First, consistent with our hypotheses, quality legal rules and enforcement and creditor rights in each country are significantly and positively related to 1998 global e-commerce revenues. The relationships between shareholder rights, technology integration and e-commerce revenues are weak. Second, consistent with 1998 results, quality legal rules and enforcement and creditor rights are significantly and positively associated with 1999 global e-commerce revenues. Finally, when 1998 and 1999 data are pooled together, the results are stronger and consistent with the individual year findings. All our results are robust to alternative model specifications, time periods and scaling or non-scaling of the dependent variable. Taken together, the results underscore the importance of quality legal rules and creditor protection in global spread of e-commerce.	e-commerce	Gordian Ndubizu;Bay Arinze	2002	Int J. Information Management	10.1016/S0268-4012(02)00004-X	international law;economics;consumer;income;computer science;public economics;economic model;economy;management;law;specification	AI	-2.9712082612548687	-8.840310758625646	130269
5d4bd9dd2e2a2d39e14c40cc2fdeade41a8f6949	dynamoc: a dynamic overlapping coalition-based multiagent system for coordination of mobile ad hoc devices	task scheduling;coalitions;multiagent systems	In this work, we focus on problems modeled as a set of tasks to be scheduled and accomplished by mobile autonomous devices that communicate via a mobile ad hoc network. In such situations, the communication cost, computational efforts and environment uncertainty are key challenges. It is intuitive to consider that keeping information about tasks globally known by devices can provide better schedules. However, there are some contexts - such as those where tasks require startup based on location - where information restricted to coalitions of devices can still produce satisfactory scheduling. The existing heuristics, however, do not consider this approach. In this paper, we propose a multiagent system that coordinates the dynamic formation of overlapping coalitions and the scheduling of tasks within them. Heuristics for calculating the size of coalitions, as well as for scheduling tasks are proposed based on a Markov decision process. The system is applied to solve the problem of area coverage in a simulated environment and the results show that good schedules are obtained with lower cost of communication and computation compared with the solution based on globally known information.	agent-based model;hoc (programming language);multi-agent system	Vitor A. dos Santos;Giovanni Cordeiro Barroso;Mario F. Aguilar;Antonio de Barros Serra;José Marques Soares	2011		10.1007/978-3-642-25486-4_31	simulation;computer science;artificial intelligence;multi-agent system;distributed computing;computer network	HCI	-1.4604548410197284	3.602553602467339	130354
6b6636438e59222697bea8c8bdfa416b4cab0719	asymmetric information and imperfect competition in a continuous time multivariate security model	continuous time;security model;imperfect competition;utility function;pricing in continuous time;asymmetric information;portfolio optimization;price formation;equilibrium theory	This paper deals with the problem of price formation in a market with asymmetric information and several risky assets. We then extend the multivariate security model of Caballe and Krishnan (1994) to a continuous time framework, and general utility function. Our model enables us to observe some results which are specific to multi security markets such as Giffen effect. An application of the main result will be the non trivial generalizations of the models of Back (1992) and Cho (1997).		Guillaume Lasserre	2004	Finance and Stochastics	10.1007/s00780-003-0118-z	computer security model;financial economics;information asymmetry;general equilibrium theory;economics;finance;portfolio optimization;microeconomics;mathematical economics	Crypto	-2.974355685184021	-3.7975134546039855	130486
078c83c5754f88988788c5411acb27b949054790	expressive commerce and its application to sourcing: how we conducted $35 billion of generalized combinatorial auctions	interest based negotiation;automated negotiation	Sourcing professionals buy several trillion dollars worth of goods and services yearly. We introduced a new paradigm called expressive commerce and applied it to sourcing. It combines the advantages of highly expressive human negotiation with the advantages of electronic reverse auctions. The idea is that supply and demand are expressed in drastically greater detail than in traditional electronic auctions, and are algorithmically cleared. This creates a Pareto efficiency improvement in the allocation (a win-win between the buyer and the sellers) but the market clearing problem is a highly complex combinatorial optimization problem. We developed the world's fastest tree search algorithms for solving it. We have hosted $35 billion of sourcing using the technology, and created $4.4 billion of hard-dollar savings plus numerous harder-to-quantify benefits. The suppliers also benefited by being able to express production efficiencies and creativity, and through exposure problem removal. Supply networks were redesigned, with quantitative understanding of the tradeoffs, and implemented in weeks instead of months.	combinatorial optimization;e-commerce;fastest;mathematical optimization;optimization problem;pareto efficiency;procurement;programming paradigm;search algorithm	Tuomas Sandholm	2007	AI Magazine	10.1145/1282100.1282165	marketing;operations management;business;commerce	AI	-1.0586099858976996	-3.4867982228773315	130516
af99fcaf7973afac087661bbb1927f094a8cfded	impact of stochastically distributed renewable pv generation on distribution network	peak power stochastically distributed renewable pv generation impact decentralized renewable distributed generation systems small scale renewable distributed generation systems distribution network planning randomly distributed dg location uncertainty removal field orientation stochastic simulation algorithm stochastically dispersed residential pv systems electricity generation costs emissions variance reduction method importance sampling;sampling of representative clusters and extreme points;monte carlo methods random variables azimuth uncertainty stochastic processes standards gaussian distribution;photovoltaic pv;and stochastic monte carlo simulation distributed generation dg photovoltaic pv importance sampling sampling of representative clusters and extreme points;and stochastic monte carlo simulation;importance sampling;distributed generation dg;stochastic processes distributed power generation importance sampling multivariable systems photovoltaic power systems power distribution planning power generation economics	Small-scale and decentralized renewable distributed generation (DG) systems, especially PV systems, will soon be dispersed in distribution networks. The objective of this study is to present tools and algorithms useful for planning distribution networks enhanced by randomly distributed DG. To remove the uncertainties of the location, the capacity, and the field orientation of randomly distributed PV systems, a stochastic simulation algorithm is implemented. The stochastic simulation analyzes the impact of stochastically dispersed residential PV systems from the perspective of energy, especially regarding peak power, electricity generation costs, and emissions, and quantifies the effects of the method of variance reduction, including importance sampling.	discontinuous galerkin method;gillespie algorithm;importance sampling;page view;randomness;sampling (signal processing);simulation;variance reduction	Miroslav M. Begovic;Insu Kim;Mladen Kezunovic	2016	2016 Power Systems Computation Conference (PSCC)	10.1109/PSCC.2016.7541018	control engineering;mathematical optimization;electronic engineering;engineering	HPC	5.902434461434284	3.677613921892233	130752
e36a9979ecf34da8fd8d8e6ee4978f91a42b0528	economics modelling for the determination of test strategies for complex vlsi boards	printed circuits;decision making tool life cycle modelling cost model test strategies complex vlsi boards economics modeling board level testing interconnected economics models predictive calculations sample runs;economic modelling;economic model;economics vlsi printed circuit testing printed circuits;very large scale integration costs economic forecasting electronic equipment testing production computer aided manufacturing pulp manufacturing virtual manufacturing assembly virtual prototyping;vlsi;printed circuit testing;economics	This paper describes the economics modeling techniques developed by the authors for the determination of optimal test strategies for board level testing. A number of interconnected economics models are used to describe the test process and the quality achieved, enabling the user to make predictive calculations for the effects of design and test choices. The results of sample runs presented, which illustrate the potential of the system as a decision making tool. >	very-large-scale integration	Chryssa Dislis;J. H. Dick;I. D. Dear;I. N. Azu;Anthony P. Ambler	1993		10.1109/TEST.1993.470700	electronic engineering;simulation;computer science;engineering;economic model;very-large-scale integration;printed circuit board	Robotics	8.393633481586068	1.8808058108802408	130799
d2f28a4892df07af44299e6a9baca2328cd7a7f0	comparison of expected failure times for several replacement policies	replacement policy planning;aging stochastic processes reliability theory distribution functions operations research costs frequency preventive maintenance availability;stochastic behavior;aging;nbue lifetime distribution;reliability theory;failure analysis;renewal processes age and block replacement policies nbue aging class;statistical distributions;stochastic processes;renewal processes;nbue aging class;ageing;stochastic processes ageing failure analysis reliability theory statistical distributions;age and block replacement policies;renewal process expected failure time replacement policy planning aging reliability theory nbue lifetime distribution stochastic behavior;expected failure time;renewal process;replacement policy	"""Planned replacement policies are used to reduce the incidence of system failures, or to return a failed system to work. New better than used aging classes are commonly used in reliability theory to model situations in which the lifetime of a new unit is """"better"""" than the lifetime of a used one. The purpose of this paper is to establish comparisons of expected failure times of an age (block) replacement policy, and a renewal process with no planned replacements when the lifetime of the unit is NBUE. As we will see, age and block replacement policies improve the stochastic behavior compared with the renewal process with no planned replacements when the underlying distribution is NBUE. Some interpretations, applications, and a discussion about some related results are included"""	incidence matrix;reliability engineering	Félix Belzunce;Eva-María Ortega;José-María Ruiz	2006	IEEE Transactions on Reliability	10.1109/TR.2006.879602	ageing;reliability engineering;stochastic process;engineering;mathematics;forensic engineering;statistics	Metrics	6.945940217633546	-1.1259308884074988	131236
b0edae3bd4cf0fec0dcd121db8e4c5e35766f1d0	optimal commitments in asymmetric auctions with incomplete information	asymmetric auctions;modeling properties;first price auctions	We solve the Bayesian sequential equilibrium of a general class of single-item first-price or all-pay auctions of incomplete information. Our main contribution is a general methodology for solving the optimal commitment problem, in closed form, for asymmetric continuous-type distributions.  Our approach consists of a number of innovations. We propose a modeling concept called equal-bid function to build a bridge between two players' strategies. Another concept called equal-utility curve transforms any commitment strategy into a weakly better continuous and everywhere directional-differentiable strategy.  The optimal commitment functions in these auctions reveal some important insights. When the player with commitment power (the leader) has low valuation, he bids passively. This is a credible way to alleviate competition and to enable collusion. We demonstrate, via concrete examples, that this is a credible way to threaten the follower so that the leader can secure a higher utility.	commitment ordering;commitment scheme;jason;search engine marketing;value (ethics)	Pingzhong Tang;Zihe Wang;Xiaoquan Zhang	2016		10.1145/2940716.2940739	mathematical optimization;economics;common value auction;microeconomics;mathematical economics;welfare economics;commerce	ECom	-2.930494381136732	-4.812398313333889	131277
964459b0242f413d8bf6e26f39affddca38311a4	electronic commerce logistics network optimization based on swarm intelligent algorithm	electronic commerce;logistics network optimization;ant colony algorithm;particle swarm algorithm	This article establish an efficient electronic commerce logistics operation system to reduce distribution costs and build a logistics network operation model based on around the B2C electronic commerce enterprise logistics network operation system. B2C electronic commerce transactions features in the enterprise network platform. To solve the NP-hard problem this article use hybrid ant colony algorithm, particle swarm algorithm and group swarm intelligence algorithm to get a best solution. According to the intelligent algorithm, design of electronic commerce logistics network optimization system, enter the national 22 electronic commerce logistics network for validation. Through the experiment to verify the optimized logistics cost greatly decreased. This research can help B2C electronic commerce enterprise logistics network to optimize decision-making under the premise of ensuring the interests of consumers and service levels also can be an effective way for enterprises to improve the efficiency of logistics services and reduce operation costs.	algorithm design;ant colony optimization algorithms;e-commerce;logistics;mathematical optimization;np-hardness;operating system;particle swarm optimization;swarm intelligence	Yabing Jiao	2013	JNW	10.4304/jnw.8.9.2163-2170	e-commerce;ant colony optimization algorithms;computer science;integrated logistics support;world wide web	AI	-0.13315321212503953	2.0026484487182823	131298
be75b62ad6c502953c39313f6e133e07ee48a611	interval reliability for aggregated markov repairable system with repair time omission	availability;time interval omission;markov repairable system;interval reliability	In this paper, Markov models of repairable systems with repair time omission are considered whose finite state space is grouped into two sets, the set of working states, W , and the set of failed states, F . If the system enters failed states from a working state at any instance, and sojourns at the failed states F less than a given nonnegative critical value τ , then the repair interval can be omitted from downtime records. Otherwise, If the system enters failed states from a working state at any instance, and sojourns at the failed states F more than the given nonnegative critical value τ , then the repair interval cannot be omitted from downtime records. In terms of the assumption, a new model is developed. The focus of attention is the new model’s availability, interval reliability and interval unreliability. Several results are derived for these reliability indexes for the new model. Some special cases and numerical examples are given to illustrate the results obtained by using Maple software in the paper.	computation;downtime;interval arithmetic;maple;markov chain;markov model;numerical analysis;numerical method;reliability engineering;semiconductor industry;state space	Baoliang Liu;Lirong Cui;Yanqing Wen	2014	Annals OR	10.1007/s10479-013-1402-8	availability;mean time to repair;computer science;operations management;algorithm	Logic	6.573823746899799	-1.0010250795550162	131391
7031461e8321cd445bbf76140a6e829dad6d6f4c	instantaneous availability model with 2-d discrete characteristics of one-unit repairable systems	discrete distribution;reliability;preventive maintenance;state transition model;availability;discrete time systems;instantaneous availability model;discrete time;maintenance engineering;corrective maintenance;availability preventive maintenance numerical models delay power system reliability;repairable system;preventive maintenance time;corrective maintenance time;repair delay time;control system synthesis;repair delay availability preventive maintenance corrective maintenance;random variable;power system reliability;repair delay;delay time;numerical models;state transition model instantaneous availability model 2d discrete time one unit repairable system corrective maintenance time preventive maintenance time repair delay time;reliability control system synthesis delays discrete time systems maintenance engineering;state transition;delays;2d discrete time one unit repairable system	The discrete-time one-unit repairable system was studied, whose lifetime, repair delay time, corrective maintenance time and preventive maintenance time are all assumed to be random variables with general discrete distributions. We investigated the relationship of system states including operational state, waiting state for repair, state for preventive maintenance, and state for corrective maintenance. Then the state transition model was built. Furthermore, we established the instantaneous availability model which has the 2-D discrete characteristics, and on the basis, we proposed the optimal maintenance interval model. Finally, numerical examples were given to illustrate the proposed models.	numerical analysis;numerical method;optimal maintenance;state transition table	Yi Yang;Lichao Wang;Yongli Yu;Rui Kang	2010	2010 11th International Conference on Control Automation Robotics & Vision	10.1109/ICARCV.2010.5707785	maintenance engineering;probability distribution;reliability engineering;random variable;preventive maintenance;availability;discrete time and continuous time;real-time computing;engineering;reliability;statistics;corrective maintenance	Robotics	6.780930317077509	-0.49601452758902415	131576
b5da982f6d5dfddfe62439d4be8b70f176b72e2c	a discrete semi-markov decision model to determine the optimal repair/replacement policy under general repairs	decision models;semi markov decision process;state space;semi markov;markov process;general repair;markov processes;renewals;replacement policy	The state of a machine (system) that may experience failures is characterized by the real age of the machine and the number of failures incurred to date. On failure, the unit may undergo a repair which can partially reset the failure intensity of the unit. In this paper, it is assumed that repairs can, at most, shift back the failure intensity so as to remove the most recent run-time sojourn. The other alternative at a failure is to conduct a major overhaul that serves to refresh the failure intensity of the unit. General cost structures, depending upon both real age and number of failures are permitted. The decision, on failure to repair or renew is formulated as a discrete semi-Markov decision process with real age and number of failures as the state space. Optimal decisions are of the threshold type. That is, on the  n th failure, if the real age is above a predetermined threshold value, refresh; otherwise conduct an imperfect repair.	markov chain;semiconductor industry	C. E. Love;Zhe George Zhang;M. A. Zitron;Renkuan G. Guo	2000	European Journal of Operational Research	10.1016/S0377-2217(99)00009-0	simulation;partially observable markov decision process;operations management;mathematics;markov process;statistics	ML	6.683178449080193	-1.0812739530617759	131688
49d2f5d83373bd92dd274846ebb8dda512bb6819	optimal interconnection planning of community microgrids with renewable energy sources	reliability;renewable energy sources;microgrids reliability planning power system reliability renewable energy sources probabilistic logic economics;community microgrid optimal interconnection planning renewable energy source microgrid reliability microgrid economic operation probabilistic minimal cut set based iterative methodology clustering based method;community microgrid distribution network planning microgrid planning minimum cut set reliability;planning;microgrids;power system reliability;economics;probabilistic logic;distributed power generation iterative methods power generation planning power generation reliability power grids power system interconnection probability renewable energy sources;reliability community microgrid distribution network planning microgrid planning minimum cut set	The optimal planning of the interconnected network of multimicrogrids is discussed in this paper. The interconnection planning will enhance the reliability and the economic operation of a community of microgrids. The proposed approach will apply a probabilistic minimal cut-set-based iterative methodology for the optimal planning of interconnection among microgrids with variable renewable energy sources. The optimal planning takes into account various factors including the economics, reliability, and variability of renewables, network- and resource-based uncertainties, and adaptability to accommodate the prevailing operating concerns. A clustering-based method is considered for analyzing the variable data concerning the potential deployment of renewable energy in microgrids. The proposed interconnection planning methodology is applied to a six-microgrid system and the planning results are discussed. The numerical results demonstrate that the proposed interconnection planning methodology will determine an optimal topology accurately and efficiently for a cluster of microgrids, and show that the proposed adaptive planning methodology can easily be applied to practical microgrid applications.	cluster analysis;heart rate variability;interconnection;iterative method;max-flow min-cut theorem;microgrid;multi categories security;numerical analysis;software deployment	Liang Che;Xiaping Zhang;Mohammad Shahidehpour;Ahmed Alabdulwahab;Abdullah M. Abusorrah	2017	IEEE Transactions on Smart Grid	10.1109/TSG.2015.2456834	renewable energy;planning;reliability engineering;mathematical optimization;engineering;operations management;reliability;probabilistic logic	Robotics	5.977171571248674	3.7103415398345776	131901
1d547c8ec6475e1765480acc3edeaf7950175812	the dynamic programming equation for the problem of optimal investment under capital gains taxes	solucion viscosidad;economie;modelizacion;dynamic programming;taxe;continuous time;hg finance;control optimo;capital;factor riesgo;consumption;tax;49j20;cout transaction;programacion dinamica;cout capital;capital gains taxes;marche financier;dynamic programming equation;risk factor;inversion;qa mathematics;http;transaction cost;tasa;temps continu;impots;econometria;tiempo continuo;viscosity solutions;solution viscosite;taxes;facteur risque;fiscalizacion;investment;protocole http;capital cost;consumo;optimal control;modelisation;solutions de viscosite;viscosity solution;time periodique new york;temps;coste capital;commande optimale;consommation;fiscalite;investissement;optimal consumption and investment in continuous time;programmation dynamique;economies et finances;coste transaccion;capital gains tax;financial market;portfolio management;cout de transaction;transaction costs;value function;gestion cartera;econometrics;protocolo http;gestion portefeuille;optimal investment;91b28;modeling;impot;35d99;econometrie;mercado financiero	This paper considers an extension of the Merton optimal investment problem to the case where the risky asset is subject to transaction costs and capital gains taxes. We derive the dynamic programming equation in the sense of constrained viscosity solutions. We next introduce a family of functions (Vε)ε>0, which converges to our value function uniformly on compact subsets, and which is characterized as the unique constrained viscosity solution of an approximation of our dynamic programming equation. In particular, this result justifies the numerical results reported in the accompanying paper [I. Ben Tahar, H. M. Soner, and N. Touzi (2005), Modeling Continuous-Time Financial Markets with Capital Gains Taxes, preprint, http://www.cmap.polytechnique.fr/∼touzi/bst06.pdf].	approximation;bellman equation;dynamic programming;numerical analysis;viscosity solution	Imen Ben Tahar;Halil Mete Soner;Nizar Touzi	2007	SIAM J. Control and Optimization	10.1137/050646044	mathematical optimization;transaction cost;mathematical economics;project portfolio management	ML	2.608445169147239	-2.760221050390465	132022
9bc8390db659455fa7182bd2e7c88f562e492cc7	market price calculations in restructured electricity markets	demand elasticity;market equilibrium;ancillary service;power market;market structure;electricity market;profitability;ancillary services;unit commitment;lagrange relaxation	In the traditional organisation of the power market, the generation Unit Commitment and Dispatch problem was solved as a cost minimisation problem. After deregulation of the electricity sector, the problem must be solved as a profit maximising problem. It is necessary to find feasible market prices. This is difficult, because simple marginal cost based prices not always cover startup and operation-independent costs, with the result that the generator would choose not to run with such prices. In this paper a market structure is proposed with a central market operator computing the market equilibrium for both energy and reserves, based on generator offers and consumer bids. It is shown that it is possible to find feasible market prices. Using a simple test system, it is shown that demand elasticity can have a profound impact on prices and generator revenues and profits during peaking hours.	elasticity (cloud computing);marginal model;turing test	Gerard Doorman;Bjørn Nygreen	2003	Annals OR	10.1023/B:ANOR.0000004762.31449.33	price elasticity of demand;market rate;market microstructure;market saturation;market price;economics;electricity market;market impact;order;capital market line;market depth;power system simulation;market structure;microeconomics;domestic market;market economy;frictionless market;factor market;market clearing;market share analysis;mark to model;profitability index;labour economics	ECom	0.15673856299537914	-3.7747884396719527	132037
68a8c04fbb4ed39cfe1e03f42265978575a2d725	a comparison of bidding strategies for simultaneous auctions	multi dimensional bid improvement;bidding strategies;performance;online auction;multi dimensional;single unit;bidding;hill climbing;experimentation;sequential auction;auctions;combinatorial auction	Bidding for multiple items or bundles on online auctions raise challenging problems. We assume that an agent has a valuation function that returns its valuation for an arbitrary bundle. In the real world all or most of the items of interest to an agent is not present in a single combinatorial auction. We focus on bidding for multiple items in a set of auctions, each of which sell only a single unit of a particular item. Hence an agent has to bid in multiple auctions to obtain item bundles. While an optimal bidding strategy is known when bidding in sequential auctions, only suboptimal strategies are available when bidding for items sold in auctions running simultaneously. We investigate a hill-climbing bidding strategy, which is optimal given an infinite number of restarts, to decide on an agent's bid for simultaneous auctions. We provide a comparison of this algorithm with existing ones, both in terms of utilities generated and computation time, along with a discussion of the strengths and weaknesses of these strategies.	algorithm;computation;hill climbing;time complexity;value (ethics)	Teddy Candale;Sandip Sen	2006	SIGecom Exchanges	10.1145/1124566.1124572	auction sniping;financial economics;mathematical optimization;eauction;combinatorial auction;economics;bidding;real-time bidding;performance;unique bid auction;computer science;hill climbing;common value auction;english auction;ebidding;microeconomics;bid shading;auction theory;commerce;forward auction	AI	-2.566904040460537	-2.197544290238919	132089
34c1cc3cedab56b678317c2b7e7dba2f96f210a8	a natural gas flow model under uncertainty in demand	natural gas	Background for the model: The model tries to determine optimal allocation of natural gas in the time horizon between 1 and 3 years by minimizing both • shortages of natural gas and • the direct costs of supplying natural gas. In order to obtain these goals, the time horizon is divided into smaller decision time periods whose durations depend on the following: • The uncertainty in future weather conditions • The demand for natural gas due to changes in weather conditions • The expected demand for natural gas that can be estimated through “reasonable extrapolation of past data” by taking consideration of 1. availability of natural gas 2. population growth 3. per capita income	extrapolation;mathematical optimization	Reuven R. Levary;Burton V. Dean	1980	Operations Research	10.1287/opre.28.6.1360	natural gas;economics;operations management;mathematics;economy;operations research	ML	7.333473476211223	-5.1155540061641345	132174
0ebbdee873dc691d7cf616311fc9b79f5134c586	solving the dual problems of dynamic programs via regression		In recent years, information relaxation and duality in dynamic programs have been studied extensively, and the resulted primal-dual approach has become a powerful procedure in solving dynamic programs by providing lower-upper bounds on the optimal value function. Theoretically, with the so-called value-based optimal dual penalty, the optimal value function could be recovered exactly via strong duality. However, in practice, obtaining tight dual bounds usually requires good approximations of the optimal dual penalty, which could be time consuming if analytical computation is not possible and nested simulation has to be used to estimate the conditional expectations inside the dual penalty. In this paper, we will develop a framework of a regression approach to approximating the optimal dual penalty in a nonnested manner, by exploring the structure of the function space consisting of all feasible dual penalties. The resulted approximations maintain to be feasible dual penalties, and thus yielding valid dual bounds on the optimal value function. We show that the proposed framework is computationally efficient, and the resulted dual penalties lead to numerically tractable dual problems. Finally, we apply the framework to a high-dimensional dynamic trading problem to demonstrate its effectiveness in solving the dual problems of complex dynamic programs.	additive model;algorithmic efficiency;approximation algorithm;bellman equation;benchmark (computing);buffalo airstation;buffalo network-attached storage series;cobham's thesis;computation;control engineering;dynamic programming;electrical engineering;enterprise system;enterprise systems engineering;entity–relationship model;execution unit;expanded memory;heuristic (computer science);holographic principle;ibm notes;john d. wiley;linear programming relaxation;markov chain;markov decision process;mathematical optimization;monte carlo method;monte carlo methods in finance;morgan;multi-armed bandit;numerical analysis;operations research;optimal control;optimization problem;performance;persistence (computer science);powell's method;reinforcement learning;simulation;software release life cycle;springer (tank);stanley (vehicle);stochastic control;strong duality;value (ethics)	Helin Zhu;Fan Ye;Enlu Zhou	2018	IEEE Transactions on Automatic Control	10.1109/TAC.2017.2747405	mathematical optimization;mathematics;mathematical economics;algorithm	ML	2.638850642593148	-0.6694043344594521	132176
d29d8017b57dcdbee650fab051b3b913bd270a86	reducing bayesian mechanism design to algorithm design		The goal is to design algorithms that succeed in models where input is reported by strategic agents (henceforth referred to as strategic input), as opposed to standard models where the input is directly given (henceforth referred to as honest input). For example, consider a resource allocation problem where a single user has m jobs to process on n self-interested machines. Each machine i can process job j in time tij , and this is privately known only to the machine. Each machine reports some processing times O tij to the user, who then runs some algorithm to determine where to process the jobs. Good approximation algorithms are known when machines are honest (i.e., O tij D tij for all i; j ) if the user’s goal is to minimize the makespan, the time elapsed until all jobs are completed, going back to seminal work of Lenstra, Shmoys, and Tardos [13]. However, such algorithms do not account for the strategic nature of the machines, which may want to minimize their own work: why would they report honestly their processing time for each job if they can elicit a more favorable schedule by lying? To accommodate such challenges, new algorithmic tools must be developed that draw inspiration from Game Theory. Requiring solutions that are robust against potential strategic manipulation potentially increases the computational difficulty of whatever problem is at hand. The discussed works provide a framework with which to design such solutions (henceforth called mechanisms) and address the following important question.	algorithm design;approximation algorithm;arjen lenstra;computation;game theory;job stream;makespan	Yang Cai;Constantinos Daskalakis;S. Matthew Weinberg	2016		10.1007/978-1-4939-2864-4_787	machine learning;job shop scheduling;game theory;algorithm design;approximation algorithm;artificial intelligence;mechanism design;bayesian probability;computer science;resource allocation	Theory	-2.439192351675523	0.1942909951596286	132230
ff06426d4499cec86e9f616a1ce5411e261fb633	an evolutionary analysis of varian's model of sales	best response dynamics;shapley polygon;price game	Following A Model of Sales by Varian (Am. Econ. Rev. 70(4):651–659, 1980) I study a model, in which shops compete for two different types of customer, informed and uninformed. I show that under these assumptions price cycles can occur and also show that these cycles are attracting. It turns out that these cycles do not have to correspond with the best response cycle for the game. But as simulations for higher dimensions suggest the occurring cycle is always unique.	am broadcasting;simulation	Martin Hahn	2012	Dynamic Games and Applications	10.1007/s13235-011-0031-6	best response;economics;marketing;operations management;microeconomics;mathematical economics	ECom	-1.8035896559676525	-4.093445746926473	132317
dce759d48fb79e9412b2bb321d722f277b7266d7	the impact of product returns on price and delivery time competition in online retailing		Abstract This paper studies price and promised delivery lead time (PDL) competition between two e-tailers in the context of e-commerce. Product returns are considered, which are affected by late and early delivery inaccuracies, i.e., the delay and early arrival of random actual delivery time relative to PDL. The goal is to examine whether the Nash Equilibrium exists in the competition, and to explore the impact of product returns on equilibrium solutions. We consider two cases where the sensitivities of the return rate to late delivery inaccuracy and early delivery inaccuracy are symmetric/asymmetric. The results suggest that (1) firms with lower basic return rates or lower return rate sensitivities, always quote higher prices and shorter PDLs; (2) it is not always profitable for firms whose competitors’ return parameters increase.	online shopping	Sisi Zhao;Feng Wu;Tao Jia;Lei Shu	2018	Computers & Industrial Engineering	10.1016/j.cie.2018.01.007	econometrics;competitor analysis;early delivery;mathematical optimization;engineering;lead time;rate of return;nash equilibrium	DB	-0.4960831709258758	-6.750087865644998	132436
8e30f27866bb70fcfde72243cd9f155592530927	a bayesian decision analysis in determining the optimal policy for pricing, production, and warranty of repairable products	bayesian updating;non homogeneous poisson process;optimal policy;decision maker;customer service;decision analysis;decision problem;mathematical programming;deterioration;expert opinion;profitability;warranty policy;bayesian analysis;historical data;new products	A successful industry strategy should be managed to integrate the decisions, such as pricing, production, and customer services, in order to maximize profits. In fact, some research has been carried out to cope with the multiple considerations for the case in which sufficient historical data are available. However, if sufficient historical data cannot be gathered to confidently estimate the deterioration of a new product, then the solution may not be assertively reliable. In dealing with such a problem for the situation of scarce historical data, a Bayesian analysis should be suitable because it can effectively assess the deterioration based on experts' opinions and possibly few relevant data. In this paper, we employed a mathematical programming approach along with a Bayesian updating process to tackle such a complex decision problem, and the optimal prior and posterior decisions of pricing scheme, production plan, and warranty policy can thus be determined simultaneously. In addition, we provided a computerized architecture to help decision makers in implementing the proposed approach. Finally, a practical application case was used to demonstrate the usefulness of the proposed model.	decision analysis	Chih-Chiang Fang;Yeu-Shiang Huang	2008	Expert Syst. Appl.	10.1016/j.eswa.2007.08.075	decision-making;optimal decision;decision analysis;bayesian probability;decision problem;data mining;management science;bayesian inference;inhomogeneous poisson process;statistics;profitability index	Metrics	4.526438471097719	-5.736646247720517	132466
79e0820144d39da91626bb23c2c38b5561174108	an empirical investigation of the auction buyer's choice to buy out or bid: cry of regret or laugh of satisfaction?		Online auction buyers often face the predicament of choosing between the buyout strategy and the bidding strategy to acquire an auctioned product. A buyer who chooses to buy out will obtain the item immediately at the posted price while the one who chooses to bid will have to monitor the bidding process in the hope of acquiring the product at a price lower than the posted one. Despite the wealth of auction literature, relatively few studies empirically assess the buyout option. This study seeks to bridge the gap by investigating how the buyout option (permanent or temporary) and price parameters (starting price and buyout price) affect the formation of two emotions, namely anticipated satisfaction of choice and anticipated regret of outcome, which in turn affect the buying strategy (i.e., buy out or bid). We employ laboratory experiments in our study and our results indicate two interesting findings. First, when the permanent buyout option is available, a buyer is more likely to exhibit loss aversion characteristics and prefer to adopt the buyout strategy. Second, when the temporary buyout option is present, the thought that one could avoid premature ending of auction by exercising the bidding option at the start decreases one’s preference for adopting the buyout strategy. Implications of these results for further research and practice are discussed.	experiment;regret (decision theory);risk aversion	Chuan-Hoo Tan;Xue Yang;Hock-Hai Teo;Grace Lin	2005			financial economics;unique bid auction;english auction;microeconomics;commerce	Web+IR	-4.272068934605417	-7.894524805740855	132628
1194b07dcd06d4e64e5be625a76ee9e6b2d97fdd	performance study of parallel kanban-base stock for a high-mix multi-stage production system with the entrance of rework	high mix multi stage production;response surface methodology;lean production;base stock;simulation analysis;rsm;rework;kanban;mixed pull system	The present study evaluates the performance of parallel kanban-base stock (PKB) system to regulate the production of high-mix items in a multi-stage shared-machine facility with the entrance of rework. The high-runner products are handled using a kanban system and low-runner products using a base stock system. The PKB systems were differentiated in terms of the model driver, loading rule, and rework entrance policy. The performance measures adopted the total output, average work-in-process, flow times and average machine utilisations. Discrete-event simulations were conducted with an analysis constituted of multi-factor ANOVA and response surface methodology. From the analysis, there is a specific R(LR) value that gives desired performance, and at the same time, its dependency is solely on accuracy of regression equation. Between rework policies, predominantly merge rework entrance policy yields more desirable results as observed within performance measures, compared to original rework entrance policy.	production system (computer science);rework (electronics)	Shaliza Azreen Mustafa;Joshua Prakash;Mei Yong Chong;Jeng Feng Chin	2014	IJAOM	10.1504/IJAOM.2014.064874	response surface methodology;simulation;economics;engineering;operations management;engineering drawing;kanban;lean manufacturing	NLP	5.464033325679342	-6.430155222107668	132784
6579a6a47265933593478896d358b1243e7ff3b7	consumer surplus in online auctions	consumer surplus;online auction;field experiment;weibull distribution;internet auction;ebay;business analytics;sniping;consumer welfare;highest bid	Despite the growing research interest in Internet auctions, particularly those on eBay, little is known about the quantifiable consumer welfare accrued from such mechanisms. Using an ongoing novel field experiment, we collect and examine a unique dataset to empirically quantify and understand determinants of consumer surplus in eBay auctions. Our analysis, based on a sample of 5187 eBay auctions, indicates that the median surplus level per auction on eBay auctions is $3.53, which roughly translates to $1.47 billion in accrued consumer surplus for the year 2003 alone. We find that consumer surplus is significantly different across currencies and item categories, negatively influenced by seller experience, auction duration and competition, and positively influenced by bidder experience, bidder aggressiveness and item price. We find that US currency auctions carry higher surpluses relative to Euro and GPB auctions, by a factor of approximately 22%. Surplus levels in Euro and GBP auctions are similar to each other. There appear to be three main groups of surplus categories. The highest surplus is accrued to the group of eBay categories that are antique or collectible in nature. This is followed by a moderate surplus group of items comprised of computers, electronics and books, among others. The lowest surplus is in the group of household items such as toys, health and beauty items and games. We find that sellers with higher feedback ratings, a proxy for experience and trust, tend to yield lower bidder surplus, and that experienced bidders tend to realize higher surplus. We find that the main effects of price, opening bid, and number of bidders have a significant influence on surplus, but so do the interactions of price with opening bid and price with number of bidders. These main effects must therefore be interpreted cautiously. Interestingly, we find that surplus is positively associated with price in auctions with many bidders, but this relationship is moderated by the opening price. We find that surplus is generally positive in auction duration and negative in sniping time, but only for “mainstream auctions” with five to seven day duration and sniping time equal to eight or nine seconds. JEL: D12 (Consumer Economics: Empirical Analysis), D44 (Auctions), C93 (Field Experiments)	auction algorithm;internet	Ravi Bapna;Wolfgang Jank;Galit Shmueli	2008	Information Systems Research	10.1287/isre.1080.0173	auction sniping;weibull distribution;field experiment;economics;computer science;marketing;proxy bid;economic surplus;business analytics;microeconomics;commerce	ECom	-4.270401611769879	-7.895656987010535	132789
d7fe834574417a21fa14fd3a615c54901f2cff65	a new portfolio selection model with interval-typed random variables and the empirical analysis		This paper proposes a new portfolio selection model, where the goal is to maximize the expected portfolio return and meanwhile minimize the risks of all the assets. The average return of every asset is considered as an interval number, and the risk of every asset is treated by probabilistic measure. An algorithm for solving the portfolio selection problem is given. Then a Pareto-maximal solution could be obtained under order relations between interval numbers. Finally, the empirical analysis is presented to show the feasibility and robustness of the model.		Chunquan Li;Jianhua Jin	2018	Soft Comput.	10.1007/s00500-016-2396-3	post-modern portfolio theory;mathematical optimization;replicating portfolio;capital asset pricing model;computer science;rate of return on a portfolio;spectral risk measure;portfolio;modern portfolio theory;portfolio optimization	Logic	5.004150935100695	-5.176422984949605	132904
1fbb7031b534f29f6a64a3975cf0b84e122f228e	analyzing the sensitivity of the optimal assignment in probabilistic multi-robot task allocation	uncertainty;resource management;random variables;sensitivity;stochastic processes;planning and scheduling coordination networked robots;uncertainty robot kinematics random variables resource management sensitivity stochastic processes;robot kinematics	We consider multi-robot teams operating in uncertain dynamic settings where the costs used for computing task-allocations are not known exactly. In such cases, the desire to minimize the team's expected cost might need to be curtailed if, in doing so, the risk that results is intolerable. We describe a parameterizable variant of the assignment problem that enables a designer to express such preferences, allowing one to take a risk-averse position if the problem demands it. We consider costs that are random variables, but which need not be independent—a useful setting because it permits one to represent inter-robot couplings. We analyze the sensitivity of assignment optima to particular risk valuations and introduce algorithms that provide an interval for the preference parameter in which all values result in the same optimal assignment. This helps in understanding the effects of risk on the problem, and whether the risk-based model is useful in a given problem domain.	algorithm;assignment problem;consistency model;interdependence;problem domain;risk aversion;robot	Changjoo Nam;Dylan A. Shell	2017	IEEE Robotics and Automation Letters	10.1109/LRA.2016.2588138	random variable;mathematical optimization;simulation;uncertainty;sensitivity;computer science;generalized assignment problem;resource management;robot kinematics;statistics	AI	6.331239727086802	-5.38998097924771	132911
74e19200a0b0211d92975f8f8220bb3f58161099	multivendor portfolio strategies in cloud computing.	cloud computing	Cloud computing emerges as a powerful driver of the information technology industry and many companies are willing to exploit the advantages this development bears. However, services provided by the cloud are subject to default which can result in major economic damage for the client. Moreover, different cloud service providers may also bear a conjoint risk and may therefore not default independently. Hence, to implement effective cloud sourcing strategies, this paper postulates requirements for evaluating multivendor sourcing decisions to select cloud service providers, considering cost, cloud computing specific risk, and interdependencies. We develop an analytic model that meets these requirements and quantitatively expresses the specific cost and risk structure of cloud computing sourcing decisions. Our approach is based on Portfolio Theory with regard to the specifics of fungible cloud services by using exponential loss distributions and one-sided risk measures. Thereby, an evaluation and optimization of a client’s cloud service provider portfolio is possible. To determine the value added we use a simulation for the evaluation of our approach.	cloud computing;device driver;glossary of computer graphics;interdependence;mathematical optimization;modern portfolio theory;requirement;risk measure;simulation;time complexity	Christian König;Philipp Mette;Hanna-Vera Müller	2013			cloud computing;computer science;cloud testing;utility computing	Metrics	-0.2712008913839135	-6.735513161244583	132991
02b6e017a95910a67aa99071cf28806a80a80d91	optimizing inventory and sales decisions in a two-stage supply chain with imperfect production and backorders	pricing;price sensitive demand;integrated inventory;backordering;imperfect production;imperfect quality	This paper develops a model of an integrated vendor–buyer supply chain with imperfect production and shortages. We assume that market demand is sensitive to the buyer’s selling price and thus study combined operations and pricing decisions in the supply chain. We first derive the expected profit per unit of time using the well-known renewal-reward theorem, and then maximize profit for the cases of independent and joint optimization. Numerical examples and a sensitivity analysis are provided to illustrate the proposed models. The results indicate that coordination and backordering improve the total expected profit of the system, and that both measures become more important for the supply chain as the price sensitivity of demand increases. Furthermore, the coordinated supply chain often prefers to perform inspection at the vendor, who is more familiar with the product and its deficiencies than the buyer in many cases. 2014 Elsevier Ltd. All rights reserved.	economic order quantity;emoticon;entity–relationship model;mathematical optimization;numerical method;optimizing compiler;purchasing;rework (electronics);scrum (software development);whole earth 'lectronic link;xfig	Mona Ahmadi Rad;Farid Khoshalhan;Christoph H. Glock	2014	Computers & Industrial Engineering	10.1016/j.cie.2014.05.004	pricing;service management;marketing;operations management;microeconomics;commerce	AI	1.2694213655868742	-5.3642666451215035	133020
b9e8f82821c04ce6b0e4c2bb3fae6e0e4410f737	pricing models for recycling used home appliances under different collecting methods in china		This paper studies the pricing decision-making for recycling used home appliances when wholesale and retail prices for the green home appliances have already been determined by other methods. In consideration of the influences of the effective recycle behavior of the used home appliances to the whole supply chain, the paper proposes three game models about the recycle pricing for the used home appliances under three different collection methods respectively. The three collection methods are 1) manufacturer collection (Model M), 2) retailer collection (Model R) and 3) third-party collection (Model 3P). Then the paper analyzes how the recycle price for the used home appliances and the total channel profits are affected by the choice of the collection methods. The pricing models presented in this paper provide a practical and theoretical guidance for home appliances enterprises in making pricing decisions.	model m keyboard;model checking	Ai Xu;Shufeng Gao	2016	2016 IEEE Intl Conference on Computational Science and Engineering (CSE) and IEEE Intl Conference on Embedded and Ubiquitous Computing (EUC) and 15th Intl Symposium on Distributed Computing and Applications for Business Engineering (DCABES)	10.1109/CSE-EUC-DCABES.2016.254	computer network;supply chain;profit (economics);operations management;computer science	Visualization	0.6480835154669566	-7.765801075711256	133051
2acebc6e8a00c7ed3d9c23df3f82c457c420fa36	an eoq model with stock and price sensitive demand	matematicas aplicadas;modele mathematique;mathematiques appliquees;pricing;optimal decision;relacion orden;ordering;stock dependent demand;modelo matematico;price setting;fijacion precios;inventory model;condition suffisante;inventory;administracion deposito;regle decision;decision optimale;profit;relation ordre;estrategia empresa;planificacion;condicion suficiente;beneficio;stock price;seasonality;modele continu;gestion stock;mathematical model;benefice;planning;profitability;regla decision;sufficient condition;planification;applied mathematics;firm strategy;inventory control;strategie entreprise;fixation prix;cours action;decision rule;continuous model;demande dependante stock;decision optimal	Many business practices show that the presence of a larger quantity of goods displayed may attract more customers than that with a smaller quantity of goods. This phenomenon implies that the demand may have a positive correlative with stock level. Under such a circumstance, a firm should seriously consider its pricing and ordering strategy since the demand for their goods may be affected by their selling prices and inventory level. This paper aims to develop a continuous inventory model for finding the strategy for a firm that sells a seasonal item over a finite planning time. The purpose of this firm is to maximize its expected profit by determining the optimal ordering quantity and price setting/changing strategy. Some sufficient conditions are found for finding the optimal decision rules. c © 2006 Elsevier Ltd. All rights reserved.	economic order quantity;inventory theory	Peng-Sheng You;Yi-Chih Hsieh	2007	Mathematical and Computer Modelling	10.1016/j.mcm.2006.09.003	inventory control;planning;pricing;profit;optimal decision;inventory;order theory;continuous modelling;mathematical model;decision rule;mathematics;law of demand;seasonality;statistics;profitability index	AI	2.061885009368054	-4.9890247122516085	133118
ca526fd82d6f2fb7a362932c333bf034e2cf1a74	reinventing the supplier negotiation process at motorola	electronic;analysis of algorithm;analysis of algorithms;industries computer	As the world market for telecommunications underwent a massive downturn in the early 2000s, Motorola, Inc. needed to cut costs and increase productivity throughout its operations. It had to identify a method of reducing the time and effort required to prepare for and conduct negotiations with its suppliers, simplify their coordination, and optimize contract awards across sectors, to save costs. Motorola’s global procurement function selected Emptoris’s end-to-end Internet negotiations platform. Combining innovative bidding, online supplier negotiations, and scenario-based optimization analysis, it identifies the best procurement strategy while enhancing supplier relationships. Sourcing over $16 billion and saving more than $600 million, including $200 million specifically driven by the platform’s advanced capabilities, Motorola changed its supplier negotiation paradigm and moved to a truly global process.	end-to-end encryption;mathematical optimization;optimization problem;procurement;programming paradigm	Theresa Metty;Rob Harlan;Quentin Samelson;Tom Moore;Thomas H. Morris;Ron Sorensen;Avner Schneur;Olga Raskina;Rina Schneur;Joshua Kanner;Kevin Potts;Jeffrey Robbins	2005	Interfaces	10.1287/inte.1040.0119	electronics;computer science;engineering;marketing;analysis of algorithms;operations management;management;operations research;commerce	HPC	3.8084250704244447	-7.39802166458054	133144
8f5258ad036a5b43cfb23cfb0b00382266674651	contingency pricing for information goods and services under industrywide performance standard	poor performance;contingent pricing;contingency pricing;performance standard;available historical performance data;additional private information;superior firm;quality-contingent pricing;information goods;standard pricing;pricing scheme	This paper demonstrates that quality-contingent pricing is a useful mechanism for mitigating the negative effects of quality uncertainty in e-commerce and information technology services. Under contingency pricing of an information good or service, the firm pre-announces a rebate for poor performance. Consumers determine performance probabilities using publicly available historical performance data, and the firm may have additional private information with respect to its future probability distribution. Examining the monopoly case, we explicate the critical role of private information and differences in belief between the firm and market in the choice of pricing scheme. Contingent pricing is useful when the market underestimates the firm’s performance; then it is optimal for the firm to offer a full-price rebate for misperformance, with a correspondingly higher price for meeting the performance stan06 bhargava.pmd 7/24/2003, 3:47 PM 115 116 BHARGAVA AND SUNDARESAN dard. We study the competitive value of contingency pricing in a duopoly setting where the firms differ in their probabilities of meeting the performance standard, but are identical in other respects. Contingency pricing is a dominant strategy for a firm when the market underestimates the firm’s performance. Whereas both firms would earn equal profits if they were constrained to standard pricing, the superior firm earns greater profits under contingency pricing by setting lower expected prices. We show that contingency pricing is efficient as well, and consumer surplus increases because more consumers buy from the superior firm.	contingency (philosophy);contingency plan;e-commerce;monopoly;personally identifiable information	Hemant K. Bhargava;Shankar Sundaresan	2003	J. of Management Information Systems		pricing;variable pricing;investment theory;economics;marketing;microeconomics;rational pricing;pricing schedule;information good;psychological pricing;commerce	AI	-3.1829942542008967	-7.632432941442061	133189
e19ddcfab7cdbee1fa742c256b39e168495c54aa	price-quoting strategies of an upstream supplier	grupo de excelencia;administracion de empresas;economia y empresa;grupo a;price discrimination;auctions;multitier supply chain	This paper studies an upstream supplier who quotes prices for a key component to multiple sellers that compete for an end-buyer's indivisible contract. At most one of the supplier's quotes may result in downstream contracting and hence produce revenue for her. We characterize the supplier's optimal price-quoting strategies and show that she will use one of two possible types of strategies, with her choice depending on the sellers' profit potentials relative to their uncertainties: secure, whereby she will always have business; or risky, whereby she may not have business. Addressing potential fairness concerns, we also study price-quoting strategies in which all sellers receive equal quotes. Finally, we show that the supplier's optimal mechanism resembles auctioning a single quote among the sellers. This paper can assist upstream suppliers in their pricing decisions and provides general insights into multitier supply chains' pricing dynamics. This paper was accepted by Martin Lariviere, operations management.		Bin Hu;Damian R. Beil;Izak Duenyas	2013	Management Science	10.1287/mnsc.1120.1697	economics;marketing;operations management;microeconomics;management;price discrimination;commerce	Theory	-1.0953341703475492	-5.785307433163005	133410
3623a21892a96ca6f718880a816ea1694e451e0e	rewards, costs and flexibility in dynamic resource allocation: a stochastic optimal control approach	stochastic optimal control approach;dynamic resource allocation	Various canonical forms of general resource allocation problemsarise naturally across a broad spectrum of computer systems andcommunication networks. As the complexities of these systemsand networks continue to grow, together with ubiquitous advancesin technology, new approaches and methods are required to effec-tively and efﬁciently solve these problems. Such environments of-ten consist of different types of resources that are allocated in com-bination to serve demand whose behavior over time is characterizedby different types of uncertainty and variability. Each type of re-source has a different reward and cost structure that ranges from thebest of a set of primary resource allocation options, having the high-est reward, highest cost and highest net-beneﬁt, to a secondary re-source allocation option, having the lowest reward, lowest cost andlowest net-beneﬁt. Each type of resource also has different struc-tures for the ﬂexibility and cost of making changes to the allocationcapacity. The resource management optimization problem we con-sider consists of adaptively determining the primary and secondaryresource allocation capacities that serve the uncertain demand andthat maximize the expected net-beneﬁt over a time horizon of in-terest based on the foregoing reward, cost and ﬂexibility structuralproperties of the different types of resources.The general class of resource allocation problems studied in thispaper arises in a wide variety of application domains such as cloudcomputing and data center environments, computer and communi-cation networks, and energy-aware and smart power grid environ-ments, among many others. Across these and many other domain-speciﬁc resource allocation problems, there is a common need forthe dynamic adjustment of allocations among multiple types of re-sources, each with different structural properties, to satisfy time-varying and uncertain demand. Taking a ﬁnancial mathematicsapproach that hedges against future risks associated with resourceallocation decisions and uncertain demand, we consider the under-lying fundamental stochastic optimal control problem where thedynamic control policy that allocates primary resource capacitiesto serve uncertain demand is a variational stochastic process withconditions on its derivative, which in turn determines the secondaryresource allocation capacity. The objective is to maximize the ex-pected discounted net-beneﬁt over time based on the structural prop-	optimal control	X. Gao;Yingdong Lu;Mayank Sharma;Mark S. Squillante;J. W. Bosman	2013	SIGMETRICS Performance Evaluation Review	10.1145/2567529.2567549	mathematical optimization	Robotics	2.3197266922969	3.336427360125312	133473
0f4244c117cf96d8d9b39b18ae101ace70e2d3d9	vwap execution and guaranteed vwap	91g80;optimal liquidation;93e20;optimal control;indifference pricing;guaranteed vwap contract;49j15;vwap strategy	Optimal liquidation using volume weighted average price (VWAP) strategies has been considered in the literature, though never in the presence of permanent market impact and only rarely with execution costs. Moreover, only VWAP strategies have been studied, and the pricing of guaranteed VWAP contracts has never been addressed. In this article, we develop a model to price guaranteed VWAP contracts in a general framework for market impact, and we highlight the differences between an agency VWAP and a guaranteed VWAP contract. Numerical methods and applications are also provided.		Olivier Guéant;Guillaume Royer	2014	SIAM J. Financial Math.	10.1137/130924676	financial economics;actuarial science;optimal control;mathematics;microeconomics	Theory	0.6054538539837139	-3.0507283258198132	133489
27c5b9f4d4c7f5e13748fd3129ee8da66621cb49	control of robotic mobility-on-demand systems: a queueing-theoretical perspective	intelligent transportation systems;vehicle routing;queueing networks;self driving cars;autonomous systems	In this paper we present and analyze a queueingtheoretical model for autonomous mobility-on-demand (MOD) systems where robotic, self-driving vehicles transport customers within an urban environment and rebalance themselves to ensure acceptable quality of service throughout the entire network. We cast an autonomous MOD system within a closed Jackson network model with passenger loss. It is shown that an optimal rebalancing algorithm minimizing the number of (autonomously) rebalancing vehicles and keeping vehicles availabilities balanced throughout the network can be found by solving a linear program. The theoretical insights are used to design a robust, real-time rebalancing algorithm, which is applied to a case study of New York City. The case study shows that the current taxi demand in Manhattan can be met with about 8,000 robotic vehicles (roughly 70% of the size of the current taxi fleet operating in Manhattan). Finally, we extend our queueingtheoretical setup to include congestion effects, and we study the impact of autonomously rebalancing vehicles on overall congestion. Collectively, this paper provides a rigorous approach to the problem of system-wide coordination of autonomously driving vehicles, and provides one of the first characterizations of the sustainability benefits of robotic transportation networks.	algorithm;autonomous robot;gated community;jackson;linear programming;microsoft windows;network congestion;network model;quality of service;real-time clock;self-balancing binary search tree;theory	Rick Zhang;Marco Pavone	2016	I. J. Robotics Res.	10.1177/0278364915581863	intelligent transportation system;simulation;autonomous system;computer science;engineering;vehicle routing problem;transport engineering	Robotics	7.4158696406616755	3.4884475483977275	133644
4d8f0e31611d07c0e06a1b204c1f7346e902440f	local martingales and the fundamental asset pricing theorems in the discrete-time case	asset prices;local martingales and the fundamental asset pricing theorems in the discrete time case;arbitrage;discrete time;jean jacod;finite horizon;equivalent martingale measure;complete models;ssrn;a n shiryaev	This paper is devoted to giving simpler proofs of the two fundamental theorems of asset pricing theory, in iscrete-time and finite horizon: namely the no-arbitrage theorem, and the market completeness theorem. Some elementary but apparently new results are also given on discrete-time martingale theory, and in particular a new condition for a local martingale to be a martingale.		Jean Jacod;Albert N. Shiryaev	1998	Finance and Stochastics	10.1007/s007800050040	financial economics;discrete time and continuous time;fundamental theorem of asset pricing;arbitrage pricing theory;economics;martingale pricing;optional stopping theorem;finance;risk-neutral measure;martingale difference sequence;mathematical economics;welfare economics;local martingale;arbitrage;azuma's inequality	Theory	1.3870609018451712	-2.234385777541981	134009
b65ad64d7f373e6c863bce36d7909c7c7bff4aff	generalized engage or retreat differential game with escort regions	games optimization trajectory game theory optical character recognition software xenon mobile communication;optimal control agents and autonomous systems behavioural systems differential games game theory	This paper is motivated by the desire to develop optimal defensive control strategies that discourage an attacker from engaging in attack while simultaneously encouraging retreat. We develop a general, two-player, differential game in which one player represents an attacker and the opposing player represents the defender. The attacker possesses superior dynamics such that it is capable of terminating the game either in engagement or retreat as it so chooses. The defender is incapable of directly preventing engagement. Instead, the defender uses the manipulation of the attacker’s utility function as a form of indirect control in an attempt to make retreat a more attractive option over engagement. The solution to the overall engage or retreat differential game is found by solving two related optimization problems: the differential game of engagement and the optimal constrained retreat. The equilibrium open-loop control strategies and resulting game values of the attack or retreat game are expressed in terms of the solutions to these subproblems. Within the optimal constrained retreat problem, a value function constraint is imposed in order to prevent the attacker from moving into regions where engagement becomes optimal. This leads to regions of constrained retreat which we refer to as escort regions.	bellman equation;initial condition;mathematical optimization;newman's lemma;utility	Zachariah E. Fuchs;Pramod P. Khargonekar	2017	IEEE Transactions on Automatic Control	10.1109/TAC.2016.2562921	non-cooperative game;combinatorial game theory;game design;simulation;simultaneous game;artificial intelligence;game mechanics;metagaming;repeated game;mathematical game;mathematics;screening game;normal-form game;simulations and games in economics education;algorithmic game theory;sequential game	AI	-0.12790489948668532	-0.10815946706040917	134029
0f35cb58120d6a20c9b6a58369ef52806eb80456	contribution games in networks	equilibrium computation;convergence;price of anarchy;pairwise equilibrium;approximate equilibrium;strong equilibrium	We consider network contribution games, where each agent in a network has a budget of effort that he can contribute to different collaborative projects or relationships. Depending on the contribution of the involved agents a relationship will flourish or drown, and to measure the success we use a reward function for each relationship. Every agent is trying to maximize the reward from all relationships that it is involved in. We consider pairwise equilibria of this game, and characterize the existence, computational complexity, and quality of equilibrium based on the types of reward functions involved. When all reward functions are concave, we prove that the price of anarchy is at most 2. For convex functions the same only holds under some special but very natural conditions. Another special case extensively treated are minimum effort games, where the reward of a relationship depends only on the minimum effort of any of the participants. In these games, we can show existence of pairwise equilibrium and a price of anarchy of 2 for concave functions and special classes of games with convex functions. Finally, we show tight bounds for approximate equilibria and convergence of dynamics in these games.	anarchy;approximation algorithm;computational complexity theory;concave function;converge;convex function;graph coloring;nash equilibrium;reinforcement learning	Elliot Anshelevich;Martin Hoefer	2011	Algorithmica	10.1007/s00453-011-9520-7	price of stability;mathematical optimization;convergence;mathematical economics;price of anarchy	ECom	-3.7872421670715535	-0.01614747333808857	134201
3d384b5eb48849bef086fd9749fef9aece781926	robust pricing with refunds		Wecharacterize a sellingmechanism that is robust to the seller’s uncertainty about the buyer’s signal structure. We show that by offering a generous refund policy the seller can significantly reduce this type of uncertainty and regain market power. A simplemechanism that utilizes a generous refundpolicy and randomdiscounts achieves the best guaranteed-profit among all possible mechanisms. JEL: D82, C79, D42		Toomas Hinnosaar;Keiichi Kawai	2018	CoRR		mathematical economics;mathematics;market power;mechanism design;robustness (computer science);monopoly;information design;microeconomics	NLP	-2.797448545702618	-4.288943659875809	134679
f23743e17f15eac606f9224d5d1a46b75ef0d7ae	a note on the effect of asymmetry on revenue in second-price auctions	second price auctions;asymmetric auctions	We compare the seller’s expected revenue in asymmetric second-price auctions with the benchmark case where all bidders have the average distribution. We show that with two bidders, asymmetry has a negative effect on revenue. However, for n > 2 bidders there is no clear observation we can make. We prove that in the case of weak asymmetry, sellers prefer asymmetry over low valuations and symmetry over high valuations. In addition, we show that a good approximation for the expected revenue in the case of weak asymmetry can be obtained by calculating the revenue of the symmetric auction with identical distributions equal to the geometric or arithmetic average.	approximation;benchmark (computing)	Arieh Gavious;Yizhaq Minchuk	2012	IGTR	10.1142/S0219198912500193	financial economics;economics;common value auction;microeconomics;commerce	Theory	-3.142838768397435	-3.91214374736291	135202
16d0cfc4931856b3eb29241bfcd3e1c5949eb323	a note on closure properties of failure rate distributions	porcentaje falla;chaine approvisionnement;probability distributions;taux defaillance;increasing failure rate;administracion deposito;taux defaillance croissant generalise;probability distribution;random variable;gestion stock;failure rate;supply chain;stochastic model;inventory production stochastic models;inventory control;modelo estocastico;modele stochastique	Increasing generalized failure rate (IGFR) distributions were introduced as a tool in the study of contracting mechanisms in supply chains. In this note, we compare and contrast the closure-and the lack thereof-of IGFR and increasing failure rate (IFR) distributions with respect to standard operations on random variables. Some implications of these results for the use of IGFR distributions in supply chain models are noted.	failure rate	Anand Paul	2005	Operations Research	10.1287/opre.1040.0206	probability distribution;econometrics;economics;operations management;mathematics;statistics	Theory	4.27023573669012	-3.8053899786483734	135204
bfd02fe93f17c9fdb20fb664f344c4978b0cdd66	cooperative advertising in a capacitated manufacturer-retailer supply chain: a game-theoretic approach	application of game theory;cooperative advertising;production capacity;supply chain management		game theory	Amir Ahmadi-Javid;Pooya Hoseinpour	2018	ITOR	10.1111/itor.12213	supply chain management;microeconomics;market economy;productive capacity;commerce	AI	-1.433078320811755	-4.554398467591463	135283
1b2a953a99c58a4b75865b9a6214f4c0f8e2bfb4	profit-maximizing incentive for participatory sensing	all pay auction;crowd sensing;weakly risk averse agents profit maximizing incentive participatory sensing all pay auctions contribution dependent prize function information asymmetry stochastic population risk neutral agents;perturbation analysis;network economics;sensors sociology statistics bayes methods games standards conferences;mechanism design;crowdsensing mechanism design bayesian game all pay auction perturbation analysis network economics;optimisation electronic commerce incentive schemes;bayesian game	We design an incentive mechanism based on all-pay auctions for participatory sensing. The organizer (principal) aims to attract a high amount of contribution from participating users (agents) while at the same time lowering his payout, which we formulate as a profit-maximization problem. We use a contribution-dependent prize function in an environment that is specifically tailored to participatory sensing, namely incomplete information (with information asymmetry), risk-averse agents, and stochastic population. We derive the optimal prize function that induces the maximum profit for the principal, while satisfying strict individual rationality (i.e., strictly have incentive to participate at equilibrium) for both risk-neutral and weakly risk-averse agents. The thus induced profit is demonstrated to be higher than the maximum profit induced by constant (yet optimized) prize. We also show that our results are readily extensible to cases of risk-neutral agents and deterministic populations.	entropy maximization;image organizer;participatory sensing;population;rationality;risk aversion	Tie Luo;Hwee Pink Tan;Lirong Xia	2014	IEEE INFOCOM 2014 - IEEE Conference on Computer Communications	10.1109/INFOCOM.2014.6847932	bayesian game;mechanism design;perturbation theory	Vision	-3.052310035958474	-1.9749254731033763	135296
41900c23fb4fb64c8ff6625f796b27e95b25c303	evaluation of optimal international economic policy based on both the parametric control theory and global computable general equilibrium model		Based on the GLOBE model global dynamic computable general equilibrium model (to describe functioning and interaction of the Customs Union (CU) of Belarus, Kazakhstan, and Russia with Armenia, Kyrgyzstan, the European Union and the rest of the world) is developed and calibrated. The calibrated model is tested for the possibility of practical application and on its base the possibility of optimal economic policy both within the CU and within functioning and interaction of the CU, the EU, Armenia, Kyrgyzstan and the rest of the world is assessed using methods of the parametric control theory. © 2014 The Authors. Published by Elsevier B.V. Selection and peer-review under responsibility of the Organizing Committee of ITQM 2014	computable function;control theory;tip (unix utility)	Abdykappar A. Ashimov;Yuriy V. Borovskiy;Nikolay Yu. Borovskiy;Zheksenbek M. Adilov;Rakhman A. Alshanov;Bahyt T. Sultanov	2014		10.1016/j.procs.2014.05.318	computable general equilibrium;globe;customs union;computable model theory;european union;parametric statistics;computer science;economic union;economic policy;control theory	Robotics	1.2059307035139857	-0.39896596672123225	135376
1d0470bf1db15e5794fb07dbd91d7f52fe1d257c	the impact of the online channel on retailers' performances: an empirical evaluation	e business;online channel;retailing;event study;empirical evaluation;firm performance	The use of the Internet as an additional sales channel offers traditional retailers opportunities to reach expanded markets while improving the efficiency of their operations. Although the potential benefits of the online channel are clear, there are significant variations in the scope and depth of online channel use among retailers. Drawing from data on more than 100 publicly traded companies, this study examines the impact of online-channel use on retailers’ performance. The results suggest that the online channel provides significant improvements in sales, cost, inventory, and return on investments. Inaddition,wefindthatthetimingofonline-channeladoptiondoesnotplayasignificant role in performance improvement, but having a local store presence does. Subject Areas: E-business, Event Study, Firm Performance, Online Channel, and Retailing.	performance	Yusen Xia;Guoqiang Peter Zhang	2010	Decision Sciences	10.1111/j.1540-5915.2010.00279.x	event study;economics;marketing;finance;electronic business;commerce	AI	-2.6427810454122826	-8.153381562733287	135429
eb5e9ff8abb6cf9d617c71c55c06c5f133120182	strategic joining in m/m/1 retrial queues	queueing;threshold strategies;balking;journal;retrials;期刊论文;m m 1 queue;equilibrium strategies	The equilibrium and socially optimal balking strategies are investigated for unobservable and observable single-server classical retrial queues. There is no waiting space in front of the server. If an arriving customer finds the server idle, he occupies the server immediately and leaves the system after service. Otherwise, if the server is found busy, the customer decides whether or not to enter a retrial pool with infinite capacity and becomes a repeated customer, based on observation of the system and the reward–cost structure imposed on the system. Accordingly, two cases with respect to different levels of information are studied and the corresponding Nash equilibrium and social optimization balking strategies for all customers are derived. Finally, we compare the equilibrium and optimal behavior regarding these two information levels through numerical examples.		Jinting Wang;Feng Zhang	2013	European Journal of Operational Research	10.1016/j.ejor.2013.03.030	m/m/1 queue;real-time computing;simulation;operations management;mathematics;queueing theory;statistics	Theory	2.1429767146636376	0.13783684876645894	135432
df356be7e53472d0e6a84d1fbe290379a4268781	increasing dominance with no efficiency effect	competition;increasing dominance;dynamic game;dynamic competition;expected value;research and development;e ciency effect;journal of economic literature;r d;trade;working paper	I uncover a new force towards increasing dominance (the property whereby, in dynamic games, the leader tends to increase his or her lead in expected terms). The new effect results from the strategic choice of covariance in races. I assume that players must choose not the amount of resources to spend but how to allocate those resources. I show that, in equilibrium, the laggard chooses a less promising path, in effect trading off lower expected value for lower correlation with respect to the leader. This results in increasing dominance and holds true even if no jointpayoff (or efficiency) effect is present. Journal of Economic Literature Classification Numbers: C7, L1. 2001 Elsevier Science		Luís M. B. Cabral	2002	J. Economic Theory	10.1006/jeth.2001.2796	competition;economics;operations management;microeconomics;sequential game;welfare economics;expected value;statistics	ECom	-4.354152270325399	-6.115131356981343	135515
41f89a3a668e715c85105b9c7fe725782b6a00f6	energy production and ghg emissions: analysis of the canadian dilemma	greenhouse gas emissions;emission reduction;energy production;lie sector energy production ghg emission reduction canadian dilemma energy plan kyoto protocol greenhouse gas large industrial emitters;carbon dioxide emission;air pollution control;planning air pollution control government policies;government policies;kyoto protocol;planning;production petroleum hydroelectric power generation nuclear power generation power generation carbon dioxide protocols natural gas liquefied natural gas global warming	The paper describes the energy production and the plan to reduce GHG emissions. It begins by reviewing energy production and carbon dioxide emissions, with particular emphasis to each source dilemma. Next, last Canadian plan on how to achieve Canada's commitment under the Kyoto protocol to reduce its greenhouse gas emissions to 6% below 1990 levels during the commitment period 2008-2012 is described, with particular emphasis to large industrial emitters LIE sector. It's established that overall target of emission reductions for LIE has been unreasonably dropped. As a consequence, the apprehension is that the government will have to buy foreign emission credits which will have no effect in reducing Canada's GHG. Moreover, it's stated that the overall measures up to date implemented are clearly insufficient, and there are no sufficiently details how new plan will be met targets	foreign key	Mohamed Benhaddadi;G. Olivier	2006	2006 Canadian Conference on Electrical and Computer Engineering	10.1109/CCECE.2006.277533	public policy;planning;greenhouse gas;climate change mitigation;carbon offset;environmental engineering;kyoto protocol;engineering;waste management	AI	7.023524132445722	-7.221103428713537	135725
04b34c76b99d0e173d2bed16bc930c0ce0582ceb	mix and match	social welfare;approximate mechanism design without money;game theory;kidney exchange;mechanism design;lower bound	Consider a matching problem on a graph where disjoint sets of vertices are privately owned by self-interested agents. An edge between a pair of vertices indicates compatibility and allows the vertices to match. We seek a mechanism to maximize the number of matches despite self-interest, with agents that each want to maximize the number of their own vertices that match. Each agent can choose to hide some of its vertices, and then privately match the hidden vertices with any of its own vertices that go unmatched by the mechanism. A prominent application of this model is to kidney exchange, where agents correspond to hospitals and vertices to donor-patient pairs. Here hospitals may game an exchange by holding back pairs and harm social welfare.  In this paper we seek to design mechanisms that are strategyproof, in the sense that agents cannot benefit from hiding vertices, and approximately maximize efficiency, i.e., produce a matching that is close in cardinality to the maximum cardinality matching. Our main result is the design and analysis of the eponymous Mix-and-Match mechanism; we show that this randomized mechanism is strategyproof and provides a 2-approximation. Lower bounds establish that the mechanism is near optimal.	matching (graph theory);randomized algorithm;vertex (geometry)	Itai Ashlagi;Felix A. Fischer;Ian A. Kash;Ariel D. Procaccia	2010		10.1145/1807342.1807392	mechanism design;game theory;mathematical optimization;combinatorics;economics;operations management;social welfare;mathematics;microeconomics;mathematical economics;upper and lower bounds;welfare economics	ECom	-2.9243081039866277	0.42798942913663024	135891
12850d0f1e4fe62b6978f4a0efce98b621cced18	the impact of uncertain yield on capacity acquisition in process plant networks	sensibilite;economie;politica optima;economia;etude sur modele;matematicas aplicadas;modele mathematique;two stage stochastic program;rendement aleatiore;mathematiques appliquees;produccion;capacite;model study;scale economies;risque;peticion;modelo matematico;optimal policy;proceso adquisicion;acquisition process;process plant network;capacidad;strategic planning;production process;riesgo;sensitivity;structure reseau;risk;quality;demande;network configuration;estudio sobre modelo;processus fabrication;mathematical model;controle qualite;planification strategique;production;economy;network structure;process plant networks;economies of scale;capacity;applied mathematics;stochastic programming;quality control;programme stochastique 2 niveaux;politique optimale;demand;processus acquisition;two stage stochastic programs;planificacion estrategica;random yield;sensibilidad;proceso fabricacion;control calidad	In this paper, we consider the case of process plant networks, which consolidate production of components. It is well known that such networks take advantage of process commonalities thereby accruing economies of scale advantages. It has also been shown in recent work that besides scale economies, process plant networks also enjoy risk-pooling advantages which are a direct outcome of network structure. In this research, motivated by real-world examples, we study capacity acquisition in a process plant network when demand and process yield are both uncertain. We show that the optimal capacity acquired in such situations may be considerably higher or lower than that acquired when yield is assumed perfect. We develop distribution-free policies for optimal capacity acquisition. We illustrate our results by means of a numerical example and study the sensitivity to important model parameters. For specific distributional assumptions we also provide closed-form results for the optimal capacity acquisition. We consider our work as perhaps the first to bridge the gap between operational level quality control studies and strategic level network configuration research. Overall, we believe that this paper opens up several avenues for future research integrating these two important areas. c © 2005 Elsevier Ltd. All rights reserved.	complex network;data acquisition;experiment;newsvendor model;numerical analysis;perturbation theory	Shailesh S. Kulkarni	2006	Mathematical and Computer Modelling	10.1016/j.mcm.2005.08.015	simulation;strategic planning;economies of scale;mathematics;operations research	AI	4.174381244662917	-5.54682271813213	136035
b3289975c121221f44c72f00fe67e82699020f27	strategic design of competing supply chain networks with foresight	model design;meta heuristic;price adjustment;market share;stackelberg game;business and management studies;game against nature;supply chain network;supply chain network design;linear bi level program;minimum regret strategy	We consider models for duopolistic competitive supply chain network designing with sequential acting and variable delivered prices. These models design a multi-tier chain operating in markets under deterministic price-depended demands and with a rival chain present. The existing rival chain tends to open some new retailers to recapture some income in a near future. These rival chains’ structures are assumed to be set ‘‘once and for all’’ in a sequential manner but further price adjustments are possible. This problem is modeled for each of the following two strategies: (1) the von Stackelberg strategy in which we assume the existing chain will choose its future entry sites in the way to optimize its market share. This problem is modeled by a linear binary bi-level program and solved by a combinatorial metaheuristic. (2) the minimum regret strategy in which we assume the existing chain’s future entry sites are totally unpredic, it is playing a ‘‘game against nature’’. This problem is modeled by linear binary programs. Crown Copyright 2010 Published by Elsevier Ltd. All rights reserved.	black and burst;crown group;metaheuristic;multitier architecture;regret (decision theory);supply chain network	Shabnam Rezapour;Reza Zanjirani Farahani;Seyed Hassan Ghodsipour;Sohrab Abdollahzadeh	2011	Advances in Engineering Software	10.1016/j.advengsoft.2010.12.004	market share;stackelberg competition	AI	-1.6361624076016212	-4.005556576035265	136108
10fa954f47d6dca826557fce6375672373eed0b7	informational substitutes	information acquisition;prediction markets;submodularity;complements;value of information;substitutes;decision problems	"""We propose definitions of substitutes and complements for pieces of information (""""signals"""") in the context of a decision or optimization problem, with game-theoretic and algorithmic applications. In a game-theoretic context, substitutes capture diminishing marginal value of information to a rational decision maker. There, we address the main open problem in a fundamental strategic-information-revelation setting, prediction markets. We show that substitutes characterize """"best-possible"""" equilibria with immediate information aggregation, while complements characterize """"worst-possible"""", delayed aggregation. Game-theoretic applications also include settings such as crowdsourcing contests and question-and-answer forums. In an algorithmic context, where substitutes capture diminishing marginal improvement of information to an optimization problem, substitutes imply efficient approximation algorithms for a very general class of (adaptive) information acquisition problems. In tandem with these broad applications, we examine the structure and design of informational substitutes and complements. They have equivalent, intuitive definitions from disparate perspectives: submodularity, geometry, and information theory. We also consider the design of scoring rules or optimization problems so as to encourage substitutability or complementarity, with positive and negative results. Taken as a whole, the results give some evidence that, in parallel with substitutable items, informational substitutes play a natural conceptual and formal role in game theory and algorithms."""	algorithm design;approximation algorithm;cobham's thesis;complementarity theory;crowdsourcing;game theory;information theory;marginal model;mathematical optimization;optimization problem;rationality	Yiling Chen;Bo Waggoner	2016	2016 IEEE 57th Annual Symposium on Foundations of Computer Science (FOCS)	10.1109/FOCS.2016.33	mathematical optimization;substitute good;value of information;decision problem;mathematics;mathematical economics;algorithm	Theory	-3.73981231162012	-0.6511195050807325	136115
ca8f0d1acd25a0aa7d18382660c461fde87e8776	a comparison of four approaches from stochastic programming for large-scale unit-commitment		In energy management, the unit-commitment problem deals with computing the most cost-efficient production schedule that meets customer load, while satisfying the operational constraints of the units. When the problem is large scale and/or much modelling detail is required, decomposition approaches are vital for solving this problem. The recent strong increase in intermittent, relative unforeseeable production has brought forth the need of examining methods from stochastic programming. In this paper we investigate and compare four such methods: probabilistically constrained programming, robust optimization and 2-stage stochastic and robust programming, on several large-scale instances from practice. The results show that the robust optimization approach is computationally the least costly but difficult to parameterize and has the highest recourse cost. The probabilistically constrained approach is second as computational cost is concerned and improves significantly the recourse cost functions with respect to the robust optimization approach. The 2-stage optimization approaches do poorly in terms of robustness, because the recourse decisions can compensate for this. Their total computational cost is highest. This leads to the insight that 2-stage flexibility and robustness can be (practically) orthogonal concepts.	algorithmic efficiency;computation;cost efficiency;defensive programming;mathematical optimization;robust optimization;stochastic programming	Wim van Ackooij	2017	EURO J. Computational Optimization	10.1007/s13675-015-0051-x	stochastic programming;econometrics;mathematical optimization;robust optimization;computer science;operations management	AI	9.783820576302137	0.16964145098684463	136184
166b61e284b53e49ba6ddd7923bfc3cd1100ba21	censored exploration and the dark pool problem	reinforce ment learning;polynomial time;experimental evaluation;inventory control	Dark pools are a recent type of stock exchange in which information about outstanding orders is deliberately hidden in order to minimize the market impact of large-volume trades. The success and proliferation of dark pools have created challenging and interesting problems in algorithmic trading---in particular, the problem of optimizing the allocation of a large trade over multiple competing dark pools. In this work, we formalize this optimization as a problem of multi-venue exploration from censored data, and provide a provably efficient and near-optimal algorithm for its solution. Our algorithm and its analysis have much in common with well-studied algorithms for managing the exploration--exploitation trade-off in reinforcement learning. We also provide an extensive experimental evaluation of our algorithm using dark pool execution data from a large brokerage.	algorithm;algorithmic trading;censoring (statistics);dark web;machine learning;mathematical optimization;reinforcement learning;venue (sound system)	Kuzman Ganchev;Yuriy Nevmyvaka;Michael Kearns;Jennifer Wortman Vaughan	2009		10.1145/1735223.1735247	inventory control;time complexity;simulation;computer science;management;operations research;algorithm;statistics	ML	-1.170921771036324	0.33151087042878097	136216
4d8d13762051b1612a8e367b8607de9ac99bcf9b	an asymptotic analysis of hierarchical control of manufacturing systems under uncertainty	manufacturing systems;commande hierarchisee;fonction valeur;gestion production;availability;disponibilidad;bellman equation;production system;systeme production;equation bellman;hierarchical control;machine;asymptotic analysis;panne;sistema produccion;optimal control;planificacion;maquina;control jerarquizado;production control;ecuacion bellman;commande optimale;gestion produccion;pana;breakdown;reparation;effects of breakdowns;production planning;planning;value function;stochastic machine availability;planification;reparacion;manufacturing system;disponibilite;repair;control optimal	This paper presents an asymptotic analysis of a hierarchical manufacturing system with machines subject to breakdown and repair. The rate of change in machine states is much larger than the rate of fluctuation in demand and the rate of discounting of costs, and this gives rise to a limiting problem in which the stochastic machine availability is replaced by the equilibrium mean availability. The value function for the original problem converges to the value function of the limiting problem. Moreover, the control for the original problem can be constructed from the optimal controls of the limiting problem in a way which guarantees asymptotic optimality of the value function. The limiting problem is computationally more tractable and sometimes has a closed form solution.		John P. Lehoczky;Suresh P. Sethi;Halil Mete Soner;Michael I. Taksar	1991	Math. Oper. Res.	10.1287/moor.16.3.596	mathematical optimization;asymptotic analysis;control theory;mathematics;bellman equation	Robotics	5.467323338894703	-1.8824394060380978	136284
44c3044613ba5af9afe959c8db8143c582adb835	mechanism design via machine learning	commerce learning artificial intelligence pricing computational complexity combinatorial mathematics;approximate algorithm;incentive compatibility;pricing;commerce;machine learning;computational complexity;loss function;revenue maximization;machine learning pricing computer science algorithm design and analysis machine learning algorithms marketing and sales measurement standards cost accounting writing automobiles;learning artificial intelligence;unlimited supply combinatorial auction machine learning sample complexity incentive compatible mechanism design revenue maximizing pricing problem optimal algorithm 1 spl epsi approximation attribute auction problem item pricing;mechanism design;sample complexity;combinatorial mathematics;profit maximization;combinatorial auction	We use techniques from sample-complexity in machine learning to reduce problems of incentive-compatible mechanism design to standard algorithmic questions, for a wide variety of revenue-maximizing pricing problems. Our reductions imply that for these problems, given an optimal (or /spl beta/-approximation) algorithm for the standard algorithmic problem, we can convert it into a (1 + /spl epsi/)-approximation (or /spl beta/(1 +/spl epsi/)-approximation) for the incentive-compatible mechanism design problem, so long as the number of bidders is sufficiently large as a function of an appropriate measure of complexity of the comparison class of solutions. We apply these results to the problem of auctioning a digital good, the attribute auction problem, and to the problem of item-pricing in unlimited-supply combinatorial auctions. From a learning perspective, these settings present several challenges: in particular the loss function is discontinuous and asymmetric, and the range of bidders' valuations may be large.	algorithm;blum axioms;loss function;machine learning	Maria-Florina Balcan;Avrim Blum;Jason D. Hartline;Yishay Mansour	2005	46th Annual IEEE Symposium on Foundations of Computer Science (FOCS'05)	10.1109/SFCS.2005.50	pricing;mechanism design;mathematical optimization;combinatorial auction;incentive compatibility;computer science;mathematical economics;computational complexity theory;loss function	Theory	-1.1921400199148235	-0.718720655612896	136305
91f0dced5ff71a12f4996647d16a6110e74bd567	information markets for product attributes: a game theoretic, dual pricing mechanism	search engine;electronic markets;efficient markets;product search engines;product information;imperfect information;differentiated products;information market;shopbots	We model the availability of information about product attributes in Internet-based markets, focusing on a phenomenon that we term as information deficit (availability of less than perfect information about product attributes) and its impact on the equilibrium strategies of sellers and buyers in electronic markets. We create a model of a market for a differentiated product and investigate how buyer uncertainty regarding the attributes of the product drives market outcomes. We show that a market for product information can partly correct the inefficiencies that arise from imperfect information and predict that product information will begin to be traded once appropriate micro-transaction payment schemes become available. We formulate a mechanism by which sellers can charge an information rent for fine-grained information about product attributes which we term as a dual pricing mechanism wherein sellers extract an information rent in addition to the price of the product from buyers. We analyze the equilibrium that results and comment on the nature of welfare gains. A key finding of the paper is that allowing sellers to charge dual rents leads to more efficient markets. This work was supported by NSF grants DMI-0121395 and SBR-9602053. ∗The Wharton School, University of Pennsylvania †The Wharton School, University of Pennsylvania ‡Computer and Information Science Department, University of Pennsylvania	comment (computer programming);electronic markets;game theory;ibm notes;information science;microtransaction	Panos M. Markopoulos;Ravi Aron;Lyle H. Ungar	2010	Decision Support Systems	10.1016/j.dss.2010.02.005	economics;marketing;efficient-market hypothesis;perfect information;product differentiation;microeconomics;search engine;new product development;commerce	ECom	-2.4487770505138116	-5.328273334851983	136317
d66567ef4859a8f2e44bb0a919039c8aba0ef19c	controller-jammer game models of denial of service in control systems operating over packet-dropping links	adversarial zero-sum games;control over adversarial channels;security of control systems;control over packet-dropping links	The paper introduces a class of zero-sum games between the adversary and controller as a scenario for a ‘denial of service’ in a networked control system. The communication link is modeled as a set of transmission regimes controlled by a strategic jammer whose intention is to wage an attack on the plant by choosing a most damaging regime-switching strategy. We demonstrate that even in the one-step case, the introduced games admit a saddle-point equilibrium, at which the jammer’s optimal policy is to randomize in a region of the plant’s state space, thus requiring the controller to undertake a nontrivial response which is different from what one would expect in a standard stochastic control problem over a packet dropping link. The paper derives conditions for the introduced games to have such a saddle-point equilibrium. Furthermore, we show that in more general multi-stage games, these conditions provide ‘greedy’ jamming strategies for the adversary.	adversary (cryptography);control system;denial-of-service attack;game controller;network packet;radio jamming;state space;stochastic control	Valery A. Ugrinovskii;Cédric Langbort	2017	Automatica	10.1016/j.automatica.2017.07.009		ECom	-3.6946679659013775	3.963452597242347	136406
99b42df83a674c17cf88aa2e9e474607e0d16653	a stochastic game approach for competition over popularity in social networks	stochastic game theory;popularity;non zero sum;advertisement;differential game;marketing;social networks;dynamic game theory;stochastic games	The global Internet has enabled a massive access of internauts to content. At the same time it allowed individuals to use the Internet in order to distribute content. When individuals pass through a conotent provider to distribute contents, they can benefit from many tools that the content provider has in order to accelerate the dessiminaton of the content. These include cashing as well as recommendation systems. The content provider gives preferencial treatment to individuals who pay for advertisement. In this paper we study competition between several contents, each characterized by some given potential popularity. We answer the question of when is it worthwhile to invest in adveretisement as a function of the potential popularity of a content as well as its competing contents, who are faced with a similar question. We formulate the problem as a stochastic game with a finite state and action space and obtain the structure of the equilibria policy under a linear structure of the dissemination utility as well as on the advertisement costs. We then consider open loop control (no state information) and solve the game using a transformation into a differential game with a compact state space.	internet;recommender system;social network;state space	Eitan Altman	2013	Dynamic Games and Applications	10.1007/s13235-012-0057-4	non-cooperative game;economics;marketing;repeated game;microeconomics;advertising;normal-form game;zero-sum game;mathematical economics;sequential game;social network	ECom	-1.3932212780744475	-4.014239775000197	136437
30cffd1ab5047def823fe3d6e9e47229d8be9b7d	uncertain price competition in a duopoly with heterogeneous availability	nash equilibrium;uncertainty;pricing;cognitive radio networks uncertain price competition duopoly heterogeneous availability secondary spectrum access network nonneutral internet microgrid network nash equilibrium probability distributions;probability distribution terminology nash equilibrium pricing games uncertainty context;probability distribution;games;probability game theory oligopoly pricing;terminology;network neutrality pricing game theory micro grid networks cognitive radio networks secondary spectrum networks;context	We study the price competition in a duopoly with an arbitrary number of buyers. Each seller can offer multiple units of a commodity depending on the availability of the commodity which is random and may be different for different sellers. Sellers seek to select a price that will be attractive to the buyers and also fetch adequate profits. The selection will in general depend on the number of units available with the seller and also that of its competitor - the seller may only know the statistics of the latter. The setting captures a secondary spectrum access network, a non-neutral Internet, or a microgrid network in which unused spectrum bands, resources of ISPs, and excess power units constitute the respective commodities of sale. We analyze this price competition as a game, and identify a set of necessary and sufficient properties for the Nash Equilibrium (NE). The properties reveal that sellers randomize their price using probability distributions whose support sets are mutually disjoint and in decreasing order of the number of availability. We prove the uniqueness of a symmetric NE in a symmetric market, and explicitly compute the price distribution in the symmetric NE.	access network;internet;microgrid;nash equilibrium;offset binary;randomness	Mohammad Hassan Lotfi;Saswati Sarkar	2016	IEEE Transactions on Automatic Control	10.1109/TAC.2015.2450091	price of stability;pricing;probability distribution;games;uncertainty;mathematics;terminology;nash equilibrium;statistics	Metrics	-1.879125070917896	-3.9446597356344495	136515
dd529b79deed78e95d5941d90e71365e875d8f97	robust management and pricing of liquefied natural gas contracts with cancelation options	risk aversion;rolling horizon;stochastic programming;cvar	Liquefied Natural Gas contracts offer cancelation options that make their pricing difficult, especially if many gas storages need to be taken into account. We develop a valuation mechanism from the buyer's perspective, a large gas company whose main interest in these contracts is to provide to clients a reliable supply of gas. The approach combines valuation with hedging, taking into account that price-risk is driven by international markets, while volume-risk depends on local weather and is stage-wise dependent. The methodology is based on setting risk-averse stochastic mixed 0-1 programs, for different contract configurations. These difficult problems are solved with light computational effort, thanks to a robust rolling-horizon approach. The resulting pricing mechanism not only shows how a specific set of contracts will impact the company business, but also provides the manager with alternative contract configurations to counter-propose to the contract seller.		Vincent Guigues;Claudia A. Sagastizábal;Jorge P. Zubelli	2014	J. Optimization Theory and Applications	10.1007/s10957-013-0309-5	stochastic programming;mathematical optimization;risk aversion;mathematics	Theory	1.296709610117289	-4.449698323725501	136568
ea2b8087f3d6636f8356ddda6fb58a6f9344c1c6	equipment renewal scheme based on the optimal comprehensive method	investment;the optimal comprehensive method;production equipment costing durability minimisation;renewal of equipment;optimal comprehensive method least total cost method optimal equipment renewal scheme economic life limit old equipment cost advantage;unlimited lifetime;machinery;educational institutions economic indicators investment machinery;limited lifetime;unlimited lifetime renewal of equipment the optimal comprehensive method limited lifetime;economic indicators	The least total cost method has been proposed by the existing literature to identify the optimal scheme of equipment renewal when the lifetime of project is limited. But this method does not take account into the condition that the renewed equipment will need to be renewed again when its service time exceeds its economic life limit. Hence, the scheme, chosen by this method is not absolutely the optimal scheme. It has not considered the comprehensive scheme of utilizing the old equipment for some time before renewing with the new equipment. Compared with the new equipment, the old equipment has the cost advantage in a short period of time, and it's economic to utilize the old equipment for a little longer. Besides the least total cost method, we use the re-renewal method and the optimal comprehensive method to determine the best scheme, then the three methods are compared to illustrate the advantage of the optimal comprehensive method. It indicates that the equipment renewal scheme based on the comprehensive method can reduce the overall costs of the project much more and have rather good values in practical application.	scheme	Xiuli Wang;Guodong Wu;Weidong Meng	2013	2013 Sixth International Conference on Business Intelligence and Financial Engineering	10.1109/BIFE.2013.91	reliability engineering;engineering;operations management;transport engineering	DB	7.849067774868961	-2.4092082940206105	136633
a7e602707a8ebfd92de7aca516870469d63d9714	u.s., japan and eu auto industries' closed loop supply chains: a system dynamics study	closed loop supply chain;reverse logistics;sustinable manufacturing;end of life vehicle elv simulationmodeling;remanufacturing;end of life vehicle elv simulation modeling;salvage	The system dynamics SD modeling approach is used to study the U.S., Japan and EU auto industries' closed loop supply chains. The objectives of this study are to examine the impact on these three supply chains of: government regulations; financial incentives for recycling, remanufacturing, and salvage; the export of used cars; market pricing for remanufactured, salvage and recycle materials on cash flows; and use of such materials for car manufacturers and routine car maintenance and repair considering similarities and differences. Disposal of cars that have reached end of life phase in the U.S., Japan and EU, as well as, the export of used cars by Japan to emerging economies are examined. Base scenario analysis using car consumption data and forecasts are explored. The SD model was also subjected to boundary conditions tests for structural validity. Dynamic analyses of different market scenarios for the U.S., Japan and EU auto industries' value chains are also conducted. The study shows the impact of government regulations, financial incentives and market pricing for remanufactured, salvage and recycle materials have a positive, but differing impact on cash flows and use of such raw materials for car manufacturers in these three market segments.	closed-loop transfer function;system dynamics	Sameer Kumar;Charu Chandra	2012	Information, Knowledge, Systems Management	10.3233/IKS-2012-0209	operations management;business;commerce	Robotics	1.220545386776252	-8.173935775382208	136647
9051d70e325815cee82dc1eaad7391cfa432606a	analysis of risk mitigation by decentralized ordering in multi-tier supply chain	decentralized ordering multi tier supply chain procurement risk;supply chains procurement pareto optimization electric breakdown probability distribution safety fluctuations;supplier downtime risk mitigation decentralized ordering multitier supply chain model price decision probability distribution;supply chains decision making pricing risk analysis statistical distributions	We address developing the simulator for multi-tier supply chain to evaluate the effect of risk mitigation by decentralized ordering. A simulator for 2-tier supply chain has been developed through our research. Because the relationship between the suppliers in the multi-tier supply chain is similar to the relationship between the retailer and the supplier in the 2-tier supply chain. In order to realize the simulation for the multi-tier supply chain, we combine the simulator for the 2-tier supply chain with the functions of price decision and updating the probability distribution of the downtime of the suppliers. Applying the simulator to the multi-tier supply chain model, we discuss the effect of the risk mitigation by decentralized ordering.	client–server model;downtime;multitier architecture;pareto efficiency;simulation;software propagation	Masakatsu Mori;Ryoji Kobayashi;Masaki Samejima;Norihisa Komoda	2014	2014 IEEE 23rd International Symposium on Industrial Electronics (ISIE)	10.1109/ISIE.2014.6864766	supply chain risk management;service management;operations management;microeconomics;business	Arch	0.46291040440722525	-5.296174953379933	136653
bcbad62eff67e3921028fbea8f3900e6a709e4b2	multi-fleet platoon matching: a game-theoretic approach		We consider the platoon matching problem for a set of trucks with the same origin, but different destinations. It is assumed that the vehicles benefit from traveling in a platoon for instance through reduced fuel consumption. The vehicles belong to different fleet owners and their strategic interaction is modeled as a non-cooperative game where the vehicle actions are their departure times. Each truck has a preferred departure time and its utility function is defined as the difference between its benefit from platooning and the cost of deviating from its preferred departure time. We show that the platoon matching game is an exact potential game. An algorithm based on best response dynamics is proposed for finding a Nash equilibrium of the game. At a Nash equilibrium, vehicles with the same departure time are matched to form a platoon. Finally, the total fuel reduction at the Nash equilibrium is studied and compared with that of a cooperative matching solution where a common utility function for all vehicles is optimized.		Alexander Johansson;Ehsan Nekouei;Karl Henrik Johansson;Jonas Mårtensson	2018	2018 21st International Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2018.8569379		Robotics	3.5701751125445234	0.48477720034470556	136694
72b92aedb37fe7a3b0db95ad14475375546550b1	sponsored search auctions with rich ads	pricing;sponsored search auctions;ad auctions;gsp;online auctions;mechanism design;local search	The generalized second price (GSP) auction has served as the core selling mechanism for sponsored search ads for over a decade. However, recent trends expanding the set of allowed ad formats—to include a variety of sizes, decorations, and other distinguishing features—have raised critical problems for GSP-based platforms. Alternatives such as the Vickrey-Clarke-Groves (VCG) auction raise different complications because they fundamentally change the way prices are computed. In this paper we report on our efforts to redesign a search ad selling system from the ground up in this new context, proposing a mechanism that optimizes an entire slate of ads globally and computes prices that achieve properties analogous to those held by GSP in the original, simpler setting of uniform ads. A careful algorithmic coupling of allocation-optimization and pricing-computation allows our auction to operate within the strict timing constraints inherent in real-time ad auctions. We report performance results of the auction in Yahoo’s Gemini Search platform.	computation;edmund m. clarke;guardian service processor;mathematical optimization;real-time clock;search engine marketing	Ruggiero Cavallo;Prabhakar Krishnamurthy;Maxim Sviridenko;Christopher A. Wilkens	2017		10.1145/3038912.3052703	pricing;mechanism design;generalized second-price auction;local search;world wide web;auction theory;forward auction	ECom	-1.7542003973642848	-1.0422900473902195	136840
192ef1a5623a664bf3d00bf7fb6b4d6d0e29d86f	optimal threshold control in discrete failure-prone manufacturing systems	stock control;discrete time systems;product model;optimal control control systems manufacturing systems production systems continuous production uncertainty exponential distribution cost function customer satisfaction fluid flow;poisson demand failure prone manufacturing systems hedging point production discrete manufacturing system production capacity discrete markovian production model cost effective control threshold control policies continuous review inventory system make to order make to stock;optimal control;production control;stochastic processes;average cost;cost effectiveness;markov processes;manufacturing system;optimal control discrete time systems production control stock control stochastic processes markov processes	Bielecki and Kumar (1988) show that the threshold or hedging-point production policies are optimal in a continuous manufacturing system, even if production ability is uncertain. Their analysis assumes constant demand and processing time. In this paper, we consider a discrete manufacturing system in which production capacity, demand, and processing time are all nondeterministic. We formulate the problem into a discrete Markovian production model, and explore the most cost-effective control policy for such a system. With two more sources of uncertainty, we find that the threshold control policies are optimal among all feasible policies when the long run average cost is to be minimized. This extends Bielecki and Kumar's result which shows that the threshold policies are optimal among a subset of feasible policies.		Youyi Feng;Baichun Xiao	2002	IEEE Trans. Automat. Contr.	10.1109/TAC.2002.800647	stochastic process;stock control;cost-effectiveness analysis;optimal control;mathematics;markov process;statistics	Robotics	6.0517636198057785	-0.8983177317339683	136928
ea80d7113266193799463fad6625f9eaf4812897	a bulk queue model for the evaluation of impact of headway variations and passenger waiting behavior on public transit performance	system attributes markov chain technique public transit systems stochastic variations passenger alighting behaviors passenger arrival behaviors passenger waiting behaviors passenger boarding behaviors headway variations finite allowance departure headway variability transit planners;stochastic processes markov processes public transport queueing theory;vehicle sizes headway variability passenger waiting behavior stochastic model;consumer behavior reliability markov processes numerical models road transportation	This paper demonstrates a model developed using the Markov chain technique, to ascertain the performance of public transit systems and examine the effects of stochastic variations in passenger arrival, waiting, boarding, and alighting behaviors on the regularity of headway along the route. The model addresses situations in which passengers abandon the system after a certain amount of waiting time. This accounts for the existence of a finite allowance of waiting time from the viewpoint of the passengers. The numerical examples included offer insights into factors that affect the reliability of public transit systems and presented analysis of the system performance measures such as mean counts of passengers served by transit systems, abandoned passengers, and unused space on vehicles. The impact of variability of departure headway on the utilization of public transit systems is illustrated. This model can be used as an analysis tool by transit planners to evaluate selection of system attributes.	bus (computing);downstream (software development);dynamic dispatch;heart rate variability;logistic regression;markov chain;numerical analysis;theory	Kamrul Islam;Upali Vandebona;Vinayak V. Dixit;Ashish K Sharma	2014	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2014.2315998	simulation;engineering;automotive engineering;transport engineering	Metrics	9.785409436426358	-9.400231562351216	136990
e37fcfb0dc4ce2296d0b9a68ff4f24e3a5dadd59	a q-decomposition lrtdp approach to resource allocation	dynamic pro gramming;resource allocation;cooperation;resource manager;trust model;null;bayesian method;resource management stochastic processes merging laboratories dynamic programming decision support systems research and development labeling acceleration convergence;labeled real time dynamic programming approaches;complex resource management problem;autonomous;multi agent systems;stochastic processes;computational complexity;linear programming;stochastic processes computational complexity linear programming resource allocation;np complete;stochastic resource allocation problems;labeled real time dynamic programming approaches stochastic resource allocation problems np complete complex resource management problem q decomposition model;q decomposition model	This paper contributes to solve effectively stochastic resource allocation problems known to be NP-Complete. To address this complex resource management problem, the merging of two approaches is made: The Q-decomposition model, which coordinates reward separated agents through an arbitrator, and the Labeled Real-Time Dynamic Programming (LRTDP) approaches are adapted in an effective way. The Q-decomposition permits to reduce the set of states to consider, while LRTDP concentrates the planning on significant states only. As demonstrated by the experiments, combining these two distinct approaches permits to further reduce the planning time to obtain the optimal solution of a resource allocation problem.	dynamic programming;experiment;np-completeness;real-time clock	Pierrick Plamondon;Brahim Chaib-draa;Abder Rezak Benaskeur	2006	2006 IEEE/WIC/ACM International Conference on Intelligent Agent Technology	10.1109/IAT.2006.22	mathematical optimization;simulation;computer science;distributed computing	Robotics	-1.1413511672158567	2.7326901561047348	137063
d0fe71d28d929a566f55ec1325e90b015621c286	investor inattention and the market reaction to merger announcements	procesamiento informacion;bolsa valores;investor inattention;trade volume;yield;stock markets;bourse valeurs;stock exchange;marche valeurs;earnings announcement;stock returns;information processing;rendimiento;traitement information;market efficiency;merger announcements;merger announcement;rendement;merger	Prior studies suggest that investors have limited attention. Tests of the inattention hypothesis have been performed in the context of relatively small corporate events, particularly earnings announcements. Presumably, large corporate events would always attract sufficient investor attention. However, we find evidence indicating that inattention affects investors' information processing even in the context of one of the largest and most important corporate events---merger announcements. More specifically, consistent with the notion that investors are less attentive to Friday announcements, we find that the market reaction to Friday stock swap announcements is muted, as evidenced by lower acquirers' merger announcement abnormal trading volumes and less pronounced acquirers' merger announcement abnormal stock returns.	regret (decision theory)	Henock Louis;Amy X. Sun	2010	Management Science	10.1287/mnsc.1100.1212	financial economics;yield;stock exchange;economics;information processing;efficient-market hypothesis;finance;monetary economics	Theory	-4.045912929890606	-8.47436344944632	137078
be21aba1efeb14bcf38c49fc4404f7e26e0454ce	many-objective evolutionary optimisation and visual analytics for product family design		Product family design involves the development of multiple products that share common components, modules and subsystems, yet target different market segments and groups of customers. The key to a successful product family is the product platform—the common components, modules and subsystems— around which the family is derived. The fundamental challenge when designing a family of products is resolving the inherent trade-off between commonality and performance. If there is too much commonality, then individual products may not meet their performance targets; however, too little sharing restricts the economies of scale that can be achieved during manufacturing and production. Multi-objective evolutionary optimisation algorithms have been used extensively to address this trade-off and determine which variables should be common (i.e., part of the platform) and which should be unique in a product family. In this chapter, we present a novel approach based on many-objective evolutionary optimisation and visual analytics to resolve trade-offs between commonality and many performance objectives. We provide a detailed example involving a family of aircraft that demonstrates the challenges of solving a 10-objective trade-off between commonality and the nine performance objectives in the family. Future research R. A. Shah T. W. Simpson (&) Industrial & Manufacturing Engineering, Pennsylvania State University, University Park, USA e-mail: tws8@psu.edu R. A. Shah e-mail: ruchit@psu.edu P. M. Reed Civil & Environmental Engineering, Pennsylvania State University, University Park, USA e-mail: preed@engr.psu.edu L. Wang et al. (eds.), Multi-objective Evolutionary Optimisation for Product Design and Manufacturing, DOI: 10.1007/978-0-85729-652-8_4, Springer-Verlag London Limited 2011 137 directions involving the use of multi-objective optimisation and visual analytics for product family design are also discussed. 4.1 Balancing Commonality and Performance During Product Family Design For most companies, product variety is a key to maintaining their market share. Today there are wide arrays of choices available for nearly all consumer products and services; thus, for a company to create a niche for itself its product offerings must be diverse enough to appeal to multiple market segments. However, offering a wide variety of products has its downsides as proliferation of product variety may incur substantial costs to the company [1–6] and reduce its profitability. Many companies struggle to provide variety in their product offerings while maintaining reasonably low costs. This often results from a company’s failure to embrace commonality, compatibility, standardisation and modularisation across the product lines [7], which degrades a company’s ability to achieve economies of scale across their production/manufacturing process. Unique product offerings are advantageous to customers but expensive for companies to achieve. High product variety offers customers options customised to their specific needs and preferences but reduces the margins for the company as the increased price might not be proportional to the perceived value estimated by the customer. Commonality on the other hand is cost-effective for the company, but it can compromise customer needs and requirements. Increased commonality allows the company to share resources across products, decrease inventory and take advantage of economies of scale to reduce procurement costs [8]. However, if the products are too common, then they can lose their distinctiveness [9]. In a customer-driven and highly competitive marketplace a company must effectively balance customer preferences against its profitability and economic stability. Thus the challenge is to meet the individual customer’s wants and needs while keeping overall costs low. Developing product platforms and designing families of products based on these platforms is one way to address the challenge associated with sharing assets across the products [7]. Product family design involves concurrent design of multiple products that share common features, components and subsystems based on a common product platform [10]. Optimising the design of product families is the key to resolving the trade-off between the conflicting objectives of commonality and individual product performance. A successful design of a product family maximises the commonality as much as possible without sacrificing the distinctiveness of the individual products in the family. Many researchers have focussed on multi-objective optimisation approaches for balancing the conflicting objectives of commonality and performance. Simpson [11] reviews and categorises over 40 such approaches. For instance, Nelson et al. [12] 138 R. A. Shah et al.	algorithm;archive;cobham's thesis;e-procurement;email;floor and ceiling functions;image resolution;interaction;interactivity;moea framework;mathematical optimization;monte carlo method;niche blogging;procurement;random search;requirement;simpson's rule;simulation;springer (tank);visual analytics	Ruchit A. Shah;Patrick M. Reed;Timothy W. Simpson	2011		10.1007/978-0-85729-652-8_4	computer vision;engineering;data science;data mining	Web+IR	0.5457850525378345	-8.060908139763765	137111
a2c7d8c1f979ed9a53bde61ef1757db879842d32	competing with privacy	information acquisition information disclosure online privacy privacy regulation;corporate disclosure;information acquisition;competition;online technology;hd28 management industrial management;grupo de excelencia;rights;privacy regulation;journal article;ethics;internet;administracion de empresas;knowledge acquisition;information disclosure;economia y empresa;grupo a;online privacy;information;privacy regulationinformation	We analyze the implications of consumer privacy for competition in the marketplace. We consider a market where rms set prices and disclosure levels for consumer information and consumers observe both before deciding which rm to patronize and how much information to provide it with. The provision and disclosure of information presents tradeo s for all market participants. Consumers bene t from providing information to the rm, as this increases the utility they derive from the service, but they incur disutility from information disclosure. This, in turn, bene ts the rm providing an additional source of revenue, but reduces consumer demand for the service. We characterize equilibrium information provision, disclosure levels, and prices, and show that competition with privacy has several e ects on the marketplace. First, competition drives the provision of services with a low level of disclosure. Second, competition ensures that services with a high level of disclosure subsidize consumers. Third, rms maximize pro ts at the extensive rather than the intensive margin, outperforming competitors by attracting a larger customer base. And fourth, higher competition intensity need not improve consumer privacy when consumers exhibit low willingness to pay. Our ndings are particularly relevant to the business models of Internet rms and contribute to inform the regulatory debate on consumer privacy.	consumer privacy;high-level programming language;utility	Ramon Casadesus-Masanell;Andres Hervas-Drane	2015	Management Science	10.1287/mnsc.2014.2023	public relations;the internet;competition;ethics;information;rights;marketing;microeconomics;management;law;commerce	Security	-2.7388756500691356	-7.196644052197844	137131
746fad885119caccf13f5313aeb05bdc1a43f2e8	a knowledge based approach to loss severity assessment in financial institutions using bayesian networks and loss determinants	modelizacion;analyse risque;capital;bayesian network;volatility;finance;base de connaissances;risk analysis;defecto;evenement rare;analisis cuantitativo;gestion risque;risk management;verticalite;loi conditionnelle;basel ii;ley condicional;operational risk;advanced measurement approach;equite;scenario;modelisation;analisis riesgo;equidad;reseau bayes;equity;institucion financiera;argumento;analyse quantitative;verticalidad;rare event;causalite;red bayes;financial institutions;defect;acontecimiento rara;script;bayes network;defaut;quantitative analysis;institution financiere;base conocimiento;volatilite;financial institution;expert knowledge;risk management or in financial institutions bayesian networks loss determinants advanced measurement approach;gestion riesgo;verticality;volatibilidad;loss determinants;scenario generation;modeling;conditional distribution;finanzas;historical data;causality;causalidad;or in financial institutions;bayesian networks;knowledge base	Modelling loss severity from rare operational risk events with potentially catastrophic consequences has proved a difficult task for practitioners in the finance industry. Efforts to develop loss severity models that comply with the BASEL II Capital Accord have resulted in two principal model directions where one is based on scenario generated data and the other on scaling of pooled external data. However, lack of relevant historical data and difficulties in constructing relevant scenarios frequently raise questions regarding the credibility of the resulting loss predictions. In this paper we suggest a knowledge based approach for establishing severity distributions based on loss determinants and their causal influence. Loss determinants are key elements affecting the actual size of potential losses, e.g. market volatility, exposure and equity capital. The loss severity distribution is conditional on the state of the identified loss determinants, thus linking loss severity to underlying causal drivers. We suggest Bayesian Networks as a powerful framework for quantitative analysis of the causal mechanisms determining loss severity. Leaning on available data and expert knowledge, the approach presented in this paper provides improved credibility of the loss predictions without being dependent on extensive data volumes.	bayesian network	David Häger;Lasse B. Andersen	2010	European Journal of Operational Research	10.1016/j.ejor.2010.06.020	knowledge base;actuarial science;economics;risk management;computer science;operations management;bayesian network;data mining;statistics	ML	4.955203831031582	-9.423582311415107	137505
347a40495745d4d90d42a6c50f3ebafbbf275d00	aircraft scheduled airframe maintenance and downtime integrated cost model		Aviation industry has grown rapidly since the first scheduled commercial aviation started one hundred years ago. There is a fast growth in the number of passengers, routes, and frequencies, with high revenues and lowmargins, which make this industry one of themost challenging businesses in theworld. Every operator aims to undertake theminimumoperating cost and gain profit asmuch as possible. One of the significant elements of operator’s operating cost is the maintenance cost. During maintenance scheduling, operator calculates the maintenance cost that it needs to budget. Previous works show that this calculation includes only costs that are directly related to the maintenance process such as cost of labor, material, and equipment. In some cases, overhead cost is also included. Some of previous works also discuss the existence of another cost throughout aircraft downtime, which is defined as cost of revenue loss. Nevertheless, there is not any standard model that shows how to define and calculate downtime cost. For that reason, the purpose of this paper is to introduce a newmodel and analysis technique that can be used to calculate aircraft downtime cost due to maintenance.		Remzi Saltoglu;Nazmia Humaira;Gökhan Inalhan	2016	Adv. Operations Research	10.1155/2016/2576825	carrying cost;marginal cost;cost contingency;total absorption costing;reliability engineering;relevant cost;simulation;total cost;operations management;semi-variable cost;cost engineering;cost centre;operations research;cost estimate	DB	7.611190880463468	-4.984823231910551	137563
2564db413c8c031582791401a5fb1cabcf73c19e	an eoq model for a deteriorating item with time-varying demand and time-dependent partial backlogging	time varying demand;inventory;time dependent partial backlogging;waiting times;economic order quantity;finite time horizons;variable backlogging;deteriorating items;deterioration;eoq;variable replenishment	This paper describes an EOQ model for a deteriorating item considering time-dependent demand and time-dependent partial backlogging, which depends on the length of the waiting time for the next replenishment over a finite time horizon and variable replenishment cycle. Equal replenishment cycle length in case of fixed planning horizon is relaxed in this model. Also, backlogging rate is taken to be dependent on waiting time of the customers, instead of waiting line of the customers. This seems to be better representation since impatient customers naturally want to know how long time they have to wait for receiving their goods, not how many customers are ahead. The model is solved analytically to obtain the optimal solution of the problem for a general time-dependent demand pattern. It is then illustrated with the help of numerical examples.	economic order quantity	S. K. Ghosh;Sudhansu Khanra;K. S. Chaudhuri	2011	IJMOR	10.1504/IJMOR.2011.040026	economic order quantity;economics;marketing;operations management;microeconomics;mathematical economics	Vision	2.54513493396221	-4.308152544194961	137791
0d474764aa3307869ea816b6870f89a1136ebe9a	multi-period aggregate production planning in a news-vendor framework	probleme vendeur journaux;forecasting;reliability;project management;productivite;stochastic process;information systems;gestion production;maintenance;agregat;soft or;information technology;industrie alimentaire;packing;operations research;location;productividad;investment;journal;industria alimenticia;consultation;production management;journal of the operational research society;consulta;inventory;purchasing;agregado;history of or;retroaccion;logistics;food industry;stochastic processes;retroaction;marketing;scheduling;base stock;gestion produccion;stock minimo;processus stochastique;programacion produccion;feedback regulation;mantenimiento;production;communications technology;production planning;control;cout production;stock minimal;computer science;operational research;productivity;production cost;proceso estocastico;planification production;newsboy problem;aggregate production planning;problema vendedor diarios;applications of operational research;or society;jors;management science;infrastructure;coste produccion;aggregate	The paper focuses on the control decisions in the area of multi-period, aggregate production planning. The plan consists of a number of sequential planning periods stretching out to a particular time horizon. Owing to machine downtime, quality, supply, and maintenance problems, true productivity differs from the expected. Therefore, at the end of each planning period, the planner must have immediate feedback about production outcome. The results are analysed for variations from the plan (shortfalls or surpluses) and any differences are used to modify subsequent plans. The goal is to minimize the expected total costs including productivity, overtime as well as overand under-production costs. Although the presented solution is generally not of base-stock type, a correspondence between it and the solution of the classical newsboy problem is revealed. This paper was developed during a consultation assignment in the food industry where the planning results were tested, and the case is presented. Journal of the Operational Research Society (2006) 57, 423–433. doi:10.1057/palgrave.jors.2602002 Published online 1 June 2005	aggregate data;downtime;newsvendor model	K. Kogan;Victor Portougal	2006	JORS	10.1057/palgrave.jors.2602002	stochastic process;logistics;aggregate;productivity;food industry;inventory;economics;forecasting;investment;marketing;operations management;sales and operations planning;reliability;mathematics;location;management;operations research;scheduling;aggregate planning;statistics	AI	5.531202624961162	-3.284414841227406	137811
3c1b4b5fe5d3e75adab9345b831be2c27b60dff2	coordination order processing in decentralized production units using hierarchical simulation models and web-technologies	decentralized production unit;hierarchical simulation model;coordination order processing;environmental management;job shop scheduling;decision support system;hierarchical model;simulation model;order processing;machine tools;production system;production systems;productivity;world wide web;logistics;internet;pressing;decision support systems	Increased dynamics and flexibility of order processing are considered the potentials of decentralized production systems. To feed these potentials a certain degree of partial autonomy is admitted. Nevertheless this given partial autonomy must be aligned to global company-wide objectives. One approach is supporting and coordinating decision-taking by using a simulation-based assistance system. Hierarchical modeling facilitates the suitable configuration of the simulation models and allows faster examination of larger production areas. Web-technologies, such as easy-to-use web-clients together with capable simulation-servers, make it possible for simulation-laymen to be supported in decision-taking by the assistance-system. Efficient order processing in decentralized production units requires a great number of decisions, which have to be taken permanently and rapidly. Depending on the extent of partial autonomy admitted to the decentralized units, many of these decisions are token locally, such as decisions on the appropriate job-sequence-order or the right malfunction handling. These local decisions are driven by local objectives, e.g. the optimal utilization of the own machines or the optimal workload in the own unit. In addition to local decisions others are token from a global point of view, such as the adaption of the product spectrum or the machine spectrum. These global decisions are driven by global objectives, e.g. the d e c e n t r a li ze d prod uc ti o n u n i t s	autonomy;point of view (computer hardware company);production system (computer science);simulation	Werner E. Lulay;G. Reinhart	1998				Arch	4.2922687506862855	0.5082707608354686	137821
c925d4d9bc822599ce4f535df1b163ec3af5b3fa	reverse logistics facility location using cyclical model of extended mrp theory	energy;reverse logistics;net present value npv;extended mrp theory;input output analysis	Grubbstrom’s well-developed MRP Theory has been mostly used in modeling production processes. Global supply chains also contain distribution, consumption and recycling processes. For this reason theory was recently further extended to incorporate all kinds of activities. Such extended model, which consists of four main sub-systems, is closed and can be used for several detailed analyses. Since the importance of reverse logistics is increasing, this paper will focus on parameters which determine Net Present Value of the whole system, depending on geographical location of recycling facilities. We will show how lead times, transportation costs, setup costs and price of labor and energy of individual location contribute to overall NPV of the system. Copyright Springer-Verlag 2013	facility location problem;logistics;media redundancy protocol	Danijel Kovacic;Marija Bogataj	2013	CEJOR	10.1007/s10100-012-0251-x	energy;input–output model;operations management;operations research;commerce	Theory	9.543776667933999	-3.1899644099422755	137848
61d30fef4ff69686cb04106f56e902c40cad4f51	optimal pricing policies for services with consideration of facility maintenance costs	poisson process;service system;maintenance cost;increasing failure rate;optimal policy;increasing price elasticity;price elasticity;profitability;service pricing;facility maintenance;comparative statics	For survival and success, pricing is an essential issue for service firms. This article deals with the pricing strategies for services with substantial facility maintenance costs. For this purpose, a mathematical framework that incorporates service demand and facility deterioration is proposed to address the problem. The facility and customers constitute a service system driven by Poisson arrivals and exponential service times. A service demand with increasing price elasticity and a facility lifetime with strictly increasing failure rate are also adopted in modelling. By examining the bidirectional relationship between customer demand and facility deterioration in the profit model, the pricing policies of the service are investigated. Then analytical conditions of customer demand and facility lifetime are derived to achieve a unique optimal pricing policy. The comparative statics properties of the optimal policy are also explored. Finally, numerical examples are presented to illustrate the effects of para...		Ruey Huei Yeh;Yi-Fang Lin	2012	Int. J. Systems Science	10.1080/00207721.2010.543489	pricing;price elasticity of demand;actuarial science;poisson process;comparative statics;profitability index;service system	AI	2.632021102855304	-5.115195000993083	138030
b965c0c2de07475f9fe210a60895723008ebef70	a study on the influences of r&d investment on information security for mechanical and electronics industry	r d investment;enterprise value;black scholes option model;market value;real option value	In this study, we have tried to analyze the influence of research and development (R&D) investment on real option value (ROV), expended net present value (ENPV) and market value by analyzing R&D investment, ROV, ENPV and market value of different industry types from an ex post perspective. The results show that ENPV, which has been deduced by real option according to R&D investment, reflects market value well and possesses a strong correlation with R&D investment, ROV, ENPV and market value. This implies that our study result corresponds with existing theories. Copyright © 2013 John Wiley & Sons, Ltd.		Seung-Ryung Oh;Kun Woo Kim	2014	Security and Communication Networks	10.1002/sec.831	market value;enterprise value	AI	-1.865439880310947	-9.427234176610263	138056
100e26e9dc4d8f971d8d65c8ca8e7423c32047a6	aggregate production planning with small data in tft-lcd manufacturing	thin film transistors manufacturing aggregates production planning robustness predictive models;demand forecast aggregate production planning small data;capacity demand mismatch aggregate production planning tft lcd manufacturing two phase research framework capacity demand mismatch high tech industry virtual data generation process data learning stochastic programming minimax regret technique tft lcd firm demand uncertainty;small data;aggregate production planning;demand forecast;stochastic programming liquid crystal displays minimax techniques production planning	This study proposes a two-phase research framework to address the problem of capacity-demand mismatch in the high-tech industry. In the first stage, due to the characteristics of small data, we apply the virtual data generation process (VDGP) to support the data learning for demand forecast. In the second stage, based on the demand scenarios, a robust capacity decision is provided by the stochastic programming (SP) technique and the minimax regret (MMR) technique addressing demand uncertainty. We conduct an empirical study of a TFT-LCD firm to validate the proposed framework. That result shows that the proposed framework, in particular the SP technique, provides a robust capacity levels addressing the problem of capacity-demand mismatch.	aggregate function;meet-me room;minimax;regret (decision theory);stochastic programming;thin-film-transistor liquid-crystal display;two-phase commit protocol	Chia-Yen Lee;Ming-Chien Chiang	2015	2015 IEEE International Conference on Automation Science and Engineering (CASE)	10.1109/CoASE.2015.7294151	simulation;economics;marketing;operations management	Robotics	1.9984494366918193	-6.215343217029914	138180
e58be0e896942b0ded328184e49c2a119c518f50	price discounts for increased profitability under partial backordering	partial backordering;inventory;price discounting;eoq	If some, but not all, customers are willing to wait for an out-of-stock product to become available, sellers may be able to increase their profits by offering a price discount to increase the number of backordered demands rather than losing those sales. We modify an existing model for the deterministic economic order quantity with partial backordering by making the backordering percentage a function of the size of the discount. We combine results about the optimal solution for a partial backordering model with a fixed backorder percentage and a search procedure to determine whether offering a discount is optimal and, if so, how large the discount should be to maximize profit.	economic order quantity;scrum (software development)	Matthew J. Drake;David W. Pentico	2011	ITOR	10.1111/j.1475-3995.2010.00779.x	financial economics;economic order quantity;inventory;economics;operations management;microeconomics	Theory	1.8750915065982998	-4.933267253154424	138268
4084821c842b1922326e407989fdddf6b9caf201	charging games in networks of electrical vehicles	game theory;nash equilibrium;distribution networks;secondary cells;games nash equilibrium vehicles batteries ieee potentials limiting standards;charging games;price of anarchy;power transformers;potential games;electric vehicles;secondary cells distribution networks electric vehicles game theory power transformers;price of anarchy electrical vehicles networks charging games static noncooperative game formulation distributed charging problem common residential distribution transformer battery charging cost functions ordinal potential game nonatomic versions equilibrium analysis distribution network joule losses;price of anarchy charging games electrical vehicle distribution networks potential games nash equilibrium;electrical vehicle	In this paper, a static non-cooperative game formulation of the problem of distributed charging in electrical vehicle (EV) networks is proposed. This formulation allows one to model the interaction between several EV which are connected to a common residential distribution transformer. Each EV aims at choosing the time at which it starts charging its battery in order to minimize an individual cost which is mainly related to the total power delivered by the transformer, the location of the time interval over which the charging operation is performed, and the charging duration needed for the considered EV to have its battery fully recharged. As individual cost functions are assumed to be memoryless, it is possible to show that the game of interest is always an ordinal potential game. More precisely, both an atomic and nonatomic versions of the charging game are considered. In both cases, equilibrium analysis is conducted. In particular, important issues such as equilibrium uniqueness and efficiency are tackled. Interestingly, both analytical and numerical results show that the efficiency loss due to decentralization (e.g., when cost functions such as distribution network Joule losses or life of residential distribution transformers when no thermal inertia is assumed) induced by charging is small and the corresponding “efficiency”, a notion close to the Price of Anarchy, tends to one when the number of EV increases.	anarchy;extended validation certificate;joule;numerical analysis;ordinal data;transformer;transformers	Olivier Beaude;Samson Lasaulce;Martin Hennebel	2012	2012 6th International Conference on Network Games, Control and Optimization (NetGCooP)		price of stability;game theory;mathematical optimization;simulation;economics;microeconomics;mathematical economics;transformer;price of anarchy;nash equilibrium	Robotics	2.017580655437887	3.7924145774755944	138546
3a4b510d68e1bcf3db83584328be52b874940523	price dispersion and loss-leader pricing: evidence from the online book industry		I this paper, we develop a theoretical model to analyze the pricing strategies of competing retailers with asymmetric cross-selling capabilities when product demand changes. Our results suggest that retailers with better opportunities for cross-selling have higher incentives to adopt loss-leader pricing on high-demand products than retailers with low cross-selling capabilities. As a result, price dispersion of a product across retailers rises when its demand increases. The predictions of our model are consistent with the empirical evidence from the online book retailing industry. Using product breadth as a proxy for cross-selling capability, we find that retailers with high cross-selling capabilities reduce prices on best sellers more aggressively than retailers with low cross-selling capabilities. As a result, price dispersion increases when a book makes it to the best-seller list, and the increase is mainly driven by the difference in pricing behavior between retailers with different cross-selling capabilities. Our empirical results are robust against a number of alternative explanations.	online book;proxy server;theory	Xinxin Li;Bin Gu;Hongju Liu	2013	Management Science	10.1287/mnsc.1120.1642	pricing;economics;marketing;microeconomics;economy;management;commerce	Web+IR	-2.382583946916931	-8.378981815083796	138647
d6a7d715417086908d5e06e9d96a03c00c76ec92	voluntary retirement and portfolio selection: dynamic programming approaches		Abstract   I consider a continuous-time optimal consumption and portfolio selection problem with voluntary retirement. When the agent’s utility of consumption and leisure are of Cobb–Douglas form, I use the dynamic programming method to derive the value function and optimal strategies in closed-form. These coincide with the solutions of Farhi and Panageas (2007)  [7] , who have solved the problem using a martingale method.	dynamic programming	Yong Hyun Shin	2012	Appl. Math. Lett.	10.1016/j.aml.2012.03.023	mathematical optimization	PL	1.4243859251461177	-2.1651723543933947	138912
2ba7c7e1083c281a15d9b2d25e07b3ca3ef45886	priority rules on atn (prt) intersections		In Autonomous Transit Networks some basic elements influence the throughput: network structure, maximum velocity, number of vehicles etc. Other parameters like station structure, dynamic routing or vehicle behavior on intersections play minor role. Yet in highly congested nets, when vehicles interfere in the traffic, some subtle decisions may influence overall system ridership. We tested the impact of intersection priority rules on passenger waiting time, which measures the throughput. The dependence occurred its relevance in a crowded network.	precomputed radiance transfer;relevance;routing;throughput;velocity (software development)	Waldemar Grabski;Wiktor B. Daszczuk	2017	CoRR		computer science;simulation;throughput;traffic engineering;computer network;adaptive routing;right of way	Networks	9.888980422493283	-9.693284738067586	138922
a305ccf609f109bcbbdc70a84e6d96fe58f36852	information sharing for competing supply chains with demand disruption	game theory;information sharing;supply chain competition;disruption management;robustness	We investigate pricing decisions and information value in two competing supply chains, each consisting of one manufacturer and one retailer. Both retailers are engaged in Bertrand retail competition and are endowed with the private information on the disrupted demand. Three information sharing scenarios have been considered, i.e. , information sharing in both chains, information sharing in only one chain, and information sharing in neither chain. For each information scenario, there always exists robustness for each manufacturer’s production plan. That is, when the disrupted amount of the market demand is sufficiently small, the manufacturer’s production plan or the retailer’s order quantity will be unchanged. Meanwhile, we also study the information value by comparing these three information scenarios, and find that the information value not only works in one chain directly, but also does in the competing chain indirectly. Through comparative analysis, we find that the retailer is reluctant to share his private information on the disrupted demand with his partner because of the fear of information leakage. Meanwhile, the performance of the whole chain may become worse off if the information of disrupted demand is shared in this chain.	denial-of-service attack	Kebing Chen;Meiling Feng;Lei Yang	2017	RAIRO - Operations Research	10.1051/ro/2016062	game theory;service management;robustness	Robotics	-3.032116422848177	-6.407594207260403	138960
08e8afd4695b0e44a0f1e70a728890034ecec989	gemini-e3, a general equilibrium model of international-national interactions between economy, energy and the environment	welfare cost;cge model;labor market;computable general equilibrium model;social security;nccr climate;general equilibrium model;european monetary union	The purpose of this paper is to present the new version of GEMINI-E3, which is the fifth and incorporates significant changes from the previous version in particular with respect to its size and its modularity. GEMINI-E3 is a Computable General Equilibrium Model and represents now a family of models of different specifications and with several successive versions. It retains many specifications that are common to CGE models but also some specific features, mainly concerning the measurement and analysis of the welfare cost of policies and the great detail in the representation of taxation and social security contributions. The paper gives a detailed presentation of the model, its main blocks and equations, and shows how it can be adapted to specific contexts. In particular a new version is being developed jointly with the standard one, taking into account the constraints of the European Monetary Union and the unbalances in the labor markets of industrialized countries (GEMINI-EMU). This clearly shows that CGE models, beside their main virtue that is total consistency at the domestic and at the world levels, are very flexible in their specification.	computable function;interaction;social security	Alain Bernard;Marc Vielle	2008	Comput. Manag. Science	10.1007/s10287-007-0047-y	computable general equilibrium;general equilibrium theory;economics;international trade;economy;international economics	AI	0.7819896400382029	-0.2222805403620476	139116
0853ad2d1495e99fcf49fc3f29f04bbbbcc3f0c8	optimal strategies for corrective assembly approach applied to a high-quality relay production system	assembly error;high quality;matching;optimization;corrective assembly approach	In the assembly of high-quality products in a corrective assembly approach, measurement and reprocessing errors occur in the measuring and reprocessing stages, and these unexpected errors can lead to the erroneous selection of the reprocessing machine, and produce unsatisfactory products. In this paper, we consider the part flow in a high-quality relay production system applying the corrective assembly approach by incorporating machining, measurement and reprocessing errors simultaneously, and formulate the production rate of high-quality products satisfying the predetermined assembly tolerance. Optimization is used to yield the maximum production rate by using reprocessing machine selection and design strategies. The results indicate the following: (1) the proposed optimization methodology effectively yields the maximum production rate and presents the optimal selection range and the optimal adjustment size of the reprocessing machine, and (2) the reprocessing accuracy affects the maximum production rate but has little effect on the optimal selection range and the optimal adjustment size.	production system (computer science);relay	Toshirou Iyama;Masahiro Mizuno;Kenneth N. McKay;Nobuhito Yoshihara;Naohiro Nishikawa	2013	Computers in Industry	10.1016/j.compind.2013.02.012	matching;reliability engineering;engineering;operations management;engineering drawing	Robotics	8.549358209764325	0.8688351556614577	139251
729e91051e3b100f0d080facb3cacd891e74b8ef	community storage for firming	resource management;smart grids;games;microgrids;electricity supply industry;conferences;real time systems	We analyze the benefit of storage capacity sharing for a set of consumers in a community (e.g., an apartment building or an industrial park). Each consumer has its own choice of either installing its own storage system or investing in a shared storage system. More precisely, they will decide on the capacity of the storage system to minimize the installation cost subject to a chance constraint for firming (e.g., to limit the exposure risk to the real time market). If the consumers decide to operate a shared storage system, they must also decide on a scheme to allocate the costs. We formulate the problem as a cooperative game and identify an efficient and stable cost allocation rule. In settings where certain statistical information is private, the cooperative storage sharing game becomes embedded with a non-cooperative information reporting game. We show our proposed cost allocation rule induces all consumers to report their private information truthfully.	computer data storage;embedded system;personally identifiable information	Chenye Wu;Jared Porter;Kameshwar Poolla	2016	2016 IEEE International Conference on Smart Grid Communications (SmartGridComm)	10.1109/SmartGridComm.2016.7778822	simulation;operations management;business;commerce	DB	2.413630555513294	3.437904239960662	139314
118217375f93904f5c6a513e246dfb2cb092473e	inventory and investment in setup and quality operations under return on investment maximization	modelizacion;rentabilidad;quality assurance;capital;global solution;non convex programming;return on investment;diminution cout;nonconvex optimization;reformulation linearization technique;inversion;investment cost;coste inversion;cost reduction;quality improvement;programmation non convexe;investment;inventory;investment strategies;administracion deposito;modelisation;aseguracion calidad;capital investment;programacion no convexa;technique linearisation;cout investissement;investissement;gestion stock;presupuesto;linearization techniques;rentabilite;global optimization;profitability;budget;solution globale;reduccion costes;modeling;assurance qualite;inventory control;budget constraint;solucion global;cost lowering	In this paper, we construct and analyze a Return On Investment (ROI) maximization model for inventory and capital investment in setup and quality operations under an investment budget constraint. Specifically, we show how such an ROI maximization model can be formulated and derive analytical results such as the conditions under which the inventory is reduced and for the determination of the unique global optimal solution. In addition, by applying the Reformulation-Linearization Technique (RLT), we show via numerical examples how this nonconvex optimization model can be solved effectively and how RLT may produce superior results to those from the conventional Cut Across the Board Rule (CABR). Various managerial insights are provided throughout the paper. For example, as the investment budget increases (or decreases), a fundamental shift of investment strategies (setup cost reduction vs. quality improvement) may be necessary so as to maximize ROI.	entropy maximization	Jie Li;K. Jo Min;Toshitsugu Otake;Timothy Van Voorhis	2008	European Journal of Operational Research	10.1016/j.ejor.2006.11.045	inversion;inventory control;quality assurance;mathematical optimization;budget constraint;return on investment;inventory;economics;capital;investment;operations management;operations research;welfare economics;global optimization	Theory	4.198473667894634	-4.822170247732507	139331
3d4862e0197b4715bd1c6264100a2084cb60461a	discrete allocation mechanisms: dimensional requirements for resource-allocation mechanisms when desired outcomes are unbounded	resource allocation	"""AWARDS, FELLOWSHIPS, ETC. Postdoctoral Fellow of Social Science Research Council, 1956 7 Fourth item in publications below awarded McKinsey Foundation prize for best article in JOURNAL OF BUSINESS, 1960 Ford Foundation Faculty Research Fellowship, 1962 3 Guggenheim Fellowship, 1965 66 Fulbright Hays Research Award, 1965 66 Elected Fellow of the Econometric Society, 1975 Article """"On Economies of Scope in Communication"""" awarded Koc University (Istanbul) Prize for best contribution to ECONOMIC DESIGN, 1997"""	requirement	Leonid Hurwicz;Thomas Marschak	1985	J. Complexity	10.1016/0885-064X(85)90015-9	resource allocation;mathematics	Theory	0.5378439903950494	0.6561048714010077	139589
349a9b775503151684787aafdfa4833990cc1e96	a buffer stock model to ensure price stabilization and availability of seasonal staple food by empowering producer using warehouse receipt system	stock control;management system;financial management;nonlinear programming;pricing;price stability;integer programming;stock price;food products;financial institutions;seasonality;availability government numerical models programming economic indicators supply and demand frequency modulation;warehousing;profitability;mixed integer nonlinear programming;mixed integer nonlinear programming approach buffer stock model price stabilization seasonal staple food availability warehouse receipt system agro industry planting season harvest season staple food scarcity price fluctuation indirect market intervention model collateral management system warehouse management financial institutions;warehousing financial management food products integer programming nonlinear programming pricing stock control;warehouse receipt buffer stock price stabilization	Staple food that is produced by agro industry has salient supply disparity during the harvest and planting season. This situation could cause both staple food scarcity and price fluctuation. An indirect market intervention model is proposed to mitigate producer's revenue loss when selling price plunges and to secure consumer's need when staple food is scarce. The model uses buffer stock scheme in accordance with warehouse receipt system (WRS) and collateral management system. By using WRS, producer can pawn some of their staple food to the warehouse management and obtain receipt, then give the receipt to the Financial Institutions to access loan. Next, they can redeem their pawn and sell them under profitable price. Mixed-integer nonlinear programming (MINLP) approach has been used to determine the decision variables for producer and government. The result shows that the model can be used to solve problem.	binocular disparity;decision theory;nonlinear programming;power supply;price point;quantum fluctuation;safety stock;the pawn	Wahyudi Sutopo;Senator Nur Bahagia;Andi Cakravastia;T. M. A. Arisamadhi	2011	2011 IEEE International Conference on Industrial Engineering and Engineering Management	10.1109/IEEM.2011.6117926	price of stability;pricing;mathematical optimization;stock control;integer programming;economics;nonlinear programming;marketing;finance;management system;microeconomics;market economy;warehouse;seasonality;commerce;profitability index	Robotics	0.8605702825711092	-6.538917572736127	139598
635b5878ee84549354f9cc6b169ce7e742b3e362	optimal cash flow and operational planning in a company supply chain	milp formulation;mixed integer linear program;optimal solution;heuristic;operational planning;satisfiability;supply chain;cash flow;supply chain management	The current paper shows the links and impact between physical flow and financial flow during the tactical planning process in a company supply chain. The target is to obtain optimal solutions during process operations preserving stock level, liquidity and satisfying customers. The proposed formalization combines a deterministic cash flow management model with a schedule management model using a mixed integer linear program (MILP) formulation. The benefits of this work are shown through a case study that illustrates the operational problem, modelled flows and necessary constraints to help high-level staff during operational planning and financial activities.		S. Bertel;P. Fenies	2008	Int. J. Computer Integrated Manufacturing	10.1080/09511920701574628	supply chain management;heuristic;marketing;operations management;cash flow;microeconomics;supply chain;satisfiability	Robotics	9.783329640542082	-2.507368180057801	139615
8d94da2f46b3b35d824ecd64789b0b7e4e7593ab	can bagging improve the forecasting performance of tourism demand models?				Haiyan Song;Stephen F. Witt;Richard T. Qiu	2017		10.1007/978-3-319-50742-2_25	financial economics;demand forecasting;marketing;microeconomics	Vision	2.1920251201983345	-9.024459826999966	139697
df3031f0fdc5e8c2d8439265534439c8425ec75f	on the application of stochastic models in nuclear power plant maintenance	reliability;stochastic process;case studies;maintenance;operations research;stochastic;nuclear power plant;stochastic model;economics;ontario power generation;maintenance management	Whereas Philip A. Scarf’s effort [Eur. J. Operat. Res. 99 (1997) 493] can be seen as an “appeal to Maintenance Modelers to work with Maintenance Engineers and Managers on real problems” the current effort can be seen as the start of a program to do just that by using the relatively large 20 year old data bases available at Ontario Power Generation (OPG). A significant portion of the traditional problem areas have been circumvented by combining well known elementary models with input from practitioners in the nuclear maintenance field of over 25 years experience.#R##N##R##N#Case studies of containment airlock seal failures are used here to illustrate the direct applicability of stochastic processes. The application is kept relatively clear and lucid to reflect the often non-stochastically trained audience. The results are displayed via economic alternatives to more easily attract the attention of maintenance managers.#R##N##R##N#The conclusions highlight several dramatic avenues that await the coordinated effort of practitioner and modeler at this particular juncture in time. Pursuit of these avenues could well result in a resurgence of all branches of operational research in large industry.	stochastic process	E. Kevin Doyle	2004	European Journal of Operational Research	10.1016/S0377-2217(02)00805-6	stochastic process;simulation;computer science;stochastic modelling;marketing;operations management;reliability;mathematics;stochastic;operations research;statistics	Vision	6.064764561682337	-7.304416962116408	139792
0b4df2af78785d78aca8e92cabd5a4d35510cba4	the economics of the cloud		This article proposes a model to study the interaction of price competition and congestion in the cloud computing marketplace. Specifically, we propose a three-tier market model that captures a marketplace with users purchasing services from Software-as-a-Service (SaaS) providers, which in turn purchase computing resources from either Provider-as-a-Service (PaaS) or Infrastructure-as-a-Service (IaaS) providers. Within each level, we define and characterize market equilibria. Further, we use these characterizations to understand the relative profitability of SaaSs and PaaSs/IaaSs and to understand the impact of price competition on the user experienced performance, that is, the “price of anarchy” of the cloud marketplace. Our results highlight that both of these depend fundamentally on the degree to which congestion results from shared or dedicated resources in the cloud.	anarchy;cloud computing;multitier architecture;network congestion;platform as a service;purchasing;software as a service	Jonatha Anselmi;Danilo Ardagna;John C. S. Lui;Adam Wierman;Yunjian Xu;Zichao Yang	2017	TOMPECS	10.1145/3086574	game theory;network economics;profitability index;cloud computing;software as a service;purchasing;price of anarchy;marketing;economics;microeconomics	Metrics	-3.220549714763864	-5.949966483618085	139814
6c2be3fd40df285b201b7478b714be2b9ac184fe	a new imperfect maintenance model based on delay-time concepts for single components with multiple failure modes		Components with multiple failure modes may encounter imperfect preventive maintenance triggered by inspections during their two-stage failure. Employing delaytime concepts and accumulative age, a new imperfect-maintenance model for these components is presented under the assumptions that failure modes are independent of each other and all kinds of defects will be dealt with in each maintenance task. Reliability and cost models are derived. Their characteristics are analyzed in numerical simulations. The results show components with more failure modes and worse imperfect inspection maintenance will have lower reliability, lower expected cycle cost and higher average cost per unit time. With an increasing inspection interval, the cycle cost will monotonically decrease while the average cost per unit time may have a local minimum. If inspection maintenance is insufficient, the minimum of the average cost per unit time will disappear, as does the best inspection interval.	analysis of algorithms;computer simulation;failure cause;maxima and minima;numerical analysis;software bug;time complexity	Xiufeng Li;Renyang He;Zhiwei Yan;Haijun Hu;Guangxu Cheng	2015	Int. J. Systems Assurance Engineering and Management	10.1007/s13198-014-0306-6	reliability engineering;engineering;operations management;forensic engineering	Robotics	6.939503869231863	-1.0992279722096563	139842
53d85739791a045c717a856d5f4641554af6421e	project scheduling using state-based probablistic decision networks	civil engineering computing;critical path analysis;decision diagrams;digital simulation;probability;scheduling;stroboscope simulation system;activity durations;add-on program;dependence;dynamic information;highway project;modeling power;probabilistic cpm scheduling;project scheduling;start date;state based probabilistic decision networks	This paper presents probabilistic CPM scheduling using add-on program to the STROBOSCOPE simulation sys that allows dependence and correlation between act durations as well as control over precedence and selection of paths. Activity durations and sequencing be defined in terms of the dynamic information th becomes available as a project evolves and includes actual start date and duration of activities already star An example highway project illustrates the modeli power of this approach.	add-ons for firefox;influence diagram;schedule (project management);scheduling (computing);simulation	Photios G. Ioannou;Julio C. Martínez	1998				Arch	7.532926274655773	0.6328284257437174	139874
a7001a000768d1088573677a711bbaaa180d64a7	a job assignment scheme based on auction and immune optimization for grid computing	optimisation;probability;resource allocation grid computing optimisation;resource allocation;immune optimization;optimal job assignment solution auction immune optimization grid computing resource trading price;cloning;grid;immune optimization grid job assignment auction;computational modeling;job assignment;tuning;auction;geographic information systems;heuristic algorithms;clustering algorithms;resource trading price;geographic information systems cloning heuristic algorithms tuning probability computational modeling clustering algorithms;grid computing;optimal job assignment solution	In this paper, a job assignment scheme in grid is proposed. It determines the resource trading price between the buyer and the provider based on the auction, finding the optimal job assignment solution based on the immune optimization. Simulation results have shown that it is both feasible and effective.	grid computing;mathematical optimization;simulation	Xingwei Wang;Yao Fu;Chengcheng Tong;Min Huang	2008	The Third ChinaGrid Annual Conference (chinagrid 2008)	10.1109/ChinaGrid.2008.13	auction algorithm;mathematical optimization;operations management;management science;weapon target assignment problem;business	HPC	-0.2522334418443238	1.6302023170968503	139892
215a89dfff10e905c9a01648301f4b94e9e8901f	do bags fly free? an empirical analysis of the operational implications of airline baggage fees	baggage fees;departure delays;event study;airlines;on time performance	In 2008, the majority of U.S. airlines began charging first for one, and then, two checked bags. One of the often cited reasons for this action by the airlines’ executives was that this would influence customers to travel with less baggage and thus improve cost and operational performance. A notable exception to the charging for checked bags trend was Southwest Airlines, who turned their resistance to this practice into a “Bags Fly Free” marketing campaign. Using a publicly available database of the airlines’ departure performance, we investigate whether the implementation of checked bag fees really did result in better operational performance metrics. At the aggregate level we find that the airlines that began charging for one checked bag saw a significant relative improvement in their on-time departure performance in the 35-day period afterwards, compared to the airlines that were not charging for a checked bag during the same time period. However, charging a fee for both checked bags results in a worse on-time departure performance compared to charging for one checked bag. We also identify the differential impact of baggage fees on ‘low-cost’ versus ‘legacy’ carriers: the departure performance of the low-cost airlines became worse while it improved for the legacy carriers when charging for one checked bag. When the airlines began charging for two checked bags, we find no significant change in departure performance of legacy carriers, but a degradation of departure performance of low-cost carriers. Thus, our study provides empirical evidence on the influence of checked baggage fee policies on airlines’ operational performance.	aggregate data;elegant degradation	Mariana Nicolae;Mazhar Arikan;Vinayak Deshpande;Mark Ferguson	2017	Management Science	10.1287/mnsc.2016.2500	simulation;event study;economics;marketing;operations management;finance;advertising;interlining	Metrics	-2.6418608987335404	-8.995758606132108	140033
8ef11486885a10889b052ac050ebf87c177e26d7	market-oriented service network design when demand is sensitive to congestion		In this paper, we present a market-oriented service network design model in which the seller’s problem is to determine how many facilities to open, where to locate them, and which service capacities and service levels they should have to maximize overall profit. Our model explicitly considers the customers’ facility choice as a function of typical choice determinants, such as travel distance and congestion delays (which are endogenously impacted by the seller’s decisions) as well as other, exogenous factors such as price level and product variety. We relax the assumption adopted in many related works that the service provider has discretion as to the assignment of customers to facilities; instead, we allow customers to self-select based on their preferences for facility attributes according to an attraction-based choice model. Furthermore, we capture not only the effect of congestion on demand but also the reciprocal impacts of demand on congestion and service level by modeling each facility as an M/G/1 q...	network congestion	Cornelia Schön;David J Wyatt	2018	Transportation Science	10.1287/trsc.2017.0797	mathematics;service provider;operations management;price level;network planning and design;m/g/1 queue;discretion;service level	Theory	0.2287830519218162	-5.7777804838622755	140348
46f3615272f989781289c05f1d16efed3691af46	criticality of detailed modeling in semiconductor supply chain simulation	stock control data processing;supply chains supply chain management semiconductor device manufacture costs computational modeling manufacturing production facilities transportation electronics industry investments;resource manager;logistics data processing;stock control data processing semiconductors electronics industry logistics data processing discrete event simulation;customer service;level of detail detailed modeling criticality semiconductor supply chain simulation supply chain management cost reduction customer service performance inventory control policies multiple factories complexity output accuracy decision quality;level of detail;electronics industry;supply chain;semiconductors;inventory control;supply chain management;discrete event simulation	Supply chain management offers a large potential f organizations to reduce costs and improve customer serv performance. Simulation of supply chains can help these objectives by evaluating the impact of alterna inventory control policies. Supply chain simulation involves modeling of multiple factories across the cha and can get quite complex. Analysts typically carry o such simulation at a coarse level of detail to keep t complexity and computing resources manageab However, modeling at coarse levels may reduce t accuracy of outputs and affect the quality of decisions. this paper, we report on a study to compare the quality results at different levels of details in a semiconduct supply chain simulation.	inventory control;level of detail;self-organized criticality;semiconductor;simulation	Sanjay Jain;Chu-Cheow Lim;Boon-Ping Gan;Malcolm Yoke-Hean Low	1999		10.1145/324138.324547	inventory control;demand chain;supply chain management;service management;systems engineering;discrete event simulation;level of detail;semiconductor;supply chain	AI	8.821826512718756	2.1502386008897574	140409
fc561aeab1f45612472930475bd65e0a0e133383	min-max and predictive control for the management of distribution in supply chains	stock control;predictive control;goods distribution;cost function;uncertainty;strategic and tactical planning;distribution chain dc management;discrete time systems;minimax techniques;model predictive control minmax control predictive control distribution management supply chain inventory control multi item multi echelon distribution chain two level hierarchical framework discrete time dynamic model generic distribution chain stock replenishment policy customer demand branch and bound algorithm safety stocks online decisions goods transportation;transportation;safety;mathematical model;supply chain;min max optimization;tree searching discrete time systems goods distribution minimax techniques predictive control stock control supply chain management;tree searching;model predictive control mpc;inventory control;supply chain management;optimization model;strategic and tactical planning distribution chain dc management inventory control min max optimization model predictive control mpc;supply chain management predictive control mathematical model minimax techniques uncertainty inventory control discrete time systems	Inventory control for the management of multi-item multi-echelon distribution chains is addressed in a two-level hierarchical framework motivated by strategic and tactical points of view. Toward this end, a discrete-time dynamic model is presented together with various types of constraints to describe a generic distribution chain in detail. As to the strategic level, a worst-case approach is proposed to set up a stock replenishment policy by using the uncertain information available on long-term predictions of customers' demands. The solution of the resulting min-max problem is obtained by using a branch-and-bound algorithm to select policy parameters such as safety stocks and delivery cycle times of goods. The online decisions on the transportation of goods are made at the tactical level instead. In order to accomplish such a task, an approach based on model predictive control is proposed to exploit recent, more reliable, short-term predictions of the demands. Simulation results are presented to show the effectiveness and potential of the proposed methodology.	algorithm;best, worst and average case;branch and bound;computation;fractal dimension;inventory control;inventory theory;mathematical model;mathematical optimization;maxima and minima;one-class classification;row echelon form;safety stock;simulation;worst-case complexity	Angelo Alessandri;Mauro Gaggero;Flavio Tonelli	2011	IEEE Transactions on Control Systems Technology	10.1109/TCST.2010.2076283	inventory control;transport;stock control;supply chain management;simulation;uncertainty;mathematical model;mathematics;supply chain;model predictive control	Robotics	9.082370882107679	-2.041266147240272	140454
38b8c62bff6220ca8b0c74d4f969be247e71b30b	same bang, fewer bucks: efficient discovery of the cost-influence skyline		Influence maximization aims to find a set of persons in a social network that can be used as seeds for a viral marketing campaign, such that the expected spread of influence is maximized. Standard approaches to this problem produce a single seed set that either maximizes influence, or the “bang for the buck” if the vertices are associated with a cost. In this paper we consider the problem of finding the cost-influence skyline, i.e., the collection of all seed sets that are Pareto optimal w.r.t. seeding cost and expected influence. Computing the cost-influence skyline has a number of advantages over finding a single solution only. First, it provides a better understanding of the trade-off between cost and influence, which enables the user to make an informed choice regarding the budget. Second, by computing the costinfluence skyline we obtain the optimal seed set for any given seeding budget, not only the one that corresponds to singleton solutions found by existing algorithms. In practice, the problem is to discover the skyline w.r.t. two functions spanned by all subsets of size k of a set of vertices. Due to the extremely large number of such subsets, this is a very hard problem. We present an efficient heuristic algorithm for computing the skyline when one of the functions is linear (e.g., the seeding cost) and the other submodular (e.g., expected influence). The experiments show that the cost-influence skyline can be computed in reasonable time for networks with up to a million vertices.	bang file;combinatorial optimization;expectation–maximization algorithm;experiment;greedy algorithm;heuristic (computer science);mathematical optimization;national fund for scientific research;pareto efficiency;persistence (computer science);selection algorithm;skyline operator;social network;submodular set function;vertex (geometry);vertex (graph theory)	Matthijs van Leeuwen;Antti Ukkonen	2015		10.1137/1.9781611974010.3	data mining;database;world wide web	DB	-1.0461041204157393	-0.18103555960846449	140712
94edd382e86bf3c226c9568d94d9ed0db130de76	forward-buying and the naive newsvendor	inventory management;forward buying;newsvendor	The newsvendor model assumes that demand in a period is independent of the discounted inventory in the previous period. In the presence of forward-buying consumers, discounted inventory in a period may reduce next period's demand. We find that incorporating forward-buying leads to smaller order quantities and possibly lower salvage value.	newsvendor model	Moutaz Khouja	2016	Oper. Res. Lett.	10.1016/j.orl.2016.01.008	newsvendor model;extended newsvendor model	NLP	1.640292063522754	-4.75687807964741	140804
068b76d6cb99e5b27ad6c24fc93c71d266704996	on irreversible investment	levy processes;sequential irreversible investment;capacity expansion;singular control problem	This paper develops a general theory of irreversible investment of a single firm that chooses a dynamic capacity expansion plan in an uncertain environment. The model is set up free of any distributional or any parametric assumptions and hence encompasses all the existing models. As the first contribution, a general existence and uniqueness result is provided for the optimal investment policy. Based upon an alternative approach developed previously to dynamic programming problems, we derive the optimal base capacity policy such that the firm always keeps the capacity at or above the base capacity. The critical base capacity is explicitly constructed and characterized via a stochastic backward equation. This method allows qualitative insights into the nature of the optimal investment under irreversibility. (It is demonstrated that the marginal profit is indeed equal to the user cost of capital in free intervals where investment occurs in an absolutely continuous way at strictly positive rates. However, the equality is maintained only in expectation on average in blocked intervals where no investment occurs. Whenever the uncertainty is generated by a diffusion, the investment is singular with respect to Lebesgue measure. In contrast to the deterministic and Brownian motion case where lump sum investment takes place only at time zero, the firm responses in general more frequently in jumps to shocks. Nevertheless, lump sum investments are shown to be possible only at information surprises which is defined as unpredictable stopping time or unanticipated information jump even at the predictable time.) Furthermore, general monotone comparative statics results are derived for the relevant ingredients of the model. Finally, explicit solutions are derived for infinite time horizon, a separable operating profit function of Cobb–Douglas type and an exponential Lévy process modelled economic shock.	brownian motion;dynamic programming;lumped element model;marginal model;optimal stopping;time complexity;monotone	Frank Riedel;Xia Su	2011	Finance and Stochastics	10.1007/s00780-010-0131-y	financial economics;economics;mathematical economics;welfare economics	ML	1.6839475256916092	-3.8964297782966084	140837
7fae854cc58f8ae37508cbf7f3d721065fe3f2a9	manufacturing systems with random breakdowns and deteriorating items	dynamic programming;production system;dynamic program;optimization problem;stochastic optimization;markov process;production systems;production rate;inventory control;manufacturing system	This paper deals with the inventory control problem for production system in which multiple part types are produced and the produced parts are supposed to be deteriorating with fixed rates. The capacity of the production system is assumed to be random and bounded. The inventory control problem is formulated as a stochastic optimization problem that falls into the framework of the optimization problem of the class of systems with Markovian jumps. The optimal production rates are characterized and a numerical example is worked out to show the validness of the theoretical results.		El Kebir Boukas;Zikuan Liu	2001	Automatica	10.1016/S0005-1098(00)00163-1	optimization problem;mathematical optimization;inventory theory;simulation;engineering;stochastic optimization;mathematics;production system	Crypto	5.902803369380226	-1.2874118096461	140942
03d86e7bb2eff6e23afec630dbcda7e5db53f090	adjustment strategies for a fixed delivery contract	inventory production fixed contract with adjustments	We consider a long term contractual agreement between buyer and seller in whichQ units are delivered to the buyer at regular time intervals. It must be true that the delivery quantity,Q, is less than the mean demand per period. In order to manage the inventory, the buyer has the option of adjusting the delivery quantity upwards just prior to a delivery, but must pay a premium to do so. Demand is assumed random, and we model the system in a continuous review setting. We show that the equations one must solve to find optimal adjustment strategies are intractable. A diffusion approximation is developed which when coupled with the solution to an even simpler deterministic version of the problem yields very simple but effective approximations. Extensive computations are included to compare the performance of the optimal and approximate policies. We also empirically derive a formula for computingQ whose accuracy is established computationally. We prove that the fixed delivery contract results in lower variance of orders to the seller. We also include a computational study to find the unit cost discount that equalizes the expected costs for the fixed delivery contract and the base stock contract for a large parameter set.		Kamran Moinzadeh;Steven Nahmias	2000	Operations Research	10.1287/opre.48.3.408.12435	mathematical optimization;economics;operations management;mathematics;microeconomics;welfare economics	Crypto	1.869029268162852	-4.195061579520784	140983
237480b476ca10c059928c595def0bc39606d65e	supply chain shortage tolerance of short life cycle products based on reliability theory	frequency modulation;short life cycle products;product life cycle management;contracts;supply chain management product life cycle management reliability theory;reliability theory;supply chains;supply chain system;shortage tolerance;customer demands supply chain shortage tolerance short life cycle products reliability theory;markov processes;supply chain management;supply chains markov processes contracts frequency modulation reliability theory educational institutions;shortage tolerance short life cycle products supply chain system	Based on the characteristics of short life cycle products and the diversity of customer demands, from the perspective of shortage tolerance, using the reliability theory to research on the supply chain system of one supplier and one retailer, and further extends to multiple suppliers and one retailer. Within the given supply time, we obtain the threshold value of shortage tolerance to supply chain system of short life cycle products. Finally, this paper puts forward some proposals to promote cooperation in supply chain system of short life cycle products.	reliability engineering	Guorong Chai;Sasa Ding	2012	2012 Fifth International Joint Conference on Computational Sciences and Optimization	10.1109/CSO.2012.164	supply chain risk management;supply chain management;economics;service management;marketing;operations management;microeconomics;supply chain;commerce	Robotics	3.195481560770938	-9.146146593789071	141148
b61ee14e0ae82b740cf379b599462877139fbb34	research on pricing and coordination strategy of a sustainable green supply chain with a capital-constrained retailer		With the gradual deepening of environmental problems and the increase in consumer awareness of environmental protection,many enterprises have already begun to pay attention to green supply chain management. However, the price of green products is higher than that of nongreen products, which is an enormous challenge for many smallor medium-sized enterprises. To study the pricing and coordination of green supply chains under capital constraints, a model consisting of a manufacturer and a capital-constrained retailer is established; the manufacturer invests in green products and provides a deferred payment contract. Setting the situation without capital constraints as a benchmark, this study explores the impact of the retailer’s capital constraints on the manufacturer’s product greenness design; an interesting result shows that deferred payment can help encourage the retailer to order more products and improve the profit of the manufacturer and the efficiency of the entire supply chain as well as the product’s greenness level simultaneously. However, the profit of the retailer will be hurt by the deferred payment contract. Therefore, to guarantee the profit of the entire channel and to make the two agents obtain a win-win outcome, a new two-way revenue-sharing contract is designed to coordinate the green supply chain.	benchmark (computing)	Liming Zhao;Ling Li;Yao Song;Cong Li;Yujie Wu	2018	Complexity	10.1155/2018/6845970	supply chain management;machine learning;supply chain;artificial intelligence;payment;mathematics;microeconomics	ECom	-1.321087921410709	-6.015065481955735	141348
88b8bd2a49e0ad1c129274e6cc36ec77ba19a450	post-harvest soybean loss during truck transport: a case study of piaui state, brazil		Reducing post-harvest losses in the grain production system are of great interest to Brazilian agricultural production. Truck transport is commonly used world wide for the distribution of goods for trade. In Brazil, truck transportation is usually the most economical way to distribute goods in places where inexpensive or natural means of transport alternatives are not available. Truck transport plays a significant role in moving raw materials and processed products from the agricultural production. This study aimed to evaluate the post-harvest loss in transportation in soybean in the state of Piaui. The route of trucks loaded with soybean was analyzed from two regions. The trucks were weighted when leaving the farm and again weighted when arriving at the processing plant. Results indicate that there was a difference in weight between the farm and final destination indicating possible losses during the road transport.		Paola Medeiros;Irenilza de Alencar Nääs;Oduvaldo Vendrametto;Mathilde Soares	2016		10.1007/978-3-319-51133-7_72	waste management;truck;business;agricultural productivity;raw material	NLP	8.82172249290855	-6.8376650794810585	141349
3ab6b782e1cb5c6fd183b159a10ce3b8a3689492	contribution of simulation to the optimization of maintenance strategies for a randomly failing production system	simulation preventive maintenance availability multi criteria analysis;time average;modelizacion;sistema operativo;multicriteria analysis;optimisation;agua abajo;indice produccion;preventive maintenance;entretien preventif;optimizacion;maintenance;linea montaje;availability;disponibilidad;production system;simulation;machine parallele;systeme production;multi criteria analysis;promedio temporal;multiple machine;maquina paralelas;periodicite;sistema produccion;modelisation;periodicity;maquina multiple;sous traitance;cout moyen;periodicidad;operating system;average cost;taux production;coste medio;rupture;defaillance;assembly line;mantenimiento;entretenimiento preventivo;production rate;aval;systeme exploitation;parallel machines;downstream;optimization;analisis multicriterio;failures;analyse multicritere;subcontratacion;subcontracting;machine multiple;modeling;disponibilite;simulation model;fallo;ruptura;chaine montage;moyenne temporelle;timing	This paper compares two strategies for operating a production system composed of two machines working in parallel and a downstream inventory supplying an assembly line. The two machines, which are prone to random failures, undergo preventive and corrective maintenance operations. These operations with a random duration make the machines unavailable. Moreover, during regular subcontracting operations, one of these machines becomes unavailable to supply the downstream inventory. In the first strategy it is assumed that the periodicity of preventive maintenance operations and the production rate of each machine are independent. The second strategy suggests an interaction between the periods of unavailability and the production rates of the two machines in order to minimize production losses during these periods. A simulation model for each strategy is developed so as to be able to compare them and to simultaneously determine the timing of preventive maintenance on each machine considering the total average cost per time unit as the performance criterion. The second strategy is then considered, and a multi-criteria analysis is adopted to reach the best cost-availability compromise.	failure;mathematical optimization;production system (computer science);randomness;simulation	V. Boschian;Nidhal Rezg;Anis Chelbi	2009	European Journal of Operational Research	10.1016/j.ejor.2008.03.037	preventive maintenance;availability;downstream;simulation;systems modeling;operations management;simulation modeling;production system;operations research	Robotics	6.577546990619663	-1.779772892747247	141404
3cfe032c206348d0b3a0cfcde645ab51924c2004	short-maturity asymptotics for a fast mean-reverting heston stochastic volatility model	91b70;stochastic volatility model;60f10;moment generating function;large deviation principle;stochastic volatility;implied volatility;multiscale asymptotics;implied volatility smile skew;heston model;article;large deviation;mean reversion	In this paper, we study the Heston stochastic volatility model in a regime where the maturity is small but large compared to the mean-reversion time of the stochastic volatility factor. We derive a large deviation principle and compute the rate function by a precise study of the moment generating function and its asymptotic. We then obtain asymptotic prices for out-of-the-money call and put options and their corresponding implied volatilities.	asymptote;capability maturity model;reversion (software development);volatility	Jin Feng;Martin Forde;Jean-Pierre Fouque	2010	SIAM J. Financial Math.	10.1137/090745465	financial economics;forward volatility;econometrics;implied volatility;variance swap;volatility;constant elasticity of variance model;economics;volatility smile;mean reversion;finance;macroeconomics;heston model;stochastic volatility;sabr volatility model;moment-generating function	AI	2.3409729150116427	-1.932888211403437	141438
0cd95c594ae255aa382742505750218801f832f7	multiproduct single-machine production system with stochastic scrapped production rate, partial backordering and service level constraint	optimal solution;analisis sensibilidad;analisis numerico;solution optimale;service level;computacion informatica;matematicas aplicadas;modele mathematique;mathematiques appliquees;49j30;variable aleatoire;production system;systeme production;variable aleatoria;common cycle;economic model;modelo matematico;quantity;sistema produccion;analyse numerique;stochastic system;objective function;modelo economico;single machine;modele economique;numerical analysis;ciencias basicas y experimentales;sensitivity analysis;single machine economic production;solucion optima;matematicas;random variable;economic production quantity;mathematical model;analyse sensibilite;production rate;limited production capacity;sistema estocastico;49k30;grupo a;applied mathematics;systeme stochastique;scrapped items;single machine economic production quantity	In this paper, a multiproduct single-machine production system under economic production quantity (EPQ) model is studied in which the existence of only one machine causes a limited production capacity for the common cycle length of all products, the production defective rates are random variables, shortages are allowed and take a combination of backorder and lost sale, and there is a service rate constraint for the company. The aim of this research is to determine the optimal production quantity, the allowable shortage level, and the period length of each product such that the expected total cost, including holding, shortage, production, setup and defective items costs, is minimized. The mathematical model of the problem is derived for which the objective function is proved to be convex. Then, a derivative approach is utilized to obtain the optimal solution. Finally, two numerical examples in each of which a sensitivity analysis is performed on the model parameters, are provided to illustrate the practical usage of the proposed methodology.	production system (computer science);scrum (software development)	Ata Allah Taleizadeh;Seyed Taghi Akhavan Niaki;Amir Abbas Najafi	2010	J. Computational Applied Mathematics	10.1016/j.cam.2009.09.021	random variable;service level;quantity;numerical analysis;economic model;mathematical model;mathematics;production system;mathematical economics;operations research;sensitivity analysis;statistics	AI	4.6046441333762305	-3.3566041053177154	141679
e9a21ce6a2bb87daef2d6d6df08d4122e8ffa7a7	investment models based on clustered scenario trees	conic programming;interior point methods;portfolio selection;robust optimization;scenario tree;stochastic programming	Stochastic programming is widely applied in financial decision problems. In particular, when we need to carry out the actual calculations for portfolio selection problems, we have to assign a value for each expected return and the associated conditional probability in advance. These estimated random parameters often rely on a scenario tree representing the distribution of the underlying asset returns. One of the drawbacks is that the estimated parameters may be deviated from the actual ones. Therefore, robustness is considered so as to cope with the issue of parameter inaccuracy. In view of this, we propose a clustered scenario-tree approach, which accommodates the parameter inaccuracy problem in the context of a scenario tree.		Man Hong Wong	2013	European Journal of Operational Research	10.1016/j.ejor.2012.11.051	financial economics;stochastic programming;econometrics;mathematical optimization;robust optimization;interior point method;mathematics;statistics	Theory	5.543417165004856	-5.323108107771338	141693
134a4b684b5d026adb31afa3244de5dfb843c67e	analysis of supply chains with quantity based fixed incentives	multiserver queue;probleme vendeur journaux;politica optima;agua abajo;belief;file n serveurs;logistique;channel efficiency;quantity based fixed incentives;long terme;optimal policy;long term;inventory;administracion deposito;profit;economic order quantity;croyance;largo plazo;logistics;beneficio;supply chain management inventory quantity based fixed incentives channel efficiency supply chain coordination;addition chain;gestion stock;benefice;aval;coordinacion;supply chain;quantite economique a commander;downstream;fila n servidores;profitability;cantidad economica pedida;creencia;politique optimale;inventory control;newsboy problem;supply chain coordination;problema vendedor diarios;supply chain management;coordination;logistica	0377-2217/$ see front matter 2009 Elsevier B.V. A doi:10.1016/j.ejor.2009.04.028 * Corresponding author. Tel.: +1 909 869 2458; fax E-mail addresses: ahalati@csupomona.edu (A. (Y. He). This paper examines the use of quantity based fixed incentives to coordinate inventory decisions in a decentralized supply chain. We consider a two stage supply chain of autonomous supplier and distributor and prove that the optimal ordering policy for the newsvendor distributor under fixed incentives is an ðs; SÞ type policy. We further show that external and internal quantity based incentives can restore channel coordination in single period and channel members can benefit through arbitrary splitting of the resulting additional chain profit. The single period results are extended to multiple periods and the impact of fixed incentives on the distributor’s optimal stocking policy and channel efficiency are examined under three different multi-period supplier strategies. Numerical examples are used to compare the multi-period strategies and to provide additional managerial insights. The results show that contrary to common belief, incentive plans developed and maintained based only on current inventory data perform poorly in long term and that such incentive plans must be periodically updated to enhance their efficiency. Furthermore, we show that high level of incentives designed to push too much inventory downstream of the supply chain can actually reduce the chain’s efficiency. 2009 Elsevier B.V. All rights reserved.	autonomous robot;downstream (software development);fax;high-level programming language;like button;newsvendor model;numerical method;throughput	Abolhassan Halati;Yuanjie He	2010	European Journal of Operational Research	10.1016/j.ejor.2009.04.028	industrial organization;inventory control;logistics;downstream;supply chain management;profit;economic order quantity;inventory;economics;marketing;operations management;belief;supply chain;economy;profitability index	AI	-0.3129656939383902	-5.296735148770569	141759
4625f6ca268ec8b75ee7f78dcafecaa5af628d9b	intermediate monitoring, sample size reassessment, and multi-treatment optimal response-adaptive designs for phase iii clinical trials with more than one constraint	experimental design;minimization;theorie echantillonnage;metodo estadistico;teoria muestreo;adaptive design;sample size;group sequential design;62l05;62k05;optimal design statistics;algoritmo busqueda;aplicacion;05bxx;algorithme recherche;tamano muestra;biometrie;ethical allocation;simulacion numerica;search algorithm;biometrics;plan experiencia;biometria;contrainte inegalite;taille echantillon;inequality constraint;clinical trial;statistical method;ecuesta estadistica;medical science;fonction objectif;objective function;sample survey;ensayo clinico;62k99;plan experience;ciencia medica;constrenimiento desigualdad;methode statistique;calcul numerique;numerical computation;simulation numerique;calculo numerico;62d05;plan optimal;plan adaptatif;funcion objetivo;essai clinique;58a25;application;sondage statistique;62p10;constraints;numerical simulation;sampling theory;science medicale	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	francis;primary source	Atanu Biswas;Pinakpani Pal	2009	Communications in Statistics - Simulation and Computation	10.1080/03610910902903125	computer simulation;sample size determination;econometrics;survey sampling;clinical trial;mathematics;design of experiments;algorithm;biometrics;statistics;search algorithm	Robotics	6.260648839637099	-9.838543577543012	141965
4e4303d7494ce0ef6e57f331fc715d3d72f56b42	system reliability and free riding		System reliability often depends on the effort of many individuals, making reliability a public good. It is well-known that purely voluntary provision of public goods may result in a free rider problem: individuals may tend to shirk, resulting in an inefficient level of the public good. How much effort each individual exerts will depend on his own benefits and costs, the efforts exerted by the other individuals, and the technology that relates individual effort to outcomes. In the context of system reliability, we can distinguish three prototype cases.	prototype	Hal R. Varian	2004		10.1007/1-4020-8090-5_1	cyber-insurance;public good;microeconomics;free riding;business;free rider problem;nash equilibrium	ECom	-4.478449750550275	-6.702067453929188	142083
778a3a7b0e6e47a582761c3e32d0e748796db1da	revenue maximizing markets for zero-day exploits		Markets for zero-day exploits (software vulnerabilities unknown to the vendor) have a long history and a growing popularity. We study these markets from a revenue-maximizing mechanism design perspective. We first propose a theoretical model for zero-day exploits markets. In our model, one exploit is being sold to multiple buyers. There are two kinds of buyers, which we call the defenders and the offenders. The defenders are buyers who buy vulnerabilities in order to fix them (e.g., software vendors). The offenders, on the other hand, are buyers who intend to utilize the exploits (e.g., national security agencies and police). Our model is more than a single-item auction. First, an exploit is a piece of information, so one exploit can be sold to multiple buyers. Second, buyers have externalities. If one defender wins, then the exploit becomes worthless to the offenders. Third, if we disclose the details of the exploit to the buyers before the auction, then they may leave with the information without paying. On the other hand, if we do not disclose the details, then it is difficult for the buyers to come up with their private valuations. Considering the above, our proposed mechanism discloses the details of the exploit to all offenders before the auction. The offenders then pay to delay the exploit being disclosed to the defenders.	artificial intelligence;e-commerce;efficient cake-cutting;experiment;exploit (computer security);facility location problem;heuristic (computer science);mathematical optimization;money;numerical method;security bug;theory;vulnerability (computing);zero;zero-day (computing)	Mingyu Guo;Hideaki Hata;Muhammad Ali Babar	2016		10.1007/978-3-319-44832-9_15	externality;mechanism design;software;valuation (finance);vendor;distributed computing;popularity;revenue;exploit;commerce;computer science	AI	-1.6001728816040888	-4.290316835634167	142148
0aaef64c8f2abd84d9e5878abe871a0ac75008c3	the folk theorem for irreducible stochastic games with imperfect public monitoring	imperfect public monitoring;public monitoring;journal article;stochastic game folk theorem self generation return generation imperfect public monitoring;return generation;stochastic game;self generation;stochastic games;folk theorem;perfect public equilibrium	In an irreducible stochastic game, no single player can prevent the stochastic process on states from being irreducible, so the other players can ensure that the current state has little effect on events in the distant future. This paper introduces stochastic games with imperfect public signals, and provides a sufficient condition for the folk theorem when the game is irreducible, thus generalizing the folk theorems of Dutta (1995) and Fudenberg, Levine, and Maskin (1994). To prove this theorem, the paper extends the concept of self-generation (Abreu, Pearce, and Stachetti (1990)) to “return generation,” which explicitly tracks actions and incentives until the next time the state returns to its current value, and asks that players not wish to deviate given the way their continuation payoffs from the time of this return depend on the public signals that have been observed.	continuation;irreducibility;stochastic process	Drew Fudenberg;Yuichi Yamamoto	2011	J. Economic Theory	10.1016/j.jet.2011.03.004	economics;public economics;folk theorem;mathematics;stochastic game;microeconomics;mathematical economics;welfare economics;statistics	AI	-4.284905756453351	-2.177578094450749	142163
54b22cacbf34d0fa951b07e90cc4ed15e88f15d1	collaborate or not? a system dynamics study on disruption recovery	surge capacity;system dynamics;collaboration;disruption recovery;supply chain disruptions;shortage gaming	Purpose – The purpose of this paper is to investigate different combinations of collaboration strategies to deal with different types of supply chain disruptions, find the best combination, and provide targeting suggestions for investments. Design/methodology/approach – A system dynamics simulation is applied to study a supply chain with three tiers: a producer, a logistics service provider (LSP), and a retailer. There are three types of disruptions to simulate: a producer capacity disruption, an LSP capacity disruption, and a demand disruption. As each tier has the option to choose whether or not to collaborate with the other two tiers, eight (2×2×2) scenarios are generated to represent different combinations of collaboration strategies. Findings – For a producer capacity disruption, both the producer and the LSP should collaborate by providing their surge capacities, while the retailer does not have to collaborate. For an LSP capacity disruption, the producer should not provide its surge capacity, while...	denial-of-service attack;system dynamics	Quan Zhu;Harold Krikke;Marjolein C. J. Caniëls	2016	Industrial Management and Data Systems	10.1108/IMDS-05-2015-0209	simulation;economics;engineering;operations management;system dynamics;management;commerce;collaboration	DB	-3.242743846503368	-6.561650690322759	142189
cf547b1922fdf305b9750af613bdfc01d51813bc	duality and martingales: a stochastic programming perspective on contingent claims	marche incomplet;bolsa valores;garantie contre risque;key words options pricing martingales incomplete markets stochastic programming;martingale;pricing;options pricing;model risk;gestion risque;risk management;programmation stochastique;discrete time;option pricing;prix marche;conjugate duality;bourse valeurs;stock exchange;market price;mesure probabilite;mathematical programming;incomplete markets;maitrise risque;warranty;garantia contra riesgo;gestion riesgo;contingent claim;stochastic programming;martingales;programmation mathematique;absence of arbitrage;probability measure;programacion estocastica;programacion matematica;fixation prix;equilibrium analysis;medida probabilidad;incomplete market	The hedging of contingent claims in the discrete time, discrete state case is analyzed from the perspective of modeling the hedging problem as a stochastic program. Application of conjugate duality leads to the arbitrage pricing theorems of financial mathematics, namely the equivalence of absence of arbitrage and the existence of a probability measure that makes the price process into a martingale. The model easily extends to the analysis of options pricing when modeling risk management concerns and the impact of spreads and margin requirements for writers of contingent claims. However, we find that arbitrage pricing in incomplete markets fails to model incentives to buy or sell options. An extension of the model to incorporate pre-existing liabilities and endowments reveals the reasons why buyers and sellers trade in options. The model also indicates the importance of financial equilibrium analysis for the understanding of options prices in incomplete markets.	analysis of algorithms;computation;contingency (philosophy);duality (optimization);jensen's inequality;mathematical structure;optimization problem;requirement;risk aversion;risk management;sampling (signal processing);stochastic programming;turing completeness;value (ethics);weak duality;whole earth 'lectronic link	Alan J. King	2002	Math. Program.	10.1007/s101070100257	arbitrage pricing theory;actuarial science;martingale;risk management;valuation of options;mathematics;mathematical economics;incomplete markets;arbitrage;risk arbitrage	ECom	0.7792756567029046	-2.4974091404886662	142538
1ad2161bc820144de1b8d24458f4184fc48af842	cloud implications on software network structure and security risks	network externalities;software patching;network economics;software as a service;versioning;on premises software;security;economics of information systems;cloud computing;security risk;saas	By software vendors offering, via the cloud, software as a service (SaaS) versions of traditionally on-premises application software, security risks associated with usage become more diversified which can greatly increase the value associated with the software. In an environment where negative security externalities are present and users make complex consumption and patching decisions, we construct a model that clarifies whether and how SaaS versions should be offered by vendors. We find that the existence of version-specific security externalities is sufficient to warrant a versioned outcome, which has been shown to be suboptimal in the absence of security risks. In high security-loss environments, we find that SaaS should be geared to the middle tier of the consumer market if patching costs and the quality of the SaaS offering are high, and geared to the lower tier otherwise. In the former case, it is noteworthy that strategic interactions between the vendor and consumers can lead a lower inherent quality product to actually be preferred by a higher tier customer segment when security risk associated with each version is endogenously determined by consumption choices. Relative to on-premises benchmarks, we find that software diversification indeed leads to lower average security losses for users when patching costs are high. However, when patching costs are low, surprisingly, average security losses can actually increase as a result of SaaS offerings and lead to lower consumer surplus. We also investigate the vendor’s security investment decision and establish that the vendor tends to increase investments in an on-premises version and decrease investments in a SaaS version as the market becomes riskier. On the other hand, in low security-loss environments, we find that SaaS is optimally targeted to a lower tier of the consumer market, average security losses decrease, and consumer surplus increases as a result. Security investments increase for both software versions as risk increases in these environments.	benchmark (computing);cloud computing;diversification (finance);interaction;multitier architecture;on-premises software;software as a service;software versioning	Terrence August;Marius F. Niculescu;Hyoduk Shin	2014	Information Systems Research	10.1287/isre.2014.0527	cloud computing security;security through obscurity;economics;computer science;information security;marketing;network effect;software as a service;microeconomics;management;world wide web;computer security;commerce	Security	-2.6872382725615154	-7.462071177570731	142556
3dba61f86385db311905b8489e83ba2634eef782	optimal policies and bounds for stochastic inventory systems with lost sales	dynamic programming;lost sales;90c39 dynamic programming;inventory control;markov chains	This paper studies the classical discrete-time, single-location inventory model with stochastic demand, lost sales, and positive lead time. We transform the problem into an equivalent problem of the Markovian demand inventory model with zero lead time and zero initial inventory, which provides a better understanding to the original problem. Based on this transformation, we introduce a key concept--effectual demand, which determines both the performance in the current period and the evolution into future periods. In this way, we provide a bridge of two research streams in the literature: Markovian demand inventory model and lost sales inventory model. We believe this Markovian approach is more straightforward to work with various applications. In this way, we easily show the existence of optimal policies in discounted and average cost, and finite and infinite horizon cases, when cost functions are of polynomial growth. The polynomial growth cost functions virtually cover all practical scenarios in real business settings. We then present simpler proofs and examples for the linear order cost case. The analytical solutions are first. We also derive bounds analytically on the optimal policy; these bounds are equivalent to those of the myopic policy but tighter than the popular bound in the literature.		Xiaoming Li	2015	J. Optimization Theory and Applications	10.1007/s10957-014-0537-3	inventory control;markov chain;mathematical optimization;inventory theory;dynamic programming;mathematics;mathematical economics	Metrics	3.092474345980327	-2.369057118073868	142645
0003135a24bb9404708f0221d7e4490b2faa8f6a	an alternative model for erp maintenance strategy	quality assurance;quality assurance erp maintenance strategy business application transaction processing system accounting manufacturing human resource enterprise resource planning system task diversity task integration planned periodic repair scheduled maintenance equipment breakdown equipment deterioration unplanned maintenance emergency maintenance scheduling monitoring;t technology general;equipment deterioration;equipment breakdown;job shop scheduling;emergency maintenance;accounting;business application;maintenance engineering;erp maintenance strategy;materials;erp system;framework enterprise resource planning maintenance strategy;maintenance engineering planning load modeling business job shop scheduling materials materials requirements planning;enterprise resource planning system;monitoring;task integration;business data processing;scheduling;human resource;business;enterprise resource planning;manufacturing;materials requirements planning;planning;task diversity;unplanned maintenance;transaction processing;planned periodic repair;maintenance strategy;load modeling;spare parts;scheduled maintenance;transaction processing system;framework;maintenance engineering business data processing enterprise resource planning	For the past few years, it has been possible to buy a business application including transaction processing systems for such tasks as accounting, manufacturing, or human resources as a packaged product. Packages to do this collection of work are generally referred to as enterprise resource planning (ERP) systems. Most ERP systems are huge because of the diversity of tasks they must perform. The ERP systems are providing an integration of several tasks, and the flexibility to perform those tasks at enterprises with vastly varying needs. But, only few of these ERP systems developed have actually considered maintenance strategies. Maintenance is a complex process that is triggered by planned periodic repair (scheduled or planned maintenance), equipment breakdown or deterioration indicated by a monitored parameter (unplanned or emergency maintenance). This process includes planning, scheduling, monitoring, quality assurance and the development of necessary resources such as workshop, labor, machines, equipment, tools, spare parts and materials.	automated planning and scheduling;business software;erp;enterprise resource planning;scheduling (computing);transaction processing system	Muhammad Rofi Imtihan;Mohd. Salihin Ngadiman;Habibollah Haron	2008	2008 Ninth ACIS International Conference on Software Engineering, Artificial Intelligence, Networking, and Parallel/Distributed Computing	10.1109/SNPD.2008.135	planning;maintenance engineering;quality assurance;job shop scheduling;planned maintenance;transaction processing;computer science;software framework;operating system;spare part;material requirements planning;manufacturing;scheduling;transaction processing system	Robotics	9.897997062227128	3.096805037572259	142679
b7462a08b842bc5833a02873363523dd32b250fa	menu theorems for bilateral contracting	bilateral contracting;pure strategy equilibrium;probability distribution;mechanism design;multiple agents;probability distribution function;mutliple principals	This paper studies bilateral contracting where multiple principals negotiate contracts with multiple agents independently. It is shown that pure-strategy equilibrium allocations relative to any ad hoc set of feasible mechanisms are supported by pure-strategy perfect Bayesian equilibria relative to the set of menus. This paper also shows that all equilibrium allocations to any ad hoc set of feasible mechanisms are supported by correlated equilibria relative to the set of menus, where a state is a probability distribution function over payoff-relevant variables. Furthermore, all equilibrium allocations relative to the set of menus persist even if principals use more complex mechanisms. Journal of Economic Literature Classification Numbers: D82, C79.	bilateral filter;hoc (programming language)	Seungjin Han	2006	J. Economic Theory	10.1016/j.jet.2005.04.002	probability distribution;mechanism design;probability density function;operations management;mathematics;microeconomics;mathematical economics;welfare economics;statistics	ECom	-3.9812225961007255	-3.5219835426611747	142835
8edbc32d3dc9da70df30f796a38c9a7d7d4a7d9c	convex duality in optimal investment and contingent claim valuation in illiquid markets		This paper studies convex duality in optimal investment and contingent claim valuation in markets where traded assets may be subject to nonlinear trading costs and portfolio constraints. Under fairly general conditions, the dual expressions decompose into tree terms, corresponding to the agent’s risk preferences, trading costs and portfolio constraints, respectively. The dual representations are shown to be valid when the market model satisfies an appropriate generalization of the no-arbitrage condition and the agent’s utility function satisfies an appropriate generalization of asymptotic elasticity conditions. When applied to classical liquid market models or models with bid-ask spreads, we recover wellknown pricing formulas in terms of martingale measures and consistent price systems. Building on the general theory of convex stochastic optimization, we also derive optimality conditions in terms of an extended notion of a “shadow price”.	contingency (philosophy);convex function;darknet market;elasticity (data store);mathematical optimization;nonlinear system;price systems;shadow price;stochastic optimization;utility;value (ethics)	Teemu Pennanen;Ari-Pekka Perkkiö	2018	Finance and Stochastics	10.1007/s00780-018-0372-8	financial economics;economics;finance;microeconomics;welfare economics	AI	0.05548807495767264	-2.9496721828438113	142902
51f5a4473960086e8e861a817c3dec834c512c2b	a modified approach to transmission loss allocation using proportional sharing method for transaction based power system operation	transaction based power flow power transaction loss allocation power tracing;transmission loss allocation pricing proportional allocation technique competitive power system transaction based power system proportional sharing method;propagation losses;generators;losses;resource allocation;pricing;resource management;generators load flow resource management propagation losses companies contracts;contracts;companies;proportional sharing method;resource allocation losses power transmission economics pricing;transaction based power system;transaction based power flow;loss allocation;load flow;competitive power system;power tracing;power transaction;power transmission economics;proportional allocation technique;transmission loss allocation	In competitive power system all services including transmission loss need to be priced properly to improve efficiency. Though a generally acceptable method for transmission loss allocation is yet to be developed, the proportional allocation technique has wide acceptance. But this method is not directly applicable to transaction based power system due to the absence of a proper transaction based power flow. This paper presents a critical analysis on the applicability of the proportional sharing principle for loss allocation to transaction based power system and suggests a modification to the method for application to transaction based power system.		Mala De;Nalin B. Dev Choudhury;S. K. Goswami	2013	Eurocon 2013	10.1109/EUROCON.2013.6625144	pricing;power-flow study;resource allocation;resource management	AI	2.2269830917530595	3.9601569921079123	142935
c8c9cd8693d84b3173a70764e823269d1acfa078	an analysis of partially-guaranteed-price contracts between farmers and agri-food companies	stackelberg game;hf commerce;agri food;sustainability;agriculture;buyer seller contracts	Global agri-food companies such as Barilla and SABMiller are purchasing agricultural products directly from farmers using different types of contracts to ensure stable supply. We examine one such contract with partially-guaranteed prices (PGP). Under a PGP contract, around sowing time, the buying firm agrees to purchase the crop when harvested by the farmer, offering a guaranteed unit price for any fraction of the produce and offering the commodity market price prevailing at the time of delivery for the remainder. The farmer then chooses the fraction. By analyzing a Stackelberg game, we show (1) how the PGP contract creates mutual benefits when the firm’s purchase quantity is taken as being exogenous. We also analyze how the PGP contract is robust in creating value for both the firm and the farmer (2) when the firm’s purchase quantity is endogenously determined; (3) when the firm provides advisory services to the farmer; and (4) when the firm offers a price premium as an incentive for farmers to exert efforts to comply with ‘sustainable’ agricultural practices.		Christopher S. Tang;ManMohan S. Sodhi;Marco Formentini	2016	European Journal of Operational Research	10.1016/j.ejor.2016.04.038	agriculture;purchase order;economics;marketing;microeconomics;sustainability;commerce	ECom	-0.7120639114265429	-6.329174387469536	143153
20abaf8aae3b8391602c5132dfe394061778cfcd	tail risk constraints and maximum entropy	mathematics and statistics;risk management;barbell portfolio strategy;economics;maximum entropy	Abstract: Portfolio selection in the financial literature has essentially been analyzed under two central assumptions: full knowledge of the joint probability distribution of the returns of the securities that will comprise the target portfolio; and investors’ preferences are expressed through a utility function. In the real world, operators build portfolios under risk constraints which are expressed both by their clients and regulators and which bear on the maximal loss that may be generated over a given time period at a given confidence level (the so-called Value at Risk of the position). Interestingly, in the finance literature, a serious discussion of how much or little is known from a probabilistic standpoint about the multi-dimensional density of the assets’ returns seems to be of limited relevance. Our approach in contrast is to highlight these issues and then adopt throughout a framework of entropy maximization to represent the real world ignorance of the “true” probability distributions, both univariate and multivariate, of traded securities’ returns. In this setting, we identify the optimal portfolio under a number of downside risk constraints. Two interesting results are exhibited: (i) the lefttail constraints are sufficiently powerful to override all other considerations in the conventional theory; (ii) the “barbell portfolio” (maximal certainty/ low risk in one set of holdings, maximal uncertainty in another), which is quite familiar to traders, naturally emerges in our construction.	downside risk;entropy (information theory);entropy maximization;maximal set;relevance;traders;utility;value at risk	Donald Geman;Hélyette Geman;Nassim Nicholas Taleb	2015	Entropy	10.3390/e17063724	actuarial science;risk management;principle of maximum entropy;portfolio optimization;spectral risk measure;statistics	ML	0.4662100014002625	-3.35354132853535	143310
c0663e644ba3aa6863388f6292792f0c15da0d96	coordination of operations planning in supply chains: a review	planning coordination;operations research operations planning;distributed planning;supply chain modelling;multi agents	Supply chains are networks of loosely coupled business units characterised by distinct, yet mutually interdependent, planning decision domains. The main question that arises in the management of these networks is the coordination of supply chain members’ operations with minimum exchange of information. In practice, supply chain operations are generally coordinated and planned hierarchically, through the central and aggregated control of a corporate planning unit, which requires a high degree of information exchanges, or through the relatively inefficient upstream planning approach, in which operations are planned and the derived dependent demand is sent to suppliers. High degree of information exchanges lead to difficulties when independent members do not want to share information, such as cost, profit margin, inventory level or capacity utilisation. In order to address these difficulties, decentralised approaches of coordination of operations planning decisions based on some minimal information sharing h...		Atour Taghipour;Jean-Marc Frayret	2013	IJBPSCM	10.1504/IJBPSCM.2013.055729	information technology operations;supply chain management;knowledge management;operations management;management science;business	Robotics	-1.015775179122583	-4.114725062383806	143347
3a7e2b5df39ba4f408a3a8427a8fd5324c6370f0	regulating an observable m/m/1 queue	regulation of a queue;strategic behavior in queue;observable queue	Naor (1969) was the first to observe that in a single-server memoryless queue, customers who inspect the queue length upon arrival and accordingly decide whether to join or not may join even if from the social point of view they are worse off. The question then is how to mechanically design the system such that customers will join only queue lengths that are advised by society, while still minding their own selfish utility. After reviewing some existing mechanisms (some involving money transfers and some not), we suggest novel ones that do not involve money transfers. They possess some advantages over the existing ones, which we itemize.	money;observable;server (computing)	Moshe Haviv;Binyamin Oz	2016	Oper. Res. Lett.	10.1016/j.orl.2016.01.002	real-time computing;simulation;multilevel queue	Metrics	2.0347552788476224	0.4459564168749764	143567
bfa8519b836e8f4af8035e69c76493727e73b51a	a complete proof on the solution procedure for non-instantaneous deteriorating items with permissible delay in payment	optimal solution;non instantaneous deterioration;cycle time;finance;permissible delay in payments;inventory model;inventory;industrial engineering	Ouyang et al. [Ouyang, L. Y., Wu, K. S., & Yang C. T. (2006). A study on an inventory model for non-instantaneous deteriorating items with permissible delay in payments. Computers &Industrial Engineering, 51, 637-651] present an inventory model for non-instantaneous deteriorating items with permissible delay in payments. They develop some theorems to characterize the optimal solutions and provide an easy-to-use method to find the optimal replenishment cycle time. Although, their inventory models are correct and interesting, processes of arguments to derive those theorems and the easy-to-use method to search for the optimal replenishment cycle time are not complete. So, the main purpose of this paper is to overcome those shortcomings and present complete proofs for Ouyang et al. (2006).		Kun-Jen Chung	2009	Computers & Industrial Engineering	10.1016/j.cie.2008.05.015	actuarial science;inventory;economics;cycle time variation;operations management;welfare economics	Logic	2.82958902565747	-4.648377047619213	143595
0d577f205edbf7e1a15b49b9c58c04cea87a2011	optimality gap of constant-order policies decays exponentially in the lead time for lost sales models	lost sales;queueing theory;grupo de excelencia;lead time;inventory;ciencias basicas y experimentales;matematicas;constant order policy;convexity;grupo a	Inventory models with lost sales and large lead times have traditionally been considered intractable, due to the curse of dimensionality which arises from having to track the set of orders placed but not yet received (i.e. pipeline vector). Recently, Goldberg et al. (2012) laid the foundations for a new approach to solving these models, by proving that as the lead time grows large (with the other problem parameters fixed), a simple constant-order policy (proposed earlier by Reiman (2004)) is asymptotically optimal. This was quite surprising, as it is exactly this setting (i.e. large lead times) that was previously believed intractable. However, the bounds proven there are impractical, requiring the lead time to be very large before the constant-order policy becomes nearly optimal, e.g. requiring a lead time which is Ω( −2) to ensure a (1 + )-approximation guarantee, and involving a massive prefactor. The authors note that numerical experiments of Zipkin (2008b) suggest that the constant-order policy performs quite well even for small lead times, and pose closing this gap (thus making the results practical) as an open problem. In this work, we make significant progress towards resolving this open problem and closing this gap. In particular, for the infinite-horizon variant of the finite-horizon problem considered by Goldberg et al. (2012), we prove that the optimality gap of the same constant-order policy actually converges exponentially fast to zero, i.e. we prove that a lead time which is O ( log( −1) ) suffices to ensure a (1+ )-approximation guarantee. We demonstrate that the corresponding rate of exponential decay is at least as fast as the exponential rate of convergence of the expected waiting time in a related single-server queue to its steady-state value. We also derive simple and explicit bounds for the optimality gap. For the special case of exponentially distributed demand, we further compute all expressions appearing in our bound in closed form, and numerically evaluate them, demonstrating good performance for a wide range of parameter values. Our main proof technique combines convexity arguments with ideas from queueing theory.	asymptotically optimal algorithm;closing (morphology);curse of dimensionality;experiment;inventory theory;numerical analysis;queueing theory;rate of convergence;server (computing);steady state;time complexity	Linwei Xin;David A. Goldberg	2016	Operations Research	10.1287/opre.2016.1514	mathematical optimization;inventory;economics;convexity;marketing;operations management;mathematics;mathematical economics;queueing theory;management;algorithm;statistics	ML	3.1320005386216447	-2.0727207910851115	143596
7b97d0dcded49e4f3f821198a510d34563821bf9	simple approximate equilibria in large games	computation of equilibria;nash equilibrium;concentration inequalities;hb economic theory;correlated equilibrium	We prove that in every normal form n-player game with m actions for each player, there exists an approximate Nash equilibrium in which each player randomizes uniformly among a set of O(log m + log n) pure actions. This result induces an O(N log log N)-time algorithm for computing an approximate Nash equilibrium in games where the number of actions is polynomial in the number of players (m=poly(n)); here N=nmn is the size of the game (the input size). Furthermore, when the number of actions is a fixed constant (m=O(1)) the same algorithm runs in O(Nlog log log N) time. In addition, we establish an inverse connection between the entropy of Nash equilibria in the game, and the time it takes to find such an approximate Nash equilibrium using the random sampling method.  We also consider other relevant notions of equilibria. Specifically, we prove the existence of approximate correlated equilibrium of support size polylogarithmic in the number of players, n, and the number of actions per player, m. In particular, using the probabilistic method, we show that there exists a multiset of action profiles of polylogarithmic size such that the uniform distribution over this multiset forms an approximate correlated equilibrium. Along similar lines, we establish the existence of approximate coarse correlated equilibrium with logarithmic support. We complement these results by considering the computational complexity of determining small-support approximate equilibria. We show that random sampling can be used to efficiently determine an approximate coarse correlated equilibrium with logarithmic support. But, such a tight result does not hold for correlated equilibrium, i.e., sampling might generate an approximate correlated equilibrium of support size Ω(m) where m is the number of actions per player. Finally, we show that finding an exact correlated equilibrium with smallest possible support is NP-hard under Cook reductions, even in the case of two-player zero-sum games.	approximation algorithm;computational complexity theory;information;monte carlo method;nash equilibrium;polylogarithmic function;polynomial;sampling (signal processing)	Yakov Babichenko;Siddharth Barman;Ron Peretz	2014		10.1145/2600057.2602873	mathematical optimization;combinatorics;sequential equilibrium;economics;mathematics;correlated equilibrium;mathematical economics;nash equilibrium	ECom	-3.0901102660721014	0.048318457217849074	143736
1dd434285f9c904b063660f7089f01207d0fe7ae	product quality uncertainty in online auction marketplaces: overcoming adverse product selection with price premiums		To overcome a market of ‘lemons’, online auction marketplaces must be able to differentiate among products and generate price premiums for high-quality ones. Still, the literature has only focused on seller quality uncertainty (seller reputation), alas ignoring the role of product quality uncertainty, which is defined as the degree by which the outcome of the transaction cannot be accurately predicted due to fears that product quality may differ from what is expected. This is especially problematic for used products where product quality uncertainty is often greater. To overcome adverse product selection, this study first introduces four product-related variables (inspection, warranty, value, and attributes) that impact price premiums, and it also proposes their interaction effect with seller reputation. The proposed model will be tested with secondary data from used cars on eBay Motors. Implications for mitigating product quality uncertainty and preventing a market of ‘lemons’ are discussed.	auction algorithm;online marketplace	Angelika Dimoka;Paul A. Pavlou	2006			marketing;microeconomics;business;commerce	AI	-2.93173597213962	-8.460361372994013	143768
1e5bc38c62b3ed9798407c6f7e4ac3dd9496fac1	a methodology for generation expansion planning for renewable energy economies	uncertainty;industries;investment;production;planning;oligopoly	In the restructured electricity industry, Generation Expansion Planning (GEP) is an oligopoly of strategic Generation Companies (GenCos) with private information investing in a highly uncertain environment. Strategic planning and uncertainties can result in market manipulation and underinvestment (short-term planning). We present a forward moving approach to the problem of investment expansion planning in the restructured electricity industry. This approach accounts for technological, political and environmental uncertainties in the problem's environment and leads to long-term planning. At each step of the approach we present a block investment market mechanism that has the following features. (F1) It is individually rational. (F2) It is budget balanced. (F3) The expansion and production allocations corresponding to the unique Nash Equilibrium (NE) of the game induced by the mechanism are the same as those that maximize the sum of utilities of the producers and the demand. (F4) It is price efficient that is, the price for electricity at equilibrium is equal to the marginal utility of the demand and to the marginal cost of production by producers with free capacity.	gene expression programming;marginal model;nash equilibrium;personally identifiable information	Mohammad Rasouli;Demosthenis Teneketzis	2016	2016 IEEE 55th Conference on Decision and Control (CDC)	10.1109/CDC.2016.7798487	planning;uncertainty;investment;oligopoly;statistics	AI	0.23513369026864964	-5.282508596499505	143910
939a6e7ba7ec9a69c458a2eb67c3d01022e2dc27	decision-making models for promoting consumption of low energy-intensive broadband terminal products in the chinese telecommunication industry		PurposernrnrnrnrnThe purpose of this paper is to extend game analysis to explore decision-making mechanisms for promoting a specific type of products, low energy consumption for individual one while the total energy consumption is huge due to the high quantity of sales, that is, low for individual and high for total (LIHT) in terms of energy consumption.rnrnrnrnrnDesign/methodology/approachrnrnrnrnrnGame models are developed to compare decisions of optimal prices for newly developed and environmentally friendly (NDEF) and regular products as well as associated sales quantity, profits, carbon emissions under different governmental policies, along with a case of low energy-intensive broadband terminal products in the Chinese telecommunication industry under the carbon tax and subsidy policies.rnrnrnrnrnFindingsrnrnrnrnrnFor both NDEF and regular products, optimal prices decrease under the subsidy policy while both increase under the tax policy. Manufacturers’ decision of optimal prices is highly relevant with unit carbon tax/subsidy and the consumers’ preference. Both the tax and subsidy policies can improve consumption of NDEF products while the subsidy policy can be more effective at the current initial stage.rnrnrnrnrnResearch limitations/implicationsrnrnrnrnrnThis paper provides decision support for manufacturers to promote sustainable consumption of LIHT products. Research ideas on models development and solutions for optimal prices can be applied to other LIHT products.rnrnrnrnrnPractical implicationsrnrnrnrnrnThe results provide insights for governments on how to effectively evaluate and motivate sustainable consumption for LIHT products.rnrnrnrnrnOriginality/valuernrnrnrnrnThis paper first explores how to motivate sustainable consumption of LIHT products by developing models, examining effectiveness of potential governmental policies as well as associated carbon emissions.		Qing Liu;Senlin Zhao;Qinghua Zhu	2018	Industrial Management and Data Systems	10.1108/IMDS-04-2017-0141	engineering;decision-making models;subsidy;tax policy;decision support system;environmentally friendly;energy consumption;sustainable consumption;carbon tax;telecommunications	DB	0.7410407890527079	-7.334152317694095	143936
1a24fdd9dc3064e83f18e08ffd29121fc54935a3	intelligent financial decision model of natural disasters risk control	decision models;risk reduction;risk control;natural disaster;financial analysis;exceeding probability ep curve	This paper describes how risk-based risk control allocation model works. We begin by discussing the economic rational for allocating risk control in a diversified organization like enterprises. The direct and indirect losses caused by the simulated disasters can be estimated using the engineering and financial analysis model. Basing on the model, we can generate exceeding probability (EP) curve and then calculate how much loss will be ceased or transferred to other entities, if somehow spending budgets on risk control actions. Results from the proposed formulations are compared in case studies. The model attempts to apply risk based budget guidelines to risk reduction measurement with a portfolio-based risk framework.		Chun-Pin Tseng;Cheng-Wu Chen;Ken Yeh;Wei-Ling Chiang	2007		10.1007/978-3-540-74171-8_6	decision model;risk management tools;actuarial science;financial analysis;financial risk;risk management;natural disaster;artificial intelligence;absolute risk reduction;risk;operations research;systemic risk;time consistency;value at risk;factor analysis of information risk	ML	4.815178723062795	-8.520641191063964	143943
48c6911b0923bc13040909c2fac3c1cd0b5a66e2	pricing in dynamic advance reservation games	analytical models;convergence;pricing;random variables;servers;resource management software pricing dynamic advance reservation games strategy learning model action learning model;games;games pricing analytical models servers conferences convergence random variables;pricing computer games learning artificial intelligence;conferences	We analyze the dynamics of advance reservation (AR) games: games in which customers compete for limited resources and can reserve resources for a fee. We introduce and analyze two different learning models. In the first model, called strategy-learning, customers are informed of the strategy adopted in the previous iteration, while in the second model, called action-learning, customers estimate the strategy by observing previous actions. We prove that in the strategy-learning model, convergence to equilibrium is guaranteed. In contrast, in the action-learning model, the system converges only if an equilibrium in which none of the customers makes AR exists. Based on those results, we show that if the provider is risk-averse and sets the AR fee low enough, action-learning yields on average greater profit than strategy-learning. However, if the provider is risk-taking and sets a high AR fee, action-learning provably yields zero profit in the long term in contrast to strategy-learning.	iteration;risk aversion;theory	Eran Simhon;Carrie Cramer;Zachary Lister;David Starobinski	2015	2015 IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)	10.1109/INFCOMW.2015.7179442	pricing;random variable;games;simulation;convergence;computer science;server;computer network	Vision	-2.750702292429882	-1.934584405254807	144026
435e0e3ba1d420a0ce9e16dc3822a1d024bf11bc	preventing strategic manipulation in iterative auctions: proxy agents and price-adjustment	price adjustment;monograph or book	Iterative auctions have many computational advantages ove r sealed-bid auctions, but can present new possibilities for strategic manipulation. We propose a two-stage technique to make iterative auctions that compute optimal allocation s with myopic best-response bidding strategies more robust t o manipulation. First, introduce proxy bidding agents to con strain bidding strategies to (possibly untruthful) myopic bestresponse. Second, after the auction terminates adjust the prices towards those given in the Vickrey auction, a sealedbid auction in which truth-revelation is optimal. We presen t an application of this methodology to iBundle, an iterative combinatorial auction which gives optimal allocations for myopic best-response agents.	iteration;iterative method;mathematical optimization;naruto shippuden: clash of ninja revolution 3;proxy server	David C. Parkes;Lyle H. Ungar	2000			auction algorithm;combinatorial auction;generalized second-price auction;computer science;vickrey–clarke–groves auction;common value auction;revenue equivalence;auction theory;forward auction	AI	-2.447170971773692	-2.5963702249420573	144059
b554fea2e1c798e91166fe5dfe5ae9273fb7218d	internet channel entry: retail coverage and entry cost advantage	market entry;b2c electronic commerce;timing game;retail pricing;cost advantage;stand alone incentive;profitability;journal magazine article;preemption incentive	In this research we study how existing market coverage affects the outcome of the Internet channel entry game between an existing retailer and a new entrant. A market is not covered when some consumers with low reservation prices are priced out by existing retailers and do not purchase. In a model with multiple existing retailers and a potential new entrant, we demonstrate that when costs are equal, one of the existing retailers enters the Internet channel first. However, if the market is covered by existing retailers before entry, then because of the threat of Internet channel entry by the potential new entrant, retailer entry cannibalizes existing retail profits—cannibalizing at a loss. In addition, if a potential new entrant has a slight advantage in Internet channel entry costs and the market is not covered by existing retailers, then the new entrant enters the Internet channel first. If the market is covered by existing retailers, then the new entrant must have a larger Internet channel entry cost advantage to be first to enter the Internet channel.	internet;resource reservation protocol	Zhuo Cheng;Barrie R. Nault	2007	Information Technology and Management	10.1007/s10799-007-0015-9	economics;marketing;commerce;profitability index	Security	-2.1399641931138706	-7.120677166524623	144060
6a177149fcc818a92e1037515d4608ea1d604edc	communication complexity of combinatorial auctions with submodular valuations	algorithms;design;number-theoretic computations;combinatorics;theory	We prove the first communication complexity lower bound for constant-factor approximation of the submodular welfare problem. More precisely, we show that a (1− 1 2e+ )-approximation (' 0.816) for welfare maximization in combinatorial auctions with submodular valuations would require exponential communication. We also show NP-hardness of (1− 1 2e+ )approximation in a computational model where each valuation is given explicitly by a table of constant size. Both results rule out better than (1 − 1 2e )approximations in every oracle model with a separate oracle for each player, such as the demand oracle model. Our main tool is a new construction of monotone submodular functions that we call multi-peak submodular functions. Roughly speaking, given a family of sets F , we construct a monotone submodular function f with a high value f(S) for every set S ∈ F (a “peak”), and a low value on every set that does not intersect significantly any set in F . We also study two other related problems: maxmin allocation (for which we also get hardness of (1− 1 2e+ )-approximation, in both models), and combinatorial public projects (for which we prove hardness of (34 + )-approximation in the communication model, and hardness of (1− 1e + )-approximation in the computational model, using constant size valuations).	approximation;communication complexity;computation;computational model;consistent pricing process;expectation–maximization algorithm;minimax;np-hardness;ptas reduction;submodular set function;time complexity;value (ethics);monotone	Shahar Dobzinski;Jan Vondrák	2013		10.1137/1.9781611973105.87	mathematical optimization;combinatorics;discrete mathematics;submodular set function;mathematics	Theory	-2.4858794609333055	-0.39203808245776234	144098
a29160ddfe24303764a80b8606024dc2993eb4c0	optimization of dynamic maximum for value-at-risks with fuzziness in asset management		A dynamic portfolio allocation is discussed in asset management with fuzziness. By perception-based extension for fuzzy random variables, a dynamic portfolio model for value-at-risks of fuzzy random variables is introduced. By dynamic programming and mathematical programming, this paper derives analytical solutions for the optimization problem. A numerical example is given to demonstrate the results.	dynamic programming;mathematical optimization;numerical analysis;optimization problem	Yuji Yoshida	2017	2017 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)	10.1109/FUZZ-IEEE.2017.8015420	fuzzy logic;value at risk;artificial intelligence;machine learning;computer science;asset management;dynamic programming;mathematical optimization;portfolio optimization;random variable;optimization problem;portfolio	Robotics	5.243565612503675	-5.1221824719856786	144134
20c968454bde6e329e51afed0d90a5cb8b1d03fd	modeling approach for managing the demand in congested airport networks: the case of mexico city airport		We introduce a discrete event simulation approach to assess flight demand when airport congestion is observed. One of the consequences of airport congestion are flight delays which in turn decrease costumer's satisfaction. The model includes flight information, airline on-time performance and flight duration and turnaround time uncertainty. When airport congestion occurs at the arrival airport, an air traffic flow management initiative is triggered as a tool for alleviating the congestion problems, particularly in the most congested slots of the airport. Analysis of selected model scenarios allows to select the parameters of the initiative where airport congestion can be minimized. The model is set up for Mexico City airport, which is Mexico's busiest airport and highly congested. This case study describes how to model the airport network for analysing the effectiveness of specific traffic flow management initiatives in Mexico City. The use of the simulation approach will enable the decision makers to analyse the effectiveness of the present traffic flow policy as well as to evaluate different policies for coping with the increasing demand in the Mexican network of airports. The flexibility of the model makes it easy to adapt to congested airport networks in other regions of the world.	network congestion;simulation;tcp congestion control	Ann Wellens;Miguel Mujica Mota	2017	2017 Winter Simulation Conference (WSC)	10.1109/WSC.2017.8248192	discrete event simulation;computer science;air traffic flow management;simulation;atmospheric model;turnaround time;traffic flow	Metrics	9.648834124264763	-9.07347408381794	144229
5f482f9525c07e5e7f9a84abf80cebdb852876fc	channel performance under consignment contract with revenue sharing	profit sharing;price elasticity;profitability;cost sharing;consignment sales;revenue sharing;supply chain management	U a consignment contract with revenue sharing, a supplier decides on the retail price and delivery quantity for his product, and retains ownership of the goods; for each item sold, the retailer deducts a percentage from the selling price and remits the balance to the supplier. In this paper we show that, under such a contract, both the overall channel performance and the performance of individual firms depend critically on demand price elasticity and on the retailer’s share of channel cost. In particular, the (expected) channel profit loss, compared with that of a centralized system, increases with demand price elasticity and decreases with retailer’s cost share, while the profit share extracted by the retailer decreases with price elasticity and increases with retailer’s cost share. With an iso-price-elastic demand model, we show that the channel profit loss cannot exceed 26.4%, and that the retailer’s profit share cannot be below 50%. When price elasticity is low, or when the retailer’s cost share approaches 100%, or both, the retailer can extract nearly all the channel profit that is almost equal to the centralized channel profit.	approximation;centralized computing;elasticity (cloud computing);elasticity (data store);revenue sharing	Yunzeng Wang;Li Jiang;Zuo-Jun Max Shen	2004	Management Science	10.1287/mnsc.1030.0168	price elasticity of demand;price elasticity of supply;supply chain management;economics;marketing;microeconomics;commerce;profitability index	ECom	-1.282115857185292	-5.782877753172776	144276
d11c6ea74514d9f04ea943cc35d146a69281465c	optimal debt ratio and consumption strategies in financial crisis	91b40;financial crisis;consumption strategies;91b70;93e20;91b42;optimal debt ratio;91b06;stochastic control	This paper derives the optimal debt ratio and consumption strategies for an economy during the financial crisis. Taking into account the impact of labor market condition during the financial crisis, the production rate function is stochastic and affected by the government fiscal policy and unanticipated shocks. The objective is to maximize the total expected discounted utility of consumption in the infinite time horizon. Using dynamic programming principle, the value function is a solution of Hamilton---Jacobi---Bellman (HJB) equation. The subsolution-supersolution method is used to verify the existence of classical solutions of the HJB equation. The explicit solution of the value function is derived, and the corresponding optimal debt ratio and consumption strategies are obtained. An example is provided to illustrate the methodologies and some interesting economic insights.	technical debt	Zhuo Jin	2015	J. Optimization Theory and Applications	10.1007/s10957-014-0629-0	stochastic control;control theory;mathematics;debt-to-equity ratio	Theory	1.967232903790029	-2.462076734066957	144326
2cb1e023a588dca8cb9c3d3e54659330d01a2914	revisiting prospect theory and the newsvendor problem		Many experimental studies have demonstrated that human decision-makers exhibit the pull-to-center effect in newsvendor decision. It has been shown in the literature that prospect theory with a decision-dependent reference point can predict the pull-to-center effect for the newsvendor problem by assuming a uniform distribution of demand. In this paper, we prove this result for a general case: prospect theory with a decision-independent reference point can predict the pull-to-center effect for the newsvendor problem with a general distribution of demand.	newsvendor model	Yuwei Shen;Xiaobo Zhao;Jinxing Xie	2017	Oper. Res. Lett.	10.1016/j.orl.2017.09.009	mathematical optimization;mathematical economics;extended newsvendor model;prospect theory;mathematics;newsvendor model;uniform distribution (continuous)	ECom	-3.973324960114216	-5.812762625072281	144738
28ae1b05aa271b66ed415d411506d88e11cebc77	revenue maximization with a single sample	satisfiability;hazard rate;revenue maximization;mechanism design;auctions	We design and analyze approximately revenue-maximizing auctions in general single-parameter settings. Bidders have publicly observable attributes, and we assume that the valuations of indistinguishable bidders are independent draws from a common distribution. Crucially, we assume all valuation distributions are a priori unknown to the seller. Despite this handicap, we show how to obtain approximately optimal expected revenue - nearly as large as what could be obtained if the distributions were known in advance - under quite general conditions.  Our most general result concerns arbitrary downward-closed single-parameter environments and valuation distributions that satisfy a standard hazard rate condition. We also assume that no bidder has a unique attribute value, which is obviously necessary with unknown and attribute-dependent valuation distributions. Here, we give an auction that, for every such environment and unknown valuation distributions, has expected revenue at least a constant fraction of the expected optimal welfare (and hence revenue). A key idea in our auction is to associate each bidder with another that has the same attribute, with the second bidder's valuation acting as a random reserve price for the first. Conceptually, our analysis shows that even a single sample from a distribution - the second bidder's valuation - is sufficient information to obtain near-optimal expected revenue, even in quite general settings.	entropy maximization;information;observable;value (ethics);witness-indistinguishable proof	Peerapong Dhangwatnotai;Tim Roughgarden;Qiqi Yan	2010		10.1145/1807342.1807364	financial economics;mechanism design;mathematical optimization;economics;common value auction;microeconomics;mathematical economics;hazard ratio;welfare economics;satisfiability	ECom	-2.6413781032885586	-2.0453473182634263	144796
44d40c628cfbd1344dcf208ef3b263b406c71c7b	online privacy at a premium	trust;econometric model;price premium;econometric models trust price premium;empirical evidence;econometric models;seals data privacy marketing and sales econometrics business consumer electronics books organizational aspects information technology protection	Online privacy has been a significant concern of customers in online transactions. Several technical, economics based, and regulatory mechanisms have been proposed to address online privacy. One proposed market-based mechanism is the privacy seal. In this paper, we present some empirical evidence of the impact of displaying a privacy seal on the product prices of online firms. Using data carefully collected on homogeneous products sold by pairs of online firms — one firm in the pair with a privacy seal, and the other firm without the seal — we find that firms with a privacy seal in fact do charge a price premium on their products, compared to firms without a seal. The amount of this price premium is affected by the product prices, but is not affected by the product demand. Based on the data, we also quantify the magnitude of this privacy seal induced price premium.	e-commerce;internet privacy;value (ethics)	Bin Mai;Nirup M. Menon;Sumit Sarkar	2006	Proceedings of the 39th Annual Hawaii International Conference on System Sciences (HICSS'06)	10.1109/HICSS.2006.368	economics;computer science;marketing;econometric model;commerce	Metrics	-3.0707222136779766	-8.43515697906222	145307
6e4435d1a8742a8045f6fd7503e5e0458cccd902	variable speed limits for area-wide reduction of emissions	predictive control;velocity control;model based traffic controller;travel times variable speed limits area wide emission reduction traffic congestion traffic flow healthy environment vehicle fuel consumption traffic network model based traffic controller emission dispersion model predictive control mpc;travel time;mpc;road traffic;velocity control air pollution control predictive control road traffic road vehicles traffic control;travel times;exhaust gases;traffic control;traffic flow;fuel consumption;area wide emission reduction;model predictive control;air pollution control;traffic network;speed limits;healthy environment;computational modeling;traffic congestion;mathematical models;vehicle fuel consumption;mathematical model;predictive models;optimization;vehicles;emission dispersion;dispersion;wind;variable speed limits;dispersion traffic control mathematical model predictive models computational modeling vehicles optimization;road vehicles	Although traffic congestion is a pressing problem that drivers face every day, improving the traffic flow does not always create a healthy environment to the people residing in the neighborhood of the freeway. Improved traffic flow neither means efficient fuel consumption of the vehicles. Moreover, reduction of total emissions or travel times in a traffic network does not always guarantee reduction in the area-wide emission levels, because there are many other factors that affect the area-wide emissions. In particular, the direction and speed of wind are important factors that play a significant role in the area-wide emission levels. Therefore, in this paper, we systematically model the effect of wind on the area-wide emission levels and design a model-based traffic controller to reduce the dispersion of emissions. More specifically, a model predictive control (MPC) is used to integrate various variable speed limits in order to provide a balanced trade-off between the area-wide emissions and the travel times. Furthermore, we present a case study to demonstrate the proposed control approach.	freeway;network congestion	Solomon Kidane Zegeye;Bart De Schutter;Hans Hellendoorn;Ewald A. Breunesse	2010	13th International IEEE Conference on Intelligent Transportation Systems	10.1109/ITSC.2010.5625032	simulation;engineering;automotive engineering;transport engineering	Robotics	9.352446259309565	-9.326180001537903	145332
f590b8502eda5d7883afa9922859582013a34598	savings potential through autonomous control in the distribution of rental articles		In general, rental articles circulate in closed logistic systems between the lender and one or more dynamically changing customers. The planning processes, related to the allocation of those articles to customer orders, are a challenging task. This is especially the case, if orders have a close temporal distance, as the corresponding order execution takes place between the poles of high customer demands and the lender’s economic interests. This paper introduces an autonomously controlled distribution system for rental articles that takes over both the allocation of articles to orders and the related logistic planning. At this, the focus lies on the results of first benchmarks and an estimation of the related potential for savings. A company from the field of event logistics serves as an application example for the distribution approach.		Florian Harjes;Bernd Scholz-Reiter	2014		10.1007/978-3-319-23512-7_12	marketing;operations management;commerce	Robotics	0.48829652674619134	-5.703773386088144	145470
438cf30656237e9f53e5428a79cfb85779728fc6	an epq model for two-warehouse in unremitting release pattern with two-level trade credit period concerning both supplier and retailer	two warehouse;trade credit;epq model;alternative approach of payment;continuous release pattern	The present study deals with the development of an integrated production inventory model of supplier and retailer where a delay in payment is accessible by supplier towards the retailer and also by retailer en route for customer. Moreover, this paper relates to two warehouse inventory policy with continuous discharge along with two-level of credit period in a finite planning horizon. A retailerthe owner of two warehouses offers and accepts a credit period to the customer and from the wholesaler respectively. Depending upon the time of offering and accepting credit periods and with respect to the time of exhaust of inventory in two warehouses, different scenarios have been depicted in this approach of study. The objective of the current study is to minimize the total integrated cost of both supplier and retailer. Furthermore, an alternative approach of payment for the remaining inventory after the credit period has also been proposed in the present study. This new approach to analyze the interest earned by the retailer has been specified in this model, which has been explained with the help of numerical examples in conjunction with sensitivity analysis and the outcome is contrasted against the above cited traditional approach as well. The model has been developed as a cost minimization problem with respect to the retailer and supplier and has been optimized using the non-linear optimization technique – Generalized Reduced Gradient method (LINGO). The optimal solutions under different scenarios have been exemplified numerically and graphically in this study. © 2015 Elsevier Inc. All rights reserved.	discharger;economic production quantity;frank–wolfe algorithm;gradient method;inventory theory;linear programming;mathematical optimization;nonlinear programming;nonlinear system;numerical analysis;numerical method	P. Majumder;Uttam Kumar Bera;Manoranjan Maiti	2016	Applied Mathematics and Computation	10.1016/j.amc.2015.10.057	mathematics;operations management;mathematical optimization;payment;time horizon;integrated production;warehouse;trade credit	AI	2.8324266646139518	-4.273184541432588	145524
b3fdd0573e415fd0434921a10c4f1eb0f29a9559	a decision-making framework for project portfolio planning at intel corporation	decision support;simulation;practice of or;analytics;elimination by aspects;binary integer linear program;portfolio management;intuition	The work we describe addresses the problem of deciding between project-funding opportunities under budget and headcount constraints. Although the projects lead to products that yield revenue in the market, complex interactions between the projects and products make the selection of a portfolio difficult. Furthermore, the senior managers in the company have a wealth of business intuition that can inform the required decisions. We combine modeling, simulation, and optimization techniques to provide a set of the best portfolios possible from the proposed projects and resulting products. We also provide a rich set of analysis and visualization tools for the decision makers to use in exploring the suggested portfolios and applying their intuition to make the final selection. The resulting interplay between analytics and intuition produces better business solutions through a more focused and effective debate in a shorter time than previously achieved.		Siddhartha Sampath;Esma Senturk Gel;John W. Fowler;Karl G. Kempf	2015	Interfaces	10.1287/inte.2015.0809	analytics;decision support system;economics;computer science;engineering;knowledge management;artificial intelligence;marketing;operations management;intuition;management science;management;operations research;project portfolio management	Robotics	4.1543908437357935	-7.676196266263061	145535
03b305ec33cb752367b473758c4812abd6de859a	stochastic mpc for real-time market-based optimal power dispatch	real time systems generators power systems energy storage stochastic processes electricity production;predictive control;generators;stochastic process;real time;power systems;real time optimization;electric power system;stochastic processes;power system;energy storage;production;trade cost;power generation;electricity;profitability;stochastic model;energy markets;tk electrical engineering electronics nuclear engineering;real time systems	We formulate the problem of dynamic, real-time optimal power dispatch for electric power systems consisting of conventional power generators, intermittent generators from renewable sources, energy storage systems and price-inelastic loads. The generation company managing the power system can place bids on the real-time energy market (the so-called regulating market) in order to balance its loads and/or to make profit. Prices, demands and intermittent power injections are considered to be stochastic processes and the goal is to compute power injections for the conventional power generators, charge and discharge levels for the storage units and exchanged power with the rest of the grid that minimize operating and trading costs. We propose a scenario-based stochastic model predictive control algorithm to solve the real-time market-based optimal power dispatch problem.	algorithm;discharger;dynamic dispatch;ibm power systems;mathematical optimization;multistage amplifier;real-time clock;real-time transcription;sampling (signal processing);simulation;stochastic optimization;stochastic process;time series	Panagiotis Patrinos;Sergio Trimboli;Alberto Bemporad	2011	IEEE Conference on Decision and Control and European Control Conference	10.1109/CDC.2011.6160798	control engineering;stochastic process;power-flow study;simulation;base load power plant;engineering;mathematics;dynamic demand;electric power system	Embedded	3.5482227020579784	4.119331440085759	145628
8f5c834b9671963c3bebc7d8944fca6e0410762b	competitive equilibrium in two sided matching markets with general utility functions	search engine;game theory;fixed point theorem;utility function;non quasilinear;pay per click;market design;matching market;competitive equilibrium;mechanism design;two sided matching;price discrimination;budget constraint	Two sided matching markets are among the most studied models in market design. There is a vast literature on the structure of competitive equilibria in these markets, yet most of it is focused on quasilinear settings. General (non-quasilinear) utilities can, for instance, model smooth budget constraints as a special case. Due to the difficulty of dealing with arbitrary non-quasilinear utilities, most of the existing work on non-quasilinear utilities is limited to the special case of hard budget constraints in which the utility of each agent is quasilinear as long as her payment is within her budget limit and is negative infinity otherwise. Most of the work on competitive equilibria with hard budget constraints rely on some form of ascending auction. For general non-quasilinear utilities, such ascending auctions may not even converge in finite time. As such, almost all of the existing work on general non-quasilinear utilities have resorted to non-constructive proofs based on fixed point theorems or discretization. We present the first direct characterization of competitive equilibria in such markets. Our approach is constructive and solely based on induction. Our characterization reveals striking similarities between the payments at the lowest competitive equilibrium for general utilities and VCG payments for quasilinear utilities. We also show that lowest competitive equilibrium is group strategyproof for the agents on one side of the market (e.g., for buyers).	converge;discretization;fixed point (mathematics);mathematical induction;nash equilibrium	Saeed Alaei;Kamal Jain;Azarakhsh Malekian	2011	SIGecom Exchanges	10.1145/1998549.1998556	mechanism design;game theory;mathematical optimization;economics;marketing;microeconomics;mathematical economics;welfare economics	ECom	-3.1008660594478537	-1.5664905590673108	145645
684d7434348842eba3b05b1fafd54397ea92164b	effects of inventory policy on supply chain performance: a simulation study of critical decision parameters	service level;operant conditioning;inventory policy;information sharing;supply chain performance;economic order quantity;simulation study;supply chain;computer simulation;early order commitment;supply chain management	This paper investigates the effects of information sharing and early order commitment on the performance of four inventory policies used by retailers in a supply chain of one capacitated supplier and four retailers. Model parameters and operating conditions are emulated from a local business supplying a standard product to its retailers. Through computer simulation and subsequent analyses, we found that the inventory policy used by the retailers, information sharing, and early order commitment can significantly influence the performance of the supply chain. Out of the four inventory policies examined, the economic order quantity rule is found to be the best for the retailers and the entire supply chain, but periodic order quantity and Silver–Meal provide the best performance for the supplier. The sharing of future order plans by the retailer and the supplier is also shown to be the most effective way for reducing the supplier’s cost and improving its service level; however, the magnitude of these benefits achieved is less for the retailers. In addition, early order commitment by the retailers is found to be beneficial to the supplier and retailers in reducing their total cost. 2008 Elsevier Ltd. All rights reserved.	carrying cost;computer simulation;economic order quantity;emulator;interaction;inventory control;programming paradigm	R. S. M. Lau;Jinxing Xie;Xiande Zhao	2008	Computers & Industrial Engineering	10.1016/j.cie.2008.02.002	computer simulation;supply chain risk management;supply chain management;economic order quantity;service level;marketing;operations management;operant conditioning;supply chain;commerce	AI	2.306643508733432	-6.197030528222508	145735
ce198136356d3f6c3dfbf0d88d6bd83dced0eff3	genetic algorithms for the dependability assurance in the design of a long-span suspension bridge	bridge design;live loads;finite element method;loads;long span bridges;dynamic response structures;suspension bridges	A long-span suspension bridge is a complex structural system that interacts with the surrounding environment and the users. The environmental actions and the corresponding loads (wind, temperature, rain, earthquake, etc.) together with the live loads (railway traffic, highway traffic), have a strong influence on the dynamic response of the bridge, and can significantly influence the structural behavior and alter its geometry, thus limiting the serviceability performance even up to a partial closure. This article will present some general considerations and operative aspects of the activities related to the analysis and design of such a complex structural system. Specific reference is made to the dependability assessment and the performance requirements of the whole system, while focus is given on methods for handling the completeness and the uncertainty in the assessment of the load scenarios. Aiming at the serviceability assessment, a method based on the combined application of genetic algorithms and a finite element method (FEM) investigation is proposed and applied.	dependability;finite element method;genetic algorithm;requirement;sandy bridge;structural load	Luca Sgambi;Konstantinos Gkoumas;Franco Bontempi	2012	Comp.-Aided Civil and Infrastruct. Engineering	10.1111/j.1467-8667.2012.00780.x	structural engineering;specified load;structural load;engineering;civil engineering;finite element method;transport engineering	HPC	7.828289051748298	-9.728808419168834	145959
37f9a8e0800bb45c4243082a8330b50847e345c7	why do consumers prefer static instead of dynamic pricing plans? an empirical study for a better understanding of the low preferences for time-variant pricing plans		Abstract Time-variant pricing plans in electricity markets aim to mitigate mismatches between demand and supply by incentivizing consumers to shift their demand from costly peak to cheaper off-peak times. Their implementation can be manifold; they could depend statically on the time of the day (i.e., time-of-use pricing) or adjust prices dynamically in nearly real time (real-time pricing). If consumers reduced demand in peak times, then they would realize lower prices and providers would operate at lower costs. Still, consumers frequently refuse time-variant pricing plans. The authors develop a new conceptual framework to study and explain this behavior. It supports the optimal choice of time-variant pricing plans by jointly considering price fairness and economic antecedents. In a discrete choice experiment, the authors use a hierarchical Bayes covariate extended logit estimation to measure respondents’ probability of switching from a time-invariant pricing plan to a time-variant pricing plan. The results show that economic antecedents, such as price consciousness and flexibility, have a stronger effect on the choice of a time-variant pricing plan than price fairness considerations; cost insurance is a promising instrument for increasing acceptance of dynamic pricing plans. The results also suggest new ways to target prospective customers.		Christian Schlereth;Bernd Skiera;Fabian Schulz	2018	European Journal of Operational Research	10.1016/j.ejor.2018.03.033	operations management;logit;empirical research;conceptual framework;mathematics;microeconomics;dynamic pricing;discrete choice;bayes' theorem;supply and demand;covariate	DB	-0.4381313061546534	-7.526768344748711	146191
5781dfe4d61470dfcd9104554177b8cc5c9604c7	derivation of the initial stock of bags - a monte carlo approach	uninterruptible power systems;investments;electric shock;uncertainty;feeds;net present value;plastic packaging;transport system;simulation technique;transportation;mathematical model;technical report;uninterruptible power systems containers feeds uncertainty electric shock costs transportation plastic packaging investments mathematical model;monte carlo;monte carlo simulation;containers	The objective of this paper is to calculate the number of bags needed to successfully supply a large package delivery operation. These bags are used to consolidate many small packages into an easier to transport large container -- thus decreasing the handling cost associated with them. Presently, disposable plastic bags are being used. The hypothesis is that permanent bags may make economical sense if the net present value of this modification is positive. The major determinant in the financial success of this proposition is the number of bags needed to feed the operation. Through monte carlo simulation techniques, we were able to accurately model the inherent dynamic uncertainty in this calculation. Thereby enabling the financial calculation to be performed.	monte carlo method;simulation	Zubin Dowlaty;Chong Loo	1996		10.1145/256562.256998	simulation;engineering;mathematics;operations research;statistics;monte carlo method	ML	7.517209351419254	-5.299336218663577	146259
0c0250ecf74e753b2b66e14553b19ee450febff6	formulation of relationship between productivity and energy consumption in manufacturing system		In the industrial world, since the amount of energy to consume is very large, it is required to manage and reduce energy consumption while maintaining a high productivity. In order to approach the theoretical realization the production conditions that affect a productivity or energy consumption, we investigate the formulation of the relationship between energy consumption and production throughput, and verify it by using numerical simulation.		Takayuki Kobayashi;Makoto Yamaguchi;Hironori Hibino	2015		10.1007/978-3-319-22756-6_89	operations management;industrial engineering;manufacturing engineering	Robotics	8.854502412546962	2.406709182038628	146289
1b1eaeacda139b1e21619ef1277137c62f6d1dfa	a machine learning approach for optimal disassembly planning	optimal disassembly planning;bayesian network;machine learning;decision making process;petri nets;petri net;expert system	With the vast amounts of environmental waste being created on a daily basis, many companies are trying to find ways optimally to reuse and recycle obsolete products. Owing to tedious and intensive nature of optimal disassembly planning, expert systems which ease the decision making process are becoming much more prevalent. This paper discusses one such system where a machine learning approach based on a disassembly Petri net (DPN) and a hybrid Bayesian network (HBN) is used. In particular, this method models the disassembly process and predicts the outcome of each disassembly action by examining the probabilistic relationships between the different aspects of the disassembly process. An overall view of the disassembly process and a simple, specific case are provided to illustrate the operation of this expert system.	disassembler;machine learning	D. E. Grochowski;Y. Tang	2009	Int. J. Computer Integrated Manufacturing	10.1080/09511920802024176	computer science;systems engineering;engineering;operations management;machine learning;petri net;expert system	Robotics	7.067612394896988	-6.667369447534472	146391
fbe56298d1a900362bb63097fe7dcd5e7759c3e2	effects of ramp type demand and weibull deterioration rate on retailers' optimal pricing and lot-sizing policies for deteriorating items with partial backlogging	optimisation;lot sizing policies;ameliorating items;inventory model;inventory;weibull deterioration rate;opportunity cost;price dependent demand;inventory modelling;lot sizing;profitability;partial backlogging;optimal pricing;ramp type of demand;replenishment cycles	This paper discusses a deterministic inventory model for Weibull deteriorating items with partial backlogging under ramp type demand function. Shortages are allowed. Here we consider replenishment cycles, the time at which shortage begins; replenishment time and the optimal selling price are taken as decision variables. The objective of this model is to maximise the total profit (TP) which includes the sales revenue, purchase cost, the set up cost, holding cost, shortage cost and opportunity cost due to lost sales. We extend the results to ameliorating items also. Numerical examples are given to illustrate the model.	ramp simulation software for modelling reliability, availability and maintainability	M. Valliathal;R. Uthayakumar	2011	IJDATS	10.1504/IJDATS.2011.042955	inventory;economics;opportunity cost;operations management;microeconomics;commerce;profitability index	ECom	2.5759495468661333	-4.732938438696141	146454
f08d7653cf9861495b169d39bf69809ce515287c	an evaluation of blood-inventory policies: a markov chain application	markov chain	A theoretical model using mainly the theory of absorbing Markov chains is applied to several human-blood-issuing policies. The objective of the model applications is to determine the effects of the issuing policies on average inventory levels, which determine blood shortage probabilities, and on the average age of blood at the time it is transfused. Issuing policies that issue (transfuse) fresher blood with a higher probability than older blood are defined as modified fifo policies, and issuing policies that issue older blood with a higher probability than fresher blood are defined as modified fifo policies. Application of the theoretical model to the various issuing policies allows complete evaluation of the policies, and a policy choice can be made on the basis of the evaluation.	markov chain	C. Carl Pegels;Andrew E. Jelmert	1970	Operations Research	10.1287/opre.18.6.1087	markov chain;actuarial science;economics;operations management;mathematics;welfare economics;statistics	Metrics	4.729943308065844	-5.904307909771906	146479
4655d35d0defda288998f3516b692902cd1eea73	a sequential fast pyrolysis facility location-allocation model		The revised Renewable Fuel Standard (RFS2) mandates the U.S. consume16 billion gallons per year (BGY) of biofuels from cellulosic sources by the year 2022. Fast Pyrolysis of biomass is a renewable conversion process developed for producing liquid transportation fuels, such as gasoline and diesel.	location-allocation	Yihua Li;Guiping Hu	2013		10.1007/978-3-642-41266-0_49	renewable fuel standard;diesel fuel;waste management;renewable energy;gasoline;pyrolysis;biofuel;environmental science;cellulosic ethanol;biomass	NLP	6.309998871785232	2.0614600464617654	146526
24e2ac43665a5777de7848a459278091539ad51b	constrained assortment optimization for the nested logit model	revenue management;grupo de excelencia;nested logit model;administracion de empresas;assortment optimization;economia y empresa;grupo a	We study assortment optimization problems where customer choices are governed by the nested logit model and there are constraints on the set of products offered in each nest. Under the nested logit model, the products are organized in nests. Each product in each nest has a fixed revenue associated with it. The goal is to find a feasible set of products, i.e. a feasible assortment, to maximize the expected revenue per customer. We consider cardinality and space constraints on the offered assortment, which respectively limit the number of products and the total space consumption of the products offered in each nest. We show that the optimal assortment under cardinality constraints can be obtained efficiently by solving a linear program. The assortment optimization problem under space constraints is NP-hard. We show how to obtain an assortment with a performance guarantee of two under space constraints. This assortment also provides a performance guarantee of 1/(1 − ε) when the space requirement of each product is at most a fraction ε of the space availability in each nest. Building on our results for constrained assortment optimization, we show that we can efficiently solve joint assortment optimization and pricing problems under the nested logit model, where we choose the assortment of products to offer to customers, as well as the prices of the offered products. Discrete choice models have long been used to describe how customers choose among a set of products that differ in attributes such as price and quality. Specifically, discrete choice models represent the demand for a particular product through the attributes of all products that are in the offered assortment, capturing substitution possibilities and complementary relationships between the products. To pursue this thought, different discrete choice models have been proposed in the literature. Some of these models are based on axioms as in Luce (1959), resulting in the basic attraction model, whereas some others are based on random utility theory as in McFadden (1974), resulting in the multinomial logit model. A popular extension to the multinomial logit model is the nested logit model introduced by Williams (1977). Under the nested logit model, the products are organized in nests. The choice process of a customer proceeds in such a way that the customer first selects a nest, and then a product within the selected nest. In this paper, we study constrained assortment optimization problems when customers choose according to the nested logit model. There is a fixed revenue contribution associated with each product. The goal is to find an assortment of products to offer so as to maximize the expected revenue per customer subject to a constraint on the assortment offered in each nest. We consider two types of constraints, which we refer to as cardinality and space constraints. Cardinality constraints limit the number of products in the assortment offered in each nest. We show that the optimal assortment under cardinality constraints can be obtained by solving a linear program. Under space constraints, each product occupies a certain amount of space and we limit the total space consumption of the products offered in each nest. The assortment optimization problem under space constraints is NP-hard, but we show that we can solve a tractable linear program to obtain an assortment with a certain performance guarantee. These results establish that we can obtain provably good assortments under cardinality or space constraints. In addition, we consider joint assortment optimization and pricing problems under the nested logit model. In the joint assortment optimization and pricing problem, the goal is to decide which assortment of products to offer and set the prices of the offered products. Customers choose among the offered products according to the nested logit model and the price of a product affects its attractiveness in the sense that if we set the price of a product higher, then it becomes less attractive to customers. Building on our results for constrained assortment optimization problems, we show that an optimal solution to the joint assortment optimization and pricing problem can be obtained efficiently by solving a linear program. Therefore, our results are not only useful for solving constrained assortment optimization problems, but they are also useful for pricing. Main Contributions. In assortment optimization problems, we consider a setting with m nests, each including n products that we can offer to customers. Under cardinality constraints, we show that we can solve a linear program with 1+m decision variables and O(mn2) constraints to obtain the optimal assortment. Under space constraints, we show that we can solve a linear program of the same size to obtain an assortment whose expected revenue deviates from the optimal expected revenue by at most a factor of two. Also, if each product consumes at most a fraction ε ∈ [0, 1)	cobham's thesis;decision theory;discrete choice;linear programming;mathematical optimization;multinomial logistic regression;np-hardness;optimization problem;program optimization;utility	Guillermo Gallego;Huseyin Topaloglu	2014	Management Science	10.1287/mnsc.2014.1931	economics;marketing;operations management;welfare economics	ECom	-1.8160763736888212	-2.000111352264204	146553
057f0af17930f84eea75dcb6fd3eedeb3865b107	quality and entry deterrence	game theory;competition;entry;platforms and content;quality	We analyze the role of quality, which we define as an attribute of a product that increases consumers’ willingness to buy, as a competitive tool in a quality-price setting. We consider an incumbent’s entry-deterrence strategies using quality as a deterrent when faced by a potential entrant. We investigate settings motivating the incumbent to blockade the entrant (i.e., prevent entry without extra effort), deter the entrant (i.e., prevent entry with extra effort), or accommodate the entrant (i.e., allow the entry to take place). We identify conditions under which the incumbent may actually over-invest in quality to deter entrance. More interestingly, we also identify conditions under which the incumbent may decrease his quality investment to make it easier for the entrant to penetrate the market. Our model sheds light on entry scenarios of particular platform product markets such as the entry of Xbox to the video game console market.		Özgen Karaer;Feryal Erhun	2015	European Journal of Operational Research	10.1016/j.ejor.2014.07.016	game theory;competition;economics;marketing;advertising;commerce	Vision	-3.1973432150965535	-7.744330598395556	146654
0c297c26115bb3c179b59a385fe7d08a4455c98c	application of new decision making model based on modified cost-benefit analysis - a case study: belgrade tramway transit	belgrade tramway rolling stock;modified cost benefit analysis	Tramway transit has an important place within the public transportation system of Belgrade. However, due to the very unfavorable age structure, the bad condition of tramway tracks and infrastructure, as well as the maintenance system that require significant advancement, Belgrade tramways are in very bad repair, so the transport requirements are not properly met. The principal task of the analysis presented in this paper is to recognize and estimate the justifiability of investment into various solutions for revitalization of Belgrade tramway rolling stock. We have chosen a somewhat different from usual approach to decision making, that is, applied a combination of cost-benefit, life-cycle cost and multi-criteria analysis.		Vladimir M. Popovic;Branko M. Vasic;Tatjana M. Lazovic;Aleksandar M. Grbovic	2012	APJOR	10.1142/S0217595912500340	operations management;mathematics;economy;operations research	NLP	8.578735983856548	-2.660784492717035	146760
c62f3c735707731e719a15990d143c7f7b2a04ae	optimal design of uptime-guarantee contracts under igfr valuations and convex costs	game theory;revenue management;maintenance;pricing;contracts;servitization	An uptime-guarantee contract commits a service provider to maintain the functionality of a customer’s equipment at least for certain fraction of working time during a contracted period. This paper addresses the optimal design of uptime-guarantee contracts for the service provider when the customer’s valuation of a contract with a given guaranteed uptime level has an Increasing Generalized Failure Rate (IGFR) distribution. We first consider the case where the service provider proposes only one contract and characterize the optimal contract in terms of price as well as guaranteed uptime level assuming that the service provider’s cost function is convex. In the second part, the case where the service provider offers a menu of contracts is considered. Given the guaranteed uptime levels of different contracts in the menu, we calculate the corresponding optimal prices. We also give the necessary and sufficient conditions for the existence of optimal contract menus with positive expected profits.	optimal design;uptime	Behzad Hezarkhani	2017	European Journal of Operational Research	10.1016/j.ejor.2016.06.032	pricing;game theory;contract management;actuarial science;economics;marketing;microeconomics;commerce	ECom	-0.017561042407111524	-4.815007623091612	146827
cbb8116fd1ebaa13d4dad47c9d93c57e3e6cfeb9	the existence of low-end firms may help high-end firms	game theory;pricing research;marketing strategy;price competition;product differentiation;competition model;product positioning;profitability;product quality;research productivity	Two models of competition between high-end and low-end products benefiting the high-end firms are presented. One is a quantity competition model, and the other is a price competition model with product differentiation. The key factor is the existence of two heterogeneous consumer groups: those who demand only high-end (name-brand) products and those who care little whether products are high or low end. We show that, under certain conditions, the profits of firms in the high-end market are larger when there are firms producing low-end products than when there are not. The existence of price-sensitive consumers who care little about product quality intensifies competition among the high-end firms. The existence of low-end firms functions as a credible threat, which induces the high-end firms not to overproduce because price-sensitive consumers buy products from the low-end firms. The result provides a new theoretical mechanism concerning the profitability and pricing of national brand firms after the entry of private labels. It has an implication for pricing and marketing strategies: Established firms should not decrease their prices after the entry of nonestablished firms.		Ikuo Ishibashi;Noriaki Matsushima	2009	Marketing Science	10.1287/mksc.1080.0388	game theory;economics;marketing;product differentiation;market structure;microeconomics;marketing strategy;commerce;profitability index	Logic	-2.230917475782169	-7.008347135410998	146846
fdc6867baae1a23de0a9214a5e5d1eabdab8a11a	ex post renegotiation-proof mechanism design	implementation;ex post renegotiation;mechanism design	We study what kind of equilibria of which mechanisms are ex post renegotiation-proof (EPRP), i.e., robust against the possibility of ex post renegotiation under a variety of renegotiation procedures, and which social choice functions are EPRP implementable. In complete information environments with two agents only budget balanced Groves allocations are EPRP implementable, while with three or more agents – all ex post efficient allocations are. In environments with independent private values essentially only the budget balanced “Groves in expectations” allocations are EPRP implementable, while with three or more agents and correlated beliefs – all ex post efficient allocations are. © 2013 Elsevier Inc. All rights reserved. JEL classification: D02; D70; D82; D86		Zvika Neeman;Gregory Pavlov	2013	J. Economic Theory	10.1016/j.jet.2012.08.003	mechanism design;economics;public economics;operations management;mathematical economics;implementation;welfare economics	AI	-4.412495073393077	-3.4638215155297076	147043
ab46c93cd2fa9ef71929f1d0097ccbf5897b0cd6	price reactions to rivals' local channel exits	agglomeration;pricing	In this paper, we study the e ect of a firm’s local channel exits on prices charged by incumbents remaining in the marketplace. Exits could result in higher prices due to tempered competition or lower prices due to reduced co-location or agglomeration benefits. The net e ect of these two countervailing forces remains unknown. In addition, little is known about how this e ect could change depending on incumbents’ geographic locations. We address this research gap by examining new car price reactions by incumbent multi-product automobile dealerships who experience the exit of a Chrysler dealership in their local markets. We find evidence that the competition e ect exceeds the co-location e ect: prices increase by about 1% ($318) following an exit relative to the price change in the absence of an exit. Importantly, we find that the price increase is lower at dealerships more proximate to the exiting dealership than dealerships farther away for the same set of cars available across these locations. This finding suggests di erences in the extent of the two forces (competition and agglomeration) at di erent distances from the closed dealership. We assess the generalizability of our results by looking at the impact of GM’s closure of Pontiac dealerships. Taken together, our results inform consumers, firms, and policymakers about possible implications of an exit.	closing (morphology);cluster analysis;distress (novel);downstream (software development);inventory;nist hash function competition;panel data	O. Cem Ozturk;Sriram Venkataraman;Pradeep Chintagunta	2016	Marketing Science	10.1287/mksc.2015.0952	industrial organization;pricing;economics;marketing;operations management;economies of agglomeration;economy	ECom	-3.800600385560426	-8.900811636005509	147053
9b6f0e2f334cf2e8f7cb214b8454002917095eb8	a shock model for the maintenance problem of a repairable system	poisson process;preventive maintenance;computational geometry;optimal policy;geometric process;repairable system;fault tolerant computer systems;failure analysis;average cost;article;replacement policy;shock	In this paper, a shock model for the maintenance problem of a repairable system is studied. Assume that shocks will arrive according to a Poisson process. If the interarrival time of two successive shocks is less than a threshold, then the system will fail. For a deteriorating system, we assume that the successive threshold values are geometrically nondecreasing after repair, and the consecutive repair times after failure form an increasing geometric process. For an improving system, we assume that the successive threshold values are geometrically decreasing after repair, and the consecutive repair times after failure form a decreasing geometric process. A replacement policy N is adopted by which we shall replace the system by an identical new one at the time following the N th failure. Then for each of the deteriorating system and improving system, an optimal policy N ∗ for minimizing the long-run average cost per unit time is determined explicitly. ? 2003 Elsevier Ltd. All rights reserved.		Yeh Lam;Yuan Lin Zhang	2004	Computers & OR	10.1016/S0305-0548(03)00121-7	preventive maintenance;failure analysis;shock;poisson process;computational geometry;computer science;mathematics	Theory	6.602763173196888	-1.1807132086219425	147279
60b2fa2b22a94bb4f48518b377311cba3a33dec0	maintenance optimization for power distribution systems subjected to hurricane hazard, timber decay and climate change	decay;reliability;climate change;power systems;hurricanes;maintenance optimization;wood pole	Electric power systems are vulnerable to extensive damage due to hurricanes with most of the damage concentrated on overhead distribution systems. There is evidence that climate change will affect future hurricane patterns. Additionally, wood poles, which are most commonly used in distribution systems, are susceptible to decay. The scarcity of resources and increasing demand for higher reliability warrant the use of optimization techniques for wood pole maintenance planning. This paper presents a framework for optimal maintenance of wood poles subjected to non-stationary hurricane hazard and decay. Maintenance cost, service life, and system performance are considered separately and simultaneously in the optimization. Periodic chemical treatment and repair of decayed poles using fiber-reinforced polymer are considered. The distribution system of a virtual city assumed to be in Florida is used to demonstrate the framework. The results of the single-objective optimization indicate that the objective that maximizes service life resulted in higher optimal maintenance time. However, delaying maintenance will lead to a larger probability of pole failure, higher corrective maintenance cost, and lower system performance. The result of the multi-objective optimization is closer to the result of the cost-based optimization because the cost function is more sensitive to the variation of maintenance time.	mathematical optimization	Abdullahi M. Salman;Yue Li;Emilio Bastidas-Arteaga	2017	Rel. Eng. & Sys. Safety	10.1016/j.ress.2017.03.002	structural engineering;reliability engineering;tropical cyclone;engineering;reliability;electric power system;forensic engineering;climate change;statistics	EDA	8.271972312021125	-5.9453330023981845	147330
0f5607396524b0749e969f311e6e88184ea0b469	railway track quality assessment and related decision making	maintenance engineering quality management decision support systems railway engineering decision making;railway engineering;rail transportation quality assessment decision making resource management predictive models railway engineering civil engineering geology inspection process design;asset management;cost saving;resource manager;maintenance engineering;numerical optimization;price level;quality assessment;decision support systems;maintenance management;maintenance and renewal management decision making railway track quality assessment extraordinary inspection condition based process resource management deterioration modeling;quality management	Railways must establish explicit processes for making decisions on various activities to be undertaken to keep these key objects within desirable (required) condition/operational limits. These activities usually represent M&R works, but could also represent other activities like additional/extraordinary inspections. This paper describes how such a condition-based process can be designed. The process consists of identifying key infra-objects and their necessary information, finding ways for collecting this data, and understanding relationships between these data (revealing the key objects' behavior in time). Certain thresholds are applied for certain condition parameters, and deterioration models are utilized to determine when these limits are reached; they signify needs for certain M&R works/inspections.	consistency model;mathematical optimization;simulation	Stanislav Jovanovic	2004	2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No.04CH37583)	10.1109/ICSMC.2004.1400992	maintenance engineering;quality management;decision support system;decision engineering;railway engineering;price level	Visualization	7.313031332726936	-6.214712736302971	147532
ba5cf5f252eeec9e9cfdd505b8f8ef64d45fbcf8	a normal copula model for the economic risk analysis of correlated failures in communications networks	risk analysis;reliable communication;community networks;settore ing inf 03 telecomunicazioni;economic loss;figure of merit;cross entropy method	The reliability of a communications network is often evaluated without taking into account the economic consequence of failures. Here a new approach is proposed to assess the economic consequences of failures as a figure of merit of reliable networks. For this purpose a partition of the network operator’s market into service basins is proposed, which includes the presence of correlation between the subsystems needed to serve different service basins as well as within the same service basin. A simulation algorithm, based on the Cross-Entropy method, is fully described to evaluate the probability that the economic loss exceeds a given threshold. An application of the method to a simple scenario is finally reported.	algorithm;cross entropy;cross-entropy method;simulation;telecommunications network;usability	Maurizio Naldi;Giuseppe D'Acquisto	2008	J. UCS	10.3217/jucs-014-05-0786	figure of merit;cross-entropy method;risk analysis;artificial intelligence;computer security	Metrics	7.434146242125859	-9.64038137031427	147881
a8d4a23b820d23bf625310e5dd79c8a5a0e7d873	on the evaluation of agvs-based warehouse operation performance		Abstract An automated guided vehicle system (AGVS) is an advanced material handling system widely used in various automated systems, particularly in e-commerce warehouses. The warehouse operation performance, mainly focusing on transportation efficiency, is affected by many factors, such as traffic-control policies and warehouse layouts. Based on the digraph theory and real-time control, two effective traffic-control policies with polynomial-time complexity are proposed to avoid the collision and to solve deadlocks. To accommodate more complicated situations, different types of warehouse layouts are tested. Extensive simulations are carried out to study the effects of policies, warehouse layouts, task densities and timing of an AGV to apply for a resource on the evaluation of the AGVS-based warehouse operation performance, which provide guidelines for warehouse designers.		Mingyao Qi;Xiaowen Li;Xuejun Yan;Canrong Zhang	2018	Simulation Modelling Practice and Theory	10.1016/j.simpat.2018.07.015	collision;real-time computing;computer science;deadlock;automated guided vehicle;warehouse	Arch	9.793524933867356	2.8830560191454913	147911
31b3d13643b6311fb0be7698832ed5ed58e30cab	nn-opt: neural network for option pricing using multinomial tree	systeme temps reel;volatility;modele geometrique;algoritmo busqueda;taux interet;bolsa valores;martingale;brownian motion;pricing;algorithme recherche;real time;search algorithm;gradiente;option pricing;gradient;contrato;trading system;fijacion precios;bourse valeurs;interest rate;stock exchange;martingale measure;tariffication;mouvement brownien;contract;tarification;geometric brownian motion;movimiento browniano;volatilite;real time system;modele donnee;sistema tiempo real;tasa interes;contrat;reseau neuronal;volatibilidad;price volatility;red neuronal;fixation prix;historical data;geometrical model;tarificacion;data models;neural network;modelo geometrico	We provide a framework for learning to price complex options by learning risk-neutral measures (Martingale measures). In a simple geometric Brownian motion model, the price volatility, fixed interest rate and a no-arbitrage condition suffice to determine a unique riskneutral measure. On the other hand, in our framework, we relax some of these assumptions to obtain a class of allowable risk-neutral measures. We then propose a framework for learning the appropriate risk-neural measure. In particular, we provide an efficient algorithm for backpropagating gradients through multinomial pricing trees. Since the risk-neutral measure prices all options simultaneously, we can use all the option contracts on a particular stock for learning. We demonstrate the performance of these models on historical data. Finally, we illustrate the power of such a framework by developing a real time trading system based upon these pricing methods.	algorithm;algorithmic trading;artificial neural network;brownian motion;gradient;multinomial logistic regression;regular language description for xml;risk-neutral measure;volatility	Hung-Ching Chen;Malik Magdon-Ismail	2006		10.1007/11893295_41	contract;pricing;econometrics;stock exchange;real-time operating system;martingale;volatility;computer science;interest rate;brownian motion;risk-neutral measure;mathematical economics;gradient;geometric brownian motion;artificial neural network;search algorithm	ML	4.012850167872124	-3.182726262917154	147977
ace9a61aedb53bee851b782d91cc38d6ebdaeba3	effect of two-echelon trade credit on pricing-inventory policy of non-instantaneous deteriorating products with probabilistic demand and deterioration functions	pricing;two echelon trade credit;price dependent probabilistic demand;non instantaneous deteriorating items;inventory control	Usually, the profit of companies will increase if they employ trade credit financing policy to encourage customer to purchase more. This paper develops a model for pricing and inventory control of non-instantaneous deteriorating items under two-echelon trade credit in which the vendor provides a credit period to the retailer and the retailer in turn offers a delay in payment to his/her customer. The price-dependent probabilistic demand function and partially backlogged shortages are adopted. Also, deterioration is shown by three different probability distribution function including (1) uniform distribution, (2) triangular distribution, and (3) beta distribution. The theoretical results are designed to determine the optimal selling price and the optimal inventory control variables so that the retailer’s total profit is maximized. Also, the necessary and sufficient conditions to prove the existence and uniqueness of the optimal solution are provided. Moreover, an algorithm is extended to describe the solution procedure. Numerical example, sensitivity analysis, and a simulation approach are presented to illustrate the performance of the algorithm and the theoretical results. Several managerial insights are also driven from computational results. The results indicate that the retailer’s total profit increases by considering the non-instantaneous deteriorating phenomenon and the trade credit policy.	row echelon form	Reza Maihami;Behrooz Karimi;Seyyed M. T. Fatemi Ghomi	2017	Annals OR	10.1007/s10479-016-2195-3	inventory control;financial economics;pricing;economics;microeconomics;commerce	Theory	1.7269254850433648	-4.992463231571871	148006
85cd42b4bcf3c346a400aa27bdf321553c5c11b8	a search procedure for perfect information games of chance: its formulation and analysis		"""An algorithm i s developed for searching the trees of """"perfect information"""" games involving chance events. Many dice games (e.g. backgammon, craps, and monopoly and similar board games), and some card games (e.g. casino blackjack), have this property. For depth 3 trees, empirical observation reveals a search reduction of more than 50 percent, while closed-form analysis reveals a best-case complexity of O(N**2) a substantial savings over This represents the O(N**3) behavior of the """"obvious"""" search strategy."""	algorithm;best, worst and average case;blackjack;monopoly	Bruce W. Ballard	1982			simulation	Logic	-1.0048364821127012	-0.9528052889851666	148063
6e7842926bfe6ed708f1a5f2f42d5e0f74fb643f	a multi-agent system for drcmpsp based on auction and critical chain	multiple projects;project management;agent based systems;parallel projects;ccm;mas;simultaneous scheduling;multi agent systems;critical chain method;project scheduling;combinatorial auctions;bid price;decentralised projects;resource constraints	This paper develops a multi-agent system based on auction and critical chain (MAS/AC) for decentralised resource constrained multiple project scheduling problem (DRCMPSP). In this system, parallel projects are to be scheduled simultaneously under the consideration of multi-objectives, where the allocation of global resources is independent from the allocation of activities and local resources through a multi-agent system. The critical chain method (CCM) is applied to adjust the schedule and local resource constraints of each single project. Subsequently, multiple objectives of different projects are considered in the process of calculating bid price. Moreover, the distribution of global resources is conducted by AA employed combinatorial auction. Through the interactive communication between AA and PAs, parallel projects could be scheduled simultaneously with respect to their different characteristics and interests, and the benefits of the whole system could be ensured meanwhile. An experimental example t...	multi-agent system	Minghui Chen;Zhe Zhang	2016	IJADS	10.1504/IJADS.2016.10001995	project management;simulation;combinatorial auction;economics;bid price;resource allocation;operations management;distributed computing;management;schedule	EDA	-0.28367828059811506	2.3491858217731596	148091
a97c6f0d4dd34c0eac21bc19996b6b78bbaaecca	a parallelizable dynamic fleet management model with random travel times	modelo dinamico;flotte;dynamic programming;duracion trayecto;programacion dinamica;fonction valeur;high dimensionality;travel time;logistique;dynamic model;dynamic program;prise decision;funcion valor;approximation fonction;large scale;transit time;logistics;distributed decision making;function approximation;modele dynamique;transportation;fleet;programmation dynamique;weather condition;temps parcours;approximation scheme;approximate dynamic programming;value function;stochastic model;fleet management;toma decision;tiempo recorrido;modelo estocastico;modele stochastique;logistica;duree trajet	In this paper, we present a stochastic model for the dynamic fleet management problem with random travel times. Our approach decomposes the problem into time-staged subproblems by formulating it as a dynamic program and uses approximations of the value function. In order to deal with random travel times, the state variable of our dynamic program includes all individual decisions over a relevant portion of the history. We show how to approximate the value function in a tractable manner under this new high-dimensional state variable. Under our approximation scheme, the subproblem for each time period decomposes with respect to locations, making our model very appealing for large-scale applications. Numerical work shows that the proposed approach provides high-quality solutions and performs significantly better than standard benchmark methods.	approximation algorithm;bellman equation;benchmark (computing);cobham's thesis;inbound marketing;microsoft windows;numerical method;optimization problem;powell's method;r language;social inequality	Huseyin Topaloglu	2006	European Journal of Operational Research	10.1016/j.ejor.2005.06.024	logistics;transport;mathematical optimization;simulation;economics;function approximation;computer science;stochastic modelling;operations management;dynamic programming;mathematics;bellman equation;operations research	ML	5.710967193259756	-2.9845893706508275	148213
305db5d05539d98c411e3138022e3ae8d1c45298	simulation and analysis of a circuit board manufacturing facility	performance measure;implementation;system performance;flexible manufacturing system;lot sizing;analysis;map 1;technical report;manufacturing system;simulation model;experience design	A simulation model is used to analyze the effects of various factors on the performance of a complex manufacturing system. The system under study is a large circuit board manufacturing facility. There, circuit boards are assembled and tested on a wide variety of automated machines and manual workstations. The simulation model, written in the SLAM II language, is highly detailed in the manner in which processes are modelled. This becomes especially important in modelling circuit board testing where boards which fail are repaired and recirculated through the test stations. Detailed modelling also allows for numerous process routings among the different product types to be permitted. The model possesses a demonstrated accuracy in its portrayal of the real-world situation. To make the most economical use of the model in the investigation of factor influence on system performance, experiments were conducted according to the principles of statistical experiment design. A 32-trial Hadamard design was employed to test the effects of such variables as lot size, order release schedules and quality on system performance. Performance measures included mean percent of work behind schedule, process flow time and in-process inventory levels. Significant results from these experiments are presented along with a set of guidelines, with respect to the factors investigated, which yielded favorable system performance results.	design of experiments;experiment;inventory;printed circuit board;schedule (computer science);simulation;workstation	Steven F. Shevell;John A. Buzacott;Michael J. Magazine	1986		10.1145/318242.318510	simulation;experience design;computer science;engineering;technical report;simulation modeling;analysis;computer performance;implementation;world wide web;engineering drawing	EDA	9.501575711084628	3.6131716382479464	148534
