id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
0179dabb23709df416c8bf297e1c83b62a1147fc	phylogenetic comparative assembly	health research;uk clinical guidelines;biological patents;complete genome;sequence similarity;europe pubmed central;citation search;physiological cellular and medical topics;computational biology bioinformatics;uk phd theses thesis;life sciences;algorithms;bacterial genome;high throughput;phylogenetic relationship;uk research reports;medical journals;europe pmc;biomedical research;genome sequence;bioinformatics	Recent high throughput sequencing technologies are capable of generating a huge amount of data for bacterial genome sequencing projects. Although current sequence assemblers successfully merge the overlapping reads, often several contigs remain which cannot be assembled any further. It is still costly and time consuming to close all the gaps in order to acquire the whole genomic sequence. Here we propose an algorithm that takes several related genomes and their phylogenetic relationships into account to create a graph that contains the likelihood for each pair of contigs to be adjacent. Subsequently, this graph can be used to compute a layout graph that shows the most promising contig adjacencies in order to aid biologists in finishing the complete genomic sequence. The layout graph shows unique contig orderings where possible, and the best alternatives where necessary. Our new algorithm for contig ordering uses sequence similarity as well as phylogenetic information to estimate adjacencies of contigs. An evaluation of our implementation shows that it performs better than recent approaches while being much faster at the same time.	biopolymer sequencing;contig mapping;dna sequence rearrangement;distance;gene transfer, horizontal;genome, bacterial;graph - visual representation;library (computing);map;phylogenesis;phylogenetic tree;phylogenetics;pierre robin syndrome;projections and predictions;reading (activity);score;scoring functions for docking;sequence alignment;throughput;whole genome sequencing;algorithm	Peter Husemann;Jens Stoye	2009		10.1186/1748-7188-5-3	high-throughput screening;biology;contig;whole genome sequencing;computer science;bioinformatics;genetics;bacterial genome size	Comp.	-0.3268647374903036	-54.364326075010204	49110
405b6670a8dc13d5f934511c8ed03acf9602da7b	sampling arg of multiple populations under complex configurations of subdivision and admixture	ancestral recombination graphs;population genomics;backward simulation algorithms	MOTIVATION Simulating complex evolution scenarios of multiple populations is an important task for answering many basic questions relating to population genomics. Apart from the population samples, the underlying Ancestral Recombinations Graph (ARG) is an additional important means in hypothesis checking and reconstruction studies. Furthermore, complex simulations require a plethora of interdependent parameters making even the scenario-specification highly non-trivial.   RESULTS We present an algorithm SimRA that simulates generic multiple population evolution model with admixture. It is based on random graphs that improve dramatically in time and space requirements of the classical algorithm of single populations.Using the underlying random graphs model, we also derive closed forms of expected values of the ARG characteristics i.e., height of the graph, number of recombinations, number of mutations and population diversity in terms of its defining parameters. This is crucial in aiding the user to specify meaningful parameters for the complex scenario simulations, not through trial-and-error based on raw compute power but intelligent parameter estimation. To the best of our knowledge this is the first time closed form expressions have been computed for the ARG properties. We show that the expected values closely match the empirical values through simulations.Finally, we demonstrate that SimRA produces the ARG in compact forms without compromising any accuracy. We demonstrate the compactness and accuracy through extensive experiments.   AVAILABILITY AND IMPLEMENTATION SimRA (Simulation based on Random graph Algorithms) source, executable, user manual and sample input-output sets are available for downloading at: https://github.com/ComputationalGenomics/SimRA CONTACT: : parida@us.ibm.com   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.		Anna Paola Carrieri;Filippo Utro;Laxmi Parida	2016	Bioinformatics	10.1093/bioinformatics/btv716	biology;bioinformatics;genetics	Comp.	1.8683633394236738	-53.433318850663774	49154
4c76b9a69d66e76d5fcf95f1e31b5c6bfd9bd5a5	a decision analysis model for kegg pathway analysis	computational biology bioinformatics;algorithms;computer appl in life sciences;microarrays;bioinformatics	The knowledge base-driven pathway analysis is becoming the first choice for many investigators, in that it not only can reduce the complexity of functional analysis by grouping thousands of genes into just several hundred pathways, but also can increase the explanatory power for the experiment by identifying active pathways in different conditions. However, current approaches are designed to analyze a biological system assuming that each pathway is independent of the other pathways. A decision analysis model is developed in this article that accounts for dependence among pathways in time-course experiments and multiple treatments experiments. This model introduces a decision coefficient—a designed index, to identify the most relevant pathways in a given experiment by taking into account not only the direct determination factor of each Kyoto Encyclopedia of Genes and Genomes (KEGG) pathway itself, but also the indirect determination factors from its related pathways. Meanwhile, the direct and indirect determination factors of each pathway are employed to demonstrate the regulation mechanisms among KEGG pathways, and the sign of decision coefficient can be used to preliminarily estimate the impact direction of each KEGG pathway. The simulation study of decision analysis demonstrated the application of decision analysis model for KEGG pathway analysis. A microarray dataset from bovine mammary tissue over entire lactation cycle was used to further illustrate our strategy. The results showed that the decision analysis model can provide the promising and more biologically meaningful results. Therefore, the decision analysis model is an initial attempt of optimizing pathway analysis methodology.	biological system;bos taurus;coefficient;decision analysis;encyclopedias;experiment;gene regulatory network;genome;kegg;knowledge base;lactation;mammary gland parenchyma;microarray;pathway analysis;silo (dataset);simulation;explanation	Junli Du;Man-Lin Li;Zhifa Yuan;Mancai Guo;Jiuzhou Song;Xiaozhen Xie;Yulin Chen	2016		10.1186/s12859-016-1285-1	computational biology;biology;dna microarray;computer science;bioinformatics;data mining	Comp.	6.4305519618196065	-55.29647066426857	49248
ac368890a4fe6957cb33dae03dab3b63299be631	pluripotency of induced pluripotent stem cells	animals;cell culture techniques;pluripotency;cell differentiation;cell nucleus;cell separation;induced pluripotent stem cells;humans;cell transplantation therapy	Induced pluripotent stem (iPS) cells can be generated by forced expression of four pluripotency factors in somatic cells. This has received much attention in recent years since it may offer us a promising donor cell source for cell transplantation therapy. There has been great progress in iPS cell research in the past few years. However, several issues need to be further addressed in the near future before the clinical application of iPS cells, like the immunogenicity of iPS cells, the variability of differentiation potential and most importantly tumor formation of the iPS derivative cells. Here, we review recent progress in research into the pluripotency of iPS cells.	cell transplantation;diploid cell;heart rate variability;induced pluripotent stem cells;neoplasms;stem of plant	Chunjing Feng;Yun-Dan Jia;Xiao-Yang Zhao	2013		10.1016/j.gpb.2013.08.003	biology;stem cell;induced pluripotent stem cell;genetics;cell culture;cellular differentiation;cell potency	ML	6.056067829319384	-65.74982364488405	49254
c5fa8f701a016baf1383ce1426d4fb938dbd1312	sabmark- a benchmark for sequence alignment that covers the entire known fold space	alignement sequence;bioinformatique;alineacion secuencia;classification;similitude;space use;similarity;sequence alignment;bioinformatica;similitud;false positive;multiple;clasificacion;multiple alignment;bioinformatics	The Sequence Alignment Benchmark (SABmark) provides sets of multiple alignment problems derived from the SCOP classification. These sets, Twilight Zone and Superfamilies, both cover the entire known fold space using sequences with very low to low, and low to intermediate similarity, respectively. In addition, each set has an alternate version in which unalignable but apparently similar sequences are added to each problem.	benchmark (computing);multiple sequence alignment;scop	Ivo Van Walle;Ignace Lasters;Lode Wyns	2005	Bioinformatics	10.1093/bioinformatics/bth493	combinatorics;discrete mathematics;similarity;type i and type ii errors;biological classification;multiple sequence alignment;bioinformatics;similitude;sequence alignment;mathematics;multiple;alignment-free sequence analysis	Comp.	-3.3416972099267763	-53.46156086552836	49327
3fce5e964a4d0b351b5d52d08d72a27689f4dd2b	comparative analysis of 3d-culture system for murine neonatal heart regeneration: a systematic approach for big gene expression data		Cardiovascular diseases are the leading cause of death worldwide. Loss or dysfunction of cardiomyocytes is associated with many forms of heart disease. The adult mammalian heart has a limited regenerative ability after damage, leading to the formation of fibrotic scar tissues, hypertrophy, contractile dysfunction and ultimately, organ failure. In contrast, neonatal mammalian cardiomyocytes retain a significant replenishing potential briefly after birth. There is increasing enthusiasm to grow neonatal cardiomyocytes in 3D culture systems to artificially restore heart function. Various scaffolds and matrices are available, but the molecular and cellular mechanisms underlying proliferation and differentiation of neonatal mammalian cardiomyocytes are not very well understood. Here, we utilize a systematic strategy to analyze the extensive genome-scale gene expression profiles of two different 3D constructs. We present a comprehensive comparison that may help improve the protocols for growing cardiomyocytes in a 3D culture system.		Julia Tzu-Ya Weng;Yi-Cheng Chen;Pei-Chann Chang;Shin-Ping Huang;Yu-Wei Chiu	2014		10.1007/978-3-319-13186-3_67	heart disease;computer science;gene expression;artificial intelligence;machine learning;scar tissues;cause of death;muscle hypertrophy;bioinformatics	ML	5.472831559825498	-65.65929614925874	49521
bc477721a1a831fdb7a2a7da9785a0ad7cabad1d	semi-quantitative modeling for the effect of oxygen level on the metabolism in escherichia coli	fermentation pathway;reduction chemical cellular biophysics enzymes fermentation genetics microorganisms oxidation;escherichia coli;batch culture modeling escherichia coli enzyme and gene level regulation;ethanol;probability density function;tca cycle;respiratory pathway flux;enzyme;enzyme level regulation;oxygen level;data mining;genetics;metabolites;gene expression;kinetic theory;oxidation;enzymes;lactate;mathematical models;reduction chemical;enzyme and gene level regulation;model development;mathematical model;production;cell growth;batch culture;oxygen biochemistry equations kinetic theory mathematical model gene expression production design engineering genetics competitive intelligence;ethanol semi quantitative modeling oxygen level metabolism escherichia coli mathematical models metabolic pathways glycolysis pentose phosphate pathway tca cycle fermentation pathway enzyme level regulation metabolic pathway gene expressions respiratory pathway flux redox ratio cell growth metabolites lactate;redox ratio;metabolic pathway;semi quantitative modeling;metabolic pathway gene expressions;pentose phosphate pathway;modeling;glycolysis;microorganisms;cellular biophysics;biochemistry;metabolic pathways;metabolism;fermentation	Mathematical models for the main metabolic pathways such as glycolysis, pentose phosphate pathway, TCA cycle, fermentation pathway etc. were considered for the enzyme level regulation in E.coli. It is quite important to develop a model which can simulate the effect of oxygen level on the metabolism in practice. For this, the effect of oxygen level on the expressions of the global regulators such as arcA/B and fnr was modeled based on the experimental data. Then the effects of these gene expressions on the metabolic pathway gene expressions were incorporated in the model, where the effects of oxygen levels on PDHc and Pfl fluxes as well as the respiratory pathway flux were expressed based on the experimental data. Thus, the model could express the increase in the redox ratio, NADH/NAD as the oxygen level decreases, and in turn the activation of the fermentation pathways. The semi-quantitative model developed in the present research enables us to simulate the effect of changing the oxygen level on the cell growth and the production of the variety of metabolites such as lactate, ethanol etc.	advanced telecommunications computing architecture;gene regulatory network;network access device;semiconductor industry;simulation	Yu Matsuoka;Kazuyuki Shimizu	2009	2009 International Conference on Complex, Intelligent and Software Intensive Systems	10.1109/CISIS.2009.179	biology;biochemistry;biotechnology;microbiology	Visualization	6.548921736956849	-61.12131239202313	49571
cd7f87fab750c2e204682bd179c178b350818ba9	analysis of whole-genome microarray replicates using mixed models	statistical data analysis;fold change;mixed model;replicated data;differential expression;dependence structure;tuberculosis	MOTIVATION Microarray experiments are inherently noisy. Replication is the key to estimating realistic fold-changes despite such noise. In the analysis of the various sources of noise the dependency structure of the replication needs to be taken into account.   RESULTS We analyzed replicate data sets from a Mycobacterium tuberculosis trcS mutant in order to identify differentially expressed genes and suggest new methods for filtering and normalizing raw array data and for imputing missing values. Mixed ANOVA models are applied to quantify the various sources of error. Such analysis also allows us to determine the optimal number of samples and arrays. Significance values for differential expression are obtained by a hierarchical bootstrapping scheme on scaled residuals. Four highly upregulated genes, including bfrB, were analyzed further. We observed an artefact, where transcriptional readthrough from these genes led to apparent upregulation of adjacent genes.   AVAILABILITY All methods and data discussed are available in the package YASMAhttp://www.cryst.bbk.ac.uk/wernisch/yasma.html for the statistical data analysis system R (http://www.R-project.org).	consistency model;estimated;experiment;ibm system r;microarray;missing data;mixed model;morphologic artifacts;mycobacterium tuberculosis;r language;self-replicating machine;transcription, genetic;visual artifact;transcription antitermination	Lorenz Wernisch;Sharon L. Kendall;Shamit Soneji;Andreas Wietzorrek;Tanya Parish;Jason Hinds;Philip D. Butcher;Neil G. Stoker	2003	Bioinformatics	10.1093/bioinformatics/19.1.53	mixed model;gene chip analysis;computer science;bioinformatics;data mining;statistics	Comp.	4.332008767305704	-52.98821078025735	49596
5c32a7606d60a5c1402b4f74950240acde619ed2	chloroplast genes transferred to the nuclear plant genome have adjusted to nuclear base composition and codon usage	plants;spermatophyta;vegetal;maize;gramineae;base composition;angiospermae;gene transfer;plastids;genome organization;estudio comparativo;cell nucleus;codon;articulo;evolucion;organizacion genoma;chloroplaste;cloroplasto;secuencia nucleotido;chloroplasts;dna cloroplastico;dna chloroplastique;nucleotide sequences;triticum aestivum;nucleotide sequence;chloroplast genetics;sequence nucleotide;etude comparative;zea mays;leguminosae;biological evolution;tobacco;comparative study;monocotyledones;peas;wheat;dicotyledones;vegetals;codon usage;genes plant;organisation genome;solanaceae;biotechnology;nicotiana tabacum;chloroplast;chloroplast dna;evolution;pisum sativum	During plant evolution, some plastid genes have been moved to the nuclear genome. These transferred genes are now correctly expressed in the nucleus, their products being transported into the chloroplast. We compared the base compositions, the distributions of some dinucleotides and codon usages of transferred, nuclear and chloroplast genes in two dicots and two monocots plant species. Our results indicate that transferred genes have adjusted to nuclear base composition and codon usage, being now more similar to the nuclear genes than to the chloroplast ones in every species analyzed.	base composition;cell nucleus;chloroplasts;genes, chloroplast;genome, plant;liliopsida;plastids	José L. Oliver;A. Marin;José Miguel Martínez-Zapater	1990	Nucleic acids research	10.1093/nar/18.1.65	biology;botany;nuclear gene;chloroplast;genetics	Comp.	3.8850646831477524	-63.50029970386354	49626
4ac056e60f25f17328dae218f0d12a6a724cc40a	toward robust qspr models: synergistic utilization of robust regression and variable elimination	robust pls;variable elimination;robust statistics;variable selection;robust pca;qspr;ive pls;robust regression	Widely used regression approaches in modeling quantitative structure-property relationships, such as PLS regression, are highly susceptible to outlying observations that will impair the prognostic value of a model. Our aim is to compile homogeneous datasets as the basis for regression modeling by removing outlying compounds and applying variable selection. We investigate different approaches to create robust, outlier-resistant regression models in the field of prediction of drug molecules' permeability. The objective is to join the strength of outlier detection and variable elimination increasing the predictive power of prognostic regression models. In conclusion, outlier detection is employed to identify multiple, homogeneous data subsets for regression modeling.		Rainer Grohmann;Torsten Schindler	2008	Journal of computational chemistry	10.1002/jcc.20831	variable elimination;robust statistics;econometrics;quantitative structure–activity relationship;feature selection;robust regression;statistics	ML	7.102252358189729	-52.710147836593464	49666
8ba99d6bde9bd5b509cf4f1744179ee45a4257c4	a model-independent approach to infer hierarchical codon substitution dynamics	evolution molecular;genomics;sequences;phylogeny;order;food web;amino acid;codon;origin;gene regulatory networks;genetic regulatory network;dynamic system;amino acid substitution;genetic code;classification;higher order;computational biology bioinformatics;protein evolution;models genetic;markov model;proteins;molecular biology;biological systems;amino acids;algorithms;patterns;combinatorial libraries;coarse grained;computer appl in life sciences;mutation;microarrays;protein interaction network;bioinformatics	"""Codon substitution constitutes a fundamental process in molecular biology that has been studied extensively. However, prior studies rely on various assumptions, e.g. regarding the relevance of specific biochemical properties, or on conservation criteria for defining substitution groups. Ideally, one would instead like to analyze the substitution process in terms of raw dynamics, independently of underlying system specifics. In this paper we propose a method for doing this by identifying groups of codons and amino acids such that these groups imply closed dynamics. The approach relies on recently developed spectral and agglomerative techniques for identifying hierarchical organization in dynamical systems. We have applied the techniques on an empirically derived Markov model of the codon substitution process that is provided in the literature. Without system specific knowledge of the substitution process, the techniques manage to """"blindly"""" identify multiple levels of dynamics; from amino acid substitutions (via the standard genetic code) to higher order dynamics on the level of amino acid groups. We hypothesize that the acquired groups reflect earlier versions of the genetic code. The results demonstrate the applicability of the techniques. Due to their generality, we believe that they can be used to coarse grain and identify hierarchical organization in a broad range of other biological systems and processes, such as protein interaction networks, genetic regulatory networks and food webs."""	amino acid substitution;amino acids;biological system;codon (nucleotide sequence);dynamical system;gene regulatory network;genetic code;hereditary diseases;inference;markov chain;markov model;molecular biology;relevance;version	Olof Görnerup;Martin Nilsson Jacobi	2009		10.1186/1471-2105-11-201	biology;genomics;amino acid;bioinformatics;genetic code;genetics	Comp.	4.052047007762955	-59.59007348278825	49724
36311748f02802c608f295f9d2abbb414898d3b3	soybean knowledge base (soykb): bridging the gap between soybean translational genomics and breeding	genomics;bioinformatics genomics data visualization knowledge based systems proteomics browsers;metabolomics;molecular configurations;rna bioinformatics cellular biophysics genomics knowledge based systems molecular configurations polymorphism proteins proteomics;database;browsers;rna;proteins;glycine max;polymorphism;data visualization;soybean;snp database soybean glycine max genomics transcriptomics proteomics metabolomics traits phenotype;transcriptomics;proteomics;phenotype;traits;cellular biophysics;knowledge based systems;soykb soybean knowledge base soybean translational genomics soybean translational breeding genome scale data genomic sequence transcriptomics microarray rna seq proteomics metabolomics datasets informatics resources web resource soybean genomics integration gene function annotations affymetrix probe id search multiple gene metabolite analysis protein 3d structure user friendly web interface genome browser graphical chromosome germplasm information genomic variation data single nucleotide polymorphisms genome wide association studies data gwas data multiomics experimental data;bioinformatics;snp	Many genome-scale data are available in soybean including genomic sequence, transcriptomics (microarray, RNA-seq), proteomics and metabolomics datasets, together with growing knowledge of soybean in gene, microRNAs, pathways, and phenotypes. This represents rich and resourceful information which can provide valuable insights, if mined in an innovative and integrative manner and thus, the need for informatics resources to achieve that. Towards this we have developed Soybean Knowledge Base (SoyKB), a comprehensive all-inclusive web resource for soybean translational genomics and breeding. SoyKB handles the management and integration of soybean genomics and multi-omics data along with gene function annotations, biological pathway and trait information. It has many useful tools including Affymetrix probelD search, gene family search, multiple gene/metabolite analysis, motif analysis tool, protein 3D structure viewer and download/upload capacity for experimental data and annotations. It has a user-friendly web interface together with genome browser and pathway viewer, which display data in an intuitive manner to the soybean researchers, breeders and consumers. SoyKB has new innovative tools for soybean breeding including a graphical chromosome visualizer targeted towards ease of navigation for breeders. It integrates QTLs, traits, germplasm information along with genomic variation data such as single nucleotide polymorphisms (SNPs) and genome-wide association studies (GWAS) data from multiple genotypes, cultivars and G. soja. QTLs for multiple traits can be queried and visualized in the chromosome visualizer simultaneously and overlaid on top of the genes and other molecular markers as well as multi-omics experimental data for meaningful inferences.	breeder (cellular automaton);bridging (networking);computational genomics;cooperative breeding;download;gene family;gene regulatory network;graphical user interface;informatics;knowledge base;metabolomics;microarray;mined;molecular marker;motif;omics;proteomics;upload;usability;web resource	Trupti Joshi;Michael R. Fitzpatrick;Shiyuan Chen;Yang Liu;Hongxin Zhang;Ryan Z. Endacott;Eric C. Gaudiello;Gary Stacey;Henry T. Nguyen;Dong Xu	2013	2013 IEEE International Conference on Bioinformatics and Biomedicine	10.1109/BIBM.2013.6732755	biology;polymorphism;genomics;rna;transcriptome;biotechnology;computer science;bioinformatics;snp;metabolomics;phenotype;proteomics;genetics;data visualization	Comp.	-1.8013879632028305	-58.80125992503127	49811
c15496ec08fa346c36e65b46d83a4bb316063b60	human metallothionein-specific riboprobes	transcription genetic;genes;investigation method;metalotioneina;methode etude;metallothioneine;hombre;metallothionein;gene expression;expression genique;metodo estudio;dna restriction enzymes;human;humans;expresion genetica;homme;cell line	In human, metallothioneins (MTs) are represented by a family of genes. All of the functional MT genes have a PvuII site 10 nucleotides upstream from the translational stop codon. MT-specific 3'-probes have been generated using this PvuII site and other restriction sites located 300-400 nucleotides downstream. With nicktranslated probe (panel 1), induction of MTI-G gene in response to metals was observed in HepG2, but not in the Wi-L2 cells. However, using riboprobe induction of MTI-G mRNA was observed in both cell lines (panel 2). There is a partially homologous (34 nucleotides, 70% G+C) region between MTI-G and MTII-A near the PvuII site. We deleted this portion from all of the three probes viz., MTI-F(l), MTI-G(2) and MTII-A. MTI-G riboprobe prepared from this did not show any hybridization in case of the Wi-L2 cells (panel 3). Since Tm of RNA:RNA duplex increases by 0.93°C per percent increase in G+C in contrast to 0.41°C for DNA (3), the deleted portion had about 30°C higher Tm than the rest of the untranslated sequence (30-35% G+C) and led to non-specific hybridization to MT-IIA. This finding may have general implications when studying the expression of any multigene family using riboprobes.	codon (nucleotide sequence);codon, terminator;cultured cell line;deletion (action);downstream (software development);duplex (telecommunications);gene family;genetic translation process;homology (biology);mcat gene;mti-ii;mathematical induction;metallothionein;metals;moving target indication;nucleic acid hybridization;nucleotides;rna;viz: the computer game	C. Sadhu;N. Jahroudi;L. Gedamu	1987	Nucleic acids research	10.1093/nar/15.13.5491	biology;molecular biology;gene expression;metallothionein;gene;genetics;cell culture	Comp.	4.291023040666597	-63.79191258491325	49856
ecb9792bf8f60852d42c90b37ebaa7f6d902652f	a knowledge-driven probabilistic framework for the prediction of protein-protein interaction networks	bayesian network;protein protein interaction network;machine and statistical learning;data integrity;bayesian approach;omic datasets;receiver operator characteristic;domain knowledge;area under the curve;statistical learning;false positive rate;assessment methods;functional genomics;protein protein interaction;true positive;roc curve;protein protein interaction networks;computational systems biology	This study applied a knowledge-driven data integration framework for the inference of protein-protein interactions (PPI). Evidence from diverse genomic features is integrated using a knowledge-driven Bayesian network (KD-BN). Receiver operating characteristic (ROC) curves may not be the optimal assessment method to evaluate a classifier's performance in PPI prediction as the majority of the area under the curve (AUC) may not represent biologically meaningful results. It may be of benefit to interpret the AUC of a partial ROC curve whereby biologically interesting results are represented. Therefore, the novel application of the assessment method referred to as the partial ROC has been employed in this study to assess predictive performance of PPI predictions along with calculating the True positive/false positive rate and true positive/positive rate. By incorporating domain knowledge into the construction of the KD-BN, we demonstrate improvement in predictive performance compared with previous studies based upon the Naive Bayesian approach.	addresses (publication format);algorithm;area under curve;bayesian network;brilliant black bn leukotriene release:mcnc:pt:wbc:qn;computation;constraint satisfaction;drug delivery systems;inference;lu decomposition;leucaena pulverulenta;myo5c gene;machine learning;markov chain monte carlo;maxima and minima;maximum;monte carlo method;np-hardness;naive bayes classifier;overfitting;pixel density;problem solving;proof-carrying code;proton pump inhibitors;rats, inbred bn;receiver operating characteristic;receiver operator characteristics;receiver operating characteristic;sdha wt allele;silo (dataset);protein protein interaction;receptor operated channel	Fiona Browne;Haiying Wang;Huiru Zheng;Francisco Azuaje	2010	Computers in biology and medicine	10.1016/j.compbiomed.2010.01.002	computer science;machine learning;pattern recognition;data mining;receiver operating characteristic;statistics	AI	8.450700431567753	-52.633060199417834	49959
372a82e3dc58193b6ad922bb10666ac8ec0757f6	tools for loading medline into a local relational database	software;extensible markup language;software tool;programming language;national library of medicine;information extraction;text mining;medline;database management systems;large dataset;databases bibliographic;text analysis;application program interface;relational database;computational biology bioinformatics;software package;algorithms;difference set;user computer interface;combinatorial libraries;software design;software validation;computer appl in life sciences;database management system;natural language processing;microarrays;bioinformatics	Researchers who use MEDLINE for text mining, information extraction, or natural language processing may benefit from having a copy of MEDLINE that they can manage locally. The National Library of Medicine (NLM) distributes MEDLINE in eXtensible Markup Language (XML)-formatted text files, but it is difficult to query MEDLINE in that format. We have developed software tools to parse the MEDLINE data files and load their contents into a relational database. Although the task is conceptually straightforward, the size and scope of MEDLINE make the task nontrivial. Given the increasing importance of text analysis in biology and medicine, we believe a local installation of MEDLINE will provide helpful computing infrastructure for researchers. We developed three software packages that parse and load MEDLINE, and ran each package to install separate instances of the MEDLINE database. For each installation, we collected data on loading time and disk-space utilization to provide examples of the process in different settings. Settings differed in terms of commercial database-management system (IBM DB2 or Oracle 9i), processor (Intel or Sun), programming language of installation software (Java or Perl), and methods employed in different versions of the software. The loading times for the three installations were 76 hours, 196 hours, and 132 hours, and disk-space utilization was 46.3 GB, 37.7 GB, and 31.6 GB, respectively. Loading times varied due to a variety of differences among the systems. Loading time also depended on whether data were written to intermediate files or not, and on whether input files were processed in sequence or in parallel. Disk-space utilization depended on the number of MEDLINE files processed, amount of indexing, and whether abstracts were stored as character large objects or truncated. Relational database (RDBMS) technology supports indexing and querying of very large datasets, and can accommodate a locally stored version of MEDLINE. RDBMS systems support a wide range of queries and facilitate certain tasks that are not directly supported by the application programming interface to PubMed. Because there is variation in hardware, software, and network infrastructures across sites, we cannot predict the exact time required for a user to load MEDLINE, but our results suggest that performance of the software is reasonable. Our database schemas and conversion software are publicly available at http://biotext.berkeley.edu .	abstract summary;application programming interface;computation (action);database schema;inclusion body myositis (disorder);indexes;information extraction;java programming language;medline;markup language;maxillary left central incisor implant;national library of medicine (u.s.);natural language processing;netware loadable module;parsing;perl;pubmed;relational database management system;text mining;version;xml;contents - htmllinktype	Diane E. Oliver;Gaurav Bhalotia;Ariel S. Schwartz;Russ B. Altman;Marti A. Hearst	2004	BMC Bioinformatics	10.1186/1471-2105-5-146	verification and validation;text mining;xml;dna microarray;application programming interface;relational database;computer science;bioinformatics;software design;data mining;database;information retrieval;difference set	DB	-4.026445574167341	-61.54687501737822	50069
81ac2275293f289b72a29374214c8e0ff568d50b	master regulators used as breast cancer metastasis classifier	molecular mechanics;breast cancer;computational systems biology;gene expression profiling;biometry;algorithms;phenotype;systems biology	Computational identification of prognostic biomarkers capable of withstanding follow-up validation efforts is still an open challenge in cancer research. For instance, several gene expression profiles analysis methods have been developed to identify gene signatures that can classify cancer sub-phenotypes associated with poor prognosis. However, signatures originating from independent studies show only minimal overlap and perform poorly when classifying datasets other than the ones they were generated from. In this paper, we propose a computational systems biology approach that can infer robust prognostic markers by identifying upstream Master Regulators, causally related to the presentation of the phenotype of interest. Such a strategy effectively extends and complements other existing methods and may help further elucidate the molecular mechanisms of the observed pathophysiological phenotype. Results show that inferred regulators substantially outperform canonical gene signatures both on the original dataset and across distinct datasets.	antivirus software;biological markers;breast carcinoma;classification;complement (complexity);complement system proteins;electronic signature;gene expression profiling;inference;metastatic neoplasm;neoplasms;phenotype;prognostic variable;silo (dataset);systems biology	Wei Keat Lim;Eugenia Lyashenko;Andrea Califano	2009	Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing		biology;molecular mechanics;bioinformatics;breast cancer;phenotype;gene expression profiling;genetics;systems biology	Comp.	7.1302929905208305	-55.484666000787335	50097
6364d8b6a544c55dd2e4a616f8b4b9a06fd09c30	network-based analysis of reverse phase protein array data	microprocessors;arrays;data analysis;proteins;breast cancer;protein engineering	In this paper, we introduce a computational method for constructing networks based on reverse phase protein array (RPPA) data to identify complex patterns in protein signaling. The method is applied to phosphoproteomic profiles of basal expression and activation/phosphorylation of 76 key signaling proteins in three breast cancer cell lines (MCF7, LCC1, and LCC9). Temporal RPPA data are acquired at 48h, 96h, and 144h after knocking down four genes in separate experiments. These genes are selected from a previous study as important determinants for breast cancer survival. Interaction networks between the proteins and phosphorylated proteins are constructed by analyzing the expression levels of protein pairs using a multivariate analysis of variance model. A new scoring criterion is introduced to determine the proteins that changed significantly at each of the three time points. Signaling networks are constructed based on statistically significant protein pairs selected from the RPPA data. Through a topology based analysis, we search for wiring patterns to help identify key network nodes that are associated with protein expression changes in various experimental conditions.	basal (phylogenetics);cell signaling;experiment;port knocking;reverse phase protein lysate microarray;wiring	Rency S. Varghese;Yiming Zuo;Yi Zhao;Yong-Wei Zhang;Sandra A. Jablonski;Mariaelena Pierobon;Emanuel F. Petricoin;Habtom W. Ressom;Louis M. Weiner	2016	2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2016.7822538	biology;molecular biology;bioinformatics;breast cancer;data mining;protein engineering;data analysis	Comp.	3.77047430977784	-57.851951713475714	50151
8acb67a7bc13e602e14b861d8b08a77c01b54df5	simulating cortical development as a self constructing process: a novel multi-scale approach combining molecular and physical aspects	cell movement;animals;models neurological;610 medicine health;axons;gene regulatory networks;neurogenesis;cell shape;dendrites;computational biology;cats;computer simulation;visual cortex	Current models of embryological development focus on intracellular processes such as gene expression and protein networks, rather than on the complex relationship between subcellular processes and the collective cellular organization these processes support. We have explored this collective behavior in the context of neocortical development, by modeling the expansion of a small number of progenitor cells into a laminated cortex with layer and cell type specific projections. The developmental process is steered by a formal language analogous to genomic instructions, and takes place in a physically realistic three-dimensional environment. A common genome inserted into individual cells control their individual behaviors, and thereby gives rise to collective developmental sequences in a biologically plausible manner. The simulation begins with a single progenitor cell containing the artificial genome. This progenitor then gives rise through a lineage of offspring to distinct populations of neuronal precursors that migrate to form the cortical laminae. The precursors differentiate by extending dendrites and axons, which reproduce the experimentally determined branching patterns of a number of different neuronal cell types observed in the cat visual cortex. This result is the first comprehensive demonstration of the principles of self-construction whereby the cortical architecture develops. In addition, our model makes several testable predictions concerning cell migration and branching mechanisms.	axon;behavior;cellular organizational structure;cerebral cortex;clinical act of insertion;cortical implant;dendrites;developmental process;embryonic development;experiment;formal language;gene expression;lineage (evolution);migration, cell;population;projections and predictions;simulation;stem cells	Frederic Zubler;Andreas Hauri;Sabina S. Pfister;Roman Bauer;John C. Anderson;Adrian M. Whatley;Rodney J. Douglas	2013		10.1371/journal.pcbi.1003173	computer simulation;computational biology;biology;gene regulatory network;neurogenesis;neuroscience;bioinformatics	ML	6.668283686704726	-66.14667261682214	50177
983c35752dfd8acec38721725fb83f4c24cf439f	alzheimer's disease target selection: a data integration approach	gene expression profile;sirna;amyloid β;pathway analysis;expression profile;human disease;data integrity;mouse model;gene expression data;target selection;tau protein;expression profiling;alzheimer s disease;tg4510;experimental validation;target tracking;scoring matrix;human brain;apoe;data integration	The integration of information across carefully selected species and experimental platforms is emerging as a powerful technique for selecting potential therapeutic targets for human diseases: this method enables a holistic view of the experimental landscape and hence of the disease. Alzheimer's disease (AD), which affects an estimated 5.3 million patients, is characterized by Amyloid-β plaques and neurofibril tangles made up of Tau aggregated protein in different regions of the brain. Current therapies produce only a minimal impact on the progression of the disease. Here we present a method that integrates gene expression profiling data from an AD mouse model (Tg4510) with in vitro cell assays plus gene expression data from different brain regions from several normal human brains as well as those displaying different degrees of AD pathology to provide a mechanism for target selection. Pathway analysis is used to put the targets into biological context, including established signaling cascades, and explore other potential novel targets. A target scoring and tracking mechanism is used to assist in new target selection and monitor the progress of the targets through several experimental validation assays.	alzheimer's disease neuroimaging initiative;color gradient;gene expression profiling;holism;pathway analysis	Bradley W. Poland;Panayiotis Zagouras;Snehal Naik;Eric Fauman;Karl Richter;Robert M. Peitzsch	2010		10.1145/1854776.1854870	biology;pathology;computer science;bioinformatics;rna interference;data integration;apolipoprotein e;position weight matrix;data integrity;gene expression profiling	Comp.	5.722114347892277	-58.21921516034025	50212
c5b69df179b6107a6d436f699c7b3185179d8ac3	potency-directed similarity searching using support vector machines	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;computer applications in chemistry;theoretical and computational chemistry;computational biology bioinformatics;uk phd theses thesis;life sciences;uk research reports;medical journals;europe pmc;documentation and information in chemistry;biomedical research;bioinformatics	Searching for active compounds in screening databases is one of the main tasks in chemoinformatics [1,2]. For this purpose, different approaches have been developed, with an increasing interest in machine learning and data mining methods [3]. Among these, support vector machine (SVM) learning has proven to be a powerful search technique in many instances [3]. Several applications of SVMs have been reported that focus on compound ranking in similarity searching [4-6]. However, similarity search and machine learning methods that are commonly utilized for virtual screening generally do not take compound potency information into account. Regardless of the applied methods, one typically attempts to distinguish “active” from “inactive” compounds. With the exception of QSAR models adapted for compound screening, no approaches have thus far been introduced that incorporate potency information as a parameter and direct search calculations toward the recognition of potent hits. Here, an SVM approach for potency-directed virtual screening is introduced [7]. A newly designed structure-activity kernel and an SVM linear combination model take potency information of reference molecules into account. Applied to highthroughput screening data sets, this potency-directed SVM approach met or exceeded the recall performance of standard SVM ranking and led to a notable enrichment of highly potent hits in database selection sets.	cheminformatics;data mining;database;gene ontology term enrichment;machine learning;quantitative structure–activity relationship;similarity search;support vector machine;virtual screening	Kathrin Heikamp;Anne Mai Wassermann;Jürgen Bajorath	2012	J. Cheminformatics	10.1186/1758-2946-4-S1-P12	biology;medical research;computer science;bioinformatics;data science;data mining;ranking svm	ML	9.299086212177905	-53.73912398281636	50225
3872e50402b594fd6eda929540239746aabfce1c	genesrf and varselrf: a web-based tool and r package for gene selection and classification using random forest	microarray data;software;web based applications;data interpretation statistical;prediction error;multiple solution;cluster of workstations;computational biology bioinformatics;internet;random forest;classification error;algorithms;source code;user computer interface;combinatorial libraries;classification accuracy;selection biases;gene selection;computer appl in life sciences;article;gene expression profiling;oligonucleotide array sequence analysis;microarrays;bioinformatics	Microarray data are often used for patient classification and gene selection. An appropriate tool for end users and biomedical researchers should combine user friendliness with statistical rigor, including carefully avoiding selection biases and allowing analysis of multiple solutions, together with access to additional functional information of selected genes. Methodologically, such a tool would be of greater use if it incorporates state-of-the-art computational approaches and makes source code available. We have developed GeneSrF, a web-based tool, and varSelRF, an R package, that implement, in the context of patient classification, a validated method for selecting very small sets of genes while preserving classification accuracy. Computation is parallelized, allowing to take advantage of multicore CPUs and clusters of workstations. Output includes bootstrapped estimates of prediction error rate, and assessments of the stability of the solutions. Clickable tables link to additional information for each gene (GO terms, PubMed citations, KEGG pathways), and output can be sent to PaLS for examination of PubMed references, GO terms, KEGG and and Reactome pathways characteristic of sets of genes selected for class prediction. The full source code is available, allowing to extend the software. The web-based application is available from http://genesrf2.bioinfo.cnio.es . All source code is available from Bioinformatics.org or The Launchpad. The R package is also available from CRAN. varSelRF and GeneSrF implement a validated method for gene selection including bootstrap estimates of classification error rate. They are valuable tools for applied biomedical researchers, specially for exploratory work with microarray data. Because of the underlying technology used (combination of parallelization with web-based application) they are also of methodological interest to bioinformaticians and biostatisticians.	bibliographic reference;bioinformatics;booting;central processing unit;clickable;computation;computer cluster;data table;estimated;evaluation procedure;kegg;launchpad;microarray;multi-core processor;parallel computing;patients;pubmed;r language;random forest;reactome: a database of reactions, pathways and biological processes.;rigor - temperature-associated observation;selection bias;solutions;source code;usability;web application;workstation;world wide web;citation	Ramón Díaz-Uriarte	2007	BMC Bioinformatics	10.1186/1471-2105-8-328	gene-centered view of evolution;random forest;biology;microarray analysis techniques;web application;the internet;dna microarray;computer science;bioinformatics;data science;mean squared prediction error;data mining;gene expression profiling;algorithm;source code	Comp.	-2.5236560462171136	-57.424744364652014	50230
363cc869c9621bf9fe5ef1e6880dade9d85e89b1	a web application for the unspecific detection of differentially expressed dna regions in strand-specific expression data	genetica;genomica;expressio genetica;info eu repo semantics article;adn	UNLABELLED Genomic technologies allow laboratories to produce large-scale data sets, either through the use of next-generation sequencing or microarray platforms. To explore these data sets and obtain maximum value from the data, researchers view their results alongside all the known features of a given reference genome. To study transcriptional changes that occur under a given condition, researchers search for regions of the genome that are differentially expressed between different experimental conditions. In order to identify these regions several algorithms have been developed over the years, along with some bioinformatic platforms that enable their use. However, currently available applications for comparative microarray analysis exclusively focus on changes in gene expression within known transcribed regions of predicted protein-coding genes, the changes that occur in non-predictable genetic elements, such as non-coding RNAs. Here, we present a web application for the visualization of strand-specific tiling microarray or next-generation sequencing data that allows customized detection of differentially expressed regions all along the genome in an unspecific manner, that allows identification of all RNA sequences, predictable or not.   AVAILABILITY AND IMPLEMENTATION The web application is freely accessible at http://tilingscan.uv.es/. TilingScan is implemented in PHP and JavaScript.   CONTACT vicente.arnau@uv.es   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	algorithm;bioinformatics;biopolymer sequencing;customize;dna microarray;gene expression;imagery;javascript;laboratory;massively-parallel sequencing;php;rna;strand (programming language);tiling window manager;transcription, genetic;web application;world wide web	José M. Juanes;Ana Miguel;Lucas J. Morales;José E. Pérez-Ortín;Vicente Arnau	2015	Bioinformatics	10.1093/bioinformatics/btv343	biology;bioinformatics;world wide web	Comp.	-1.5193589410387653	-58.046499020968	50247
7b9a83eb965291d42de9ffddc6cea20b2242dc83	de novo assembly of lucina pectinata genome using ion torrent reads		Lucina pectinata is a bivalve that lives in sulfide-rich environments and houses intracellular sulfide oxidizing endosymbiont. This organism is an ideal model to understand adaptive mechanisms and chemoautotrophic endosymbiosis in organisms living in sulfide-rich environments. However, only three hemoglobins have been completely characterized at protein and gene level leaving a gap in understanding the biology of this organism. In this work, we produced draft genomic assemblies with data produced by the Ion Proton Next Generation Sequencing System using both the MIRA4 and SPAdes assemblers. We compare and contrast these draft assemblies using metrics such as N50, total assembled length, number of predicted genes and other measures. We conclude that de novo assembly of eukaryotic organisms with NGS data from the Ion technology family remains complicated and may benefit from the use of multiple genome assemblers.	bittorrent;communications satellite;de novo transcriptome assembly;spades	Ingrid M. Montes-Rodríguez;Carmen L. Cadilla;Ricardo R González-Méndez;Juan López-Garriga;Alexander Ropelewski	2017		10.1145/3093338.3093362	lucina pectinata;endosymbiosis;gene;organism;computational biology;ion semiconductor sequencing;sequence assembly;genome;dna sequencing;genetics;biology	Comp.	3.4910198792967693	-62.724583225377025	50327
42b09a02a83434189cc438dcdad0a88541ff8112	astral: genome-scale coalescent-based species tree estimation	genes;animals;genomics;data interpretation statistical;phylogeny;genetic speciation;algorithms;mammals	MOTIVATION Species trees provide insight into basic biology, including the mechanisms of evolution and how it modifies biomolecular function and structure, biodiversity and co-evolution between genes and species. Yet, gene trees often differ from species trees, creating challenges to species tree estimation. One of the most frequent causes for conflicting topologies between gene trees and species trees is incomplete lineage sorting (ILS), which is modelled by the multi-species coalescent. While many methods have been developed to estimate species trees from multiple genes, some which have statistical guarantees under the multi-species coalescent model, existing methods are too computationally intensive for use with genome-scale analyses or have been shown to have poor accuracy under some realistic conditions.   RESULTS We present ASTRAL, a fast method for estimating species trees from multiple genes. ASTRAL is statistically consistent, can run on datasets with thousands of genes and has outstanding accuracy-improving on MP-EST and the population tree from BUCKy, two statistically consistent leading coalescent-based methods. ASTRAL is often more accurate than concatenation using maximum likelihood, except when ILS levels are low or there are too few gene trees.   AVAILABILITY AND IMPLEMENTATION ASTRAL is available in open source form at https://github.com/smirarab/ASTRAL/. Datasets studied in this article are available at http://www.cs.utexas.edu/users/phylo/datasets/astral.   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	bioinformatics;cardiomyopathies;concatenation;conflict (psychology);estimated;gene prediction;integrated learning system;lineage (evolution);numerous;open-source software;partial;sorting;trees (plant)	Siavash Mirarab;Rezwana Reaz;Md. Shamsuzzoha Bayzid;Théo Zimmermann;M. Shel Swenson;Tandy J. Warnow	2014		10.1093/bioinformatics/btu462	biology;genomics;bioinformatics;gene;data mining;genetics	Comp.	1.9291141453992553	-53.58323801626508	50402
54033b98eef8b744e4e4582a653d6f14e23a6cf9	small rna database	animals;plants;computer communication networks;viruses;fungi;internet;rna;genbank;world wide web;rna small nuclear;humans;molecular sequence data;bacteria;databases factual;base sequence;small rna;rna small	The small RNA database is a compilation of all the small size RNA sequences available to date, including nuclear, nucleolar, cytoplasmic and mitochondrial small RNAs from eukaryotic organisms and small RNAs from prokaryotic cells as well as viruses. Currently, about 600 small RNA sequences are in our database. It also gives the sources of individual RNAs and their GenBank accession numbers. The small RNA database can be accessed through WWW(World Wide Web). Our WWW URL address is: http://mbcr.bcm.tmc.edu/smallRNA/smallrna. html . The new small RNA sequences published since our last compilation are listed in this paper.		Jian Hua Gu;Ram Reddy	1996	Nucleic acids research	10.1093/nar/24.1.73	biology;genbank;the internet;rna;bacteria;bioinformatics;genetics	Comp.	-2.004907935105207	-60.338465271156565	50435
721a1c7b3f120a4fe8f986c203aba7096e0b8a93	lassap, a large scale sequence comparison package	software;sequence comparison;secuencia aminoacido;base donnee;proteine;sequence aminoacide;aminoacid sequence;logiciel;computerized processing;tratamiento informatico;estudio comparativo;database;base dato;methode;secuencia nucleotido;application program interface;nucleotide sequence;sequence nucleotide;algorithme;etude comparative;algorithm;large scale;performance improvement;proteins;system design;pattern matching;comparative study;software package;on the fly;logicial;proteina;acido nucleico;string matching;acide nucleique;metodo;high performance;nucleic acid;traitement informatique;method;algoritmo	MOTIVATION This paper presents LASSAP, a new software package for sequence comparison. LASSAP is a programmable, high-performance system designed to raise current limitations of sequence comparison programs in order to fit the needs of large-scale analysis. LASSAP provides an API (Application Programming Interface) allowing the integration of any generic pairwise-based algorithm.   RESULTS Whatever pairwise algorithm is used in LASSAP, it shares with all other algorithms numerous enhancements such as: (i) intra- and inter-databank comparisons; (ii) computational requests (selections and computations are achieved on the fly); (iii) frame translations on queries and databanks; (iv) structured results allowing easy and powerful post-analysis; (v) performance improvements by parallelization and the driving of specialized hardware. LASSAP currently implements all major sequence comparison algorithms (Fasta, Blast, Smith/Waterman), and other string matching and pattern matching algorithms. LASSAP is both an integrated software for end-users and a framework allowing the integration and the combination of new algorithms. LASSAP is used in different projects such as the building of PRODOM, the exhaustive comparison of yeast sequences, and the subfragments matching problem of TREMBL.	application programming interface;blast;computation;computer programming;databases;emoticon;fasta;generic drugs;integrated software;language translations;on the fly;pairwise algorithm;parallel computing;pattern matching;smith–waterman algorithm;string searching algorithm;uniprot	Eric Glémet;Jean-Jacques Codani	1997	Computer applications in the biosciences : CABIOS	10.1093/bioinformatics/13.2.137	nucleic acid;method;application programming interface;nucleic acid sequence;computer science;bioinformatics;comparative research;pattern matching;genetics;algorithm;string searching algorithm;systems design	HPC	-4.212655351895735	-55.82014436272443	50514
c180111c9f044edf988c43674291fed3b5f1705c	predictive modelling of mitochondrial spatial structure and health		Mitochondria are mobile organelles that exist in living cells as a tubular network. They continuously join the mitochondrial network by fusion and divide by fission events. Mitochondrial fission is mainly regulated by two nuclear-encoded proteins, fission protein 1 (Fis1) and dynamin related protein 1 (Drp1). Mitochondrial dynamics have been shown to be an essential quality control mechanism in order to maintain mitochondrial health. A proxy for mitochondrial health and integrity is the mitochondrial membrane potential [5]. Recent wetlab studies have shown that the mitochondrial membrane potential is disturbed by an imbalance of the mitochondrial fission proteins. It is therefore the objective of this study to develop an in silico prediction model for the influence of Fis1 and Drp1 on mitochondrial spatial structure and health.		Arne T. Bittig;Florian Reinhardt;Simone Baltrusch;Adelinde M. Uhrmacher	2014		10.1007/978-3-319-12982-2_20	predictive modelling;theoretical computer science;biophysics;mitochondrial fission;computer science;fission;rule-based modeling;fis1;mitochondrion;membrane potential;organelle	AI	4.518519088118755	-65.68198169326314	51020
2b239ed6b1ba42cf6cb47be5f8934843b30ae031	computationally inspired biotechnologies: improved dna synthesis and associative search using error-correcting codes and vector-quantization	error correcting code;molecular model;pulga de dna;procesamiento informacion;codigo corrector error;puce a dna;reaction chaine polymerase;modelo molecular;polymerase chain reaction;codificacion;cuantificacion vectorial;reaccion cadena polimerasa;vector quantization;error correction code;modele moleculaire;sintesis adn;synthese dna;information processing;coding;dna chip;vector quantizer;traitement information;code correcteur erreur;information theoretic;codage;dna synthesis;quantification vectorielle	The main theme of this paper is to take inspiration from methods used in computer science and related disciplines, and to apply these to develop improved biotechnology. In particular, our proposed improvements are made by adapting various information theoretic coding techniques which originate in computational and information processing disciplines, but which we re-tailor to work in the biotechnology context. (a) We apply Error-Correcting Codes, developed to correct transmission errors in electronic media, to decrease (in certain contexts, optimally) error rates in optically-addressed DNA synthesis (e.g., of DNA chips). (b) We apply Vector-Quantization (VQ) Coding techniques (which were previously used to cluster, quantize, and compress data such as speech and images) to improve I/O rates (in certain contexts, optimally) for transformation of electronic data to and from DNA with bounded error. (c) We also apply VQ Coding techniques, some of which hierarchically cluster the data, to improve associative search in DNA databases by reducing the problem to that of exact aanity separation. These improvements in biotechnology appear to have some general applicability beyond biomolecular computing. As a motivating example, this paper improves biotechnology methods to do associative search in DNA databases. Baum B95] previously proposed the use of biotechnology aanity methods (DNA annealing) to do massively parallel associative search in large databases encoded as DNA strands, but many remaining issues were not developed. Using in part our improved biotechnology techniques based on Error-Correction and VQ Coding, we develop detailed procedures for the following tasks: (i) The database may initially be in conventional (electronic, magnetic, or optical) media, rather than the form of DNA strands. For input and output (I/O) to and from conventional media, we apply DNA chip technology improved by Error-Correction and VQ Coding methods for error-correction and compression. ? A postscript version of this paper is at URL (ii) The query may not be an exact match or even partial match with any data in the database, but since DNA annealing aanity methods work best for these cases, we apply various VQ Coding methods for reening the associative search to exact matches. (iii) We also brieey discuss how to extend associative search queries in DNA databases to more sophisticated hybrid queries that include also Boolean formula conditionals with a bounded number of Boolean variables , by combining our methods for DNA associative search with known BMC methods for solving small size SAT problems. For example, these extended queries could …	baum–welch algorithm;computer science;dna database;dna microarray;data compression;emoticon;error detection and correction;information processing;information theory;input/output;integrated circuit;postscript;quantization (signal processing);simulated annealing;vector quantization;web search query	John H. Reif;Thomas H. LaBean	2000		10.1007/3-540-44992-2_11	computer science;bioinformatics;theoretical computer science;algorithm	ML	-3.586848000021464	-52.972673665083605	51123
4447455910be07a6ec3046ce1f3a706925c1548c	isolation and identification of vibrio rotiferianus from diseased half-smooth tongue sole (cynoglossus semilaevis günther)	suspensions;drugs;extracellular proucts cynoglossus semilaevis vibrio rotiferianus 16s rrna gene gyrb gene;strain tongue microorganisms pathogens marine animals extracellular phylogeny;molecular phylogenetics;tetracycline bacteria isolation bacteria identification vibrio rotiferianus diseased half smooth tongue sole cynoglossus semilaevis günther skin ulcers bacterial strain bv1 pathogen muscle injection bacteria suspension morphological characteristics physiological characteristics biochemical characteristics 16s rrna gene gyrb gene gene sequences genebank molecular phylogenetic trees extracellular products hemolysin amylase lipase urease lecithinase β haemolysis defibrinated rabbit blood proteinase gelatinase drug resistance streptomycin;molecular configurations;skin;molecular identification;suspensions biochemistry blood cellular biophysics diseases drugs enzymes genetics microorganisms molecular biophysics molecular configurations muscle skin;genetics;enzymes;blood;molecular biophysics;antimicrobial agent;diseases;drug resistance;microorganisms;cellular biophysics;biochemistry;muscle	Four strains dominant bacteria associated with skin ulcers were isolated from half-smooth tongue sole, Cynoglossus semilaevis. Bacterial strain BV1 was proved to be a pathogen by muscle injection with bacteria suspension, the LD50 was 1.5×105 cfu/mL. The morphological, physiological and biochemical characteristics were examined, the 16S rRNA and gyrB gene were partially sequenced and compared with sequences deposited in genebank, and the molecular phylogenetic trees were constructed. The sequenced 16S rRNA gene of strain BV1 (GenBank accession No. JN391272) is 1379bp in length, the sequenced gyrB gene of strain BV1 (GenBank accession No. JN 168882) is 1130bp in length, and gyrB gene exhibited high similarity in 99% with the gyrB gene of Vibrio rotiferianus from GenBank database. The results of physiological and biochemical tests and molecular identification suggested that the pathogen was V. rotiferianus. Detection of the activity of extracellular products (ECP) and hemolysin showed that the strain BV1 could produced amylase, lipase, urease, lecithinase, and with β-haemolysis in containing 4% defibrinated rabbit blood of TSA plates, but no proteinase, gelatinase. Drug resistance of the pathogen to 17 antimicrobial agents were detected, the results showed that the strain was sensitive to streptomycin, tetracycline and so on.	accession number (bioinformatics);genbank;johnson–nyquist noise;molecular phylogenetics;phylogenetic tree	Zhengqiang Chen;Zhixian Yao;Mao Lin;Jianbo Chang	2011	2011 4th International Conference on Biomedical Engineering and Informatics (BMEI)	10.1109/BMEI.2011.6098731	biology;biochemistry;enzyme;molecular biology;muscle;drug resistance;antimicrobial;skin;microorganism;molecular phylogenetics;microbiology;molecular biophysics	Visualization	4.576041394356597	-63.8592850738907	51125
f983cbcbbd3f6dcd2e5f1728e6a89b59b38a76ad	specific and cooperative binding of e. coli single-stranded dna binding protein to mrna	dna monocatenario;escherichia coli;inhibicion;single stranded dna;dna binding proteins;rna mensajero;interaction moleculaire;rna messenger;bacterie;molecular interaction;dna monocatenaire;binding sites;dna single stranded;regulation control;binding molecular function;plasmids;enterobacteriaceae;rna messager;gene expression;traduction;expression genique;interaccion molecular;escherichieae;single stranded dna binding protein;translation;titration method;gene expression regulation;messenger rna;proteine de liaison dna;protein binding;regulation;traduccion;carrier proteins;bacteria;inhibition;proteina de enlace dna;regulacion;expresion genetica;dna binding protein	Fluorometric titration of E. coli single-stranded DNA binding protein with various RNAs showed that the protein specifically and cooperatively binds to its own mRNA. The binding inhibited in vitro expression of ssb and bla but not nusA. This inhibition takes place at a physiological concentration of SSB. The function of the protein in gene regulation is discussed.	cooperative mimo;dna breaks, single-stranded;dna binding site;super smash bros.;titration method	Nobuo Shimamoto;N. Ikushima;H. Utiyama;H. Tachibana;K. Horie	1987	Nucleic acids research	10.1093/nar/15.13.5241	biology;dna-binding protein;molecular biology;hmg-box;bioinformatics;genetics;binding protein	Comp.	3.9485015083220545	-64.11818932986336	51144
d6dd44a0190693721a307190e1feddedc5129b17	predicting disordered regions in proteins based on decision trees of reduced amino acid composition	disordered region;decision tree;protein trafficking;amino acid composition;intrinsically unstructured proteins;reduced amino acid composition	Intrinsically unstructured proteins (IUPs) are proteins lacking a fixed three dimensional structure or containing long disordered regions. IUPs play an important role in biology and disease. Identifying disordered regions in protein sequences can provide useful information on protein structure and function, and can assist high-throughput protein structure determination. In this paper we present a system for predicting disordered regions in proteins based on decision trees and reduced amino acid composition. Concise rules based on biochemical properties of amino acid side chains are generated for prediction. Coarser information extracted from the composition of amino acids can not only improve the prediction accuracy but also increase the learning efficiency. In cross-validation tests, with four groups of reduced amino acid composition, our system can achieve a recall of 80% at a 13% false positive rate for predicting disordered regions, and the overall accuracy can reach 83.4%. This prediction accuracy is comparable to most, and better than some, existing predictors. Advantages of our approach are high prediction accuracy for long disordered regions and efficiency for large-scale sequence analysis. Our software is freely available for academic use upon request.	advanced audio coding;amino acid sequence;amino acids;celf proteins;cross reactions;cross-validation (statistics);decision trees;decision tree model;extraction;high-throughput computing;intrinsically disordered proteins;peptide sequence;protein, organized by structure;rule (guideline);sequence analysis;throughput;trees (plant);polarity	Pengfei Han;Xiuzhen Zhang;Raymond S. Norton;Zhi-Ping Feng	2006	Journal of computational biology : a journal of computational molecular cell biology	10.1089/cmb.2006.13.1723	biology;biochemistry;computer science;bioinformatics;machine learning;decision tree	Comp.	9.12689755029121	-56.33625234020094	51206
04a51b7df5774fa3077541b5706c16c245d09709	exploring drug space with chemmaps.com		Motivation Easily navigating chemical space has become more important due to the increasing size and diversity of publicly-accessible databases such as DrugBank, ChEMBL or Tox21. To do so, modelers typically rely on complex projection techniques using molecular descriptors computed for all the chemicals to be visualized. However, the multiple cheminformatics steps required to prepare, characterize, compute and explore those molecules, are technical, typically necessitate scripting skills, and thus represent a real obstacle for non-specialists.   Results We developed the ChemMaps.com webserver to easily browse, navigate and mine chemical space. The first version of ChemMaps.com features more than 8000 approved, in development, and rejected drugs, as well as over 47 000 environmental chemicals.   Availability and implementation The webserver is freely available at http://www.chemmaps.com.	browsing;chembl;chemical space;cheminformatics;database;databases;drugbank;molecular descriptor;web server	Alexandre Borrel;Nicole C. Kleinstreuer;Denis Fourches	2018	Bioinformatics	10.1093/bioinformatics/bty412	data science;drug;data mining;computer science	Comp.	-3.2989294501568605	-59.448926271585385	51314
98a8f2f6b66004dca753b6669623446e4107f0fd	gene characteristics predicting missense, nonsense and frameshift mutations in tumor samples	cosmic;cancer genes;catalog of somatic mutations in cancer;frameshift mutations;missense;nonsense;somatic mutations	Because driver mutations provide selective advantage to the mutant clone, they tend to occur at a higher frequency in tumor samples compared to selectively neutral (passenger) mutations. However, mutation frequency alone is insufficient to identify cancer genes because mutability is influenced by many gene characteristics, such as size, nucleotide composition, etc. The goal of this study was to identify gene characteristics associated with the frequency of somatic mutations in the gene in tumor samples. We used data on somatic mutations detected by genome wide screens from the Catalog of Somatic Mutations in Cancer (COSMIC). Gene size, nucleotide composition, expression level of the gene, relative replication time in the cell cycle, level of evolutionary conservation and other gene characteristics (totaling 11) were used as predictors of the number of somatic mutations. We applied stepwise multiple linear regression to predict the number of mutations per gene. Because missense, nonsense, and frameshift mutations are associated with different sets of gene characteristics, they were modeled separately. Gene characteristics explain 88% of the variation in the number of missense, 40% of nonsense, and 23% of frameshift mutations. Comparisons of the observed and expected numbers of mutations identified genes with a higher than expected number of mutations– positive outliers. Many of these are known driver genes. A number of novel candidate driver genes was also identified. By comparing the observed and predicted number of mutations in a gene, we have identified known cancer-associated genes as well as 111 novel cancer associated genes. We also showed that adding the number of silent mutations per gene reported by genome/exome wide screens across all cancer type (COSMIC data) as a predictor substantially exceeds predicting accuracy of the most popular cancer gene predicting tool - MutsigCV.	cosmic;clone;conserved sequence;diploid cell;exome;frameshift mutation function;genes, vif;immutable object;kerrison predictor;linear iga bullous dermatosis;neoplasms;nonsense mutation;nucleotides;silent mutation;somatic mutation;stepwise regression;subgroup;algorithm	Ivan P. Gorlov;Claudio W. Pikielny;H. Robert Frost;Stephanie C. Her;Michael D. Cole;Samuel D. Strohbehn;David Wallace-Bradley;Marek Kimmel;Olga Y. Gorlova;Christopher I. Amos	2018		10.1186/s12859-018-2455-0		Comp.	3.8435432393886733	-60.847342426501875	51338
3463e7353c41cf01d4a339788d2e16d937b72ce7	dupliphy-web: a web server for dupliphy and dupliphy-ml	evolution molecular;software;phylogeny;gene duplication;internet;likelihood functions;humans;computational biology	SUMMARY Gene duplication and loss are important processes in the evolution of gene families. Moreover, growth of families by duplication and retention is an important mechanism by which organisms gain new functions. Therefore the ability to infer the evolutionary histories of families is an important step in understanding the evolution of function. We have recently developed DupliPHY, a software tool to infer gene family histories using parsimony and maximum likelihood. Here, we present DupliPHY-Web a web server for DupliPHY that implements additional maximum likelihood functionality and provides users an intuitive interface to run DupliPHY.   AVAILABILITY AND IMPLEMENTATION DupliPHY-Web is available at www.bioinf.manchester.ac.uk/dupliphy/   CONTACT : ryan.ames@manchester.ac.uk   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	bioinformatics;gene duplication abnormality;gene family;inference;interface device component;maximum parsimony (phylogenetics);occam's razor;programming tool;server (computer);server (computing);web server	Ryan M. Ames;Simon C. Lovell	2015		10.1093/bioinformatics/btu645	biology;the internet;bioinformatics;genetics;gene duplication;phylogenetics	Comp.	-0.6964222775970443	-58.603712400701234	51441
c217ed7a1b36490d9cf74239ca64e9b66994cbb7	non-repetitive dna sequence compression using memoization	compression algorithm;computer science information science engineering;text compression;repetitive dna;statistical inference;compression ratio;repetitive sequence;dna sequence;memoization;dna compression	With increasing number of DNA sequences being discovered the problem of storing and using genomic databases has become vital. Since DNA sequences consist of only four letters, two bits are sufficient to store each base. Many algorithms have been proposed in the recent past that push the bits/base limit further. The subtle patterns in DNA along with statistical inferences have been exploited to increase the compression ratio. From the compression perspective, the entire DNA sequences can be considered to be made of two types of sequences: repetitive and non-repetitive. The repetitive parts are compressed used dictionary-based schemes and non-repetitive sequences of DNA are usually compressed using general text compression schemes. In this paper, we present a memoization based encoding scheme for non-repeat DNA sequences. This scheme is incorporated with a DNA-specific compression algorithm, DNAPack, which is used for compression of DNA sequences. The results show that our method noticeably performs better than other techniques of its kind.		K. G. Srinivasa;M. Jagadish;K. R. Venugopal;Lalit M. Patnaik	2006		10.1007/11946465_36	computer science;bioinformatics;theoretical computer science;algorithm	ML	-3.3021148159893876	-52.519393973835	51567
489964032096b7bd79541c40709c98c7264bb47e	modular prediction of protein structural classes from sequences of twilight-zone identity with predicting sequences	numerical method;protein sequence;structure function;computational biology bioinformatics;protein structure;proteins;protein conformation;secondary structure;background knowledge;error rate;algorithms;protein folding;feature selection;sequence alignment;prediction model;support vector machine;combinatorial libraries;computational biology;membrane protein;computer appl in life sciences;sequence analysis protein;databases protein;microarrays;bioinformatics	Knowledge of structural class is used by numerous methods for identification of structural/functional characteristics of proteins and could be used for the detection of remote homologues, particularly for chains that share twilight-zone similarity. In contrast to existing sequence-based structural class predictors, which target four major classes and which are designed for high identity sequences, we predict seven classes from sequences that share twilight-zone identity with the training sequences. The proposed MODular Approach to Structural class prediction (MODAS) method is unique as it allows for selection of any subset of the classes. MODAS is also the first to utilize a novel, custom-built feature-based sequence representation that combines evolutionary profiles and predicted secondary structure. The features quantify information relevant to the definition of the classes including conservation of residues and arrangement and number of helix/strand segments. Our comprehensive design considers 8 feature selection methods and 4 classifiers to develop Support Vector Machine-based classifiers that are tailored for each of the seven classes. Tests on 5 twilight-zone and 1 high-similarity benchmark datasets and comparison with over two dozens of modern competing predictors show that MODAS provides the best overall accuracy that ranges between 80% and 96.7% (83.5% for the twilight-zone datasets), depending on the dataset. This translates into 19% and 8% error rate reduction when compared against the best performing competing method on two largest datasets. The proposed predictor provides accurate predictions at 58% accuracy for membrane proteins class, which is not considered by majority of existing methods, in spite that this class accounts for only 2% of the data. Our predictive model is analyzed to demonstrate how and why the input features are associated with the corresponding classes. The improved predictions stem from the novel features that express collocation of the secondary structure segments in the protein sequence and that combine evolutionary and secondary structure information. Our work demonstrates that conservation and arrangement of the secondary structure segments predicted along the protein chain can successfully predict structural classes which are defined based on the spatial arrangement of the secondary structures. A web server is available at http://biomine.ece.ualberta.ca/MODAS/ .	amino acid sequence;benchmark (computing);class;collocation;feature selection;homology (biology);kerrison predictor;largest;membrane proteins;predictive modelling;server (computing);silo (dataset);strand (programming language);subgroup;support vector machine;web server	Marcin J. Mizianty;Lukasz A. Kurgan	2009		10.1186/1471-2105-10-414	biology;protein structure;computer science;bioinformatics;machine learning;feature selection	Comp.	9.429945646323988	-56.02071763996103	51658
6bcf8a8838e51e06e83f7d8442eb29e64a509f6b	an r package suite for microarray meta-analysis in quality control, differentially expressed gene analysis and pathway enrichment detection	software;genomics;male;microarray analysis;prostatic neoplasms;algorithms;humans;meta analysis as topic;computational biology;quality control;gene expression profiling	SUMMARY With the rapid advances and prevalence of high-throughput genomic technologies, integrating information of multiple relevant genomic studies has brought new challenges. Microarray meta-analysis has become a frequently used tool in biomedical research. Little effort, however, has been made to develop a systematic pipeline and user-friendly software. In this article, we present MetaOmics, a suite of three R packages MetaQC, MetaDE and MetaPath, for quality control, differentially expressed gene identification and enriched pathway detection for microarray meta-analysis. MetaQC provides a quantitative and objective tool to assist study inclusion/exclusion criteria for meta-analysis. MetaDE and MetaPath were developed for candidate marker and pathway detection, which provide choices of marker detection, meta-analysis and pathway analysis methods. The system allows flexible input of experimental data, clinical outcome (case-control, multi-class, continuous or survival) and pathway databases. It allows missing values in experimental data and utilizes multi-core parallel computing for fast implementation. It generates informative summary output and visualization plots, operates on different operation systems and can be expanded to include new algorithms or combine different types of genomic data. This software suite provides a comprehensive tool to conveniently implement and compare various genomic meta-analysis pipelines.   AVAILABILITY http://www.biostat.pitt.edu/bioinfo/software.htm   CONTACT ctseng@pitt.edu   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	algorithm;bioinformatics;choice behavior;computation (action);database;databases;exclusion;gene ontology term enrichment;gene regulatory network;high-throughput computing;information;microarray;missing data;multi-core processor;numerous;parallel computing;pathway analysis;pipeline (computing);r language;software suite;throughput;usability	Xingbin Wang;Dongwan D. Kang;Kui Shen;Chi Song;Shuya Lu;Lun-Ching Chang;Serena G. Liao;Zhiguang Huo;Shaowu Tang;Ying Ding;Naftali Kaminski;Etienne Sibille;Yan Lin;Jia Li;George C. Tseng	2012	Bioinformatics	10.1093/bioinformatics/bts485	biology;microarray analysis techniques;quality control;genomics;gene chip analysis;computer science;bioinformatics;data science;data mining;gene expression profiling;microarray databases	Comp.	-1.4842121994641648	-57.49639811649772	51669
a5de80ffb66b6bcabaaea9d908be2ae9e5384e52	a space efficient algorithm for finding the best nonoverlapping alignment score	complejidad espacio;alignement sequence;human disease;algoritmo busqueda;proteine;algorithme recherche;efficient algorithm;secuencia repetida;search algorithm;dna fingerprinting;sequence repetee;alineacion secuencia;non overlap;sequence nucleotide;proteins;score optimal;homology;non chevauchement;space complexity;sequence alignment;complexite espace;homologia;repeated sequence;nucleic acid sequences;homologie	Repeating patterns make up a significant fraction of DNA and protein molecules. These repeating regions are impor tant to biological function because they may act as catalytic, regulatory or evolutionary sites and because they have been implicated in human disease. Addit ionally, these regions often serve as useful laboratory tools for such tasks as localizing genes on a chromosome and DNA fingerprinting. In this paper, we present a space eg~icient algorithm for finding the maximum alignment score for any two substrings of a single string T under the condition that the substrings do not overlap. In a biological context, this corresponds to the largest repeating region in the molecule. The algori thm runs in O(n ~ log S n) time and uses only O(n 2) space. 1 I n t r o d u c t i o n D N A and pro te ins are long l inear molecules made up of several k inds of indiv idual uni ts . In DNA, there are four k inds of uni ts (bases or nucleotides); in p ro te ins there are 20 kinds of uni ts ( amino acids). Because of their l inear s t ruc tu re , these molecules can be thought of as s t r ings over a finite a l p h a b e t . R e p e a t i n g p a t t e r n s make up a significant f ract ion of D N A and pro te in molecules . The exact funct ion of m a n y of these r epea t ing regions is unknown. In some cases (e.g. the pro te in collagen), the repe t i t ion p roduces a s t ruc tu ra l a t t r i b u t e . But , in m a n y others , the repe t i t ion may funct ion as a ca ta ly t ic , r e gu l a to ry or evolut i ona ry site. For example , the cent romer ic region of D N A controls the m o v e m e n t of the ch romosome dur ing cell division. This regio~u t e r m e d a satellite consis ts of m a n y cont iguous copies of a species specific p a t t e r n and m a y serve as a p ro te in b ind ing site. In still o ther cases, r epea t i ng regions have been imp l i ca t ed in h u m a n disease. A region consis t ing of a three nucleot ide r epea t on the h u m a n X ch romosome is somet imes rep l ica ted incorrect ly , causing the number of r epea t s to ba l loon f rom 50 to hundreds or thousands . Ind iv idua l s wi th this defect suffer f rom fragi le-X men ta l r e t a r d a t i o n . Several o ther diseases are also now known to have thei r basis in huge expans ions of different t r inucleot ide repea ts . * Supported by NSF grants DMS-87-20208, DMS-90-05833 and NIH grant GM-36230. Besides their importance in understanding protein and DNA function, repeating regions are useful laboratory tools. For example, the number of copies of a pattern at a particular site on a chromosome is often variable among indivinduals (polymorphic). Such polymorphic regions are helpful in localizing genes to specific regions of the chromosome and also in determining the probability of a match between two samples of genetic material (DNA fingerprinting). Given their importance and given the exponential growth in the size of the DNA and protein databases, efficient methods for detecting repeating regions are required. Due to the action of evolutionary mutation, repeating regions rarely consist of exact repeats. Rather they are approximate repeats contaminated with substitutions, deletions and insertions. It is thus natural to consider approximate string matching techniques when designing algorithms for detecting repeats. Let T = t l . ' t ,~ and W = wl . -w,~ be two strings over an alphabet ~. Let T[i,j] = ti . . . t j and W[g,h] = wg ' ' 'Wh be two substrings. An alignment of T[i, j] and Wig, h] is a sequence Q of edit operations [5] that transforms substring T[i, j] into substring Wig, h]. The allowed operations are: insert a symbol into T[i, j], delete a symbol from T[i, j] and replace a symbol in T[i, j] with a (possibly identical) symbol in Wig, h]. If a weighting function ~ is defined for each possible edit operation [9], then, we can compute a score for an alignment by adding the weights assigned to each operation in Q. In the global alignment problem, we seek the optimal cost alignment for T and W. In the local alignment problem, initial deletions and terminal insertions have zero cost. This has the effect of permitting a global alignment for any two substrings T[i,j] and Wig, h]. Either problem can be solved in O(nm) time by dynamic programming. Typically, in the biological domain, g is negative for all operations except replacement of similar symbols and the object is to maximize the alignment score. In this paper, we consider the problem of finding the maximum alignment score for any two substrings of a single string T under the condition that the substrings do not overlap. That is, the maximum alignment score between two substrings T[g, h] and T[i, j] such that g < h < i < j . In a biological context, this corresponds to the largest repeating region in the molecule. In [6], Miller observed that for a general weighting function g, the problem can be solved in O(n 3) time and O(n 2) space by a modification of the SmithWaterman algorithm [8]. That time was improved by Kannan and Myers [2] to O(n21og ~ n) in a rather complicated recursive algorithm. Unfortunately, their algorithm requires O(n21ogn) space. They considered reducing the space to O(n 2) to be an important open problem. In a similar vein, Landau and Schmidt [4] gave an algorithm for identifing approximate tandem or contiguous repeats. Their algorithm uses a very restricted	approximate string matching;approximation algorithm;dna barcoding;dna microarray;dna profiling;database;dynamic programming;fingerprint (computing);function (biology);ibm notes;original net animation;read-only memory;recursion (computer science);romer;schmidt decomposition;sensor;sequence alignment;smith–waterman algorithm;software bug;string (computer science);string searching algorithm;substring;time complexity;weight function	Gary Benson	1995	Theor. Comput. Sci.	10.1016/0304-3975(95)92848-R	homology;dna profiling;repeated sequence;computer science;bioinformatics;sequence alignment;dspace;algorithm;search algorithm	Theory	3.3597417848406455	-64.02425752082658	51673
8cb66a8d10bc55b40b7c5c7840a8a3feb476dfbc	information theoretic approach to complex biological network reconstruction: application to cytokine release in raw 264.7 macrophages	health research;uk clinical guidelines;biological patents;simulation and modeling;europe pubmed central;systems biology;citation search;physiological cellular and medical topics;computational biology bioinformatics;uk phd theses thesis;life sciences;algorithms;uk research reports;medical journals;europe pmc;biomedical research;bioinformatics	High-throughput methods for biological measurements generate vast amounts of quantitative data, which necessitate the development of advanced approaches to data analysis to help understand the underlying mechanisms and networks. Reconstruction of biological networks from measured data of different components is a significant challenge in systems biology. We use an information theoretic approach to reconstruct phosphoprotein-cytokine networks in RAW 264.7 macrophage cells. Cytokines are secreted upon activation of a wide range of regulatory signals transduced by the phosphoprotein network. Identifying these components can help identify regulatory modules responsible for the inflammatory phenotype. The information theoretic approach is based on estimation of mutual information of interactions by using kernel density estimators. Mutual information provides a measure of statistical dependencies between interacting components. Using the topology of the network derived, we develop a data-driven parsimonious input–output model of the phosphoprotein-cytokine network. We demonstrate the applicability of our information theoretic approach to reconstruction of biological networks. For the phosphoprotein-cytokine network, this approach not only captures most of the known signaling components involved in cytokine release but also predicts new signaling components involved in the release of cytokines. The results of this study are important for gaining a clear understanding of macrophage activation during the inflammation process.	anatomy, regional;biological network;cell secretion;cytokine network pathway;information theory;input/output;interaction;kernel;macrophage activation;mutual information;occam's razor;phosphoproteins;protein phosphatase;systems biology;throughput;inflammatory response	Farzaneh Farhangmehr;Mano Ram Maurya;Daniel M. Tartakovsky;Shankar Subramaniam	2013		10.1186/1752-0509-8-77	biology;medical research;computer science;bioinformatics;data science;data mining;systems biology	Comp.	5.228794708507055	-57.90358100491076	51701
52c59dcf290f22d8510c278824ca261c0b3dff5a	importing mage-ml format microarray data into bioconductor	microarray data;extensible markup language;p16ink4a;bioinformatique;gene expression data;gene expression;5 fluorouracil;data analysis;adjuvant chemotherapy;colorectal cancer;cdna microarray;bioinformatica;sista;thymidylate synthase;markup language;experience design;bioinformatics	UNLABELLED The microarray gene expression markup language (MAGE-ML) is a widely used XML (eXtensible Markup Language) standard for describing and exchanging information about microarray experiments. It can describe microarray designs, microarray experiment designs, gene expression data and data analysis results. We describe RMAGEML, a new Bioconductor package that provides a link between cDNA microarray data stored in MAGE-ML format and the Bioconductor framework for preprocessing, visualization and analysis of microarray experiments.   AVAILABILITY http://www.bioconductor.org. Open Source.	bioconductor;dna, complementary;design of experiments;experiment;imagery;markup language;microarray and gene expression;preprocessor;protein microarray analysis;xml	Steffen Durinck;Joke Allemeersch;Vincent Carey;Yves Moreau;Bart De Moor	2004	Bioinformatics	10.1093/bioinformatics/bth396	biology;microarray analysis techniques;gene chip analysis;xml;gene expression;thymidylate synthase;experience design;computer science;bioinformatics;colorectal cancer;data mining;database;markup language;data analysis;microarray databases;genetics	Comp.	-3.1312674428263687	-57.786211940243675	51765
d68deba2ecd00b64d824163d01b56d11d6865b8b	estimation of membrane proteins in the human proteome		Genomics and proteomics have added valuable information to our knowledgebase of the human biological system including the discovery of therapeutic targets and disease biomarkers. However, molecular profiling studies commonly result in the identification of novel proteins of unknown localization. A class of proteins of special interest is membrane proteins, in particular plasma membrane proteins. Despite their biological and medical significance, the 3-dimensional structures of less than 1% of plasma membrane proteins have been determined. In order to aid in identification of membrane proteins, a number of computational methods have been developed. These tools operate by predicting the presence of transmembrane segments. Here, we utilized five topology prediction methods (TMHMM, SOSUI, waveTM, HMMTOP, and TopPred II) in order to estimate the ratio of integral membrane proteins in the human proteome. These methods employ different algorithms and include a newly-developed method (waveTM) that has yet to be tested on a large proteome database. Since these tools are prone for error mainly as a result of falsely predicting signal peptides as transmembrane segments, we have utilized an additional method, SignalP. Based on our analyses, the ratio of human proteins with transmembrane segments is estimated to fall between 15% and 39% with a consensus of 13%. Agreement among the programs is reduced further when both a positive identification of a membrane protein and the number of transmembrane segments per protein are considered. Such a broad range of prediction depends on the selectivity of the individual method in predicting integral membrane proteins. These methods can play a critical role in determining protein structure and, hence, identifying suitable drug targets in humans.		Mamoun Ahram;Zoi I. Litou;Ruihua Fang;Ghaith Al-Tawallbeh	2006	In silico biology		integral membrane protein;sosui;bioinformatics;transmembrane protein;transmembrane domain;membrane protein;proteome;human proteome project;signal peptide;biology;biochemistry	Comp.	9.407835247318774	-59.83450054642486	51888
08b942cbd91344a852115aa4bcd10ac0a886a67b	unraveling the allosteric inhibition mechanism of ptp1b by free energy calculation based on umbrella sampling		Protein tyrosine phosphatase 1B (PTP1B) is a promising target for the treatment of obesity and type II diabetes. Allosteric inhibitors can stabilize an active conformation of PTP1B by hindering the conformational transition of the WPD loop of PTP1B from the open to the closed state. Here, the umbrella sampling molecular dynamics (MD) simulations were employed to compute the reaction path of the conformational transition of PTP1B, and the snapshots extracted from the MD trajectory were clustered into 58 conformational groups based on the key conformational parameter. Then, the impact of the conformational change of the WPD loop on the interactions between the allosteric site of PTP1B and an allosteric inhibitor BB3 was explored by using the MM/GBSA binding free energy calculations and free energy decomposition analysis. The simulation results show that the binding free energy of BB3 increases gradually from the open to the closed conformation of the WPD loop, providing the molecular mechanism of allosteric inhibition. Correlation analysis of the different energy terms indicates that the allosteric inhibitor with more negative van der Waals contribution cannot only exhibit stronger binding affinity but also hinder the swing of the WPD loop more effectively. Besides, it is found that the energy contribution of Lys292 in the α7 helix undergoes significant change, which reveals that Lys292 is not only the key residue for ligand binding but also plays an important role in hindering the conformational change of the WPD loop.	brs3 wt allele;diabetes mellitus, non-insulin-dependent;extraction;feedback;interaction;ligand binding;ligands;molecular dynamics;population parameter;processor affinity;protein tyrosine phosphatase;sampling (signal processing);sampling - surgical action;simulation;umbrella sampling;wavelet packet decomposition;free energy;protein tyrosine phosphatase, non-receptor type 1	Wei Cui;Yuanhua Cheng;Lingling Geng;Den-Sheng Liang;Tingjun Hou;Mingjuan Ji	2013	Journal of chemical information and modeling	10.1021/ci300526u	allosteric enzyme;crystallography;stereochemistry;chemistry;computational chemistry	Comp.	9.179066709488033	-62.82284898210338	51893
e22150b12671306ea563953c879feff32fdd8ff7	padel-ddpredictor: open-source software for pd-pk-t prediction	quantitative structure activity relationship;pkpd;absorption distribution metabolism excretion and toxicity;prediction;open source	ADMET (absorption, distribution, metabolism, excretion, and toxicity)-related failure of drug candidates is a major issue for the pharmaceutical industry today. Prediction of PD-PK-T properties using in silico tools has become very important in pharmaceutical research to reduce cost and enhance efficiency. PaDEL-DDPredictor is an in silico tool for rapid prediction of PD-PK-T properties of compounds from their chemical structures. It is free and open-source software that, has both graphical user interface and command line interface, can work on all major platforms (Windows, Linux, and MacOS) and supports more than 90 different molecular file formats. The software can be downloaded from http://padel.nus.edu.sg/software/padelddpredictor.	chemical file format;command-line interface;dosage forms;graphical user interface;heart failure;linux;microsoft windows;open-source software;parkinson disease;public-key cryptography;user interface device component	Yuye He;Chin Yee Liew;Nitin Sharma;Sze Kwang Woo;Yi Ting Chau;Chun Wei Yap	2013	Journal of computational chemistry	10.1002/jcc.23173	chemistry;prediction;toxicology;pk/pd models;quantitative structure–activity relationship	SE	-3.704984210619062	-59.29645878689765	51960
116a196cfce1e39c72780085b7143cb7f20d9d5d	cavka – a new automatic pharmacophore elucidation method in progress	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;computer applications in chemistry;theoretical and computational chemistry;computational biology bioinformatics;uk phd theses thesis;life sciences;uk research reports;medical journals;europe pmc;documentation and information in chemistry;biomedical research;bioinformatics	Three dimensional pharmacophore models can be considered as an ensemble of steric and electronic features in space, which are necessary to ensure intermolecular interaction with a specific target in order to trigger or to block biological activity [1]. By identifying these features, a 3D pharmacophore model can be built in order to screen multi-conformatorial databases with the aim to detect compounds matching the pharmacophoric hypothesis and subsequently submit them to a biological testing. Even if a 3D crystal structure is at hand, the creation of a reliable pharmacophore model remains a challenging task. CavKA (Cavity Knowledge Acceleration), our own inhouse strategy employs the information of Co-crystallised ligand-receptor complexes for an automatic pharmacophore creation. Ligand features interacting with the binding site are detected and Grid [2] force field information is additionally taken into account as to weight and prioritize the identified features in question, to transform them into a pharmacophore model without any user intervention. Our method is compared to LigandScout [3] and a custom MOE [4] implementation, similar to LigandScout, two powerful standard tools. Both are identifying ligand-receptor interactions to highlight important ligand features to be selected for creating pharmacophore models automatically. The performance is evaluated in a retrospective screening on the FieldScreen [5] dataset outlining strengths, weaknesses and as well as similarities of each method for the scrutinized targets.	crystal structure;dna binding site;database;force field (chemistry);interaction;ligandscout;moe;pharmacophore	Florian Koelling;Knut Baumann	2011		10.1186/1758-2946-3-S1-P31	biology;medical research;medicine;computer science;bioinformatics;data science	Comp.	9.971173531884103	-58.53973356558074	51971
1c6d64e82c770ef1fd343554ea98d5e3a975ca3d	the relationship between low-frequency motions and community structure of residue network in protein molecules	community structure;critical residue interaction pair;low frequency dynamics;protein structure dynamics	The global shape of a protein molecule is believed to be dominant in determining low-frequency deformational motions. However, how structure dynamics relies on residue interactions remains largely unknown. The global residue community structure and the local residue interactions are two important coexisting factors imposing significant effects on low-frequency normal modes. In this work, an algorithm for community structure partition is proposed by integrating Miyazawa-Jernigan empirical potential energy as edge weight. A sensitivity parameter is defined to measure the effect of local residue interaction on low-frequency movement. We show that community structure is a more fundamental feature of residue contact networks. Moreover, we surprisingly find that low-frequency normal mode eigenvectors are sensitive to some local critical residue interaction pairs (CRIPs). A fair amount of CRIPs act as bridges and hold distributed structure components into a unified tertiary structure by bonding nearby communities. Community structure analysis and CRIP detection of 116 catalytic proteins reveal that breaking up of a CRIP can cause low-frequency allosteric movement of a residue at the far side of protein structure. The results imply that community structure and CRIP may be the structural basis for low-frequency motions.	4-dichlorobenzene;anatomy, regional;crip1 gene;community;global optimization;interaction;motion;movement;network partition;normal mode;population parameter;protein data bank;pyschological bonding;staphylococcal protein a;statistical potential;stiffness;algorithm;tertiary	Weitao Sun	2018	Journal of computational biology : a journal of computational molecular cell biology	10.1089/cmb.2017.0171	computational chemistry;mathematics;artificial intelligence;machine learning;partition (number theory);community structure;molecule;potential energy;normal mode;residue (complex analysis);protein tertiary structure;eigenvalues and eigenvectors	Comp.	8.790521652034622	-64.11256097990358	52017
0957d7b0acc3af16d37bc4019814ed4e777b1a52	ecodrug: a database connecting drugs and conservation of their targets across species		Pharmaceuticals are designed to interact with specific molecular targets in humans and these targets generally have orthologs in other species. This provides opportunities for the drug discovery community to use alternative model species for drug development. It also means, however, there is potential for mode of action related effects in non-target wildlife species as many pharmaceuticals reach the environment through patient use and manufacturing wastes. Acquiring insight in drug target ortholog predictions across species and taxonomic groups has proven difficult because of the lack of an optimal strategy and because necessary information is spread across multiple and diverse sources and platforms. We introduce a new research platform tool, ECOdrug, that reliably connects drugs to their protein targets across divergent species. It harmonizes ortholog predictions from multiple sources via a simple user interface underpinning critical applications for a wide range of studies in pharmacology, ecotoxicology and comparative evolutionary biology. ECOdrug can be used to identify species with drug targets and identify drugs that interact with those targets. As such, it can be applied to support intelligent targeted drug safety testing by ensuring appropriate and relevant species are selected in ecological risk assessments. ECOdrug is freely accessible and available at: http://www.ecodrug.org.		Bas Verbruggen;Lina Gunnarsson;Erik Kristiansson;Tobias Österlund;Stewart F. Owen;Jason R. Snape;Charles R. Tyler	2018		10.1093/nar/gkx1024	drug;genetics;drug discovery;ecotoxicology;drug development;biology;user interface;bioinformatics	Comp.	1.0380806549796953	-61.0729536846884	52040
1cb744b248c42274753b92ba16a5e5a9c5d779a0	seme: a fast mapper of illumina sequencing reads with statistical evaluation	auto match function high throughput sequencing;high throughput sequencing;mapping;automatch function;indel;perfect match	Mapping reads to a reference genome is a routine yet computationally intensive task in research based on high-throughput sequencing. In recent years, the sequencing reads of the Illumina platform get longer and their quality scores get higher. According to our calculation, this allows perfect k-mer seed match for almost all reads when a close reference genome is available subject to reasonable specificity. Our another observation is that the majority reads contain at most one short INDEL polymorphism. Based on these observations, we propose a fast mapping approach, referred to as “SEME”, which has two core steps: first it scans a read sequentially in a specific order for a k-mer exact match seed; next it extends the alignment on both sides allowing at most one short-INDEL each, using a novel method “auto-match function”. We decompose the evaluation of the sensitivity and specificity into two parts corresponding to the seed and extension step, and the composite result provides an approximate overall reliability estimate of each mapping. We compare SEME with some existing mapping methods on several data sets, and SEME shows better performance in terms of both running time and mapping rates.	approximation algorithm;high-throughput computing;k-mer;mer;sensitivity and specificity;throughput;time complexity	Shijian Chen;Anqi Wang;Lei M. Li	2013		10.1007/978-3-642-37195-0_2	biology;dna sequencing;indel;computer science;bioinformatics;data mining;genetics	Comp.	-0.31941766109758096	-54.04611334884903	52062
c160b84b124e910937f400fe1b19c6093f5f6448	bindn+ for accurate prediction of dna and rna-binding residues from protein sequence features	dna;evolution molecular;simulation and modeling;position specific scoring matrix;amino acid;systems biology;protein sequence;amino acid sequence;physiological cellular and medical topics;dna binding;binding site;computational biology bioinformatics;internet;rna;proteins;system biology;roc curve;protein binding;artificial intelligence;algorithms;molecular sequence data;support vector machine;nucleic acid;databases protein;bioinformatics	Understanding how biomolecules interact is a major task of systems biology. To model protein-nucleic acid interactions, it is important to identify the DNA or RNA-binding residues in proteins. Protein sequence features, including the biochemical property of amino acids and evolutionary information in terms of position-specific scoring matrix (PSSM), have been used for DNA or RNA-binding site prediction. However, PSSM is rather designed for PSI-BLAST searches, and it may not contain all the evolutionary information for modelling DNA or RNA-binding sites in protein sequences. In the present study, several new descriptors of evolutionary information have been developed and evaluated for sequence-based prediction of DNA and RNA-binding residues using support vector machines (SVMs). The new descriptors were shown to improve classifier performance. Interestingly, the best classifiers were obtained by combining the new descriptors and PSSM, suggesting that they captured different aspects of evolutionary information for DNA and RNA-binding site prediction. The SVM classifiers achieved 77.3% sensitivity and 79.3% specificity for prediction of DNA-binding residues, and 71.6% sensitivity and 78.7% specificity for RNA-binding site prediction. Predictions at this level of accuracy may provide useful information for modelling protein-nucleic acid interactions in systems biology studies. We have thus developed a web-based tool called BindN+ ( http://bioinfo.ggc.org/bindn+/ ) to make the SVM classifiers accessible to the research community.		Liangjiang Wang;Caiyan Huang;Mary Yang;Jack Y. Yang	2010		10.1186/1752-0509-4-S1-S3	biology;support vector machine;nucleic acid;plasma protein binding;molecular biology;the internet;rna;amino acid;bioinformatics;binding site;protein sequencing;peptide sequence;genetics;systems biology;dna;receiver operating characteristic	Comp.	9.438935453237354	-56.83855397874161	52087
b3b35239f3ed9d2a44dc5563b22159260b557835	estweb: bioinformatics services for est sequencing projects		ESTWeb is an internet based software package designed for uniform data processing and storage for large-scale EST sequencing projects. The package provides for: (a) reception of sequencing chromatograms; (b) sequence processing such as base-calling, vector screening, comparison with public databases; (c) storage of data and analysis in a relational database, (d) generation of a graphical report of individual sequence quality; and (e) issuing of reports with statistics of productivity and redundancy. The software facilitates real-time monitoring and evaluation of EST sequence acquisition progress along an EST sequencing project.	bioinformatics;biopolymer sequencing;databases;emoticon;graphical user interface;real-time transcription;relational database	Apuã C. M. Paquola;Milton Y. Nishyiama;Eduardo M. Reis;Aline Maria da Silva;Sergio Verjovski-Almeida	2003	Bioinformatics	10.1093/bioinformatics/btg196	computer science;bioinformatics;data mining;database	SE	-3.1442050040222473	-58.53002235142548	52113
3bbe47e633451a1be9562e139b35f2e35abdf03c	modeling of stress-induced regulatory cascades involving transcription factor dimers	transcriptional network regulation;specific stress;stress;biology computing;expression profile;neural nets;stress response;biological cascades stress induced regulatory cascades modeling artificial neural networks stress induced gene modules ann modeling specific stress transcription factors tf dimerization transcriptional network regulation;biological system modeling;anns;transcription factors;regulators stress artificial neural networks gene expression biological system modeling fungi proteins systems biology computational biology biotechnology;neural nets biology computing genetics;genetics;stress induced regulatory cascades modeling;gene expression;transcription regulation;artificial neural networks;proteins;tf dimerization;gene modules;transcription factor;ann modeling;prediction accuracy;biological cascades;stress induced gene modules;regulators;artificial neural network;anns tf dimerization gene modules;bioinformatics	Regulatory cascades consisting of stress-induced gene modules and their transcriptional regulators were recently identified and quantitatively modeled using Artificial Neural Networks (ANNs). Here, we extent our approach to account for regulators that consist of transcription factor dimers. The latter are frequently missed by module-finding tools since the expression profile of one of the dimers is typically un-altered while the profile of the second dimer changes significantly during the stress response. We identify two modules of stress-associated genes that are regulated by transcription factor dimers and show that ANN modeling can be used to accurately predict the expression of all genes in these modules. We also find that prediction accuracy is dependent on the specific stress category, in agreement with experimental studies where constitutively expressed transcription factors exert different regulatory actions upon different exposures to stressful stimuli. Overall, we show that TF dimerization is an important attribute of the transcriptional network regulation, which is frequently ignored by module finding tools, and can lead to the identification of important biological cascades whose regulatory action can be quantitatively simulated with ANNs.	artificial neural network;domino tiling;gene expression profiling;gene regulatory network;medical transcription;neural networks;tf–idf;transcription (software)	Maria Manioudaki;Panayiota Poirazi	2010	2010 International Conference on Complex, Intelligent and Software Intensive Systems	10.1109/CISIS.2010.171	biology;bioinformatics;genetics	Comp.	5.720675541884234	-59.3928941478905	52114
b98b2a3280051b24651a8129ce95f5f29c2c49fd	deducing the kinetics of protein synthesis in vivo from the transition rates measured in vitro 	codon;models biological;proteins;open access;thermodynamics;computational biology;kinetics;ribosomes;protein biosynthesis	The molecular machinery of life relies on complex multistep processes that involve numerous individual transitions, such as molecular association and dissociation steps, chemical reactions, and mechanical movements. The corresponding transition rates can be typically measured in vitro but not in vivo. Here, we develop a general method to deduce the in-vivo rates from their in-vitro values. The method has two basic components. First, we introduce the kinetic distance, a new concept by which we can quantitatively compare the kinetics of a multistep process in different environments. The kinetic distance depends logarithmically on the transition rates and can be interpreted in terms of the underlying free energy barriers. Second, we minimize the kinetic distance between the in-vitro and the in-vivo process, imposing the constraint that the deduced rates reproduce a known global property such as the overall in-vivo speed. In order to demonstrate the predictive power of our method, we apply it to protein synthesis by ribosomes, a key process of gene expression. We describe the latter process by a codon-specific Markov model with three reaction pathways, corresponding to the initial binding of cognate, near-cognate, and non-cognate tRNA, for which we determine all individual transition rates in vitro. We then predict the in-vivo rates by the constrained minimization procedure and validate these rates by three independent sets of in-vivo data, obtained for codon-dependent translation speeds, codon-specific translation dynamics, and missense error frequencies. In all cases, we find good agreement between theory and experiment without adjusting any fit parameter. The deduced in-vivo rates lead to smaller error frequencies than the known in-vitro rates, primarily by an improved initial selection of tRNA. The method introduced here is relatively simple from a computational point of view and can be applied to any biomolecular process, for which we have detailed information about the in-vitro kinetics.	codon (nucleotide sequence);computation;gene expression;kinesiology;kinetics (discipline);kinetics internet protocol;markov chain;markov model;movement;population parameter;protein biosynthesis;ribosomes;small;video-in video-out;free energy	Sophia Rudorf;Michael Thommen;Marina V. Rodnina;Reinhard Lipowsky	2014		10.1371/journal.pcbi.1003909	biology;biochemistry;simulation;bioinformatics;ribosome;genetic code;genetics;kinetics;protein biosynthesis	ML	7.726084688072513	-64.43243067892878	52186
db6a5cb6ceddb6d7b1df5033c11cb2cb7f38ef2f	a probabilistic model for mining implicit 'chemical compound-gene' relations from literature	statistical significance;probabilistic model;molecular biology;cross validation	MOTIVATION The importance of chemical compounds has been emphasized more in molecular biology, and 'chemical genomics' has attracted a great deal of attention in recent years. Thus an important issue in current molecular biology is to identify biological-related chemical compounds (more specifically, drugs) and genes. Co-occurrence of biological entities in the literature is a simple, comprehensive and popular technique to find the association of these entities. Our focus is to mine implicit 'chemical compound and gene' relations from the co-occurrence in the literature.   RESULTS We propose a probabilistic model, called the mixture aspect model (MAM), and an algorithm for estimating its parameters to efficiently handle different types of co-occurrence datasets at once. We examined the performance of our approach not only by a cross-validation using the data generated from the MEDLINE records but also by a test using an independent human-curated dataset of the relationships between chemical compounds and genes in the ChEBI database. We performed experimentation on three different types of co-occurrence datasets (i.e. compound-gene, gene-gene and compound-compound co-occurrences) in both cases. Experimental results have shown that MAM trained by all datasets outperformed any simple model trained by other combinations of datasets with the difference being statistically significant in all cases. In particular, we found that incorporating compound-compound co-occurrences is the most effective in improving the predictive performance. We finally computed the likelihoods of all unknown compound-gene (more specifically, drug-gene) pairs using our approach and selected the top 20 pairs according to the likelihoods. We validated them from biological, medical and pharmaceutical viewpoints.	algorithm;chebi;chemicals;chemogenomics;cross-validation (statistics);entity;estimated;medline;molecular biology;published comment;silo (dataset);statistical model;triangulation	Shanfeng Zhu;Yasushi Okuno;Gozoh Tsujimoto;Hiroshi Mamitsuka	2005	Bioinformatics	10.1093/bioinformatics/bti1141	statistical model;computer science;bioinformatics;data science;data mining;statistical significance;cross-validation;statistics	Comp.	5.526116763644419	-54.65447685567837	52216
6ec9934df9a01d30709f78ab287300b24135a598	genome structure and characterisation of an endogenous retrovirus from the zebrafish genome project database	reverse transcriptase;sequence similarity;genome organization;nucleotide sequence;genome size	A 9.5Kb nucleotide sequence of an endogenous retrovirus was ob- tained during an attempt to screen a reverse transcriptase-like element in the ze- brafish genome project database. The element termed here as ZFERV-2 has the typical genomic organization of a retrovirus in which the LTR flanks the viral genes in this way: LTR-gag-pol-env-LTR. ZFERV-2, resembles a zebrafish en- dogenous retrovirus, ZFERV discovered previously by Shen and Steiner (2004) and has all the major conserved motifs of the viral genes. In addition, ZFERV-2 has several characteristics possessed by a retrovirus. Firstly, ZFERV-2 shows a replication defective retrovirus because of huge deletion at the protease gene proximal to gag gene is observed. Secondly, an intact genome structure of ZFERV-2 together with 99% sequence similarity on both ends of the LTRs indicate a recent integration into the zebrafish genome. Thirdly, a long leader sequence at 1.5Kb upstream of the viral genes and a large genome size are characteristics shared by retroviruses isolated from lower vertebrates.		Roziah Kambol;M. Faris Abtholuddin	2008		10.1007/978-3-540-70600-7_29	biology;nucleic acid sequence;bioinformatics;genome evolution;virology;genome size;genomic organization;genome project;genetics;endogenous retrovirus;reverse transcriptase	Logic	4.174803243988164	-62.06672729716594	52342
36386e8449b36b9cba8e823001c60ba3e1df1af4	dialign: finding local similarities by multiple sequence alignment	software;secuencia aminoacido;systeme unix;alignement sequence;sequence aminoacide;aminoacid sequence;logiciel;computerized processing;tratamiento informatico;deteccion;unix system;methode;secuencia nucleotido;detection;alineacion secuencia;nucleotide sequence;sequence nucleotide;homology;logicial;sequence alignment;multiple sequence alignment;sistema unix;homologia;metodo;traitement informatique;method;homologie	MOTIVATION DIALIGN is a new method for pairwise as well as multiple alignment of nucleic acid and protein sequences. While standard alignment programs rely on comparing single residues and imposing gap penalties, DIALIGN constructs alignments by comparing whole segments of the sequences. No gap penalty is employed. This point of view is especially adequate if sequences are not globally related, but share only local similarities, as is the case in genomic DNA sequences and in many protein families.   RESULTS Using four different data sets, we show that DIALIGN is able correctly to align conserved motifs in protein sequences. Alignments produced by DIALIGN are compared systematically to the results of five other alignment programs.   AVAILABILITY DIALIGN is available to the scientific community free of charge for non-commercial use. Executables for various UNIX platforms including LINUX can be downloaded at http://www.gsf.de/biodv/dialign.html   CONTACT werner, morgenstern@gsf.de	align (company);amino acid sequence;executable;gap penalty;linux;multiple sequence alignment;nucleic acids;peptide sequence;point of view (computer hardware company);protein family;sequence motif;unix	Burkhard Morgenstern;Kornelie Frech;Andreas W. M. Dress;Thomas Werner	1998	Bioinformatics	10.1093/bioinformatics/14.3.290	biology;homology;method;multiple sequence alignment;nucleic acid sequence;computer science;bioinformatics;sequence alignment;algorithm	Comp.	-4.092988436484626	-55.85097056813085	52351
130cefe532f8783b27de9ed8bce26df62ed2a570	exploratory and inferential analysis of gene cluster neighborhood graphs	software;cluster algorithm;inferential;cluster;gene cluster;interactive visualization;databases genetic;statistik;graphs;computational biology bioinformatics;mathematik informatik und statistik;clustering method;ddc 610;gene;medizin;technische reports;algorithms;pattern recognition automated;analysis;exploratory;combinatorial libraries;functional group;gene expression data analysis;computational biology;neighborhood;computationale statistik;computer appl in life sciences;ddc 510;multigene family;gene expression profiling;microarrays;bioinformatics	Many different cluster methods are frequently used in gene expression data analysis to find groups of co-expressed genes. However, cluster algorithms with the ability to visualize the resulting clusters are usually preferred. The visualization of gene clusters gives practitioners an understanding of the cluster structure of their data and makes it easier to interpret the cluster results. In this paper recent extensions of R package gcExplorer are presented. gcExplorer is an interactive visualization toolbox for the investigation of the overall cluster structure as well as single clusters. The different visualization options including arbitrary node and panel functions are described in detail. Finally the toolbox can be used to investigate the quality of a given clustering graphically as well as theoretically by testing the association between a partition and a functional group under study. It is shown that gcExplorer is a very helpful tool for a general exploration of microarray experiments. The identification of potentially interesting gene candidates or functional groups is substantially accelerated and eased. Inferential analysis on a cluster solution is used to judge its ability to provide insight into the underlying mechanistic biology of the experiment.	algorithm;bio-informatics;bioconductor;bioinformatics;biological factors;cluster headache;cluster analysis;computation (action);computational statistics;data table;databases;experiment;exploratory testing;flumazenil;gene expression profiling;gerald weinberg;graph - visual representation;graph coloring;html;home page;imagery;inferential programming;inferential theory of learning;interaction;interactive visualization;manuscripts;microarray;microsoft windows;node - plant part;operating system;programming languages;programming language;published database;r language;relevance;requirement;software testing;unix;web site;xslt/muenchian grouping;citation;statistical cluster	Theresa Scharl;Ingo Voglhuber;Friedrich Leisch	2009	BMC Bioinformatics	10.1186/1471-2105-10-288	biology;dna microarray;interactive visualization;gene cluster;computer science;bioinformatics;data science;gene;analysis;data mining;gene expression profiling;graph;genetics;exploratory research;algorithm;cluster	Comp.	0.9455143408777302	-56.97299745077482	52399
012daf32fba68b9e9a00e241c960482e78796a0a	a novel missense-mutation-related feature extraction scheme for 'driver' mutation identification	software;artificial intelligence;algorithms;humans;neoplasms;mutation missense	MOTIVATION It becomes widely accepted that human cancer is a disease involving dynamic changes in the genome and that the missense mutations constitute the bulk of human genetic variations. A multitude of computational algorithms, especially the machine learning-based ones, has consequently been proposed to distinguish missense changes that contribute to the cancer progression ('driver' mutation) from those that do not ('passenger' mutation). However, the existing methods have multifaceted shortcomings, in the sense that they either adopt incomplete feature space or depend on protein structural databases which are usually far from integrated.   RESULTS In this article, we investigated multiple aspects of a missense mutation and identified a novel feature space that well distinguishes cancer-associated driver mutations from passenger ones. An index (DX score) was proposed to evaluate the discriminating capability of each feature, and a subset of these features which ranks top was selected to build the SVM classifier. Cross-validation showed that the classifier trained on our selected features significantly outperforms the existing ones both in precision and robustness. We applied our method to several datasets of missense mutations culled from published database and literature and obtained more reasonable results than previous studies.   AVAILABILITY The software is available online at http://www.methodisthealth.com/software and https://sites.google.com/site/drivermutationidentification/.   CONTACT xzhou@tmhs.org.   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.		Hua Tan;Jiguang Bao;Xiaobo Zhou	2012	Bioinformatics	10.1093/bioinformatics/bts558	computer science;bioinformatics;machine learning;data mining	Comp.	7.9097039019001265	-54.40970561259039	52401
c8ef99c4c78b34054378e6a2737093b898caa3b3	a time-varying group sparse additive model for genome-wide association studies of dynamic complex traits		MOTIVATION Despite the widespread popularity of genome-wide association studies (GWAS) for genetic mapping of complex traits, most existing GWAS methodologies are still limited to the use of static phenotypes measured at a single time point. In this work, we propose a new method for association mapping that considers dynamic phenotypes measured at a sequence of time points. Our approach relies on the use of Time-Varying Group Sparse Additive Models (TV-GroupSpAM) for high-dimensional, functional regression.   RESULTS This new model detects a sparse set of genomic loci that are associated with trait dynamics, and demonstrates increased statistical power over existing methods. We evaluate our method via experiments on synthetic data and perform a proof-of-concept analysis for detecting single nucleotide polymorphisms associated with two phenotypes used to assess asthma severity: forced vital capacity, a sensitive measure of airway obstruction and bronchodilator response, which measures lung response to bronchodilator drugs.   AVAILABILITY AND IMPLEMENTATION Source code for TV-GroupSpAM freely available for download at http://www.cs.cmu.edu/~mmarchet/projects/tv_group_spam, implemented in MATLAB.   CONTACT epxing@cs.cmu.edu   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.		Micol Marchetti-Bowick;Junming Yin;Judie A. Howrylak;Eric P. Xing	2016	Bioinformatics	10.1093/bioinformatics/btw347	machine learning;pattern recognition;statistics	Comp.	5.62541026384225	-53.329033614142894	52416
33d073322bed3997ee119a588b2ae0e8c7f9a318	ikap: a heuristic framework for inference of kinase activities from phosphoproteomics data	mouse;networks;cells	MOTIVATION Phosphoproteomics measurements are widely applied in cellular biology to detect changes in signalling dynamics. However, due to the inherent complexity of phosphorylation patterns and the lack of knowledge on how phosphorylations are related to functions, it is often not possible to directly deduce protein activities from those measurements. Here, we present a heuristic machine learning algorithm that infers the activities of kinases from Phosphoproteomics data using kinase-target information from the PhosphoSitePlus database. By comparing the estimated kinase activity profiles to the measured phosphosite profiles, it is furthermore possible to derive the kinases that are most likely to phosphorylate the respective phosphosite.   RESULTS We apply our approach to published datasets of the human cell cycle generated from HeLaS3 cells, and insulin signalling dynamics in mouse hepatocytes. In the first case, we estimate the activities of 118 at six cell cycle stages and derive 94 new kinase-phosphosite links that can be validated through either database or motif information. In the second case, the activities of 143 kinases at eight time points are estimated and 49 new kinase-target links are derived.   AVAILABILITY AND IMPLEMENTATION The algorithm is implemented in Matlab and be downloaded from github. It makes use of the Optimization and Statistics toolboxes. https://github.com/marcel-mischnik/IKAP.git.   CONTACT marcel.mischnik@gmail.com   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.		Marcel Mischnik;Francesca Sacco;Juergen Cox;Hans-Christoph Schneider;Matthias Schäfer;Manfred Hendlich;Daniel Crowther;Matthias Mann;Thomas Klabunde	2016	Bioinformatics	10.1093/bioinformatics/btv699	computer science;bioinformatics;machine learning;data mining	Comp.	3.4390567859203998	-55.880116559770954	52418
78a06d971a969f0b65c39f40fc5b019a4d95c9e0	on the use of gene ontology annotations to assess functional similarity among orthologs and paralogs: a short report	animals;genomics;mice;probability;cell nucleus;phosphorylation;molecular sequence annotation;open world assumption;genetics;large scale;models genetic;gene ontology annotation;genome human;human genome;molecular biology;genome;human;algorithm animation;life sciences;health science;models statistical;algorithms;humans;statistical;computational biology;experience base;models;species specificity;gene ontology;genetic	"""A recent paper (Nehrt et al., PLoS Comput. Biol. 7:e1002073, 2011) has proposed a metric for the """"functional similarity"""" between two genes that uses only the Gene Ontology (GO) annotations directly derived from published experimental results. Applying this metric, the authors concluded that paralogous genes within the mouse genome or the human genome are more functionally similar on average than orthologous genes between these genomes, an unexpected result with broad implications if true. We suggest, based on both theoretical and empirical considerations, that this proposed metric should not be interpreted as a functional similarity, and therefore cannot be used to support any conclusions about the """"ortholog conjecture"""" (or, more properly, the """"ortholog functional conservation hypothesis""""). First, we reexamine the case studies presented by Nehrt et al. as examples of orthologs with divergent functions, and come to a very different conclusion: they actually exemplify how GO annotations for orthologous genes provide complementary information about conserved biological functions. We then show that there is a global ascertainment bias in the experiment-based GO annotations for human and mouse genes: particular types of experiments tend to be performed in different model organisms. We conclude that the reported statistical differences in annotations between pairs of orthologous genes do not reflect differences in biological function, but rather complementarity in experimental approaches. Our results underscore two general considerations for researchers proposing novel types of analysis based on the GO: 1) that GO annotations are often incomplete, potentially in a biased manner, and subject to an """"open world assumption"""" (absence of an annotation does not imply absence of a function), and 2) that conclusions drawn from a novel, large-scale GO analysis should whenever possible be supported by careful, in-depth examination of examples, to help ensure the conclusions have a justifiable biological basis."""	annotation;complementarity theory;exemplification;experiment;function (biology);gene ontology;genome;open-world assumption;orthologous gene;scientific publication;sequence homology	Paul D. Thomas;Valerie Wood;Christopher J Mungall;Suzanna Lewis;Judith A. Blake	2012		10.1371/journal.pcbi.1002386	phosphorylation;biology;genomics;human genome;open-world assumption;bioinformatics;probability;genetics;genome	Comp.	3.5047790895340296	-56.322484376921196	52457
33c220bbb12ee8a1a522ed888fe2d8d56189fbef	structural and dynamic requirements for optimal activity of the essential bacterial enzyme dihydrodipicolinate synthase	substrate specificity;catalytic domain;escherichia coli;hydrogen bond;protein dynamics;enzyme;pyruvic acid;methicillin resistant staphylococcus aureus;molecular dynamics simulation;protein structure quaternary;molecular dynamic simulation;mutagenesis site directed;models molecular;structure and function;escherichia coli proteins;hydro lyases;computational biology;crystallography x ray;computer simulation;active site;dimerization;bacterial proteins;enzyme stability;species specificity	Dihydrodipicolinate synthase (DHDPS) is an essential enzyme involved in the lysine biosynthesis pathway. DHDPS from E. coli is a homotetramer consisting of a 'dimer of dimers', with the catalytic residues found at the tight-dimer interface. Crystallographic and biophysical evidence suggest that the dimers associate to stabilise the active site configuration, and mutation of a central dimer-dimer interface residue destabilises the tetramer, thus increasing the flexibility and reducing catalytic efficiency and substrate specificity. This has led to the hypothesis that the tetramer evolved to optimise the dynamics within the tight-dimer. In order to gain insights into DHDPS flexibility and its relationship to quaternary structure and function, we performed comparative Molecular Dynamics simulation studies of native tetrameric and dimeric forms of DHDPS from E. coli and also the native dimeric form from methicillin-resistant Staphylococcus aureus (MRSA). These reveal a striking contrast between the dynamics of tetrameric and dimeric forms. Whereas the E. coli DHDPS tetramer is relatively rigid, both the E. coli and MRSA DHDPS dimers display high flexibility, resulting in monomer reorientation within the dimer and increased flexibility at the tight-dimer interface. The mutant E. coli DHDPS dimer exhibits disorder within its active site with deformation of critical catalytic residues and removal of key hydrogen bonds that render it inactive, whereas the similarly flexible MRSA DHDPS dimer maintains its catalytic geometry and is thus fully functional. Our data support the hypothesis that in both bacterial species optimal activity is achieved by fine tuning protein dynamics in different ways: E. coli DHDPS buttresses together two dimers, whereas MRSA dampens the motion using an extended tight-dimer interface.	anabolism;domino tiling;escherichia coli infections;exhibits as topic;gene regulatory network;hydrogen;interface device component;lysine;methicillin;molecular dynamics;muscle rigidity;mutation;sensitivity and specificity;simulation;substrate specificity;tight binding;monomer	Cyril F. Reboul;Benjamin T. Porebski;M. D. W. Griffin;Renwick C J Dobson;M. A. Perugini;Juliet A Gerrard;Ashley M. Buckle	2012		10.1371/journal.pcbi.1002537	computer simulation;biology;biochemistry;enzyme;active site;hydrogen bond;escherichia coli	Visualization	7.459652854521947	-62.918568235542374	52477
8de24bcfe3a0dff6a3bb73164a819ac9b7de181b	tsetse fly rdna: an analysis of structure and sequence	transcription genetic;genes;animals;dna ribosomal;cloning molecular;genetic vectors;repetitive sequences nucleic acid;tsetse flies;dna restriction enzymes;sequence homology nucleic acid;drosophila melanogaster;base sequence;species specificity	A genomic library of Glossina morsitans morsitans (tsetse fly) has been constructed in the phage vector EMBL 4 and a complete rDNA unit isolated by using a D. melanogaster rDNA clone as a probe. The overall organisation is typical of higher eukaryotes, including an intergenic spacer consisting of a subrepeating structure. Atypically, however, the 45S precursor RNA promoter was shown to lie within the last subrepeat by S1 mapping; i.e. the last subrepeat extends 90 bp into the ETS. The sequence of the spacer subrepeats, the ETS and the first 151 nucleotides of the 18S gene was determined. Comparisons with the corresponding regions of other higher eukaryotes, including insects shows that the ETS has completely diverged, raising questions concerning their functional significance and evolutionary retention; depending on the method of alignment, only two short regions of reasonable homology are shared with Drosophila species: a stretch of nucleotides around the transcription initiation site, and AACATA at the NTS-18S gene junction; and the functionally important G at -16, conserved in all other examined species, is displaced no matter what method of alignment is used. These and other features reflect continual processes of change in the rDNA family to which the several functions of the repeating unit need to adjust.	alignment;clone;diptera;enterprise test software;glossina <genus>;homologous gene;homology (biology);internal transcribed spacer;nucleotides;rna;spacer device component;transcription (software);transcription initiation	N. C. Cross;G. A. Dover	1987	Nucleic acids research	10.1093/nar/15.1.15	biology;molecular biology;gene;genetics	Comp.	4.7370122245007416	-62.52359452295259	52532
89a86ba5ee0454064656b415403c1c590fc4f1ae	relationship between amino acid properties and functional parameters in olfactory receptors and discrimination of mutants with enhanced specificity	animals;mice;goldfish;ligands;signal transduction;amino acid substitution;molecular conformation;computational biology bioinformatics;algorithms;regression analysis;humans;combinatorial libraries;odors;computer appl in life sciences;receptors odorant;mutation;microarrays;bioinformatics	Olfactory receptors are key components in signal transduction. Mutations in olfactory receptors alter the odor response, which is a fundamental response of organisms to their immediate environment. Understanding the relationship between odorant response and mutations in olfactory receptors is an important problem in bioinformatics and computational biology. In this work, we have systematically analyzed the relationship between various physical, chemical, energetic and conformational properties of amino acid residues, and the change of odor response/compound's potency/half maximal effective concentration (EC50) due to amino acid substitutions. We observed that both the characteristics of odorant molecule (ligand) and amino acid properties are important for odor response and EC50. Additional information on neighboring and surrounding residues of the mutants enhanced the correlation between amino acid properties and EC50. Further, amino acid properties have been combined systematically using multiple regression techniques and we obtained a correlation of 0.90-0.98 with odor response/EC50 of goldfish, mouse and human olfactory receptors. In addition, we have utilized machine learning methods to discriminate the mutants, which enhance or reduce EC50 values upon mutation and we obtained an accuracy of 93% and 79% for self-consistency and jack-knife tests, respectively. Our analysis provides deep insights for understanding the odor response of olfactory receptor mutants and the present method could be used for identifying the mutants with enhanced specificity.	amino acid substitution;amino acids;bioinformatics;computational biology;goldfish;gonadotropin-releasing hormone receptor;jack device component;machine learning;maximal set;mutation;odorants;odors;olfactory receptor cells;receptors, odorant;sensitivity and specificity;seventy nine;signal transduction;transduction (machine learning);mutant	M. Michael Gromiha;K. Harini;R. Sowdhamini;Kazuhiko Fukui	2012		10.1186/1471-2105-13-S7-S1	mutation;biology;biochemistry;dna microarray;bioinformatics;ligand;genetics;signal transduction;regression analysis	Comp.	8.37253100920009	-61.10013762768774	52552
c1308587dcf5fd1152b6b854e7295a7070cb6b85	dynamic, covert network simulation	simulation;covert;dynamic systems;multi agent;network;terrorism	Introduction Model Description Results Conclusion Motivation Problems There is a lack of open source covert network data. Any data on covert networks is almost certainly incomplete. Data we do have corresponds to one specific network with unique evolution. Introduction Model Description Results Conclusion Motivation Problems There is a lack of open source covert network data. Any data on covert networks is almost certainly incomplete. Data we do have corresponds to one specific network with unique evolution. Solution Generating data with DCNS allows us to test network analysis algorithms on a wide variety of networks, for which we know the ground truth. Introduction Model Description Results Conclusion Motivation Problems There is a lack of open source covert network data. Any data on covert networks is almost certainly incomplete. Data we do have corresponds to one specific network with unique evolution. Solution Generating data with DCNS allows us to test network analysis algorithms on a wide variety of networks, for which we know the ground truth. Objective: Generate a dynamic network which grows and evolves in response to internal characteristics as well as external intervention.	algorithm;ground truth;network theory;open-source software;simulation	Patrick M O'Neil	2012		10.1007/978-3-642-29047-3_29	simulation;network formation;computer science;dynamic network analysis;artificial intelligence;dynamical system;machine learning;data mining;network simulation;terrorism;computer security	ML	6.768706127112085	-58.42034126966305	52647
502b2c1921dee5a47272ed053921e07e8cc575ce	systematic identification of class i hdac substrates	prediction;deacetylation;class i hdacs;sequence feature;specificity	Lysine acetylation is a common post-translational modification of histone and non-histone proteins. This process has an important function in regulating transcriptional activities and other biological processes. Although several computer programs have been developed to predict protein acetylation sites, deacetylases responsible for known or predicted acetylation sites remain unknown. In this research, Class I histone deacetylases (HDACs) substrates were manually obtained, and sequence features of deacetylation sites were analyzed. We found that three members of Class I HDACs (HDAC1, HDAC2 and HDAC3) shared similar sequence features. Therefore, a method was proposed to identify the substrates of Class I HDACs. We evaluated the efficiency of the prediction based on P-value distribution analysis and leave-one-out test. To validate the result of the prediction, we overexpressed Class I HDACs in cells and detected the acetylation levels of potential substrates. In the experiment, five of the seven predicted proteins were deacetylated by Class I HDACs. These results suggested that our method could effectively predict protein deacetylation sites. The work has been integrated to the website ASEB, which was freely available at http://cmbi.bjmu.edu.cn/huac.	computer program;deacetylation;genetic translation process;hdac2 gene;histones;lysine;post-translational protein processing;transcription, genetic;histone deacetylase 3	Tingting Li;Boyan Song;Zheng Wu;Ming Lu;Wei-Guo Zhu	2014	Briefings in bioinformatics	10.1093/bib/bbt060	biology;biochemistry;bioinformatics;genetics	Comp.	9.044205405613319	-56.39832687188861	52652
5da7a39a952581faca5b568084cdb7be6754416a	identification of genomic signatures for the design of assays for the detection and monitoring of anthrax threats	biological agents;hybridization;efficiency;identification;bioassay;algorithms;cost effectiveness;genetics;fingerprints;sequences;genome;drug resistance;terrorism;dna fingerprinting	Sequences that are present in a given species or strain while absent from or different in any other organisms can be used to distinguish the target organism from other related or un-related species. Such DNA signatures are particularly important for the identification of genetic source of drug resistance of a strain or for the detection of organisms that can be used as biological agents in warfare or terrorism. Most approaches used to find DNA signatures are laboratory based, require a great deal of effort and can only distinguish between two organisms at a time. We propose a more efficient and cost-effective bioinformatics approach that allows identification of genomic fingerprints for a target organism. We validated our approach using a custom microarray, using sequences identified as DNA fingerprints of Bacillus anthracis. Hybridization results showed that the sequences found using our algorithm were truly unique to B. anthracis and were able to distinguish B. anthracis from its close relatives B. cereus and B. thuringiensis.	antivirus software;bacillus anthracis;bioinformatics;biological factors;biological science disciplines;biological warfare agents;cereus <cactus>;dna microarray format;dna barcoding;dna profiling;electronic signature;fingerprint;genome;ibm notes;inhalational anthrax;nephrogenic systemic fibrosis;nucleic acid hybridization;subgroup;type signature;algorithm	Sorin Draghici;Purvesh Khatri;Yanhong Liu;Kitty J. Chase;Elizabeth A. Bode;David A. Kulesh;Leonard P. Wasieloski;David A. Norwood;Jaques Reifman	2005	Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing		identification;biology;orbital hybridisation;fingerprint;dna profiling;drug resistance;cost-effectiveness analysis;biotechnology;bioinformatics;sequence;bioassay;efficiency;terrorism;biological agent;genetics;genome	Comp.	3.897790262671207	-60.38526541028526	52693
1e9402823fd561426d5176bfdee5ce3fb254d0fc	palindromic sequence impedes sequencing-by-ligation mechanism	escherichia coli;simulation and modeling;cloning molecular;systems biology;physiological cellular and medical topics;dna single stranded;deoxyribonucleases type ii site specific;computational biology bioinformatics;gene library;genome bacterial;algorithms;sequence analysis;molecular sequence data;inverted repeat sequences;base sequence;bioinformatics	Current next-generation sequencing (NGS) platforms adopt two types of sequencing mechanisms: by synthesis or by ligation. The former is employed by 454 and Solexa systems, while the latter by SOLiD system. Although the pros and cons for each sequencing mechanism have more or less been discussed in a number of occasions, the potential obstacle imposed by palindromic sequences has not yet been addressed. To test the effect of the palindromic region on sequencing efficacy, we clonally amplified a paired-end ditag sequence composed of a 24-bp palindromic sequence flanked by a pair of tags from the E. coli genome. We used the near homogeneous fragments produced from Mme I digestion of the amplified clone to generate a sequencing library for SOLiD 5500xl sequencer. Results showed that, traditional ABI sequencers, which adopt sequencing-by-synthesis mechanism, were able to read through the palindromic region. However, SOLiD 5500xl was unable to do so. Instead, the palindromic region was read as miscellaneous random sequences. Moreover, readable tag sequence turned obscure ~2 bp prior to the palindromic region. Taken together, we demonstrate that SOLiD machines, which employ sequencing-by-ligation mechanism, are unable to read through the palindromic region. On the other hand, sequencing-by-synthesis sequencers had no difficulty in doing so.	application binary interface;biopolymer sequencing;clone;communications satellite;completely unable;dvd region code;human-readable medium;ligation;mme gene;massively-parallel sequencing;microsequencer;protein digestion (research activity);negative regulation of reactive oxygen species biosynthetic process	Yu-Feng Huang;Sheng-Chung Chen;Yih-Shien Chiang;Tzu-Han Chen;Kuo-Ping Chiu	2012		10.1186/1752-0509-6-S2-S10	biology;molecular biology;bioinformatics;genomic library;sequence analysis;escherichia coli;genetics;systems biology	Comp.	2.4996885980098007	-60.95060926135701	52993
765151f53c333d76beb5035897ad553def566ec9	precedence temporal networks from gene expression data	dna;biology computing;cell cycle regulation precedence temporal networks gene expression data data extraction graphical represention precedence temporal network time series temporal abstraction technique association rules labeled graph gene expression temporal behavior dna microarrays expression analysis genes subset;gene expression dna data mining association rules proteins neoplasms data analysis measurement techniques genomics bioinformatics;gene expression data;time series;genetics;cell cycle regulation;gene expression;biology computing dna genetics molecular biophysics cellular biophysics temporal databases time series biochemistry;temporal abstraction;association rule;molecular biophysics;temporal databases;dna microarray;cellular biophysics;biochemistry	In this paper we introduce a novel method to extract from data and graphically represent the temporal relationships between events, called precedence temporal network. The new approach first derives events from time series by exploiting the temporal abstraction technique, then derives temporal precedence between abstractions in terms of association rules and finally expresses the relationships as a labeled graph. The method is applied to the problem of representing the temporal behavior of gene expressions, as they are collected by DNA microarrays. In particular, in this paper we present the results obtained from the analysis of the expression of a subset of the genes involved in cell-cycle regulation.	association rule learning;dna microarray;graph labeling;time series	Lucia Sacchi;Riccardo Bellazzi;Riccardo Porreca;Cristiana Larizza;Paolo Magni	2005	18th IEEE Symposium on Computer-Based Medical Systems (CBMS'05)	10.1109/CBMS.2005.83	gene expression;association rule learning;dna microarray;bioinformatics;theoretical computer science;cell cycle;time series;data mining;temporal database;dna;molecular biophysics	Theory	3.7746059815854984	-57.088431813753985	53088
f819364b1c4e8e2126b071b87777cc213f9d9b05	organocatalytic enantioselective henry reactions		A large number of interesting organocatalytic enantioselective protocols have been explored and successfully applied in the last decade. Among them, the Henry (nitroaldol) reaction represents a powerful carbon-carbon bond-forming procedure for the preparation of valuable synthetic intermediates, such as enantioenriched nitro alcohols, which can be further transformed in a number of important nitrogen and oxygen-containing compounds. This area of research is still in expansion and a more complex version of this useful process has recently emerged, the domino Michael/Henry protocol, affording highly functionalized cycles with multiple stereogenic centers.	chirality (chemistry);compiler;nitro (wireless networking);synthetic data	Yolanda Alvarez-Casao;Eugenia Marqués-López;Raquel P. Herrera	2011	Symmetry	10.3390/sym3020220	organocatalysis;enantioselective synthesis	Vision	-1.1414925435254535	-65.44893928830159	53153
ec513de0cd2dfe2a048e302500ace45632ae1746	mining proteomic ms/ms data for mrm transitions		Multiple reaction monitoring (MRM) of peptides is a popular proteomics technique that employs tandem mass spectrometry to quantify selected proteins of interest, such as those previously identified in differential protein identification studies. Using this technique, the specificity of precursor to product transitions is exploited to determine the absolute quantity of multiple proteins in a single sample. Selection of suitable transitions is critical for the success of MRM experiments, but accurate theoretical prediction of fragmentation patterns and peptide signal intensity is currently not possible. A recently proposed solution to this problem is to combine knowledge of the preferred properties of transitions for MRM, taken from expert practitioners, with MS/MS evidence extracted from a proteomics data repository. In addition, by predicting retention time for each peptide candidate, it allows selection of several compatible transition candidates that can be monitored simultaneously, permitting MRM. In this chapter, we explain how to go about designing transitions using the web-based transition design tool, MRMaid, which leverages high quality MS/MS evidence from the Genome Annotating Proteomic Pipeline (GAPP).		Jennifer A. Mead;Luca Bianco;Conrad Bessant	2010	Methods in molecular biology	10.1007/978-1-60761-444-9_13	biology	Comp.	4.603766883798122	-55.49682851759667	53159
44595b9e64c4a7f95d79c3516ed60383f10257dc	the stanford tissue microarray database	software;classification algorithm;image processing;rna messenger;databases genetic;in situ hybridization;immunohistochemistry;tissue array analysis;internet;proteins;tissue microarray;source code;humans;user computer interface;nucleic acid;antibodies	The Stanford Tissue Microarray Database (TMAD; http://tma.stanford.edu) is a public resource for disseminating annotated tissue images and associated expression data. Stanford University pathologists, researchers and their collaborators worldwide use TMAD for designing, viewing, scoring and analyzing their tissue microarrays. The use of tissue microarrays allows hundreds of human tissue cores to be simultaneously probed by antibodies to detect protein abundance (Immunohistochemistry; IHC), or by labeled nucleic acids (in situ hybridization; ISH) to detect transcript abundance. TMAD archives multi-wavelength fluorescence and bright-field images of tissue microarrays for scoring and analysis. As of July 2007, TMAD contained 205 161 images archiving 349 distinct probes on 1488 tissue microarray slides. Of these, 31 306 images for 68 probes on 125 slides have been released to the public. To date, 12 publications have been based on these raw public data. TMAD incorporates the NCI Thesaurus ontology for searching tissues in the cancer domain. Image processing researchers can extract images and scores for training and testing classification algorithms. The production server uses the Apache HTTP Server, Oracle Database and Perl application code. Source code is available to interested researchers under a no-cost license.	annotated tissue;body tissue;cell nucleus;contain (action);fluorescence;http;image processing;immunohistochemistry;in situ hybridization;information privacy;mandibular right second molar tooth;microarray databases;nc (complexity);nci thesaurus;neoplasms;nucleic acid hybridization;nucleic acids;numerous;ontology;oracle database;perl;score;server (computer);server (computing);slide (glass microscope);source code;tissue microarray;tracer;transcript;algorithm;archive	Robert J. Marinelli;Kelli Montgomery;Chih Long Liu;Nigam Haresh Shah;Wijan Prapong;Michael Nitzberg;Zachariah K. Zachariah;Gavin Sherlock;Yasodha Natkunam;Robert B. West;Matt van de Rijn;Patrick O. Brown;Catherine A. Ball	2008		10.1093/nar/gkm861	immunohistochemistry;biology;nucleic acid;tissue microarray;the internet;image processing;bioinformatics;antibody;in situ hybridization;source code	Comp.	-3.2288683520676296	-60.649890142983374	53197
1d6e6185a1ab7bf2654598e8c74cc92bcaf9efd6	decomposition of overlapping patterns by cumulative local cross-correlation	cross correlation;cumulative cross correlation;sequence repeat;sequence motif;pattern decomposition;cumulant;pattern reconstruction	A large portion of the usual eukaryotic genome is comprised of repetitive sequences. A common situation, when several related but different repeat families share the same conserved motif, complicates repeat classification and repeat boundary definition. If the repeats are aligned by the motif position, then the sequence profile (pattern) resulting from the alignment will represent overlapping of the profiles (patterns) corresponding to the individual families. A novel algorithm for the decomposition of overlapping patterns is proposed. It can be used with both continuous and gapped patterns. The technique is based on accumulation of simultaneously occurring pattern features found by cross-correlation procedure with limited lag length; thus, the name is Cumulative Local Cross-Correlation (referred further as CLCC). Its sensitivity is tested on human genomic sequences. Software implementation of the algorithm is available on request from the author.		Simon B. Kogan	2006	Journal of bioinformatics and computational biology	10.1142/S021972000600193X	biology;bioinformatics;cross-correlation;pattern recognition;mathematics;statistics;cumulant;sequence motif	Comp.	1.1409364498152041	-56.37367924953051	53202
cd98aac3e21c1d46ce4564f327cac12fb309801e	evolutionary and expression profiles of gene families crucial for central nervous system development	expression profile;gene family;functional diversity;central nervous system	Tissue or developmental-specificity in central nervous system (CNS) represents strong functional diversity in high eukaryote genomes. Expression profile and sequence data become two major lines of information. In this paper, we conducted evolutionary analysis for the expression profiles of 14 gene families (57 genes) in vertebrate CNS development. We found the strong association between developmental profile and the gene family diversity. We speculate that gen(om)e duplication might be the evolutionary basis for functional diversity. This expression/sequence dual informatics approach is useful for tracking the genetic regulatory changes in complex biosystem. 2002 Elsevier Science Inc. All rights reserved.	cns;ecosystem;gene family;informatics;sensitivity and specificity	Yufeng Wang;Xun Gu	2002	Inf. Sci.	10.1016/S0020-0255(02)00233-5	bioinformatics;central nervous system;gene family	Comp.	4.438679857843867	-61.259957280177694	53228
b5c6eb60e2a3d2f006d1dba58623425657e03f04	a new reference implementation of the psicquic web service	software;information resources;proteome;binding molecular function;internet;proteomics;languages	The Proteomics Standard Initiative Common QUery InterfaCe (PSICQUIC) specification was created by the Human Proteome Organization Proteomics Standards Initiative (HUPO-PSI) to enable computational access to molecular-interaction data resources by means of a standard Web Service and query language. Currently providing >150 million binary interaction evidences from 28 servers globally, the PSICQUIC interface allows the concurrent search of multiple molecular-interaction information resources using a single query. Here, we present an extension of the PSICQUIC specification (version 1.3), which has been released to be compliant with the enhanced standards in molecular interactions. The new release also includes a new reference implementation of the PSICQUIC server available to the data providers. It offers augmented web service capabilities and improves the user experience. PSICQUIC has been running for almost 5 years, with a user base growing from only 4 data providers to 28 (April 2013) allowing access to 151 310 109 binary interactions. The power of this web service is shown in PSICQUIC View web application, an example of how to simultaneously query, browse and download results from the different PSICQUIC servers. This application is free and open to all users with no login requirement (http://www.ebi.ac.uk/Tools/webservices/psicquic/view/main.xhtml).	augmented web;browsing;compliance behavior;download;information resources;interaction information;login;proteome;proteomics standards initiative;query language;question (inquiry);reference implementation;server (computing);specification;user experience;web application;web service;standards characteristics	Noemi del-Toro;Marine Dumousseau;Sandra E. Orchard;Rafael C. Jimenez;Eugenia Galeota;Guillaume Launay;Johannes B Goll;Karin Breuer;Keiichiro Ono;Lukasz Salwínski;Henning Hermjakob	2013		10.1093/nar/gkt392	web service;biology;the internet;web api;proteome;proteomics	Web+IR	-3.714318489916	-60.054609877805404	53245
4e38d12ce92df43e83637e2e3b7db8ffd45ca78b	nonsynonymous to synonymous substitution ratio ka/ks: measurement for rate of evolution in evolutionary computation	second order;sequence evolution;amino acid;genetic variation;optimization problem;evolutionary process;evolutionary system;evolutionary computing;rate of evolution	Measuring fitness progression using numeric quantification in an Evolutionary Computation (EC) system may not be sufficient to capture the rate of evolution precisely. In this paper, we define the rate of evolution Re in an EC system based on the rate of efficient genetic variations being accepted by the EC population. This definition is motivated by the measurement of “amino acid to synonymous substitution ratio” ka/ks in biology, which has been widely accepted to measure the rate of gene sequence evolution. Experimental applications to investigate the effects of four major configuration parameters on our rate of evolution measurement show that Re well reflects how evolution proceeds underneath fitness development and provides some insights into the effectiveness of EC parameters in evolution acceleration.	color gradient;evolutionary computation;ka band;software evolution	Ting Hu;Wolfgang Banzhaf	2008		10.1007/978-3-540-87700-4_45	optimization problem;amino acid;computer science;bioinformatics;genetic variation;genetics;second-order logic;evolutionary computation	Metrics	4.837388497212775	-61.1505207524357	53309
f30a3c2ac9b5f56dac20a9a456bd7416d75dab5b	metamapr: pathway independent metabolomic network analysis incorporating unknowns		UNLABELLED Metabolic network mapping is a widely used approach for integration of metabolomic experimental results with biological domain knowledge. However, current approaches can be limited by biochemical domain or pathway knowledge which results in sparse disconnected graphs for real world metabolomic experiments. MetaMapR integrates enzymatic transformations with metabolite structural similarity, mass spectral similarity and empirical associations to generate richly connected metabolic networks. This open source, web-based or desktop software, written in the R programming language, leverages KEGG and PubChem databases to derive associations between metabolites even in cases where biochemical domain or molecular annotations are unknown. Network calculation is enhanced through an interface to the Chemical Translation System, which allows metabolite identifier translation between >200 common biochemical databases. Analysis results are presented as interactive visualizations or can be exported as high-quality graphics and numerical tables which can be imported into common network analysis and visualization tools.   AVAILABILITY AND IMPLEMENTATION Freely available at http://dgrapov.github.io/MetaMapR/. Requires R and a modern web browser. Installation instructions, tutorials and application examples are available at http://dgrapov.github.io/MetaMapR/.   CONTACT ofiehn@ucdavis.edu.	data table;database;databases;desktop computer;experiment;gene regulatory network;graph - visual representation;graphics;identifier;imagery;interactive visualization;internet;kegg;mental association;metabolomics;network mapping;numerical analysis;open-source software;programming language;pubchem;r language;sparse matrix;structural similarity;web application;cell transformation	Dmitry Grapov;Kwanjeera Wanichthanarak;Oliver Fiehn	2015	Bioinformatics	10.1093/bioinformatics/btv194	computer science;bioinformatics;data mining;database	Comp.	-4.136872086512955	-58.8794129848354	53318
069835be197ef1b6c92bc1b91173b7579a5ad76c	reverse engineering gene regulatory networks using approximate bayesian computation	escherichia coli;high dimensionality;approximate bayesian computation;gene network;gene expression data;genetics;repairable system;gene expression;markov chain monte carlo;time use;biological systems;high throughput;longitudinal data;gene regulatory network;reverse engineering	Gene regulatory networks are collections of genes that interact with one other and with other substances in the cell. By measuring gene expression over time using high-throughput technologies, it may be possible to reverse engineer, or infer, the structure of the gene network involved in a particular cellular process. These gene expression data typically have a high dimensionality and a limited number of biological replicates and time points. Due to these issues and the complexity of biological systems, the problem of reverse engineering networks from gene expression data demands a specialized suite of statistical tools and methodologies. We propose a non-standard adaptation of a simulationbased approach known as Approximate Bayesian Computing based on Markov chain Monte Carlo sampling. This approach is particularly well suited for the inference of gene regulatory networks from longitudinal data. The performance of this approach is investigated via simulations and using longitudinal expression data from a genetic repair system in Escherichia coli.	approximation algorithm;biological system;computation;gene regulatory network;high-throughput computing;markov chain monte carlo;monte carlo method;reverse engineering;sampling (signal processing);simulation;throughput	Andrea Rau;Florence Jaffrézic;Jean-Louis Foulley;R. W. Doerge	2012	Statistics and Computing	10.1007/s11222-011-9309-1	gene regulatory network;computer science;bioinformatics;machine learning;data mining	Comp.	2.7061540324567472	-53.53272445688355	53322
0da9829cb471037efb8fbd138021959a08cd0bda	cobweb: a java applet for network exploration and visualisation	indonesia;indonesie;exploracion;langage java;reseau;red;asie;exploration;lenguaje java;network;asia;java language;java	SUMMARY Cobweb is a Java applet for real-time network visualization; its strength lies in enabling the interactive exploration of networks. Therefore, it allows new nodes to be interactively added to a network by querying a database on a server. The network constantly rearranges to provide the most meaningful topological view.   AVAILABILITY Cobweb is available under the GPLv3 and may be freely downloaded at http://bioinformatics.charite.de/cobweb.	bioinformatics;graph drawing;imagery;interactivity;java programming language;java applet;real-time computing;real-time web;scientific visualization;server (computing)	Joachim von Eichborn;Philip E. Bourne;Robert Preissner	2011	Bioinformatics	10.1093/bioinformatics/btr195	biology;java api for xml-based rpc;simulation;jsr 94;exploration;computer science;operating system;strictfp;real time java;java;world wide web;java applet;java annotation	Visualization	-4.4956984681204615	-58.01236137756186	53397
163d24c197d63d6264ffee84680f3306be558410	sinebase: a database and tool for sine analysis	software;animals;databases nucleic acid;position specific scoring matrices;consensus sequence;short interspersed nucleotide elements;internet;humans;base sequence	SINEBase (http://sines.eimb.ru) integrates the revisited body of knowledge about short interspersed elements (SINEs). A set of formal definitions concerning SINEs was introduced. All available sequence data were screened through these definitions and the genetic elements misidentified as SINEs were discarded. As a result, 175 SINE families have been recognized in animals, flowering plants and green algae. These families were classified by the modular structure of their nucleotide sequences and the frequencies of different patterns were evaluated. These data formed the basis for the database of SINEs. The SINEBase website can be used in two ways: first, to explore the database of SINE families, and second, to analyse candidate SINE sequences using specifically developed tools. This article presents an overview of the database and the process of SINE identification and analysis.	algae;angiosperms;caption;chlorophyta;classification;consensus sequence;nar 2;nucleotides;projection screen;short interspersed nucleotide elements;interferon alfacon-1	Nikita S. Vassetzky;Dmitri A. Kramerov	2013		10.1093/nar/gks1263	consensus sequence;biology;the internet;bioinformatics;genetics	DB	0.2503928021472662	-57.97005714694956	53451
803910c63ae457a06b7e8deef110ed25f4ae95dd	pairwise sequence alignment using bio-database compression by improved fine tuned enhanced suffix array		Sequence alignment is a bioinformatics application that determines the degree of similarity between nucleotide sequences which is assumed to have same ancestral relationships. This sequence alignment method reads query sequence from the user and makes an alignment against large and genomic sequence data sets and locate targets that are similar to an input query sequence. Existing accurate algorithm, such as smith-waterman and FASTA are computationally very expensive, which limits their use in practice. The existing search tools, such as BLAST and WUBLAST, employ heuristics to improve the speed of such searches. However, such heuristics can sometimes miss targets, in which many cases are undesirable. Considering the rapid growth of database sizes, this problem demands evergrowing computation resources and remains as a computational challenge. Most common sequence alignment algorithms like BLAST, WU-BLAST and Sequance Comparasion Tool (SCT) searches a given query sequence against set of database sequences. In this paper, Biological Data Base Compression Tool using Minimum Perfect Hash Function (BioDBMPHF) tool has been developed to find pair wise local sequence alignment by preprocessing the database. Preprocessing is done by means of finding Longest Common Substring (LCS) from the database of sequences that have the highest local similarity with a given query sequence and reduces the size of the database based on frequent common subsequence. In this BioDBMPHF tool fine-tuned enhanced suffix array is constructed and used to find LCS. Experimental results show that hash index algorithm reduces the time and space complexity to access LCS. Time complexity to find LCS of the hash index algorithm is O(2+γ) where ‘γ’ is the time taken to access the pattern. Space complexity of fine-tuned enhanced suffix array is 5n bytes per character for reduced enhanced Longest Common Prefix (LCP) table and to store bucket table it requires 32 bytes. Data mining technique is used to cross validate the result. It is proved that the developed BioDBMPHF tool effectively compresses the database and obtains same results compared to that traditional algorithm in approximately half the time taken by them thereby reducing the time complexity.	blast;bioinformatics;british informatics olympiad;byte;computation;dspace;data mining;fasta;hash table;heuristic (computer science);longest common substring problem;perfect hash function;preprocessor;sequence alignment;smith–waterman algorithm;suffix array;time complexity	Arumugam Kunthavai;Somasundaram Vasantharathna;Swaminathan Thirumurugan	2015	Int. Arab J. Inf. Technol.		computer science;bioinformatics;theoretical computer science;machine learning;data mining;algorithm	DB	-2.1660018909005543	-52.37778339059029	53540
98e45a4cccd7cbffd7af78ec87eed635839ab40c	the human oral microbiome database: a web accessible resource for investigating oral microbe taxonomic and genomic information	computers;software;mouth;web accessibility;databases genetic;metagenome;rna bacterial;internet;metagenomics;genome bacterial;rna ribosomal 16s;humans;sequence alignment;bacteria;phenotype	The human oral microbiome is the most studied human microflora, but 53% of the species have not yet been validly named and 35% remain uncultivated. The uncultivated taxa are known primarily from 16S rRNA sequence information. Sequence information tied solely to obscure isolate or clone numbers, and usually lacking accurate phylogenetic placement, is a major impediment to working with human oral microbiome data. The goal of creating the Human Oral Microbiome Database (HOMD) is to provide the scientific community with a body site-specific comprehensive database for the more than 600 prokaryote species that are present in the human oral cavity based on a curated 16S rRNA gene-based provisional naming scheme. Currently, two primary types of information are provided in HOMD--taxonomic and genomic. Named oral species and taxa identified from 16S rRNA gene sequence analysis of oral isolates and cloning studies were placed into defined 16S rRNA phylotypes and each given unique Human Oral Taxon (HOT) number. The HOT interlinks phenotypic, phylogenetic, genomic, clinical and bibliographic information for each taxon. A BLAST search tool is provided to match user 16S rRNA gene sequences to a curated, full length, 16S rRNA gene reference data set. For genomic analysis, HOMD provides comprehensive set of analysis tools and maintains frequently updated annotations for all the human oral microbial genomes that have been sequenced and publicly released. Oral bacterial genome sequences, determined as part of the Human Microbiome Project, are being added to the HOMD as they become available. We provide HOMD as a conceptual model for the presentation of microbiome data for other human body sites. Database URL: http://www.homd.org.	blast;bacterial 16s rna;clone;colony count, microbial;dental caries;genome;genome, bacterial;intestinal microbiome;microorganism;name;oral microbiome;oral cavity;phylogenetics;prokaryote;search engine;sequence analysis;url data type	Tsute Chen;Wen-Han Yu;Jacques Izard;Oxana V. Baranova;Abirami Lakshmanan;Floyd E. Dewhirst	2010		10.1093/database/baq013	biology;the internet;bacteria;bioinformatics;phenotype;web accessibility;sequence alignment;earth microbiome project;genetics;metagenomics	Comp.	-0.9499821898178271	-60.25058382401042	53561
9b0899c6b5d1938c12d519a7d7172d771935137d	analytic derivation of bacterial growth laws from a simple model of intracellular chemical dynamics	bacterial growth laws;cellular economy;chemical dynamics;growth rate optimization;mathematical modeling	Experiments have found that the growth rate and certain other macroscopic properties of bacterial cells in steady-state cultures depend upon the medium in a surprisingly simple manner; these dependencies are referred to as ‘growth laws’. Here we construct a dynamical model of interacting intracellular populations to understand some of the growth laws. The model has only three population variables: an amino acid pool, a pool of enzymes that transport an external nutrient and produce the amino acids, and ribosomes that catalyze their own and the enzymes’ production from the amino acids. We assume that the cell allocates its resources between the enzyme sector and the ribosomal sector to maximize its growth rate. We show that the empirical growth laws follow from this assumption and derive analytic expressions for the phenomenological parameters in terms of the more basic model parameters. Interestingly, the maximization of the growth rate of the cell as a whole implies that the cell allocates resources to the enzyme and ribosomal sectors in inverse proportion to their respective ‘efficiencies’. The work introduces a mathematical scheme in which the cellular growth rate can be explicitly determined and shows that two large parameters, the number of amino acid residues per enzyme and per ribosome, are useful for making approximations.	amino acids;approximation;chemical dynamics;computation (action);dicom derivation;dill (dietary);dynamical system;expectation–maximization algorithm;experiment;interaction;mathematical optimization;mathematics;nonlinear system;population parameter;ribosomes;steady state;cell growth	Parth Pratim Pandey;Sanjay Jain	2016		10.1007/s12064-016-0227-9	biology;biochemistry;bioinformatics;ecology	ML	7.733325908709087	-64.14904348761507	53623
17fe53695d789d61b7516d2456bb8ed3972704b3	improved mutation tagging with gene identifiers applied to membrane protein stability prediction	genes;animals;genomics;stability region;databases genetic;protein stability;amino acid substitution;periodicals as topic;structure function relationship;computational biology bioinformatics;g protein coupled receptor;protein structure;models genetic;named entity recognition;point mutation;algorithms;pattern recognition automated;sequence analysis;humans;combinatorial libraries;computational biology;phenotype;membrane protein;computer appl in life sciences;information storage and retrieval;pubmed;regular expression;mutation;microarrays;membrane proteins;bioinformatics	The automated retrieval and integration of information about protein point mutations in combination with structure, domain and interaction data from literature and databases promises to be a valuable approach to study structure-function relationships in biomedical data sets. We developed a rule- and regular expression-based protein point mutation retrieval pipeline for PubMed abstracts, which shows an F-measure of 87% for the mutation retrieval task on a benchmark dataset. In order to link mutations to their proteins, we utilize a named entity recognition algorithm for the identification of gene names co-occurring in the abstract, and establish links based on sequence checks. Vice versa, we could show that gene recognition improved from 77% to 91% F-measure when considering mutation information given in the text. To demonstrate practical relevance, we utilize mutation information from text to evaluate a novel solvation energy based model for the prediction of stabilizing regions in membrane proteins. For five G protein-coupled receptors we identified 35 relevant single mutations and associated phenotypes, of which none had been annotated in the UniProt or PDB database. In 71% reported phenotypes were in compliance with the model predictions, supporting a relation between mutations and stability issues in membrane proteins. We present a reliable approach for the retrieval of protein mutations from PubMed abstracts for any set of genes or proteins of interest. We further demonstrate how amino acid substitution information from text can be utilized for protein structure stability studies on the basis of a novel energy model.	abstract summary;amino acid substitution;amino acids;benchmark (computing);database;databases;gene prediction;identifier;membrane proteins;name;named entity;named-entity recognition;phenotype;point mutation;protein data bank;protein structure;pubmed;regular expression;relevance;silo (dataset);uniprot;algorithm	Rainer Winnenburg;Conrad Plake;Michael Schroeder	2008	BMC Bioinformatics	10.1186/1471-2105-10-S8-S3	biology;genomics;bioinformatics;membrane protein;genetics	Comp.	0.4817272464679256	-60.213470228563445	53657
2a85d3d248186f57ad6533db49e40e5a4864758e	actin-interacting proteins in flagellated pathogenic leishmania spp.: a genome-based bioinformatics report on profilins, formins and katanins	katanin genes;aip;formin genes;genome based bioinformatics;intraflagellar mechanisms;flagellar proteins;actin interacting proteins;profilin genes;leishmania;sequence analysis;structural analysis	In search for genomic and proteomic evidences of flagellar genes/proteins in Leishmania spp., we have used available databases and bioinformatics tools to distinguish Actin-Interacting Proteins (AIPs) that are flagellar and, also, probable virulence factors. Here we present results of sequence and structural analyses of profilins, formins and katanins, whose sequences were in silico selected for predicting viable roles on flagellum assembly, disassembly and dynamics in terms of intraflagellar mechanisms. Taken together, our results provide the first bioinformatics analyses of Leishmania profilin, katanin and formin genes and their gene products to contribute to a more detailed annotation of these important AIPs.	bioinformatics;database;disassembler;proteomics	Elton José R. Vasconcelos;Ana Carolina L. Pacheco;Joao J. S. Gouveia;Fabiana Freire Araújo;Michely C. Diniz;Michel T. Kamimura;Marcilia P. Costa;Raimundo Araujo-Filho;Diana Magalhaes de Oliveira	2008	I. J. Functional Informatics and Personalised Medicine	10.1504/IJFIPM.2008.021389	biology;cell biology;bioinformatics;sequence analysis;structural analysis;genetics	Comp.	4.57724103075415	-60.33296135555467	53692
92d4bd266689fc0b4017a062add4852050fcaf55	data-driven integration of epidemiological and toxicological data to select candidate interacting genes and environmental factors in association with disease	gene environment interaction;genome wide association study;databases genetic;environment;diabetes mellitus type 2;humans;toxicogenetics;computational biology	MOTIVATION Complex diseases, such as Type 2 Diabetes Mellitus (T2D), result from the interplay of both environmental and genetic factors. However, most studies investigate either the genetics or the environment and there are a few that study their possible interaction in context of disease. One key challenge in documenting interactions between genes and environment includes choosing which of each to test jointly. Here, we attempt to address this challenge through a data-driven integration of epidemiological and toxicological studies. Specifically, we derive lists of candidate interacting genetic and environmental factors by integrating findings from genome-wide and environment-wide association studies. Next, we search for evidence of toxicological relationships between these genetic and environmental factors that may have an etiological role in the disease. We illustrate our method by selecting candidate interacting factors for T2D.	choose (action);dna integration;diabetes mellitus;diabetes mellitus, non-insulin-dependent;documented;epidemiology;interaction;software documentation	Chirag J. Patel;Rong Chen;Atul J. Butte	2012		10.1093/bioinformatics/bts229	genome-wide association study;biology;gene–environment interaction;toxicology;bioinformatics;natural environment;candidate gene;genetics	AI	4.844366840237736	-58.18250573900648	53738
7dd73dbabdf5f5ac192dbc8e255cc15bb14c6f66	data-driven prediction and design of bzip coiled-coil interactions	peptides;protein multimerization;protein structure secondary;amino acid sequence;basic leucine zipper transcription factors;models molecular;models statistical;humans;computational biology;article	Selective dimerization of the basic-region leucine-zipper (bZIP) transcription factors presents a vivid example of how a high degree of interaction specificity can be achieved within a family of structurally similar proteins. The coiled-coil motif that mediates homo- or hetero-dimerization of the bZIP proteins has been intensively studied, and a variety of methods have been proposed to predict these interactions from sequence data. In this work, we used a large quantitative set of 4,549 bZIP coiled-coil interactions to develop a predictive model that exploits knowledge of structurally conserved residue-residue interactions in the coiled-coil motif. Our model, which expresses interaction energies as a sum of interpretable residue-pair and triplet terms, achieves a correlation with experimental binding free energies of R = 0.68 and significantly out-performs other scoring functions. To use our model in protein design applications, we devised a strategy in which synthetic peptides are built by assembling 7-residue native-protein heptad modules into new combinations. An integer linear program was used to find the optimal combination of heptads to bind selectively to a target human bZIP coiled coil, but not to target paralogs. Using this approach, we designed peptides to interact with the bZIP domains from human JUN, XBP1, ATF4 and ATF5. Testing more than 132 candidate protein complexes using a fluorescence resonance energy transfer assay confirmed the formation of tight and selective heterodimers between the designed peptides and their targets. This approach can be used to make inhibitors of native proteins, or to develop novel peptides for applications in synthetic biology or nanotechnology.	atf4 gene;atf5 gene;coil device component;coiled-coil domain;dimerization;energy transfer;energy, physics;fluorescence;greater than;homology (biology);integer (number);interaction;leucine;linear programming;motif;predictive modelling;programming, linear;resonance;score;scoring functions for docking;sensitivity and specificity;synthetic biology;synthetic intelligence;transcription factor;transcription (software);triplet state;xbp1 gene	Vladimir Potapov;Jenifer B. Kaplan;Amy E. Keating	2015		10.1371/journal.pcbi.1004046	computational biology;biology;biochemistry;bioinformatics;peptide sequence;bzip domain	Comp.	9.80170264547401	-59.65279176367465	53754
68818b79d360aa92e479864e12414dc502820e1e	automated protein distribution detection in high-throughput image-based sirna library screens	rna interference;edge detection;distributed detection;protein aggregation;computational method;high throughput screening;automatic detection;fluorescence microscopy;intermediate filament;image analysis;high throughput;drug screening;keratin proteins;in vitro culture;object detection;mutant detection	The availability of RNA interference (RNAi) libraries, automated microscopy and computational methods enables millions of biochemical assays to be carried out simultaneously. This allows systematic, data driven highthroughput experiments to generate biological hypotheses that can then be verified with other techniques. Such highthroughput screening holds great potential for new discoveries and is especially useful in drug screening. In this study, we present a computational framework for an automatic detection of changes in images of in vitro cultured keratinocytes when phosphatase genes are silenced using RNAi technology. In these high-throughput assays, the change in pattern only happens in 1–2% of the cells and fewer than one in ten genes that are silenced cause phenotypic changes in the keratin intermediate filament network, with small keratin aggregates appearing in cells in addition to the normal reticular network seen in untreated cells. By taking advantage of incorporating prior biological knowledge about phenotypic changes into our algorithm, it can successfully filter out positive ‘hits’ in this assay which is shown in our experiments. We have taken a stepwise approach to the problem, combining different analyses, each of which is well-designed to solve a portion of the problem. These include, aggregate enhancement, edge detection, circular object detection, aggregate clustering, prior to final classification. This strategy has been instrumental in our ability to successfully detect cells containing protein aggregates.	aggregate data;algorithm;cluster analysis;edge detection;experiment;high-throughput computing;interference (communication);library (computing);object detection;stepwise regression;throughput;virtual screening	Yan Nei Law;Stephen Ogg;John Common;David Tan;E. Birgitte Lane;Andy M. Yip;Hwee Kuan Lee	2009	Signal Processing Systems	10.1007/s11265-008-0205-7	high-throughput screening;computer vision;image analysis;computer science;bioinformatics	Comp.	3.1968403410670123	-56.69378780130189	53946
bcc3cf11e64e60c726a3007896a3f311d3e54a6f	cemitool: a bioconductor package for performing comprehensive modular co-expression analyses	co-expression modules;gene networks;leishmaniasis;modular analysis;transcriptomics	The analysis of modular gene co-expression networks is a well-established method commonly used for discovering the systems-level functionality of genes. In addition, these studies provide a basis for the discovery of clinically relevant molecular pathways underlying different diseases and conditions. In this paper, we present a fast and easy-to-use Bioconductor package named CEMiTool that unifies the discovery and the analysis of co-expression modules. Using the same real datasets, we demonstrate that CEMiTool outperforms existing tools, and provides unique results in a user-friendly html report with high quality graphs. Among its features, our tool evaluates whether modules contain genes that are over-represented by specific pathways or that are altered in a specific sample group, as well as it integrates transcriptomic data with interactome information, identifying the potential hubs on each network. We successfully applied CEMiTool to over 1000 transcriptome datasets, and to a new RNA-seq dataset of patients infected with Leishmania, revealing novel insights of the disease’s physiopathology. The CEMiTool R package provides users with an easy-to-use method to automatically implement gene co-expression network analyses, obtain key information about the discovered gene modules using additional downstream analyses and retrieve publication-ready results via a high-quality interactive report.	base sequence;bioconductor;display resolution;downstream (software development);functional disorder;gene co-expression network;genus: leishmania;html;interactome;name;one thousand;patients;rna;silo (dataset);usability	Pedro S. T. Russo;Gustavo R. Ferreira;Lucas E. Cardozo;Matheus C. Bürger;Raúl Arias-Carrasco;Sandra Regina Maruyama;Thiago D. C. Hirata;Diógenes S. Lima;Fernando M. Passos;Kiyoshi F. Fukutani;Melissa Lever;João S. Silva;Vinicius Maracaja-Coutinho;Helder I. Nakaya	2018		10.1186/s12859-018-2053-1	dna microarray;bioconductor;biology;transcriptome;gene regulatory network;gene;bioinformatics;modular design	Comp.	-0.4494954625842058	-58.53745095115789	53967
0ac3a04bce0d11d6668d43d4f344a8661aca0b0c	pisces: a protein sequence culling server	protein sequence;quality criteria;protein data bank	PISCES is a public server for culling sets of protein sequences from the Protein Data Bank (PDB) by sequence identity and structural quality criteria. PISCES can provide lists culled from the entire PDB or from lists of PDB entries or chains provided by the user. The sequence identities are obtained from PSI-BLAST alignments with position-specific substitution matrices derived from the non-redundant protein sequence database. PISCES therefore provides better lists than servers that use BLAST, which is unable to identify many relationships below 40% sequence identity and often overestimates sequence identity by aligning only well-conserved fragments. PDB sequences are updated weekly. PISCES can also cull non-PDB sequences provided by the user as a list of GenBank identifiers, a FASTA format file, or BLAST/PSI-BLAST output.	amino acid sequence;blast;fasta format;fishes;genbank;identifier;peptide sequence;protein data bank;sense of identity (observable entity);sequence alignment;sequence database;server (computer);server (computing);staphylococcal protein a;substitution matrix	Guoli Wang;Roland L. Dunbrack	2003	Bioinformatics	10.1093/bioinformatics/btg224	biology;sequence profiling tool;protein data bank;bioinformatics;protein sequencing;database;world wide web	Comp.	-1.9434833155942768	-60.17927234078085	53989
8be988e25af7cdd59ef8b49137e13c1a4389a506	scpc: a method to structurally compare protein complexes	protein complexes;efficient automated method;novel method;existing method;protein complex;bioinformatics online;jp supplementary information;conventional classification;protein interaction;protein data bank	MOTIVATION Protein-protein interactions play vital functional roles in various biological phenomena. Physical contacts between proteins have been revealed using experimental approaches that have solved the structures of protein complexes at atomic resolution. To examine the huge number of protein complexes available in the Protein Data Bank, an efficient automated method that compares protein complexes is required.   RESULTS We have developed Structural Comparison of Protein Complexes (SCPC), a novel method to structurally compare protein complexes. SCPC compares the spatial arrangements of subunits in a complex with those in another complex using secondary structure elements. Similar substructures are detected in two protein complexes and the similarity is scored. SCPC was applied to dimers, homo-oligomers and haemoglobins. SCPC properly estimated structural similarities between the dimers examined as well as an existing method, MM-align. Conserved substructures were detected in a homo-tetramer and a homo-hexamer composed of homologous proteins. Classification of quaternary structures of haemoglobins using SCPC was consistent with the conventional classification. The results demonstrate that SCPC is a valuable tool to investigate the structures of protein complexes.   AVAILABILITY SCPC is available at http://idp1.force.cs.is.nagoya-u.ac.jp/scpc/.   CONTACT rkoike@is.nagoya-u.ac.jp   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.		Ryotaro Koike;Motonori Ota	2012	Bioinformatics	10.1093/bioinformatics/btr654	biology;bioinformatics	Comp.	8.17904900263219	-57.627664789152455	54005
2404304a89b1586cb904cb9f75da659772f83f00	ixdb, an x chromosome integrated database (update)	chromosome mapping;terminology as topic;gene expression;internet;humans;databases factual;x chromosome;information storage and retrieval	Chromosome specific databases are an important research tool as they integrate data from different directions, such as genetic and physical mapping data, expression data, sequences etc. They supplement the genome-wide repositories in molecular biology, such as GenBank, Swiss-Prot or OMIM, which usually concentrate on one type of information. The Integrated X Chromosome Database (IXDB, http://ixdb.mpimg-berlin-dahlem.mpg.de/) is a repository for physical mapping data of the human X chromosome and aims at providing a global view of genomic data at a chromosomal level. We present here an update of IXDB which includes schema extensions for storing submaps and sequence information, additional links to external databases, and the integration of an increasing number of physical and transcript mapping data. The gene data was completely updated according to the approved gene symbols of the HUGO Nomenclature Committee. IXDB receives over 1000 queries per month, an indication that its content is valuable to researchers seeking mapping data of the human X chromosome.	committee, drug;congenital chromosomal disease;genbank;hgnc;molecular biology;one thousand;online mendelian inheritance in man;published database;rodent nomenclature name;swiss-model;software repository;switzerland;transcript	Ulf Leser;Hugues Roest Crollius;Hans Lehrach;Ralf Sudbrak	1999	Nucleic acids research	10.1093/nar/27.1.123	biology;the internet;gene expression;bioinformatics;genetics;x chromosome	DB	-2.3586008626533297	-61.000438481072585	54089
18d6a1c8c50e881acfade5625fd266991598b842	distinct functional and conformational states of the human lymphoid tyrosine phosphatase catalytic domain can be targeted by choice of the inhibitor chemotype	catalytic domain;ptpn22;lyp;drug design;docking;protein tyrosine phosphorylation;homology modeling	The lymphoid tyrosine phosphatase (LYP), encoded by the PTPN22 gene, has recently been identified as a promising drug target for human autoimmunity diseases. Like the majority of protein-tyrosine phosphatases LYP can adopt two functionally distinct forms determined by the conformation of the WPD-loop. The WPD-loop plays an important role in the catalytic dephosphorylation by protein-tyrosine phosphatases. Here we investigate the binding modes of two chemotypes of small molecule LYP inhibitors with respect to both protein conformations using computational modeling. To evaluate binding in the active form, we built a LYP protein structure model of high quality. Our results suggest that the two different compound classes investigated, bind to different conformations of the LYP phosphatase domain. Binding to the closed form is facilitated by an interaction with Asp195 in the WPD-loop, presumably stabilizing the active conformation. The analysis presented here is relevant for the design of inhibitors that specifically target either the closed or the open conformation of LYP in order to achieve better selectivity over phosphatases with similar binding sites.	autoimmune diseases;binding sites;catalytic domain;class;display resolution;drug delivery systems;hematological disease;phosphoric monoester hydrolases;protein tyrosine phosphatase;protein tyrosine phosphatase, non-receptor type 6;protein dephosphorylation;protein, organized by structure;selectivity (electronic);small molecule;wavelet packet decomposition	Dusica Vidovic;Yuli Xie;Alison Rinderspacher;Shi-Xian Deng;Donald W. Landry;Caty Chung;Deborah H. Smith;Lutz Tautz;Stephan C. Schürer	2011	Journal of computer-aided molecular design	10.1007/s10822-011-9469-2	docking;biology;biochemistry;stereochemistry;homology modeling;chemistry;bioinformatics;drug design	Comp.	9.37206783840208	-60.80642855748481	54099
679e27576ba6bd229ea09eb7b5824f8535fb4215	modeling biochemical pathways using an artificial chemistry	fatty acid;biomolecular engineering;scalability artificial chemistry biochemical pathways biomolecular engineering reasoning modularity;pattern matching;biochemical pathways;modularity;scalability;reasoning;artificial chemistry	Artificial chemistries are candidates for methodologies that model and design biochemical systems. If artificial chemistries can deal with such systems in beneficial ways, they may facilitate activities in the new area of biomolecular engineering. In order to explore such possibilities, we illustrate four models of biochemical pathways described in our artificial chemistry based on string pattern matching and recombination. The modeled pathways are the replication of DNA, transcription from DNA to mRNA, translation from mRNA to protein, and the oxidation of fatty acids. The descriptions show that the present approach has good modularity and scalability that will be useful for modeling a huge network of pathways. Moreover, we give a procedure to perform reasoning in the artificial chemistry, which checks whether a specified collection of molecules can be generated in a given model, and we demonstrate that it works on a model that describes a natural biochemical pathway.	artificial chemistry;crossover (genetic algorithm);description;fatty acids;gene regulatory network;pattern matching;reasoning;scalability;transcription (software);oxidation	Kazuto Tominaga;Yoshikazu Suzuki;Keiji Kobayashi;Tooru Watanabe;Kazumasa Koizumi;Koji Kishi	2009	Artificial Life	10.1162/artl.2009.15.1.15108	biology;artificial chemistry;metabolic pathway;scalability;biomolecular engineering;computer science;bioinformatics;theoretical computer science;machine learning;pattern matching;modularity;fatty acid;reason	AI	2.950515246873079	-64.96483407408644	54457
b9ff0d209684708530f16e8b98b2177732335d66	web-based metabolic network visualization with a zooming user interface	software;zooming user interface;escherichia coli;metabolic networks and pathways;metabolic network;enzyme;web service;computational biology bioinformatics;cells;internet;algorithms;user computer interface;databases factual;combinatorial libraries;computer appl in life sciences;microarrays;bioinformatics	Displaying complex metabolic-map diagrams, for Web browsers, and allowing users to interact with them for querying and overlaying expression data over them is challenging. We present a Web-based metabolic-map diagram, which can be interactively explored by the user, called the Cellular Overview. The main characteristic of this application is the zooming user interface enabling the user to focus on appropriate granularities of the network at will. Various searching commands are available to visually highlight sets of reactions, pathways, enzymes, metabolites, and so on. Expression data from single or multiple experiments can be overlaid on the diagram, which we call the Omics Viewer capability. The application provides Web services to highlight the diagram and to invoke the Omics Viewer. This application is entirely written in JavaScript for the client browsers and connect to a Pathway Tools Web server to retrieve data and diagrams. It uses the OpenLayers library to display tiled diagrams. This new online tool is capable of displaying large and complex metabolic-map diagrams in a very interactive manner. This application is available as part of the Pathway Tools software that powers multiple metabolic databases including Biocyc.org: The Cellular Overview is accessible under the Tools menu.	cdisc adas-cog - commands summary score;database;diagram;experiment;gene regulatory network;graph drawing;imagery;interactivity;internet;javascript;map;metabolic process, cellular;metabolite;omics;openlayers;power (psychology);server (computer);server (computing);user interface device component;web server;web service;zooming user interface	Mario Latendresse;Peter D. Karp	2010		10.1186/1471-2105-12-176	web service;biology;enzyme;the internet;dna microarray;human–computer interaction;computer science;bioinformatics;escherichia coli;zoom;world wide web;metabolic network	HCI	-4.102933122940031	-58.674705062062266	54465
214793564bcbcfd85b1a89c448c93e00cf6835a3	biomine: a network-structured resource of biological entities for link prediction	biological concept;biomine graph database;million relation;million entity;gene code;possible link prediction measure;biological graph database;biological entity;network-structured resource;link discovery;biological graph	biological concept;biomine graph database;million relation;million entity;gene code;possible link prediction measure;biological graph database;biological entity;network-structured resource;link discovery;biological graph	entity	Lauri Eronen;Petteri Hintsanen;Hannu Toivonen	2012		10.1007/978-3-642-31830-6_26	computer science;bioinformatics;theoretical computer science;data mining	NLP	4.667538174339539	-56.55905508541497	54497
85d130da98c2e58b78249919e2fb8073bfea9f07	discovering structural alerts for mutagenicity using stable emerging molecular patterns		This study is dedicated to the introduction of a novel method that automatically extracts potential structural alerts from a data set of molecules. These triggering structures can be further used for knowledge discovery and classification purposes. Computation of the structural alerts results from an implementation of a sophisticated workflow that integrates a graph mining tool guided by growth rate and stability. The growth rate is a well-established measurement of contrast between classes. Moreover, the extracted patterns correspond to formal concepts; the most robust patterns, named the stable emerging patterns (SEPs), can then be identified thanks to their stability, a new notion originating from the domain of formal concept analysis. All of these elements are explained in the paper from the point of view of computation. The method was applied to a molecular data set on mutagenicity. The experimental results demonstrate its efficiency: it automatically outputs a manageable number of structural patterns that are strongly related to mutagenicity. Moreover, a part of the resulting structures corresponds to already known structural alerts. Finally, an in-depth chemical analysis relying on these structures demonstrates how the method can initiate promising processes of chemical knowledge discovery.	archive;association rule learning;benchmark (computing);biologic preservation;chemical library;cheminformatics;class;computation (action);data mining;description;extraction;fifty nine;formal concept analysis;forty nine;graph - visual representation;https;hasse diagram;how true feel alert right now;internet;journal of chemical information and modeling;mandibular right second molar tooth;molecular structure;name;ontology (information science);point of view (computer hardware company);rule (guideline);silo (dataset);small molecule libraries;statistical classification;structural pattern;structure mining;test set;contents - htmllinktype;explanation	Jean-Philippe Métivier;Alban Lepailleur;Aleksey Buzmakov;Guillaume Poezevara;Bruno Crémilleux;Sergei O. Kuznetsov;Jérémie Le Goff;Amedeo Napoli;Ronan Bureau;Bertrand Cuissart	2015	Journal of chemical information and modeling	10.1021/ci500611v	computer science;bioinformatics;theoretical computer science;machine learning;data mining	ML	3.4162550639596247	-56.877264721122295	54593
9b9dd1aa108b720a68828213b5da6558e5a909e5	windock: structure-based drug discovery on windows-based pcs	drug discovery;windows based pc;computer aided drug discovery;virtual screening;homology modeling;high throughput docking;structure based drug discovery	In recent years, virtual database screening using high-throughput docking (HTD) has emerged as a very important tool and a well-established method for finding new lead compounds in the drug discovery process. With the advent of powerful personal computers (PCs), it is now plausible to perform HTD investigations on these inexpensive PCs. To make HTD more accessible to a broad community, we present here WinDock, an integrated application designed to help researchers perform structure-based drug discovery tasks under a uniform, user friendly graphical interface for Windows-based PCs. WinDock combines existing small molecule searchable three-dimensional (3D) libraries, homology modeling tools, and ligand-protein docking programs in a semi-automatic, interactive manner, which guides the user through the use of each integrated software component. WinDock is coded in C++.		Zengjian Hu;William M. Southerland	2007	Journal of computational chemistry	10.1002/jcc.20756	pharmacology;homology modeling;chemistry;virtual screening;combinatorial chemistry;drug discovery	Graphics	-2.787147837561511	-59.3571828690591	54594
1fe86c6f870cb726fe1ac09856ca368a6f9bf8fd	finding short dna motifs using permuted markov models	maximal dependence decomposition;model selection;transcription factor binding site;transcription factor binding sites;splice sites;markov model;permuted variable length markov models;dna motifs;maximal dependence decomposition models;weight matrix models;jeffreys mixture;matrix model	Many short DNA motifs such as transcription factor binding sites (TFBS) and splice sites exhibit strong local as well as non-local dependence. We introduce permuted variable length Markov models (PVLMM) which could capture the potentially important dependencies among positions, and apply them to the problem of detecting splice and TFB sites. They have been satisfactory from the viewpoint of prediction performance, and also give ready biological interpretations of the sequence dependence observed. The issue of model selection is also studied.	binding sites;dna binding site;interpretation process;markov chain;markov model;model selection;published comment;sensor;splice (system call);transcription factor;thin film lithium-ion battery;transcription (software)	Xiaoyue Zhao;Haiyan Huang;Terence P. Speed	2004	Journal of computational biology : a journal of computational molecular cell biology	10.1145/974614.974624	combinatorics;bioinformatics;mathematics;genetics;dna binding site;statistics	Comp.	3.4639383353342175	-62.98795437670428	54602
542845a1bede43ecafdc122696110ca31efb9721	a crowdsourcing method for correcting sequencing errors for the third-generation sequencing data	the third generation sequencing data;sequencing error;error correction method;hybrid crowdsourcing algorithm	The third generation sequencing data exposes great advantage on read length, which extremely benefits the genomic analyses. However, the third generation sequencing data implies error models different from the ones that the second generation data brings. It is suggested to correct sequencing errors, which could significantly reduce false positives in downstream analyses. Existing error correction approaches often suffer accuracy loss when the hybrid reads present diversity or the coverage varies. In this paper, we propose a novel method based on crowdsourcing strategy, which is implemented as CLTC. CLTC is also a hybrid correction algorithm, which consists of four steps. The second generation reads are first collected and mapped to the third generation reads. Then, the base difficult level is defined to describe the diversities on a base among a group of 2nd-generation reads covered it. The capability is evaluated for each 2nd-generation read, which considers the base difficult levels across the read, the consistency among overlapped reads and the mapping quality between the 2nd- and 3rd-generation reads. A heuristic algorithm is designed for the calculation of capabilities. An expectation-maximization algorithm is finally used to compute the corrected result for each base-pair. We test CLTC on different datasets and compare to the existing approaches. The results demonstrate that CLTC is able to achieve higher accuracy and performs faster than the existing ones.	cross-validation (statistics);crowdsourcing;downstream (software development);error detection and correction;expectation–maximization algorithm;experiment;heuristic (computer science);high-level programming language;second generation multiplex plus;simulation;time complexity	Yu Geng;Zhongmeng Zhao;Zhaofang Du;Yixuan Wang;Tian Zheng;Siyu He;Xuanping Zhang;Jiayin Wang	2017	2017 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2017.8217903	computer science;error detection and correction;machine learning;cltc;artificial intelligence;algorithm design;heuristic (computer science);false positive paradox;crowdsourcing	SE	0.3853242955441352	-54.298570792055656	54631
d0cbc34cef42ba207d038d55f5af8d6f3f5fb6ee	identification of transcript regulatory patterns in cell differentiation		Motivation Studying transcript regulatory patterns in cell differentiation is critical in understanding its complex nature of the formation and function of different cell types. This is done usually by measuring gene expression at different stages of the cell differentiation. However, if the gene expression data available are only from the mature cells, we have some challenges in identifying transcript regulatory patterns that govern the cell differentiation.   Results We propose to exploit the information of the lineage of cell differentiation in terms of correlation structure between cell types. We assume that two different cell types that are close in the lineage will exhibit many common genes that are co-expressed relative to those that are far in the lineage. Current analysis methods tend to ignore this correlation by testing for differential expression assuming some sort of independence between cell types. We employ a Bayesian approach to estimate the posterior distribution of the mean of expression in each cell type, by taking into account the cell formation path in the lineage. This enables us to infer genes that are specific in each cell type, indicating the genes are involved in directing the cell differentiation to that particular cell type. We illustrate the method using gene expression data from a study of haematopoiesis.   Availability and implementation R codes to perform the analysis are available in http://www1.maths.leeds.ac.uk/∼arief/R/CellDiff/.   Contact a.gusnanto@leeds.ac.uk.   Supplementary information Supplementary data are available at Bioinformatics online.	bioinformatics;cell (microprocessor);cell differentiation process;code;gene expression;geographic information systems;hematopoiesis;inference;lineage (evolution);transcript;cell type	Arief Gusnanto;John Paul Gosling;Christopher Pope	2017	Bioinformatics	10.1093/bioinformatics/btx406	cellular differentiation;gene expression;haematopoiesis;gene;cell type;bioinformatics;cell;genetics;biology	Comp.	3.8214541154286996	-58.88561547072311	54684
73c74a4a56c18f1389f2758da61e27b5ada3873f	engineering signal processing in cells: towards molecular concentration band detection	protein ligand interaction;gene network;genetics;acyl homoserine lactone;fluorescent protein;signal processing;cell communication;ribosome binding site;kinetics;dna binding protein	We seek to couple protein-ligand interactions with synthetic gene networks in order to equip cells with the ability to process internal and environmental information in novel ways. In this paper, we propose and analyze a new genetic signal processing circuit that can be configured to detect various chemical concentration ranges of ligand molecules. These molecules freely diffuse from the environment into the cell. The circuit detects acyl-homoserine lactone ligand molecules, determines if the molecular concentration falls within two prespecified thresholds, and reports the outcome with a fluorescent protein. In the analysis of the circuit and the description of preliminary experimental results, we demonstrate how to adjust the concentration band thresholds by altering the kinetic properties of specific genetic elements, such as ribosome binding site efficiencies or dna-binding protein affinities to their operators.	signal processing	Subhayu Basu;David K. Karig;Ron Weiss	2002		10.1007/3-540-36440-4_6	biology;biochemistry;molecular biology;bioinformatics	ML	5.361220263168808	-65.33870477552713	54873
7eab9ececfc2bc3ac1d90b8ad85961af8b61c8da	analysis of gene expression data using a linear mixed model/finite mixture model approach: application to regional differences in the human brain		MOTIVATION Gene expression data exhibit common information over the genome. This article shows how data can be analysed from an efficient whole-genome perspective. Further, the methods have been developed so that users with limited expertise in bioinformatics and statistical computing techniques could use and modify this procedure to their own needs. The method outlined first uses a large-scale linear mixed model for the expression data genome-wide, and then uses finite mixture models to separate differentially expressed (DE) from non-DE transcripts. These methods are illustrated through application to an exceptional UK Brain Expression Consortium involving 12 human frozen post-mortem brain regions.   RESULTS Fitting linear mixed models has allowed variation in gene expression between different biological states (e.g. brain regions, gender, age) to be investigated. The model can be extended to allow for differing levels of variation between different biological states. Predicted values of the random effects show the effects of each transcript in a particular biological state. Using the UK Brain Expression Consortium data, this approach yielded striking patterns of co-regional gene expression. Fitting the finite mixture model to the effects within each state provides a convenient method to filter transcripts that are DE: these DE transcripts can then be extracted for advanced functional analysis.   AVAILABILITY The data for all regions except HYPO and SPCO are available at the Gene Expression Omnibus (GEO) site, accession number GSE46706. R code for the analysis is available in the Supplementary file.	accession number (identifier);accession number (bioinformatics);bioinformatics;computational statistics;consortium;curve fitting;extraction;gene expression;mixed model;mixture model;r language;random effects model;station hypo;switch;transcript	Daniah Trabzuni;Peter C. Thomson	2014	Bioinformatics	10.1093/bioinformatics/btu088	computer science;bioinformatics;data science;data mining	Comp.	3.3393083899197613	-58.59551292644562	54906
c23121bcdb8e9fc74cfc80da38f220592dff07c7	from uncertain protein interaction networks to signaling pathways through intensive color coding		Discovering signaling pathways in protein interaction networks is a key ingredient in understanding how proteins carry out cellular functions. These interactions however can be uncertain events that may or may not take place depending on many factors including the internal factors, such as the size and abundance of the proteins, or the external factors, such as mutations, disorders and drug intake. In this paper, we consider the problem of finding causal orderings of nodes in such protein interaction networks to discover signaling pathways. We adopt color coding technique to address this problem. Color coding method may fail with some probability. By allowing it to run for sufficient time, however, its confidence in the optimality of the result can converge close to 100%. Our key contribution in this paper is elimination of the key conservative assumptions made by the traditional color coding methods while computing its success probability. We do this by carefully establishing the relationship between node colors, network topology and success probability. As a result our method converges to any confidence value much faster than the traditional methods. Thus, it is scalable to larger protein interaction networks and longer signaling pathways than existing methods. We demonstrate, both theoretically and experimentally that our method outperforms existing methods.	anatomic node;anatomy, regional;causal filter;color;color-coding;composite blocking list;converge;deregulation;emoticon;excretory function;experiment;gene expression;graph coloring;high-throughput computing;interaction network;iteration;large;mutation;network topology;occur (action);ptpn1 gene;pixel density;proton pump inhibitors;shc1 gene;scalability;silo (dataset);throughput;growth factor receptor-bound protein 2;hepatocyte growth factor-regulated tyrosine kinase substrate;protein protein interaction	Haitham Gabr;Alin Dobra;Tamer Kahveci	2013	Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing		bioinformatics;scalability;signal transduction;network topology;protein interaction networks;biology;color-coding	Comp.	5.6054878905635155	-57.48478890338257	54948
6affecd7922a7984e09139bd674aa6e4cf9eac5b	snplink: multipoint linkage analysis of densely distributed snp data incorporating automated linkage disequilibrium removal	aves;linkage equilibrium;high density;analisis datos;liaison genetique;linkage analysis;polimorfismo mononucleotido;automatisation;vertebrata;equilibre linkage;methode;automatizacion;genetic mapping;molecular population genetics;data analysis;polymorphisme mononucleotide;genetic linkage;genome;carte genetique;analyse donnee;non parametric statistics;equilibrio ligazon;mapa genetico;genoma;metodo;linkage disequilibrium;method;single nucleotide polymorphism;falco columbarius;automation;ligamiento genetico	SUMMARY SNPLINK is a Perl script that performs full genome linkage analysis of high-density single nucleotide polymorphism (SNP) marker sets. The presence of linkage disequilibrium (LD) between closely spaced SNP markers can falsely inflate linkage statistics. SNPLINK removes LD from the marker sets in an automated fashion before carrying out linkage analysis. SNPLINK can compute both parametric and non-parametric statistics, utilizing the freely available Allegro and Merlin software. Graphical outputs of whole genome multipoint linkage statistics are provided allowing comparison of results before and after the removal of LD.	allegro;graphical user interface;linkage disequilibrium;multipoint ground;nitroprusside;nucleotides;perl;single nucleotide polymorphism;single-chain antibodies;statistics, nonparametric;whole genome sequencing;genetic linkage;heparan sulfate proteoglycan biosynthetic process, linkage to polypeptide	Emily L. Webb;Gabrielle S. Sellick;Richard S. Houlston	2005	Bioinformatics	10.1093/bioinformatics/bti449	linkage disequilibrium;biology;genetic linkage;bioinformatics;genetics	Comp.	-3.173601546676566	-56.136932040907205	55055
9c7f677a5606a655e4dee9740bef61cec8e9f8da	a frequent polymorphism of the complement component c4 gene	complement c4;chromosome;gen;hombre;chromosomes human 6 12 and x;complemento c4;polymorphism genetic;fragmento restriccion;fragment restriction;dna restriction enzymes;polymorphism;cromosoma;human;gene;polymorphisme;humans;polimorfismo;restriction fragment;homme		complement component c4	R. Goldstein;J. Gruhn;F. C. Arnett;Madeleine Duvic	1986	Nucleic acids research	10.1093/nar/14.13.5570	biology;polymorphism;molecular biology;restriction fragment;gene;chromosome;genetics	Logic	3.3273326163686505	-63.669885990935136	55070
09f584727243143c264f469ed0003e1779350548	inferring a protein interaction map of mycobacterium tuberculosis based on sequences and interologs	animals;escherichia coli;support vector machines;computational biology bioinformatics;host pathogen interactions;algorithms;humans;combinatorial libraries;protein interaction maps;computer appl in life sciences;article;mycobacterium tuberculosis;microarrays;bioinformatics	Mycobacterium tuberculosis is an infectious bacterium posing serious threats to human health. Due to the difficulty in performing molecular biology experiments to detect protein interactions, reconstruction of a protein interaction map of M. tuberculosis by computational methods will provide crucial information to understand the biological processes in the pathogenic microorganism, as well as provide the framework upon which new therapeutic approaches can be developed. In this paper, we constructed an integrated M. tuberculosis protein interaction network by machine learning and ortholog-based methods. Firstly, we built a support vector machine (SVM) method to infer the protein interactions of M. tuberculosis H37Rv by gene sequence information. We tested our predictors in Escherichia coli and mapped the genetic codon features underlying its protein interactions to M. tuberculosis. Moreover, the documented interactions of 14 other species were mapped to the interactome of M. tuberculosis by the interolog method. The ensemble protein interactions were validated by various functional relationships, i.e., gene coexpression, evolutionary relationship and functional similarity, extracted from heterogeneous data sources. The accuracy and validation demonstrate the effectiveness and efficiency of our framework. A protein interaction map of M. tuberculosis is inferred from genetic codons and interologs. The prediction accuracy and numerically experimental validation demonstrate the effectiveness and efficiency of our method. Furthermore, our methods can be straightforwardly extended to infer the protein interactions of other bacterial species.	biological processes;cdisc sdtm microorganism terminology;codon (nucleotide sequence);document completion status - documented;experiment;extraction;genetic heterogeneity;genus mycobacterium;homology (biology);inference;interaction network;interactome;interolog;machine learning;molecular biology;mycobacterium tuberculosis genotype:prid:pt:isolate:nom;numerical analysis;staphylococcal protein a;support vector machine;mapped;protein protein interaction	Zhi-Ping Liu;Jiguang Wang;Yu-Qing Qiu;Ross K. K. Leung;Xiang-Sun Zhang;Stephen Kwok-Wing Tsui;Luonan Chen	2012		10.1186/1471-2105-13-S7-S6	biology;support vector machine;dna microarray;computer science;bioinformatics;microbiology;escherichia coli;genetics	Comp.	6.210548793373897	-56.735269859682326	55233
53968e7476b14b354d761dc493fd71ab8540451d	computational systems biology-based feature selection for cancer prognosis			computation;feature selection;modelling biological systems;systems biology	Syed Abbas Haider	2012				Logic	1.101393026489538	-66.07336718590645	55236
ab9ef56dc925cd6bf40f17085cc7a75e2017d16c	state of the journal		The views expressed in this article do not necessarily reflect the views of the journal or of ASM .nnThe Journal of Bacteriology (JB) is a prestigious periodical that publishes research articles that probe fundamental processes in bacteria, archaea, and their viruses and the molecular mechanisms by		David A. Forsyth	2015	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/TPAMI.2014.2370854		Vision	0.3818766366195349	-64.36512993626305	55309
fc8508abc3a4f2b22af7c6bcf74ec54008ad2b06	lenvardb: database of length-variant protein domains	indel mutation;genetic variation;models molecular;internet;proteins;protein structure tertiary;sequence alignment;sequence analysis protein;databases protein	Protein domains are functionally and structurally independent modules, which add to the functional variety of proteins. This array of functional diversity has been enabled by evolutionary changes, such as amino acid substitutions or insertions or deletions, occurring in these protein domains. Length variations (indels) can introduce changes at structural, functional and interaction levels. LenVarDB (freely available at http://caps.ncbs.res.in/lenvardb/) traces these length variations, starting from structure-based sequence alignments in our Protein Alignments organized as Structural Superfamilies (PASS2) database, across 731 structural classification of proteins (SCOP)-based protein domain superfamilies connected to 2 730 625 sequence homologues. Alignment of sequence homologues corresponding to a structural domain is available, starting from a structure-based sequence alignment of the superfamily. Orientation of the length-variant (indel) regions in protein domains can be visualized by mapping them on the structure and on the alignment. Knowledge about location of length variations within protein domains and their visual representation will be useful in predicting changes within structurally or functionally relevant sites, which may ultimately regulate protein function. Non-technical summary: Evolutionary changes bring about natural changes to proteins that may be found in many organisms. Such changes could be reflected as amino acid substitutions or insertions-deletions (indels) in protein sequences. LenVarDB is a database that provides an early overview of observed length variations that were set among 731 protein families and after examining >2 million sequences. Indels are followed up to observe if they are close to the active site such that they can affect the activity of proteins. Inclusion of such information can aid the design of bioengineering experiments.	amino acid sequence;amino acid substitution;amino acids;clinical act of insertion;database;experiment;homology (biology);indel mutation;peptide sequence;protein domain;protein family;superfamily;scop;sequence alignment;tracing (software);tympanostomy tube insertion	Eshita Mutt;Oommen K. Mathew;Ramanathan Sowdhamini	2014		10.1093/nar/gkt1014	biology;structural alignment;molecular biology;homology modeling;the internet;multiple sequence alignment;bioinformatics;genetic variation;loop modeling;sequence alignment;protein function prediction;protein domain;genetics;structural classification of proteins database	Comp.	1.5969011282498158	-60.296102786505685	55329
f4dabe90b031b9ed23e478e73e26f87712f7be02	origin of amino acid homochirality: relationship with the rna world and origin of trna aminoacylation	amino acid;trna;homochirality;minihelix;origin of life;rna world;amino acids;aminoacylation;stereochemistry	The origin of homochirality of l-amino acids has long been a mystery. Aminoacylation of tRNA might have provided chiral selectivity, since it is the first process encountered by amino acids and RNA. An RNA minihelix (progenitor of the modern tRNA) was aminoacylated by an aminoacyl phosphate oligonucleotide that exhibited a clear preference for l- as opposed to d-amino acids. A mirror-image RNA system with l-ribose exhibited the opposite selectivity, i.e., it exhibited an apparent preference for the d-amino acid. The selectivity for l-amino acids is based on the stereochemistry of RNA. The side chain of d-amino acids is located much closer to the terminal adenosine of the minihelix, causing them collide and interfere during the amino acid-transfer step. These results suggest that the putative RNA world that preceded the protein theatre determined the homochirality of l-amino acids through tRNA aminoacylation.	adenosine;amino acid metabolism, inborn errors;amino acids;amino acids, branched-chain;carbamoyl-phosphate synthase i deficiency disease;chirality (chemistry);ribose;selectivity (electronic);stereochemistry (discipline);transfer rna aminoacylation;inorganic phosphate	Koji Tamura	2008	Bio Systems	10.1016/j.biosystems.2007.12.005	biology;biochemistry;amino acid;genetics	Comp.	5.94614916135075	-63.49646454280028	55332
8b1469b47c3a6aee701251474f3c3c35b7575682	the protein common interface database (protcid)—a comprehensive database of interactions of homologous proteins in multiple crystal forms	proximal isovelocity surface area;phylogeny;chronic fatigue syndrome;protein interaction domains and motifs;dimers;models molecular;proteins;sequence homology amino acid;crystal structure;cystic fibrosis;protein interaction mapping;crystallography x ray;architecture;protein data bank;dimerization;databases protein	The protein common interface database (ProtCID) is a database that contains clusters of similar homodimeric and heterodimeric interfaces observed in multiple crystal forms (CFs). Such interfaces, especially of homologous but non-identical proteins, have been associated with biologically relevant interactions. In ProtCID, protein chains in the protein data bank (PDB) are grouped based on their PFAM domain architectures. For a single PFAM architecture, all the dimers present in each CF are constructed and compared with those in other CFs that contain the same domain architecture. Interfaces occurring in two or more CFs comprise an interface cluster in the database. The same process is used to compare heterodimers of chains with different domain architectures. By examining interfaces that are shared by many homologous proteins in different CFs, we find that the PDB and the Protein Interfaces, Surfaces, and Assemblies (PISA) are not always consistent in their annotations of biological assemblies in a homologous family. Our data therefore provide an independent check on publicly available annotations of the structures of biological interactions for PDB entries. Common interfaces may also be useful in studies of protein evolution. Coordinates for all interfaces in a cluster are downloadable for further analysis. ProtCiD is available at http://dunbrack2.fccc.edu/protcid.	architecture as topic;databases;gentian violet;geographic coordinate system;homology (biology);interaction;interface device component;pfam;protcid;protein data bank	Qifang Xu;Roland L. Dunbrack	2011		10.1093/nar/gkq1059	biology;protein data bank;bioinformatics;crystal structure;architecture;phylogenetics	Comp.	-0.05377743987487975	-59.666700783378	55446
354f95e0f7a5106f67de0096e81311aebeeae20e	clare: cracking the language of regulatory elements	software;animals;genomics;mice;prosencephalon;transcription factors;gene expression regulation;humans;regulatory sequences nucleic acid;organ specificity;enhancer elements genetic	UNLABELLED CLARE is a computational method designed to reveal sequence encryption of tissue-specific regulatory elements. Starting with a set of regulatory elements known to be active in a particular tissue/process, it learns the sequence code of the input set and builds a predictive model from features specific to those elements. The resulting model can then be applied to user-supplied genomic regions to identify novel candidate regulatory elements. CLARE's model also provides a detailed analysis of transcription factors that most likely bind to the elements, making it an invaluable tool for understanding mechanisms of tissue-specific gene regulation.   AVAILABILITY CLARE is freely accessible at http://clare.dcode.org/.	encryption;password cracking;predictive modelling;providing (action);transcription factor;transcription (software)	Leila Taher;Leelavati Narlikar;Ivan Ovcharenko	2012	Bioinformatics	10.1093/bioinformatics/btr704	biology;genomics;regulation of gene expression;bioinformatics;genetics;transcription factor	Comp.	1.1608710251357988	-59.72117700431274	55553
7efdaa9faa2c8ae06020c0aaa668d9103d5eb86f	whichp450: a multi-class categorical model to predict the major metabolising cyp450 isoform for a compound	cytochrome p450;drug–drug interactions;metabolism;multi-class classification;random forests	In the development of novel pharmaceuticals, the knowledge of how many, and which, Cytochrome P450 isoforms are involved in the phase I metabolism of a compound is important. Potential problems can arise if a compound is metabolised predominantly by a single isoform in terms of drug-drug interactions or genetic polymorphisms that would lead to variations in exposure in the general population. Combined with models of regioselectivities of metabolism by each isoform, such a model would also aid in the prediction of the metabolites likely to be formed by P450-mediated metabolism. We describe the generation of a multi-class random forest model to predict which, out of a list of the seven leading Cytochrome P450 isoforms, would be the major metabolising isoforms for a novel compound. The model has a 76% success rate with a top-1 criterion and an 88% success rate for a top-2 criterion and shows significant enrichment over randomised models.	cytochrome p450;diagnostic accuracy assessment criterion;dosage forms;gene ontology term enrichment;genetic algorithm;hereditary diseases;interaction;metabolite;numerous;protein isoforms;random forest	Peter A. Hunt;Matthew D. Segall;Jonathan D. Tyzack	2018	Journal of computer-aided molecular design	10.1007/s10822-018-0107-0	computational biology;chemistry;bioinformatics;categorical variable;cytochrome p450;random forest;gene isoform;population;drug metabolism	ML	7.464769353755795	-54.89507536611177	55579
3e5ee595d5d8a3bce333f18fae19741858196dbf	tmcompare: transmembrane region sequence and structure	anotacion;helical structure;secuencia aminoacido;proteina membranar;sequence aminoacide;visualizacion;aminoacid sequence;deteccion;selection;annotation;estructura helicoidal;detection;proteine membranaire;visualization;internet;visualisation;structure helice;seleccion;membrane protein	UNLABELLED TMCompare is an alignment and visualization tool for comparison of sequence information for membrane proteins contained in SWISS-PROT entries, with structural information contained in PDB files. The program can be used for: detection of breaks in alpha helical structure of transmembrane regions; examination of differences in coverage between PDB and SWISS-PROT files; examination of annotation differences between PDB files and associated SWISS-PROT files; examination and comparison of assigned PDB alpha helix regions and assigned SWISS-PROT transmembrane regions in linear sequence (one letter code) format; examination of these differences in 3D using the CHIME plugin, allowing; analysis of the alpha and non-alpha content of transmembrane regions.   AVAILABILITY TMCompare is available for use through selection of a query protein via the internet (http://www.membraneproteins.org/TMCompare)   CONTACT tmcompare@membraneproteins.org	alignment;annotation;cheese swiss ab.igg:acnc:pt:ser:qn;contain (action);membrane proteins;personnameuse - assigned;protein data bank;question (inquiry);swiss-model;switzerland;transmembrane domain	Roberto C. Togawa;John F. Antoniw;Jonathan G. L. Mullins	2001	Bioinformatics	10.1093/bioinformatics/17.12.1238	biology;visualization;computer science;bioinformatics;world wide web	Comp.	-3.9733791616720517	-57.16655511151949	55755
82a5093091b1ebe31cb80db114b7766cb205c9be	using boolean networks to model post-transcriptional regulation in gene regulatory networks	gene regulatory networks;network analysis;boolean networks;mirna;complex systems;post transcriptional regulation	Gene Regulatory Networks (GRNs) model some of the mechanisms that regulate gene expression. Among the computational approaches available to model and study GNRs, Boolean Network (BN) emerged as very successful to better understand both the structural and dynamical properties of GRNs. Nevertheless, the most widely used models based on BNs do not include any post-transcriptional regulation mechanism. Since miRNAs have been proved to play an important regulatory role, in this paper we show how the post-transcriptional regulation mechanism mediated by miRNAs has been included in an enhanced BN-based model. We resort to the miR-7 in two Drosophila cell fate determination networks to verify the effectiveness of miRNAs modeling in BNs, by implementing it in our tool for the analysis of Boolean Networks.	boolean network;dynamical system;gene regulatory network	Gianfranco Politano;Alessandro Savino;Alfredo Benso;Stefano Di Carlo;Hafeez Ur Rehman;Alessandro Vasciaveo	2014	J. Comput. Science	10.1016/j.jocs.2013.10.005	gene regulatory network;complex systems;network analysis;bioinformatics;post-transcriptional regulation;data mining;microrna	Theory	6.072879933930912	-58.96136504018735	55830
8867b065ba717821c422f63b0b66c76c05ff4cb9	disorder in protein structure and function - session introduction	protein structure	It is commonly assumed that a protein must attain a stable, folded conformation in order to carry out its specific biological function. Not all proteins conform to this simple view of protein structure and function, however. Certain regions within proteins, and in some cases entire proteins, are not ordered into a unique tertiary structure, but instead appear to exist as ensembles of structures. Protein structures determined by X-ray crystallography and NMR have revealed numerous such disordered regions, some of them quite extensive. Recent progress in predicting regions of disorder from amino acid sequence has provided evidence that these regions occur in nature with an unexpectedly high frequency 1. There is now a growing awareness of the fundamental importance of disordered protein sequences in many biological processes. Disordered protein sequences function in some cases to mechanically uncouple structured domains, making their dynamics less constrained. Linkers of this type are important in a diverse collection of proteins, from viral attachment proteins to transcription factors. Disordered regions also provide access for protease digestion, which is critical for the regulation of many important cellular processes. Disorder-to-order transitions in proteins may be one of the major factors in biomechanics, for example in the development of force by protein assemblies. Disorder-to-order transitions may have a crucial role to play in macromolecular recognition. There are numerous examples of protein-protein, protein-nucleic acid, and protein-ligand interactions involving disordered protein segments. It has been postulated that disorder-to-order transitions provide a mechanism for uncoupling binding affinity and specificity 2 , thereby permitting weak but highly specific interactions, or conversely, strong but relatively nonspecific interactions.	attachments;function (biology);interaction;peptide sequence;processor affinity;sensitivity and specificity;transcription (software)	C. Kissinger;A. Keith Dunker;Eugene I. Shakhnovich	1999			bioinformatics;traction (orthopedics);tread;shield;biology	Comp.	7.2705662056249745	-62.74022431946574	55899
95f0fbb128fb710d77eb607f8b6292479ece77b2	chemically based mathematical model for development of cerebral cortical folding patterns	progenitor cell;animals;models neurological;temporal lobe;lemurs;pattern formation;reaction diffusion system;models chemical;eigenvalues;mathematical models;mathematical model;ventricular zone;cerebral cortex;primates;humans;local interaction;neurons;subventricular zone	The mechanism for cortical folding pattern formation is not fully understood. Current models represent scenarios that describe pattern formation through local interactions, and one recent model is the intermediate progenitor model. The intermediate progenitor (IP) model describes a local chemically driven scenario, where an increase in intermediate progenitor cells in the subventricular zone correlates to gyral formation. Here we present a mathematical model that uses features of the IP model and further captures global characteristics of cortical pattern formation. A prolate spheroidal surface is used to approximate the ventricular zone. Prolate spheroidal harmonics are applied to a Turing reaction-diffusion system, providing a chemically based framework for cortical folding. Our model reveals a direct correlation between pattern formation and the size and shape of the lateral ventricle. Additionally, placement and directionality of sulci and the relationship between domain scaling and cortical pattern elaboration are explained. The significance of this model is that it elucidates the consistency of cortical patterns among individuals within a species and addresses inter-species variability based on global characteristics and provides a critical piece to the puzzle of cortical pattern formation.	approximation algorithm;brain;heart rate variability;image scaling;inter-process communication;interaction;lateral computing;lateral thinking;lateral ventricle structure;mathematical model;mathematics;pattern formation;stem cells;subventricular zone;turing	Deborah A. Striegel;Monica K. Hurdal	2009		10.1371/journal.pcbi.1000524	biology;mathematical model;genetics;anatomy	ML	8.558615672387957	-65.20716778592278	55910
1d1731fc5e72e26509729a119d6ce51cfe718a2d	jerarca: efficient analysis of complex networks using hierarchical clustering	engineering;software;hierarchical clustering;public library of science;articulo;complex network;signal transduction;biology;automatic evaluation;graphs;genetic networks;network analysis;physics;cluster analysis;open access;chemistry;inclusive;neighbor joining algorithm;ante disciplinary;algorithms;medicine;efficiency analysis;neighbor joining;plos;computational biology;protein interaction networks;biological network;phylogenetics;phylogenetic analysis	BACKGROUND How to extract useful information from complex biological networks is a major goal in many fields, especially in genomics and proteomics. We have shown in several works that iterative hierarchical clustering, as implemented in the UVCluster program, is a powerful tool to analyze many of those networks. However, the amount of computation time required to perform UVCluster analyses imposed significant limitations to its use.   METHODOLOGY/PRINCIPAL FINDINGS We describe the suite Jerarca, designed to efficiently convert networks of interacting units into dendrograms by means of iterative hierarchical clustering. Jerarca is divided into three main sections. First, weighted distances among units are computed using up to three different approaches: a more efficient version of UVCluster and two new, related algorithms called RCluster and SCluster. Second, Jerarca builds dendrograms based on those distances, using well-known phylogenetic algorithms, such as UPGMA or Neighbor-Joining. Finally, Jerarca provides optimal partitions of the trees using statistical criteria based on the distribution of intra- and intercluster connections. Outputs compatible with the phylogenetic software MEGA and the Cytoscape package are generated, allowing the results to be easily visualized.   CONCLUSIONS/SIGNIFICANCE THE FOUR MAIN ADVANTAGES OF JERARCA IN RESPECT TO UVCLUSTER ARE: 1) Improved speed of a novel UVCluster algorithm; 2) Additional, alternative strategies to perform iterative hierarchical clustering; 3) Automatic evaluation of the hierarchical trees to obtain optimal partitions; and, 4) Outputs compatible with popular software such as MEGA and Cytoscape.	algorithm;biological network;cluster analysis;computation;cytoscape;dendrogram;distance;hierarchical clustering;interaction;iteration;iterative method;list of phylogenetics software;neighbor joining;proteomics;time complexity;trees (plant);upgma;statistical cluster	Rodrigo Aldecoa;Ignacio Marín	2010		10.1371/journal.pone.0011585	biology;biological network;network analysis;bioinformatics;neighbor joining;hierarchical clustering;cluster analysis;graph;complex network;signal transduction;phylogenetics	ML	3.9925741004403656	-55.699132544877806	55918
02a7858733098bb1ad17615b0d65c64c68866ccd	calculation of the relative metastabilities of proteins in subcellular compartments of saccharomyces cerevisiae	simulation and modeling;environmental variables;saccharomyces cerevisiae;intracellular space;model system;systems biology;oxygen;saccharomyces cerevisiae proteins;physiological cellular and medical topics;journal article;computational biology bioinformatics;oxidation reduction;endoplasmic reticulum;relative abundance;oxidation reduction potential;open system;thermodynamics;algorithms;electrochemical techniques;bioinformatics	Protein subcellular localization and differences in oxidation state between subcellular compartments are two well-studied features of the the cellular organization of S. cerevisiae (yeast). Theories about the origin of subcellular organization are assisted by computational models that can integrate data from observations of compositional and chemical properties of the system. I adopt the hypothesis that the state of yeast subcellular organization is in a local energy minimum. This hypothesis implies that equilibrium thermodynamic models can yield predictions about the interdependence between populations of proteins and their subcellular chemical environments. Three types of tests are proposed. First, there should be correlations between modeled and observed oxidation states for different compartments. Second, there should be a correspondence between the energy requirements of protein formation and the order the appearance of organelles during cellular development. Third, there should be correlations between the predicted and observed relative abundances of interacting proteins within compartments. The relative metastability fields of subcellular homologs of glutaredoxin and thioredoxin indicate a trend from less to more oxidizing as mitochondrion – cytoplasm – nucleus. Representing the overall amino acid compositions of proteins in 23 different compartments each with a single reference model protein suggests that the formation reactions for proteins in the vacuole (in relatively oxidizing conditions), ER and early Golgi (in relatively reducing conditions) are relatively highly favored, while that for the microtubule is the most costly. The relative abundances of model proteins for each compartment inferred from experimental data were found in some cases to correlate with the predicted abundances, and both positive and negative correlations were found for some assemblages of proteins in known complexes. The results of these calculations and tests suggest that a tendency toward a metastable energy minimum could underlie some organizational links between the the chemical thermodynamic properties of proteins and subcellular chemical environments. Future models of this kind will benefit from consideration of additional thermodynamic variables together with more detailed subcellular observations.	amino acids;anatomical compartments;cell nucleus;cellular organizational structure;composition;computational model;equilibrium;inference;interaction;interdependence;microtubules;mitochondria;multi-compartment model;organelles;population;protein biosynthesis;reference model;requirement;saccharomyces cerevisiae;thermodynamics;thioredoxins;vacuole;chemical properties;glutaredoxin;oxidation	Jeffrey M. Dick	2009	BMC Systems Biology	10.1186/1752-0509-3-75	biology;relative species abundance;redox;cell biology;intracellular;endoplasmic reticulum;bioinformatics;protein subcellular localization prediction;oxygen;open system;reduction potential;systems biology	Comp.	8.116585619919595	-62.72988348963259	55922
c190d61c32d64740f93dc06153f4e71d2b402d36	apoptosis: an optimization approach	minimum protein consumption;apoptosis;blood coagulation;procaspase concentrations;enzyme;optimization problem;kinetics;optimization model;oxygen transport	The present study examined the levels of procaspases (zymogens of the main apoptosis enzymes, caspases) that are predicted based on application of the optimization principle. Optimization models have previously been successfully developed for many other physiological systems (e.g., circulation, oxygen transport system, fibrinolysis, and blood coagulation) but have not previously been applied to apoptotic biochemical pathways. Our model assumed that apoptotic pathways are designed to minimize protein consumption. Procaspase concentrations were predicted based on this assumption, along with known schemes of apoptosis reactions and kinetic constants for procaspase activation and target cleavage. Good agreement between the model predictions and actual procaspase levels was observed.		Michael A. Khanin;Aleksey N. Lobanov;Scott H. Kaufmann	2004	Computers in biology and medicine	10.1016/S0010-4825(03)00089-1	optimization problem;enzyme;apoptosis;immunology;kinetics	Comp.	9.65980607023522	-63.73264093608554	56119
ad959ed7fb169e3c94a24d29853e37a02e8b2efc	mcsm–na: predicting the effects of mutations on protein–nucleic acids interactions		Over the past two decades, several computational methods have been proposed to predict how missense mutations can affect protein structure and function, either by altering protein stability or interactions with its partners, shedding light into potential molecular mechanisms giving rise to different phenotypes. Effectively and efficiently predicting consequences of mutations on protein-nucleic acid interactions, however, remained until recently a great and unmet challenge. Here we report an updated webserver for mCSM-NA, the only scalable method we are aware of capable of quantitatively predicting the effects of mutations in protein coding regions on nucleic acid binding affinities. We have significantly enhanced the original method by including a pharmacophore modelling and information of nucleic acid properties into our graph-based signatures, considering the reverse mutation and by using a refined, more reliable data set, based on a new release of the ProNIT database, which has significantly improved the reliability and applicability of the methodology. Our new predictive model was capable of achieving a correlation coefficient of up to 0.70 on cross-validation and 0.68 on blind-tests, outperforming its previous version. The server is freely available via a user-friendly web interface at: http://structure.bioc.cam.ac.uk/mcsm_na.	antivirus software;cell nucleus;coefficient;cross-sectional studies;cross-validation (statistics);interaction;interface device component;leabhar na ngenealach;missense mutation;nucleic acid binding;nucleic acids;open reading frames;pharmacophore;phenotype;scalability;server (computer);server (computing);sodium;usability;user interface;web server	Douglas Eduardo Valente Pires;David B. Ascher	2017		10.1093/nar/gkx236		Comp.	8.195977239775386	-58.120464831590446	56128
6b2f8f0fc7369786692917b78d4b49115646ccf0	a robust, high-sensitivity algorithm for automated detection of proteins in two-dimensional electrophoresis gels	traitement automatise;software;proteine;gel electrophoresis;logiciel;computerized processing;tratamiento informatico;deteccion;implementation;electroforesis gel;detection;electroforesis bidimensional;algorithme;algorithm;ejecucion;proteins;tratamiento automatizado;two dimensional electrophoresis;electrophorese gel;logicial;proteina;electrophorese bidimensionnelle;caltech library services;high sensitivity;traitement informatique;automated processing;algoritmo	The automated interpretation of two-dimensional gel electrophoresis images used in protein separation and analysis presents a formidable problem in the detection and characterization of ill-defined spatial objects. We describe in this paper a hierarchical algorithm that provides a robust, high-sensitivity solution to this problem, which can be easily adapted to a variety of experimental situations. The software implementation of this algorithm functions as part of a complete package designed for general protein gel analysis applications.	electrophoresis, gel, two-dimensional;gel electrophoresis (lab technique);physical object;algorithm	J. E. Solomon;M. G. Harrington	1993	Computer applications in the biosciences : CABIOS	10.1093/bioinformatics/9.2.133	biology;computer science;bioinformatics;gel electrophoresis;implementation;algorithm	Comp.	-4.379749041438718	-55.93155478675481	56159
9824bbb1ecef900a44954e55dd8e9a42bbb88c7c	integrating 5hmc and gene expression data to infer regulatory mechanisms		Motivation Epigenetic mechanisms are known to play a major role in breast cancer. However, the role of 5-hydroxymethylcytosine (5hmC) remains understudied. We hypothesize that 5hmC mediates redox regulation of gene expression in an aggressive subtype known as triple negative breast cancer (TNBC). To address this, our objective was to highlight genes that may be the target of this process by identifying redox-regulated, antioxidant-sensitive, gene-localized 5hmC changes associated with mRNA changes in TNBC cells.   Results We proceeded to develop an approach to integrate novel Pvu-sequencing and RNA-sequencing data. The result of our approach to merge genome-wide, high-throughput TNBC cell line datasets to identify significant, concordant 5hmC and mRNA changes in response to antioxidant treatment produced a gene set with relevance to cancer stem cell function. Moreover, we have established a method that will be useful for continued research of 5hmC in TNBC cells and tissue samples.   Availability and implementation Data are available at Gene Expression Omnibus (GEO) under accession number GSE103850.   Contact bollig@karmanos.org.		Cristina Mitrea;Priyanga Wijesinghe;Gregory Dyson;Adéle Kruger;Douglas M. Ruden;Sorin Draghici;Aliccia Bollig-Fischer	2018	Bioinformatics	10.1093/bioinformatics/btx777	gene expression;computer science;bioinformatics	Comp.	5.215590990382347	-59.70049763436764	56199
b8830e75fec226a1b41ada33c06b6aa87ceb4b29	identifying time-lagged gene clusters using gene expression data	agregado gen;edge detection;gene cluster;efficient algorithm;gen;bioinformatique;gene expression data;time series;gene expression;expression genique;time lag;gene;batterie gene;bioinformatica;expresion genetica;bioinformatics	MOTIVATION Analysis of gene expression data can provide insights into the time-lagged co-regulation of genes/gene clusters. However, existing methods such as the Event Method and the Edge Detection Method are inefficient as they compare only two genes at a time. More importantly, they neglect some important information due to their scoring criterian. In this paper, we propose an efficient algorithm to identify time-lagged co-regulated gene clusters. The algorithm facilitates localized comparison and processes several genes simultaneously to generate detailed and complete time-lagged information for genes/gene clusters.   RESULTS We experimented with the time-series Yeast gene dataset and compared our algorithm with the Event Method. Our results show that our algorithm is not only efficient, but also delivers more reliable and detailed information on time-lagged co-regulation between genes/gene clusters.   AVAILABILITY The software is available upon request.   CONTACT jiliping@comp.nus.edu.sg   SUPPLEMENTARY INFORMATION Supplementary tables and figures for this paper can be found at http://www.comp.nus.edu.sg/~jiliping/p2.htm.		Liping Ji;Kian-Lee Tan	2005	Bioinformatics	10.1093/bioinformatics/bti026	biology;molecular biology;gene expression;edge detection;gene cluster;bioinformatics;time series;gene;genetics	Comp.	2.9893823317882644	-55.26008138574698	56298
cb9eeade7924b6f3711d444ffa418234e1950697	ehive: an artificial intelligence workflow system for genomic analysis	databases;software;genomics;genome analysis;comparative genomics;distributed processing;databases genetic;gene trees;computational biology bioinformatics;artificial intelligent;autonomous agent;workflow system;genome;algorithms;combinatorial libraries;high throughput;computer appl in life sciences;microarrays;bioinformatics;genetic	The Ensembl project produces updates to its comparative genomics resources with each of its several releases per year. During each release cycle approximately two weeks are allocated to generate all the genomic alignments and the protein homology predictions. The number of calculations required for this task grows approximately quadratically with the number of species. We currently support 50 species in Ensembl and we expect the number to continue to grow in the future. We present eHive, a new fault tolerant distributed processing system initially designed to support comparative genomic analysis, based on blackboard systems, network distributed autonomous agents, dataflow graphs and block-branch diagrams. In the eHive system a MySQL database serves as the central blackboard and the autonomous agent, a Perl script, queries the system and runs jobs as required. The system allows us to define dataflow and branching rules to suit all our production pipelines. We describe the implementation of three pipelines: (1) pairwise whole genome alignments, (2) multiple whole genome alignments and (3) gene trees with protein homology inference. Finally, we show the efficiency of the system in real case scenarios. eHive allows us to produce computationally demanding results in a reliable and efficient way with minimal supervision and high throughput. Further documentation is available at: http://www.ensembl.org/info/docs/eHive/ .	arcinfo;artificial intelligence;autonomous agent;autonomous robot;blackboard system;ccir system a;docs (software);dataflow;diagram;distributed computing;documentation;ensembl;fault tolerance;homologous gene;homology (biology);inference;mysql;occupations;perl;pipeline (computing);rule (guideline);sequence alignment;software release life cycle;throughput;trees (plant)	Jessica Severin;Kathryn Beal;Albert J. Vilella;Stephen Fitzgerald;Michael Schuster;Leo Gordon;Abel Ureta-Vidal;Paul Flicek;Javier Herrero	2009		10.1186/1471-2105-11-240	computational biology;high-throughput screening;biology;genomics;dna microarray;computer science;bioinformatics;autonomous agent;data mining;comparative genomics;genetics;genome	Networks	-1.3236794145452284	-57.03431302523197	56327
53a79e68f05e86b885134a0d5c640940d4ecc5dc	pubchem promiscuity: a web resource for gathering compound promiscuity data from pubchem	search engine;data collection;pharmaceutical preparations;internet;protein binding;databases factual	SUMMARY Promiscuity counts allow for a better understanding of a compound's assay activity profile and drug potential. Although PubChem contains a vast amount of compound and assay data, it currently does not have a convenient or efficient method to obtain in-depth promiscuity counts for compounds. PubChem promiscuity fills this gap. It is a Java servlet that uses NCBI Entrez (eUtils) web services to interact with PubChem and provide promiscuity counts in a variety of categories along with compound descriptors, including PAINS-based functional group detection.   AVAILABILITY http://chemutils.florida.scripps.edu/pcpromiscuity   CONTACT southern@scripps.edu	categories;entrez;java programming language;java servlet;ncbi taxonomy;pain;pubchem;web resource;web service	Stephanie A. Canny;Yasel Cruz;Mark R. Southern;Patrick R. Griffin	2012	Bioinformatics	10.1093/bioinformatics/btr622	plasma protein binding;the internet;pubchem;computer science;bioinformatics;data mining;search engine;statistics;data collection	Comp.	-1.2715496063610534	-59.86933596950109	56352
55fbb8b3e7425b81d54c7c52307a7bd4e5dfb5d5	mitopred: a web server for the prediction of mitochondrial proteins	software;mitochondrial proteins;animals;cell nucleus;internet;protein structure tertiary;genome;algorithms;humans;software design;sequence analysis protein;databases protein	MITOPRED web server enables prediction of nucleus-encoded mitochondrial proteins in all eukaryotic species. Predictions are made using a new algorithm based primarily on Pfam domain occurrence patterns in mitochondrial and non-mitochondrial locations. Pre-calculated predictions are instantly accessible for proteomes of Saccharomyces cerevisiae, Caenorhabditis elegans, Drosophila, Homo sapiens, Mus musculus and Arabidopsis species as well as all the eukaryotic sequences in the Swiss-Prot and TrEMBL databases. Queries, at different confidence levels, can be made through four distinct options: (i) entering Swiss-Prot/TrEMBL accession numbers; (ii) uploading a local file with such accession numbers; (iii) entering protein sequences; (iv) uploading a local file containing protein sequences in FASTA format. Automated updates are scheduled for the pre-calculated prediction database so as to provide access to the most current data. The server, its documentation and the data are available from http://mitopred.sdsc.edu.	accession number (identifier);accession number (bioinformatics);algorithm;amino acid sequence;caenorhabditis elegans;cell nucleus;databases;documentation;fasta format;mitochondrial inheritance;mus;muscle;peptide sequence;pfam;proteome;rafivirumab;swiss-model;schedule (document type);server (computer);server (computing);switzerland;uniprot;upload;web server	Chittibabu Guda;Purnima Guda;Eoin Fahy;Shankar Subramaniam	2004	Nucleic acids research	10.1093/nar/gkh374	biology;the internet;bioinformatics;software design;genetics;genome	Comp.	-1.746583907473559	-60.047916537620765	56409
48cdfc391175c4ed8d7ecd7e4ec782e0f83e1fb3	selective advantage for sexual reproduction with random haploid fusion	second order;saccharomyces cerevisiae;stress response;sexual reproduction;mutation rate;genetics;quasispecies;first order;random mating;population density;mate selection;growth rate;recombination;energy cost;diploid;selective mating;haploid	This article develops a simplified set of models describing asexual and sexual replication in unicellular diploid organisms. The models assume organisms whose genomes consist of two chromosomes, where each chromosome is assumed to be functional if it is equal to some master sequence σ0, and non-functional otherwise. We review the previously studied case of selective mating, where it is assumed that only haploids with functional chromosomes can fuse, and also consider the case of random haploid fusion. When the cost for sex is small, as measured by the ratio of the characteristic haploid fusion time to the characteristic growth time, we find that sexual replication with random haploid fusion leads to a greater mean fitness for the population than a purely asexual strategy. However, independently of the cost for sex, we find that sexual replication with a selective mating strategy leads to a higher mean fitness than the random mating strategy. The results of this article are consistent with previous studies suggesting that sex is favored at intermediate mutation rates, for slowly replicating organisms, and at high population densities. Furthermore, the results of this article provide a basis for understanding sex as a stress response in unicellular organisms such as Saccharomyces cerevisiae (Baker’s yeast).	assumed;chromosomes;diploidy;genome;haploidy;microorganism;mutation;saccharomyces cerevisiae;biological adaptation to stress;density;sexual reproduction	Emmanuel Tannenbaum	2008	Theory in Biosciences	10.1007/s12064-008-0054-8	biology;botany;ploidy;genetics	Comp.	6.374008604194549	-63.646409007995786	56541
d788070fd3807b3166b684274154e5c66374eaf3	kinetic and affinity constraints on reactions between antihapten antibodies and nonpeptidic b-cell epitopes: implications for predicting antibody-mediated modulation of pharmacokinetics and pharmacodynamics	drugs;antihapten antibodies;pharmacokinetics;b cell epitope prediction;nonpeptidic antigens;pharmacodynamics	For antihapten antibody-mediated modulation of pharmacodynamics and pharmacokinetics, B-cell epitope prediction may be formulated as estimation of quantities describing antibody-hapten affinity, reaction kinetics (for noncatalytic or even catalytic binding) and, in turn, parameters such as drug concentration and half-life.	delta-sigma modulation;kinetics internet protocol;processor affinity	Salvador Eugenio C. Caoili	2016		10.1145/2975167.2985643	pharmacology;biology;pharmacodynamics;bioinformatics;pharmacokinetics;immunology	NLP	7.833513975322859	-63.21464301163305	56578
9cd77b4873f22488549e99882e335ed0a4e0bf39	the 2nd dbcls biohackathon: interoperable bioinformatics web services for integrated applications	biological patents;pathway analysis;biomedical journals;programming language;text mining;europe pubmed central;integrable system;best practice;citation search;transcription factor binding site;enzyme;differential gene expression;data mining and knowledge discovery;web service;citation networks;data format;computational biology bioinformatics;protein structure;research articles;abstracts;open access;software development;life sciences;clinical guidelines;algorithms;full text;metabolic pathway;combinatorial libraries;protein interaction;sista;computer appl in life sciences;use case;fruit flies;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	"""BACKGROUND The interaction between biological researchers and the bioinformatics tools they use is still hampered by incomplete interoperability between such tools. To ensure interoperability initiatives are effectively deployed, end-user applications need to be aware of, and support, best practices and standards. Here, we report on an initiative in which software developers and genome biologists came together to explore and raise awareness of these issues: BioHackathon 2009.   RESULTS Developers in attendance came from diverse backgrounds, with experts in Web services, workflow tools, text mining and visualization. Genome biologists provided expertise and exemplar data from the domains of sequence and pathway analysis and glyco-informatics. One goal of the meeting was to evaluate the ability to address real world use cases in these domains using the tools that the developers represented. This resulted in i) a workflow to annotate 100,000 sequences from an invertebrate species; ii) an integrated system for analysis of the transcription factor binding sites (TFBSs) enriched based on differential gene expression data obtained from a microarray experiment; iii) a workflow to enumerate putative physical protein interactions among enzymes in a metabolic pathway using protein structure data; iv) a workflow to analyze glyco-gene-related diseases by searching for human homologs of glyco-genes in other species, such as fruit flies, and retrieving their phenotype-annotated SNPs.   CONCLUSIONS Beyond deriving prototype solutions for each use-case, a second major purpose of the BioHackathon was to highlight areas of insufficiency. We discuss the issues raised by our exploration of the problem/solution space, concluding that there are still problems with the way Web services are modeled and annotated, including: i) the absence of several useful data or analysis functions in the Web service """"space""""; ii) the lack of documentation of methods; iii) lack of compliance with the SOAP/WSDL specification among and between various programming-language libraries; and iv) incompatibility between various bioinformatics data formats. Although it was still difficult to solve real world problems posed to the developers by the biological researchers in attendance because of these problems, we note the promise of addressing these issues within a semantic framework."""	best practice;binding sites;bioinformatics;community informatics;convergence insufficiency;diptera;documentation;enumerated type;feasible region;gene regulatory network;informatics (discipline);interaction;interoperability;invertebrates;libraries;microarray;partial;pathway analysis;prototype;soap;single nucleotide polymorphism;software developer;software incompatibility;specification;transcription factor;text mining;tissue-specific gene expression;transcription (software);web service definition language;web services description language;world wide web;format;standards characteristics	Toshiaki Katayama;Mark D. Wilkinson;Rutger A. Vos;Takeshi Kawashima;Shuichi Kawashima;Mitsuteru Nakao;Yasunori Yamamoto;Hong-Woo Chun;Atsuko Yamaguchi;Shin Kawano;Jan Aerts;Kiyoko F. Aoki-Kinoshita;Kazuharu Arakawa;Bruno Aranda;Raoul J. P. Bonnal;José María Fernández;Takatomo Fujisawa	2011		10.1186/2041-1480-2-4	use case;web service;integrable system;enzyme;protein structure;metabolic pathway;text mining;computer science;bioinformatics;data science;software development;data mining;dna binding site;best practice	Comp.	-2.1769912694995233	-63.04899486521457	56686
64a522b33b80a70600e88758ad0f21b9dcba4f5f	computational identification of mirnas and their target genes from expressed sequence tags of tea (camellia sinensis)	plant species;transcription factor;g r prabu a k a mandal mirnas 表达序列标签 基因组测序 茶树 计算 识别 小分子rna 植物物种 computational identification of mirnas and their target genes from expressed sequence tags of tea camellia sinensis;mirna;est;tea;camellia sinensis;microrna;expressed sequence tag	MicroRNAs (miRNAs) are a newly identified class of small non-protein-coding post-transcriptional regulatory RNA in both plants and animals. The use of computational homology based search for expressed sequence tags (ESTs) with the Ambros empirical formula and other structural feature criteria filter is a suitable combination towards the discovery and isolation of conserved miRNAs from tea and other plant species whose genomes are not yet sequenced. In the present study, we blasted the database of tea (Camellia sinensis) ESTs to search for potential miRNAs, using previously known plant miRNAs. For the first time, four candidate miRNAs from four families were identified in tea. Using the newly identified miRNA sequences, a total of 30 potential target genes were identified for 11 miRNA families; 6 of these predicted target genes encode transcription factors (20%), 16 target genes appear to play roles in diverse physiological processes (53%) and 8 target genes have hypothetical or unknown functions (27%). These findings considerably broaden the scope of understanding the functions of miRNA in tea.	camellia sinensis ab.ige:acnc:pt:ser:qn;computation;encode (action);expressed sequence tags;genome;homologous gene;homology (biology);micrornas;physiological processes;rna;role playing disorder;transcription factor;tea;thea plant;transcription (software);transcription, genetic	G. R. Prabu;Abul Kalam Azad Mandal	2010		10.1016/S1672-0229(10)60012-5	biology;botany;bioinformatics;genetics;microrna	Comp.	3.4603772260002064	-60.35412796269636	56783
bfcf39a487b15bb5ce494320ef02ba4fae9facac	additive risk survival model with microarray data	microarray data;survival rate;incidence;high dimensionality;survival data;proportional hazards models;proportional hazard model;tumor markers biological;computational biology bioinformatics;gene expression;risk factors;survival time;neoplasm proteins;survival analysis;risk assessment;algorithms;least absolute shrinkage and selection operator;humans;prediction model;cross validation;combinatorial libraries;hazard function;gene selection;computer appl in life sciences;prognosis;leave one out cross validation;gene expression profiling;lymphoma mantle cell;oligonucleotide array sequence analysis;right censoring;microarrays;bioinformatics	Microarray techniques survey gene expressions on a global scale. Extensive biomedical studies have been designed to discover subsets of genes that are associated with survival risks for diseases such as lymphoma and construct predictive models using those selected genes. In this article, we investigate simultaneous estimation and gene selection with right censored survival data and high dimensional gene expression measurements. We model the survival time using the additive risk model, which provides a useful alternative to the proportional hazards model and is adopted when the absolute effects, instead of the relative effects, of multiple predictors on the hazard function are of interest. A Lasso (least absolute shrinkage and selection operator) type estimate is proposed for simultaneous estimation and gene selection. Tuning parameter is selected using the V-fold cross validation. We propose Leave-One-Out cross validation based methods for evaluating the relative stability of individual genes and overall prediction significance. We analyze the MCL and DLBCL data using the proposed approach. A small number of probes represented on the microarrays are identified, most of which have sound biological implications in lymphoma development. The selected probes are relatively stable and the proposed approach has overall satisfactory prediction power.	additive model;censoring (statistics);clinical trial censoring;cross reactions;cross-validation (statistics);diffuse large b-cell lymphoma;entity name part qualifier - adopted;failure rate;financial risk modeling;gene expression;lasso;least squares;macintosh common lisp;microarray;population parameter;predictive modelling;proportional hazards model;utility functions on indivisible goods	Shuangge Ma;Jian Huang	2006	BMC Bioinformatics	10.1186/1471-2105-8-192	biology;computer science;bioinformatics;data mining;cross-validation	Comp.	6.845602363327874	-52.94266600232377	56846
b736b6508dab408e9e0f73abd5623c89f410fdde	novel adaptors of amyloid precursor protein intracellular domain and their functional implications	phosphorylation;alzheimer s disease;amyloid precursor protein intracellular domain;adaptors	Amyloid precursor protein intracellular domain (AICD) is one of the potential candidates in deciphering the complexity of Alzheimer's disease. It plays important roles in determining cell fate and neurodegeneration through its interactions with several adaptors. The presence or absence of phosphorylation at specific sites determines the choice of partners. In this study, we identified 20 novel AICD-interacting proteins by in vitro pull down experiments followed by 2D gel electrophoresis and MALDI-MS analysis. The identified proteins can be grouped into different functional classes including molecular chaperones, structural proteins, signaling and transport molecules, adaptors, motor proteins and apoptosis determinants. Interactions of nine proteins were further validated either by colocalization using confocal imaging or by co-immunoprecipitation followed by immunoblotting. The cellular functions of most of the proteins can be correlated with AD. Hence, illustration of their interactions with AICD may shed some light on the disease pathophysiology.	alzheimer's disease;amyloid beta-protein precursor;apoptosis;class;co-immunoprecipitation;disease ontology;experiment;gel electrophoresis (lab technique);immunoblotting;interaction;molecular chaperones;nervous system disorder	Arunabha Chakrabarti;Debashis Mukhopadhyay	2012		10.1016/j.gpb.2012.07.002	phosphorylation;biology;molecular biology;cell biology;bioinformatics;genetics	Comp.	7.637223108895358	-61.76010928609131	56872
4dc8f5d19d37e82f3ea0335f9b0c0eb914c166be	g-blastn: accelerating nucleotide alignment by graphics processors		MOTIVATION Since 1990, the basic local alignment search tool (BLAST) has become one of the most popular and fundamental bioinformatics tools for sequence similarity searching, receiving extensive attention from the research community. The two pioneering papers on BLAST have received over 96 000 citations. Given the huge population of BLAST users and the increasing size of sequence databases, an urgent topic of study is how to improve the speed. Recently, graphics processing units (GPUs) have been widely used as low-cost, high-performance computing platforms. The existing GPU-BLAST is a promising software tool that uses a GPU to accelerate protein sequence alignment. Unfortunately, there is still no GPU-accelerated software tool for BLAST-based nucleotide sequence alignment.   RESULTS We developed G-BLASTN, a GPU-accelerated nucleotide alignment tool based on the widely used NCBI-BLAST. G-BLASTN can produce exactly the same results as NCBI-BLAST, and it has very similar user commands. Compared with the sequential NCBI-BLAST, G-BLASTN can achieve an overall speedup of 14.80X under 'megablast' mode. More impressively, it achieves an overall speedup of 7.15X over the multithreaded NCBI-BLAST running on 4 CPU cores. When running under 'blastn' mode, the overall speedups are 4.32X (against 1-core) and 1.56X (against 4-core). G-BLASTN also supports a pipeline mode that further improves the overall performance by up to 44% when handling a batch of queries as a whole. Currently G-BLASTN is best optimized for databases with long sequences. We plan to optimize its performance on short database sequences in our future work.   AVAILABILITY http://www.comp.hkbu.edu.hk/∼chxw/software/G-BLASTN.html   CONTACT chxw@comp.hkbu.edu.hk   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	amdahl's law;amino acid sequence;base sequence;bioinformatics;blast injuries;cdisc adas-cog - commands summary score;cpu (central processing unit of computer system);central processing unit;computation (action);computer graphics;graphics processing unit;handling (psychology);multi-core processor;ncbi taxonomy;national center for biotechnology information;nucleotides;paper;programming tool;published database;search engine;sequence alignment;sequence database;smith–waterman algorithm;speedup;supercomputer;thread (computing);citation	Kaiyong Zhao;Xiaowen Chu	2014	Bioinformatics	10.1093/bioinformatics/btu047	real-time computing;computer science;bioinformatics;theoretical computer science	HPC	-1.4735660655010485	-54.118364491667315	56973
7bed3f37b7765c9c33537533c1a425e2c469d422	creation and maintenance of helix, a web based database of medical genetics laboratories, to serve the needs of the genetics community	programming languages;internet;database management systems;phenotype;genotype	Helix (healthlinks.washington.edu/helix) is a web accessible database that serves as the main U.S. directory of laboratories offering genetic testing. The database was designed to address the previously unmet need for a centralized, continuously updated source of information about clinical and research genetic testing to keep pace with the rapid rate of gene discovery resulting from the Human Genome Project. The Helix project began in 1992 at the University of Washington and Children's Hospital and Regional Medical Center. It has evolved from a single user stand alone relational database to a fully Web enabled database queried and maintained via the web and linked to other web accessible genomic databases. As of February, 1998 it lists more than 500 diseases and 290 laboratories, with over 5,200 registered users making approximately 250 queries/day (90% via the Internet). We describe the iterative design, implementation, population and assessment of the database over a six year period.	candidate gene identification;centralized computing;directory (computing);genetic screening method;information source;internet;iterative design;iterative method;laboratory;medical genetics specialty;project xanadu;published directory;registration;relational database	Peter Tarczy-Hornoch;Maxine L. Covington;Joseph Edwards;Paul Shannon;Sherrilynne S. Fuller;Roberta A. Pagon	1998	Proceedings. AMIA Symposium		world wide web;pace;iterative design;web application;relational database;the internet;database;population;directory;genetic testing;computer science	Comp.	-2.691952165432322	-61.33744291896312	57013
32389e6dce6588a782d48b95a3c960a9e6882739	how and when should interactome-derived clusters be used to predict functional modules and protein function?	use;cluster algorithm;protein protein interaction network;modulo;cluster;protein function;protein complex;saccharomyces cerevisiae;proteine;proteome;amas;interactome;utilisation;cluster analysis;proteins;functional analysis;uso;algorithms;proteina;monton;function prediction;protein interaction mapping;computational biology;protein;module;biological network;biological process;databases protein;gene ontology	MOTIVATION Clustering of protein-protein interaction networks is one of the most common approaches for predicting functional modules, protein complexes and protein functions. But, how well does clustering perform at these tasks?   RESULTS We develop a general framework to assess how well computationally derived clusters in physical interactomes overlap functional modules derived via the Gene Ontology (GO). Using this framework, we evaluate six diverse network clustering algorithms using Saccharomyces cerevisiae and show that (i) the performances of these algorithms can differ substantially when run on the same network and (ii) their relative performances change depending upon the topological characteristics of the network under consideration. For the specific task of function prediction in S.cerevisiae, we demonstrate that, surprisingly, a simple non-clustering guilt-by-association approach outperforms widely used clustering-based approaches that annotate a protein with the overrepresented biological process and cellular component terms in its cluster; this is true over the range of clustering algorithms considered. Further analysis parameterizes performance based on the number of annotated proteins, and suggests when clustering approaches should be used for interactome functional analyses. Overall our results suggest a re-examination of when and how clustering approaches should be applied to physical interactomes, and establishes guidelines by which novel clustering approaches for biological networks should be justified and evaluated with respect to functional analysis.   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	algorithm;bioinformatics;biological processes;biological network;cluster analysis;erewhon;gene ontology;interaction network;interactome;performance;protein, organized by function;staphylococcal protein a;protein protein interaction;statistical cluster	Jimin Song;M T Singh	2009		10.1093/bioinformatics/btp551	functional analysis;module;biology;constrained clustering;biological network;fuzzy clustering;computer science;bioinformatics;interactome;machine learning;proteome;data mining;multiprotein complex;cluster analysis;biological process;modulo;cluster	Comp.	4.449481271341517	-55.33653485775416	57125
414af704249f9f7f5f4c29ceb5bf42589b24d316	modelling t cell proliferation: dynamics heterogeneity depending on cell differentiation, age, and genetic background	thymus;cell cycle and cell division;thymocytes;cell differentiation;cytotoxic t cells;spleen;t cells;synthesis phase	"""Cell proliferation is the common characteristic of all biological systems. The immune system insures the maintenance of body integrity on the basis of a continuous production of diversified T lymphocytes in the thymus. This involves processes of proliferation, differentiation, selection, death and migration of lymphocytes to peripheral tissues, where proliferation also occurs upon antigen recognition. Quantification of cell proliferation dynamics requires specific experimental methods and mathematical modelling. Here, we assess the impact of genetics and aging on the immune system by investigating the dynamics of proliferation of T lymphocytes across their differentiation through thymus and spleen in mice. Our investigation is based on single-cell multicolour flow cytometry analysis revealing the active incorporation of a thymidine analogue during S phase after pulse-chase-pulse experiments in vivo, versus cell DNA content. A generic mathematical model of state transition simulates through Ordinary Differential Equations (ODEs) the evolution of single cell behaviour during various durations of labelling. It allows us to fit our data, to deduce proliferation rates and estimate cell cycle durations in sub-populations. Our model is simple and flexible and is validated with other durations of pulse/chase experiments. Our results reveal that T cell proliferation is highly heterogeneous but with a specific """"signature"""" that depends upon genetic origins, is specific to cell differentiation stages in thymus and spleen and is altered with age. In conclusion, our model allows us to infer proliferation rates and cell cycle phase durations from complex experimental 5-ethynyl-2'-deoxyuridine (EdU) data, revealing T cell proliferation heterogeneity and specific signatures."""	5-ethynyl-2'-deoxyuridine;analog;biological system;body tissue;cell cycle phase;cell differentiation process;cell proliferation;cellular phone;cessation of life;chronic lymphocytic leukemia;differential diagnosis;electronic signature;experiment;flow cytometry;generic drugs;genetic heterogeneity;immune system;inference;mathematical model;mathematics;national origin;peripheral;population;quantitation;spleen tissue;state transition table;thymic tissue;thymidine;video-in video-out	Julien Vibert;Veronique Thomas-Vaslin	2017		10.1371/journal.pcbi.1005417	biology;antigen-presenting cell;il-2 receptor;lymphokine-activated killer cell;cytotoxic t cell;cell biology;immunology;genetics;cellular differentiation;interleukin 21;s phase	ML	7.288867456766797	-64.94864406908091	57173
52851cdb5b7c03f8562ba7175a0847b21818265b	privacy-preserving microbiome analysis using secure computation	biological patents;biomedical journals;text mining;europe pubmed central;citation search;citation networks;research articles;abstracts;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	MOTIVATION Developing targeted therapeutics and identifying biomarkers relies on large amounts of research participant data. Beyond human DNA, scientists now investigate the DNA of micro-organisms inhabiting the human body. Recent work shows that an individual's collection of microbial DNA consistently identifies that person and could be used to link a real-world identity to a sensitive attribute in a research dataset. Unfortunately, the current suite of DNA-specific privacy-preserving analysis tools does not meet the requirements for microbiome sequencing studies.   RESULTS To address privacy concerns around microbiome sequencing, we implement metagenomic analyses using secure computation. Our implementation allows comparative analysis over combined data without revealing the feature counts for any individual sample. We focus on three analyses and perform an evaluation on datasets currently used by the microbiome research community. We use our implementation to simulate sharing data between four policy-domains. Additionally, we describe an application of our implementation for patients to combine data that allows drug developers to query against and compensate patients for the analysis.   AVAILABILITY AND IMPLEMENTATION The software is freely available for download at: http://cbcb.umd.edu/∼hcorrada/projects/secureseq.html   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.   CONTACT hcorrada@umiacs.umd.edu.	bioinformatics;biological markers;biopolymer sequencing;categorization;classification;computation (action);description;download;expect;hl7publishingsubsection <operations>;matrix method;metagenomics;microbiome;microorganism;patients;precomputation;privacy;qualitative comparative analysis;rare diseases;repository;requirement;secure multi-party computation;silo (dataset);simulation;sparse matrix;statistic (data);therapeutic procedure;drug development	Justin Wagner;Joseph N. Paulson;Xiao Wang;Bobby Bhattacharjee;Héctor Corrada Bravo	2016		10.1093/bioinformatics/btw073	text mining;medical research;computer science;bioinformatics;data science;data mining	Comp.	5.35580133546927	-55.051486882409016	57195
7378a9f362c2dede093d8752a50a82ceacbc5c4c	analysis on steady states of photosynthetic carbon metabolic system	carbon;biological system modeling;asymptotic behavior steady states analysis photosynthetic carbon metabolic system reduced molecular network autocatalytic cycle photosynthate utilization photorespiration effects stablity equilibria independent 2 dimensional subsystem physiologically feasible steady state;asymptotic behavior;2 dimensional;molecular biophysics;carbon metabolism;mathematical model;steady state biochemistry crops biological system modeling systems biology absorption mathematics computational biology chemicals plants biology;physiological models biochemistry carbon molecular biophysics photosynthesis;electronics packaging;photosynthesis;physiological models;equivalent transformation;biochemistry;steady state	In this paper, we propose a reduced molecular network of the photosynthetic carbon metabolism, which includes the nine major metabolites with 48 parameters. The reduced molecular network can represent the key ingredients of photosynthetic carbon metabolism, i.e. the autocatalytic cycle, the utilization of photosynthate, and the effect of photorespiration. Based on the model, we theoretically study steady states or stable equilibria of photosynthetic carbon metabolism, and prove that such a system actually has at most one feasible steady state in the domain of a parameter set defined around nominal values for that parameter set. Specifically, we first equivalently transform the original system into an independent 2-dimensional subsystem which contains just 10 parameters, and then show that steady states of the original system can be determined by the 2-dimensional subsystem uniquely. Finally, we show that when the 10 parameters for the 2-dimensional subsystem all stay in an appropriate domain around the nominal value of each parameter, the reduced model has at most one physiologically feasible steady state no matter how the other 38 parameters in the original model are taken. In addition, we also derive parameter domain to ensure such an asymptotical behavior.	call of duty: black ops;email;gene regulatory network;steady state;turing completeness	Hong-Bo Lei;Xin Wang;Ruiqi Wang;Xin-Guang Zhu;Luonan Chen;Ji-Feng Zhang	2009	Proceedings of the 48h IEEE Conference on Decision and Control (CDC) held jointly with 2009 28th Chinese Control Conference	10.1109/CDC.2009.5399509	carbon;two-dimensional space;mathematical model;mathematics;electronic packaging;photosynthesis;steady state;molecular biophysics	Visualization	8.008827125064158	-64.90032434015822	57198
7da8fd60e68906f33657e80ae55c96d464d17524	p-cats: prediction of catalytic residues in proteins from their tertiary structures	prediccion;alignement sequence;mammalia;proteine;fissipedia;estructura terciaria;available p;bioinformatique;vertebrata;alineacion secuencia;chat;protein structure;structural genomics;carnivora;cat;protein folding;proteina;sequence alignment;multiple sequence alignment;bioinformatica;molecular surface;protein;multiple;spatial configuration;prediction;structure tertiaire;protein data bank;similarity search;genome sequence;gato;tertiary structure;bioinformatics	UNLABELLED P-cats is a web server that predicts the catalytic residues in proteins from the atomic coordinates. P-cats receives a coordinate file of the tertiary structure and sends out analytical results via e-mail. The reply contains a summary and two URLs to allow the user to examine the conserved residues: one for interactive images of the prediction results and the other for a graphical view of the multiple sequence alignment.   AVAILABILITY P-cats is freely available at http://p-cats.hgc.jp/p-cats   CONTACT kino@ims.u-tokyo.ac.jp	email;graphical user interface;multiple sequence alignment;server (computing);web server;tertiary	Kengo Kinoshita;Motonori Ota	2005	Bioinformatics	10.1093/bioinformatics/bti561	computer-assisted translation;protein folding;structural genomics;biology;protein structure;whole genome sequencing;protein tertiary structure;protein data bank;prediction;multiple sequence alignment;computer science;bioinformatics;sequence alignment;genetics;multiple	Comp.	-4.135433968214911	-57.66373527523425	57372
e0f1de32a2ab3c820b35a8b0393e986c6802279d	pach: ploidy-agnostic haplotyping	genomics biological techniques cellular biophysics;mnimum error corection ploidy agnostic haplotyping genomic studies diploid organisms homologous chromosomes phylogenetic study evolution study human body tissues haplotype assembly computational algorithms polyploidy organisms dna sequencing data ploidy levels ploidy agnostic phasing framework fragment partitioning approach fragment conflict graph model inter fragment dissimilarities partition merging technique;genomics bioinformatics biological cells dna	Organisms can be categorized based on the copy number of each chromosome they have. In genomic studies, diploid organisms such as humans, mice, etc. have been the focus of extensive research for decades. Organisms with more than two sets of homologous chromosomes, however, have received attention from the community only recently, in studying the genomics of disease, phylogenetic, and evolution studies. The presence of more than two copies of each chromosome in the cells of an organism which is common in plants, some animals, and human body tissues is referred to as Polyploidy. To understand structure of each chromosome, haplotype assembly is needed. Current computational algorithms for phasing, however, either focus on diploid organisms or fail to accurately reconstruct haplotypes on polyploidy organisms. This has limited scalability and generalizability of such algorithms. Therefore, there is a need to develop new algorithms that are not only accurate in reconstructing chromosome copies from DNA sequencing data but also can be applied to organisms of various ploidy levels. In this paper, we present PACH, a novel and ploidy-agnostic phasing framework. PACH is a fragment partitioning approach based on a fragment conflict graph model to quantify inter-fragment dissimilarities. We introduce a partitioning approach followed by a partition merging technique to accurately group similar fragments into any number of partitions depending on the ploidy level of the organism from which the sequencing data are derived. Our preliminary results demonstrate that PACH outperforms the state-of-the-art computational techniques. The amount of improvement in the MEC (Minimum Error Correction) score ranges from 82 to 98% using triploid, tetraploid, and decaploid data.	algorithm;categorization;phylogenetics;qr code;scalability;serial digital video out;serializability	Sepideh Mazrouee	2015	2015 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2015.7359963	biology;bioinformatics;genetics	Visualization	1.4681965650088595	-53.93571191721452	57392
5dbad201ab66b3c5dff3387b425ddaaeacd7f3a0	discrimination of outer membrane proteins using support vector machines	juvenile idiopathic arthritis;measurement;outer membrane protein;amino acid composition;cross validation;support vector machine;disease activity;membrane protein;genome sequence	MOTIVATION Discriminating outer membrane proteins from other folding types of globular and membrane proteins is an important task both for dissecting outer membrane proteins (OMPs) from genomic sequences and for the successful prediction of their secondary and tertiary structures.   RESULTS We have developed a method based on support vector machines using amino acid composition and residue pair information. Our approach with amino acid composition has correctly predicted the OMPs with a cross-validated accuracy of 94% in a set of 208 proteins. Further, this method has successfully excluded 633 of 673 globular proteins and 191 of 206 alpha-helical membrane proteins. We obtained an overall accuracy of 92% for correctly picking up the OMPs from a dataset of 1087 proteins belonging to all different types of globular and membrane proteins. Furthermore, residue pair information improved the accuracy from 92 to 94%. This accuracy of discriminating OMPs is higher than that of other methods in the literature, which could be used for dissecting OMPs from genomic sequences.   AVAILABILITY Discrimination results are available at http://tmbeta-svm.cbrc.jp.	amino acid sequence;amino acids;exclusion;membrane proteins;membrane computing;peptide sequence;pseudo amino acid composition;support vector machine;web server;outer membrane;tertiary	Keun-Joon Park;M. Michael Gromiha;Paul Horton;Makiko Suwa	2005	Bioinformatics	10.1093/bioinformatics/bti697	biology;support vector machine;biochemistry;whole genome sequencing;computer science;bioinformatics;membrane protein;cross-validation;measurement	Comp.	9.092106388516525	-55.735200456985766	57429
bcf2bf8a9661a6d59f1916042df83f38faddc5b3	a viral dynamic model for treatment regimens with direct-acting antivirals for chronic hepatitis c infection	sustained virologic response;drug therapy computer assisted;hepacivirus;dynamic model;models biological;clinical trial;treatment response;hepatitis c;antiviral agent;protease inhibitor;chronic hepatitis c;clinical study;humans;antiviral agents;mechanistic model;computer simulation;dose response relationship drug	We propose an integrative, mechanistic model that integrates in vitro virology data, pharmacokinetics, and viral response to a combination regimen of a direct-acting antiviral (telaprevir, an HCV NS3-4A protease inhibitor) and peginterferon alfa-2a/ribavirin (PR) in patients with genotype 1 chronic hepatitis C (CHC). This model, which was parameterized with on-treatment data from early phase clinical studies in treatment-naïve patients, prospectively predicted sustained virologic response (SVR) rates that were comparable to observed rates in subsequent clinical trials of regimens with different treatment durations in treatment-naïve and treatment-experienced populations. The model explains the clinically-observed responses, taking into account the IC50, fitness, and prevalence prior to treatment of viral resistant variants and patient diversity in treatment responses, which result in different eradication times of each variant. The proposed model provides a framework to optimize treatment strategies and to integrate multifaceted mechanistic information and give insight into novel CHC treatments that include direct-acting antiviral agents.	antiviral agents;chemical and drug induced liver injury;chronic electrode implant;endopeptidases;hepatitis b;hepatitis c antibodies;hepatitis c virus;hepatitis c, chronic;hepatitis, chronic;mechatronics;naivety;patients;population;protease inhibitors;ribavirin;science of virology;total peripheral resistance;peginterferon alfa-2a;telaprevir	Bambang S. Adiwijaya;Tara L. Kieffer;Joshua Henshaw;Karen Eisenhauer;Holly Kimko;John J. Alam;Robert S. Kauffman;Varun Garg	2012		10.1371/journal.pcbi.1002339	computer simulation;pharmacology;biology;virology;clinical trial;immunology	ML	8.016056159121293	-60.96614836678437	57448
039d250e90210550cc1f898ed2cad625fb80550a	three-dimensional protein structure prediction: methods and computational strategies	knowledge based methods;structural bioinformatics;ab initio methods;three dimensional protein structure prediction	A long standing problem in structural bioinformatics is to determine the three-dimensional (3-D) structure of a protein when only a sequence of amino acid residues is given. Many computational methodologies and algorithms have been proposed as a solution to the 3-D Protein Structure Prediction (3-D-PSP) problem. These methods can be divided in four main classes: (a) first principle methods without database information; (b) first principle methods with database information; (c) fold recognition and threading methods; and (d) comparative modeling methods and sequence alignment strategies. Deterministic computational techniques, optimization techniques, data mining and machine learning approaches are typically used in the construction of computational solutions for the PSP problem. Our main goal with this work is to review the methods and computational strategies that are currently used in 3-D protein prediction.	algorithm;amino acids;class;data mining;emoticon;homology modeling;machine learning;mathematical optimization;pneumothorax, primary spontaneous;progressive supranuclear palsy;protein structure prediction;protein, organized by structure;sequence alignment;solutions;staphylococcal protein a;structural bioinformatics;thread (computing);threading (protein sequence)	Márcio Dorn;Mariel Barbachan e Silva;Luciana S. Buriol;Luís C. Lamb	2014	Computational biology and chemistry	10.1016/j.compbiolchem.2014.10.001	biology;computer science;bioinformatics;machine learning;data mining;structural bioinformatics;protein structure database	Comp.	9.18081734113781	-58.53763326077755	57613
895f7321c7fbbcde120fef324be834c13e1cd74a	detection of mixed infection from bacterial whole genome sequence data allows assessment of its role in clostridium difficile transmission	phylogeny;bacterial infections;databases genetic;clostridium difficile;sequence analysis dna;sequence databases;molecular typing;genomic databases;cross infection;genome bacterial;sequence analysis;humans;sequence alignment;nucleotide sequencing;computational biology;nucleotide mapping;computer simulation;haplotypes;coinfection;disease outbreaks	Bacterial whole genome sequencing offers the prospect of rapid and high precision investigation of infectious disease outbreaks. Close genetic relationships between microorganisms isolated from different infected cases suggest transmission is a strong possibility, whereas transmission between cases with genetically distinct bacterial isolates can be excluded. However, undetected mixed infections-infection with ≥2 unrelated strains of the same species where only one is sequenced-potentially impairs exclusion of transmission with certainty, and may therefore limit the utility of this technique. We investigated the problem by developing a computationally efficient method for detecting mixed infection without the need for resource-intensive independent sequencing of multiple bacterial colonies. Given the relatively low density of single nucleotide polymorphisms within bacterial sequence data, direct reconstruction of mixed infection haplotypes from current short-read sequence data is not consistently possible. We therefore use a two-step maximum likelihood-based approach, assuming each sample contains up to two infecting strains. We jointly estimate the proportion of the infection arising from the dominant and minor strains, and the sequence divergence between these strains. In cases where mixed infection is confirmed, the dominant and minor haplotypes are then matched to a database of previously sequenced local isolates. We demonstrate the performance of our algorithm with in silico and in vitro mixed infection experiments, and apply it to transmission of an important healthcare-associated pathogen, Clostridium difficile. Using hospital ward movement data in a previously described stochastic transmission model, 15 pairs of cases enriched for likely transmission events associated with mixed infection were selected. Our method identified four previously undetected mixed infections, and a previously undetected transmission event, but no direct transmission between the pairs of cases under investigation. These results demonstrate that mixed infections can be detected without additional sequencing effort, and this will be important in assessing the extent of cryptic transmission in our hospitals.	algorithmic efficiency;clostridium difficile (bacteria);coinfection;communicable diseases;direct transmission;escherichia coli infections;experiment;genetic polymorphism;haplotypes;in vitro [publication type];infection;mutual exclusion;parkinson disease;pathogenic organism;sensor;single nucleotide polymorphism;whole genome sequencing;algorithm	David W. Eyre;Madeleine L. Cule;David Griffiths;Derrick W. Crook;Tim E. A. Peto;A. Sarah Walker;Daniel J. Wilson	2013		10.1371/journal.pcbi.1003059	computer simulation;biology;haplotype;bioinformatics;virology;sequence analysis;sequence alignment;genetics	Comp.	1.7239072192839104	-55.167361943073004	57650
42a046057a23cdfebf26b49aaad76ad719e1f3a7	cudamap: a gpu accelerated program for gene expression connectivity mapping	software;drugs;map;paper;tesla c2050;computer graphics;drug repositioning;signatures;biology;computational biology bioinformatics;cuda;gene expression;antineoplastic agents;package;nvidia;algorithms;humans;neoplasms;combinatorial libraries;computational biology;computer appl in life sciences;microarrays;bioinformatics	Modern cancer research often involves large datasets and the use of sophisticated statistical techniques. Together these add a heavy computational load to the analysis, which is often coupled with issues surrounding data accessibility. Connectivity mapping is an advanced bioinformatic and computational technique dedicated to therapeutics discovery and drug re-purposing around differential gene expression analysis. On a normal desktop PC, it is common for the connectivity mapping task with a single gene signature to take > 2h to complete using sscMap, a popular Java application that runs on standard CPUs (Central Processing Units). Here, we describe new software, cudaMap, which has been implemented using CUDA C/C++ to harness the computational power of NVIDIA GPUs (Graphics Processing Units) to greatly reduce processing times for connectivity mapping. cudaMap can identify candidate therapeutics from the same signature in just over thirty seconds when using an NVIDIA Tesla C2050 GPU. Results from the analysis of multiple gene signatures, which would previously have taken several days, can now be obtained in as little as 10 minutes, greatly facilitating candidate therapeutics discovery with high throughput. We are able to demonstrate dramatic speed differentials between GPU assisted performance and CPU executions as the computational load increases for high accuracy evaluation of statistical significance. Emerging ‘omics’ technologies are constantly increasing the volume of data and information to be processed in all areas of biomedical research. Embracing the multicore functionality of GPUs represents a major avenue of local accelerated computing. cudaMap will make a strong contribution in the discovery of candidate therapeutics by enabling speedy execution of heavy duty connectivity mapping tasks, which are increasingly required in modern cancer research. cudaMap is open source and can be freely downloaded from http://purl.oclc.org/NET/cudaMap .	accessibility;antivirus software;bio-informatics;bioinformatics;biomedical research;c++;cuda;central processing unit;computation (action);computational technique;graphics processing unit;java programming language;multi-core processor;nvidia tesla;omics;open-source software;p-value;tesla - unit;therapeutic procedure;throughput;tissue-specific gene expression	Darragh G. McArt;Peter Bankhead;Philip D. Dunne;Manuel Salto-Tellez;Peter Hamilton;Shu-Dong Zhang	2013		10.1186/1471-2105-14-305	biology;computational science;gene expression;dna microarray;drug repositioning;computer science;bioinformatics;theoretical computer science;map;computer graphics;package	HPC	-1.419684910240052	-54.919229296815864	57666
8d5c5b10c822d1c62a1a80cb4557b8bd247979c6	prediction of b-cell epitopes using evolutionary information and propensity scales	evolution molecular;sensitivity and specificity;support vector machines;position specific scoring matrices;propensity score;computational biology bioinformatics;area under curve;amino acids;algorithms;epitopes b lymphocyte;combinatorial libraries;computational biology;computer appl in life sciences;microarrays;bioinformatics	Development of computational tools that can accurately predict presence and location of B-cell epitopes on pathogenic proteins has a valuable application to the field of vaccinology. Because of the highly variable yet enigmatic nature of B-cell epitopes, their prediction presents a great challenge to computational immunologists. We propose a method, BEEPro (B-cell e pitope prediction by e volutionary information and pro pensity scales), which adapts a linear averaging scheme on 16 properties using a support vector machine model to predict both linear and conformational B-cell epitopes. These 16 properties include position specific scoring matrix (PSSM), an amino acid ratio scale, and a set of 14 physicochemical scales obtained via a feature selection process. Finally, a three-way data split procedure is used during the validation process to prevent over-estimation of prediction performance and avoid bias in our experiment results. In our experiment, first we use a non-redundant linear B-cell epitope dataset curated by Sollner et al. for feature selection and parameter optimization. Evaluated by a three-way data split procedure, BEEPro achieves significant improvement with the area under the receiver operating curve (AUC) = 0.9987, accuracy = 99.29%, mathew's correlation coefficient (MCC) = 0.9281, sensitivity = 0.9604, specificity = 0.9946, positive predictive value (PPV) = 0.9042 for the Sollner dataset. In addition, the same parameters are used to evaluate performance on other independent linear B-cell epitope test datasets, BEEPro attains an AUC which ranges from 0.9874 to 0.9950 and an accuracy which ranges from 93.73% to 97.31%. Moreover, five-fold cross-validation on one benchmark conformational B-cell epitope dataset yields an accuracy of 92.14% and AUC of 0.9066. Compared with other current models, our method achieves a significant improvement with respect to AUC, accuracy, MCC, sensitivity, specificity, and PPV. Thus, we have shown that an appropriate combination of evolutionary information and propensity scales with a support vector machine model can significantly enhance the prediction performance of both linear and conformational B-cell epitopes.	amino acids;area under curve;benchmark (computing);chronic lymphocytic leukemia;coefficient;cross reactions;cross-validation (statistics);epitopes;feature selection;hypothalamic area, lateral;level of measurement;mathematical optimization;population parameter;position weight matrix;position-specific scoring matrices;positive predictive value of diagnostic test;receiver operating characteristic;score;sensitivity and specificity;silo (dataset);support vector machine	Scott Lin;Cheng-Wei Cheng;Emily Chia-Yu Su	2013		10.1186/1471-2105-14-S2-S10	biology;support vector machine;dna microarray;integral;computer science;bioinformatics;propensity score matching	ML	8.858711899154256	-54.97970893508414	57800
a953aad5d98f0235264c9155246a7bc2083e8f4e	a computational procedure for assessing the significance of rna secondary structure	metodo cuadrado menor;computadora;prediccion;computer aided analysis;evaluation performance;methode moindre carre;energie libre;analyse assistee;performance evaluation;least squares method;structure secondaire;rna secondary structure;ordinateur;evaluacion prestacion;computer;algorithme;algorithm;modelo;ecuacion;rna;estructura secundaria;secondary structure;analisis asistido;modele;energia libre;acido nucleico;acide nucleique;equation;nucleic acid;prediction;free energy;models;algoritmo	In our recent series of papers, we have used the structures of statistical significance from Monte Carlo simulations to improve the predictions of secondary structure of RNA and to analyze the possible role of locally significant structures in the life cycle of human immunodeficiency virus. Because of intensive computational requirements for Monte Carlo simulation, it becomes impractical even using a supercomputer to assess the significance of a structure with a window size greater than 200 along an RNA sequence of 1000 bases or more. In this paper, we have developed a new procedure that drastically reduces the time needed to assess the significance of structures. In fact, the efficiency of this new method allows us to assess structures on the VAX as well as the CRAY.		Jih-Hsiang Chen;Shu-Yun Le;Bruce A. Shapiro;Kathleen M. Currey;Jacob V. Maizel	1990	Computer applications in the biosciences : CABIOS	10.1093/bioinformatics/6.1.7	biology;nucleic acid;rna;prediction;computer science;artificial intelligence;equation;nucleic acid secondary structure;least squares;genetics;algorithm;protein secondary structure	Comp.	-4.138643733925555	-54.40560309391426	57920
01f777f6a9e82597bfb454fd75a2b65c214bfa97	synchronous versus asynchronous modeling of gene regulatory networks	modelizacion;software;proteome;cell differentiation;signal transduction;gen;bioinformatique;logistic models;reduced ordered binary decision diagram;modelisation;models genetic;t helper;gene expression regulation;gene;biological systems;algorithms;reseau de regulation genetique;bioinformatica;protein interaction;modeling;gene regulatory network;cellular differentiation;computer simulation;boolean model;dynamic properties;steady state;bioinformatics;in silico	MOTIVATION In silico modeling of gene regulatory networks has gained some momentum recently due to increased interest in analyzing the dynamics of biological systems. This has been further facilitated by the increasing availability of experimental data on gene-gene, protein-protein and gene-protein interactions. The two dynamical properties that are often experimentally testable are perturbations and stable steady states. Although a lot of work has been done on the identification of steady states, not much work has been reported on in silico modeling of cellular differentiation processes.   RESULTS In this manuscript, we provide algorithms based on reduced ordered binary decision diagrams (ROBDDs) for Boolean modeling of gene regulatory networks. Algorithms for synchronous and asynchronous transition models have been proposed and their corresponding computational properties have been analyzed. These algorithms allow users to compute cyclic attractors of large networks that are currently not feasible using existing software. Hereby we provide a framework to analyze the effect of multiple gene perturbation protocols, and their effect on cell differentiation processes. These algorithms were validated on the T-helper model showing the correct steady state identification and Th1-Th2 cellular differentiation process.   AVAILABILITY The software binaries for Windows and Linux platforms can be downloaded from http://si2.epfl.ch/~garg/genysis.html.	algorithm;binary decision diagram;binary file;biological science disciplines;biological system;biotechnology;boolean;cell differentiation process;diabetes insipidus;ephrin type-b receptor 1, human;experiment;gene regulatory network;histopathologic grade differentiation;interaction;linux;manuscripts;microsoft windows;moderate response;packet analyzer;perturbation theory;protocols documentation;risk aversion;run time (program lifecycle phase);simulation;steady state	Abhishek Garg;Alessandro Di Cara;Ioannis Xenarios;Luis Mendoza;Giovanni De Micheli	2008	Bioinformatics	10.1093/bioinformatics/btn336	computer simulation;biology;simulation;computer science;bioinformatics;theoretical computer science;genetics;cellular differentiation	Comp.	6.6146638466050405	-60.13468318152152	57928
35f1b00da6991cc23ebe2d937272905a60caada0	meisetz and the birth of the krab motif	last common ancestor;n terminal;zinc finger protein;sea urchin;transcription factor;human genome	The largest family of transcription factors in mammals is of Cys(2)His(2) zinc finger-proteins, each with an NH(2)-terminal KRAB motif. Extensive expansions of this family have occurred in separate mammalian lineages, with approximately 400 such genes known in the human genome. Despite their widespread occurrence, the evolutionary provenance of the KRAB motif is unclear since previously it has not been found outside of the tetrapod vertebrates. Here, we show that homologues of the histone methyltransferase Meisetz are present within the sea urchin (Strongylocentrotus purpuratus) genome. Sea urchin and mammalian Meisetz sequences each contain an N-terminal KRAB motif, which thereby establishes an early origin of the KRAB motif prior to the divergence of echinoderm and chordate lineages. Finally, we present evidence that KRAB motifs derive from a novel family of KRI (KRAB Interior) motifs that were present in the last common ancestor of animals, plants and fungi.	chordata;color gradient;echinodermata;experiment;genome;histone h3;histones;leo (computer);leo 43204;largest;lysine;mammals;methyltransferase;mitotic prophase;most recent common ancestor;prdm9 gene;panthera;repression, psychology;russian game developers conference;setdb1 protein, human;sequence motif;strongylocentrotus purpuratus;transcription factor;transcription (software);transcription coactivator;transcription, genetic;transcriptional activation;transcriptional repression;vertebrates;zinc fingers	Zoë Birtle;Chris Paul Ponting	2006	Bioinformatics	10.1093/bioinformatics/btl498	biology;zinc finger;human genome;most recent common ancestor;n-terminus;paleontology;genetics;transcription factor	Comp.	3.694461646663022	-61.92418481688447	57934
aa4dcd674b48c77ab903240cc063bc9bb189296b	drug design using an iterative computer aided process	drug design			Ruediger Goetz;Corinna Morys-Wortmann;Marcel Thürk	1999			computer-aided;bioinformatics;biology	EDA	1.3547195222643422	-64.28575616443851	58008
f9d6aec7a860a095500db0eecb197cf2fd3f350a	kdbi: kinetic data of bio-molecular interactions database	dna;two hybrid system techniques;ligands;databases genetic;ligand binding;internet;rna;rate constant;proteins;structure and function;macromolecular substances;binding affinity;user computer interface;kinetics;chemical reaction;molecular interactions;nucleic acid;3d structure	Understanding of cellular processes and underlying molecular events requires knowledge about different aspects of molecular interactions, networks of molecules and pathways in addition to the sequence, structure and function of individual molecules involved. Databases of interacting molecules, pathways and related chemical reaction equations have been developed. The kinetic data for these interactions, which is important for mechanistic investigation, quantitative study and simulation of cellular processes and events, is not provided in the existing databases. We introduce a new database of Kinetic Data of Bio-molecular Interactions (KDBI) aimed at providing experimentally determined kinetic data of protein-protein, protein-RNA, protein-DNA, protein-ligand, RNA-ligand, DNA-ligand binding or reaction events described in the literature. KDBI contains information about binding or reaction event, participating molecules (name, synonyms, molecular formula, classification, SWISS-PROT AC or CAS number), binding or reaction equation, kinetic data and related references. The kinetic data is in terms of one or a combination of the following quantities as given in the literature of a particular event: association/dissociation or on/off rate constant, first/second/third/. order rate constant, equilibrium rate constant, catalytic rate constant, equilibrium association/dissociation constant, inhibition constant and binding affinity constant. Each entry can be retrieved through protein or nucleic acid or ligand name, SWISS-PROT AC number, ligand CAS number and full-text search of a binding or reaction event. KDBI currently contains 8273 entries of biomolecular binding or reaction events involving 1380 proteins, 143 nucleic acids and 1395 small molecules. Hyperlinks are provided for accessing references in Medline and available 3D structures in PDB and NDB. This database can be accessed at http://xin.cz3.nus.edu.sg/group/kdbi/kdbi.asp.	belousov–zhabotinsky reaction;bibliographic reference;cell nucleus;chemical formula;database;experiment;hyperlink;interaction;kinetics;ligands;medline;ndb cluster;name binding;nucleic acids;processor affinity;protein data bank;quantity;rna;swiss-model;simulation;small molecule;switzerland	Zhi Liang Ji;Xi Chen;C. J. Zheng;L. X. Yao;L. Y. Han;Wee Kiang Yeo;P. C. Chung;H. S. Puy;Y. T. Tay;A. Muhammad;Yu Zong Chen	2003	Nucleic acids research	10.1093/nar/gkg067	biology;bioinformatics;ligand;genetics	Comp.	-0.6244960779872836	-60.70399344776911	58034
34fce1fea3ad155d1ab508d4225abaa1999218e1	inferring the recent duplication history of a gene cluster	evolutionary history;gene cluster;computational method	Much important evolutionary activity occurs in gene clusters, where a copy of a gene may be free to evolve new functions. Computational methods to extract evolutionary information from sequence data for such clusters are currently imperfect, in part because accurate sequence data are often lacking in these genomic regions, making the existing methods difficult to apply. We describe a new method for reconstructing the recent evolutionary history of gene clusters. The method’s performance is evaluated on simulated data and on actual human gene clusters.		Giltae Song;Louxin Zhang;Tomás Vinar;Webb Miller	2009		10.1007/978-3-642-04744-2_10	biology;gene cluster;bioinformatics;genetics	Comp.	1.5172779088562809	-53.41498454241517	58053
b1ec6f2b6e93ca5606eab8825c2e9cbc678aa3a6	length bias correction for rna-seq data in gene set analyses	dato;analisis datos;data;bias epidemiology;error sistematico;gen;correction;corrections;data analysis;rna;bias;donnee;bias correction;high throughput sequencing;gene;correccion;analyse donnee;humans;sequencage a haut debit;sequence analysis rna;computer simulation;gene expression profiling;oligonucleotide array sequence analysis;erreur systematique	MOTIVATION Next-generation sequencing technologies are being rapidly applied to quantifying transcripts (RNA-seq). However, due to the unique properties of the RNA-seq data, the differential expression of longer transcripts is more likely to be identified than that of shorter transcripts with the same effect size. This bias complicates the downstream gene set analysis (GSA) because the methods for GSA previously developed for microarray data are based on the assumption that genes with same effect size have equal probability (power) to be identified as significantly differentially expressed. Since transcript length is not related to gene expression, adjusting for such length dependency in GSA becomes necessary.   RESULTS In this article, we proposed two approaches for transcript-length adjustment for analyses based on Poisson models: (i) At individual gene level, we adjusted each gene's test statistic using the square root of transcript length followed by testing for gene set using the Wilcoxon rank-sum test. (ii) At gene set level, we adjusted the null distribution for the Fisher's exact test by weighting the identification probability of each gene using the square root of its transcript length. We evaluated these two approaches using simulations and a real dataset, and showed that these methods can effectively reduce the transcript-length biases. The top-ranked GO terms obtained from the proposed adjustments show more overlaps with the microarray results.   AVAILABILITY R scripts are at http://www.soph.uab.edu/Statgenetics/People/XCui/r-codes/.	base sequence;biopolymer sequencing;downstream (software development);gnas wt allele;gene expression;global storage architecture;microarray;null value;rna;sequence number;silo (dataset);simulation;transcript;emotional dependency	Liyan Gao;Zhide Fang;Kui Zhang;Degui Zhi;Xiangqin Cui	2011	Bioinformatics	10.1093/bioinformatics/btr005	computer simulation;biology;dna sequencing;rna;bioinformatics;bias;gene;gene expression profiling;data analysis;genetics;statistics;data	Comp.	4.521274022693319	-52.69402674321634	58124
ab2ccee776858683b75f8469407580d3dee896c7	computational probing protein-protein interactions targeting small molecules	期刊论文	MOTIVATION With the booming of interactome studies, a lot of interactions can be measured in a high throughput way and large scale datasets are available. It is becoming apparent that many different types of interactions can be potential drug targets. Compared with inhibition of a single protein, inhibition of protein-protein interaction (PPI) is promising to improve the specificity with fewer adverse side-effects. Also it greatly broadens the drug target search space, which makes the drug target discovery difficult. Computational methods are highly desired to efficiently provide candidates for further experiments and hold the promise to greatly accelerate the discovery of novel drug targets.   RESULTS Here, we propose a machine learning method to predict PPI targets in a genomic-wide scale. Specifically, we develop a computational method, named as PrePPItar, to Predict PPIs as drug targets by uncovering the potential associations between drugs and PPIs. First, we survey the databases and manually construct a gold-standard positive dataset for drug and PPI interactions. This effort leads to a dataset with 227 associations among 63 PPIs and 113 FDA-approved drugs and allows us to build models to learn the association rules from the data. Second, we characterize drugs by profiling in chemical structure, drug ATC-code annotation, and side-effect space and represent PPI similarity by a symmetrical S-kernel based on protein amino acid sequence. Then the drugs and PPIs are correlated by Kronecker product kernel. Finally, a support vector machine (SVM), is trained to predict novel associations between drugs and PPIs. We validate our PrePPItar method on the well-established gold-standard dataset by cross-validation. We find that all chemical structure, drug ATC-code, and side-effect information are predictive for PPI target. Moreover, we can increase the PPI target prediction coverage by integrating multiple data sources. Follow-up database search and pathway analysis indicate that our new predictions are worthy of future experimental validation.   CONCLUSION In conclusion, PrePPItar can serve as a useful tool for PPI target discovery and provides a general heterogeneous data integrative framework.   AVAILABILITY AND IMPLEMENTATION PrePPItar is available at http://doc.aporc.org/wiki/PrePPItar.   CONTACT ycwang@nwipb.cas.cn or ywang@amss.ac.cn   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	advanced transportation controller;amino acid sequence;amino acids;annotation;association rule learning;bioinformatics;chemical structure;computation;cross reactions;cross-validation (statistics);database;drug delivery systems;experiment;genetic heterogeneity;interactome;machine learning;mental association;name;pathway analysis;pixel density;profiling (computer programming);proton pump inhibitors;rule (guideline);sensitivity and specificity;side effect (computer science);silo (dataset);small molecule;support vector machine;throughput;whole earth 'lectronic link;cellular targeting;protein protein interaction	Yong-Cui Wang;Shi-Long Chen;Nai-Yang Deng;Yong Wang	2016	Bioinformatics	10.1093/bioinformatics/btv528	biology	Comp.	8.429701914701416	-56.63666949675444	58157
27087f8ecb85d31844bf70ebe1cda0d07eb241dd	invhogen: a database of homologous invertebrate genes	evolution molecular;genes;invertebrates;animals;client server architecture;phylogeny;maximum likelihood;databases genetic;internet;proteins;phylogenetic tree;functional analysis;sequence homology amino acid;gene family;sequence alignment;user computer interface;027 743613;wien universitatsbibliothek;databases protein	Classification of proteins into families of homologous sequences constitutes the basis of functional analysis or of evolutionary studies. Here we present INVertebrate HOmologous GENes (INVHOGEN), a database combining the available invertebrate protein genes from UniProt (consisting of Swiss-Prot and TrEMBL) into gene families. For each family INVHOGEN provides a multiple protein alignment, a maximum likelihood based phylogenetic tree and taxonomic information about the sequences. It is possible to download the corresponding GenBank flatfiles, the alignment and the tree in Newick format. Sequences and related information have been structured in an ACNUC database under a client/server architecture. Thus, complex selections can be performed. An external graphical tool (FamFetch) allows access to the data to evaluate homology relationships between genes and distinguish orthologous from paralogous sequences. Thus, INVHOGEN complements the well-known HOVERGEN database. The databank is available at http://www.bi.uni-duesseldorf.de/~invhogen/invhogen.html.	alignment;client–server model;complement system proteins;databases;download;genbank;gene family;homologous gene;invertebrates;newick format;phylogenetic tree;phylogenetics;swiss-model;sequence homology;server (computing);switzerland;uniprot;whole earth 'lectronic link	Ingo Paulsen;Arndt von Haeseler	2006	Nucleic Acids Research	10.1093/nar/gkj100	functional analysis;biology;phylogenetic tree;the internet;invertebrate;bioinformatics;gene family;gene;sequence alignment;sequence database;maximum likelihood;genetics;client–server model	Comp.	-1.6798653132772585	-59.580195793359714	58179
50df86b11e0af4d0dbee8c839d4b57132a51e952	genomic and proteomic approaches to understand host-pathogen interactions	genomics;disease pathogenesis;host parasite interactions;host pathogen interaction;proteins;pathogenesis;immune modulation;filariaisis;informatics;proteomics;human filarial parasite;in silico predictions;in vitro	Genomic and proteomic approaches using in silico predictions, help in functional interpretation of the sequence information contained in biological organisms. These studies provide valuable insights into the structure and function of a protein under consideration. But certain studies which focus on host-pathogen interaction can be completed only when a protein is characterised with an aim to understand its role in disease pathogenesis using appropriate in vitro studies. In this regard, in the last several years, our lab has been instrumental in identification and characterisation of proteins from human filarial parasite. These studies were primarily carried out to assess their role in host pathogenesis and immune modulation using in silico and wet lab studies. The current review, thus provides a bird’s eye view on the benefits, a scientific community can reap with respect to the wealth information, if genomic and proteomic studies go hand in hand with wet lab experimentation and in silico predictions.	bird's-eye view;experiment;interaction;modulation;proteomics	N. S. A. Krushna;C. Shiny;R. B. Narayanan	2009	IJMEI	10.1504/IJMEI.2009.022643	genomics;bioinformatics;in vitro;proteomics;informatics	Comp.	6.913912607971308	-61.11792562025326	58251
f541717924c2cf6ee05c193d8269fe6cb3cf20e6	molecular recognition system controlled by thermosensitive complexation using cyclodextrin-conjugated poly(&#949;-lysine)s	molecular recognition;spectroscopy;biology;chemistry;amino acids;nuclear magnetic resonance;control systems	Molecular recognition in chemistry and biology is a kind of host-guest phenomena, which concerns inclusion complexes formed through noncovalently controlled interactions between the host and guest. Possessing well-defined hydrophobic cavities of cyclodextrins (CDs), which can bind various organic, inorganic, and biological molecules to form stable inclusion complexes or supramolecular species, have been employed as excellent hosts in supramolecular chemistry and chiral selectors in separation science and technology. Hence, a great deal of efforts has been devoted to the design and syntheses of novel CD derivatives that display enhanced molecular binding abilities and selectivities for specific substrates.	chirality (chemistry);interaction	Akihiro Takahashi;Hak Soo Choi;Tooru Ooya;Nobuhiko Yui	2004	2004 International Conference on MEMS, NANO and Smart Systems (ICMENS'04)	10.1109/ICMENS.2004.102	stereochemistry;chemistry;spectroscopy;organic chemistry;nanotechnology;molecular recognition;supramolecular chemistry;physics	EDA	3.7530535648929892	-65.622302536769	58260
10b734f7c7a58ae979a7d51aa0389fc68543cc3d	binary response models for recognition of antimicrobial peptides	amps;antimicrobial peptides;logistic regression models	There is now great urgency in developing new antibiotics to combat bacterial resistance. Recent attention has turned to naturally-occurring antimicrobial peptides (AMPs) that can serve as templates for antibacterial drug research. As natural AMPs have a wide range of activity against various bacteria, current research is focusing on modifying existing peptides or designing new ones to increase potency. This paper presents a computational approach to further our understanding of what physicochemical properties or features confer to a peptide antimicrobial activity. One of the contributions of this paper is the ability to rigorously test the relevance of features obtained by biological or computational researchers in the context of AMP recognition. A second contribution is the construction of a predictive model that employs relevant features and their combinations to associate with a novel peptide sequence a probability to have antimicrobial activity. Taken together, the work in this paper seeks to help researchers elucidate features of importance for antimicrobial activity. This is an important first step towards modification or design of novel AMPs for treatment. With this goal in mind, we provide access to the proposed methodology through a web server, which allows users to replicate the findings here or evaluate their own feature set.	computation;mind;peptide sequence;predictive modelling;relevance;self-replicating machine;server (computing);web server	Elena G. Randou;Daniel Veltri;Amarda Shehu	2013		10.1145/2506583.2506597	biology;ampere;biotechnology;bioinformatics;engineering;antimicrobial peptides;biological engineering	Vision	8.290100872003617	-60.68466756804178	58289
2d073513af70b44c523a6de624e462b21ebad435	a bayesian graphical model for integrative analysis of tcga data	biological patents;biomedical journals;text mining;europe pubmed central;citation search;genes bayesian graphical model integrative analysis tcga data matched dna copy numbers dna methylation mrna expression ovarian cancer samples methylation controlled transcription methylational variation copy number variation;citation networks;research articles;abstracts;open access;life sciences;clinical guidelines;full text;rna bayes methods biochemistry biology computing cancer dna genetics graph theory gynaecology molecular biophysics;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	We integrate three TCGA data sets including measurements on matched DNA copy numbers (C), DNA methylation (M), and mRNA expression (E) over 500+ ovarian cancer samples. The integrative analysis is based on a Bayesian graphical model treating the three types of measurements as three vertices in a network. The graph is used as a convenient way to parameterize and display the dependence structure. Edges connecting vertices infer specific types of regulatory relationships. For example, an edge between M and E and a lack of edge between C and E implies methylation-controlled transcription, which is robust to copy number changes. In other words, the mRNA expression is sensitive to methylational variation but not copy number variation. We apply the graphical model to each of the genes in the TCGA data independently and provide a comprehensive list of inferred profiles. Examples are provided based on simulated data as well.	bayesian network;copy number;graph - visual representation;graphical model;inference;malignant neoplasm of ovary;the cancer genome atlas;transcription (software);vertex (geometry);ovarian neoplasm	Yanxun Xu;Jie Zhang;Yuan Yuan;Riten Mitra;Peter Mueller;Yuan Ji	2012	Proceedings 2012 IEEE International Workshop on Genomic Signal Processing and Statistics (GENSIPS)	10.1109/GENSIPS.2012.6507747	text mining;medical research;computer science;bioinformatics;data science;data mining;genetics	Comp.	5.690161713083267	-55.34333930930823	58375
5c346b1e3d229576a548925b2ee5a9b911ef3ada	automated structural classification of lipids by machine learning		MOTIVATION Modern lipidomics is largely dependent upon structural ontologies because of the great diversity exhibited in the lipidome, but no automated lipid classification exists to facilitate this partitioning. The size of the putative lipidome far exceeds the number currently classified, despite a decade of work. Automated classification would benefit ongoing classification efforts by decreasing the time needed and increasing the accuracy of classification while providing classifications for mass spectral identification algorithms.   RESULTS We introduce a tool that automates classification into the LIPID MAPS ontology of known lipids with >95% accuracy and novel lipids with 63% accuracy. The classification is based upon simple chemical characteristics and modern machine learning algorithms. The decision trees produced are intelligible and can be used to clarify implicit assumptions about the current LIPID MAPS classification scheme. These characteristics and decision trees are made available to facilitate alternative implementations. We also discovered many hundreds of lipids that are currently misclassified in the LIPID MAPS database, strongly underscoring the need for automated classification.   AVAILABILITY AND IMPLEMENTATION Source code and chemical characteristic lists as SMARTS search strings are available under an open-source license at https://www.github.com/princelab/lipid_classifier.	algorithm;cellular automaton;classification;decision trees;decision tree;lipids measurement;machine learning;ontology (information science);open-source license;open-source software;smiles arbitrary target specification;source code;trees (plant)	Ryan M. Taylor;Ryan H. Miller;Ryan D. Miller;Michael Porter;James Dalgleish;John T. Prince	2015	Bioinformatics	10.1093/bioinformatics/btu723	computer science;bioinformatics;machine learning;data mining	Comp.	2.005721244850666	-56.107953649996915	58418
8ca1fe3e6dc2075332758a689c31ec59128486c1	rapid and selective surveillance of arabidopsis thaliana genome annotations with centrifuge	software;anotacion;sequence comparison;invertebrata;caenorhabditis elegans;ontologie;cruciferae;nemathelminthia;spermatophyta;proteine;gramineae;homo sapiens;angiospermae;genome annotation;arthropoda;surveillance;gen;annotation;oryza sativa;drosophilidae;arabidopsis thaliana;organism;gene expression;vigilancia;insecta;transcription;helmintha;diptera;drosophila melanogaster;nematoda;genome;monocotyledones;transcripcion;organisme;gene;organismo;dicotyledones;ontologia;proteina;genoma;transmembrane domain;user computer interface;high throughput;protein;ontology	UNLABELLED Centrifuge is a user-friendly system to simultaneously access Arabidopsis gene annotations and intra- and inter-organism sequence comparison data. The tool allows rapid retrieval of user-selected data for each annotated Arabidopsis gene providing, in any combination, data on the following features: predicted protein properties such as mass, pI, cellular location and transmembrane domains; SWISS-PROT annotations; Interpro domains; Gene Ontology records; verified transcription; BLAST matches to the proteomes of A.thaliana, Oryza sativa (rice), Caenorhabditis elegans, Drosophila melanogaster and Homo sapiens. The tool lends itself particularly well to the rapid analysis of contigs or of tens or hundreds of genes identified by high-throughput gene expression experiments. In these cases, a summary table of principal predicted protein features for all genes is given followed by more detailed reports for each individual gene. Centrifuge can also be used for single gene analysis or in a word search mode.   AVAILABILITY http://centrifuge.unil.ch/   CONTACT edward.farmer@unil.ch.	blast;caenorhabditis elegans;experiment;gene annotation;gene expression;gene ontology;high-throughput computing;interpro;oryza (plant);proteome;rafivirumab;switzerland;throughput;transcription (software);usability	Florence Armand;Philipp Bucher;C. Victor Jongeneel;Edward E. Farmer	2005	Bioinformatics	10.1093/bioinformatics/bti435	high-throughput screening;biology;organism;gene expression;transmembrane domain;bioinformatics;gene;ontology;genome project;transcription;genetics;genome	Comp.	-1.3927483556616371	-59.030644495341924	58494
45cd0856afb9798a224b0ba496b74fd94b7708c6	conserved hydration sites in pin1 reveal a distinctive water recognition motif in proteins	biological patents;biomedical journals;text mining;europe pubmed central;citation search;citation networks;research articles;abstracts;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	Structurally conserved water molecules are important for biomolecular stability, flexibility, and function. X-ray crystallographic studies of Pin1 have resolved a number of water molecules around the enzyme, including two highly conserved water molecules within the protein. The functional role of these localized water molecules remains unknown and unexplored. Pin1 catalyzes cis/trans isomerizations of peptidyl prolyl bonds that are preceded by a phosphorylated serine or threonine residue. Pin1 is involved in many subcellular signaling processes and is a potential therapeutic target for the treatment of several life threatening diseases. Here, we investigate the significance of these structurally conserved water molecules in the catalytic domain of Pin1 using molecular dynamics (MD) simulations, free energy calculations, analysis of X-ray crystal structures, and circular dichroism (CD) experiments. MD simulations and free energy calculations suggest the tighter binding water molecule plays a crucial role in maintaining the integrity and stability of a critical hydrogen-bonding network in the active site. The second water molecule is exchangeable with bulk solvent and is found in a distinctive helix-turn-coil motif. Structural bioinformatics analysis of nonredundant X-ray crystallographic protein structures in the Protein Data Bank (PDB) suggest this motif is present in several other proteins and can act as a water site, akin to the calcium EF hand. CD experiments suggest the isolated motif is in a distorted PII conformation and requires the protein environment to fully form the α-helix-turn-coil motif. This study provides valuable insights into the role of hydration in the structural integrity of Pin1 that can be exploited in protein engineering and drug design.		Arghya Barman;Crystal Smitherman;Michael Souffrant;Giovanni Gadda;Donald Hamelberg	2016	Journal of chemical information and modeling	10.1021/acs.jcim.5b00560	biology;biochemistry;text mining;medical research;chemistry;computer science;bioinformatics;nanotechnology;genetics	Comp.	8.612793328000238	-62.246926717532205	58545
2c21a9fcac95328f1a83c3287c170d53de30ebc5	computing highly specific and mismatch tolerant oligomers efficiently	dna;dynamic programming;biology computing;dynamic programming algorithm;abrahamson s algorithm oligomers genomes expressed sequence tags complementary dna genomic markers pcr primers dna oligo microarrays mismatch tolerance dynamic programming algorithm solution;genetics;suffix array;arrays;large scale;human genome;genetic algorithms;biology computing genetics dna arrays dynamic programming polymers genetic algorithms;polymers;sequences bioinformatics genomics humans databases dna frequency gene expression fluorescence biology computing	The sequencing of the genomes of a variety of species and the growing databases containing expressed sequence tags (ESTs) and complementary DNAs (cDNAs) facilitate the design of highly specific oligomers for use as genomic markers, PCR primers, or DNA oligo microarrays. The first step in evaluating the specificity of short oligomers of about twenty units in length is to determine the frequencies at which the oligomers occur. However, for oligomers longer than about fifty units this is not efficient, as they usually have a frequency of only 1. A more suitable procedure is to consider the mismatch tolerance of an oligomer, that is, the minimum number of mismatches that allows a given oligomer to match a sub-sequence other than the target sequence anywhere in the genome or the EST database. However, calculating the exact value of mismatch tolerance is computationally costly and impractical. Therefore, we studied the problem of checking whether an oligomer meets the constraint that its mismatch tolerance is no less than a given threshold. Here, we present an efficient dynamic programming algorithm solution that utilizes suffix and height arrays. We demonstrated the effectiveness of this algorithm by efficiently computing a dense list of oligo-markers applicable to the human genome. Experimental results show that the algorithm runs faster than well-known Abrahamson's algorithm by orders of magnitude and is able to enumerate 63% to approximately 79% of qualified oligomers.	2',5'-oligoadenylate;biopolymer sequencing;checking (action);complementary rna;computation (action);database;databases;dijkstra's algorithm;dynamic programming;enumerated type;expressed sequence tags;genome;immune tolerance;less than;microarray;oligo primer analysis software;oligonucleotides;sensitivity and specificity;seventy nine	Tomoyuki Yamada;Shinichi Morishita	2003	Proceedings. IEEE Computer Society Bioinformatics Conference	10.1109/CSB.2003.1227332	biology;molecular biology;computer science;bioinformatics;dynamic programming;genetics	Comp.	-0.9561017898200386	-53.07881442984534	58552
f82264b18502a433587c66575f27eea43459d99c	an adaptive and memory efficient algorithm for genotype imputation	evolutionary history;genomics;ucla;efficient algorithm;genome wide association study;genetics;genetic variation;large scale;statistics;reference data;high throughput;single nucleotide polymorphism;health sciences;population genetics	"""Genome wide association studies have proven to be a highly successful method for identification of genetic loci for complex phenotypes in both humans and model organisms. These large scale studies rely on the collection of hundreds of thousands of single nucleotide polymorphisms (SNPs) across the genome. Standard high-throughput genotyping technologies capture only a fraction of the total genetic variation. Recent efforts have shown that it is possible to """"impute"""" with high accuracy the genotypes of SNPs that are not collected in the study provided that they are present in a reference data set which contains both SNPs collected in the study as well as other SNPs. We here introduce a novel HMM based technique to solve the imputation problem that addresses several shortcomings of existing methods. First, our method is adaptive which lets it estimate population genetic parameters from the data and be applied to model organisms that have very different evolutionary histories. Compared to traditional methods, our method is up to ten times more accurate on model organisms such as mouse. Second, our algorithm scales in memory usage in the number of collected markers as opposed to the number of known SNPs. This issue is very relevant due to the size of the reference data sets currently being generated. We compare our method over mouse and human data sets to existing methods and show that each has either comparable or better performance and much lower memory usage. The method is available for download at      http://genetics.cs.ucla.edu/eminim        ."""	algorithm;geo-imputation	Hyun Min Kang;Noah Zaitlen;Buhm Han;Eleazar Eskin	2009		10.1007/978-3-642-02008-7_34	single-nucleotide polymorphism;genome-wide association study;high-throughput screening;biology;genomics;reference data;bioinformatics;genetic variation;population genetics;genetics	Logic	1.985646663638649	-53.455957864808305	58575
fd6065d4b845457e5ffafdae3619c0a3d9997597	modelling metabolic rewiring during melanoma progression using flux balance analysis		Improvements in melanoma diagnosis, treatment and prognosis are urgently warranted, given that it causes 3 out of 4 skin cancer deaths. A large amount of genomic and molecular data indicate that alterations occur at multiple scales in different stages of melanoma. Metabolic rewiring is a characteristic feature of progressive cancers that facilitates sustenance of tumors, and caters to the changing energy requirements. Since such rewiring involves multiple variations in the metabolic network that are orchestrated, a systems perspective is necessary to understand the nature, significance, mechanisms and identification of the key steps. To address this, we integrate patient transcriptome data with a prior human reference metabolic model and construct stage-specific genome-scale metabolic models. Using flux balance analysis, we simulate the metabolic flows and compute the reaction fluxes specific to normal skin, primary melanoma and metastatic melanoma, from which the reactions with flux differences between conditions were identified. Reactions related to Warburg effect, as anticipated and in addition, ROS detoxification and tyrosine metabolism were largely altered in all stages of melanoma. Vitamin A and vitamin C sub-systems are identified to be involved in different stages, consistent with experimental studies from literature that indicate their support to cancer progression. Gene essentiality studies using the melanoma model identified 5 important genes NME2, CMPK1, HSD17B4, DTYMK and PRODH for the proliferation of melanoma cells, which can be explored as potential drug targets.	color gradient;flux balance analysis;gene prediction;requirement;simulation	Rahul Metri;Shikhar Saxena;Madhulika Mishra;Nagasuma R. Chandra	2017	2017 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2017.8217638	computational biology;metabolic network;bioinformatics;cancer;computer science;warburg effect;flux balance analysis;gene;transcriptome;skin cancer;melanoma	Visualization	7.083394791955793	-60.79060998350391	58593
71356438797fbc90628fe24da8d579b76eb05051	bayexer: an accurate and fast bayesian demultiplexer for illumina sequences	mathematics;technology;physical sciences;biochemical research methods;statistics probability;science technology;computer science interdisciplinary applications;biotechnology applied microbiology;life sciences biomedicine;biochemistry molecular biology;mathematical computational biology;computer science	UNLABELLED Demultiplexing is used after high-throughput sequencing to in silico assign reads to the samples of origin based on the sequenced reads of the indices. Existing demultiplexing tools based on the similarity between the read index and the reference index sequences may fail to provide satisfactory results on low-quality datasets. We developed Bayexer, a Bayesian demultiplexing algorithm for Illumina sequencers. Bayexer uses the information extracted directly from the contaminant sequences of the targeting reads as the training dataset for a naïve Bayes classifier to assign reads. According to our evaluation, Bayexer provides higher capability, accuracy and speed on various real datasets than other tools.   AVAILABILITY AND IMPLEMENTATION Bayexer is implemented in Perl and freely available at https://github.com/HaisiYi/Bayexer.		Haisi Yi;Zhe Li;Tao Li;Jindong Zhao	2015	Bioinformatics	10.1093/bioinformatics/btv501	biology;computer science;bioinformatics;data science;data mining;technology	Comp.	-0.32603674198418187	-56.24000748073573	58617
8465a2a05e03de600cd4e634823cd9e8b7201e27	using predicate and provenance information from a knowledge graph for drug efficacy screening	computational pharmacology;drug efficacy screening;drug repurposing;knowledge graph;machine learning;predicate;provenance;systems pharmacology	BACKGROUND Biomedical knowledge graphs have become important tools to computationally analyse the comprehensive body of biomedical knowledge. They represent knowledge as subject-predicate-object triples, in which the predicate indicates the relationship between subject and object. A triple can also contain provenance information, which consists of references to the sources of the triple (e.g. scientific publications or database entries). Knowledge graphs have been used to classify drug-disease pairs for drug efficacy screening, but existing computational methods have often ignored predicate and provenance information. Using this information, we aimed to develop a supervised machine learning classifier and determine the added value of predicate and provenance information for drug efficacy screening. To ensure the biological plausibility of our method we performed our research on the protein level, where drugs are represented by their drug target proteins, and diseases by their disease proteins.   RESULTS Using random forests with repeated 10-fold cross-validation, our method achieved an area under the ROC curve (AUC) of 78.1% and 74.3% for two reference sets. We benchmarked against a state-of-the-art knowledge-graph technique that does not use predicate and provenance information, obtaining AUCs of 65.6% and 64.6%, respectively. Classifiers that only used predicate information performed superior to classifiers that only used provenance information, but using both performed best.   CONCLUSION We conclude that both predicate and provenance information provide added value for drug efficacy screening.	area under curve;bibliographic reference;cross reactions;cross-validation (statistics);drug delivery systems;forests;graph - visual representation;knowledge graph;machine learning;plausibility structure;random forest;receiver operating characteristic;scientific publication;supervised learning	Wytze J. Vlietstra;Rein Vos;Anneke M. Sijbers;Erik M. van Mulligen;Jan A. Kors	2018		10.1186/s13326-018-0189-6	data mining;predicate (grammar);biological plausibility;systems pharmacology;computer science;efficacy;learning classifier system;added value;graph	ML	-2.681680088338859	-65.33529902205875	58668
8385f65e1d66fb5bf7cd869d86da3c02c491e884	refprimecouch—a reference gene primer couchapp	databases genetic;internet;statistics as topic;dna primers;user computer interface;reference standards	To support a quantitative real-time polymerase chain reaction standardization project, a new reference gene database application was required. The new database application was built with the explicit goal of simplifying not only the development process but also making the user interface more responsive and intuitive. To this end, CouchDB was used as the backend with a lightweight dynamic user interface implemented client-side as a one-page web application. Data entry and curation processes were streamlined using an OpenRefine-based workflow. The new RefPrimeCouch database application provides its data online under an Open Database License. Database URL: http://hpclife.th-wildau.de:5984/rpc/_design/rpc/view.html.	apache couchdb;biological database;blink;client-side;compliance behavior;data curation;digital curation;gecko;high- and low-level;open database license;primer;real-time polymerase chain reaction;real-time transcription;spreadsheet;standards-compliant;technical support;url data type;usability;user interface device component;user experience;web application;webkit;standards characteristics	Jascha Silbermann;Catrin Wernicke;Heike Pospisil;Marcus Frohme	2013		10.1093/database/bat081	the internet;computer science;bioinformatics;data mining;database;law;world wide web;primer;information retrieval;database testing;database design	Visualization	-3.810447286724563	-59.65712832347158	58813
da9f0820d5a706aa16d3df15961e26fe172a2c34	increased robustness of early embryogenesis through collective decision-making by key transcription factors	animals;simulation and modeling;mice;systems biology;single cell analysis;physiological cellular and medical topics;transcription factors;models biological;computational biology bioinformatics;algorithms;embryonic development;gene expression profiling;blastocyst;bioinformatics	Understanding the mechanisms by which hundreds of diverse cell types develop from a single mammalian zygote has been a central challenge of developmental biology. Conrad H. Waddington, in his metaphoric “epigenetic landscape” visualized the early embryogenesis as a hierarchy of lineage bifurcations. In each bifurcation, a single progenitor cell type produces two different cell lineages. The tristable dynamical systems are used to model the lineage bifurcations. It is also shown that a genetic circuit consisting of two auto-activating transcription factors (TFs) with cross inhibitions can form a tristable dynamical system. We used gene expression profiles of pre-implantation mouse embryos at the single cell resolution to visualize the Waddington landscape of the early embryogenesis. For each lineage bifurcation we identified two clusters of TFs – rather than two single TFs as previously proposed – that had opposite expression patterns between the pair of bifurcated cell types. The regulatory circuitry among each pair of TF clusters resembled a genetic circuit of a pair of single TFs; it consisted of positive feedbacks among the TFs of the same cluster, and negative interactions among the members of the opposite clusters. Our analyses indicated that the tristable dynamical system of the two-cluster regulatory circuitry is more robust than the genetic circuit of two single TFs. We propose that a modular hierarchy of regulatory circuits, each consisting of two mutually inhibiting and auto-activating TF clusters, can form hierarchical lineage bifurcations with improved safeguarding of critical early embryogenesis against biological perturbations. Furthermore, our computationally fast framework for modeling and visualizing the epigenetic landscape can be used to obtain insights from experimental data of development at the single cell resolution.	activating transcription factors;anatomic bifurcation;bifurcation theory;decision making;dynamical system;electronic circuit;embryo;embryonic development;interaction;ion implantation;language development disorders;lineage (evolution);mammals;psychological inhibition;stem cells;structure of zygote;transcription factor;transcription (software);cell type;study of epigenetics	Ali Sharifi-Zarchi;Mehdi Totonchi;Keynoush Khaloughi;Razieh Karamzadeh;Marcos Jesús Araúzo-Bravo;Hossein Baharvand;Ruzbeh Tusserkani;Hamid Pezeshk;Hamidreza Chitsaz;Mehdi Sadeghi	2015		10.1186/s12918-015-0169-8	biology;embryogenesis;cell biology;bioinformatics;gene expression profiling;genetics;systems biology;transcription factor	Comp.	6.620336103207938	-66.06394346697549	58973
fc9135c1810458e6432304ff6eae56e179e33e29	bioq: tracing experimental origins in public genomic databases using a novel data provenance model	disease;databases genetic;genetic variation;internet;genome human;genome;hapmap project;humans	UNLABELLED Public genomic databases, which are often used to guide genetic studies of human disease, are now being applied to genomic medicine through in silico integrative genomics. These databases, however, often lack tools for systematically determining the experimental origins of the data.   RESULTS We introduce a new data provenance model that we have implemented in a public web application, BioQ, for assessing the reliability of the data by systematically tracing its experimental origins to the original subjects and biologics. BioQ allows investigators to both visualize data provenance as well as explore individual elements of experimental process flow using precise tools for detailed data exploration and documentation. It includes a number of human genetic variation databases such as the HapMap and 1000 Genomes projects.   AVAILABILITY AND IMPLEMENTATION BioQ is freely available to the public at http://bioq.saclab.net.	biological factors;databases;documentation;ephrin type-b receptor 1, human;international hapmap project;national origin;one thousand;published database;variation (genetics);web application	Scott F. Saccone;Jiaxi Quan;Peter L. Jones	2012	Bioinformatics	10.1093/bioinformatics/bts117	biology;international hapmap project;the internet;bioinformatics;data science;genetic variation;data mining;genetics;genome	Comp.	-1.9082091440498519	-60.773282791145576	58990
7f07b9df087628542401f191dbb70ee5d36f9c30	genome-scale fluxes predicted under the guidance of enzyme abundance using a novel hyper-cube shrink algorithm		Motivation One of the long-expected goals of genome-scale metabolic modelling is to evaluate the influence of the perturbed enzymes on flux distribution. Both ordinary differential equation (ODE) models and constraint-based models, like Flux balance analysis (FBA), lack the capacity to perform metabolic control analysis (MCA) for large-scale networks.   Results In this study, we developed a hyper-cube shrink algorithm (HCSA) to incorporate the enzymatic properties into the FBA model by introducing a pseudo reaction V constrained by enzymatic parameters. Our algorithm uses the enzymatic information quantitatively rather than qualitatively. We first demonstrate the concept by applying HCSA to a simple three-node network, whereby we obtained a good correlation between flux and enzyme abundance. We then validate its prediction by comparison with ODE and with a synthetic network producing voilacein and analogues in Saccharomyces cerevisiae. We show that HCSA can mimic the state-state results of ODE. Finally, we show its capability of predicting the flux distribution in genome-scale networks by applying it to sporulation in yeast. We show the ability of HCSA to operate without biomass flux and perform MCA to determine rate-limiting reactions.   Availability and implementation Algorithm was implemented by Matlab and C ++. The code is available at https://github.com/kekegg/HCSA.   Contact xiezhengwei@hsc.pku.edu.cn or qi@pku.edu.cn.   Supplementary information Supplementary data are available at Bioinformatics online.	20-methylcholanthrene;anatomic node;bioinformatics;biomass;cube dosage form;differential diagnosis;flux balance analysis;geographic information systems;hyper-igm immunodeficiency syndrome, type 1;hyperactive behavior;matlab;metabolic process, cellular;metabolic control analysis;metabolic network modelling;pseudo brand of pseudoephedrine;rate limiting;synthetic intelligence;algorithm;sporulation	Zhengwei Xie;Tianyu Zhang;Qi Ouyang	2018	Bioinformatics	10.1093/bioinformatics/btx574	flux;computer science;algorithm;flux balance analysis;ordinary differential equation;bioinformatics;protein expression;metabolic control analysis;hypercube	Comp.	6.409104481229397	-59.14816421521339	59001
6d2fd71ea1b1c49f77b6a150d9ebf83199dab0cb	using protein abundance to indicate underlying mrna expression levels in e.coli: an sem modelling approach	escherichia coli;rna messenger;models theoretical;proteomics transcriptomic relationship;systems biology;sem;gene expression;structural equation modelling;rna bacterial;gene expression regulation bacterial;escherichia coli proteins;proteomics;gene expression profiling	Do steady-state protein levels accurately predict mRNA levels? Based on the central dogma (DNA RNA protein) current protein levels are representative of mRNA present at an earlier time. However, most cellular mRNA protein comparative studies try to relate steady-state protein levels to current mRNA levels in cells. Protein steady-states are more correctly related to protein production, protein degradation and other complex cellular conditions. Using Structural Equation Modelling (SEM) we relate linear protein measurements to latent mRNA in E.coli. This method can be used to find the optimal protein measurements that explain underlying mRNA expression, and better understand the proteomic and transcriptomic relationship in E.coli gene expression.	elegant degradation;gene expression programming;proteomics;rna;steady state;structural equation modeling	Jacqueline J. Harris;Christine W. Duarte;Michael C. Mossing	2011	International journal of computational biology and drug design	10.1504/IJCBDD.2011.044445	biology;structural equation modeling;molecular biology;gene expression;cell biology;bioinformatics;gene expression profiling;proteomics;escherichia coli;scanning electron microscope;genetics;systems biology	Comp.	5.397389446717917	-59.874174538147805	59064
95e0ee6bfda148080baa37d86758d166763c45d5	moderated effect size and p-value combinations for microarray meta-analyses	effect size;taille;effet dimensionnel;analyse;valeur p;microreseau;meta analisis;metaanalysis;size effect;microarreglo;talla;metaanalyse;analysis;microarray;efecto dimensional;size;analisis	MOTIVATION With the proliferation of microarray experiments and their availability in the public domain, the use of meta-analysis methods to combine results from different studies increases. In microarray experiments, where the sample size is often limited, meta-analysis offers the possibility to considerably increase the statistical power and give more accurate results.   RESULTS A moderated effect size combination method was proposed and compared with other meta-analysis approaches. All methods were applied to real publicly available datasets on prostate cancer, and were compared in an extensive simulation study for various amounts of inter-study variability. Although the proposed moderated effect size combination improved already existing effect size approaches, the P-value combination was found to provide a better sensitivity and a better gene ranking than the other meta-analysis methods, while effect size methods were more conservative.   AVAILABILITY An R package metaMA is available on the CRAN.	experiment;heart rate variability;meta analysis (statistical procedure);microarray;prostatic neoplasms;r language;simulation	Guillemette Marot;Jean-Louis Foulley;Claus-Dieter Mayer;Florence Jaffrézic	2009	Bioinformatics	10.1093/bioinformatics/btp444	econometrics;meta-analysis;analysis;data mining;mathematics;statistics	Comp.	6.41140213705356	-52.499662509013206	59121
c69d4c6990075c7f1879258834096c84ab4d591d	hiv-associated neuropathogenesis: a systems biology perspective for modeling and therapy	hiv;brain;systems biology;hiv infections;models biological;hiv 1;neuropathogenesis;nervous system diseases;machine learning;artificial intelligence;humans;macrophages;microrna;microglia;data integration	Despite the development of powerful antiretroviral drugs, HIV-1 associated neurological disorders (HAND) will affect approximately half of those infected with HIV-1. Combined anti-retroviral therapy (cART) targets viral replication and increases T-cell counts, but it does not always control macrophage polarization, brain infection or inflammation. Moreover, it remains difficult to identify those at risk for HAND. New therapies that focus on modulating host immune response by making use of biological pathways could prove to be more effective than cART for the treatment of neuroAIDS. Additionally, while numerous HAND biomarkers have been suggested, they are of little use without methods for appropriate data integration and a systems-level interpretation. Machine learning, could be used to develop multifactorial computational models that provide clinicians and researchers with the ability to identify which factors (in what combination and relative importance) are considered important to outcome.		Susanna L. Lamers;Gary B. Fogel;David J. Nolan;Michael S. McGrath;Marco Salemi	2014	Bio Systems	10.1016/j.biosystems.2014.04.002	biology;computer science;bioinformatics;artificial intelligence;data integration;virology;machine learning;immunology;genetics;systems biology;microrna	Comp.	7.5705808600588345	-60.855807022178084	59135
bca6cda574c10c67cd2af5ba6e119fefb6f12f55	evaluation and comparison of bioinformatic tools for the enrichment analysis of metabolomics data	bioinformatic tools;database;enrichment;humancyc;kegg;metabolite;metabolomics;over-representation analysis;pathway;reactome	Bioinformatic tools for the enrichment of ‘omics’ datasets facilitate interpretation and understanding of data. To date few are suitable for metabolomics datasets. The main objective of this work is to give a critical overview, for the first time, of the performance of these tools. To that aim, datasets from metabolomic repositories were selected and enriched data were created. Both types of data were analysed with these tools and outputs were thoroughly examined. An exploratory multivariate analysis of the most used tools for the enrichment of metabolite sets, based on a non-metric multidimensional scaling (NMDS) of Jaccard’s distances, was performed and mirrored their diversity. Codes (identifiers) of the metabolites of the datasets were searched in different metabolite databases (HMDB, KEGG, PubChem, ChEBI, BioCyc/HumanCyc, LipidMAPS, ChemSpider, METLIN and Recon2). The databases that presented more identifiers of the metabolites of the dataset were PubChem, followed by METLIN and ChEBI. However, these databases had duplicated entries and might present false positives. The performance of over-representation analysis (ORA) tools, including BioCyc/HumanCyc, ConsensusPathDB, IMPaLA, MBRole, MetaboAnalyst, Metabox, MetExplore, MPEA, PathVisio and Reactome and the mapping tool KEGGREST, was examined. Results were mostly consistent among tools and between real and enriched data despite the variability of the tools. Nevertheless, a few controversial results such as differences in the total number of metabolites were also found. Disease-based enrichment analyses were also assessed, but they were not found to be accurate probably due to the fact that metabolite disease sets are not up-to-date and the difficulty of predicting diseases from a list of metabolites. We have extensively reviewed the state-of-the-art of the available range of tools for metabolomic datasets, the completeness of metabolite databases, the performance of ORA methods and disease-based analyses. Despite the variability of the tools, they provided consistent results independent of their analytic approach. However, more work on the completeness of metabolite and pathway databases is required, which strongly affects the accuracy of enrichment analyses. Improvements will be translated into more accurate and global insights of the metabolome.	bio-informatics;biocyc database collection;bioinformatics;chebi;chamaecyparis lawsoniana;chemspider;code;consensuspathdb;databases;distance;gene ontology term enrichment;gene regulatory network;http 404;heart rate variability;human metabolome database;identifier;image scaling;jaccard index;kegg;metabolite;metabolomics;multidimensional scaling;omics;paget's disease, mammary;pathvisio;pubchem;repository;search - action;silo (dataset);spatial variability	Anna Marco-Ramell;Magali Palau-Rodriguez;Ania Alay;Sara Tulipani;Mireia Urpi-Sardà;Alex Sánchez-Pla;Cristina Andres-Lacueva	2017		10.1186/s12859-017-2006-0	computational biology;jaccard index;genetics;metabolomics;metabolome;consensuspathdb;kegg;pubchem;biology;false positive paradox;metlin	HPC	3.822453254645051	-55.846030410045955	59136
2ac7da3678bdf2065ad16b1c30b25868e2b2487d	wnt signal transduction pathways: modules, development and evolution	simulation and modeling;systems biology;physiological cellular and medical topics;computational biology bioinformatics;algorithms;bioinformatics	Wnt signal transduction pathway (Wnt STP) is a crucial intracellular pathway mainly due to its participation in important biological processes, functions, and diseases, i.e., embryonic development, stem-cell management, and human cancers among others. This is why Wnt STP is one of the highest researched signal transduction pathways. Study and analysis of its origin, expansion and gradual development to the present state as found in humans is one aspect of Wnt research. The pattern of development and evolution of the Wnt STP among various species is not clear till date. A phylogenetic tree created from Wnt STPs of multiple species may address this issue. In this respect, we construct a phylogenetic tree from modules of Wnt STPs of diverse species. We term it as the ‘Module Tree’. A module is nothing but a self-sufficient minimally-dependent subset of the original Wnt STP. Authenticity of the module tree is tested by comparing it with the two reference trees. The module tree performs better than an alternative phylogenetic tree constructed from pathway topology of Wnt STPs. Moreover, an evolutionary emergence pattern of the Wnt gene family is created and the module tree is tallied with it to showcase the significant resemblances.	anatomy, regional;embryonic development;emergence;gene family;gene regulatory network;malignant neoplasms;phylogenetic tree;phylogenetics;signal transduction pathways;subgroup;transduction (machine learning);trees (plant);negative regulation of notch signaling pathway involved in somitogenesis	Losiana Nayak;Nitai P. Bhattacharyya;Rajat K. De	2016		10.1186/s12918-016-0299-7	biology;cell biology;computer science;bioinformatics;systems biology	Comp.	4.447862154668659	-58.4888596582451	59198
ed8eaa810bd40e69016b70ee8afea5bc3613b789	pssm-based prediction of dna binding sites in proteins	dna;computers;software;prediction method;sensitivity and specificity;protein structure secondary;predictive value;protein sequence;gene regulation;amino acid sequence;dna binding;binding sites;computational biology bioinformatics;models molecular;its sequences;time factors;internet;proteins;protein conformation;genome;prediction accuracy;reference data;roc curve;protein binding;algorithms;sequence alignment;sequence space;neural networks computer;combinatorial libraries;base sequence;computational biology;computer appl in life sciences;computer simulation;sequence analysis protein;dna binding protein;neural network;databases protein;microarrays;bioinformatics	Detection of DNA-binding sites in proteins is of enormous interest for technologies targeting gene regulation and manipulation. We have previously shown that a residue and its sequence neighbor information can be used to predict DNA-binding candidates in a protein sequence. This sequence-based prediction method is applicable even if no sequence homology with a previously known DNA-binding protein is observed. Here we implement a neural network based algorithm to utilize evolutionary information of amino acid sequences in terms of their position specific scoring matrices (PSSMs) for a better prediction of DNA-binding sites. An average of sensitivity and specificity using PSSMs is up to 8.7% better than the prediction with sequence information only. Much smaller data sets could be used to generate PSSM with minimal loss of prediction accuracy. One problem in using PSSM-derived prediction is obtaining lengthy and time-consuming alignments against large sequence databases. In order to speed up the process of generating PSSMs, we tried to use different reference data sets (sequence space) against which a target protein is scanned for PSI-BLAST iterations. We find that a very small set of proteins can actually be used as such a reference data without losing much of the prediction value. This makes the process of generating PSSMs very rapid and even amenable to be used at a genome level. A web server has been developed to provide these predictions of DNA-binding sites for any new protein from its amino acid sequence. Online predictions based on this method are available at http://www.netasa.org/dbs-pssm/	amino acid sequence;amino acids;artificial neural network;blast;binding sites;biological neural networks;dna binding site;gene expression regulation;homologous gene;iteration;psi protein classifier;position weight matrix;position-specific scoring matrices;published database;scanning;score;sensitivity and specificity;sequence database;sequence homology;server (computing);small;staphylococcal protein a;web server;algorithm;cellular targeting	Shandar Ahmad;Akinori Sarai	2004	BMC Bioinformatics	10.1186/1471-2105-6-33	computer simulation;biology;protein structure;plasma protein binding;dna-binding protein;molecular biology;the internet;regulation of gene expression;dna microarray;reference data;bioinformatics;binding site;protein sequencing;sequence alignment;peptide sequence;sequence space;genetics;dna;receiver operating characteristic;genome	Comp.	1.0566279854121439	-54.622070587750365	59281
cf43d314482de42be2fcf19b664614b86afec1f8	the reversible dna-alkylating activity of duocarmycin and its analogues	dna;hela cell line;anticancereux;effet temperature;producto adicion molecular;reaction reversible;lignee hela;celula hela;interaction moleculaire;bacterie;molecular interaction;hombre;indoles;agent alkylant;saline solution;bacillus subtilis;agente alquilante;pyrrolidinones;temperature effect;reaccion reversible;ph;reversible reaction;structure activity relationship;solution saline;interaccion molecular;biological activity;alkylating agents;human;chromatography high pressure liquid;nucleic acid conformation;antibiotic;antineoplastic agent;efecto temperatura;molecular adduct;bacteria;solucion salina;bacillaceae;antibiotico;duocarmycine;actividad biologica;dna damage;activite biologique;bacillales;adduit moleculaire;antibiotique;anticanceroso;homme;alkylating agent	Intact drugs with spirocyclopropylhexadienone moieties can be regenerated from the covalent DNA adducts induced by antitumor antibiotics duocarmycin (DUM) A, SA and some DUMA analogues in neutral aqueous solution. We detected the reversible nature of DUMs by determination of the antimicrobial activity and cytotoxicity of DUM-DNA adducts. All of the adducts selectively inhibited the growth of a sensitive strain of Bacillus but not that of the wild type strain, a property of parent DUM and its analogues. Most of the DNA adducts were also cytotoxic to HeLa S3. These results suggested that active drugs can be released from their covalent DNA adducts under these biological assay conditions. Regeneration of intact drugs was quantitatively analyzed by HPLC and the amount of free drug released from DNA adducts revealed that the rate and efficiency of this reversal were dependent on structural variables among the drugs. The differences in rates of reversibility were correlated with the biological activity of DUMs. The effect of pH, temperature and salt concentration on the regeneration of drugs from their DNA adducts suggest a catalytic role of double-helical DNA on the reversal pathway.	antibiotics, antineoplastic;biological assay;covalent interaction;dna adducts;duma;gene regulatory network;hela cells;hela s3;natural regeneration;sulfanilamide;wild type;adduct	Akira Asai;Satoru Nagamura;Hiromitsu Saito;Isami Takahashi;Hirofumi Nakano	1994	Nucleic acids research	10.1093/nar/22.1.88	biology;biochemistry;structure–activity relationship;bacteria;dna damage;reversible reaction;biological activity;ph;genetics;alkylation;dna	Comp.	8.101066833351261	-63.0753195569979	59377
2fb644582995253653c3b40459e135a2a196c20e	interpro, progress and status in 2005	genes;protein family;catheterization;binding site;binding sites;serveur institutionnel;taxonomic classification;proteins;archive institutionnelle;protein structure tertiary;protein processing post translational;open access;humans;sequence alignment;archive ouverte unige;cybertheses;systems integration;3d structure;article;active site;institutional repository;sequence analysis protein;databases protein;gene ontology	InterPro, an integrated documentation resource of protein families, domains and functional sites, was created to integrate the major protein signature databases. Currently, it includes PROSITE, Pfam, PRINTS, ProDom, SMART, TIGRFAMs, PIRSF and SUPERFAMILY. Signatures are manually integrated into InterPro entries that are curated to provide biological and functional information. Annotation is provided in an abstract, Gene Ontology mapping and links to specialized databases. New features of InterPro include extended protein match views, taxonomic range information and protein 3D structure data. One of the new match views is the InterPro Domain Architecture view, which shows the domain composition of protein matches. Two new entry types were introduced to better describe InterPro entries: these are active site and binding site. PIRSF and the structure-based SUPERFAMILY are the latest member databases to join InterPro, and CATH and PANTHER are soon to be integrated. InterPro release 8.0 contains 11 007 entries, representing 2573 domains, 8166 families, 201 repeats, 26 active sites, 21 binding sites and 20 post-translational modification sites. InterPro covers over 78% of all proteins in the Swiss-Prot and TrEMBL components of UniProt. The database is available for text- and sequence-based searches via a webserver (http://www.ebi.ac.uk/interpro), and for download by anonymous FTP (ftp://ftp.ebi.ac.uk/pub/databases/interpro).	binding sites;cath;databases;documentation;download;electronic signature;file transfer protocol;gene ontology;genetic translation process;interpro;panther;prints;prosite;pfam;post-translational protein processing;protein family;smart;superfamily;swiss-model;semantic integration;switzerland;tigrfams;uniprot;web server	Nicola J. Mulder;Rolf Apweiler;Terri K. Attwood;Amos Bairoch;Alex Bateman;David Binns;Paul Bradley;Peer Bork;Phillip Bucher;Lorenzo Cerutti;Richard R. Copley;Emmanuel Courcelle;Ujjwal Das;Richard Durbin;Wolfgang Fleischmann;Julian Gough;Daniel H. Haft;Nicola Harte;Nicolas Hulo;Daniel Kahn	2005	Nucleic Acids Research	10.1093/nar/gki106	biology;bioinformatics;binding site;simple modular architecture research tool;interpro	Comp.	-2.428085263664372	-61.19940708935348	59495
351028fc8edb9a4a8bab7157eb41c4d16e67cf23	first-passage time analysis of a one-dimensional diffusion-reaction model: application to protein transport along dna	dna bacterial;dna binding proteins;models biological;computational biology bioinformatics;monte carlo method;reproducibility of results;algorithms;combinatorial libraries;kinetics;computer appl in life sciences;diffusion;bacterial proteins;microarrays;bioinformatics	Proteins search along the DNA for targets, such as transcription initiation sequences, according to one-dimensional diffusion, which is interrupted by micro- and macro-hopping events and intersegmental transfers that occur under close packing conditions. A one-dimensional diffusion-reaction model in the form of difference-differential equations is proposed to analyze the nonequilibrium protein sliding kinetics along a segment of bacterial DNA. A renormalization approach is used to derive an expression for the mean first-passage time to arrive at sites downstream of the origin from the occupation probabilities given by the individual transport equations. Monte Carlo simulations are employed to assess the validity of the proposed approach, and all results are interpreted within the context of bacterial transcription. Mean first-passage times decrease with increasing reaction rates, indicating that, on average, surviving proteins more rapidly locate downstream targets than their reaction-free counterparts, but at the price of increasing rarity. Two qualitatively different screening regimes are identified according to whether the search process operates under “small” or “large” values for the dissociation rate of the protein-DNA complex. Lower bounds are placed on the overall search time for varying reactive conditions. Good agreement with experimental estimates requires the reaction rate reside near the transition between both screening regimes, suggesting that biology balances a need for rapid searches against maximum exploration during each round of the sliding phase.	downstream (software development);estimated;first-hitting-time model;frequency-hopping spread spectrum;interrupt;kinetics internet protocol;monte carlo method;probability;reside;set packing;simulation;transcription (software);transcription initiation;intracellular protein transport	Michael L. Mayo;Edward J. Perkins;Preetam Ghosh	2011		10.1186/1471-2105-12-S10-S18	biology;dna-binding protein;biophysics;molecular biology;dna microarray;bioinformatics;diffusion;genetics;kinetics;monte carlo method	ML	8.566479629644682	-64.64333731720306	59567
3d1e9e64874aea5c2d9c40f3c3f0515577042cd9	computational analysis of whole-genome differential allelic expression data in human	statistical approach;genomics;high resolution;hidden markov model;non coding rna;robust statistics;genetics;genetic variation;machine learning;differential expression;genome;gene expression regulation;allelic imbalance;algorithms;humans;computer analysis;polymorphism single nucleotide;gene expression profiling;oligonucleotide array sequence analysis;markov chains;permutation test	Allelic imbalance (AI) is a phenomenon where the two alleles of a given gene are expressed at different levels in a given cell, either because of epigenetic inactivation of one of the two alleles, or because of genetic variation in regulatory regions. Recently, Bing et al. have described the use of genotyping arrays to assay AI at a high resolution (approximately 750,000 SNPs across the autosomes). In this paper, we investigate computational approaches to analyze this data and identify genomic regions with AI in an unbiased and robust statistical manner. We propose two families of approaches: (i) a statistical approach based on z-score computations, and (ii) a family of machine learning approaches based on Hidden Markov Models. Each method is evaluated using previously published experimental data sets as well as with permutation testing. When applied to whole genome data from 53 HapMap samples, our approaches reveal that allelic imbalance is widespread (most expressed genes show evidence of AI in at least one of our 53 samples) and that most AI regions in a given individual are also found in at least a few other individuals. While many AI regions identified in the genome correspond to known protein-coding transcripts, others overlap with recently discovered long non-coding RNAs. We also observe that genomic regions with AI not only include complete transcripts with consistent differential expression levels, but also more complex patterns of allelic expression such as alternative promoters and alternative 3' end. The approaches developed not only shed light on the incidence and mechanisms of allelic expression, but will also help towards mapping the genetic causes of allelic expression and identify cases where this variation may be linked to diseases.	alleles;allelic imbalance;aortic valve insufficiency;autosome;binge eating disorder;computation;genotype determination;hidden markov model;incidence matrix;international hapmap project;machine learning;markov chain;regulatory sequences, nucleic acid;scientific publication;single nucleotide polymorphism;transcript;variation (genetics);promoter;study of epigenetics	James R. Wagner;Bing Ge;Dmitry Pokholok;Kevin L. Gunderson;Tomi Pastinen;Mathieu Blanchette	2010		10.1371/journal.pcbi.1000849	biology;robust statistics;markov chain;genomics;molecular biology;regulation of gene expression;image resolution;resampling;bioinformatics;genetic variation;non-coding rna;gene expression profiling;genetics;hidden markov model;genome	Comp.	3.26996605232288	-53.602618531639045	59593
b073764e949d2c124f5282c2e148f4ccba039301	validation of a constraint-based model of pichia pastoris metabolism under data scarcity	simulation and modeling;model combination;extracellular space;intracellular space;metabolic networks and pathways;systems biology;physiological cellular and medical topics;models biological;computational biology bioinformatics;pichia pastoris;growth rate;biomass;algorithms;possibility theory;protein expression;databases factual;computational biology;kinetics;constraint based modeling;pichia;bioinformatics	Constraint-based models enable structured cellular representations in which intracellular kinetics are circumvented. These models, combined with experimental data, are useful analytical tools to estimate the state exhibited (the phenotype) by the cells at given pseudo-steady conditions. In this contribution, a simplified constraint-based stoichiometric model of the metabolism of the yeast Pichia pastoris, a workhorse for heterologous protein expression, is validated against several experimental available datasets. Firstly, maximum theoretical growth yields are calculated and compared to the experimental ones. Secondly, possibility theory is applied to quantify the consistency between model and measurements. Finally, the biomass growth rate is excluded from the datasets and its prediction used to exemplify the capability of the model to calculate non-measured fluxes. This contribution shows how a small-sized network can be assessed following a rational, quantitative procedure even when measurements are scarce and imprecise. This approach is particularly useful in lacking data scenarios.	biomass;exclusion;exemplification;kinetics internet protocol;pichia;possibility theory;pseudo brand of pseudoephedrine;protein expression	Marta Tortajada;Francisco Llaneras;Jesús Picó	2010		10.1186/1752-0509-4-115	biology;possibility theory;extracellular;intracellular;biomass;biotechnology;bioinformatics;protein expression;systems biology;kinetics	ML	7.27870455516454	-59.67087010939431	59608
36091b1404029431a10ab74cb04032ab61e68240	toward protein structure analysis with self-organizing maps	fine structure;protein engineering;structure analysis;proteomics;sun;biology;computer science;information analysis;reference model;molecular structure;protein family;bioinformatics;secondary structure;unsupervised machine learning;sequence alignment;protein structure	Establishing structure-function relationships on the proteomic scale is a unique challenge faced by bioinformatics and molecular biosciences. Large protein families represent natural libraries of analogues of a given catalytic or protein function, thus making them ideal targets for the investigation of structure-function relationships in proteins. To this end, we have developed a new technique for analyzing large amounts of detailed molecular structure information focusing on the functional centers of homologous proteins. Our approach uses unsupervised machine learning, in particular, self-organizing maps. The information captured by a self-organizing map and stored in its reference models highlights the essential structure of the proteins under investigation and can be effectively used to study detailed structural differences and similarities among homologous proteins. Our preliminary results obtained with a prototype based on these techniques demonstrate that we can classify proteins and identify common and unique structures within a family and, more importantly, identify common and unique structural features of different conformations of the same protein. The approach developed here outperforms many of today’s structure analysis tools. These tools are usually either limited by the number of proteins they can process at the same time or they are limited by the structural resolution they can accommodate, that is, many of the structural analysis tools that can handle multiple proteins at the same time limit themselves to secondary structure analysis and therefore miss fine structural nuances within proteins.	algorithm;bioinformatics;computation;computational geometry;computer vision;experiment;feature vector;high-throughput computing;homology (biology);it baseline protection;library (computing);machine learning;mathematical model;organizing (structure);protein family;proteomics;prototype;self-organization;self-organizing map;structural analysis;throughput	Lutz Hamel;Gongqin Sun;Jing Zhang	2005	2005 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology		biology;protein structure;reference model;molecule;computer science;bioinformatics;data science;fine structure;sequence alignment;structural bioinformatics;protein engineering;structural analysis;proteomics;data analysis;protein family;protein secondary structure	Comp.	2.140490789423172	-57.95027369669321	59649
2a11afffd9c4cc93f29341d1d3f0baf482c07217	structural fluctuation and concerted motions in f1-atpase: a molecular dynamics study	molecular dynamics;structural dynamics;contact analysis;molecular dynamic;correlation matrix;f1 atpase	F(1)-ATPase is an adenosine tri-phosphate (ATP)-driven rotary motor enzyme. We investigated the structural fluctuations and concerted motions of subunits in F(1)-ATPase using molecular dynamics (MD) simulations. An MD simulation for the alpha(3)beta(3)gamma complex was carried out for 30 ns. Although large fluctuations of the N-terminal domain observed in simulations of the isolated beta(E) subunit were suppressed in the complex simulation, the magnitude of fluctuations in the C-terminal domain was clearly different among the three beta subunits (beta(E), beta(TP), and beta(DP)). Despite fairly similar conformations of the beta(TP) and beta(DP) subunits, the beta(DP) subunit exhibits smaller fluctuations in the C-terminal domain than the beta(TP) subunit due to their dissimilar interface configurations. Compared with the beta(TP) subunit, the beta(DP) subunit stably interacts with both the adjacent alpha(DP) and alpha(E) subunits. This sandwiched configuration in the beta(DP) subunit leads to strongly correlated motions between the beta(DP) and adjacent alpha subunits. The beta(DP) subunit exhibits an extensive network of highly correlated motions with bound ATP and the gamma subunit, as well as with the adjacent alpha subunits, suggesting that the structural changes occurring in the catalytically active beta(DP) subunit can effectively induce movements of the gamma subunit.	adenosine;automated theorem proving;exhibits as topic;f1-atpase;gamma correction;molecular dynamics;motion;movement;quantum fluctuation;rotary woofer;simulation;three-state logic;triangular function;procollagen type i n-terminal peptide	Yuko Ito;Mitsunori Ikeguchi	2010	Journal of computational chemistry	10.1002/jcc.21508	contact analysis;covariance matrix;f-atpase;molecular dynamics;structural dynamics;biophysics;chemistry;computational chemistry;physics;quantum mechanics	Visualization	9.239545339181007	-64.5385485996814	59666
d9f3bb4ed4b3fddef0d1a2335775d23364acffde	seqant: cloud-based whole-genome annotation and search		Describing, prioritizing, and selecting alleles from large sequencing experiments remains technically challenging. SeqAnt (https://seqant.emory.edu) is the first online, cloud-based application that makes these tasks accessible for non-programmers, even for terabyte-sized experiments containing thousands of whole-genome samples. It rapidly describes the alleles found within submitted VCF files, and then indexes the results in a natural-language search engine, which enables users to locate alleles of interest in milliseconds using normal English phrases. Our results show that SeqAnt decreases processing time by orders of magnitude and that its search engine can be used to precisely identify alleles by phenotype, genomic structure, and population genetics characteristics.	cloud computing;experiment;natural language user interface;programmer;terabyte;variant call format;web search engine	Alex V. Kotlar;Cristina E. Trevino;Michael E. Zwick;David J. Cutler;Thomas S. Wingo	2017		10.1145/3107411.3108231	genomics;cloud computing;bioinformatics;big data;population genetics;genome project;computer science;search engine;annotation	Web+IR	-1.5090414204189369	-55.54547220568375	59742
4bbbeaab9fe2ffa94b84b9ecec348711361f1a23	uprobe 2008: an online resource for universal overgo hybridization-based probe retrieval and design†	software;animals;sequence comparison;genomics;whole genome shotgun;dna probes;comparative genomics;marsupialia;genetics;rodentia;physical chromosome mapping;nonhuman primate;internet;genomic dna;genomic library;region of interest;carnivora;humans;sequence alignment;hominidae;physical map;cercopithecidae;genome sequence	Cross-species sequence comparisons are a prominent method for analyzing genomic DNA and an ever increasing number of species are being selected for whole-genome sequencing. Targeted comparative genomic sequencing is a complementary approach to whole-genome shotgun sequencing and can produce high-quality sequence assemblies of orthologous chromosomal regions of interest from multiple species. Genomic libraries necessary to support targeted mapping and sequencing projects are available for more than 90 vertebrates. An essential step for utilizing these and other genomic libraries for targeted mapping and sequencing is the development of the hybridization-based probes, which are necessary to screen a genomic library of interest. The Uprobe website (http://uprobe.genetics.emory.edu) provides a public online resource for identifying or designing 'universal' overgo-hybridization probes from conserved sequences that can be used to efficiently screen one or more genomic libraries from a designated group of species. Currently, Uprobe provides the ability to search or design probes for use in broad groups of species, including mammals and reptiles, as well as more specific clades, including marsupials, carnivores, rodents and nonhuman primates. In addition, Uprobe has the capability to design custom probes from multiple-species sequence alignments provided by the user, thus providing a general tool for targeted comparative physical mapping.	biopolymer sequencing;carnivore;clade;conserved sequence;crossbreeding;genomic library;greater than;homology (biology);libraries;mammals;nucleic acid hybridization;primates;region of interest;reptiles;rodent;sequence alignment;sequence assembly;sequence homology;superorder marsupalia (organism);vertebrates;web site;whole genome sequencing;whole-genome shotgun sequencing;comparative genomic analysis	Robert T. Sullivan;Caroline B. Morehouse;James W. Thomas	2008		10.1093/nar/gkn293	biology;hybridization probe;genomics;whole genome sequencing;the internet;bioinformatics;genomic library;genomic dna;sequence alignment;dna sequencing theory;comparative genomics;genetics;shotgun sequencing;region of interest	Comp.	-0.5064596357174312	-59.99015010923769	59780
131a910765377f74fdb3f289e21564644ad39d18	molecular computation of complex markov chains with self-loop state transitions		This paper describes a systematic method for molecular implementation of complex Markov chain processes with self-loop transitions. Generally speaking, Markov chains consist of two parts: a set of states, and state transition probabilities. Each state is modeled by a unique molecular type, referred to as a data molecule. Each state transition is modeled by a unique molecular type, referred to as a control molecule, and a unique molecular reaction. Each reaction consumes data molecules of one state and produces data molecules of another state. As we show in this paper, the produced data molecules are the same as the reactant data molecules for self-loop transitions. Although the reactions corresponding to self-loop transitions do not change the molecular concentrations of the data molecules, they are required in order for the system to compute probabilities correctly. The concentrations of control molecules are initialized according to the probabilities of corresponding state transitions in the chain. The steady-state probability of Markov chain is computed by equilibrium concentration of data molecules. We demonstrate our method for a molecular design of a seven-state Markov chain as an instance of a complex Markov chain process with self-loop state transitions. The molecular reactions are then mapped to DNA strand displacement reactions. Using the designed DNA system we compute the steady-state probability matrix such that its element (i, j) corresponds to the long-term probability of staying in state j, given it starts from state i. For example, the error in the computed probabilities is shown to be less than 2% for DNA strand-displacement reactions.	computation;displacement mapping;loop (graph theory);markov chain;self-replication;simulation;state transition table;steady state;stochastic matrix;strand (programming language)	Sayed Ahmad Salehi;Marc D. Riedel;Keshab K. Parhi	2017	2017 51st Asilomar Conference on Signals, Systems, and Computers	10.1109/ACSSC.2017.8335385	steady state;mathematical optimization;computational chemistry;stochastic matrix;computation;computer science;molecule;markov process;markov chain;data modeling	Logic	7.087123344906184	-65.18287839403315	59864
3d1450326f180a9a7d1cdb1dd24f6b6f2936ce0f	using the saccharomyces genome database (sgd) for analysis of protein similarities and structure	software;saccharomyces cerevisiae;genome fungal;internet;protein conformation;sequence homology amino acid;saccharomyces genome database;databases factual;computational biology;fungal proteins	The Saccharomyces Genome Database (SGD) collects and organizes information about the molecular biology and genetics of the yeast Saccharomyces cerevisiae. The latest protein structure and comparison tools available at SGD are presented here. With the completion of the yeast sequence and the Caenorhabditis elegans sequence soon to follow, comparison of proteins from complete eukaryotic proteomes will be an extremely powerful way to learn more about a particular protein's structure, its function, and its relationships with other proteins. SGD can be accessed through the World Wide Web at http://genome-www.stanford.edu/Saccharomyces/	molecular biology;proteome;saccharomyces genome database (sgd);saccharomyces cerevisiae;world wide web	Stephen A. Chervitz;Erich T. Hester;Catherine A. Ball;Kara Dolinski;Selina S. Dwight;Midori A. Harris;Gail Juvik;Alice Malekian;Shannon Roberts;TaiYun Roe;Charles R. Scafe;Mark Schroeder;Gavin Sherlock;Shuai Weng;Yan Zhu;J. Michael Cherry;David Botstein	1999	Nucleic acids research	10.1093/nar/27.1.74	biology;protein structure;the internet;bioinformatics;genetics	Comp.	-1.2293803097322704	-59.822129031479335	59910
1fc31a844796fdb04c9760e197390e62cf0dbf05	franz: fast reconstruction of wild pedigrees	natural population	We present a software package for fast pedigree reconstruction in natural populations using co-dominant genomic markers such as microsatellites and SNPs. If available, the algorithm makes use of prior information such as known relationships (sub-pedigrees) or the age and sex of individuals. Statistical confidence is estimated by a simulation of the sampling process. The accuracy of the algorithm is demonstrated for simulated data as well as an empirical data set with known pedigree. The parentage inference is robust even in the presence of genotyping errors.	algorithm;population;sampling (signal processing);simulation;the witcher 3: wild hunt	Markus Riester;Peter F. Stadler;Konstantin Klemm	2008			bioinformatics;single-nucleotide polymorphism;genotyping;sampling (statistics);statistical confidence;microsatellite;natural population growth;inference;pedigree chart;biology	Comp.	2.6817227427449986	-52.267302104324514	59966
5ce8e4bcc93220b33bfeb4d9c25d1fa90abf5650	a computer-based microarray experiment design-system for gene-regulation pathway discovery		This paper reports the methods and evaluation of a computer-based system that recommends microarray experimental design for biologists - causal discovery in Gene Expression data using Expected Value of Experimentation (GEEVE). The GEEVE system uses causal Bayesian networks and generates a decision tree for recommendations. To evaluate the GEEVE system, we first built an expression simulation model based on a gene regulation model assessed by an expert biologist. Using the simulation model, we conducted a controlled study that involved 10 biologists, some of whom used GEEVE and some of whom did not. The results show that biologists who used GEEVE reached correct causal assessments about gene regulation more often than did those biologists who did not use GEEVE.	bayesian network;causal filter;causality;decision tree;design of experiments;drug design;evaluation procedure;experiment;gene regulatory network;ibm notes;microarray;schmidt decomposition;simulation;united states national aeronautics and space administration	Changwon Yoo;Gregory F. Cooper	2003	AMIA ... Annual Symposium proceedings. AMIA Symposium		computational biology;regulation of gene expression;gene expression profiling;decision tree;dna microarray experiment;bayesian network;bayes' theorem;genetics;biology	Logic	6.441141403541348	-54.87086934603939	60008
1a953bc32de96a62ceafd9dcd4ac0840919420d5	effect of low-expression gene filtering on detection of differentially expressed genes in rna-seq data	filtering pipelines bioinformatics sensitivity yttrium gene expression genomics;differentially expressed genes low expression gene filtering rna seq data rna seq low expression genes rna seq technology gene expression quantification sampling noise deg detection sensitivity seqc benchmark dataset rna seq pipelines optimal filtering thresholds;rna biological techniques genetics molecular biophysics	We compare methods for filtering RNA-seq lowexpression genes and investigate the effect of filtering on detection of differentially expressed genes (DEGs). Although RNA-seq technology has improved the dynamic range of gene expression quantification, low-expression genes may be indistinguishable from sampling noise. The presence of noisy, low-expression genes can decrease the sensitivity of detecting DEGs. Thus, identification and filtering of these low-expression genes may improve DEG detection sensitivity. Using the SEQC benchmark dataset, we investigate the effect of different filtering methods on DEG detection sensitivity. Moreover, we investigate the effect of RNA-seq pipelines on optimal filtering thresholds. Results indicate that the filtering threshold that maximizes the total number of DEGs closely corresponds to the threshold that maximizes DEG detection sensitivity. Transcriptome reference annotation, expression quantification method, and DEG detection method are statistically significant RNA-seq pipeline factors that affect the optimal filtering threshold.	benchmark (computing);degree (graph theory);dynamic range;experiment;gene expression;gene co-expression network;manuscripts;pipeline (computing);quantitation;rna;sampling (signal processing);sensor;sequence number;silo (dataset);throughput;transcriptome	Ying Sha;John H. Phan;May D. Wang	2015	2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2015.7319872	biology;molecular biology;bioinformatics;genetics	Comp.	3.6150433576553294	-54.30556256663812	60057
4f4f8f524d8cbfc2879286afb4c1a8be9a81c702	designing an optimally ethanol producing e. coli strain using constrained minimal cut sets	metabolic engineering;elementary flux modes;minimal cut sets;strain design	To turn microorganisms into highly efficient cell factories computational tools, which allow analyzing the network structure of cellular metabolism in order to predict promising engineering targets, are needed. To this end minimal intervention strategies based on constrained minimal cut sets (cMCS) have been developed recently. Here we utilize cMCS to design the most efficient ethanol producing E. coli-strain. For our metabolic model of E. coli we find that at least five deletions are necessary. This is a significant decrease compared to previous designs, which predicted at least seven interventions.	max-flow min-cut theorem	Christian Jungreuthmayer;Margot Sonnleitner;Gerald Striedner;Juergen Mairhofer;Jürgen Zanghellini	2013	21st European Signal Processing Conference (EUSIPCO 2013)		structural engineering;mathematical optimization;nanotechnology;mathematics	EDA	6.736443701868714	-61.467778049883925	60076
b91220541d49dc9c4b548e151cbc12ff3b159eec	geni-db: a database of global events for epidemic intelligence	internationality;animals;mass media;population surveillance;internet;veterinary medicine;humans;databases factual	UNLABELLED We present a novel public health database (GENI-DB) in which news events on the topic of over 176 infectious diseases and chemicals affecting human and animal health are compiled from surveillance of the global online news media in 10 languages. News event frequency data were gathered systematically through the BioCaster public health surveillance system from July 2009 to the present and is available to download by the research community for purposes of analyzing trends in the global burden of infectious diseases. Database search can be conducted by year, country, disease and language.   AVAILABILITY The GENI-DB is freely available via a web portal at http://born.nii.ac.jp/.	bio-informatics;bioinformatics;communicable diseases;compiler;database;decibel;download;information overload;languages;public health surveillance;synthetic data	Nigel Collier;Son Doan	2012		10.1093/bioinformatics/bts099	the internet;bioinformatics;data science;data mining;world wide web;mass media	Web+IR	-3.461489737342891	-61.521282351279204	60099
c8c84950abbcaf9939462edb965b39d32dd139f1	generation of patterns from gene expression data by assigning confidence to differentially expressed genes	microarray data;software;expression differentielle;prediccion;computer aided analysis;criblage;computer program;metodo estadistico;hibridacion molecular;pulga de dna;expression pattern;analyse assistee;logiciel;puce a dna;confidence measure;screening;dna array;statistical method;gene expression data;algorithme;gene expression;algorithm;expression genique;false positive rate;reseau dna;methode statistique;differential expression;dna chip;cernido;logicial;analisis asistido;differentially expressed gene;molecular hybridization;hybridation moleculaire;multiple;programa computador;prediction;expresion genetica;programme ordinateur;algoritmo	MOTIVATION A protocol is described to attach expression patterns to genes represented in a collection of hybridization array experiments. Discrete values are used to provide an easily interpretable description of differential expression. Binning cutoffs for each sample type are chosen automatically, depending on the desired false-positive rate for the predictions of differential expression. Confidence levels are derived for the statement that changes in observed levels represent true changes in expression. We have a novel method for calculating this confidence, which gives better results than the standard methods. Our method reflects the broader change of focus in the field from studying a few genes with many replicates to studying many (possibly thousands) of genes simultaneously, but with relatively few replicates. Our approach differs from standard methods in that it exploits the fact that there are many genes on the arrays. These are used to estimate for each sample type an appropriate distribution that is employed to control the false-positive rate of the predictions made. Satisfactory results can be obtained using this method with as few as two replicates.   RESULTS The method is illustrated through applications to macroarray and microarray datasets. The first is an erythroid development dataset that we have generated using nylon filter arrays. Clones for genes whose expression is known in these cells were assigned expression patterns which are in accordance with what was expected and which are not picked up by the standards methods. Moreover, genes differentially expressed between normal and leukemic cells were identified. These included genes whose expression was altered upon induction of the leukemic cells to differentiate. The second application is to the microarray data by Alizadeh et al. (2000). Our results are in accordance with their major findings and offer confidence measures for the predictions made. They also provide new insights for further analysis.	choose (action);experiment;gene expression;let expression;mathematical induction;microarray;nucleic acid hybridization;nylons;personnameuse - assigned;product binning;quine (computing);silo (dataset);standards characteristics	Elisabetta Manduchi;Gregory R. Grant;Steven E. McKenzie;G. Christian Overton;Saul Surrey;Christian J. Stoeckert	2000	Bioinformatics	10.1093/bioinformatics/16.8.685	biology;dna microarray;bioinformatics;genetics;algorithm	Comp.	4.693902824865728	-53.23552274797465	60114
0929949bebc4e4a824ec7386297bf75d005ed786	bioinformatic analysis of genomic sequencing data : read alignment and variant evaluation			bioinformatics;sequence alignment	Kimon Frousios	2014			bioinformatics	Comp.	0.9604113001127855	-63.451875318728455	60205
471935bf76aa624baa094fbef93f7dd3ceee4b26	cloudrs: an error correction algorithm of high-throughput sequencing data based on scalable framework	biology computing;genome assembly;error correction algorithm design and analysis sequential analysis assembly bioinformatics genomics benchmark testing;error correction;next generation sequencing error correction mapreduce genome assembly;high throughput sequencing data cloudrs error correction algorithm hadoop mapreduce framework allpaths lg computer scientists biologists on demand computing resources data quality ngs technologies next generation sequencing scalable framework;mapreduce;next generation sequencing;error correction biology computing cloud computing;cloud computing	Next-generation sequencing (NGS) technologies produce huge amounts of data. These sequencing data unavoidably are accompanied by the occurrence of sequencing errors which constitutes one of the major problems of further analyses. Error correction is indeed one of the critical steps to the success of NGS applications such as de novo genome assembly and DNA resequencing as illustrated in literature. However, it requires computing time and memory space heavily. To design an algorithm to improve data quality by efficiently utilizing on-demand computing resources in the cloud is a challenge for biologists and computer scientists. In this study, we present an error-correction algorithm, called the CloudRS algorithm, for correcting errors in NGS data. The CloudRS algorithm aims at emulating the notion of error correction algorithm of ALLPATHS-LG on the Hadoop/ MapReduce framework. It is conservative in correcting sequencing errors to avoid introducing false decisions, e.g., when dealing with reads from repetitive regions. We also illustrate several probabilistic measures we introduce into CloudRS to make the algorithm more efficient without sacrificing its effectiveness. Running time of using up to 80 instances each with 8 computing units shows satisfactory speedup. Experiments of comparing with other error correction programs show that CloudRS algorithm performs lower false positive rate for most evaluation benchmarks and higher sensitivity on genome S. cerevisiae. We demonstrate that CloudRS algorithm provides significant improvements in the quality of the resulting contigs on benchmarks of NGS de novo assembly.	algorithm;apache hadoop;cloud computing;communications satellite;computer scientist;dna microarray;dspace;dtime;data quality;de novo transcriptome assembly;emulator;error detection and correction;high-throughput computing;mapreduce;qr code;scalability;speedup;throughput	Chien-Chih Chen;Yu-Jung Chang;Wei-Chun Chung;D. T. Lee;Jan-Ming Ho	2013	2013 IEEE International Conference on Big Data	10.1109/BigData.2013.6691642	computer science;bioinformatics;theoretical computer science;data mining	Visualization	-0.5894693962485121	-52.69594505358339	60239
5577e4a3abe6273766ea500bc3ad3abcbec989bb	increased entropy of signal transduction in the cancer metastasis phenotype	neoplasm metastasis;breast neoplasms;genomics;simulation and modeling;stochastic matrix;expression pattern;disease progression;growth factor;rna messenger;systems biology;signal transduction;gene regulatory networks;physiological cellular and medical topics;gene expression data;computational biology bioinformatics;signalling pathway;statistical properties;proteins;stochastic processes;reproducibility of results;algorithms;cell cycle;humans;entropy;neoplasms;protein interaction;metastatic breast cancer;computational biology;mrna expression;phenotype;gene expression pattern;prognosis;breast cancer;gene expression profiling;cohort studies;biological network;protein interaction network;bioinformatics	The statistical study of biological networks has led to important novel biological insights, such as the presence of hubs and hierarchical modularity. There is also a growing interest in studying the statistical properties of networks in the context of cancer genomics. However, relatively little is known as to what network features differ between the cancer and normal cell physiologies, or between different cancer cell phenotypes. Based on the observation that frequent genomic alterations underlie a more aggressive cancer phenotype, we asked if such an effect could be detectable as an increase in the randomness of local gene expression patterns. Using a breast cancer gene expression data set and a model network of protein interactions we derive constrained weighted networks defined by a stochastic information flux matrix reflecting expression correlations between interacting proteins. Based on this stochastic matrix we propose and compute an entropy measure that quantifies the degree of randomness in the local pattern of information flux around single genes. By comparing the local entropies in the non-metastatic versus metastatic breast cancer networks, we here show that breast cancers that metastasize are characterised by a small yet significant increase in the degree of randomness of local expression patterns. We validate this result in three additional breast cancer expression data sets and demonstrate that local entropy better characterises the metastatic phenotype than other non-entropy based measures. We show that increases in entropy can be used to identify genes and signalling pathways implicated in breast cancer metastasis and provide examples of de-novo discoveries of gene modules with known roles in apoptosis, immune-mediated tumour suppression, cell-cycle and tumour invasion. Importantly, we also identify a novel gene module within the insulin growth factor signalling pathway, alteration of which may predispose the tumour to metastasize. These results demonstrate that a metastatic cancer phenotype is characterised by an increase in the randomness of the local information flux patterns. Measures of local randomness in integrated protein interaction mRNA expression networks may therefore be useful for identifying genes and signalling pathways disrupted in one phenotype relative to another. Further exploration of the statistical properties of such integrated cancer expression and protein interaction networks will be a fruitful endeavour.	apoptosis;biological network;carcinoma breast stage iv;endeavour (supercomputer);ethernet hub;flux;gene expression;gene co-expression network;gene regulatory network;growth factor;interaction;mammary neoplasms;neoplasm metastasis;phenotype;randomness;signal transduction;stochastic matrix;transduction (machine learning);weighted network;zero suppression;biological signaling;cancer cell	Andrew E. Teschendorff;Simone Severini	2010		10.1186/1752-0509-4-104	biology;entropy;gene regulatory network;biological network;genomics;cell biology;cohort study;bioinformatics;breast cancer;cell cycle;phenotype;stochastic matrix;gene expression profiling;systems biology;signal transduction	Comp.	5.488001200416963	-57.49224569550871	60422
5028df880991a784301719fb33c0500d9a84b165	the ntd nanoscope: potential applications and implementations	transducers;sequence analysis dna;nanotechnology;computational biology bioinformatics;oligonucleotides;algorithms;molecular sequence data;nanopores;combinatorial libraries;base sequence;computer appl in life sciences;polymorphism single nucleotide;microarrays;bioinformatics	Nanopore transduction detection (NTD) offers prospects for a number of highly sensitive and discriminative applications, including: (i) single nucleotide polymorphism (SNP) detection; (ii) targeted DNA re-sequencing; (iii) protein isoform assaying; and (iv) biosensing via antibody or aptamer coupled molecules. Nanopore event transduction involves single-molecule biophysics, engineered information flows, and nanopore cheminformatics. The NTD Nanoscope has seen limited use in the scientific community, however, due to lack of information about potential applications, and lack of availability for the device itself. Meta Logos Inc. is developing both pre-packaged device platforms and component-level (unassembled) kit platforms (the latter described here). In both cases a lipid bi-layer workstation is first established, then augmentations and operational protocols are provided to have a nanopore transduction detector. In this paper we provide an overview of the NTD Nanoscope applications and implementations. The NTD Nanoscope Kit, in particular, is a component-level reproduction of the standard NTD device used in previous research papers. The NTD Nanoscope method is shown to functionalize a single nanopore with a channel current modulator that is designed to transduce events, such as binding to a specific target. To expedite set-up in new lab settings, the calibration and troubleshooting for the NTD Nanoscope kit components and signal processing software, the NTD Nanoscope Kit, is designed to include a set of test buffers and control molecules based on experiments described in previous NTD papers (the model systems briefly described in what follows). The description of the Server-interfacing for advanced signal processing support is also briefly mentioned. SNP assaying, SNP discovery, DNA sequencing and RNA-seq methods are typically limited by the accuracy of the error rate of the enzymes involved, such as methods involving the polymerase chain reaction (PCR) enzyme. The NTD Nanoscope offers a means to obtain higher accuracy as it is a single-molecule method that does not inherently involve use of enzymes, using a functionalized nanopore instead.	base sequence;biophysics;biopolymer sequencing;buffers;calibration;cheminformatics;detectors;experiment;flow;mast/stem cell growth factor receptor kit, human;modulation;modulator device component;neural tube defects;nitroprusside;notice and take down;nucleotides;paper;polymerase chain reaction;protocols documentation;rna;snp array;server (computer);signal processing;single nucleotide polymorphism;transduction (machine learning);workstation;aptamer	Stephen Winters-Hilt;Evenie Horton-Chao;Eric Morales	2011		10.1186/1471-2105-12-S10-S21	biology;nanopore;molecular biology;dna microarray;transducer;bioinformatics;genetics;oligonucleotide	Comp.	3.7474641782410054	-54.754479582906484	60492
0f86cc7d036aa50807da77f5666cbbf954807029	partigene-constructing partial genomes	dna;databases;software;sequence homology;bioinformatique;chromosome mapping;public domain;large scale;genome;sequence analysis;sequence alignment;genoma;bioinformatica;user computer interface;nucleic acid;chromatography;expressed sequence tag;expressed sequence tags;bioinformatics	UNLABELLED Expressed sequence tags (ESTs) offer a low-cost approach to gene discovery and are being used by an increasing number of laboratories to obtain sequence information for a wide variety of organisms. The challenge lies in processing and organizing this data within a genomic context to facilitate large scale analyses. Here we present PartiGene, an integrated sequence analysis suite that uses freely available public domain software to (1) process raw trace chromatograms into sequence objects suitable for submission to dbEST; (2) place these sequences within a genomic context; (3) perform customizable first-pass annotation of the data; and (4) present the data as HTML tables and an SQL database resource. PartiGene has been used to create a number of non-model organism database resources including NEMBASE (http://www.nematodes.org) and LumbriBase (http://www.earthworms.org/). The packages are readily portable, freely available and can be run on simple Linux-based workstations.   AVAILABILITY PartiGene is available from http://www.nematodes.org/PartiGene and also forms part of the EST analysis software, associated with the Natural Environmental Research Council (UK) Bio-Linux project (http://envgen.nox.ac.uk/biolinux.html).	annotation;candidate gene identification;data table;expressed sequence tags;genome;html;laboratory;linux;organizing (structure);physical object;public-domain software;regulatory submission;sequence analysis;structured query language;workstation	John Parkinson;Alasdair Anthony;James Wasmuth;Ralf Schmid;Ann Hedley;Mark L. Blaxter	2004	Bioinformatics	10.1093/bioinformatics/bth101	biology;bioinformatics;data mining;world wide web;genetics;expressed sequence tag	Comp.	-2.3920622418706747	-58.69635096550986	60523
fb44d06caaff5f826418552b11f2a64c38a6fbb5	svm classification model of similar bacteria species using negative marker: based on matrix-assisted laser desorption/ionization time-of-flight mass spectrometry		MALDI-TOF mass spectrometry has high social and economic value in rapid identification of microorganisms based on the protein mass profile represented in a mass spectrum of the microorganism. Numerous studies have been conducted to identify microorganisms using MALDI-TOF MS. Markers are characteristics that can be used to uniquely distinguish microorganisms. Microorganisms can be identified by applying markers selected based on the extracted mass information. Previous studies demonstrated that combining mass information extracted by MALDI-TOF MS with machine-learning techniques can improve microorganism classification. Classification of microorganisms is particularly difficult and critical for mycobacteria because various pathogens should be treated with different prescriptions, although they exhibit similar compositions. It is quite challenging to accurately identify mycobacteria using conventional methods because their MALDI-TOF MS patterns are similar to each other. In this study, we propose a support vector machine model for improving the distinction of similar species by learning positive and negative markers separately extracted in each group. We classified species in the Mycobacterium abscessus group and Mycobacterium fortuitum group. Our novel approach applies negative markers to classify similar species and improves the identification of similar species using a combination of positive and negative markers.	deep learning;machine learning;statistical classification;support vector machine	Jongseo Lee;Yoonsu Shin;Songkuk Kim;Kyoohyoung Rho;Kyu H. Park	2017	2017 IEEE 17th International Conference on Bioinformatics and Bioengineering (BIBE)	10.1109/BIBE.2017.00-64	artificial intelligence;mycobacterium abscessus;computer science;mycobacterium fortuitum;support vector machine;mass spectrum;time-of-flight mass spectrometry;machine learning;matrix-assisted laser desorption/ionization;mass spectrometry;biological system;microorganism classification	SE	9.274261389459802	-55.71437031147579	60568
4388246129017b31c48a018673af3fdd1aa5c876	structure-based virtual screening to identify the beta-lactamase ctx-m-9 inhibitors: an in silico effort to overcome antibiotic resistance in e. coli	e coli;molecular dynamics;ctx m 9;autodock vina;beta lactamase	Recently, the quick spreads of broad-spectrum beta-lactams antibiotic resistance in pathogenic strains of bacteria have become a major global health problem. These new emerging resistances cause ineffectiveness of antibiotics and increasing the severity of diseases and treatment costs. Among different and diverse resistance targets, we chose a class A beta lactamase, CTX-M-9, with the aim of identifying new chemical entities to be used for further rational drug design. Based on this purpose, a set of 5000 molecules from the Zinc database have been screened by docking experiments using AutoDock Vina software. The best ranked compound, with respect of the previously proved inhibitor compound 19, was further tested by molecular dynamics (MD) simulation. Our molecular modeling analysis demonstrates that ZINC33264777 has ideal characteristics a potent beta lactamase CTX-M-9 inhibitor. In the free form of beta lactamase, NMR relaxation studies showed the extensive motions near the active site and in the Ω-loop. However, our molecular dynamics studies revealed that in the compound 1: beta lactamase complex, the flexibility of Ω-loop was restricted.		Kambiz Davari;Jamileh Nowroozi;Farzaneh Hosseini;Abbas Akhavan Sepahy;Sako Mirzaie	2017	Computational biology and chemistry	10.1016/j.compbiolchem.2017.01.009	biology;molecular dynamics;chemistry;biotechnology;bioinformatics;computational chemistry;microbiology;physics;quantum mechanics	Comp.	9.099017006965836	-61.61684775256767	60572
495f19821f262a3645a09a9796b64ad8826bc82d	fractal and transgenerational genetic effects on phenotypic variation and disease risk	genetic effect;genetics;phenotypic variation	  To understand human biology and to manage heritable diseases, a complete picture of the genetic basis for phenotypic variation  and disease risk is needed. Unexpectedly however, most of these genetic variants, even for highly heritable traits, continue  to elude discovery for poorly understood reasons. The genetics community is actively exploring the usual explanations for  missing heritability. But given the extraordinary work that has already been done and the exceptional magnitude of the problem,  it seems likely that unconventional genetic properties are involved.    	fractal	Joe Nadeau	2011		10.1007/978-3-642-20036-6_25	biology;genetic architecture;genetics;evolutionary biology	NLP	2.844002795241646	-61.751583246981816	60613
96fdc96288070c124312f1ea881c35a9cd246d9f	protein complex prediction by date hub removal	date hub proteins;ppi network decomposition;ppi networks;protein complex prediction	Proteins physically interact with each other and form protein complexes to perform their biological functions. The prediction of protein complexes from protein-protein interaction (PPI) network is usually difficult when the complexes are overlapping with each other in a dense region of the network. To address the problem of predicting overlapping complexes, a previously proposed network-decomposition approach is promising. It decomposes a PPI network by e.g. removing proteins with high degree (hubs) which may participate in different complexes. This motivates us to examine a list of proteins, which bind their different partners at different time or at different location (viz. date hubs), manually collected from literature, for network decomposition. Results show that the CMC complex discovery algorithm after removing date hubs recalls more overlapping complexes that were missed earlier. Further improvement in performance is achieved when we predict date hub proteins based on simple network features and remove them from PPI networks.	algorithm;pixel density;proton pump inhibitors;usb hub;viz: the computer game;protein protein interaction	Iana Pyrogova;Limsoon Wong	2018	Computational biology and chemistry	10.1016/j.compbiolchem.2018.03.012	bioinformatics;biology	Comp.	8.787552900072885	-58.69825299212878	60683
336197f7b922f53260fa428e627c57ca0fc22be2	sno/scarnabase: a curated database for small nucleolar rnas and cajal body-specific rnas	search engine;rna polymerase ii;genome organization;databases nucleic acid;coiled bodies;rna guide;rna small nucleolar;internet;secondary structure;sequence motif;user computer interface;base sequence;database search	Small nucleolar RNAs (snoRNAs) and Cajal body-specific RNAs (scaRNAs) are named for their subcellular localization within nucleoli and Cajal bodies (conserved subnuclear organelles present in the nucleoplasm), respectively. They have been found to play important roles in rRNA, tRNA, snRNAs, and even mRNA modification and processing. All snoRNAs fall in two categories, box C/D snoRNAs and box H/ACA snoRNAs, according to their distinct sequence and secondary structure features. Box C/D snoRNAs and box H/ACA snoRNAs mainly function in guiding 2'-O-ribose methylation and pseudouridilation, respectively. ScaRNAs possess both box C/D snoRNA and box H/ACA snoRNA sequence motif features, but guide snRNA modifications that are transcribed by RNA polymerase II. Here we present a Web-based sno/scaRNA database, called sno/scaRNAbase, to facilitate the sno/scaRNA research in terms of providing a more comprehensive knowledge base. Covering 1979 records derived from 85 organisms for the first time, sno/scaRNAbase is not only dedicated to filling gaps between existing organism-specific sno/scaRNA databases that are focused on different sno/scaRNA aspects, but also provides sno/scaRNA scientists with an opportunity to adopt a unified nomenclature for sno/scaRNAs. Derived from a systematic literature curation and annotation effort, the sno/scaRNAbase provides an easy-to-use gateway to important sno/scaRNA features such as sequence motifs, possible functions, homologues, secondary structures, genomics organization, sno/scaRNA gene's chromosome location, and more. Approximate searches, in addition to accurate and straightforward searches, make the database search more flexible. A BLAST search engine is implemented to enable blast of query sequences against all sno/scaRNAbase sequences. Thus our sno/scaRNAbase serves as a more uniform and friendly platform for sno/scaRNA research. The database is free available at http://gene.fudan.sh.cn/snoRNAbase.nsf.	american cryptogram association;annotation;blast;categories;coiled bodies;database;digital curation;genomics;knowledge base;name;nomenclature;nucleoplasm;organelles;question (inquiry);rna polymerase ii;ribose;sbno1 gene;skil gene;sequence motif;small nuclear rna;small nucleolar rna;web search engine;negative regulation of protein localization to cajal body	Jun Xie;Ming Zhang;Tao Zhou;Xia Hua;LiSha Tang;Weilin Wu	2007		10.1093/nar/gkl873	biology;database search engine;the internet;rna polymerase ii;bioinformatics;small nucleolar rna;genomic organization;genetics;search engine;protein secondary structure;sequence motif	Comp.	-0.8245816109456966	-60.38629092662554	60705
255d2cf3b92e700f3449fecb4000c45b6dea86f7	bio-inspired data mining: treating malware signatures as biosequences		The application of machine learning to bioinformatics problems is well established. Less well understood is the application of bioinformatics techniques to machine learning and, in particular, the representation of non-biological data as biosequences. The aim of this paper is to explore the effects of giving amino acid representation to problematic machine learning data and to evaluate the benefits of supplementing traditional machine learning with bioinformatics tools and techniques. The signatures of 60 computer viruses and 60 computer worms were converted into amino acid representations and first multiply aligned separately to identify conserved regions across different families within each class (virus and worm). This was followed by a second alignment of all 120 aligned signatures together so that nonconserved regions were identified prior to input to a number of machine learning techniques. Differences in length between virus and worm signatures after the first alignment were resolved by the second alignment. Our first set of experiments indicates that representing computer malware signatures as amino acid sequences followed by alignment leads to greater classification and prediction accuracy. Our second set of experiments indicates that checking the results of data mining from artificial virus and worm data against known proteins can lead to generalizations being made from the domain of naturally occurring proteins to malware signatures. However, further work is needed to determine the advantages and disadvantages of different representations and sequence alignment methods for handling problematic machine learning data. All data, machine learning and biological tools used in this paper are publicly available and free. Computer malware signatures were downloaded from VX heavens: www.vxheavens.com. The multiple sequence alignment techniques were ClustalW and T-Coffee from EBI: www.ebi.ac.uk/Tools/msa/tcoffee. Various data mining functions within Weka (Waikato Environment for Knowledge Analysis) were used for machine learning involving cross-validation, rule extraction and classification: www.cs.waikato.ac.nz/ml/weka. Biological match of consensuses and meta-signatures was checked through the PRINTS database available via Motif3D at the University of Manchester http://www.bioinf.manchester.ac.uk/dbbrowser/motif3d/motif3d.html and FingerPRINTScan at the EBI (http address above). QUARK and the Protein Data Bank were used for consensus modeling and protein matching: zhanglab.ccmb.med.umich.edu/QUARK/ and www.pdb.org/pdb/home/home.do, respectively. The National Centre for Biotechnology Information (NCBI) was used for checking the biological function of matched proteins: ncbi.nlm.nih.gov/. The commercial package SPSS v19 was used for statistical analysis of alignment lengths and accuracy results by T tests and analysis of variance.  Corresponding author: Ajit Narayanan, Ajit.Narayanan@aut.ac.nz. Tel: +64 9921 9345; Fax: +64 9921 9944	antivirus software;bioinformatics;clustalw/clustalx;computer virus;cross-validation (statistics);data mining;experiment;external bus interface;fax;function (biology);hypertext transfer protocol;machine learning;malware;multiple sequence alignment;prints;protein data bank;rpgツクールvx value! +ツクールシリーズ素材集 和;rule induction;spss;t-coffee;uniform resource identifier;weka	Ajit Narayanan;Yi Chen	2013	CoRR		computer science;bioinformatics;machine learning;data mining	ML	-2.6771568631804903	-62.68565109118644	60828
ba4bc024efad119fd93c13e7c1c63cf9b5340d48	mycbase: a database of functional sites and biochemical properties of myc in both normal and cancer cells	computational biology bioinformatics;algorithms;computer appl in life sciences;microarrays;bioinformatics	Myc is an essential gene having multiple functions such as in cell growth, differentiation, apoptosis, genomic stability, angiogenesis, and disease biology. A large number of researchers dedicated to Myc biology are generating a substantial amount of data in normal and cancer cells/tissues including Burkitt’s lymphoma and ovarian cancer. MYCbase ( http://bicresources.jcbose.ac.in/ssaha4/mycbase ) is a collection of experimentally supported functional sites in Myc that can influence the biological cellular processes. The functional sites were compiled according to their role which includes mutation, methylation pattern, post-translational modifications, protein-protein interactions (PPIs), and DNA interactions. In addition, biochemical properties of Myc are also compiled, which includes metabolism/pathway, protein abundance, and modulators of protein-protein interactions. The OMICS data related to Myc- like gene expression, proteomics expression using mass-spectrometry and miRNAs targeting Myc were also compiled in MYCbase. The mutation and pathway data from the MYCbase were analyzed to look at the patterns and distributions across different diseases. There were few proteins/genes found common in Myc-protein interactions and Myc-DNA binding, and these can play a significant role in transcriptional feedback loops. In this report, we present a comprehensive integration of relevant information regarding Myc in the form of MYCbase. The data compiled in MYCbase provides a reliable data resource for functional sites at the residue level and biochemical properties of Myc in various cancers.	apoptosis;body tissue;compiler;experiment;feedback;gene expression;gene regulatory network;genetic translation process;lymphoma;lymphoma, non-hodgkin;malignant neoplasms;malignant neoplasm of ovary;micrornas;mutation (genetic algorithm);omics;post-translational protein processing;proteomics;proto-oncogene proteins c-myc;spectrometry;transcription, genetic;cancer cell;cell growth;dna binding;ovarian neoplasm;protein protein interaction	Debangana Chakravorty;Tanmoy Jana;Sukhen Das Mandal;Anuradha Seth;Anubrata Bhattacharya;Sudipto Saha	2017		10.1186/s12859-017-1652-6	biology;molecular biology;dna microarray;computer science;bioinformatics;genetics	Comp.	1.613804809154309	-59.611954629545984	60875
18bb612739e39fc85fbc94c94c1303c350a69496	zero-inflated beta regression for differential abundance analysis with metagenomics data	biological patents;biomedical journals;text mining;europe pubmed central;citation search;statistical models;citation networks;metagenomics;machine learning;research articles;abstracts;open access;life sciences;clinical guidelines;graphs and networks;algorithms;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	Metagenomics data have been growing rapidly due to the advances in NGS technologies. One goal of human microbial studies is to detect abundance differences across clinical conditions. Besides small sample size and high dimension, metagenomics data are usually represented as compositions (proportions) with a large number of zeros and skewed distribution. Efficient tools for handling such compositional data need to be developed. We propose a zero-inflated beta regression approach (ZIBSeq) for identifying differentially abundant features between multiple clinical conditions. The proposed method takes the sparse nature of metagenomics data into account and handle the compositional data efficiently. Compared with other available methods, the proposed approach demonstrates better performance with large AUC values for most simulation studies. When applied to a human metagenomics data, it also identifies biologically important taxa reported from previous studies. The software in R is available upon request from the first author.		Xiaoling Peng;Gang Li;Zhenqiu Liu	2016	Journal of computational biology : a journal of computational molecular cell biology	10.1089/cmb.2015.0157	statistical model;biology;text mining;computer science;bioinformatics;data science;data mining;metagenomics	Comp.	5.477448555153345	-52.63109325472651	60976
24e731c6c476fa56d10b99f548cdaa76b75d0b75	franz: reconstruction of wild multi-generation pedigrees	software;reconstruction;pedigri;prior information;monte carlo method;software package;algorithms;source code;pedigree;computational biology;polymorphism single nucleotide;markov chains;natural population;reconstruccion	SUMMARY We present a software package for pedigree reconstruction in natural populations using co-dominant genomic markers such as microsatellites and single nucleotide polymorphisms (SNPs). If available, the algorithm makes use of prior information such as known relationships (sub-pedigrees) or the age and sex of individuals. Statistical confidence is estimated by Markov Chain Monte Carlo (MCMC) sampling. The accuracy of the algorithm is demonstrated for simulated data as well as an empirical dataset with known pedigree. The parentage inference is robust even in the presence of genotyping errors.   AVAILABILITY The C source code of FRANz can be obtained under the GPL from http://www.bioinf.uni-leipzig.de/Software/FRANz/.	genetic polymorphism;genotype determination;inference;markov chain monte carlo;monte carlo method;nucleotides;numerous;population;sampling (signal processing);short tandem repeat;silo (dataset);single nucleotide polymorphism;source code;algorithm;genetic pedigree	Markus Riester;Peter F. Stadler;Konstantin Klemm	2009		10.1093/bioinformatics/btp064	markov chain;computer science;bioinformatics;theoretical computer science;natural population growth;genetics;statistics;monte carlo method;source code	Comp.	2.744819523873196	-52.26629028841045	61035
a8931dbdbb3c5ac8df7444717a3659ed5be58a22	probelynx: a tool for updating the association of microarray probes to genes	microarray data;software;animals;genomics;mice;dna probes;rna messenger;databases nucleic acid;internet;cattle;chickens;dna complementary;gene prediction;humans;oligonucleotide probes;base sequence;gene function;database management system;gene expression profiling;oligonucleotide array sequence analysis;genome sequence	As genome sequence data and gene prediction improve, probes developed for a given microarray experiment should be continuously re-evaluated for their specificity for given genes. ProbeLynx(www.pathogenomics.ca/probelynx) is a new web service which uses current genomic sequence information to re-examine microarray probe specificity and provide annotation updates relevant to determining which gene(s) and transcript(s) are associated with a given probe. Probe sequences (either oligonucleotide- or cDNA-based) are uploaded in FASTA format and the results returned as a tab-delimited flat file for insertion into a spreadsheet application or database management system for further analysis. ProbeLynx has been initially developed to focus on arrays derived from human, mouse, chicken and bovine genomes, but may be expanded to handle other genomic datasets. ProbeLynx offers microarray users the important ability to continuously assess the potential of a probe to cross-hybridize to paralogous genes and the suitability of a given probe to investigate a transcript of interest. By also including the latest gene function annotation information in the output, ProbeLynx provides the critical first step in updating microarray data annotation.	array data structure;awards;cattle;cellular immunity;clinical act of insertion;dna, complementary;data base management;database management systems;delimiter;dosage forms;fasta format;flat file database;gene annotation;gene prediction;genome;homology (biology);insertion mutation;microarray;nar 2;nucleic acid hybridization;partial;probability;sensitivity and specificity;sequence homology;spreadsheet;tablet dosage form;transcript;web service	Fiona M. Roche;Karsten Hokamp;Michael Acab;Lorne A. Babiuk;Robert E. W. Hancock;Fiona S. L. Brinkman	2004	Nucleic acids research	10.1093/nar/gkh452	biology;microarray analysis techniques;hybridization probe;genomics;molecular biology;gene chip analysis;whole genome sequencing;the internet;bioinformatics;gene expression profiling;microarray databases;genetics;gene prediction	Comp.	-1.6919924611018222	-59.878930609176045	61095
22e03da738b70c35301a440270f5259f3b5e9949	dsstox chemical-index files for exposure-related experiments in arrayexpress and gene expression omnibus: enabling toxico-chemogenomics data linkages	dato;fichier;exposition;data;liaison genetique;gen;index;fichero;genetic mapping;gene expression;expression genique;genetic linkage;file;donnee;data extraction;indice;indexation;carte genetique;gene;data linkage;exposicion;mapa genetico;expresion genetica;exposure;gene expression omnibus;ligamiento genetico	SUMMARY The Distributed Structure-Searchable Toxicity (DSSTox) ARYEXP and GEOGSE files are newly published, structure-annotated files of the chemical-associated and chemical exposure-related summary experimental content contained in the ArrayExpress Repository and Gene Expression Omnibus (GEO) Series (based on data extracted on September 20, 2008). ARYEXP and GEOGSE contain 887 and 1064 unique chemical substances mapped to 1835 and 2381 chemical exposure-related experiment accession IDs, respectively. The standardized files allow one to assess, compare and search the chemical content in each resource, in the context of the larger DSSTox toxicology data network, as well as across large public cheminformatics resources such as PubChem (http://pubchem.ncbi.nlm.nih.gov).   AVAILABILITY Data files and documentation may be accessed online at http://epa.gov/ncct/dsstox/.	accession number (identifier);accession number (bioinformatics);adverse reaction to drug;cheminformatics;chemogenomics;contain (action);documentation;experiment;extraction;large;pubchem;scientific publication;toxnet: hazardous substances data bank	ClarLynda R. Williams-DeVane;Maritja A. Wolf;Ann M. Richard	2009	Bioinformatics	10.1093/bioinformatics/btp042	biology;gene expression;gene mapping;computer file;genetic linkage;bioinformatics;exposure;gene;data mining;database;genetics;data	Comp.	-2.7170161728191777	-61.07289200155016	61142
53d262e2413e4484ca2ce3fada859467f723ccd0	sws: accessing srs sites contents through web services	software;search engine;database management systems;web service;computational biology bioinformatics;data analysis;workflow system;internet;algorithms;workflow management system;biological data;user computer interface;databases factual;combinatorial libraries;networked systems;computer appl in life sciences;information storage and retrieval;microarrays;bioinformatics;in silico	Web Services and Workflow Management Systems can support creation and deployment of network systems, able to automate data analysis and retrieval processes in biomedical research. Web Services have been implemented at bioinformatics centres and workflow systems have been proposed for biological data analysis. New databanks are often developed by taking into account these technologies, but many existing databases do not allow a programmatic access. Only a fraction of available databanks can thus be queried through programmatic interfaces. SRS is a well know indexing and search engine for biomedical databanks offering public access to many databanks and analysis tools. Unfortunately, these data are not easily and efficiently accessible through Web Services. We have developed ‘SRS by WS’ (SWS), a tool that makes information available in SRS sites accessible through Web Services. Information on known sites is maintained in a database, srsdb. SWS consists in a suite of WS that can query both srsdb, for information on sites and databases, and SRS sites. SWS returns results in a text-only format and can be accessed through a WSDL compliant client. SWS enables interoperability between workflow systems and SRS implementations, by also managing access to alternative sites, in order to cope with network and maintenance problems, and selecting the most up-to-date among available systems. Development and implementation of Web Services, allowing to make a programmatic access to an exhaustive set of biomedical databases can significantly improve automation of in-silico analysis. SWS supports this activity by making biological databanks that are managed in public SRS sites available through a programmatic interface.	bioinformatics;compliance behavior;deploy;health services research;indexes;interoperability;management system;published database;question (inquiry);rss gene;sinewave synthesis;sturge-weber syndrome;text-based user interface;web service definition language;web services description language;web search engine;contents - htmllinktype	Paolo Romano;Domenico Marra	2008	BMC Bioinformatics	10.1186/1471-2105-9-S2-S15	web service;the internet;dna microarray;biological data;computer science;bioinformatics;data mining;database;data analysis;world wide web;workflow management system;search engine	DB	-3.14116343440946	-61.2976253429633	61236
53b67438d2d0fbba09b67337e98c34f4403898f3	analyzing microarray data using clans	microarray data;sequence homology;protein family;phylogeny;computer graphics;genetic database;journal article;gene expression;keywords amino acid sequence;algorithm;microarray analysis;cluster analysis;nonhuman;quantitative analysis;computer int;priority journal;article;automation	UNLABELLED Analysis of microarray experiments is complicated by the huge amount of data involved. Searching for groups of co-expressed genes is akin to searching for protein families in a database as, in both cases, small subsets of genes with similar features are to be found within vast quantities of data. CLANS was originally developed to find protein families in large sets of amino acid sequences where the amount of data involved made phylogenetic approaches overly cumbersome. We present a number of improvements that greatly extend the previous version of CLANS and show its application to microarray data as well as its ability of incorporating additional information to facilitate interactive analysis.   AVAILABILITY The program is available for download from: http://bioinfoserver.rsbs.anu.edu.au/downloads/clans/	amino acid sequence;amino acids;database;download;experiment;microarray;phylogenetics;protein family;quantity	Tancred Frickey;Georg F. Weiller	2007	Bioinformatics	10.1093/bioinformatics/btm079	biology;microarray analysis techniques;computer science;bioinformatics;data mining;world wide web;genetics;phylogenetics	Comp.	0.019013969576863122	-56.780118195676	61242
637924cba7f615aa3e49bda82586f5307b44a7ed	batch rnai selector: a standalone program to predict specific sirna candidates in batches with enhanced sensitivity	rna interference;homology search;fasta;short interfering;gene expression;rna interference rnai;gene silencing;short interfering rnas sirna;database search;ssearch	RNA interference (RNAi) is a popular and effective method for silencing gene expression. siRNAs should be gene-specific and effective to achieve specific and potent gene silencing. However, most currently available siRNA design programs are web-based programs that either require each sequence be submitted individually, making large-batch analyses difficult to conduct, or only provide limited options for searching off-target candidates (e.g. NCBI-BLAST). We have developed a stand-alone, enhanced RNAi design program that overcomes these shortcomings. We have implemented WU-BLAST, FASTA and SSEARCH homology searches for siRNA candidates to improve gene specific siRNA selection and to identity siRNA candidates that could lead to off-target gene silencing. We also included many new features such as siRNA score calculation and calculation of siRNA internal stability to help select highly potent siRNAs. This program is freely available for academic and commercial use (), and can be installed and run on any Linux machine. Our program automates the search for siRNAs and the resulting data files including a list of siRNA primers with scores and database search results for each siRNA candidate are stored locally for easy retrieval and inspection when needed.	blast injuries;effective method;fasta;gene expression;gene silencing;homologous gene;homology (biology);interference (communication);linux;rna interference;rna, small interfering;standalone program;web application	Shyamala Iyer;Kerry Deutsch;Xiaowei Yan;Biaoyang Lin	2007	Computer methods and programs in biomedicine	10.1016/j.cmpb.2006.11.004	database search engine;gene expression;gene silencing;bioinformatics;rna interference	Comp.	-0.03156127413416686	-57.05224671541123	61260
3b01267b7a24601ad6708090e7ac30e0c5a61ada	inference of gene regulatory network based on module network model with gene functional classifications	biology computing;cellular biophysics;classification;genetics;inference mechanisms;physiological models;g1 phase;biological knowledge;gene functional classifications;gene regulatory network;genome-wide expression data;inference;module network model;yeast cell-cycle	We propose a novel method for an exhaustive inference of gene regulatory networks from genome-wide expression data and biological knowledge. Our method performs the inferences based on module network model. In the model a module is a set of genes with similar features, and a network represents regulatory relationships among the modules. Our method makes modules using gene functional classification together with expression data. We apply our method to inferences of the networks of yeast cell-cycle. Modules inferred by our method show consistency with experimentally-determined results on yeast cell-cycle, especially on G1 phase. Robust modules built by our method permit us to infer informative regulatory relationships.	experiment;gene regulatory network;information;network model	Kohei Taki;Reiji Teramoto;Yoichi Takenaka;Hideo Matsuda	2004	Proceedings. 2004 IEEE Computational Systems Bioinformatics Conference, 2004. CSB 2004.	10.1109/CSB.2004.1332524	biological network inference;biology;gene regulatory network;biological network;biological classification;bioinformatics;network model;cell cycle;data mining;genetics	Comp.	6.1952173212216275	-56.240850553323746	61270
3244eaab49774e128512e588c4000072ff8c9577	wormbase 2012: more genomes, more data, new website	animals;genomics;caenorhabditis elegans;caenorhabditis;computer graphics;molecular sequence annotation;databases genetic;internet;genome helminth;nematoda;phenotype;gene expression profiling	Since its release in 2000, WormBase (http://www.wormbase.org) has grown from a small resource focusing on a single species and serving a dedicated research community, to one now spanning 15 species essential to the broader biomedical and agricultural research fields. To enhance the rate of curation, we have automated the identification of key data in the scientific literature and use similar methodology for data extraction. To ease access to the data, we are collaborating with journals to link entities in research publications to their report pages at WormBase. To facilitate discovery, we have added new views of the data, integrated large-scale datasets and expanded descriptions of models for human disease. Finally, we have introduced a dramatic overhaul of the WormBase website for public beta testing. Designed to balance complexity and usability, the new site is species-agnostic, highly customizable, and interactive. Casual users and developers alike will be able to leverage the public RESTful application programming interface (API) to generate custom data mining solutions and extensions to the site. We report on the growth of our database and on our work in keeping pace with the growing demand for data, efforts to anticipate the requirements of users and new collaborations with the larger science community.	application programming interface;data mining;description;digital curation;entity;file spanning;genome;interface device component;journal;large;page (document);representational state transfer;requirement;scientific literature;software release life cycle;software testing;solutions;usability;web site;wormbase	Karen Yook;Todd W. Harris;Tamberlyn Bieri;Abigail Cabunoc;Juancarlos Chan;Wen J. Chen;Paul Davis;Norie De La Cruz;Adrian Duong;Ruihua Fang;Uma Ganesan;Christian Grove;Kevin L. Howe;Snehalata Kadam;Ranjana Kishore;Raymond Y. N. Lee;Yuling Li;Hans-Michael Müller;Cecilia Nakamura;Bill Nash	2012		10.1093/nar/gkr954	biology;genomics;the internet;bioinformatics;phenotype;gene expression profiling;computer graphics;genetics	HCI	-2.6405732915909748	-59.63505602473532	61394
b1f90f2568468e22514df9a61baeb82ad0630e65	comparative analysis of long dna sequences by per element information content using different contexts	dna;comparative analysis;information systems;sequence analysis dna;information content;journal article;computational biology bioinformatics;sequence homology nucleic acid;linear time;linear transformation;plasmodium falciparum;algorithms;molecular sequence data;sequence alignment;combinatorial libraries;base sequence;dna sequence;linear space;computer appl in life sciences;information storage and retrieval;information theory;microarrays;bioinformatics	Features of a DNA sequence can be found by compressing the sequence under a suitable model; good compression implies low information content. Good DNA compression models consider repetition, differences between repeats, and base distributions. From a linear DNA sequence, a compression model can produce a linear information sequence. Linear space complexity is important when exploring long DNA sequences of the order of millions of bases. Compressing a sequence in isolation will include information on self-repetition. Whereas compressing a sequence Y in the context of another X can find what new information X gives about Y. This paper presents a methodology for performing comparative analysis to find features exposed by such models. We apply such a model to find features across chromosomes of Cyanidioschyzon merolae. We present a tool that provides useful linear transformations to investigate and save new sequences. Various examples illustrate the methodology, finding features for sequences alone and in different contexts. We also show how to highlight all sets of self-repetition features, in this case within Plasmodium falciparum chromosome 2. The methodology finds features that are significant and that biologists confirm. The exploration of long information sequences in linear time and space is fast and the saved results are self documenting.	base;chromosomes;compression;dspace;dioon merolae;documented;qualitative comparative analysis;self-information;software documentation;time complexity;cell transformation	Trevor I. Dix;David R. Powell;Lloyd Allison;Julie Bernal;Samira Jaeger;Linda Stern	2007	BMC Bioinformatics	10.1186/1471-2105-8-S2-S10	time complexity;qualitative comparative analysis;biology;dna sequencing;dna microarray;self-information;information theory;bioinformatics;theoretical computer science;sequence alignment;linguistic sequence complexity;linear map;genetics;dna;information system;linear space	Comp.	-3.292665054620347	-52.86354677280477	61455
6aeec4d3594c0cb86f0a01d9d52d47123f34b518	estimate haplotype frequencies in pedigrees	evolution molecular;haplotype block;linear time algorithm;frequency estimation;chromosome mapping;sequence analysis dna;genetic variation;association study;computational biology bioinformatics;configuration space;models genetic;expectation maximization;gene frequency;human genome;models statistical;algorithms;haplotype inference;molecular sequence data;combinatorial libraries;pedigree;base sequence;em algorithm;computer appl in life sciences;computer simulation;linkage disequilibrium;haplotypes;microarrays;bioinformatics	Haplotype analysis has gained increasing attention in the context of association studies of disease genes and drug responsivities over the last years. The potential use of haplotypes has led to the initiation of the HapMap project which is to investigate haplotype patterns in the human genome in different populations. Haplotype inference and frequency estimation are essential components of this endeavour. We present a two-stage method to estimate haplotype frequencies in pedigrees, which includes haplotyping stage and estimation stage. In the haplotyping stage, we propose a linear time algorithm to determine all zero-recombinant haplotype configurations for each pedigree. In the estimation stage, we use the expectation-maximization (EM) algorithm to estimate haplotype frequencies based on these haplotype configurations. The experiments demonstrate that our method runs much faster and gives more credible estimates than other popular haplotype analysis software that discards the pedigree information. Our method suggests that pedigree information is of great importance in haplotype analysis. It can be used to speedup estimation process, and to improve estimation accuracy as well. The result also demonstrates that the whole haplotype configuration space can be substituted by the space of zero-recombinant haplotype configurations in haplotype frequency estimation, especially when the considered haplotype block is relatively short.	arabic numeral 0;blast e-value;endeavour (supercomputer);estimated;expectation–maximization algorithm;experiment;haplotypes;inference;international hapmap project;population;recombinant dna;recombinants;spectral density estimation;speedup;time complexity;transcription initiation;efmoroctocog alfa 1 unt injection;genetic pedigree	Qiangfeng Zhang;YuZhong Zhao;Guoliang Chen;Yun Xu	2006	BMC Bioinformatics	10.1186/1471-2105-7-S4-S5	modal haplotype;computer simulation;biology;haplotype estimation;expectation–maximization algorithm;bioinformatics;genetics	Comp.	2.5565531104414125	-52.5909995566029	61603
309ac615e6bdde19afbb55bae46848f98933f5a5	a numerical method for allocating microbial isolates to strain types when characterized by typing methods that are not 100% reproducible	computer program;isolate;aislado;computerized processing;tratamiento informatico;bacterie;numerical method;implementation;reproductibilite;algorithme;algorithm;ejecucion;tipificacion;typing;isolat;reproductividad;typage;fortran;bacteria;programa computador;traitement informatique;programme ordinateur;reproducibility;algoritmo	Many methods for typing microbial strains are not 100% reproducible. This can create problems when deciding whether different groups of isolates are really distinct or represent typing errors or variation of a single strain. Neither hierarchical clustering nor iterative partitioning methods are suited for analysing such data. A novel iterative partitioning method is described which allows for the uncertainty of the typing method in use. Before grouping strains, the maximum dimension of the groups is set based on a previous knowledge of the typing method's reproducibility. Isolates are only allocated to a group if they differ from that group's typical strain type by less than the number of reaction differences required to distinguish between two strains. In a series of Monte Carlo studies the accuracy of strain allocation was found to be very good, even when the two groups were situated close to each other.		Paul R Hunter	1993	Computer applications in the biosciences : CABIOS	10.1093/bioinformatics/9.4.403	biology;bacteria;numerical analysis;computer science;bioinformatics;theoretical computer science;reproducibility;implementation;algorithm	Graphics	-4.080443282223943	-54.61305482281604	61693
52422a7c34ec4fd4558b4daff019e57883e5e589	pharmacophore screening of the protein data bank for specific binding site chemistry	criblage;cavidad;proteine;interaction moleculaire;molecular interaction;cavite;screening;biologia molecular;database;base dato;hombre;binding site;epigenetique;residu;pharmacophore;structure proteine;site fixation;protein structure;biblioteca electronica;interaccion molecular;molecular biology;human;epigenetica;base de donnees;depistage;descubrimiento;cavity;cernido;electronic library;medical screening;proteina;residuo;protein;residue;sitio fijacion;epigenetics;protein data bank;bibliotheque electronique;farmacoforo;homme;biologie moleculaire	A simple computational approach was developed to screen the Protein Data Bank (PDB) for putative pockets possessing a specific binding site chemistry and geometry. The method employs two commonly used 3D screening technologies, namely identification of cavities in protein structures and pharmacophore screening of chemical libraries. For each protein structure, a pocket finding algorithm is used to extract potential binding sites containing the correct types of residues, which are then stored in a large SDF-formatted virtual library; pharmacophore filters describing the desired binding site chemistry and geometry are then applied to screen this virtual library and identify pockets matching the specified structural chemistry. As an example, this approach was used to screen all human protein structures in the PDB and identify sites having chemistry similar to that of known methyl-lysine binding domains that recognize chromatin methylation marks. The selected genes include known readers of the histone code as well as novel binding pockets that may be involved in epigenetic signaling. Putative allosteric sites were identified on the structures of TP53BP1, L3MBTL3, CHEK1, KDM4A, and CREBBP.	binding sites;chek1 gene;chemical library;chemistry techniques, analytical;dental caries;digital library;histones;kdm4a gene;lysine;matching;pharmacophore;protein data bank;small molecule libraries;tp53bp1 gene;algorithm;study of epigenetics	Valérie Campagna-Slater;Andrew G. Arrowsmith;Yong Zhao;Matthieu Schapira	2010	Journal of chemical information and modeling	10.1021/ci900427b	protein structure;chemistry;pharmacophore;protein data bank;bioinformatics;binding site;epigenetics;combinatorial chemistry;residue;genetics	Comp.	-4.091817779414497	-56.720601535114	61695
628a7d0f8cbd5334df79d687a8a590b3c7c4b41f	oden: a program package for molecular evolutionary analysis and database search of dna and amino acid sequences	dna;evolution moleculaire;computadora;software;computer program;secuencia aminoacido;base donnee;sequence aminoacide;langage c;aminoacid sequence;logiciel;computerized processing;tratamiento informatico;ordinateur;information retrieval;amino acid sequence;database;base dato;secuencia nucleotido;computer;nucleotide sequence;sequence nucleotide;evolucion molecular;c language;molecular evolution;recherche information;logicial;recuperacion informacion;database search;programa computador;traitement informatique;programme ordinateur;lenguaje c		amino acid sequence;amino acids;computer program package	Y. Ina	1994	Computer applications in the biosciences : CABIOS	10.1093/bioinformatics/10.1.11	biology;database search engine;molecular evolution;nucleic acid sequence;bioinformatics;peptide sequence;genetics;dna;algorithm	Theory	-4.361867861800055	-56.18120466205892	61713
1683ab719861fc6f1604b7141b2d34cef3bd5100	rna polymerase activity and template activity of chromatin after butyrate induced hyperacetylation of histones in physarum	transcription genetic;butyric acid;dna directed rna polymerases;physarum;butyric acids;templates genetic;histones;amanitins;chromatin;rna polymerase;butyrates;kinetics;acetylation	We have studied the effect of sodium-n-butyrate on endogenous RNA polymerase in Physarum polycephalum. 1 mM butyrate strongly reduces RNA polymerase activity measured in isolated nuclei or chromatin; both RNA polymerase A as well as the alpha-amanitin sensitive RNA polymerase B are equally affected. Despite a concomitant hyperacetylation of histone H4 the template activity of chromatin, as analyzed by in vitro transcription of the chromatin with exogenous RNA polymerase from E. coli or RNA polymerase II from wheat germ, remains unaltered as compared to untreated control chromatin, indicating that there is no positive correlation between histone acetylation and template activity of chromatin for transcription in this organism. The results further indicate, that butyrate acts primarily as a quick but reversible inhibitor of protein synthesis in Physarum; the fast decrease of endogenous RNA polymerase activity after butyrate treatment is due to inhibition of enzyme synthesis rather than inactivation of other factors necessary for transcription.	alpha-amanitin;amanitins;butyrates;clinical use template;dna-directed rna polymerase;histone acetylation;histones;medical transcription;rna polymerase i;rna polymerase ii;sodium;transcription (software);negative regulation of rna-directed rna polymerase activity	P. Loidl;Alois Loidl;B. Puschendorf;P. Grobner	1984	Nucleic acids research	10.1093/nar/12.13.5405	transcription factor ii d;rna-induced transcriptional silencing;sigma factor;biology;biochemistry;termination factor;molecular biology;gene expression;chromatin;acetylation;rna polymerase ii;rna polymerase i;histone-modifying enzymes;rna-dependent rna polymerase;histone;small nuclear rna;non-coding rna;transcription;genetics;transcription bubble;general transcription factor;transcription factories;transcriptional regulation;kinetics;rna polymerase ii holoenzyme;polymerase	Comp.	5.66427253676954	-63.2434994301378	61755
7bf4145035c12c92490c33c2ef92f37bb03b8262	complementary gene signature integration in multiplatform microarray experiments	gene signature overlap breast cancer gene signature evaluation gene signature integration;multiplatform microarray experiments;cancer;training;statistical significance;gene signature evaluation;data distribution;ontologies artificial intelligence;genetics;sensitivity;gene signature overlap;research paper;statistical analysis;statistical analysis bioinformatics biological techniques cancer data handling genetics knowledge engineering ontologies artificial intelligence;complementary gene signature integration;biological processes training breast cancer diseases sensitivity;diseases;data handling;biological techniques;data distributions;algorithms area under curve breast neoplasms cluster analysis computational biology databases nucleic acid female gene expression profiling humans kaplan meier estimate oligonucleotide array sequence analysis roc curve tumor markers biological;data distributions complementary gene signature integration multiplatform microarray experiments gene signature overlap statistical significance biological knowledge;breast cancer;biological processes;gene signature integration;biological knowledge;biological process;bioinformatics;knowledge engineering	The concept of gene signature overlap has been addressed previously in a number of research papers. A common conclusion is the absence of significant overlap. In this paper, we verify the aforementioned fact, but we also assess the issue of similarities not on the gene level, but on the biology level hidden underneath a given signature. We proceed by taking into account the biological knowledge that exists among different signatures, and use it as a means of integrating them and refining their statistical significance on the datasets. In this form, by integrating biological knowledge with information stemming from data distributions, we derive a unified signature that is significantly improved over its predecessors in terms of performance and robustness. Our motive behind this approach is to assess the problem of evaluating different signatures not in a competitive but rather in a complementary manner, where one is treated as a pool of knowledge contributing to a global and unified solution.	antivirus software;biological processes;contribution;dna integration;design of experiments;digital signature;electronic signature;evolution strategy;greater than;knowledge-based systems;microarray;neuritis, autoimmune, experimental;p-value;paper;silo (dataset);stemming;type signature	Michalis E. Blazadonakis;Michalis E. Zervakis;Dimitris Kafetzopoulos	2011	IEEE Transactions on Information Technology in Biomedicine	10.1109/TITB.2010.2072964	medicine;computer science;bioinformatics;data science;knowledge engineering;data mining;biological process;statistics	Comp.	6.747132414543037	-54.40443523317147	61849
b3e2a3b6d362e0992a7baf986c06d22cbfc721d2	parameter estimation and inference for stochastic reaction-diffusion systems: application to morphogenesis in d. melanogaster	experimental design;animals;simulation and modeling;bayesian approach;stochastic method;systems biology;bayesian inference;physiological cellular and medical topics;models biological;reaction diffusion system;trans activators;credible interval;homeodomain proteins;models chemical;state estimation;scaling up;computational biology bioinformatics;expected value;posterior distribution;stochastic processes;drosophila melanogaster;system biology;algorithms;morphogenesis;parameter estimation;diffusion;computer simulation;bioinformatics	Reaction-diffusion systems are frequently used in systems biology to model developmental and signalling processes. In many applications, count numbers of the diffusing molecular species are very low, leading to the need to explicitly model the inherent variability using stochastic methods. Despite their importance and frequent use, parameter estimation for both deterministic and stochastic reaction-diffusion systems is still a challenging problem. We present a Bayesian inference approach to solve both the parameter and state estimation problem for stochastic reaction-diffusion systems. This allows a determination of the full posterior distribution of the parameters (expected values and uncertainty). We benchmark the method by illustrating it on a simple synthetic experiment. We then test the method on real data about the diffusion of the morphogen Bicoid in Drosophila melanogaster. The results show how the precision with which parameters can be inferred varies dramatically, indicating that the ability to infer full posterior distributions on the parameters can have important experimental design consequences. The results obtained demonstrate the feasibility and potential advantages of applying a Bayesian approach to parameter estimation in stochastic reaction-diffusion systems. In particular, the ability to estimate credibility intervals associated with parameter estimates can be precious for experimental design. Further work, however, will be needed to ensure the method can scale up to larger problems.	benchmark (computing);design of experiments;dhrystone;estimated;estimation theory;experiment;heart rate variability;inference;large;morphogenesis;neuritis, autoimmune, experimental;population parameter;systems biology	Michael Dewar;Visakan Kadirkamanathan;Manfred Opper;Guido Sanguinetti	2009		10.1186/1752-0509-4-21	biology;morphogenesis;bayesian probability;computer science;bioinformatics;machine learning;diffusion;posterior probability;estimation theory;design of experiments;bayesian inference;credible interval;systems biology;expected value	ML	7.708703655334357	-58.5882563836428	61944
4be3861bb0120c1a0dbc6836e191b6bd1c0cec02	structure of protein interaction networks and their implications on drug design	budding yeast;genomics;protein protein interaction network;drug delivery systems;drug targeting;yeasts;signal transduction;preferential attachment;essential gene;protein interaction domains and motifs;degree distribution;statistical properties;scale free;cluster analysis;proteins;drug design;side effect;biological systems;humans;highly optimized tolerance;protein interaction network;fungal proteins	Protein-protein interaction networks (PINs) are rich sources of information that enable the network properties of biological systems to be understood. A study of the topological and statistical properties of budding yeast and human PINs revealed that they are scale-rich and configured as highly optimized tolerance (HOT) networks that are similar to the router-level topology of the Internet. This is different from claims that such networks are scale-free and configured through simple preferential-attachment processes. Further analysis revealed that there are extensive interconnections among middle-degree nodes that form the backbone of the networks. Degree distributions of essential genes, synthetic lethal genes, synthetic sick genes, and human drug-target genes indicate that there are advantageous drug targets among nodes with middle- to low-degree nodes. Such network properties provide the rationale for combinatorial drugs that target less prominent nodes to increase synergetic efficacy and create fewer side effects.	anatomy, regional;attachments;biological system;design rationale;drug delivery systems;genes, essential;genes, lethal;highly optimized tolerance;internet backbone;router (computing);synergetics (fuller);synthetic genes;synthetic intelligence;vertebral column	Takeshi Hase;Hiroshi Tanaka;Yasuhiro Suzuki;So Nakagawa;Hiroaki Kitano	2009		10.1371/journal.pcbi.1000550	biology;genomics;targeted drug delivery;degree distribution;biotechnology;bioinformatics;scale-free network;cluster analysis;genetics;side effect;signal transduction;drug design	Metrics	5.186417913742135	-56.80513744180281	61965
cc4628861d3c52d6018928cf6bce5d237a2282d5	a sensitive sequence comparison method.	sequence comparison;homology search;sequence alignment;database search	Biologists highly rely on good algorithms to find the homologous regions in bimolecular sequences. One advanced homology search program, PatternHunter, has been developed in 2002. Unlike the well-known program Blast using a consecutive model, it benefited from gapped (nonconsecutive) model to work better. By observing and analyzing some significant properties of gapped-models, we propose a new program, which extends from using single gapped-model to multiple gapped models.	algorithm;blast;homology (biology);patternhunter;whole earth 'lectronic link	Xiaoqiu Huang;Liang Ye;I-Hsuan Yang;Kun-Mao Chao	2004			database search engine;multiple sequence alignment;computer science;sequence alignment;conserved domain database;sequence logo;alignment-free sequence analysis	ML	-1.2011656034075036	-52.94019083444148	61993
27b6b3afbaa324992be0d53075e6f8033f7a6371	statistical issues in the analysis of dna copy number variations	dna;animals;calling algorithm;genotype;array cgh;normalisation;hidden markov model;cnv genotyping;reference values;genome wide association study;biostatistics;comparative genomic hybridization;vertebrates;whole genome amplification;genetic variation;models genetic;circular binary segmentation;statistical analysis;gwas;human genome project;cbs;algorithms;humans;complex disorders;association analysis;dna copy number;copy number variations;oligonucleotide array sequence analysis;microarrays	Approaches to assess copy number variation have advanced rapidly and are being incorporated into genetic studies. While the technology exists for CNV genotyping, a further understanding and discussion of how to use the CNV data for association analyses is warranted. We present the options available for processing and analysing CNV data. We break these steps down into choice of genotyping platform, normalisation of the array data, calling algorithm, and statistical analysis.	copy number polymorphism;dna copy number variations;genotype determination;algorithm	Nathan E. Wineinger;Richard E. Kennedy;Stephen W. Erickson;Mary K. Wojczynski;Carl E. Bruder;Hemant K. Tiwari	2008	International journal of computational biology and drug design	10.1504/IJCBDD.2008.022208	genome-wide association study;biology;molecular biology;bioinformatics;biostatistics;genetics;hidden markov model	Comp.	3.243546727178892	-53.524312797066756	62047
8dc14a193069d904233fc4eb47c644f129f2367d	reverse engineering of biological signaling networks via integration of data and knowledge using probabilistic graphical models			graphical model;reverse engineering	Paurush Praveen	2014			data mining;biological signaling;reverse engineering;computer science;graphical model	ML	0.492263505592888	-65.7251341927396	62116
fa811320ccb570c86a08bd4a17b4ffe5beb032f7	phenofam-gene set enrichment analysis through protein structural information	gene expression profile;software;rna interference;genomics;functional annotation;web based applications;protein domains;web interface;databases genetic;power method;structure function;breast carcinoma;computational biology bioinformatics;gene expression;development tool;protein structure;data analysis;large scale;proteins;protein conformation;structure and function;algorithms;gene set enrichment analysis;user computer interface;combinatorial libraries;high throughput;computer appl in life sciences;breast cancer;gene expression profiling;oligonucleotide array sequence analysis;microarrays;bioinformatics	With the current technological advances in high-throughput biology, the necessity to develop tools that help to analyse the massive amount of data being generated is evident. A powerful method of inspecting large-scale data sets is gene set enrichment analysis (GSEA) and investigation of protein structural features can guide determining the function of individual genes. However, a convenient tool that combines these two features to aid in high-throughput data analysis has not been developed yet. In order to fill this niche, we developed the user-friendly, web-based application, PhenoFam. PhenoFam performs gene set enrichment analysis by employing structural and functional information on families of protein domains as annotation terms. Our tool is designed to analyse complete sets of results from quantitative high-throughput studies (gene expression microarrays, functional RNAi screens, etc.) without prior pre-filtering or hits-selection steps. PhenoFam utilizes Ensembl databases to link a list of user-provided identifiers with protein features from the InterPro database, and assesses whether results associated with individual domains differ significantly from the overall population. To demonstrate the utility of PhenoFam we analysed a genome-wide RNA interference screen and discovered a novel function of plexins containing the cytoplasmic RasGAP domain. Furthermore, a PhenoFam analysis of breast cancer gene expression profiles revealed a link between breast carcinoma and altered expression of PX domain containing proteins. PhenoFam provides a user-friendly, easily accessible web interface to perform GSEA based on high-throughput data sets and structural-functional protein information, and therefore aids in functional annotation of genes.	acquired immunodeficiency syndrome;annotation;ensembl;gene expression;gene ontology term enrichment;high-throughput computing;identifier;interpro;interface device component;interference (communication);mammary neoplasms;microarray;niche blogging;pixel;protein domain;published database;rna interference;throughput;usability;user interface;web application	Maciej Paszkowski-Rogacz;Mikolaj Slabicki;M. Teresa Pisabarro;Frank Buchholz	2010		10.1186/1471-2105-11-254	biology;protein structure;genomics;molecular biology;bioinformatics;genetics	Comp.	-0.9174477314259851	-58.57039048078006	62197
2607e48346d4c9dcbe65a0e7b99af0a106ac3efb	advanced significance analysis of microarray data based on weighted resampling: a comparative study and application to gene deletions in mycobacterium bovis	microarray data;delecion;sensitivity and specificity;gene deletion;sample size;data interpretation statistical;mycobacteriaceae;mycobacteriales;web pages;canal ionique;programming language;analisis datos;bacterie;significance analysis of microarray;estudio comparativo;gen;ionic channel;mycobacterium bovis;genetic variation;mutacion;gene expression;etude comparative;variations;expression genique;data analysis;models genetic;actinomycetes;mixture model;genome bacterial;comparative study;reproducibility of results;gene;models statistical;algorithms;analyse donnee;canal ionico;bacteria;variacion;variation;expresion genetica;mutation;gene expression profiling;oligonucleotide array sequence analysis;deletion	MOTIVATION When analyzing microarray data, non-biological variation introduces uncertainty in the analysis and interpretation. In this paper we focus on the validation of significant differences in gene expression levels, or normalized channel intensity levels with respect to different experimental conditions and with replicated measurements. A myriad of methods have been proposed to study differences in gene expression levels and to assign significance values as a measure of confidence. In this paper we compare several methods, including SAM, regularized t-test, mixture modeling, Wilk's lambda score and variance stabilization. From this comparison we developed a weighted resampling approach and applied it to gene deletions in Mycobacterium bovis.   RESULTS We discuss the assumptions, model structure, computational complexity and applicability to microarray data. The results of our study justified the theoretical basis of the weighted resampling approach, which clearly outperforms the others.	computational complexity theory;electrosurgical device;gene deletion;gene expression;microarray;mixture model;mycobacterium bovis ag:prthr:pt:bld:ord;resampling (statistics);sam;sample variance;t test	Zoltán Kutalik;Jacqueline Inwald;Steve V. Gordon;R. Glyn Hewinson;Philip D. Butcher;Jason Hinds;Kwang-Hyun Cho;Olaf Wolkenhauer	2004	Bioinformatics	10.1093/bioinformatics/btg417	mutation;sample size determination;biology;microarray analysis techniques;gene expression;bacteria;bioinformatics;comparative research;genetic variation;gene;web page;mixture model;gene expression profiling;data analysis;theme and variations;genetics;statistics	Comp.	4.672642535042074	-52.23372655307131	62249
8c3be5a7e98c70917d6c63c0bb75d98f720ee11f	bistable forespore engulfment in bacillus subtilis by a zipper mechanism in absence of the cell wall	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;uk phd theses thesis;life sciences;uk research reports;medical journals;europe pmc;biomedical research;bioinformatics	To survive starvation, the bacterium Bacillus subtilis forms durable spores. The initial step of sporulation is asymmetric cell division, leading to a large mother-cell and a small forespore compartment. After division is completed and the dividing septum is thinned, the mother cell engulfs the forespore in a slow process based on cell-wall degradation and synthesis. However, recently a new cell-wall independent mechanism was shown to significantly contribute, which can even lead to fast engulfment in [Formula: see text] 60 [Formula: see text] of the cases when the cell wall is completely removed. In this backup mechanism, strong ligand-receptor binding between mother-cell protein SpoIIIAH and forespore-protein SpoIIQ leads to zipper-like engulfment, but quantitative understanding is missing. In our work, we combined fluorescence image analysis and stochastic Langevin simulations of the fluctuating membrane to investigate the origin of fast bistable engulfment in absence of the cell wall. Our cell morphologies compare favorably with experimental time-lapse microscopy, with engulfment sensitive to the number of SpoIIQ-SpoIIIAH bonds in a threshold-like manner. By systematic exploration of model parameters, we predict regions of osmotic pressure and membrane-surface tension that produce successful engulfment. Indeed, decreasing the medium osmolarity in experiments prevents engulfment in line with our predictions. Forespore engulfment may thus not only be an ideal model system to study decision-making in single cells, but its biophysical principles are likely applicable to engulfment in other cell types, e.g. during phagocytosis in eukaryotes.	anatomical compartments;asymmetric cell division;bacillus subtilis;backup;cell wall;decision making;elegant degradation;experiment;fluorescence;image analysis;ligands;multi-compartment model;osmolarity;osmotic pressure;phagocytosis;septum - general anatomical term;simulation;spore;stem cells;surface tension;tissue membrane;forespore	Nikola Ojkic;Javier López-Garrido;Kit Pogliano;Robert G. Endres	2014		10.1371/journal.pcbi.1003912	biology;medical research;bioinformatics	ML	6.497598581764626	-63.97279647036476	62265
db07e708c44513ed9d6b44e094aa58020a67d72e	structure prediction of rna loops with a probabilistic approach	rna structure prediction;rna folding;rna structure;rna annealing;atoms;protein structure prediction;monte carlo method;ribosomal rna	The knowledge of the tertiary structure of RNA loops is important for understanding their functions. In this work we develop an efficient approach named RNApps, specifically designed for predicting the tertiary structure of RNA loops, including hairpin loops, internal loops, and multi-way junction loops. It includes a probabilistic coarse-grained RNA model, an all-atom statistical energy function, a sequential Monte Carlo growth algorithm, and a simulated annealing procedure. The approach is tested with a dataset including nine RNA loops, a 23S ribosomal RNA, and a large dataset containing 876 RNAs. The performance is evaluated and compared with a homology modeling based predictor and an ab initio predictor. It is found that RNApps has comparable performance with the former one and outdoes the latter in terms of structure predictions. The approach holds great promise for accurate and efficient RNA tertiary structure prediction.	ab initio quantum chemistry methods;algorithm;branch predictor;homology (biology);homology modeling;kerrison predictor;mathematical optimization;monte carlo method;name;numerous;ribosomal rna;silo (dataset);simulated annealing;statistical potential;tertiary	Jun Li;Jian Zhang;Jun Wang;Wenfei Li;Wei Wang	2016		10.1371/journal.pcbi.1005032	biology;nucleic acid structure;ribosomal rna;atom;bioinformatics;protein structure prediction;statistics;monte carlo method	Comp.	9.452696609518943	-57.873331775298894	62278
d365f3b7f79b840952339fe7e243c49cc1a42aaf	diark – the database for eukaryotic genome and transcriptome assemblies in 2014	genomics;databases genetic;internet;eukaryota;sequence analysis rna;gene expression profiling	Eukaryotic genomes are the basis for understanding the complexity of life from populations to the molecular level. Recent technological innovations have revolutionized the speed of data generation enabling the sequencing of eukaryotic genomes and transcriptomes within days. The database diArk (http://www.diark.org) has been developed with the aim to provide access to all available assembled genomes and transcriptomes. In September 2014, diArk contains about 2600 eukaryotes with 6000 genome and transcriptome assemblies, of which 22% are not available via NCBI/ENA/DDBJ. Several indicators for the quality of the assemblies are provided to facilitate their comparison for selecting the most appropriate dataset for further studies. diArk has a user-friendly web interface with extensive options for filtering and browsing the sequenced eukaryotes. In this new version of the database we have also integrated species, for which transcriptome assemblies are available, and we provide more analyses of assemblies.	access network;biopolymer sequencing;dna data bank ofjapan;diffusion of innovation;genome;interface device component;national center for biotechnology information;organic chemistry phenomena;population;random access;silo (dataset);transcriptome;usb hub;usability;user interface;wdfy2 wt allele	Martin Kollmar;Lotte Kollmar;Björn Hammesfahr;Dominic Simm	2015		10.1093/nar/gku990	biology;genomics;the internet;bioinformatics;gene expression profiling;genetics	Comp.	-1.3215039398209654	-59.73425688080826	62331
beb6824f1f6a18ae6ecf62d60e58c87e0f0ac970	compilation of trna sequences	purines;mutation;escherichia coli	As a supplement to the compilation of tRNA sequences, this section presents the nucleotide sequence of published mutant tRNAs together with a brief description of some interesting properties of these mutants. Mutant tRNAs have been derived by mutation of suppressor tRNAs genes present in E. coli, 80 and bacteriophage T4. In all cases mutants having different levels of suppressor activity have been isolated. These mutants present single base substitutions and in many cases (those mutants having no suppressor activity) it has been possible to isolate double mutants among the revertants that have recovered suppressor activity. Double mutants have also been constructed by genetic recombination. To designate a particular nucleotide substitution one refers to the identity of the new nucleotide followed by a number indicating its position in the tRNA sequence starting from the 5 end. For example, the mutant A31 in tyrosine suppressor tRNA refers to a tRNA that contains an A at position 31 instead of the usual base (G). To conform with the rules for numbering tRNAs used by Sprinzl, Grliter and Gauss, I have added the new numbering system for these mutants. Thus mutant A31 will correspond to A30 according to the new numbering system. In the case of mutant T4 tRNAs, many of these tRNAs have been sequenced in the precursor as these mutants do not produce any detectable amount of mature tRNA. In this case I have listed these mutants in a separate table and have indicated which part of the tRNA precursor is the one carrying the mutation. The position of the nucleotide substitution in this case has been numbered from the 5 terminus of the altered tRNA in the precursor sequence.	bacteriophages;base sequence;cd4 positive t lymphocytes;compiler;eighty;gauss;mandibular right second molar tooth;mutation;nucleotides;recombination, genetic;rule (guideline);scientific publication;tyrosine;mutant	Mathias Sprinzl;F. Grueter;A. Spelzhaus;D. H. Gauss	1980	Nucleic acids research	10.1093/nar/8.1.197-a	transfer rna;genetics;genetic code;numbering;prefix;biology	Comp.	3.8944800523409375	-63.29516572241361	62386
6a04da6a05a3832915b076005a67e0a59536ee3f	bbcontacts: prediction of β-strand pairing from direct coupling patterns		MOTIVATION It has recently become possible to build reliable de novo models of proteins if a multiple sequence alignment (MSA) of at least 1000 homologous sequences can be built. Methods of global statistical network analysis can explain the observed correlations between columns in the MSA by a small set of directly coupled pairs of columns. Strong couplings are indicative of residue-residue contacts, and from the predicted contacts a structure can be computed. Here, we exploit the structural regularity of paired β-strands that leads to characteristic patterns in the noisy matrices of couplings. The β-β contacts should be detected more reliably than single contacts, reducing the required number of sequences in the MSAs.   RESULTS bbcontacts predicts β-β contacts by detecting these characteristic patterns in the 2D map of coupling scores using two hidden Markov models (HMMs), one for parallel and one for antiparallel contacts. β-bulges are modelled as indel states. In contrast to existing methods, bbcontacts uses predicted instead of true secondary structure. On a standard set of 916 test proteins, 34% of which have MSAs with < 1000 sequences, bbcontacts achieves 50% precision for contacting β-β residue pairs at 50% recall using predicted secondary structure and 64% precision at 64% recall using true secondary structure, while existing tools achieve around 45% precision at 45% recall using true secondary structure.   AVAILABILITY AND IMPLEMENTATION bbcontacts is open source software (GNU Affero GPL v3) available at https://bitbucket.org/soedinglab/bbcontacts .	accessibility;amino acids;antiparallel (electronics);arbitrary unit of igg isotype for phospholipid antigen;bitbucket;column (database);de novo transcriptome assembly;direct coupling;direct coupling analysis;emission - male genitalia finding;gnu;graphics processing unit;hidden markov model;homology (biology);indel mutation;interaction;jart armin;jones calculus;kerrison predictor;lenna;markov chain;multiple sequence alignment;one thousand;open-source software;psipred;ploidies;probability;sensor;setun;statistical model;stimulation (motivation);strand (programming language);tpo wt allele;tesla - unit;viterbi algorithm;xeon phi	Jessica Andreani;Johannes Söding	2015	Bioinformatics	10.1093/bioinformatics/btv041	bioinformatics;machine learning;mathematics	Comp.	3.1680301736375513	-59.96264918580734	62643
1d564917113388925d84c07014ecc107fc85e0fe	representing and decomposing genomic structural variants as balanced integer flows on sequence graphs	computational biology bioinformatics;algorithms;computer appl in life sciences;microarrays;bioinformatics	The study of genomic variation has provided key insights into the functional role of mutations. Predominantly, studies have focused on single nucleotide variants (SNV), which are relatively easy to detect and can be described with rich mathematical models. However, it has been observed that genomes are highly plastic, and that whole regions can be moved, removed or duplicated in bulk. These structural variants (SV) have been shown to have significant impact on phenotype, but their study has been held back by the combinatorial complexity of the underlying models. We describe here a general model of structural variation that encompasses both balanced rearrangements and arbitrary copy-number variants (CNV). In this model, we show that the space of possible evolutionary histories that explain the structural differences between any two genomes can be sampled ergodically.	copy number polymorphism;dna sequence rearrangement;flow;genome;graph - visual representation;integer (number);mathematical model;mathematics;mutation;nucleotides;sampling (signal processing);sampling - surgical action;sequence alignment;single-chain antibodies;systemverilog	Daniel R. Zerbino;Tracy Ballinger;Benedict Paten;Glenn Hickey;David Haussler	2016		10.1186/s12859-016-1258-4	biology;dna microarray;computer science;bioinformatics;genetics	Comp.	3.9404967418358696	-61.112698118335906	62787
1cbaaa44ec990bb89be78b669666ef49859b67fd	predicting mhc-ii binding affinity using multiple instance regression	prediction method;amino acid mhc ii binding affinity multiple instance regression antigen peptide major histocompatibility complex class ii vaccine pathogenesis immune response;peptides;major histocompatibility complex class ii;multiple instance;organic compounds;antigen peptide;multiple instance regression;multiple instance learning;amino acid;training;amino acid sequence;prediction algorithms;peptides training prediction methods amino acids shape proteins prediction algorithms;computational method;indexing terms;regression analysis bioinformatics molecular biophysics organic compounds;prediction methods;proteins;shape;major histocompatibility complex;pathogenesis;molecular biophysics;amino acids;regression analysis;binding affinity;amino acid sequence animals area under curve computational biology dna binding proteins genes mhc class ii humans mice models statistical molecular sequence data peptides protein binding regression analysis reproducibility of results transcription factors;mhc ii binding affinity;immune response;mhc ii peptide prediction;multiple instance regression mhc ii peptide prediction multiple instance learning;bioinformatics;vaccine	Reliably predicting the ability of antigen peptides to bind to major histocompatibility complex class II (MHC-II) molecules is an essential step in developing new vaccines. Uncovering the amino acid sequence correlates of the binding affinity of MHC-II binding peptides is important for understanding pathogenesis and immune response. The task of predicting MHC-II binding peptides is complicated by the significant variability in their length. Most existing computational methods for predicting MHC-II binding peptides focus on identifying a nine amino acids core region in each binding peptide. We formulate the problems of qualitatively and quantitatively predicting flexible length MHC-II peptides as multiple instance learning and multiple instance regression problems, respectively. Based on this formulation, we introduce MHCMIR, a novel method for predicting MHC-II binding affinity using multiple instance regression. We present results of experiments using several benchmark data sets that show that MHCMIR is competitive with the state-of-the-art methods for predicting MHC-II binding peptides. An online web server that implements the MHCMIR method for MHC-II binding affinity prediction is freely accessible at http://ailab.cs.iastate.edu/mhcmir.	marijuana abuse;model of hierarchical complexity;processor affinity	Yasser El-Manzalawy;Drena Dobbs;Vasant Honavar	2011	IEEE/ACM Transactions on Computational Biology and Bioinformatics	10.1109/TCBB.2010.94	biology;biochemistry;amino acid;computer science;bioinformatics;machine learning;mathematics;immunology;molecular biophysics	Comp.	9.774527868039868	-57.00040093670818	63034
8905b8b9daade9a52ad27d6b76f5e31e90faf6e5	inferring stabilizing mutations from protein phylogenies: application                     to influenza hemagglutinin	evolution molecular;sequence evolution;hemagglutinin glycoproteins influenza virus;influenza virus;phylogeny;bayesian approach;amino acid;protein sequence;amino acid sequence;protein stability;conceptual framework;dna mutational analysis;biological evolution;molecular evolution;temperature sensitive;genomic instability;protein folding;molecular sequence data;base sequence;experimental measurement;mutation;phylogenetic inference;sequence analysis protein	One selection pressure shaping sequence evolution is the requirement that a protein fold with sufficient stability to perform its biological functions. We present a conceptual framework that explains how this requirement causes the probability that a particular amino acid mutation is fixed during evolution to depend on its effect on protein stability. We mathematically formalize this framework to develop a Bayesian approach for inferring the stability effects of individual mutations from homologous protein sequences of known phylogeny. This approach is able to predict published experimentally measured mutational stability effects (DeltaDeltaG values) with an accuracy that exceeds both a state-of-the-art physicochemical modeling program and the sequence-based consensus approach. As a further test, we use our phylogenetic inference approach to predict stabilizing mutations to influenza hemagglutinin. We introduce these mutations into a temperature-sensitive influenza virus with a defect in its hemagglutinin gene and experimentally demonstrate that some of the mutations allow the virus to grow at higher temperatures. Our work therefore describes a powerful new approach for predicting stabilizing mutations that can be successfully applied even to large, complex proteins such as hemagglutinin. This approach also makes a mathematical link between phylogenetics and experimentally measurable protein properties, potentially paving the way for more accurate analyses of molecular evolution.	3d computer graphics;amino acid sequence;amino acids;computational phylogenetics;evolution, molecular;experiment;homologous protein;inference;mathematics;noise shaping;orthomyxoviridae;peptide sequence;point accepted mutation;scientific publication;software bug;staphylococcal protein a	Jesse D. Bloom;Matthew J. Glassman	2009	PLoS Computational Biology	10.1371/journal.pcbi.1000349	mutation;protein folding;biology;biochemistry;amino acid;genome instability;molecular evolution;bayesian probability;bioinformatics;virology;protein sequencing;conceptual framework;peptide sequence;genetics;phylogenetics	Comp.	7.254008590757537	-59.38591365990497	63059
dbc5530693f6e58b8d1d1c8dd79d6ba4cb3e6fe4	comparative modeling of dna and rna polymerases from moniliophthora perniciosa mitochondrial plasmid	catalytic domain;statistics for life sciences medicine health sciences;mitochondria;protein structure secondary;dna directed rna polymerases;systems biology;physiological cellular and medical topics;generation time;templates genetic;plasmids;thermodynamic stability;models molecular;comparative modeling;protein structure tertiary;mitochondrial genome;force field;agaricales;reproducibility of results;molecular dynamic;algorithms;rna polymerase;theobroma cacao l;molecular mechanics;dna directed dna polymerase;md simulation;biomedicine general	The filamentous fungus Moniliophthora perniciosa (Stahel) Aime & Phillips-Mora is a hemibiotrophic Basidiomycota that causes witches' broom disease of cocoa (Theobroma cacao L.). This disease has resulted in a severe decrease in Brazilian cocoa production, which changed the position of Brazil in the market from the second largest cocoa exporter to a cocoa importer. Fungal mitochondrial plasmids are usually invertrons encoding DNA and RNA polymerases. Plasmid insertions into host mitochondrial genomes are probably associated with modifications in host generation time, which can be involved in fungal aging. This association suggests activity of polymerases, and these can be used as new targets for drugs against mitochondrial activity of fungi, more specifically against witches' broom disease. Sequencing and modeling: DNA and RNA polymerases of M. perniciosa mitochondrial plasmid were completely sequenced and their models were carried out by Comparative Homology approach. The sequences of DNA and RNA polymerase showed 25% of identity to 1XHX and 1ARO (pdb code) using BLASTp, which were used as templates. The models were constructed using Swiss PDB-Viewer and refined with a set of Molecular Mechanics (MM) and Molecular Dynamics (MD) in water carried out with AMBER 8.0, both working under the ff99 force fields, respectively. Ramachandran plots were generated by Procheck 3.0 and exhibited models with 97% and 98% for DNA and RNA polymerases, respectively. MD simulations in water showed models with thermodynamic stability after 2000 ps and 300 K of simulation. This work contributes to the development of new alternatives for controlling the fungal agent of witches' broom disease.	assisted model building with energy refinement (amber);blast;basidiomycota;cocoa (digital humanities);cacao plant;clinical use template;clinical act of insertion;cocoa extract;cytisus;dna-directed rna polymerase;filamentous fungus;fungi;genome;genome, mitochondrial;homology modeling;largest;mitochondrial inheritance;molecular dynamics;molecular mechanics;mycoses;plasmids;protein data bank;ps (unix);simulation;switzerland;thermodynamics	Bruno S. Andrade;Alex Gutterres Taranto;Shaila C. S. Roessle;Aristóteles Góes-Neto;Mitchell A. Avery	2008	Theoretical Biology & Medical Modelling	10.1186/1742-4682-6-22	biology;homology modeling;mitochondrial dna;mitochondrion;molecular mechanics;bioinformatics;chemical stability;force field;generation time;plasmid;genetics;systems biology	Comp.	3.751193645979981	-63.21238100494311	63190
0e862a91d5de4e03c645caf0fa542ff3cc4c668a	detecting disease-associated genotype patterns	genotype;disease susceptibility;gene environment interaction;journal;genetic marker;computational biology bioinformatics;genetic predisposition to disease;algorithms;humans;parkinson disease;combinatorial libraries;interaction effect;computer appl in life sciences;computer simulation;logistic regression model;genetic markers;polymorphism single nucleotide;single nucleotide polymorphism;microarrays;bioinformatics	In addition to single-locus (main) effects of disease variants, there is a growing consensus that gene-gene and gene-environment interactions may play important roles in disease etiology. However, for the very large numbers of genetic markers currently in use, it has proven difficult to develop suitable and efficient approaches for detecting effects other than main effects due to single variants. We developed a method for jointly detecting disease-causing single-locus effects and gene-gene interactions. Our method is based on finding differences of genotype pattern frequencies between case and control individuals. Those single-nucleotide polymorphism markers with largest single-locus association test statistics are included in a pattern. For a logistic regression model comprising three disease variants exerting main and epistatic interaction effects, we demonstrate that our method is vastly superior to the traditional approach of looking for single-locus effects. In addition, our method is suitable for estimating the number of disease variants in a dataset. We successfully apply our approach to data on Parkinson Disease and heroin addiction. Our approach is suitable and powerful for detecting disease susceptibility variants with potentially small main effects and strong interaction effects. It can be applied to large numbers of genetic markers.	addictive behavior;disease susceptibility;estimated;genetic markers;heroin dependence;interaction;locus;largest;logistic regression;parkinson disease;parkinsonian disorders;sensor;silo (dataset)	Quan Long;Qingrun Zhang;Jürg Ott	2009	BMC Bioinformatics	10.1186/1471-2105-10-S1-S75	computer simulation;biology;biotechnology;bioinformatics;genetic marker;genetics	Comp.	6.1082954450676885	-53.75740685979865	63293
2cd5f5973c10b09350c37e6d15ceea19d5b977f2	image phylogeny for simulating multiple print-scan		Image phylogeny tackles images by using approaches in bioinformatics like the minimum spanning tree. As a bioinformatics-inspired approach, it rarely appears in digital image processing. In this paper, we will probe image phylogeny by using phylogenetic trees in bioinformatics. These trees are generated by using multiple aligned DNA sequences of an original image and its degraded ones from multiple print-scan (MPS). Our contributions are (a) image encoding as a DNA sequence, (b) multiple sequence alignment (MSA) for the encoded images and (c) generating a phylogenetic tree to group degraded images from MPS. Experimental results have revealed the novelty of our proposed approach for effectively grouping original and degraded images from MPS. The proposed method upgrades our knowledge of image grouping and contributes to classifying the degraded images. To the best of our knowledge, this is the first time that image phylogeny has been employed for image grouping.	algorithm;bioinformatics;categorization;digital image processing;emoticon;file spanning;minimum spanning tree;multiple sequence alignment;phylogenetic tree;simulation;watermark (data file);xslt/muenchian grouping	Abhimanyu Singh Garhwal;Wei Qi Yan;Ajit Narayanan	2017	2017 International Conference on Image and Vision Computing New Zealand (IVCNZ)	10.1109/IVCNZ.2017.8402504	novelty;minimum spanning tree;computer science;artificial intelligence;multiple sequence alignment;digital image processing;pattern recognition;phylogenetics;phylogenetic tree;dna sequencing	Vision	0.2453408584949766	-53.39392728736043	63328
76ae25d34f372227bb11802414607d39704b5054	evidence of a cancer type-specific distribution for consecutive somatic mutation distances	kataegis;cancer;mutation distribution;power law	Specific molecular mechanisms may affect the pattern of mutation in particular regions, and therefore leaving a footprint or signature in the DNA of their activity. The common approach to identify these signatures is studying the frequency of substitutions. However, such an analysis ignores the important spatial information, which is important with regards to the mutation occurrence statistics. In this work, we propose that the study of the distribution of distances between consecutive mutations along the DNA molecule can provide information about the types of somatic mutational processes. In particular, we have found that specific cancer types show a power-law in interoccurrence distances, instead of the expected exponential distribution dictated with the Poisson assumption commonly made in the literature. Cancer genomes exhibiting power-law interoccurrence distances were enriched in cancer types where the main mutational process is described to be the activity of the APOBEC protein family, which produces a particular pattern of mutations called Kataegis. Therefore, the observation of a power-law in interoccurence distances could be used to identify cancer genomes with Kataegis.	antivirus software;departure - action;digital signature;diploid cell;distance;exhibits as topic;genome;geographic information system;mutation (genetic algorithm);protein family;somatic mutation;time complexity;apolipoprotein b mrna editing enzyme complex	Jose M. Muiño;Ercan Engin Kuruoglu;Peter F. Arndt	2014	Computational biology and chemistry	10.1016/j.compbiolchem.2014.08.012	biology;power law;bioinformatics;mathematics;genetics;statistics;cancer	Comp.	3.7481790102210852	-61.39271650426002	63445
9a791d1749445eb92d7eabbb8b29b016f9ba686c	odds ratio based multifactor-dimensionality reduction method for detecting gene-gene interactions	genetic association;multifactor dimensionality reduction;odd ratio;false positive;low risk;environmental factor;high risk	MOTIVATION The identification and characterization of genes that increase the susceptibility to common complex multifactorial diseases is a challenging task in genetic association studies. The multifactor dimensionality reduction (MDR) method has been proposed and implemented by Ritchie et al. (2001) to identify the combinations of multilocus genotypes and discrete environmental factors that are associated with a particular disease. However, the original MDR method classifies the combination of multilocus genotypes into high-risk and low-risk groups in an ad hoc manner based on a simple comparison of the ratios of the number of cases and controls. Hence, the MDR approach is prone to false positive and negative errors when the ratio of the number of cases and controls in a combination of genotypes is similar to that in the entire data, or when both the number of cases and controls is small. Hence, we propose the odds ratio based multifactor dimensionality reduction (OR MDR) method that uses the odds ratio as a new quantitative measure of disease risk.   RESULTS While the original MDR method provides a simple binary measure of risk, the OR MDR method provides not only the odds ratio as a quantitative measure of risk but also the ordering of the multilocus combinations from the highest risk to lowest risk groups. Furthermore, the OR MDR method provides a confidence interval for the odds ratio for each multilocus combination, which is extremely informative in judging its importance as a risk factor. The proposed OR MDR method is illustrated using the dataset obtained from the CDC Chronic Fatigue Syndrome Research Group.   AVAILABILITY The program written in R is available.	chronic fatigue syndrome;confidence intervals;genetic association studies;genotype;hoc (programming language);information;interaction;international normalized ratio;multifactor dimensionality reduction;odds ratio;r language;sensor;silo (dataset)	Yujin Chung;Seung Yeoun Lee;Robert C. Elston;Taesung Park	2007	Bioinformatics	10.1093/bioinformatics/btl557	biology;diagnostic odds ratio;econometrics;type i and type ii errors;multifactor dimensionality reduction;computer science;genetic association;data mining;mathematics;genetics;statistics;odds ratio	Comp.	6.193421773441807	-52.62743407130983	63460
debc16618bece4b0e842ba30ac0ede599c4deb48	an approach for dividing models of biological reaction networks into functional units	biology computing;equation differentielle;biological system;reseau reaction biologique;biological model;reaction biochimique;systems biology;differential equation;modelo biologico;ecuacion diferencial;functional units;systeme biologique;biologie systeme;cluster analysis;modele biologique;systems analysis;functional unit;biochemical reaction;biologie informatique;sistema biologico;electrical engineering electronics nuclear engineering;biochemical reaction networks;reaccion bioquimica	Biological reaction networks consist of many substances and reactions between them. Like many other biological systems, they have a modular structure. Therefore, a division of a biological reaction network into smaller units highly facilitates its investigation. The authors propose an algorithm to divide an ordinary differential equation (ODE) model of a biological reaction network hierarchically into functional units. For every compound, an activity function dependent on concentration or concentration change rate is defined. After performing suitable simulations, distances between the compounds are computed by comparing the activities along the trajectories of the simulation. The distance information is used to generate a dendrogram revealing the internal structure of the reaction network. The algorithm identifies functional units in two models of different networks: catabolite repression in Escherichia coli and epidermal growth factor (EGF) signal transduction in mammalian cells.	algorithm;biological system;dendrogram;semantic network;simulation;transduction (machine learning)	Michael Ederer;Thomas Sauter;Eric Bullinger;Ernst Dieter Gilles;Frank Allgöwer	2003	Simulation	10.1177/0037549703040940	systems analysis;computer science;artificial intelligence;calculus;cluster analysis;differential equation;systems biology	ML	4.186539896933738	-65.78748873787808	63731
cf741feea0b08b8571177b68f32e53081a602ecb	modeling the evolution of regulatory elements by simultaneous detection and alignment with phylogenetic pair hmms	evolution molecular;animals;generic model;phylogeny;hidden markov model;species conservation;gene regulation;regulatory element;sequence analysis dna;binding site;journal article;drosophila melanogaster;gene expression regulation;roc curve;regulatory elements transcriptional;molecular sequence data;sequence alignment;base sequence;computational biology;computer simulation;markov chains	The computational detection of regulatory elements in DNA is a difficult but important problem impacting our progress in understanding the complex nature of eukaryotic gene regulation. Attempts to utilize cross-species conservation for this task have been hampered both by evolutionary changes of functional sites and poor performance of general-purpose alignment programs when applied to non-coding sequence. We describe a new and flexible framework for modeling binding site evolution in multiple related genomes, based on phylogenetic pair hidden Markov models which explicitly model the gain and loss of binding sites along a phylogeny. We demonstrate the value of this framework for both the alignment of regulatory regions and the inference of precise binding-site locations within those regions. As the underlying formalism is a stochastic, generative model, it can also be used to simulate the evolution of regulatory elements. Our implementation is scalable in terms of numbers of species and sequence lengths and can produce alignments and binding-site predictions with accuracy rivaling or exceeding current systems that specialize in only alignment or only binding-site prediction. We demonstrate the validity and power of various model components on extensive simulations of realistic sequence data and apply a specific model to study Drosophila enhancers in as many as ten related genomes and in the presence of gain and loss of binding sites. Different models and modeling assumptions can be easily specified, thus providing an invaluable tool for the exploration of biological hypotheses that can drive improvements in our understanding of the mechanisms and evolution of gene regulation.	binding sites;biological evolution;gene expression regulation;general-purpose modeling;generative model;genome;hidden markov model;inference;markov chain;open reading frames;phylogenetics;protein structure prediction;regulatory sequences, nucleic acid;scalability;semantics (computer science);sequence alignment;simulation;stochastic process	William H. Majoros;Uwe Ohler	2010		10.1371/journal.pcbi.1001037	computer simulation;biology;regulation of gene expression;bioinformatics;genetics;hidden markov model;alignment-free sequence analysis	Comp.	4.169377898549769	-59.05533738328627	63742
8b399617db68b9de90927b474512475ca23e54e3	real-time gene newtorks control in microfluidics	eukaryote s cerevisiae real time gene network control microfluidics gene regulatory networks microfluidics based platform baker yeast;real time systems biocontrol microfluidics networked control systems;sugar integrated circuit modeling proteins control systems mathematical model biological system modeling real time systems	This tutorial paper presents two examples of invivo real-time control of gene regulatory networks in the eukaryote S. cerevisiae (baker's yeast). I discuss the theoretical and experimental challenges this problem poses and describe a microfluidics-based platform to address them. The results obtained using this setup demonstrate the proposed approach is both feasible and capable of achieving superior performances.	gene regulatory network;performance;real-time clock;real-time transcription	Filippo Menolascina	2014	2014 European Control Conference (ECC)	10.1109/ECC.2014.6862646	biology;molecular biology;biotechnology;bioinformatics	Robotics	7.384142661124507	-59.467738942079734	63848
15280fc9205fe04dac0687e62e60060a66517628	primer design for whole genome amplification using genetic algorithms	primer;amorce;conception;algoritmo genetico;whole genome amplification;gene amplification;genome;diseno;algorithme genetique;iniciador;amplificacion genica;design;genetic algorithm;genetic algorithms;genoma;amplification genique	Whole Genome Amplification (WGA) is an important process to increase limiting amounts of genomic DNA prior to genomic analyses. Current amplification methods based on primer extension or strand displacement principles employ primers of partially or totally random sequence. In this paper, we present a method using Genetic Algorithms to optimize a single primer design to be used in a primer extension reaction to achieve unbiased WGA. Computational simulation and prediction of a suitable primer proposed two candidates NYP6-1 (ATCTCA) and NYP6-2 (TGAGAT). NYP6-1 amplified to a maximum length of 2537 base pairs (bp), had genome coverage of approximately 45.62%, with an average of 493 and variance of 163 amplicons per 1 megabasepairs (Mb). NYP6-2 amplified to a maximum length of 2926 bp and covered 54.35% of the genome with an average of 579 and a variance of 191 amplicons per Mb. In contrast, the original primer used in Degenerate Oligonucleotide-Primed PCR (DOP-PCR) had coverage of 20.93%, an average of 74 and variance of 188 amplicons per Mb when extended up to a length of 2000 bp. Successful WGA of miniscule amounts of genomic DNA requires the amplification method used to resolve issues on efficiency, accurate representation of the whole genome and ability to degraded DNA. The sequence NYP6-2 discovered using our method can be confidently used in a primer extension based protocol to perform quantitatively unbiased WGA.	abnormal degeneration;amplifier;base pairing;computation;displacement mapping;gene amplification technique;genetic algorithm;primer extension;sample variance;simulation;strand (programming language);whole genome amplification;strand displacement	Adrian E. H. Png;Keng Wah Choo;Cheryl I. P. Lee;Siew Hong Leong;Oi Lian Kon	2006	In silico biology		biology;molecular biology;genetic algorithm;bioinformatics;multiplex ligation-dependent probe amplification;multiple displacement amplification;genetics	Comp.	0.5564664209389603	-54.01503806762788	63998
83cd39f01a130d41870b0e283dbb6ffbc3cb043a	the effectiveness of reactant pools for generating structurally-diverse combinatorial libraries		Current approaches to the design of combinatorial libraries assume that structural diversity in the reactant pools corresponds to structural diversity in the combinatorial libraries that result from reacting these pools together. In experiments with three different published libraries, dissimilarity-based compound selection (DBCS) is applied at two levels. First, the DBCS algorithm is applied at the reactant level, a library is built, and its diversity is measured. Second, the DBCS algorithm is applied to the full set of products generated by enumeration of all the reactants and the diversity of the subset is measured. Results show that reactant-based selection, which attempts to maximize diversity in the pools, results in noticeably less diverse libraries than if the selection is performed at the product level. Experiments are reported to estimate the upperbound to diversity achievable using DBCS, and it appears that DBCS is very effective at finding maximally diverse subsets. However, applying DBCS sele...	library (computing)	Valerie J. Gillet;Peter Willett;John Bradshaw	1997	Journal of Chemical Information and Computer Sciences	10.1021/ci970420g	combinatorial chemistry;enumeration;mathematics	Theory	9.42178788628332	-59.15073708320768	64118
6d4da63435d1c5eb7fff10cddeba8595db2ffb4d	branch: boosting rna-seq assemblies with partial or related genomic sequences	initial assembly;branch processing;supplementary data;genomic information;branch software;genomic sequence;rna-seq data;rna-seq assembly;real data;genomic contigs	MOTIVATION De novo transcriptome assemblies of RNA-Seq data are important for genomics applications of unsequenced organisms. Owing to the complexity and often incomplete representation of transcripts in sequencing libraries, the assembly of high-quality transcriptomes can be challenging. However, with the rapidly growing number of sequenced genomes, it is now feasible to improve RNA-Seq assemblies by guiding them with genomic sequences.   RESULTS This study introduces BRANCH, an algorithm designed for improving de novo transcriptome assemblies by using genomic information that can be partial or complete genome sequences from the same or a related organism. Its input includes assembled RNA reads (transfrags), genomic sequences (e.g. contigs) and the RNA reads themselves. It uses a customized version of BLAT to align the transfrags and RNA reads to the genomic sequences. After identifying exons from the alignments, it defines a directed acyclic graph and maps the transfrags to paths on the graph. It then joins and extends the transfrags by applying an algorithm that solves a combinatorial optimization problem, called the Minimum weight Minimum Path Cover with given Paths. In performance tests on real data from Caenorhabditis elegans and Saccharomyces cerevisiae, assisted by genomic contigs from the same species, BRANCH improved the sensitivity and precision of transfrags generated by Velvet/Oases or Trinity by 5.1-56.7% and 0.3-10.5%, respectively. These improvements added 3.8-74.1% complete transcripts and 8.3-3.8% proteins to the initial assembly. Similar improvements were achieved when guiding the BRANCH processing of a transcriptome assembly from a more complex organism (mouse) with genomic sequences from a related species (rat).   AVAILABILITY The BRANCH software can be downloaded for free from this site: http://manuals.bioinformatics.ucr.edu/home/branch.   CONTACT thomas.girke@ucr.edu   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	align (company);blat;bioinformatics;biopolymer sequencing;combinatorial optimization;communications satellite;customize;dna-directed dna polymerase;de novo transcriptome assembly;directed acyclic graph;elfacos ow 100;exons;genome assembly sequence;genomics;graph - visual representation;investments;libraries;map;mathematical optimization;minimum weight;optimization problem;partial;path cover;rna;reading (activity);saccharomyces cerevisiae;sequence number;transcript;trinity;uc browser;united states department of agriculture;velvet assembler;video post-processing;algorithm;funding grant;negative regulation of nonmotile primary cilium assembly	Ergude Bao;Tao Jiang;Thomas Girke	2013	Bioinformatics	10.1093/bioinformatics/btt127	biology;bioinformatics;genetics	Comp.	-0.40665976801140497	-54.25059569885355	64119
4d207b3b6feaa8bd65478d568fdfa157bb2ffefc	an integrated framework for strain optimization	biology computing;optimisation;optimization linear programming strain genetics graphical user interfaces biological system modeling libraries;optimisation biology computing genetics graphical user interfaces;genetics;graphical user interfaces;gplv3 licence genetic modification identification mutant strains metabolic engineering strain optimization strategy phenotype simulation method gui strain optimization plug in optflux workbench me	The identification of genetic modifications leading to mutant strains able to overproduce compounds of industrial interest is a challenging task in Metabolic Engineering (ME). Several methods have been proposed but, to some extent, none of them is suitable for all the specificities of each particular strain optimization problem. This work proposes an integrated framework that allows its users to configure and fine tune all the various steps involved in a strain optimization strategy, including the loading of models in distinct formats, the definition of a suitable phenotype simulation method and the choice and configuration of the strain optimization engine. Moreover, it is designed to suit the needs of users skilled at programming, as well as less advanced users. The framework includes a GUI implemented as the strain optimization plug-in for the OptFlux workbench (version 3), a reference platform for ME (http://www.optflux.org). All the code is distributed under the GPLv3 licence and it is fully available (http://sourceforge.net/projects/optflux/).	graphical user interface;mathematical optimization;open-source software;optimization problem;plug-in (computing);programmer;rendering (computer graphics);simulation;workbench	Paulo Maia;Isabel Rocha;Miguel Rocha	2013	2013 IEEE Congress on Evolutionary Computation	10.1109/CEC.2013.6557571	simulation;computer science;bioinformatics;theoretical computer science;graphical user interface	Embedded	-1.1637694590967695	-56.847348890410174	64315
f0453c8e2221cd7ef3ef542521b57abf692e0ce5	quantifying stochasticity in gene-expression with extrinsic parameter fluctuations	gene expression process stochasticity quantification extrinsic parameter fluctuation homogeneous cell population cell to cell variation protein level intrinsic noise protein variability stochastic nature biochemical process extrinsic noise shared cellular enzymes enzyme level translation rate exact analytical formula transcription rate two color reporter system;stochastic processes enzymes genetics;genetics;noise proteins stochastic processes mathematical model degradation production;enzymes;stochastic processes	Homogeneous cell populations can exhibit considerable cell-to-cell variation in the level of a given protein. Both intrinsic and extrinsic sources of noise have been implicated in driving this variability in protein level. More specifically, intrinsic noise is the protein variability that is different across genes and arises from the inherent stochastic nature of biochemical processes involved in gene-expression. In contrast, extrinsic noise is the protein variability that is common across genes and comes from random fluctuations in the levels of shared cellular enzymes. These fluctuations in enzyme levels induce fluctuations in different gene-expression parameters such as the transcription and translation rate. Here, we derive exact analytical formulas quantifying the extent of variability in protein levels in the presence of both intrinsic noise and extrinsic parameter fluctuations. Consistent with previous results, we find that extrinsic fluctuations in the transcription rate enhance extrinsic noise in gene-expression but do not affect the intrinsic noise. Interestingly, analysis reveals that extrinsic fluctuations in the translation rate dramatically increase both intrinsic and extrinsic noise in gene-expression. Implications of our results in the context of quantifying intrinsic and extrinsic noise from two-color reporter systems are discussed. In summary, formulas developed here show how extrinsic parameter fluctuations propagate through the gene-expression process to create heterogeneity in protein level and have important implications for discriminating between alternative sources of stochasticity in gene-expression.	heart rate variability;population;spatial variability;stochastic process;transcription (software)	Abhyudai Singh	2012	2012 IEEE 51st IEEE Conference on Decision and Control (CDC)	10.1109/CDC.2012.6426155	stochastic process;enzyme;mathematics;statistics	Comp.	7.182693864283369	-65.26725904210824	64496
f56ef8e86e5fdab07a28c939868f909fafa765be	inferring biological basis about psychrophilicity by interpreting the rules generated from the correctly classified input instances by a classifier	cold adaptation;rotation forest;part rule induction method;amino acid composition patterns;biologically interpretable rules	Organisms thriving at extreme cold surroundings are called as psychrophiles and they present a wealth of knowledge about sequence adjustments in proteins that had occurred during the adaptation to low temperatures. In this paper, we propose a new cascading model to investigate the basis for psychrophilicity. In this model, a superior classifier was used to discriminate psychrophilic from mesophilic protein sequences, and then the PART rule generating algorithm was applied on the input instances that are correctly classified by the classifier, to generate human interpretable rules. These derived rules were further validated on a structural dataset and finally analyzed to discover the underlying biological basis about the psychrophilicity. In this study, we have used one of the key features of psychrophilic proteins accountable for remaining functional in extreme cold temperature surroundings i.e., global patterns of amino acid composition as the input features. The rotation forest classifier outperformed all the other classifiers with maximum accuracy of 70.5% and maximum AUC of 0.78. The effect of sequence length on the classification accuracy was also investigated. The analysis of the derived rules and interpretation of the analyzed results had revealed some interesting phenomena such as the amino acids A, D, G, F, and S are over-represented, and T is under-represented in psychrophilic proteins. These findings augment the existing domain knowledge for psychrophilic sequence features.		Abhigyan Nath;Karthikeyan Subbiah	2014	Computational biology and chemistry	10.1016/j.compbiolchem.2014.10.002	biology;bioinformatics;machine learning;data mining	ML	8.102551428011868	-56.060937058254744	64640
4bf43e9ac61688f501bc0dfab873a4d38f51833c	img/m: a data management and analysis system for metagenomes	genes;software;forecasting;genomics;processing;microbial communities;data integrity;environmental molecular sciences laboratory;protein families;database management systems;genome archaeal;data management;59;environmental microbiology;data processing;databases genetic;integrated microbial genomes;genomes;gut microbiome;data analysis;internet;genome bacterial;life sciences;production;agriculture;communities;management;microbial community;functionals	IMG/M is a data management and analysis system for microbial community genomes (metagenomes) hosted at the Department of Energy's (DOE) Joint Genome Institute (JGI). IMG/M consists of metagenome data integrated with isolate microbial genomes from the Integrated Microbial Genomes (IMG) system. IMG/M provides IMG's comparative data analysis tools extended to handle metagenome data, together with metagenome-specific analysis tools. IMG/M is available at http://img.jgi.doe.gov/m.	genome;genome, microbial;img;metagenome;temporomandibular joint disorders	Victor M. Markowitz;Natalia N Ivanova;Ernest Szeto;Krishna Palaniappan;Ken Chu;Daniel Dalevi;I-Min A. Chen;Yuri Grechkin;Inna Dubchak;Iain Anderson;Athanasios Lykidis;Konstantinos Mavrommatis;Philip Hugenholtz;Nikos C Kyrpides	2008		10.1093/nar/gkm869	biology;agriculture;genomics;data processing;forecasting;data management;bioinformatics;processing;data integrity;data analysis;ecology	HPC	-2.8192625560318243	-61.34568046068643	64645
a19ba41cfacc40514033e958a6f991a2cc2abf2a	iedb-3d: structural data within the immune epitope database	epitopes;complex;ligands;receptors antigen t cell;histocompatibility antigens;protein conformation;xml;molecule;epitopes b lymphocyte;user computer interface;epitopes t lymphocyte;3d structure;databases protein;antibodies	IEDB-3D is the 3D structural component of the Immune Epitope Database (IEDB) available via the 'Browse by 3D Structure' page at http://www.iedb.org. IEDB-3D catalogs B- and T-cell epitopes and Major Histocompatibility Complex (MHC) ligands for which 3D structures of complexes with antibodies, T-cell receptors or MHC molecules are available in the Protein Data Bank (PDB). Journal articles that are primary citations of PDB structures and that define immune epitopes are curated within IEDB as any other reference along with accompanying functional assays and immunologically relevant information. For each curated structure, IEDB-3D provides calculated data on intermolecular contacts and interface areas and includes an application, EpitopeViewer, to visualize the structures. IEDB-3D is fully embedded within IEDB, thus allowing structural data, both curated and calculated, and all accompanying information to be queried using multiple search interfaces. These include queries for epitopes recognized in different pathogens, eliciting different functional immune responses, and recognized by different components of the immune system. The query results can be downloaded in Microsoft Excel format, or the entire database, together with structural data both curated and calculated, can be downloaded in either XML or MySQL formats.	browsing;catalogs;embedded system;embedding;epitopes;immune system diseases;immune response;ligands;major histocompatibility complex;model of hierarchical complexity;mysql;protein data bank;question (inquiry);receptors, cell surface;structural element;xml;citation;format	Julia V. Ponomarenko;Nikitas Papangelopoulos;Dirk M. Zajonc;Bjoern Peters;Alessandro Sette;Philip E. Bourne	2011		10.1093/nar/gkq888	biology;protein structure;xml;molecule;bioinformatics;antibody;histocompatibility;immunology;ligand;epitope	DB	-1.4385007109580585	-60.59558551277207	64700
f43590881306e85ea5867bbc0fff5781c7607523	predicting peptide structures in native proteins from physical simulations of fragments	molecular simulation;weights and measures;study design;bayesian classifier;bayes theorem;logistic models;replica exchange molecular dynamics;models chemical;solvents;models molecular;large scale simulation;local structure;proteins;protein conformation;force field;structure prediction;thermodynamics;artificial intelligence;protein folding;proteomics;computer simulation;water;logistic regression model;physical simulation	It has long been proposed that much of the information encoding how a protein folds is contained locally in the peptide chain. Here we present a large-scale simulation study designed to examine the extent to which conformations of peptide fragments in water predict native conformations in proteins. We perform replica exchange molecular dynamics (REMD) simulations of 872 8-mer, 12-mer, and 16-mer peptide fragments from 13 proteins using the AMBER 96 force field and the OBC implicit solvent model. To analyze the simulations, we compute various contact-based metrics, such as contact probability, and then apply Bayesian classifier methods to infer which metastable contacts are likely to be native vs. non-native. We find that a simple measure, the observed contact probability, is largely more predictive of a peptide's native structure in the protein than combinations of metrics or multi-body components. Our best classification model is a logistic regression model that can achieve up to 63% correct classifications for 8-mers, 71% for 12-mers, and 76% for 16-mers. We validate these results on fragments of a protein outside our training set. We conclude that local structure provides information to solve some but not all of the conformational search problem. These results help improve our understanding of folding mechanisms, and have implications for improving physics-based conformational sampling and structure prediction using all-atom molecular simulations.	bayesian programming;classification;code;computer simulation;contain (action);force field (chemistry);gper protein, human;implicit solvation;inference;logistic regression;molecular dynamics;molecular modelling;naive bayes classifier;numerous;parallel tempering;peptide fragments;sampling (signal processing);sampling - surgical action;search problem;solvent models;staphylococcal protein a;test set	Vincent A. Voelz;M. Scott Shell;Ken A. Dill	2009	PLoS Computational Biology	10.1371/journal.pcbi.1000281	computer simulation;protein folding;biochemistry;protein structure;water;naive bayes classifier;computer science;bioinformatics;units of measurement;machine learning;force field;logistic regression;proteomics;bayes' theorem;clinical study design;statistics	Comp.	9.630106766859917	-58.67600084011055	64717
119abb3b31baf60040e647b729aacdaf83e1df3c	on the use of qualitative reasoning to simulate and identify metabolic pathway	use;via metabolica;text;dk atira pure researchoutput researchoutputtypes contributiontojournal article;learning;ordinary differential equation;voie metabolique;methode;biology;biologia;proceso adquisicion;acquisition process;aprendizaje;utilisation;apprentissage;identification;uso;modele simulation;identificacion;qualitative reasoning;modelo simulacion;metabolic pathway;metodo;simulation model;method;processus acquisition;biologie;in silico	MOTIVATION Perhaps the greatest challenge of modern biology is to develop accurate in silico models of cells. To do this we require computational formalisms for both simulation (how according to the model the state of the cell evolves over time) and identification (learning a model cell from observation of states). We propose the use of qualitative reasoning (QR) as a unified formalism for both tasks. The two most commonly used alternative methods of modelling biochemical pathways are ordinary differential equations (ODEs), and logical/graph-based (LG) models.   RESULTS The QR formalism we use is an abstraction of ODEs. It enables the behaviour of many ODEs, with different functional forms and parameters, to be captured in a single QR model. QR has the advantage over LG models of explicitly including dynamics. To simulate biochemical pathways we have developed 'enzyme' and 'metabolite' QR building blocks that fit together to form models. These models are finite, directly executable, easy to interpret and robust. To identify QR models we have developed heuristic chemoinformatics graph analysis and machine learning procedures. The graph analysis procedure is a series of constraints and heuristics that limit the number of ways metabolites can combine to form pathways. The machine learning procedure is generate-and-test inductive logic programming. We illustrate the use of QR for modelling and simulation using the example of glycolysis.   AVAILABILITY All data and programs used are available on request.	cheminformatics;constraint (mathematics);differential diagnosis;executable;gene regulatory network;glycolysis;graph - visual representation;heuristics;inductive logic programming;inductive reasoning;machine learning;qr decomposition;qualitative research;reasoning - publishing subsection;robustness (computer science);semantics (computer science);simulation	Ross D. King;Simon M. Garrett;George Macleod Coghill	2005	Bioinformatics	10.1093/bioinformatics/bti255	identification;ordinary differential equation;metabolic pathway;method;qualitative reasoning;computer science;artificial intelligence;simulation modeling;mathematics;algorithm	Comp.	-4.0954571506876425	-54.42615414022969	64754
50a3058f4111c6eadfd235688c6e0c08856754fb	using literature-based discovery to explain adverse drug effects	literature based discovery;text mining;pharmacovigilance;adverse drug reactions;adverse drug effects;pharmacogenomics	We report on our research in using literature-based discovery (LBD) to provide pharmacological and/or pharmacogenomic explanations for reported adverse drug effects. The goal of LBD is to generate novel and potentially useful hypotheses by analyzing the scientific literature and optionally some additional resources. Our assumption is that drugs have effects on some genes or proteins and that these genes or proteins are associated with the observed adverse effects. Therefore, by using LBD we try to find genes or proteins that link the drugs with the reported adverse effects. These genes or proteins can be used to provide insight into the processes causing the adverse effects. Initial results show that our method has the potential to assist in explaining reported adverse drug effects.	adverse reaction to drug;drug kinetics;lafora disease;pharmacogenomics;pharmacology;scientific literature;explanation	Dimitar Hristovski;Andrej Kastrin;Dejan Dinevski;Anita Burgun-Parenthoine;Lovro Ziberna;Thomas C. Rindflesch	2016	Journal of Medical Systems	10.1007/s10916-016-0544-z	text mining;medicine;toxicology;computer science;pharmacogenomics;data mining;pharmacovigilance	ML	-1.9226911708817542	-64.59212775260504	64763
4d29862b6d3cbbfb2c8635fd823a8c77acdcf330	a trim distance between positions as packaging signals in h3n2 influenza viruses	packaging signal;influenza viruses;influenza a virus trim distance packaging signal h3n2 influenza virus phylogeny based distance nucleotide sequence lca preserving distance phylogenetic tree;trim distance packaging signal influenza viruses;trim distance;signal processing biology computing genetic engineering microorganisms molecular biophysics	A trim distance as a phylogeny-based distance between two positions in nucleotide sequences is formulated as an LCA-preserving distance between the trimmed phylogenetic trees by the positions. In this paper, in order to investigate the positions as packaging signals of nucleotide sequences in influenza A (H3N2) viruses, we compute and compare the trim distances between positions in the nucleotide sequences of influenza A (H3N2) viruses provided from NCBI.	phylogenetic tree	Shunsuke Makino;Takaharu Shimada;Kouichi Hirata;Kouki Yonezawa;Kimihito Ito	2012	The 6th International Conference on Soft Computing and Intelligent Systems, and The 13th International Symposium on Advanced Intelligence Systems	10.1109/SCIS-ISIS.2012.6505355	bioinformatics	Embedded	3.120039223763178	-63.761075949197235	64786
0cd3c478fe12db7da8907bbf46b7b1355e60bbf5	antisense properties of tricyclo-dna	dna;ribonuclease h;animals;alternative splicing;rna complementary;rna messenger;hela cell;nucleic acid denaturation;biology;thermal stability;spectrometry mass matrix assisted laser desorption ionization;oligonucleotides;globins;cattle;transfection;point mutation;nucleic acid conformation;570 life sciences;humans;globin gene;fetal blood;dna antisense;hela cells;540 chemistry;fetal calf serum	Tricyclo (tc)-DNA belongs to the class of conformationally constrained DNA analogs that show enhanced binding properties to DNA and RNA. We prepared tc-oligonucleotides up to 17 nt in length, and evaluated their binding efficiency and selectivity towards complementary RNA, their biological stability in serum, their RNase H inducing potential and their antisense activity in a cellular assay. Relative to RNA or 2'-O-Me-phosphorothioate (PS)-RNA, fully modified tc-oligodeoxynucleotides, 10-17 nt in length, show enhanced selectivity and enhanced thermal stability by approximately 1 degrees C/modification in binding to RNA targets. Tricyclodeoxyoligonucleotides are completely stable in heat-deactivated fetal calf serum at 37 degree C. Moreover, tc-DNA-RNA duplexes are not substrates for RNase H. To test for antisense effects in vivo, we used HeLa cell lines stably expressing the human beta-globin gene with two different point mutations in the second intron. These mutations lead to the inclusion of an aberrant exon in beta-globin mRNA. Lipofectamine-mediated delivery of a 17mer tc-oligodeoxynucleotide complementary to the 3'-cryptic splice site results in correction of aberrant splicing already at nanomolar concentrations with up to 100-fold enhanced efficiency relative to a 2'-O-Me-PS-RNA oligonucleotide of the same length and sequence. In contrast to 2'-O-Me-PS-RNA, tc-DNA shows antisense activity even in the absence of lipofectamine, albeit only at much higher oligonucleotide concentrations.	analog;cellular assay;complementary rna;dna computing;fetal bovine serum;hbb wt allele;hemoglobin subunit beta;introns;leukemia, b-cell;lipofectamine;oligodeoxyribonucleotides;oligonucleotides;point mutation;rna splicing;selectivity (electronic);splice (system call);video-in video-out;antisense therapy;enniatin e;globin activity;phosphorothioate	Dorte Renneberg;Emilie Bouliong;Ulrich Reber;Daniel Schümperli;Christian J. Leumann	2002	Nucleic acids research	10.1093/nar/gkf412	thermal stability;point mutation;globin;biology;biochemistry;molecular biology;nuclease protection assay;alternative splicing;transfection;rnase h;genetics;dna;oligonucleotide	Comp.	5.386660338673002	-63.764485605170165	64837
040fbcd81ccb3a7e838037b43224a53b96fe3b7d	computing gene functional similarity using combined graphs	gene functional similarity;ontology integration;gene ontology annotation;gene function;biological process;gene ontology	The Gene Ontology has been used extensively for measuring the functional similarity among genes of various organisms. All the existing gene similarity methods use either molecular function or biological process taxonomies in computing gene similarity. In this paper, we apply an algorithm for combining graphs to connect the molecular function (F) and biological process (P) taxonomies into one FP taxonomy graph. We then measure the functional similarity of two genes using the resulting FP graph with path length function. The two aspects of GO, molecular function and biological process, are combined by connecting F nodes with P nodes using gene ontology annotation, GOA, databases. By combining two GO graphs, we can have more comprehensive way to explore the functional relationships between genes. We conducted the evaluation on a dataset of OMIM disease phenotypes to estimate the similarity of disease proteins from various diseases.	algorithm;database;gene ontology;graph (discrete mathematics);online mendelian inheritance in man;taxonomy (general)	Anurag Nagar;Hisham Al-Mubaid;Saïd Bettayeb	2012		10.1145/2245276.2231995	critical assessment of function annotation;bioinformatics;data mining;biological process;information retrieval	Comp.	4.352989686122865	-56.69244109902478	64845
438fe325b6f721dc713af5854d48f46dbf591d0e	a role for rebinding in rapid and reliable t cell responses to antigen	animals;models neurological;high concentrate;receptors antigen t cell;t cell receptor;kinetic parameter;antigens;antigen presenting cell;immune system;humans;t lymphocytes;immunity innate;kinetics;computer simulation	Experimental work has shown that T cells of the immune system rapidly and specifically respond to antigenic molecules presented on the surface of antigen-presenting-cells and are able to discriminate between potential stimuli based on the kinetic parameters of the T cell receptor-antigen bond. These antigenic molecules are presented among thousands of chemically similar endogenous peptides, raising the question of how T cells can reliably make a decision to respond to certain antigens but not others within minutes of encountering an antigen presenting cell. In this theoretical study, we investigate the role of localized rebinding between a T cell receptor and an antigen. We show that by allowing the signaling state of individual receptors to persist during brief unbinding events, T cells are able to discriminate antigens based on both their unbinding and rebinding rates. We demonstrate that T cell receptor coreceptors, but not receptor clustering, are important in promoting localized rebinding, and show that requiring rebinding for productive signaling reduces signals from a high concentration of endogenous pMHC. In developing our main results, we use a relatively simple model based on kinetic proofreading. However, we additionally show that all our results are recapitulated when we use a detailed T cell receptor signaling model. We discuss our results in the context of existing models and recent experimental work and propose new experiments to test our findings.	antigen-presenting cells;antigens;chronic lymphocytic leukemia;cluster analysis;experiment;immune system;kinetics;leukemia, b-cell;peptide/mhc complex;promotion (action);signal transduction;receptor clustering;statistical cluster	Omer Dushek;Raibatak Das;Daniel Coombs	2009		10.1371/journal.pcbi.1000578	computer simulation;biology;antigen-presenting cell;streptamer;immune system;virology;antigen;immunology;t-cell receptor;kinetics	ML	8.313391031181528	-62.422519523459925	64860
3aa58eeff54f9a0976c4f6d70220209742ea8133	a density functional study of the hydrogen-bond network within the hiv-1 protease catalytic site cleft	hydrogen bond;protonation states;hiv protease;model size importance;hiv 1 protease;dft;density functional	The relative energy between two different protonation sites of the Asp25' catalytic site residue is computed and analyzed for various HIV-1 Protease/inhibitor complexes and compared to the wild-type structure. By comparing calculations of negatively charged fragments of gradually increasing size up to 105 atoms we show that correct modeling of the HIV-1 Protease active site requires much larger models than the commonly used acetic acid/acetate moieties. The energy difference between the two proposed protonation sites decreases as the size of the system increases and tends to converge only when the entire catalytic triad of both monomers is taken into account. The importance of the Gly27 backbone amine groups in the stabilization of the negative charge within the catalytic site cleft is revealed. Comparison of the wild-type structure with the structures from various Pr/drug complexes indicates that the HIV-1 protease has a particular catalytic site flexibility.	absolutely sure;acetate;acetic acid;amines;anions;aspartic acid;behavioral tic;catalytic domain;charge (electrical);conserved sequence;converge;duoxa1 gene;density functional theory;endopeptidases;glycine;hydrogen;hydrogen bonding;image resolution;interaction energy;internet backbone;large;mutation;oxygen;proteolytic enzyme;quantum mechanics;small;software release life cycle;surgical flaps;tic disorder;triad acrylic resin;vertebral column;water model;dolutegravir;kilocalorie;monomer;mutant;newton	Suzanne W. Sirois;Emil I. Proynov;Jean-François Truchon;Christos M. Tsoukas;Dennis R. Salahub	2003	Journal of computational chemistry	10.1002/jcc.10176	biochemistry;stereochemistry;chemistry;organic chemistry;discrete fourier transform;hydrogen bond	Comp.	8.50808045350155	-63.12362091054883	65015
abe304b55d9e5735e67dd5dad5232b5cb3d64ac3	application of eagle algorithm for modules identification in biological networks	biology computing;genomics;complex networks;transcriptional regulatory networks eagle algorithm functional modules identification genome scale biological networks biological data flood giant strong component gsc staphylococcus aureus metabolic network genome sequencing metabolic networks protein protein interaction networks;genomics bioinformatics visualization;functional modules;visualization;functional modules biological networks complex networks;biological networks;data handling;genomics biology computing data handling;bioinformatics	The biological data flood makes more and more genome-scale biological networks available. There is a need to identify functional modules in these biological networks, complex networks based methods offer promise in this regard. Here, we show that EAGLE algorithm can be used for functional modules identification. By applying the algorithm to the giant strong component (GSC) of Staphylococcus aureus metabolic network, we obtain 12 functional modules. We find that all of 12 identified functional modules have high modularity, and they also have obvious biological insights, which suggested the high efficiency of using EAGLE algorithm to identify functional modules in biological networks.	algorithm;biological network;complex network;gsc bus;information explosion	De-wu Ding;Long Ying	2012	2012 IEEE International Conference on Granular Computing	10.1109/GrC.2012.6468616	biological network;genomics;visualization;computer science;bioinformatics;group method of data handling;complex network	Comp.	4.625181265274595	-57.05042813101658	65036
57f43b1973bd302c6c9e8194b2472bacf6e70eb7	automatic learning of pre-mirnas from different species	computational biology bioinformatics;algorithms;computer appl in life sciences;microarrays;bioinformatics	Discovery of microRNAs (miRNAs) relies on predictive models for characteristic features from miRNA precursors (pre-miRNAs). The short length of miRNA genes and the lack of pronounced sequence features complicate this task. To accommodate the peculiarities of plant and animal miRNAs systems, tools for both systems have evolved differently. However, these tools are biased towards the species for which they were primarily developed and, consequently, their predictive performance on data sets from other species of the same kingdom might be lower. While these biases are intrinsic to the species, their characterization can lead to computational approaches capable of diminishing their negative effect on the accuracy of pre-miRNAs predictive models. We investigate in this study how 45 predictive models induced for data sets from 45 species, distributed in eight subphyla/classes, perform when applied to a species different from the species used in its induction. Our computational experiments show that the separability of pre-miRNAs and pseudo pre-miRNAs instances is species-dependent and no feature set performs well for all species, even within the same subphylum/class. Mitigating this species dependency, we show that an ensemble of classifiers reduced the classification errors for all 45 species. As the ensemble members were obtained using meaningful, and yet computationally viable feature sets, the ensembles also have a lower computational cost than individual classifiers that rely on energy stability parameters, which are of prohibitive computational cost in large scale applications. In this study, the combination of multiple pre-miRNAs feature sets and multiple learning biases enhanced the predictive accuracy of pre-miRNAs classifiers of 45 species. This is certainly a promising approach to be incorporated in miRNA discovery tools towards more accurate and less species-dependent tools. The material to reproduce the results from this paper can be downloaded from http://dx.doi.org/10.5281/zenodo.49754 .	algorithmic efficiency;class;computation;experiment;linear separability;machine learning;mathematical induction;micrornas;predictive modelling;pseudo brand of pseudoephedrine;subphylum;emotional dependency	Ivani de Oliveira Negrão Lopes;Alexander Schliep;André Carlos Ponce de Leon Ferreira de Carvalho	2016		10.1186/s12859-016-1036-3	biology;dna microarray;computer science;bioinformatics;data mining	ML	9.243513562601505	-55.27864577335408	65090
176aef8951d0fe5c726be65bdbf684ead122dea1	the sulfolobus database	first year;databases nucleic acid;genome archaeal;web interface;internet;data extraction;chromosomes archaeal;genes archaeal;user computer interface;sulfolobus	The Sulfolobus database (http://www.sulfolobus.org) integrates, for the first time, all currently available Sulfolobus chromosome sequences with annotations. It also includes all the sequence data for the extrachromosomal elements which can propagate in Sulfolobus organisms. All genomes and annotations deposited in GenBank are included in the database and a genefinder has been run on the sequences to ensure that all potential genes are present, and identifiable, in the database. Every month, all genes are searched against a range of external databases and new results are incorporated. The Sulfolobus database was developed as an asset to the rapidly-growing international community working with Sulfolobus as a model organism for the kingdom Crenarchaeota of the Archaea. It was accessed more that 46 000 times in its first year. The database aims to provide researchers easy access to sequence and gene information and the web-interface includes various searches, free text and BLAST, as well as genome browsing and data extraction. Updated annotations are incorporated regularly and the database will continue to expand as new information becomes available. This includes new sequences, newly identified genes, annotations and other related information.	accessibility;blast;database;genbank;genome;organism;sulfolobus;thermoprotei;user interface	Kim Brügger	2007		10.1093/nar/gkl847	biology;the internet;bioinformatics;user interface;genetics	DB	-2.291324194063123	-60.63892949867321	65116
1afde1bbf0930b1cf2033c6ed62a9ff8f74e19dc	the molecular basis for the selectivity of tadalafil toward phosphodiesterase 5 and 6: a modeling study		Great attention has been paid to the clinical significance of phosphodiesterase 5 (PDE5) inhibitors, such as sildenafil, tadalafil, and vardenafil widely used for erectile dysfunction. However, sildenafil causes side effects on visual functions since it shows similar potencies to inhibit PDE5 and PDE6, whereas tadalafil gives a high selectivity of 1020-fold against PDE6. Till now, their molecular mechanisms of selectivity of PDE5 versus PDE6 have remained unknown in the absence of the crystal structure of PDE6. In order to elucidate its isoform-selective inhibitory mechanism, a 3D model of PDE6 was constructed by homology modeling, and its interaction patterns with tadalafil plus sildenafil were exploited by molecular docking, molecular dynamics (MD) simulations, and binding free energy calculations. The present work reveals that tadalafil exhibits a less negative predicted binding free energy of -35.21 kcal/mol with PDE6 compared with the value of -41.12 kcal/mol for PDE5, which suggests that tadalafil prefers PDE5 rather than PDE6 and confers a high selectivity for PDE5 versus PDE6. The binding free energy results for tadalafil were consistent with external bioassay studies (IC50 = 5100 and 5 nM toward PDE6 and PDE5, respectively). Two important residues from the Q2 pockets (Val782 and Leu804 in PDE5 and their corresponding Val738 and Met760 in PDE6) were further identified to account for the high selectivity of tadalafil for PDE5 versus PDE6. These findings have shed light on the continuous puzzle of why sildenafil (IC50 = 74 and 6 nM toward PDE6 and PDE5, respectively) causes visual disorders because of its poor selectivity but tadalafil does not. In addition, the homology model of PDE6 can be used to design more potent and selective second-generation PDE5 inhibitors with less inhibitory potency against PDE6.		Yi-You Huang;Zhe Li;Ying-Hong Cai;Ling-Jun Feng;Yinuo Wu;Xingshu Li;Hai-Bin Luo	2013	Journal of chemical information and modeling	10.1021/ci400458z	pharmacology;endocrinology;stereochemistry;chemistry	Visualization	9.632751530576554	-62.2828077218752	65170
f3c887a6964dabe7baef669de1064503066d8b8f	tadb 2.0: an updated database of bacterial type ii toxin–antitoxin loci		TADB2.0 (http://bioinfo-mml.sjtu.edu.cn/TADB2/) is an updated database that provides comprehensive information about bacterial type II toxin-antitoxin (TA) loci. Compared with the previous version, the database refined and the new data schema is employed. With the aid of text mining and manual curation, it recorded 6193 type II TA loci in 870 replicons of bacteria and archaea, including 105 experimentally validated TA loci. In addition, the newly developed tool TAfinder combines the homolog searches and the operon structure detection, allowing the prediction for type II TA pairs in bacterial genome sequences. It also helps to investigate the genomic context of predicted TA loci for putative virulence factors, antimicrobial resistance determinants and mobile genetic elements via alignments to the specific public databases. Additionally, the module TAfinder-Compare allows comparing the presence of the given TA loci across the close relative genomes. With the recent updates, TADB2.0 might provide better support for understanding the important roles of type II TA systems in the prokaryotic life activities.	access network;antitoxins;archaea;archive;data mining;digital curation;ethanol 0.62 ml/ml topical gel;experiment;genome;genome, bacterial;homology (biology);mined;nar 2;natural science disciplines;neutralization (chemistry);operon;published database;replicon;text mining;toxin and toxin-target database;virulence	Yingzhou Xie;Yiqing Wei;Yue Shen;Xiaobin Li;Hao Zhou;Cui Tai;Zixin Deng;Hong-Yu Ou	2018		10.1093/nar/gkx1033	genetics;locus (genetics);antitoxin;bioinformatics;biology;toxin	SE	0.057068471447110546	-60.11534442998779	65230
8895d3c99ce6938f87c31bd9ef40377d8eb5fb3c	aaindex: amino acid index database	protein structure secondary;amino acid;amino acid substitution;molecular conformation;internet;indexation;genome;sequence homology amino acid;amino acids;sequence alignment;databases factual;information storage and retrieval;mutation	AAindex is a database of numerical indices representing various physicochemical and biochemical properties of amino acids and pairs of amino acids. It consists of two sections: AAindex1 for the amino acid index of 20 numerical values and AAindex2 for the amino acid mutation matrix of 210 numerical values. Each entry of either AAindex1 or AAindex2 consists of the definition, the reference information, a list of related entries in terms of the correlation coefficient, and the actual data. The database may be accessed through the DBGET/LinkDB system at GenomeNet (http://www.genome.ad. jp/dbget/) or may be downloaded by anonymous FTP (ftp://ftp.genome. ad.jp/db/genomenet/aaindex/).	amino acid metabolism, inborn errors;amino acids;coefficient;database;mutation;numerical analysis	Shuichi Kawashima;Hiroyuki Ogata;Minoru Kanehisa	1999	Nucleic acids research	10.1093/nar/27.1.368	biology;biochemistry;amino acid;bioinformatics;genetics	DB	-1.3474963630666712	-60.56241635305151	65247
7c89663a0f2db704a95c5654ceb6e847eb9dd7ae	mechanistic study of human glucose transport mediated by glut1	biological patents;biomedical journals;text mining;europe pubmed central;citation search;citation networks;research articles;abstracts;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	The glucose transporter 1 (GLUT1) belongs to the major facilitator superfamily (MFS) and is responsible for the constant uptake of glucose. However, the molecular mechanism of sugar transport remains obscure. In this study, homology modeling and molecular dynamics (MD) simulations in lipid bilayers were performed to investigate the combination of the alternate and multisite transport mechanism of glucose with GLUT1 in atomic detail. To explore the substrate recognition mechanism, the outward-open state human GLUT1 homology model was generated based on the template of xylose transporter XylE (PDB ID: 4GBZ), which shares up to 29% sequence identity and 49% similarity with GLUT1. Through the MD simulation study of glucose across lipid bilayer with both the outward-open GLUT1 and the GLUT1 inward-open crystal structure, we investigated six different conformational states and identified four key binding sites in both exofacial and endofacial loops that are essential for glucose recognition and transport. The study further revealed that four flexible gates consisting of W65/Y292/Y293-M420/TM10b-W388 might play important roles in the transport cycle. The study showed that some side chains close to the central ligand binding site underwent larger position changes. These conformational interchanges formed gated networks within an S-shaped central channel that permitted staged ligand diffusion across the transporter. This study provides new inroads for the understanding of GLUT1 ligand recognition paradigm and configurational features which are important for molecular, structural, and physiological research of the MFS members, especially for GLUT1-targeted drug design and discovery.	4-dichlorobenzene;binding sites;clinical use template;cooley's anemia;crystal structure;direct inward dial;forty nine;glucose transporter;homologous gene;homology (biology);homology modeling;keyboard shortcut;large;ligands;lipid metabolism disorders;marfan syndrome;molecular dynamics;moose file system;programming paradigm;protein data bank;slc2a1 gene;superfamily;sequence alignment;simulation;sugar;transporter classification database;xylose;glucose transport	Xuegang Fu;Gang Zhang;Ran Liu;Jing Wei;Daisy Zhang-Negrerie;Xiaodong Jian;Qingzhi Gao	2016	Journal of chemical information and modeling	10.1021/acs.jcim.5b00597	biology;biochemistry;text mining;medical research;computer science;bioinformatics;data mining;nanotechnology;genetics	HCI	6.190127393819281	-62.66447266218612	65252
3243ceb0d4b07c0482713bbc7a3e33993c12c3e1	sample size calculation for microarray experiments with blocked one-way design	false discovery rate;effect size;sample size;treatment effect;research design;statistical method;computational biology bioinformatics;gene expression;microarray analysis;cluster analysis;differential expression;analysis of variance;algorithms;differentially expressed gene;combinatorial libraries;computer appl in life sciences;computer simulation;gene expression profiling;oligonucleotide array sequence analysis;microarrays;bioinformatics	One of the main objectives of microarray analysis is to identify differentially expressed genes for different types of cells or treatments. Many statistical methods have been proposed to assess the treatment effects in microarray experiments. In this paper, we consider discovery of the genes that are differentially expressed among K (> 2) treatments when each set of K arrays consists of a block. In this case, the array data among K treatments tend to be correlated because of block effect. We propose to use the blocked one-way ANOVA F-statistic to test if each gene is differentially expressed among K treatments. The marginal p-values are calculated using a permutation method accounting for the block effect, adjusting for the multiplicity of the testing procedure by controlling the false discovery rate (FDR). We propose a sample size calculation method for microarray experiments with a blocked one-way design. With FDR level and effect sizes of genes specified, our formula provides a sample size for a given number of true discoveries. The calculated sample size is shown via simulations to provide an accurate number of true discoveries while controlling the FDR at the desired level.	experiment;false discovery rate;marginal model;microarray;one-way function;simulation	Sin-Ho Jung;Insuk Sohn;Stephen L. George;Liping Feng;Phyllis C. Leppert	2008	BMC Bioinformatics	10.1186/1471-2105-10-164	computer simulation;sample size determination;biology;microarray analysis techniques;molecular biology;false discovery rate;gene expression;dna microarray;analysis of variance;computer science;bioinformatics;gene expression profiling;cluster analysis;average treatment effect;genetics;effect size	Comp.	5.029441659744024	-53.18430822290993	65333
1872c2a0bb94d04a8ccf738a4f0f16e3c1e77cc3	codon-based sequence alignment for mutation analysis by high-throughput sequencing		The advance of high-throughput sequencing has made it possible to perform large-scale mutation analysis by altering codons on a sequence and investigating the effect of the changes. While sequence alignment algorithms can be applied to compare the reads to the original unaltered sequence, neither nucleotide-based nor protein-based alignment is completely suitable for analyzing changes at the codon level.We develop a codon-based sequence alignment algorithm by modifying the dynamic programming equations so that an exact match of three letters in a codon is assigned a positive score, a mismatch of at least one letter in a codon is assigned a negative score, and an indel of either one, two or three letters is assigned a constant negative score. This strategy models what could happen within each codon directly. It has the same time complexity as the nucleotide-based dynamic programming algorithm.We apply our algorithm to analyze the effect of mutations within the RNA Polymerase II trigger loop from high-throughput sequencing libraries that we have generated in our lab. We compare our results to the ones obtained with nucleotide-based alignment. We show that our algorithm is able to avoid systematic errors that could be made with nucleotide-based alignment.	algorithm;dynamic programming;high-throughput computing;library (computing);mutation testing;sequence alignment;throughput;time complexity	Sing-Hoi Sze;Craig D Kaplan	2018	2018 IEEE 8th International Conference on Computational Advances in Bio and Medical Sciences (ICCABS)	10.1109/ICCABS.2018.8542085		Comp.	-0.21060559814324092	-55.211732928314774	65470
91ccb7dacba19e970570f1d7cf1e49c996120fd7	recognition of eukaryotic promoters using a genetic algorithm based on iterative discriminant analysis	discriminant analysis;genetic algorithm	A new approach to recognizing promoter regions of eukaryotic genes is proposed and illustrated by an example of Drosophila melanogaster. The essence of its novelty is in realizing the genetic algorithm to search for optimal partition of a promoter region into local nonoverlapping fragments and selection of the most significant dinucleotide frequencies for the fragments obtained. The method developed was applied to recognizing TATA-containing (TATA+) and DPE-containing (DPE+) promoters of Drosophila melanogaster genes. The program for promoter recognition is included into the GeneExpress system, section RegScan (http://wwwmgs.bionet.nsc.ru/mgs/programs/proga/).	amine oxidase (copper-containing);dinucleoside phosphates;genetic algorithm;iterative method;linear discriminant analysis;promoter regions, genetic	Victor G. Levitsky;Alexey V. Katokhin	2003	In silico biology		promoter;genetic algorithm;gene;genetics;novelty;bioinformatics;drosophila melanogaster;linear discriminant analysis;biology	Comp.	2.8213766482718357	-63.27958460972101	65536
9ec2d4fc70864d68ac5a5df14889d3af80fc1dbe	an improved algorithm on detecting transcription and translation motif in archaeal genomic sequences	gibbs sampler;binding site;position weight matrix;difference set;computational biology;genome sequence	Identifying the binding sites and promoters in the genomes remains one of the most research topics in computational biology in past ten years. In the upstream region of the start codon, there exist transcription and translation motifs whose distances and patterns vary among different genomic sequences. However, the existing computational approaches for detecting them are mostly general-purpose. For archaea, binding motifs are almost undiscovered as they are more hidden than bacteria or eukaryotes. In this report, an improved algorithm based on PWM (position-weight matrix) and Gibbs Sampler was proposed for finding any number of patterns in a given range. Experiments using this algorithm were done to detect the potential binding motifs in archaeal genomic sequences, and the results were analyzed among different settings and species. The comparison with biological experiments result shows that the improved algorithm is feasible to find more significant patterns for archaea than the traditional approaches.	algorithm;medical transcription;motif;sensor	Minghui Wu;Xian Chen;Fanwei Zhu;Jing Ying	2007		10.1007/978-3-540-74771-0_23	biology;bioinformatics;genetics	Comp.	0.3172041212711609	-53.654698214172235	65539
1f9fa98ccb9893d6d17534bf2efc108c71caafc0	inmode: tools for learning and visualizing intra-motif dependencies of dna binding sites		Summary Recent studies have shown that the traditional position weight matrix model is often insufficient for modeling transcription factor binding sites, as intra-motif dependencies play a significant role for an accurate description of binding motifs. Here, we present the Java application InMoDe, a collection of tools for learning, leveraging and visualizing such dependencies of putative higher order. The distinguishing feature of InMoDe is a robust model selection from a class of parsimonious models, taking into account dependencies only if justified by the data while choosing for simplicity otherwise.   Availability and Implementation InMoDe is implemented in Java and is available as command line application, as application with a graphical user-interface, and as an integration into Galaxy on the project website at http://www.jstacs.de/index.php/InMoDe .   Contact ralf.eggeling@cs.helsinki.fi.		Ralf Eggeling;Ivo Grosse;Jan Grau	2017		10.1093/bioinformatics/btw689	bioinformatics	Comp.	-0.17163120482316166	-57.66159213537359	65628
d1685cf772f0ae1190bbc3e88e8bd951decb279e	improving protein conformational sampling by using guiding projections	proteins biological techniques molecular biophysics path planning;proteins;exploration process protein conformational sampling guiding projection sampling based motion planning algorithms protein conformational space degrees of freedom standard robotic approaches low dimensional projection molecular system expert projection	"""Sampling-based motion planning algorithms from the field of robotics have been very successful in exploring the conformational space of proteins. However, studying the flexibility of large proteins with hundreds or thousands of Degrees of Freedom (DoFs) remains a big challenge. Large proteins are also highly-constrained systems, which makes them more challenging for standard robotic approaches. So-called """"expansive"""" motion planning algorithms were specifically developed to address highly-dimensional and highly-constrained problems. Many such planners employ a low-dimensional projection to estimate exploration coverage and direct their search based on this information. We believe that such a projection plays an essential role in the success of these planners. This paper shows how the low-dimensional projection used by expansive planners can be tailored with respect to a given molecular system to enhance the process of conformational sampling. We introduce a methodology to generate an expert projection using any available information about a given protein. We evaluate this methodology on several conformational search problems involving proteins with hundreds of DoFs. Our experiments demonstrate that incorporating expert knowledge into the projection can significantly benefit the exploration process."""	algorithm;automated planning and scheduling;experiment;gene regulatory network;graph theory;motion planning;principal component analysis;randomness;robot;robotics;sampling (signal processing);the sims	Anastasia Novinskaya;Didier Devaurs;Mark Moll;Lydia E. Kavraki	2015	2015 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2015.7359863	biology;computer vision;mathematical optimization;fox proteins;bioinformatics;mathematics;genetics	Robotics	8.717022185231615	-58.581286286577324	65635
012291b1bca42d8524d53b8cb4eeb4107fa13af4	the hts barcode checker pipeline, a tool for automated detection of illegally traded species from high-throughput sequencing data	software;internationality;databases nucleic acid;classification;computational biology bioinformatics;medicine chinese traditional;endangered species;algorithms;combinatorial libraries;computer appl in life sciences;dna barcoding taxonomic;drugs chinese herbal;microarrays;bioinformatics	Mixtures of internationally traded organic substances can contain parts of species protected by the Convention on International Trade in Endangered Species of Wild Fauna and Flora (CITES). These mixtures often raise the suspicion of border control and customs offices, which can lead to confiscation, for example in the case of Traditional Chinese medicines (TCMs). High-throughput sequencing of DNA barcoding markers obtained from such samples provides insight into species constituents of mixtures, but manual cross-referencing of results against the CITES appendices is labor intensive. Matching DNA barcodes against NCBI GenBank using BLAST may yield misleading results both as false positives, due to incorrectly annotated sequences, and false negatives, due to spurious taxonomic re-assignment. Incongruence between the taxonomies of CITES and NCBI GenBank can result in erroneous estimates of illegal trade. The HTS barcode checker pipeline is an application for automated processing of sets of ‘next generation’ barcode sequences to determine whether these contain DNA barcodes obtained from species listed on the CITES appendices. This analytical pipeline builds upon and extends existing open-source applications for BLAST matching against the NCBI GenBank reference database and for taxonomic name reconciliation. In a single operation, reads are converted into taxonomic identifications matched with names on the CITES appendices. By inclusion of a blacklist and additional names databases, the HTS barcode checker pipeline prevents false positives and resolves taxonomic heterogeneity. The HTS barcode checker pipeline can detect and correctly identify DNA barcodes of CITES-protected species from reads obtained from TCM samples in just a few minutes. The pipeline facilitates and improves molecular monitoring of trade in endangered species, and can aid in safeguarding these species from extinction in the wild. The HTS barcode checker pipeline is available at https://github.com/naturalis/HTS-barcode-checker .	blast;barcode;bibliographic database;biopolymer sequencing;chamaecyparis lawsoniana;cross-reference;dna barcoding;estimated;genbank;genetic heterogeneity;high-throughput computing;high-throughput satellite;hypotrichosis simplex;matching;medicine, east asian traditional;ncbi taxonomy;name;national center for biotechnology information;open-source software;reading (activity);saline solution, hypertonic;throughput;mixture;negative regulation of reactive oxygen species biosynthetic process	Youri Lammers;Tamara Peelen;Rutger A. Vos	2013		10.1186/1471-2105-15-44	biology;dna microarray;biological classification;biotechnology;bioinformatics;endangered species;genetics	Embedded	-1.0789551989792705	-61.86578174701411	65926
02ca63a8d30d26128752281f09779f1ed19ef617	merav: a tool for comparing gene expression across human tissues and cell types	genes;software;metabolic networks and pathways;databases genetic;gene expression;cell function;internet;cell line tumor;genome;humans;neoplasms;article;tumor progression;gene expression profiling;oligonucleotide array sequence analysis;metabolism;tumor cells malignant;cell line	The oncogenic transformation of normal cells into malignant, rapidly proliferating cells requires major alterations in cell physiology. For example, the transformed cells remodel their metabolic processes to supply the additional demand for cellular building blocks. We have recently demonstrated essential metabolic processes in tumor progression through the development of a methodological analysis of gene expression. Here, we present the Metabolic gEne RApid Visualizer (MERAV, http://merav.wi.mit.edu), a web-based tool that can query a database comprising ∼4300 microarrays, representing human gene expression in normal tissues, cancer cell lines and primary tumors. MERAV has been designed as a powerful tool for whole genome analysis which offers multiple advantages: one can search many genes in parallel; compare gene expression among different tissue types as well as between normal and cancer cells; download raw data; and generate heatmaps; and finally, use its internal statistical tool. Most importantly, MERAV has been designed as a unique tool for analyzing metabolic processes as it includes matrixes specifically focused on metabolic genes and is linked to the Kyoto Encyclopedia of Genes and Genomes pathway search.	access network;aggregate data;biological science disciplines;body tissue;cell physiology;color gradient;cultured cell line;download;encyclopedias;gene expression;gene regulatory network;genes, vif;genome;heat map;histocompatibility testing;kegg;metabolic process, cellular;metabolism;microarray;my life as a teenage robot;nar 2;neoplasms;non-small cell lung carcinoma;promotion (action);repository;tumor progression;united states national institutes of health;web application;cancer cell;cell type;eric;physiological aspects;primary tumor	Yoav D. Shaul;Bingbing Yuan;Prathapan Thiru;Andy Nutter-Upham;Scott McCallum;Carolyn Lanzkron;George W. Bell;David M. Sabatini	2016		10.1093/nar/gkv1337	biology;molecular biology;the internet;gene expression;bioinformatics;gene;gene expression profiling;genetics;metabolism;cell culture;genome	Comp.	-1.0150019278281597	-61.451843611997134	66038
dbe3b63184d9bd32fbb77950d16aaff9448e4cb5	multiplex sequencing by hybridization	pooling strategies;dna array;sequencing by hybridization	"""One of the limitations of classical sequencing by hybridization (SBH) is the inefficient use of probes in the """"all k-mers"""" array. This limitation occurs due to the relatively short length (roughly the square root of C) of target that may be reconstructed by an array with C probes. We propose a new strategy, multiplex sequencing by hybridization, that greatly increases the efficiency of target reconstruction. In the typical multiplex SBH method, many different target sequences are simultaneously reconstructed (as compared to a single sequence in classic SBH). This is accomplished by pooling the target sequences and performing several hybridization experiments. This procedure makes more efficient use of probes so that the combined length of sequence reconstructed per DNA array increases significantly as compared to classical SBH."""		Earl Hubbell	2001	Journal of computational biology : a journal of computational molecular cell biology	10.1089/106652701300312913	sequencing by hybridization;biology;molecular biology;dna microarray;bioinformatics;genetics	Comp.	-0.3591190459279423	-53.47073588461863	66062
692f749553a9a535a78d35c0d0cec40b999b6647	regmex: a statistical tool for exploring motifs in ranked sequence lists from genomics experiments		Motif analysis methods have long been central for studying biological function of nucleotide sequences. Functional genomics experiments extend their potential. They typically generate sequence lists ranked by an experimentally acquired functional property such as gene expression or protein binding affinity. Current motif discovery tools suffer from limitations in searching large motif spaces, and thus more complex motifs may not be included. There is thus a need for motif analysis methods that are tailored for analyzing specific complex motifs motivated by biological questions and hypotheses rather than acting as a screen based motif finding tool. We present Regmex (REGular expression Motif EXplorer), which offers several methods to identify overrepresented motifs in ranked lists of sequences. Regmex uses regular expressions to define motifs or families of motifs and embedded Markov models to calculate exact p-values for motif observations in sequences. Biases in motif distributions across ranked sequence lists are evaluated using random walks, Brownian bridges, or modified rank based statistics. A modular setup and fast analytic p value evaluations make Regmex applicable to diverse and potentially large-scale motif analysis problems. We demonstrate use cases of combined motifs on simulated data and on expression data from micro RNA transfection experiments. We confirm previously obtained results and demonstrate the usability of Regmex to test a specific hypothesis about the relative location of microRNA seed sites and U-rich motifs. We further compare the tool with an existing motif discovery tool and show increased sensitivity. Regmex is a useful and flexible tool to analyze motif hypotheses that relates to large data sets in functional genomics. The method is available as an R package (https://github.com/muhligs/regmex).		Morten Muhlig Nielsen;Paula Tataru;Tobias Madsen;Asger Hobolth;Jakob Skou Pedersen	2018		10.1186/s13015-018-0135-2	function (biology);motif (music);computational biology;genetics;functional genomics;genomics;computer science;plasma protein binding;ranking	Comp.	2.351613035171018	-54.21871289267603	66143
ed49f091ea688496b0a8abfc805cc24dd165033f	gene selection and clustering for time-course and dose–response microarray experiments using order-restricted inference	breast cancer cells;ordered set;time course;statistical significance;gene expression data;cdna microarray;dose response;gene selection	We propose an algorithm for selecting and clustering genes according to their time-course or dose-response profiles using gene expression data. The proposed algorithm is based on the order-restricted inference methodology developed in statistics. We describe the methodology for time-course experiments although it is applicable to any ordered set of treatments. Candidate temporal profiles are defined in terms of inequalities among mean expression levels at the time points. The proposed algorithm selects genes when they meet a bootstrap-based criterion for statistical significance and assigns each selected gene to the best fitting candidate profile. We illustrate the methodology using data from a cDNA microarray experiment in which a breast cancer cell line was stimulated with estrogen for different time intervals. In this example, our method was able to identify several biologically interesting genes that previous analyses failed to reveal.	cluster analysis;dna, complementary;estrogens;experiment;gene expression;genetic selection;inference;leukemia, b-cell;mammary neoplasms;microarray;p-value;algorithm;cancer cell;statistical cluster	Shyamal D. Peddada;Edward K. Lobenhofer;Leping Li;Cynthia A. Afshari;Clarice R. Weinberg;David M. Umbach	2003	Bioinformatics	10.1093/bioinformatics/btg093	gene-centered view of evolution;biology;dose–response relationship;bioinformatics;data mining;statistical significance;genetics	Comp.	5.665113970095383	-54.19948741357578	66159
6d1d4939eafb8b13c0507c6b200d23e0ff3fc24e	the sbase protein domain library, release 5.0: a collection of annotated protein sequence segments	protein domains;protein sequence	SBASE 5.0 is the fifth release of SBASE, a collection of annotated protein domain sequences that represent various structural, functional, ligand-binding and topogenic segments of proteins. SBASE was designed to facilitate the detection of functional homologies and can be searched with standard database-search programs. The present release contains over 79863 entries provided with standardized names and is cross-referenced to all major sequence databases and sequence pattern collections. The information is assigned to individual domains rather than to entire protein sequences, thus SBASE contains substantially more cross-references and links than do the protein sequence databases. The entries are clustered into >16 000 groups in order to facilitate the detection of distant similarities. SBASE 5.0 is freely available by anonymous 'ftp' file transfer from <ftp.icgeb.trieste.it >. Automated searching of SBASE with BLAST can be carried out with the WWW-server <http://www.icgeb.trieste.it/sbase/ >. and with the electronic mail server <sbase@icgeb.trieste.it >which now also provides a graphic representation of the homologies. A related WWW-server <http://www.abc.hu/blast.html > and e-mail server <domain@hubi.abc.hu > predicts SBASE domain homologies on the basis of SWISS-PROT searches.		Péter Fábián;János Murvai;Zsolt Hátsági;Kristian Vlahovicek;Hedvig Hegyi;Sándor Pongor	1997	Nucleic acids research	10.1093/nar/25.1.240		Comp.	-2.0245234831136054	-60.205684135306456	66162
26387dd1cf52cc458fb1b0b6676f45d15b50860e	multiple conformational states in retrospective virtual screening – homology models vs. crystal structures: beta-2 adrenergic receptor case study	biological patents;biomedical journals;text mining;europe pubmed central;citation search;computer applications in chemistry;citation networks;theoretical and computational chemistry;computational biology bioinformatics;research articles;abstracts;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;documentation and information in chemistry;biomedical research;bioinformatics;literature search	BACKGROUND Distinguishing active from inactive compounds is one of the crucial problems of molecular docking, especially in the context of virtual screening experiments. The randomization of poses and the natural flexibility of the protein make this discrimination even harder. Some of the recent approaches to post-docking analysis use an ensemble of receptor models to mimic this naturally occurring conformational diversity. However, the optimal number of receptor conformations is yet to be determined. In this study, we compare the results of a retrospective screening of beta-2 adrenergic receptor ligands performed on both the ensemble of receptor conformations extracted from ten available crystal structures and an equal number of homology models. Additional analysis was also performed for homology models with up to 20 receptor conformations considered.   RESULTS The docking results were encoded into the Structural Interaction Fingerprints and were automatically analyzed by support vector machine. The use of homology models in such virtual screening application was proved to be superior in comparison to crystal structures. Additionally, increasing the number of receptor conformational states led to enhanced effectiveness of active vs. inactive compounds discrimination.   CONCLUSIONS For virtual screening purposes, the use of homology models was found to be most beneficial, even in the presence of crystallographic data regarding the conformational space of the receptor. The results also showed that increasing the number of receptors considered improves the effectiveness of identifying active compounds by machine learning methods. Graphical abstractComparison of machine learning results obtained for various number of beta-2 AR homology models and crystal structures.	adrenergic receptor;boat dock;crystal structure;docking (molecular);docking -molecular interaction;experiment;extraction;fingerprint;homologous gene;homology (biology);homology modeling;ligands;machine learning;physical inactivity;support vector machine;virtual screening;beta-2 adrenergic receptors	Stefan Mordalski;Jagna Witek;Sabina Smusz;Krzysztof Rataj;Andrzej J. Bojarski	2015		10.1186/s13321-015-0062-x	biology;text mining;medical research;medicine;computer science;bioinformatics;data science;data mining	Comp.	9.96249373046469	-57.29330532064438	66177
caaf3d70b2933d97ee2d2a83c1c3b0936ca87084	combining probabilistic alignments with read pair information improves accuracy of split-alignments		Motivation Split-alignments provide base-pair-resolution evidence of genomic rearrangements. In practice, they are found by first computing high-scoring local alignments, parts of which are then combined into a split-alignment. This approach is challenging when aligning a short read to a large and repetitive reference, as it tends to produce many spurious local alignments leading to ambiguities in identifying the correct split-alignment. This problem is further exacerbated by the fact that rearrangements tend to occur in repeat-rich regions.   Results We propose a split-alignment technique that combats the issue of ambiguous alignments by combining information from probabilistic alignment with positional information from paired-end reads. We demonstrate that our method finds accurate split-alignments, and that this translates into improved performance of variant-calling tools that rely on split-alignments.   Availability and implementation An open-source implementation is freely available at: https://bitbucket.org/splitpairedend/last-split-pe.   Supplementary information Supplementary data are available at Bioinformatics online.	alignment;bioinformatics;bitbucket;dna sequence rearrangement;geographic information systems;open-source software;reading (activity);score	Anish Man Singh Shrestha;Naruki Yoshikawa;Kiyoshi Asai	2018		10.1093/bioinformatics/bty398	data mining;probabilistic logic;computer science;artificial intelligence;pattern recognition	Comp.	0.40402169749599576	-54.35101294135693	66190
25dae505bdaa6941a9ed1d04bdae036b7babbf3b	modeling heterogeneous responsiveness of intrinsic apoptosis pathway	apoptosis;simulation and modeling;extrinsic noise;systems biology;intrinsic apoptosis pathway;signal transduction;physiological cellular and medical topics;models biological;computational biology bioinformatics;stochastic processes;algorithms;stochastic model;intrinsic noise;bioinformatics	Apoptosis is a cell suicide mechanism that enables multicellular organisms to maintain homeostasis and to eliminate individual cells that threaten the organism’s survival. Dependent on the type of stimulus, apoptosis can be propagated by extrinsic pathway or intrinsic pathway. The comprehensive understanding of the molecular mechanism of apoptotic signaling allows for development of mathematical models, aiming to elucidate dynamical and systems properties of apoptotic signaling networks. There have been extensive efforts in modeling deterministic apoptosis network accounting for average behavior of a population of cells. Cellular networks, however, are inherently stochastic and significant cell-to-cell variability in apoptosis response has been observed at single cell level. To address the inevitable randomness in the intrinsic apoptosis mechanism, we develop a theoretical and computational modeling framework of intrinsic apoptosis pathway at single-cell level, accounting for both deterministic and stochastic behavior. Our deterministic model, adapted from the well-accepted Fussenegger model, shows that an additional positive feedback between the executioner caspase and the initiator caspase plays a fundamental role in yielding the desired property of bistability. We then examine the impact of intrinsic fluctuations of biochemical reactions, viewed as intrinsic noise, and natural variation of protein concentrations, viewed as extrinsic noise, on behavior of the intrinsic apoptosis network. Histograms of the steady-state output at varying input levels show that the intrinsic noise could elicit a wider region of bistability over that of the deterministic model. However, the system stochasticity due to intrinsic fluctuations, such as the noise of steady-state response and the randomness of response delay, shows that the intrinsic noise in general is insufficient to produce significant cell-to-cell variations at physiologically relevant level of molecular numbers. Furthermore, the extrinsic noise represented by random variations of two key apoptotic proteins, namely Cytochrome C and inhibitor of apoptosis proteins (IAP), is modeled separately or in combination with intrinsic noise. The resultant stochasticity in the timing of intrinsic apoptosis response shows that the fluctuating protein variations can induce cell-to-cell stochastic variability at a quantitative level agreeing with experiments. Finally, simulations illustrate that the mean abundance of fluctuating IAP protein is positively correlated with the degree of cellular stochasticity of the intrinsic apoptosis pathway. Our theoretical and computational study shows that the pronounced non-genetic heterogeneity in intrinsic apoptosis responses among individual cells plausibly arises from extrinsic rather than intrinsic origin of fluctuations. In addition, it predicts that the IAP protein could serve as a potential therapeutic target for suppression of the cell-to-cell variation in the intrinsic apoptosis responsiveness.	apoptosis;biochemical reaction;bistability;cell signaling;dynamical system;experiment;gene regulatory network;genetic heterogeneity;heart rate variability;hereditary diseases;homeostasis;mathematical model;mathematics;microtransaction;positive feedback;randomness;responsiveness;resultant;scsi initiator and target;simulation;steady state;therapeutic targets database;whole earth 'lectronic link;zero suppression;apoptotic signaling pathway;inhibitor-of-apoptosis protein	Hsu Kiang Ooi;Lan Ma	2012		10.1186/1752-0509-7-65	biology;cell biology;bioinformatics;apoptosis;stochastic modelling;systems biology;signal transduction	ML	7.229500483116871	-65.35821466431288	66317
4b2bbd15d9bb5035636cb7b6b79d694073658955	selection for replicases in protocells	evolution molecular;cell division analysis;cell cycle and cell division;biochemical phenomena;vesicles;ribozymes;biochemical processes;parasite evolution;models biological;biology;selection genetic;journal article;nucleotidyltransferases;evolutionary modeling;origin of life;natural selection;point mutation;cell division;computational biology;biogenesis;artificial cells	We consider a world of nucleotide sequences and protocells. The sequences have the property of spontaneous self-replication. Some sequences - so-called replicases - have enzymatic activity in the sense of enhancing the replication rate of all (or almost all) sequences. In a well-mixed medium, natural selection would not favor such replicases because their presence equally benefits sequences with or without replicase activity. Here we show that protocells can select for replicases. We assume that sequences replicate within protocells and that protocells undergo spontaneous division. This leads to particular population structures which can augment the abundance of replicases. We explore various assumptions regarding replicase activity and protocell division. We calculate the error threshold that is compatible with selecting for replicases.	genetic selection;natural selection;nucleotides;protocell;protocells;self-replication;spontaneous order;benefit;replicase	Ginestra Bianconi;Kun Zhao;Irene A. Chen;Martin A. Nowak	2013		10.1371/journal.pcbi.1003051	point mutation;biology;natural selection;vesicle;cell biology;abiogenesis;ribozyme;bioinformatics;biogenesis;genetics;cell division	Crypto	5.800389777320577	-63.1353298936655	66375
ae08ee23077d04fe84961eea5c793252055c2bca	genomic database resources for dictyostelium discoideum	forecasting;animals;sequence homology;model system;amino acid sequence;databases genetic;chromosome mapping;spectrum;relational database;internet;gene expression regulation developmental;dna protozoan;dictyostelium discoideum;dictyostelium;genome protozoan;base sequence;information storage and retrieval;protozoan proteins;genes protozoan;genome sequence	Dictyostelium is an attractive model system for the study of mechanisms basic to cellular function or complex multicellular developmental processes. Recent advances in Dictyostelium genomics have generated a wide spectrum of resources. However, much of the current genomic sequence information is still not currently available through GenBank or related databases. Thus, many investigators are unaware that extensive sequence data from Dictyostelium has been compiled, or of its availability and access. Here, we discuss progress in Dictyostelium genomics and gene annotation, and highlight the primary portals for sequence access, manipulation and analysis (http://genome.imb-jena.de/dictyostelium/; http://dictygenome.bcm.tmc.edu/; http://www.sanger. ac.uk/Projects/D_discoideum/; http://www.csm.biol. tsukuba.ac.jp/cDNAproject.html).	biological database;cell physiology;compiler;genbank;gene annotation;genomics;portals	Lisa Kreppel;Alan R. Kimmel	2002	Nucleic acids research	10.1093/nar/30.1.84	biology;spectrum;whole genome sequencing;the internet;forecasting;relational database;bioinformatics;peptide sequence;dictybase;genetics	DB	-1.1682143412954982	-60.668877018326846	66611
844211e6603dfa5b5c2e3de9514f04e1b97288f3	precedence temporal networks to represent temporal relationships in gene expression data	dna microarrays;gene expression data;time series;cell cycle regulation;gene expression;temporal abstraction;association rule;temporal pattern;dictyostelium discoideum;cell cycle;dna microarray;temporal data mining;gene regulatory network;temporal networks;temporal association rules	The reconstruction of gene regulatory networks from gene expression time series is nowadays an interesting research challenge. A key problem in this kind of analysis is the automated extraction of precedence and synchronization between interesting patterns assumed by genes over time. The present work introduces Precedence Temporal Networks (PTN), a novel method to extract and visualize temporal relationships between genes. PTNs are a special kind of temporal network where nodes represent temporal patterns while edges identify precedence or synchronization relationships between the nodes. The method is tested on two case studies: the expression of a subset of genes in the soil amoeba Dictyostelium discoideum and of a set of well-studied genes involved in the human cell cycle regulation. The extracted networks reflect the capability of the algorithm to clearly reconstruct the timing of the considered gene sets, highlighting different stages in Dictyostelium development and in the cell cycle, respectively.	amoeba genus;assumed;causal filter;cell cycle control;cluster analysis;default;dental restoration, temporary;epilepsy, temporal lobe;extraction;gene expression;gene regulatory network;graphical user interface;interface device component;molecular dynamics;programming tool;published comment;rule induction;serializability;subgroup;thermal-assisted switching;time series;trial arms domain;usability;algorithm;cytarabine/thioguanine;statistical cluster	Lucia Sacchi;Cristiana Larizza;Paolo Magni;Riccardo Bellazzi	2007	Journal of biomedical informatics	10.1016/j.jbi.2007.06.003	dna microarray;bioinformatics;cell cycle;data mining;genetics	Comp.	3.649027705307356	-57.03544037021856	67041
0ed06c6a88d4e0f7a12b2f37ac41b5ee7b8cd6f8	towards enabling the semantic access of phenotypic information in clinical letters		Over the past 3 years there has been a massive growth in genetic testing both in terms of the scope of testing and the numbers of individuals offered genetic testing. Targeted sequencing of small genomic regions has been replaced by panel testing, whole exome sequencing and most recently whole genome sequencing [4]. Furthermore, genetic testing in research, but also clinical settings has extended beyond small numbers of selected individuals with very rare, highly-defined disorders to cover larger populations. While this information presents new clinical opportunities and opens the way for development of novel therapies, it also presents major challenges. For clinicians, reliable identification of disease-associated genetic variants from amongst the broader background of variants present in all human genomes that are rare, but not actually pathogenic, is a concern. It is likely that for many rare genetic disorders obtaining clarity will require a worldwide effort and so the ability to capture and share key clinical information, as well as genetic information, is becoming increasingly important. However, at present there are major challenges with regard to the collection and storage of clinical information, particularly in the context of rare genetic disorders. The process of studying a patient with a possible rare genetic disorder typically involves many different clinical specialists with no “standard” patient route. During this process, it is very common to refer from one specialist to another in order to obtain a range of opinions and access different tests. The output of this process is usually clinical letters which are used both to document the patient’s progress and communicate findings between specialists (e.g. patient history, examination findings, investigation results and clinical impression). Since clinical letters are a key source of knowledge, their proper annotation and storage would enable access to the information they contain in a systematic way. Currently, the creation and processing of clinical letters requires the following steps: 1. Letters are dictated using a speech recognition system by the clinician. 2. The recording is uploaded to a server. 3. The voice data is transcribed using another application. 4. The text is downloaded and checked by qualified personnel. 5. The letter is tagged manually by a specialist responsible for reading and annotating the interesting terms.	genetic algorithm;population;server (computing);speech recognition;whole genome sequencing	Shahad Kudama;Rafael Berlanga Llavori;Henry Houlden;Ernesto Jiménez-Ruiz;Hallgeir Jonvik;Adam Milward;Huw Morris;Mina Ryten;Jake R Saklatvala;Michael Simpson;Nicholas Wood	2015			computer science;knowledge management;data mining;information retrieval	ML	-3.103382925448238	-63.99249254326368	67083
9380e1e9536a8da2a8bfb363be2fbb6a766e1c4b	mhcbn: a comprehensive database of mhc binding and non-binding peptides	qh301 biology	MHCBN is a comprehensive database of Major Histocompatibility Complex (MHC) binding and non-binding peptides compiled from published literature and existing databases. The latest version of the database has 19 777 entries including 17 129 MHC binders and 2648 MHC non-binders for more than 400 MHC molecules. The database has sequence and structure data of (a) source proteins of peptides and (b) MHC molecules. MHCBN has a number of web tools that include: (i) mapping of peptide on query sequence; (ii) search on any field; (iii) creation of data sets; and (iv) online data submission. The database also provides hypertext links to major databases like SWISS-PROT, PDB, IMGT/HLA-DB, GenBank and PUBMED.	compiler;database;emoticon;genbank;hypertext;major histocompatibility complex;model of hierarchical complexity;protein data bank;pubmed;regulatory submission;swiss-model;scientific publication;switzerland	Manoj Bhasin;Harpreet Singh;Gajendra P. S. Raghava	2003	Bioinformatics	10.1093/bioinformatics/btg055	biology;computer science;bioinformatics;data mining;world wide web	DB	-1.8297016373668453	-60.6591887152992	67101
89123bf4af41e212376ef3c063a550a8fb87e855	performance characterization of blast for the grid	level of service;biology computing;new technology;sequences databases grid computing performance analysis biology computing bioinformatics information analysis dna costs application software;job search;protein database;genetics;performance characterization;proteins;performance trade off;protein database blast basic local alignment search tool bioinformatics application query searches biological data analysis grid computing genomic sequences;job performance;blast;molecular biophysics;biological data analysis;benchmarks;benchmarks performance trade off similarity search genomic sequences sequence database;query searches;biological data;sequence database;grid computing;genomic sequences;proteins biology computing genetics grid computing molecular biophysics;basic local alignment search tool;similarity search;genome sequence;bioinformatics application	BLAST is a commonly used bioinformatics application for performing query searches and analysis of biological data. As the amount of search data increases so does job search times. As means of reducing job turnaround times, scientists are resorting to new technologies such as grid computing to obtain needed computational and storage resources. Inherent with advent of new technologies, are additional complexities that arise, forcing scientists to deal with them. Grid computing exemplifies dynamic and transient state of heterogeneous resources that become a major obstacle in realizing user-desired levels of service. Many users do not realize that techniques applied in more traditional cluster environments do not simply transition into grid environment. This paper analyzes resource and application dependencies for BLAST in terms of job parameters that result in performance tradeoffs. We present a set of examples showing performance variability and point out a set of guidelines, which lead to establishing job performance tradeoffs.	blast;bioinformatics;grid computing;heart rate variability;software performance testing;transient state	Enis Afgan;Purushotham Bangalore	2007	2007 IEEE 7th International Symposium on BioInformatics and BioEngineering	10.1109/BIBE.2007.4375754	biology;whole genome sequencing;biological data;computer science;bioinformatics;data science;job performance;sequence database;data mining;level of service;genetics;grid computing;molecular biophysics	HPC	-2.709327665393202	-53.7787692952987	67240
49488ff893dd455dce110594c1d1dd9856324f0a	exploring alternative transcript structure in the humangenome using blocks and interpro	interpro;alternative splicing;cd79b;aire;blocks;meox1;visualization;plat	Understanding how alternative splicing affects gene function is an important challenge facing modern-day molecular biology. Using homology-based, protein sequence analysis methods, it should be possible to investigate how transcript diversity impacts protein function. To test this, high-quality exon-intron structures were deduced for over 8000 human genes, including over 1300 (17 percent) that produce multiple transcript variants. A data mining technique (DiffMotif) was developed to identify genes in which transcript variation coincides with changes in conserved motifs between variants. Applying this method, we found that 30 percent of the multi-variant genes in our test set exhibited a differential profile of conserved InterPro and/or BLOCKS motifs across different mRNA variants. To investigate these, a visualization tool (ProtAnnot) that displays amino acid motifs in the context of genomic sequence was developed. Using this tool, genes revealed by the DiffMotif method were analyzed, and when possible, hypotheses regarding the potential role of alternative transcript structure in modulating gene function were developed. Examples of these, including: MEOX1, a homeobox-containing protein; AIRE, involved in auto-immune disease; PLAT, tissue type plasminogen activator; and CD79b, a component of the B-cell receptor complex, are presented. These results demonstrate that amino acid motif databases like BLOCKS and InterPro are useful tools for investigating how alternative transcript structure affects gene function.	alternative splicing;amino acid sequence;amino acids;antigens, cd79b;chronic lymphocytic leukemia;data mining;database;databases;histocompatibility testing;homeo box sequence;homologous gene;homology (biology);immune system diseases;interpro;introns;leukemia, b-cell;molecular biology;motif;numerous;plasminogen activator;sequence analysis;test set;transcript;alteplase	Ann E. Loraine;Gregg A. Helt;Melissa S. Cline;Michael A. Siani-Rose	2003	Journal of bioinformatics and computational biology	10.1142/S0219720003000113	plat;biology;molecular biology;visualization;blocks;computer science;bioinformatics;alternative splicing;genetics;interpro	Comp.	3.8543547853864837	-60.008840022625385	67306
38af176e6a5f257e1921f4837d90412909602cfc	a new model of time scheme for progression of colorectal cancer	simulation and modeling;disease progression;pancreatic neoplasms;systems biology;tumor burden;physiological cellular and medical topics;models biological;computational biology bioinformatics;time factors;algorithms;humans;carcinogenesis;mutation;colorectal neoplasms;bioinformatics	tumourigenesis can be regarded as an evolutionary process, in which the transformation of a normal cell into a tumour cell involves a number of limiting genetic and epigenetic events. To study the progression process, time schemes have been proposed for studying the process of colorectal cancer based on extensive clinical investigations. Moreover, a number of mathematical models have been designed to describe this evolutionary process. These models assumed that the mutation rate of genes is constant during different stages. However, it has been pointed that the subsequent driver mutations appear faster than the previous ones and the cumulative time to have more driver mutations grows with the growing number of gene mutations. Thus it is still a challenge to calculate the time when the first mutation occurs and to determine the influence of tumour size on the mutation rate. In this work we present a general framework to remedy the shortcoming of existing models. Rather than considering the information of gene mutations based on a population of patients, we for the first time determine the values of the selective advantage of cancer cells and initial mutation rate for individual patients. The averaged values of doubling time and selective advantage coefficient determined by our model are consistent with the predictions made by the published models. Our calculation showed that the values of biological parameters, such as the selective advantage coefficient, initial mutation rate and cell doubling time diversely depend on individuals. Our model has successfully predicted the values of several important parameters in cancer progression, such as the selective advantage coefficient, initial mutation rate and cell doubling time. In addition, experimental data validated our predicted initial mutation rate and cell doubling time. The introduced new parameter makes our proposed model more flexible to fix various types of information based on different patients in cancer progression.	assumed;cell (microprocessor);cell signaling;coefficient;color gradient;colorectal carcinoma;doubling;mathematical model;mathematics;mutation;neoplasms;non-small cell lung carcinoma;patients;population parameter;scientific publication;tumor progression;cancer cell;study of epigenetics	Shuhao Sun;Fima C. Klebaner;Tianhai Tian	2014		10.1186/1752-0509-8-S3-S2	mutation;biology;bioinformatics;genetics;systems biology;carcinogenesis	Comp.	9.039192166143062	-65.77003352977974	67427
601396ea6068193501ac339b589f362d7848caf2	modeling activated states of gpcrs: the rhodopsin template	normal mode;active conformation;distance constraint;normal mode analysis;zinc binding site	Activation of G Protein-Coupled Receptors (GPCRs) is an allosteric mechanism triggered by ligand binding and resulting in conformational changes transduced by the transmembrane domain. Models of the activated forms of GPCRs have become increasingly necessary for the development of a clear understanding of signal propagation into the cell. Experimental evidence points to a multiplicity of conformations related to the activation of the receptor, rendered important physiologically by the suggestion that different conformations may be responsible for coupling to different signaling pathways. In contrast to the inactive state of rhodopsin (RHO) for which several high quality X-ray structures are available, the structure-related information for the active states of rhodopsin and all other GPCRs is indirect. We have collected and stored such information in a repository we maintain for activation-specific structural data available for rhodopsin-like GPCRs, http://www.physiology.med.cornell.edu/GPCRactivation/gpcrindex.html . Using these data as structural constraints, we have applied Simulated Annealing Molecular Dynamics to construct a number of different active state models of RHO starting from the known inactive structure. The common features of the models indicate that TM3 and TM5 play an important role in activation, in addition to the well-established rearrangement of TM6. Some of the structural changes observed in these models occur in regions that were not involved in the constraints, and have not been previously tested experimentally; they emerge as interesting candidates for further experimental exploration of the conformational space of activated GPCRs. We show that none of the normal modes calculated from the inactive structure has a dominant contribution along the path of conformational rearrangement from inactive to the active forms of RHO in the models. This result may differentiate rhodopsin from other GPCRs, and the reasons for this difference are discussed in the context of the structural properties and the physiological function of the protein.		Masha Y. Niv;Lucy Skrabanek;Marta Filizola;Harel Weinstein	2006	Journal of computer-aided molecular design	10.1007/s10822-007-9117-z	crystallography;biochemistry;molecular dynamics;chemistry;transmembrane domain;simulated annealing;normal mode;data model;bioinformatics;g protein-coupled receptor;structural change;ligand;signal transduction;quantum mechanics	Comp.	8.916252270921083	-62.97089972426925	67509
633a4b382f2e98c58243eb59e9a0d8c962bd5eae	splicing of a human endogenous retrovirus to a novel phospholipase a2 related gene	dna;transcription genetic;recombinant fusion proteins;splicing;animals;alternative splicing;blotting northern;blotting southern;phospholipases a2;cloning molecular;rna splicing;empalme;amino acid sequence;virus;malignant teratoma;lignee cellulaire;enzyme;hombre;dna complementario;teratoma maligno;secuencia nucleotido;human endogenous retrovirus;enzima;gene pla2l;repetitive sequences nucleic acid;restriction mapping;genetic variation;nucleotide sequence;linea celular;sequence nucleotide;hybrid gene;dna transposable elements;complementary dna;gene expression;expression genique;epissage;dna complementaire;gen hibrido;endogenous;human;gene hybride;endogeno;phospholipases a;phospholipase a2;humans;molecular sequence data;base sequence;retroviridae;teratome malin;expresion genetica;exons;lignee ntera2d1;homme;endogene;cell line	As part of an investigation into the effects of endogenous retroviruses on adjacent genes, we have isolated a cDNA clone derived from the human teratocarcinoma cell line NTera2D1 representing a chimeric transcript in which an endogenous retrovirus-like element, RTVL-H, has been spliced to downstream cellular sequences. The 5' terminus of this clone, termed AF-5, occurs one bp downstream of the predicted transcriptional start site in the RTVL-H long terminal repeat (LTR). AF-5 contains an open reading frame of 689 amino acids beginning within RTVL-H sequences that has two domains of homology with phospholipase A2 (PLA2). These domains, of approximately 120 amino acids each, are 30-38% identical to secreted PLA2s and contain sequence features of both group I and II enzymes. The corresponding AF-5 transcript is 2.5 kb and is derived from a single copy novel gene termed PLA2L. Southern analysis indicates that the RTVL-H element is normally present in human DNA upstream of the PLA2L gene. RTVL-H/PLA2L chimeric transcripts were detected in two independent teratocarcinoma cell lines but not in several other cell lines or primary human tissues. Characterization of additional cDNA clones and PCR analysis indicates that multiple RTVL-H/PLA2L alternatively spliced transcripts are expressed. No evidence has been found for transcription from a non-LTR promoter. These findings strongly suggest that the endogenous LTR promotes expression of the human PLA2L gene in teratocarcinoma cells.	amino acids;cell secretion;chimera organism;clone;dna, complementary;downstream (software development);endogenous retroviruses;grimoire of the rift;homologous gene;homology (biology);long terminal repeat;open reading frame;reading frames (nucleotide sequence);retroviridae;teratocarcinoma;terminal repeat sequences;transcript;transcription (software);transcription, genetic;phospholipase a2-alpha	Anita E. Feuchter-Murthy;J. Douglas Freeman;Dixie L. Mager	1993	Nucleic acids research	10.1093/nar/21.1.135	biology;molecular biology;bioinformatics;genetics;rna splicing	Comp.	4.233565664798352	-63.59023173528191	67536
fb1153648e6aa42e26a2342e48f6464c1019e118	estimating population diversity with catchall	software;genetics population;qa mathematics;likelihood functions;bacteriophages;models statistical;algorithms;computational biology;linear models;ha statistics;qh301 biology	MOTIVATION The massive data produced by next-generation sequencing require advanced statistical tools. We address estimating the total diversity or species richness in a population. To date, only relatively simple methods have been implemented in available software. There is a need for software employing modern, computationally intensive statistical analyses including error, goodness-of-fit and robustness assessments.   RESULTS We present CatchAll, a fast, easy-to-use, platform-independent program that computes maximum likelihood estimates for finite-mixture models, weighted linear regression-based analyses and coverage-based non-parametric methods, along with outlier diagnostics. Given sample 'frequency count' data, CatchAll computes 12 different diversity estimates and applies a model-selection algorithm. CatchAll also derives discounted diversity estimates to adjust for possibly uncertain low-frequency counts. It is accompanied by an Excel-based graphics program.   AVAILABILITY Free executable downloads for Linux, Windows and Mac OS, with manual and source code, at www.northeastern.edu/catchall.   CONTACT jab18@cornell.edu.	biopolymer sequencing;count data;estimated;evaluation procedure;executable;graphics software;linux;massively-parallel sequencing;microsoft windows;mixture model;operating system;outlier;regression analysis;robustness (computer science);selection algorithm;source code;system 7	John Bunge;Linda Woodard;Dankmar Böhning;James A. Foster;Sean Connolly;Heather K. Allen	2012	Bioinformatics	10.1093/bioinformatics/bts075	biology;econometrics;computer science;bioinformatics;linear model;mathematics;statistics	Comp.	3.0765896373334773	-52.43351194277277	67573
8dbeb41916c52d35937ff372d701d3966ef2bdcf	flyex, the quantitative atlas on segmentation gene expression at cellular resolution	genes;animals;blastoderm;microscopy confocal;large dataset;databases genetic;datasets;embryos;gene expression;drosophila melanogaster;embryo;reference data;drosophila proteins;user computer interface;quality of data;gene expression pattern;genes insect	The datasets on gene expression are the valuable source of information about the functional state of an organism. Recently, we have acquired the large dataset on expression of segmentation genes in the Drosophila blastoderm. To provide efficient access to the data, we have developed the FlyEx database (http://urchin.spbcas.ru/flyex). FlyEx contains 4716 images of 14 segmentation gene expression patterns obtained from 1579 embryos and 9,500,000 quantitative data records. Reference data are available for all segmentation genes in cycles 11-13 and all temporal classes of cycle 14A. FlyEx supports operations on images of gene expression patterns. The database can be used to examine the quality of data, analyze the dynamics of formation of segmentation gene expression domains, as well as to estimate the variability of gene expression patterns. Currently, a user is able to monitor and analyze the dynamics of formation of segmentation gene expression domains over the whole period of segment determination, that amounts to 1.5 h of development. FlyEx supports the data downloads and construction of personal reference datasets, that makes it possible to more effectively use and analyze data.	blastoderm;cervical atlas;class;embryo;gene expression;gene co-expression network;hl7publishingsubsection <operations>;information source;reference implementation;silo (dataset);spatial variability;biologic segmentation	Andrei Pisarev;Ekaterina Poustelnikova;Maria Samsonova;John Reinitz	2009		10.1093/nar/gkn717	biology;embryo;bioinformatics;genetics	Comp.	-0.17160448967583314	-60.70360108757546	67608
f9c095f559e8666445326afd3e38bfcb770cbf1c	pfdb: a generic protein family database integrating the cath domain structure database with sequence based protein family resources	assignment;genomics;relational data;complete genome;protein family;computer science and information systems;protein domains;relational database;database integration;classification;genetics;system;materialized views;biological data;database design;biological sciences;psi blast;domain structure	MOTIVATION The PFDB (Protein Family Database) is a new database designed to integrate protein family-related data with relevant functional and genomic data. It currently manages biological data for three projects-the CATH protein domain database (Orengo et al., 1997; Pearl et al., 2001), the VIDA virus domains database (Albà et al., 2001) and the Gene3D database (Buchan et al., 2001). The PFDB has been designed to accommodate protein families identified by a variety of sequence based or structure based protocols and provides a generic resource for biological research by enabling mapping between different protein families and diverse biochemical and genetic data, including complete genomes.   RESULTS A characteristic feature of the PFDB is that it has a number of meta-level entities (for example aggregation, collection and inclusion) represented as base tables in the final design. The explicit representation of relationships at the meta-level has a number of advantages, including flexibility-both in terms of the range of queries that can be formulated and the ability to integrate new biological entities within the existing design. A potential drawback with this approach-poor performance caused by the number of joins across meta-level tables-is avoided by implementing the PFDB with materialized views using the mature relational database technology of Oracle 8i. The resultant database is both fast and flexible. This paper presents the principles on which the database has been designed and implemented, and describes the current status of the database and query facilities supported.	cath;data table;entity;generic drugs;genome;materialized view;maxillary right central incisor implant;oracle database;protein family;protocols documentation;question (inquiry);relational database;resultant	Adrian J. Shepherd;Nigel J. Martin;Roger G. Johnson;Paul Kellam;Christine A. Orengo	2002	Bioinformatics	10.1093/bioinformatics/18.12.1666	genomics;relational database;computer science;bioinformatics;data mining;database;protein structure database;database schema;database design	Comp.	-4.145168127784032	-63.28481387136747	67634
0e87d3e6f47469b8dbf6843fed9cb0b4f3d92ceb	o-glycbase version 3.0: a revised database of o-glycosylated proteins		O-GLYCBASE is a database of glycoproteins with O-linked glycosylation sites. Entries with at least one experimentally verified O-glycosylation site have been compiled from protein sequence databases and literature. Each entry contains information about the glycan involved, the species, sequence, a literature reference and http-linked cross-references to other databases. Version 4.0 contains 179 protein entries, an approximate 15% increase over the last version. Sequence logos representing the acceptor specificity patterns for GalNAc, GlcNAc, mannosyl and xylosyl transferases are shown. The O-GLYCBASE database is available through the WWW at http://www.cbs.dtu.dk/databases/OGLYCBASE/	acceptor (semiconductors);approximation algorithm;compiler;cross-reference;experiment;hypertext transfer protocol;linked list;list of biological databases;pierre robin syndrome;published database;revision procedure;sensitivity and specificity;transferase;www;polysaccharide-k	Jan E. Hansen;Ole Lund;Jette Nilsson;Kristoffer Rapacki;Søren Brunak	1998	Nucleic acids research	10.1093/nar/26.1.387	glycoprotein;n-acetylglucosaminyltransferases;prosite;genetics;database;peptide sequence;mannose;biology;glycan;glycosylation;protein data bank (rcsb pdb)	DB	-1.8111400311660155	-60.64747566265751	67695
f07d8ed79168e9fcd0b6ae21491d93647ba6e276	an algorithm for the discovery of phenotype related metabolic pathways	databases;graph search;phylogenetic profile;organisms;comparative genomics phenotype related pathways phylogenetic profile metabolic pathways;biology computing;genomics;anaerobic organisms;compounds;phylogeny;metabolic network;comparative genomics;enzyme;seed networks;aerobic respiration;genetics;enzymes;phenotype related pathways;enzymes phenotype related metabolic pathways generic metabolic network phenotype expressing organisms seed networks aerobic organisms anaerobic organisms aerobic respiration phylogenetic profile;generic metabolic network;phenotype expressing organisms;metabolic pathway;biochemistry;metabolic pathways;bioinformatics organisms genomics phylogeny databases biochemistry chemical compounds computer science mathematics biomedical computing;aerobic organisms;genetics biology computing;bioinformatics;phenotype related metabolic pathways	Microorganisms are being increasingly used in industrial processes due to certain beneficial phenotypes they exhibit. Improving the ability of microorganisms to exhibit these phenotypes has driven interest in identifying the genes that are responsible for a given phenotype. Some of these phenotypes are the result of various chemical compounds being modified by a series of metabolic reactions, or metabolic pathways, catalyzed by specific enzymes. Recently, comprehensive, generic metabolic networks have been defined, which describe possible ways in which certain chemical compounds may be modified by known metabolic reactions. In this paper, we aim to discover phenotype related metabolic pathways by identifying subnetworks of a generic metabolic network that are highly conserved in phenotype expressing organisms and rarely conserved in non-phenotype expressing organisms. To do this, we introduce a graph search algorithm that finds and expands highly conserved seed networks based on their evolutionary bias towards phenotype expressing organisms. We hypothesize that the evolutionarily conservation of these subnetworks in phenotype expressing organisms is likely due to the fact that they represent metabolic pathways responsible for the expression of the phenotype. We test our approach using aerobic and anaerobic organisms to identify pathways related to aerobic respiration. We find that the pathways identified by our algorithm are found primarily in aerobic organisms and that metabolic pathways known to be related to aerobic respiration are covered by the pathways identified by our algorithm. We finish by discussing the ongoing and future work related to this methodology.	conserved sequence;graph traversal;search algorithm	Matthew C. Schmidt;Nagiza F. Samatova	2009	2009 IEEE International Conference on Bioinformatics and Biomedicine	10.1109/BIBM.2009.78	biology;biochemistry;enzyme;metabolic pathway;genomics;bioinformatics;genetics;metabolic network	Comp.	3.3239104527304066	-59.91226487324323	67720
57ee3d3be4f75b3d5d6c46e67c3d3c36a1884f39	genetic network reverse-engineering and network size; can we identify large grns?	genetic engineering;biology computing;optimisation;optimisation reverse engineering genetic regulatory networks;genetic regulatory network;indexing terms;genetics;genetic network;genetics biological system modeling data engineering reverse engineering pattern analysis computer science data analysis reliability engineering computer network reliability gene expression;biology computing genetics optimisation genetic engineering;reverse engineering	The reverse engineering of genetic regulatory networks (GRNs) is a highly challenging optimisation problem, surrounded by many unresolved questions concerning the extent to which we can regard a reverse-engineered GRN to reflect the target GRN, which we call the fidelity of the reverse engineered GRN. Related questions concern the ability of reverse-engineering algorithms to find networks that fit the data under consideration, that is, their accuracy. Most research works with networks two orders of magnitude smaller than those of biological interest, and the following question is consequently unexplored: how can we expect fidelity and accuracy to vary with network size? Answers to this question will reveal whether or not we can reliably extrapolate, to large networks, results obtained on the ability of reverse-engineering methods on small networks. We use real-world data to explore accuracy and fidelity of a simple GRN reverse-engineering approach, over sizes of networks varying from 100 to 6,000. We find that accurate networks can be found with ease at any size. However, the diversity of accurate reverse-engineered GRNs increases sharply between 100 and around 2,000 genes, then settling down to a maximal level, indicating that the fidelity of reverse-engineered networks is likely to decrease sharply with size.	extrapolation;gene regulatory network;genetic algorithm;mathematical optimization;maximal set;reverse engineering	Carey Pridgeon;David W. Corne	2004	2004 Symposium on Computational Intelligence in Bioinformatics and Computational Biology	10.1109/CIBCB.2004.1393928	genetic engineering;biology;index term;computer science;bioinformatics;artificial intelligence;machine learning;data mining;genetics;reverse engineering	Comp.	5.0292643730951845	-59.53511396621242	67885
06e16ac06f0f927310281bcc9682c9fb7e61a772	a structural systems biology approach for quantifying the systemic consequences of missense mutations in proteins	systems biology;protein stability;map kinase signaling system;models molecular;proteins;humans;institutional repository research archive oaister;computer simulation;mutation missense;g2 phase cell cycle checkpoints	Gauging the systemic effects of non-synonymous single nucleotide polymorphisms (nsSNPs) is an important topic in the pursuit of personalized medicine. However, it is a non-trivial task to understand how a change at the protein structure level eventually affects a cell's behavior. This is because complex information at both the protein and pathway level has to be integrated. Given that the idea of integrating both protein and pathway dynamics to estimate the systemic impact of missense mutations in proteins remains predominantly unexplored, we investigate the practicality of such an approach by formulating mathematical models and comparing them with experimental data to study missense mutations. We present two case studies: (1) interpreting systemic perturbation for mutations within the cell cycle control mechanisms (G2 to mitosis transition) for yeast; (2) phenotypic classification of neuron-related human diseases associated with mutations within the mitogen-activated protein kinase (MAPK) pathway. We show that the application of simplified mathematical models is feasible for understanding the effects of small sequence changes on cellular behavior. Furthermore, we show that the systemic impact of missense mutations can be effectively quantified as a combination of protein stability change and pathway perturbation.	cell cycle control;control system;gene regulatory network;mathematical model;mathematics;missense mutation;mitogen-activated protein kinases;mitosis;neuron;nucleotides;personalization;single nucleotide polymorphism;systems biology	Tammy M. K. Cheng;Lucas Goehring;Linda Jeffery;Yu-En Lu;Jacqueline Hayles;Béla Novák;Paul A. Bates	2012		10.1371/journal.pcbi.1002738	computer simulation;biology;fox proteins;bioinformatics;genetics;systems biology	Comp.	7.080786257070942	-60.11388767535461	67896
4515c47fea87ca505396d5ec3c138cf162840107	non-linear dimensionality reduction of signaling networks	least squares analysis;apoptosis;simulation and modeling;signaling network;tumor necrosis factor alpha;tumor necrosis factor;metabolic networks and pathways;growth factor;partial least square;systems biology;epidermal growth factor;signal transduction;supervised classification;physiological cellular and medical topics;models biological;signal transduction pathway;intracellular signaling;cytokines;computational biology bioinformatics;discriminant analysis;cluster analysis;principal component analysis;prediction accuracy;insulin;algorithms;k nearest neighbor;humans;signaling pathway;prediction model;neoplasms;neural networks computer;quadratic discriminant analysis;dimensional reduction;high dose;cell signaling;modeling and analysis;bioinformatics	Systems wide modeling and analysis of signaling networks is essential for understanding complex cellular behaviors, such as the biphasic responses to different combinations of cytokines and growth factors. For example, tumor necrosis factor (TNF) can act as a proapoptotic or prosurvival factor depending on its concentration, the current state of signaling network and the presence of other cytokines. To understand combinatorial regulation in such systems, new computational approaches are required that can take into account non-linear interactions in signaling networks and provide tools for clustering, visualization and predictive modeling. Here we extended and applied an unsupervised non-linear dimensionality reduction approach, Isomap, to find clusters of similar treatment conditions in two cell signaling networks: (I) apoptosis signaling network in human epithelial cancer cells treated with different combinations of TNF, epidermal growth factor (EGF) and insulin and (II) combination of signal transduction pathways stimulated by 21 different ligands based on AfCS double ligand screen data. For the analysis of the apoptosis signaling network we used the Cytokine compendium dataset where activity and concentration of 19 intracellular signaling molecules were measured to characterise apoptotic response to TNF, EGF and insulin. By projecting the original 19-dimensional space of intracellular signals into a low-dimensional space, Isomap was able to reconstruct clusters corresponding to different cytokine treatments that were identified with graph-based clustering. In comparison, Principal Component Analysis (PCA) and Partial Least Squares – Discriminant analysis (PLS-DA) were unable to find biologically meaningful clusters. We also showed that by using Isomap components for supervised classification with k-nearest neighbor (k-NN) and quadratic discriminant analysis (QDA), apoptosis intensity can be predicted for different combinations of TNF, EGF and insulin. Prediction accuracy was highest when early activation time points in the apoptosis signaling network were used to predict apoptosis rates at later time points. Extended Isomap also outperformed PCA on the AfCS double ligand screen data. Isomap identified more functionally coherent clusters than PCA and captured more information in the first two-components. The Isomap projection performs slightly worse when more signaling networks are analyzed; suggesting that the mapping function between cues and responses becomes increasingly non-linear when large signaling pathways are considered. We developed and applied extended Isomap approach for the analysis of cell signaling networks. Potential biological applications of this method include characterization, visualization and clustering of different treatment conditions (i.e. low and high doses of TNF) in terms of changes in intracellular signaling they induce.	apoptosis;behavior;cell signaling;coherence (physics);compendium;imagery;interaction;isomap;k-nearest neighbors algorithm;ligands;linear discriminant analysis;machine learning;nonlinear dimensionality reduction;nonlinear system;papillon-lefevre disease;partial least squares regression;predictive modelling;principal component analysis;quadratic classifier;scientific visualization;signal transduction pathways;silo (dataset);single linkage cluster analysis;supervised learning;transduction (machine learning);tumor necrosis factors;cytokine;statistical cluster	Sergii Ivakhno;J. Douglas Armstrong	2006	BMC Systems Biology	10.1186/1752-0509-1-27	biology;computer science;bioinformatics;machine learning;systems biology;signal transduction	ML	6.940854816066258	-56.225397286054836	67942
910800cf54714e9a905e2b061aa84065eab6485f	dbteu: a protein database of trace element utilization	software;molybdenum;proteine;nickel;trace element;database;base dato;base de donnees;trace elements;proteina;cobalt;proteomics;copper;protein;utilization;selenium;databases protein	UNLABELLED Biological trace elements are required for numerous biological processes and by all organisms. We describe a database, dbTEU (DataBase of Trace Element Utilization), that features known transporters and user proteins for five trace elements (copper, molybdenum, nickel, cobalt and selenium) and represents sequenced organisms from the three domains of life. The manually curated dbTEU currently includes approximately 16,500 proteins from >700 organisms, and offers interactive trace element, protein, organism and sequence search and browse tools.   AVAILABILITY AND IMPLEMENTATION dbTEU is freely available at http://gladyshevlab.bwh.harvard.edu/trace_element/	biological processes;browsing;cobalt;databases, protein;membrane transport proteins;molybdenum;selenium;sequence database;staphylococcal protein a;trace elements;nickel	Yan Zhang;Vadim N. Gladyshev	2010	Bioinformatics	10.1093/bioinformatics/btp705	biology;bioinformatics;proteomics;mineralogy;trace element	Comp.	-1.1248022033839802	-59.40725158196071	68015
92f319e7e049620a09e1e6df9cd99a3e7678c9a0	a nonhomogeneous hidden markov model for gene mapping based on next-generation sequencing data	nonhomogeneous hidden markov model;quantitative trait loci analysis;single nucleotide polymorphisms;next generation sequencing	The analysis of polygenetic characteristics for mapping quantitative trait loci (QTL) remains an important challenge. QTL analysis requires two or more strains of organisms that differ substantially in the (poly-)genetic trait of interest, resulting in a heterozygous offspring. The offspring with the trait of interest is selected and subsequently screened for molecular markers such as single-nucleotide polymorphisms (SNPs) with next-generation sequencing. Gene mapping relies on the co-segregation between genes and/or markers. Genes and/or markers that are linked to a QTL influencing the trait will segregate more frequently with this locus. For each identified marker, observed mismatch frequencies between the reads of the offspring and the parental reference strains can be modeled by a multinomial distribution with the probabilities depending on the state of an underlying, unobserved Markov process. The states indicate whether the SNP is located in a (vicinity of a) QTL or not. Consequently, genomic loci associated with the QTL can be discovered by analyzing hidden states along the genome. The aforementioned hidden Markov model assumes that the identified SNPs are equally distributed along the chromosome and does not take the distance between neighboring SNPs into account. The distance between the neighboring SNPs could influence the chance of co-segregation between genes and markers. To address this issue, we propose a nonhomogeneous hidden Markov model with a transition matrix that depends on a set of distance-varying observed covariates. The application of the model is illustrated on the data from a study of ethanol tolerance in yeast.	aicardi's syndrome;akaike information criterion;bayesian information criterion;biopolymer sequencing;byzantine fault tolerance;choose (action);chromosome mapping;computation;concordance (publishing);entity name part qualifier - adopted;ethanol;fits;forward–backward algorithm;generalized linear model;genetic polymorphism;greater;hidden markov model;immune tolerance;locus;markov chain;massively-parallel sequencing;molecular marker;multinomial logistic regression;neonatal hemochromatosis;nethack;nitroprusside;nucleotides;probability;projection screen;quantitative trait loci;reading (activity);seizures;single nucleotide polymorphism;stochastic matrix;tacrolimus binding proteins;the offspring;time complexity;imidazole mustard	Fatemeh Zamanzad Ghavidel;Jürgen Claesen;Tomasz Burzykowski	2015	Journal of computational biology : a journal of computational molecular cell biology	10.1089/cmb.2014.0258	single-nucleotide polymorphism;biology;dna sequencing;family-based qtl mapping;biotechnology;bioinformatics;genetics;quantitative trait locus	Comp.	3.56844428730122	-59.93343658222925	68074
eeced1a44c7ddfca479ee9095714745aff686872	status of the inchi algorithm and inchi trust	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;computer applications in chemistry;theoretical and computational chemistry;computational biology bioinformatics;uk phd theses thesis;life sciences;uk research reports;medical journals;europe pmc;documentation and information in chemistry;biomedical research;bioinformatics	Progress of the IUPAC InChI/InChIKey project continues to move ahead quote well. Use of the algorithm has increased over the past year to the point that numerous publications use and refer to InChI. The Markush and Polymer/Mixtures IUPAC InChI working groups have completed their initial work and/or are moving ahead at a good pace. Publicity for the project is good and has resulted in considerable increase in the usage of the InChI algorithm. The Trust web site is now available to the public and is updated regularly. Even CAS now allows for an InChI string to be used as input for a SciFinder search. Extensions to the project’s current capabilities are being developed by a number of expert, experienced individuals and groups from various areas of chemistry. This presentation will describe the current technical state of the InChI algorithm and how the InChI Trust is working to assure the continued support and delivery of the InChI algorithm.	algorithm;inchi;polymer	Stephen R. Heller	2012		10.1186/1758-2946-4-S1-P13	biology;medical research;computer science;bioinformatics;data mining	HCI	-3.4475362020333207	-62.51107611796895	68076
69e15ea6202f021752c51dd2bb4f4a1bcb446e8d	modulating protein-dna interactions by post-translational modifications at disordered regions		Intrinsically disordered regions, particularly disordered tails, are very common in DNA-binding proteins (DBPs). The ability of disordered tails to modulate specific and nonspecific interactions with DNA is tightly linked to their being rich in positively charged residues that are often non-randomly distributed along the tail. Perturbing the composition and distribution of charged residues in the disordered regions by post-translational modifications, such as phosphorylation and acetylation, may impair the ability of the tail to interact nonspecifically with DNA by reducing its DNA affinity. In this study, we analyzed datasets of 3398 and 8943 human proteins that undergo acetylation or phosphorylation, respectively. Both modifications are common on the disordered tails of DBPs (3.1 ± 0.2 (0.07 ± 0.007) and 2.0 ± 0.2 (0.02 ± 0.003) acetylation and phosphorylation sites per tail (per tail residue), respectively). Phosphorylation sites are abundant in disordered regions and particularly in flexible tails for both DBPs and non-DBPs. While acetylation sites are also frequently occurred in the disordered tails of DBPs, in non-DBPs they are often found in ordered regions. This difference may indicate that acetylation has different function in DBPs and non-DBPs. Post-translational modifications, which often take place at disordered sites of DBPs, can modulate the interactions of proteins with DNA by changing the local and global properties of the tails. The effect of the modulation can be tuned by adjusting the number of modifications and the cross-talks between them.	charge (electrical);dna binding site;genetic translation process;interaction;modulation;occur (action);post-translational protein processing;post-traumatic stress disorder;processor affinity;protein acetylation;randomness;tail;tails	Dana Vuzman;Yonit Hoffman;Yaakov Levy	2012	Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing		dna;biophysics;human proteins;genetics;phosphorylation;acetylation;posttranslational modification;biology	Comp.	5.934360131933997	-63.33027059340483	68085
0d16235660bfac5db659c92b0d485e923cafa190	mirecords: an integrated resource for microrna–target interactions	rna messenger;databases nucleic acid;gene expression regulation;micrornas;systems integration;microrna	MicroRNAs (miRNAs) are an important class of small noncoding RNAs capable of regulating other genes' expression. Much progress has been made in computational target prediction of miRNAs in recent years. More than 10 miRNA target prediction programs have been established, yet, the prediction of animal miRNA targets remains a challenging task. We have developed miRecords, an integrated resource for animal miRNA-target interactions. The Validated Targets component of this resource hosts a large, high-quality manually curated database of experimentally validated miRNA-target interactions with systematic documentation of experimental support for each interaction. The current release of this database includes 1135 records of validated miRNA-target interactions between 301 miRNAs and 902 target genes in seven animal species. The Predicted Targets component of miRecords stores predicted miRNA targets produced by 11 established miRNA target prediction programs. miRecords is expected to serve as a useful resource not only for experimental miRNA researchers, but also for informatics scientists developing the next-generation miRNA target prediction programs. The miRecords is available at http://miRecords.umn.edu/miRecords.	computation;documentation;experiment;informatics (discipline);interaction;micrornas	Feifei Xiao;Zhixiang Zuo;Guoshuai Cai;Shuli Kang;Xiaolian Gao;Tongbin Li	2009		10.1093/nar/gkn851	biology;bioinformatics;genetics;microrna	Comp.	-0.6555634700688979	-60.10017893078223	68111
19fccda5ff640d51f848090b8316a5c97183d4cc	an approximate de bruijn graph approach to multiple local alignment and motif discovery in protein sequences	motif discovery;amino acid;protein sequence;proteins;protein sequence analysis;de bruijn graph;dna sequence;local alignment	Motif discovery is an important problem in protein sequence analysis. Computationally, it can be viewed as an application of the more general multiple local alignment problem, which often encounters the difficulty of computer time when aligning many sequences. We introduce a new algorithm for multiple local alignment for protein sequences, based on the de Bruijn graph approach first proposed by Zhang and Waterman for aligning DNA sequence. We generalize their approach to aligning protein sequences by building an approximate de Bruijn graph to allow gluing similar but not identical amino acids. We implement this algorithm and test it on motif discovery of 100 sets of protein sequences. The results show that our method achieved comparable results as other popular motif discovery programs, while offering advantages in terms of speed.	approximation algorithm;de bruijn graph;peptide sequence;sequence analysis;sequence motif;smith–waterman algorithm	Rupali Patwardhan;Haixu Tang;Sun Kim;Mehmet M. Dalkilic	2006		10.1007/11960669_14	de bruijn graph;dna sequencing;combinatorics;amino acid;multiple sequence alignment;bioinformatics;theoretical computer science;smith–waterman algorithm;protein sequencing;sequence analysis;mathematics;sequence motif	Comp.	-1.3666512489982967	-52.218469017526736	68168
36ce54a4245856788b18a92b0b02b6377098e7dc	a theoretical study on the electronic structures and equilibrium constants evaluation of deferasirox iron complexes	iron;spin;deferasirox;chelator;compex	Elemental iron is essential for cellular growth and homeostasis but it is potentially toxic to the cells and tissues. Excess iron can contribute in tumor initiation and tumor growth. Obviously, in iron overload issues using an iron chelator in order to reduce iron concentration seems to be vital. This study presents the density functional theory calculations of the electronic structure and equilibrium constant for iron-deferasirox (Fe-DFX) complexes in the gas phase, water and DMSO. A comprehensive study was performed to investigate the Deferasirox-iron complexes in chelation therapy. Calculation was performed in CAMB3LYP/6-31G(d,p) to get the optimized structures for iron complexes in high and low spin states. Natural bond orbital and quantum theory of atoms in molecules analyses was carried out with B3LYP/6-311G(d,p) to understand the nature of complex bond character and electronic transition in complexes. Electrostatic potential effects on the complexes were evaluated using the CHelpG calculations. The results indicated that higher affinity for Fe(III) is not strictly a function of bond length but also the degree of Fe-X (X=O,N) covalent bonding. Based on the quantum reactivity parameters which have been investigated here, it is possible reasonable design of the new chelators to improve the chelator abilities.	body tissue;chelpg;chelating activity;chelating agents;chelation therapy;covalent interaction;density functional theory;dimethyl sulfoxide;electronic structure;equilibrium;field electron emission;functional theories of grammar;homeostasis;iron man;iron overload;molecular orbital;neoplasms;offset binary;processor affinity;pyschological bonding;quantum dots;quantum mechanics;tumor initiation;visual effects;cell growth;deferasirox;elemental iron;newton	Samie Salehi;Amir Shokooh Saljooghi;Mohammad Izadyar	2016	Computational biology and chemistry	10.1016/j.compbiolchem.2016.05.010	stereochemistry;chemistry;inorganic chemistry;spin;iron;quantum mechanics	ECom	9.938573857690763	-64.1608177650227	68319
e16851fcd09144af2ab94f87cf05eee6bf04b431	progenetix.net: an online repository for molecular cytogenetic aberration data	genetique;site web;sequencage;red www;aberration chromosomique;genetica;reseau web;ressource;citogenetica;data mining;genetics;aberracion cromosomica;cytogenetics;sequencing;fouille donnee;cytogenetique;world wide web;sitio web;chromosomal aberration;busca dato;recurso;web site;resource	UNLABELLED Through sequencing projects and, more recently, array-based expression analysis experiments, a wealth of genetic data has become accessible via online resources. In contrast, few of the (molecular-) cytogenetic aberration data collected in the last decades are available in a format suitable for data mining procedures. www.progenetix.net is a new online repository for previously published chromosomal aberration data, allowing the addition of band-specific information about chromosomal imbalances to oncologic data analysis efforts.   AVAILABILITY http://www.progenetix.net   CONTACT mbaudis@stanford.edu	biopolymer sequencing;chromosome aberrations;congenital chromosomal disease;cytogenetic analysis;data mining;ephrin type-b receptor 1, human;experiment;scientific publication	Michael Baudis;Michael L. Cleary	2001	Bioinformatics	10.1093/bioinformatics/17.12.1228	biology;cytogenetics;bioinformatics;sequencing;world wide web;genetics;resource	Comp.	-3.2652279029227427	-57.79534099002498	68387
d1feb77680ea67a14a616e929241812e4c12de4c	impacts of somatic mutations on gene expression: an association perspective	cancer gene;gene expression;mutation cluster;mutation type;somatic mutation	Assessing the functional impacts of somatic mutations in cancer genomes is critical for both identifying driver mutations and developing molecular targeted therapies. Currently, it remains a fundamental challenge to distinguish the patterns through which mutations execute their biological effects and to infer biological mechanisms underlying these patterns. To this end, we systematically studied the association between somatic mutations in protein-coding regions and expression profiles, which represents an indirect measurement of impacts. We defined mutation features (mutation type, cluster and status) and built linear regression models to assess mutation associations with mRNA expression and protein expression. Our results presented a comprehensive landscape of the associations between mutation features and expression profile in multiple cancer types, including 62 genes showing mutation type associated expression changes, 21 genes showing mutation cluster associations and 51 genes showing mutation status associations. We revealed four characteristics of the patterns that mutations impact on expression. First, we showed that mutation type (truncation versus amino acid-altering mutations) was the most important determinant of expression levels. Second, we detected mutation clusters in well-studied oncogenes that were associated with gene expression. Third, we found both similarities and differences in association patterns existed within and across cancer types. Fourth, although many of the observed associations stay stable at both mRNA and protein expression levels, there are also novel associations uniquely observed at the protein level, which warrant future investigation. Taken together, our findings provided implications for cancer driver gene prioritization and insights into the functional consequences of somatic mutations.	amino acids;diploid cell;function (biology);gene expression profiling;genome;inference;linear iga bullous dermatosis;mental association;molecular targeted therapy;neoplasms;oncogenes;protein truncation abnormality;protein structure prediction;somatic mutation;protein expression	Peilin Jia;Zhongming Zhao	2017	Briefings in bioinformatics	10.1093/bib/bbw037	genetics	Comp.	5.553930660960135	-57.81503122199388	68416
e3320f9c9c904f525be1b4a3d163b39ed51d624c	cdh1/e-cadherin and solid tumors. an updated gene-disease association analysis using bioinformatics tools	solid tumors;epithelial cadherin;somatic mutations;cdh1;bioinformatics	Cancer is a group of diseases that causes millions of deaths worldwide. Among cancers, Solid Tumors (ST) stand-out due to their high incidence and mortality rates. Disruption of cell-cell adhesion is highly relevant during tumor progression. Epithelial-cadherin (protein: E-cadherin, gene: CDH1) is a key molecule in cell-cell adhesion and an abnormal expression or/and function(s) contributes to tumor progression and is altered in ST. A systematic study was carried out to gather and summarize current knowledge on CDH1/E-cadherin and ST using bioinformatics resources. The DisGeNET database was exploited to survey CDH1-associated diseases. Reported mutations in specific ST were obtained by interrogating COSMIC and IntOGen tools. CDH1 Single Nucleotide Polymorphisms (SNP) were retrieved from the dbSNP database. DisGeNET analysis identified 609 genes annotated to ST, among which CDH1 was listed. Using CDH1 as query term, 26 disease concepts were found, 21 of which were neoplasms-related terms. Using DisGeNET ALL Databases, 172 disease concepts were identified. Of those, 80 ST disease-related terms were subjected to manual curation and 75/80 (93.75%) associations were validated. On selected ST, 489 CDH1 somatic mutations were listed in COSMIC and IntOGen databases. Breast neoplasms had the highest CDH1-mutation rate. CDH1 was positioned among the 20 genes with highest mutation frequency and was confirmed as driver gene in breast cancer. Over 14,000 SNP for CDH1 were found in the dbSNP database. This report used DisGeNET to gather/compile current knowledge on gene-disease association for CDH1/E-cadherin and ST; data curation expanded the number of terms that relate them. An updated list of CDH1 somatic mutations was obtained with COSMIC and IntOGen databases and of SNP from dbSNP. This information can be used to further understand the role of CDH1/E-cadherin in health and disease.		María Florencia Abascal;María José Besso;Marina Rosso;María Victoria Mencucci;Evangelina Aparicio;Gala Szapiro;Laura Inés Furlong;Mónica Hebe Vazquez-Levin	2016	Computational biology and chemistry	10.1016/j.compbiolchem.2015.10.002	biology;computer science;bioinformatics;apc/c activator protein cdh1;genetics	Comp.	-1.714342765757309	-63.67511415233305	68669
374ba50202b8b464198f2a9d018d1cf0010ee456	integrative genomics identifies candidate micrornas for pathogenesis of experimental biliary atresia	animals;genomics;simulation and modeling;mice;systems biology;physiological cellular and medical topics;biliary atresia;computational biology bioinformatics;time factors;gallbladder;algorithms;micrornas;bile ducts;gene expression profiling;bioinformatics	Biliary atresia is a fibroinflammatory obstruction of extrahepatic bile duct that leads to end-stage liver disease in children. Despite advances in understanding the pathogenesis of biliary atresia, very little is known about the role of microRNAs (miRNAs) in onset and progression of the disease. In this study, we aimed to investigate the entire biliary transcriptome to identify miRNAs with potential role in the pathogenesis of bile duct obstruction. By profiling the expression levels of miRNA in extrahepatic bile ducts and gallbladder (EHBDs) from a murine model of biliary atresia, we identified 14 miRNAs whose expression was suppressed at the times of duct obstruction and atresia (≥2 fold suppression, P < 0.05, FDR 5%). Next, we obtained 2,216 putative target genes of the 14 miRNAs using in silico target prediction algorithms. By integrating this result with a genome-wide gene expression analysis of the same tissue (≥2 fold increase, P < 0.05, FDR 5%), we identified 26 potential target genes with coordinate expression by the 14 miRNAs. Functional analysis of these target genes revealed a significant relevance of miR-30b/c, -133a/b, -195, -200a, -320 and −365 based on increases in expression of at least 3 target genes in the same tissue and 1st-to-3rd tier links with genes and gene-groups regulating organogenesis and immune response. These miRNAs showed higher expression in EHBDs above livers, a unique expression in cholangiocytes and the subepithelial compartment, and were downregulated in a cholangiocyte cell line after RRV infection. Integrative genomics reveals functional relevance of miR-30b/c, -133a/b, -195, -200a, -320 and −365. The coordinate expression of miRNAs and target genes in a temporal-spatial fashion suggests a regulatory role of these miRNAs in pathogenesis of experimental biliary atresia.	anatomical compartments;bile ducts, extrahepatic;bile duct structure;biliary atresia;cholestasis;color gradient;computational genomics;duct (organ) structure;end stage liver disease;false discovery rate;gene expression programming;impatent structure;liver diseases;micrornas;multi-compartment model;multitier architecture;obstruction;onset (audio);organogenesis;relevance;ross river virus;the times;vocal cord paralysis;zero suppression;algorithm	Kazuhiko Bessho;Kumar Shanmukhappa;Rachel Sheridan;Pranavkumar Shivakumar;Reena Mourya;Stephanie Walters;Vivek Kaimal;Eric Dilbone;Anil G. Jegga;Jorge A. Bezerra	2012		10.1186/1752-0509-7-104	biology;genomics;bioinformatics;gene expression profiling;systems biology;microrna	Comp.	5.664238369050083	-60.42620952380848	68756
639d660c6946eb310fbcfe59e2e36849dee12427	getting started in gene expression microarray analysis	experimental design;statistical data;drug discovery;complementary dna;gene expression;microarray analysis;oligonucleotides;data visualization;computational biology;oligonucleotide array sequence analysis;microarrays	Gene expression microarrays provide a snapshot of all the transcriptional activity in a biological sample. Unlike most traditional molecular biology tools, which generally allow the study of a single gene or a small set of genes, microarrays facilitate the discovery of totally novel and unexpected functional roles of genes. The power of these tools has been applied to a range of applications, including discovering novel disease subtypes, developing new diagnostic tools, and identifying underlying mechanisms of disease or drug response. However, this technology necessarily produces a large amount of data, challenging us to interpret it by exploiting modern computational and statistical tools. In this brief review, we aim to indicate the major issues involved in microarray analysis and provide a useful starting point for new microarray users. Figure 1 outlines the steps in a typical expression microarray experiment and maps them to the different sections of this review.	computation;exploit (computer security);gene expression programming;map;microarray;outlines (document);snapshot (computer storage);subtype (attribute);transcription, genetic;drug response	Donna K. Slonim;Itai Yanai	2009		10.1371/journal.pcbi.1000543	biology;microarray analysis techniques;molecular biology;gene expression;dna microarray;bioinformatics;gene expression profiling;design of experiments;microarray databases;genetics;complementary dna;chemical compound microarray;drug discovery;data visualization;oligonucleotide	Comp.	2.0220160275140056	-57.52356399212092	68835
62d3f5ec33ceb38fe1f39330bdb11100e7332c9c	nmrnet: a deep learning approach to automated peak picking of protein nmr spectra		Motivation Automated selection of signals in protein NMR spectra, known as peak picking, has been studied for over 20 years, nevertheless existing peak picking methods are still largely deficient. Accurate and precise automated peak picking would accelerate the structure calculation, and analysis of dynamics and interactions of macromolecules. Recent advancement in handling big data, together with an outburst of machine learning techniques, offer an opportunity to tackle the peak picking problem substantially faster than manual picking and on par with human accuracy. In particular, deep learning has proven to systematically achieve human-level performance in various recognition tasks, and thus emerges as an ideal tool to address automated identification of NMR signals.   Results We have applied a convolutional neural network for visual analysis of multidimensional NMR spectra. A comprehensive test on 31 manually annotated spectra has demonstrated top-tier average precision (AP) of 0.9596, 0.9058 and 0.8271 for backbone, side-chain and NOESY spectra, respectively. Furthermore, a combination of extracted peak lists with automated assignment routine, FLYA, outperformed other methods, including the manual one, and led to correct resonance assignment at the levels of 90.40%, 89.90% and 90.20% for three benchmark proteins.   Availability and implementation The proposed model is a part of a Dumpling software (platform for protein NMR data analysis), and is available at https://dumpling.bio/.   Supplementary information Supplementary data are available at Bioinformatics online.		Piotr Klukowski;Michal Augoff;Maciej Zieba;Maciej Drwal;Adam Gonczarek;Michal J. Walczak	2018	Bioinformatics	10.1093/bioinformatics/bty134	computer science;deep learning;nmr spectra database;bioinformatics;artificial intelligence	Comp.	8.92997530270098	-57.127923825864585	68853
f5372c73c1b972bf5c6cb5ff94a6ba5ec836de24	molecular dynamics simulations of the adenosine a2a receptor in popc and pope lipid bilayers: effects of membrane on protein behavior		Analysis of 300 ns (ns) molecular dynamics (MD) simulations of an adenosine A2a receptor (A2a AR) model, conducted in triplicate, in 1-palmitoyl-2-oleoylphosphatidylcholine (POPC) and 1-palmitoyl-2-oleoylphosphatidylethanolamine (POPE) bilayers reveals significantly different protein dynamical behavior. Principal component analysis (PCA) shows that the dissimilarities stem from interhelical rather than intrahelical motions. The difference in the hydrophobic thicknesses of these simulated lipid bilayers is potentially a significant reason for the observed difference in results. The distinct lipid headgroups might also lead to different molecular interactions and hence different protein loop motions. Overall, the A2a AR shows higher mobility and flexibility in POPC as compared to POPE.	1-palmitoyl-2-oleoylphosphatidylcholine;1-palmitoyl-2-oleoylphosphatidylethanolamine;adenosine a2a receptor;computer simulation;interaction;lipid metabolism disorders;molecular dynamics;motion;principal component analysis;triplicate	Hui Wen Ng;Charles A. Laughton;Stephen W. Doughty	2014	Journal of chemical information and modeling	10.1021/ci400463z	crystallography;biochemistry;chemistry;nanotechnology	Comp.	9.628662197204504	-63.0160327864129	68857
99c16bb76337bc9bda4169780476798a33fa724a	automatic decomposition of kinetic models of signaling networks minimizing the retroactivity among modules	signaling network;kinetic model;a priori knowledge;community structure;decomposition algorithm;biochemical network;modeling tool;protein interaction network	MOTIVATION The modularity of biochemical networks in general, and signaling networks in particular, has been extensively studied over the past few years. It has been proposed to be a useful property to analyze signaling networks: by decomposing the network into subsystems, more manageable units are obtained that are easier to analyze. While many powerful algorithms are available to identify modules in protein interaction networks, less attention has been paid to signaling networks de.ned as chemical systems. Such a decomposition would be very useful as most quantitative models are de.ned using the latter, more detailed formalism.   RESULTS Here, we introduce a novel method to decompose biochemical networks into modules so that the bidirectional (retroactive) couplings among the modules are minimized. Our approach adapts a method to detect community structures, and applies it to the so-called retroactivity matrix that characterizes the couplings of the network. Only the structure of the network, e.g. in SBML format, is required. Furthermore, the modularized models can be loaded into ProMoT, a modeling tool which supports modular modeling. This allows visualization of the models, exploiting their modularity and easy generation of models of one or several modules for further analysis. The method is applied to several relevant cases, including an entangled model of the EGF-induced MAPK cascade and a comprehensive model of EGF signaling, demonstrating its ability to uncover meaningful modules. Our approach can thus help to analyze large networks, especially when little a priori knowledge on the structure of the network is available.   AVAILABILITY The decomposition algorithms implemented in MATLAB (Mathworks, Inc.) are freely available upon request. ProMoT is freely available at http://www.mpi-magdeburg.mpg.de/projects/promot.   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	algorithm;bioinformatics;cascade device component;cell signaling;kinetics;matlab;sbml;slpi protein, human;semantics (computer science)	Julio Saez-Rodriguez;Stefan Gayer;Martin Ginkel;Ernst Dieter Gilles	2008	Bioinformatics	10.1093/bioinformatics/btn289	a priori and a posteriori;computer science;bioinformatics;modularity;theoretical computer science;machine learning;community structure;statistics	Comp.	6.467644345595177	-58.99945665021367	68966
b84586ba4145725056b7800a0410015365da36c5	bioprofiling.de: analytical web portal for high-throughput cell biology	genes;software;animals;mice;rats;drug discovery;mining;gene regulatory networks;quinolines;aniline compounds;internet;proteins;micro rna;cellular biology;nitriles;humans;spiders;databases factual;protein kinase inhibitors;protein interaction mapping;high throughput screening assays	BioProfiling.de provides a comprehensive analytical toolkit for the interpretation gene/protein lists. As input, BioProfiling.de accepts a gene/protein list. As output, in one submission, the gene list is analyzed by a collection of tools which employs advanced enrichment or network-based statistical frameworks. The gene list is profiled with respect to the most information available regarding gene function, protein interactions, pathway relationships, in silico predicted microRNA to gene associations, as well as, information collected by text mining. BioProfiling.de provides a user friendly dialog-driven web interface for several model organisms and supports most available gene identifiers. The web portal is freely available at http://www.BioProfiling.de/gene_list.	access network;amino acids;blue gene;class;gene ontology term enrichment;gene expression programming;gene regulatory network;high-throughput computing;identifier;interaction;interface device component;kegg;knowledge bases;knowledge base;mental association;regulatory submission;systems biology;text mining;throughput;trait;usability;user interface;world wide web;dialog;gene function	Alexey V. Antonov	2011		10.1093/nar/gkr372	biology;gene regulatory network;molecular biology;mining;the internet;bioinformatics;gene;genetics;drug discovery;microrna	Comp.	-0.607525344134605	-61.51212645401098	68996
6e82b92dbe658167b6d161c860332cf5150e576c	biq analyzer himod: an interactive software tool for high-throughput locus-specific analysis of 5-methylcytosine and its oxidized derivatives	dna;software;animals;mice;high throughput nucleotide sequencing;sequence analysis dna;5 methylcytosine;oxidation reduction;internet;dna methylation;genetic loci	Recent data suggest important biological roles for oxidative modifications of methylated cytosines, specifically hydroxymethylation, formylation and carboxylation. Several assays are now available for profiling these DNA modifications genome-wide as well as in targeted, locus-specific settings. Here we present BiQ Analyzer HiMod, a user-friendly software tool for sequence alignment, quality control and initial analysis of locus-specific DNA modification data. The software supports four different assay types, and it leads the user from raw sequence reads to DNA modification statistics and publication-quality plots. BiQ Analyzer HiMod combines well-established graphical user interface of its predecessor tool, BiQ Analyzer HT, with new and extended analysis modes. BiQ Analyzer HiMod also includes updates of the analysis workspace, an intuitive interface, a custom vector graphics engine and support of additional input and output data formats. The tool is freely available as a stand-alone installation package from http://biq-analyzer-himod.bioinf.mpi-inf.mpg.de/.	5-methylcytosine;analyzer, body composition;access network;alloy analyzer;analyzer device component;analyzer, device;biopolymer sequencing;dna modification process;european viper;game engine;graphical user interface;high-throughput computing;hypertensive disease;input/output;julia set;locus;microsoft outlook for mac;nar 2;pascal;preprocessor;profiling (computer programming);programming paradigm;programming tool;reading (activity);slpi protein, human;sequence number;sequence alignment;software design;technical support;throughput;track (course);usability;user interface device component;vector graphics;web site;workspace;format;julia <dryas julia>;newton per square metre	Daniel Becker;Pavlo Lutsik;Peter Ebert;Christoph Bock;Thomas Lengauer;Jörn Walter	2014		10.1093/nar/gku457	biology;the internet;redox;bioinformatics;locus;dna methylation;genetics;dna	Comp.	-2.9279324397572886	-58.50526168910358	69100
a430054468fe2044fc22ca8323ec3c8629ece74b	mechanistic insights into mode of action of rice allene oxide synthase on hydroxyperoxides: an intermediate step in herbivory-induced jasmonate pathway	jasmonates;hydroxyperoxide;oryza;allene oxide synthase;md simulation	Various types of oxygenated fatty acids termed 'oxylipins' are involved in plant response to herbivory. Oxylipins like jasmonic acid (JA) and green leafy volatiles (GLVs) are formed by the action of enzymes like allene oxide synthase (AOS) and hydroxyperoxide lyase (HPL) respectively. In this study, we focus on AOS of Oryza sativa sb. Japonica, that interact with 9- and 13- hydroxyperoxides to produce intermediates of jasmonate pathway and compare it with rice HPL that yields GLVs. We attempt to elucidate the interaction pattern by computational docking protocols keeping the Arabidopsis AOS system as the reference model system. Both 9-hydroxyperoxide and 13-hydroxyperoxide fit into the active site of AOS completely with Phe347, Phe92, Ile463, Val345, and Asn278 being the common interacting residues. Phe347 and Phe92 were mutated with Leucine and docked again with the hydroxyperoxides. The Phe347→Leu347 mutant showed a different mode of action than AOS-hydroxyperoxide complex with Trp413 in direct bonding with the OOH group of 9-hydroxyperoxide. The loss of Lys88-OOH interaction in 13-hydroxyperoxide and loss-of-interaction of Leu347 indicated the importance of Phe347 residue in hydroxyperoxide catalysis. The second mutant Phe92→Leu92 also shows a very different interaction pattern with 13-hydroxyperoxide but not with 9-hydroxyperoxide.Therefore, it can be concluded that Phe347 is more crucial for AOS functionality than Phe92. The aromatic ring of a Phenylalanine residue is important for catalysis and its mutation affects the binding of the two ligands. Another important residue is Asn278 which is an important part of the AOS catalytic site for maintaining stability and can be compared with the Arabidopsis AOS residue Asn321. Lastly, the interaction of HPL with these two derivatives involves Leu363 residue instead of Phe347 and thus, validating the importance of Phe→Leu substitution to be the reason of different modes of action that result in completely different products from same substrates.		Chetna Tyagi;Archana Singh;Indrakant Kumar Singh	2016	Computational biology and chemistry	10.1016/j.compbiolchem.2016.07.002	biochemistry;botany;chemistry;organic chemistry	Comp.	9.476482086845772	-62.486330194204406	69163
e1f5da78ffd60d8639a51c5a52d260f69d11845e	the phytophthora genome initiative database: informatics and analysis for distributed pathogenomic research	databases;libraries;oomycetes;genome plant;plant pathogens;plant pathology;phytophthora;nucleotide sequences;genomes;phytophthora infestans;destructive behavior;internet;genome;plant pathogen;control;computer techniques;computer software;plant pathogenic fungi;databases factual;distributed collaboration;information storage and retrieval;similarity search;evolution	The Phytophthora Genome Initiative (PGI) is a distributed collaboration to study the genome and evolution of a particularly destructive group of plant pathogenic oomycete, with the goal of understanding the mechanisms of infection and resistance. NCGR provides informatics support for the collaboration as well as a centralized data repository. In the pilot phase of the project, several investigators prepared Phytophthora infestans and Phytophthora sojae EST and Phytophthora sojae BAC libraries and sent them to another laboratory for sequencing. Data from sequencing reactions were transferred to NCGR for analysis and curation. An analysis pipeline transforms raw data by performing simple analyses (i.e., vector removal and similarity searching) that are stored and can be retrieved by investigators using a web browser. Here we describe the database and access tools, provide an overview of the data therein and outline future plans. This resource has provided a unique opportunity for the distributed, collaborative study of a genus from which relatively little sequence data are available. Results may lead to insight into how better to control these pathogens. The homepage of PGI can be accessed at http:www.ncgr.org/pgi, with database access through the database access hyperlink.	bacterial artificial chromosomes;batman: arkham city;biopolymer sequencing;centralized computing;digital curation;genome-wide association study;genus (mathematics);hyperlink;hypertext transfer protocol;informatics (discipline);information repository;libraries;phylum oomycetes;phytophthora lacustris	Mark E. Waugh;Peter T. Hraber;Jennifer W. Weller;Yihe Wu;Guanghong Chen;Jeff T. Inman;Donald Kiphart;Bruno W. S. Sobral	2000	Nucleic acids research	10.1093/nar/28.1.87	biology;botany;bioinformatics;genetics;genome	DB	-2.6799975020695435	-60.857339249209296	69251
73cefae78d16f0adca976d57beba4722ee8532d8	substrate recognition by norovirus polymerase: microsecond molecular dynamics study	norwalk virus;hepatitis c virus;rna dependent rna polymerase;molecular dynamics;phosphonate;competitive inhibitor;chain terminator;namd;gpu;cuda;acemd	Molecular dynamics simulations of complexes between Norwalk virus RNA dependent RNA polymerase and its natural CTP and 2dCTP (both containing the O5'-C5'-C4'-O4' sequence of atoms bridging the triphosphate and sugar moiety) or modified coCTP (C5'-O5'-C4'-O4'), cocCTP (C5'-O5'-C4'-C4'') substrates were produced by means of CUDA programmable graphical processing units and the ACEMD software package. It enabled us to gain microsecond MD trajectories clearly showing that similar nucleoside triphosphates can bind surprisingly differently into the active site of the Norwalk virus RNA dependent RNA polymerase. It corresponds to their different modes of action (CTP-substrate, 2dCTP-poor substrate, coCTP-chain terminator, cocCTP-inhibitor). Moreover, extremely rare events-as repetitive pervasion of Arg182 into a potentially reaction promoting arrangement-were captured.	bridging (networking);cuda;cytidine triphosphate;dna-directed rna polymerase;graphical user interface;molecular dynamics;murine sarcoma viruses;norovirus;nucleoside-diphosphate kinase;nucleosides;promotion (action);rare events;simulation;software release life cycle;sugars	Kamil Malác;Ivan Barvík	2013	Journal of computer-aided molecular design	10.1007/s10822-013-9652-8	biology;biochemistry;molecular biology;virology;polymerase	Comp.	7.3932705084911685	-63.698123134480056	69349
08ba156f31fdfedb3540f9bb035d43d52a5b2efb	signaling network prediction by the ontology fingerprint enhanced bayesian network	simulation and modeling;systems biology;phosphorylation;signal transduction;gene regulatory networks;molecular sequence annotation;bayes theorem;physiological cellular and medical topics;databases genetic;models biological;computational biology bioinformatics;algorithms;humans;proteomics;computer simulation;hep g2 cells;bioinformatics	Despite large amounts of available genomic and proteomic data, predicting the structure and response of signaling networks is still a significant challenge. While statistical method such as Bayesian network has been explored to meet this challenge, employing existing biological knowledge for network prediction is difficult. The objective of this study is to develop a novel approach that integrates prior biological knowledge in the form of the Ontology Fingerprint to infer cell-type-specific signaling networks via data-driven Bayesian network learning; and to further use the trained model to predict cellular responses. We applied our novel approach to address the Predictive Signaling Network Modeling challenge of the fourth (2009) Dialog for Reverse Engineering Assessment's and Methods (DREAM4) competition. The challenge results showed that our method accurately captured signal transduction of a network of protein kinases and phosphoproteins in that the predicted protein phosphorylation levels under all experimental conditions were highly correlated (R2 = 0.93) with the observed results. Based on the evaluation of the DREAM4 organizer, our team was ranked as one of the top five best performers in predicting network structure and protein phosphorylation activity under test conditions. Bayesian network can be used to simulate the propagation of signals in cellular systems. Incorporating the Ontology Fingerprint as prior biological knowledge allows us to efficiently infer concise signaling network structure and to accurately predict cellular responses.	bayesian network;electronic organizer;fingerprint;inference;phosphoproteins;protein kinases;protein phosphorylation;proteomics;reverse engineering;signal transduction;simulation;software propagation;transduction (machine learning);web ontology language;dialog	Tingting Qin;Lam C. Tsoi;Kellie J. Sims;Xinghua Lu;W. Jim Zheng	2012		10.1186/1752-0509-6-S3-S3	computer simulation;phosphorylation;biology;gene regulatory network;variable-order bayesian network;computer science;bioinformatics;machine learning;data mining;proteomics;bayes' theorem;systems biology;signal transduction	Comp.	7.3939096352971365	-57.15901301714918	69455
858cfa272ee0c5eaca0cb3e8c1c15decc9f076e1	fcdecomp: decomposition of metabolic networks based on flux coupling relations	partitioning;subsystem;module	A metabolic network model provides a computational framework to study the metabolism of a cell at the system level. Due to their large sizes and complexity, rational decomposition of these networks into subsystems is a strategy to obtain better insight into the metabolic functions. Additionally, decomposing metabolic networks paves the way to use computational methods that will be otherwise very slow when run on the original genome-scale network. In the present study, we propose FCDECOMP decomposition method based on flux coupling relations (FCRs) between pairs of reaction fluxes. This approach utilizes a genetic algorithm (GA) to obtain subsystems that can be analyzed in isolation, i.e. without considering the reactions of the original network in the analysis. Therefore, we propose that our method is useful for discovering biologically meaningful modules in metabolic networks. As a case study, we show that when this method is applied to the metabolic networks of barley seeds and yeast, the modules are in good agreement with the biological compartments of these networks.		Abolfazl Rezvan;Sayed-Amir Marashi;Changiz Eslahchi	2014	Journal of bioinformatics and computational biology	10.1142/S0219720014500280	module;computer science;bioinformatics;theoretical computer science;system	Comp.	4.274075068622655	-58.2091104243054	69561
e1d34051d7deb564a621baa8d9638606685d5f63	genenames.org: the hgnc resources in 2013		The HUGO Gene Nomenclature Committee situated at the European Bioinformatics Institute assigns unique symbols and names to human genes. Since 2011, the data within our database has expanded largely owing to an increase in naming pseudogenes and non-coding RNA genes, and we now have >33,500 approved symbols. Our gene families and groups have also increased to nearly 500, with ∼45% of our gene entries associated to at least one family or group. We have also redesigned the HUGO Gene Nomenclature Committee website http://www.genenames.org creating a constant look and feel across the site and improving usability and readability for our users. The site provides a public access portal to our database with no restrictions imposed on access or the use of the data. Within this article, we review our online resources and data with particular emphasis on the updates to our website.	bioinformatics;committee, drug;fndc3a gene;gene family;hgnc;look and feel;no extremity functional restrictions;pseudogenes;rodent nomenclature name;situated;usability;web site	Kristian A. Gray;Louise Daugherty;Susan M. Gordon;Ruth L. Seal;Mathew W. Wright;Elspeth A. Bruford	2013		10.1093/nar/gks1066	gene nomenclature;hugo gene nomenclature committee;the internet;genetics;pseudogene;readability;gene family;look and feel;usability;biology	Comp.	-2.39881757895507	-61.34924673454817	69678
786a5f54ecc5acd4a4a53e8ade3ec1645ffe616d	gpminer: an integrated system for mining combinatorial cis-regulatory elements in mammalian gene group	software;animals;base composition;support vector machines;ncku 成功大學 成大 圖書館 機構典藏;databases genetic;animal genetics and genomics;transcription factors;binding sites;promoter regions genetic;life sciences general;dissertations and theses journal referred papers conference papers nsc reserach report patent nckur ir ncku institutional repostiory 博碩士論文 期刊論文 國科會研究報告 專利 成大機構典藏;algorithms;humans;microbial genetics and genomics;proteomics;computational biology;article;cpg islands;regulatory sequences nucleic acid;transcription initiation site;microarrays;plant genetics genomics	Sequence features in promoter regions are involved in regulating gene transcription initiation. Although numerous computational methods have been developed for predicting transcriptional start sites (TSSs) or transcription factor (TF) binding sites (TFBSs), they lack annotations for do not consider some important regulatory features such as CpG islands, tandem repeats, the TATA box, CCAAT box, GC box, over-represented oligonucleotides, DNA stability, and GC content. Additionally, the combinatorial interaction of TFs regulates the gene group that is associated with same expression pattern. To investigate gene transcriptional regulation, an integrated system that annotates regulatory features in a promoter sequence and detects co-regulation of TFs in a group of genes is needed. This work identifies TSSs and regulatory features in a promoter sequence, and recognizes co-occurrence of cis-regulatory elements in co-expressed genes using a novel system. Three well-known TSS prediction tools are incorporated with orthologous conserved features, such as CpG islands, nucleotide composition, over-represented hexamer nucleotides, and DNA stability, to construct the novel Gene Promoter Miner (GPMiner) using a support vector machine (SVM). According to five-fold cross-validation results, the predictive sensitivity and specificity are both roughly 80%. The proposed system allows users to input a group of gene names/symbols, enabling the co-occurrence of TFBSs to be determined. Additionally, an input sequence can also be analyzed for homogeneity of experimental mammalian promoter sequences, and conserved regulatory features between homologous promoters can be observed through cross-species analysis. After identifying promoter regions, regulatory features are visualized graphically to facilitate gene promoter observations. The GPMiner, which has a user-friendly input/output interface, has numerous benefits in analyzing human and mouse promoters. The proposed system is freely available at http://GPMiner.mbc.nctu.edu.tw/ .	binding sites;cpg islands;cross reactions;cross-validation (statistics);eighty;gene ontology;homology (biology);input/output;mammals;name;nucleotides;oligonucleotides;promoter regions, genetic;regulatory sequences, nucleic acid;sensitivity and specificity;sequence homology;support vector machine;transcription factor;tandem repeat sequences;toxic shock syndrome;transcription (software);transcription initiation;transcription, genetic;transcriptional regulation;usability;benefit	Tzong-Yi Lee;Wen-Chi Chang;Justin Bo-Kai Hsu;Tzu-Hao Chang;Dray-Ming Shien	2012		10.1186/1471-2164-13-S1-S3	biology;support vector machine;dna microarray;computer science;bioinformatics;binding site;cpg site;proteomics;caat box;genetics;transcription factor	Comp.	0.3700243586400725	-59.537710076108574	69694
79d46588f5863c871b28801b486d66655369a985	estimating classification probabilities in high-dimensional diagnostic studies	610 medizin;570 biowissenschaften biologie;500 naturwissenschaften	MOTIVATION Classification algorithms for high-dimensional biological data like gene expression profiles or metabolomic fingerprints are typically evaluated by the number of misclassifications across a test dataset. However, to judge the classification of a single case in the context of clinical diagnosis, we need to assess the uncertainties associated with that individual case rather than the average accuracy across many cases. Reliability of individual classifications can be expressed in terms of class probabilities. While classification algorithms are a well-developed area of research, the estimation of class probabilities is considerably less progressed in biology, with only a few classification algorithms that provide estimated class probabilities.   RESULTS We compared several probability estimators in the context of classification of metabolomics profiles. Evaluation criteria included sparseness biases, calibration of the estimator, the variance of the estimator and its performance in identifying highly reliable classifications. We observed that several of them display artifacts that compromise their use in practice. Classification probabilities based on a combination of local cross-validation error rates and monotone regression prove superior in metabolomic profiling.   AVAILABILITY The source code written in R is freely available at http://compdiag.uni-regensburg.de/software/probEstimation.shtml.   CONTACT inka.appel@klinik.uni-regensburg.de.		Inka J. Appel;Wolfram Gronwald;Rainer Spang	2011	Bioinformatics	10.1093/bioinformatics/btr434	econometrics;computer science;bioinformatics;data mining;statistics	Metrics	5.684360937362529	-52.287831863751094	69733
1c2efe6ca9ceaff6f79c2cdf1a24fd55b61954bb	in-vitro diagnosis of single and poly microbial species targeted for diabetic foot infection using e-nose technology	gas chromatography mass spectrometry;in vitro techniques;support vector machines;biosensing techniques;data mining;computational biology bioinformatics;discriminant analysis;diabetic foot;algorithms;humans;bacteria;neural networks computer;combinatorial libraries;electronic nose;odors;computer appl in life sciences;microarrays;bioinformatics	Effective management of patients with diabetic foot infection is a crucial concern. A delay in prescribing appropriate antimicrobial agent can lead to amputation or life threatening complications. Thus, this electronic nose (e-nose) technique will provide a diagnostic tool that will allow for rapid and accurate identification of a pathogen. This study investigates the performance of e-nose technique performing direct measurement of static headspace with algorithm and data interpretations which was validated by Headspace SPME-GC-MS, to determine the causative bacteria responsible for diabetic foot infection. The study was proposed to complement the wound swabbing method for bacterial culture and to serve as a rapid screening tool for bacteria species identification. The investigation focused on both single and poly microbial subjected to different agar media cultures. A multi-class technique was applied including statistical approaches such as Support Vector Machine (SVM), K Nearest Neighbor (KNN), Linear Discriminant Analysis (LDA) as well as neural networks called Probability Neural Network (PNN). Most of classifiers successfully identified poly and single microbial species with up to 90% accuracy. The results obtained from this study showed that the e-nose was able to identify and differentiate between poly and single microbial species comparable to the conventional clinical technique. It also indicates that even though poly and single bacterial species in different agar solution emit different headspace volatiles, they can still be discriminated and identified using multivariate techniques.	agar;anterior descending branch of left coronary artery;artificial neural network;complement system proteins;diabetes mellitus;electronic nose;interpretation process;k-nearest neighbors algorithm;linear discriminant analysis;neural network simulation;numerous;pathogenic organism;patients;poly a;rhinorrhea;support vector machine;diabetic foot infection;perineuronal net (cell component)	Nurlisa Yusuf;Ammar Zakaria;Mohammad Omar;Ali Yeon Md Shakaff;Maz Jamilah Masnan;Latifah Kamarudin;Norasmadi Abdul Rahim;Nur Zawatil Isqi Zakaria;Azian Abdullah;Amizah Othman;Mohd Yasin	2015		10.1186/s12859-015-0601-5	electronic nose;biology;support vector machine;dna microarray;gas chromatography–mass spectrometry;bacteria;computer science;bioinformatics;linear discriminant analysis	HCI	8.85404341987206	-55.88055524018653	69754
07bed1b29864821a3577e071c2d8f3481909b534	mitocarta2.0: an updated inventory of mammalian mitochondrial proteins	mitochondrial proteins;animals;genomics;mice;bayes theorem;journal article;internet;humans;databases protein	Mitochondria are complex organelles that house essential pathways involved in energy metabolism, ion homeostasis, signalling and apoptosis. To understand mitochondrial pathways in health and disease, it is crucial to have an accurate inventory of the organelle's protein components. In 2008, we made substantial progress toward this goal by performing in-depth mass spectrometry of mitochondria from 14 organs, epitope tagging/microscopy and Bayesian integration to assemble MitoCarta (www.broadinstitute.org/pubs/MitoCarta): an inventory of genes encoding mitochondrial-localized proteins and their expression across 14 mouse tissues. Using the same strategy we have now reconstructed this inventory separately for human and for mouse based on (i) improved gene transcript models, (ii) updated literature curation, including results from proteomic analyses of mitochondrial sub-compartments, (iii) improved homology mapping and (iv) updated versions of all seven original data sets. The updated human MitoCarta2.0 consists of 1158 human genes, including 918 genes in the original inventory as well as 240 additional genes. The updated mouse MitoCarta2.0 consists of 1158 genes, including 967 genes in the original inventory plus 191 additional genes. The improved MitoCarta 2.0 inventory provides a molecular framework for system-level analysis of mammalian mitochondria.	anatomical compartments;apoptosis;body tissue;digital curation;energy metabolism;homologous gene;homology (biology);ions;mammals;mitochondrial inheritance;organ;organelles;proteomics;version;biological signaling;ion homeostasis	Sarah E. Calvo;Karl R. Clauser;Vamsi K. Mootha	2016	Nucleic acids research	10.1093/nar/gkv1003	biology;genomics;the internet;bioinformatics;bayes' theorem;genetics	Comp.	-0.5580013886798373	-61.095731983977885	69831
6849a5fc97effc92a420ea24bccce042aab0d977	parallel computation of phylogenetic consensus trees	majority rule;performance improvement;evolutionary trees;phylogenetic tree;parallel computer;phylogenetic inference;open source	The field of bioinformatics is witnessing a rapid and overwhelming accumulation of molecular sequence data, predominantly driven by novel wet-lab sequencing techniques. This trend poses scalability challenges for tool developers. In the field of phylogenetic inference (reconstruction of evolutionary trees from molecular sequence data), scalability is becoming an increasingly important issue for operations other than the tree reconstruction itself. In this paper we focus on a post-analysis task in reconstructing very large trees, specifically the step of building (extended) majority rules consensus trees from a collection of equally plausible trees or a collection of bootstrap replicate trees. To this end, we present sequential optimizations that establish our implementation as the current fastest exact implementation in phylogenetics, and our novel parallelized routines are the first of their kind. Our sequential optimizations achieve a performance improvement of factor 50 compared to the previous version of our code and we achieve a maximum speedup of 5.5 on a 8-core Nehalem node for building consensi on trees comprising up to 55,000 organisms. The methods developed here are integrated into the widely used open-source tool RAxML for phylogenetic tree reconstruction.	bioinformatics;computation;computational phylogenetics;decision tree;fastest;nehalem (microarchitecture);open-source software;parallel computing;phylogenetic tree;scalability;self-replication;speedup;tree accumulation	Andre J. Aberer;Nicholas D. Pattengale;Alexandros Stamatakis	2010		10.1016/j.procs.2010.04.118	phylogenetic tree;computer science;bioinformatics;theoretical computer science;machine learning;tree rearrangement;distributed computing;law;algorithm	Comp.	-1.3299184960290116	-53.54821958674712	69868
84d41d56b2db8035341e8a9c7d1cac0845681442	mbgd update 2010: toward a comprehensive resource for exploring microbial genome diversity	software;animals;genomics;phylogeny;genome fungal;databases nucleic acid;databases genetic;internet;protein structure tertiary;genome bacterial;humans;sequence alignment;computational biology;information storage and retrieval;databases protein	The microbial genome database (MBGD) for comparative analysis is a platform for microbial comparative genomics based on automated ortholog group identification. A prominent feature of MBGD is that it allows users to create ortholog groups using a specified subgroup of organisms. The database is constantly updated and now contains almost 1000 genomes. To utilize the MBGD database as a comprehensive resource for investigating microbial genome diversity, we have developed the following advanced functionalities: (i) enhanced assignment of functional annotation, including external database links to each orthologous group, (ii) interface for choosing a set of genomes to compare based on phenotypic properties, (iii) the addition of more eukaryotic microbial genomes (fungi and protists) and some higher eukaryotes as references and (iv) enhancement of the MyMBGD mode, which allows users to add their own genomes to MBGD and now accepts raw genomic sequences without any annotation (in such a case, it runs a gene-finding procedure before identifying the orthologs). Some analysis functions, such as the function to find orthologs with similar phylogenetic patterns, have also been improved. MBGD is accessible at http://mbgd.genome.ad.jp/.	accepting of extremity;annotation;choose (action);fungi;gene prediction;genome;genome, microbial;genome-wide association study;genomics;homology (biology);one thousand;orthologous gene;phylogenetics;qualitative comparative analysis;sequence clustering;sequence homology;subgroup a nepoviruses;protists	Ikuo Uchiyama;Toshio Higuchi;Mikihiko Kawai	2010		10.1093/nar/gkp948	biology;genomics;the internet;bioinformatics;sequence alignment;genetics	Comp.	-0.3909249380846988	-59.276497608499945	69993
e7e0e1c96de5180a31ea5ed6b0157e7fca9e712e	similarity boosting for label noise tolerance in protein-chemical interaction prediction	sensitivity and specificity;large scale;cross validation;interactive space;protein interaction;application;chemical reaction	The analysis of protein-chemical reactions on a large scale is critical to understanding the complex interrelated mechanisms that govern biological life at the cellular level. Chemical proteomics is a new research area aimed at proteome-wide screening of such chemical-protein interactions. In order to model the diverse and complex chemical-protein interaction space, recent work on local models has emerged. Local models improve generalization by training a series of independent models each localized to predict a single interaction. One limitation of this approach is that the localized models are not tolerant to noise in the interaction labels, which is a characteristic of much protein-chemical interaction data.  This work proposes and evaluates a boosting framework incorporating sample similarity to localize base models to appropriate regions of the interaction space, thereby ensuring that similar samples are given similar predictions and providing a measure of tolerance to noise in the training labels. The framework is described and compared to local models and several other competing classification methods. Chemical-protein interaction data sets are constructed from publicly available data, and a series of cross-validation experiments are performed in order to compare the noise tolerance, accuracy, sensitivity, and specificity of various methods.	cross-validation (statistics);experiment;interaction;proteomics;sensitivity and specificity	Aaron Smalter Hall;Jun Huan;Gerald H. Lushington	2011		10.1145/2147805.2147830	computer science;machine learning;data mining;statistics	ML	8.450551534296066	-55.5634202327097	70135
f2e7649c15e51f5b170fa5e24aa959989f2dabf5	detecting distant homologies on protozoans metabolic pathways using scientific workflows	via metabolica;genomic pipelines;gestion;voie metabolique;scientific workflow;enfermedad olvidada;scientific workflows;trypanomatids;wfms;maladie negligee;homology;distant homologies;genome homology workflows;workflow;workflow management systems;kepler;metabolic pathway;homologia;management;neglected disease;metabolic pathways;neglected diseases;protozoans;bioinformatics;homologie	Bioinformatics experiments are typically composed of programs in pipelines manipulating an enormous quantity of data. An interesting approach for managing those experiments is through workflow management systems (WfMS). In this work we discuss WfMS features to support genome homology workflows and present some relevant issues for typical genomic experiments. Our evaluation used Kepler WfMS to manage a real genomic pipeline, named OrthoSearch, originally defined as a Perl script. We show a case study detecting distant homologies on trypanomatids metabolic pathways. Our results reinforce the benefits of WfMS over script languages and point out challenges to WfMS in distributed environments.		Sérgio Manuel Serra da Cruz;Vanessa Batista;Edno Silva;Frederico Tosta;Clarissa Vilela;Rafael R. C. Cuadrat;Diogo A. Tschoeke;Alberto M. R. Dávila;Maria Luiza Machado Campos;Marta Mattoso	2010	International journal of data mining and bioinformatics	10.1504/IJDMB.2010.033520	biology;metabolic pathway;simulation;computer science;bioinformatics;data mining;genetics	DB	-4.497753839387572	-61.10913039569327	70254
5a3ab1a8104d358cf230c4ac8d6b0ea8a9c34389	developing an antituberculosis compounds database and data mining in the search of a motif responsible for the activity of a diverse class of antituberculosis agents	data mining;computer programs;computers in chemistry	A novel data mining procedure to look for new antitubercular agents and targets as well as to find a minimum common bioactive substructure (MCBS), has been reported here. The methodology extracts MCBS, both across the diverse chemical classes and within the particular chemical class, known to be present in the various marketed drugs alongside antimycobacterial compounds with known MICs. For this purpose a small in-house database of compounds has been created, for which MICs against Mycobacterium are known. The compounds have been collected from literature available on the synthetic compounds, having known MICs against Mycobacterium tuberculosis. An elaborate HQSAR (Hologram QSAR) study has been attempted to extract active fragment from a diverse class of compounds, in combination with the clustering technique to select a homogeneous group of compounds having good a profile toward the activity. The 2D pharmacophore (the 2D fragments extracted from HQSAR) has been validated searching the database. It has been found further that this validated 2D pharmacophore could be used for searching the orphan target in Mycobacterium effectively.	antitubercular agents;attempt;class;cluster analysis;data mining;extraction;genus mycobacterium;holography;motif;mycobacterium tuberculosis;quantitative structure-activity relationship;quantitative structure–activity relationship;synthetic intelligence;pharmacophore;statistical cluster	Om Prakash Pandey;Indira Ghosh	2006	Journal of chemical information and modeling	10.1021/ci050115s	toxicology;bioinformatics;combinatorial chemistry	ML	1.9175488632754523	-57.86886635411762	70344
e5bc152aa93a0c7ce7fe2c4c2661a170d4f5dcd0	sv2: accurate structural variation genotyping and de novo mutation detection from whole genomes		Motivation Structural variation (SV) detection from short-read whole genome sequencing is error prone, presenting significant challenges for population or family-based studies of disease.   Results Here, we describe SV2, a machine-learning algorithm for genotyping deletions and duplications from paired-end sequencing data. SV2 can rapidly integrate variant calls from multiple structural variant discovery algorithms into a unified call set with high genotyping accuracy and capability to detect de novo mutations.   Availability and implementation SV2 is freely available on GitHub (https://github.com/dantaki/SV2).   Contact jsebat@ucsd.edu.   Supplementary information Supplementary data are available at Bioinformatics online.	bioinformatics;cognitive dimensions of notations;de novo mutation;de novo transcriptome assembly;genotype determination;geographic information systems;systemverilog;whole genome sequencing;algorithm	Danny Antaki;William M. Brandler;Jonathan Sebat	2018	Bioinformatics	10.1093/bioinformatics/btx813	genotyping;computer science;structural variation;bioinformatics;genome;mutation	Comp.	1.566989797180317	-54.99184672259809	70421
6b74b4a3228d67d0658872a2588854bd7b6ff6ae	logchem: interactive discriminative mining of chemical structure	mining model;logchem;drugs;drug discovery;database management systems;molecular configurations;chemistry computing;structure activity relationship problems;inductive logic programming;structure activity relationship drug discovery inductive logic programming;data mining;dtp aids anti viral screen;medical computing;artigo em livro de atas de conferencia internacional;interactive discriminative chemical structure mining;epa;structure activity relationship;chemoinformatics datasets;dtp aids anti viral screen logchem interactive discriminative chemical structure mining inductive logic programming structure activity relationship problems chemical compound activity ilp scalability problems mining model chemoinformatics datasets epa dsstox database;engenharia do conhecimento tecnologia farmaceutica matematica;dsstox database;chemical compound activity;chemical structure;ilp scalability problems;logic programming databases scalability desktop publishing acquired immune deficiency syndrome drugs bioinformatics chemical compounds decision support systems filters;bioinformatics;molecular configurations bioinformatics chemistry computing data mining database management systems drugs medical computing	One of the most well known successes of Inductive Logic Programming (ILP) is on Structure-Activity Relationship (SAR) problems. In such problems, ILP has proved several times to be capable of constructing expert comprehensible models that help to explain the activity of chemical compounds based on their structure and properties. However, despite its successes on SAR problems, ILP has severe scalability problems that prevent its application on larger datasets. In this paper we present LogCHEM, an ILP based tool for discriminative interactive mining of chemical fragments. LogCHEM tackles ILP's scalability issues in the context of SAR applications. We show that LogCHEM benefits from the flexibility of ILP, both by its ability to quickly extend the original mining model, and by its ability to interface with external tools. Furthermore, we demonstrate that LogCHEM can be used to mine effectively large chemoinformatics datasets, namely several datasets from EPA's DSSTox database and on a dataset based on the DTP AIDS anti-viral screen.	cheminformatics;distributed transaction;inductive logic programming;inductive reasoning;scalability;search algorithm;simplified molecular-input line-entry system;theory	Vítor Santos Costa;Nuno A. Fonseca;Rui Camacho	2008	2008 IEEE International Conference on Bioinformatics and Biomedicine	10.1109/BIBM.2008.45	structure–activity relationship;computer science;bioinformatics;data science;machine learning;data mining;chemical structure;drug discovery	Visualization	9.196706291815964	-52.69261117082628	70438
b3fcd916cb4d994252ba09d2af3bd4b009015915	embopro--an automatically generated protein sequence database	software;secuencia aminoacido;base donnee;traduccion automatica;proteine;sequence aminoacide;aminoacid sequence;logiciel;protein sequence;database;base dato;secuencia nucleotido;automatic generation;nucleotide sequence;sequence nucleotide;traduction automatique;proteins;mechanical translation;logicial;proteina;fortran	For the identification of newly sequenced proteins it is necessary to have a large stock of known proteins for comparison. In this paper we present an automatically generated protein sequence database. The translation program introduced allows a periodical translation of every new release of the EMBL database. Possible errors of the translation are discussed as well as the reliability of the nucleotide sequence data, which turns out to be quite good. A comparison of our translated database with some established ones is given.		R. Stulich;K. Rohde	1989	Computer applications in the biosciences : CABIOS	10.1093/bioinformatics/5.1.15	biology;nucleic acid sequence;bioinformatics;protein sequencing;protein structure database;genetics;algorithm	DB	-4.349759743713792	-56.067366493800556	70497
c6b24183f49d20506a42c388781197beb209a20d	ontodas – a tool for facilitating the construction of complex queries to the gene ontology	vocabulary controlled;database management systems;computer graphics;databases genetic;computational biology bioinformatics;terminology as topic;interactive environment;algorithms;user computer interface;combinatorial libraries;computational biology;computer appl in life sciences;systems integration;use case;natural language processing;information visualisation;microarrays;bioinformatics;gene ontology	Ontologies such as the Gene Ontology can enable the construction of complex queries over biological information in a conceptual way, however existing systems to do this are too technical. Within the biological domain there is an increasing need for software that facilitates the flexible retrieval of information. OntoDas aims to fulfil this need by allowing the definition of queries by selecting valid ontology terms. OntoDas is a web-based tool that uses information visualisation techniques to provide an intuitive, interactive environment for constructing ontology-based queries against the Gene Ontology Database. Both a comprehensive use case and the interface itself were designed in a participatory manner by working with biologists to ensure that the interface matches the way biologists work. OntoDas was further tested with a separate group of biologists and refined based on their suggestions. OntoDas provides a visual and intuitive means for constructing complex queries against the Gene Ontology. It was designed with the participation of biologists and compares favourably with similar tools. It is available at http://ontodas.nbn.ac.za	academia (organization);apache tomcat;application program interface;bio-informatics;bioinformatics;ephrin type-b receptor 1, human;gene ontology;gnatholepis sp. ct-2003;home page;information visualization;internet;java programming language;javascript;mysql;name;niche blogging;ontology (information science);operating system;programming languages;question (inquiry);registered jack;requirement;server (computing);silver;software license;sourceforge;web application;omacetaxine mepesuccinate	Kieran O'Neill;Alexander García Castro;Anita Schwegmann;Rafael C. Jimenez;Dan Jacobson;Henning Hermjakob	2008	BMC Bioinformatics	10.1186/1471-2105-9-437	use case;upper ontology;information visualization;dna microarray;computer science;bioinformatics;ontology;data mining;ontology-based data integration;computer graphics;information retrieval;process ontology;system integration;suggested upper merged ontology	Web+IR	-3.434610160443238	-60.76048629099604	70518
9bdf68c2756cf9f61b995edbb1a84fe39de48bf7	detecting intergene correlation changes in microarray analysis: a new approach to gene selection	databases genetic;computational biology bioinformatics;microarray analysis;differential expression;algorithms;biological data;combinatorial libraries;computational biology;gene selection;computer appl in life sciences;gene expression profiling;oligonucleotide array sequence analysis;candidate gene;microarrays;bioinformatics	Microarray technology is commonly used as a simple screening tool with a focus on selecting genes that exhibit extremely large differential expressions between different phenotypes. It lacks the ability to select genes that change their relationships with other genes in different biological conditions (differentially correlated genes). We intend to enrich the above procedure by proposing a nonparametric selection procedure that selects differentially correlated genes. Using both simulations and resampling techniques, we found that our procedure correctly detected genes that were not differentially expressed but differentially correlated. We also applied our procedure to a set of biological data and found some potentially important genes that were not selected by the traditional method. Microarray technology yields multidimensional information on the function of the whole genome. Rather than treating intergene correlation as a nuisance to the traditional gene selection procedures which are essentially univariate, our method utilizes the rich information contained in the correlation as a new selection criterion. It can provide additional useful candidate genes for the biologists.	candidate disease gene;contain (action);dna microarray;phenotype;protein microarray analysis;resampling (statistics);sensor;simulation	Rui Hu;Xing Qiu;Galina V. Glazko;Lev Klebanov;Andrei Yakovlev	2008	BMC Bioinformatics	10.1186/1471-2105-10-20	gene-centered view of evolution;biology;microarray analysis techniques;molecular biology;dna microarray;biological data;bioinformatics;gene expression profiling;microarray databases;candidate gene;genetics	Comp.	5.28248616228845	-52.55959704646903	70606
3a70d8dc41a6feda7f89600438484b899a554f6e	polypeptide folding on a conformational-space network: dependence of network topology on the structural discretization procedure.	structural clustering;space network;molecular dynamics simulation;network topology;polypeptide folding;complex network analysis;conformational space network	Mapping the conformational space of a polypeptide onto a network of conformational states involves a number of subjective choices, mostly in relation to the definition of conformation and its discrete nature in a network framework. Here, we evaluate the robustness of the topology of conformational-space networks derived from Molecular Dynamics (MD) simulations with respect to the use of different discretization (clustering) methods, variation of their parameters, simulation length and analysis time-step, and removing high-frequency motions from the coordinate trajectories. In addition, we investigate the extent to which polypeptide dynamics can be reproduced on the resulting networks when assuming Markovian behavior. The analysis is based on eight 500 ns and eight 400 ns MD simulations in explicit water of two 10-residue peptides. Three clustering algorithms were used, two of them based on the pair-wise root-mean-square difference between structures and one on dihedral-angle patterns. A short characteristic path length and a power-law behavior of the probability distribution of the node degree are obtained irrespective of the clustering method or the value of any of the tested parameters. The average cliquishness is consistently one or two orders of magnitude larger than that of a random realization of a network of corresponding size and connectivity. The cliquishness as function of node degree and the kinetic properties of the networks are found to be most dependent on clustering method and/or parameters. Although Markovian simulations on the networks reproduce cluster populations accurately, their kinetic properties most often differ from those observed in the MD simulations.	algorithm;anatomic node;anatomy, regional;cop9 signalosome;cpl;cell signaling;cluster analysis;clustering coefficient;computer cluster;confusion;diameter (qualifier value);digital object identifier;directed graph;discretization;first-hitting-time model;greater than;heph gene;inference;journal of computational chemistry;k-means clustering;k-medoids;kinetics;kinetics internet protocol;large;medoid;molecular dynamics;molecular dynamics;motion;network topology;node - plant part;one thousand;polypeptides;population;ps (unix);stmn1 gene;sampling (signal processing);sampling - surgical action;simulation;spatial variability;time complexity;algorithm;exponential;orders - hl7publishingdomain;statistical cluster	Roman Affentranger;Xavier Daura	2010	Journal of computational chemistry	10.1002/jcc.21476	molecular dynamics;computational chemistry;network topology	ML	6.8955682371977485	-58.51177346317169	70739
02bae752ca57e451253ef268ae8706bc79e60265	dna structural transitions within the pkd1 gene	dna;autosomal dominant polycystic kidney disease;electrophoresis gel two dimensional;trpp cation channels;single stranded;chemical modification;proteins;two dimensional gel electrophoresis;dna structure;human genome;polycystic kidney autosomal dominant;nucleic acid conformation;humans;molecular sequence data;base sequence;mutagenesis	Autosomal dominant polycystic kidney disease (ADPKD) affects over 500 000 Americans. Eighty-five percent of these patients have mutations in the PKD1 gene. The focal nature of cyst formation has recently been attributed to innate instability in the PKD1 gene. Intron 21 of this gene contains the largest polypurine. polypyrimidine tract (2.5 kb) identified to date in the human genome. Polypurine.polypyrimidine mirror repeats form intramolecular triplexes, which may predispose the gene to mutagenesis. A recombinant plasmid containing the entire PKD1 intron 21 was analyzed by two-dimensional gel electrophoresis and it exhibited sharp structural transitions under conditions of negative supercoiling and acidic pH. The superhelical density at which the transition occurred was linearly related to pH, consistent with formation of protonated DNA structures. P1 nuclease mapping studies of a plasmid containing the entire intron 21 identified four single-stranded regions where structural transitions occurred at low superhelical densities. Two-dimensional gel electrophoresis and chemical modification studies of the plasmid containing a 46 bp mirror repeat from one of the four regions demonstrated the formation of an H-y3 triplex structure. In summary, these experiments demonstrate that a 2500 bp polypurine.polypyrimidine tract within the PKD1 gene is capable of forming multiple non-B-DNA structures.	acids;electrophoresis, gel, two-dimensional;ethanol 0.62 ml/ml topical gel;experiment;focal (programming language);gel electrophoresis (lab technique);instability;introns;mutation;optic nerve glioma, childhood;patients;polycystic kidney diseases;polycystic kidney, autosomal dominant;recombinant dna;recombinants;structural modifier;tract (literature);density;nuclease	Richard T. Blaszak;Vladimir Potaman;Richard R. Sinden;John J. Bissler	1999	Nucleic acids research	10.1093/nar/27.13.2610	biology;molecular biology;bioinformatics;genetics;dna	Comp.	5.0817883609804975	-63.51876325538522	70784
2c0fdd98f75f8e60449f0662d39f4da4a83c0775	an algorithm for the identification of similar oligopeptides between amino acid sequences	cadena peptidica β;computer program;peptides;secuencia aminoacido;alignement sequence;proteine;sequence aminoacide;aminoacid sequence;chaine peptidique β;computerized processing;tratamiento informatico;virus hiv1;implementation;estudio comparativo;amino acid sequence;virus;sistema hla;hombre;human immunodeficiency virus;hiv 1 virus;alineacion secuencia;virus immunodeficience humaine;algorithme;peptido;etude comparative;algorithm;ejecucion;systeme hla;proteins;homology;glycoproteine gp120;peptide;human;comparative study;hla system;proteina;sequence alignment;fortran;lentivirinae;beta peptide chain;retroviridae;programa computador;homologia;traitement informatique;programme ordinateur;homme;algoritmo;homologie	Molecular mimicry is the origin of common structural patterns in sequences of viral and host proteins, and it appears to be related to the development of autoimmune diseases. The identification of structural molecular similarities among viral and host proteins is thus very relevant in the development of engineered antiviral vaccines to avoid potentially dangerous effects. In this respect identifying pairs of similar oligopeptides between given proteins, independently of the overall degree of similarity of their amino acid sequences, is of interest. To this aim we have designed and implemented an algorithm capable of finding and classifying (with respect to their statistical significance) all possible pairs of similar oligopeptides between two proteins irrespective of length, number, location and ordering of the pairs along the sequences. The algorithm is very efficient and much more suited for this kind of local search than standard alignment programs. The latter, dealing with the sequences as a whole, are, in these cases, of very limited applicability. We have used the algorithm to compare a glycoprotein of the human immunodeficiency virus (HIV) type 1 and with the beta-chains of human leukocyte antigen (HLA). Besides a previously identified peptide, we have found a new peptide located in the fusion site of HIV that shares high similarity with the transmembrane domains of HLA.	amino acid sequence;amino acids;antiviral agents;autoimmune diseases;classification;hiv infections;hla antigens;immunologic deficiency syndromes;leukocytes;local search (optimization);molecular mimicry;oligopeptides;p-value;structural pattern;algorithm	Valerio Balzarotti;Vittorio Colizzi;S. Morante;Valerio Parisi	1993	Computer applications in the biosciences : CABIOS	10.1093/bioinformatics/9.1.93	peptide bond;biology;homology;virus;computer science;bioinformatics;virology;comparative research;sequence alignment;peptide sequence;implementation;genetics	Comp.	-4.138877072134408	-55.52578727361236	70863
5510e05ca1e272e32e9a301ba912c281c623e540	molecular insight into γ-γ tubulin lateral interactions within the γ-tubulin ring complex (γ-turc)		γ-Tubulin is essential for the nucleation and organization of mitotic microtubules in dividing cells. It is localized at the microtubule organizing centers and mitotic spindle fibres. The most well accepted hypothesis for the initiation of microtubule polymerization is that α/β-tubulin dimers add onto a γ-tubulin ring complex (γTuRC), in which adjacent γ-tubulin subunits bind to the underlying non-tubulin components of the γTuRC. This template thus determines the resulting microtubule lattice. In this study we use molecular modelling and molecular dynamics simulations, combined with computational MM-PBSA/MM-GBSA methods, to determine the extent of the lateral atomic interaction between two adjacent γ-tubulins within the γTuRC. To do this we simulated a γ-γ homodimer for 10 ns and calculated the ensemble average of binding free energies of -107.76 kcal/mol by the MM-PBSA method and of -87.12 kcal/mol by the MM-GBSA method. These highly favourable binding free energy values imply robust lateral interactions between adjacent γ-tubulin subunits in addition to their end-interactions longitudinally with other proteins of γTuRC. Although the functional reconstitution of γ-TuRC subunits and their stepwise in vitro assembly from purified components is not yet feasible, we nevertheless wanted to recognize hotspot amino acids responsible for key γ-γ interactions. Our free energy decomposition data from converting a compendium of amino acid residues identified an array of hotspot amino acids. A subset of such mutants can be expressed in vivo in living yeast. Because γTuRC is important for the growth of yeast, we could test whether this subset of the hotspot mutations support growth of yeast. Consistent with our model, γ-tubulin mutants that fall into our identified hotspot do not support yeast growth.		Charu Suri;Triscia W. Hendrickson;Harish C. Joshi;Pradeep Kumar Naik	2014	Journal of computer-aided molecular design	10.1007/s10822-014-9779-2	crystallography;biology;biochemistry;bioinformatics	Comp.	8.199736839904926	-62.88471981339499	70885
277a93cb663640579572f432fafb93bd50a34ee5	information theoretic approach in molecular interactions and implications in molecular evolution	cellular networks;biological pattern analysis;cellular information systems;shannon s information communication theory;pattern recognition;biomolecular recognition	10 11 12 scope of application in communication technologies. The aim of this work is to present the implementation of 13 the information communication theory in the cellular recognition or molecular interaction event models to 14 quantify the message transmission capacities of molecular binding patterns and complexes. It has implications 15 in molecular evolution such that the pattern formation by varied combinations of a possible number of binding 16 events does not necessitate the presence of different types of receptor-ligand complexes. Signals through the 17 same and different types of receptor-ligand complexes seem to have equal information amounts. This is 18 suggesting the possible role of pattern formation in differentiation of distinct conditions, maybe even changing 19 local concentration gradients or so, through sensing the patterns of relevance. Further, recognition of the 20 patterns that are formed up of the same binding partners would be the step preceding the recognition of the 21 patterns with discrete binding partners. All these considerations are valid for cellular networks, wherein the 22 communicating cells are the sources of binding target molecules and are thus imposing diffusion dependent 23 concentration gradients and variations in the probabilities of the binding events. 24	gradient;interaction;interactome;pattern formation;relevance;theory	Yekbun Adiguzel	2017	Nano Comm. Netw.	10.1016/j.nancom.2016.09.002	cellular network;computer science;bioinformatics;theoretical computer science	Comp.	8.287027644512401	-65.64006307763479	70972
55eaafb003fa5eb35d7191589ce3a7720169cf7b	metaquant: a tool for the automatic quantification of gc/ms-based metabolome data	operating system;systems biology markup language;source code;open source	UNLABELLED MetaQuant is a Java-based program for the automatic and accurate quantification of GC/MS-based metabolome data. In contrast to other programs MetaQuant is able to quantify hundreds of substances simultaneously with minimal manual intervention. The integration of a self-acting calibration function allows the parallel and fast calibration for several metabolites simultaneously. Finally, MetaQuant is able to import GC/MS data in the common NetCDF format and to export the results of the quantification into Systems Biology Markup Language (SBML), Comma Separated Values (CSV) or Microsoft Excel (XLS) format.   AVAILABILITY MetaQuant is written in Java and is available under an open source license. Precompiled packages for the installation on Windows or Linux operating systems are freely available for download. The source code as well as the installation packages are available at http://bioinformatics.org/metaquant	bioinformatics;download;gas chromatography-mass spectrometry;java programming language;linux;manuscripts;markup language;metabolite;metabolome;metabolomics;microsoft windows;netcdf;open-source license;open-source software;operating system;quantitation;sbml;source code;systems biology;throughput	Boyke Bunk;Martin Kucklick;Rochus Jonas;Richard Münch;Max Schobert;Dieter Jahn;Karsten Hiller	2006	Bioinformatics	10.1093/bioinformatics/btl526	computer science;bioinformatics;operating system;database;world wide web;source code	Comp.	-2.8296763020178974	-57.81519376175111	70984
1d76c758019299a26e0ac72ceb2fbd5582cb3104	cistromemap: a knowledgebase and web server for chip-seq and dnase-seq studies in mouse and human	software;animals;mice;knowledge bases;databases genetic;chromatin immunoprecipitation;gene expression regulation;humans;oligonucleotide array sequence analysis	SUMMARY Transcription and chromatin regulators, and histone modifications play essential roles in gene expression regulation. We have created CistromeMap as a web server to provide a comprehensive knowledgebase of all of the publicly available ChIP-Seq and DNase-Seq data in mouse and human. We have also manually curated metadata to ensure annotation consistency, and developed a user-friendly display matrix for quick navigation and retrieval of data for specific factors, cells and papers. Finally, we provide users with summary statistics of ChIP-Seq and DNase-Seq studies.	base sequence;dnase b ab.streptococcal:titr:pt:ser:qn;deoxyribonuclease i;deoxyribonucleases;gene expression regulation;histones;knowledge bases;knowledge base;medical transcription;paper;server (computing);usability;web server	Bo Qin;Meng Zhou;Ying Ge;Len Taing;Tao Liu;Qian Wang;Su Wang;Junsheng Chen;Lingling Shen;Xikun Duan;Sheng'en Hu;Wei Li;Henry Long;Yong Zhang;Xiaole Shirley Liu	2012	Bioinformatics	10.1093/bioinformatics/bts157	biology;chromatin immunoprecipitation;regulation of gene expression;bioinformatics;data mining;world wide web;genetics	Web+IR	-1.7061571274309497	-59.861722728086576	71053
0f18ddb14eafd26de91c1a7d7c5575fb37910316	tutorial section: designing microarray oligonucleotide probes	bioinformatique;oligonucleotide probe;oligonucleotide;oligonucleotido;bioinformatica;bioinformatics	INTRODUCTION DNA microarrays are one of a few technologies that enable the monitoring of thousands of gene expression levels in parallel. In general, microarrays comprise a solid planar substrate on which an ordered array of probes has been deposited. Each probe represents a gene or transcript of interest and there are essentially three main types of probe: polymerase chain reaction (PCR) products of cDNA clones, ‘long’ oligonucleotides and ‘short’ oligonucleotides. Synthetic oligonucleotides, long or short, offer a number of practical advantages over cDNA clones for constructing arrays, making oligonucleotides an attractive alternative. The ease of automated synthesis, in comparison to the preparation of libraries of cDNA molecules, is a major attraction. In addition, synthetic probes offer the possibility of precise control over the composition and size of each probe. There is also the possibility of using nonnatural nucleic acid analogues in the construction of oligonucleotide arrays, which may have advantages. Peptide nucleic acids (PNA), for example, have a neutral backbone that overcomes the usual, mutual repulsion of a duplex of natural phosphodiesters. Hence PNA has a higher binding affinity for DNA and shows greater stringency in hybridisation than DNA. Finally, oligonucleotide probes can be designed based on published sequences in a wide variety of databases and, consequently, there has been a substantial interest in the development of bioinformatics tools that allow for the design of oligonucleotide probes from these databases.	array data structure;bioinformatics;cross-reference;dna microarray;database;duplex (telecommunications);fax;homepna;internet backbone;library (computing);mail (macos);processor affinity;synthetic data;synthetic intelligence;uniform resource identifier;world wide web	Roslin Russell	2003	Briefings in Bioinformatics	10.1093/bib/4.4.361	biology;bioinformatics;oligomer restriction;dna-encoded chemical library;oligonucleotide	Comp.	-2.760766619599217	-59.49795021134435	71129
ca24e62f5addaee149f092feb5cd306d17b139f6	comparative analysis of tools for predicting the functional impact of mtdna variants		Recent advances in DNA sequencing technologies has transformed the study of DNA sequence variation. Over the last decade, the development of a number of functional impact predictors and annotation tools have been implemented to aid in this DNA variant analysis. While many annotation tools and pipelines have been built to annotate nuclear genome variants, only a few software predictors address the thousands of variants found in human mitochondrial DNA. Many prediction tools built for nuclear DNA have been retrofitted to annotate mitochondrial DNA, but because of the vast differences between the two, nuclear annotators fail to produce accurate predictions for mitochondrial mutations. Conventional annotation tools and predictors such as SIFT and PolyPhen2 are a few of the tools that produce less than accurate pathogenicity scores for mitochondrial variants. More recently, tools such as APOGEE have addressed the need for specialized tools to annotate mtDNA exonic variants with high-confidence. In addition, most of the annotation tools only annotate exonic mutations, but variants in mitochondrial tRNA and rRNA are important and are a common cause of mitochondrial disease. A few papers have addressed the need to accurately predict the pathogenicity of tRNA variants, such as MitoTIP, while no known tools exist for annotating rRNA variant pathogenicity for mtDNA variants. We have constructed a comparative analysis of both standard and non-standard annotation tools and their ability to accurately predict the pathogenicity of mitochondrial mutations. We carefully curated a complete list of all potential non-synonymous exonic, tRNA and rRNA mitochondrial mutations and ran selected tools for each dataset. We have analyzed the accuracy and precision of each tool compared to the consensus among the tools combined with pathogenicity predictions from MITOMAP disease associations. Over the course of our testing, we confirmed that many of the prediction tools typically used for nuclear DNA were subpar when tested on mitochondrial DNA. Newer annotation tools built specifically for mtDNA such as APOGEE had higher overall assessment scores. Based on our analysis, we are creating an online annotation tool specifically for mtDNA variants that integrates pathogencity scores from our top-rated prediction tools.	dna barcoding;pipeline (computing);qualitative comparative analysis;scale-invariant feature transform	Madeline P. Griffin;Catherine E. Welsh	2018		10.1145/3233547.3233643	human mitochondrial genetics;computational biology;machine learning;transfer rna;nuclear gene;mitochondrial disease;dna sequencing;artificial intelligence;mitochondrial dna;nuclear dna;annotation;computer science	Comp.	1.3552695891478368	-55.308508185541434	71150
df2a2ea85b6b32c24a0af1ac6941f2a7edffe21f	an efficient method to identify essential proteins for different species by integrating protein subcellular localization information	protein subcellular localization information;protein protein interaction networks essential protein protein subcellular localization information;proteins gold;essential protein;protein protein interaction networks;topology biochemistry cellular biophysics microorganisms molecular biophysics proteins;topology indispensable efficient method integrating protein subcellular localization information living organisms pathology synthetic biology drug design computational methods protein protein interaction networks compartment importance centrality method integrating protein subcellular localization information saccharomyces cerevisiae homo sapiens mus musculus drosophila melanogaster	Essential proteins are indispensable to maintain life activities in living organisms, and play important roles in the studies of pathology, synthetic biology, and drug design. Many computational methods are employed to identify essential proteins from Protein-protein Interaction Networks (PINs). In this paper, considering the different importance of protein-protein interactions which take place in different subcellular compartments, a Compartment Importance Centrality (CIC) method is proposed to detect essential proteins by integrating protein subcellular localization information. The experiments were carried on four species (Saccharomyces cerevisiae, Homo sapiens, Mus musculus and Drosophila melanogaster), and the performance of CIC was compared with other centrality methods, including the centrality methods solely based on topology and the ones combining both topology and other biological knowledge. The results show that CIC method has better performance to predict essential protein on four species. Furthermore, different from methods which overfits with the features of essential proteins of one species and may perform poor for other species, CIC has a wide applicable scope to identify essential proteins for different species.	centrality;experiment;interaction;multi-compartment model;overfitting;synthetic biology	Xiaoqing Peng;Jianxing Wang;Jiancheng Zhong;Junwei Luo;Yi Pan	2015	2015 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2015.7359693	biology;cell biology;bioinformatics;protein subcellular localization prediction;protein function prediction	Comp.	5.989872381054811	-57.33465821059265	71220
9c2a8ff273f7f119d6165abe4c96a4d440feb4ac	hvrbase++: a phylogenetic database for primate species	animals;dna mitochondrial;genetics population;phylogeny;databases nucleic acid;computer graphics;web interface;sequence analysis dna;internet;mitochondrial genome;primates;humans;user computer interface;interactive graphics;027 743613;x chromosome;wien universitatsbibliothek;chromosomes mammalian	HvrBase++ is the improved and extended version of HvrBase. Extensions are made by adding more population-based sequence samples from all primates including humans. The current collection comprises 13,873 hypervariable region I (HVRI) sequences and 4940 hypervariable region II (HVRII) sequences. In addition, we included 1376 complete mitochondrial genomes, 205 sequences from X-chromosomal loci and 202 sequences from autosomal chromosomes 1, 8, 11 and 16. In order to reduce the introduction of erroneous data into HvrBase++, we have developed a procedure that monitors GenBank for new versions of the current data in HvrBase++ and automatically updates the collection if necessary. For the stored sequences, supplementary information such as geographic origin, population affiliation and language of the sequence donor can be retrieved. HvrBase++ is Oracle based and easily accessible by a web interface (http://www.hvrbase.org). As a new key feature, HvrBase++ provides an interactive graphical tool to easily access data from dynamically created geographical maps.	autosome;chromosomes;complementarity determining regions;electronic supplementary materials;genbank;genome;genome, mitochondrial;graphical user interface;map;phylogenetics;primates;region-based memory management;version	Jochen Kohl;Ingo Paulsen;Thomas Laubach;Achim Radtke;Arndt von Haeseler	2006	Nucleic Acids Research	10.1093/nar/gkj030	biology;the internet;mitochondrial dna;bioinformatics;computer graphics;user interface;genetics;x chromosome;phylogenetics	Theory	-2.156543238424853	-59.84878611030918	71244
13412605b9be074f7a803a8cc9d36f0286650009	the sufficient minimal set of mirna seed types	semilla;rna interference;animals;mice;rna messenger;semence;seeds;interference arn;arn interferencia;silence expression genique;micro arn;micro rna;oligonucleotides;gene silencing;silencio expresion genetica;semillas;algorithms;seed;humans;graine;base sequence;eukaryotic initiation factors;micrornas;gene expression profiling;oligonucleotide array sequence analysis	MOTIVATION Pairing between the target sequence and the 6-8 nt long seed sequence of the miRNA presents the most important feature for miRNA target site prediction. Novel high-throughput technologies such as Argonaute HITS-CLIP afford meanwhile a detailed study of miRNA:mRNA duplices. These interaction maps enable a first discrimination between functional and non-functional target sites in a bulky fashion. Prediction algorithms apply different seed paradigms to identify miRNA target sites. Therefore, a quantitative assessment of miRNA target site prediction is of major interest.   RESULTS We identified a set of canonical seed types based on a transcriptome wide analysis of experimentally verified functional target sites. We confirmed the specificity of long seeds but we found that the majority of functional target sites are formed by less specific seeds of only 6 nt indicating a crucial role of this type. A substantial fraction of genuine target sites arenon-conserved. Moreover, the majority of functional sites remain uncovered by common prediction methods.	argonaute proteins;binding sites;contain (action);cross-linking immunoprecipitation high-throughput sequencing;experiment;high-throughput computing;map;micrornas;plant seeds;seed;seeds (cellular automaton);sensitivity and specificity;silo (dataset);specification;systems biology;throughput;transcriptome;word lists by frequency;algorithm	Daniel C. Ellwanger;Florian Buettner;Hans-Werner Mewes;Volker Stümpflen	2011		10.1093/bioinformatics/btr149	biology;molecular biology;bioinformatics;genetics;microrna	Comp.	3.1665584823546333	-58.73338771227136	71337
414e15d9918eeb0acd338acbfe17e812bf834992	ribopeaks: a web tool for bacterial classification through m/z data from ribosomal proteins		Summary MALDI-TOF MS is a rapid, sensitive and economic tool for bacterial identification. Highly abundant bacterial proteins are detected by this technique, including ribosomal proteins (r-protein), and the generated mass spectra are compared with a MALDI-TOF MS spectra database. Currently, it allows mainly the classification of clinical bacteria due to the limited number of environmental bacteria included in the spectra database. We present a wide-ranging bacterium classifier tool, called Ribopeaks, which was created based on r-protein data from the Genbank. The Ribopeaks database has more than 28 500 bacterial taxonomic records. It compares the incoming m/z data from MALDI-TOF MS analysis with models stored in the Ribopeaks database created by machine learning and then taxonomically classifies the bacteria.   Availability and implementation The software is available at http://www.ribopeaks.com.   Supplementary information Supplementary data are available at Bioinformatics online.		Douglas Tomachewski;Carolina Weigert Galvão;Arion de Campos Júnior;Alaine Margarete Guimarães;José Carlos Ferreira da Rocha;Rafael Mazer Etto	2018	Bioinformatics	10.1093/bioinformatics/bty215	bacterial taxonomy;computer science;bioinformatics;ribosomal protein	Comp.	-0.3177496585989552	-59.20128482903589	71357
168d29a70ef56a32320f952c83b585df24fe77ff	an individualized predictor of health and disease using paired reference and target samples	influenza a virus h3n2 subtype;respiratory syncytial viruses;genes essential;sparse multi block classifier algorithm;reference aided prediction;pedestrian safety;poison control;automated diagnostics;injury prevention;rhinovirus;safety literature;traffic safety;injury control;computational biology bioinformatics;home safety;gene expression;microarray analysis;injury research;models molecular;safety abstracts;human factors;biomarker discovery;precision medicine;occupational safety;safety;virus diseases;safety research;algorithms;influenza a virus h1n1 subtype;accident prevention;violence prevention;humans;bicycle safety;combinatorial libraries;poisoning prevention;computer appl in life sciences;falls;ergonomics;genetic markers;suicide prevention;microarrays;bioinformatics	Consider the problem of designing a panel of complex biomarkers to predict a patient’s health or disease state when one can pair his or her current test sample, called a target sample, with the patient’s previously acquired healthy sample, called a reference sample. As contrasted to a population averaged reference this reference sample is individualized. Automated predictor algorithms that compare and contrast the paired samples to each other could result in a new generation of test panels that compare to a person’s healthy reference to enhance predictive accuracy. This paper develops such an individualized predictor and illustrates the added value of including the healthy reference for design of predictive gene expression panels. The objective is to predict each subject’s state of infection, e.g., neither exposed nor infected, exposed but not infected, pre-acute phase of infection, acute phase of infection, post-acute phase of infection. Using gene microarray data collected in a large scale serially sampled respiratory virus challenge study we quantify the diagnostic advantage of pairing a person’s baseline reference with his or her target sample. The full study consists of 2886 microarray chips assaying 12,023 genes of 151 human volunteer subjects under 4 different inoculation regimes (HRV, RSV, H1N1, H3N2). We train (with cross-validation) reference-aided sparse multi-class classifier algorithms on this data to show that inclusion of a subject’s reference sample can improve prediction accuracy by as much as 14 %, for the H3N2 cohort, and by at least 6 %, for the H1N1 cohort. Remarkably, these gains in accuracy are achieved by using smaller panels of genes, e.g., 39 % fewer for H3N2 and 31 % fewer for H1N1. The biomarkers selected by the predictors fall into two categories: 1) contrasting genes that tend to differentially express between target and reference samples over the population; 2) reinforcement genes that remain constant over the two samples, which function as housekeeping normalization genes. Many of these genes are common to all 4 viruses and their roles in the predictor elucidate the function that they play in differentiating the different states of host immune response. If one uses a suitable mathematical prediction algorithm, inclusion of a healthy reference in biomarker diagnostic testing can potentially improve accuracy of disease prediction with fewer biomarkers.	baseline (configuration management);biological markers;categories;cross reactions;cross-validation (statistics);dna microarray format;diagnostic tests;gene expression programming;heart rate variability;kerrison predictor;mathematics;murine sarcoma viruses;numerous;patients;reinforcement learning;respiratory syncytial virus;sampling - surgical action;small;sparse matrix;algorithm	Tzu-Yu Liu;Thomas Burke;Lawrence P. Park;Christopher W. Woods;Aimee K. Zaas;Geoffrey S. Ginsburg;Alfred O. Hero	2016		10.1186/s12859-016-0889-9	biology;microarray analysis techniques;gene expression;dna microarray;bioinformatics;suicide prevention;human factors and ergonomics;injury prevention;genetic marker;precision medicine;biomarker discovery	ML	7.222869918203798	-53.67276349439265	71433
4a9829e96a5497bc9829149d331be5e3fd28f64e	proteomic analysis of bovine nucleolus	lc ms ms;nucleolus;scx;cation exchange;1d sds page;madin darby bovine kidney;structure and function;bovine;amrutlal k patel doug olson suresh k tikoo 蛋白质组分 细胞核 lc ms ms 牛 核仁结构 数据库检索 细胞周期调控 色谱分离 proteomic analysis of bovine nucleolus;cell cycle control;proteome analysis;proteomics;database search	Nucleolus is the most prominent subnuclear structure, which performs a wide variety of functions in the eukaryotic cellular processes. In order to understand the structural and functional role of the nucleoli in bovine cells, we analyzed the proteomic composition of the bovine nucleoli. The nucleoli were isolated from Madin Darby bovine kidney cells and subjected to proteomic analysis by LC-MS/MS after fractionation by SDS-PAGE and strong cation exchange chromatography. Analysis of the data using the Mascot database search and the GPM database search identified 311 proteins in the bovine nucleoli, which contained 22 proteins previously not identified in the proteomic analysis of human nucleoli. Analysis of the identified proteins using the GoMiner software suggested that the bovine nucleoli contained proteins involved in ribosomal biogenesis, cell cycle control, transcriptional, translational and post-translational regulation, transport, and structural organization.	bos taurus;cations;cattle;cell cycle control;cell nucleolus;contain (action);genetic translation process;gominer;mascot scoring engine;morphogenesis;polyacrylamide gel electrophoresis;proteomics;renal tissue;transcription, genetic;translational regulation	Amrutlal K. Patel;Doug Olson;Suresh K. Tikoo	2010		10.1016/S1672-0229(10)60017-4	biology;molecular biology;database search engine;cation-exchange capacity;bioinformatics;proteomics;nucleolus	Comp.	5.795740385490259	-62.68840810572893	71455
02f9546fa1ee0cfa93a825d98f912b2f30301658	an algorithm for modularity analysis of directed and weighted biological networks based on edge-betweenness centrality	betweenness centrality;biological network	MOTIVATION Modularity analysis is a powerful tool for studying the design of biological networks, offering potential clues for relating the biochemical function(s) of a network with the 'wiring' of its components. Relatively little work has been done to examine whether the modularity of a network depends on the physiological perturbations that influence its biochemical state. Here, we present a novel modularity analysis algorithm based on edge-betweenness centrality, which facilitates the use of directional information and measurable biochemical data.	algorithm;betweenness centrality;biological network;wiring	Jeongah Yoon;Anselm Blumer;Kyongbum Lee	2006	Bioinformatics	10.1093/bioinformatics/btl533	network theory;network science;biology;biological network;computer science;bioinformatics;artificial intelligence;modularity;alpha centrality;machine learning;betweenness centrality	Comp.	5.716579165722109	-58.409301646132285	71558
2e572a6ae53d769d4469f3e2ab3030e8e6cbbfca	chemical method for dna sequence determination from the 5'-extremity on pcr amplified fragments	produit reaction;saccharomyces cerevisiae;analisis estructural;reaction chaine polymerase;rna ribosomal 5s;reaction product;formamides;secuencia nucleotido;piperidines;nucleotide sequence;sequence nucleotide;fragmento nucleotido;polymerase chain reaction;reaccion cadena polimerasa;extremite 5 p;fragment nucleotidique;metodo quimico;producto reaccion;molecular sequence data;methode chimique;analyse structurale;base sequence;extremidad 5 p;dna sequence;structural analysis;5 end;chemical method;nucleotide fragment	"""We have previously described a protocol for the' chemical sequencing of 3'-labelled DNA (1), further developed for onelane fluorescent DNA analysis (2). The method can be coupled to an automatized system (laser scan) and to a quantitative software that allows a rapid determination of the sequence of cloned, dideoxy fluorescently terminally labelled DNA. The resulting procedure (2) is based on the treatment of DNA with piperidine and formamide, in this order, and is particularly useful for the identification of mutations. This method is not suited for the sequencing of 5 '-labelled DNA because the reaction with formamide (alone or used after piperidine treatment) results in smeared sequence profiles (1), due to the preferential cleavage of the phosphodiester bond at the 3' side and to the concurrent, less efficient cleavage at the 5' side (4). It is known that piperidine efficiently cleaves phosphodiester bonds at both the 3' and 5' sides of removed or damaged bases (3), in addition to a base-selective cleavage (2, 4). Therefore the following protocol based essentially on the inversion of the 'piperidine followed by formamide' treatments was developed, yielding base-selective and non-smeared cleavages. This protocol allows the sequence determination of 5'-labelled DNA fragments, obtained by amplification from radioactive or fluorescent oligos (Figures 1 and 3) or by kinase end-labeling (Figure 2). 1 5 ng ( .5-2x 10 cpm) of 5'-labelled DNA were dissolved in 80% formamide, and heated 10 min. at 110°C. After cooling on ice, piperidine was added to 10% final concentration and the sample was heated 30 min. at 95°C. After 5-fold dilution with water and evaporation to the original volume (to eliminate piperidine) the sample was denatured (2 min., 90°C) and loaded on a sequencing gel. Alternatively, piperidine can be eliminated by ethanol precipitation. One practical important feature of the protocol used is that piperidine is added directly to the DNA-containing formamide hot aqueous solution, thus making the whole procedure simple and rapid. The intensity of the bands produced i s G > A > O T . This method can be used to sequence a DNA fragment starting directly from genomic DNA, amplifying it with two oligos, one of which is 5'-labelled. After amplification, the DNA product is ethanol-precipitated or purified on a gel filtration column and sequenced (Figure la). The method is compatible with fluorescent labelling, thus allowing direct and accurate quantitative evaluation (Figure lb). In the case of ambiguity, an easy solution is provided Figure 1. Sequencing of PCR-amplified DNA samples by fonnamide-piperidine treatment, a. A 170 bp portion of the S.cerevisiae 5S RNA repeat gene (1) was PCR-amplified using as a template 5 ng of pBBl 11R piasmid (3125 bp) containing the entire gene. Two internal 20 bp-long oligonucleotides were used as primers, one of which had been terminally labelled at the 5'-end by polynucleotide kinase. The amplification mixture (20 cycles) was ethanol !""""•*• i|iimn-H, treated as described in the text and loaded on a 6% sequencing gel. Scanning denshometry (coding strand from residue +57 to +89) is shown, b. Densitogram obtained by the 373A automatic sequencer (ABI) software (2) on a DNA sample amplified using an ABI fluorescently labelled primer and treated as in Figure la."""	2',5'-oligoadenylate;ankle brachial pressure index (observable entity);application binary interface;bands;base;biopolymer sequencing;clinical use template;clone cells;computer cooling;cool - action;eighty nine;ethanol;evaporation;formamide (substance);gel chromatography;lactic acid;linear algebra;maxima and minima;microsequencer;mutation;oligonucleotides;pnkp gene;primer;polynucleotides;position weight matrix;probability of precipitation;rna;radioactivity;sol-gel;strand (programming language);phosphodiester;poly-n-oxy-1-2-ethylene piperidine	Rodolfo Negri;Sergio Ferraboli;Sergio Barlati;Ernesto Di Mauro	1994	Nucleic acids research	10.1093/nar/22.1.111	amplified fragment length polymorphism;biology;biochemistry;dna sequencing;molecular biology;primer dimer;nucleic acid sequence;polymerase chain reaction;rapd;structural analysis;genetics	Comp.	3.8197402140297276	-63.92547545354801	71722
1f18b73c659e966bb9a3494881a90c4b11c86ef6	the reduced graph descriptor in virtual screening and data-driven clustering of high-throughput screening data	high throughput screening;virtual screening	Virtual screening and high-throughput screening are two major components of lead discovery within the pharmaceutical industry. In this paper we describe improvements to previously published methods for similarity searching with reduced graphs, with a particular focus on ligand-based virtual screening, and describe a novel use of reduced graphs in the clustering of high-throughput screening data. Literature methods for reduced graph similarity searching encode the reduced graphs as binary fingerprints, which has a number of issues. In this paper we extend the definition of the reduced graph to include positively and negatively ionizable groups and introduce a new method for measuring the similarity of reduced graphs based on a weighted edit distance. Moving beyond simple similarity searching, we show how more flexible queries can be built using reduced graphs and describe a database system that allows iterative querying with multiple representations. Reduced graphs capture many important features of ligand-receptor interactions and, in conjunction with other whole molecule descriptors, provide an informative way to review HTS data. We describe a novel use of reduced graphs in this context, introducing a method we have termed data-driven clustering, that identifies clusters of molecules represented by a particular whole molecule descriptor and enriched in active compounds.	cluster analysis;database;dosage forms;edit distance;encode (action);fingerprint;graph - visual representation;high-throughput computing;high-throughput satellite;hypotrichosis simplex;information;interaction;iterative method;ligands;scientific publication;throughput;virtual screening;statistical cluster	Gavin Harper;Gianpaolo Bravi;Stephen D. Pickett;Jameed Hussain;Darren V. S. Green	2004	Journal of chemical information and computer sciences	10.1021/ci049860f	edit distance;combinatorics;theoretical computer science;virtual screening;high-throughput screening;cluster analysis;graph;computer science;artificial intelligence;pattern recognition	ML	2.734406069636743	-57.01929115351137	71735
217ae0d0e6081e7aafe3d6376549c1f46b587e2b	promir ii: a web server for the probabilistic prediction of clustered, nonclustered, conserved and nonconserved micrornas	model identification;software;animals;genomics;mice;rats;genome viral;computational method;conserved sequence;internet;human genome;snu;models statistical;efficiency analysis;humans;user computer interface;base sequence;micrornas;microrna;free energy;multigene family;web based service	ProMiR is a web-based service for the prediction of potential microRNAs (miRNAs) in a query sequence of 60-150 nt, using a probabilistic colearning model. Identification of miRNAs requires a computational method to predict clustered and nonclustered, conserved and nonconserved miRNAs in various species. Here we present an improved version of ProMiR for identifying new clusters near known or unknown miRNAs. This new version, ProMiR II, integrates additional evidence, such as free energy data, G/C ratio, conservation score and entropy of candidate sequences, for more controllable prediction of miRNAs in mouse and human genomes. It also provides a wider range of services, e.g. the prediction of miRNA genes in long nonrelated sequences such as viral genomes. Importantly, we have validated this method using several case studies. All data used in ProMiR II are structured in the MySQL database for efficient analysis. The ProMiR II web server is available at http://cbit.snu.ac.kr/~ProMiR2/.	micrornas;mysql;question (inquiry);server (computer);server (computing);viral genome;web application;web server;free energy;negative regulation of phosphorylation of rna polymerase ii c-terminal domain	Jin-Wu Nam;Jinhan Kim;Sung-Kyu Kim;Byoung-Tak Zhang	2006	Nucleic Acids Research	10.1093/nar/gkl321	biology;genomics;bioinformatics;genetics;microrna	Comp.	0.3490502550533811	-59.053037123602316	71815
ee82066d54aa71a4d4b44f495d3a9d9d4efbf7ab	identifying complexes from protein interaction networks according to different types of neighborhood density	software;proteins;neighborhood density;protein complexes;algorithms;protein interaction mapping;protein interaction maps;protein interaction networks	To facilitate the realization of biological functions, proteins are often organized into complexes. While computational techniques are used to predict these complexes, detailed understanding of their organization remains inadequate. Apart from complexes that reside in very dense regions of a protein interaction network in which most algorithms are able to identify, we observe that many other complexes, while not residing in very dense regions, reside in regions with low neighborhood density. We develop an algorithm for identifying protein complexes by considering these two types of complexes separately. We test our algorithm on a few yeast protein interaction networks, and show that our algorithm is able to identify complexes more accurately than existing algorithms. A software program NDComplex for implementing the algorithm is available at http://faculty.cse.tamu.edu/shsze/ndcomplex.		Jia-Hao Fan;Jianer Chen;Sing-Hoi Sze	2012	Journal of computational biology : a journal of computational molecular cell biology	10.1089/cmb.2012.0195	biology;bioinformatics;machine learning;data mining;multiprotein complex;algorithm	Comp.	3.810997417646579	-57.36754255641191	71828
00944a7cfa9bcfae9d96ce4c9f4f273d7c9a1ab1	new descriptors of evolutionary information for accurate prediction of dna and rna-binding residues in protein sequences	dna;model specification;protein function;dna or rna binding site prediction;position specific scoring matrix;evolutionary information descriptors;support vector machines;protein sequence;selection;dna binding residues;dna binding;site directed mutagenesis;binding site;support vector machines bioinformatics dna proteomics;machine learning dna or rna binding site prediction evolutionary information descriptors feature extraction selection support vector machines;machine learning;protein sequences;feature extraction;biological sequence analysis;dna proteins sequences amino acids support vector machines support vector machine classification artificial neural networks biological information theory biological system modeling encoding;support vector machine;mutagenesis evolutionary information descriptors dna binding residues rna binding residues protein sequences position specific scoring matrix biological sequence analysis support vector machines;proteomics;mutagenesis;nucleic acid;rna binding residues;bioinformatics	Evolutionary information in terms of position-specific scoring matrix (PSSM) has been often used to construct classifiers for biological sequence analyses. However, PSSM is rather designed for PSI-BLAST searches, and it may not contain all the evolutionary information for modeling specific sequence patterns. In this study, several new descriptors of evolutionary information have been developed and evaluated for sequence-based prediction of DNA and RNA-binding residues using support vector machines (SVMs). The new descriptors were shown to improve classifier performance. Interestingly, the best classifiers were obtained by combining the new descriptors and PSSM, suggesting that they captured different aspects of evolutionary information for DNA and RNA-binding site prediction. The SVM classifiers achieved 77.3% sensitivity and 79.3% specificity for prediction of DNA-binding residues, and 71.6% sensitivity and 78.7% specificity for RNA-binding site prediction. Predictions at this level of accuracy may provide useful information for protein functional annotation, protein-nucleic acid docking and experimental studies such as site-directed mutagenesis.	blast;docking (molecular);position weight matrix;sensitivity and specificity;server (computing);statistical classification;support vector machine;web server	Liangjiang Wang;Caiyan Huang	2009	2009 International Joint Conference on Bioinformatics, Systems Biology and Intelligent Computing	10.1109/IJCBS.2009.102	biology;support vector machine;computer science;bioinformatics;machine learning;pattern recognition;proteomics;genetics	Comp.	9.525834364473205	-56.53296145003053	71894
efe1142fe5b3d29f6a27e59bddf842cdf87d56b3	a possible mechanism for determining the directionality of myosin molecular motors	actin filaments;processive;driving force;actin;myosin;direction;computer simulation;structure;molecular motor;elastic energy	There is a large superfamily of myosins, which play various fundamental roles in cellular motility. In this superfamily, most of myosins, including myosins II and V, move to the barbed end of an actin filament, whereas myosin VI was found to move in the opposite direction to the pointed end. Although myosin VI has structural differences compared with the other myosins, the mechanism for the reversal of the directionality has not been satisfactorily explained by conventional theories for myosin motility, including the widely accepted lever-arm hypothesis. In this paper, a simple mechanism for determining the directionality is proposed. The mechanism assumes that the driving force for the power stroke is caused by elastic energy stored within a myosin molecule at the joint between the head and the neck. The elastic energy originates from the attractive force between myosin and actin, and accumulates during the docking process. The energy of ATP is used to reduce the attractive force between myosin and actin and to facilitate the dissociation of these molecules. Therefore, it is not directly engaged in the power stroke. With this mechanism, the directionality of the myosin motility is simply determined by the direction of the neck with respect to the head in the dissociated configuration. This structural difference is actually observed in myosin VI. The same mechanism also explains the behavior of a backward moving engineered myosin. Computer simulations demonstrated the feasibility of this working mechanism.	actins;adenosine triphosphate;boat dock;cerebrovascular accident;computer simulation;cytoskeletal filaments;docking (molecular);microfilaments;myosin atpase;superfamily;myosin vi	Tadashi Masuda	2008	Bio Systems	10.1016/j.biosystems.2008.03.009	computer simulation;actin;myosin head;biology;nanotechnology;genetics;anatomy	AI	9.27448903119511	-64.33216807613717	71909
392b485755cf5374b0f14031884291c1eceeadba	kernel methods for calmodulin binding and binding site prediction	amino acid;calcium binding protein;binding site;gene function prediction;hierarchical multilabel classification;machine learning;yeast two hybrid;roc curve;kernel method;binding protein;false positive;high throughput;calmodulin;data integration;bioinformatics;gene ontology	Calmodulin (CaM) is a calcium-binding protein that is involved in a variety of cellular processes, interacting with many proteins. Since many CaM interactions are calcium-dependent, they are difficult to detect using high-throughput methods like yeast-two-hybrid. Furthermore, detection of CaM binding sites requires a significant experimental effort. Using a collection of CaM binding sites extracted from the Calmodulin Target Database we trained SVM-based classifiers to detect CaM binding sites using a variety of sequence features; our best classifier achieved an area under the ROC curve of 0.89 for detecting binding site locations at the amino acid level. We apply our classifiers to the problem of detecting CaM binding proteins in Arabidopsis; at a false-positive level of 0.05 we detected 638 novel putative CaM binding proteins. These proteins share overrepresented Gene Ontology terms associated with the functions of known CaM binders.	gene ontology;high-throughput computing;interaction;kernel method;receiver operating characteristic;sensor;throughput;two-hybrid screening	Michael Hamilton;A. S. N. Reddy;Asa Ben-Hur	2011		10.1145/2147805.2147855	biology;bioinformatics;machine learning;pattern recognition	Comp.	9.2969781035282	-56.24346052241381	71987
b6cd3660ceac492f9d3c89d63e9eae1bc4e388ac	network-based analysis of genotype-phenotype correlations between different inheritance modes		MOTIVATION Recent studies on human disease have revealed that aberrant interaction between proteins probably underlies a substantial number of human genetic diseases. This suggests a need to investigate disease inheritance mode using interaction, and based on which to refresh our conceptual understanding of a series of properties regarding inheritance mode of human disease.   RESULTS We observed a strong correlation between the number of protein interactions and the likelihood of a gene causing any dominant diseases or multiple dominant diseases, whereas no correlation was observed between protein interaction and the likelihood of a gene causing recessive diseases. We found that dominant diseases are more likely to be associated with disruption of important interactions. These suggest inheritance mode should be understood using protein interaction. We therefore reviewed the previous studies and refined an interaction model of inheritance mode, and then confirmed that this model is largely reasonable using new evidences. With these findings, we found that the inheritance mode of human genetic diseases can be predicted using protein interaction. By integrating the systems biology perspectives with the classical disease genetics paradigm, our study provides some new insights into genotype-phenotype correlations.   CONTACT haodapeng@ems.hrbmu.edu.cn or biofomeng@hotmail.com   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	bioinformatics;denial-of-service attack;endocrine system diseases;genes, vif;hematological disease;hereditary diseases;interaction;mode of inheritance;programming paradigm;systems biology	Dapeng Hao;Chuanxing Li;Shaojun Zhang;Jianping Lu;Yongshuai Jiang;Shiyuan Wang;Meng Zhou	2014	Bioinformatics	10.1093/bioinformatics/btu482	biology;bioinformatics;genetics	Comp.	5.639174051317692	-60.652178275751425	72207
262ed3c7ca2bafecb77bfd7e766de426cd081226	combining multiple microarray studies and modeling interstudy variation	effect size;permutation test;gene expression;statistical significance;data integrity;meta analysis;difference set;random effects model;fixed effects model;indexation	We have established a method for systematic integration of multiple microarray datasets. The method was applied to two different sets of cancer profiling studies. The change of gene expression in cancer was expressed as 'effect size', a standardized index measuring the magnitude of a treatment or covariate effect. The effect sizes were combined to obtain the estimate of the overall mean. The statistical significance was determined by a permutation test extended to multiple datasets. It was shown that the data integration promotes the discovery of small but consistent expression changes with increased sensitivity and reliability. The effect size methods provided the efficient modeling framework for addressing interstudy variation as well. Based on the result of homogeneity tests, a fixed effects model was adopted for one set of datasets that had been created in controlled experimental conditions. By contrast, a random effects model was shown to be appropriate for the other set of datasets that had been published by independent groups. We also developed an alternative modeling procedure based on a Bayesian approach, which would offer flexibility and robustness compared to the classical procedure.	doppler effect;entity name part qualifier - adopted;fixed effects model;gene expression;microarray;neoplasms;p-value;profiling (computer programming);random effects model;resampling (statistics);robustness (computer science);scientific publication	Jung Kyoon Choi;Ungsik Yu;Sangsoo Kim;Ook Joon Yoo	2003	Bioinformatics		econometrics;meta-analysis;gene expression;resampling;bioinformatics;fixed effects model;data integrity;mathematics;statistical significance;effect size;difference set;statistics;random effects model	Comp.	5.471926229873829	-52.72064904443772	72231
04a1142034d0957187cdb8950e4865d254f422fe	a summary of genomic databases: overview and discussion	data format;biological data;biological database	In the last few years both the amount of electronically stored biological data and the number of biological data repositories grew up significantly (today, more than eight hundred can be counted thereof). In spite of the enormous amount of available resources, a user may be disoriented when he/she searches for specific data. Thus, the accurate analysis of biological data and repositories turn out to be useful to obtain a systematic view of biological database structures, tools and contents and, eventually, to facilitate the access and recovery of such data. In this chapter, we propose an analysis of genomic databases, which are databases of fundamental importance for the research in bioinformatics. In particular, we provide a small catalog of 74 selected genomic databases, analyzed and classified by considering both their biological contents and their technical features (e.g, how they may be queried, the database schemas they are based on, the different data formats, etc.). We think that such a work may be an useful guide and reference for everyone needing to access and to retrieve information from genomic databases.	bioinformatics;biological database;database schema	Erika De Francesco;Giuliana Di Santo;Luigi Palopoli;Simona E. Rombo	2009		10.1007/978-3-642-02193-0_3	computer science;bioinformatics;data mining;information retrieval;database testing	DB	-4.531047792322745	-62.045134522652745	72243
09d4315058124e9efcad8b7dfb6d201598a15200	cpipe: a comprehensive computational platform for sequence and structure-based analyses of cysteine residues		Summary Due to their chemical plasticity, Cysteine residues (Cys) can serve many different functions. Identification and classification of reactive Cys isn't a trivial job: currently, no available tool exists for an all-round, comprehensive (inclusive of all different functional types) analysis of Cys; herein we present a computational platform called Cp i pe, dedicated to this task: it implements state-of-the art protocols, elaborating and displaying a wealth of information, sufficiently orthogonal to allow a thorough evaluation of all major aspects of Cys reactivity.   Availability and Implementation Cp i pe is implemented in Python and freely available at http://cpipe.explora-biotech.com/cpipe/start.py . All major browsers are supported.   Contact s.marino@explora-biotech.com.   Supplementary information Supplementary data are available at Bioinformatics online.		Inanc Soylu;Stefano M. Marino	2017	Bioinformatics	10.1093/bioinformatics/btx181	computer science;cysteine;bioinformatics	Comp.	-0.3836626274169407	-58.02574893983248	72392
408b210f25274d2e085a37a087a7cbf63253fa3c	co-expression network analysis identifies spleen tyrosine kinase (syk) as a candidate oncogenic driver in a subset of small-cell lung cancer	simulation and modeling;cell survival;systems biology;gene regulatory networks;molecular targeted therapy;physiological cellular and medical topics;computational biology bioinformatics;oncogene proteins;cell line tumor;cell proliferation;small cell lung carcinoma;algorithms;humans;proteomics;lung neoplasms;gene expression profiling;gene knockdown techniques;intracellular signaling peptides and proteins;bioinformatics;protein tyrosine kinases	Oncogenic mechanisms in small-cell lung cancer remain poorly understood leaving this tumor with the worst prognosis among all lung cancers. Unlike other cancer types, sequencing genomic approaches have been of limited success in small-cell lung cancer, i.e., no mutated oncogenes with potential driver characteristics have emerged, as it is the case for activating mutations of epidermal growth factor receptor in non-small-cell lung cancer. Differential gene expression analysis has also produced SCLC signatures with limited application, since they are generally not robust across datasets. Nonetheless, additional genomic approaches are warranted, due to the increasing availability of suitable small-cell lung cancer datasets. Gene co-expression network approaches are a recent and promising avenue, since they have been successful in identifying gene modules that drive phenotypic traits in several biological systems, including other cancer types. We derived an SCLC-specific classifier from weighted gene co-expression network analysis (WGCNA) of a lung cancer dataset. The classifier, termed SCLC-specific hub network (SSHN), robustly separates SCLC from other lung cancer types across multiple datasets and multiple platforms, including RNA-seq and shotgun proteomics. The classifier was also conserved in SCLC cell lines. SSHN is enriched for co-expressed signaling network hubs strongly associated with the SCLC phenotype. Twenty of these hubs are actionable kinases with oncogenic potential, among which spleen tyrosine kinase (SYK) exhibits one of the highest overall statistical associations to SCLC. In patient tissue microarrays and cell lines, SCLC can be separated into SYK-positive and -negative. SYK siRNA decreases proliferation rate and increases cell death of SYK-positive SCLC cell lines, suggesting a role for SYK as an oncogenic driver in a subset of SCLC. SCLC treatment has thus far been limited to chemotherapy and radiation. Our WGCNA analysis identifies SYK both as a candidate biomarker to stratify SCLC patients and as a potential therapeutic target. In summary, WGCNA represents an alternative strategy to large scale sequencing for the identification of potential oncogenic drivers, based on a systems view of signaling networks. This strategy is especially useful in cancer types where no actionable mutations have emerged.	activating function;biological markers;biological system;biopolymer sequencing;cell (microprocessor);cell death;cultured cell line;electronic signature;exhibits as topic;gene co-expression network;malignant neoplasm of lung;microarray;mutation;neoplasms;oncogenes;patients;protein tyrosine kinase;proteomics;receptor protein-tyrosine kinases;syk gene;sequence number;silo (dataset);small cell carcinoma of lung;subgroup;therapeutic targets database;tissue-specific gene expression;trait;usb hub;weighted correlation network analysis	Akshata R. Udyavar;Megan D. Hoeksema;Jonathan E. Clark;Yong Zou;Zuojian Tang;Zhiguo Li;Ming Li;Heidi Chen;Alexander R. Statnikov;Shyr Yu;Daniel C. Liebler;John K. Field;Rosana Eisenberg;Lourdes Estrada;Pierre P. Massion;Vito Quaranta	2013		10.1186/1752-0509-7-S5-S1	cancer research;biology;gene regulatory network;bioinformatics;gene expression profiling;immunology;proteomics;cell growth;systems biology	Comp.	5.919991512206217	-57.16125674771133	72404
937d696f76af792802a7ee37c2d45a0f8a22da39	a dynamic view to the modulation of phosphorylation and o-glcnacylation by inhibition of o-glcnacase		Protein phosphorylation and O-GlcNAcylation are reciprocally regulated. As hyperphosphorylation is implicated in tau pathology, approaches have been exploited to reduce the magnitude of tau phosphorylation by increasing the level of tau O-GlcNAcylation. With mathematic models constructed to describe different kinetic scenarios, we analyzed the temporal change of an O-GlcNAcylated protein in contrast to that of the phosphorylated form upon inhibition of O-GlcNAcase (OGA). The analyses indicate that when degradation of the modified protein is negligible relative to the naked one, the magnitude of O-GlcNAcylated protein increase is proportional to the level of inhibition, while the extent of phosphorylated protein decline varies due to other factors. Furthermore, the increase of O-GlcNAcylated protein parallels with the decrease of phosphorylated form upon acute or short-term inhibition of OGA, as observed in many in vitro and short term in vivo studies. However, phosphorylated protein is predicted to return to its initial level while O-GlcNAcylated protein to achieve a higher steady level under sustained inhibition. This simulated result is in line with a recent report on long-term inhibition of OGA in transgenic mice. Noticeably, inhibition withdrawal is anticipated to cause a transient rise of phosphorylated protein. If degradation of modified proteins proceeds in addition to the naked one, the characteristic temporal profiles of each form in response to OGA inhibition would depend on the relative importance of individual degradation pathways. The models described herein may serve as a useful investigational tool that will provide insight into pharmacological intervention for tauopathies in particular and for reciprocally modulated reactions in general.	elegant degradation;kinetics;mathematics;modulation;parallels desktop for mac;pharmacology;tau-leaping;tauopathies;video-in video-out;investigational monitoring program	Cuyue Tang;Devin F. Welty	2013	Computational biology and chemistry	10.1016/j.compbiolchem.2013.03.001	biology;biochemistry;bioinformatics;nanotechnology	Comp.	9.444958640796433	-63.60187040540179	72457
d58e1d925f143196673ba65a1e339ae59bcd5cf2	transactions on petri nets and other models of concurrency viii		Comparison of metabolic pathways is useful in phylogenetic analysis and for understanding metabolic functions when studying diseases and in drugs engineering. In the literature many techniques have been proposed to compare metabolic pathways. Most of them focus on structural aspects, while behavioural or functional aspects are generally not considered. In this paper we propose a new method for comparing metabolic pathways of different organisms based on a similarity measure which considers both homology of reactions and functional aspects of the pathways. The latter are captured by relying on a Petri net representation of the pathways and comparing the corresponding T-invariant bases, which represent minimal subsets of reactions that can operate at a steady state. A prototype tool, CoMeta, implements this approach and allows us to test and validate our proposal. Some experiments with CoMeta are presented.	experiment;homology (biology);petri net;phylogenetics;prototype;similarity measure;steady state	Yann Ben Maissa;Fabrice Kordon;Salma Mouline;Yann Thierry-Mieg	2013		10.1007/978-3-642-40465-8	concurrency;petri net	SE	6.397501190577876	-57.6930701507987	72498
7db62a0f0912165f6ba60617da6f6dd9844cffaf	detailed estimation of bioinformatics prediction reliability through the fragmented prediction performance plots	sensitivity and specificity;computational biology bioinformatics;reproducibility of results;predictive value of tests;algorithms;combinatorial libraries;computational biology;figure of merit;computer appl in life sciences;microarrays;bioinformatics	An important and yet rather neglected question related to bioinformatics predictions is the estimation of the amount of data that is needed to allow reliable predictions. Bioinformatics predictions are usually validated through a series of figures of merit, like for example sensitivity and precision, and little attention is paid to the fact that their performance may depend on the amount of data used to make the predictions themselves. Here I describe a tool, named Fragmented Prediction Performance Plot (FPPP), which monitors the relationship between the prediction reliability and the amount of information underling the prediction themselves. Three examples of FPPPs are presented to illustrate their principal features. In one example, the reliability becomes independent, over a certain threshold, of the amount of data used to predict protein features and the intrinsic reliability of the predictor can be estimated. In the other two cases, on the contrary, the reliability strongly depends on the amount of data used to make the predictions and, thus, the intrinsic reliability of the two predictors cannot be determined. Only in the first example it is thus possible to fully quantify the prediction performance. It is thus highly advisable to use FPPPs to determine the performance of any new bioinformatics prediction protocol, in order to fully quantify its prediction power and to allow comparisons between two or more predictors based on different types of data.	bioinformatics;intrinsic function;kerrison predictor;name;protein structure prediction	Oliviero Carugo	2007	BMC Bioinformatics	10.1186/1471-2105-8-380	biology;figure of merit;dna microarray;computer science;bioinformatics;data science;predictive value of tests;data mining	HPC	6.842635309408304	-52.73114373859915	72565
bc7c9a98ebb5fb75f8fddb7dd8d430fd521cfa9f	modeling hiv-1 drug resistance as episodic directional selection	evolution molecular;antiretroviral therapy;evolutionary model;drug resistance viral;protein sequence;hiv infections;hiv 1;selection genetic;genetic variation;models genetic;biological evolution;null model;true positive;direction selectivity;false positive;drug resistance;article;computer simulation;anti hiv agents	The evolution of substitutions conferring drug resistance to HIV-1 is both episodic, occurring when patients are on antiretroviral therapy, and strongly directional, with site-specific resistant residues increasing in frequency over time. While methods exist to detect episodic diversifying selection and continuous directional selection, no evolutionary model combining these two properties has been proposed. We present two models of episodic directional selection (MEDS and EDEPS) which allow the a priori specification of lineages expected to have undergone directional selection. The models infer the sites and target residues that were likely subject to directional selection, using either codon or protein sequences. Compared to its null model of episodic diversifying selection, MEDS provides a superior fit to most sites known to be involved in drug resistance, and neither one test for episodic diversifying selection nor another for constant directional selection are able to detect as many true positives as MEDS and EDEPS while maintaining acceptable levels of false positives. This suggests that episodic directional selection is a better description of the process driving the evolution of drug resistance.	amino acid sequence;antiretroviral therapy;codon (nucleotide sequence);genetic selection;inference;microcephaly, epilepsy, and diabetes syndrome;models of dna evolution;null model;patients;peptide sequence;selection (user interface);specification	Ben Murrell;Tulio de Oliveira;Christopher John Seebregts;Sergei L. Kosakovsky Pond;Konrad Scheffler	2012		10.1371/journal.pcbi.1002507	computer simulation;biology;drug resistance;null model;type i and type ii errors;bioinformatics;genetic variation;protein sequencing;genetics	Comp.	3.880739038301471	-61.23095190167283	72660
2636716edb8096eea20041843ee0f52e3dfdfe53	the proximal lilly collection: mapping, exploring and exploiting feasible chemical space		Venturing into the immensity of the small molecule universe to identify novel chemical structure is a much discussed objective of many methods proposed by the chemoinformatics community. To this end, numerous approaches using techniques from the fields of computational de novo design, virtual screening and reaction informatics, among others, have been proposed. Although in principle this objective is commendable, in practice there are several obstacles to useful exploitation of the chemical space. Prime among them are the sheer number of theoretically feasible compounds and the practical concern regarding the synthesizability of the chemical structures conceived using in silico methods. We present the Proximal Lilly Collection initiative implemented at Eli Lilly and Co. with the aims to (i) define the chemical space of small, drug-like compounds that could be synthesized using in-house resources and (ii) facilitate access to compounds in this large space for the purposes of ongoing drug discovery efforts. The implementation of PLC relies on coupling access to available synthetic knowledge and resources with chemo/reaction informatics techniques and tools developed for this purpose. We describe in detail the computational framework supporting this initiative and elaborate on the characteristics of the PLC virtual collection of compounds. As an example of the opportunities provided to drug discovery researchers by easy access to a large, realistically feasible virtual collection such as the PLC, we describe a recent application of the technology that led to the discovery of selective kinase inhibitors.		Christos A. Nicolaou;Ian A. Watson;Hong Hu;Ji-Bo Wang	2016	Journal of chemical information and modeling	10.1021/acs.jcim.6b00173	pharmacology;chemistry;computer science;bioinformatics;combinatorial chemistry;nanotechnology;mathematics	Comp.	-1.3341293257424993	-65.4890357699219	72749
0db771e5f0fbf87691e095dfac298076f53324d9	qpcr: an r package for sigmoidal model selection in quantitative real-time polymerase chain reaction analysis	model selection;reaction chaine polymerase;analisis cuantitativo;real time;selection;bioinformatique;polymerase chain reaction;modelo;reaccion cadena polimerasa;analyse quantitative;temps reel;quantitative analysis;tiempo real;modele;bioinformatica;seleccion;real time polymerase chain reaction;models;bioinformatics	UNLABELLED The qpcR library is an add-on to the free R statistical environment performing sigmoidal model selection in real-time quantitative polymerase chain reaction (PCR) data analysis. Additionally, the package implements the most commonly used algorithms for real-time PCR data analysis and is capable of extensive statistical comparison for the selection and evaluation of the different models based on several measures of goodness of fit.   AVAILABILITY www.dr-spiess.de/qpcR.html.   SUPPLEMENTARY INFORMATION Statistical evaluations of the implemented methods can be found at www.dr-spiess.de under 'Supplemental Data'.	add-ons for firefox;algorithm;evaluation;model selection;real-time polymerase chain reaction;real-time clock;real-time computing;sigmoid function	Christian Ritz;Andrej-Nikolai Spiess	2008	Bioinformatics	10.1093/bioinformatics/btn227	biology;selection;real-time polymerase chain reaction;simulation;bioinformatics;quantitative analysis;polymerase chain reaction;model selection	Comp.	-3.7552391574582757	-55.23570978611041	72787
1c2719a99061442798cc68e6e44800e375eef9ed	pathvisio 3: an extendable pathway analysis toolbox	software;animals;mice;metabolomics;signal transduction;graphical user interface;transcriptome analysis;internet;database searching;data visualization;software tools;humans;databases factual;computational biology;operating systems;proteomic databases	PathVisio is a commonly used pathway editor, visualization and analysis software. Biological pathways have been used by biologists for many years to describe the detailed steps in biological processes. Those powerful, visual representations help researchers to better understand, share and discuss knowledge. Since the first publication of PathVisio in 2008, the original paper was cited more than 170 times and PathVisio was used in many different biological studies. As an online editor PathVisio is also integrated in the community curated pathway database WikiPathways. Here we present the third version of PathVisio with the newest additions and improvements of the application. The core features of PathVisio are pathway drawing, advanced data visualization and pathway statistics. Additionally, PathVisio 3 introduces a new powerful extension systems that allows other developers to contribute additional functionality in form of plugins without changing the core application. PathVisio can be downloaded from http://www.pathvisio.org and in 2014 PathVisio 3 has been downloaded over 5,500 times. There are already more than 15 plugins available in the central plugin repository. PathVisio is a freely available, open-source tool published under the Apache 2.0 license (http://www.apache.org/licenses/LICENSE-2.0). It is implemented in Java and thus runs on all major operating systems. The code repository is available at http://svn.bigcat.unimaas.nl/pathvisio. The support mailing list for users is available on https://groups.google.com/forum/#!forum/wikipathways-discuss and for developers on https://groups.google.com/forum/#!forum/wikipathways-devel.	data visualization;extensibility;gene regulatory network;greater than;imagery;java programming language;open-source software;operating system;pathvisio;pathway analysis;plug-in (computing);repository (version control);scientific publication	Martina Kutmon;Martijn P. van Iersel;Anwesha Bohler;Thomas Kelder;Nuno Nunes;Alexander R. Pico;Chris T. A. Evelo	2015		10.1371/journal.pcbi.1004085	biology;the internet;transcriptome;computer science;bioinformatics;metabolomics;data mining;graphical user interface;world wide web;data visualization;signal transduction	Visualization	-3.719140975070194	-59.147768363590586	72834
7a199a0c579160a93157f3d6975ded8aeb295fd9	clovr: a virtual machine for automated and portable sequence analysis from the desktop using cloud computing	computers;software;genomics;high throughput nucleotide sequencing;sequence analysis dna;computational biology bioinformatics;internet;algorithms;combinatorial libraries;computational biology;computer appl in life sciences;microarrays;bioinformatics	Next-generation sequencing technologies have decentralized sequence acquisition, increasing the demand for new bioinformatics tools that are easy to use, portable across multiple platforms, and scalable for high-throughput applications. Cloud computing platforms provide on-demand access to computing infrastructure over the Internet and can be used in combination with custom built virtual machines to distribute pre-packaged with pre-configured software. We describe the Cloud Virtual Resource, CloVR, a new desktop application for push-button automated sequence analysis that can utilize cloud computing resources. CloVR is implemented as a single portable virtual machine (VM) that provides several automated analysis pipelines for microbial genomics, including 16S, whole genome and metagenome sequence analysis. The CloVR VM runs on a personal computer, utilizes local computer resources and requires minimal installation, addressing key challenges in deploying bioinformatics workflows. In addition CloVR supports use of remote cloud computing resources to improve performance for large-scale sequence processing. In a case study, we demonstrate the use of CloVR to automatically process next-generation sequencing data on multiple cloud computing platforms. The CloVR VM and associated architecture lowers the barrier of entry for utilizing complex analysis protocols on both local single- and multi-core computers and cloud systems for high throughput data processing.	bioinformatics;biopolymer sequencing;cloud computing;computation (action);computers;desktop computer;genomics;high-throughput computing;internet;massively-parallel sequencing;metagenome;multi-core processor;numerous;personal computer;pipeline (computing);protocols documentation;push-button;scalability;sequence analysis;throughput;virtual machine;voltage-sensitive dye imaging	Samuel V. Angiuoli;Malcolm Matalka;Aaron Gussman;Kevin Galens;Mahesh Vangala;David R. Riley;Cesar Arze;James Robert White;Owen White;W. Florian Fricke	2011		10.1186/1471-2105-12-356	computational biology;biology;genomics;the internet;dna microarray;computer science;bioinformatics;theoretical computer science	OS	-1.898014054079344	-57.77611070091285	72858
6dbce3d1155aac64231d568c9f7b3d73ee8048ba	reconstructing the topology of protein complexes	multiple perspectives;learning algorithm;protein complex;rna polymerase ii;complex data;protein protein interaction;protein interaction;high throughput	Recent advances in high-throughput experimental techniques have yielded a wealth of protein interaction data, rich in both quantity and variety. While the sheer quantity and variety of data present special difficulties for modeling, they also present unique opportunities for gaining insight into protein behavior by leveraging multiple perspectives. Recent work on the modularity of protein interactions has revealed that reasoning about protein interactions at the level of domain interactions can be quite useful. We present PROCTOR, a learning algorithm for reconstructing the internal topology of protein complexes, at the domain level, from both direct protein interaction data (Y2H) and from protein co-complex data (AP-MS). While other methods have attempted to use data from both these kinds of assays, they usually require that co-complex data first be transformed into pairwise interaction data, under a spoke or clique model, a transformation which is not semantically appropriate. We incorporate all data from eight high-throughput datasets, resulting in coverage of 5,925 proteins, essentially all of the yeast proteome. First, we show that our algorithm outperforms other algorithms for predicting domain-domain and protein-protein interactions from Y2H and AP-MS data. Then we show that our algorithm can reconstruct the topology of the APMS purifications, revealing known complexes, such as Arp2/3 and RNA polymerase II, as well as suggesting many new complexes along with corresponding topologies.	algorithm;design of experiments;high-throughput computing;interaction;throughput;two-hybrid screening	Allister Bernard;David S. Vaughn;Alexander J. Hartemink	2007		10.1007/978-3-540-71681-5_3	protein–protein interaction;high-throughput screening;biology;rna polymerase ii;bioinformatics;machine learning;multiprotein complex;genetics;complex data type	Comp.	3.4564474837185295	-58.19727485653644	73012
05a427de06784497a145ade8856a0fbe3d683cda	integrating metabolic, transcriptional regulatory and signal transduction models in escherichia coli	escherichia coli;bacterie;signal transduction;bioinformatique;transduccion senal;enterobacteriaceae;modelo;transcription;transcripcion;modele;bacteria;bioinformatica;models;transduction signal;bioinformatics	MOTIVATION The effort to build a whole-cell model requires the development of new modeling approaches, and in particular, the integration of models for different types of processes, each of which may be best described using different representation. Flux-balance analysis (FBA) has been useful for large-scale analysis of metabolic networks, and methods have been developed to incorporate transcriptional regulation (regulatory FBA, or rFBA). Of current interest is the integration of these approaches with detailed models based on ordinary differential equations (ODEs).   RESULTS We developed an approach to modeling the dynamic behavior of metabolic, regulatory and signaling networks by combining FBA with regulatory Boolean logic, and ordinary differential equations. We use this approach (called integrated FBA, or iFBA) to create an integrated model of Escherichia coli which combines a flux-balance-based, central carbon metabolic and transcriptional regulatory model with an ODE-based, detailed model of carbohydrate uptake control. We compare the predicted Escherichia coli wild-type and single gene perturbation phenotypes for diauxic growth on glucose/lactose and glucose/glucose-6-phosphate with that of the individual models. We find that iFBA encapsulates the dynamics of three internal metabolites and three transporters inadequately predicted by rFBA. Furthermore, we find that iFBA predicts different and more accurate phenotypes than the ODE model for 85 of 334 single gene perturbation simulations, as well for the wild-type simulations. We conclude that iFBA is a significant improvement over the individual rFBA and ODE modeling paradigms.   AVAILABILITY All MATLAB files used in this study are available at http://www.simtk.org/home/ifba/.   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	bioinformatics;boolean algebra;carbohydrates;differential diagnosis;flux balance analysis;form-based authentication;glucose;glucose-6-phosphate;lactose;logical connective;matlab;membrane transport proteins;metabolic process, cellular;open dynamics engine;phenotype;signal transduction;simulation;transcription, genetic;transcriptional regulation;transduction (machine learning)	Markus W. Covert;Nan Xiao;Tiffany J. Chen;Jonathan R. Karr	2008	Bioinformatics	10.1093/bioinformatics/btn352	biology;bacteria;biotechnology;bioinformatics;escherichia coli;transcription;genetics;signal transduction	Comp.	6.482210372606913	-60.48595170934587	73123
b93d2d7872dae9159f91a65dc05c189ee776b965	explicit diversity index (edi): a novel measure for assessing the diversity of compound databases	diversity index	A novel diversity assessment method, the Explicit Diversity Index (EDI), is introduced for druglike molecules. EDI combines structural and synthesis-related dissimilarity values and expresses them as a single number. As an easily interpretable measure, it facilitates the decision making in the design of combinatorial libraries, and it might assist in the comparison of compound sets provided by different manufacturers. Because of its rapid calculation algorithm, EDI enables the diversity assessment of in-house or commercial compound collections.	algorithm;body mass index;collections (publication);combinatorial chemistry;database;decision making;electronic data interchange;library (computing)	Ákos Papp;Anna Gulyás-Forró;Zsolt Gulyás;György Dormán;László Ürge;Ferenc Darvas	2006	Journal of chemical information and modeling	10.1021/ci060074f	bioinformatics;data mining;diversity index;computer science	ML	0.8727273834703526	-58.09693625250514	73237
cc607a7f2843081dd52c625f0ea1cff671353b44	game: a simple and efficient whole genome alignment method using maximal exact match filtering	maximal exact match;whole genome alignment;anchor filtering;matched filter	In this paper, we present a simple and efficient whole genome alignment method using maximal exact match (MEM). The major problem with the use of MEM anchor is that the number of hits in non-homologous regions increases exponentially when shorter MEM anchors are used to detect more homologous regions. To deal with this problem, we have developed a fast and accurate anchor filtering scheme based on simple match extension with minimum percent identity and extension length criteria. Due to its simplicity and accuracy, all MEM anchors in a pair of genomes can be exhaustively tested and filtered. In addition, by incorporating the translation technique, the alignment quality and speed of our genome alignment algorithm have been further improved. As a result, our genome alignment algorithm, GAME (Genome Alignment by Match Extension), performs competitively over existing algorithms and can align large whole genomes, e.g., A. thaliana, without the requirement of typical large memory and parallel processors. This is shown using an experiment which compares the performance of BLAST, BLASTZ, PatternHunter, MUMmer and our algorithm in aligning all 45 pairs of 10 microbial genomes. The scalability of our algorithm is shown in another experiment where all pairs of five chromosomes in A. thaliana were compared.		Jeong-Hyeon Choi;Hwan-Gue Cho;Sun Kim	2005	Computational biology and chemistry	10.1016/j.compbiolchem.2005.04.004	simulation;computer science;bioinformatics;theoretical computer science;mathematics;matched filter	Comp.	-1.9305914488464924	-52.49601029539403	73343
ce576c92a50c83cd5acdf270e99c14556b579260	experimental validation of in silico target predictions on synergistic protein targets	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;computer applications in chemistry;theoretical and computational chemistry;computational biology bioinformatics;uk phd theses thesis;life sciences;uk research reports;medical journals;europe pmc;documentation and information in chemistry;biomedical research;bioinformatics	Two trends are apparent in current early-stage drug discovery settings, firstly a revival of phenotypic screening strategies [1], and secondly the increasing acceptance that drugs modulate multiple targets in parallel (‘multi-target drugs’) [2].The work presented here combines those aspects by integrating experimental phenotypic screening for cytotoxic compounds with an experimental validation of individual protein targets modulated by the compounds. In silico target predictions for a dataset comprising cytotoxic compounds showed an enrichment of crucial enzymes for the cell cycle (such as Topoisomerase I, Bcl-X and protein kinase C alpha) and for the defense against xenobiotics (such as P-gp 1 and CYP450 enzymes). Subsequently, ten compounds from an external library (HitFinder) predicted to be active on two of the enriched targets, P-glycoprotein 1 and Topoisomerase I, were tested in vitro. Hoechst 33342 dye uptake, P-gp ATPase activity and Topoisomerase I DNA relaxation assays were able to identify two inhibitors of P-gp with IC50 values of 37 ± 5 and 28 ± 2 μM, respectively, comparable to the activity of Verapamil (12 μM). Also identified were five moderate inhibitors of Topoisomerase I inhibitors, four of which produce a synergistic effect in HeLa cell cultures in the presence of the aforesaid P-gp inhibitors (two independent samples t-test, p<0.01). Hence, this appears to be the first study work where multiple aspects of compound action phenotypic effect as well as activity on multiple protein targets were prospectively validated, and where partial compound synergism could be experimentally confirmed. Author details Institute of Biocomputation and Physics of Complex Systems (BIFI), Unidad Asociada IQFR-CSIC-BIFI, and Department of Biochemistry and Molecular and Cellular Biology, Universidad de Zaragoza, Zaragoza, Spain. Unilever Centre for Molecular Science Informatics, Chemistry Department, University of Cambridge, Cambridge CB2 1EW, UK. Aragon Health Sciences Institute (I+CS), Zaragoza, Spain. Fundacion ARAID, Diputacion General de Aragon, Spain.	bioinformatics;complex systems;experiment;gene ontology term enrichment;informatics;linear programming relaxation;modulation;synergy	Isidro Cortes-Ciriano;Alexios Koutsoukas;Olga Abian;Andreas Bender;Adrián Velázquez-Campoy	2013		10.1186/1758-2946-5-S1-P31	pharmacology;biology;medical research;medicine;toxicology;computer science;bioinformatics	Comp.	9.737875254995979	-59.57375443622079	73353
41f3751b648d7992717121285b59db16e6233cb2	structure-function relationship in dna sequence recognition by transcription factors	statistical potential;amino acid;gene regulation;empirical method;transcription factors;structure function relationship;structure function;target prediction;structure function relation;structure and function;target recognition;transcription factor;protein dna interaction;molecular mechanics;potential function;dna sequence;computer simulation;genome sequence;structured data;protein dna recognition;knowledge base	Transcription factors play essential role in the gene regulation in higher organisms, binding to multiple target sequences and regulating multiple genes in a complex manner. In order to understand the molecular mechanism of target recognition, and to predict target genes for transcription factors at the genome level, it is important to analyze the relationship between the structure and function (specificity) of transcription factors. We have used a knowledge-based approach, utilizing rapidly increasing structural data of protein-DNA complexes, to derive empirical potential functions for the specific interactions between bases and amino acids as well as for DNA conformation, from the statistical analyses on the structural data. Then these statistical potentials are used to quantify the specificity of protein-DNA recognition. The quantification of specificity has enabled us to establish the structure-function analysis of transcription factors, such as the effects of binding cooperativity on target recognition. The method is also applied to real genome sequences, predicting potential target sites. We are also using computer simulations of protein-DNA interactions in order to complement the empirical method. Combining the two approaches together, we can better understand the mechanism of protein-DNA recognition and improve the target prediction of transcription factors1.	computer simulation;interaction;medical transcription;sensitivity and specificity;statistical potential;transcription (software)	Akinori Sarai;Samuel Selvaraj;M. Michael Gromiha;Hidetoshi Kono	2004			computer simulation;biology;knowledge base;computer science;bioinformatics;genetics;transcription factor	Comp.	4.543404217706068	-58.88135030507748	73441
262059bf746282ef63fc456a145519d06a403a06	mining big data in neurogenetics to understand muscular dystrophy		The recent advances in genome sequencing and analyses of the billions of base pairs in genomic data have been a boon for moving forward our understanding of human disease. In this talk I will describe how genome sequencing has dramatically improved our understanding of the most common adult form of muscular dystrophy, which is myotonic dystrophy. Two different genetic mutations cause thousands of changes in the cells and tissues of myotonic dystrophy patients. Genome sequencing has allowed us to precisely determine the degree of changes across patients, correlate these changes to disease symptoms and allow us to determine quickly in cell and animal models the effectiveness of therapeutic strategies for myotonic dystrophy.	big data;whole genome sequencing	Andy Berglund	2017		10.1145/3097983.3105813	muscular dystrophy;artificial intelligence;computer science;machine learning;computational biology;myotonic dystrophy;big data;disease;dna sequencing;neurogenetics;bioinformatics	Comp.	2.048792231876703	-61.60810186319072	73452
50eaf90115c3fd29938d31ef35d921a4c71851b4	deogen2: prediction and interactive visualization of single amino acid variant deleteriousness in human proteins		High-throughput sequencing methods are generating enormous amounts of genomic data, giving unprecedented insights into human genetic variation and its relation to disease. An individual human genome contains millions of Single Nucleotide Variants: to discriminate the deleterious from the benign ones, a variety of methods have been developed that predict whether a protein-coding variant likely affects the carrier individual's health. We present such a method, DEOGEN2, which incorporates heterogeneous information about the molecular effects of the variants, the domains involved, the relevance of the gene and the interactions in which it participates. This extensive contextual information is non-linearly mapped into one single deleteriousness score for each variant. Since for the non-expert user it is sometimes still difficult to assess what this score means, how it relates to the encoded protein, and where it originates from, we developed an interactive online framework (http://deogen2.mutaframe.com/) to better present the DEOGEN2 deleteriousness predictions of all possible variants in all human proteins. The prediction is visualized so both expert and non-expert users can gain insights into the meaning, protein context and origins of each prediction.	amino acids;biopolymer sequencing;genetic heterogeneity;imagery;interaction;interactive visualization;national origin;relevance;staphylococcal protein a;throughput;variation (genetics);mapped	Daniele Raimondi;Ibrahim Tanyalcin;Julien Ferté;Andrea M. Gazzo;Gabriele Orlando;Tom Lenaerts;Marianne Rooman;Wim F. Vranken	2017		10.1093/nar/gkx390	biochemistry;bioinformatics;genetics	Comp.	2.3526058723734753	-59.28190749751027	73486
1027af10ffadf807553becacb3356012fd0d63b1	phytocrisp-ex: a web-based and stand-alone application to find specific target sequences for crispr/cas editing	computational biology bioinformatics;algorithms;computer appl in life sciences;microarrays;bioinformatics	With the emerging interest in phytoplankton research, the need to establish genetic tools for the functional characterization of genes is indispensable. The CRISPR/Cas9 system is now well recognized as an efficient and accurate reverse genetic tool for genome editing. Several computational tools have been published allowing researchers to find candidate target sequences for the engineering of the CRISPR vectors, while searching possible off-targets for the predicted candidates. These tools provide built-in genome databases of common model organisms that are used for CRISPR target prediction. Although their predictions are highly sensitive, the applicability to non-model genomes, most notably protists, makes their design inadequate. This motivated us to design a new CRISPR target finding tool, PhytoCRISP-Ex. Our software offers CRIPSR target predictions using an extended list of phytoplankton genomes and also delivers a user-friendly standalone application that can be used for any genome. The software attempts to integrate, for the first time, most available phytoplankton genomes information and provide a web-based platform for Cas9 target prediction within them with high sensitivity. By offering a standalone version, PhytoCRISP-Ex maintains an independence to be used with any organism and widens its applicability in high throughput pipelines. PhytoCRISP-Ex out pars all the existing tools by computing the availability of restriction sites over the most probable Cas9 cleavage sites, which can be ideal for mutant screens. PhytoCRISP-Ex is a simple, fast and accurate web interface with 13 pre-indexed and presently updating phytoplankton genomes. The software was also designed as a UNIX-based standalone application that allows the user to search for target sequences in the genomes of a variety of other species.	canonical account;clustered regularly interspaced short palindromic repeats;database;databases;genome editing;index;phytoplankton;pipeline (computing);probability;scientific publication;throughput;unix;usability;user interface;web application;protists	Achal Rastogi;Omer Murik;Chris Bowler;Leila Tirichine	2016		10.1186/s12859-016-1143-1	biology;dna microarray;computer science;bioinformatics;genetics	Comp.	-0.04523609345554097	-58.06477480643098	73507
b997c96bdfa21d2f1ab8cdd6782f19f97ac332ee	effect of carbon source perturbations on transcriptional regulation of metabolic fluxes in saccharomyces cerevisiae	transcription genetic;carbon;amino acid metabolism;simulation and modeling;saccharomyces cerevisiae;metabolic networks and pathways;ethanol;metabolic network;rna messenger;amino acid;systems biology;environmental conditions;enzyme;physiological cellular and medical topics;computational biology bioinformatics;glucose;gene expression;transcription regulation;metabolic regulation;gene expression regulation fungal;weighted sums;carbon metabolism;algorithms;correlation coefficient;acetic acid;carbon source;lactic acid;bioinformatics;fermentation	Control effective flux (CEF) of a reaction is the weighted sum of all fluxes through that reaction, derived from elementary flux modes (EFM) of a metabolic network. Change in CEFs under different environmental conditions has earlier been proven to be correlated with the corresponding changes in the transcriptome. Here we use this to investigate the degree of transcriptional regulation of fluxes in the metabolism of Saccharomyces cerevisiae. We do this by quantifying correlations between changes in CEFs and changes in transcript levels for shifts in carbon source, i.e. between the fermentative carbon source glucose and nonfermentative carbon sources like ethanol, acetate, and lactate. The CEF analysis is based on a simple stoichiometric model that includes reactions of the central carbon metabolism and the amino acid metabolism. The effect of the carbon shift on the metabolic fluxes was investigated for both batch and chemostat cultures. For growth on glucose in batch (respiro-fermentative) cultures, EFMs with no by-product formation were removed from the analysis of the CEFs, whereas those including any by-products (ethanol, glycerol, acetate, succinate) were omitted in the analysis of growth on glucose in chemostat (respiratory) cultures. This resulted in improved correlations between CEF changes and transcript levels. A regression correlation coefficient of 0.60 was obtained between CEF changes and gene expression changes in the central carbon metabolism for the analysis of 5 different perturbations. Out of 45 data points there were no more than 6 data points deviating from the correlation. Additionally, up- or down-regulation of at least 75% of the genes were in qualitative agreement with the CEF changes for all perturbations studied. The analysis indicates that changes in carbon source are associated with a high degree of hierarchical regulation of metabolic fluxes in the central carbon metabolism as the change in fluxes are correlating directly with the change in transcript levels of genes encoding their corresponding enzymes. For amino acid biosynthesis there was, however, not found to exist a similar correlation, and this may point to either post-transcriptional and/or metabolic regulation, or be due to the absence of a direct perturbation on the amino acid pathways in these experiments.	acetate;amino acid biosynthesis;amino acids;anabolism;chromium embedded framework;coefficient;data point;down-regulation;ethanol;experiment;fec protocol;fetal doppler monitoring;gene expression;glucose;glycerin;greater than;http 404;lactic acid;metabolic process, cellular;succinates;transcript;transcription, genetic;transcriptional regulation;weight function;amino acid metabolism	Tunahan Çakir;Betül Kirdar;Z. Ilsen Önsan;Kutlu Ö. Ülgen;Jens Nielsen	2006	BMC Systems Biology	10.1186/1752-0509-1-18	carbon;biology;biochemistry;enzyme;gene expression;amino acid;biotechnology;bioinformatics;ethanol fuel;fermentation;systems biology;transcriptional regulation;metabolic network	Comp.	4.929207035580135	-61.08027400596736	73652
e476b82646cbd3aa85b4fc93e949d71d4eddeeed	haplo2ped: a tool using haplotypes as markers for linkage analysis	software;disease;genome wide association study;retinitis pigmentosa;computational biology bioinformatics;genetic linkage;algorithms;humans;combinatorial libraries;pedigree;computer appl in life sciences;polymorphism single nucleotide;haplotypes;microarrays;bioinformatics	Generally, SNPs are abundant in the genome; however, they display low power in linkage analysis because of their limited heterozygosity. Haplotype markers, on the other hand, which are composed of many SNPs, greatly increase heterozygosity and have superiority in linkage statistics. Here we developed Haplo2Ped to automatically transform SNP data into haplotype markers and then to compute the logarithm (base 10) of odds (LOD) scores of regional haplotypes that are homozygous within the disease co-segregation haploid group. The results are reported as a hypertext file and a 3D figure to help users to obtain the candidate linkage regions. The hypertext file contains parameters of the disease linked regions, candidate genes, and their links to public databases. The 3D figure clearly displays the linkage signals in each chromosome. We tested Haplo2Ped in a simulated SNP dataset and also applied it to data from a real study. It successfully and accurately located the causative genomic regions. Comparison of Haplo2Ped with other existing software for linkage analysis further indicated the high effectiveness of this software. Haplo2Ped uses haplotype fragments as mapping markers in whole genome linkage analysis. The advantages of Haplo2Ped over other existing software include straightforward output files, increased accuracy and superior ability to deal with pedigrees showing incomplete penetrance. Haplo2Ped is freely available at: http://bighapmap.big.ac.cn/software.html .	candidate disease gene;database;databases;haploidy;haplotypes;heterozygote;homozygote;hypertext;linkage (software);nitroprusside;partial;penetrance;snp array;silo (dataset);single nucleotide polymorphism;genetic linkage	Feng Cheng;Xianglong Zhang;Yinan Zhang;Chaohua Li;Changqing Zeng	2011		10.1186/1471-2105-12-350	tag snp;genome-wide association study;biology;dna microarray;haplotype;genetic linkage;bioinformatics;genetics	Comp.	1.9146447140063432	-53.484469891887414	73653
d24fb7001ee26c0512c26414bd90247ab5e524dc	phyloflow: a fully customizable and automatic workflow for phylogenetic reconstruction	dna;phyloflow source code phylogenetic reconstruction phylogeny estimation systems phylogenetic analysis phylogenetic tree dactal human mitochondrial dna parallel system biological system htc cluster;source code software biology computing dna evolution biological genetics molecular biophysics;supertree scientific workflow phylogeny estimation maximum likelihood model selection;phylogeny;biological system modeling;phylogeny estimation dna biological system modeling accuracy buildings;accuracy;estimation;buildings	Most phylogeny estimation systems such as SATe2 or DACTAL use fixed configurations and tools that make them suitable only for solving specific problems. Out of that scope, a hand-made combination of individual tools and methods has to be composed in order to get the desired phylogeny estimation. PhyloFlow is a new framework based on a workflow extendable to a wide range of tasks in phylogenetic analysis. This system is specially intended to build large phylogenies, where most of the methods do not provide a solution at all or the computing time required is not affordable. The workflow can scale to different phylogenetic estimation problems, the methods and stages already included can be fully customizable and once the user has set up the system, it will run automatically until the phylogenetic tree is completely estimated. With the current version we have recreated two different phy-logenetic systems: DACTAL and a study case for the human mitochondrial DNA. The first one displays the capabilities of our framework to reproduce the existing systems, in addition with the properties that a parallel system can provide. The second one shows the possibilities of building a real case workflow to estimate a phylogenetic tree for more than 23000 sequences of human mitochondrial DNA (16569 bp on average) applying biological knowledge to the process. Both workflows have been run sequentially and in parallel in a HTC cluster (HTCCondor and DAGMan). PhyloFlow source code, the datasets and the workflow configurations are available by request to the first author.	database;extensibility;hoc (programming language);homology (biology);model selection;phylogenetic tree;phylogenetics	Jorge Álvarez;Gregorio de Miguel Casado;Elvira Mayordomo	2014	2014 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2014.6999303	biology;estimation;bioinformatics;theoretical computer science;accuracy and precision;dna;statistics;phylogenetics	HPC	-0.7922395401339553	-56.26287544384645	73729
24e8f2371e0c3187a690bd19d7c6f0f36243e887	the plant ontology database: a community resource for plant structure and developmental stages controlled vocabulary and annotations	databases;genes;community;software;plant components;controlled vocabulary;plants;vocabulary controlled;maize;genome plant;databases genetic;plant development;data type;plant;genomics and proteomics;developmental stages;internet;genome;arabidopsis;genes plant;resource availability;user computer interface;phenotype;article;bioinformatics;gene ontology;rice	The Plant Ontology Consortium (POC, http://www.plantontology.org) is a collaborative effort among model plant genome databases and plant researchers that aims to create, maintain and facilitate the use of a controlled vocabulary (ontology) for plants. The ontology allows users to ascribe attributes of plant structure (anatomy and morphology) and developmental stages to data types, such as genes and phenotypes, to provide a semantic framework to make meaningful cross-species and database comparisons. The POC builds upon groundbreaking work by the Gene Ontology Consortium (GOC) by adopting and extending the GOC's principles, existing software and database structure. Over the past year, POC has added hundreds of ontology terms to associate with thousands of genes and gene products from Arabidopsis, rice and maize, which are available through a newly updated web-based browser (http://www.plantontology.org/amigo/go.cgi) for viewing, searching and querying. The Consortium has also implemented new functionalities to facilitate the application of PO in genomic research and updated the website to keep the contents current. In this report, we present a brief description of resources available from the website, changes to the interfaces, data updates, community activities and future enhancement.	anatomic structures;consortium;controlled vocabulary;database;galaxy morphological classification;gene ontology;genome, plant;pomc gene;phenotype;plant ontology;plant physiological phenomena;plant structures;web site;web application;contents - htmllinktype	Shulamit Avraham;Chih-Wei Tung;Katica Ilic;Pankaj Jaiswal;Elizabeth A. Kellogg;Susan R McCouch;Anuradha Pujar;Leonore Reiser;Seung Yon Rhee;Martin M. Sachs;Mary L. Schaeffer;Lincoln Stein;Peter Stevens;Leszek Vincent;Felipe Zapata;Doreen Ware	2008		10.1093/nar/gkm908	biology;open biomedical ontologies;community;controlled vocabulary;the internet;bibliographic ontology;data type;plant;developmental stage theories;bioinformatics;phenotype;gene;ontology-based data integration;genetics;process ontology;genome	Web+IR	-1.8167442895885173	-61.47770086078875	73739
3a802168b87f83a03d31533f6da39569cce60a00	evolving random boolean networks with genetic algorithms for regulatory networks reconstruction	regulatory network;random boolean networks;genetic regulatory network;boolean network;gene interactions;genetic algorithm;gene regulatory network;reverse engineering	The discovery of the structure of genetic regulatory networks is of great interest for biologists and geneticists due to its pivotal role in organisms' metabolism. In the present paper we aim to investigate the inference power of genetic regulatory networks modeled as random boolean networks without the use of any prior biological information. The solutions space is explored by means of genetic algorithms, whose main goal is to find a consistent network given the target data obtained from biological experiments. We show that this approach succeeds in reconstructing a model with satisfactory level of accuracy, representing an useful tool to guide biologist towards the most probable interactions between the target genes.	boolean network;experiment;genetic algorithm;interaction	Mariana Recamonde Mendoza;Ana L. C. Bazzan	2011		10.1145/2001576.2001617	gene regulatory network;biological network;boolean network;genetic algorithm;computer science;bioinformatics;artificial intelligence;machine learning;data mining;reverse engineering	AI	5.168737580700577	-58.52793439791377	73809
630bb8f0121518a1f3704828df6e61ff94fc00b1	inference of a genetic network by a combined approach of cluster analysis and graphical gaussian modeling	graphical gaussian model;expression profile;regulatory network;saccharomyces cerevisiae;cluster analysis;partial correlation;genetic network;dna microarray;cumulant	MOTIVATION Recent advances in DNA microarray technologies have made it possible to measure the expression levels of thousands of genes simultaneously under different conditions. The data obtained by microarray analyses are called expression profile data. One type of important information underlying the expression profile data is the 'genetic network,' that is, the regulatory network among genes. Graphical Gaussian Modeling (GGM) is a widely utilized method to infer or test relationships among a plural of variables.   RESULTS In this study, we developed a method combining the cluster analysis with GGM for the inference of the genetic network from the expression profile data. The expression profile data of 2467 Saccharomyces cerevisiae genes measured under 79 different conditions (Eisen et al., PROC: Natl Acad. Sci. USA, 95, 14683-14868, 1998) were used for this study. At first, the 2467 genes were classified into 34 clusters by a cluster analysis, as a preprocessing for GGM. Then, the expression levels of the genes in each cluster were averaged for each condition. The averaged expression profile data of 34 clusters were subjected to GGM, and a partial correlation coefficient matrix was obtained as a model of the genetic network of S. cerevisiae. The accuracy of the inferred network was examined by the agreement of our results with the cumulative results of experimental studies.	classification;cluster analysis;coefficient;dna microarray format;dividend discount model;gene expression profiling;gene regulatory network;generic group model;graphical user interface;inference;iron;normal statistical distribution;numerous;proc gene;preprocessor;activated t cell autonomous cell death	Hiroyuki Toh;Katsuhisa Horimoto	2002	Bioinformatics	10.1093/bioinformatics/18.2.287	dna microarray;computer science;bioinformatics;partial correlation;data mining;cluster analysis;statistics;cumulant	Comp.	5.394277214967441	-54.260270262413556	73831
3b284850c9f5e812986b4890f1e2b2d2fd43a9a0	eva: exome variation analyzer, an efficient and versatile tool for filtering strategies in medical genomics	software;databases genetic;sequence analysis dna;computational biology bioinformatics;exome;algorithms;humans;combinatorial libraries;alzheimer disease;computer appl in life sciences;polymorphism single nucleotide;microarrays;bioinformatics	Whole exome sequencing (WES) has become the strategy of choice to identify a coding allelic variant for a rare human monogenic disorder. This approach is a revolution in medical genetics history, impacting both fundamental research, and diagnostic methods leading to personalized medicine. A plethora of efficient algorithms has been developed to ensure the variant discovery. They generally lead to ~20,000 variations that have to be narrow down to find the potential pathogenic allelic variant(s) and the affected gene(s). For this purpose, commonly adopted procedures which implicate various filtering strategies have emerged: exclusion of common variations, type of the allelics variants, pathogenicity effect prediction, modes of inheritance and multiple individuals for exome comparison. To deal with the expansion of WES in medical genomics individual laboratories, new convivial and versatile software tools have to implement these filtering steps. Non-programmer biologists have to be autonomous combining themselves different filtering criteria and conduct a personal strategy depending on their assumptions and study design. We describe EVA (Exome Variation Analyzer), a user-friendly web-interfaced software dedicated to the filtering strategies for medical WES. Thanks to different modules, EVA (i) integrates and stores annotated exome variation data as strictly confidential to the project owner, (ii) allows to combine the main filters dealing with common variations, molecular types, inheritance mode and multiple samples, (iii) offers the browsing of annotated data and filtered results in various interactive tables, graphical visualizations and statistical charts, (iv) and finally offers export files and cross-links to external useful databases and softwares for further prioritization of the small subset of sorted candidate variations and genes. We report a demonstrative case study that allowed to identify a new candidate gene related to a rare form of Alzheimer disease. EVA is developed to be a user-friendly, versatile, and efficient-filtering assisting software for WES. It constitutes a platform for data storage and for drastic screening of clinical relevant genetics variations by non-programmer geneticists. Thereby, it provides a response to new needs at the expanding era of medical genomics investigated by WES for both fundamental research and clinical diagnostics.	alzheimer's disease;analyzer device component;analyzer, device;attention deficit hyperactivity disorder;autonomous robot;chart;computer data storage;confidentiality;data table;database;eva (benchmark);eva conferences;entity name part qualifier - adopted;exclusion;extended vector animation;genomics;graphical user interface;laboratory;medical genetics specialty;mode of inheritance;pathogenicity;personalization;precision medicine;programmer device component;subgroup;usability;whole exome sequencing;algorithm	Sophie Coutant;Chloé Cabot;Arnaud Lefebvre;Martine Léonard;Élise Prieur;Dominique Campion;Thierry Lecroq;Hélène Dauchel	2012		10.1186/1471-2105-13-S14-S9	biology;dna microarray;computer science;bioinformatics;exome;genetics	ML	-0.6768458950372193	-58.4805777533326	73863
c067f20da5d5c3257c4aa37925cc17a0a237f7ec	a cybernetic modeling framework for analysis of metabolic systems	environmental influence;model identification;computacion informatica;metabolic network;system modeling;enzyme;grupo de excelencia;cybernetic modeling;ciencias basicas y experimentales;system design;metabolic systems;quimica;modeling framework;biological systems;bacterial growth;experimental evaluation;choice behavior;chemical reaction	We present a cybernetic perspective of metabolic systems, designed to take full account of regulatory processes, which profoundly influence the course of metabolism through dependence not only on the organism’s genomic constitution, but also on abiotic environmental influences. The cybernetic perspective relies on proposing “mechanisms” of choice behavior by which biological systems drive enzyme syntheses and allosteric processes for chemical reactions that promote perceived local or global cellular objectives. This article is an exposition of the framework, attempting to show how experimental data can be used to facilitate model identification. Such an approach is proposed with the view to exploit detailed cellular measurements such as metabolite and mRNA or enzyme levels. We present a modular approach that o e modeled u estigation o ; S . o ecific c ork for the i ©	biological system;cybernetics;ork;software framework;system identification	Abhijit Anand Namjoshi;Doraiswami Ramkrishna	2005	Computers & Chemical Engineering	10.1016/j.compchemeng.2004.08.011	enzyme;simulation;systems modeling;chemical reaction;system identification;computer science;engineering;artificial intelligence;bacterial growth;chemical engineering;metabolic network;systems design	Comp.	6.340006488732861	-60.93038454230031	73931
b08c0297cf56c549d4ce30a1bb904a989835984a	database resources of the national center for biotechnology information		In addition to maintaining the GenBank® nucleic acid sequence database, the National Center for Biotechnology Information (NCBI) provides analysis and retrieval resources for the data in GenBank and other biological data made available through the NCBI Web site. NCBI resources include Entrez, the Entrez Programming Utilities, MyNCBI, PubMed, PubMed Central (PMC), Entrez Gene, the NCBI Taxonomy Browser, BLAST, BLAST Link (BLink), Primer-BLAST, COBALT, Electronic PCR, OrfFinder, Splign, ProSplign, RefSeq, UniGene, HomoloGene, ProtEST, dbMHC, dbSNP, dbVar, Epigenomics, Cancer Chromosomes, Entrez Genomes and related tools, the Map Viewer, Model Maker, Evidence Viewer, Trace Archive, Sequence Read Archive, Retroviral Genotyping Tools, HIV-1/Human Protein Interaction Database, Gene Expression Omnibus (GEO), Entrez Probe, GENSAT, Online Mendelian Inheritance in Man (OMIM), Online Mendelian Inheritance in Animals (OMIA), the Molecular Modeling Database (MMDB), the Conserved Domain Database (CDD), the Conserved Domain Architecture Retrieval Tool (CDART), IBIS, Biosystems, Peptidome, OMSSA, Protein Clusters and the PubChem suite of small molecule databases. Augmenting many of the Web applications are custom implementations of the BLAST program optimized to search specialized data sets. All of these resources can be accessed through the NCBI home page at www.ncbi.nlm.nih.gov.	blast;base sequence;cdd;cobalt;entrez;epigenomics;genbank;genome;home page;homologene;in silico pcr;list of mass spectrometry software;mode of inheritance;molecular modeling database;national center for biotechnology information;nucleic acids;online mendelian inheritance in animals;online mendelian inheritance in man;primer;paramyotonia congenita (disorder);pubchem;pubmed central;published database;refseq;sequence read archive;sequence database;type iii site-specific deoxyribonuclease;unigene (experimental system);world wide web;dbsnp	Eric W. Sayers;Tanya Barrett;Dennis A. Benson;Evan Bolton;Stephen H. Bryant;Kathi Canese;Vyacheslav Chetvernin;Deanna M. Church;Michael DiCuccio;Scott Federhen;Michael Feolo;Ian M. Fingerman;Lewis Y. Geer;Wolfgang Helmberg;Yuri Kapustin;David Landsman;David J. Lipman;Zhiyong Lu;Thomas L. Madden	2011	Nucleic acids research	10.1093/nar/gkq1172		Comp.	-2.5076619442895214	-60.98674274983193	73999
e8e8ec59038f096ff6c87a0a3417ee797b43d607	partitioning of copy-number genotypes in pedigrees	genotype;linkage analysis;genetics;genetic variation;computational biology bioinformatics;copy number;dna copy number variations;gene dosage;genetic association;polymorphism;algorithms;humans;combinatorial libraries;pedigree;phenotype;computer appl in life sciences;copy number variation;single nucleotide polymorphism;microarrays;bioinformatics;congenital heart defect	Copy number variations (CNVs) and polymorphisms (CNPs) have only recently gained the genetic community's attention. Conservative estimates have shown that CNVs and CNPs might affect more than 10% of the genome and that they may be at least as important as single nucleotide polymorphisms in assessing human variability. Widely used tools for CNP analysis have been implemented in Birdsuite and PLINK for the purpose of conducting genetic association studies based on the unpartitioned total number of CNP copies provided by the intensities from Affymetrix's Genome-Wide Human SNP Array. Here, we are interested in partitioning copy number variations and polymorphisms in extended pedigrees for the purpose of linkage analysis on familial data. We have developed CNGen, a new software for the partitioning of copy number polymorphism using the integrated genotypes from Birdsuite with the Affymetrix platform. The algorithm applied to familial trios or extended pedigrees can produce partitioned copy number genotypes with distinct parental alleles. We have validated the algorithm using simulations on a complex pedigree structure using frequencies calculated from a real dataset of 300 genotyped samples from 42 pedigrees segregating a congenital heart defect phenotype. CNGen is the first published software for the partitioning of copy number genotypes in pedigrees, making possible the use CNPs and CNVs for linkage analysis. It was implemented with the Python interpreter version 2.5.2. It was successfully tested on current Linux, Windows and Mac OS workstations.	affymetrix;behavior;cone (formal languages);congenital heart defects;contract net protocol;copy (object);dna copy number variations;estimated;genetic association studies;genetic polymorphism;genotype;heart failure;linkage (software);linux;operating system;plink (genetic tool-set);python;snp array;scientific publication;silo (dataset);simulation;single-chain antibodies;software bug;spatial variability;system 7;workstation;algorithm;genetic linkage;genetic pedigree	Louis-Philippe Lemieux Perreault;Gregor U. Andelfinger;Géraldine Asselin;Marie-Pierre Dubé	2009		10.1186/1471-2105-11-226	biology;molecular biology;bioinformatics;copy-number variation;genetics	Comp.	3.4480796093136905	-53.38074895964507	74170
db17a3486bd58d47f48a56ebb525faddf4dae3de	design and synthesis of type-iii mimetics of shk toxin	ion channel;potassium channel;structure and function;t lymphocyte	ShK toxin is a structurally defined, 35-residue polypeptide which blocks the voltage-gated Kv1.3 potassium channel in T-lymphocytes and has been identified as a possible immunosuppressant. Our interest lies in the rational design and synthesis of type-III mimetics of protein and polypeptide structure and function. ShK toxin is a challenging target for mimetic design as its binding epitope consists of relatively weakly binding residues, some of which are discontinuous. We discuss here our investigations into the design and synthesis of 1st generation, small molecule mimetics of ShK toxin and highlight any principles relevant to the generic design of type-III mimetics of continuous and discontinuous binding epitopes. We complement our approach with attempted pharmacophore-based database mining.	attempt;botulinum toxin type a;complement system proteins;generic drugs;immunosuppressive agents;pharmacophore;polypeptides;potassium channel;small molecule;structure mining;toxin and toxin-target database	Jonathan B. Baell;Andrew J. Harvey;Raymond S. Norton	2002	Journal of computer-aided molecular design	10.1023/A:1020214720560	biochemistry;stereochemistry;chemistry;potassium channel;combinatorial chemistry;ion channel	EDA	7.312553413587042	-62.31287708218923	74215
3eddc315b93021db14916dd829e12cf48d6dab5e	a computational model for predicting fusion peptide of retroviruses	similarity comparison;fusion peptide domain prediction;hidden markov method	As a pivotal domain within envelope protein, fusion peptide (FP) plays a crucial role in pathogenicity and therapeutic intervention. Taken into account the limited FP annotations in NCBI database and absence of FP prediction software, it is urgent and desirable to develop a bioinformatics tool to predict new putative FPs (np-FPs) in retroviruses. In this work, a sequence-based FP model was proposed by combining Hidden Markov Method with similarity comparison. The classification accuracies are 91.97% and 92.31% corresponding to 10-fold and leave-one-out cross-validation. After scanning sequences without FP annotations, this model discovered 53,946 np-FPs. The statistical results on FPs or np-FPs reveal that FP is a conserved and hydrophobic domain. The FP software programmed for windows environment is available at https://sourceforge.net/projects/fptool/files/?source=navbar.		Sijia Wu;Jiuqiang Han;Ruiling Liu;Jun Liu;Hongqiang Lv	2016	Computational biology and chemistry	10.1016/j.compbiolchem.2016.02.013	computer science;bioinformatics;artificial intelligence;data mining	Comp.	8.682833337659781	-57.448340225816075	74280
e2bbc430f6c154fc413c563049353a87ca22c1da	exact-iebp: a new technique for estimating evolutionary distances between whole genomes	evolutionary trees	Evolution operates on whole genomes by operations that change the order and strandedness of genes within the genomes. This type of data presents new opportunities for discoveries about deep evolutionary rearrangement events, provided that sufficiently accurate methods can be developed to reconstruct evolutionary trees in these models [3,11,13,18]. A necessary component of any such method is the ability to accurately estimate the true evolutionary distance between two genomes,which is the number of rearrangement events that took place in the evolutionary history between them. We improve the technique (IEBP) in with a new method, Exact-IEBP, for estimating the true evolutionary distance between two signed genomes. Our simulation study shows Exact-IEBP is a better estimation of true evolutionary distances. Furthermore, Exact-IEBP produces more accurate trees than IEBP when used with the popular distance-based method, neighbor joining [16].		Li-San Wang	2001		10.1007/3-540-44696-6_14	biology;phylogenetic tree;computer science;bioinformatics;machine learning	Theory	1.5978834713215122	-52.818649306137594	74316
60c7162b0b41b321da73b4a268d8d19fc95e6528	dmirnet: inferring direct microrna-mrna association networks	simulation and modeling;systems biology;physiological cellular and medical topics;computational biology bioinformatics;algorithms;bioinformatics	MicroRNAs (miRNAs) play important regulatory roles in the wide range of biological processes by inducing target mRNA degradation or translational repression. Based on the correlation between expression profiles of a miRNA and its target mRNA, various computational methods have previously been proposed to identify miRNA-mRNA association networks by incorporating the matched miRNA and mRNA expression profiles. However, there remain three major issues to be resolved in the conventional computation approaches for inferring miRNA-mRNA association networks from expression profiles. 1) Inferred correlations from the observed expression profiles using conventional correlation-based methods include numerous erroneous links or over-estimated edge weight due to the transitive information flow among direct associations. 2) Due to the high-dimension-low-sample-size problem on the microarray dataset, it is difficult to obtain an accurate and reliable estimate of the empirical correlations between all pairs of expression profiles. 3) Because the previously proposed computational methods usually suffer from varying performance across different datasets, a more reliable model that guarantees optimal or suboptimal performance across different datasets is highly needed. In this paper, we present DMirNet, a new framework for identifying direct miRNA-mRNA association networks. To tackle the aforementioned issues, DMirNet incorporates 1) three direct correlation estimation methods (namely Corpcor, SPACE, Network deconvolution) to infer direct miRNA-mRNA association networks, 2) the bootstrapping method to fully utilize insufficient training expression profiles, and 3) a rank-based Ensemble aggregation to build a reliable and robust model across different datasets. Our empirical experiments on three datasets demonstrate the combinatorial effects of necessary components in DMirNet. Additional performance comparison experiments show that DMirNet outperforms the state-of-the-art Ensemble-based model [1] which has shown the best performance across the same three datasets, with a factor of up to 1.29. Further, we identify 43 putative novel multi-cancer-related miRNA-mRNA association relationships from an inferred Top 1000 direct miRNA-mRNA association network. We believe that DMirNet is a promising method to identify novel direct miRNA-mRNA relations and to elucidate the direct miRNA-mRNA association networks. Since DMirNet infers direct relationships from the observed data, DMirNet can contribute to reconstructing various direct regulatory pathways, including, but not limited to, the direct miRNA-mRNA association networks.	computation;deconvolution;elegant degradation;experiment;inference;mental association;micrornas;microarray;numerous;one thousand;repression, psychology;silo (dataset);translational repression;mrna degradation	Min-Su Lee;HyungJune Lee	2016		10.1186/s12918-016-0373-1	biology;computer science;bioinformatics;machine learning;data mining;systems biology	Comp.	5.449204586810943	-55.8070914679176	74357
62f3a7a470ef02f0627c96afb5be297e6f445a0c	hptaa database-potential target genes for clinical diagnosis and immunotherapy of human carcinoma	databases genetic;clinical diagnosis;tumor markers biological;gene expression;internet;antigens neoplasm;immunotherapy;humans;user computer interface;carcinoma	Tumor-associated antigens (TAAs) have been the most actively employed targets in the clinical diagnosis and treatment of human carcinoma, such as PSA in the diagnosis of prostate cancer and NY-ESO-1 in the immunotherapy of melanoma and other cancers. However, identification of TAAs has often been hampered by the complicated and laborsome laboratory procedures. In order to accelerate the process of tumor antigen discovery, and thereby improve diagnosis and treatment of human carcinoma, we have made an effort to establish a publicly available Human Potential Tumor Associated Antigen database (HPtaa) with potential TAAs identified by in silico computing (http://www.hptaa.org). Tumor specificity was chosen as the core of tumor antigen evaluation, together with other relevant clues. Various platforms of gene expression, including microarray, expressed sequence tag and SAGE data, were processed and integrated by several penalty algorithms. A total of 3518 potential TAAs have been included in the database, which is freely available to academic users. As far as we know, this database is the first one addressing human potential TAAs, and the first one integrating various kinds of expression platforms for one purpose.	carcinoma;computation (action);diagnosis, clinical;expressed sequence tags;gene expression;hiv antigens;immunotherapy;malignant neoplasms;microarray;ny-eso-1 peptide vaccine;prostatic neoplasms;sensitivity and specificity;tumor antigens;algorithm;melanoma	Xiaosong Wang;Haitao Zhao;Qingwen Xu;Weibo Jin;Changning Liu;Huagang Zhang;Zhibin Huang;Xinyu Zhang;Yu Zhang;Dianqi Xin;Andrew J. G. Simpson;Lloyd J. Old;Yanqun Na;Yi Zhao;Weifeng Chen	2006	Nucleic Acids Research	10.1093/nar/gkj082	biology;the internet;gene expression;bioinformatics;immunology;genetics	Comp.	8.293164149812187	-57.80645500566989	74419
c9bb21cc3620952888e129bf7952a60e23c03e31	hybrid elementary flux analysis/nonparametric modeling: application for bioprocess control	cho cells;animals;metabolic network;proteome;baby hamster kidney;cricetinae;glycoprotein;signal transduction;environmental conditions;models biological;recombinant proteins;computational biology bioinformatics;optimal control;metabolic clearance rate;cricetulus;hybrid system;biological systems;cell growth;algorithms;combinatorial libraries;kinetics;computer appl in life sciences;computer simulation;protein engineering;monitoring and control;control method;reaction mechanism;steady state;microarrays;bioinformatics	"""The progress in the """"-omic"""" sciences has allowed a deeper knowledge on many biological systems with industrial interest. This knowledge is still rarely used for advanced bioprocess monitoring and control at the bioreactor level. In this work, a bioprocess control method is presented, which is designed on the basis of the metabolic network of the organism under consideration. The bioprocess dynamics are formulated using hybrid rigorous/data driven systems and its inherent structure is defined by the metabolism elementary modes. The metabolic network of the system under study is decomposed into elementary modes (EMs), which are the simplest paths able to operate coherently in steady-state. A reduced reaction mechanism in the form of simplified reactions connecting substrates with end-products is obtained. A dynamical hybrid system integrating material balance equations, EMs reactions stoichiometry and kinetics was formulated. EMs kinetics were defined as the product of two terms: a mechanistic/empirical known term and an unknown term that must be identified from data, in a process optimisation perspective. This approach allows the quantification of fluxes carried by individual elementary modes which is of great help to identify dominant pathways as a function of environmental conditions. The methodology was employed to analyse experimental data of recombinant Baby Hamster Kidney (BHK-21A) cultures producing a recombinant fusion glycoprotein. The identified EMs kinetics demonstrated typical glucose and glutamine metabolic responses during cell growth and IgG1-IL2 synthesis. Finally, an online optimisation study was conducted in which the optimal feeding strategies of glucose and glutamine were calculated after re-estimation of model parameters at each sampling time. An improvement in the final product concentration was obtained as a result of this online optimisation. The main contribution of this work is a novel bioreactor optimal control method that uses detailed information concerning the metabolism of the underlying biological system. Moreover, the method allows the identification of structural modifications in metabolism over batch time."""	biological system;bioreactors;dynamical system;elementary particles;flux limiter;glucose;glutamine;hybrid system;kinetics (discipline);kinetics internet protocol;mathematical optimization;metabolic process, cellular;omics;optimal control;quantitation;recombinant dna;recombinants;renal tissue;sampling (signal processing);science;steady state;cell growth	Ana P. Teixeira;Carlos Alves;Paula M. Alves;Manuel J. T. Carrondo;Rui Oliveira	2006	BMC Bioinformatics	10.1186/1471-2105-8-30	computer simulation;biology;dna microarray;optimal control;recombinant dna;biotechnology;bioinformatics;reaction mechanism;proteome;protein engineering;glycoprotein;chinese hamster ovary cell;steady state;cell growth;genetics;signal transduction;kinetics;metabolic network;hybrid system	ML	6.602590495177926	-61.1072925403635	74497
6fb92182319beafa5de51e96c2c50126c057e696	class ii mhc quantitative binding motifs derived from a large molecular database with a versatile iterative stepwise discriminant analysis meta- algorithm	software;antigeno histocompatibilidad clase ii;prediccion;linfocito t;logiciel;computerized processing;tratamiento informatico;systeme histocompatibilite majeur;lymphocyte t;hombre;binding site;sistema histocompatibilidad mayor;algorithme;antigene histocompatibilite classe ii;discriminant analysis;analyse discriminante;site fixation;algorithm;analisis discriminante;class ii histocompatibility antigen;determinante antigenico;human;logicial;determinant antigenique;major histocompatibility system;traitement informatique;sitio fijacion;prediction;stepwise discriminant analysis;antigenic determinant;t lymphocyte;homme;algoritmo	MOTIVATION The identification of T-cell epitopes can be crucial for vaccine development. An epitope is a peptide segment that binds to both a T-cell receptor and a major histocompatibility complex (MHC) molecule. Predicting which peptide segments bind MHC molecules is the first step in epitope prediction.   RESULTS An iterative stepwise discriminant analysis meta-algorithm explores a large molecular database to derive quantitative motifs for peptide binding. The applications presented here demonstrate the algorithm's versatility by producing four closely related models for HLA-DR1. Two models use an expert initial estimate and two do not; two models use amino acid residues as the only predictors and two use amino acid groupings as additional predictors. Each model correctly classifies >90% of the peptides in the database.   AVAILABILITY Software is available commercially; data are free over the Internet.	algorithm;amino acids;databases, molecular;epitopes;internet;iterative method;linear discriminant analysis;major histocompatibility complex;metaheuristic;model of hierarchical complexity;stepwise regression;vaccine development	R. R. Mallios	1999	Bioinformatics	10.1093/bioinformatics/15.6.432	biology;prediction;computer science;bioinformatics;binding site;artificial intelligence;immunology;linear discriminant analysis;epitope;statistics	Comp.	-3.912336060429933	-55.38888315481306	74524
e7d5d90dde2a74fd98669cd126f1e93e00b2d2d1	follicle structure influences the availability of oxygen to the oocyte in antral follicles	animals;female;ovarian follicle;oxygen;models biological;numerical analysis computer assisted;cattle;follicular fluid;oocytes	The ability of an oocyte to successfully mature is highly dependent on intrafollicular conditions, including the size and structure of the follicle. Here we present a mathematical model of oxygen transport in the antral follicle. We relate mean oxygen concentration in follicular fluid of bovine follicles to the concentration in the immediate vicinity of the cumulus-oocyte complex (COC). The model predicts that the oxygen levels within the antral follicle are dependent on the size and structure of the follicle and that the mean level of dissolved oxygen in follicular fluid does not necessarily correspond to that reaching the COC.	biologic development;calculus of constructions;cattle;cumulus;follicular fluid;mathematical model;mathematics;oocytes;ovarian follicle;ovary;oxygen	Alys R. Clark;Yvonne M. Stokes	2011		10.1155/2011/287186	biology;endocrinology;antral follicle;folliculogenesis;gynecology;oxygen;anatomy	ML	9.898881999623482	-64.71961859787241	74554
999eceff54c05d602d99ab6d4ed28677ee66936c	reconstructing biological networks using conditional correlation analysis	use;topology;escherichia coli;arquitectura red;bacterie;topologie;cribado alta productividad;methode;reseau;architecture reseau;network analysis;red;enterobacteriaceae;topologia;high throughput screening;utilisation;criblage haut debit;uso;analyse correlation;network architecture;bacteria;analyse circuit;metodo;method;analisis circuito;biological network;analisis correlacion;network;correlation analysis	MOTIVATION One of the present challenges in biological research is the organization of the data originating from high-throughput technologies. One way in which this information can be organized is in the form of networks of influences, physical or statistical, between cellular components. We propose an experimental method for probing biological networks, analyzing the resulting data and reconstructing the network architecture.   METHODS We use networks of known topology consisting of nodes (genes), directed edges (gene-gene interactions) and a dynamics for the genes' mRNA concentrations in terms of the gene-gene interactions. We proposed a network reconstruction algorithm based on the conditional correlation of the mRNA equilibrium concentration between two genes given that one of them was knocked down. Using simulated gene expression data on networks of known connectivity, we investigated how the reconstruction error is affected by noise, network topology, size, sparseness and dynamic parameters.   RESULTS Errors arise from correlation between nodes connected through intermediate nodes (false positives) and when the correlation between two directly connected nodes is obscured by noise, non-linearity or multiple inputs to the target node (false negatives). Two critical components of the method are as follows: (1) the choice of an optimal correlation threshold for predicting connections and (2) the reduction of errors arising from indirect connections (for which a novel algorithm is proposed). With these improvements, we can reconstruct networks with the topology of the transcriptional regulatory network in Escherichia coli with a reasonably low error rate.	algorithm;anatomic node;anatomy, regional;biological network;bit error rate;chamaecyparis lawsoniana;experiment;gene expression;high-throughput computing;interaction;network architecture;network topology;neural coding;nonlinear system;throughput;transcription, genetic	John Jeremy Rice;Yuhai Tu;Gustavo Stolovitzky	2005	Bioinformatics	10.1093/bioinformatics/bti064	high-throughput screening;biology;biological network;method;network architecture;network analysis;telecommunications;bacteria;computer science;artificial intelligence;mathematics;escherichia coli;genetics	Comp.	5.569546196738265	-56.797806956961	74787
266a50408d949715b1b3af393b03cf5479774481	a hybrid method of propensity scales and support vector machine in a linear epitope prediction	peptides;amino acid segment linear epitope support vector machine physico chemical property antibody antigen;support vector machines;amino acid;training;physico chemical property;support vector machines amino acids accuracy sensitivity proteins training peptides;physico chemical properties;accuracy;sensitivity;proteins;hybrid method;amino acids;positive prediction value propensity scale hybrid method support vector machine technique linear epitope prediction synthetic peptides development bioinformatics approach physico chemical properties bepipred abcpred fbcpred;support vector machine;support vector machines bioinformatics;amino acid segment;bioinformatics;linear epitope;antibody antigen	An epitope activates B cells to amplify and induce antibodies which can neutralize the foreign molecules, particles and pathogens. It also plays a crucial role in developing synthetic peptides for vaccination. Identification of epitopes using biological screening approaches is time consuming and high cost. Therefore, bioinformatics approaches are developed to enhance the speed of identifying the epitopes and conserve time. Herein, a combinatorial methodology based on physico-chemical properties and SVM (Support Vector Machine) techniques was proposed to address the aim of this study. Datasets of epitope and non epitope segments with 2, 3 and 4 residues in length were trained and applied as statistical features of SVM. After training, three datasets including one curated and two public ones were employed to evaluate the performance of the proposed system which was also compared with four existing LE predictors, BepiPred, ABCpred, BCPred and FBCPred. Our proposed system has presented better specificity, accuracy, and positive prediction value (PPV) in most testing cases. High specificity and PPV of a linear epitope prediction can lead to an efficient and effective design on biological experiments.	bioinformatics;branch predictor;experiment;sensitivity and specificity;support vector machine;synthetic intelligence	Hsin-Wei Wang;Ya-Chi Lin;Tun-Wen Pai;Pei-Wen Tsai;Hao-Teng Chang	2011	2011 International Conference on Complex, Intelligent, and Software Intensive Systems	10.1109/CISIS.2011.89	biology;molecular biology;bioinformatics;combinatorial chemistry	SE	9.42955887552062	-56.14650862289395	74901
6a3bce3ca9dd2064a9f53af1c5ea885aa045534c	automated hierarchical classification of protein domain subfamilies based on functionally-divergent residue signatures	phylogeny;amino acid sequence;computational biology bioinformatics;conserved sequence;proteins;protein structure tertiary;monte carlo method;algorithms;protein folding;sequence alignment;combinatorial libraries;computer appl in life sciences;markov chains;databases protein;microarrays;bioinformatics	The NCBI Conserved Domain Database (CDD) consists of a collection of multiple sequence alignments of protein domains that are at various stages of being manually curated into evolutionary hierarchies based on conserved and divergent sequence and structural features. These domain models are annotated to provide insights into the relationships between sequence, structure and function via web-based BLAST searches. Here we automate the generation of conserved domain (CD) hierarchies using a combination of heuristic and Markov chain Monte Carlo (MCMC) sampling procedures and starting from a (typically very large) multiple sequence alignment. This procedure relies on statistical criteria to define each hierarchy based on the conserved and divergent sequence patterns associated with protein functional-specialization. At the same time this facilitates the sequence and structural annotation of residues that are functionally important. These statistical criteria also provide a means to objectively assess the quality of CD hierarchies, a non-trivial task considering that the protein subgroups are often very distantly related—a situation in which standard phylogenetic methods can be unreliable. Our aim here is to automatically generate (typically sub-optimal) hierarchies that, based on statistical criteria and visual comparisons, are comparable to manually curated hierarchies; this serves as the first step toward the ultimate goal of obtaining optimal hierarchical classifications. A plot of runtimes for the most time-intensive (non-parallelizable) part of the algorithm indicates a nearly linear time complexity so that, even for the extremely large Rossmann fold protein class, results were obtained in about a day. This approach automates the rapid creation of protein domain hierarchies and thus will eliminate one of the most time consuming aspects of conserved domain database curation. At the same time, it also facilitates protein domain annotation by identifying those pattern residues that most distinguish each protein domain subgroup from other related subgroups.	algorithm;annotation;antivirus software;blast;cdd;classification;digital curation;heuristic;markov chain monte carlo;monte carlo method;multiple sequence alignment;ncbi taxonomy;partial template specialization;phylogenetics;protein domain;sampling (signal processing);subgroup a nepoviruses;time complexity;web application	Andrew F. Neuwald;Christopher J. Lanczycki;Aron Marchler-Bauer	2012		10.1186/1471-2105-13-144	protein folding;biology;markov chain;dna microarray;bioinformatics;simple modular architecture research tool;sequence alignment;peptide sequence;conserved sequence;conserved domain database;genetics;phylogenetics;monte carlo method	Comp.	0.9494065914984388	-55.49538826224148	74939
c4e2b10abe59c041d638cb65afada37270b12961	de novo svm classification of precursor micrornas from genomic pseudo hairpins using global and intrinsic folding measures	rna interference;computer program;refolding;precursor;repliegue;cytomegalovirus;inverted repeat;fonction base radiale;maquina vector soporte;bioinformatique;original document;regulation control;classification;document original;programa informatico;machine vecteur support;micro arn;radial basis function;rna;simian virus;identification;precurseur;documento original;participacion;score test;regulation;thermodynamics;identificacion;de novo;cross validation;bioinformatica;support vector machine;regulacion;funcion radial base;microrna;arn non codant;repliement;similarity measure;participation;clasificacion;programme ordinateur;bioinformatics	MOTIVATION MicroRNAs (miRNAs) are small ncRNAs participating in diverse cellular and physiological processes through the post-transcriptional gene regulatory pathway. Critically associated with the miRNAs biogenesis, the hairpin structure is a necessary feature for the computational classification of novel precursor miRNAs (pre-miRs). Though many of the abundant genomic inverted repeats (pseudo hairpins) can be filtered computationally, novel species-specific pre-miRs are likely to remain elusive.   RESULTS miPred is a de novo Support Vector Machine (SVM) classifier for identifying pre-miRs without relying on phylogenetic conservation. To achieve significantly higher sensitivity and specificity than existing (quasi) de novo predictors, it employs a Gaussian Radial Basis Function kernel (RBF) as a similarity measure for 29 global and intrinsic hairpin folding attributes. They characterize a pre-miR at the dinucleotide sequence, hairpin folding, non-linear statistical thermodynamics and topological levels. Trained on 200 human pre-miRs and 400 pseudo hairpins, miPred achieves 93.50% (5-fold cross-validation accuracy) and 0.9833 (ROC score). Tested on the remaining 123 human pre-miRs and 246 pseudo hairpins, it reports 84.55% (sensitivity), 97.97% (specificity) and 93.50% (accuracy). Validated onto 1918 pre-miRs across 40 non-human species and 3836 pseudo hairpins, it yields 87.65% (92.08%), 97.75% (97.42%) and 94.38% (95.64%) for the mean (overall) sensitivity, specificity and accuracy. Notably, A.mellifera, A.geoffroyi, C.familiaris, E.Barr, H. Simplex virus, H.cytomegalovirus, O.aries, P.patens, R.lymphocryptovirus, Simian virus and Z.mays are unambiguously classified with 100.00% (sensitivity) and >93.75% (specificity).   AVAILABILITY Data sets, raw statistical results and source codes are available at http://web.bii.a-star.edu.sg/~stanley/Publications	classification;code;cross reactions;cross-validation (statistics);de novo transcriptome assembly;dinucleoside phosphates;gucy2c protein, human;gene regulatory network;micrornas;nonlinear system;normal statistical distribution;phylogenetics;physiological processes;pseudo brand of pseudoephedrine;radial basis function kernel;sensitivity and specificity;similarity measure;support vector machine;thermodynamics;transcription, genetic	Stanley Ng Kwang Loong;Santosh Kumar Mishra	2007	Bioinformatics	10.1093/bioinformatics/btm026	identification;biology;support vector machine;inverted repeat;regulation;radial basis function;rna;score test;biological classification;computer science;bioinformatics;rna interference;artificial intelligence;genetics;cross-validation;microrna	Comp.	9.211830404290989	-56.740013741248475	75019
e841936cf0bac1d4d939e4b37402901e56e7f5d1	comparative analysis of the annotation systems of mus musculus high density expression microarray		Annotations created by microarrays producer Affymetrix are based on the genomic and transcriptomic knowledge that was available at a time of construction of a particular chip. However scientific databases are regularly updated so there is a need of performing re-annotation processes. The goal of this work was to assess the relevance of the probes located on the given Affymetrix 3’ expression or promoter microarray and to perform a re-annotation procedure. The use of updated definition files proved that they can improve the results of the microarray data analysis comparing to the standard Affymetrix approach.	database;experiment;microarray;relevance	Anna Cichonska;Roman Jaksik;Joanna Polanska;Wieslawa Widlak	2013			dna microarray;transcriptome;microarray databases;affymetrix genechip operating software;gene chip analysis;microarray analysis techniques;microarray;biology;bioinformatics;annotation	Comp.	-1.3139247670330496	-58.33706728890824	75157
ba269026aa3191ac3a91f989b443cdf59748eb71	identifying cancer biomarkers by knowledge discovery from medical literature	cancer;information extraction;text mining;biological organs;medical computing biological organs cancer data mining gynaecology;data mining;data format;abstracts data mining diseases feature extraction breast cancer databases frequency measurement;gynaecology;medical computing;breast cancers identifying cancer biomarkers knowledge discovery medical literature automated extraction domain specific information medbuilder row data format association network reliable system;network text mining information extraction;breast cancer;domain specificity;network	The importance of extracting valuable information from published articles has been well recognized by the research community. The literature is growing exponentially bringing the need for automated extraction of domain specific information. The outcome could serve a wide range of applications. We present MedBuilder as a tool capable of extracting relationships and association links from row data format, to produce an association network. It is a reliable system and has high flexibility to be used in wide range of areas. We test MedBuilder on biomedical field by extracting pubmed abstracts related to breast cancers.	information retrieval;pubmed	Khaled Dawoud;Ala Qabaja;Shang Gao;Reda Alhajj;Jon G. Rokne	2012	2012 IEEE 2nd International Conference on Computational Advances in Bio and medical Sciences (ICCABS)	10.1109/ICCABS.2012.6182651	text mining;computer science;bioinformatics;data science;breast cancer;data mining;information extraction;cancer	Visualization	-3.0543502883828233	-66.01958876691951	75212
11dd1338e1e955640757924c2bc17a29a7033e80	bistability in gene transcription: interplay of messenger rna, protein, and nonprotein coding rna	kinetic equation;publikationer;fluctuations;positive feedback;kinetic model;subcellular processes;konferensbidrag;mrna ncrna mirna and protein synthesis and degradation;protein synthesis;messenger ribonucleic acid;mean field;mean field kinetic equations;negative feedback;messenger rna;artiklar;rapporter;bistability;monte carlo simulation;kinetics;microrna;monte carlo simulations;gene transcription;steady state	The author proposes a kinetic model describing the interplay of messenger ribonucleic acid (mRNA), protein, produced via translation of this RNA, and nonprotein coding RNA (ncRNA). The model includes association of mRNA and ncRNA and regulation of the ncRNA production by protein. In the case of positive feedback between the production of protein and ncRNA, the steady state of the system is found to be unique. For negative feedback, the model predicts in the mean-field case either unique steady state or bistable kinetics. With incorporation of fluctuations, the bistability is manifested in the form of kinetic bursts provided that the number of reactants is low. Basically, the model describes the simplest biological switch operating with participation of ncRNA. Although the results obtained are applicable to ncRNSs in general, the presentation is focused primarily on microRNAs (miRNAs) which form a large important subclass of ncRNAs and are thought to regulate up to one third of all human genes.	bistability;kinetics internet protocol;micrornas;negative feedback;positive feedback;retinal nonattachment, nonsyndromic congenital;rna;rna, messenger;rna, untranslated;steady state;transcription (software);transcription, genetic;subclass	Vladimir P. Zhdanov	2009	Bio Systems	10.1016/j.biosystems.2008.07.002	biology;molecular biology;bioinformatics;genetics;monte carlo method	Comp.	6.733412124314613	-65.09753853612729	75227
4b2cd9be940d9c04c646c1ce210fe73d6bc578f5	a physicochemical descriptor-based scoring scheme for effective and rapid filtering of kinase-like chemical space	health research;uk clinical guidelines;physicochemical properties;biological patents;europe pubmed central;citation search;phosphorus transferases;data bases;computer applications in chemistry;theoretical and computational chemistry;computational biology bioinformatics;uk phd theses thesis;life sciences;reprints;uk research reports;medical journals;europe pmc;documentation and information in chemistry;biomedical research;bioinformatics	BACKGROUND The current chemical space of known small molecules is estimated to exceed 1060 structures. Though the largest physical compound repositories contain only a few tens of millions of unique compounds, virtual screening of databases of this size is still difficult. In recent years, the application of physicochemical descriptor-based profiling, such as Lipinski's rule-of-five for drug-likeness and Oprea's criteria of lead-likeness, as early stage filters in drug discovery has gained widespread acceptance. In the current study, we outline a kinase-likeness scoring function based on known kinase inhibitors.   RESULTS The method employs a collection of 22,615 known kinase inhibitors from the ChEMBL database. A kinase-likeness score is computed using statistical analysis of nine key physicochemical descriptors for these inhibitors. Based on this score, the kinase-likeness of four publicly and commercially available databases, i.e., National Cancer Institute database (NCI), the Natural Products database (NPD), the National Institute of Health's Molecular Libraries Small Molecule Repository (MLSMR), and the World Drug Index (WDI) database, is analyzed. Three of these databases, i.e., NCI, NPD, and MLSMR are frequently used in the virtual screening of kinase inhibitors, while the fourth WDI database is for comparison since it covers a wide range of known chemical space. Based on the kinase-likeness score, a kinase-focused library is also developed and tested against three different kinase targets selected from three different branches of the human kinome tree.   CONCLUSIONS Our proposed methodology is one of the first that explores how the narrow chemical space of kinase inhibitors and its relevant physicochemical information can be utilized to build kinase-focused libraries and prioritize pre-existing compound databases for screening. We have shown that focused libraries generated by filtering compounds using the kinase-likeness score have, on average, better docking scores than an equivalent number of randomly selected compounds. Beyond library design, our findings also impact the broader efforts to identify kinase inhibitors by screening pre-existing compound libraries. Currently, the NCI library is the most commonly used database for screening kinase inhibitors. Our research suggests that other libraries, such as MLSMR, are more kinase-like and should be given priority in kinase screenings.	boat dock;chembl;chemical library;chemical space;database;databases;docking (molecular);drug discovery;gain;largest;libraries;limited stage (cancer stage);lipinski's rule of five;nc (complexity);neoplasms;new product development;randomness;repository;score;screening procedure;transcutaneous electric nerve stimulation;virtual screening	Narender Singh;Hongmao Sun;Sidhartha Chaudhury;Mohamed Diwan M. AbdulHameed;Anders Wallqvist;Gregory J. Tawa	2012		10.1186/1758-2946-4-4	biology;medical research;medicine;computer science;bioinformatics;data science;data mining	Comp.	-0.5014082719497017	-62.74363554553992	75342
83329ddbc3c2f4212881fb98014e0b2be2183d99	evidence for sequence-independent evolutionary traces in genomics data	protein sequence;genome sequence;false positive	Sequence conservation during evolution is the foundation for the functional classification of the enormous number of new protein sequences being discovered in the current era of genome sequencing. Conventional methods to detect homologous proteins are not always able to distinguish between true homologs and false positive hits in the twilight zone of sequence similarity. Several different approaches have been proposed to improve the sensitivity of these methods. Among the most successful are sequence profiles, multi-linked alignment, and threading. However, evolution might offer up other clues about a protein's ancestry that are sequence independent. Here we report the discovery of two such traces of evolution that could potentially be used to help infer the fold of a protein and hence improve the ability to predict the biochemical function. The first such evolutionary trace is a conservation of fold along the genome, i.e. nearby genes tend to share a fold more often than expected by chance alone--a not unexpected observation, but one which holds true even when no pair of genes being examined share appreciable homology. The second such evolutionary trace is, surprisingly, present in expression data: genes that are correlated in expression are more apt to share a fold than two randomly chosen genes. This result is surprising because correlations in expression have previously only been considered useful for determining biological function (e.g. what pathway a particular gene fits into), yet the observed fold enrichment in the expression data permits us to say something about biochemical function since fold corresponds strongly with biochemical function. Again, the fold enrichment observed in the expression data is apparent even when no pair of genes being examined share appreciable homology.	amino acid sequence;conserved sequence;evolution;fits;function (biology);gene ontology term enrichment;gene regulatory network;homologous gene;homology (biology);inference;lypla2p1 gene;license;numerous;peptide sequence;pierre robin syndrome;position weight matrix;randomness;staphylococcal protein a;thread (computing);tracing (software);whole genome sequencing	Wayne Volkmuth;N. Alexandrov	2002	Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing		biology;whole genome sequencing;type i and type ii errors;bioinformatics;protein sequencing;genetics;statistics	Comp.	3.761968302318719	-59.17726662729777	75363
eedf297b317baa543a397ea9b28d36d5aaa8ddb2	ab initio quantum mechanical and x-ray crystallographic studies of gemcitabine and 2'-deoxy cytosine	ribonucleotide reductase;clinical trial;quantum mechanics;x ray structure;x rays	Gemcitabine 2',2'-difluoro 2'-deoxy cytosine (GEM) is a novel nucleoside which has demonstrated broad preclinical anti-cancer activity and appears promising in early stage human clinical trials. One purpose of this study was to characterize the energetically favored conformational modes of GEM by means of ab initio quantum mechanical studies with comparison to a novel X-ray crystallographic structure, and to determine the performance of ab initio quantum mechanical theory by comparison with X-ray structural data for GEM and 2'-deoxy cytosine (CYT). Another objective of this study was to attempt to determine key structural and electronic atomic interactions relating to the 2',2'-difluoro substitution in GEM by the application of ab initio quantum mechanical methods. To our knowledge, these are the first reported ab initio quantum mechanical geometry optimizations of nucleosides using large (e.g. 6-31G*) slit valence function basis sets. The development of accurate physicochemical models on a small scale enables us to extend our studies of GEM to more complex studies including DNA incorporation, deamination, ribonucleotide reductase inhibition, and triphosphorylation.	ab initio quantum chemistry methods;basis set (chemistry);crystal structure;cytarabine;cytosine;deamination;diagnostic radiologic examination;interaction;limited stage (cancer stage);mandibular right second molar tooth;neoplasms;nucleosides;quantum mechanics;ribonucleotide reductase;ribonucleotides;gemcitabine	Frederick H. Hausheer;Noel D. Jones;Peddaiahgari Seetharamulu;U. C. Singh;Jack B. Deeter;Larry W. Hertel;Julian S. Kroin	1996	Computers & chemistry	10.1016/0097-8485(95)00079-8	crystallography;biology;stereochemistry;ribonucleotide reductase;chemistry;clinical trial;computational chemistry;quantum mechanics	HCI	9.957056916824543	-61.93691262961901	75373
55bc374406b77fed8084446cdb5719177db871cc	evolutionary search for paths on protein energy landscapes		Proteins are in perpetual motion, switching between structures to regulate interactions with molecular partners. These motions correspond to hops in an energy landscape that organizes the structures available to a protein by their potential energies. Here we introduce an evolutionary algorithm (EA) that computes structural excursions of a protein without the need to reconstruct its energy landscape a priori. The preliminary results are promising and suggest further directions of research.	evolutionary algorithm;interaction	Emmanuel Sapin;Kenneth A. De Jong;Amarda Shehu	2017		10.1145/3067695.3075599	machine learning;fitness landscape;mathematical optimization;artificial intelligence;computer science;energy landscape;evolutionary algorithm;perpetual motion;protein structure prediction	Comp.	8.815628848005572	-63.6167738137392	75504
31f4e87ff12f27a686512a8d32cf35a7b603cf34	segmentation of short human exons based on spectral features of double curves	exon;simulation;gen;bioinformatique;hombre;gene identification;spectrum;secuencia nucleotido;segmentation;short protein coding regions;data mining;nucleotide sequence;sequence nucleotide;double curves;identification;human;spectre;gene;identificacion;short human exons;dna sequence analysis;bioinformatica;spectral analysis;fourier spectrum;segmentacion;triplets;homme;espectro;bioinformatics	This paper presents a new segmentation method based on spectral analysis to locate borders between short protein coding regions and non-coding regions. We formulate the innovative double curve representation of a DNA sequence and apply local three-codon measurement on the discrete Fourier spectral features at 1/3 frequency to identify short protein coding regions. The proposed spectral segmentation method based on double curves requires no prior knowledge of the DNA data. Our simulation results show that the proposed spectral method greatly improves the accuracy of identifying short coding regions in DNA sequences compared with the results obtained from the other methods that analyse DNA sequences directly.	algorithm;binary number;exons;frame (physical object);open reading frames;open reading frame;reading frames (nucleotide sequence);sequence motif;simulation;spectral density estimation;spectral method;biologic segmentation	Rong Jiang;Hong Yan	2008	International journal of data mining and bioinformatics	10.1504/IJDMB.2008.016754	identification;biology;spectrum;exon;nucleic acid sequence;computer science;bioinformatics;sequence analysis;gene;segmentation;genetics	Comp.	2.429670813081324	-63.348134457343505	75509
841933e76a3416cbc2db8cca1ebc944768d2c62b	considering scores between unrelated proteins in the search database improves profile comparison	protein sequence;statistical significance;power method;computational biology bioinformatics;protein structure;proteins;structure prediction;algorithms;multiple sequence alignment;databases factual;combinatorial libraries;computational biology;computer appl in life sciences;3d structure;sequence analysis protein;databases protein;microarrays;bioinformatics	Profile-based comparison of multiple sequence alignments is a powerful methodology for the detection remote protein sequence similarity, which is essential for the inference and analysis of protein structure, function, and evolution. Accurate estimation of statistical significance of detected profile similarities is essential for further development of this methodology. Here we analyze a novel approach to estimate the statistical significance of profile similarity: the explicit consideration of background score distributions for each database template (subject). Using a simple scheme to combine and analytically approximate query- and subject-based distributions, we show that (i) inclusion of background distributions for the subjects increases the quality of homology detection; (ii) this increase is higher when the distributions are based on the scores to all known non-homologs of the subject rather than a small calibration subset of the database representatives; and (iii) these all known non-homolog distributions of scores for the subject make the dominant contribution to the improved performance: adding the calibration distribution of the query has a negligible additional effect. The construction of distributions based on the complete sets of non-homologs for each subject is particularly relevant in the setting of structure prediction where the database consists of proteins with solved 3D structure (PDB, SCOP, CATH, etc.) and therefore structural relationships between proteins are known. These results point to a potential new direction in the development of more powerful methods for remote homology detection.	amino acid sequence;approximation algorithm;cath;calibration;clinical use template;hl7publishingsubsection <query>;homologous gene;inference;multiple sequence alignment;p-value;protein data bank;scop;semantic similarity;subgroup	Ruslan I Sadreyev;Yong Wang;Nick V. Grishin	2009		10.1186/1471-2105-10-399	biology;protein structure;dna microarray;power iteration;multiple sequence alignment;computer science;bioinformatics;data science;protein sequencing;data mining;statistical significance	Comp.	7.5147198605680385	-56.172647060377976	75550
716efa9e03a9e6ffb739197d298e28e7244e1c3b	cgi: a new approach for prioritizing genes by combining gene expression and protein-protein interaction data	usc;gene expression;protein protein interaction;protein interaction;candidate gene	MOTIVATION Identifying candidate genes associated with a given phenotype or trait is an important problem in biological and biomedical studies. Prioritizing genes based on the accumulated information from several data sources is of fundamental importance. Several integrative methods have been developed when a set of candidate genes for the phenotype is available. However, how to prioritize genes for phenotypes when no candidates are available is still a challenging problem.   RESULTS We develop a new method for prioritizing genes associated with a phenotype by Combining Gene expression and protein Interaction data (CGI). The method is applied to yeast gene expression data sets in combination with protein interaction data sets of varying reliability. We found that our method outperforms the intuitive prioritizing method of using either gene expression data or protein interaction data only and a recent gene ranking algorithm GeneRank. We then apply our method to prioritize genes for Alzheimer's disease.   AVAILABILITY The code in this paper is available upon request.	alzheimer's disease;candidate disease gene;common gateway interface;computer file;gene expression;phenotype;algorithm;protein protein interaction	Xiaotu Ma;Hyunju Lee;Li Wang;Fengzhu Sun	2007	Bioinformatics	10.1093/bioinformatics/btl569	protein–protein interaction;biology;gene expression;bioinformatics;data mining;candidate gene;genetics	Comp.	3.062114949589049	-56.30435623730809	75712
4092debae44088925112bbf10a36f05a96e905ec	inferring the effective tor-dependent network: a computational study in yeast	sirolimus;simulation and modeling;saccharomyces cerevisiae;systems biology;gene regulatory networks;saccharomyces cerevisiae proteins;physiological cellular and medical topics;transcription factors;computational biology bioinformatics;genes fungal;protein processing post translational;algorithms;transcriptome;protein serine threonine kinases;bioinformatics;gene ontology	Calorie restriction (CR) is one of the most conserved non-genetic interventions that extends healthspan in evolutionarily distant species, ranging from yeast to mammals. The target of rapamycin (TOR) has been shown to play a key role in mediating healthspan extension in response to CR by integrating different signals that monitor nutrient-availability and orchestrating various components of cellular machinery in response. Both genetic and pharmacological interventions that inhibit the TOR pathway exhibit a similar phenotype, which is not further amplified by CR. In this paper, we present the first comprehensive, computationally derived map of TOR downstream effectors, with the objective of discovering key lifespan mediators, their crosstalk, and high-level organization. We adopt a systematic approach for tracing information flow from the TOR complex and use it to identify relevant signaling elements. By constructing a high-level functional map of TOR downstream effectors, we show that our approach is not only capable of recapturing previously known pathways, but also suggests potential targets for future studies. Information flow scores provide an aggregate ranking of relevance of proteins with respect to the TOR signaling pathway. These rankings must be normalized for degree bias, appropriately interpreted, and mapped to associated roles in pathways. We propose a novel statistical framework for integrating information flow scores, the set of differentially expressed genes in response to rapamycin treatment, and the transcriptional regulatory network. We use this framework to identify the most relevant transcription factors in mediating the observed transcriptional response, and to construct the effective response network of the TOR pathway. This network is hypothesized to mediate life-span extension in response to TOR inhibition. Our approach, unlike experimental methods, is not limited to specific aspects of cellular response. Rather, it predicts transcriptional changes and post-translational modifications in response to TOR inhibition. The constructed effective response network greatly enhances understanding of the mechanisms underlying the aging process and helps in identifying new targets for further investigation of anti-aging regimes. It also allows us to identify potential network biomarkers for diagnosis and prognosis of age-related pathologies.	aggregate data;aging-related process;crosstalk;downstream (software development);forecast of outcome;futures studies;gene regulatory network;genetic translation process;hereditary diseases;high- and low-level;information flow (information theory);mammals;norm (social);pharmacology;post-translational protein processing;relevance;signal transduction pathways;sirolimus;transcription factor;tor messenger;transcription (software);transcription, genetic	Shahin Mohammadi;Shankar Subramaniam;Ananth Grama	2013		10.1186/1752-0509-7-84	biology;gene regulatory network;transcriptome;bioinformatics;genetics;systems biology;transcription factor	Comp.	5.79713106410423	-59.410169992690996	75757
07a29c1a0081e72263c68053c56c007ccc43b95f	the genetics home reference: a new nlm consumer health resource	genetics medical;medlineplus;health system;health education;genetics;human genome project;databases as topic;humans	The Genetics Home Reference (GHR) is a new information resource developed to be part of the National Library of Medicine's (NLM's) consumer health initiatives. The GHR's guiding principle is to make the health implications of the Human Genome Project accessible to the public. The GHR accomplishes this by providing a bridge between the NLM's consumer health systems MEDLINEplus and ClinicalTrials.gov on the one hand and the multiple resources emanating from the Human Genome Project on the other. The initial focus is on single gene conditions that are main topics in MEDLINEplus.	clinicaltrials.gov;information resources;medlineplus health topics;national library of medicine (u.s.);netware loadable module	Joyce A. Mitchell;Alexa T. McCray	2003	AMIA ... Annual Symposium proceedings. AMIA Symposium		medicine;biotechnology;bioinformatics;genealogy	Logic	-2.5379790645540172	-62.122949507526	75830
27c63e283139bad7370d7eaea54e63542c31d643	evolution and selection in yeast promoters: analyzing the combined effect of diverse transcription factor binding sites	evolution molecular;evolutionary dynamics;evolutionary model;saccharomyces cerevisiae;genome fungal;comparative genomics;transcription factor binding site;transcription factors;sequence analysis dna;binding site;binding sites;genetic variation;probabilistic model;models genetic;promoter regions genetic;transcription factor;protein binding;molecular sequence data;evolutionary process;base sequence;computer simulation	In comparative genomics one analyzes jointly evolutionarily related species in order to identify conserved and diverged sequences and to infer their function. While such studies enabled the detection of conserved sequences in large genomes, the evolutionary dynamics of regulatory regions as a whole remain poorly understood. Here we present a probabilistic model for the evolution of promoter regions in yeast, combining the effects of regulatory interactions of many different transcription factors. The model expresses explicitly the selection forces acting on transcription factor binding sites in the context of a dynamic evolutionary process. We develop algorithms to compute likelihood and to learn de novo collections of transcription factor binding motifs and their selection parameters from alignments. Using the new techniques, we examine the evolutionary dynamics in Saccharomyces species promoters. Analyses of an evolutionary model constructed using all known transcription factor binding motifs and of a model learned from the data automatically reveal relatively weak selection on most binding sites. Moreover, according to our estimates, strong binding sites are constraining only a fraction of the yeast promoter sequence that is under selection. Our study demonstrates how complex evolutionary dynamics in noncoding regions emerges from formalization of the evolutionary consequences of known regulatory mechanisms.	binding sites;biological evolution;collections (publication);conserved sequence;dna binding site;de novo transcriptome assembly;estimated;evolutionary algorithm;genetic selection;genome;genomics;inference;interaction;medical transcription;models of dna evolution;promoter regions, genetic;regulatory sequences, nucleic acid;statistical model;transcription (software);transcription factor binding	Daniela Raijman;Ron Shamir;Amos Tanay	2008	PLoS Computational Biology	10.1371/journal.pcbi.0040007	computer simulation;biology;bioinformatics;binding site;genetics;transcription factor	Comp.	4.252232256908538	-59.625559959094396	76253
0ed23f8a39b438faf74c39561820bccb7c532861	numerical analysis of image based high throughput zebrafish infection screens - matching meaning with data		Tuberculosis is an ancient disease; however, the molecular mechanism of tuberculosis pathology is not completely elucidated yet. In our research we aim to contribute to the understanding of the genes/proteins that are involved in the infection. As a model for the infection study we use the bacterium Mycobacterium marinum, which is closely related to Mycobacterium tuberculosis, the causative agent of tuberculosis in humans. M. marinum causes tuberculosis like disease and is applied to the zebrafish larva as a model (host) organism. We are using a novel pattern recognition framework which allows for in depth analysis of the spread of infection within the zebrafish organism. The amount of infection has been analyzed. However, in depth analysis of the spatial distribution was not yet accomplished. Therefore, as a proof of concept we investigate the presence of specific spatial and quantitive infection patterns.	machine learning;numerical analysis;pattern recognition;throughput;zfin	Alexander E. Nezhinsky;Esther Stoop;Astrid van der Sar;Fons J. Verbeek	2012			computer vision;computer science;bioinformatics;theoretical computer science	AI	5.986419409449469	-60.074954481831625	76322
957340aae399fc74364e0bb1751f1e46a1d1aa6e	towards optimal views of proteins	dimension reduction;protein domains;protein structure;graphical representation;source code;self organising map;coordinate system	MOTIVATION Graphical representations of proteins in online databases generally give default views orthogonal to the PDB file coordinate system. These views are often uninformative in terms of protein structure and/or function. Here we discuss the development of a simple automatic algorithm to provide a 'good' view of a protein domain with respect to its structural features.   RESULTS We used dimension reduction with the preservation of topology (using Kohonen's self organising map) to map 3D carbon alpha coordinates into 2D. The original protein structure was then rotated to the view which corresponded most closely to the 2D mapping. This procedure, which we call OVOP, was evaluated in a public blind trial on the web against random views and a 'flattest' view. The OVOP views were consistently rated 'better' than the other views by our volunteers.   AVAILABILITY The source code is available from the OVOP homepage: http://www.sbc.su.se/~oscar/ovop.	anatomy, regional;biologic preservation;default;dimensionality reduction;graphical user interface;home page;protein data bank;published database;self-organization;self-organizing map;source code;staphylococcal protein a;algorithm	Oscar Sverud;Robert M. MacCallum	2003	Bioinformatics	10.1093/bioinformatics/btg100	protein structure;computer science;bioinformatics;theoretical computer science;coordinate system;machine learning;data mining;mathematics;protein domain;dimensionality reduction;source code	Comp.	-2.1966950815295694	-59.76682745500102	76386
0aed8fc424c3915890b246a0a626ad58e9e218b3	identification of atp binding residues of a protein from its primary sequence	functional annotation;position specific scoring matrix;amino acid sequence;protein ligand interaction;binding sites;amino acid composition;computational biology bioinformatics;its sequences;adenosine triphosphate;proteins;algorithms;sequence alignment;binding protein;support vector machine;combinatorial libraries;computational biology;interaction region;computer appl in life sciences;qh301 biology;sequence analysis protein;genome sequence;databases protein;microarrays;bioinformatics	One of the major challenges in post-genomic era is to provide functional annotations for large number of proteins arising from genome sequencing projects. The function of many proteins depends on their interaction with small molecules or ligands. ATP is one such important ligand that plays critical role as a coenzyme in the functionality of many proteins. There is a need to develop method for identifying ATP interacting residues in a ATP binding proteins (ABPs), in order to understand mechanism of protein-ligands interaction. We have compared the amino acid composition of ATP interacting and non-interacting regions of proteins and observed that certain residues are preferred for interaction with ATP. This study describes few models that have been developed for identifying ATP interacting residues in a protein. All these models were trained and tested on 168 non-redundant ABPs chains. First we have developed a Support Vector Machine (SVM) based model using primary sequence of proteins and obtained maximum MCC 0.33 with accuracy of 66.25%. Secondly, another SVM based model was developed using position specific scoring matrix (PSSM) generated by PSI-BLAST. The performance of this model was improved significantly (MCC 0.5) from the previous one, where only the primary sequence of the proteins were used. This study demonstrates that it is possible to predict 'ATP interacting residues' in a protein with moderate accuracy using its sequence. The evolutionary information is important for the identification of 'ATP interacting residues', as it provides more information compared to the primary sequence. This method will be useful for researchers studying ATP-binding proteins. Based on this study, a web server has been developed for predicting 'ATP interacting residues' in a protein http://www.imtech.res.in/raghava/atpint/ .	adenosine triphosphate;amino acids;automated theorem proving;blast;coenzymes;dna binding site;interaction;ligands;mcc gene;merkel cell carcinoma;position weight matrix;position-specific scoring matrices;score;server (computing);small molecule;staphylococcal protein a;support vector machine;web server;whole genome sequencing	Jagat Singh Chauhan;Nitish K. Mishra;Gajendra P. S. Raghava	2009		10.1186/1471-2105-10-434	biology;support vector machine;molecular biology;whole genome sequencing;dna microarray;computer science;bioinformatics;binding site;sequence alignment;peptide sequence;genetics;binding protein	Comp.	9.364749645199673	-56.73444082030814	76439
32fce60ffb3bfc0f2339b8ef687feca361ba94d2	on the importance of comprehensible classification models for protein function prediction	bioinformatics;classification;knowledge representation;molecular biophysics;physiological models;proteins;comprehensible classification models;data error detection;knowledge representation;protein function prediction;review;biology;classifier design and evaluation;induction;machine learning;classifier design and evaluation;induction;machine learning.	The literature on protein function prediction is currently dominated by works aimed at maximizing predictive accuracy, ignoring the important issues of validation and interpretation of discovered knowledge, which can lead to new insights and hypotheses that are biologically meaningful and advance the understanding of protein functions by biologists. The overall goal of this paper is to critically evaluate this approach, offering a refreshing new perspective on this issue, focusing not only on predictive accuracy but also on the comprehensibility of the induced protein function prediction models. More specifically, this paper aims to offer two main contributions to the area of protein function prediction. First, it presents the case for discovering comprehensible protein function prediction models from data, discussing in detail the advantages of such models, namely, increasing the confidence of the biologist in the system's predictions, leading to new insights about the data and the formulation of new biological hypotheses, and detecting errors in the data. Second, it presents a critical review of the pros and cons of several different knowledge representations that can be used in order to support the discovery of comprehensible protein function prediction models.	protein function prediction	Alex Alves Freitas;Daniela Wieser;Rolf Apweiler	2010	IEEE/ACM Trans. Comput. Biology Bioinform.	10.1145/1719272.1719290	computer science;bioinformatics;machine learning;data mining;computer programming;protein function prediction;molecular biophysics	Metrics	7.7340832383207845	-54.89314836238098	76468
45b701b15ca566434e25a034ebcdce4f011e0536	bntagger: improved tagging snp selection using bayesian networks.	bayesian network;genetic variation;prediction accuracy;single nucleotide polymorphism	Genetic variation analysis holds much promise as a basis for disease-gene association. However, due to the tremendous number of candidate single nucleotide polymorphisms (SNPs), there is a clear need to expedite genotyping by selecting and considering only a subset of all SNPs. This process is known as tagging SNP selection. Several methods for tagging SNP selection have been proposed, and have shown promising results. However, most of them rely on strong assumptions such as prior block-partitioning, bi-allelic SNPs, or a fixed number or location of tagging SNPs. We introduce BNTagger, a new method for tagging SNP selection, based on conditional independence among SNPs. Using the formalism of Bayesian networks (BNs), our system aims to select a subset of independent and highly predictive SNPs. Similar to previous prediction-based methods, we aim to maximize the prediction accuracy of tagging SNPs, but unlike them, we neither fix the number nor the location of predictive tagging SNPs, nor require SNPs to be bi-allelic. In addition, for newly-genotyped samples, BNTagger directly uses genotype data as input, while producing as output haplotype data of all SNPs. Using three public data sets, we compare the prediction performance of our method to that of three state-of-the-art tagging SNP selection methods. The results demonstrate that our method consistently improves upon previous methods in terms of prediction accuracy. Moreover, our method retains its good performance even when a very small number of tagging SNPs are used.	bayesian network;formal system;genetic polymorphism;genotype determination;haplotypes;hereditary diseases;information privacy;nitroprusside;nucleotides;snp array;single nucleotide polymorphism;subgroup;tag (metadata);variable rules analysis	Phil Hyoun Lee;Hagit Shatkay	2006	Bioinformatics	10.1093/bioinformatics/btl233	single-nucleotide polymorphism;biology;computer science;bioinformatics;genetic variation;pattern recognition;bayesian network;genetics	Comp.	3.649383653248777	-52.42153202985899	76486
059901ff29714cd164eed803c16158ba2ad61ef3	the guide rna database	world wide web;rna editing;three dimensional	The RNA editing process in protozoan parasites is controlled by small RNA molecules known as guide RNAs (gRNAs). The gRNA database is a comprehensive compilation of published guide RNA sequences from eight different kinetoplastid organisms. In addition to the RNA primary sequences, information on the gene localization, the experimental verification of the transcripts, and literature citations are provided. Accessory information includes the secondary structures of fourTrypanosoma bruceigRNAs as well as a computer modelled three dimensional gRNA structure. The database is made available as a hypertext document accessible via the World Wide Web (WWW) or from the authors in a printed form.	chromosome mapping;compiler;hypertext;parasites;printing;protozoa;rna editing;rna, guide;scientific publication;transcript;verification of theories;www;world wide web;citation;negative regulation of production of sirna involved in rna interference	Augustine E. Souza;H. Ulrich Göringer	1997	Nucleic acids research	10.1093/nar/26.1.168	rna;gene localization;database;genetics;hypertext;small rna;rna editing;guide rna;biology	Comp.	-0.6536549147650895	-60.73051454496772	76499
c312b1424c9d25fd8ebd1f01a0c7fb6cba9e998f	getting started in text mining	text mining;database management systems;databases bibliographic;scientists;speech;biologists;periodicals as topic;software engineering;database searching;artificial intelligence;algorithms;language;information storage and retrieval;breast cancer;natural language processing	Text mining is the use of automated methods for exploiting the enormous amount of knowledge available in the biomedical literature. There are at least as many motivations for doing text mining work as there are types of bioscientists. Model organism database curators have been heavy participants in the development of the field due to their need to process large numbers of publications in order to populate the many data fields for every gene in their species of interest. Bench scientists have built biomedical text mining applications to aid in the development of tools for interpreting the output of high-throughput assays and to improve searches of sequence databases (see [1] for a review). Bioscientists of every stripe have built applications to deal with the dual issues of the doubleexponential growth in the scientific literature over the past few years and of the unique issues in searching PubMed/ MEDLINE for genomics-related publications. A surprising phenomenon can be noted in the recent history of biomedical text mining: although several systems have been built and deployed in the past few years—Chilibot, Textpresso, and PreBIND (see Text S1 for these and most other citations), for example—the ones that are seeing high usage rates and are making productive contributions to the working lives of bioscientists have been built not by text mining specialists, but by bioscientists. We speculate on why this might be so below. Three basic types of approaches to text mining have been prevalent in the biomedical domain. Co-occurrence– based methods do no more than look for concepts that occur in the same unit of text—typically a sentence, but sometimes as large as an abstract—and posit a relationship between them. (See [2] for an early co-occurrence–based system.) For example, if such a system saw that BRCA1 and breast cancer occurred in the same sentence, it might assume a relationship between breast cancer and the BRCA1 gene. Some early biomedical text mining systems were co-occurrence–based, but such systems are highly error prone, and are not commonly built today. In fact, many text mining practitioners would not consider them to be text mining systems at all. Co-occurrence of concepts in a text is sometimes used as a simple baseline when evaluating more sophisticated systems; as such, they are nontrivial, since even a co-occurrence– based system must deal with variability in the ways that concepts are expressed in human-produced texts. For example, BRCA1 could be referred to by any of its alternate symbols—IRIS, PSCP, BRCAI, BRCC1, or RNF53 (or by any of their many spelling variants, which include BRCA1, BRCA-1, and BRCA 1)— or by any of the variants of its full name, viz. breast cancer 1, early onset (its official name per Entrez Gene and the Human Gene Nomenclature Committee), as breast cancer susceptibility gene 1, or as the latter’s variant breast cancer susceptibility gene-1. Similarly, breast cancer could be referred to as breast cancer, carcinoma of the breast, or mammary neoplasm. These variability issues challenge more sophisticated systems, as well; we discuss ways of coping with them in Text S1. Two more common (and more sophisticated) approaches to text mining exist: rule-based or knowledgebased approaches, and statistical or machine-learning-based approaches. The variety of types of rule-based systems is quite wide. In general, rulebased systems make use of some sort of knowledge. This might take the form of general knowledge about how language is structured, specific knowledge about how biologically relevant facts are stated in the biomedical literature, knowledge about the sets of things that bioscientists talk about and the kinds of relationships that they can have with one another, and the variant forms by which they might be mentioned in the literature, or any subset or combination of these. (See [3] for an early rule-based system, and [4] for a discussion of rule-based approaches to various biomedical text mining tasks.) At one end of the spectrum, a simple rule-based system might use hardcoded patterns—for example, ,gene. plays a role in ,disease. or ,disease. is associated with ,gene.—to find explicit statements about the classes of things in which the researcher is interested. At the other end of the spectrum, a rulebased system might use sophisticated linguistic and semantic analyses to recognize a wide range of possible ways of making assertions about those classes of things. It is worth noting that useful systems have been built using technologies at both ends of the spectrum, and at many points in between. In contrast, statistical or machine-learning–based systems operate by building classifiers that may operate on any level, from labelling part of speech to choosing syntactic parse trees to classifying full sentences or documents. (See [5] for an early learning-based system, and [4] for a discussion of learning-based approaches to various biomedical text mining tasks.) Rule-based and statistical systems each have their advantages and	animal mammary neoplasms;biosci;brca1 gene;brca1 wt allele;baseline (configuration management);biomedical text mining;breast cancer type 1 susceptibility protein measurement;breast carcinoma;choose (action);class;classification;cognitive dimensions of notations;coping behavior;database;dual;entrez;gene nomenclature;hard coding;heart rate variability;high-throughput computing;linguistics;medline;machine learning;motivation;onset (audio);parse tree;parsing;population;putty;rodent nomenclature name;rule-based system;scientific literature;stripes;subgroup;throughput;trees (plant);viz: the computer game;citation;sentence;spelling	K. Bretonnel Cohen;Lawrence Hunter	2008	PLoS Computational Biology	10.1371/journal.pcbi.0040020	text mining;computer science;bioinformatics;speech;artificial intelligence;breast cancer;data mining;language	ML	-2.417373450539331	-64.35439801359867	76549
61778da059e82c2596e7ed06dee28ccba09ae5e3	comprehensive proteomic analysis of bovine spermatozoa of varying fertility rates and identification of biomarkers associated with fertility	acrosome reaction;sperm motility;animals;simulation and modeling;cell motility;mammalian sperm capacitation;reproductive efficiency;systems biology;male;molecular marker;male infertility;physiological cellular and medical topics;embryo quality;chemical fractionation;semen quality;spermatogenesis;spermatozoa;seminal plasma;computational biology bioinformatics;tandem mass spectrometry;chromatin structure assay;male fertility;producer recorded data;cattle;chromatography liquid;birth rate;system biology;proteome analysis;cell communication;algorithms;cell cycle;signaling pathway;fertility;protein interaction;protein interaction mapping;biological markers;proteomics;fertility rate;energy metabolism;dna damage;spectrometry mass electrospray ionization;protein identifications;protein interaction network;genetic selection;bioinformatics;cell cycle proteins	Male infertility is a major problem for mammalian reproduction. However, molecular details including the underlying mechanisms of male fertility are still not known. A thorough understanding of these mechanisms is essential for obtaining consistently high reproductive efficiency and to ensure lower cost and time-loss by breeder. Using high and low fertility bull spermatozoa, here we employed differential detergent fractionation multidimensional protein identification technology (DDF-Mud PIT) and identified 125 putative biomarkers of fertility. We next used quantitative Systems Biology modeling and canonical protein interaction pathways and networks to show that high fertility spermatozoa differ from low fertility spermatozoa in four main ways. Compared to sperm from low fertility bulls, sperm from high fertility bulls have higher expression of proteins involved in: energy metabolism, cell communication, spermatogenesis, and cell motility. Our data also suggests a hypothesis that low fertility sperm DNA integrity may be compromised because cell cycle: G2/M DNA damage checkpoint regulation was most significant signaling pathway identified in low fertility spermatozoa. This is the first comprehensive description of the bovine spermatozoa proteome. Comparative proteomic analysis of high fertility and low fertility bulls, in the context of protein interaction networks identified putative molecular markers associated with high fertility phenotype.	animal for breeding;breeder (cellular automaton);cattle;cell communication;cell cycle checkpoints;detergents;disk data format;fertility agents;gene regulatory network;mammals;modelling biological systems;molecular marker;proteomics;reproduction;signal transduction pathways;spermatogenesis;spermatozoa cell count;systems biology;transaction processing system;cell motility;sperm cell	Divyaswetha Peddinti;Bindu Nanduri;Abdullah Kaya;Jean M. Feugang;Shane C. Burgess;Erdogan Memili	2007	BMC Systems Biology	10.1186/1752-0509-2-19	total fertility rate;tandem mass spectrometry;biology;selection;fertility;cell signaling;bioinformatics;spermatogenesis;cell cycle;dna damage;birth rate;motility;genetics;systems biology;signal transduction	Comp.	7.363489654849217	-64.40592161523793	76653
38b5133dbdd595208bcc53845ffc9fa76b1b5663	nucleic acid enzymes: the fusion of self-assembly and conformational computing	self assembly;t technology;enzyme;information processing;nucleic acid	Macromolecules are the predominant physical substrate supporting information processing in organisms. Two key characteristics— conformational dynamics and self-assembly properties—render macromolecules unique in this context. Both characteristics have been investigated for technical applications. In nature’s information processors selfassembly and conformational switching commonly appear in combination and are typically realised with proteins. At the current state of biotechnology the best candidates for implementing artifical molecular information processing systems that utilise the combination self-assembly and conformational switching are functional nucleic acids. The increasingly realised prevalence of oligonucleotides in intracellular control points towards potential applications. The present paper reviews approaches to integrating the self-assembly and the conformational paradigm with allosterically controlled nucleic acid enzymes. It also introduces a new computational workflow to design functional nucleic acids for information processing. 1 Biomolecular Computing Paradigms With the feature size of solid-state devices approaching nanometer scale molecules are coming increasingly into focus as an alternative material substrate for the implementation of information processing devices. A prominent difference between solid-state materials and macromolecular materials is the large range of properties found in molecules. Biomolecules are mainly composed from only six (C, H, O, N, S, P) out of the 91 naturally occurring chemical elements. The number of possible compounds that could in principle be formed from these six atoms is very large. Even though there are many restrictions on how the atoms can be combined, stable macromolecules comprising hundreds or thousands of atoms can be formed. Macromolecules occurring in organisms are typically formed from a set of building block molecules. These building blocks link through covalent bonds originating at specific atoms, but can be combined in arbitrary order. The twenty commonly occurring amino acids form such a set of building blocks. Linear polymers from up to a few hundred of these amino acids linked in arbitrary sequential order, constitute an important class of biomacromolecules, the proteins. Another set of building blocks found in nature are the nucleotides which combine, again in arbitrary order, to long nucleic acid molecules. The exact linear sequence of the building blocks may have a relatively small influence on the properties of the complete macromolecule, as is the case with the deoxyribonucleic acids (DNA), the carriers of genetic information in the cell. But the exact sequence can also be crucial to the properties of the macromolecule, as is typical for proteins. Both cases have practical advantages. The former is ideally suited for representing information, because the physical properties of the macromolecule are largely independent of its information content. The latter case gives rise to the diverse specificity and large range of material properties that is the basis of the tremendous variety of organisms seen in nature. Two phenomena are key to the interaction and function of macromolecules: self-assembly and conformational dynamics. Both play also an important role for molecular information processing in nature and each serves as a paradigm for man-made molecular computing schemes. Figure 1 illustrates these paradigms. Atoms attached through covalent bonds in a molecule can exert weak, short-	central processing unit;computation;computer memory;control system;dna computing;information processing;interaction;natural computing;programming paradigm;protein structure prediction;self-assembly;self-information;sensitivity and specificity;simulation;substrate (electronics);unconventional computing	Effirul I. Ramlan;Klaus-Peter Zauner	2009	IJUC		biology;biochemistry;bioinformatics;nanotechnology	Comp.	3.7720298310509217	-65.66443430696818	76693
097e60ec4973436fc553905254c9d01afeb9ffff	an integrated pharmacogenomic analysis of doxorubicin response using genotype information on dmet genes	doxorubicin;nci 60;cancer;probabilistic networks;dmet;pharmacogenomics	Genetic variations like single nucleotide polymorphism (SNPs) in drug metabolizing and transporter (DMET) genes can impact their downstream function and behavior, and play a crucial role in the pharmacokinetics of substrate drugs. These polymorphisms can alter drug response in some patients leading to adverse drug response like toxicity, resistance or lack of sensitivity. We have identified variants in a number of genes that are significantly associated with doxorubicin response in an effort to enhance personalized medicine in the clinic.	downstream (software development);personalization	Krithika Bhuvaneshwar;Michael Harris;Thanemozhi Natarajan;Laura Sheahan;Difei Wang;Subha Madhavan;Mahlet G. Tadesse;John F Deeken	2013		10.1145/2506583.2506661	pharmacology;biology;medicine;bioinformatics;pharmacogenomics;genetics;cancer	Comp.	7.656340246797222	-60.69644472832089	76783
22acf992dbfc8d89b7aa85449305519470047275	detecting differentially co-expressed genes for drug target analysis	biological networks	Many novel therapeutics originally aimed at a specific protein have in fact complex target profiles and interact promiscuously with many other proteins and pathways. Discovering new molecular targets and related pharmacodynamic effectors for existing drugs can help us understand mechanisms behind drug resistance, discover potential side effects, and point to target for new drugs. Often, the study of novel targets and receptors starts with building up diverse panel of drug sensitive and resistant cell lines, which is then profiled using high-throughput method such as gene expression microarrays or proteomic arrays. Analysis of profiling data requires statistical methods that move beyond univariate tests of differential expression between sensitive and resistant cell lines. Here, we propose a new approach for analysing differential co-expression, which allows for detecting changes of co-expression pattern in gene pairs, bringing spotlight on the differences in complex dynamic relationships and regulation mechanisms between genes in sensitive and resistant phenotypes. In contrast to existing methods, the proposed approach can deal with confounding factors such as tissue heterogeneity of the cell line panels that leads to presence of clusters and outliers, and together with relatively small number of samples can result in many false discoveries. We applied our method to study differences of gene co-expression patterns between cell lines sensitive and resistant to dasatinib, a novel targeted anticancer drug, and we discovered a closely-linked network of differentially co-expressed genes related to molecular effects of the drug.	dbpedia;gene co-expression network;high-throughput computing;let expression;microarray;proteomics;second generation multiplex plus;sensor;throughput	Xi Gao;Tomasz Arodz	2013		10.1016/j.procs.2013.05.306	bioinformatics	Comp.	4.724063296054944	-56.17783787639509	76798
eb4e5ea126a4f4a2d57ae2aac4db29fed223af0a	statistical evidence for ancestral correlation patterns	repetitive dna;short range correlation;short range correlations;genome evolution;ancestral genomes;genomic signatures;dna sequence;processes of genome evolution	Statistical correlations in DNA sequences are an important source of information for processes of genome evolution. As a special case of such correlations and building up on our previous work, here we study, how short-range correlations in Eukaryotic genomes change under elimination of various classes of repetitive DNA. Our main result is that a residual correlation pattern, common to most mammalian species, emerges under elimination of all repetitive DNA, suggesting features of an ancestral correlation signature. Furthermore, using this general framework, we find classes of repeats, which upon deletion move the correlation pattern towards this residual pattern (simple repeats and SINEs) or away from this residual pattern (LINEs). These findings suggest that the common correlation pattern visible in the mammalian species after repeat elimination can be associated with a common mammalian ancestor.	class;deletion mutation;excretory function;genome;information source;mammals;short interspersed nucleotide elements	Andrea Kuhn;Manuel Dehnert;Werner E. Helm;Marc-Thorsten Hütt	2010	Bio Systems	10.1016/j.biosystems.2010.03.006	biology;dna sequencing;repeated sequence;bioinformatics;genome evolution;genetics	Vision	3.781061872065096	-61.90194863085831	76832
40ed3d022a77e7a9e984be1b9dee0fb2f3d96c79	how landscape heterogeneity frames optimal diffusivity in searching processes	animals;articulo;search strategy;models biological;behavior animal;conservation of natural resources;landscape heterogeneity;landscape structure;low density;computational biology;ecosystem;feeding behavior	Theoretical and empirical investigations of search strategies typically have failed to distinguish the distinct roles played by density versus patchiness of resources. It is well known that motility and diffusivity of organisms often increase in environments with low density of resources, but thus far there has been little progress in understanding the specific role of landscape heterogeneity and disorder on random, non-oriented motility. Here we address the general question of how the landscape heterogeneity affects the efficiency of encounter interactions under global constant density of scarce resources. We unveil the key mechanism coupling the landscape structure with optimal search diffusivity. In particular, our main result leads to an empirically testable prediction: enhanced diffusivity (including superdiffusive searches), with shift in the diffusion exponent, favors the success of target encounters in heterogeneous landscapes.	genetic heterogeneity;interaction;tree traversal	Ernesto P. Raposo;Frederic Bartumeus;Marcos G. E. da Luz;P. J. Ribeiro-Neto;T. A. Souza;Gandhi M. Viswanathan	2011		10.1371/journal.pcbi.1002233	computational biology;biology;ecosystem;bioinformatics;ecology	ML	6.534183337402245	-64.63651411012923	76839
14ce4dfb0cafe0c6d70e1003290dfbbafa094502	multialign: a multiple lc-ms analysis tool for targeted omics analysis	software;peptides;carcinoma hepatocellular;metabolomics;environmental molecular sciences laboratory;proteome;mass spectrometry;computational biology bioinformatics;tandem mass spectrometry;cluster analysis;liver neoplasms;chromatography liquid;algorithms;humans;combinatorial libraries;proteomics;computer appl in life sciences;microarrays;bioinformatics	MultiAlign is a free software tool that aligns multiple liquid chromatography-mass spectrometry datasets to one another by clustering mass and chromatographic elution features across datasets. Applicable to both label-free proteomics and metabolomics comparative analyses, the software can be operated in several modes. For example, clustered features can be matched to a reference database to identify analytes, used to generate abundance profiles, linked to tandem mass spectra based on parent precursor masses, and culled for targeted liquid chromatography-tandem mass spectrometric analysis. MultiAlign is also capable of tandem mass spectral clustering to describe proteome structure and find similarity in subsequent sample runs. MultiAlign was applied to two large proteomics datasets obtained from liquid chromatography-mass spectrometry analyses of environmental samples. Peptides in the datasets for a microbial community that had a known metagenome were identified by matching mass and elution time features to those in an established reference peptide database. Results compared favorably with those obtained using existing tools such as VIPER, but with the added benefit of being able to trace clusters of peptides across conditions to existing tandem mass spectra. MultiAlign was further applied to detect clusters across experimental samples derived from a reactor biomass community for which no metagenome was available. Several clusters were culled for further analysis to explore changes in the community structure. Lastly, MultiAlign was applied to liquid chromatography-mass spectrometry-based datasets obtained from a previously published study of wild type and mitochondrial fatty acid oxidation enzyme knockdown mutants of human hepatocarcinoma to demonstrate its utility for analyzing metabolomics datasets. MultiAlign is an efficient software package for finding similar analytes across multiple liquid chromatography-mass spectrometry feature maps, as demonstrated here for both proteomics and metabolomics experiments. The software is particularly useful for proteomic studies where little or no genomic context is known, such as with environmental proteomics.	bibliographic database;cluster analysis;experiment;fatty acids;limited company;liquid chromatography mass spectrometry;liver carcinoma;map;metabolomics;metagenome;omics;programming tool;proteome;proteomics;reactor (software);reactor device component;scientific publication;spectral clustering;wild type;analyte;fatty acid oxidation;mutant;statistical cluster	Brian L. LaMarche;Kevin L. Crowell;Navdeep Jaitly;Vladislav A. Petyuk;Anuj R. Shah;Ashoka D. Polpitiya;John D. Sandoval;Gary R. Kiebel;Matthew E. Monroe;Stephen J. Callister;Thomas O. Metz;Gordon A. Anderson;Richard D. Smith	2012		10.1186/1471-2105-14-49	tandem mass spectrometry;biology;dna microarray;mass spectrometry;computer science;bioinformatics;metabolomics;proteome;cluster analysis;proteomics	Comp.	0.6401927189857161	-57.97958027844685	76840
b2ba6866cfa44f28d354c5e791cf0dc018714598	genedig: a web application for accessing genomic and bioinformatics knowledge	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;computational biology bioinformatics;uk phd theses thesis;life sciences;algorithms;combinatorial libraries;uk research reports;medical journals;computer appl in life sciences;europe pmc;biomedical research;microarrays;bioinformatics	With the exponential increase and widespread availability of genomic, transcriptomic, and proteomic data, accessing these ‘-omics’ data is becoming increasingly difficult. The current resources for accessing and analyzing these data have been created to perform highly specific functions intended for specialists, and thus typically emphasize functionality over user experience. We have developed a web-based application, GeneDig.org, that allows any general user access to genomic information with ease and efficiency. GeneDig allows for searching and browsing genes and genomes, while a dynamic navigator displays genomic, RNA, and protein information simultaneously for co-navigation. We demonstrate that our application allows more than five times faster and efficient access to genomic information than any currently available methods. We have developed GeneDig as a platform for bioinformatics integration focused on usability as its central design. This platform will introduce genomic navigation to broader audiences while aiding the bioinformatics analyses performed in everyday biology research.	bioinformatics;genome;greater than;omics;proteomics;rna;usability;user experience;web application	Radu M. Suciu;Emir Aydin;Brian E. Chen	2015		10.1186/s12859-015-0497-0	biology;dna microarray;computer science;bioinformatics;data science	Comp.	-2.7389883265032715	-59.04473044808061	76870
ca42fce3d667464c469677b749e57167a24fff25	pantools: representation, storage and exploration of pan-genomic data		MOTIVATION Next-generation sequencing technology is generating a wealth of highly similar genome sequences for many species, paving the way for a transition from single-genome to pan-genome analyses. Accordingly, genomics research is going to switch from reference-centric to pan-genomic approaches. We define the pan-genome as a comprehensive representation of multiple annotated genomes, facilitating analyses on the similarity and divergence of the constituent genomes at the nucleotide, gene and genome structure level. Current pan-genomic approaches do not thoroughly address scalability, functionality and usability.   RESULTS We introduce a generalized De Bruijn graph as a pan-genome representation, as well as an online algorithm to construct it. This representation is stored in a Neo4j graph database, which makes our approach scalable to large eukaryotic genomes. Besides the construction algorithm, our software package, called PanTools, currently provides functionality for annotating pan-genomes, adding sequences, grouping genes, retrieving gene sequences or genomic regions, reconstructing genomes and comparing and querying pan-genomes. We demonstrate the performance of the tool using datasets of 62 E. coli genomes, 93 yeast genomes and 19 Arabidopsis thaliana genomes.   AVAILABILITY AND IMPLEMENTATION The Java implementation of PanTools is publicly available at http://www.bif.wur.nl   CONTACT sandra.smit@wur.nl.	annotation;avian crop;biopolymer sequencing;clade;collections (publication);computational resource;de bruijn graph;genome;genomics;graph - visual representation;graph database;java programming language;neo4j;next-generation network;nucleotides;numerous;online algorithm;phylogenetics;plant physiological phenomena;polyarteritis nodosa;published database;scalability;science;scientific publication;synteny;usability;vergence;anatomical layer	Siavash Sheikhizadeh;Michael Eric Schranz;Mehmet Akdel;Dick de Ridder;Sandra Smit	2016	Bioinformatics	10.1093/bioinformatics/btw455	biology;bioinformatics;theoretical computer science;data mining	Comp.	-1.1654318574569262	-59.14120251049922	76935
9022a51d83ac4a83178ed32872dda814ec6f2c3a	redundant interactions in protein rigid cluster analysis	software;biology computing;game theory;rigidity;rigidity analysis;game analysis;folded proteins;computer model;biomechanics;redundant interactions;kinases;classification;pebble game analysis;shear modulus biology computing biomechanics classification enzymes game theory molecular biophysics;indexes;barnase;computational modeling;cluster analysis;redundancy;enzymes;proteins;kinari web;games;indexation;molecular biophysics;mathematical model;flexibility proteins rigidity;shear modulus;cytochrome c;kinases redundant interactions protein rigid cluster analysis folded proteins weak noncovalent interactions kinari web rigidity analysis pebble game analysis flexibility classification cytochrome c barnase;weak noncovalent interactions;protein rigid cluster analysis;flexibility;proteins redundancy indexes games software mathematical model computational modeling	Folded proteins are held together mainly by weak noncovalent interactions. We propose a method for classifying which of these interactions are critical to maintaining the protein's 3D shape, using information about their redundancy within the rigid clusters of atoms. We have developed KINARI-Web, a server performing rigidity analysis of proteins. It implements pebble game analysis to determine rigid clusters and flexibility information. The method presented here is provided as an additional module. We classify each of the noncovalent interactions as either redundant or critical. An interaction is critical if removing it would cause the rigid cluster to break apart and become flexible, otherwise an interaction is redundant. In addition, we propose a new method for assigning scores to the rigid clusters based on the number of redundant and critical interactions in the cluster. We present data on the redundancy of the rigid clusters of cytochrome c, barnase, and a dataset of kinases.	cluster analysis;computer cluster;interaction;pebble game;protein data bank;redundancy (engineering);server (computing)	Naomi Fox;Ileana Streinu	2011	2011 IEEE 1st International Conference on Computational Advances in Bio and Medical Sciences (ICCABS)	10.1109/ICCABS.2011.5729952	database index;biology;games;game theory;biochemistry;enzyme;simulation;biological classification;computer science;bioinformatics;cytochrome c;biomechanics;shear modulus;mathematical model;cluster analysis;redundancy;computational model;rigidity;kinase;molecular biophysics	Visualization	8.053324774677094	-56.73622422178664	76974
ac50edf3f2e2344b9f8e95c6f70b7a29e999215a	critically assessing the predictive power of qsar models for human liver microsomal stability		To lower the possibility of late-stage failures in the drug development process, an up-front assessment of absorption, distribution, metabolism, elimination, and toxicity is commonly implemented through a battery of in silico and in vitro assays. As in vitro data is accumulated, in silico quantitative structure-activity relationship (QSAR) models can be trained and used to assess compounds even before they are synthesized. Even though it is generally recognized that QSAR model performance deteriorates over time, rigorous independent studies of model performance deterioration is typically hindered by the lack of publicly available large data sets of structurally diverse compounds. Here, we investigated predictive properties of QSAR models derived from an assembly of publicly available human liver microsomal (HLM) stability data using variable nearest neighbor (v-NN) and random forest (RF) methods. In particular, we evaluated the degree of time-dependent model performance deterioration. Our results show that when evaluated by 10-fold cross-validation with all available HLM data randomly distributed among 10 equal-sized validation groups, we achieved high-quality model performance from both machine-learning methods. However, when we developed HLM models based on when the data appeared and tried to predict data published later, we found that neither method produced predictive models and that their applicability was dramatically reduced. On the other hand, when a small percentage of randomly selected compounds from data published later were included in the training set, performance of both machine-learning methods improved significantly. The implication is that 1) QSAR model quality should be analyzed in a time-dependent manner to assess their true predictive power and 2) it is imperative to retrain models with any up-to-date experimental data to ensure maximum applicability.	adverse reaction to drug;cross-validation (statistics);excretory function;imperative programming;liver diseases;machine learning;predictive modelling;quantitative structure-activity relationship;radio frequency;random forest;randomness;scientific publication;single linkage cluster analysis;test set;drug development;hierarchical linear modeling;triangulation	Ruifeng Liu;Patric Schyman;Anders Wallqvist	2015	Journal of chemical information and modeling	10.1021/acs.jcim.5b00255	toxicology;bioinformatics	AI	8.13353537994092	-53.62547907414321	77017
8f0eaa001bd96d340f8cc2f595b3fe3d00f6ead1	supersecondary structure prediction using chou's pseudo amino acid composition	supersecondary structures;support vector machines;diversity measure;pseudo amino acid composition;structure prediction;quadratic discriminant analysis	Supersecondary structures (SSSs) are the building blocks of protein 3D structures. Accurate prediction of SSSs can be one important step toward building a tertiary structure from the specified secondary structure. How to improve the accuracy of prediction of SSSs by effectively incorporating the sequence order effects is an important and challenging problem. Based on a different form of Chou's pseudo amino acid composition, a novel approach for feature representation of SSSs is proposed. Amino acid basic compositions, dipeptide components, and amino acid composition distribution are incorporated to represent the compositional features of proteins. Each supersecondary structural motif is characterized as a vector of 36 dimensions. In addition, we propose a novel prediction system by using SVM and IDQD algorithm as classifiers. Our method is trained and tested on ArchDB40 dataset containing 3088 proteins. The highest overall accuracy for the training dataset and the independent testing dataset are 77.7 and 69.4%, respectively.		Dongsheng Zou;Zhongshi He;Jingyuan He;Yuxian Xia	2011	Journal of computational chemistry	10.1002/jcc.21616	support vector machine;quadratic classifier;mathematics	Comp.	9.92409412924101	-55.704474840025014	77032
29d0fcd66cd4e80f7bf32637000659e874938495	gatb: genome assembly & analysis tool box	software;genomics;computer graphics;high throughput nucleotide sequencing;biostatistics;genome human;algorithms;humans	MOTIVATION Efficient and fast next-generation sequencing (NGS) algorithms are essential to analyze the terabytes of data generated by the NGS machines. A serious bottleneck can be the design of such algorithms, as they require sophisticated data structures and advanced hardware implementation.   RESULTS We propose an open-source library dedicated to genome assembly and analysis to fasten the process of developing efficient software. The library is based on a recent optimized de-Bruijn graph implementation allowing complex genomes to be processed on desktop computers using fast algorithms with low memory footprints.   AVAILABILITY AND IMPLEMENTATION The GATB library is written in C++ and is available at the following Web site http://gatb.inria.fr under the A-GPL license.   CONTACT lavenier@irisa.fr   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	algorithm;bioinformatics;bioinformatics;biopolymer sequencing;c++;communications satellite;computers;data structure;de bruijn graph;desktop computer;gatb gene;genome assembly sequence;graph - visual representation;massively-parallel sequencing;open-source software;terabyte;time complexity	Erwan Drezen;Guillaume Rizk;Rayan Chikhi;Charles Deltel;Claire Lemaitre;Pierre Peterlongo;Dominique Lavenier	2014		10.1093/bioinformatics/btu406	biology;genomics;computer science;bioinformatics;theoretical computer science;computer graphics;biostatistics;world wide web	Comp.	-1.6277309364133103	-54.36320874170218	77060
f68c88ba04c4a97e9184011a8a5b1814a6939749	prediction of mhc class ii binding affinity using smm-align, a novel stabilization matrix alignment method	hla dr antigens;epitopes;histocompatibility antigens class ii;prediction method;animals;peptides;mice;alleles;t helper cell;gibbs sampler;design and development;amino acid;amino acid sequence;inhibitory concentration 50;mhc class ii;databases genetic;computational biology bioinformatics;monte carlo method;antigen presenting cell;reproducibility of results;predictive value of tests;protein binding;algorithms;humans;sequence alignment;cross validation;binding affinity;combinatorial libraries;computer appl in life sciences;set cover;amino acid motifs;sequence analysis protein;microarrays;bioinformatics	Antigen presenting cells (APCs) sample the extra cellular space and present peptides from here to T helper cells, which can be activated if the peptides are of foreign origin. The peptides are presented on the surface of the cells in complex with major histocompatibility class II (MHC II) molecules. Identification of peptides that bind MHC II molecules is thus a key step in rational vaccine design and developing methods for accurate prediction of the peptide:MHC interactions play a central role in epitope discovery. The MHC class II binding groove is open at both ends making the correct alignment of a peptide in the binding groove a crucial part of identifying the core of an MHC class II binding motif. Here, we present a novel stabilization matrix alignment method, SMM-align, that allows for direct prediction of peptide:MHC binding affinities. The predictive performance of the method is validated on a large MHC class II benchmark data set covering 14 HLA-DR (human MHC) and three mouse H2-IA alleles. The predictive performance of the SMM-align method was demonstrated to be superior to that of the Gibbs sampler, TEPITOPE, SVRMHC, and MHCpred methods. Cross validation between peptide data set obtained from different sources demonstrated that direct incorporation of peptide length potentially results in over-fitting of the binding prediction method. Focusing on amino terminal peptide flanking residues (PFR), we demonstrate a consistent gain in predictive performance by favoring binding registers with a minimum PFR length of two amino acids. Visualizing the binding motif as obtained by the SMM-align and TEPITOPE methods highlights a series of fundamental discrepancies between the two predicted motifs. For the DRB1*1302 allele for instance, the TEPITOPE method favors basic amino acids at most anchor positions, whereas the SMM-align method identifies a preference for hydrophobic or neutral amino acids at the anchors. The SMM-align method was shown to outperform other state of the art MHC class II prediction methods. The method predicts quantitative peptide:MHC binding affinity values, making it ideally suited for rational epitope discovery. The method has been trained and evaluated on the, to our knowledge, largest benchmark data set publicly available and covers the nine HLA-DR supertypes suggested as well as three mouse H2-IA allele. Both the peptide benchmark data set, and SMM-align prediction method (NetMHCII) are made publicly available.	align (company);alignment;amino acids;amino acids, basic;amino acids, neutral;antigen-presenting cells;benchmark (computing);cross reactions;flank (surface region);gibbs sampling;hla-dr antigens;histocompatibility antigens class ii;interaction;knowledge discovery metamodel;major histocompatibility complex;model of hierarchical complexity;motif;myosin heavy chains;overfitting;peptide phi;peptide sequence;processor affinity;sampling (signal processing);cell surface furrow	Morten Nielsen;Claus Lundegaard;Ole Lund	2007	BMC Bioinformatics	10.1186/1471-2105-8-238	allele;biology;plasma protein binding;antigen-presenting cell;amino acid;dna microarray;gibbs sampling;mhc restriction;computer science;bioinformatics;predictive value of tests;cd74;sequence alignment;set cover problem;ligand;peptide sequence;immunology;epitope;genetics;cross-validation;monte carlo method	Comp.	9.72891124834912	-57.99996115357222	77084
0e32461f19ae1ebc513af2d267591def64ab1094	alphavirus protease inhibitors from natural sources: a homology modeling and molecular docking investigation	semliki forest virus;o nyong nyong virus;eastern equine encephalitis virus;nsp2 protease;sindbis virus;ross river virus;venezuelan equine encephalitis virus;western equine encephalitis virus;chikungunya virus	Alphaviruses such as Chikungunya virus (CHIKV), O'Nyong-Nyong virus (ONNV), Ross River virus (RRV), Eastern equine encephalitis virus (EEEV), Venezuelan equine encephalitis virus (VEEV), and Western equine encephalitis virus (WEEV), are mosquito-transmitted viruses that can cause fevers, rash, and rheumatic diseases (CHIKV, ONNV, RRV) or potentially fatal encephalitis (EEEV, VEEV, WEEV) in humans. These diseases are considered neglected tropical diseases for which there are no current antiviral therapies or vaccines available. The alphavirus non-structural protein 2 (nsP2) contains a papain-like protease, which is considered to be a promising target for antiviral drug discovery. In this work, molecular docking analyses have been carried out on a library of 2174 plant-derived natural products (290 alkaloids, 664 terpenoids, 1060 polyphenolics, and 160 miscellaneous phytochemicals) with the nsP2 proteases of CHIKV, ONNV, RRV, EEEV, VEEV, WEEV, as well as Aura virus (AURV), Barmah Forest Virus (BFV), Semliki Forest virus (SFV), and Sindbis virus (SINV) in order to identity structural scaffolds for inhibitor design or discovery. Of the 2174 phytochemicals examined, a total of 127 showed promising docking affinities and poses to one or more of the nsP2 proteases, and this knowledge can be used to guide experimental investigation of potential inhibitors.	alphavirus;antiviral agents;aura virus;barmah forest virus;boat dock;chikungunya fever;chikungunya virus;culicidae;docking (molecular);drug discovery;encephalitis virus, eastern equine;encephalitis virus, western equine;encephalitis viruses;encephalomyelitis, eastern equine;encephalomyelitis, equine;encephalomyelitis, western equine;endopeptidases;exanthema;homology (biology);homology modeling;kaspersky anti-virus;natural products;o'nyong-nyong virus;papain;parainfluenza virus 2, human;phytochemicals;rheumatism;ross river virus;semliki forest virus;simple file verification;sindbis virus;terpenes;tropical disease;venezuelan equine encephalitis virus;disease transmission;non-t, non-b childhood acute lymphoblastic leukemia	Kendall G. Byler;Jasmine Collins;Ifedayo Victor Ogungbe;William N. Setzer	2016	Computational biology and chemistry	10.1016/j.compbiolchem.2016.06.005	biology;virology;veterinary virology;immunology;microbiology;recombinant virus	Comp.	8.654931214900964	-61.588433882393055	77265
4c94a7dac995cc39274bae7ced9c463ad637b03c	learning hmms for nucleotide sequences from amino acid alignments	artigo	Profile hidden Markov models (profile HMMs) are known to efficiently predict whether an amino acid (AA) sequence belongs to a specific protein family. Profile HMMs can also be used to search for protein domains in genome sequences. In this case, HMMs are typically learned from AA sequences and then used to search on the six-frame translation of nucleotide (NT) sequences. However, this approach demands additional processing of the original data and search results. Here, we propose an alternative and more direct method which converts an AA alignment into an NT one, after which an NT-based HMM is trained to be applied directly on a genome.	alignment;amino acids;direct method in the calculus of variations;genome;hidden markov model;introns;markov chain;nucleotides;phosphoric monoester hydrolases;protein domain;protein family;pseudo amino acid composition	Carlos Fischer;Claudia M. A. Carareto;Renato A. C. dos Santos;Ricardo Cerri;Eduardo P. Costa;Leander Schietgat;Celine Vens	2015	Bioinformatics	10.1093/bioinformatics/btv054	biology	Comp.	-2.6407318428594206	-55.53036999236818	77373
5a95c5ea2b7d21661f16c9e95b59e8a3459d2830	outcome prediction based on microarray analysis: a critical perspective on methods	genes;performance measure;microarray data;performance evaluation;information extraction;databases genetic;statistical significance;computational biology bioinformatics;confidence interval;microarray analysis;decision support system;hybrid method;least square;algorithms;feature selection;cross validation;support vector machine;neoplasms;methodology;combinatorial libraries;computational biology;gene selection;computer appl in life sciences;prediction;gene expression profiling;oligonucleotide array sequence analysis;evaluation framework;microarrays;bioinformatics	Information extraction from microarrays has not yet been widely used in diagnostic or prognostic decision-support systems, due to the diversity of results produced by the available techniques, their instability on different data sets and the inability to relate statistical significance with biological relevance. Thus, there is an urgent need to address the statistical framework of microarray analysis and identify its drawbacks and limitations, which will enable us to thoroughly compare methodologies under the same experimental set-up and associate results with confidence intervals meaningful to clinicians. In this study we consider gene-selection algorithms with the aim to reveal inefficiencies in performance evaluation and address aspects that can reduce uncertainty in algorithmic validation. A computational study is performed related to the performance of several gene selection methodologies on publicly available microarray data. Three basic types of experimental scenarios are evaluated, i.e. the independent test-set and the 10-fold cross-validation (CV) using maximum and average performance measures. Feature selection methods behave differently under different validation strategies. The performance results from CV do not mach well those from the independent test-set, except for the support vector machines (SVM) and the least squares SVM methods. However, these wrapper methods achieve variable (often low) performance, whereas the hybrid methods attain consistently higher accuracies. The use of an independent test-set within CV is important for the evaluation of the predictive power of algorithms. The optimal size of the selected gene-set also appears to be dependent on the evaluation scheme. The consistency of selected genes over variation of the training-set is another aspect important in reducing uncertainty in the evaluation of the derived gene signature. In all cases the presence of outlier samples can seriously affect algorithmic performance. Multiple parameters can influence the selection of a gene-signature and its predictive power, thus possible biases in validation methods must always be accounted for. This paper illustrates that independent test-set evaluation reduces the bias of CV, and case-specific measures reveal stability characteristics of the gene-signature over changes of the training set. Moreover, frequency measures on gene selection address the algorithmic consistency in selecting the same gene signature under different training conditions. These issues contribute to the development of an objective evaluation framework and aid the derivation of statistically consistent gene signatures that could eventually be correlated with biological relevance. The benefits of the proposed framework are supported by the evaluation results and methodological comparisons performed for several gene-selection algorithms on three publicly available datasets.	algorithm;antivirus software;best, worst and average case;confidence intervals;crisscross heart;cross reactions;cross-validation (statistics);feature selection;forecast of outcome;information extraction;instability;least squares;microarray;p-value;performance evaluation;relevance;support system;support vector machine;test set;benefit	Michalis E. Zervakis;Michalis E. Blazadonakis;Georgia Tsiliki;Vasiliki Danilatou;Manolis Tsiknakis;Dimitris Kafetzopoulos	2008	BMC Bioinformatics	10.1186/1471-2105-10-53	biology;microarray analysis techniques;decision support system;computer science;bioinformatics;data science;data mining;feature selection;information extraction	Web+IR	6.706828291082733	-52.57400158555011	77566
53708bc3516b6565f33f451144660aaf21b01f65	multistage sequencing by hybridization	sequencing by hybridization	The sequencing of DNA is an important and difficult problem. Many interesting algorithms combine various technologies in an attempt to sequence long regions of DNA. One such algorithm is sequencing by hybridization (SBH). We briefly review SBH and mention the drawbacks that prevent it from being used in practice. We then present a theoretical algorithm that uniquely determines a sequence of length n through hybridization experiments that require the examination of only O(n2log(n)) subsequences. The key idea is to double subsequence length in each iteration of the algorithm. There are various problems associated with transforming the theoretical algorithm into a practical biological procedure. However, the general strategy of increasing subsequence length may be used to develop algorithms that are feasible given the current state of technology. Combining this strategy with a computer processing phase leads to a novel method of extending the resolving power of standard SBH techniques.	biopolymer sequencing;crossbreeding;experiment;iteration;multistage amplifier;nucleic acid hybridization;subcortical band heterotopia;algorithm	Semyon Kruglyak	1998	Journal of computational biology : a journal of computational molecular cell biology	10.1089/cmb.1998.5.165	sequencing by hybridization;biology;computer science;bioinformatics;genetics;algorithm	Comp.	-0.2785998477216749	-53.47224503005915	77620
0ca144cb2e8e804c529b9645332493ed062b0ca9	sequence and base modifications of two phenylalanine-trnas from thermus thermophilus hb8	dna;rna transfer phe;escherichia coli;bacterie;phenylalanine;secuencia nucleotido;rna transfert;nucleotide sequence;sequence nucleotide;thermus thermophilus;sequence homology nucleic acid;fenilalanina;nucleic acid conformation;arn transferencia;molecular sequence data;bacteria;base sequence;t rna	Bulk tRNAs were prepared (1) from Thermus themophilus HB8 grown at 70°C, and purified by chromatography on BD Cellulose, Sepharose 4B, and RPC-5 (2-4). The phenylalanineaccepting tRNAs were identified by amino-acylation. Nucleotide sequences were determined chemically, by mobility shift, and by a post-labeling method (summarized in 5). HPLC (6) was used for the quantification of modified nucleosides and identification of A4 and A5 (for abbreviations of modified bases, see 7).	abbreviations;base;blu-ray;cellulose;high pressure liquid chromatography procedure;nucleosides;phenylalanine;quantitation;thermus thermophilus (bacterium)	Ulf Grawunder;Astrid Schon;Mathias Sprinzl	1992	Nucleic acids research	10.1093/nar/20.1.137	biology;biochemistry;transfer rna;bacteria;nucleic acid sequence;bioinformatics;escherichia coli;genetics;dna	Crypto	3.584946307843159	-63.843897504914246	77651
d10ff712eeff7e1169aff81f84095f9bc8e28fc1	pmsga: a fast dna fragment assembler	dna fragmentation	The DNA fragment assembly is an essential step in DNA sequencing projects. Since DNA sequencers output fragments, the original genome must be reconstructed from these small reads. In this paper, a new fragment assembly algorithm, Pattern Matching based String Graph Assembler (PMSGA), is presented. The algorithm uses multipattern matching to detect overlaps and a minimum cost flow algorithm to detect repeats. Special care was taken to reduce the algorithm’s run time without compromising the quality of the assembly. PMSGA was compared with well-known fragment assemblers. The algorithm is faster than other assemblers. PMSGA produced high quality assemblies with prokaryotic data sets. The results for eukaryotic data are comparable with other assemblers.	academy;algorithm;application binary interface;assembly language;automatic parallelization;display resolution;euler;job control (unix);lurker;maximum flow problem;minimum-cost flow problem;overlap–add method;pattern matching;phrap;run time (program lifecycle phase);string graph	Juho Mäkinen;Jorma Tarhio;Sami Khuri	2010			dna;machine learning;string graph;artificial intelligence;dna sequencer;pattern matching;genome;assemblers;minimum-cost flow problem;algorithm;dna sequencing;computer science	Comp.	-1.1561481515661263	-52.643258110620245	77713
cf6d086cb7f04d44bd461fb60ff7e12e16e5a0ae	an hmm approach to identify components that influence phenotypes	hidden markov models biological system modeling vectors mathematical model biochemistry biological systems trajectory;learning artificial intelligence biology computing genetics hidden markov models;photosynthetic rate hmm approach phenotypes biological systems gene enzyme metabolic pathway levels higher level biological phenomena photosynthetic pathway biological organization decomposition algorithm machine learning tools sensitivity analysis c3 plants	Mathematical models of biological systems have traditionally described processes that occur at the gene, enzyme, and metabolic pathway levels. We are often unable to relate these low-level models to higher-level biological phenomena. For example, models that describe the photosynthetic pathway do not explicitly relate the components to changes in photosynthetic rate. Thus, there is a need for developing methods that can link low levels of biological organization and higher-level phenotypes. We present an approach to solve this bottleneck that combines 1) a decomposition algorithm, 2) machine learning tools and 3) sensitivity analysis. With this approach, we quantified the influence of key components and functional modules on specific phenotypes, such as the photosynthetic pathway in C3 plants. Our algorithm was able to predict the relationship between specific components and the photosynthetic rate, where these results were consistent with previous experimental data. With these results we demonstrate that computational methods can be used to identify key modules and/or components that influence a measurable output of a biological system.	algorithm;biological organisation;biological system;black box;computation;experiment;gene regulatory network;hidden markov model;high- and low-level;machine learning;mathematical model	Maria A. de Luis Balaguer;Cranos M. Williams	2014	2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)	10.1109/SMC.2014.6974094	bioinformatics;machine learning	Comp.	6.30386943987515	-59.59862399763588	77988
5395e08afb1b0d55b5117938cb049579db682ef1	data driven polypharmacological drug design for lung cancer: analyses for targeting alk, met, and egfr	alk;egfr;lung cancer;met;protein flexibility;protein kinase inhibitor;structure based drug design	Drug design of protein kinase inhibitors is now greatly enabled by thousands of publicly available X-ray structures, extensive ligand binding data, and optimized scaffolds coming off patent. The extensive data begin to enable design against a spectrum of targets (polypharmacology); however, the data also reveal heterogeneities of structure, subtleties of chemical interactions, and apparent inconsistencies between diverse data types. As a result, incorporation of all relevant data requires expert choices to combine computational and informatics methods, along with human insight. Here we consider polypharmacological targeting of protein kinases ALK, MET, and EGFR (and its drug resistant mutant T790M) in non small cell lung cancer as an example. Both EGFR and ALK represent sources of primary oncogenic lesions, while drug resistance arises from MET amplification and EGFR mutation. A drug which inhibits these targets will expand relevant patient populations and forestall drug resistance. Crizotinib co-targets ALK and MET. Analysis of the crystal structures reveals few shared interaction types, highlighting proton-arene and key CH-O hydrogen bonding interactions. These are not typically encoded into molecular mechanics force fields. Cheminformatics analyses of binding data show EGFR to be dissimilar to ALK and MET, but its structure shows how it may be co-targeted with the addition of a covalent trap. This suggests a strategy for the design of a focussed chemical library based on a pan-kinome scaffold. Tests of model compounds show these to be compatible with the goal of ALK, MET, and EGFR polypharmacology.	alk gene;alk protein, human;arene;chemical library;choice behavior;computation;covalent interaction;crystal structure;drug design;force field (chemistry);hydrogen bonding;informatics (discipline);ligands;molecular mechanics;mutation;non-small cell lung carcinoma;patients;population;protein kinases;proton-phosphate symporters;protons;pyschological bonding;small cell carcinoma of lung;cellular targeting;cheminformatics;crizotinib	Dilip Narayanan;Osman A. B. S. M. Gani;Franz X. E. Gruber;Richard Alan Engh	2017		10.1186/s13321-017-0229-8	chemical library;lung cancer;bioinformatics;protein kinase inhibitor;t790m;cheminformatics;drug resistance;ligand (biochemistry);crizotinib;biology	Comp.	1.7123436866455555	-60.58639052531532	78057
5cd4af5cf98c91b53ba19ab7cebbbbc9303f5140	gampms: genetic algorithm managed peptide mutant screening	high throughput virtual screening;bepress selected works;high throughput virtual screening peptide mutation molecular docking genetic algorithm heuristic screen;genetic algorithm;peptide mutation;heuristic screen;molecular docking	The prominence of endogenous peptide ligands targeted to receptors makes peptides with the desired binding activity good molecular scaffolds for drug development. Minor modifications to a peptide's primary sequence can significantly alter its binding properties with a receptor, and screening collections of peptide mutants is a useful technique for probing the receptor-ligand binding domain. Unfortunately, the combinatorial growth of such collections can limit the number of mutations which can be explored using structure-based molecular docking techniques. Genetic algorithm managed peptide mutant screening (GAMPMS) uses a genetic algorithm to conduct a heuristic search of the peptide's mutation space for peptides with optimal binding activity, significantly reducing the computational requirements of the virtual screening. The GAMPMS procedure was implemented and used to explore the binding domain of the nicotinic acetylcholine receptor (nAChR) α3β2-isoform with a library of 64,000 α-conotoxin (α-CTx) MII peptide mutants. To assess GAMPMS's performance, it was compared with a virtual screening procedure that used AutoDock to predict the binding affinity of each of the α-CTx MII peptide mutants with the α3β2-nAChR. The GAMPMS implementation performed AutoDock simulations for as few as 1140 of the 64,000 α-CTx MII peptide mutants and could consistently identify a set of 10 peptides with an aggregated binding energy that was at least 98% of the aggregated binding energy of the 10 top peptides from the exhaustive AutoDock screening.	acetylcholine;autodock;cholinergic receptors;collections (publication);conotoxin;docking (molecular);genetic algorithm;heuristic;heuristics;ligands;mii;mutation;nicotinic receptors;processor affinity;requirement;simulation;teenage mutant ninja turtles;two-hybrid screening;virtual screening;drug development	Thomas Long;Owen M. McDougal;Timothy L. Andersen	2015	Journal of computational chemistry	10.1002/jcc.23928	genetic algorithm;chemistry;docking;combinatorial chemistry;computational chemistry	Comp.	9.848340665715885	-59.859793706989066	78101
f6cac1c427845e189d2f4a5c12aed9852e9ee511	exploiting sample variability to enhance multivariate analysis of microarray data	gene expression profile;microarray data;sensitivity and specificity;variabilidad;analyse multivariable;sample size;data interpretation statistical;multivariate analysis;methods gene expression profiling;analisis datos;genetics genetic variation;bioinformatique;gene expression data;microreseau;gene expression;data analysis;models genetic;microarreglo;reproducibility of results;echantillon;models statistical;algorithms;analisis multivariable;analyse donnee;microarray;sample;methods oligonucleotide array sequence analysis;bioinformatica;variability;variabilite;article;computer simulation;muestra;bioinformatics	MOTIVATION Biological and technical variability is intrinsic in any microarray experiment. While most approaches aim to account for this variability, they do not actively exploit it. Here, we consider a novel approach that uses the variability between arrays to provide an extra source of information that can enhance gene expression analyses.   RESULTS We develop a method that uses sample similarity to incorporate sample variability into the analysis of gene expression profiles. This allows each pairwise correlation calculation to borrow information from all the data in the experiment. Results on synthetic and human cancer microarray datasets show that the inclusion of this information leads to a significant increase in the ability to identify previously characterized relationships and a reduction in false discovery rate, when compared to a standard analysis using Pearson correlation. The information carried by the variability between arrays can be exploited to significantly improve the analysis of gene expression data.   AVAILABILITY Matlab script files are available from the author.   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	bioinformatics;gene expression;heart rate variability;information source;matlab;microarray;spatial variability;synthetic data	Carla S. Möller-Levet;Catharine M. West;Crispin J. Miller	2007	Bioinformatics	10.1093/bioinformatics/btm441	computer simulation;sample size determination;biology;microarray analysis techniques;gene chip analysis;gene expression;sample;computer science;bioinformatics;microarray;data mining;multivariate analysis;data analysis;statistics	Comp.	5.000895029300004	-52.39521596830302	78131
790a2e964afa07b58abe174b6e6ec0e2648f42fd	binding of dna-bending non-histone proteins destabilizes regular 30-nm chromatin structure	biochemical simulations;dna binding proteins;histones;protein structure;nucleosomes;chromatin;dna structure;protein interactions	Why most of the in vivo experiments do not find the 30-nm chromatin fiber, well studied in vitro, is a puzzle. Two basic physical inputs that are crucial for understanding the structure of the 30-nm fiber are the stiffness of the linker DNA and the relative orientations of the DNA entering/exiting nucleosomes. Based on these inputs we simulate chromatin structure and show that the presence of non-histone proteins, which bind and locally bend linker DNA, destroys any regular higher order structures (e.g., zig-zag). Accounting for the bending geometry of proteins like nhp6 and HMG-B, our theory predicts phase-diagram for the chromatin structure as a function of DNA-bending non-histone protein density and mean linker DNA length. For a wide range of linker lengths, we show that as we vary one parameter, that is, the fraction of bent linker region due to non-histone proteins, the steady-state structure will show a transition from zig-zag to an irregular structure-a structure that is reminiscent of what is observed in experiments recently. Our theory can explain the recent in vivo observation of irregular chromatin having co-existence of finite fraction of the next-neighbor (i + 2) and neighbor (i + 1) nucleosome interactions.	30 nm chromatin fiber;bending - changing basic body position;chromatin structure;experiment;hmga1a protein;histones;interaction;nucleosomes;phase diagram;population parameter;simulation;steady state;tissue fiber;video-in video-out	Gaurav Bajpai;Ishutesh Jain;Mandar M. Inamdar;Dibyendu Das;Ranjith Padinhateeri	2017		10.1371/journal.pcbi.1005365	protein–protein interaction;biology;protein structure;dna-binding protein;molecular biology;chromatin;hmg-box;linker dna;solenoid;bioinformatics;histone;histone code;nucleosome;genetics;dna	Comp.	8.45479189257238	-64.51555506572592	78210
678efdaa6549fd76ed63964595f6042f9666a264	gene expression by software mechanisms	pipe;signals;gene expression;operating system;molecular biology;signal;process communication;molecular interactions;modules;cell biology;operating systems	This paper describes the molecular interactions and coordination of cell processes using computer operating system concepts related to synchronization and communication. We argue that in molecular biology, the genes and their chromatin context provide communication and interaction with various cell processes in a similar way to that in which computer processes synchronize and communicate with each other.		Gabriel Ciobanu;Bogdan Tanasa	2002	Fundam. Inform.		real-time computing;gene expression;computer science;bioinformatics;modular programming;pipe;signal	Logic	2.9522480427924367	-66.13590104090406	78217
8f84f24022fdd1fd6fa0a55fe9edba0c55f922db	pdb_isl: an intermediate sequence library for protein structure assignment	sequence comparison;homology search;hidden markov model;large scale structure;search method;protein structure;structural genomics;homology;pdb_isl;error rate;structure assignment;psi blast	For large scale structural assignment to sequences, as in computational structural genomics, a fast yet sensitive homology search procedure is essential. A new approach using intermediate sequences was tested as a shortcut to iterative multiple sequence search methods such as PSI-BLAST and hidden Markov models. A library containing potential intermediate sequences for proteins of known structure (PDB_ISL) was constructed. The sequences in the library were collected from a large sequence database using the sequences of the domains of proteins of known structure as the query sequences and the program PSI-BLAST. Sequences of proteins of unknown structure can be matched to distantly related proteins of known structure by using any pairwise sequence comparison methods to find homologues in PDB_ISL. Searches of PDB_ISL were calibrated, and the number of correct matches found at a given error rate was the same as that found by PSI_BLAST. The advantage of this library is that it uses pairwise sequence comparison methods, such as FASTA or BLAST2, and can, therefore, be searched easily and, in many cases, much more quickly than an iterative multiple sequence comparison method. The procedure is roughly twenty times faster than PSI-BLAST for small genomes and several hundred times for large genomes such as C. elegans. Sequences can be submitted to the PDB_ISL servers at http://stash.mrc-lmb.cam.ac.uk/PDB_ISL/ ftp://ftp.ebi.ac.uk/pub/databases/pdb_isl/	blast;fasta;hidden markov model;homology (biology);iterative method;keyboard shortcut;markov chain;sequence database	Sarah A. Teichmann;Cyrus Chothia;George M. Church;Jong Park	2000		10.1145/332306.332566	structural genomics;biology;protein structure;homology;word error rate;computer science;bioinformatics;data mining;world wide web;hidden markov model	Comp.	-2.2320286329887065	-54.09733625806288	78346
12b4389ae05b0f0ea9edddd88907033382b8c181	identification of olfactory receptors using a parametric model	dna walk;fractal dimension;olfactory receptors;haar wavelet coefficients;wavelet coefficients	Human nose can smell number of chemicals having distinct odors. These odor molecules are detected by the olfactory receptors. Olfactory Receptors (ORs) have a large family of mouse, rat, human, chimpanzee, earthworm, dog, etc. As there are number of families of distinct species, the mouse OR genes are identified to work upon, because restricted amount of work has been done using this species. In this paper, OR family of mouse and human has been studied by using quantification of Barcode matrix, DNA walk and Haar wavelet coefficients. These parameters have been studied for the proper understanding of their DNA sequences, to know the difference between intricate sequences of DNA and to know the hidden symmetries between the DNA sequences. Subsequently, clustering method is applied after knowing the quantitative results. Then a proper study has been done for the clustering results to examine the mouse OR. Using this proposed model, a probable justification or deterministic nullification can be given that whether a given sequence of DNA string composed of nucleotides is a probable mouse OR or not.	barcode;cluster analysis;coefficient;haar wavelet;parametric model;time complexity	Pranay Sakhare;Rajneesh Rani;Ranjeet Kumar Rout	2016	2016 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2016.7732165	bioinformatics;mathematics;fractal dimension	ML	7.764418400537225	-57.09459106835032	78874
a819b6ea2c5804c8a126f2223ddec5d0df717e05	a novel approach for structured consensus motif inference under specificity and quorum constraints	transcription factor binding site;dna sequence;search space	We address the issue of structured motif inference. This problem is stated as follows: given a set of n DNA sequences and a quorum q (%), find the optimal structured consensus motif described as gaps alternating with specific regions and shared by at least q × n sequences. Our proposal is in the domain of metaheuristics: it runs solutions to convergence through a cooperation between a sampling strategy of the search space and a quick detection of local similarities in small sequence samples. The contributions of this paper are: (1) the design of a stochastic method whose genuine novelty rests on driving the search with a threshold frequency f discrimining between specific regions and gaps; (2) the original way for justifying the operations especially designed; (3) the implementation of a mining tool well adapted to biologists’exigencies: few input parameters are required (quorum q, minimal threshold frequency f , maximal gap length g). Our approach proves efficient on simulated data, promoter sites in Dicot plants and transcription factor binding sites in E. coli genome. Our algorithm, Kaos, compares favorably with MEME and STARS in terms of accuracy.	algorithm;maximal set;meme;metaheuristic;motif;photoelectric effect;sampling (signal processing);sensitivity and specificity;transcription (software)	Christine Sinoquet	2006			dna binding site;motif (music);novelty;artificial intelligence;machine learning;metaheuristic;inference;kaos;convergence (routing);biology;bioinformatics	Comp.	1.0670514526236758	-52.70196261255179	78898
a03384b4b47c00a1425b08e4793d95c064bb6d32	mpidb: the microbial protein interaction database	proteine;interaction moleculaire;database management systems;molecular interaction;database;base dato;bioinformatique;models biological;binding sites;models chemical;models molecular;interaccion molecular;internet;base de donnees;protein binding;proteina;bioinformatica;user computer interface;protein interaction;protein interaction mapping;protein;bacterial proteins;databases protein;bioinformatics	SUMMARY The microbial protein interaction database (MPIDB) aims to collect and provide all known physical microbial interactions. Currently, 22,530 experimentally determined interactions among proteins of 191 bacterial species/strains can be browsed and downloaded. These microbial interactions have been manually curated from the literature or imported from other databases (IntAct, DIP, BIND, MINT) and are linked to 24,060 experimental evidences (PubMed ID, PSI-MI methods). In contrast to these databases, interactions in MPIDB are further supported by 8150 additional evidences based on interaction conservation, co-purification and 3D domain contacts (iPfam, 3did).   AVAILABILITY http://www.jcvi.org/mpidb/	3did;database;experiment;mint;microbial interactions;pfam;pubmed;purification of quantum state;spen gene;protein protein interaction	Johannes B Goll;Seesandra V. Rajagopala;Shen C. Shiau;Hank Wu;Brian T. Lamb;Peter Uetz	2008	Bioinformatics	10.1093/bioinformatics/btn285	biology;plasma protein binding;the internet;computer science;bioinformatics;binding site;data mining;world wide web	Comp.	-1.0599582301925141	-60.27242493535493	78934
0e5162d9288eb8db069047a320885fd4c16ae59e	a deep hybrid model to detect multi-locus interacting snps in the presence of noise	deep neural networks;genetic heterogeneity;genome-wide association studies;genotyping error;phenocopy;random forest;snp-snp interactions	Identifying genetic variants associated with complex diseases is a central focus of genome-wide association studies. These studies extensively adopt univariate analysis by ignoring interaction effects. It is widely accepted that the etiology of most complex diseases depends on interactions between genetic variants and / or environmental factors. Several machine learning and data mining methods have been consistently successful in exposing these interaction effects. However, there has been no major breakthrough due to various biological complexities, and statistical computational challenges facing in the field of genetic epidemiology, despite of many efforts. Deep learning is emerging machine learning approach that promises to reveal the hidden patterns of big data for accurate predictions. In this study, a deep neural network is unified with a random forest by forming hybrid architecture, for achieving reliable detection of multi-locus interactions between single nucleotide polymorphisms. The proposed hybrid method is evaluated on various simulated scenarios in the absence of main effect for six epistasis models. The best model with optimal hyper-parameters (grid and random grid search) is chosen to enhance the power of the method by maximising the model's prediction accuracy. The performance metrics of each model is analysed for both training and validation. Further, the performance of the method in the presence of noise due to missing data, genotyping errors, genetic heterogeneity, and phenocopy, and their combined effects are evaluated. The power of the method in detecting two-locus interactions is compared with the previous methods in the presence and absence of noise. On an average, the power of the proposed method is much higher than the previous methods for all simulated scenarios. Finally, findings are confirmed on a chronical dialysis patient's data, obtained from the published study performed at the Kaohsiung Chang Gung Memorial Hospital. It is observed that the interaction between SNP 21 (2) and SNP 28 (2) in the mitochondrial D-loop has the highest risk for the disease manifestation.		Suneetha Uppu;Aneesh Krishna	2018	International journal of medical informatics	10.1016/j.ijmedinf.2018.09.003	genetic epidemiology;data mining;architecture;artificial neural network;main effect;missing data;hyperparameter optimization;deep learning;random forest;medicine;artificial intelligence;pattern recognition	Comp.	7.189148017910798	-53.50151050036681	79051
211d648bf941d733f6bb2c872b6be3f70e77c957	sequence database search using jumping alignments	amino acid;database search	"""We describe a new algorithm for amino acid sequence classification and the detection of remote homologues. The rationale is to exploit both vertical and horizontal information of a multiple alignment in a well balanced manner. This is in contrast to established methods like profiles and hidden Markov models which focus on vertical information as they model the columns of the alignment independently. In our setting, we want to select from a given database of """"candidate sequences"""" those proteins that belong to a given superfamily. In order to do so, each candidate sequence is separately tested against a multiple alignment of the known members of the superfamily by means of a new jumping alignment algorithm. This algorithm is an extension of the Smith-Waterman algorithm and computes a local alignment of a single sequence and a multiple alignment. In contrast to traditional methods, however, this alignment is not based on a summary of the individual columns of the multiple alignment. Rather, the candidate sequence at each position is aligned to one sequence of the multiple alignment, called the """"reference sequence"""". In addition, the reference sequence may change within the alignment, while each such jump is penalized. To evaluate the discriminative quality of the jumping alignment algorithm, we compared it to hidden Markov models on a subset of the SCOP database of protein domains. The discriminative quality was assessed by counting the number of false positives that ranked higher than the first true positive (FP-count). For moderate FP-counts above five, the number of successful searches with our method was considerably higher than with hidden Markov models."""	amino acid sequence;amino acids;chamaecyparis lawsoniana;column (database);design rationale;hidden markov model;markov chain;multiple sequence alignment;protein domain;sdha wt allele;superfamily;scop;sequence analysis;sequence database;smith–waterman algorithm;subgroup	Constantin Bannert;Marc Rehmsmeier;Rainer Spang;Jens Stoye	2000	Proceedings. International Conference on Intelligent Systems for Molecular Biology		biology;structural alignment;database search engine;amino acid;multiple sequence alignment;computer science;bioinformatics;machine learning;sequence alignment;data mining;alignment-free sequence analysis	Comp.	8.705075115696058	-55.2813531838463	79069
ec99f47b8c747419259ab7231b5d1bbb443ebbe0	bssv: bayesian based somatic structural variation identification with whole genome dna-seq data	dna;breast neoplasms;female;ptprd gene bssv method bayesian based somatic structural variation identification whole genome dna seq data dna sequencing tumor the cancer genome atlas breast cancer data rad51 gene brip1 gene er gene pgr gene;bioinformatics genomics tumors bayes methods breast cancer sensitivity;tumours bayes methods cancer dna genomics;high throughput nucleotide sequencing;bayes theorem;sequence analysis dna;area under curve;biomarkers tumor;genome human;roc curve;algorithms;humans;mutation	High coverage whole genome DNA-sequencing enables identification of somatic structural variation (SSV) more evident in paired tumor and normal samples. Recent studies show that simultaneous analysis of paired samples provides a better resolution of SSV detection than subtracting shared SVs. However, available tools can neither identify all types of SSVs nor provide any rank information regarding their somatic features. In this paper, we have developed a Bayesian framework, by integrating read alignment information from both tumor and normal samples, called BSSV, to calculate the significance of each SSV. Tested by simulated data, the precision of BSSV is comparable to that of available tools and the false negative rate is significantly lowered. We have also applied this approach to The Cancer Genome Atlas breast cancer data for SSV detection. Many known breast cancer specific mutated genes like RAD51, BRIP1, ER, PGR and PTPRD have been successfully identified.	base sequence;biopolymer sequencing;diploid cell;mammary neoplasms;non-small cell lung carcinoma;p-value;pdgfb gene;pgr gene;ptprd gene;rad51 gene;stage 0 breast carcinoma	Xi Chen;Xu Shi;Ayesha N. Shajahan;Leena Hilakivi-Clarke;Robert Clarke;Jianhua Xuan	2014	2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/EMBC.2014.6944485	mutation;cancer research;biology;integral;bioinformatics;bayes' theorem;genetics;dna;receiver operating characteristic	Visualization	4.315300531284011	-53.50103524743304	79197
23451342a3f54148810aecf373b13c63c3d3ceb2	error detection and correction of gene trees		Reconstructing the phylogeny of a gene family and reconciling the obtained gene tree with the species tree reveals the history of duplications, losses and other events that have shaped the gene family, with important implications towards the functional specificity of genes. However, evolutionary histories inferred by reconciliation are strongly dependent upon the accuracy of the trees, and few misplaced leaves will lead to a completely different history. Furthermore, sequence data alone often lack the information to confidently support a gene tree topology. We outline a number of criteria that can be used to detect erroneous gene trees. Analysing Ensembl gene trees of the fish genomes Stickleback, Medaka, Tetraodon, and Zebrafish reveals a significant number of erroneous gene trees. Finally, some potential directions for error correction of gene trees are explored.	cluster analysis;error detection and correction;gene family;homology (biology);peptide sequence;phylogenetic tree;sensitivity and specificity;synteny;tree network	Manuel Lafond;Krister M. Swenson;Nadia El-Mabrouk	2013		10.1007/978-1-4471-5298-9_12	zebrafish;ensembl;phylogenetics;random tree;genome;gene;gene family;bioinformatics;tetraodon;biology	Comp.	3.129520863969044	-61.01405143239858	79238
ec53566daefe7e187ad596c5f16289be04f5ef69	"""ligercat: using """"mesh clouds"""" from journal, article, or gene citations to facilitate the identification of relevant biomedical literature"""	biomedical research;genes	"""The identification of relevant literature from within large collections is often a challenging endeavor. In the context of indexed resources, such as MEDLINE, it has been shown that keywords from a controlled vocabulary (e.g., MeSH) can be used in combination to retrieve relevant search results. One effective strategy for identifying potential search terms is to examine a collection of documents for frequently occurring terms. In this way, """"Tag clouds"""" are a popular mechanism for ascertaining terms associated with a collection of documents. Here, we present the Literature and Genomic Electronic Resource Catalogue (LigerCat) system for exploring biomedical literature through the selection of terms within a """"MeSH cloud"""" that is generated based on an initial query using journal, article, or gene data. The resultant interface is encapsulated within a Web interface: http://ligercat.ubio.org. The system is also available for installation under an MIT license."""	collections (publication);controlled vocabulary;index;interface device component;medline;question (inquiry);resultant;tag cloud;citation	Indra Neil Sarkar;Ryan Schenk;Holly Miller;Catherine N. Norton	2009	AMIA ... Annual Symposium proceedings. AMIA Symposium		world wide web;information retrieval;tag cloud;controlled vocabulary;mit license;medline;cloud computing;computer science;user interface	Comp.	-2.989648832029479	-63.12884526185679	79271
a1a67451e607ca8a71d5c5513c20e5a2320f29aa	g-sesame: web tools for go-term-based gene similarity analysis and knowledge discovery	genes;semantic similarity;software;vocabulary controlled;semantics;databases genetic;cluster analysis;internet;gene ontology;knowledge discovery	We have developed a set of online tools for measuring the semantic similarities of Gene Ontology (GO) terms and the functional similarities of gene products, and for further discovering biomedical knowledge from the GO database. The tools have been used for about 6.9 million times by 417 institutions from 43 countries since October 2006. The online tools are available at: http://bioinformatics.clemson.edu/G-SESAME.	access network;batch processing;bioinformatics;blog;cluster analysis;gene ontology;interactivity;lobular neoplasia;requirement;sesame - dietary;user requirements document;statistical cluster	Zhidian Du;Lin Li;Chin-Fu Chen;Philip S. Yu;James Zijun Wang	2009		10.1093/nar/gkp463	semantic similarity;the internet;bioinformatics;gene;semantics;cluster analysis	Comp.	-3.4708096983740844	-61.47819970548709	79287
1f73a07adebfdad3179e6df2abbd1403723c510c	grouping pharmacovigilance terms with semantic distance		Pharmacovigilance is the activity related to the collection, analysis and prevention of adverse drug reactions (ADRs) induced by drugs or biologics. Besides other methods, statistical algorithms are used to detect previously unknown ADRs, and it was noted that groupings of ADR terms can further improve safety signal detection. Standardised MedDRA Queries are developed to assist retrieval and evaluation of MedDRA-coded ADR reports. Dependent on the context of their application, different SMQs show varying degrees of specificity and sensitivity; some appear to be over-inclusive, some might miss relevant terms. Moreover, several important safety topics are not yet fully covered by SMQs. The objective of this work is to propose an automatic method for the creation of groupings of terms. This method is based on the application of the semantic distance between MedDRA terms. Several experiments are performed, showing a promising precision and an acceptable recall.	adverse reaction to drug;algorithm;biological factors;detection theory;doxorubicin;experiment;flight recorder;meddra;pharmacovigilance;sensitivity and specificity	Marie Dupuch;Magnus Lerch;Anne Jamet;Marie-Christine Jaulent;Reinhard Fescharek;Natalia Grabar	2011	Studies in health technology and informatics	10.3233/978-1-60750-806-9-794	information retrieval;semantic similarity;data mining;pharmacovigilance;recall;meddra;medicine	Web+IR	-2.4573220865691896	-65.17861202450689	79432
3376e8304c7b80a0f5c14d399b148cff558cb277	extraction et sélection de motifs émergents minimaux : application à la chémoinformatique. (extraction and selection of minimal emerging patterns : application to chemoinformatics)			cheminformatics;linear algebra	Mouhamadou Bamba Kane	2017				Crypto	0.8991324845660208	-65.29584020879435	79434
dda0277a4e054bda22e4cc6c70c29c982309ec08	agenda: gene prediction by comparative sequence analysis	comparative sequence analysis;gene prediction	UNLABELLED Comparative sequence analysis is a powerful approach to identify functional elements in genomic sequences. Herein, we describe AGenDA (Alignment-based GENe Detection Algorithm), a novel method for gene prediction that is based on long-range alignment of syntenic regions in eukaryotic genome sequences. Local sequence homologies identified by the DIALIGN program are searched for conserved splice signals to define potential protein-coding exons; these candidate exons are then used to assemble complete gene structures. The performance of our method was tested on a set of 105 human-mouse sequence pairs. These test runs showed that sensitivity and specificity of AGenDA are comparable with the best gene- prediction program that is currently available. However, since our method is based on a completely different type of input information, it can detect genes that are not detectable by standard methods and vice versa. Thus, our approach seems to be a useful addition to existing gene-prediction programs.   AVAILABILITY DIALIGN is available through the Bielefeld Bioinformatics Server (BiBiServ) at http://bibiserv.techfak.uni-bielefeld.de/dialign/ The gene-prediction program AGenDA described in this paper will be available through the BiBiServ or MIPS web server at http://mips.gsf.de.		Oliver Rinner;Burkhard Morgenstern	2002	In silico biology		biology;bioinformatics;gene prediction	Comp.	-1.4121355151988957	-57.22974670013496	79439
e0fe47999fdedb509d03152b32bbd52aae34b9d4	three-dimensional definition of leaf morphological traits of arabidopsis in silico phenotypic analysis	3d;polygon model;morphological traits;phenome;three dimensional;morphological trait;arabidopsis;in silico	The detection of phenotypic alterations of mutants and variants is one of the bottlenecks that hinder systematic gene functional studies of the model plant Arabidopsis. In an earlier study, we have addressed this problem by proposing a novel methodology for phenome analysis based on in silico analysis of polygon models that are acquired by 3-dimensional (3D) measurement and which precisely reconstruct the actual plant shape. However, 3D quantitative descriptions of morphological traits are rare, whereas conventional 2D descriptions have already been studied but may lack the necessary precision. In this report, we focus on six major leaf morphological traits, which are commonly used in the current manual mutant screens, and propose new 3D quantitative definitions that describe these traits. In experiments to extract the traits, we found significant differences between two variants of Arabidopsis with respect to blade roundness and blade epinasty. Remarkably, the detected difference between variants in the blade roundness trait was undetectable when using conventional 2D descriptions. Thus, the result of the experiment indicates that the proposed definitions with 3D description may lead to new discoveries of phenotypic alteration in gene functional studies that would not be possible using conventional 2D descriptions.		Eli Kaminuma;Naohiko Heida;Yuko Tsumoto;Miki Nakazawa;Nobuharu Goto;Akihiko Konagaya;Minami Matsui;Tetsuro Toyoda	2005	Journal of bioinformatics and computational biology	10.1142/S0219720005001119	phenome;biology;three-dimensional space;botany;computer science;bioinformatics;mathematics;genetics;3d computer graphics	Comp.	1.7821025679083993	-55.48183666866497	79682
f00a5acadfbd67522077dbe00af0cf94133c5e84	tandem repeats detection in dna sequences using kaiser window based adaptive s-transform			kaiser window;s transform	Sunil Datt Sharma;Rajiv Saxena;S. N. Sharma	2017	Bio-Algorithms and Med-Systems	10.1515/bams-2017-0014	tandem repeat;s transform;kaiser window;genetics;mathematics;dna sequencing	Vision	2.277849207541136	-63.56905120674598	79814
c544f25ad0f1a93b24754de4661a644687409313	a reliable and distributed lims for efficient management of the microarray experiment environment	data sharing;expression profile;service provider;data management;p2p;digital signature;molecular biology;genetic network;project scheduling;peer to peer;system management;laboratory information management system	A microarray is a principal technology in molecular biology. It generates thousands of expressions of genotypes at once. Typically, a microarray experiment contains many kinds of information, such as gene names, sequences, expression profiles, scanned images, and annotation. So, the organization and analysis of vast amounts of data are required. Microarray LIMS (Laboratory Information Management System) provides data management, search, and basic analysis. Recently, microarray joint researches, such as the skeletal system disease and anti-cancer medicine have been widely conducted. This research requires data sharing among laboratories within the joint research group. In this paper, we introduce a web based microarray LIMS, SMILE (Small and solid MIcroarray Lims for Experimenters), especially for shared data management. The data sharing function of SMILE is based on Friend-to-Friend (F2F), which is based on anonymous P2P (Peer-to-Peer), in which people connect directly with their “friends”. It only allows its friends to exchange data directly using IP addresses or digital signatures you trust. In SMILE, there are two types of friends: “service provider”, which provides data, and “client”, which is provided with data. So, the service provider provides shared data only to its clients. SMILE provides useful functions for microarray experiments, such as variant data management, image analysis, normalization, system management, project schedule management, and shared data management. Moreover, it connections with two systems: ArrayMall for analyzing microarray images and GENAW for constructing a genetic network. SMILE is available on http://neobio.cs.pusan.ac.kr:8080/smile.	antivirus software;data visualization;digital signature;experiment;friend-to-friend;gene regulatory network;image analysis;image scanner;information management system (ims);laboratory information management system;microarray;peer-to-peer;skeletal animation;systems management	Hee-Jeong Jin;Jeong-Won Lee;Hwan-Gue Cho	2007	J. Integrative Bioinformatics	10.2390/biecoll-jib-2007-57	service provider;digital signature;systems management;data management;computer science;bioinformatics;peer-to-peer;data mining;database;world wide web;schedule	Networks	-3.8243350953811297	-60.8228480644255	79964
b9f063ab66715b75706b11ab3b0a2af52294cd5b	sheddomedb: the ectodomain shedding database for membrane-bound shed markers	computational biology bioinformatics;algorithms;computer appl in life sciences;microarrays;bioinformatics	A number of membrane-anchored proteins are known to be released from cell surface via ectodomain shedding. The cleavage and release of membrane proteins has been shown to modulate various cellular processes and disease pathologies. Numerous studies revealed that cell membrane molecules of diverse functional groups are subjected to proteolytic cleavage, and the released soluble form of proteins may modulate various signaling processes. Therefore, in addition to the secreted protein markers that undergo secretion through the secretory pathway, the shed membrane proteins may comprise an additional resource of noninvasive and accessible biomarkers. In this context, identifying the membrane-bound proteins that will be shed has become important in the discovery of clinically noninvasive biomarkers. Nevertheless, a data repository for biological and clinical researchers to review the shedding information, which is experimentally validated, for membrane-bound protein shed markers is still lacking. In this study, the database SheddomeDB was developed to integrate publicly available data of the shed membrane proteins. A comprehensive literature survey was performed to collect the membrane proteins that were verified to be cleaved or released in the supernatant by immunological-based validation experiments. From 436 studies on shedding, 401 validated shed membrane proteins were included, among which 199 shed membrane proteins have not been annotated or validated yet by existing cleavage databases. SheddomeDB attempted to provide a comprehensive shedding report, including the regulation of shedding machinery and the related function or diseases involved in the shedding events. In addition, our published tool ShedP was embedded into SheddomeDB to support researchers for predicting the shedding event on unknown or unrecorded membrane proteins. To the best of our knowledge, SheddomeDB is the first database for the identification of experimentally validated shed membrane proteins and currently may provide the most number of membrane proteins for reviewing the shedding information. The database included membrane-bound shed markers associated with numerous cellular processes and diseases, and some of these markers are potential novel markers because they are not annotated or validated yet in other databases. SheddomeDB may provide a useful resource for discovering membrane-bound shed markers. The interactive web of SheddomeDB is publicly available at http://bal.ym.edu.tw/SheddomeDB/ .	attempt;biological markers;cell secretion;cleaved cell;database;embedded system;experiment;gene regulatory network;membrane proteins;plasma membrane;research data archiving;review [publication type];scientific publication;secretory pathway;supernatant;tissue membrane	Wei-Sheng Tien;Jun-Hong Chen;Kun-Pin Wu	2017		10.1186/s12859-017-1465-7	biology;dna microarray;cell biology;computer science;bioinformatics	Comp.	7.016813264437302	-59.672554607710886	80267
06bdb5a4861b3534ba85114669c18770ff94e8a8	finding more effective microsatellite markers for forensics	databases;genomics;testing;statistics;sociology;forensics;bioinformatics	Published by the Combined DNA Index System (CODIS) program of the Federal Bureau of Investigation (FBI) in 1997, the 13 core short tandem repeat (STR) loci are widely adopted as genetic markers in forensic applications, e.g., identity testing and paternity testing. However, these loci may be biased and suffer from reduced sensitivities towards specific population groups. In addition, the rapid growth of entries in forensic databases raises the chance of random hits, which can cause false judgments of innocents as criminals. A solution to these problems is to introduce more effective STR markers. The availability of whole genome sequencing enables us to identify more reliable STR markers for forensic applications computationally. In this study, we proposed an algorithm to identify STR markers with high discriminative abilities from the next-generation sequencing (NGS) data. Our algorithm could select a customized set of loci for a given population with pre-specified discriminative thresholds. We have applied the method to 320 Chinese individuals from the 1,000 Genomes Project and obtained various numbers of loci, which were able to statistically identify an individual worldwide and had higher combined powers of discrimination (CPD) and combined probabilities of exclusion (CPE) than the existing CODIS 13 loci. For identity testing, the mean frequency of DNA profile (FDP) with the selected 11 STRs was smaller than that with CODIS 13 STRs by student's t-test. With more loci, much smaller FDPs were obtained. The database matching probabilities (DMP) for selected loci were also lower than that for CODIS 13 STRs in a database with 10 billion entries. Moreover, the selected loci were able to provide considerably low chance of random profile matches so that statistically no false judgments could occur. The selected loci also reduced the risk of random allele matches when doing the familial search, with lower random allele matching probabilities. In addition, the selected STRs were statistically better than CODIS STRs for paternity testing in our simulated data, with lower probabilities of false inclusions and exclusions.	algorithm;collaborative product development;combined dna index system;communications satellite;constant phase element;database;tandem computers;whole genome sequencing	Bowen Tan;Zhe Zhang;Zicheng Zhao;Shengbin Li;Shuai Cheng Li	2016	2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2016.7822596	biology;genomics;computer science;bioinformatics;software testing;genetics	DB	2.9926340724813802	-53.54067393162213	80352
1bc2274ffa51fc660fef4dfbc31dd901cd0694a2	modelling regulatory pathways in e. coli from time series expression profiles	hidden variables;cell cycle;dynamic bayesian network;time series data;time series;feedback loop;gene expression	MOTIVATION Cells continuously reprogram their gene expression network as they move through the cell cycle or sense changes in their environment. In order to understand the regulation of cells, time series expression profiles provide a more complete picture than single time point expression profiles. Few analysis techniques, however, are well suited to modelling such time series data.   RESULTS We describe an approach that naturally handles time series data with the capabilities of modelling causality, feedback loops, and environmental or hidden variables using a Dynamic Bayesian network. We also present a novel way of combining prior biological knowledge and current observations to improve the quality of analysis and to model interactions between sets of genes rather than individual genes. Our approach is evaluated on time series expression data measured in response to physiological changes that affect tryptophan metabolism in E. coli. Results indicate that this approach is capable of finding correlations between sets of related genes.	causality;cellular phone;dynamic bayesian network;feedback;gene expression programming;hidden variable theory;interaction;reprogram;time series;tryptophan metabolism pathway	Irene M. Ong;Jeremy D. Glasner;David Page	2002	Bioinformatics		biology;computer science;bioinformatics;machine learning;time series;data mining;genetics;statistics	Comp.	5.19519345208237	-58.95331379227671	80445
ad8e17e24f43014fb0838f7454fa24af7e380a95	linking tissues to phenotypes using gene expression profiles	animals;mice;internet;genome;gene expression regulation;humans;user computer interface;phenotype;gene expression profiling;organ specificity;gene ontology	Despite great biological and computational efforts to determine the genetic causes underlying human heritable diseases, approximately half (3500) of these diseases are still without an identified genetic cause. Model organism studies allow the targeted modification of the genome and can help with the identification of genetic causes for human diseases. Targeted modifications have led to a vast amount of model organism data. However, these data are scattered across different databases, preventing an integrated view and missing out on contextual information. Once we are able to combine all the existing resources, will we be able to fully understand the causes underlying a disease and how species differ. Here, we present an integrated data resource combining tissue expression with phenotypes in mouse lines and bringing us one step closer to consequence chains from a molecular level to a resulting phenotype. Mutations in genes often manifest in phenotypes in the same tissue that the gene is expressed in. However, in other cases, a systems level approach is required to understand how perturbations to gene-networks connecting multiple tissues lead to a phenotype. Automated evaluation of the predicted tissue-phenotype associations reveals that 72-76% of the phenotypes are associated with disruption of genes expressed in the affected tissue. However, 55-64% of the individual phenotype-tissue associations show spatially separated gene expression and phenotype manifestation. For example, we see a correlation between 'total body fat' abnormalities and genes expressed in the 'brain', which fits recent discoveries linking genes expressed in the hypothalamus to obesity. Finally, we demonstrate that the use of our predicted tissue-phenotype associations can improve the detection of a known disease-gene association when combined with a disease gene candidate prediction tool. For example, JAK2, the known gene associated with Familial Erythrocytosis 1, rises from the seventh best candidate to the top hit when the associated tissues are taken into consideration. Database URL: http://www.sanger.ac.uk/resources/databases/phenodigm/phenotype/list.	apc gene;access network;adipocytes, beige;alternaria sp. u54;bar codes;barcode;body tissue;computation;congenital abnormality;contain (action);denial-of-service attack;drug delivery systems;embryo;endocrine system diseases;execution;fits;gene expression;gene expression programming;groovy;hypothalamic structure;interface device component;janus kinase 2;manuscripts;mental association;mouse genetics project;mutagenesis, site-directed;mutation (genetic algorithm);phenotype;population parameter;published database;subgroup;thrombocytopenia;uniform resource locator;united states national institutes of health;user interface;matrix gla protein	Anika Oellrich;Damian Smedley	2014		10.1093/database/bau017	biology;the internet;regulation of gene expression;bioinformatics;phenotype;gene expression profiling;candidate gene;genetics;genome	Comp.	2.8800769804031456	-60.67555729646154	80451
4bf6c2520b02c0fd2ff3833e5cb82f0aa8bb810a	support vector machines for separation of mixed plant?cpathogen est collections based on codon usage		MOTIVATION Discovery of host and pathogen genes expressed at the plant-pathogen interface often requires the construction of mixed libraries that contain sequences from both genomes. Sequence identification requires high-throughput and reliable classification of genome origin. When using single-pass cDNA sequences difficulties arise from the short sequence length, the lack of sufficient taxonomically relevant sequence data in public databases and ambiguous sequence homology between plant and pathogen genes.   RESULTS A novel method is described, which is independent of the availability of homologous genes and relies on subtle differences in codon usage between plant and fungal genes. We used support vector machines (SVMs) to identify the probable origin of sequences. SVMs were compared to several other machine learning techniques and to a probabilistic algorithm (PF-IND) for expressed sequence tag (EST) classification also based on codon bias differences. Our software (Eclat) has achieved a classification accuracy of 93.1% on a test set of 3217 EST sequences from Hordeum vulgare and Blumeria graminis, which is a significant improvement compared to PF-IND (prediction accuracy of 81.2% on the same test set). EST sequences with at least 50 nt of coding sequence can be classified using Eclat with high confidence. Eclat allows training of classifiers for any host-pathogen combination for which there are sufficient classified training sequences.   AVAILABILITY Eclat is freely available on the Internet (http://mips.gsf.de/proj/est) or on request as a standalone version.   CONTACT friedel@informatik.uni-muenchen.de.	classification;collections (publication);dna, complementary;database;databases;expressed sequence tags;genes, fungal;genome;high-throughput computing;homologous gene;hordeum;internet;libraries;machine learning;open reading frames;pathogenic organism;probability;puccinia graminis;randomized algorithm;sequence homology;support vector machine;test set;throughput	Caroline C. Friedel;Katharina Jahn;Selina Sommer;Stephen Rudd;Hans-Werner Mewes;Igor V. Tetko	2005	Bioinformatics			Comp.	1.3491898129112607	-56.24852557709459	80456
bb2883609498aca5c8ee7682f4eee644883db774	a study of cell-free dna fragmentation pattern and its application in dna sample type classification		Plasma cell-free DNA (cfDNA) has certain fragmentation patterns, which can bring non-random base content curves of the sequencing datau0027s beginning cycles. We studied the patterns and found that we could determine whether a sample is cfDNA or not by just looking into the first 10 cycles of its base content curves. We analyzed 3,189 FastQ files, including 1,442 plasma cfDNA, 1,234 genomic DNA, 507 FFPE tumour DNA, and 6 urinary cfDNA. By deep analyzing these data, we found the patterns were stable enough to distinguish cfDNA from other kinds of DNA samples. Based on this finding, we built classification models to recognize cfDNA samples by their sequencing data. Pattern recognition models were then trained with different classification algorithms like k-nearest neighbors (KNN), random forest, and support vector machine (SVM). The result of 1,000 iteration .632+ bootstrapping showed that all these classifiers could give an average accuracy higher than 98 percent, indicating that the cfDNA patterns are unique and can make the dataset highly separable. The best result was obtained using a random forest classifier with a 99.89 percent average accuracy ( $sigma =0.00068$ ). A tool called CfdnaPattern ( http://github.com/OpenGene/CfdnaPattern ) has been developed to train the model and to predict whether a sample is cfDNA or not.	biopolymer sequencing;bootstrapping;dna fragmentation;fastq format;fragmentation (computing);iteration;k-nearest neighbors algorithm;pattern recognition;plasma active;random forest;randomness;silo (dataset);support vector machine;cfdna	Shifu Chen;Ming Liu;Xiaoni Zhang;Renwen Long;Yixing Wang;Yue Han;Shiwei Zhang;Mingyan Xu;Jia Gu	2017	IEEE/ACM Transactions on Computational Biology and Bioinformatics	10.1109/TCBB.2017.2723388	cell-free fetal dna;artificial intelligence;machine learning;genomics;support vector machine;computer science;fastq format;data mining;bioinformatics;bootstrapping;random forest;genomic dna;statistical classification	ML	9.93519030636019	-53.9049523703176	80525
485bdad09d4d61145886c575cc4ae51224e6c781	extracting tailored protein complexes from protein-protein interaction networks	protein protein interaction network;interactome;personalized pagerank algorithm;continuous attractor dynamics;bioinformatics	Suppose that we wish to know a group of proteins responsible for a certain cellular biological process. Here we propose to infer such a protein complex from a protein-protein interaction network by using a class of algorithm, which has originally been developed to achieve web page ranking that reflects user's personal interest or context. The inference of proteins responsible for a given biological process, namely, personalized ranking of proteins is whereby performed in analogy with personalized ranking of web pages. Searching for the best approach to personalized protein ranking, we carry out a series of experiments to compare the performance between two major personalized ranking methods: the personalized PageRank algorithm and the continuous-attractor dynamics algorithm, both applied to a yeast protein-protein interaction network. Results of these comparison experiments suggest that the continuous-attractor dynamics algorithm is the most efficient for personalized protein ranking.		Hiroshi Okamoto	2012		10.1007/978-3-642-28792-3_30	computer science;bioinformatics;data mining;world wide web	Comp.	1.553621462828295	-59.030669934766934	80626
9cc4ed05198f8baaccb85ffdb824b2a6c87a2c06	ecdomainminer: discovering hidden associations between enzyme commission numbers and pfam domains	content based filtering;protein function;enzyme commission number;computational biology bioinformatics;pfam domain;algorithms;computer appl in life sciences;protein domain;microarrays;bioinformatics	Many entries in the protein data bank (PDB) are annotated to show their component protein domains according to the Pfam classification, as well as their biological function through the enzyme commission (EC) numbering scheme. However, despite the fact that the biological activity of many proteins often arises from specific domain-domain and domain-ligand interactions, current on-line resources rarely provide a direct mapping from structure to function at the domain level. Since the PDB now contains many tens of thousands of protein chains, and since protein sequence databases can dwarf such numbers by orders of magnitude, there is a pressing need to develop automatic structure-function annotation tools which can operate at the domain level. This article presents ECDomainMiner, a novel content-based filtering approach to automatically infer associations between EC numbers and Pfam domains. ECDomainMiner finds a total of 20,728 non-redundant EC-Pfam associations with a F-measure of 0.95 with respect to a “Gold Standard” test set extracted from InterPro. Compared to the 1515 manually curated EC-Pfam associations in InterPro, ECDomainMiner infers a 13-fold increase in the number of EC-Pfam associations. These EC-Pfam associations could be used to annotate some 58,722 protein chains in the PDB which currently lack any EC annotation. The ECDomainMiner database is publicly available at http://ecdm.loria.fr/ .	annotation;dwarf;enzyme commission number;extraction;function (biology);inference;interpro;interaction;ligands;list of biological databases;mental association;online and offline;pfam;protein data bank;protein domain;recommender system;test set	Seyed Ziaeddin Alborzi;Marie-Dominique Devignes;David W. Ritchie	2017		10.1186/s12859-017-1519-x	biology;dna microarray;computer science;bioinformatics;data science;data mining;protein domain;enzyme commission number	Comp.	-1.90619577158733	-63.02552273065738	80653
dc75e043940631468e080f84616ac5ce6762b327	predicting essential genes and synthetic lethality via influence propagation in signaling pathways of cancer cell fates	signaling pathways;synthetic lethality;data driven	A major goal of personalized anti-cancer therapy is to increase the drug effects while reducing the side effects as much as possible. A novel therapeutic strategy called synthetic lethality (SL) provides a great opportunity to achieve this goal. SL arises if mutations of both genes lead to cell death while mutation of either single gene does not. Hence, the SL partner of a gene mutated only in cancer cells could be a promising drug target, and the identification of SL pairs of genes is of great significance in pharmaceutical industry. In this paper, we propose a hybridized method to predict SL pairs of genes. We combine a data-driven model with knowledge of signalling pathways to simulate the influence of single gene knock-down and double genes knock-down to cell death. A pair of genes is considered as an SL candidate when double knock-down increases the probability of cell death significantly, but single knock-down does not. The single gene knock-down is confirmed according to the human essential genes database. Our validation against literatures shows that the predicted SL candidates agree well with wet-lab experiments. A few novel reliable SL candidates are also predicted by our model.	cell death;cessation of life;database;dosage forms;drug delivery systems;experiment;genes, essential;genes, vif;literature;mutation;personalization;sl (complexity);side effect (computer science);simulation;sleep polysomnography domain;software propagation;synthetic lethality;synthetic intelligence;biological signaling;cancer cell	Fan Zhang;Min Wu;Xuejuan Li;Xiaoli Li;Chee Keong Kwoh;Jie Zheng	2015	Journal of bioinformatics and computational biology	10.1142/S0219720015410024	biology;bioinformatics;genetics;signal transduction	Comp.	7.633865413737342	-60.331065462410685	80665
1f3f8c4f7dad4ea89a503051fdf7296b3d83a3a2	fast genomic prediction of breeding values using parallel markov chain monte carlo with convergence diagnosis	bayesian models;convergence diagnosis;genomic prediction;high-performance computing;tunable burn-in	Running multiple-chain Markov Chain Monte Carlo (MCMC) provides an efficient parallel computing method for complex Bayesian models, although the efficiency of the approach critically depends on the length of the non-parallelizable burn-in period, for which all simulated data are discarded. In practice, this burn-in period is set arbitrarily and often leads to the performance of far more iterations than required. In addition, the accuracy of genomic predictions does not improve after the MCMC reaches equilibrium. Automatic tuning of the burn-in length for running multiple-chain MCMC was proposed in the context of genomic predictions using BayesA and BayesCπ models. The performance of parallel computing versus sequential computing and tunable burn-in MCMC versus fixed burn-in MCMC was assessed using simulation data sets as well by applying these methods to genomic predictions of a Chinese Simmental beef cattle population. The results showed that tunable burn-in parallel MCMC had greater speedups than fixed burn-in parallel MCMC, and both had greater speedups relative to sequential (single-chain) MCMC. Nevertheless, genomic estimated breeding values (GEBVs) and genomic prediction accuracies were highly comparable between the various computing approaches. When applied to the genomic predictions of four quantitative traits in a Chinese Simmental population of 1217 beef cattle genotyped by an Illumina Bovine 770 K SNP BeadChip, tunable burn-in multiple-chain BayesCπ (TBM-BayesCπ) outperformed tunable burn-in multiple-chain BayesCπ (TBM-BayesA) and Genomic Best Linear Unbiased Prediction (GBLUP) in terms of the prediction accuracy, although the differences were not necessarily caused by computational factors and could have been intrinsic to the statistical models per se. Automatically tunable burn-in multiple-chain MCMC provides an accurate and cost-effective tool for high-performance computing of Bayesian genomic prediction models, and this algorithm is generally applicable to high-performance computing of any complex Bayesian statistical model.	algorithm;bayesian network;burn-in;cattle for beef production;computation (action);convergence (action);cooperative breeding;iteration;leucaena pulverulenta;linear iga bullous dermatosis;markov chain monte carlo;monte carlo method;nitroprusside;parallel computing;simulation;statistical model;supercomputer;tobramycin;trait	Peng Guo;Bo Zhu;Hong Niu;Zezhao Wang;Yonghu Liang;Lupei Zhang;Hemin Ni;Yong Guo;El Hamidi A. Hay;Xue Gao;Huijiang Gao;Xiaolin Wu;Lingyang Xu;Junya Li	2017		10.1186/s12859-017-2003-3	genetics;best linear unbiased prediction;biology;algorithm;markov chain monte carlo;data set;population;statistical model;supercomputer;convergence (routing);bayesian probability	HPC	2.9954645248046883	-52.33942100775481	80710
0b0e53976fd6e5915c2aff7d1cf835639ba7d239	genome-wide identification of the regulatory targets of a transcription factor using biochemical characterization and computational genomic analysis	transcription genetic;software;recombinant fusion proteins;genomics;dna binding proteins;genome fungal;models theoretical;genome analysis;saccharomyces cerevisiae proteins;target identification;transcription factors;binding site;binding sites;computational biology bioinformatics;transcription regulation;models genetic;time factors;false positive rate;false positive reactions;chromatin immunoprecipitation;transcription factor;protein binding;models statistical;algorithms;binding affinity;combinatorial libraries;computational biology;computer appl in life sciences;selection criteria;amino acid motifs;microarrays;bioinformatics;open reading frames	A major challenge in computational genomics is the development of methodologies that allow accurate genome-wide prediction of the regulatory targets of a transcription factor. We present a method for target identification that combines experimental characterization of binding requirements with computational genomic analysis. Our method identified potential target genes of the transcription factor Ndt80, a key transcriptional regulator involved in yeast sporulation, using the combined information of binding affinity, positional distribution, and conservation of the binding sites across multiple species. We have also developed a mathematical approach to compute the false positive rate and the total number of targets in the genome based on the multiple selection criteria. We have shown that combining biochemical characterization and computational genomic analysis leads to accurate identification of the genome-wide targets of a transcription factor. The method can be extended to other transcription factors and can complement other genomic approaches to transcriptional regulation.	binding sites;complement system proteins;computation (action);computational genomics;mathematics;processor affinity;requirement;selection (user interface);transcription factor;transcription (software);transcription, genetic;transcriptional regulation;sporulation	Emmitt R. Jolly;Chen-Shan Chin;Ira Herskowitz;Hao Li	2005	BMC Bioinformatics	10.1186/1471-2105-6-275	biology;genomics;molecular biology;bioinformatics;binding site;genetics;transcription factor;computational genomics	Comp.	4.272706148885144	-58.5334707341715	80901
a5c5b0add437d013d0507832a00fb7199b3753c1	insertion and deletion correcting dna barcodes based on watermarks	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;computational biology bioinformatics;uk phd theses thesis;life sciences;algorithms;combinatorial libraries;uk research reports;medical journals;computer appl in life sciences;europe pmc;biomedical research;microarrays;bioinformatics	Barcode multiplexing is a key strategy for sharing the rising capacity of next-generation sequencing devices: Synthetic DNA tags, called barcodes, are attached to natural DNA fragments within the library preparation procedure. Different libraries, can individually be labeled with barcodes for a joint sequencing procedure. A post-processing step is needed to sort the sequencing data according to their origin, utilizing these DNA labels. The final separation step is called demultiplexing and is mainly determined by the characteristics of the DNA code words used as labels. Currently, we are facing two different strategies for barcoding: One is based on the Hamming distance, the other uses the edit metric to measure distances of code words. The theory of channel coding provides well-known code constructions for Hamming metric. They provide a large number of code words with variable lengths and maximal correction capability regarding substitution errors. However, some sequencing platforms are known to have exceptional high numbers of insertion or deletion errors. Barcodes based on the edit distance can take insertion and deletion errors into account in the decoding process. Unfortunately, there is no explicit code-construction known that gives optimal codes for edit metric. In the present work we focus on an entirely different perspective to obtain DNA barcodes. We consider a concatenated code construction, producing so-called watermark codes, which were first proposed by Davey and Mackay, to communicate via binary channels with synchronization errors. We adapt and extend the concepts of watermark codes to use them for DNA sequencing. Moreover, we provide an exemplary set of barcodes that are experimentally compatible with common next-generation sequencing platforms. Finally, a realistic simulation scenario is use to evaluate the proposed codes to show that the watermark concept is suitable for DNA sequencing applications. Our adaption of watermark codes enables the construction of barcodes that are capable of correcting substitutions, insertion and deletion errors. The presented approach has the advantage of not needing any markers or technical sequences to recover the position of the barcode in the sequencing reads, which poses a significant restriction with other approaches.	acclimatization;barcode;biopolymer sequencing;clinical act of insertion;code word;concatenated error correction code;concatenation;deletion mutation;edit distance;experiment;forward error correction;hamming distance;insertion mutation;insertion sort;library (computing);massively-parallel sequencing;maximal set;multiplexing;simulation;synthetic data;tracer;video post-processing	David Kracht;Steffen Schober	2015		10.1186/s12859-015-0482-7	biology;dna microarray;computer science;bioinformatics;theoretical computer science;data mining;genetics;algorithm	Theory	-0.06225324435512206	-54.4701066027775	80929
d887d4d826f613c644aa3e3e2fc4df1ab122acd8	moduli spaces of phylogenetic trees describing tumor evolutionary patterns		Cancers follow a clonal Darwinian evolution, with fitter subclones replacing more quiescent cells, ultimately giving rise to macroscopic disease. High-throughput genomics provides the opportunity to investigate these processes and determine specific genetic alterations driving disease progression. Genomic sampling of a patient’s cancer provides a molecular history, represented by a phylogenetic tree. Cohorts of patients represent a forest of related phylogenetic structures. To extract clinically relevant information, one must represent and statistically compare these collections of trees. We propose a framework based on an application of the work by Billera, Holmes and Vogtmann on phylogenetic tree spaces to the case of unrooted trees of intra-individual cancer tissue samples. We observe that these tree spaces are globally nonpositively curved, allowing for statistical inference on populations of patient histories. A projective tree space is introduced, permitting visualizations of aggregate evolutionary behavior. Published data from three types of human malignancies are explored within our framework.	aggregate data;color gradient;phylogenetic tree;phylogenetics;population;quiesce;sampling (signal processing);spaces;throughput	Sakellarios Zairis;Hossein Khiabanian;Andrew J. Blumberg;Raul Rabadan	2014		10.1007/978-3-319-09891-3_48	biology;phylogenetic tree;bioinformatics;tree rearrangement;mathematics;ecology;genetics	Comp.	1.842054352483177	-61.88067327520812	80936
161e6d904193f7c502a34fafda7272721e020cc9	a scalable and portable framework for massively parallel variable selection in genetic association studies	software;genome wide association study;male;prostatic neoplasms;algorithms;humans;polymorphism single nucleotide;programming languages	UNLABELLED The deluge of data emerging from high-throughput sequencing technologies poses large analytical challenges when testing for association to disease. We introduce a scalable framework for variable selection, implemented in C++ and OpenCL, that fits regularized regression across multiple Graphics Processing Units. Open source code and documentation can be found at a Google Code repository under the URL http://bioinformatics.oxfordjournals.org/content/early/2012/01/10/bioinformatics.bts015.abstract.   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	bioinformatics;biopolymer sequencing;c++;documentation;fits;feature selection;genetic association studies;google developers;high-throughput computing;opencl api;scalability;source code;throughput;url data type	Gary K. Chen	2012		10.1093/bioinformatics/bts015	genome-wide association study;biology;computer science;bioinformatics;theoretical computer science;data mining;genetics	Comp.	-2.4646948664201287	-57.63427220508638	80962
370df9e0784adeeb259aa9ce28362b423fbd2802	accuracy of four heuristics for the full sibship reconstruction problem in the presence of genotype errors	indexation;genetic marker;exact solution;computational biology;mutation rate	The full sibship reconstruction (FSR) problem is the problem of inferring all groups of full siblings from a given population sample using genetic marker data without parental information. The FSR problem remains a significant challenge for computational biology, since an exact solution for the problem has not been found. The new algorithm, named SIMPSON-assisted Descending Ratio (SDR), is devised combining a new Simpson index based O(n) algorithm (MS2) and the existing Descending Ratio (DR) algorithm. The SDR algorithm outperforms the SIMPSON, MS2, and DR algorithms in accuracy and robustness when tested on a variety of sample family structures. The accuracy error is measured as the percentage of incorrectly assigned individuals. The robustness of the FSR algorithms is assessed by simulating a 2% mutation rate per locus (a 1% rate per allele).	algorithm;computation;computational biology;etsi satellite digital radio;heuristic (computer science);locus;reconstruction conjecture;simpson's rule;simulation	Dmitry A. Konovalov	2006			biology;mutation rate;econometrics;bioinformatics;genetic marker;mathematics;genetics;statistics	Comp.	2.7471085664747865	-52.58335795314447	81051
a9f2073396c993e004a0b018575972bc4fca60fe	large-scale discovery of promoter motifs in drosophila melanogaster	animals;expression pattern;motif discovery;building block;gene regulation;regulatory element;invertebrate genomics;chromosome mapping;transcription factors;statistical significance;sequence analysis dna;binding sites;embryos;sequence databases;gene expression;large scale;genomic databases;promoter regions genetic;transcription factor;drosophila melanogaster;gene prediction;imagos;sequence motif analysis;protein binding;drosophila proteins;molecular sequence data;sequence alignment;base sequence;dna sequence;amino acid motifs	A key step in understanding gene regulation is to identify the repertoire of transcription factor binding motifs (TFBMs) that form the building blocks of promoters and other regulatory elements. Identifying these experimentally is very laborious, and the number of TFBMs discovered remains relatively small, especially when compared with the hundreds of transcription factor genes predicted in metazoan genomes. We have used a recently developed statistical motif discovery approach, NestedMICA, to detect candidate TFBMs from a large set of Drosophila melanogaster promoter regions. Of the 120 motifs inferred in our initial analysis, 25 were statistically significant matches to previously reported motifs, while 87 appeared to be novel. Analysis of sequence conservation and motif positioning suggested that the great majority of these discovered motifs are predictive of functional elements in the genome. Many motifs showed associations with specific patterns of gene expression in the D. melanogaster embryo, and we were able to obtain confident annotation of expression patterns for 25 of our motifs, including eight of the novel motifs. The motifs are available through Tiffin, a new database of DNA sequence motifs. We have discovered many new motifs that are overrepresented in D. melanogaster promoter regions, and offer several independent lines of evidence that these are novel TFBMs. Our motif dictionary provides a solid foundation for further investigation of regulatory elements in Drosophila, and demonstrates techniques that should be applicable in other species. We suggest that further improvements in computational motif discovery should narrow the gap between the set of known motifs and the total number of transcription factors in metazoan genomes.	annotation;computation;conserved sequence;dna binding site;dictionary [publication type];experiment;gene expression regulation;genome;inference;mental association;promoter regions, genetic;sequence motif;transcription factor;taf1protein, drosophila;transcription (software);if protein, drosophila	Thomas A. Down;Casey M. Bergman;Jing Su;Tim J. P. Hubbard	2007	PLoS Computational Biology	10.1371/journal.pcbi.0030007	biology;molecular biology;bioinformatics;genetics;transcription factor	Comp.	2.9159822592085267	-58.25989278371706	81149
5099f2d004a7297d7ca02e2a77a0ab75e8e9a7e1	inferring branching pathways in genome-scale metabolic networks	software;shortest path;simulation and modeling;pathway analysis;metabolic networks and pathways;metabolic network;metabolic engineering;amino acid;systems biology;physiological cellular and medical topics;models biological;computational method;path finding;scaling up;computational biology bioinformatics;computational complexity;algorithms;metabolic pathway;false positive;computational biology;carbon flux;steady state;bioinformatics	A central problem in computational metabolic modelling is how to find biochemically plausible pathways between metabolites in a metabolic network. Two general, complementary frameworks have been utilized to find metabolic pathways: constraint-based modelling and graph-theoretical path finding approaches. In constraint-based modelling, one aims to find pathways where metabolites are balanced in a pseudo steady-state. Constraint-based methods, such as elementary flux mode analysis, have typically a high computational cost stemming from a large number of steady-state pathways in a typical metabolic network. On the other hand, graph-theoretical approaches avoid the computational complexity of constraint-based methods by solving a simpler problem of finding shortest paths. However, while scaling well with network size, graph-theoretic methods generally tend to return more false positive pathways than constraint-based methods. In this paper, we introduce a computational method, ReTrace, for finding biochemically relevant, branching metabolic pathways in an atom-level representation of metabolic networks. The method finds compact pathways which transfer a high fraction of atoms from source to target metabolites by considering combinations of linear shortest paths. In contrast to current steady-state pathway analysis methods, our method scales up well and is able to operate on genome-scale models. Further, we show that the pathways produced are biochemically meaningful by an example involving the biosynthesis of inosine 5'-monophosphate (IMP). In particular, the method is able to avoid typical problems associated with graph-theoretic approaches such as the need to define side metabolites or pathways not carrying any net carbon flux appearing in results. Finally, we discuss an application involving reconstruction of amino acid pathways of a recently sequenced organism demonstrating how measurement data can be easily incorporated into ReTrace analysis. ReTrace is licensed under GPL and is freely available for academic use at http://www.cs.helsinki.fi/group/sysfys/software/retrace/ . ReTrace is a useful method in metabolic path finding tasks, combining some of the best aspects in constraint-based and graph-theoretic methods. It finds use in a multitude of tasks ranging from metabolic engineering to metabolic reconstruction of recently sequenced organisms.	arm architecture;academy;algorithmic efficiency;amino acids;biological phenomena;carbon cycle;computation;computational complexity theory;cyclophosphamide;cylinder-head-sector;distance;eighty;encode (action);ephrin type-b receptor 1, human;expectation propagation;experiment;gene expression;gene regulatory network;generalization (psychology);glucose;graph - visual representation;graph theory;hl7publishingsubsection <query>;il31ra gene;image scaling;indirect treatment;kegg;large;manuscripts;metabolic engineering;metabolic process, cellular;metabolic network modelling;metabolite;mordechai ben-ari;pathfinding;pathway analysis;pseudo brand of pseudoephedrine;question (inquiry);relevance;scalability;short;shortest path problem;simulation;steady state;stemming;test scaling;weight;wolff-parkinson-white syndrome;zo antigen;algorithm;citation;funding grant	Esa Pitkänen;Paula Jouhten;Juho Rousu	2009		10.1186/1752-0509-3-103	biology;metabolic pathway;amino acid;type i and type ii errors;computer science;bioinformatics;pathfinding;theoretical computer science;machine learning;metabolic engineering;shortest path problem;computational complexity theory;steady state;systems biology;metabolic network	Comp.	6.006207891827134	-55.28257206606243	81258
cfcd8af0fc268be29ff0ba322d7102c1bf68dcf8	scientific workflow optimization for improved peptide and protein identification	software;mass spectrometry;computational biology bioinformatics;peptide fragments;proteins;models statistical;workflow;algorithms;humans;user computer interface;combinatorial libraries;proteomics;computational biology;computer appl in life sciences;programming languages;databases protein;microarrays;bioinformatics	Peptide-spectrum matching is a common step in most data processing workflows for mass spectrometry-based proteomics. Many algorithms and software packages, both free and commercial, have been developed to address this task. However, these algorithms typically require the user to select instrument- and sample-dependent parameters, such as mass measurement error tolerances and number of missed enzymatic cleavages. In order to select the best algorithm and parameter set for a particular dataset, in-depth knowledge about the data as well as the algorithms themselves is needed. Most researchers therefore tend to use default parameters, which are not necessarily optimal. We have applied a new optimization framework for the Taverna scientific workflow management system ( http://ms-utils.org/Taverna_Optimization.pdf ) to find the best combination of parameters for a given scientific workflow to perform peptide-spectrum matching. The optimizations themselves are non-trivial, as demonstrated by several phenomena that can be observed when allowing for larger mass measurement errors in sequence database searches. On-the-fly parameter optimization embedded in scientific workflow management systems enables experts and non-experts alike to extract the maximum amount of information from the data. The same workflows could be used for exploring the parameter space and compare algorithms, not only for peptide-spectrum matching, but also for other tasks, such as retention time prediction. Using the optimization framework, we were able to learn about how the data was acquired as well as the explored algorithms. We observed a phenomenon identifying many ammonia-loss b-ion spectra as peptides with N-terminal pyroglutamate and a large precursor mass measurement error. These insights could only be gained with the extension of the common range for the mass measurement error tolerance parameters explored by the optimization framework.	ammonia;b-ion;default;embedded system;embedding;error-tolerant design;gain;ions;large;matching;mathematical optimization;population parameter;proteomics;pyroglutamate;sequence database;silo (dataset);spectrometry;algorithm;procollagen type i n-terminal peptide	Sonja Holl;Yassene Mohammed;Olav Zimmermann;Magnus Palmblad	2015		10.1186/s12859-015-0714-x	biology;workflow;dna microarray;mass spectrometry;computer science;bioinformatics;data science;data mining;proteomics	Metrics	1.4976376602811519	-56.60033976618919	81291
3eadf2d98686fde95d1e0a1b14acdd252278ff6f	rapid software prototyping in computational molecular biology			computation;software prototyping	Oliver Kohlbacher;Hans-Peter Lenhof	1999			computational biology	Comp.	0.8010689078972668	-64.49468209027931	81343
330ff52b3788eb764a4eb9fe37039392c54e66b8	ttp: tool for tumor progression	cell division time;mutation rate;growth dynamic;cell division;tumor progression;flexible tool;evolutionary dynamic;fitness landscape;average time;cancer cell	In this work we present a flexible tool for tumor progression, which simulates the evolutionary dynamics of cancer. Tumor progression implements a multi-type branching process where the key parameters are the fitness landscape, the mutation rate, and the average time of cell division. The fitness of a cancer cell depends on the mutations it has accumulated. The input to our tool could be any fitness landscape, mutation rate, and cell division time, and the tool produces the growth dynamics and all relevant statistics.	color gradient;evolutionary algorithm;trusted third party	Johannes G. Reiter;Ivana Bozic;Krishnendu Chatterjee;Martin A. Nowak	2013		10.1007/978-3-642-39799-8_6	biology;bioinformatics;genetics	Logic	3.7172283847827687	-64.7037062216103	81353
9939c591aaabba3b10e45bfae4c138910febc0e3	binding affinity prediction of s. cerevisiae 14-3-3 and gyf peptide-recognition domains using support vector regression	peptides;support vector machines;biological system modeling;g900 others in mathematical and computing sciences;computational modeling;proteins;amino acids;predictive models	Proteins interact with other proteins and bio-molecules to carry out biological processes in a cell. Computational models help understanding complex biochemical processes that happens throughout the life of a cell. Domain-mediated protein interaction to peptides one such complex problem in bioinformatics that requires computational predictive models to identify meaningful bindings. In this study, domain-peptide binding affinity prediction models are proposed based on support vector regression. Proposed models are applied to yeast bmh 14-3-3 and syh GYF peptide-recognition domains. The cross validated results of the domain-peptide binding affinity data sets show that predictive performance of the support vector based models are efficient.	14-3-3 proteins;biochemical processes;bioinformatics;biological processes;british informatics olympiad;computation;computational model;predictive modelling;processor affinity;saccharomyces cerevisiae ab.iga:acnc:pt:ser:qn;support vector machine;peptide binding	Volkan Uslan;Huseyin Seker	2016	2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2016.7591469	support vector machine;computer science;bioinformatics;machine learning;data mining;predictive modelling;computational model	HPC	8.784283610704717	-58.310135936274065	81427
ee82ed5abd3f68980422626e53f9f212a988b72f	explanes: exploring planes in triplet data	arabidopsis metabolism entropy statistics as topic methods	Many methods for the analysis of gene expression-, protein- or metabolite-data focus on the investigation of binary relationships, while the underlying biological processes creating this data may generate relations of higher than bivariate complexity. We give a novel method ExPlanes that helps to explore certain types of ternary relationships in a statistically robust, Bayesian framework. To arrive at an characterization of the data structure contained in triplet data we investigate 2-dimensional planes being the only linear structures that cannot be inferred from projections of the data. The key part of our methodology is the definition of a robust, Bayesian plane posterior under the assumption of an invariant prior and a Gaussian error model. A numerical representation of the plane posterior can be explored interactively. Beyond this purely Bayesian approach we can use the plane posterior to construct a family of posterior-based test statistics that allow testing the data for different plane related hypotheses. To demonstrate practicability we queried triplets of metabolic data from a plant crossing experiment for the presence of plane-, line- and point-structures by using posterior-based test statistics and were able to show their distinctiveness.	bivariate data;contain (action);data structure;gene expression;inference;interactivity;metabolic process, cellular;normal statistical distribution;numerical analysis;projections and predictions;triplet state	Bruno B. Schwenk;Joachim Selbig;Yehuda Ben-Zion;Matthias Holschneider	2010	Journal of integrative bioinformatics	10.2390/biecoll-jib-2010-132	biology;computer science;bioinformatics;machine learning;statistics	ML	5.835260125756345	-53.772109417993555	81459
38274e0d9a539f57284e861a089fc03a10e1e77b	fairdomhub: a repository and collaboration environment for sharing systems biology research		The FAIRDOMHub is a repository for publishing FAIR (Findable, Accessible, Interoperable and Reusable) Data, Operating procedures and Models (https://fairdomhub.org/) for the Systems Biology community. It is a web-accessible repository for storing and sharing systems biology research assets. It enables researchers to organize, share and publish data, models and protocols, interlink them in the context of the systems biology investigations that produced them, and to interrogate them via API interfaces. By using the FAIRDOMHub, researchers can achieve more effective exchange with geographically distributed collaborators during projects, ensure results are sustained and preserved and generate reproducible publications that adhere to the FAIR guiding principles of data stewardship.	application programming interface;biologic preservation;data steward;findability;interoperability;protocols documentation;software repository;systems biology	Katy Wolstencroft;Olga Krebs;Jacky L. Snoep;Natalie J. Stanford;Finn Bacall;Martin Golebiewski;Rostyk Kuzyakiv;Quyen Nguyen;Stuart Owen;Stian Soiland-Reyes;Jakub Straszewski;David D. van Niekerk;Alan R. Williams;Lars Malmström;Bernd Rinn;Wolfgang Müller;Carole A. Goble	2017		10.1093/nar/gkw1032	genetics;computational biology;digital library;nucleic acid;citation;systems biology;biology	HPC	-4.387147902081093	-60.73651814669901	81518
01762ce0d89d086fc64dd5ca33f6618c86b3bd0f	getting started in tiling microarray analysis	animals;mice;data interpretation statistical;deoxyribonucleases;rna messenger;signal processing computer assisted;microarray analysis;nucleosomes;algorithms;humans;computational biology;biotechnology;oligonucleotide array sequence analysis	The availability of sequenced eukaryotic genomes and commercial oligonucleotide tiling microarrays has enabled many genomics applications. Different from expression microarrays, tiling microarrays have probes that cover the entire genome or contigs of the genome in an unbiased fashion. Currently three commercial sources provide tiling microarrays with different probe lengths and spacing, and array design characteristics. Affymetrix tiles 6 million 25-mer probes per array, which offers the lowest price per probe and the highest resolution (chromosomal distance between neighboring probe centers). Its arrays use one-color assays, so individual samples are hybridized to different arrays. NimbleGen can tile 385,000 50to 75-mer probes, and Agilent can tile 244,000 60-mer probes per array. The latter two platforms, with longer oligonucleotide probes and two-color assays for which treatment and control samples are differentially labeled and put on the same array for competitive hybridization, have slightly better sensitivity. They are also flexible for custom array design, especially Agilent’s multiplex arrays, which allow multiple samples to hybridize on different subareas of the same array. These tiling arrays offer diverse genomic applications, each with its own data analysis challenges.	affymetrix;commercial sources;gper protein, human;genome;genomics;microarray;multiplexing;nucleic acid hybridization;rna probes;tiling array;tiling window manager;tracer;wang tile	Xiaole Shirley Liu	2007	PLoS Computational Biology	10.1371/journal.pcbi.0030183	computational biology;biology;microarray analysis techniques;molecular biology;tiling array;bioinformatics;microarray;nucleosome;genetics	Comp.	-0.5852985795167064	-56.400625791004416	81578
a509f04406fd1a22522d39376bd5163f76f5c8aa	model formulation: cagrid 1.0: an enterprise grid infrastructure for biomedical research	information sources;research design;mathematics and computing;application program interface;data analysis;large scale;web service resource framework;research programs;source code;clinical research;basic biological sciences;neoplasms;c codes;biomedical informatics;grid computing;use case;data base management;documentation;open source	OBJECTIVE To develop software infrastructure that will provide support for discovery, characterization, integrated access, and management of diverse and disparate collections of information sources, analysis methods, and applications in biomedical research.   DESIGN An enterprise Grid software infrastructure, called caGrid version 1.0 (caGrid 1.0), has been developed as the core Grid architecture of the NCI-sponsored cancer Biomedical Informatics Grid (caBIG) program. It is designed to support a wide range of use cases in basic, translational, and clinical research, including 1) discovery, 2) integrated and large-scale data analysis, and 3) coordinated study.   MEASUREMENTS The caGrid is built as a Grid software infrastructure and leverages Grid computing technologies and the Web Services Resource Framework standards. It provides a set of core services, toolkits for the development and deployment of new community provided services, and application programming interfaces for building client applications.   RESULTS The caGrid 1.0 was released to the caBIG community in December 2006. It is built on open source components and caGrid source code is publicly and freely available under a liberal open source license. The core software, associated tools, and documentation can be downloaded from the following URL: https://cabig.nci.nih.gov/workspaces/Architecture/caGrid.   CONCLUSIONS While caGrid 1.0 is designed to address use cases in cancer research, the requirements associated with discovery, analysis and integration of large scale data, and coordinated studies are common in other biomedical fields. In this respect, caGrid 1.0 is the realization of a framework that can benefit the entire biomedical community.	application programming interface;biomedical research;cancer bioinformatics grid;collections (publication);computation (action);deploy;documentation;epidemiologic research design;genetic translation process;grid computing;informatics (discipline);list of toolkits;nc (complexity);neoplasms;open-source license;open-source software;requirement;source code;uniform resource locator;web services resource framework;web service;world wide web;cagrid;standards characteristics	Scott Oster;Stephen Langella;Shannon Hastings;David Ervin;Ravi K. Madduri;Joshua Phillips;Tahsin M. Kurç;Frank Siebenlist;Peter A. Covitz;Krishnakant Shanbhag;Ian T. Foster;Joel H. Saltz	2008	Journal of the American Medical Informatics Association : JAMIA	10.1197/jamia.M2522	use case;clinical research;health informatics;documentation;computer science;data mining;database;data analysis;world wide web;grid computing;source code	HPC	-4.367715036343313	-60.516056263116305	81605
46ab45fddc6eaf705faef3d0022f568fc1aefe10	structural dynamics of human argonaute2 and its interaction with sirnas designed to target mutant tdp43		"""The human Argonaute2 protein (Ago2) is a key player in RNA interference pathway and small RNA recognition by Ago2 is the crucial step in siRNA mediated gene silencing mechanism. The present study highlights the structural and functional dynamics of human Ago2 and the interaction mechanism of Ago2 with a set of seven siRNAs for the first time. The human Ago2 protein adopts two conformations such as """"open"""" and """"close"""" during the simulation of 25 ns. One of the domains named as PAZ, which is responsible for anchoring the 3'-end of siRNA guide strand, is observed as a highly flexible region. The interaction between Ago2 and siRNA, analyzed using a set of siRNAs (targeting at positions 128, 251, 341, 383, 537, 1113, and 1115 of mRNA) designed to target tdp43 mutants causing Amyotrophic Lateral Sclerosis (ALS) disease, revealed the stable and strong recognition of siRNA by the Ago2 protein during dynamics. Among the studied siRNAs, the siRNA341 is identified as a potent siRNA to recognize Ago2 and hence could be used further as a possible siRNA candidate to target the mutant tdp43 protein for the treatment of ALS patients."""	amyotrophic lateral sclerosis;base pairing;decisional diffie–hellman assumption;gene silencing;gene regulatory network;interaction;interference (communication);lateral thinking;molecular dynamics;name;nucleotides;paget's disease, mammary;patients;protein argonaute-2;rna interference pathway;rna, messenger;rna, small interfering;sensitivity and specificity;simulation;strand (programming language);structural dynamics;tardbp gene;cellular targeting;free energy;interest;mutant;nervous system disorder	Vishwambhar Vishnu Bhandare;Amutha Ramaswamy	2016		10.1155/2016/8792814	biology;molecular biology;bioinformatics;trans-acting sirna;genetics	Comp.	8.43550464785668	-61.99764209630118	81626
d76f06b0156534df4d79e91a7330ffdeee04dcb3	vga: a method for viral quasispecies assembly from ultra-deep sequencing data	vga viral assembly method rare quasispecies hiv viral quasispecies real datasets synthetic datasets sequencing fragments individual barcodes sequencing errors viral genome assembler high fidelity sequencing protocol ultradeep sequencing data viral quasispecies assembly;viral assembly;protocols;viral quasispecies;viral assembly ngs viral quasispecies error correction protocol;sequential analysis;human immunodeficiency virus;assembly;error correction protocol;statistics;sequential analysis assembly protocols sociology statistics human immunodeficiency virus computer science;microorganisms diseases genomics medical computing;ngs;computer science;sociology	We present VGA, an accurate method for viral quasispecies assembly from ultra-deep sequencing data. The proposed method consists of a high-fidelity sequencing protocol and an accurate method for viral quasispecies assembly, referred to as Viral Genome Assembler (VGA). The proposed protocol is able to eliminate sequencing errors by using individual barcodes attached to the sequencing fragments. Results on both synthetic and real datasets show that our method able to accurately assemble HIV viral quasispecies and detect rare quasispecies previously undetectable due to sequencing errors. VGA outperforms state-of-the-art methods for the viral assembly. Furthermore, our method is the first viral assembly method which scales to millions of sequencing reads. Our tool VGA is freely available at http://genetics.cs.ucla.edu/vga/	assembly language;barcode;synthetic intelligence;video graphics array	Serghei Mangul;Nicholas C. Wu;Nicholas Mancuso;Alex Zelikovsky;Ren Sun;Eleazar Eskin	2014	2014 IEEE 4th International Conference on Computational Advances in Bio and Medical Sciences (ICCABS)	10.1109/ICCABS.2014.6863932	biology;communications protocol;computer science;bioinformatics;sequential analysis;virology;assembly;viral quasispecies;genetics;statistics	Visualization	1.9994958422670412	-54.53355098188908	81766
ebe38984f8b3003f02b472d993f1ee424a2b8e11	identifying novel molecular structures for advanced melanoma by ligand-based virtual screening	software;animals;mice;ligands;inhibitory concentration 50;melanoma;virtual screening;antineoplastic agents;cell line tumor;reproducibility of results;drug evaluation preclinical;humans;user computer interface;molecular structure	We recently discovered a new class of thiazole analogs that are highly potent against melanoma cells. To expand the structure-activity relationship study and to explore potential new molecular scaffolds, we performed extensive ligand-based virtual screening against a compound library containing 342,910 small molecules. Two different approaches of virtual screening were carried out using the structure of our lead molecule: (1) connectivity-based search using Scitegic Pipeline Pilot from Accelerys and (2) molecular shape similarity search using Schrodinger software. Using a testing compound library, both approaches can rank similar compounds very high and rank dissimilar compounds very low, thus validating our screening methods. Structures identified from these searches were analyzed, and selected compounds were tested in vitro to assess their activity against melanoma cancer cell lines. Several molecules showed good anticancer activity. While none of the identified compounds showed better activity than our lead compound, they provided important insight into structural modifications for our lead compound and also provided novel platforms on which we can optimize new classes of anticancer compounds. One of the newly synthesized analogs based on this virtual screening has improved potency and selectivity against melanoma.	analog;chemical library;class;cultured cell line;lead compound;ligands;molecular diagnostic techniques;non-small cell lung carcinoma;pipeline pilot;selectivity (electronic);similarity search;small molecule;thiazoles;virtual screening;cancer cell;melanoma	Zhao Wang;Yan Lu;William Seibel;Duane D. Miller;Wei Li	2009	Journal of chemical information and modeling	10.1021/ci800445a	chemistry;molecule;virtual screening;bioinformatics;organic chemistry;combinatorial chemistry;ligand;quantum mechanics	Comp.	9.754579231418678	-60.22564776688302	81768
330c3e65782b593671f9fa65544ea9fbae8d2d39	gsva: gene set variation analysis for microarray and rna-seq data	software;female;ovarian neoplasms;info eu repo semantics article;genetic variation;computational biology bioinformatics;leukemia biphenotypic acute;survival analysis;analysis of variance;algorithms;humans;sequence analysis rna;combinatorial libraries;precursor cell lymphoblastic leukemia lymphoma;computer appl in life sciences;gene expression profiling;statistics nonparametric;oligonucleotide array sequence analysis;microarrays;bioinformatics	Gene set enrichment (GSE) analysis is a popular framework for condensing information from gene expression profiles into a pathway or signature summary. The strengths of this approach over single gene analysis include noise and dimension reduction, as well as greater biological interpretability. As molecular profiling experiments move beyond simple case-control studies, robust and flexible GSE methodologies are needed that can model pathway activity within highly heterogeneous data sets. To address this challenge, we introduce Gene Set Variation Analysis (GSVA), a GSE method that estimates variation of pathway activity over a sample population in an unsupervised manner. We demonstrate the robustness of GSVA in a comparison with current state of the art sample-wise enrichment methods. Further, we provide examples of its utility in differential pathway activity and survival analysis. Lastly, we show how GSVA works analogously with data from both microarray and RNA-seq experiments. GSVA provides increased power to detect subtle pathway activity changes over a sample population in comparison to corresponding methods. While GSE methods are generally regarded as end points of a bioinformatic analysis, GSVA constitutes a starting point to build pathway-centric models of biology. Moreover, GSVA contributes to the current need of GSE methods for RNA-seq data. GSVA is an open source software package for R which forms part of the Bioconductor project and can be downloaded at http://www.bioconductor.org .	bio-informatics;bioconductor;bioinformatics;communication endpoint;dimensionality reduction;estimated;experiment;gene ontology term enrichment;gene regulatory network;generic stream encapsulation;genetic heterogeneity;microarray;molecular profiling;open-source software;r language;rna;sequence number;variable rules analysis	Sonja Hänzelmann;Robert Castelo;Justin Guinney	2012		10.1186/1471-2105-14-7	biology;molecular biology;dna microarray;analysis of variance;bioinformatics;genetic variation;survival analysis;gene expression profiling;genetics	Comp.	5.246218301026898	-52.885174748117315	81813
0122ced85e3493bfb0923baa4ae025c5c0aa27bd	combining molecular dynamics and machine learning to improve protein function recognition	binding sites;proteins;protein structure;artificial intelligence;calcium;crystal structure;machine learning;computer simulation;algorithms;structural genomics;structural similarity;thermodynamics;molecular dynamic;computational biology	As structural genomics efforts succeed in solving protein structures with novel folds, the number of proteins with known structures but unknown functions increases. Although experimental assays can determine the functions of some of these molecules, they can be expensive and time consuming. Computational approaches can assist in identifying potential functions of these molecules. Possible functions can be predicted based on sequence similarity, genomic context, expression patterns, structure similarity, and combinations of these. We investigated whether simulations of protein dynamics can expose functional sites that are not apparent to the structure-based function prediction methods in static crystal structures. Focusing on Ca2+ binding, we coupled a machine learning tool that recognizes functional sites, FEATURE, with Molecular Dynamics (MD) simulations. Treating molecules as dynamic entities can improve the ability of structure-based function prediction methods to annotate possible functional sites.	calcium ion;computation;crystal structure;entity;machine learning;molecular dynamics;pierre robin syndrome;sequence alignment;simulation	Dariya S. Glazer;Randall J. Radmer;Russ B. Altman	2008	Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing		protein structure;bioinformatics;structural similarity;molecular dynamics;artificial intelligence;machine learning;biology;protein dynamics;structural genomics	Comp.	9.218024731073347	-58.671733186614254	81904
65c756c970c11b710d5392e0ccf816e31e874c29	models and information-theoretic bounds for nanopore sequencing		Nanopore sequencing is an emerging new technology for sequencing Deoxyribonucleic acid (DNA), which can read long fragments of DNA (~50 000 bases), in contrast to most current short-read sequencing technologies which can only read hundreds of bases. While nanopore sequencers can acquire long reads, the high error rates (20%–30%) pose a technical challenge. In a nanopore sequencer, a DNA is migrated through a nanopore, and current variations are measured. The DNA sequence is inferred from this observed current pattern using an algorithm called a base-caller. In this paper, we propose a mathematical model for the “channel” from the input DNA sequence to the observed current, and calculate bounds on the information extraction capacity of the nanopore sequencer. This model incorporates impairments, such as (non-linear) inter-symbol interference, deletions, and random response. These information bounds have two-fold application: 1) The decoding rate with a uniform input distribution can be used to calculate the average size of the plausible list of DNA sequences given an observed current trace. This bound can be used to benchmark existing base-calling algorithms, as well as serving a performance objective to design better nanopores. 2) When the nanopore sequencer is used as a reader in a DNA storage system, the storage capacity is quantified by our bounds.	acid;algorithm;benchmark (computing);computer data storage;information extraction;interference (communication);mathematical model;microsequencer;nonlinear system	Wei Mao;Suhas N. Diggavi;Sreeram Kannan	2017	IEEE Transactions on Information Theory	10.1109/ISIT.2017.8006971	bioinformatics;theoretical computer science	Comp.	0.2051765803416057	-53.604771143496805	81954
41b894c3a7af531bc31ff3f501f18f45ee8825f7	multiple receptor-ligand based pharmacophore modeling and molecular docking to screen the selective inhibitors of matrix metalloproteinase-9 from natural products	matrix metalloproteinase-9;inhibitor;pharmacophore model;molecular docking;virtual screening;natural product	Matrix metalloproteinase-9 (MMP-9) is an attractive target for cancer therapy. In this study, the pharmacophore model of MMP-9 inhibitors is built based on the experimental binding structures of multiple receptor-ligand complexes. It is found that the pharmacophore model consists of six chemical features, including two hydrogen bond acceptors, one hydrogen bond donor, one ring aromatic regions, and two hydrophobic (HY) features. Among them, the two HY features are especially important because they can enter the S1' pocket of MMP-9 which determines the selectivity of MMP-9 inhibitors. The reliability of pharmacophore model is validated based on the two different decoy sets and relevant experimental data. The virtual screening, combining pharmacophore model with molecular docking, is performed to identify the selective MMP-9 inhibitors from a database of natural products. The four novel MMP-9 inhibitors of natural products, NP-000686, NP-001752, NP-014331, and NP-015905, are found; one of them, NP-000686, is used to perform the experiment of in vitro bioassay inhibiting MMP-9, and the IC50 value was estimated to be only 13.4 µM, showing the strongly inhibitory activity of NP-000686 against MMP-9, which suggests that our screening results should be reliable. The binding modes of screened inhibitors with MMP-9 active sites were discussed. In addition, the ADMET properties and physicochemical properties of screened four compounds were assessed. The found MMP-9 inhibitors of natural products could serve as the lead compounds for designing the new MMP-9 inhibitors by carrying out structural modifications in the future.		Qi Gao;Yijun Wang;Jiaying Hou;Qizheng Yao;Ji Zhang	2017	Journal of computer-aided molecular design	10.1007/s10822-017-0028-3	chemistry;bioinformatics;experimental data;docking (molecular);matrix metalloproteinase;pharmacophore;combinatorial chemistry;virtual screening;hydrogen bond;ligandscout;receptor	ML	10.000203398215392	-60.41871670642642	82027
5adc30f2b1245513fbeb3216d026ddda44f27ec6	asterias: integrated analysis of expression and acgh data using an open-source, web-based, parallelized software suite	software;animals;genomics;nucleic acid hybridization;internet;humans;user computer interface;computational biology;article;gene expression profiling;oligonucleotide array sequence analysis;programming languages;open source;automation	Asterias (http://www.asterias.info) is an open-source, web-based, suite for the analysis of gene expression and aCGH data. Asterias implements validated statistical methods, and most of the applications use parallel computing, which permits taking advantage of multicore CPUs and computing clusters. Access to, and further analysis of, additional biological information and annotations (PubMed references, Gene Ontology terms, KEGG and Reactome pathways) are available either for individual genes (from clickable links in tables and figures) or sets of genes. These applications cover from array normalization to imputation and preprocessing, differential gene expression analysis, class and survival prediction and aCGH analysis. The source code is available, allowing for extention and reuse of the software. The links and analysis of additional functional information, parallelization of computation and open-source availability of the code make Asterias a unique suite that can exploit features specific to web-based environments.	asterias (invertebrate);bibliographic reference;central processing unit;clickable;computation (action);data table;gene ontology;geo-imputation;kegg;license;minicore myopathy with external ophthalmoplegia (disorder);multi-core processor;open-source software;parallel computing;preprocessor;pubmed;reuse (action);software suite;source code;statistical imputation;tissue-specific gene expression;web application	Ramón Díaz-Uriarte;Andreu Alibés;Edward R. Morrissey;Andrés Cañada;Oscar M. Rueda;Mariana L. Neves	2007		10.1093/nar/gkm229	biology;genomics;the internet;bioinformatics;automation;gene expression profiling;genetics;nucleic acid thermodynamics	Comp.	-2.3737965686051825	-58.31544670439418	82171
379da992a2d0dd9b391dffb948d480e0e115fe67	the prints database: a fine-grained protein sequence annotation and analysis resource—its status in 2012	amino acid sequence;molecular sequence annotation;conserved sequence;proteins;humans;sequence alignment;user computer interface;amino acid motifs;databases protein	The PRINTS database, now in its 21st year, houses a collection of diagnostic protein family 'fingerprints'. Fingerprints are groups of conserved motifs, evident in multiple sequence alignments, whose unique inter-relationships provide distinctive signatures for particular protein families and structural/functional domains. As such, they may be used to assign uncharacterized sequences to known families, and hence to infer tentative functional, structural and/or evolutionary relationships. The February 2012 release (version 42.0) includes 2156 fingerprints, encoding 12 444 individual motifs, covering a range of globular and membrane proteins, modular polypeptides and so on. Here, we report the current status of the database, and introduce a number of recent developments that help both to render a variety of our annotation and analysis tools easier to use and to make them more widely available. Database URL: www.bioinf.manchester.ac.uk/dbbrowser/PRINTS/.	amino acid sequence;annotation;antivirus software;fingerprint;inference;membrane proteins;multiple sequence alignment;prints;peptide sequence;pierre robin syndrome;polypeptides;protein family;sequence motif;uniform resource locator	Terri K. Attwood;Alain Coletta;Gareth Muirhead;Athanasia Pavlopoulou;Peter B. Philippou;Ivan Popov;Carlos Romá-Mateo;Athina Theodosiou;Alex L. Mitchell	2012		10.1093/database/bas019	consensus sequence;biology;computer science;bioinformatics;simple modular architecture research tool;sequence analysis;sequence alignment;sequence database;peptide sequence;conserved sequence;conserved domain database;protein structure database;genetics;alignment-free sequence analysis	Comp.	-0.6132517907907583	-59.89610570945857	82174
b2068442608f7d8efa7e19f6c2c17b01810d06df	neural models for predicting viral vaccine targets	immunoinformatics;neural model;320299 immunology not elsewhere classified;viral vaccines;artificial neural networks;780105 biological sciences	"""We applied artificial neural networks (ANN) for the prediction of targets of immune responses that are useful for study of vaccine formulations against viral infections. Using a novel data representation, we developed a system termed MULTIPRED that can predict peptide binding to multiple related human leukocyte antigens (HLA). This implementation showed high accuracy in the prediction of the promiscuous peptides that bind to five HLA-A2 allelic variants. MULTIPRED is useful for the identification of peptides that bind multiple HLA-A2 variants as a group. By implementing ANN as a classification engine, we enabled both the prediction of peptides binding to multiple individual HLA-A2 molecules and the prediction of promiscuous binders using a single model. The ANN MULTIPRED predicts peptide binding to HLA-A*0205 with excellent accuracy (area under the receiver operating characteristic curve--AROC>0.90), and to HLA-A*0201, HLA-A*0204 and HLA-A*0206 with high accuracy (AROC>0.85). Antigenic regions with high density of binders (""""antigenic hot-spots"""") represent best targets for vaccine design. MULTIPRED not only predicts individual 9-mer binders but also predicts antigenic hot spots. Two HLA-A2 hot-spots in Severe Acute Respiratory Syndrome Coronavirus (SARS-CoV) membrane protein were predicted by using MULTIPRED."""	artificial neural network;city of heroes;coronaviridae;data (computing);exanthema;gper protein, human;hiv antigens;hla antigens;hla-dq antigens;immune response;leukocytes;membrane proteins;receiver operating characteristic;sars coronavirus;virus diseases	Guanglan Zhang;Asif M. Khan;Kellathur N. Srinivasan;J. Thomas August;Vladimir Brusic	2005	Journal of bioinformatics and computational biology	10.1142/S0219720005001466	biology;computer science;bioinformatics;virology;machine learning;immunology;artificial neural network	Comp.	9.429865682653663	-56.159700004169366	82205
309c91b864f1637c6ee5f28b02be3e63b40ac003	uorfdb—a comprehensive literature database on eukaryotic uorf biology	databases;genes;animals;alternative splicing;mice;rna messenger;databases nucleic acid;disease;yeasts;nonsense mediated mrna decay;genetic variation;rna stability;internet;promoter regions genetic;humans;ribosomes;protein biosynthesis;open reading frames	Approximately half of all human transcripts contain at least one upstream translational initiation site that precedes the main coding sequence (CDS) and gives rise to an upstream open reading frame (uORF). We generated uORFdb, publicly available at http://cbdm.mdc-berlin.de/tools/uorfdb, to serve as a comprehensive literature database on eukaryotic uORF biology. Upstream ORFs affect downstream translation by interfering with the unrestrained progression of ribosomes across the transcript leader sequence. Although the first uORF-related translational activity was observed >30 years ago, and an increasing number of studies link defective uORF-mediated translational control to the development of human diseases, the features that determine uORF-mediated regulation of downstream translation are not well understood. The uORFdb was manually curated from all uORF-related literature listed at the PubMed database. It categorizes individual publications by a variety of denominators including taxon, gene and type of study. Furthermore, the database can be filtered for multiple structural and functional uORF-related properties to allow convenient and targeted access to the complex field of eukaryotic uORF biology.	bibliographic database;color gradient;computer-mediated communication;downstream (software development);frame language;genetic translation process;open reading frame;pubmed;reading frames (nucleotide sequence);ribosomes;signal peptides;transcript;transcription initiation;translation initiation;upstream (software development)	Klaus Wethmar;Adriano Barbosa-Silva;Miguel A. Andrade-Navarro;Achim Leutz	2014		10.1093/nar/gkt952	open reading frame;biology;five prime untranslated region;molecular biology;the internet;upstream open reading frame;bioinformatics;ribosome;genetic variation;alternative splicing;gene;genetics;nonsense-mediated decay;protein biosynthesis	Comp.	0.9792103802066261	-61.369938552285376	82283
492583b3d42ce18d439a666d2825bfb89d1a93d4	a copy-number variation detection pipeline for single cell sequencing data on bgi online	pipeline;single cell sequencing;copy number variation detection;bgi online	The revolutionary invention of single-cell sequencing technology carves out a new way to delineate intra tumor heterogeneity and traces the evolution of single cells at the molecular level. To cater for fast and convenient needs in calling copy-number variations in analyzing single-cell sequencing data, a systematical protocol and a working pipeline is reported. The proposed pipeline consists of six modules in total. Every module in the pipeline is designed to achieve unitary task, and is unattached, thus facilitating user-customized applications. Our proposed pipeline is implemented on BGI Online to provide a user-friendly graphical interface for processing single-cell sequencing data. It consists of automatic and powerful functionalities that would facilitate the management of online Web modules for a full range of analysis, such as read alignment, genome bias correction, bin segmentation, copy number variants (CNVs) calling, data clustering, and visualization. The pipeline is open for public usage and its address is http://www.bgionline.cn.	borland graphics interface;cluster analysis;graphical user interface;tracing (software);usability	Jingying Huang;Yuwen Zhou;Aodan Xu;Enhong Zhuo;Xin Jin;Hongmin Cai	2017	2017 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2017.8217656	bioinformatics;data visualization;bin;genomics;computer science;single cell sequencing;visualization;cluster analysis;copy-number variation;graphical user interface	Visualization	-2.2892300213843395	-58.01823379560283	82497
8c82e2fca9a7be0c4a4fa0f949333927ddc169e0	computer-aided drug discovery research at a global contract research organization	chemical library design;computer-aided drug discovery;docking;drug-likeness;virtual screening	Computer-aided drug discovery started at Albany Molecular Research, Inc in 1997. Over nearly 20 years the role of cheminformatics and computational chemistry has grown throughout the pharmaceutical industry and at AMRI. This paper will describe the infrastructure and roles of CADD throughout drug discovery and some of the lessons learned regarding the success of several methods. Various contributions provided by computational chemistry and cheminformatics in chemical library design, hit triage, hit-to-lead and lead optimization are discussed. Some frequently used computational chemistry techniques are described. The ways in which they may contribute to discovery projects are presented based on a few examples from recent publications.	approximation algorithm;binding sites;boat dock;buffalo airstation;calorimetry;chemical library;cheminformatics;chemistry techniques, analytical;computation;computational chemistry;computer;computer-aided design;covalent interaction;database;databases;decipher prostate cancer test;design of experiments;docking (molecular);docking -molecular interaction;dosage forms;drug discovery;energy, physics;estimated;experiment;genetic translation process;halogens;image analysis;machine learning;mathematical optimization;medicinal chemistry;one thousand;organizing (structure);persistence (computer science);polytetrafluoroethylene;sampling (signal processing);score;simulation;surface plasmon resonance;synthetic intelligence;terabyte;thrombocytopenia;titration method;translational medical research;triage;video-in video-out;research center	Douglas B. Kitchen	2017	Journal of computer-aided molecular design	10.1007/s10822-016-9991-3	pharmacology;bioinformatics;data science;combinatorial chemistry	ML	1.0966533899514286	-64.42034228696384	82620
3bd121434614c8c5cdcb90590e7799798c790ad6	role of stable isotopes in life—testing isotopic resonance hypothesis	roman a zubarev 稳定同位素 同位素测试 共振现象 假说 生活 同位素丰度 生物元素 生物过程 role of stable isotopes in life testing isotopic resonance hypothesis;origin of life;stable isotope;isotopic resonance	"""Stable isotopes of most important biological elements, such as C, H, N and O, affect living organisms. In rapidly growing species, deuterium and to a lesser extent other heavy isotopes reduce the growth rate. At least for deuterium it is known that its depletion also negatively impacts the speed of biological processes. As a rule, living organisms """"resist"""" changes in their isotopic environment, preferring natural isotopic abundances. This preference could be due to evolutionary optimization; an additional effect could be due to the presence of the """"isotopic resonance"""". The isotopic resonance phenomenon has been linked to the choice of earliest amino acids, and thus affected the evolution of genetic code. To test the isotopic resonance hypothesis, literature data were analyzed against quantitative and qualitative predictions of the hypothesis. Four studies provided five independent datasets, each in very good quantitative agreement with the predictions. Thus, the isotopic resonance hypothesis is no longer simply plausible; it can now be deemed likely. Additional testing is needed, however, before full acceptance of this hypothesis."""	amino acid metabolism, inborn errors;biological processes;depletion region;deuterium;genetic code;isotopes;mathematical optimization;mike lesser;organism;resonance;terrestrial television	Roman A. Zubarev	2011		10.1016/S1672-0229(11)60003-X	biology;abiogenesis;stable isotope ratio;paleontology;ecology	Comp.	6.2434730843692305	-64.41538599804372	82689
c67f07cd6713d06d131dfc8cf42786dbb62d379a	beam: a beam search algorithm for the identification of cis-regulatory elements in groups of genes	motif finder;bounded search;search space;efficient algorithm;gene regulation;search algorithm;transcription factor binding site;regulatory element;transcription factor binding sites;objective function;gene expression;protein binding;promoter motifs;failure rate;dna sequence;coregulated genes	The identification of potential protein binding sites (cis-regulatory elements) in the upstream regions of genes is key to understanding the mechanisms that regulate gene expression. To this end, we present a simple, efficient algorithm, BEAM (beam-search enumerative algorithm for motif finding), aimed at the discovery of cis-regulatory elements in the DNA sequences upstream of a related group of genes. This algorithm dramatically limits the search space of expanded sequences, converting the problem from one that is exponential in the length of motifs sought to one that is linear. Unlike sampling algorithms, our algorithm converges and is capable of finding statistically overrepresented motifs with a low failure rate. Further, our algorithm is not dependent on the objective function or the organism used. Limiting the space of candidate motifs enables the algorithm to focus only on those motifs that are most likely to be biologically relevant and enables the algorithm to use direct evaluations of background frequencies instead of resorting to probabilistic estimates. In addition, limiting the space of candidate motifs makes it possible to use computationally expensive objective functions that are able to correctly identify biologically relevant motifs.		Jonathan M. Carlson;Arijit Chakravarty;Robert H. Gross	2006	Journal of computational biology : a journal of computational molecular cell biology	10.1089/cmb.2006.13.686	biology;molecular biology;bioinformatics;genetics;dna binding site	Comp.	0.7810835500929668	-53.58134746111076	82834
21e9e0e69d7f7c7a3682ed0cc5f8ec8ae9ef16d2	related enhancers in the intron of the beta1 tubulin gene of drosophila melanogaster are essential for maternal and cns-specific expression during embryogenesis	genes;animals;female;dna binding proteins;rna messenger;introns;animals genetically modified;sequence deletion;tissue distribution;tubulin;nuclear proteins;oogenesis;gene expression regulation developmental;drosophila melanogaster;embryo;molecular sequence data;enhancer of transcription;base sequence;central nervous system;genes insect;enhancer elements genetic	Expression of the beta1 tubulin gene of Drosophila melanogaster is under complex developmental control. For high levels of transcription in the embryonic central nervous system (CNS) different modules dispersed over 3 kb have to co-operate. Combination of a core promoter with either far upstream localized enhancer elements or, alternatively, with an enhancer from the intron results in expression limited to only a few neuronal cells. Cooperation of all three modules, however, leads to high level expression in most neuronal cells of the CNS. In the intron, we identified a 6 bp core element which is essential for transcription in the CNS, as well as an 8 bp element required for maternal expression. Interestingly, both motifs are quite similar, with CAAAAT as the CNS core and CAAAAAT as the maternal enhancer core. Specific binding of proteins from nuclear extracts to the CNS-specific element could be demonstrated. We suggest that the beta1 tubulin gene represents an ideal marker gene to elucidate connections between pro-neural or neurogenic genes and downstream target genes throughout the CNS.	cns disorder;downstream (software development);embryonic development;enhancer elements, genetic;enhancer of transcription;gene regulatory network;high-level programming language;introns;transcription (software)	Jörg Köhler;Sabine Schäfer-Preuss;Detlev Buttgereit	1996	Nucleic acids research	10.1093/nar/24.13.2543	biology;intron;embryo;dna-binding protein;molecular biology;enhancer trap;central nervous system;tubulin;enhancer;nuclear protein;gene;oogenesis;genetics	Comp.	5.308340764199153	-62.96678765009143	82870
bf88d77369054ce1138c91a1cab1a792c1894d0e	meta-storms: efficient search for similar microbial communities based on a novel indexing scheme and similarity score for metagenomic data	caries;diversity;biosphere;mathematics;convergence;technology;physical sciences;biochemical research methods;statistics probability;gut microbiome;relevant;science technology;computer science interdisciplinary applications;biotechnology applied microbiology;life sciences biomedicine;diet;biochemistry molecular biology;mathematical computational biology;computer science	BACKGROUND It has long been intriguing scientists to effectively compare different microbial communities (also referred as 'metagenomic samples' here) in a large scale: given a set of unknown samples, find similar metagenomic samples from a large repository and examine how similar these samples are. With the current metagenomic samples accumulated, it is possible to build a database of metagenomic samples of interests. Any metagenomic samples could then be searched against this database to find the most similar metagenomic sample(s). However, on one hand, current databases with a large number of metagenomic samples mostly serve as data repositories that offer few functionalities for analysis; and on the other hand, methods to measure the similarity of metagenomic data work well only for small set of samples by pairwise comparison. It is not yet clear, how to efficiently search for metagenomic samples against a large metagenomic database.   RESULTS In this study, we have proposed a novel method, Meta-Storms, that could systematically and efficiently organize and search metagenomic data. It includes the following components: (i) creating a database of metagenomic samples based on their taxonomical annotations, (ii) efficient indexing of samples in the database based on a hierarchical taxonomy indexing strategy, (iii) searching for a metagenomic sample against the database by a fast scoring function based on quantitative phylogeny and (iv) managing database by index export, index import, data insertion, data deletion and database merging. We have collected more than 1300 metagenomic data from the public domain and in-house facilities, and tested the Meta-Storms method on these datasets. Our experimental results show that Meta-Storms is capable of database creation and effective searching for a large number of metagenomic samples, and it could achieve similar accuracies compared with the current popular significance testing-based methods.   CONCLUSION Meta-Storms method would serve as a suitable database management and search system to quickly identify similar metagenomic samples from a large pool of samples.   CONTACT ningkang@qibebt.ac.cn   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	3-iodobenzylguanidine;bioinformatics;community;database;deletion mutation;greater than;indexes;insertion mutation;meta-object facility;metagenomics;phylogenetics;search - action;software repository;taxonomy (general);interest	Xiaoquan Su;Jian Xu;Kang Ning	2012	Bioinformatics	10.1093/bioinformatics/bts470	biology;biosphere;convergence;computer science;bioinformatics;data science;data mining;technology	DB	-0.2808283611039937	-56.2549862239481	82926
02e821951b6db1e030d46d2c23da6aa885ed8f35	simple adjustment of the sequence weight algorithm remarkably enhances psi-blast performance	computational biology bioinformatics;algorithms;computer appl in life sciences;microarrays;bioinformatics	PSI-BLAST, an extremely popular tool for sequence similarity search, features the utilization of Position-Specific Scoring Matrix (PSSM) constructed from a multiple sequence alignment (MSA). PSSM allows the detection of more distant homologs than a general amino acid substitution matrix does. An accurate estimation of the weights for sequences in an MSA is crucially important for PSSM construction. PSI-BLAST divides a given MSA into multiple blocks, for which sequence weights are calculated. When the block width becomes very narrow, the sequence weight calculation can be odd. We demonstrate that PSI-BLAST indeed generates a significant fraction of blocks having width less than 5, thereby degrading the PSI-BLAST performance. We revised the code of PSI-BLAST to prevent the blocks from being narrower than a given minimum block width (MBW). We designate the modified application of PSI-BLAST as PSI-BLASTexB. When MBW is 25, PSI-BLASTexB notably outperforms PSI-BLAST consistently for three independent benchmark sets. The performance boost is even more drastic when an MSA, instead of a sequence, is used as a query. Our results demonstrate that the generation of narrow-width blocks during the sequence weight calculation is a critically important factor that restricts the PSI-BLAST search performance. By preventing narrow blocks, PSI-BLASTexB upgrades the PSI-BLAST performance remarkably. Binaries and source codes of PSI-BLASTexB (MBW = 25) are available at https://github.com/kyungtaekLIM/PSI-BLASTexB .	amino acid substitution;amino acids;blast;benchmark (computing);block cipher;code;dna polymerase iii, clamp loader chi/psi subcomplex;hl7publishingsubsection <query>;homology (biology);less than;mbrwizard;mobitz type ii atrioventricular block;multiple sequence alignment;position weight matrix;revision procedure;similarity search;substitution matrix;tpo wt allele;algorithm;width	Toshiyuki Oda;Kyungtaek Lim;Kentaro Tomii	2017		10.1186/s12859-017-1686-9	substitution matrix;dna microarray;multiple sequence alignment;matrix (mathematics);bioinformatics;nearest neighbor search;computer science	HPC	-1.7326371874763007	-53.6501217241431	83402
c1a6b01f4c804b0848792677586175c89a07d101	transcript-based reannotation for microarray probesets	gene expression data integration;mrna sequence alignment;microarray probe reannotation;differential expression	DNA microarrays are one of the most used technologies for gene expression measurement. However, there are several distinct microarray platforms, from different manufacturers, each with its own measurement protocol, resulting in data that can hardly be compared or directly integrated. Data integration from multiple sources aims to improve the assertiveness of statistical tests, reducing the data dimensionality problem. This work intends to establish a basis for the integration of gene expression measurements from several manufacturers, a problem that can be addressed at different levels. We will focus on the reannotation process, a cornerstone of multi-platform integration. The proposed approach is based on a reannotation from probesets to transcripts, preserving valuable information for further analysis. Gene expression data from glioblastoma studies will be used as case studies, considering data from Agilent and Affymetrix platforms.	dna microarray	Eduardo Valente;Miguel Rocha	2015		10.1145/2695664.2695704	bioinformatics;data mining;microarray databases	Comp.	4.931025771829133	-52.64255585020199	83429
3e04e86a623ad5a118a2bf6940934c33f442a9d6	cyanolyase: a database of phycobilin lyase sequences, motifs and functions	software;selected works;lyases;molecular sequence annotation;rhodophyta;internet;phycobiliproteins;bepress;phycobilins;amino acid motifs;cyanobacteria;sequence analysis protein;databases protein	CyanoLyase (http://cyanolyase.genouest.org/) is a manually curated sequence and motif database of phycobilin lyases and related proteins. These enzymes catalyze the covalent ligation of chromophores (phycobilins) to specific binding sites of phycobiliproteins (PBPs). The latter constitute the building bricks of phycobilisomes, the major light-harvesting systems of cyanobacteria and red algae. Phycobilin lyases sequences are poorly annotated in public databases. Sequences included in CyanoLyase were retrieved from all available genomes of these organisms and a few others by similarity searches using biochemically characterized enzyme sequences and then classified into 3 clans and 32 families. Amino acid motifs were computed for each family using Protomata learner. CyanoLyase also includes BLAST and a novel pattern matching tool (Protomatch) that allow users to rapidly retrieve and annotate lyases from any new genome. In addition, it provides phylogenetic analyses of all phycobilin lyases families, describes their function, their presence/absence in all genomes of the database (phyletic profiles) and predicts the chromophorylation of PBPs in each strain. The site also includes a thorough bibliography about phycobilin lyases and genomes included in the database. This resource should be useful to scientists and companies interested in natural or artificial PBPs, which have a number of biotechnological applications, notably as fluorescent markers.	algae;amino acid [epc];blast;bibliography;binding sites;clans;classification;covalent interaction;cyanobacteria;database;genome;ligation;lyase;pattern matching;phycobilins;phycobiliproteins;phycobilisomes;phylogenetics;rhodophyta;sequence motif	Anthony Bretaudeau;François Coste;Florian Humily;Laurence Garczarek;Gildas Le Corguillé;Christophe Six;Morgane Ratin;Olivier Collin;Wendy M. Schluchter;Frédéric Partensky	2013		10.1093/nar/gks1091	biology;botany;the internet;bioinformatics;phycobiliprotein;genetics	Comp.	-0.6549937472125558	-59.5782889967281	83500
5f8c11e1d8a831a0cd1985511fc1cdc6b3d0379e	a new approach to predict interactions between integral membrane proteins in yeast	budding yeast;biology computing;evolutionary computation;saccharomyces cerevisiae;genomic context;proteins biology computing genetics molecular biophysics;protein protein interactions;genetics;predict interactions;biomembranes;domain domain interaction;fungi;false positive rate;proteins;yeast two hybrid assay;molecular biophysics;protein protein interaction;true positive;genomic context predict interactions integral membrane proteins protein protein interactions saccharomyces cerevisiae domain domain interaction protein protein interaction;membrane protein;integral membrane proteins	Protein-protein interactions (PPIs) play an extremely important role in performing a variety of biological functions. The interactomes of several model organisms including budding yeast Saccharomyces cerevisiae have recently been studied using experimental techniques such as the yeast two-hybrid assay. However, these techniques are generally biased against integral membrane proteins due to their intrinsic limitations. Given the fact that the interactions between integral membrane proteins cover a large fraction of the whole interactome, we report a study of predicting interactions between integral membrane proteins in yeast by a quantitative model We integrate protein-protein interaction and domain-domain interaction (DDI) data from disparate sources and apply a log likelihood scoring method on all putative integral membrane proteins in yeast to predict their interactions based on a cut-off threshold. We show that our approach improves on other predictive approaches when tested on a ldquogold-standardrdquo data set and achieves 74.6% true positive rate at the expense of 0.43% false positive rate. Furthermore, we find that two integral membrane proteins are more likely to interact with each other if they share more common interaction partners. This study allows us to reach a more extensive understanding of the yeast integral membrane proteins from a network view, which also complements the previous prediction approaches based on the genomic context.	design of experiments;interaction;interactome;sensitivity and specificity;two-hybrid screening	Kelvin Xi Zhang;B. F. Francis Ouellette	2008	2008 IEEE Congress on Evolutionary Computation (IEEE World Congress on Computational Intelligence)	10.1109/CEC.2008.4631033	protein–protein interaction;computer science;bioinformatics;evolutionary computation;molecular biophysics	Comp.	6.770681835637046	-57.628240677210194	83508
8a03a9158734f412fc465712abf6156ee02e83cc	focus: a new multilayer graph model for short read analysis and extraction of biologically relevant features	data mining;metagenomics;graph modeling;next generation sequencing	With the increasing number of applications in which a group of organisms associated with a common environment are sequenced, there is an urgent need for a new model for representing the sequenced short reads in a way that takes the nature of these organisms into consideration. In addition to facilitating the assembly process, such new models should allow for easy extraction of other useful biological information from the short reads, including conserved regions among the input genomics, sequence motifs, and other information critical to the recognition and/or classification of the organisms. We present Focus, a new multilayer graph model for short read analysis and extraction of biologically relevant features. The proposed model can be viewed as a data-mining tool that takes advantage of the multilayer graph representation of the reads to extract useful information about the associated genomes/organisms. While not primarily an assembly tool, we assessed Focus using known assemblers with excellent results. We also applied Focus in a case study on a HIV read dataset and were able to successfully extract biologically relevant graph features.	data mining;focus;graph (abstract data type);sequence motif	Julia Warnke-Sommer;Hesham H. Ali	2014		10.1145/2649387.2649434	biology;dna sequencing;bioinformatics;machine learning;data mining;metagenomics	Comp.	2.919322079700407	-57.76586913689468	83533
68cbeafa3abc793e6d7df95b7ff9bc02d2f51df9	comparison of affymetrix data normalization methods using 6,926 experiments across five array generations	microarray data;311 basic medicine;data integrity;318 medical biotechnology;oligonucleotide microarray;housekeeping gene;217 medical engineering;gene expression data;method integration;a1 refereed journal article;312 clinical medicine;computational biology bioinformatics;gene expression;weibull distribution;statistical distributions;algorithms;118 biological sciences;combinatorial libraries;computational biology;data preprocessing;computer appl in life sciences;gene expression profiling;oligonucleotide array sequence analysis;microarrays;bioinformatics	Gene expression microarray technologies are widely used across most areas of biological and medical research. Comparing and integrating microarray data from different experiments would be very useful, but is currently very challenging due to the experimental and hybridization conditions, as well as data preprocessing and normalization methods. Furthermore, even in the case of the widely-used, industry-standard Affymetrix oligonucleotide microarrays, the various array generations have different probe sets representing different genes, hindering the data integration. In this study our objective is to find systematic approaches to normalize the data emerging from different Affymetrix array generations and from different laboratories. We compare and assess the accuracy of five normalization methods for Affymetrix gene expression data using 6,926 Affymetrix experiments from five array generations. The methods that we compare include 1) standardization, 2) housekeeping gene based normalization, 3) equalized quantile normalization, 4) Weibull distribution based normalization and 5) array generation based gene centering. Our results indicate that the best results are achieved when the data is normalized first within a sample and then between-samples with Array Generation based gene Centering (AGC) normalization. We conclude that with the AGC method integrating different Affymetrix datasets results in values that are significantly more comparable across the array generations than in the cases where no array generation based normalization is used. The AGC method was found to be the best method for normalizing the data from several different array generations, and achieve comparable gene values across thousands of samples.	affymetrix;atypical glandular cell;automatic gain control;data pre-processing;database normalization;experiment;gene co-expression network;gene expression profiling;laboratory;microarray;normalize;nucleic acid hybridization;preprocessor	Reija Autio;Sami Kilpinen;Matti Saarela;Olli-P. Kallioniemi;Sampsa Hautaniemi;Jaakko Astola	2009	BMC Bioinformatics	10.1186/1471-2105-10-S1-S24	probability distribution;biology;weibull distribution;microarray analysis techniques;molecular biology;gene chip analysis;gene expression;dna microarray;computer science;bioinformatics;data integrity;data mining;housekeeping gene;data pre-processing;gene expression profiling;genetics	Comp.	4.661822959302249	-52.578481196362226	83558
6f30b6d6a4b23edf4917b2ad18f086e6b4b46538	an exploration of some factors affecting the correlation of mrna and proteomic data	domain knowledge;proteome analysis;life prediction;protein expression;metabolic pathway;high throughput;correlation coefficient;mrna expression	  The recent availability of technologies for high throughput proteome analysis has led to the emergence of integrated mRNA  and protein expression data. In one such study by Ideker and co-workers, changes in mRNA and protein abundance levels were  quantified following systematic perturbation of a specific metabolic pathway [1]. The authors calculated an overall Pearson  correlation coefficient between changes in mRNA and protein expression of 0.61, however, no change in protein expression was  observed for almost 80% of genes reported as having a significant change in mRNA indicating that a complex relationship exists  between mRNA and protein expression. To try and address this issue, the data were sorted according to various criteria: protein  and mRNA expression ratios, confidence values, length of protein, fraction of cysteine residues and half-life prediction,  to try and identify any bias in experimental technique which may affect the correlation. mRNA expression ratio and the confidence  value had the strongest affect on how well the data correlated, whilst protein detection was weakly dependent on the fraction  of cysteine residues in the protein. Initial investigations have indicated that integrating the data with domain knowledge  provides the best opportunity for distinguishing between those transcriptome results which may be interpreted in a straightforward  manner and those which should be treated with caution.    	proteomics	Catherine J. Hack;Jesús Adrián López	2004		10.1007/978-3-540-30478-4_2	biology;molecular biology;cell biology;bioinformatics	HCI	7.211385402119402	-57.823314199621294	83576
34a00d32156cd30ad24b850778b69136857077db	from pull-down data to protein interaction networks and complexes with biological relevance	protein complex;saccharomyces cerevisiae;proteine;interaction moleculaire;molecular interaction;mass spectrometry;false negative;pertinencia;bioinformatique;reseau;red;statistical evaluation;interaccion molecular;pertinence;protein protein interaction;ornl;proteina;relevance;bioinformatica;false positive;high throughput;protein;network;protein interaction network;bioinformatics;gene ontology	MOTIVATION Recent improvements in high-throughput Mass Spectrometry (MS) technology have expedited genome-wide discovery of protein-protein interactions by providing a capability of detecting protein complexes in a physiological setting. Computational inference of protein interaction networks and protein complexes from MS data are challenging. Advances are required in developing robust and seamlessly integrated procedures for assessment of protein-protein interaction affinities, mathematical representation of protein interaction networks, discovery of protein complexes and evaluation of their biological relevance.   RESULTS A multi-step but easy-to-follow framework for identifying protein complexes from MS pull-down data is introduced. It assesses interaction affinity between two proteins based on similarity of their co-purification patterns derived from MS data. It constructs a protein interaction network by adopting a knowledge-guided threshold selection method. Based on the network, it identifies protein complexes and infers their core components using a graph-theoretical approach. It deploys a statistical evaluation procedure to assess biological relevance of each found complex. On Saccharomyces cerevisiae pull-down data, the framework outperformed other more complicated schemes by at least 10% in F(1)-measure and identified 610 protein complexes with high-functional homogeneity based on the enrichment in Gene Ontology (GO) annotation. Manual examination of the complexes brought forward the hypotheses on cause of false identifications. Namely, co-purification of different protein complexes as mediated by a common non-protein molecule, such as DNA, might be a source of false positives. Protein identification bias in pull-down technology, such as the hydrophilic bias could result in false negatives.	affinity analysis;annotation;chamaecyparis lawsoniana;expedited report;gene ontology term enrichment;graph - visual representation;graph theory;high-throughput computing;inference;interaction network;mass spectrometry;mathematics;numerous;purification of quantum state;relevance;selection (genetic algorithm);sensor;staphylococcal protein a;throughput;protein protein interaction	Bing Zhang;Byung-Hoon Park;Tatiana V. Karpinets;Nagiza F. Samatova	2008	Bioinformatics	10.1093/bioinformatics/btn036	protein–protein interaction;high-throughput screening;biology;relevance;mass spectrometry;type i and type ii errors;bioinformatics;multiprotein complex;genetics	Comp.	5.095263176025865	-56.443532332311875	83630
883f8be889f401d9d1913557037babd48f4065b2	chromosome segregation in escherichia coli division: a free energy-driven string model	escherichia coli;prokaryotic cell division;structure optimization;langevin equation;chromosome segregation;structural change;locally compact;force field;cell division;self organization;free energy;dna compaction	Although the mechanisms of eukaryotic chromosome segregation and cell division have been elucidated to a certain extent, those for bacteria remain largely unknown. Here we present a computational string model for simulating the dynamics of Escherichia coli chromosome segregation. A novel thermal-average force field accounting for stretching, bending, volume exclusion, friction and random fluctuation is introduced. A Langevin equation is used to simulate the chromosome structural changes. The mechanism of chromosome segregation is thereby postulated as a result of free energy-driven structural optimization with replication introduced chromosomal mass increase. Predictions of the model agree well with observations of fluorescence labeled chromosome loci movement in living cells. The results demonstrate the possibility of a mechanism of chromosome segregation that does not involve cytoskeletal guidance or advanced apparatus in an E. coli cell. The model also shows that DNA condensation of locally compacted domains is a requirement for successful chromosome segregation. Simulations also imply that the shape-determining protein MreB may play a role in the segregation via modification of the membrane pressure.		Jianmiao Fan;Kagan Tuncay;Peter J. Ortoleva	2007	Computational biology and chemistry	10.1016/j.compbiolchem.2007.05.003	biology;molecular biology;genetics;cell division	Comp.	6.942130812547386	-63.88437195974032	83709
1540c4f0f5bd040f6cbdf481e14cec40c8f85673	molden 2.0: quantum chemistry meets proteins	molecular visualisation;molecular modelling;quantum mechanics;electrostatic potential;electron density;protein manipulation	Since the first distribution of Molden in 1995 and the publication of the first article about this software in 2000 work on Molden has continued relentlessly. A few of the many improved or fully novel features such as improved and broadened support for quantum chemistry calculations, preparation of ligands for use in drug design related softwares, and working with proteins for the purpose of ligand docking.	acclimatization;boat dock;converter device component;docking (molecular);docking -molecular interaction;drug design;ewald summation;goto;license;ligands;mopac;molden;movies;openbabel;organic chemistry phenomena;over-the-top content;pharmacophore;sane;small molecule;web search engine;quantum chemistry	Gijs Schaftenaar;Elias Vlieg;Gert Vriend	2017		10.1007/s10822-017-0042-5	chemistry;computational chemistry;molecular docking simulation;nanotechnology;quantum chemistry	Comp.	1.9630623411446384	-64.97369987139693	83711
84cb4a8891a9be7b400004c6d5efa8696346eb49	aligning 415 519 proteins in less than two hours on pc				Sebastian Deorowicz;Agnieszka Debudaj-Grabysz;Adam Gudys	2016	CoRR		computer science;bioinformatics;data mining;world wide web	NLP	-0.0993194403945111	-63.004075774741025	83816
c73d0b8639b595eb45053aad23e19d77c4db092c	an efficient network motif discovery approach for co-regulatory networks		Co-regulatory networks, which consist of transcription factors (TFs), micro ribose nucleic acids (miRNAs), and target genes, have provided new insight into biological processes, revealing complicated and comprehensive regulatory relationships between biomolecules. To uncover the key co-regulatory mechanisms between these biomolecules, the identification of co-regulatory motifs has become beneficial. However, due to high-computational complexity, it is a hard task to identify co-regulatory network motifs with more than four interacting nodes in large-scale co-regulatory networks. To overcome this limitation, we propose an efficient algorithm, named large co-regulatory network motif (LCNM), to detect large co-regulatory network motifs. This algorithm is able to store a set of co-regulatory network motifs within a  $G$ -tries structure. Moreover, we propose two ways to generate candidate motifs. For three- or four-interacting-node motifs, LCNM is able to generate all different types of motif through an enumeration method. For larger network motifs, we adopt a sampling method to generate candidate co-regulatory motifs. The experimental results demonstrate that LCNM cannot only improve the computational performance in exhaustive identification of all of the three- or four-node motifs but can also identify co-regulatory network motifs with a maximum of eight nodes. In addition, we implement a parallel version of our LCNM algorithm to further accelerate the motif detection process.	algorithm;computation;computational complexity theory;interaction;sampling (signal processing);sequence motif;transcription (software)	Jiawei Luo;Lv Ding;Cheng Liang;Nguyen Hoang Tu	2018	IEEE Access	10.1109/ACCESS.2018.2796565	computational complexity theory;distributed computing;network motif;computer science;bioinformatics	Comp.	2.8535263954976178	-57.47491322087489	83897
48699b603022871d78033466be59fc79e0c8a660	pseudomap: an innovative and comprehensive resource for identification of sirna-mediated mechanisms in human transcribed pseudogenes	transcription genetic;animals;mice;databases genetic;pseudogenes;sequence analysis dna;internet;gene expression regulation;rna small interfering;humans;user computer interface;micrornas;article	RNA interference (RNAi) is a gene silencing process within living cells, which is controlled by the RNA-induced silencing complex with a sequence-specific manner. In flies and mice, the pseudogene transcripts can be processed into short interfering RNAs (siRNAs) that regulate protein-coding genes through the RNAi pathway. Following these findings, we construct an innovative and comprehensive database to elucidate siRNA-mediated mechanism in human transcribed pseudogenes (TPGs). To investigate TPG producing siRNAs that regulate protein-coding genes, we mapped the TPGs to small RNAs (sRNAs) that were supported by publicly deep sequencing data from various sRNA libraries and constructed the TPG-derived siRNA-target interactions. In addition, we also presented that TPGs can act as a target for miRNAs that actually regulate the parental gene. To enable the systematic compilation and updating of these results and additional information, we have developed a database, pseudoMap, capturing various types of information, including sequence data, TPG and cognate annotation, deep sequencing data, RNA-folding structure, gene expression profiles, miRNA annotation and target prediction. As our knowledge, pseudoMap is the first database to demonstrate two mechanisms of human TPGs: encoding siRNAs and decoying miRNAs that target the parental gene. pseudoMap is freely accessible at http://pseudomap.mbc.nctu.edu.tw/. Database URL: http://pseudomap.mbc.nctu.edu.tw/	101 mouse;access network;aleurites (plant);annotation;anti-thrombin unit;compiler;database;deep sequencing;diptera;experiment;gene silencing;gene regulatory network;genes, vif;interaction;interference (communication);internal transcribed spacer;john r. rice (computer scientist);libraries;long-term support;moe;micrornas;national supercomputer centre in sweden;ninety nine;pseudogenes;rna interference;rna, small interfering;transcript;uniform resource locator;alcoholism treatment unit;asulacrine;positive regulation of deadenylation-independent decapping of nuclear-transcribed mrna	Wen-Ling Chan;Wen-Kuang Yang;Hsien-Da Huang;Jan-Gowth Chang	2013		10.1093/database/bat001	biology;molecular biology;the internet;regulation of gene expression;bioinformatics;trans-acting sirna;genetics;pseudogene;microrna	Comp.	0.6871834980245098	-60.14867115413681	84053
66cf1c39d205c48e4e1eb17dc35488f7c59b4b38	ariadne: pattern-directed inference and hierarchical abstraction in protein structure recognition	higher order;protein structure;molecular structure	The macro-molecular structural conformations of proteins exhibit higher order regularities whose recognition is complicated by many factors. ARIADNE searches for similarities between structural descriptors and hypothesized protein structure at levels more abstract than the primary sequence.		Richard H. Lathrop;Teresa A. Webster;Temple F. Smith	1987	Commun. ACM	10.1145/32206.32207	protein structure;higher-order logic;molecule;computer science;bioinformatics;programming language;algorithm	Comp.	7.53997917381433	-62.75189570350464	84155
a672b53a694b2c45f84b39daa12ddc648ff6fd0f	a new approach in applying systems engineering tools and analysis to determine hepatocyte toxicogenomics risk levels to human health	hepatocyte;systems engineering;risk threshold and systems biology;toxicology;toxicity;mahalanobis;toxicogenomics	There is an increasing backlog of potentially toxic compounds that cannot be evaluated with current animal-based approaches in a cost-effective and expeditious manner, thus putting human health at risk. Extrapolation of animal-based test results for human risk assessment often leads to different physiological outcomes. This article introduces the use of quantitative tools and methods from systems engineering to evaluate the risk of toxic compounds by the analysis of the amount of stress that human hepatocytes undergo in vitro when metabolizing GW7647 1 over extended times and concentrations. Hepatocytes are exceedingly connected systems that make it challenging to understand the highly varied dimensional genomics data to determine risk of exposure. Gene expression data of peroxisome proliferator-activated receptor-α (PPARα) 2 binding was measured over multiple concentrations and varied times of GW7647 exposure and leveraging mahalanombis distance to establish toxicity threshold risk levels. The application of these novel systems engineering tools provides new insight into the intricate workings of human hepatocytes to determine risk threshold levels from exposure. This approach is beneficial to decision makers and scientists, and it can help reduce the backlog of untested chemical compounds due to the high cost and inefficiency of animal-based models.	adverse reaction to drug;chemicals;extrapolation;gene expression;genomics;hepatocyte;peroxisome proliferators;risk assessment;systems engineering;toxic effect;toxicogenomics	James Gigrich;Shahryar Sarkani;Thomas Holzer	2017	Journal of computational biology : a journal of computational molecular cell biology	10.1089/cmb.2016.0073	pharmacology;biology;toxicology;bioinformatics;mahalanobis distance;toxicity;toxicogenomics	Comp.	7.816902887559749	-61.03460158897826	84225
32ff567150018548364e2a0cdc01aa67731a3138	inchi - the worldwide chemical structure standard	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;computer applications in chemistry;theoretical and computational chemistry;computational biology bioinformatics;uk phd theses thesis;life sciences;uk research reports;medical journals;europe pmc;documentation and information in chemistry;biomedical research;bioinformatics	Progress of the IUPAC InChI/InChIKey project continues to move ahead with many new features and support. A collection of four short videos explaining the InChI project have been produced and are available via the InChI Trust web site. Use of the algorithm has increased over the past year to the point that numerous publications use and refer to InChI. Publicity for the project is good and has resulted in considerable increase in the usage of the InChI algorithm. The Trust web site is now available to the public and is updated regularly. Even CAS now allows for an InChI string to be used as input for a SciFinder search and the Sigma-Aldrich catalogue is InChI searchable. Extensions to the project’s current capabilities, such as InChI for chemical reactions, are being developed by a number of expert, experienced individuals and groups from various areas of chemistry. This poster presentation will describe the current technical state of the InChI algorithm and how the InChI Trust is working to assure the continued support and delivery of the InChI algorithm.	algorithm;inchi;ws-trust	Stephen R. Heller	2013		10.1186/1758-2946-6-S1-P4	biology;medical research;medicine;computer science;bioinformatics;data science	Web+IR	-3.402089229756775	-62.45178027175441	84333
cfa96f6d60f6ad3c954bae608289e4009841bad2	tape measure protein having mt3 motif facilitates phage entry into stationary phase cells of mycobacterium tuberculosis	mycobacteriophage;stationary phase;luciferase reporter phage assay;experimental evaluation;laboratory;tuberculosis;tape measure protein;mycobacterium tuberculosis;in silico	Tape measure protein (TMP) having MT3 motif in mycobacteriophage TM4 genome has been reported to enable the phage infection of Mycobacterium smegmatis during stationary phase. In the present work looking at eight additional mycobacteriophage genomes by in silico analysis, six of them have been found to possess MT3 motif in TMP. The absence of MT3 motif in Che12 and D29 probably makes them incapable of infecting stationary phase cells of Mycobacterium tuberculosis which was experimentally evaluated by the performance of respective luciferase reporter phage constructs developed from the parental phages Che12, D29 and TM4.	bacteriophages;ensembl genomes;experiment;g1 to g0 transition;genome;genus mycobacterium;luciferases;mt3 protein, human;motif;mycobacteriophages;mycobacterium smegmatis;mycobacterium tuberculosis;star trek:;stationary process	V. N. Azger Dusthackeer;V. N. Sameer Hassan;Vanaja Kumar	2008	Computational biology and chemistry	10.1016/j.compbiolchem.2008.03.016	biology;molecular biology;virology;microbiology;laboratory	Comp.	3.741693782884277	-63.26360759277506	84359
defa87ed489889ee91866b8ef34da0a4e216cd11	protein family structure signature for multidomain proteins		The rapid increase in available protein structure datasets requires new techniques for fast, yet, effective analysis of protein 3D structures. In this work, we propose a structure-based signature for protein families, suitable for rapid analysis of multidomain protein structures. Our method is alignment-free, using protein strings as the basic representation. A key novelty is the two-stage approach, whereby an initial list of candidate protein superfamilies are rapidly identified using the protein family signature, and then information retrieval methods are applied only to the members of the candidate superfamilies. This approach is the key to both improved speed, and improved structure retrieval accuracy. Experimental results, including comparative results with state-of-the-art methods, demonstrate the performance of the proposed protein family signature on queries with multidomain protein structures.	protein family	Jun Tan;Donald A. Adjeroh	2018	IJDMB	10.1504/IJDMB.2018.10016312	computational biology;novelty;machine learning;artificial intelligence;protein structure;computer science;protein family	ML	-2.187261951128819	-53.30618378455552	84526
8e14f79db4b0d7109ad4db46771ed8673cd265b6	the mg-rast metagenomics database and portal in 2015	databases nucleic acid;general and miscellaneous;knowledge management and preservation;internet;metagenomics;sequence alignment	MG-RAST (http://metagenomics.anl.gov) is an open-submission data portal for processing, analyzing, sharing and disseminating metagenomic datasets. The system currently hosts over 200,000 datasets and is continuously updated. The volume of submissions has increased 4-fold over the past 24 months, now averaging 4 terabasepairs per month. In addition to several new features, we report changes to the analysis workflow and the technologies used to scale the pipeline up to the required throughput levels. To show possible uses for the data from MG-RAST, we present several examples integrating data and analyses from MG-RAST into popular third-party analysis tools or sequence alignment tools.	list of sequence alignment software;metagenomics;mg (editor);radioallergosorbent test;regulatory submission;throughput	Andreas Wilke;Jared Bischof;Wolfgang Gerlach;Elizabeth M. Glass;Travis Harrison;Kevin P. Keegan;Tobias Paczian;William L. Trimble;Saurabh Bagchi;Ananth Grama;Somali Chaterji;Folker Meyer	2016	Nucleic acids research	10.1093/nar/gkv1322	biology;the internet;bioinformatics;sequence alignment;metagenomics	HPC	-3.6026553357799282	-60.191300927083425	84603
c7b6cc8d9c652e90dc39aeefd82d7ab919689112	large-scale annotation of small-molecule libraries using public databases		While many large publicly accessible databases provide excellent annotation for biological macromolecules, the same is not true for small chemical compounds. Commercial data sources also fail to encompass an annotation interface for large numbers of compounds and tend to be cost prohibitive to be widely available to biomedical researchers. Therefore, using annotation information for the selection of lead compounds from a modern day high-throughput screening (HTS) campaign presently occurs only under a very limited scale. The recent rapid expansion of the NIH PubChem database provides an opportunity to link existing biological databases with compound catalogs and provides relevant information that potentially could improve the information garnered from large-scale screening efforts. Using the 2.5 million compound collection at the Genomics Institute of the Novartis Research Foundation (GNF) as a model, we determined that approximately 4% of the library contained compounds with potential annotation in such databases as PubChem and the World Drug Index (WDI) as well as related databases such as the Kyoto Encyclopedia of Genes and Genomes (KEGG) and ChemIDplus. Furthermore, the exact structure match analysis showed 32% of GNF compounds can be linked to third party databases via PubChem. We also showed annotations such as MeSH (medical subject headings) terms can be applied to in-house HTS databases in identifying signature biological inhibition profiles of interest as well as expediting the assay validation process. The automated annotation of thousands of screening hits in batch is becoming feasible and has the potential to play an essential role in the hit-to-lead decision making process.		Yingyao Zhou;Bin Zhou;Kaisheng Chen;S. Frank Yan;Frederick J. King;Shumei Jiang;Elizabeth A. Winzeler	2007	Journal of chemical information and modeling	10.1021/ci700092v	genomics;bioinformatics;biological inhibition;database;information retrieval;kegg;pubchem;annotation;small molecule libraries;computer science;biological database	Comp.	-1.304424767572477	-61.85540180379785	84621
176ac72ca31e3f9bc387ad2ffaec2f2a09953d25	assessing the lipophilicity of fragments and early hits	ligand efficiency;lipophilicity;ligand lipophilicity efficiency;fragment-based drug design;fragment optimisation	A key challenge in many drug discovery programs is to accurately assess the potential value of screening hits. This is particularly true in fragment-based drug design (FBDD), where the hits often bind relatively weakly, but are correspondingly small. Ligand efficiency (LE) considers both the potency and the size of the molecule, and enables us to estimate whether or not an initial hit is likely to be optimisable to a potent, druglike lead. While size is a key property that needs to be controlled in a small molecule drug, there are a number of additional properties that should also be considered. Lipophilicity is amongst the most important of these additional properties, and here we present a new efficiency index (LLE(AT)) that combines lipophilicity, size and potency. The index is intuitively defined, and has been designed to have the same target value and dynamic range as LE, making it easily interpretable by medicinal chemists. Monitoring both LE and LLE(AT) should help both in the selection of more promising fragment hits, and controlling molecular weight and lipophilicity during optimisation.	complement system proteins;drug design;drug discovery;dynamic range;intuition;mathematical optimization;medicinal chemistry;molecular weight;thrombocytopenia;combine;lipophilicity	Paul N. Mortenson;Christopher W. Murray	2011	Journal of computer-aided molecular design	10.1007/s10822-011-9435-z	stereochemistry;chemistry;toxicology;combinatorial chemistry	ML	9.62131895420085	-60.06691508658479	84635
d316fbfe5acdeb0782c49ead5bd6678107c04d86	efficient branch-and-bound techniques for two-locus association mapping	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;computational biology bioinformatics;uk phd theses thesis;life sciences;algorithms;combinatorial libraries;uk research reports;medical journals;computer appl in life sciences;europe pmc;biomedical research;microarrays;bioinformatics	Material and methods For a large-scale dataset of over 200,000 SNPs from about 200 individuals together with several phenotypes, published by Atwell et al. [1], we develop efficient methods to find pairs of SNPs which are strongly associated with the phenotype. As an exhaustive search of all possible combinations of interacting SNPs is often unfeasible, even when only considering pairs of interacting SNPs, the challenge is to find methods which avoid an exhaustive search but can still guarantee to find the causal pair. We propose two distinct approaches to efficiently determine the t top-scoring pairs of SNPs.	branch and bound;brute-force search;causal filter;interaction;locus	Karin Klotzbücher;Yasushi Kobayashi;Nino Shervashidze;Oliver Stegle;Bertram Müller-Myhsok;Detlef Weigel;Karsten M. Borgwardt	2011		10.1186/1471-2105-12-S11-A3	biology;dna microarray;computer science;bioinformatics;data science	NLP	2.9205522977467857	-56.06285999613782	84640
bd6c7e3510dd301102a0a794cc2fc7892fcfd544	a machine learning based method for the prediction of secretory proteins using amino acid composition, their order and similarity-search	psi-blast;n-terminal sequence;classical pathway;prediction;secretory proteins;svm;non-classical pathway;redundancy;ann;blast;dataset size;srtpred;support vector machine;genome sequence;artificial neural network;signal peptide;false positive;n terminal;machine learning;amino acid;similarity search;cross validation	Most of the prediction methods for secretory proteins require the presence of a correct N-terminal end of the preprotein for correct classification. As large scale genome sequencing projects sometimes assign the 5'-end of genes incorrectly, many proteins are encoded without the correct N-terminus leading to incorrect prediction. In this study, a systematic attempt has been made to predict secretory proteins irrespective of presence or absence of N-terminal signal peptides (also known as classical and non-classical secreted proteins respectively), using machine-learning techniques; artificial neural network (ANN) and support vector machine (SVM). We trained and tested our methods on a dataset of 3321 secretory and 3654 non-secretory mammalian proteins using five-fold cross-validation technique. First, ANN-based modules have been developed for predicting secretory proteins using 33 physico-chemical properties, amino acid composition and dipeptide composition and achieved accuracies of 73.1%, 76.1% and 77.1%, respectively. Similarly, SVM-based modules using 33 physico-chemical properties, amino acid, and dipeptide composition have been able to achieve accuracies of 77.4%, 79.4% and 79.9%, respectively. In addition, BLAST and PSI-BLAST modules designed for predicting secretory proteins based on similarity search achieved 23.4% and 26.9% accuracy, respectively. Finally, we developed a hybrid-approach by integrating amino acid and dipeptide composition based SVM modules and PSI-BLAST module that increased the accuracy to 83.2%, which is significantly better than individual modules. We also achieved high sensitivity of 60.4% with low value of 5% false positive predictions using hybrid module. A web server SRTpred has been developed based on above study for predicting classical and non-classical secreted proteins from whole sequence of mammalian proteins, which is available from http://www.imtech.res.in/raghava/srtpred/.	amino acids;artificial neural network;blast;cell secretion;cross reactions;cross-validation (statistics);dipeptides;hybrid integrated circuit;machine learning;mammals;server (computer);server (computing);signal peptides;similarity search;support vector machine;web server;whole genome sequencing;chemical properties;newton	Aarti Garg;Gajendra P. S. Raghava	2008	In silico biology		support vector machine;cross-validation;bioinformatics;amino acid;signal peptide;secretory protein;dipeptide;machine learning;biology;artificial intelligence;nearest neighbor search	Comp.	9.74333727963675	-56.10068947201496	84652
3093b8f51838584a421b998eb339f591b0b1ff16	the role of tgf-β signaling and apoptosis in innate and adaptive immunity in zebrafish: a systems biology approach	apoptosis;animals;simulation and modeling;candida albicans;intracellular space;systems biology;signal transduction;physiological cellular and medical topics;computational biology bioinformatics;zebrafish;transforming growth factor beta;algorithms;humans;protein interaction mapping;immunity innate;adaptive immunity;bioinformatics	The immune system is a key biological system present in vertebrates. Exposure to pathogens elicits various defensive immune mechanisms that protect the host from potential threats and harmful substances derived from pathogens such as parasites, bacteria, and viruses. The complex immune system of humans and many other vertebrates can be divided into two major categories: the innate and the adaptive immune systems. At present, analysis of the complex interactions between the two subsystems that regulate host defense and inflammatory responses remains challenging. Based on time-course microarray data following primary and secondary infection of zebrafish by Candida albicans, we constructed two intracellular protein–protein interaction (PPI) networks for primary and secondary responses of the host. 57 proteins and 341 PPIs were identified for primary infection while 90 proteins and 385 PPIs were identified for secondary infection. There were 20 proteins in common while 37 and 70 proteins specific to primary and secondary infection. By inspecting the hub proteins of each network and comparing significant changes in the number of linkages between the two PPI networks, we identified TGF-β signaling and apoptosis as two of the main functional modules involved in primary and secondary infection. Smad7, a member of the inhibitor SMADs, was identified to be a key protein in TGF-β signaling involved in secondary infection only. Indeed, the Smad7-dependent feedback system is related to the TGF-β signaling pathway and the immune response, suggesting that Smad7 may be an important regulator of innate and adaptive immune responses in zebrafish. Furthermore, we found that apoptosis was differentially involved in the two infection phases; more specifically, whereas apoptosis was promoted in response to primary infection, it was inhibited during secondary infection. Our initial in silico analyses pave the way for further investigation into the interesting roles played by the TGF-β signaling pathway and apoptosis in innate and adaptive immunity in zebrafish. Such insights could lead to therapeutic advances and improved drug design in the continual battle against infectious diseases.	apoptosis;biological system;categories;communicable diseases;drug design;gene regulatory network;humoral immune response;immune system;interaction;microarray;parasites;pixel density;proton pump inhibitors;smad7 gene;secondary infections;signal transduction pathways;systems biology;the hub (forum);usb hub;vertebrates;zebrafish;host defense;inflammatory response;primary infection nos	Che Lin;Chin-Nan Lin;Yu-Chao Wang;Fang-Yu Liu;Yung-Jen Chuang;Chung-Yu Lan;Wen-Ping Hsieh;Bor-Sen Chen	2014		10.1186/s12918-014-0116-0	transforming growth factor;biology;acquired immune system;zebrafish information network genome database;cell biology;intracellular;bioinformatics;apoptosis;classical complement pathway;immunology;genetics;systems biology;signal transduction	Comp.	6.211051251754433	-61.44897933965825	84671
48088b65a09d29478b83979bff02a59cead94f7e	cas-database: web-based genome-wide guide rna library design for gene knockout screens using crispr-cas9		MOTIVATION CRISPR-derived RNA guided endonucleases (RGENs) have been widely used for both gene knockout and knock-in at the level of single or multiple genes. RGENs are now available for forward genetic screens at genome scale, but single guide RNA (sgRNA) selection at this scale is difficult.   RESULTS We develop an online tool, Cas-Database, a genome-wide gRNA library design tool for Cas9 nucleases from Streptococcus pyogenes (SpCas9). With an easy-to-use web interface, Cas-Database allows users to select optimal target sequences simply by changing the filtering conditions. Furthermore, it provides a powerful way to select multiple optimal target sequences from thousands of genes at once for the creation of a genome-wide library. Cas-Database also provides a web application programming interface (web API) for advanced bioinformatics users.   AVAILABILITY AND IMPLEMENTATION Free access at http://www.rgenome.net/cas-database/   CONTACT sangsubae@hanyang.ac.kr or jskim01@snu.ac.kr   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	ajax (programming);application programming interface;bioinformatics;biological science disciplines;clustered regularly interspaced short palindromic repeats;cooperative breeding;design tool;ephrin type-b receptor 1, human;experiment;gene knockout techniques;interface device component;irritable bowel syndrome;libraries;library (computing);rna;rna, guide;streptococcus pyogenes;user interface;web api;web site;web application;web development;world wide web;endonuclease;nuclease	Jeongbin Park;Jin-Soo Kim;Sangsu Bae	2016		10.1093/bioinformatics/btw103	computer science;bioinformatics;data mining;world wide web	Comp.	-1.8463475801394462	-59.01929941197632	84754
84d20589e0ae945ea1de017e1fe088fb25363890	propepper: a curated database for identification and analysis of peptide and immune-responsive epitope composition of cereal grain protein families		ProPepper is a database that contains prolamin proteins identified from true grasses (Poaceae), their peptides obtained with single- and multi-enzyme in silico digestions as well as linear T- and B-cell-specific epitopes that are responsible for wheat-related food disorders. The integrated database and analysis platform contains datasets that are collected from multiple public databases (UniprotKB, IEDB, NCBI GenBank), manually curated and annotated, and interpreted in three main data tables: Protein-, Peptide- and Epitope list views that are cross-connected by unique identifications. Altogether 21 genera and 80 different species are represented. Currently, the database contains 2146 unique and complete protein sequences related to 2618 GenBank entries and 35 657 unique peptide sequences that are a result of 575 110 unique digestion events obtained by in silico digestion methods involving six proteolytic enzymes and their combinations. The interface allows advanced global and parametric search functions along with a download option, with direct connections to the relevant public databases. Database URL: https://propepper.net.	access network;amino acids;amylases;b-lymphocytes;cereals;chaitin's constant;dec alpha;data table;database;digeorge syndrome;download;eighty;ephrin type-b receptor 1, human;epitopes;function (biology);genbank;genera;gliadin;homologous gene;homology (biology);hungarian language;ncbi taxonomy;numerous;parametric search;peptide hydrolases;peptide sequence;pierre robin syndrome;poaceae;prolamins;protein digestion (research activity);protein family;proteomics;superfamily;sequence homology;silo (dataset);structural similarity;alpha-amylases	Angéla Juhász;Réka Haraszi;Csaba Maulis	2015		10.1093/database/bav100	biology;bioinformatics;data mining;refseq;genetics	Comp.	-0.6846232784102166	-60.05187135230557	84760
e756ba8a9e859d88401c2b9fa3f883a96ae31bd5	a folding algorithm for extended rna secondary structures	software;base pairing;angewandte informatik sonstiges;models molecular;rna;nucleic acid conformation;algorithms;sequence analysis rna	MOTIVATION RNA secondary structure contains many non-canonical base pairs of different pair families. Successful prediction of these structural features leads to improved secondary structures with applications in tertiary structure prediction and simultaneous folding and alignment.   RESULTS We present a theoretical model capturing both RNA pair families and extended secondary structure motifs with shared nucleotides using 2-diagrams. We accompany this model with a number of programs for parameter optimization and structure prediction.   AVAILABILITY All sources (optimization routines, RNA folding, RNA evaluation, extended secondary structure visualization) are published under the GPLv3 and available at www.tbi.univie.ac.at/software/rnawolf/.	alignment;base pairing;mathematical optimization;nucleotides;population parameter;rna folding;scientific publication;theory;algorithm;tertiary	Christian Höner zu Siederdissen;Stephan H. Bernhart;Peter F. Stadler;Ivo L. Hofacker	2011		10.1093/bioinformatics/btr220	biology;structural alignment;rna;base pair;bioinformatics;genetics	Comp.	0.22476983236028233	-58.37729286363414	84902
d9dd6904fa28d370f31aa915d9384310c446e494	mechanical unfolding reveals stable 3-helix intermediates in talin and α-catenin		Mechanical stability is a key feature in the regulation of structural scaffolding proteins and their functions. Despite the abundance of α-helical structures among the human proteome and their undisputed importance in health and disease, the fundamental principles of their behavior under mechanical load are poorly understood. Talin and α-catenin are two key molecules in focal adhesions and adherens junctions, respectively. In this study, we used a combination of atomistic steered molecular dynamics (SMD) simulations, polyprotein engineering, and single-molecule atomic force microscopy (smAFM) to investigate unfolding of these proteins. SMD simulations revealed that talin rod α-helix bundles as well as α-catenin α-helix domains unfold through stable 3-helix intermediates. While the 5-helix bundles were found to be mechanically stable, a second stable conformation corresponding to the 3-helix state was revealed. Mechanically weaker 4-helix bundles easily unfolded into a stable 3-helix conformation. The results of smAFM experiments were in agreement with the findings of the computational simulations. The disulfide clamp mutants, designed to protect the stable state, support the 3-helix intermediate model in both experimental and computational setups. As a result, multiple discrete unfolding intermediate states in the talin and α-catenin unfolding pathway were discovered. Better understanding of the mechanical unfolding mechanism of α-helix proteins is a key step towards comprehensive models describing the mechanoregulation of proteins.	adherens junction;atomic-force microscopy;clamping (graphics);experiment;focal (programming language);focal adhesions;gene regulatory network;microscopy, atomic force;molecular dynamics;service mapping description;simulation;tln1 gene;tissue adhesions;unfolding (dsp implementation);mutant	Vasyl V. Mykuliak;Alexander William M. Haining;Magdaléna von Essen;Armando del Río Hernández;Vesa P. Hytönen	2018		10.1371/journal.pcbi.1006126	molecular dynamics;bioinformatics;helix;scaffold protein;cytoskeleton;catenin;focal adhesion;cell biology;biology;adherens junction;atomic force microscopy	ML	9.170212826361116	-63.1868411745039	84952
0018ece872bb78b06eb26ea35d5ed27f53702ce6	protein function prediction using the protein link explorer (plex)	prediccion;medio ambiente;protein function;proteine;phylogeny;phylogenese;liaison genetique;amino acid sequence;cellular system;hybrid gene;genoma a;protein function prediction;genetic linkage;construccion;gen hibrido;genome a;environment;filogenesis;gene hybride;environnement;proteina;a genome;protein;gene function;gene fusion;prediction;construction;ligamiento genetico	UNLABELLED We introduce the Protein Link EXplorer (PLEX), a web-based environment that allows the construction of a phylogenetic profile for any given amino acid sequence, and its comparison with profiles of approximately 350,000 predicted genes from 89 genomes, as a means of interactively identifying functionally linked genes and predicting protein function. PLEX can be searched iteratively and also enables searches for chromosomal gene neighbors and Rosetta Stone linkages. PLEX search results are accompanied by quantitative estimates of linkage confidence, enabling users to take advantage of coinheritance, operon and gene fusion-based methods for inferring gene function and reconstructing cellular systems and pathways.   AVAILABILITY http://bioinformatics.icmb.utexas.edu/plex	amino acid sequence;amino acids;bioinformatics;eighty nine;estimated;gene fusion;genome;interactivity;linkage (software);operon;phylogenetic profiling;phylogenetics;protein function prediction;protein, organized by function;web application	Shailesh V. Date;Edward M. Marcotte	2005	Bioinformatics	10.1093/bioinformatics/bti313	biology;construction;prediction;genetic linkage;bioinformatics;fusion gene;peptide sequence;protein function prediction;natural environment;genetics;phylogenetics	Comp.	-3.935456916213391	-57.9021641504697	85059
fbea74229df94176560b39781da587554df4cf5f	cancer and signaling pathway deregulation		Cancer is a complex disease that is associated with a variety of genetic aberrations. The diagnosis and treatment of cancer have been difficult because of poor understanding of cancer and lack of effective cancer therapies. Many studies have investigated cancer from different perspectives. It remains unclear what molecular mechanisms have triggered and sustained the transition of normal cells to malignant tumor cells in cancer patients. This chapter gives an introduction to the genetic aberrations associated with cancer and a brief view of the topics key to decode cancer, from identifying clinically relevant cancer subtypes to uncovering the pathways deregulated in particular subtypes of cancer.	gene regulatory network	Yingchun Liu	2011		10.4018/978-1-60960-491-2.ch017	cancer;cancer research;signal transduction;deregulation;suppressor of cytokine signalling;biology	Comp.	5.538327803422887	-60.00281124287176	85086
a314f3b7dce98226a87e97460e6e708983cc40f9	sarment: python modules for hmm analysis and partitioning of sequences	modelo markov oculto;programmation;modele markov cache;hidden markov model;bioinformatique;segmentation;programacion;algorithme;algorithm;object oriented;oriente objet;bioinformatica;orientado objeto;programming;segmentacion;bioinformatics;algoritmo	Sarment is a package of Python modules for easy building and manipulation of sequence segmentations. It provides efficient implementation of usual algorithms for hidden Markov Model computation, as well as for maximal predictive partitioning. Owing to its very large variety of criteria for computing segmentations, Sarment can handle many kinds of models. Because of object-oriented programming, the results of the segmentation are very easy tomanipulate.	algorithm;computation (action);hidden markov model;markov chain;maximal set;python;biologic segmentation	Laurent Gueguen	2005	Bioinformatics	10.1093/bioinformatics/bti533	programming;computer science;bioinformatics;theoretical computer science;machine learning;database;object-oriented programming;segmentation;genetics;hidden markov model	Comp.	-4.269322473487963	-55.19791191727137	85097
2df7065c24c560ea3928e594e914f58c958f563e	a java applet for visualizing protein-protein interaction	java applet;protein protein interaction	UNLABELLED A web applet for browsing protein-protein interactions was implemented. It enables the display of interaction relationships, based upon neighboring distance and biological function.   AVAILABILITY The Java applet is available at http://www.charite.de/bioinformatics	function (biology);java programming language;java applet;protein protein interaction	Ralf Mrowka	2001	Bioinformatics	10.1093/bioinformatics/17.7.669	protein–protein interaction;biology;computer science;operating system;world wide web;java applet;computer graphics (images)	Comp.	-4.140529949851254	-58.4196914971164	85200
4ce1cbdcc3b0b40aa091e09f4842cad50c1b90c0	bi-grappin: bipartite graph based protein-protein interaction network similarity search	graph theory;organisms;biology computing;sequences;protein protein interaction network;mathematics;protein function;bipartite graph proteins organisms bioinformatics biology computing computer networks sequences testing evolution biology mathematics;sequence similarity;testing;maximum weight matching;computer networks;bi grappin;evolution biology;proteins;functional genomics;molecular biophysics;protein protein interaction networks;synthetic data;bipartite graph;similarity search;biochemistry;bioinformatics	"""We propose an algorithm, called BI-GRAPPIN, to search for similarities across PPI networks. The technique core consists in computing a maximum weight matching of bipartite graphs to compare the neighborhoods of pairs of proteins in different PPI networks. The idea is that proteins belonging to different networks should be matched look- ing not only at their own sequence similarity, but also at the similarity of proteins they """"strongly"""" interact with, ei- ther directly or indirectly. We implemented the method and tested it on both real and synthetic data, showing its effec- tiveness in solving ambiguous situations and in individuat- ing functionally related proteins. Differently from previous work, the presented algorithm allows to take into account both quantitative and reliability information possibly avail- able about interactions."""	algorithm;homology (biology);interaction network;matched filter;matching (graph theory);pixel density;similarity search;synthetic data	Valeria Fionda;Luigi Palopoli;Simona Panni;Simona E. Rombo	2007	2007 IEEE International Conference on Bioinformatics and Biomedicine (BIBM 2007)	10.1109/BIBM.2007.36	functional genomics;organism;biochemistry;bipartite graph;computer science;bioinformatics;graph theory;theoretical computer science;machine learning;data mining;sequence;mathematics;software testing;synthetic data;molecular biophysics	Visualization	6.967293877083391	-56.49268288085157	85247
d5128dda7ba6c1c6605bee0988d844d829bc1eb1	non-coding, mrna-like rnas database y2k	rna messenger;internet;databases factual	In last few years much data has accumulated on various non-translatable RNA transcripts that are synthesised in different cells. They are lacking in protein coding capacity and it seems that they work mainly or exclusively at the RNA level. All known non-coding RNA transcripts are collected in the database: http://www. man.poznan.pl/5SData/ncRNA/index.html	transcript;non-t, non-b childhood acute lymphoblastic leukemia	Volker A. Erdmann;Maciej Szymanski;Abraham Hochberg;Nathan de Groot;Jan Barciszewski	2000	Nucleic acids research	10.1093/nar/28.1.197	biology;the internet;bioinformatics	Comp.	0.4511720920456416	-61.566654898632784	85260
205cd4f7b21ec4acd380c1fefd07975ad9011534	automated analysis of mitotic phenotypes in fluorescence microscopy images of human cells	cell culture;automatic segmentation;high throughput screening;large scale;fluorescence microscopy;image analysis;high throughput;classification accuracy;gene function	High-throughput screens of the gene function provide rapidly increasing amounts of data. In particular, the analysis of image  data acquired in genome-wide cell phenotype screens constitutes a substantial bottleneck in the evaluation process and motivates  the development of automated image analysis tools for large-scale experiments. Here we introduce a computational scheme to  process multi-cell time-lapse images as they are produced in high-throughput screens. We describe an approach to automatically  segment and classify cell nuclei into different mitotic phenotypes. This enables automated identification of cell cultures  that show an abnormal mitotic behaviour. Our scheme proves a high classification accuracy, suggesting a promising future for  automating the evaluation of high-throughput experiments.  		Nathalie Harder;Beate Neumann;Michael Held;Urban Liebel;Holger Erfle;Jan Ellenberg;Roland Eils;Karl Rohr	2006		10.1007/3-540-32137-3_76	biology;cell biology;bioinformatics;analytical chemistry	Vision	3.1661593693820684	-56.84535704720515	85316
807ea57606507c759f28cd021cbb1c206987c1a0	binding profiles of chromatin-modifying proteins are predictive for transcriptional activity and promoter-proximal pausing	transcriptional regulation;stability solution;regression analysis;chromatin proteins	The establishment and maintenance of proper gene expression patterns is essential for stable cell differentiation. Using unsupervised learning techniques, chromatin states have been linked to discrete gene expression states, but these models cannot predict continuous gene expression levels, nor do they reveal detailed insight into the chromatin-based control of gene expression. Here, we employ regularized regression techniques to link, in a quantitative manner, binding profiles of chromatin proteins to gene expression levels and promoter-proximal pausing of RNA polymerase II in Drosophila melanogaster on a genome-wide scale. We apply stability selection to reliably detect interactions of chromatin features and predict several known, suggested, and novel proteins and protein pairs as transcriptional activators or repressors. Our integrative analysis reveals new insights into the complex interplay of transcriptional regulators in the context of gene expression. Supplementary Material is available at www.libertonline.com/cmb.	cell differentiation process;cellular material:mcnt:pt:calculus:qn:estimated;gene expression;interaction;name binding;rna polymerase ii;transcription, genetic;unsupervised learning	Thomas Sakoparnig;Tobias Kockmann;Renato Paro;Christian Beisel;Niko Beerenwinkel	2012	Journal of computational biology : a journal of computational molecular cell biology	10.1089/cmb.2011.0258	biology;chia-pet;molecular biology;regulation of gene expression;bioinformatics;chromatin remodeling;genetics;transcriptional regulation;regression analysis;bivalent chromatin;chip-sequencing	Comp.	4.919244160130127	-59.58307045902722	85339
a68a0abf392d8a0c81017a8321a83d1fb29395b8	quinoline containing chalcone derivatives as cholinesterase inhibitors and their in silico modeling studies	butyrylcholinesterase;chalcone;cholinesterase;molecular modeling;neurodegenerative disease	Cholinesterases (ChEs) play a vital role in regulating cholinergic transmission. Inhibition of ChEs is thought to be an emerging and useful therapeutic target for neurodegenerative disorders through restoration of acetylcholine (ACh) levels in the brain (e.g. Alzheimer's disease). To increase the chemical diversity of cholinesterase inhibitors, a series of quinoline chalcones derivatives were tested against acetylcholinesterase (AChE) and butyrylcholinesterase (BChE) isoenzymes. All tested compounds (4a-1; 5a-s) exhibited inhibitory activities against AChE and BChE to a considerable extent. Molecular docking studies were performed by using homology models on both AChE and BChE isoenzymes with the aim of exploring probable binding modes of the most potent inhibitor. In order to evaluate drug likeness of newly tested molecules, we carried out in-silico ADME evaluation. All compounds displayed favourable ADME findings which predict good oral bioavailability of these derivatives. Due to an excellent ADME profile the tested compounds were predicted to be safer which can be considered as novel cholinesterase inhibitors.	adme study;acetylcholine;alzheimer's disease;boat dock;butyrylcholinesterase;chalcone;cholinesterase inhibitors;cholinesterases;circuit restoration;diarylquinolines;docking (molecular);homologous gene;homology (biology);isoenzymes;maxillary right first premolar abutment;neurodegenerative disorders;probability;quinolines;therapeutic targets database;trusted computer system evaluation criteria	Muhammad Shakil Shah;Muhammad Najam-ul-Haq;Hamid Saeed Shah;Syed Umar Farooq Rizvi;Jamshed Iqbal	2018	Computational biology and chemistry	10.1016/j.compbiolchem.2018.08.003	quinoline;acetylcholine;adme;genetics;cholinergic;cholinesterase;chalcone;butyrylcholinesterase;acetylcholinesterase;biology;biochemistry	Comp.	9.213856070129141	-61.877524081499665	85662
8e9d6e4511c13bcd813aa93e2e49cda2c639a5c5	gene length and codon usage bias in drosophila melanogaster, saccharomyces cerevisiae and escherichia coli	animals;escherichia coli;saccharomyces cerevisiae;codon;codon usage bias;drosophila melanogaster	The relationship between gene length and synonymous codon usage bias was investigated in Drosophila melanogaster, Escherichia coli and Saccharomyces cerevisiae. Simulation studies indicate that the correlations observed in the three organisms are unlikely to be due to sampling errors or any potential bias in the methods used to measure codon usage bias. The correlation was significantly positive in E.coli genes, whereas negative correlations were obtained for D. melanogaster and S.cerevisiae genes. When only ribosomal protein genes were used, whose expression levels are assumed to be similar, E.coli and S.cerevisiae showed significantly positive correlations. For the two eukaryotes, the distribution of effective number of codons was different in short genes (300-500 bp) compared with longer genes; this was not observed in E.coli. Both positive and negative correlations can be explained by translational selection. Energetically costly longer genes have higher codon usage bias to maximize translational efficiency. Selection may also be acting to reduce the size of highly expressed proteins, and the effect is particularly pronounced in eukaryotes. The different relationships between codon usage bias and gene length observed in prokaryotes and eukaryotes may be the consequence of these different types of selection.	assumed;codon (nucleotide sequence);codon genus;drosophila melanogaster;genetic selection;genetic translation process;prokaryote;ribosomal proteins;sampling (signal processing);simulation	Etsuko N. Moriyama;Jeffrey R. Powell	1998	Nucleic acids research	10.1093/nar/26.13.3188	biology;synonymous substitution;molecular biology;codon usage bias;bioinformatics;genetic code;escherichia coli;genetics	Comp.	6.475658961466652	-63.49376101611973	85813
56ba29739babc3e61bec06ea5d646b2615fb71a9	combining n-grams and alignment in g-protein coupling specificity prediction	g protein coupled receptor;g protein;linear order	G-protein coupled receptors (GPCR) interact with G-proteins to regulate much of the cell’s response to external stimuli; abnormalities in which cause numerous diseases. We developed a new method to predict the families of G-proteins with which it interacts, given its residue sequence. We combine both alignment and n-gram features. The former captures long-range interactions but assumes the linear ordering of conserved segments is preserved. The latter makes no such assumption but cannot capture long-range interactions. By combining alignment and n-gram features, and using the entire GPCR sequence (instead of intracellular regions alone, as was done by others), our method outperformed the current state-of-the-art in precision, recall and F1, attaining 0.753 in F1 and 0.796 in accuracy on the PTbase 2004 dataset. Moreover, analysis of our results shows that the majority of coupling specificity information lies in the beginning of the 2nd intracellular loop and over the length of the 3rd.	grams;in the beginning... was the command line;interaction;n-gram;sensitivity and specificity	Betty Yee Man Cheng;Jaime G. Carbonell	2007			coupling;stimulus (physiology);g protein;receptor;g protein-coupled receptor;intracellular;biology;bioinformatics	NLP	5.785081682521467	-62.69018997766349	85825
b371818a865d07bb3c74f4acaee7be43caca4807	oma, a comprehensive, automated project for the identification of orthologs from complete genome data: introduction and first achievements	computers;complete genome;ucl;protein sequence;discovery;theses;conference proceedings;large scale;digital web resources;ucl discovery;open access;protein classification;consistency checking;ucl library;book chapters;open access repository;phylogenetic analysis;ucl research	The OMA project is a large-scale effort to identify groups of orthologs from complete genome data, currently 150 species. The algorithm relies solely on protein sequence information and does not require any human supervision. It has several original features, in particular a verification step that detects paralogs and prevents them from being clustered together. Consistency checks and verification are performed throughout the process. The resulting groups, whenever a comparison could be made, are highly consistent both with EC assignments, and with assignments from the manually curated database HAMAP. A highly accurate set of orthologous sequences constitutes the basis for several other investigations, including phylogenetic analysis and protein classification. Complete genomes give scientists a valuable resource to assign functions to sequences and to analyze their evolutionary history. These analyses rely heavily on gene comparison through sequence alignment algorithms that output the level of similarity, which gives an indication of homology. When homologous sequences are of interest, care must often be taken to distinguish between orthologous and paralogous proteins [1]. Both orthologs and paralogs come from the same ancestral sequence, and therefore are homologous, but they differ in the way they arise: paralogous sequences are the product of gene duplication, while orthologous sequences are the product of speciation. Practically, the distinction is very useful, because as opposed to paralogs, orthologs often carry the same function, in different organisms. As Eugene Koonin states it [2], whenever we speak of ”the same gene in different species”, we actually mean orthologs. 1 Previous Large-Scale Efforts The systematic identification of orthologous sequences is an important problem that several other projects have addressed so far. Among them, the COG Corresponding author. A. McLysaght et al. (Eds.): RECOMB 2005 Ws on Comparative Genomics, LNBI 3678, pp. 61–72, 2005. c © Springer-Verlag Berlin Heidelberg 2005 62 C. Dessimoz et al. database [3], [4] is probably the most established. From BLAST alignments [5] between all proteins (”all-against-all”), they identify genome-specific best hits, then group members that form triangles of best hits. Finally, the results are reviewed and corrected manually. A further initiative is KEGG Orthology (KO) [6], [7]. KEGG is best known for its detailed database on metabolic pathways, but as the project evolved, an effort to cluster proteins into orthologous groups was initiated as well. The method is somewhat similar to COG: it starts with Smith-Waterman [8] allagainst-all alignments, and identifies symmetrical best hits. It then uses a quasiclique algorithm to generate ”Ortholog clusters”, that are used to create the KO groups, the last step being performed manually. Finally, we mention here Inparanoid [9], OrthoMCL [10] and EGO (previously called TOGA) [11]. All three projects exclusively cover eukaryotic genomes. The two first insist on the inclusion of so-called ”in-paralogs”, sequences that result from a duplication event that occurred after all speciations. A noticeable shortcoming of Inparanoid is the fact that it only handles pairs of genomes at a time. As for EGO, although their last release contains almost half a million genes from 82 eukaryotes, many sequences appear in more than one group and many groups contain paralogs. Because of that, we consider Inparanoid and EGO outside the present scope and limit our comparisons below to COG, KO and OrthoMCL. 2 Overview of the OMA Project The project presented in this article is a new approach to identify groups of orthologs. It has some very specific properties: – Automated. Unlike COG and KEGG Orthology, the whole workflow does not require human intervention, thereby insuring consistency, scalability and full transparency of the process. – Extensive. The analysis so far has been performed on more than 150 genomes (Prokaryotes and Eukaryotes), with new ones added by the day. The goal is to include all available complete genomes. – Strict. Consistency checks are performed throughout the workflow, particularly at the integration step of genomic data. The algorithm for the identification of orthologous proteins excludes paralogs. 98.3% of the groups we could test are made of bona fide orthologous proteins (Sect. 4.1). The algorithm for the identification of orthologous groups relies solely on protein sequence alignments from complete genomes, and hence does not depend on previous knowledge in terms of phylogeny, synteny information or experimental data. It is described in detail in the next section. From the orthologous groups, we build a two-dimensional matrix in which each row represents an orthologous group and each column represents a species. 1 At the time the final version of this article is submitted, 181 genomes have been included in the analysis. OMA, A Comprehensive, Automated Project 63 The applications of that matrix are numerous and fall beyond the scope of this article. However, a few are worth mentioning. The rows provide phyletic patterns of the orthologous groups and can be used for phylogenetic profiling [12]. Parsimony trees can be constructed from the matrix to give either a phylogenetic tree when built from the columns, or protein families when built from the rows. We believe that both trees are very valuable contributions, and they will be presented, among others, in separate articles. Also, a large set of orthologous sequences is a prerequisite for the construction of reliable phylogenetic distance trees.	blast;cog (project);column (database);database;ego;eventual consistency;homology (biology);inparanoid;kegg;lecture notes in computer science;maximum parsimony (phylogenetics);oma;phylogenetic profiling;phylogenetic tree;phylogenetics;protein family;research in computational molecular biology;scalability;sequence alignment;sequence homology;smith–waterman algorithm;springer (tank);synteny;the matrix	Christophe Dessimoz;Gina Cannarozzi;Manuel Gil;Daniel Margadant;Alexander C. J. Roth;Adrian Schneider;Gaston H. Gonnet	2005		10.1007/11554714_6	computer science;bioinformatics;protein sequencing;data mining;world wide web	Comp.	-0.14509030859924943	-56.02315928822871	85870
328873cf984ad1b692c11f76825f8c2d54fb95ac	model of the interaction between the nf-κb inhibitory protein p100 and the e3 ubiquitin ligase β-trcp based on nmr and docking experiments		NF-κB is a major transcription factor whose activation is triggered through two main activation pathways: the canonical pathway involving disruption of IκB-α/NF-κB complexes and the alternative pathway whose activation relies on the inducible proteolysis of the inhibitory protein p100. One central step controlling p100 processing consists in the interaction of the E3 ubiquitin ligase β-TrCP with p100, thereby leading to its ubiquitinylation and subsequent either complete degradation or partial proteolysis by the proteasome. However, the interaction mechanism between p100 and β-TrCP is still poorly defined. In this work, a diphosphorylated 21-mer p100 peptide model containing the phosphodegron motif was used to characterize the interaction with β-TrCP by NMR. In parallel, docking simulations were performed in order to obtain a model of the 21P-p100/β-TrCP complex. Saturation transfer difference (STD) experiments were performed in order to highlight the residues of p100 involved in the interaction with the β-TrCP protein. These results highlighted the importance of pSer865 and pSer869 residues in the interaction with β-TrCP and particularly the Tyr867 that fits inside the hydrophobe β-TrCP cavity with the Arg474 guanidinium group. Four other arginines, Arg285, Arg410, Arg431, and Arg521, were found essential in the stabilization of p100 on the β-TrCP surface. Importantly, the requirement for these five arginine residues of β-TrCP for the interaction with p100 was further confirmed in vivo, thereby validating the docking model through a biological approach.		Maxime Melikian;Baptiste Eluard;Gildas Bertho;Véronique Baud;Nathalie Evrard-Todeschi	2017	Journal of chemical information and modeling	10.1021/acs.jcim.5b00409	biology;biochemistry;molecular biology;bioinformatics	Comp.	8.844210597210127	-62.67527791979513	85920
2d0ec61bb2507ce273adc5b0547d6a248f055978	residual viremia in treated hiv+ individuals	hiv;hiv infection;viremia;antiretroviral therapy;hiv infections;viral evolution;viral load;viral replication;basic biological sciences viral replication;basic biological sciences;cell activation	Antiretroviral therapy (ART) effectively controls HIV infection, suppressing HIV viral loads. However, some residual virus remains, below the level of detection, in HIV-infected patients on ART. The source of this viremia is an area of debate: does it derive primarily from activation of infected cells in the latent reservoir, or from ongoing viral replication? Observations seem to be contradictory: there is evidence of short term evolution, implying that there must be ongoing viral replication, and viral strains should thus evolve. However, phylogenetic analyses, and rare emergent drug resistance, suggest no long-term viral evolution, implying that virus derived from activated latent cells must dominate. We use simple deterministic and stochastic models to gain insight into residual viremia dynamics in HIV-infected patients. Our modeling relies on two underlying assumptions for patients on suppressive ART: that latent cell activation drives viral dynamics and that the reproductive ratio of treated infection is less than 1. Nonetheless, the contribution of viral replication to residual viremia in patients on ART may be non-negligible. However, even if the portion of viremia attributable to viral replication is significant, our model predicts (1) that latent reservoir re-seeding remains negligible, and (2) some short-term viral evolution is permitted, but long-term evolution can still be limited: stochastic analysis of our model shows that de novo emergence of drug resistance is rare. Thus, our simple models reconcile the seemingly contradictory observations on residual viremia and, with relatively few parameters, recapitulates HIV viral dynamics observed in patients on suppressive therapy.	antiretroviral therapy;cell (microprocessor);de novo transcriptome assembly;emergence;hiv infections;intrinsic drive;patients;reproduction;reservoir device component;stochastic process;viremia;virus replication	Jessica M. Conway;Alan S. Perelson	2016		10.1371/journal.pcbi.1004677	biology;viral evolution;viral load;virology;immunology;viral replication;genetics	ML	6.620340651313784	-65.61001548945436	85995
2a0ec5249cfc329348b61ab503c07be117f97df1	discriminative structural approaches for enzyme active-site prediction	catalytic domain;enzyme activity;enzyme;computational biology bioinformatics;protein structure;local structure;enzymes;drug design;protein conformation;machine learning;artificial intelligence;algorithms;combinatorial libraries;computational biology;computer appl in life sciences;active site;reaction mechanism;microarrays;bioinformatics	Predicting enzyme active-sites in proteins is an important issue not only for protein sciences but also for a variety of practical applications such as drug design. Because enzyme reaction mechanisms are based on the local structures of enzyme active-sites, various template-based methods that compare local structures in proteins have been developed to date. In comparing such local sites, a simple measurement, RMSD, has been used so far. This paper introduces new machine learning algorithms that refine the similarity/deviation for comparison of local structures. The similarity/deviation is applied to two types of applications, single template analysis and multiple template analysis. In the single template analysis, a single template is used as a query to search proteins for active sites, whereas a protein structure is examined as a query to discover the possible active-sites using a set of templates in the multiple template analysis. This paper experimentally illustrates that the machine learning algorithms effectively improve the similarity/deviation measurements for both the analyses.	clinical use template;dna binding site;drug design;experiment;machine learning;multiple sequence alignment;question (inquiry);science;staphylococcal protein a;algorithm	Tsuyoshi Kato;Nozomi Nagano	2011		10.1186/1471-2105-12-S1-S49	biology;enzyme;protein structure;biophysics;bioinformatics	Comp.	10.02494040627354	-56.834538310655425	86051
fe9374d7cc1d5ba901119f9ad6cd5cb77de7e19d	mruninovo: an efficient tool for de novo peptide sequencing utilizing the hadoop distributed computing framework		Summary Tandem mass spectrometry-based de novo peptide sequencing is a complex and time-consuming process. The current algorithms for de novo peptide sequencing cannot rapidly and thoroughly process large mass spectrometry datasets. In this paper, we propose MRUniNovo, a novel tool for parallel de novo peptide sequencing. MRUniNovo parallelizes UniNovo based on the Hadoop compute platform. Our experimental results demonstrate that MRUniNovo significantly reduces the computation time of de novo peptide sequencing without sacrificing the correctness and accuracy of the results, and thus can process very large datasets that UniNovo cannot.   Availability and Implementation MRUniNovo is an open source software tool implemented in java. The source code and the parameter settings are available at http://bioinfo.hupo.org.cn/MRUniNovo/index.php.   Contact s131020002@hnu.edu.cn ; taochen1019@163.com.   Supplementary information Supplementary data are available at Bioinformatics online.		Chuang Li;Tao Chen;Qiang He;Yunping Zhu;Keqin Li	2017	Bioinformatics	10.1093/bioinformatics/btw721	real-time computing;bioinformatics;theoretical computer science	Comp.	-1.7094922104965389	-55.660618081773556	86052
976975fe722da7fca680d5b3144c71b86932ce8a	space: a suite of tools for protein structure prediction and analysis based on complementarity and environment	software;nucleic acids;models molecular;internet;proteins;protein conformation;contact maps;protein structure prediction;point mutation;amino acids;crystallography x ray;nucleic acid;molecular docking;water;structure analysis;databases protein;molecular structure	We describe a suite of SPACE tools for analysis and prediction of structures of biomolecules and their complexes. LPC/CSU software provides a common definition of inter-atomic contacts and complementarity of contacting surfaces to analyze protein structure and complexes. In the current version of LPC/CSU, analyses of water molecules and nucleic acids have been added, together with improved and expanded visualization options using Chime or Java based Jmol. The SPACE suite includes servers and programs for: structural analysis of point mutations (MutaProt); side chain modeling based on surface complementarity (SCCOMP); building a crystal environment and analysis of crystal contacts (CryCo); construction and analysis of protein contact maps (CMA) and molecular docking software (LIGIN). The SPACE suite is accessed at http://ligin.weizmann.ac.il/space.	cma-es;complementarity theory;crystal oscillator;docking (molecular);gentian violet;hepatitis b surface antigens;imagery;java programming language;jmol;mdl chime;map;nucleic acids;pcsk7 gene;protein structure prediction;protein, organized by structure;structural analysis;chaperone-mediated autophagy	Vladimir Sobolev;Eran Eyal;Sergey Gerzon;Vladimir Potapov;Mariana Babor;Jaime Prilusky;Marvin Edelman	2005	Nucleic Acids Research	10.1093/nar/gki398	biology;nucleic acid;bioinformatics;genetics	Comp.	-2.659309761622407	-58.90391067152408	86328
41126abad75d66f9c71208d70e5750ddf8287928	dbd: a transcription factor prediction database	prediction method;animals;sequence comparison;regulation of gene expression;mice;dna binding proteins;genome annotation;hidden markov model;protein sequence;dna binding;transcription factors;dna binding domain;internet;protein structure tertiary;transcription factor;sequence homology amino acid;user computer interface;dna sequence;tree of life;markov chains;biological process;databases protein	Regulation of gene expression influences almost all biological processes in an organism; sequence-specific DNA-binding transcription factors are critical to this control. For most genomes, the repertoire of transcription factors is only partially known. Hitherto transcription factor identification has been largely based on genome annotation pipelines that use pairwise sequence comparisons, which detect only those factors similar to known genes, or on functional classification schemes that amalgamate many types of proteins into the category of 'transcription factor'. Using a novel transcription factor identification method, the DBD transcription factor database fills this void, providing genome-wide transcription factor predictions for organisms from across the tree of life. The prediction method behind DBD identifies sequence-specific DNA-binding transcription factors through homology using profile hidden Markov models (HMMs) of domains. Thus, it is limited to factors that are homologus to those HMMs. The collection of HMMs is taken from two existing databases (Pfam and SUPERFAMILY), and is limited to models that exclusively detect transcription factors that specifically recognize DNA sequences. It does not include basal transcription factors or chromatin-associated proteins, for instance. Based on comparison with experimentally verified annotation, the prediction procedure is between 95% and 99% accurate. Between one quarter and one-half of our genome-wide predicted transcription factors represent previously uncharacterized proteins. The DBD (www.transcriptionfactor.org) consists of predicted transcription factor repertoires for 150 completely sequenced genomes, their domain assignments and the hand curated list of DNA-binding domain HMMs. Users can browse, search or download the predictions by genome, domain family or sequence identifier, view families of transcription factors based on domain architecture and receive predictions for a protein sequence.	amino acid sequence;annotation;basal (phylogenetics);browsing;code coverage;dna binding site;defective by design;download;experiment;fungi;gene expression regulation;genome;greater than;hidden markov model;homologous gene;homology (biology);hope (emotion);identifier;interface device component;line mode browser;markov chain;medical transcription;mitolactol;nar 2;ninety nine;pfam;pipeline (computing);superfamily;scop;shading;splice (system call);staphylococcal protein a;transcription factor;thirteen;transcription (software);transcription, genetic;transcriptional regulation;user interface	Sarah K. Kummerfeld;Sarah A. Teichmann	2006	Nucleic Acids Research	10.1093/nar/gkj131	biology;molecular biology;bioinformatics;cis-regulatory module;genetics;hidden markov model;transcription factor	Comp.	0.4081403679712111	-59.335209805692884	86366
97bdb923675d88e9cfc38b302f880c293738d6ca	n-acyl homoserine lactone-producing pseudomonas putida strain t2-2 from human tongue surface	n acylhomoserine lactone;pheromones;4 butyrolactone;quorum quenching;oral buccal cavity;quorum sensing;autoinducer;bioreporter;tongue;humans;pseudomonas putida;luxs;species specificity	Bacterial cell-to-cell communication (quorum sensing) refers to the regulation of bacterial gene expression in response to changes in microbial population density. Quorum sensing bacteria produce, release and respond to chemical signal molecules called autoinducers. Bacteria use two types of autoinducers, namely autoinducer-1 (AI-1) and autoinducer-2 (AI-2) where the former are N-acylhomoserine lactones and the latter is a product of the luxS gene. Most of the reported literatures show that the majority of oral bacteria use AI-2 for quorum sensing but rarely the AI-1 system. Here we report the isolation of Pseudomonas putida strain T2-2 from the oral cavity. Using high resolution mass spectrometry, it is shown that this isolate produced N-octanoylhomoserine lactone (C8-HSL) and N-dodecanoylhomoserine lactone (C12-HSL) molecules. This is the first report of the finding of quorum sensing of P. putida strain T2-2 isolated from the human tongue surface and their quorum sensing molecules were identified.	biosensors;body cavities;cell communication;dental caries;gene expression;genes, bacterial;image resolution;lactones;literature;microsoft outlook for mac;oral cavity;tandem mass spectrometry;quorum sensing;romidepsin	Jian Woon Chen;Shenyang Chin;Kok-Keng Tee;Wai-Fong Yin;Yeun-Mun Choo;Kok Gan Chan	2013		10.3390/s131013192	biochemistry;quorum sensing;bioreporter;autoinducer;sex pheromone	Mobile	5.019401233834998	-63.7789823876408	86431
ed10b2fa88925485c03790837d6838a1e9f9de05	distinct subfamilies of primate l1gg retroposons, with some elements carrying tandem repeats in the 5' region	dna;transcription genetic;secuencia repetida en tandem;evolution moleculaire;mouse;5 terminal sequence;animals;carte restriction;mammalia;secuencia 5 terminal;concensus sequence;estudio comparativo;tandemly repeated sequence;galago;hombre;vertebrata;secuencia nucleotido;element l1;repetitive sequences nucleic acid;sequence concensus;rodentia;raton;nucleotide sequence;sequence nucleotide;etude comparative;transposition;sequence 5 terminale;evolucion molecular;comparacion interespecifica;molecular evolution;restriction map;homology;promoter regions genetic;souris;elemento transportable;galago garnetti;human;comparative study;element transposable;primates;tandem repeat;molecular sequence data;mapa restriccion;base sequence;transposable element;homologia;interspecific comparison;lemuroidea;homme;comparaison interspecifique;transposicion;homologie;sequence repetee en tandem	Two subfamilies of L1 elements, differing dramatically in the first 1.2 kb of sequence at their 5' ends, were identified in the prosimian primate, Galago garnetti. Interesting patterns of sequence similarity were observed between the galago subfamilies, and with the L1s from human and from another prosimian, the slow loris. Furthermore, members of one of the subfamilies have six to eight tandemly repeated units of 73 bp, starting about 730 bp from their 5' ends. Such tandem repeats have not been reported in other primate L1s, but a striking sequence similarity was found between the galago tandem repeats and those previously described at the 5' termini of some mouse L1s [Loeb, D. D. et al. Mol. Cell. Biol. 6, 168-182, 1986]. Although the similar sequence indicates a shared, conserved function, the galago repeats are sub-terminal and therefore cannot serve as portable RNA polymerase II promoters, as has been suggested for the mouse tandem repeats.	5' region;galago genus;homology (biology);long interspersed nucleotide element-1;pierre robin syndrome;primates;rna polymerase ii;sequence alignment;tandem repeat sequences;promoter	Joyce A. Lloyd;S. Steven Potter	1988	Nucleic acids research	10.1093/nar/16.13.6147	biology;homology;transposable element;transposition;molecular evolution;nucleic acid sequence;bioinformatics;restriction map;direct repeat;comparative research;genetics;dna;tandem repeat	Comp.	3.9055864854388633	-63.55364003675601	86577
d5d46aa7a2442d3304dc46080ee4e6a68603e146	prediction of selenoproteins based on motif recognition	motif recognition;computational method;proteomics proteins;gpx1 family;proteins;gpx1 family selenoproteins prediction motif recognition multiple em for motif elicitation;amino acids sequences proteins predictive models organisms pulse width modulation educational institutions software learning systems humans;false positive;proteomics;selenoproteins prediction;multiple em for motif elicitation	−At present available computational methods can not predict selenoproteins correctly because of the special features of selenoproteins. It is known that there are some conservative sections around U in selenoproteins from previous research. So we bring forward a new method to predict selenoproteins based on motif recognition, we use Multiple Em for Motif Elicitation (MEME) to discover motif around U in selenoproteins and then predict selenoproteins based on the motif. The new method found all the selenoproteins in 9 seleno families expect one false positive in family of GPX1 and one in SelS. From the experiment, it is showed that this method can effectively predict almost all the selenoproteins in the known seleno families, and better than the methods of locating the position of U and blasting the Sec/Cys pairing based on handcraft. Keywords−Selenoproteins, Prediction, MEME, Motif	meme;multiple em for motif elicitation	Lan Tao;Geng Liu;Xiaoli Wang	2009	2009 2nd International Conference on Biomedical Engineering and Informatics	10.1109/BMEI.2009.5302720	biology;type i and type ii errors;computer science;bioinformatics;data mining;proteomics;multiple em for motif elicitation	Robotics	9.565678261050953	-55.148016723866405	86599
b6e78d11e9943a30b3dd15a6b0f031512804a1b1	behavioral sequence analysis reveals a novel role for                     ß2* nicotinic receptors in exploration	animals;mice;mice knockout;hyperkinesis;behavior animal;nicotinic acetylcholine receptor;open field;first order;nicotinic receptor;brain structure;wild type mice;receptors nicotinic;sequence analysis;brain function;central nervous system;exploratory behavior;statistics nonparametric;markov chains;markov chain	"""Nicotinic acetylcholine receptors (nAChRs) are widely expressed throughout the central nervous system and modulate neuronal function in most mammalian brain structures. The contribution of defined nAChR subunits to a specific behavior is thus difficult to assess. Mice deleted for beta2-containing nAChRs (beta2-/-) have been shown to be hyperactive in an open-field paradigm, without determining the origin of this hyperactivity. We here develop a quantitative description of mouse behavior in the open field based upon first order Markov and variable length Markov chain analysis focusing on the time-organized sequence that behaviors are composed of. This description reveals that this hyperactivity is the consequence of the absence of specific inactive states or """"stops"""". These stops are associated with a scanning of the environment in wild-type mice (WT), and they affect the way that animals organize their sequence of behaviors when compared with stops without scanning. They characterize a specific """"decision moment"""" that is reduced in beta2-/- mutant mice, suggesting an important role of beta2-nAChRs in the strategy used by animals to explore an environment and collect information in order to organize their behavior. This integrated analysis of the displacement of an animal in a simple environment offers new insights, specifically into the contribution of nAChRs to higher brain functions and more generally into the principles that organize sequences of behaviors in animals."""	acetylcholine;cns disorder;cholinergic receptors;displacement mapping;hyperactive behavior;mammals;markov chain;nicotinic receptors;physical inactivity;programming paradigm;psychologic displacement;sequence analysis	Nicolas Maubourguet;Annick Lesne;Jean-Pierre Changeux;Uwe Maskos;Philippe Faure	2008	PLoS Computational Biology	10.1371/journal.pcbi.1000229	biology;markov chain;simulation;statistics	Comp.	9.134456629038384	-65.74148138354164	86739
4f92be14da4a8b64d04c41fa7961b43027fd0635	nonisotopic sscp and competitive pcr for dna quantification: p53 in breast cancer cells	dosage;breast neoplasms;breast cancer cells;tumor cells cultured;deteccion;reaction chaine polymerase;analisis cuantitativo;mammary gland;gene suppresseur tumeur;methode;dna single stranded;detection;polymorphism genetic;polymerase chain reaction;glandula mamaria;dna cromosomico;genes p53;reaccion cadena polimerasa;gene p53;gene amplification;dosificacion;analyse quantitative;dna chromosomique;tumor;tumor suppressor gene;assay;nucleic acid conformation;quantitative analysis;tumeur;amplificacion genica;glande mammaire;humans;metodo;method;chromosome dna;amplification genique	PCR product yield does not quantitatively reflect the original concentration of template DNA due to variations in amplification efficiency (1,2). This necessitates the coamplification of known amounts of a control standard. The control template may be of different size (1,2) but this assumes that length difference does not affect amplification efficiencies. Alternatively, an internal restriction site may be created or deleted in the mutant competitor (2); however digestion-resistant heteroduplexes must either be minimised by limiting the reaction to the linear phase or maximised by a denaturation-reannealing step that results in a binomial distribution of duplexes. These difficulties may be circumvented by the use of single-strand confomation polymorphism (SSCP) (3) to detect single base-pair differences. We describe here the quantification of the p53 gene and alleles in genomic DNA extracted from MDA cells and human breast cancer biopsies respectively, using a rapid nonisotopic SSCP method. The p53 gene in the breast cancer cell line, MDA-MB-231 (ATCC), can be distinguished from the cDNA plasmid by nonisotopic SSCP, based on a single base polymorphism ('G'vs 'C') in codon 72 (4). Serial 1:2 dilutions of plasmid DNA were added to fixed amounts of MDA DNA. A 185-bp fragment spanning the polymorphic site was amplified in 20 /tl reactions by PCR. p53 was also amplified from paired blood and tumour DNA samples from breast cancer patients. Non-isotopic SSCP was then performed (4). Three bands representing a DNA duplex and two single strands were seen with the slower migrating single-stranded band showing sequence-dependent mobility (Fig. la, b). The relative amount of allelic products correlated with the initial concentrations of templates in the dilution series visually (Fig. la, b) and by densitometry (Fig. lc). Increasing the amount of target DNA gave the expected shift in cross-over of relative band intensities. Furthermore, increasing the yield to saturation limits by lowering the denaturation temperature (5) did not affect the band pattern and only increased the brightness of both bands (Fig. la). The initial amount of DNA template could be quantitated in absolute terms within a factor of 2. Relative loss of a p53 allele in human tumour DNA of constitutionally heterozygous individuals could also be demonstrated (Fig. Id).	3,4-methylenedioxyamphetamine;bands;biopsy;clinical use template;dna computing;dna, complementary;densitometry;duplex (telecommunications);efficiency;emoticon;extraction;file spanning;ibm systems network architecture;lc circuit;lactic acid;linear algebra;linear phase;mammary neoplasms;patients;quantitation;strand (programming language);tomography, emission-computed, single-photon;wnt signaling pathway involved in midbrain dopaminergic neuron differentiation;xfig;brightness;cancer cell	Eric P. H. Yap;James O'D. McGee	1992	Nucleic acids research	10.1093/nar/20.1.145	cancer research;biology;molecular biology;method;quantitative analysis;polymerase chain reaction;assay;genetics	Comp.	4.156066237413319	-63.90415559376425	86923
18f4a821369cfee980b1bd75f748d5d9f679fea3	the many faces of sequence alignment	sequence alignment	Starting with the sequencing of the mouse genome in 2002, we have entered a period where the main focus of genomics will be to compare multiple genomes in order to learn about human biology and evolution at the DNA level. Alignment methods are the main computational component of this endeavour. This short review aims to summarise the current status of research in alignments, emphasising large-scale genomic comparisons and suggesting possible directions that will be explored in the near future.	align (company);biopolymer sequencing;breakpoint;computation;dna sequence rearrangement;database;dizziness;endeavour (supercomputer);face;function (biology);functional genomics;gene duplication abnormality;gene prediction;genome;homology (biology);jurassic park;mammals;numerous;on the fly;phylogenetic tree;phylogenetics;population;question (inquiry);seamless3d;sequence alignment;sequence alignment;sequence analysis;sequence homology;synteny;tree (data structure)	Serafim Batzoglou	2005	Briefings in bioinformatics	10.1093/bib/6.1.6	biology;computer science;bioinformatics;sequence alignment	Comp.	0.7657268477665687	-63.065103221690116	86997
82dd1b6357e6d9f19bf4b7e7585f18dd191f29e7	asmpks: an analysis system for modular polyketide synthases	genetic engineering;computers;carbon;software;catalytic domain;genomics;chemical composition;models theoretical;protein sequence;web interface;enzyme;models biological;multienzyme complexes;computational biology bioinformatics;biological activity;genome bacterial;algorithms;polyketide synthase;computer analysis;combinatorial libraries;secondary metabolites;computational biology;computer appl in life sciences;polyketide synthases;genome sequence;microarrays;bioinformatics	Polyketides are secondary metabolites of microorganisms with diverse biological activities, including pharmacological functions such as antibiotic, antitumor and agrochemical properties. Polyketides are synthesized by serialized reactions of a set of enzymes called polyketide synthase(PKS)s, which coordinate the elongation of carbon skeletons by the stepwise condensation of short carbon precursors. Due to their importance as drugs, the volume of data on polyketides is rapidly increasing and creating a need for computational analysis methods for efficient polyketide research. Moreover, the increasing use of genetic engineering to research new kinds of polyketides requires genome wide analysis. We describe a system named ASMPKS (Analysis System for Modular Polyketide Synthesis) for computational analysis of PKSs against genome sequences. It also provides overall management of information on modular PKS, including polyketide database construction, new PKS assembly, and chain visualization. ASMPKS operates on a web interface to construct the database and to analyze PKSs, allowing polyketide researchers to add their data to this database and to use it easily. In addition, the ASMPKS can predict functional modules for a protein sequence submitted by users, estimate the chemical composition of a polyketide synthesized from the modules, and display the carbon chain structure on the web interface. ASMPKS has powerful computation features to aid modular PKS research. As various factors, such as starter units and post-processing, are related to polyketide biosynthesis, ASMPKS will be improved through further development for study of the factors.	amino acid sequence;computation;genetic engineering;interface device component;microorganism;name;pharmacology;polyketides;skeleton;staphylococcal protein a;stepwise regression;user interface;video post-processing;negative regulation of polyketide biosynthetic process;polyketide synthase	Hongseok Tae;Eun-Bae Kong;Kiejung Park	2007	BMC Bioinformatics	10.1186/1471-2105-8-327	carbon;genetic engineering;biology;enzyme;chemical composition;genomics;whole genome sequencing;dna microarray;bioinformatics;protein sequencing;biological activity;user interface	Comp.	0.24186392515478133	-59.78138881810049	87122
15a5f96935f72851febf6c31aec89bef173e16df	towards mechanism classifiers: expression-anchored gene ontology signature predicts clinical outcome in lung adenocarcinoma patients	transcriptome;gene expression profiling	We aim to provide clinically applicable, reproducible, mechanistic interpretations of gene expression changes that lack in gene overlap among predictive gene-signatures. Using a method we recently developed, Functional Analysis of Individual Microarray Expression (FAIME), we provide evidence that Gene Ontology-anchored signatures (GO-signatures) show reliable prognosis in lung cancer. In order to demonstrate the biological congruence and reproducibility of FAIME-derived mechanism classifiers, we chose a disease where gene expression classifiers signatures alone had failed to significantly stratify a larger collection of samples and that exhibited poor or no genetic overlap. For each patient in the two lung adenocarcinoma studies, personalized FAIME-profiles of GO biological processes are generated from genome-wide expression profiles. For both training studies, GO-signatures significantly associated to patient mortality were identified (Prediction Analysis for Microarrays; three-fold cross-validation). These two GO-signatures could effectively stratify patients from an independent validation cohort into sub-groups that show significant differences in disease-free survival (log-rank test P=0.019; P=0.001). Importantly, significant mechanism overlaps assessed by information-theory similarity were detected between the two GO-signatures (Fischer Exact Test p=0.001). Hence, together with machine learning technologies, FAIME could be utilized to develop an ontology-driven and expression-anchored prognostic signature that is personalized for an individual patient.	adenocarcinoma of lung (disorder);antivirus software;carcinoma of lung;choose (action);congruence of squares;cross reactions;cross-validation (statistics);dna microarray;digital curation;gene expression;gene ontology;gene prediction;informatics;information theory;interpretation process;laboratory procedures;large;machine learning;manuscripts;michael j. fischer;non-small cell lung carcinoma;parsing expression grammar;patients;personalization;population;programming paradigm;snord54 gene;type signature	Xinan Yang;Haiquan Li;Kelly Regan;Jianrong Li;Yong Huang;H. Rosie Xing;Yves A. Lussier	2012	AMIA ... Annual Symposium proceedings. AMIA Symposium		dna microarray;gene expression;functional analysis;lung cancer;transcriptome;gene expression profiling;microarray;adenocarcinoma;bioinformatics;biology	Comp.	6.9574823336159755	-55.53684427688639	87130
2bfaec392b427471aaea35fbe37024ce9b91b484	tmrdb (tmrna database)	phylogeny;rna messenger;databases nucleic acid;rna bacterial;internet;prokaryotic cells;nucleic acid conformation;sequence alignment;bacteria;databases factual;rna transfer	The tmRNA database (tmRDB) is maintained at the University of Texas Health Science Center at Tyler, Texas, and is accessible on the WWW at URL http://psyche.uthct.edu/dbs/tmRDB/tmRDB.++ +html. A tmRDB mirror site is located on the campus of Auburn University, Auburn, Alabama, reachable at the URL http://www.ag.auburn.edu/mirror/tmRDB/. Since April 1997, the tmRDB has provided sequences of tmRNA (previously called 10Sa RNA), a molecule present in most bacteria and some organelles. This release adds 17 new sequences for a total of 60 tmRNAs. Sequences and corresponding tmRNA-encoded tag peptides are tabulated in alphabetical and phylo-genetic order. The updated tmRNA alignment improves the secondary structures of known tmRNAs on the level of individual basepairs. tmRDB also provides an introduction to tmRNA function in trans-translation (with links to relevant literature), a limited number of tmRNA secondary structure diagrams, and numerous three-dimensional models generated interactively with the program ERNA-3D.		Christian Zwieb;Jan Gorodkin;Bjarne Knudsen;Jody Burks;Jacek Wower	2000	Nucleic acids research	10.1093/nar/gkg019	biology;the internet;bacteria;bioinformatics;sequence alignment;phylogenetics	Comp.	-2.03579851778387	-60.41960182086294	87216
a3267fcba7583448438773ba8efcb8cbd304d817	the modular organization of protein interactions in escherichia coli	escherichia coli;cell cycle and cell division;protein complex;bacterial evolution;dna polymerase;signal transduction;models biological;genetic networks;multienzyme complexes;gene expression;biosynthesis;molecular evolution;evolutionary genetics;escherichia coli proteins;cell wall;protein interaction;protein interaction mapping;computer simulation;protein interaction networks;physical interaction;protein interactions	Escherichia coli serves as an excellent model for the study of fundamental cellular processes such as metabolism, signalling and gene expression. Understanding the function and organization of proteins within these processes is an important step towards a 'systems' view of E. coli. Integrating experimental and computational interaction data, we present a reliable network of 3,989 functional interactions between 1,941 E. coli proteins ( approximately 45% of its proteome). These were combined with a recently generated set of 3,888 high-quality physical interactions between 918 proteins and clustered to reveal 316 discrete modules. In addition to known protein complexes (e.g., RNA and DNA polymerases), we identified modules that represent biochemical pathways (e.g., nitrate regulation and cell wall biosynthesis) as well as batteries of functionally and evolutionarily related processes. To aid the interpretation of modular relationships, several case examples are presented, including both well characterized and novel biochemical systems. Together these data provide a global view of the modular organization of the E. coli proteome and yield unique insights into structural and evolutionary relationships in bacterial networks.	anabolism;dna-directed dna polymerase;fundamental interaction;gene expression;nitrate;proteome;rna;biological signaling;cell wall biogenesis	José M. Peregrín-Alvarez;Xuejian Xiong;Chong Su;John Parkinson	2009		10.1371/journal.pcbi.1000523	protein–protein interaction;computer simulation;biology;molecular biology;gene expression;molecular evolution;bioinformatics;multiprotein complex;dna polymerase;human evolutionary genetics;escherichia coli;genetics;biosynthesis;cell wall;signal transduction	Comp.	6.017782353983513	-60.957612757996124	87331
0b7afa927a282ca0c7cdaa2d8b58ed9617ad1364	applying support vector machines for gene ontology based gene function prediction	genes;animals;functional annotation;controlled vocabulary;mice;rats;average precision;large dataset;databases genetic;xenopus laevis;computational biology bioinformatics;genes fungal;large scale;genes helminth;predictive value of tests;classification system;artificial intelligence;algorithms;genes plant;cross validation;support vector machine;neural networks computer;combinatorial libraries;computational biology;gene function;genes bacterial;computer appl in life sciences;genes protozoan;genes insect;microarrays;bioinformatics;gene ontology	The current progress in sequencing projects calls for rapid, reliable and accurate function assignments of gene products. A variety of methods has been designed to annotate sequences on a large scale. However, these methods can either only be applied for specific subsets, or their results are not formalised, or they do not provide precise confidence estimates for their predictions. We have developed a large-scale annotation system that tackles all of these shortcomings. In our approach, annotation was provided through Gene Ontology terms by applying multiple Support Vector Machines (SVM) for the classification of correct and false predictions. The general performance of the system was benchmarked with a large dataset. An organism-wise cross-validation was performed to define confidence estimates, resulting in an average precision of 80% for 74% of all test sequences. The validation results show that the prediction performance was organism-independent and could reproduce the annotation of other automated systems as well as high-quality manual annotations. We applied our trained classification system to Xenopus laevis sequences, yielding functional annotation for more than half of the known expressed genome. Compared to the currently available annotation, we provided more than twice the number of contigs with good quality annotation, and additionally we assigned a confidence value to each predicted GO term. We present a complete automated annotation system that overcomes many of the usual problems by applying a controlled vocabulary of Gene Ontology and an established classification method on large and well-described sequence data sets. In a case study, the function for Xenopus laevis contig sequences was predicted and the results are publicly available at ftp://genome.dkfz-heidelberg.de/pub/agd/gene_association.agd_Xenopus .	annotation;benchmark (computing);biopolymer sequencing;classification;controlled vocabulary;cross reactions;cross-validation (statistics);eighty;estimated;gene ontology;greater than;information retrieval;personnameuse - assigned;silo (dataset);support vector machine;gene function	Arunachalam Vinayagam;Rainer König;Jutta Moormann;Falk Schubert;Roland Eils;Karl-Heinz Glatting;Sándor Suhai	2004	BMC Bioinformatics	10.1186/1471-2105-5-116	biology;support vector machine;controlled vocabulary;dna microarray;computer science;bioinformatics;predictive value of tests;gene;data mining;genetics;cross-validation	Comp.	8.80027089531662	-55.506551909422136	87487
60ea8255be2561dddcdcf674efea81e4e2188699	mirnafold: a web server for fast mirna precursor prediction in genomes		Computational methods are required for prediction of non-coding RNAs (ncRNAs), which are involved in many biological processes, especially at post-transcriptional level. Among these ncRNAs, miRNAs have been largely studied and biologists need efficient and fast tools for their identification. In particular, ab initio methods are usually required when predicting novel miRNAs. Here we present a web server dedicated for miRNA precursors identification at a large scale in genomes. It is based on an algorithm called miRNAFold that allows predicting miRNA hairpin structures quickly with high sensitivity. miRNAFold is implemented as a web server with an intuitive and user-friendly interface, as well as a standalone version. The web server is freely available at: http://EvryRNA.ibisc.univ-evry.fr/miRNAFold.	ab initio quantum chemistry methods;algorithm;genome;interface device component;micrornas;server (computer);server (computing);transcription, genetic;usability;web server;world wide web	Christophe Tav;Sébastien Tempel;Laurent Poligny;Fariza Tahi	2016		10.1093/nar/gkw459	bioinformatics	Comp.	-0.13462046803462352	-58.377341350543425	87606
7fbf837ab266b3ca0421167bbe0b7911181479d7	confac: automated application of comparative genomic promoter analysis to dna microarray datasets	software;animals;genomics;nf kappa b;mice;gene cluster;comparative genomics;transcription factor binding site;male;transcription factors;promoter analysis;sequence analysis dna;binding sites;ccaat enhancer binding proteins;ccaat enhancer binding protein delta;false positive rate;internet;gene expression analysis;prostatic neoplasms;promoter regions genetic;humans;user computer interface;dna microarray;high throughput;proof of principle;gene expression profiling;oligonucleotide array sequence analysis	The advent of DNA microarray technology and the sequencing of multiple vertebrate genomes has provided a unique opportunity for the integration of comparative genomics with high-throughput gene expression analysis. Here we describe the conserved transcription factor binding site (CONFAC) software that enables the high-throughput identification of conserved transcription factor binding sites (TFBSs) in the regulatory regions of hundreds of genes at a time (http://morenolab.whitehead.emory.edu/cgi-bin/confac/login.pl). The CONFAC software compares non-coding regulatory sequences between human and mouse genomes to enable identification of conserved TFBSs that are significantly enriched in promoters of gene clusters from microarray analyses compared to sets of unchanging control genes using a Mann-Whitney U-test. Analysis of random gene sets demonstrated that using our approach, over 98% of TFBSs had false positive rates below 5%. As a proof-of-principle, we have validated the CONFAC software using gene sets from four separate microarray studies and identified TFBSs known to be functionally important for regulation of each of the four gene sets.	binding sites;biopolymer sequencing;dna microarray format;dna binding site;genome;genomics;high-throughput computing;microarray analysis;regulatory sequences, nucleic acid;transcription factor;throughput;transcription (software);promoter	Suresh Karanam;Carlos Sanchez Moreno	2004	Nucleic acids research	10.1093/nar/gkh353	ccaat-enhancer-binding proteins;high-throughput screening;biology;genomics;molecular biology;the internet;gene expression;dna microarray;gene cluster;nfkb1;false positive rate;bioinformatics;binding site;gene expression profiling;comparative genomics;proof of concept;genetics;dna binding site;transcription factor	Comp.	0.018167129535841268	-58.906693144675494	87658
ce72dbcb414d7e2300b3cca5d146ed06fac6014a	targetatpsite: a template-free method for atp-binding sites prediction with residue evolution image sparse representation and classifier ensemble	protein functional annotation;classifier ensemble;residue evolution image;sparse representation;protein atp binding sites prediction	Understanding the interactions between proteins and ligands is critical for protein function annotations and drug discovery. We report a new sequence-based template-free predictor (TargetATPsite) to identify the Adenosine-5'-triphosphate (ATP) binding sites with machine-learning approaches. Two steps are implemented in TargetATPsite: binding residues and pockets predictions, respectively. To predict the binding residues, a novel image sparse representation technique is proposed to encode residue evolution information treated as the input features. An ensemble classifier constructed based on support vector machines (SVM) from multiple random under-samplings is used as the prediction model, which is effective for dealing with imbalance phenomenon between the positive and negative training samples. Compared with the existing ATP-specific sequence-based predictors, TargetATPsite is featured by the second step of possessing the capability of further identifying the binding pockets from the predicted binding residues through a spatial clustering algorithm. Experimental results on three benchmark datasets demonstrate the efficacy of TargetATPsite.	adenosine triphosphate;algorithm;automated theorem proving;benchmark (computing);binding sites;clinical use template;cluster analysis;drug discovery;encode;ensemble learning;interaction;kerrison predictor;ligands;machine learning;sparse approximation;sparse matrix;support vector machine;statistical cluster	Dong-Jun Yu;Jun Hu;Yan Huang;Hong-Bin Shen;Yong Qi;Zhenmin Tang;Jingyu Yang	2013	Journal of computational chemistry	10.1002/jcc.23219	sparse approximation	ML	9.541495772236775	-54.842580864418046	87695
b0ea52ef304e668a2c763dc4da97b5a59ad180a5	genome-wide identification of antioxidant component biosynthetic enzymes: comprehensive analysis of ascorbic acid and tocochromanols biosynthetic genes in rice	tocochromanols;expression analysis;l ascorbic acid;stress response;enzyme;transcription factors;antioxidant;l;ascorbic acid;transcription factor;mpss database;signaling pathway;computer analysis	During the last two decades, several exciting reports have provided many advances in the role and biosynthesis of l-ascorbic acid (AsA) and tocochromanols, including tocopherols and tocotrienols, in higher plants. There are increasing bodies of experimental evidence that demonstrate that AsA and tocochromanols (especially tocopherols) play an important role as antioxidants and nutrients in mammals and photosynthetic organisms and are also involved in plant responses to stimuli. Although AsA and tocochromanol biosynthesis pathways have been well characterized using Arabidopsis, these pathways are still poorly understood in rice, which is an economically important monocot cereal crop. In this study using computational analysis of sequenced rice genome, we identified eight and seven potential non-redundant members involved in AsA and tocochromanol biosynthetic pathways, respectively. The results reveal that the common feature of these gene promoters is the combination of light-responsive, hormone-responsive, and stress-responsive elements. These findings, together with expression analysis in the MPSS database, indicate that AsA and tocochromanols might be co-related with the complex signaling pathways involved in plant responses.		Yeonhwa Jo;Tae Kyung Hyun	2011	Computational biology and chemistry	10.1016/j.compbiolchem.2011.07.004	biology;biochemistry;botany;biotechnology;genetics;transcription factor	Comp.	5.250988903394503	-61.46721917391126	87700
6643e51823721bfe3f528d196eafb1a547af778e	modulemaster: a new tool to decipher transcriptional regulatory networks	cis regulatory module;cis regulatory modules;regulatory network;gene regulation;dynamic model;transcription factors;large scale;transcription factor;batch process;graphic user interface;matrix scan;sequence analysis;regulatory sequence analysis;transcriptional regulatory network	UNLABELLED In this article we present ModuleMaster, a novel application for finding cis-regulatory modules (CRMs) in sets of co-expressed genes. The application comes with a newly developed method which not only considers transcription factor binding information but also multivariate functional relationships between regulators and target genes to improve the detection of CRMs. Given only the results of a microarray and a subsequent clustering experiment, the program includes all necessary data and algorithms to perform every step to find CRMs. This workbench possesses an easy-to-use graphical user interface, together with job-processing and command-line options, making ModuleMaster a sophisticated program for large-scale batch processing. The detected CRMs can be visualized and evaluated in various ways, i.e., generating GraphML- and R-based whole regulatory network visualizations or generating SBML files for subsequent analytical processing and dynamic modeling.   AVAILABILITY ModuleMaster is freely available to academics as a webstart application and for download at http://www.ra.cs.uni-tuebingen.de/software/ModuleMaster/, including comprehensive documentation.	academia (organization);algorithm;batch processing;carcinoma in situ;cluster analysis;command-line interface;dna binding site;decipher prostate cancer test;documentation;download;gene regulatory network;graphml;graphical user interface;java web start;microarray;sbml;transcription factor;transcription (software);transcription, genetic;user interface device component;workbench;statistical cluster	Clemens Wrzodek;Adrian Schröder;Andreas Dräger;Dierk Wanke;Kenneth W. Berendzen;Marcel Kronfeld;Klaus Harter;Andreas Zell	2010	Bio Systems	10.1016/j.biosystems.2009.09.005	biology;computer science;bioinformatics;cis-regulatory module;data mining;world wide web;genetics;transcription factor	Comp.	-2.2987736929691587	-58.06534488125663	87929
23eb0fb1060bb9ee08bf8215f321fcf66e2102dd	inferring new drug indications using the complementarity between clinical disease signatures and drug effects	electronic clinical information;drug repositioning;clinical disease signatures;clinical drug effects	"""BACKGROUND Drug repositioning is the process of finding new indications for existing drugs. Its importance has been dramatically increasing recently due to the enormous increase in new drug discovery cost. However, most of the previous molecular-centered drug repositioning work is not able to reflect the end-point physiological activities of drugs because of the inherent complexity of human physiological systems.   METHODS Here, we suggest a novel computational framework to make inferences for alternative indications of marketed drugs by using electronic clinical information which reflects the end-point physiological results of drug's effects on the biological activities of humans. In this work, we use the concept of complementarity between clinical disease signatures and clinical drug effects. With this framework, we establish disease-related clinical variable vectors (clinical disease signature vectors) and drug-related clinical variable vectors (clinical drug effect vectors) by applying two methodologies (i.e., statistical analysis and literature mining). Finally, we assign a repositioning possibility score to each disease-drug pair by the calculation of complementarity (anti-correlation) and association between clinical states (""""up"""" or """"down"""") of disease signatures and clinical effects (""""up"""", """"down"""" or """"association"""") of drugs. A total of 717 clinical variables in the electronic clinical dataset (NHANES), are considered in this study.   RESULTS The statistical significance of our prediction results is supported through two benchmark datasets (Comparative Toxicogenomics Database and Clinical Trials). We discovered not only lots of known relationships between diseases and drugs, but also many hidden disease-drug relationships. For example, glutathione and edetic-acid may be investigated as candidate drugs for asthma treatment. We examined prediction results by using statistical experiments (enrichment verification, hyper-geometric and permutation test P<0.009 in Comparative Toxicogenomics Database and Clinical Trials) and presented evidences for those with already published literature.   CONCLUSION The results show that electronic clinical information is a feasible data resource and utilizing the complementarity (anti-correlated relationships) between clinical signatures of disease and clinical effects of drugs is a potentially predictive concept in drug repositioning research. It makes the proposed approach useful to identity novel relationships between diseases and drugs that have a high probability of being biologically valid."""	antivirus software;benchmark (computing);comparative toxicogenomics database (ctd);complementarity (physics);complementarity theory;drug discovery;drug repositioning;entity name part qualifier - adopted;experiment;gene ontology term enrichment;glutathione;hyperactive behavior;manuscripts;p-value;pharmaceutical preparations;repositioning (procedure);resampling (statistics);scientific publication;silo (dataset);thioctic acid;verification of theories	Dongjin Jang;Sejoon Lee;Jae-Hyun Lee;Kiseong Kim;Doheon Lee	2016	Journal of biomedical informatics	10.1016/j.jbi.2015.12.003	medicine;drug repositioning;computer science;bioinformatics	AI	7.2636443727908935	-55.777097074842864	88025
b44de2ad43d7a83ef29f2e948b2060d0603c3847	revealing metabolite biomarkers for acupuncture treatment by linear programming based feature selection	simulation and modeling;systems biology;physiological cellular and medical topics;computational biology bioinformatics;acupuncture points;metabolome;programming linear;期刊论文;algorithms;humans;acupuncture therapy;biological markers;bioinformatics	Acupuncture has been practiced in China for thousands of years as part of the Traditional Chinese Medicine (TCM) and has gradually accepted in western countries as an alternative or complementary treatment. However, the underlying mechanism of acupuncture, especially whether there exists any difference between varies acupoints, remains largely unknown, which hinders its widespread use. In this study, we develop a novel Linear Programming based Feature Selection method (LPFS) to understand the mechanism of acupuncture effect, at molecular level, by revealing the metabolite biomarkers for acupuncture treatment. Specifically, we generate and investigate the high-throughput metabolic profiles of acupuncture treatment at several acupoints in human. To select the subsets of metabolites that best characterize the acupuncture effect for each meridian point, an optimization model is proposed to identify biomarkers from high-dimensional metabolic data from case and control samples. Importantly, we use nearest centroid as the prototype to simultaneously minimize the number of selected features and the leave-one-out cross validation error of classifier. We compared the performance of LPFS to several state-of-the-art methods, such as SVM recursive feature elimination (SVM-RFE) and sparse multinomial logistic regression approach (SMLR). We find that our LPFS method tends to reveal a small set of metabolites with small standard deviation and large shifts, which exactly serves our requirement for good biomarker. Biologically, several metabolite biomarkers for acupuncture treatment are revealed and serve as the candidates for further mechanism investigation. Also biomakers derived from five meridian points, Zusanli (ST36), Liangmen (ST21), Juliao (ST3), Yanglingquan (GB34), and Weizhong (BL40), are compared for their similarity and difference, which provide evidence for the specificity of acupoints. Our result demonstrates that metabolic profiling might be a promising method to investigate the molecular mechanism of acupuncture. Comparing with other existing methods, LPFS shows better performance to select a small set of key molecules. In addition, LPFS is a general methodology and can be applied to other high-dimensional data analysis, for example cancer genomics.	acupuncture points;acupuncture and oriental medicine;acupuncture procedure;acupuncture therapy discipline;biological markers;clustering high-dimensional data;excretory function;feature selection;genetic selection;high-throughput computing;horner's method;linear programming;mathematical optimization;meridians;metabolic process, cellular;metabolic profile;metabolomics;multinomial logistic regression;nortel meridian;prototype;recursion;sensitivity and specificity;sparse matrix;standard deviation;throughput;toolkit for conceptual modeling;traditional chinese medicine;triangulation	Yong Wang;Qiao-Feng Wu;Chen Chen;Ling-Yun Wu;Xian-Zhong Yan;ShuGuang Yu;Xiang-Sun Zhang;Fan-Rong Liang	2012		10.1186/1752-0509-6-S1-S15	biology;bioinformatics;metabolome;systems biology	AI	8.565266008329584	-54.540617210770854	88178
6415a7a6ca7f5880734e8efa900bfb5d2e8b09bf	unipathway: a resource for the exploration and annotation of metabolic pathways	metabolic networks and pathways;molecular sequence annotation;serveur institutionnel;lysine;enzymes;archive institutionnelle;open access;archive ouverte unige;databases factual;cybertheses;institutional repository;databases protein	UniPathway (http://www.unipathway.org) is a fully manually curated resource for the representation and annotation of metabolic pathways. UniPathway provides explicit representations of enzyme-catalyzed and spontaneous chemical reactions, as well as a hierarchical representation of metabolic pathways. This hierarchy uses linear subpathways as the basic building block for the assembly of larger and more complex pathways, including species-specific pathway variants. All of the pathway data in UniPathway has been extensively cross-linked to existing pathway resources such as KEGG and MetaCyc, as well as sequence resources such as the UniProt KnowledgeBase (UniProtKB), for which UniPathway provides a controlled vocabulary for pathway annotation. We introduce here the basic concepts underlying the UniPathway resource, with the aim of allowing users to fully exploit the information provided by UniPathway.	annotation;controlled vocabulary;gene regulatory network;kegg;large;metacyc;spontaneous order;uniprot;uniprotkb	Anne Morgat;Eric Coissac;Elisabeth Coudert;Kristian B. Axelsen;Guillaume Keller;Amos Bairoch;Alan Bridge;Lydie Bougueleret;Ioannis Xenarios;Alain Viari	2012		10.1093/nar/gkr1023	biology;enzyme;bioinformatics	Comp.	-0.6986249294621936	-61.1238662019815	88186
fc002018eee636962f38bf960ab4d4ffcec84fad	prediction of scaffold proteins based on protein interaction and domain architectures	computational biology bioinformatics;algorithms;computer appl in life sciences;microarrays;bioinformatics	Motivation: Scaffold proteins are known as crucial regulators of various cellular functions by assembling multiple proteins involved in signaling and metabolic pathways. Identification of scaffold proteins and the study of their molecular mechanisms can open a new aspect of cellular systemic regulation and the resulting application on medicine and engineering. There have been highlighted the regulatory roles of dozens of scaffold proteins, but just one computational approach tried to find scaffold proteins from interactomes until now. However, there was a limitation to find diverse types of scaffold proteins because their criteria were restricted to the classical scaffold proteins.  Methods: Here we suggest a systematic approach to predict massive scaffold proteins from interactomes and to characterize the roles of scaffold proteins comprehensively. We gathered known and predicted scaffold proteins from articles and interactomes. First, we carried out extraction of known scaffold proteins from review articles and collection of scaffold protein candidates from the UniProt and the PubMed using query search. Second, we proposed criteria for finding scaffold proteins and predicted scaffold proteins from interactome according to the criteria. Scaffold proteins are defined as proteins that: (i) directly interact with at least two proteins, (ii) have domain-domain interactions with two partner proteins using different domain regions, and (iii) are component of the same protein complex with two partner proteins. To characterize functional roles, we assigned the localization, pathway, and enzyme information of their partner proteins and classified functional roles of them from their partners' function  Results: From total 10,419 basic scaffold protein candidates in protein interactomes, we classified them into three classes according to structural evidences for scaffolding, such as domain architectures, domain interactions and protein complexes. Finally, we could define 2,716 highly reliable scaffold protein candidates and characterized functional features of these scaffold proteins. To assess the accuracy of our prediction, the gold standard positive and negative data sets are constructed. We prepared 158 gold standard positive data and 844 gold standard negative data based on functional information from Gene Ontology consortium. The precision, sensitivity and specificity of our testing was 83.8%, 42.4%, and 90.1%, respectively. Through function enrichment analysis about highly reliable scaffold proteins, we could confirm significantly enriched functions related on binding and found unexpected functions like transcription regulator activity, kinase activity, and ubiquitin protein ligase binding, etc. Furthermore, we identified functional association between scaffold proteins and their recruited proteins. From these results, we inferred novel functional information of scaffold proteins from recruited proteins. We also compared disease association of scaffold proteins with kinases and the result showed that the disease association of scaffold proteins is higher than kinases. As revealing more understandings about the roles of scaffold proteins in future studies, scaffolds will be used as generate novel and predictable pathway to program useful cellular behaviors. In conclusion, our finding can support further investigation to understand scaffold proteins and discover targets for molecular engineering and therapy.	architecture as topic;behavior;class;classification;domain engineering;futures studies;gene ontology term enrichment;gene regulatory network;inference;interactome;internationalization and localization;internationalized domain name;personnameuse - assigned;pubmed;scaffold protein;sensitivity and specificity;transcription (software);uniprot;kinase activity;protein protein interaction;transcription regulator activity;ubiquitin-protein ligase	Kimin Oh;Gwan-Su Yi	2015		10.1186/s12859-016-1079-5	computational biology;biology;dna microarray;cell biology;computer science;bioinformatics	Comp.	6.816822244239754	-57.46036781435886	88320
8106e73a42db78b2b9b9fc10b0c0631c828b05e2	synthesis and reactivity of intermediates formed in the t4 rna ligase reaction	substrate specificity;escherichia coli;activite catalytique;intermediaire reaction;actividad catalitica;t phages;oligodeoxyribonucleotides;polynucleotide ligases;virus;catalyst activity;magnetic resonance spectroscopy;polyribonucleotide synthetase atp;indicators and reagents;rna ligase atp;reaction intermediate;bacteriophage t4;bacteriophage;kinetics;intermediario reaccion	The intermediate adenylated donor derivatives A(5')pp(5')dTp and A(5')pp(5')GpGpGp have been prepared from suitable phosphorylating reagents activated by 1-hydroxybenzotriazole. Phosphodiester bond formation between donor and acceptor oligonucleotides as catalyzed by T4 RNA ligase is shown to be more efficient when the adenylated form of the donor molecule is used.	1-hydroxybenzotriazole;acceptor (semiconductors);oligonucleotides;rna ligase (atp);reagents;negative regulation of rna-directed rna polymerase activity	Peter U. Hoffmann;Larry W. McLaughlin	1987	Nucleic acids research	10.1093/nar/15.13.5289	nuclear magnetic resonance spectroscopy;biology;biochemistry;molecular biology;virus;escherichia coli;genetics;kinetics;reaction intermediate	ML	7.196722022128364	-63.16196590633603	88529
40d3ecf93864a3dddb9bdb901a07bfa94ab0a53f	distinguishing between microrna targets from diverse species using sequence motifs and k-mers		A disease phenotype is often due to dysregulation of gene expression. Post-translational regulation of protein abundance by microRNAs (miRNAs) is, therefore, of high importance in, for example, cancer studies. MicroRNAs provide a complementary sequence to their target messenger RNA (mRNA) as part of a complex molecular machinery. Known miRNAs and targets are listed in miRTarBase for a variety of organisms. The experimental detection of such pairs is convoluted and, therefore, their computational detection is desired which is complicated by missing negative data. For machine learning, many features for parameterization of the miRNA targets are available and k-mers and sequence motifs have previously been used. Unrelated organisms like intracellular pathogens and their hosts may communicate via miRNAs and, therefore, we investigated whether miRNA targets from one species can be differentiated from miRNA targets of another. To achieve this end, we employed target information of one species as positive and the other as negative training and testing data. Models of species with higher evolutionary distance generally achieved better results of up to 97% average accuracy (mouse versus Caenorhabditis elegans) while more closely related species did not lead to successful models (human versus mouse; 60%). In the future, when more targeting data becomes available, models can be established which will be able to more precisely determine miRNA targets in hostpathogen systems using this approach.	complementary sequences;computation;k-mer;machine learning;sequence motif	Malik Yousef;Waleed Khalifa;Ilhan Erkin Acar;Jens Allmer	2017		10.5220/0006137901330139	bioinformatics;microrna;computer science;sequence motif	Comp.	4.0051537934432595	-59.33402486449605	88569
785239c7c74c0c02246cb39f779b0df51cd39c71	towards using probabilities and logic to model regulatory networks	genomics;probabilistic logical model;time series gene expression data analysis;cell response;transcriptional regulation;probability;network pathway;cellular decision;gene regulation;biological system modeling;time series;hog1 pathway;genetics;statistical relational learning bioinformatics gene regulation genomics network pathway;gene expression;proteins;statistical analysis;logic gates;diverse environmental cues;statistical relational learning;gene expression correlation probabilistic logic logic gates proteins biological system modeling;network hypotheses;logic based regulation models;regulatory network model;correlation;probabilistic logic;learning artificial intelligence;network hypotheses regulatory network model transcriptional regulation cellular decision cell response diverse environmental cues logic based regulation models statistical relational learning time series gene expression data analysis hog1 pathway probabilistic logical model;time series bioinformatics cellular biophysics genetics genomics learning artificial intelligence probabilistic logic probability statistical analysis;cellular biophysics;bioinformatics	Transcriptional regulation plays an important role in every cellular decision. Unfortunately, understanding the dynamics that govern how a cell will respond to diverse environmental cues is difficult using intuition alone. We introduce logic based regulation models based on state-of-the-art work on statistical relational learning, and validate our approach by using it to analyze time-series gene expression data of the Hog1 pathway. Our results show that plausible regulatory networks can be learned from time series gene expression data using a probabilistic logical model. Hence, network hypotheses can be generated from existing gene expression data for use by experimental biologists.	gene regulatory network;statistical relational learning;time series	António Gonçalves;Irene M. Ong;Jeffrey A. Lewis;Vítor Santos Costa	2014	2014 IEEE 27th International Symposium on Computer-Based Medical Systems	10.1109/CBMS.2014.9	genomics;regulation of gene expression;gene expression;statistical relational learning;logic gate;computer science;bioinformatics;machine learning;time series;probability;data mining;probabilistic logic;correlation;transcriptional regulation	Embedded	5.44772331199928	-58.71295148028724	88570
d4ce84827237c72e31627a6e6a3b79b13f5d7705	evolution and phenotypic selection of cancer stem cells	cell division analysis;cell cycle and cell division;disease progression;models biological;cancer stem cells;biopsy;evolutionary genetics;cell proliferation;humans;neoplasms;computational biology;phenotype;mutation;cell death;neoplastic stem cells;phenotypes;cancer cell migration	Cells of different organs at different ages have an intrinsic set of kinetics that dictates their behavior. Transformation into cancer cells will inherit these kinetics that determine initial cell and tumor population progression dynamics. Subject to genetic mutation and epigenetic alterations, cancer cell kinetics can change, and favorable alterations that increase cellular fitness will manifest themselves and accelerate tumor progression. We set out to investigate the emerging intratumoral heterogeneity and to determine the evolutionary trajectories of the combination of cell-intrinsic kinetics that yield aggressive tumor growth. We develop a cellular automaton model that tracks the temporal evolution of the malignant subpopulation of so-called cancer stem cells(CSC), as these cells are exclusively able to initiate and sustain tumors. We explore orthogonal cell traits, including cell migration to facilitate invasion, spontaneous cell death due to genetic drift after accumulation of irreversible deleterious mutations, symmetric cancer stem cell division that increases the cancer stem cell pool, and telomere length and erosion as a mitotic counter for inherited non-stem cancer cell proliferation potential. Our study suggests that cell proliferation potential is the strongest modulator of tumor growth. Early increase in proliferation potential yields larger populations of non-stem cancer cells(CC) that compete with CSC and thus inhibit CSC division while a reduction in proliferation potential loosens such inhibition and facilitates frequent CSC division. The sub-population of cancer stem cells in itself becomes highly heterogeneous dictating population level dynamics that vary from long-term dormancy to aggressive progression. Our study suggests that the clonal diversity that is captured in single tumor biopsy samples represents only a small proportion of the total number of phenotypes.	biological evolution;cancer stem cells;cell cycle kinetics (discipline);cell death;cell proliferation;cell division;cellular automaton;central serous chorioretinopathy;cessation of life;clone;color gradient;genetic drift;genetic heterogeneity;genetic selection;kinetics internet protocol;large;modulation;modulator device component;neoplasms;organ;phenotype;population;semantic heterogeneity;spontaneous order;stem cell self-renewal;stem of plant;total number;track (course);trait;tree accumulation;tumor progression;cancer cell;telomere	Jan Poleszczuk;Philip Hahnfeldt;Heiko Enderling	2015		10.1371/journal.pcbi.1004025	biology;cell biology;phenotype;genetics	ML	6.787909055638346	-63.27417941112793	88627
c413004aea0a277f03ae12979ea7930c080cf949	spliced alignment: a new approach to gene recognition	alternative splicing;software tool;amino acid;genetic mapping;computational molecular biology;artificial intelligent;large scale;human chromosomes;cdna sequence;computer calculations;polynomial time;pattern recognition;gene structure;codon usage;codons;biology and medicine basic studies;exons	Gene structure prediction is one of the most important problems in computational molecular biology. Previous attempts to solve this problem were based on statistics and artificial intelligence and, surprisingly enough, applications of theoretical computer science methods for gene recognition were almost unexplored. Recent advances in large-scale cDNA sequencing open a way towards a new combinatorial approach to gene recognition. This paper describes a spliced alignment algorithm and a software tool which explores all possible exon assemblies in polynomial time and finds the multi-exon structure with the best fit to a related protein. Unlike other existing methods, the algorithm successfully recognizes genes even in the case of short exons or exons with unusual codon usage; the authors also report correct assemblies for genes with more than 10 exons. On a test sample of human genes with known mammalian relatives the average correlation between the predicted and the actual genes was 99%, which is a very high accuracy as compared with other existing methods. The algorithm correctly reconstructed 87% of genes and the rare discrepancies between the predicted and real exon-intron structures were caused by either (i) extremely short (less than 5 amino acids) initial or terminal exons, or (ii) alternative splicing,more » or (iii) errors in database feature tables. 38 refs., 3 tabs.« less		Mikhail S. Gelfand;Andrey A. Mironov;Pavel A. Pevzner	1996		10.1007/3-540-61258-0_12	time complexity;codon usage bias;amino acid;gene mapping;exon;bioinformatics;alternative splicing;gene;chromosome;genetic code;genetics	Vision	-0.11404368404570488	-52.97346703932674	88655
151b8b2afc2bfee59a632dc71f31d41a3ace3c29	effects of double-strand break repair proteins on vertebrate telomere structure	gene deletion;animals;antigens nuclear;dna binding proteins;non homologous end joining;saccharomyces cerevisiae proteins;telomere length;double strand break;telomere;homologous recombination;avian proteins;dna helicases;double strand break repair;nuclear proteins;humans;dna repair;rad51 recombinase;mutation;cell line	Although telomeres are not recognized as double-strand breaks (DSBs), some DSB repair proteins are present at telomeres and are required for telomere maintenance. To learn more about the telomeric function of proteins from the homologous recombination (HR) and non-homologous end joining pathways (NHEJ), we have screened a panel of chicken DT40 knockout cell lines for changes in telomere structure. In contrast to what has been observed in Ku-deficient mice, we found that Ku70 disruption did not result in telomere-telomere fusions and had no effect on telomere length or the structure of the telomeric G-strand overhang. G-overhang length was increased by Rad51 disruption but unchanged by disruption of DNA-PKcs, Mre11, Rad52, Rad54, XRCC2 or XRCC3. The effect of Rad51 depletion was unexpected because gross alterations in telomere structure have not been detected in yeast HR mutants. Thus, our results indicate that Rad51 has a previously undiscovered function at vertebrate telomeres. They also indicate that Mre11 is not required to generate G-overhangs. Although Mre11 has been implicated in overhang generation, overhang structure had not previously been examined in Mre11-deficient cells. Overall our findings indicate that there are significant species-specific differences in the telomeric function of DSB repair proteins.	dna breaks, double-stranded;denial-of-service attack;depletion region;depletion-load nmos logic;double strand break repair;knockout;ku protein;ku band;ku70 protein;mre11a gene;mre11a wt allele;non-homologous dna end-joining;nucleic acid strand;projection screen;rad51 gene;strand (programming language);telomere maintenance;xrcc2 protein, human;xrcc3 protein, human;double-strand break repair via homologous recombination;mutant;non-t, non-b childhood acute lymphoblastic leukemia	Chao Wei;Rose Skopp;Minoru Takata;Shunichi Takeda;Carolyn M. Price	2002	Nucleic acids research	10.1093/nar/gkf396	mutation;biology;telomere;homologous recombination;dna-binding protein;molecular biology;non-homologous end joining;dna repair;telomere-binding protein;nuclear protein;genetics;cell culture	Comp.	4.875571631699025	-63.697059510853784	88661
623e2803d7e375a97c5eb9d4f742426baf3a4d36	identification of long non-coding transcripts with feature selection: a comparative study	computational biology bioinformatics;algorithms;computer appl in life sciences;microarrays;bioinformatics	The unveiling of long non-coding RNAs as important gene regulators in many biological contexts has increased the demand for efficient and robust computational methods to identify novel long non-coding RNAs from transcripts assembled with high throughput RNA-seq data. Several classes of sequence-based features have been proposed to distinguish between coding and non-coding transcripts. Among them, open reading frame, conservation scores, nucleotide arrangements, and RNA secondary structure have been used with success in literature to recognize intergenic long non-coding RNAs, a particular subclass of non-coding RNAs. In this paper we perform a systematic assessment of a wide collection of features extracted from sequence data. We use most of the features proposed in the literature, and we include, as a novel set of features, the occurrence of repeats contained in transposable elements. The aim is to detect signatures (groups of features) able to distinguish long non-coding transcripts from other classes, both protein-coding and non-coding. We evaluate different feature selection algorithms, test for signature stability, and evaluate the prediction ability of a signature with a machine learning algorithm. The study reveals different signatures in human, mouse, and zebrafish, highlighting that some features are shared among species, while others tend to be species-specific. Compared to coding potential tools and similar supervised approaches, including novel signatures, such as those identified here, in a machine learning algorithm improves the prediction performance, in terms of area under precision and recall curve, by 1 to 24%, depending on the species and on the signature. Understanding which features are best suited for the prediction of long non-coding RNAs allows for the development of more effective automatic annotation pipelines especially relevant for poorly annotated genomes, such as zebrafish. We provide a web tool that recognizes novel long non-coding RNAs with the obtained signatures from fasta and gtf formats. The tool is available at the following url: http://www.bioinformatics-sannio.org/software/ .	annotation;antivirus software;class;computation;contain (action);dna transposable elements;extraction;fasta;feature selection;genome;machine learning;open reading frame;pipeline (computing);precision and recall;rna;reading frames (nucleotide sequence);sequence number;throughput;transcript;type signature;zebrafish;algorithm;format;subclass	Giovanna M. M. Ventola;Teresa M. R. Noviello;Salvatore D'Aniello;Antonietta Spagnuolo;Michele Ceccarelli;Luigi Cerulo	2017		10.1186/s12859-017-1594-z	biology;dna microarray;computer science;bioinformatics;data mining;world wide web;genetics	Comp.	1.7525562268577366	-57.696526716721394	88671
a7b77e0ac14e6d59896bc86de3799276e2dcaa7c	improving compound-protein interaction prediction by building up highly credible negative samples		MOTIVATION Computational prediction of compound-protein interactions (CPIs) is of great importance for drug design and development, as genome-scale experimental validation of CPIs is not only time-consuming but also prohibitively expensive. With the availability of an increasing number of validated interactions, the performance of computational prediction approaches is severely impended by the lack of reliable negative CPI samples. A systematic method of screening reliable negative sample becomes critical to improving the performance of in silico prediction methods.   RESULTS This article aims at building up a set of highly credible negative samples of CPIs via an in silico screening method. As most existing computational models assume that similar compounds are likely to interact with similar target proteins and achieve remarkable performance, it is rational to identify potential negative samples based on the converse negative proposition that the proteins dissimilar to every known/predicted target of a compound are not much likely to be targeted by the compound and vice versa. We integrated various resources, including chemical structures, chemical expression profiles and side effects of compounds, amino acid sequences, protein-protein interaction network and functional annotations of proteins, into a systematic screening framework. We first tested the screened negative samples on six classical classifiers, and all these classifiers achieved remarkably higher performance on our negative samples than on randomly generated negative samples for both human and Caenorhabditis elegans. We then verified the negative samples on three existing prediction models, including bipartite local model, Gaussian kernel profile and Bayesian matrix factorization, and found that the performances of these models are also significantly improved on the screened negative samples. Moreover, we validated the screened negative samples on a drug bioactivity dataset. Finally, we derived two sets of new interactions by training an support vector machine classifier on the positive interactions annotated in DrugBank and our screened negative interactions. The screened negative samples and the predicted interactions provide the research community with a useful resource for identifying new drug targets and a helpful supplement to the current curated compound-protein databases.   AVAILABILITY Supplementary files are available at: http://admis.fudan.edu.cn/negative-cpi/.	amino acid sequence;amino acids;carbohydrate processing inhibitor;computation;computational model;database;drug delivery systems;drugbank;interaction network;kernel density estimation;normal statistical distribution;performance;procedural generation;projection screen;silo (dataset);support vector machine;protein protein interaction	Hui Liu;Jianjiang Sun;Jihong Guan;Jie Zheng;Shuigeng Zhou	2015	Bioinformatics	10.1093/bioinformatics/btv256	bioinformatics;machine learning;data mining	Comp.	9.89311639870601	-57.28318581058398	88754
7198f93569cd9af20a19c733909ce91336c42283	prediction of protein-protein binding site by using core interface residue and support vector machine	software;prediction method;sensitivity and specificity;recognition sites;amino acid sequence;protein docking;binding site;binding sites;functional sites;identify;data driven docking;computational biology bioinformatics;complexes;hot spots;protein structure;models genetic;proteins;capri;protein protein interaction;protein binding;algorithms;surfaces;support vector machine;combinatorial libraries;protein interaction;proteomics;sequence;computer appl in life sciences;information;microarrays;bioinformatics	The prediction of protein-protein binding site can provide structural annotation to the protein interaction data from proteomics studies. This is very important for the biological application of the protein interaction data that is increasing rapidly. Moreover, methods for predicting protein interaction sites can also provide crucial information for improving the speed and accuracy of protein docking methods. In this work, we describe a binding site prediction method by designing a new residue neighbour profile and by selecting only the core-interface residues for SVM training. The residue neighbour profile includes both the sequential and the spatial neighbour residues of an interface residue, which is a more complete description of the physical and chemical characteristics surrounding the interface residue. The concept of core interface is applied in selecting the interface residues for training the SVM models, which is shown to result in better discrimination between the core interface and other residues. The best SVM model trained was tested on a test set of 50 randomly selected proteins. The sensitivity, specificity, and MCC for the prediction of the core interface residues were 60.6%, 53.4%, and 0.243, respectively. Our prediction results on this test set were compared with other three binding site prediction methods and found to perform better. Furthermore, our method was tested on the 101 unbound proteins from the protein-protein interaction benchmark v2.0. The sensitivity, specificity, and MCC of this test were 57.5%, 32.5%, and 0.168, respectively. By improving both the descriptions of the interface residues and their surrounding environment and the training strategy, better SVM models were obtained and shown to outperform previous methods. Our tests on the unbound protein structures suggest further improvement is possible.	101 mouse;annotation;benchmark (computing);description;docking (molecular);docking -molecular interaction;interface device component;ligand binding domain;mcc gene;macromolecular docking;microelectronics and computer technology corporation;protein binding;proteomics;randomness;sensitivity and specificity;support vector machine;test set;protein protein interaction	Nan Li;Zhonghua Sun;Fan Jiang	2008	BMC Bioinformatics	10.1186/1471-2105-9-553	biology;molecular biology;computer science;bioinformatics;binding site;proteomics	Comp.	9.572407462275828	-56.421461364369414	88854
54ee48d183af75bb708e75950cf6123e3c910d9c	modern genome annotation . edited by dmitrij frishman and alfonso valencia	genome annotation			Dae-Won Kim;Hong-Seog Park	2010	Briefings in Bioinformatics	10.1093/bib/bbp040	biology;computer science;bioinformatics;genome project;genetics	Comp.	0.7913636468591937	-63.50589994392363	88872
7da26ca8d146f937a552ce9ac7ec246e60f3e00f	bioinformatics classification and functional analysis of phoh homologs	functional analysis	PhoH protein is a putative ATPase belonging to the phosphate regulon in Escherichia coli. EC-PhoH homologs are present in different organisms, but it is not clear if they are functionally related, besides nothing is known about their regulation. To distinguish true functional orthologs of EC-PhoH in different classes of bacteria and to identify their functional role in bacterial metabolic network we performed phylogenetic analysis of these proteins and comparative study of position and regulation of the related genes. Three groups of proteins were identified. Proteins of the first group (BS-PhoH orthologs) are present in most of bacteria and are proposed to be functionally linked to phospholipid metabolism and RNA modification. Proteins of the second group (BS-YlaK orthologs) are present in most of aerobes and Actinobacterial YlaK orthologs are shown to be members of a fatty acid beta-oxidation regulons. EC-PhoH orthologs are classified in a third group, specific for Enterobacteria. Functional role of PhoH homologs in the lipid and RNA metabolism and proposed interrelation of PhoH paralogs in one organism are discussed.	bacteria, aerobic;bioinformatics;class;classification;fatty acids;homology (biology);phospholipid metabolism;phylogenetics;regulon;fatty acid beta-oxidation;inorganic phosphate;oxidation	Alexei E. Kazakov;Olga Vassieva;Mikhail S. Gelfand;Andrei Osterman;Ross A. Overbeek	2003	In silico biology		biology;bioinformatics;genetics	Comp.	4.783497426915056	-61.50251572465287	88987
c06f454d054a31b557596b0dc8dae39f317eaafc	genio/frame - frame shift analysis and sequencing error detection of eukaryotic cds	error detection		error detection and correction	Niels Mache;Paul Levi	1998			error detection and correction;bioinformatics;frameshift mutation;biology	Vision	2.3934900649838076	-63.55066586240925	89001
42fad59e9c49e8beb4c4946c5bbb9c8b825d5aae	iptm-mlys: identifying multiple lysine ptm sites and their different types		MOTIVATION Post-translational modification, abbreviated as PTM, refers to the change of the amino acid side chains of a protein after its biosynthesis. Owing to its significance for in-depth understanding various biological processes and developing effective drugs, prediction of PTM sites in proteins have currently become a hot topic in bioinformatics. Although many computational methods were established to identify various single-label PTM types and their occurrence sites in proteins, no method has ever been developed for multi-label PTM types. As one of the most frequently observed PTMs, the K-PTM, namely, the modification occurring at lysine (K), can be usually accommodated with many different types, such as 'acetylation', 'crotonylation', 'methylation' and 'succinylation'. Now we are facing an interesting challenge: given an uncharacterized protein sequence containing many K residues, which ones can accommodate two or more types of PTM, which ones only one, and which ones none?   RESULTS To address this problem, a multi-label predictor called IPTM-MLYS: has been developed. It represents the first multi-label PTM predictor ever established. The novel predictor is featured by incorporating the sequence-coupled effects into the general PseAAC, and by fusing an array of basic random forest classifiers into an ensemble system. Rigorous cross-validations via a set of multi-label metrics indicate that the first multi-label PTM predictor is very promising and encouraging.   AVAILABILITY AND IMPLEMENTATION For the convenience of most experimental scientists, a user-friendly web-server for iPTM-mLys has been established at http://www.jci-bioinfo.cn/iPTM-mLys, by which users can easily obtain their desired results without the need to go through the complicated mathematical equations involved.   CONTACT wqiu@gordonlifescience.org, xxiao@gordonlifescience.org, kcchou@gordonlifescience.orgSupplementary information: Supplementary data are available at Bioinformatics online.	amino acid sequence;amino acids;anabolism;arginine;bioinformatics;biotinylation;cysteine;genetic translation process;kerrison predictor;lysine;mathematics;multi-label classification;numerous;ptms gene;phentolamine;polynomial texture mapping;post-translational protein processing;random forest;server (computing);usability;web site;web server	Wangren Qiu;Bi-Qian Sun;Xuan Xiao;Zhao-Chun Xu;Kuo-Chen Chou	2016	Bioinformatics	10.1093/bioinformatics/btw380	data mining;computational biology;computer science;random forest;protein sequencing;succinylation;lysine	Comp.	9.477391503102773	-55.79994562492932	89153
0e6ef2809bad0965b3df599b05be1e6d859d5543	the protein data bank	magnetic resonance spectroscopy;internet;proteins;protein conformation;macromolecule;databases factual;information storage and retrieval;protein data bank;structured data	The Protein Data Bank [PDB; Berman, Westbrook et al. (2000), Nucleic Acids Res. 28, 235-242; http://www.pdb.org/] is the single worldwide archive of primary structural data of biological macromolecules. Many secondary sources of information are derived from PDB data. It is the starting point for studies in structural bioinformatics. This article describes the goals of the PDB, the systems in place for data deposition and access, how to obtain further information and plans for the future development of the resource. The reader should come away with an understanding of the scope of the PDB and what is provided by the resource.	archive;chemical vapor deposition;protein data bank;secondary source;structural bioinformatics;macromolecule	Helen M. Berman;John D. Westbrook;Zukang Feng;Gary Gilliland;T. N. Bhat;Helge Weissig;Ilya N. Shindyalov;Philip E. Bourne	2000	Acta crystallographica. Section D, Biological crystallography	10.1093/nar/28.1.235	macromolecule;nuclear magnetic resonance spectroscopy;biology;protein structure;the internet;protein data bank;data model;bioinformatics	Comp.	-1.4641819536496927	-61.44497245349302	89161
7258c57375985ec5413487631d375801e61696bf	experiments on and numerical modeling of the capture and concentration of transcription-translation machinery inside vesicles	synthetic cells cell free transcription translation tx tl liposomes power law stochastic encapsulation synthetic biology;cell free transcription translation tx tl;synthetic biology;liposomes;stochastic encapsulation;synthetic cells;power law	Synthetic or semi-synthetic minimal cells are those cell-like artificial compartments that are based on the encapsulation of molecules inside lipid vesicles (liposomes). Synthetic cells are currently used as primitive cell models and are very promising tools for future biotechnology. Despite the recent experimental advancements and sophistication reached in this field, the complete elucidation of many fundamental physical aspects still poses experimental and theoretical challenges. The interplay between solute capture and vesicle formation is one of the most intriguing ones. In a series of studies, we have reported that when vesicles spontaneously form in a dilute solution of proteins, ribosomes, or ribo-peptidic complexes, then, contrary to statistical predictions, it is possible to find a small fraction of liposomes (<1%) that contain a very large number of solutes, so that their local (intravesicular) concentrations largely exceed the expected value. More recently, we have demonstrated that this effect (spontaneous crowding) operates also on multimolecular mixtures, and can drive the synthesis of proteins inside vesicles, whereas the same reaction does not proceed at a measurable rate in the external bulk phase. Here we firstly introduce and discuss these already published observations. Then, we present a computational investigation of the encapsulation of transcription-translation (TX-TL) machinery inside vesicles, based on a minimal protein synthesis model and on different solute partition functions. Results show that experimental data are compatible with an entrapment model that follows a power law rather than a Gaussian distribution. The results are discussed from the viewpoint of origin of life, highlighting open questions and possible future research directions.	anatomical compartments;artificial cells;cell (microprocessor);continuous phase;crowding;encapsulation (networking);entrapment of medical device or device component;experiment;genetic translation process;liposomes;medical transcription;ribosomes;scientific publication;semiconductor industry;spontaneous order;synthetic intelligence;transcription (software);transcription, genetic;transform, clipping, and lighting;vesicle (morphologic abnormality);membrane budding;solute;thymus-leukemia antigens	Fabio Mavelli;Pasquale Stano	2015	Artificial Life	10.1162/ARTL_a_00187	biology;liposome;power law;computer science;synthetic biology	ML	6.424085250830078	-65.70754035124594	89187
5e5d2f5a407d2684dc43f2610678872afd3d47a1	compression of next-generation sequencing quality scores using memetic algorithm	data compression;high throughput nucleotide sequencing;sequence analysis dna;computational biology bioinformatics;algorithms;combinatorial libraries;computer appl in life sciences;microarrays;bioinformatics	The exponential growth of next-generation sequencing (NGS) derived DNA data poses great challenges to data storage and transmission. Although many compression algorithms have been proposed for DNA reads in NGS data, few methods are designed specifically to handle the quality scores. In this paper we present a memetic algorithm (MA) based NGS quality score data compressor, namely MMQSC. The algorithm extracts raw quality score sequences from FASTQ formatted files, and designs compression codebook using MA based multimodal optimization. The input data is then compressed in a substitutional manner. Experimental results on five representative NGS data sets show that MMQSC obtains higher compression ratio than the other state-of-the-art methods. Particularly, MMQSC is a lossless reference-free compression algorithm, yet obtains an average compression ratio of 22.82% on the experimental data sets. The proposed MMQSC compresses NGS quality score data effectively. It can be utilized to improve the overall compression ratio on FASTQ formatted files.	biopolymer sequencing;codebook;communications satellite;computer data storage;data compression;evolutionary multimodal optimization;fastq format;lossless compression;massively-parallel sequencing;mathematical optimization;memetic algorithm;multimodal interaction;exponential	Jiarui Zhou;Zhen Ji;Zexuan Zhu;Shan He	2014		10.1186/1471-2105-15-S15-S10	data compression;computational biology;biology;dna microarray;computer science;bioinformatics;genetics	ML	-1.0385955381788416	-53.44292492326591	89230
e6959d2f585da87529e4e8e673e5f6fd0733ff5e	systems level analysis of systemic sclerosis shows a network of immune and profibrotic pathways connected with genetic polymorphisms	female;middle aged;male;extracellular matrix;databases genetic;scleroderma systemic;risk;inflammation;transcriptome;humans;computational biology;gene expression profiling;aged	Systemic sclerosis (SSc) is a rare systemic autoimmune disease characterized by skin and organ fibrosis. The pathogenesis of SSc and its progression are poorly understood. The SSc intrinsic gene expression subsets (inflammatory, fibroproliferative, normal-like, and limited) are observed in multiple clinical cohorts of patients with SSc. Analysis of longitudinal skin biopsies suggests that a patient's subset assignment is stable over 6-12 months. Genetically, SSc is multi-factorial with many genetic risk loci for SSc generally and for specific clinical manifestations. Here we identify the genes consistently associated with the intrinsic subsets across three independent cohorts, show the relationship between these genes using a gene-gene interaction network, and place the genetic risk loci in the context of the intrinsic subsets. To identify gene expression modules common to three independent datasets from three different clinical centers, we developed a consensus clustering procedure based on mutual information of partitions, an information theory concept, and performed a meta-analysis of these genome-wide gene expression datasets. We created a gene-gene interaction network of the conserved molecular features across the intrinsic subsets and analyzed their connections with SSc-associated genetic polymorphisms. The network is composed of distinct, but interconnected, components related to interferon activation, M2 macrophages, adaptive immunity, extracellular matrix remodeling, and cell proliferation. The network shows extensive connections between the inflammatory- and fibroproliferative-specific genes. The network also shows connections between these subset-specific genes and 30 SSc-associated polymorphic genes including STAT4, BLK, IRF7, NOTCH4, PLAUR, CSK, IRAK1, and several human leukocyte antigen (HLA) genes. Our analyses suggest that the gene expression changes underlying the SSc subsets may be long-lived, but mechanistically interconnected and related to a patients underlying genetic risk.	adaptive immunity;autoimmune diseases;blk gene;biopsy;cell proliferation;cluster analysis;color gradient;consensus clustering;extracellular matrix;factor analysis;fibrosis;gene expression;gene co-expression network;genes, vif;genetic polymorphism;hla antigens;histocompatibility antigens class ii;irak1 gene;irf7 protein, human;information theory;interaction network;interferon signaling process;leukocytes;mastocytosis, systemic;multiple sclerosis;mutual information;numerous;plaur gene;patients;stat4 protein;subgroup;systemic scleroderma;systemic therapy (psychotherapy);statistical cluster	J. Matthew Mahoney;Jaclyn Taroni;Viktor Martyanov;Tammara A. Wood;Casey S. Greene;Patricia A. Pioli;Monique Hinchcliff;Michael L. Whitfield	2015		10.1371/journal.pcbi.1004005	biology;extracellular matrix;transcriptome;bioinformatics;risk;gene expression profiling;immunology;genetics	ML	5.947875280131904	-56.98872933463086	89325
b3fbd39b32b3c917d0a0667f17e89b07c02357c3	mouse tumor biology database (mtb): status update and future directions	genetically engineered mice;animals;relational data;controlled vocabulary;mice;management system;database management systems;computer graphics;web interface;genetics;computer graphic;internet;neoplasms experimental;genome;disease models animal;user computer interface;databases factual;neoplasms;mouse genome informatics;database management system;pathology	The Mouse Tumor Biology (MTB) database provides access to data about endogenously arising tumors (both spontaneous and induced) in genetically defined mice (inbred, hybrid, mutant and genetically engineered mice). Data include information on the frequency and latency of mouse tumors, pathology reports and images, genomic changes occurring in the tumors, genetic (strain) background and literature or contributor citations. Data are curated from the primary literature or submitted directly from researchers. MTB is accessed via the Mouse Genome Informatics web site (http://www.informatics.jax.org). Integrated searches of MTB are enabled through use of multiple controlled vocabularies and by adherence to standardized nomenclature, when available. Recently MTB has been redesigned and its database infrastructure replaced with a robust relational database management system (RDMS). Web interface improvements include a new advanced query form and enhancements to already existing search capabilities. The Tumor Frequency Grid has been revised to enhance interactivity, providing an overview of reported tumor incidence across mouse strains and an entrée into the database. A new pathology data submission tool allows users to submit, edit and release data to the MTB system.	biomarkers, tumor;controlled vocabulary;data base management;database management systems;digital curation;genetic engineering;inbred strain;incidence matrix;informatics;interactivity;interface device component;neoplasms;nephroblastoma;primary source;question (inquiry);regulatory submission;relational database management system;revision procedure;rodent nomenclature name;spontaneous order;web site;citation;pathology report	Dale A. Begley;Debra M. Krupke;Matthew J. Vincent;John P. Sundberg;Carol J. Bult;Janan T. Eppig	2007		10.1093/nar/gkl983	controlled vocabulary;the internet;relational database;bioinformatics;management system;computer graphics;user interface;genetics;genome	DB	-1.6244864715617613	-61.80523424160547	89328
d8c7eaf9bb8323ad328a902e9a9a04f385e15b87	gene functional similarity search tool (gfsst)	genes;directed acyclic graph;software;search engine;controlled vocabulary;human disease;database management systems;drug targeting;chromosome mapping;information storage and retrieval systems science;statistical model;genetics;computational biology bioinformatics;chip;genetic association;database searching;functional genomics;sequence homology amino acid;algorithms;sequence alignment;combinatorial libraries;high throughput;gene function;computer appl in life sciences;animal model;similarity search;sequence analysis protein;genome sequence;candidate gene;databases protein;microarrays;bioinformatics;gene ontology	With the completion of the genome sequences of human, mouse, and other species and the advent of high throughput functional genomic research technologies such as biomicroarray chips, more and more genes and their products have been discovered and their functions have begun to be understood. Increasing amounts of data about genes, gene products and their functions have been stored in databases. To facilitate selection of candidate genes for gene-disease research, genetic association studies, biomarker and drug target selection, and animal models of human diseases, it is essential to have search engines that can retrieve genes by their functions from proteome databases. In recent years, the development of Gene Ontology (GO) has established structured, controlled vocabularies describing gene functions, which makes it possible to develop novel tools to search genes by functional similarity. By using a statistical model to measure the functional similarity of genes based on the Gene Ontology directed acyclic graph, we developed a novel Gene Functional Similarity Search Tool (GFSST) to identify genes with related functions from annotated proteome databases. This search engine lets users design their search targets by gene functions. An implementation of GFSST which works on the UniProt (Universal Protein Resource) for the human and mouse proteomes is available at GFSST Web Server. GFSST provides functions not only for similar gene retrieval but also for gene search by one or more GO terms. This represents a powerful new approach for selecting similar genes and gene products from proteome databases according to their functions.	animal model;biological markers;candidate disease gene;controlled vocabulary;database;databases;directed acyclic graph;drug delivery systems;gene ontology;genetic association studies;genetic research;graph - visual representation;proteome;similarity search;statistical model;throughput;uniprot;universal protein resource;web search engine;web server	Peisen Zhang;Jinghui Zhang;Huitao Sheng;James J. Russo;Brian Osborne;Kenneth H. Buetow	2005	BMC Bioinformatics	10.1186/1471-2105-7-135	chip;functional genomics;high-throughput screening;statistical model;biology;controlled vocabulary;targeted drug delivery;whole genome sequencing;dna microarray;computer science;bioinformatics;genetic association;gene;sequence alignment;data mining;candidate gene;genetics;directed acyclic graph;search engine	Comp.	-1.1740287620163201	-60.47558637231489	89338
5dee5969f0d6ac5f0f2b2baf84c7b35f0de148b9	comparative analysis of the mechanisms of sulfur anion oxidation and reduction by dsr operon to maintain environmental sulfur balance	dsr operon;chromatiaceae;dissimilarity sulfite reductase dsir dsrab;dsroperon;models molecular;oxidation reduction;sulfur anion oxidation;protein protein docking;desulfovibrio vulgaris;homology modeling;operon;sulfur;anions;computational biology;protein ligand docking;sulfur anion reduction;bacterial proteins	Sulfur metabolism is one of the oldest known redox geochemical cycles in our atmosphere. These redox processes utilize different sulfur anions and the reactions are performed by the gene products of dsr operon from phylogenetically diverse sets of microorganisms. The operon is involved in the maintenance of environmental sulfur balance. Interestingly, the dsr operon is found to be present in both sulfur anion oxidizing and reducing microorganisms and in both types of organisms DsrAB protein complex plays a vital role. Though there are various reports regarding the genetics of dsr operon there are practically no reports dealing with the structural aspects of sulfur metabolism by dsr operon. In our present study, we tried to compare the mechanisms of sulfur anion oxidation and reduction by Allochromatium vinosum and Desulfovibrio vulgaris respectively through DsrAB protein complex. We analyzed the modes of bindings of sulfur anions to the DsrAB protein complex and observed that for sulfur anion oxidizers, sulfide and thiosulfate are the best substrates whereas for reducers sulfate and sulfite have the best binding abilities. We analyzed the binding interaction pattern of the DsrA and DsrB proteins while forming the DsrAB protein complexes in Desulfovibrio vulgaris and Allochromatium vinosum. To our knowledge this is the first report that analyzes the differences in binding patterns of sulfur substrates with DsrAB protein from these two microorganisms. This study would therefore be essential to predict the biochemical mechanism of sulfur anion oxidation and reduction by these two microorganisms i.e., Desulfovibrio vulgaris (sulfur anion reducer) and Allochromatium vinosum (sulfur anion oxidizer). Our observations also highlight the mechanism of sulfur geochemical cycle which has important implications in future study of sulfur metabolism as it has a huge application in waste remediation and production of industrial bio-products viz. vitamins, bio-polyesters and bio-hydrogen.		Semanti Ghosh;Angshuman Bagchi	2015	Computational biology and chemistry	10.1016/j.compbiolchem.2015.07.001	biology;biochemistry;homology modeling;chemistry;sulfur;organic chemistry;inorganic chemistry;operon;genetics	Comp.	8.670164795904514	-61.430279218027394	89375
a392df7028dfcb8d304c17fe946db5ad963c1e31	rapid searches for complex patterns in biological molecules		The intrinsic redundancy of genetic information makes searching for patterns in biological sequences a difficult task. We have designed an interactive self-documenting computer program called QUEST that allows rapid searching of large DNA and protein data banks for highly redundant consensus sequences or character patterns. QUEST uses a concise language for specifying character patterns containing several levels of ambiguity and pattern arrangement. Examples of the use of this program for sequence data are given. Details of the algorithm and pattern optimization are explained.	algorithm;bank (environment);character encoding;computer program;consensus sequence;documented;mathematical optimization;self-documenting code;software documentation;triple modular redundancy	R. M. Abarbanel;Paul R. Wieneke;E. Mansfield;David A. Jaffe;Douglas L. Brutlag	1984	Nucleic acids research	10.1093/nar/12.1Part1.263	redundancy (engineering);dna;consensus sequence;software;ambiguity;computer program;bioinformatics;biology	Graphics	-1.3056737438167698	-56.37424121253082	89401
27493c8e77aca74adda9f2c3e81c3b353007cd8e	a novel data structure to support ultra-fast taxonomic classification of metagenomic sequences with k-mer signatures		Motivation Metagenomic read classification is a critical step in the identification and quantification of microbial species sampled by high-throughput sequencing. Although many algorithms have been developed to date, they suffer significant memory and/or computational costs. Due to the growing popularity of metagenomic data in both basic science and clinical applications, as well as the increasing volume of data being generated, efficient and accurate algorithms are in high demand.   Results We introduce MetaOthello, a probabilistic hashing classifier for metagenomic sequencing reads. The algorithm employs a novel data structure, called l-Othello, to support efficient querying of a taxon using its k-mer signatures. MetaOthello is an order-of-magnitude faster than the current state-of-the-art algorithms Kraken and Clark, and requires only one-third of the RAM. In comparison to Kaiju, a metagenomic classification tool using protein sequences instead of genomic sequences, MetaOthello is three times faster and exhibits 20-30% higher classification sensitivity. We report comparative analyses of both scalability and accuracy using a number of simulated and empirical datasets.   Availability and implementation MetaOthello is a stand-alone program implemented in C ++. The current version (1.0) is accessible via https://doi.org/10.5281/zenodo.808941.   Contact liuj@cs.uky.edu.   Supplementary information Supplementary data are available at Bioinformatics online.	algorithm;amino acid sequence;bioinformatics;biopolymer sequencing;data structure;exhibits as topic;geographic information systems;high-throughput computing;k-mer;mer;metagenomics;peptide sequence;quantitation;random-access memory;reading (activity);reversi;sampling - surgical action;scalability;throughput;type signature;basic research	Xinan Liu;Ye Yu;Jinpeng Liu;Corrine F. Elliott;Chen Qian;Jinze Liu	2018	Bioinformatics	10.1093/bioinformatics/btx432	computer science;bioinformatics;biological classification;k-mer;metagenomics;data structure	Comp.	0.38801156803151277	-54.44099239933025	89639
425ad832a37bf32b323e4ccbac3ccc98eb76c3f4	mapdamage: testing for damage patterns in ancient dna sequences	dna;software;dna damage genetics;paleontology;dna contamination;secuencia nucleotido;lesion;nucleotide sequence;sequence nucleotide;sequence analysis dna methods;dna restriction enzymes;genome human;secuencia adn;humans;sequence dna;base sequence;dna sequence;reference standards;computational biology methods	SUMMARY Ancient DNA extracts consist of a mixture of contaminant DNA molecules, most often originating from environmental microbes, and endogenous fragments exhibiting substantial levels of DNA damage. The latter introduce specific nucleotide misincorporations and DNA fragmentation signatures in sequencing reads that could be advantageously used to argue for sequence validity. mapDamage is a Perl script that computes nucleotide misincorporation and fragmentation patterns using next-generation sequencing reads mapped against a reference genome. The Perl script outputs are further automatically processed in embedded R script in order to detect typical patterns of genuine ancient DNA sequences.   AVAILABILITY AND IMPLEMENTATION The Perl script mapDamage is freely available with documentation and example files at http://geogenetics.ku.dk/all_literature/mapdamage/. The script requires prior installation of the SAMtools suite and R environment and has been validated on both GNU/Linux and MacOSX operating systems.	biopolymer sequencing;dna damage;dna fragmentation;dna, ancient;documentation;embedded system;embedding;exhibits as topic;fork (software development);fragmentation (computing);gnu;linux;massively-parallel sequencing;nucleotides;operating system;perl;reading (activity);samtools;type signature;macos;mapped	Aurelien Ginolhac;Morten Rasmussen;Marcus Thomas Pius Gilbert;Eske Willerslev;Ludovic Orlando	2011	Bioinformatics	10.1093/bioinformatics/btr347	biology;dna sequencing;nucleic acid sequence;bioinformatics;genetics;dna	Comp.	-2.2398647770922486	-56.81459418664446	89685
5eaa1f33dc6ce2f8abdf8e5e2a3ffa97de4a8fb9	comprehensive molecular characterization of urothelial bladder carcinoma	cancer genomics; data integration; drug discovery; biomarkers	Urothelial carcinoma of the bladder is a common malignancy that causes approximately 150,000 deaths per year worldwide. So far, no molecularly targeted agents have been approved for treatment of the disease. As part of The Cancer Genome Atlas project, we report here an integrated analysis of 131 urothelial carcinomas to provide a comprehensive landscape of molecular alterations. There were statistically significant recurrent mutations in 32 genes, including multiple genes involved in cell-cycle regulation, chromatin regulation, and kinase signalling pathways, as well as 9 genes not previously reported as significantly mutated in any cancer. RNA sequencing revealed four expression subtypes, two of which (papillary-like and basal/squamous-like) were also evident in microRNA sequencing and protein data. Whole-genome and RNA sequencing identified recurrent in-frame activating FGFR3–TACC3 fusions and expression or integration of several viruses (including HPV16) that are associated with gene inactivation. Our analyses identified potential therapeutic targets in 69% of the tumours, including 42% with targets in the phosphatidylinositol-3-OH kinase/AKT/mTOR pathway and 45% with targets (including ERBB2) in the RTK/MAPK pathway. Chromatin regulatory genes were more frequently mutated in urothelial carcinoma than in any other common cancer studied so far, indicating the future possibility of targeted therapy for chromatin abnormalities.	basal (phylogenetics);bladder neoplasm;carcinoma, transitional cell;cell cycle control;cessation of life;congenital abnormality;gene regulatory network;genes, regulator;mutation;neoplasms;non-small cell lung carcinoma;proto-oncogene proteins c-akt;rna;real time kinematic;receptor protein-tyrosine kinases;recurrent neural network;subtype (attribute);transitional cell carcinoma of bladder;urinary bladder;urothelial carcinoma;biological signaling	The Cancer Genome Atlas Research Network	2014		10.1038/nature12965	bioinformatics	Comp.	6.737809158197097	-60.68010504577293	89762
8de1d3a855131432ef2ba06d36312024d982c466	a novel genome-scale repeat finder geared towards transposons	bioinformatique;transposon;iterative algorithm;genoma a;genome a;bioinformatica;a genome;false positive;transposable element;bioinformatics	MOTIVATION Repeats are ubiquitous in genomes and play important roles in evolution. Transposable elements are a common kind of repeat. Transposon insertions can be nested and make the task of identifying repeats difficult.   RESULTS We develop a novel iterative algorithm, called Greedier, to find repeats in a target genome given a repeat library. Greedier distinguishes itself from existing methods by taking into account the fragmentation of repeats. Each iteration consists of two passes. In the first pass, it identifies the local similarities between the repeat library and the target genome. Greedier then builds graphs from this comparison output. In each graph, a vertex denotes a similar subsequence pair. Edges denote pairs of subsequences that can be connected to form higher similarities. In the second pass, Greedier traverses these graphs greedily to find matches to individual repeat units in the repeat library. It computes a fitness value for each such match denoting the similarity of that match. Matches with fitness values greater than a cutoff are removed, and the rest of the genome is stitched together. The similarity cutoff is then gradually reduced, and the iteration is repeated until no hits are returned from the comparison. Our experiments on the Arabidopsis and rice genomes show that Greedier identifies approximately twice as many transposon bases as those found by cross_match and WindowMasker. Moreover, Greedier masks far fewer false positive bases than either cross_match or WindowMasker. In addition to masking repeats, Greedier also reports potential nested transposon structures.		Xuehui Li;Tamer Kahveci;A. Mark Settles	2008	Bioinformatics	10.1093/bioinformatics/btm613	biology;transposable element;bioinformatics;genetics	Comp.	-0.7933220838834774	-55.19038850193842	89827
11cecbb3e0915b5d12663d803c6897461fa2c760	solution for underflow problem in linkage and segregation analysis	genetic analysis;complex traits;linkage analysis;large data sets;underflow;statistical analysis;peeling;software package;human genetics;likelihood function;likelihood;single nucleotide polymorphism	Finding genes for complex traits is one of the major challenges of modern human genetics. Current developments of molecular techniques facilitated use of large pedigrees and marker sets of thousands of single-nucleotide polymorphisms (SNPs). However, one of the problems occurring in statistical analysis of such large data sets is that the likelihood is very low and underflow may easily occur. In this work we describe a method permitting to avoid underflow during computation of a likelihood function, using different algorithms. Our method makes practically possible analysis of thousands of individuals and thousands of SNPs. The method is easy to implement without major change of the code of existing programs. It also helps to reduce the amount of computer memory used in analysis without noticeable alteration of the program running time. The algorithm was implemented in the software packages for segregation and linkage analysis, which are available from http://mga.bionet.nsc.ru/.		Tatiana I. Axenovich;Yurii S. Aulchenko	2006	Computational biology and chemistry	10.1016/j.compbiolchem.2006.06.001	biology;computer science;bioinformatics;likelihood function;genetics;statistics	ML	2.6229608873616543	-53.176185977227725	89918
a8458c4988a4edb3ff4c7f5d5eeea8f85f8a5aa2	improving structural similarity based virtual screening using background knowledge	biological patents;biomedical journals;text mining;europe pubmed central;citation search;computer applications in chemistry;citation networks;theoretical and computational chemistry;computational biology bioinformatics;research articles;abstracts;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;documentation and information in chemistry;biomedical research;bioinformatics;literature search	BACKGROUND Virtual screening in the form of similarity rankings is often applied in the early drug discovery process to rank and prioritize compounds from a database. This similarity ranking can be achieved with structural similarity measures. However, their general nature can lead to insufficient performance in some application cases. In this paper, we provide a link between ranking-based virtual screening and fragment-based data mining methods. The inclusion of binding-relevant background knowledge into a structural similarity measure improves the quality of the similarity rankings. This background knowledge in the form of binding relevant substructures can either be derived by hand selection or by automated fragment-based data mining methods.   RESULTS In virtual screening experiments we show that our approach clearly improves enrichment factors with both applied variants of our approach: the extension of the structural similarity measure with background knowledge in the form of a hand-selected relevant substructure or the extension of the similarity measure with background knowledge derived with data mining methods.   CONCLUSION Our study shows that adding binding relevant background knowledge can lead to significantly improved similarity rankings in virtual screening and that even basic data mining approaches can lead to competitive results making hand-selection of the background knowledge less crucial. This is especially important in drug discovery and development projects where no receptor structure is available or more frequently no verified binding mode is known and mostly ligand based approaches can be applied to generate hit compounds.	data mining;drug discovery;experiment;gene ontology term enrichment;ligands;similarity measure;structural similarity;thrombocytopenia;virtual screening	Tobias Girschick;Lucia Puchbauer;Stefan Kramer	2013		10.1186/1758-2946-5-50	text mining;medical research;computer science;bioinformatics;data science;data mining;information retrieval	DB	7.436084532907633	-54.982173022312836	89951
06f8f45e41c7384ac0ef410ea5f141e5faf045e3	protein frustratometer: a tool to localize energetic frustration in protein molecules	software;internet;proteins;protein conformation;protein structure tertiary;frustration;algorithms;protein folding;molecule;user computer interface;mutation	The frustratometer is an energy landscape theory-inspired algorithm that aims at quantifying the location of frustration manifested in protein molecules. Frustration is a useful concept for gaining insight to the proteins biological behavior by analyzing how the energy is distributed in protein structures and how mutations or conformational changes shift the energetics. Sites of high local frustration often indicate biologically important regions involved in binding or allostery. In contrast, minimally frustrated linkages comprise a stable folding core of the molecule that is conserved in conformational changes. Here, we describe the implementation of these ideas in a webserver freely available at the National EMBNet node-Argentina, at URL: http://lfp.qb.fcen.uba.ar/embnet/.	embnet.journal;frustration;inspiration function;mutation;name binding;node - plant part;uniform resource locator;web server;algorithm	Michael Jenik;R. Gonzalo Parra;Leandro G. Radusky;Adrian Gustavo Turjanski;Peter G. Wolynes;Diego U. Ferreiro	2012		10.1093/nar/gks447	mutation;protein folding;biology;protein structure;the internet;molecule;bioinformatics;genetics;frustration	Comp.	2.3894282353862084	-61.61267031911251	90088
f4f6606bc190dd188d7b70d35a6d85885594832a	ortholog-based protein-protein interaction prediction and its application to inter-species interactions	animals;human interaction;drug discovery;receptors tumor necrosis factor;host pathogen interaction;tnf receptor associated factor;bayes theorem;models biological;calcium;network analysis;computational biology bioinformatics;models genetic;species interaction;host pathogen interactions;immune system;protein protein interaction;plasmodium falciparum;algorithms;humans;combinatorial libraries;protein interaction mapping;high throughput;computational biology;calmodulin;computer appl in life sciences;immune response;species specificity;databases protein;microarrays;bioinformatics	The rapid growth of protein-protein interaction (PPI) data has led to the emergence of PPI network analysis. Despite advances in high-throughput techniques, the interactomes of several model organisms are still far from complete. Therefore, it is desirable to expand these interactomes with ortholog-based and other methods. Orthologous pairs of 18 eukaryotic species were expanded and merged with experimental PPI datasets. The contributions of interologs from each species were evaluated. The expanded orthologous pairs enable the inference of interologs for various species. For example, more than 32,000 human interactions can be predicted. The same dataset has also been applied to the prediction of host-pathogen interactions. PPIs between P. falciparum calmodulin and several H. sapiens proteins are predicted, and these interactions may contribute to the maintenance of host cell Ca2+ concentration. Using comparisons with Bayesian and structure-based approaches, interactions between putative HSP40 homologs of P. falciparum and the H. sapiens TNF receptor associated factor family are revealed, suggesting a role for these interactions in the interference of the human immune response to P. falciparum. The PPI datasets are available from POINT http://point.bioinformatics.tw/ and POINeT http://poinet.bioinformatics.tw/ . Further development of methods to predict host-pathogen interactions should incorporate multiple approaches in order to improve sensitivity, and should facilitate the identification of targets for drug discovery and design.	calcium ion;drug discovery;emergence;greater than;high-throughput computing;homology (biology);inference;interactome;interference (communication);interolog;merge;orthologous gene;pathogenic organism;pixel density;proton pump inhibitors;sequence homology;throughput;tumor necrosis factor receptor;protein protein interaction	Sheng-An Lee;Chen-hsiung Chan;Chi-Hung Tsai;Jin-Mei Lai;Feng-Sheng Wang;Cheng-Yan Kao;Chi-Ying F. Huang	2008	BMC Bioinformatics	10.1186/1471-2105-9-S12-S11	biology;immune system;computer science;bioinformatics;genetics	Comp.	6.662548758247749	-57.995861677483695	90095
5ca75bd657acc2faff7da518dbc118e2880c5e14	inferring disease associated phosphorylation sites via random walk on multi-layer heterogeneous network	databases;biological patents;biomedical journals;text mining;europe pubmed central;citation search;citation networks;proteins cellular biophysics diseases drug delivery systems molecular biophysics multilayers;disease random walk phosphorylation heterogeneous network;proteins;research articles;abstracts;open access;life sciences;clinical guidelines;diseases;diseases substrates heterogeneous networks proteins databases protein engineering amino acids;amino acids;substrates;full text;classification methods disease associated phosphorylation sites protein phosphorylation cellular processes phosphorylation related activity drug design disease treatment heterogeneous network multilayer heterogeneous network model kinase layer random walk model;heterogeneous networks;protein engineering;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	As protein phosphorylation plays an important role in numerous cellular processes, many studies have been undertaken to analyze phosphorylation-related activities for drug design and disease treatment. However, although progresses have been made in illustrating the relationship between phosphorylation and diseases, no existing method focuses on disease-associated phosphorylation sites prediction. In this work, we proposed a multi-layer heterogeneous network model that makes use of the kinase information to infer disease-phosphorylation site relationship and implemented random walk on the heterogeneous network. Experimental results reveal that multi-layer heterogeneous network model with kinase layer is superior in inferring disease-phosphorylation site relationship when comparing with existing random walk model and common used classification methods.	anatomic node;cholangiocarcinoma;drug design;genetic heterogeneity;inference;interaction;k-nearest neighbors algorithm;layer (electronics);network model;numerous;paget's disease, mammary;phosphorylation site;pixel density;support vector machine	Xiaoyi Xu;Minghui Wang	2016	IEEE/ACM Transactions on Computational Biology and Bioinformatics	10.1109/TCBB.2015.2498548	biology;text mining;heterogeneous network;computer science;bioinformatics;data science;data mining;protein engineering	Metrics	6.662208110918025	-56.84566407936392	90134
5ec27642a4b5a4c3f2f90639ec64e4b3f22f017d	dianna 1.1: an extension of the dianna web server for ternary cysteine classification	software;cysteine;feed forward neural network;amino acid sequence;iron;disulfides;spectrum;oxidation reduction;internet;proteins;disulfide bond;artificial intelligence;zinc;support vector machine;user computer interface;sequence analysis protein;artificial neural network;neural network	DiANNA is a recent state-of-the-art artificial neural network and web server, which determines the cysteine oxidation state and disulfide connectivity of a protein, given only its amino acid sequence. Version 1.0 of DiANNA uses a feed-forward neural network to determine which cysteines are involved in a disulfide bond, and employs a novel architecture neural network to predict which half-cystines are covalently bound to which other half-cystines. In version 1.1 of DiANNA, described here, we extend functionality by applying a support vector machine with spectrum kernel for the cysteine classification problem-to determine whether a cysteine is reduced (free in sulfhydryl state), half-cystine (involved in a disulfide bond) or bound to a metallic ligand. In the latter case, DiANNA predicts the ligand among iron, zinc, cadmium and carbon. Available at: http://bioinformatics.bc.edu/clotelab/DiANNA/.	a library for support vector machines;amino acid sequence;amino acids;anatomy, regional;artificial neural network;binary classification;bioinformatics;cadmium;cysteine;cystine;disulfide linkage;feedforward neural network;hemifacial hyperplasia;ibm notes;interface device component;ligands;microsoft windows;nephrogenic systemic fibrosis;polynomial kernel;server (computer);server (computing);sulfhydryl compounds;support vector machine;user interface;web server;oxidation	Fabrizio Ferrè;Peter Clote	2006	Nucleic Acids Research	10.1093/nar/gkl189	spectrum;support vector machine;biochemistry;bioinformatics;zinc;iron;artificial neural network;disulfide bond	ML	9.978508462586785	-56.74039765625731	90157
36b90abf0e82339faf69a8dd1acee0d1a1f90f49	inferring the regulatory interaction models of transcription factors in transcriptional regulatory networks	transcriptional regulation;hidden markov model	Living cells are realized by complex gene expression programs that are moderated by regulatory proteins called transcription factors (TFs). The TFs control the differential expression of target genes in the context of transcriptional regulatory networks (TRNs), either individually or in groups. Deciphering the mechanisms of how the TFs control the differential expression of a target gene in a TRN is challenging, especially when multiple TFs collaboratively participate in the transcriptional regulation. To unravel the roles of the TFs in the regulatory networks, we model the underlying regulatory interactions in terms of the TF-target interactions' directions (activation or repression) and their corresponding logical roles (necessary and/or sufficient). We design a set of constraints that relate gene expression patterns to regulatory interaction models, and develop TRIM (Transcriptional Regulatory Interaction Model Inference), a new hidden Markov model, to infer the models of TF-target interactions in large-scale TRNs of complex organisms. Besides, by training TRIM with wild-type time-series gene expression data, the activation timepoints of each regulatory module can be obtained. To demonstrate the advantages of TRIM, we applied it on yeast TRN to infer the TF-target interaction models for individual TFs as well as pairs of TFs in collaborative regulatory modules. By comparing with TF knockout and other gene expression data, we were able to show that the performance of TRIM is clearly higher than DREM (the best existing algorithm). In addition, on an individual Arabidopsis binding network, we showed that the target genes' expression correlations can be significantly improved by incorporating the TF-target regulatory interaction models inferred by TRIM into the expression data analysis, which may introduce new knowledge in transcriptional dynamics and bioactivation.	experiment;gene expression;hidden markov model;inference;interaction;knock-out;knockout;markov chain;probability;repression, psychology;t-cell receptor interacting molecule;transcription factor;trn-gtt2-1 gene;time series;transcription (software);transcription, genetic;transcriptional regulation;algorithm;biological adaptation to stress;emotional dependency;trim resin	Sherine Awad;Nicholas Panchy;See-Kiong Ng;Jin Chen	2012	Journal of bioinformatics and computational biology	10.1142/S0219720012500126	biology;computer science;bioinformatics;data mining;genetics;hidden markov model;transcriptional regulation	Comp.	5.101211052360274	-59.37742211812873	90303
a8a76e40b6ebe65f97f9ed7f5a57102a6f0dbba7	expression atlas: gene and protein expression across multiple studies and organisms		Expression Atlas (http://www.ebi.ac.uk/gxa) is an added value database that provides information about gene and protein expression in different species and contexts, such as tissue, developmental stage, disease or cell type. The available public and controlled access data sets from different sources are curated and re-analysed using standardized, open source pipelines and made available for queries, download and visualization. As of August 2017, Expression Atlas holds data from 3,126 studies across 33 different species, including 731 from plants. Data from large-scale RNA sequencing studies including Blueprint, PCAWG, ENCODE, GTEx and HipSci can be visualized next to each other. In Expression Atlas, users can query genes or gene-sets of interest and explore their expression across or within species, tissues, developmental stages in a constitutive or differential context, representing the effects of diseases, conditions or experimental interventions. All processed data matrices are available for direct download in tab-delimited format or as R-data. In addition to the web interface, data sets can now be searched and downloaded through the Expression Atlas R package. Novel features and visualizations include the on-the-fly analysis of gene set overlaps and the option to view gene co-expression in experiments investigating constitutive gene expression across tissues or other conditions.	blueprint;body tissue;cervical atlas;delimiter;digital curation;download;encode;experiment;expression atlas;gene expression;gene co-expression network;genotype-tissue expression program;interface device component;open-source software;pipeline (computing);question (inquiry);search - action;tablet dosage form;user interface;protein expression	Irene Papatheodorou;Nuno A. Fonseca;Maria Keays;Y. Amy Tang;Elisabet Barrera;Wojciech Bazant;Melissa Burke;Anja Füllgrabe;Alfonso Muñoz-Pomer Fuentes;Nancy George;Laura Huerta;Satu Koskinen;Suhaib Mohammed;Matthew J. Geniza;Justin Preece;Pankaj Jaiswal;Andrew Jarnuczak;Wolfgang Huber;Oliver Stegle	2018		10.1093/nar/gkx1158	genetics;expression quantitative trait loci;gene;protein expression;biology;bioinformatics	Comp.	-2.5225400837988987	-58.93229579926622	90316
4a6ac64f0132790b43b580c578ac8675def2916c	exploiting sequence similarity to validate the sensitivity of snp arrays in detecting fine-scaled copy number variations	sensibilite;sequence similarity;deteccion;polimorfismo mononucleotido;detection;similitude;red;variations;copy number;sensitivity;polymorphisme mononucleotide;numero copia;reseau arrangement;nombre copie;similarity;array;variacion;variation;similitud;copy number variation;sensibilidad;single nucleotide polymorphism	MOTIVATION High-density single nucleotide polymorphism (SNP) genotyping arrays are efficient and cost effective platforms for the detection of copy number variation (CNV). To ensure accuracy in probe synthesis and to minimize production costs, short oligonucleotide probe sequences are used. The use of short probe sequences limits the specificity of binding targets in the human genome. The specificity of these short probeset sequences has yet to be fully analysed against a normal reference human genome. Sequence similarity can artificially elevate or suppress copy number measurements, and hence reduce the reliability of affected probe readings. For the purpose of detecting narrow CNVs reliably down to the width of a single probeset, sequence similarity is an important issue that needs to be addressed.   RESULTS We surveyed the Affymetrix Human Mapping SNP arrays for probeset sequence similarity against the reference human genome. Utilizing sequence similarity results, we identified a collection of fine-scaled putative CNVs between gender from autosomal probesets whose sequence matches various loci on the sex chromosomes. To detect these variations, we utilized our statistical approach, Detecting REcurrent Copy number change using rank-order Statistics (DRECS), and showed that its performance was superior and more stable than the t-test in detecting CNVs. Through the application of DRECS on the HapMap population datasets with multi-matching probesets filtered, we identified biologically relevant SNPs in aberrant regions across populations with known association to physical traits, such as height, covered by the span of a single probe. This provided empirical confirmation of the existence of naturally occurring narrow CNVs as well as the sensitivity of the Affymetrix SNP array technology in detecting them.   AVAILABILITY The MATLAB implementation of DRECS is available at http://ww2.cs.mu.oz.au/ approximately gwong/DRECS/index.html.	affymetrix;autosome;copy number polymorphism;genotype determination;homology (biology);international hapmap project;matlab;name binding;nitroprusside;nucleotides;numerous;pierre robin syndrome;population;snp array;sensitivity and specificity;sensor;sequence tagged sites;sequence alignment;sex chromosomes;single-chain antibodies;trait;webserver directory index;confirmation - responselevel;t test;width	Gerard Wong;Christopher Leckie;Kylie L. Gorringe;Izhak Haviv;Ian G. Campbell;Adam Kowalczyk	2010	Bioinformatics	10.1093/bioinformatics/btq088	biology;molecular inversion probe;bioinformatics;copy-number variation;genetics	Comp.	2.897143528546173	-54.1567876141762	90323
32bf2cc16bb7d11b4ad0938374f7f09c2e3e9c30	modules identification in protein structures: the topological and geometrical solutions	transition state;graph theory;pseudomonas aeruginosa azurin;electron transfer;ligand binding;domain;dynamics;contact networks;amino acids;biology and life sciences;allostery;settore bio 10 biochimica	"""The identification of modules in protein structures has major relevance in structural biology, with consequences in protein stability and functional classification, adding new perspectives in drug design. In this work, we present the comparison between a topological (spectral clustering) and a geometrical (k-means) approach to module identification, in the frame of a multiscale analysis of the protein architecture principles. The global consistency of an adjacency matrix based technique (spectral clustering) and a method based on full rank geometrical information (k-means) give a proof-of-concept of the relevance of protein contact networks in structure determination. The peculiar """"small-world"""" character of protein contact graphs is established as well, pointing to average shortest path as a mesoscopic crucial variable to maximize the efficiency of within-molecule signal transmission. The specific nature of protein architecture indicates topological approach as the most proper one to highlight protein functional domains, and two new representations linking sequence and topological role of aminoacids are demonstrated to be of use for protein structural analysis. Here we present a case study regarding azurin, a small copper protein implied in the Pseudomonas aeruginosa respiratory chain. Its pocket molecular shape and its electron transfer function have challenged the method, highlighting its potentiality to catch jointly the structure and function features of protein structures through their decomposition into modules."""	adjacency matrix;amino acids;azurin;cluster analysis;drug design;graph - visual representation;k-means clustering;mesoscopic physics;mitochondrial electron transport chain;relevance;short;shortest path problem;spectral clustering;structural analysis;transfer function;statistical cluster	Setareh Tasdighian;Luisa Di Paola;Micol De Ruvo;Paola Paci;Daniele Santoni;Pasquale Palumbo;Giampiero Mei;Almerinda Di Venere;Alessandro Giuliani	2014	Journal of chemical information and modeling	10.1021/ci400218v	crystallography;biology;biochemistry;dynamics;chemistry;allosteric regulation;domain;bioinformatics;graph theory;electron transfer;machine learning;computational chemistry;nanotechnology;transition state;ligand	Comp.	4.719387187673618	-56.90913601261945	90334
5e4043cb6840d8e51a9ef0f60465824c74a9ae3a	a stepwise approach for defining the applicability domain of sar and qsar models		A stepwise approach for determining the model applicability domain is proposed. Four stages are applied to account for the diversity and complexity of the current SAR/QSAR models, reflecting their mechanistic rationality (including metabolic activation of chemicals) and transparency. General parametric requirements are imposed in the first stage, specifying in the domain only those chemicals that fall in the range of variation of the physicochemical properties of the chemicals in the training set. The second stage defines the structural similarity between chemicals that are correctly predicted by the model. The structural neighborhood of atom-centered fragments is used to determine this similarity. The third stage in defining the domain is based on a mechanistic understanding of the modeled phenomenon. Here, the model domain combines the reliability of specific reactive groups hypothesized to cause the effect and the domain of explanatory variables determining the parametric requirements in order for functional groups to elicit their reactivity. Finally, the reliability of simulated metabolism (metabolites, pathways, and maps) is taken into account in assessing the reliability of predictions, if metabolic activation of chemicals is a part of the (Q)SAR model. Some of the stages of the proposed approach for defining the model domain can be eliminated depending on the availability and quality of the experimental data used to derive the model, the specificity of (Q)SARs, and the goals of their ultimate application. The performance of the proposed definition of the model domain is tested using several examples of (Q)SARs that have been externally validated, including models for predicting acute toxicity, skin sensitization, and biodegradation. The results clearly showed that credibility in predictions of QSAR models for chemicals belonging to their domain is much higher than for chemicals outside this domain.	activation, metabolic;adverse reaction to drug;applicability domain;biodegradation;map;metabolite;quantitative structure-activity relationship;quantitative structure–activity relationship;rationality;requirement;sensitivity and specificity;sensitization (observable entity);stage level 1;stage level 2;stage level 3;stepwise regression;structural similarity;test set;transparency (graphic);explanation	Sabcho Dimitrov;Gergana Dimitrova;Todor Pavlov;Nadezhda Dimitrova;Grace Patlewicz;Jay Niemela;Ovanes Mekenyan	2005	Journal of chemical information and modeling	10.1021/ci0500381	chemistry;toxicology;bioinformatics;artificial intelligence;applicability domain	Comp.	8.710801012239378	-59.7643612908485	90336
663d246ba6d349489e24328d56efadf633d21e52	hia: a genome mapper using hybrid index-based sequence alignment	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;physiological cellular and medical topics;computational biology bioinformatics;uk phd theses thesis;life sciences;algorithms;uk research reports;medical journals;europe pmc;biomedical research;bioinformatics	A number of alignment tools have been developed to align sequencing reads to the human reference genome. The scale of information from next-generation sequencing (NGS) experiments, however, is increasing rapidly. Recent studies based on NGS technology have routinely produced exome or whole-genome sequences from several hundreds or thousands of samples. To accommodate the increasing need of analyzing very large NGS data sets, it is necessary to develop faster, more sensitive and accurate mapping tools. HIA uses two indices, a hash table index and a suffix array index. The hash table performs direct lookup of a q-gram, and the suffix array performs very fast lookup of variable-length strings by exploiting binary search. We observed that combining hash table and suffix array (hybrid index) is much faster than the suffix array method for finding a substring in the reference sequence. Here, we defined the matching region (MR) is a longest common substring between a reference and a read. And, we also defined the candidate alignment regions (CARs) as a list of MRs that is close to each other. The hybrid index is used to find candidate alignment regions (CARs) between a reference and a read. We found that aligning only the unmatched regions in the CAR is much faster than aligning the whole CAR. In benchmark analysis, HIA outperformed in mapping speed compared with the other aligners, without significant loss of mapping accuracy. Our experiments show that the hybrid of hash table and suffix array is useful in terms of speed for mapping NGS sequencing reads to the human reference genome sequence. In conclusion, our tool is appropriate for aligning massive data sets generated by NGS sequencing.	align (company);array data structure;benchmark (computing);binary search algorithm;biopolymer sequencing;cell hybridization;communications satellite;database index;exome;experiment;hash table;longest common substring problem;lookup table;magnetic resonance spectroscopy;marijuana abuse;massively-parallel sequencing;n-gram;pattern matching;reading (activity);sequence alignment;suffix array;gram	JongPill Choi;Kiejung Park;Seong Beom Cho;Myungguen Chung	2015		10.1186/s13015-015-0062-4	biology;medical research;computer science;bioinformatics;data science;data mining	Comp.	-1.119256775512586	-53.841887735816144	90370
3f9821fcf8f2ec3545b632098be3a9ee41e4402e	statistical mechanics of relative species abundance	diversity;lotka volterra;statistical mechanics;lognormal distribution;replicator dynamic;interspecies interaction;gene expression;lotka volterra equation;relative species abundance;productivity;canonical hypothesis;species abundance;replicator equation;biological network	Statistical mechanics of relative species abundance (RSA) patterns in biological networks is presented. The theory is based on multispecies replicator dynamics equivalent to the LotkaVolterra equation, with diverse interspecies interactions. Various RSA patterns observed in nature are derived from a single parameter related to productivity or maturity of a community. The abundance distribution is formed like a widely observed left-skewed lognormal distribution. It is also found that the “canonical hypothesis” is supported in some parameter region where the typical RSA patterns are observed. As the model has a general form, the result can be applied to similar patterns in other complex biological networks, e.g. gene expression.	biological network;capability maturity model;interaction	Kei Tokita	2006	Ecological Informatics	10.1016/j.ecoinf.2005.12.003	biology;relative species abundance;statistical mechanics;ecology;statistics	Theory	3.6122471402816987	-61.65945579385481	90373
60f0187a55c51eef3a523a1bdcc18b6f2345b511	characterization of n-acyl homoserine lactones in vibrio tasmaniensis lgp32 by a biosensor-based uhplc-hrms/ms method	fractionation;quorum sensing;n acyl homoserine lactone ahl;uhplc hrms ms;vibrio tasmaniensis lgp32;biosensors	Since the discovery of quorum sensing (QS) in the 1970s, many studies have demonstrated that Vibrio species coordinate activities such as biofilm formation, virulence, pathogenesis, and bioluminescence, through a large group of molecules called N-acyl homoserine lactones (AHLs). However, despite the extensive knowledge on the involved molecules and the biological processes controlled by QS in a few selected Vibrio strains, less is known about the overall diversity of AHLs produced by a broader range of environmental strains. To investigate the prevalence of QS capability of Vibrio environmental strains we analyzed 87 Vibrio spp. strains from the Banyuls Bacterial Culture Collection (WDCM911) for their ability to produce AHLs. This screening was based on three biosensors, which cover a large spectrum of AHLs, and revealed that only 9% of the screened isolates produced AHLs in the defined experimental conditions. Among these AHL-producing strains, Vibrio tasmaniensis LGP32 is a well-known pathogen of bivalves. We further analyzed the diversity of AHLs produced by this strain using a sensitive bioguided UHPLC-HRMS/MS approach (Ultra-High-Performance Liquid Chromatography followed by High-Resolution tandem Mass Spectrometry) and we identified C10-HSL, OH-C12-HSL, oxo-C12-HSL and C14:1-HSL as QS molecules. This is the first report that documents the production of AHL by Vibrio tasmaniensis LGP32.	accession number (identifier);accession number (bioinformatics);acyl-homoserine lactones;biosensors;class bivalvia;dose-fractionation theorem;fragmentation (computing);gary kimura;genbank;homoserine;hydroxyl radical;leukoencephalitis, acute hemorrhagic;microbial biofilms;pathogenic organism;population parameter;projection screen;tandem mass spectrometry;virulence;physiological aspects;potassium oxonate;quorum sensing;standards characteristics	Léa Girard;Élodie Blanchet;Laurent Intertaglia;Julia Baudart;Didier Stien;Marcelino T Suzuki;Philippe Lebaron;Raphaël Lami	2017		10.3390/s17040906	biochemistry;quorum sensing;chemistry;nanotechnology;fractionation;biosensor	ML	4.7587881720544924	-63.37611833427109	90467
3568dbe766e45c31e689f6365c35237198fe61d1	scaffold assembly based on genome rearrangement analysis	genome rearrangements;genome assembly;breakpoint graph;scaffolding;mgra	Advances in DNA sequencing technology over the past decade have increased the volume of raw sequenced genomic data available for further assembly and analysis. While there exist many algorithms for assembly of sequenced genomic material, they often experience difficulties in constructing complete genomic sequences. Instead, they produce long genomic subsequences (scaffolds), which then become a subject to scaffold assembly aimed at reconstruction of their order along genome chromosomes. The balance between reliability and cost for scaffold assembly is not there just yet, which inspires one to seek for new approaches to address this problem. We present a new method for scaffold assembly based on the analysis of gene orders and genome rearrangements in multiple related genomes (some or even all of which may be fragmented). Evaluation of the proposed method on artificially fragmented mammalian genomes demonstrates its high reliability. We also apply our method for incomplete anophelinae genomes, which expose high fragmentation, and further validate the assembly results with referenced-based scaffolding. While the two methods demonstrate consistent results, the proposed method is able to identify more assembly points than the reference-based scaffolding.	chromosomes;dna sequence rearrangement;existential quantification;fragmentation (computing);genome;mammals;partial;algorithm;orders - hl7publishingdomain;scaffold	Sergey Aganezov;Nadia Sitdykova;Max A. Alekseyev	2015	Computational biology and chemistry	10.1016/j.compbiolchem.2015.02.005	biology;computer science;bioinformatics;sequence assembly;genetics;hybrid genome assembly	Comp.	-0.08956395649417769	-53.58939148514319	90532
7be0f4e772b5aef9eeebe96d10a50c24e24ade4d	a novel drug-mouse phenotypic similarity method detects molecular determinants of drug effects	drug discovery;adverse reactions;drug interactions;drug therapy;drug information;mouse models;pharmacogenetics;phenotypes	The molecular mechanisms that translate drug treatment into beneficial and unwanted effects are largely unknown. We present here a novel approach to detect gene-drug and gene-side effect associations based on the phenotypic similarity of drugs and single gene perturbations in mice that account for the polypharmacological property of drugs. We scored the phenotypic similarity of human side effect profiles of 1,667 small molecules and biologicals to profiles of phenotypic traits of 5,384 mouse genes. The benchmarking with known relationships revealed a strong enrichment of physical and indirect drug-target connections, causative drug target-side effect links as well as gene-drug links involved in pharmacogenetic associations among phenotypically similar gene-drug pairs. The validation by in vitro assays and the experimental verification of an unknown connection between oxandrolone and prokineticin receptor 2 reinforces the ability of this method to provide new molecular insights underlying drug treatment. Thus, this approach may aid in the proposal of novel and personalized treatments.	biological factors;drug delivery systems;gene ontology term enrichment;mental association;oxandrolone;prokr2 gene;prokr2 protein, human;personalization;pharmacogenomic analysis;score;small molecule;trait;verification of theories	Jeanette Prinz;Ingo Vogt;Gianluca Adornetto;Monica Campillos	2016		10.1371/journal.pcbi.1005111	pharmacotherapy;pharmacology;biology;pharmacogenetics;toxicology;bioinformatics;phenotype;genetics;drug discovery	Comp.	7.608725601632679	-60.134493163414234	90550
39d8bc45865b096504b465e56f82fffb9c2a4ef6	fmprpmf: a web implementation for protein identification by robust peptide mass fingerprinting		Peptide mass fingerprinting continues to play an important role in current proteomics studies based on its good performance in sample throughput, specificity for single peptides, and insensitivity to unexpected post-translational modifications as compared with MSn. We previously proposed and evaluated the use of feature-matching pattern-based support vector machines SVMs for robust protein identification. This approach is now facilitated with an updated web server fmpRPMF incorporated with several newly developed or improved modules and workflows allowing identification of proteins from MS1 data. Development of the latest fmpRPMF web tool successfully provides a rapid and effective strategy for narrowing the range of candidate proteins. First, a mass-scanning procedure screens all candidate proteins matching the theoretical peptide mass at least three times, thereby reducing the number of candidate proteins from tens of thousands to thousands. Second, a crude ranking procedure screens true-positive proteins among the top six ranked times of candidates based on 17 selected features to reduce the number used for SVM prediction from thousands to tens. The improvement of forecasting efficiency met the requirements of multi-user and multi-task identification for web services. The updated fmpRPMF server is freely available at http://bioinformatics.datawisdom.net/fmp.	bioinformatics;computer multitasking;ephrin type-b receptor 1, human;fingerprint (computing);genetic translation process;matching;multi-user;numerous;peptide-mass fingerprint;post-translational protein processing;projections and predictions;proteomics;radio fingerprinting;requirement;sensitivity and specificity;server (computing);support vector machine;throughput;transcutaneous electric nerve stimulation;web server;web service	Youyuan Li;Yingping Zhuang	2017	IEEE/ACM Transactions on Computational Biology and Bioinformatics	10.1109/TCBB.2017.2762682	support vector machine;web service;throughput;computer science;web server;fingerprint recognition;pattern matching;bioinformatics;peptide mass fingerprinting;proteomics	Comp.	9.072168718309104	-56.98176974256201	90624
a993672e02d1af6a5a5f328d906d9e6601317fa8	a knock-out for nsaids.	microarray data;hierarchical clustering;animals;cluster algorithm;nad p h dehydrogenase quinone;interaction analysis;paired box transcription factors;plug and play;gene cluster;k means;models biological;eye proteins;aging;homeodomain proteins;data analysis;microarray analysis;models genetic;cluster analysis;open system;algorithms;self organized map;source code;humans;repressor proteins;neurons;false positive;receptor insulin;alzheimer disease;computational biology;detoxification;human brain;oligonucleotide array sequence analysis;insulin receptor;species specificity	OSCAR is a web platform for cluster and crossspecies analysis of microarray data. It provides a comprehensive but friendly environment to both users and algorithm developers. For users, OSCAR provides cluster tools for both single and multiple species data, together with interactive analysis features. For single species data, OSCAR currently provides Hierarchical Clustering, K-means, partition around medoids (PAM), Self-Organizing Map (SOM), Tight Clustering and a novel algorithm called ‘Consensus Tight-clustering’. The new Consensus Tight-clustering algorithm delivers robust gene clusters and its result is more resistant to false positives than other state-of-the-art algorithms. For cross-species data analysis, OSCAR provides two novel computational tools: ‘coherentCluster’, ‘coherentSubset’ and a novel visualization tool: ‘comparative heatmap’. Applying the coherentCluster algorithm to human and fly aging data, we identified several coherent clusters of genes, which share co-regulation patterns that are highly correlated with the aging process in both of the two species. One coherent cluster suggests insulin receptor (INSR) may regulate Pax6 in both species and across different tissues. Further analysis with human brain expression and pathological data suggests an INSR-̀ Pax6-̀ quinone oxidoreductase (NQO1)-̀ detoxification neuro-protective pathway might be present in aging or diseased brain. For algorithm developers, OSCAR is a plug-and-play platform. With little effort, developers can plug their own algorithms into the OSCAR server without revealing the source codes, which will equip their command line executables with user-friendly interface and interactive analysis capability. In summary, OSCAR initiates an open platform for development and application of clustering and cross-species analysis programs. OSCAR stands for an open system for cluster analysis of microarray data. It is available at: http://biocomp.bioen.		Yue Lu;Xin He;Sheng Zhong	1996	Environmental Health Perspectives	10.1093/nar/gkm408	biology;microarray analysis techniques;bioinformatics;genetics	ML	0.3178659808182283	-58.449180168963196	90747
218001523b3b4aed0c66de298a99a7588e035480	computational biology: a recipe for ligand-binding proteins	drug discovery;biochemistry;computational biology and bioinformatics	Cellular cross-talk, enzymatic catalysis and regulation of gene expression all depend on molecular recognition. A method that allows the design of proteins with desired recognition sites could thus be revolutionary. See Letter p.212	computation;computational biology;ligands	Giovanna Ghirlanda	2013	Nature	10.1038/nature12463	computational biology;biology;biophysics;bioinformatics;drug discovery;computational genomics	Comp.	3.0481406441711236	-64.36618357265581	91012
1012dcbc09e48ecb331718e6a3923203546f11dd	improvements to the gdb human genome data base	databases;genes;community;animals;mice;computer communication networks;computer graphics;genetics;polymorphism genetic;genome human;human genome;genome;humans;user computer interface;databases factual;phenotype	Version 6.0 of the Human Genome Data Base introduces a number of significant improvements over previous releases of GDB. The most important of these are revised data representations for genes and genomic maps and a new curatorial model for the database. GDB 6.0 is the first major genomic database to provide read/write access directly to the scientific community, including capabilities for third-party annotation. The revised database can represent all major categories of genetic and physical maps, along with the underlying order and distance information used to construct them. The improved representation permits more sophisticated map queries to be posed and supports the graphical display of maps. In addition the new GDB has a richer model for gene information, better suited for supporting cross-references to databases describing gene function, structure, products, expression and associated phenotypes.	angis;annotation;categories;cross-reference;data acquisition;database;databases;digital curation;documentation;eliza;email;fax;file system permissions;flat file database;gnu debugger;glycyrrhiza uralensis;infographic;internet;keyword;locus;license;like button;map;map;mutation (genetic algorithm);nucleic acids;phenotype;regulatory submission;revision procedure;search algorithm;server (computing);uniform resource identifier;user (computing);www;wechsler adult intelligence scale (assessment scale);citation	Kenneth H. Fasman;Stanley Letovsky;Robert W. Cottingham;David T. Kingsbury	1996	Nucleic acids research	10.1093/nar/24.1.57	biology;community;human genome;bioinformatics;phenotype;gene;computer graphics;genetics;genome	Comp.	-2.578040599980037	-60.644364035301244	91024
52f192f0e29f9b8ab37b67cf0a4eb656c85ef1af	in-silico prediction of surface residue clusters for enzyme-substrate specificity	surface residue clusters;complementary role;enzyme-substrate interaction;specificity determination;case study;current method;in-silico prediction;high substrate specificity;substrate recognition;critical mono-residue;multi-residue cluster;enzyme-substrate specificity;basic molecular mechanism;molecular biophysics;enzymes;botany;enzyme;malate dehydrogenase;molecular mechanics	One of the most remarkable properties of enzyme-substrate binding is the high substrate specificity among homologous enzymes. Identification of regions in enzymes that play an important role in substrate recognition presents an opportunity to understand their basic molecular mechanisms. Current methods are limited to identifying conserved residues, ignoring potential contributions of non-conserved residues. Our method overcomes this limitation. In case studies, we investigated several highly homologous enzymatic protein pairs such as guanylyl vs. adenylyl cyclases and lactate vs. malate dehydrogenases, and applied our method on plant and cyano-bacterial RuBisCos. We identified several critical mono-residue and multi-residue clusters that were consistent with experimental results. Some of the identified clusters, primarily the mono-residue ones, represent residues that are directly involved in enzyme-substrate interactions. Others, mostly the multi-residue ones, represent residues vital for domain-domain and regulator-enzyme interactions, indicating their complementary roles in specificity determination.	homology (biology);interaction;sensitivity and specificity	Gong-Xin Yu;Byung-Hoon Park;Praveen Chandramohan;Al Geist;Nagiza F. Samatova	2004	Proceedings. 2004 IEEE Computational Systems Bioinformatics Conference, 2004. CSB 2004.	10.1109/CSB.2004.1332548	biology;biochemistry;enzyme;molecular biology;bioinformatics;molecular biophysics	Comp.	8.780939115073846	-60.90533378047061	91031
c638a636a66ff3fc06ae77bd9a736b201a76a006	primegens-v2: genome-wide primer design for analyzing dna methylation patterns of cpg islands	dna;cpg island;primer;amorce;bioinformatique;conception;metilacion;methylation;genome;diseno;iniciador;design;dna methylation;genoma;bioinformatica;primer design;bioinformatics	MOTIVATION DNA methylation plays important roles in biological processes and human diseases, especially cancers. High-throughput bisulfite genomic sequencing based on new generation of sequencers, such as the 454-sequencing system provides an efficient method for analyzing DNA methylation patterns. The successful implementation of this approach depends on the use of primer design software capable of performing genome-wide scan for optimal primers from in silico bisulfite-treated genome sequences. We have developed a method, which fulfills this requirement and conduct primer design for sequences including regions of given promoter CpG islands.   RESULTS The developed method has been implemented using the C and JAVA programming languages. The primer design results were tested in the PCR experiments of 96 selected human DNA sequences containing CpG islands in the promoter regions. The results indicate that this method is efficient and reliable for designing sequence-specific primers.   AVAILABILITY The sequence-specific primer design for DNA meth-ylated sequences including CpG islands has been integrated into the second version of PRIMEGENS as one of the primer design features. The software is freely available for academic use at http://digbio.missouri.edu/primegens/.	biopolymer sequencing;cpg islands;experiment;java;malignant neoplasms;methamphetamine;methylation;primer;portable software apps;programming languages;programming language;promoter regions, genetic;throughput;cytidylyl-3'-5'-guanosine;hydrogen sulfite	Gyan Prakash Srivastava;Juyuan Guo;Huidong Shi;Dong Xu	2008	Bioinformatics	10.1093/bioinformatics/btn320	biology;design;molecular biology;bioinformatics;methylation;dna methylation;genetics;primer;dna;genome	Comp.	-0.32127609748015606	-57.39481033846449	91143
0ae4ee1c091ceda60e786a6080f506cb2c387f9e	modeling the integration of bacterial rrna fragments into the human cancer genome	histocompatibility antigens class ii;gpi linked proteins;host parasite interactions;cell adhesion molecules;antigens cd;computational biology bioinformatics;5 untranslated regions;genome human;nucleic acid conformation;algorithms;humans;pseudomonas;neoplasms;combinatorial libraries;rna ribosomal;recombination genetic;antigens differentiation b lymphocyte;computer appl in life sciences;carcinoembryonic antigen;microarrays;bioinformatics	Cancer is a disease driven by the accumulation of genomic alterations, including the integration of exogenous DNA into the human somatic genome. We previously identified in silico evidence of DNA fragments from a Pseudomonas-like bacteria integrating into the 5′-UTR of four proto-oncogenes in stomach cancer sequencing data. The functional and biological consequences of these bacterial DNA integrations remain unknown. Modeling of these integrations suggests that the previously identified sequences cover most of the sequence flanking the junction between the bacterial and human DNA. Further examination of these reads reveals that these integrations are rich in guanine nucleotides and the integrated bacterial DNA may have complex transcript secondary structures. The models presented here lay the foundation for future experiments to test if bacterial DNA integrations alter the transcription of the human genes.	dna integration;diploid cell;experiment;flank (surface region);guanine nucleotides;oncogenes;proto-oncogenes;reading (activity);stomach carcinoma;transcript;transcription (software);tree accumulation	Karsten B. Sieber;Pawel Gajer;Julie C. Dunning Hotopp	2016		10.1186/s12859-016-0982-0	biology;cell adhesion molecule;molecular biology;cancer genome sequencing;dna microarray;computer science;bioinformatics;genetics	Comp.	5.708552180793666	-62.86811637170159	91149
d149e636784aed2fb6e24bd5a0c71fbe5db0879d	construction of reliable protein-protein interaction networks with a new interaction generality measure	protein protein interaction network;protein complex;interaction network;signal transduction pathway;computational method;topological properties;protein protein interaction;protein interaction;false positive	MOTIVATION Recent screening techniques have made large amounts of protein-protein interaction data available, from which biologically important information such as the function of uncharacterized proteins, the existence of novel protein complexes, and novel signal-transduction pathways can be discovered. However, experimental data on protein interactions contain many false positives, making these discoveries difficult. Therefore computational methods of assessing the reliability of each candidate protein-protein interaction are urgently needed.   RESULTS We developed a new 'interaction generality' measure (IG2) to assess the reliability of protein-protein interactions using only the topological properties of their interaction-network structure. Using yeast protein-protein interaction data, we showed that reliable protein-protein interactions had significantly lower IG2 values than less-reliable interactions, suggesting that IG2 values can be used to evaluate and filter interaction data to enable the construction of reliable protein-protein interaction networks.	chamaecyparis lawsoniana;interaction network;transduction (machine learning);yeast proteins;protein protein interaction	Rintaro Saito;Harukazu Suzuki;Yoshihide Hayashizaki	2003	Bioinformatics	10.1093/bioinformatics/btg070	protein–protein interaction;methods to investigate protein–protein interactions;interaction network;biology;type i and type ii errors;bioinformatics;data mining;multiprotein complex;protein–protein interaction prediction;signal transduction	Comp.	6.244275622858227	-57.52057407557096	91219
55b4bbe5e7ae51356b04fb0b5989030379350c20	the web server of ibm's bioinformatics and pattern discovery group: 2004 update	software;peptides;antimicrobial activity;protein structure secondary;genome annotation;databases genetic;anti infective agents;gene expression;pattern discovery;internet;proteins;genome;sequence analysis;multiple sequence alignment;computational biology	In this report, we provide an update on the services and content which are available on the web server of IBM's Bioinformatics and Pattern Discovery group. The server, which is operational around the clock, provides access to a large number of methods that have been developed and published by the group's members. There is an increasing number of problems that these tools can help tackle; these problems range from the discovery of patterns in streams of events and the computation of multiple sequence alignments, to the discovery of genes in nucleic acid sequences, the identification--directly from sequence--of structural deviations from alpha-helicity and the annotation of amino acid sequences for antimicrobial activity. Additionally, annotations for more than 130 archaeal, bacterial, eukaryotic and viral genomes are now available on-line and can be searched interactively. The tools and code bundles continue to be accessible from http://cbcsrv.watson.ibm.com/Tspd.html whereas the genomics annotations are available at http://cbcsrv.watson.ibm.com/Annotations/.	amino acid sequence;amino acids;annotation;bioinformatics;cell nucleus;computation (action);greater than;inclusion body myositis (disorder);interactivity;multiple sequence alignment;nucleic acids;online and offline;scientific publication;server (computer);server (computing);viral genome;web server;world wide web	Tien Huynh;Isidore Rigoutsos	2004	Nucleic acids research	10.1093/nar/gkh367	biology;the internet;gene expression;multiple sequence alignment;bioinformatics;sequence analysis;genome project;genetics;genome	Comp.	-0.8960426692335534	-59.62873667605616	91381
8b90c83b21d0dca4df0560f22605c3184fa42282	construction of anatomically correct models of mouse brain networks	web pages;network motif;network simulator;web crawler;web based database;neuron morphologies;mouse brain networks;network motifs;spatial distribution;compartmental model;neuronal morphology;federated databases;synaptic assembly	The Mouse Brain Web (MBW), a web-organized database, provides for the construction of anatomically correct models of mouse brain networks. Each web page in this database provides the position, orientation, morphology, and putative synapses for each biologically observed neuron. The MBW has been designed to support (1) mapping of the spatial distribution and morphology of neurons by type; (2) wiring of the network–synaptic assembly; (3) projection of neuron morphology and synapses to geometric multi-compartmental models; (4) search for motifs and basic circuits in the brain networks using customized web-crawlers; and (5) the mapping of anatomically correct networks to physiologically correct network simulations. c © 2004 Published by Elsevier B.V.	galaxy morphological classification;mbrwizard;mathematical morphology;multi-compartment model;neuron;paging;sequence motif;simulation;synapse;web page;wiring	Bruce H. McCormick;Wonryull Koh;Yoonsuck Choe;Louise C. Abbott;John Keyser;David Mayerich;Zeki Melek;Purna Doddapaneni	2004	Neurocomputing	10.1016/j.neucom.2004.01.070	neuromorphology;computer science;bioinformatics;network motif;theoretical computer science;web crawler;machine learning;web page;network simulation	ML	-4.368759701654095	-58.7094555136257	91479
5210bebfd3b5e601ffc020610b7d96c972e4d7a2	molecular docking, md simulation, dft and adme-toxicity study on analogs of zerumbone against ikk-β enzyme as anti-cancer agents		The inhibitor of kappaB kinase beta (IKK-β) is an important target for the therapeutic treatment of cancer and inflammatory diseases. On the other hand, zerumbone an isolate from Zingiber zerumbet has become an important molecule for targeting various cancer drug targets and enzyme. Although zerumbone is also a good inhibitor of IKK-β, its usage is limited because of its bioavailability problem. Hence, the objective of this investigation focuses on discovering new analogs of zerumbone with better bioavailability. The study involves DFT-based molecular docking and molecular dynamics simulation studies on zerumbone against the IKK-β enzyme. The best docking pose of the analogs was further analyzed for molecular interaction map and carried forward for molecular dynamics simulation production. They were also analyzed for HOMO and LUMO energies calculated at DFT/B3LYP/6-31G (d′, p′) levels of theory to calculate the band gap energy. The study observed that the analogs of zerumbone inhibit the IKK-β with favorable binding affinity than zerumbone.		Salam Pradeep Singh;Ningthoujam Indrajit Singh;Khumukcham Nongalleima;Pradip Doley;Chingakham Brajakishor Singh;Dinabandhu Sahoo	2018	Network Modeling Analysis in Health Informatics and Bioinformatics	10.1007/s13721-018-0171-3	docking (molecular);iκb kinase;adme;ligand (biochemistry);biochemistry;homo/lumo;kinase;enzyme;bioinformatics;biology	Comp.	9.423604694337431	-61.68502006485792	91495
a59c09e577d1f5908c6532636c7768428de44456	an estimate of the mutation rates of the active sites of influenza a/h5n1 neuraminidases	active site;mutation rate			Jack Horner	2010			influenza a/h5n1;active site;mutation rate;virology;biology	ML	3.5382985808571794	-63.93420902834687	91541
30865470755af64caf732ee88523b81136dc5ef4	gene prediction in metagenomic fragments based on the svm algorithm	dna;biology computing;genomics;complete genome;genomics dna bioinformatics proteins training microorganisms databases;support vector machines;support vector machines biology computing dna genomics molecular biophysics;power method;dna fragmentation;metagenomic sequence metagenomic fragment svm algorithm supervised universal model data specific novel model entropy density profile codon usage translation initiation signal scoring open read frame length model training fixed length artificial shotgun sequence gene prediction method metagenomic sample human gut community genomic sequence data dna fragments;genomic dna;numerical computation;gene prediction;open reading frame;molecular biophysics;codon usage;genome sequence;translation initiation	Metagenomic sequencing is becoming a powerful method to explore various environmental organisms without isolation and cultivation. Genomic sequences data generated by this technology is growing explosively while numerous computational methods for analysis are still urgently in need. One of the first and most important processes is exhaustive gene prediction. As short and anonymous DNA fragments, assembly of metagenomic sequences usually has not a fixed end point to obtain complete genomes and moreover is often not available. This situation makes the annotation more complicated than in complete genomes. Here, we present a newly developed SVM-based algorithm which comprises a supervised universal model and a data-specific novel model. It utilizes entropy density profiles of codon usage, translation initiation signal scoring and open read frame length for model training. Tests on fixed-length artificial shotgun sequences of 700 bp showed a sensitivity of 94.7% and a specificity of 94.9% on average, which indicate that our method has the totally higher performance than the best of current gene prediction methods. Thousands of additional genes are predicted when applied to two metagenomic samples from human gut community. Furthermore, compared to other gene predictors, our algorithm predicts the most potential novel genes.	algorithm;gene prediction;metagenomics	Yongchu Liu;Jiangtao Guo;Huaiqiu Zhu	2011		10.1109/BMEI.2011.6098588	open reading frame;biology;support vector machine;dna fragmentation;genomics;molecular biology;eukaryotic translation;codon usage bias;whole genome sequencing;power iteration;bioinformatics;genomic dna;genetics;dna;gene prediction;molecular biophysics	NLP	9.502901236912644	-55.02149277654997	91556
f5285177b5cdba9e5ceed53460be773c7b41eeee	symbolic generation and clustering of rna 3-d motifs	guanine;rna;helical configuration;algorithms;biology and medicine basic studies;structural models;mathematics computers information science management law miscellaneous;molecular structure	Non canonical G.A. base pairs play important structural and functional roles in ribonucleic [sequence: see text] acids (RNA). In particular, the 3'-A-G-5' motif and three of its sequence variants have a relatively high occurrence in 16S and 23S ribosomal RNA. Extensive 3-D modeling of these variants has allowed to support a previously proposed 3-D model and to identify another series of conformations consistent with phylogenetic data. The library of 3-D conformations generated by the MC-SYM program was then used to produce 3-D conformations of the small ribonucleotide r(GGCGAGCC)2. This new library includes the conformation determined by nuclear magnetic resonance spectroscopy.	3d modeling;base pairing;libraries;library (computing);motif;phylogenetics;ribonucleotides;ribosomal rna;sympk gene;sequence motif;spectroscopy, nuclear magnetic resonance;statistical cluster	Marielle Foucrault;François Major	1995	Proceedings. International Conference on Intelligent Systems for Molecular Biology		crystallography;biology;rna;molecule;bioinformatics;genetics	Comp.	1.6892040483195303	-59.863193180368434	91563
c91cc994002c663ef06fd172a24b2cb490b4b715	protein sequences classification by means of feature extraction with substitution matrices	protein sequence;amino acid sequence;supervised classification;amino acid substitution;feature space;computational biology bioinformatics;feature vector;proteins;machine learning;feature extraction;protein classification;sequence homology amino acid;artificial intelligence;algorithms;molecular sequence data;sequence alignment;combinatorial libraries;classification accuracy;computer appl in life sciences;sequence analysis protein;databases protein;microarrays;bioinformatics	This paper deals with the preprocessing of protein sequences for supervised classification. Motif extraction is one way to address that task. It has been largely used to encode biological sequences into feature vectors to enable using well-known machine-learning classifiers which require this format. However, designing a suitable feature space, for a set of proteins, is not a trivial task. For this purpose, we propose a novel encoding method that uses amino-acid substitution matrices to define similarity between motifs during the extraction step. In order to demonstrate the efficiency of such approach, we compare several encoding methods using some machine learning classifiers. The experimental results showed that our encoding method outperforms other ones in terms of classification accuracy and number of generated attributes. We also compared the classifiers in term of accuracy. Results indicated that SVM generally outperforms the other classifiers with any encoding method. We showed that SVM, coupled with our encoding method, can be an efficient protein classification system. In addition, we studied the effect of the substitution matrices variation on the quality of our method and hence on the classification quality. We noticed that our method enables good classification accuracies with all the substitution matrices and that the variances of the obtained accuracies using various substitution matrices are slight. However, the number of generated features varies from a substitution matrix to another. Furthermore, the use of already published datasets allowed us to carry out a comparison with several related works. The outcomes of our comparative experiments confirm the efficiency of our encoding method to represent protein sequences in classification tasks.	amino acid sequence;classification;encode;experiment;feature extraction;feature vector;machine learning;motif;peptide sequence;preprocessor;scientific publication;substitution matrix	Rabie Saidi;Mondher Maddouri;Engelbert Mephu Nguifo	2009		10.1186/1471-2105-11-175	biology;feature vector;computer science;bioinformatics;machine learning;pattern recognition	ML	9.557540708890723	-53.89672310457062	91620
890646de7d9364cf43e7dbe8affb9cbb7c0375aa	structure prediction and antigenic site determination of cd4 antigen	hiv;side chain residue;human immunodeficiency virus;cd4 antigen;mhc molecules;comparative modelling;antigenic epitope;major histocompatibility complex;molecular modelling;electrostatic representation;molecule binding	CD antigen are playing vital role in many diseases. The human CD4 molecule binds both human immunodeficiency virus (HIV) envelope protein gp120 and class II major histocompatibility complex (MHC) molecules. This binding help for the internalisation of HIV and its replication in host CD4 T-cells concentration fall drastically, a disastrous fall in CD4 T-cells destroy cell immediate defence and leaves the patients open to life threatening infection through opportunistic organism such as Pnemoastic carinii and cytomegalovirus. In the present investigation attempts have been made to study the structural and molecular aspects of CD4. To illustrate the stability of electrostatic representation, the solvent-accessible surface of the molecules was calculated using the Deepveiw or Swisspdb package. Two large positive and two large negative potential patches characterise the surface of the antigen in this system. One interesting feature of the CD4 interface is the high number of side chain residue. Energy minimisation analysis results showed the bond energy 550.838 KJ/mol, angle 1,176.970 KJ/mol, torsion 2,205.20 KJ/mol, non-bonded –9,726.67 KJ/mol, electrostatic-10,237.85 KJ/mol and improper 465.336 KJ/mol.	accessible surface area;model of hierarchical complexity;torsion (gastropod)	Arun G. Ingale	2010	IJMEI	10.1504/IJMEI.2010.035219	medicine;virology;immunology;major histocompatibility complex	Comp.	8.828416704226537	-62.44130314385029	91731
7708f444c410a6b459d72ffac52a1449c7263dfd	effect of the mutation rate and background size on the quality of pathogen identification	qualite;mutation rate;bioinformatique;taille;mutacion;genome size;quality;identification;talla;identificacion;total length;bioinformatica;false positive;monte carlo simulation;size;mutation;calidad;bioinformatics	MOTIVATION Genomic-based methods have significant potential for fast and accurate identification of organisms or even genes of interest in complex environmental samples (air, water, soil, food, etc.), especially when isolation of the target organism cannot be performed by a variety of reasons. Despite this potential, the presence of the unknown, variable and usually large quantities of background DNA can cause interference resulting in false positive outcomes.   RESULTS In order to estimate how the genomic diversity of the background (total length of all of the different genomes present in the background), target length and target mutation rate affect the probability of misidentifications, we introduce a mathematical definition for the quality of an individual signature in the presence of a background based on its length and number of mismatches needed to transform the signature into the closest subsequence present in the background. This definition, in conjunction with a probabilistic framework, allows one to predict the minimal signature length required to identify the target in the presence of different sizes of backgrounds and the effect of the target's mutation rate on the quality of its identification. The model assumptions and predictions were validated using both Monte Carlo simulations and real genomic data examples. The proposed model can be used to determine appropriate signature lengths for various combinations of target and background genome sizes. It also predicted that any genomic signatures will be unable to identify target if its mutation rate is >5%.   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	antivirus software;bioinformatics;genome size;interference (communication);mathematics;monte carlo method;pathogenic organism;quantity;simulation	Chris Reed;Viacheslav Fofanov;Catherine Putonti;Sergei Chumakov;Tom Slezak;Yuriy Fofanov	2007	Bioinformatics	10.1093/bioinformatics/btm420	identification;mutation;biology;mutation rate;type i and type ii errors;bioinformatics;genome size;size;genetics;statistics;monte carlo method	Comp.	5.131679844173905	-53.76224273448498	91760
37b503cf87b2bc43817df010751760c286a9dbc9	promot: a fortran program to scan protein sequences against a library of known motifs	computadora;software;secuencia aminoacido;base donnee;proteine;sequence aminoacide;aminoacid sequence;logiciel;computerized processing;tratamiento informatico;ordinateur;information retrieval;protein sequence;estructura terciaria;database;motif structural;base dato;computer;motivo estructural;proteins;recherche information;structure moleculaire;structural unit;logicial;proteina;fortran;recuperacion informacion;estructura molecular;traitement informatique;structure tertiaire;tertiary structure;molecular structure	Information about the three-dimensional structure or function of a newly determined protein sequence can be obtained if the protein is found to contain a characterized motif or pattern of residues. Recently a database (PROSITE) has been established that contains 337 known motifs encoded as a list of allowed residue types at specific positions along the sequence. PROMOT is a FORTRAN computer program that takes a protein sequence and examines if it contains any of the motifs in PROSITE. The program also extends the definitions of patterns beyond those used in PROSITE to provide a simple, yet flexible, method to scan either a PROSITE or a user-defined pattern against a protein sequence database.	amino acid sequence;computer program;fortran;motif;prosite;peptide sequence;sequence database;staphylococcal protein a	Michael J. E. Sternberg	1991	Computer applications in the biosciences : CABIOS	10.1093/bioinformatics/7.2.257	biology;protein tertiary structure;molecule;bioinformatics;structural unit;protein sequencing;algorithm	Comp.	-4.384659473697467	-56.278692351592866	91921
3c49ac164dc021500c01799095ab5626f8c3805e	the poisson margin test for normalization-free significance analysis of ngs data	algorithms	"""The current methods for the determination of the statistical significance of peaks and regions in next generation sequencing (NGS) data require an explicit normalization step to compensate for (global or local) imbalances in the sizes of sequenced and mapped libraries. There are no canonical methods for performing such compensations; hence, a number of different procedures serving this goal in different ways can be found in the literature. Unfortunately, the normalization has a significant impact on the final results. Different methods yield very different numbers of detected """"significant peaks"""" even in the simplest scenario of ChIP-Seq experiments that compare the enrichment in a single sample relative to a matching control. This becomes an even more acute issue in the more general case of the comparison of multiple samples, where a number of arbitrary design choices will be required in the data analysis stage, each option resulting in possibly (significantly) different outcomes. In this article, we investigate a principled statistical procedure that eliminates the need for a normalization step. We outline its basic properties, in particular the scaling upon depth of sequencing. For the sake of illustration and comparison, we report the results of re-analyzing a ChIP-Seq experiment for transcription factor binding site detection. In order to quantify the differences between outcomes, we use a novel method based on the accuracy of in silico prediction by support vector machine (SVM) models trained on part of the genome and tested on the remainder. See Kowalczyk et al. ( 2009 ) for supplementary material."""		Adam Kowalczyk;Justin Bedo;Thomas C. Conway;Bryan Beresford-Smith	2011	Journal of computational biology : a journal of computational molecular cell biology	10.1089/cmb.2010.0272	mathematics;machine learning;statistics;artificial intelligence;normalization (statistics);poisson distribution	Comp.	4.557128750121634	-53.938471098610485	92229
667c5308fcee5fc25e23af2ca04229832cc9a1e2	cdd: a conserved domain database for the functional annotation of proteins	conserved domain database;functional annotation;amino acid sequence;national library of medicine u s;models biological;datasets;conserved sequence;proteins;protein structure tertiary;united states national institutes of health;sequence analysis protein;databases protein	NCBI's Conserved Domain Database (CDD) is a resource for the annotation of protein sequences with the location of conserved domain footprints, and functional sites inferred from these footprints. CDD includes manually curated domain models that make use of protein 3D structure to refine domain models and provide insights into sequence/structure/function relationships. Manually curated models are organized hierarchically if they describe domain families that are clearly related by common descent. As CDD also imports domain family models from a variety of external sources, it is a partially redundant collection. To simplify protein annotation, redundant models and models describing homologous families are clustered into superfamilies. By default, domain footprints are annotated with the corresponding superfamily designation, on top of which specific annotation may indicate high-confidence assignment of family membership. Pre-computed domain annotation is available for proteins in the Entrez/Protein dataset, and a novel interface, Batch CD-Search, allows the computation and download of annotation for large sets of protein queries. CDD can be accessed via http://www.ncbi.nlm.nih.gov/Structure/cdd/cdd.shtml.	amino acid sequence;cdd;computation;default;download;entrez;identifier;inference;ncbi taxonomy;peptide sequence;protein annotation;superfamily;silo (dataset)	Aron Marchler-Bauer;Shennan Lu;John B. Anderson;Farideh Chitsaz;Myra K. Derbyshire;Carol DeWeese-Scott;Jessica H. Fong;Lewis Y. Geer;Renata C. Geer;Noreen R. Gonzales;Marc Gwadz;David I. Hurwitz;John D. Jackson;Zhaoxi Ke;Christopher J. Lanczycki;Fu Lu;Gabriele H. Marchler;Mikhail Mullokandov	2011		10.1093/nar/gkq1189	biology;bioinformatics;peptide sequence;conserved sequence;conserved domain database	Comp.	-1.4031811518988404	-60.73501022954731	92334
2607dbd41f0f8247e7ec0dff2f3aba2f5aa3abf3	follicle online: an integrated database of follicle assembly, development and ovulation	animals;female;mice;rats;polycystic ovary syndrome;ovarian follicle;databases genetic;ovulation;online systems;cattle;humans;primary ovarian insufficiency	Folliculogenesis is an important part of ovarian function as it provides the oocytes for female reproductive life. Characterizing genes/proteins involved in folliculogenesis is fundamental for understanding the mechanisms associated with this biological function and to cure the diseases associated with folliculogenesis. A large number of genes/proteins associated with folliculogenesis have been identified from different species. However, no dedicated public resource is currently available for folliculogenesis-related genes/proteins that are validated by experiments. Here, we are reporting a database 'Follicle Online' that provides the experimentally validated gene/protein map of the folliculogenesis in a number of species. Follicle Online is a web-based database system for storing and retrieving folliculogenesis-related experimental data. It provides detailed information for 580 genes/proteins (from 23 model organisms, including Homo sapiens, Mus musculus, Rattus norvegicus, Mesocricetus auratus, Bos Taurus, Drosophila and Xenopus laevis) that have been reported to be involved in folliculogenesis, POF (premature ovarian failure) and PCOS (polycystic ovary syndrome). The literature was manually curated from more than 43,000 published articles (till 1 March 2014). The Follicle Online database is implemented in PHP + MySQL + JavaScript and this user-friendly web application provides access to the stored data. In summary, we have developed a centralized database that provides users with comprehensive information about genes/proteins involved in folliculogenesis. This database can be accessed freely and all the stored data can be viewed without any registration. Database URL: http://mcg.ustc.edu.cn/sdap1/follicle/index.php	bos taurus;centralized computing;database;experiment;function (biology);hematological disease;javascript;mus;muscle;mysql;ovarian follicle;ovarian failure;ovum;php;polycystic ovary syndrome;premature menopause;rafivirumab;rattus norvegicus;reliability engineering;reproduction;scientific publication;syrian hamster skin extract 50 mg/ml injectable solution;url data type;usability;web application;registration - actclass	Juan Hua;Bo Xu;Yifan Yang;Rongjun Ban;Furhan Iqbal;Howard J. Cooke;Yuanwei Zhang;Qinghua Shi	2015		10.1093/database/bav036	biology;endocrinology;bioinformatics	DB	-1.4465270758246678	-61.6033693981645	92432
3354998e2f58a01e8d67599e7331f84afe110a11	interactive visual comparison of multiple trees	microorganisms biology computing data visualisation evolution biological;organisms;biology computing;phylogeny;protein sequence;evolution biological;interactive visualization;enzyme;bacterial ancestry interactive visual comparison multiple trees hierarchy visual analysis phylogenetic trees 16s ribosomal rna protein sequences enzymes evolutionary biology domain;statistical significance;vegetation;data visualisation;visualization;local structure;level of detail;phylogenetic tree;image color analysis;evolutionary biology;visual analysis;data visualization;ribosomal rna;inproceedings;evolutionary process;visual analytics;microorganisms;visualization phylogeny vegetation image color analysis data visualization organisms	Traditionally, the visual analysis of hierarchies, respectively, trees, is conducted by focusing on one given hierarchy. However, in many research areas multiple, differing hierarchies need to be analyzed simultaneously in a comparative way - in particular to highlight differences between them, which sometimes can be subtle. A prominent example is the analysis of so-called phylogenetic trees in biology, reflecting hierarchical evolutionary relationships among a set of organisms. Typically, the analysis considers multiple phylogenetic trees, either to account for statistical significance or for differences in derivation of such evolutionary hierarchies; for example, based on different input data, such as the 16S ribosomal RNA and protein sequences of highly conserved enzymes. The simultaneous analysis of a collection of such trees leads to more insight into the evolutionary process. We introduce a novel visual analytics approach for the comparison of multiple hierarchies focusing on both global and local structures. A new tree comparison score has been elaborated for the identification of interesting patterns. We developed a set of linked hierarchy views showing the results of automatic tree comparison on various levels of details. This combined approach offers detailed assessment of local and global tree similarities. The approach was developed in close cooperation with experts from the evolutionary biology domain. We apply it to a phylogenetic data set on bacterial ancestry, demonstrating its application benefit.		Sebastian Bremm;Tatiana von Landesberger;Martin Hess;Tobias Schreck;Philipp Weil;Kay Hamacher	2011	2011 IEEE Conference on Visual Analytics Science and Technology (VAST)	10.1109/VAST.2011.6102439	organism;enzyme;visual analytics;phylogenetic tree;visualization;ribosomal rna;computer science;bioinformatics;level of detail;protein sequencing;tree rearrangement;data mining;statistical significance;microorganism;data visualization;vegetation;statistics	Visualization	2.201563451632871	-57.903050371337294	92483
d13b0e94be9b35671204887c4d36b4e508a93549	the 2010 nucleic acids research database issue and online database collection: a community of data resources	software;animals;databases nucleic acid;databases genetic;internet;humans;computational biology;nucleic acid;information storage and retrieval;gene expression profiling;cell biology;databases protein	The current issue of Nucleic Acids Research includes descriptions of 58 new and 73 updated data resources. The accompanying online Database Collection, available at http://www.oxfordjournals.org/nar/database/a/, now lists 1230 carefully selected databases covering various aspects of molecular and cell biology. While most data resource descriptions remain very brief, the issue includes several longer papers that highlight recent significant developments in such databases as Pfam, MetaCyc, UniProt, ELM and PDBe. The databases described in the Database Issue and Database Collection, however, are far more than a distinct set of resources; they form a network of connected data, concepts and shared technology. The full content of the Database Issue is available online at the Nucleic Acids Research web site (http://nar.oxfordjournals.org/).	description;elm;metacyc;paper;pfam;trans fatty acids;uniprot	Guy Cochrane;Michael Y. Galperin	2010		10.1093/nar/gkp1077	biology;nucleic acid;the internet;bioinformatics;gene expression profiling;protein structure database;genetics	DB	-1.9833240603218103	-61.127508406258364	92509
f9369ac8f98a2c3cf67e763767ec502a4076b56f	gene-disease prioritization through cost-sensitive graph-based methodologies	settore inf 01 informatica	Finding genes associated with human genetic disorders is one of the most challenging problems in bio-medicine. In this context, to guide researchers in detecting the most reliable candidate causativegenes for the disease of interest, gene prioritization methods represent a necessary support to automatically rank genes according to their involvement in the disease under study. This problem is characterized by highly unbalanced classes (few causative and much more non-causative genes) and requires the adoption of cost-sensitive techniques to achieve reliable solutions. In this work we propose a network-based methodology for disease-gene prioritization designed to expressly cope with the data imbalance. Its validation over a benchmark composed of 708 selected medical subject headings (MeSH) diseases, shows that our approach is competitive with state-of-art methodologies, and its reduced time complexity makes its application feasible on large-size datasets.	benchmark (computing);british informatics olympiad;database;online mendelian inheritance in man;sensor;time complexity;unbalanced circuit	Marco Frasca;Simone Bassis	2016		10.1007/978-3-319-31744-1_64	biology;chemistry;computer science	ML	7.6831416201968	-54.440341900987114	92652
967aa9c22c6ca4f192f30e740945d9b12f541340	symbolic reinterpretation of hla gene products--impact on interpretation of hla data at the molecular level		In the HLA system genes are defined by antibody/antigen reactions and are denoted by single symbolic identifiers. This symbolization assumes a one-to-one correspondence between antibodies, antigens and genes. It is important, however, to label each reagent with symbols corresponding to all genes coding for antigens with which the reagent will react. The problems of cross-reactive groups and unexplained linkage relations may be elucidated by the redefinition and clarification of certain HLA antigens. A computer program can suggest such labelling schemes using input given by phenotype reaction patterns with a panel of reagents. When this program was applied to data on the class I HLA antigens a genetic model was suggested that differs somewhat from the currently accepted view. The new model is consistent with applicable and available family data on recombinants and has implications for the interpretation of data at the DNA level.	clarify;computer program;cross reactions;hla antigens;histocompatibility antigens class ii;identifier;linkage (software);one-to-one (data model);reagents	A. Wohlgemuth;D. P. Dubey	1987	Computer applications in the biosciences : CABIOS	10.1093/bioinformatics/3.3.233	computer science;genetics;algorithm	Comp.	5.046913340973235	-60.95761806451112	92753
410c4e5821c8658bbe8502545900bc341e97371a	topofit-db, a database of protein structural alignments based on the topofit method	functional annotation;mathematical computing;protein structure alignment;comparative analysis;web pages;protein structure;internet;structural homology protein;indexation;sequence alignment;user computer interface;databases protein	TOPOFIT-DB (T-DB) is a public web-based database of protein structural alignments based on the TOPOFIT method, providing a comprehensive resource for comparative analysis of protein structure families. The TOPOFIT method is based on the discovery of a saturation point on the alignment curve (topomax point) which presents an ability to objectively identify a border between common and variable parts in a protein structural family, providing additional insight into protein comparison and functional annotation. TOPOFIT also effectively detects non-sequential relations between protein structures. T-DB provides users with the convenient ability to retrieve and analyze structural neighbors for a protein; do one-to-all calculation of a user provided structure against the entire current PDB release with T-Server, and pair-wise comparison using the TOPOFIT method through the T-Pair web page. All outputs are reported in various web-based tables and graphics, with automated viewing of the structure-sequence alignments in the Friend software package for complete, detailed analysis. T-DB presents researchers with the opportunity for comprehensive studies of the variability in proteins and is publicly available at http://mozart.bio.neu.edu/topofit/index.php.	4-dichlorobenzene;accessibility;align (company);browsing;data table;decibel;erbb2 protein, human;graphics;http 404;heart rate variability;protein data bank;protein family;qualitative comparative analysis;sequence alignment;server (computer);staphylococcal protein a;web application;web page	Chesley M. Leslin;Alexej Abyzov;Valentin A. Ilyin	2007		10.1093/nar/gkl809	qualitative comparative analysis;biology;protein structure;the internet;bioinformatics;sequence alignment;web page;protein structure database	Comp.	-1.466084549209306	-59.99056226714484	92765
9fa37c27e37ff4e4b23a379c9550d69ed09753be	sequence-based identification of interface residues by an integrative profile combining hydrophobic and evolutionary information	evolution molecular;software;protein function;protein complex;numerical method;amino acid sequence;accessible surface area;journal article;computational biology bioinformatics;hydrophobic and hydrophilic interactions;models molecular;proteins;drug design;indexation;protein protein interaction;algorithms;self organized map;humans;support vector machine;combinatorial libraries;protein interaction;computer appl in life sciences;microarrays;bioinformatics	Protein-protein interactions play essential roles in protein function determination and drug design. Numerous methods have been proposed to recognize their interaction sites, however, only a small proportion of protein complexes have been successfully resolved due to the high cost. Therefore, it is important to improve the performance for predicting protein interaction sites based on primary sequence alone. We propose a new idea to construct an integrative profile for each residue in a protein by combining its hydrophobic and evolutionary information. A support vector machine (SVM) ensemble is then developed, where SVMs train on different pairs of positive (interface sites) and negative (non-interface sites) subsets. The subsets having roughly the same sizes are grouped in the order of accessible surface area change before and after complexation. A self-organizing map (SOM) technique is applied to group similar input vectors to make more accurate the identification of interface residues. An ensemble of ten-SVMs achieves an MCC improvement by around 8% and F1 improvement by around 9% over that of three-SVMs. As expected, SVM ensembles constantly perform better than individual SVMs. In addition, the model by the integrative profiles outperforms that based on the sequence profile or the hydropathy scale alone. As our method uses a small number of features to encode the input vectors, our model is simpler, faster and more accurate than the existing methods. The integrative profile by combining hydrophobic and evolutionary information contributes most to the protein-protein interaction prediction. Results show that evolutionary context of residue with respect to hydrophobicity makes better the identification of protein interface residues. In addition, the ensemble of SVM classifiers improves the prediction performance. Datasets and software are available at http://mail.ustc.edu.cn/~bigeagle/BMCBioinfo2010/index.htm .	accessible surface area;adverse reaction to drug;encode;interface device component;mcc gene;microelectronics and computer technology corporation;organizing (structure);self-organization;self-organizing map;staphylococcal protein a;support vector machine;protein protein interaction	Peng Chen;Jinyan Li	2010		10.1186/1471-2105-11-402	protein–protein interaction;biology;support vector machine;dna microarray;numerical analysis;computer science;bioinformatics;multiprotein complex;peptide sequence;accessible surface area;drug design	AI	9.487244603203697	-56.39450608081561	92780
6fa671d991abd938ff73eb6cf113ea4fa2ba34e3	recognizing metal and acid radical ion-binding sites by integrating ab initio modeling with template-based transferals			binding sites;clinical use template;de novo protein structure prediction;ions	Xiaohua Hu;Q. Dong;J. Yang;Yongzhi Zhang	2016	Bioinformatics	10.1093/bioinformatics/btw637	computer science;data mining;computational chemistry;ion;ab initio;metal;binding site;acid radical	Comp.	3.3167790232177023	-64.10156584442092	93035
0103f3c61058c4ad81798e9ad10e51bd8d792315	pairwise alignment of protein interaction networks	protein protein interaction network;evolutionary model;evolutionary models;protein protein interactions;optimization problem;interaction pattern;fast algorithm;network alignment;protein protein interaction;mathematical model;sequence alignment;protein interaction;protein interaction network	With an ever-increasing amount of available data on protein-protein interaction (PPI) networks and research revealing that these networks evolve at a modular level, discovery of conserved patterns in these networks becomes an important problem. Although available data on protein-protein interactions is currently limited, recently developed algorithms have been shown to convey novel biological insights through employment of elegant mathematical models. The main challenge in aligning PPI networks is to define a graph theoretical measure of similarity between graph structures that captures underlying biological phenomena accurately. In this respect, modeling of conservation and divergence of interactions, as well as the interpretation of resulting alignments, are important design parameters. In this paper, we develop a framework for comprehensive alignment of PPI networks, which is inspired by duplication/divergence models that focus on understanding the evolution of protein interactions. We propose a mathematical model that extends the concepts of match, mismatch, and gap in sequence alignment to that of match, mismatch, and duplication in network alignment and evaluates similarity between graph structures through a scoring function that accounts for evolutionary events. By relying on evolutionary models, the proposed framework facilitates interpretation of resulting alignments in terms of not only conservation but also divergence of modularity in PPI networks. Furthermore, as in the case of sequence alignment, our model allows flexibility in adjusting parameters to quantify underlying evolutionary relationships. Based on the proposed model, we formulate PPI network alignment as an optimization problem and present fast algorithms to solve this problem. Detailed experimental results from an implementation of the proposed framework show that our algorithm is able to discover conserved interaction patterns very effectively, in terms of both accuracies and computational cost.	algorithmic efficiency;computation;gene duplication abnormality;graph - visual representation;inspiration function;mathematical model;mathematical optimization;mathematics;optimization problem;pixel density;proton pump inhibitors;score;scoring functions for docking;sequence alignment;time complexity	Mehmet Koyutürk;Yohan Kim;Umut Topkara;Shankar Subramaniam;Wojciech Szpankowski;Ananth Grama	2006	Journal of computational biology : a journal of computational molecular cell biology	10.1089/cmb.2006.13.182	protein–protein interaction;biology;computer science;bioinformatics;machine learning;data mining;mathematics	Comp.	6.3992858065761835	-58.62113298639814	93049
ebac7388b0d2ced033156913cabaf6933163f5d7	bsqa: integrated text mining using entity relation semantics extracted from biological literature of insects	software;animals;text mining;trans activators;homeodomain proteins;behavior animal;data mining;internet;drosophila melanogaster;gene expression regulation;insects;systems integration;genes insect	Text mining is one promising way of extracting information automatically from the vast biological literature. To maximize its potential, the knowledge encoded in the text should be translated to some semantic representation such as entities and relations, which could be analyzed by machines. But large-scale practical systems for this purpose are rare. We present BeeSpace question/answering (BSQA) system that performs integrated text mining for insect biology, covering diverse aspects from molecular interactions of genes to insect behavior. BSQA recognizes a number of entities and relations in Medline documents about the model insect, Drosophila melanogaster. For any text query, BSQA exploits entity annotation of retrieved documents to identify important concepts in different categories. By utilizing the extracted relations, BSQA is also able to answer many biologically motivated questions, from simple ones such as, which anatomical part is a gene expressed in, to more complex ones involving multiple types of relations. BSQA is freely available at http://www.beespace.uiuc.edu/QuestionAnswer.	annotation;body part;categories;entity;extraction;interaction;medline;question (inquiry);question answering;rem sleep behavior disorder;text mining	Xin He;Yanen Li;Radhika S. Khetani;Barry Sanders;Yue Lu;Xu Ling;ChengXiang Zhai;Bruce R. Schatz	2010		10.1093/nar/gkq544	biology;text mining;the internet;regulation of gene expression;bioinformatics;co-occurrence networks;system integration	NLP	-2.4403241957104496	-63.68959108870901	93111
1452fc72fe72871c55a7324e10af5036ef9887fc	phewas and genetics define subphenotypes in drug response				Robert J. Carroll;Jeremy L. Warner;Anne E. Eyler;Charles Moore;Jayanth Doss;Katherine P. Liao;Robert M. Plenge;Joshua C. Denny	2014			drug;biology;pharmacology	ML	1.949816253807074	-63.931617563459056	93178
8e11b64af0bdd117a7ee50908f86122844353c84	 pgg.population: a database for understanding the genomic diversity and genetic ancestry of human populations		There are a growing number of studies focusing on delineating genetic variations that are associated with complex human traits and diseases due to recent advances in next-generation sequencing technologies. However, identifying and prioritizing disease-associated causal variants relies on understanding the distribution of genetic variations within and among populations. The PGG.Population database documents 7122 genomes representing 356 global populations from 107 countries and provides essential information for researchers to understand human genomic diversity and genetic ancestry. These data and information can facilitate the design of research studies and the interpretation of results of both evolutionary and medical studies involving human populations. The database is carefully maintained and constantly updated when new data are available. We included miscellaneous functions and a user-friendly graphical interface for visualization of genomic diversity, population relationships (genetic affinity), ancestral makeup, footprints of natural selection, and population history etc. Moreover, PGG.Population provides a useful feature for users to analyze data and visualize results in a dynamic style via online illustration. The long-term ambition of the PGG.Population, together with the joint efforts from other researchers who contribute their data to our database, is to create a comprehensive depository of geographic and ethnic variation of human genome, as well as a platform bringing influence on future practitioners of medicine and clinical investigators. PGG.Population is available at https://www.pggpopulation.org.		Chao Zhang;Yang Gao;J. Liu;Zhe Xue;Yan Lu;Lian Deng;Lei Tian;Qidi Feng;Shuhua Xu	2018		10.1093/nar/gkx1032		Visualization	3.2232428626074374	-56.517973258422636	93398
27627712c5b7900c92af8ef5a8683b9e1a06b591	an unbiased adaptive sampling algorithm for the exploration of rna mutational landscapes under evolutionary pressure	nucleotides;computational molecular biology;rna;molecular evolution;polynomial time;adaptive sampling;algorithms;protein folding;free energy	The analysis of the relationship between sequences and structures (i.e., how mutations affect structures and reciprocally how structures influence mutations) is essential to decipher the principles driving molecular evolution, to infer the origins of genetic diseases, and to develop bioengineering applications such as the design of artificial molecules. Because their structures can be predicted from the sequence data only, RNA molecules provide a good framework to study this sequence-structure relationship. We recently introduced a suite of algorithms called RNAmutants which allows a complete exploration of RNA sequence-structure maps in polynomial time and space. Formally, RNAmutants takes an input sequence (or seed) to compute the Boltzmann-weighted ensembles of mutants with exactly k mutations, and sample mutations from these ensembles. However, this approach suffers from major limitations. Indeed, since the Boltzmann probabilities of the mutations depend of the free energy of the structures, RNAmutants has difficulties to sample mutant sequences with low G+C-contents. In this article, we introduce an unbiased adaptive sampling algorithm that enables RNAmutants to sample regions of the mutational landscape poorly covered by classical algorithms. We applied these methods to sample mutations with low G+C-contents. These adaptive sampling techniques can be easily adapted to explore other regions of the sequence and structural landscapes which are difficult to sample. Importantly, these algorithms come at a minimal computational cost. We demonstrate the insights offered by these techniques on studies of complete RNA sequence structures maps of sizes up to 40 nucleotides. Our results indicate that the G+C-content has a strong influence on the size and shape of the evolutionary accessible sequence and structural spaces. In particular, we show that low G+C-contents favor the apparition of internal loops and thus possibly the synthesis of tertiary structure motifs. On the other hand, high G+C-contents significantly reduce the size of the evolutionary accessible mutational landscapes.	adaptive sampling;algorithmic efficiency;decipher prostate cancer test;evolution, molecular;hereditary diseases;inference;map;mental suffering;mutation;national origin;nucleotides;probability;rna;sampling (signal processing);sampling - surgical action;time complexity;algorithm;contents - htmllinktype;free energy;mutant;tertiary	Jérôme Waldispühl;Yann Ponty	2011	Journal of computational biology : a journal of computational molecular cell biology	10.1089/cmb.2011.0181	protein folding;time complexity;biology;nucleotide;rna;molecular evolution;bioinformatics;genetics;algorithm	Comp.	8.265343657980072	-58.805840888034346	93514
34ed30a15dbbb66f32a54df08d0002a88c9e37e4	detection of lineage-specific evolutionary changes among primate species	software;animals;positive selection;negative selection;phylogeny;computational biology bioinformatics;biological evolution;genome human;human genome;genome;primates;evolutionary changes;algorithms;humans;combinatorial libraries;computer appl in life sciences;article;microarrays;bioinformatics;rate of evolution	Comparison of the human genome with other primates offers the opportunity to detect evolutionary events that created the diverse phenotypes among the primate species. Because the primate genomes are highly similar to one another, methods developed for analysis of more divergent species do not always detect signs of evolutionary selection. We have developed a new method, called DivE, specifically designed to find regions that have evolved either more or less rapidly than expected, for any clade within a set of very closely related species. Unlike some previous methods, DivE does not rely on rates of synonymous and nonsynonymous substitution, which enables it to detect evolutionary events in noncoding regions. We demonstrate using simulated data that DivE compares favorably to alternative methods, and we then apply DivE to the ENCODE regions in 14 primate species. We identify thousands of regions in these primates, ranging from 50 to >10000 bp in length, that appear to have experienced either constrained or accelerated rates of evolution. In particular, we detected 4942 regions that have potentially undergone positive selection in one or more primate species. Most of these regions occur outside of protein-coding genes, although we identified 20 proteins that have experienced positive selection. DivE provides an easy-to-use method to predict both positive and negative selection in noncoding DNA, that is particularly well-suited to detecting lineage-specific selection in large genomes.	clade;encode;genome;lineage (evolution);phenotype;primates;sensor;substitution matrix	Mihaela Pertea;Geo Pertea;Steven L Salzberg	2011		10.1186/1471-2105-12-274	biology;human genome;dna microarray;bioinformatics;genetics;negative selection;directional selection;phylogenetics;genome	Comp.	3.0957692198793234	-59.07738329194481	93518
56c4eab2b75df7a26937dca4f063bdd94dcc6516	iscreen: world's first cloud-computing web server for virtual screening and de novo drug design based on tcm database@taiwan	traditional chinese medicine (tcm);cloud-computing;docking;screening;de novo	The rapidly advancing researches on traditional Chinese medicine (TCM) have greatly intrigued pharmaceutical industries worldwide. To take initiative in the next generation of drug development, we constructed a cloud-computing system for TCM intelligent screening system (iScreen) based on TCM Database@Taiwan. iScreen is compacted web server for TCM docking and followed by customized de novo drug design. We further implemented a protein preparation tool that both extract protein of interest from a raw input file and estimate the size of ligand bind site. In addition, iScreen is designed in user-friendly graphic interface for users who have less experience with the command line systems. For customized docking, multiple docking services, including standard, in-water, pH environment, and flexible docking modes are implemented. Users can download first 200 TCM compounds of best docking results. For TCM de novo drug design, iScreen provides multiple molecular descriptors for a user's interest. iScreen is the world's first web server that employs world's largest TCM database for virtual screening and de novo drug design. We believe our web server can lead TCM research to a new era of drug development. The TCM docking and screening server is available at http://iScreen.cmu.edu.tw/.	acupuncture and oriental medicine;application program interface;boat dock;chinese herbal formulation lc09;cloud computing;command-line interface;computation (action);computer cooling;customize;de novo transcriptome assembly;docking (molecular);download;drug design;graphical user interface;molecular descriptor;pharmacy (field);server (computer);server (computing);staphylococcal protein a;toolkit for conceptual modeling;traditional chinese medicine;usability;virtual screening;web server;drug development	Tsung-Ying Tsai;Kai-Wei Chang;Calvin Yu-Chian Chen	2011	Journal of computer-aided molecular design	10.1007/s10822-011-9438-9	simulation;bioinformatics;world wide web	Comp.	-3.196546120708636	-59.35606756414867	93533
8c4d119a75e1ac3364f97cb7bb711fe401cf415e	hypoxiadb: a database of hypoxia-regulated proteins	chromosomes human;anoxia;sequence homology amino acid;humans;user computer interface;databases protein;gene ontology	There has been intense interest in the cellular response to hypoxia, and a large number of differentially expressed proteins have been identified through various high-throughput experiments. These valuable data are scattered, and there have been no systematic attempts to document the various proteins regulated by hypoxia. Compilation, curation and annotation of these data are important in deciphering their role in hypoxia and hypoxia-related disorders. Therefore, we have compiled HypoxiaDB, a database of hypoxia-regulated proteins. It is a comprehensive, manually-curated, non-redundant catalog of proteins whose expressions are shown experimentally to be altered at different levels and durations of hypoxia. The database currently contains 72 000 manually curated entries taken on 3500 proteins extracted from 73 peer-reviewed publications selected from PubMed. HypoxiaDB is distinctive from other generalized databases: (i) it compiles tissue-specific protein expression changes under different levels and duration of hypoxia. Also, it provides manually curated literature references to support the inclusion of the protein in the database and establish its association with hypoxia. (ii) For each protein, HypoxiaDB integrates data on gene ontology, KEGG (Kyoto Encyclopedia of Genes and Genomes) pathway, protein-protein interactions, protein family (Pfam), OMIM (Online Mendelian Inheritance in Man), PDB (Protein Data Bank) structures and homology to other sequenced genomes. (iii) It also provides pre-compiled information on hypoxia-proteins, which otherwise requires tedious computational analysis. This includes information like chromosomal location, identifiers like Entrez, HGNC, Unigene, Uniprot, Ensembl, Vega, GI numbers and Genbank accession numbers associated with the protein. These are further cross-linked to respective public databases augmenting HypoxiaDB to the external repositories. (iv) In addition, HypoxiaDB provides an online sequence-similarity search tool for users to compare their protein sequences with HypoxiaDB protein database. We hope that HypoxiaDB will enrich our knowledge about hypoxia-related biology and eventually will lead to the development of novel hypothesis and advancements in diagnostic and therapeutic activities. HypoxiaDB is freely accessible for academic and non-profit users via http://www.hypoxiadb.com.	accession number (bioinformatics);amino acid sequence;annotation;compiler;customize;data curation;databases, protein;digital curation;encyclopedias;ensembl;entrez;experiment;extraction;genbank;gene ontology;gene regulatory network;genome;hgnc;high-throughput computing;histocompatibility testing;homologous gene;homologous protein;homology (biology);identifier;interaction;kegg;knowledge bases;knowledge base;mode of inheritance;motif;muscle;nonprofit organizations;nucleotides;online mendelian inheritance in man;peptide sequence;pfam;protein data bank;protein domain;protein family;proteomics;pubmed;repository;search engine;sequence similarity;sequence alignment;similarity search;single nucleotide polymorphism;trametes versicolor fruiting body 0.05 g in 1 g oral pill [soma arthrit];throughput;transcript;transcription (software);unigene;uniprot;usability;anatomical layer;cellular response to hypoxia;vedolizumab	Pankaj Khurana;Ragumani Sugadev;Jaspreet Jain;Shashi Bala Singh	2013		10.1093/database/bat074	biology;bioinformatics;data mining;database;world wide web;genetics;information retrieval	Comp.	-0.6001560654296587	-60.5027598612782	93812
682ad484f3d55881b6769e5ff8261396ccd3cf00	an approach to comparative analysis of chromatographic fingerprints for assuring the quality of botanical drugs	comparative analysis	The present study was focused on developing the chemometric methods for analysis of the chromatographic fingerprint to control the quality of botanical drugs, which has gained attention in Asia and other countries. We developed a novel approach to generate a set of fingerprint features, called Fisher components (FCs) that were extracted from the chromatographic fingerprint. The method greatly reduces the dimensionality of the fingerprint vector, and the resulting FCs still retain most discriminatory information of the original fingerprint. Choosing an example of relevance to contemporary botanical drugs, we applied the FCs to a set of Shenmai injection samples. We successfully identified the manufacturers of the samples using two classifiers, linear discriminant analysis (LDA) and k-Nearest Neighbor (k-NN) based on the FCs. We also applied a similarity assessment together with the visual analysis using the FCs to exam the products from different manufacturers. We found that the lot-to-lot consistency of products can be accurately determined using the FCs. Finally, we demonstrated that the application of chemometric methods for chromatographic fingerprinting offers reliability to detect suspected fraud samples. In summary, we demonstrated that the presented approaches could be useful to determine the identity, consistency, and authenticity of Shenmai injection through chromatographic fingerprinting. The methods are equally applicable to other botanical drugs.	anterior descending branch of left coronary artery;botanical;chemometrics;dimensionality reduction;extraction;fingerprint (computing);k-nearest neighbors algorithm;linear discriminant analysis;radio fingerprinting;relevance;viral components;fructus schizandrae, radix ginseng, radix ophiopogonis drug combination	Yiyu Cheng;Minjun Chen;Weida Tong	2003	Journal of chemical information and computer sciences	10.1021/ci034034c	qualitative comparative analysis;chemistry;computer science;analytical chemistry;data mining	Comp.	8.475913215288507	-53.90893116105245	93903
22ba0af5a1e36c45f141a25a141c850db933f76b	ancestral sequence alignment under optimal conditions	evolution molecular;data interpretation statistical;phylogeny;maximum likelihood;simulated evolution;computational biology bioinformatics;models molecular;phylogenetic tree;likelihood functions;algorithms;sequence alignment;combinatorial libraries;computer appl in life sciences;optimality condition;multiple alignment;microarrays;bioinformatics	Multiple genome alignment is an important problem in bioinformatics. An important subproblem used by many multiple alignment approaches is that of aligning two multiple alignments. Many popular alignment algorithms for DNA use the sum-of-pairs heuristic, where the score of a multiple alignment is the sum of its induced pairwise alignment scores. However, the biological meaning of the sum-of-pairs of pairs heuristic is not obvious. Additionally, many algorithms based on the sum-of-pairs heuristic are complicated and slow, compared to pairwise alignment algorithms. An alternative approach to aligning alignments is to first infer ancestral sequences for each alignment, and then align the two ancestral sequences. In addition to being fast, this method has a clear biological basis that takes into account the evolution implied by an underlying phylogenetic tree. In this study we explore the accuracy of aligning alignments by ancestral sequence alignment. We examine the use of both maximum likelihood and parsimony to infer ancestral sequences. Additionally, we investigate the effect on accuracy of allowing ambiguity in our ancestral sequences. We use synthetic sequence data that we generate by simulating evolution on a phylogenetic tree. We use two different types of phylogenetic trees: trees with a period of rapid growth followed by a period of slow growth, and trees with a period of slow growth followed by a period of rapid growth. We examine the alignment accuracy of four ancestral sequence reconstruction and alignment methods: parsimony, maximum likelihood, ambiguous parsimony, and ambiguous maximum likelihood. Additionally, we compare against the alignment accuracy of two sum-of-pairs algorithms: ClustalW and the heuristic of Ma, Zhang, and Wang. We find that allowing ambiguity in ancestral sequences does not lead to better multiple alignments. Regardless of whether we use parsimony or maximum likelihood, the success of aligning ancestral sequences containing ambiguity is very sensitive to the choice of gap open cost. Surprisingly, we find that using maximum likelihood to infer ancestral sequences results in less accurate alignments than when using parsimony to infer ancestral sequences. Finally, we find that the sum-of-pairs methods produce better alignments than all of the ancestral alignment methods.	algorithm;align (company);ancestral reconstruction;bioinformatics;clustalw/clustalx;heuristic;inference;maximum parsimony (phylogenetics);multiple sequence alignment;occam's razor;phylogenetic tree;phylogenetics;simulation;synthetic intelligence;trees (plant)	Alexander K. Hudek;Daniel G. Brown	2005	BMC Bioinformatics	10.1186/1471-2105-6-273	biology;phylogenetic tree;dna microarray;multiple sequence alignment;bioinformatics;theoretical computer science;machine learning;sequence alignment;maximum likelihood;alignment-free sequence analysis;phylogenetics	Comp.	1.2869531918711372	-52.642998948623216	93905
3203b39f681368805bf8e1ac198d2c4c1060adce	an error correction algorithm for ngs data		The Oxford Nanopore and Pacbio SMRT sequencing technologies has revolutionized the Next-Generation Sequencing (NGS) environment by producing long reads that exceed 60 kbp and helped to the completion of many biological projects. But, long reads are characterized by a high error rate which increases the difficulty of biological problems like the genome assembly problem. Error correction of long reads has become a challenge for bioinformaticians, which motivates the development of new approaches for error correction adapted to NGS technologies. In this paper, we present a new denovo self-error correction algorithm using only long reads. Our algorithm operates in two steps: First, we use a fast hashing method which allows to find alignments between the longest reads and other reads in a set of long reads. Next, we use the longest reads as seeds to obtain the final alignment of long reads by using a dynamic programming algorithm in a band of width w. Our error correction algorithm does not require high quality reads, in contrast to existing hybrid error correction ones.	algorithm;communications satellite;display resolution;dynamic programming;error detection and correction;whole genome sequencing	Mehdi Kchouk;Jean-François Gibrat;Mourad Elloumi	2017	2017 28th International Workshop on Database and Expert Systems Applications (DEXA)	10.1109/DEXA.2017.33	error detection and correction;computer science;word error rate;data mining;genomics;nanopore sequencing;algorithm;sequence assembly;dynamic programming;hash function;single molecule real time sequencing;bioinformatics	Comp.	-0.9296044643789254	-53.57756314534664	93911
dc2ffe104c67f3c05b20a66d0001362028c62eac	the ogcleaner: filtering false-positive homology clusters		Detecting homologous sequences in organisms is an essential step in protein structure and function prediction, gene annotation and phylogenetic tree construction. Heuristic methods are often employed for quality control of putative homology clusters. These heuristics, however, usually only apply to pairwise sequence comparison and do not examine clusters as a whole. We present the Orthology Group Cleaner (the OGCleaner), a tool designed for filtering putative orthology groups as homology or non-homology clusters by considering all sequences in a cluster. The OGCleaner relies on high-quality orthologous groups identified in OrthoDB to train machine learning algorithms that are able to distinguish between true-positive and false-positive homology groups. This package aims to improve the quality of phylogenetic tree construction especially in instances of lower-quality transcriptome assemblies.   AVAILABILITY AND IMPLEMENTATION https://github.com/byucsl/ogcleaner CONTACT: sfujimoto@gmail.comSupplementary information: Supplementary data are available at Bioinformatics online.		M. Stanley Fujimoto;Anton Suvorov;Nicholas O. Jensen;Mark J. Clement;Quinn Snell;Seth M. Bybee	2017	Bioinformatics	10.1093/bioinformatics/btw571	computer science;cluster (physics);filter (signal processing);bioinformatics;homology (biology)	Comp.	0.34751205771700516	-56.09137604710175	94002
543dc2be7a90a51462988c4d22086e6ea383b400	enhanced methods to detect haplotypic effects on gene expression		Motivation Expression quantitative trait loci (eQTLs), genetic variants associated with gene expression levels, are identified in eQTL mapping studies. Such studies typically test for an association between single nucleotide polymorphisms (SNPs) and expression under an additive model, which ignores interaction and haplotypic effects. Mismatches between the model tested and the underlying genetic architecture can lead to a loss of association power. Here we introduce a new haplotype-based test for eQTL studies that looks for haplotypic effects on expression levels. Our test is motivated by compound heterozygous architectures, a common disease model for recessive monogenic disorders, where two different alleles can have the same effect on a gene's function.   Results When the underlying true causal architecture for a simulated gene is a compound heterozygote, our method is better able to capture the signal than the marginal SNP method. When the underlying model is a single SNP, there is no difference in the power of our method relative to the marginal SNP method. We apply our method to empirical gene expression data measured in 373 European individuals from the GEUVADIS study and find 29 more eGenes (genes with at least one association) than the standard marginal SNP method. Furthermore, in 974 of the 3529 total eGenes, our haplotype-based method results in a stronger association signal than the standard marginal SNP method. This demonstrates our method both increases power over the standard method and provides evidence of haplotypic architectures regulating gene expression.   Availability and Implementation http://bogdan.bioinformatics.ucla.edu/software/.   Contact rob.brown@ucla.edu or pasaniuc@ucla.edu.	additive model;alleles;architecture as topic;causal filter;expression quantitative trait locus;gene expression;haplotypes;heterozygote;horner's method;marginal model;nitroprusside;quantitative trait loci;single nucleotide polymorphism;nervous system disorder	Robert Brown;Gleb Kichaev;Nicholas Mancuso;James Boocock;Bogdan Pasaniuc	2017	Bioinformatics	10.1093/bioinformatics/btx142	computer science;gene expression;bioinformatics	Comp.	5.833670926655442	-53.900535839639	94012
cd45253773b0a5976cc6844b729f4ff70d62276a	precis: protein reports engineered from concise information in swiss-prot		MOTIVATION There have been several endeavours to address the problem of annotating sequence data computationally, but the task is non-trivial and few tools have emerged that gather useful information on a given sequence, or set of sequences, in a simple and convenient manner. As more genome projects bear fruit, the mass of uncharacterized sequence data accumulating in public repositories grows ever larger. There is thus a pressing need for tools to support the process of automatic analysis and annotation of newly determined sequences. With this in mind, we have developed PRECIS, which automatically creates protein reports from sets of SWISS-PROT entries, collating results into structured reports, detailing known biological and medical information, literature and database cross-references, and relevant keywords.	am broadcasting;annotation;blast;cheese swiss ab.igg:acnc:pt:ser:qn;clinical trial protocol document;cross-reference;database;dual;emoticon;human-readable medium;large;machine-readable medium;precis;protein family;repository;swiss-model;switzerland;usability	Alex L. Mitchell;Jacqueline Renée Reich;Terri K. Attwood	2003	Bioinformatics	10.1093/bioinformatics/btg204	computer science;bioinformatics;data science;data mining	Comp.	-3.4421497656238484	-61.82233509894742	94220
0d64da588e00f2d963c1784279f24afe5dffc703	acdc – automated contamination detection and confidence estimation for single-cell genome data	single cell sequencing;computational biology bioinformatics;machine learning;binning;clustering;algorithms;quality control;computer appl in life sciences;microarrays;bioinformatics;contamination detection	A major obstacle in single-cell sequencing is sample contamination with foreign DNA. To guarantee clean genome assemblies and to prevent the introduction of contamination into public databases, considerable quality control efforts are put into post-sequencing analysis. Contamination screening generally relies on reference-based methods such as database alignment or marker gene search, which limits the set of detectable contaminants to organisms with closely related reference species. As genomic coverage in the tree of life is highly fragmented, there is an urgent need for a reference-free methodology for contaminant identification in sequence data. We present acdc, a tool specifically developed to aid the quality control process of genomic sequence data. By combining supervised and unsupervised methods, it reliably detects both known and de novo contaminants. First, 16S rRNA gene prediction and the inclusion of ultrafast exact alignment techniques allow sequence classification using existing knowledge from databases. Second, reference-free inspection is enabled by the use of state-of-the-art machine learning techniques that include fast, non-linear dimensionality reduction of oligonucleotide signatures and subsequent clustering algorithms that automatically estimate the number of clusters. The latter also enables the removal of any contaminant, yielding a clean sample. Furthermore, given the data complexity and the ill-posedness of clustering, acdc employs bootstrapping techniques to provide statistically profound confidence values. Tested on a large number of samples from diverse sequencing projects, our software is able to quickly and accurately identify contamination. Results are displayed in an interactive user interface. Acdc can be run from the web as well as a dedicated command line application, which allows easy integration into large sequencing project analysis workflows. Acdc can reliably detect contamination in single-cell genome data. In addition to database-driven detection, it complements existing tools by its unsupervised techniques, which allow for the detection of de novo contaminants. Our contribution has the potential to drastically reduce the amount of resources put into these processes, particularly in the context of limited availability of reference species. As single-cell genome data continues to grow rapidly, acdc adds to the toolkit of crucial quality assurance tools.	adipoq gene;algorithm;alignment;biopolymer sequencing;calcification of joints and arteries;clean;cluster analysis;command-line interface;complement system proteins;contaminant;databases;de novo transcriptome assembly;gene prediction;limited availability;machine learning;nonlinear dimensionality reduction;nonlinear system;organism;published database;specimen source codes - quality control;supervised learning;type signature;unsupervised learning;user interface device component;virtual screening;well-posed problem;statistical cluster	Markus Lux;Jan Krüger;Christian Rinke;Irena Maus;Andreas Schlüter;Tanja Woyke;Alexander Sczyrba;Barbara Hammer	2016		10.1186/s12859-016-1397-7	quality control;dna microarray;computer science;bioinformatics;data science;single cell sequencing;data mining;cluster analysis	Comp.	0.3421413303796164	-56.099667596295525	94241
326633292741951ee42ab19dd977bb7ea73ddfb5	estimating genealogies from linked marker data: a bayesian approach	quantitative trait loci;female;genetics population;data interpretation statistical;alleles;bayesian approach;probabilistic method;male;bayes theorem;chromosome mapping;gene mapping;genetics;computational biology bioinformatics;models genetic;genetic linkage;sampling technique;gene frequency;markov chain monte carlo;computational complexity;monte carlo method;state space;population structure;founder effect;algorithms;gene flow;identity by descent;a;humans;combinatorial libraries;pedigree;computer appl in life sciences;linkage disequilibrium;genetic markers;haplotypes;markov chains;bayesian model;microarrays;bioinformatics	Answers to several fundamental questions in statistical genetics would ideally require knowledge of the ancestral pedigree and of the gene flow therein. A few examples of such questions are haplotype estimation, relatedness and relationship estimation, gene mapping by combining pedigree and linkage disequilibrium information, and estimation of population structure. We present a probabilistic method for genealogy reconstruction. Starting with a group of genotyped individuals from some population isolate, we explore the state space of their possible ancestral histories under our Bayesian model by using Markov chain Monte Carlo (MCMC) sampling techniques. The main contribution of our work is the development of sampling algorithms in the resulting vast state space with highly dependent variables. The main drawback is the computational complexity that limits the time horizon within which explicit reconstructions can be carried out in practice. The estimates for IBD (identity-by-descent) and haplotype distributions are tested in several settings using simulated data. The results appear to be promising for a further development of the method.	algorithm;bayesian network;chromosome mapping;computational complexity theory;estimated;gene flow;haplotypes;ion beam deposition;irritable bowel syndrome;linkage (software);linkage disequilibrium;markov chain monte carlo;monte carlo method;sampling (signal processing);state space;genetic pedigree	Dario Gasbarra;Matti Pirinen;Mikko J. Sillanpää;Elja Arjas	2007	BMC Bioinformatics	10.1186/1471-2105-8-411	allele;linkage disequilibrium;biology;sampling;markov chain;gene flow;gene mapping;dna microarray;markov chain monte carlo;haplotype;genetic linkage;identity by descent;bayesian probability;bioinformatics;state space;probabilistic method;allele frequency;genetic marker;founder effect;bayes' theorem;computational complexity theory;bayesian inference;genetics;quantitative trait locus;monte carlo method	Comp.	2.6701684760464244	-52.3548527764868	94599
31d252bb4078f6b7e5b28daca96d8f0370f90a7b	relation between sequence and structure in membrane proteins	info eu repo semantics article	MOTIVATION Integral polytopic membrane proteins contain only two types of folds in their transmembrane domains: α-helix bundles and β-barrels. The increasing number of available crystal structures of these proteins permits an initial estimation of how sequence variability affects the structure conservation in their transmembrane domains. We, thus, aim to determine the pairwise sequence identity necessary to maintain the transmembrane molecular architectures compatible with the hydrophobic nature of the lipid bilayer.   RESULTS Root-mean-square deviation (rmsd) and sequence identity were calculated from the structural alignments of pairs of homologous polytopic membrane proteins sharing the same fold. Analysis of these data reveals that transmembrane segment pairs with sequence identity in the so-called 'twilight zone' (20-35%) display high-structural similarity (rmsd < 1.5 Å). Moreover, a large group of β-barrel pairs with low-sequence identity (<20%) still maintain a close structural similarity (rmsd < 2.5 Å). Thus, we conclude that fold preservation in transmembrane regions requires less sequence conservation than for globular proteins. These findings have direct implications in homology modeling of evolutionary-related membrane proteins.   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	architecture as topic;bioinformatics;bioinformatics;biologic preservation;conserved sequence;crystal structure;homology modeling;license;lipid metabolism disorders;membrane proteins;plant roots;sequence alignment;spatial variability;structural similarity	Mireia Olivella;Ángel González;Leonardo Pardo;Xavier Deupí	2013	Bioinformatics	10.1093/bioinformatics/btt249	biology;transmembrane domain;bioinformatics	Comp.	7.42965371906103	-61.48725588948002	94607
153ef06512a5bcc2863fb7cdc6dedb388334a8e5	simultaneous identification of robust synergistic subnetwork markers for effective cancer prognosis	signal image and speech processing;systems biology;computational biology bioinformatics;biomedical engineering	BACKGROUND Accurate prediction of cancer prognosis based on gene expression data is generally difficult, and identifying robust prognostic markers for cancer remains a challenging problem. Recent studies have shown that modular markers, such as pathway markers and subnetwork markers, can provide better snapshots of the underlying biological mechanisms by incorporating additional biological information, thereby leading to more accurate cancer classification.   RESULTS In this paper, we propose a novel method for simultaneously identifying robust synergistic subnetwork markers that can accurately predict cancer prognosis. The proposed method utilizes an efficient message-passing algorithm called affinity propagation, based on which we identify groups - or subnetworks - of discriminative and synergistic genes, whose protein products are closely located in the protein-protein interaction (PPI) network. Unlike other existing subnetwork marker identification methods, our proposed method can simultaneously identify multiple nonoverlapping subnetwork markers that can synergistically predict cancer prognosis.   CONCLUSIONS Evaluation results based on multiple breast cancer datasets demonstrate that the proposed message-passing approach can identify robust subnetwork markers in the human PPI network, which have higher discriminative power and better reproducibility compared to those identified by previous methods. The identified subnetwork makers can lead to better cancer classifiers with improved overall performance and consistency across independent cancer datasets.	affinity propagation;algorithm;cancer prognosis;forecast of outcome;gene expression;gene regulatory network;mammary neoplasms;message passing;non-small cell lung carcinoma;pixel density;processor affinity;prognostic variable;proton pump inhibitors;software propagation;subnetwork;synergy;cancer classification;protein protein interaction	Navadon Khunlertgit;Byung-Jun Yoon	2014		10.1186/s13637-014-0019-9	biology;computer science;bioinformatics;machine learning;data mining;biological engineering;systems biology	Comp.	7.030241388755394	-54.07455278800166	94659
70ef01514df8c289a099ebb53ce975466b28edb1	efficient removal of pcr inhibitors using agarose-embedded dna preparations	dna;inorganic compounds;humic substances;sepharose;polysaccharides;polymerase chain reaction;humic acid;genomic dna	The use of agarose blocks containing embedded DNA improves the PCR amplification from templates naturally contaminated with polysaccharides or humic acids, two powerful PCR inhibitors. Presumably, the difference in size between the DNA macromolecules and these contaminants allows their effective removal from the agarose blocks by diffusion during the washing steps, whereas genomic DNA remains trapped within them. In addition, agarose-embedded DNA can be directly used for PCR since low melting point agarose does not interfere with the reaction. This simple and inexpensive method is also convenient for genomic DNAs extracted by other procedures, and it is potentially useful for samples containing other kinds of soluble inhibitors, overcoming this important problem of current amplification techniques.	clinical use template;dna-directed dna polymerase;embedded system;embedding;extraction;humic acids;polysaccharides	David Moreira	1998	Nucleic acids research	10.1093/nar/26.13.3309	biology;biochemistry;molecular biology;primer dimer;polymerase chain reaction;genomic dna;polysaccharide;genetics;dna	Graphics	5.334176623460923	-64.30037124001996	95031
3e5b7b4f40941c6c46d8ede9c01e0bb4470386d5	machine learning assisted design of highly active peptides for drug discovery	peptides;drug discovery;amino acid sequence;bacterial physiological phenomena;antimicrobial cationic peptides;structure activity relationship;machine learning;pattern recognition automated;molecular sequence data;protein interaction mapping;sequence analysis protein	The discovery of peptides possessing high biological activity is very challenging due to the enormous diversity for which only a minority have the desired properties. To lower cost and reduce the time to obtain promising peptides, machine learning approaches can greatly assist in the process and even partly replace expensive laboratory experiments by learning a predictor with existing data or with a smaller amount of data generation. Unfortunately, once the model is learned, selecting peptides having the greatest predicted bioactivity often requires a prohibitive amount of computational time. For this combinatorial problem, heuristics and stochastic optimization methods are not guaranteed to find adequate solutions. We focused on recent advances in kernel methods and machine learning to learn a predictive model with proven success. For this type of model, we propose an efficient algorithm based on graph theory, that is guaranteed to find the peptides for which the model predicts maximal bioactivity. We also present a second algorithm capable of sorting the peptides of maximal bioactivity. Extensive analyses demonstrate how these algorithms can be part of an iterative combinatorial chemistry procedure to speed up the discovery and the validation of peptide leads. Moreover, the proposed approach does not require the use of known ligands for the target protein since it can leverage recent multi-target machine learning predictors where ligands for similar targets can serve as initial training data. Finally, we validated the proposed approach in vitro with the discovery of new cationic antimicrobial peptides. Source code freely available at http://graal.ift.ulaval.ca/peptide-design/.	academia (organization);adverse reaction to drug;algorithm;chemical procedure;combinatorial chemistry;computation;cyclic gmp;dna binding site;dosage forms;drug discovery;entity;experiment;graph - visual representation;graph theory;heuristics;hit (internet);immune complex;iteration;kernel method;kerrison predictor;libraries;library (computing);ligands;machine learning;mammals;mathematical optimization;maximal set;microsoft outlook for mac;numerous;portable document format;predictive modelling;roland gs;sample variance;small;solutions;sorting;source code;stochastic optimization;thrombocytopenia;time complexity	Sébastien Giguère;François Laviolette;Mario Marchand;Denise Tremblay;Sylvain Moineau;Xinxia Liang;Éric Biron;Jacques Corbeil	2015		10.1371/journal.pcbi.1004074	biology;structure–activity relationship;bioinformatics;machine learning;peptide sequence;drug discovery	ML	8.942768375666612	-53.751774080463036	95118
021aaaa3578059c336d5d33a414dc73a925bb863	computational analyses of curcuminoid analogs against kinase domain of her2	female;curcumin;ligands;molecular dynamics simulation;computational biology bioinformatics;hydrophobic and hydrophilic interactions;drug design;protein structure tertiary;antineoplastic agents;algorithms;humans;protein kinase inhibitors;combinatorial libraries;molecular docking simulation;computer appl in life sciences;receptor erbb 2;microarrays;bioinformatics	Human epidermal growth factor receptor 2 (HER2) has an important role in cancer aggressiveness and poor prognosis. HER2 has been used as a drug target for cancers. In particular, to effectively treat HER2-positive cancer, small molecule inhibitors were developed to target HER2 kinase. Knowing that curcumin has been used as food to inhibit cancer activity, this study evaluated the efficacy of natural curcumins and curcumin analogs as HER2 inhibitors using in vitro and in silico studies. The curcumin analogs considered in this study composed of 4 groups classified by their core structure, β-diketone, monoketone, pyrazole, and isoxazole. In the present study, both computational and experimental studies were performed. The specificity of curcumin analogs selected from the docked results was examined against human breast cancer cell lines. The screened curcumin compounds were then subjected to molecular dynamics simulation study. By modifying curcumin analogs, we found that protein-ligand affinity increases. The benzene ring with a hydroxyl group could enhance affinity by forming hydrophobic interactions and the hydrogen bond with the hydrophobic pocket. Hydroxyl, carbonyl or methoxy group also formed hydrogen bonds with residues in the adenine pocket and sugar pocket of HER2-TK. These modifications could suggest the new drug design for potentially effective HER2-TK inhibitors. Two outstanding compounds, bisdemethylcurcumin (AS-KTC006) and 3,5-bis((E)-3,4-dimethoxystyryl)isoxazole (AS-KTC021 ),were well oriented in the binding pocket almost in the simulation time, 30 ns. This evidence confirmed the results of cell-based assays and the docking studies. They possessed more distinguished interactions than known HER2-TK inhibitors, considering them as a promising drug in the near future. The series of curcumin compounds were screened using a computational molecular docking and followed by human breast cancer cell lines assay. Both AS-KTC006 and AS-KTC021 could inhibit breast cancer cell lines though inhibiting of HER2-TK. The intermolecular interactions were confirmed by molecular dynamics simulation studies. This information would explore more understanding of curcuminoid structures and HER2-TK.	adenine;analog;boat dock;breast cancer cell;classification;computation;cultured cell line;curcumin;curcuminoid;docking (molecular);drug delivery systems;drug design;growth factor receptors;hydrogen bonding;hydroxyl radical;in vitro [publication type];inhibition;interaction;isoxazoles;leukemia, b-cell;ligands;mammary neoplasms;molecular dynamics;non-small cell lung carcinoma;personality disorders;processor affinity;projection screen;sensitivity and specificity;simulation;small molecule;sugars;pyrazole	Wannarat Yim-im;Orathai Sawatdichaikul;Suwanna Semsri;Natharinee Horata;Wanwimon Mokmak;Sissades Tongsima;Apichart Suksamrarn;Kiattawee Choowongkomon	2014		10.1186/1471-2105-15-261	pharmacology;biology;biochemistry;molecular dynamics;dna microarray;bioinformatics;ligand;drug design	Comp.	9.52212402880587	-61.50532950280346	95148
cd5df68ca5c2496d30a9d3c59b6fce3cd9bf3da1	a novel method for assigning functional linkages to proteins using enhanced phylogenetic trees	arbre phylogenetique;proteine;phylogeny;phylogenese;liaison genetique;methode;arbol filogenetico;genetic mapping;genetic linkage;phylogenetic tree;filogenesis;carte genetique;proteina;mapa genetico;protein;metodo;method;ligamiento genetico	MOTIVATION Functional linkages implicate pairwise relationships between proteins that work together to implement biological tasks. During evolution, functionally linked proteins are likely to be preserved or eliminated across a range of genomes in a correlated fashion. Based on this hypothesis, phylogenetic profiling-based approaches try to detect pairs of protein families that show similar evolutionary patterns. Traditionally, the evolutionary pattern of a protein is encoded by either a binary profile of presence and absence of this protein across species or an occurrence profile that indicates the distribution of copies of this protein across species.   RESULTS In our study, we characterize each protein by its enhanced phylogenetic tree, a novel graphical model of the evolution of a protein family with explicitly marked by speciation and duplication events. By topological comparison between enhanced phylogenetic trees, we are able to detect the functionally associated protein pairs. Because the enhanced phylogenetic trees contain more evolutionary information of proteins, our method shows greater performance and discovers functional linkages among proteins more reliably compared with the conventional approaches.	biologic preservation;copy (object);gene duplication abnormality;genome;graphical model;phylogenetic profiling;phylogenetic tree;phylogenetics;protein family;trees (plant)	Hung Xuan Ta;Patrik Koskinen;Liisa Holm	2011	Bioinformatics	10.1093/bioinformatics/btq705	biology;method;phylogenetic tree;gene mapping;genetic linkage;bioinformatics;phylogenetic network;genetics;phylogenetics	Comp.	3.6186085112128117	-59.626171534810524	95156
2122640d3103612c3d95e2f55634b2391fe6bf9f	conpath: scaffold analysis tool using mate-pair information for genome sequencing	dna;separate sequence contig ordering;v vulinificus;tissue engineering biology computing cellular biophysics dna microorganisms molecular biophysics;separate sequence contig orienting;biology computing;contig algorithm;conpath;fixed sized mate pair library;relative orientation;printing complex scaffold structures conpath scaffold analysis tool mate pair information genome sequencing windows based program separate sequence contig orienting separate sequence contig ordering contig algorithm end read pairs fixed sized mate pair library microbial genome projects m succiniciproducens v vulinificus edge information list;scaffold analysis tool;genome sequencing;windows based program;printing complex scaffold structures;information analysis genomics bioinformatics assembly libraries dna sequences visualization joining processes information technology;directed graph;microbial genome projects;molecular biophysics;m succiniciproducens;edge information list;end read pairs;microorganisms;cellular biophysics;mate pair information;genome sequence;tissue engineering	We have developed a Windows-based program, ConPath, as a scaffold analyzer which constructs scaffolds by ordering and orienting separate sequence contigs by exploiting the mate-pair information between contig-pairs. Our algorithm builds directed graphs from link information and traverses them to find out the longest acyclic graphs. Using end-read pairs of fixed-sized mate-pair library, ConPath determines relative orientations of all contigs, estimates the gap size of each adjacent contig pairs, and reports wrong assembly information by validating orientations and gap sizes. We have utilized ConPath in more than 10 microbial genome projects, including M. succiniciproducens [12] and V.vulinificus, where we have verified contig assembly by finding out some erroneous contigs with four kinds of error types defined in ConPath. It also supports some convenient features and viewers to investigate each contig in detail, like contig viewer, scaffold viewer, edge information list, mate-pair list, printing complex scaffolds structures, and so on.	algorithm;directed acyclic graph;directed graph;microsoft windows;printing	Pan-Gyu Kim;Hwan-Gue Cho;Kiejung Park	2007	2007 Frontiers in the Convergence of Bioscience and Information Technologies	10.1109/FBIT.2007.119	biology;bioinformatics;genetics	Comp.	-1.1528473887638828	-55.50683168190083	95367
f8635d3e9255de925f2733081587169e597934a8	building a biomedical semantic network in wikipedia with semantic wiki links	molecular sequence annotation;semantics;databases genetic;internet;humans;biomedical research	Wikipedia is increasingly used as a platform for collaborative data curation, but its current technical implementation has significant limitations that hinder its use in biocuration applications. Specifically, while editors can easily link between two articles in Wikipedia to indicate a relationship, there is no way to indicate the nature of that relationship in a way that is computationally accessible to the system or to external developers. For example, in addition to noting a relationship between a gene and a disease, it would be useful to differentiate the cases where genetic mutation or altered expression causes the disease. Here, we introduce a straightforward method that allows Wikipedia editors to embed computable semantic relations directly in the context of current Wikipedia articles. In addition, we demonstrate two novel applications enabled by the presence of these new relationships. The first is a dynamically generated information box that can be rendered on all semantically enhanced Wikipedia articles. The second is a prototype gene annotation system that draws its content from the gene-centric articles on Wikipedia and exposes the new semantic relationships to enable previously impossible, user-defined queries. DATABASE URL: http://en.wikipedia.org/wiki/Portal:Gene_Wiki.	access network;biocurator;computable function;crowdfunding;data curation;database;digital curation;ecosystem;embedding;gene annotation;interface device component;prototype;rendering (computer graphics);semantic web;semantic network;uniform resource locator;wiki;wikipedia	Benjamin M. Good;Erik L. Clarke;Salvatore Loguercio;Andrew I. Su	2012		10.1093/database/bar060	the internet;computer science;bioinformatics;data mining;database;semantics;world wide web;information retrieval	Web+IR	-2.30163477961741	-62.13511632524382	95412
447e856275d65c66c28ee3e44d75e59c7a346ef2	the use of computer based structure-activity relationships in the risk assessment of industrial chemicals	structure activity relationship;risk assessment	The concept of a two-step approach toward the assessment of toxicity endpoints for a chemical is proposed. The first step involves the selection of chemical analogues for which toxicity data is available in a noncongeneric database. The next step is the derivation of a Quantitative Structure-Activity Relationship (QSAR) for the chemical domain, predetermined by the selection rules. The software tools needed for the computer implementation of such an approach are summarized. By making use of them, we have derived aquatic toxicity QSARs, of which two are given as example. The latter pertain to chemicals that have been automatically extracted from noncongeneric databases, after defining the substructure recognition rules implied by the putative mechanism of toxicity.	adverse reaction to drug;aquatic ecosystem;database;extraction;quantitative structure-activity relationship;risk assessment;rule (guideline);selection rule	Walter Karcher;Stoyan Karabunarliev	1996	Journal of chemical information and computer sciences	10.1021/ci9501305	risk assessment;structure–activity relationship;chemistry	DB	7.699406664705587	-57.584128038722405	95433
9656fe936a7136519f50199c0c7d66e475ff1fa8	genprobis: web server for mapping of sequence variants to protein binding sites		Discovery of potentially deleterious sequence variants is important and has wide implications for research and generation of new hypotheses in human and veterinary medicine, and drug discovery. The GenProBiS web server maps sequence variants to protein structures from the Protein Data Bank (PDB), and further to protein-protein, protein-nucleic acid, protein-compound, and protein-metal ion binding sites. The concept of a protein-compound binding site is understood in the broadest sense, which includes glycosylation and other post-translational modification sites. Binding sites were defined by local structural comparisons of whole protein structures using the Protein Binding Sites (ProBiS) algorithm and transposition of ligands from the similar binding sites found to the query protein using the ProBiS-ligands approach with new improvements introduced in GenProBiS. Binding site surfaces were generated as three-dimensional grids encompassing the space occupied by predicted ligands. The server allows intuitive visual exploration of comprehensively mapped variants, such as human somatic mis-sense mutations related to cancer and non-synonymous single nucleotide polymorphisms from 21 species, within the predicted binding sites regions for about 80 000 PDB protein structures using fast WebGL graphics. The GenProBiS web server is open and free to all users at http://genprobis.insilab.org.	access network;binding sites;cell nucleus;computation;cooperative breeding;dna binding site;diploid cell;drug discovery;eighty;experiment;genetic polymorphism;genetic translation process;graphics;imagery;ions;ligands;metal ion binding;mutation;name binding;nucleic acids;nucleotides;personalization;phosphor;plant physiological phenomena;post-translational protein processing;precision medicine;probis;protein binding;protein data bank;question (inquiry);server (computer);server (computing);single-chain antibodies;staphylococcal protein a;veterinary medicine (discipline);web server;webgl;algorithm;protein folding	Janez Konc;Blaz Skrlj;Nika Erzen;Tanja Kunej;Dusanka Janezic	2017		10.1093/nar/gkx420	bioinformatics	Comp.	1.4690878065291524	-61.43878877827535	95460
b3a12df31f90e41e517c42fc831ad9f8f08465f6	flavordb: a database of flavor molecules		Flavor is an expression of olfactory and gustatory sensations experienced through a multitude of chemical processes triggered by molecules. Beyond their key role in defining taste and smell, flavor molecules also regulate metabolic processes with consequences to health. Such molecules present in natural sources have been an integral part of human history with limited success in attempts to create synthetic alternatives. Given their utility in various spheres of life such as food and fragrances, it is valuable to have a repository of flavor molecules, their natural sources, physicochemical properties, and sensory responses. FlavorDB (http://cosylab.iiitd.edu.in/flavordb) comprises of 25,595 flavor molecules representing an array of tastes and odors. Among these 2254 molecules are associated with 936 natural ingredients belonging to 34 categories. The dynamic, user-friendly interface of the resource facilitates exploration of flavor molecules for divergent applications: finding molecules matching a desired flavor or structure; exploring molecules of an ingredient; discovering novel food pairings; finding the molecular essence of food ingredients; associating chemical features with a flavor and more. Data-driven studies based on FlavorDB can pave the way for an improved understanding of flavor mechanisms.	alpha compositing;aroma <invertebrate>;behavior;categories;compiler;computation;computational biology;cytology;entity;esthesia;flavoring;floor and ceiling functions;metabolism;microsoft outlook for mac;nar 2;natural language processing;odors;perfume;synthetic intelligence;taste perception;usability	Neelansh Garg;Apuroop Sethupathy;Rudraksh Tuwani;NK Rakhi;Shubham Dokania;Arvind Iyer;Ayushi Gupta;Shubhra Agrawal;Navjot Singh;Shubham Shukla;Kriti Kathuria;Rahul Badhwar;Rakesh Kanji;Anupam Jain;Avneet Kaur;Rashmi Nagpal;Ganesh Bagler	2018		10.1093/nar/gkx957	flavor;genetics;medicinal chemistry;molecule;biology	ML	0.2882006775961236	-62.025482219460386	95472
9ae337004ea8ad993ec82c07a87dd3ac9bf701be	using genomic signatures for hiv-1 sub-typing	hiv;laboratory procedures;complete genome;laboratory examinations and diagnoses;genome viral;nucleotides;technology;hiv infections;human immunodeficiency virus;medical procedures;hiv 1;genetic diversity;genetic variation;computational biology bioinformatics;hiv testing;delivery of health care;research and development;research methodology;word length;chaos game representation;viral diseases;diseases;algorithms;medicine;research report;health;health services;europe;combinatorial libraries;dna sequence;computer appl in life sciences;acquired immune deficiency syndrome;africa;examinations and diagnoses;qh301 biology;area analysis;phylogenetic analysis;developing countries;microarrays;bioinformatics;economic factors	Human Immunodeficiency Virus type 1 (HIV-1), the causative agent of Acquired Immune Deficiency Syndrome (AIDS), exhibits very high genetic diversity with different variants or subtypes prevalent in different parts of the world. Proper classification of the HIV-1 subtypes, displaying differential infectivity, plays a major role in monitoring the epidemic and is also a critical component for effective treatment strategy. The existing methods to classify HIV-1 sequence subtypes, based on phylogenetic analysis focusing only on specific genes/regions, have shown inconsistencies as they lack the capability to analyse whole genome variations. Several isolates are left unclassified due to unresolved sub-typing. It is apparent that classification of subtypes based on complete genome sequences, rather than sub-genomic regions, is a more robust and comprehensive approach to address genome-wide heterogeneity. However, no simple methodology exists that directly computes HIV-1 subtype from the complete genome sequence. We use Chaos Game Representation (CGR) as an approach to identify the distinctive genomic signature associated with the DNA sequence organisation in different HIV-1 subtypes. We first analysed the effect of nucleotide word lengths (k = 2 to 8) on whole genomes of the HIV-1 M group sequences, and found the optimum word length of k = 6, that could classify HIV-1 subtypes based on a Test sequence set. Using the optimised word length, we then showed accurate classification of the HIV-1 subtypes from both the Reference Set sequences and from all available sequences in the database. Finally, we applied the approach to cluster the five unclassified HIV-1 sequences from Africa and Europe, and predict their possible subtypes. We propose a genomic signature-based approach, using CGR with suitable word length optimisation, which can be applied to classify intra-species variations, and apply it to the complex problem of HIV-1 subtype classification. We demonstrate that CGR is a simple and computationally less intensive method that not only accurately segregates the HIV-1 subtype and sub-subtypes, but also aid in the classification of the unclassified sequences. We hope that it will be useful in subtype annotation of the newly sequenced HIV-1 genomes.	acquired immunodeficiency syndrome;angular defect;annotation;antivirus software;chaos game;deficiency of glucose-6-phosphate dehydrogenase;emoticon;exhibits as topic;genetic heterogeneity;genome;genomic signature;hiv infections;hiv-1;hereditary diseases;immunologic deficiency syndromes;mathematical optimization;nucleotides;phylogenetics;subtype (attribute)	Aridaman Pandit;Somdatta Sinha	2010		10.1186/1471-2105-11-S1-S26	biology;bioinformatics;virology;genetic variation;health;genetics;genetic diversity;technology	Comp.	3.501948697711127	-55.3488824594097	95583
41697011f79acc3902ba94593fc19099eab025f8	ion pathways in the na+/k+-atpase		Na+/K+-ATPase (NKA) is an essential cation pump protein responsible for the maintenance of the sodium and potassium gradients across the plasma membrane. Recently published high-resolution structures revealed amino acids forming the cation binding sites (CBS) in the transmembrane domain and variable position of the domains in the cytoplasmic headpiece. Here we report molecular dynamic simulations of the human NKA α1β1 isoform embedded into DOPC bilayer. We have analyzed the NKA conformational changes in the presence of Na+- or K+-cations in the CBS, for various combinations of the cytoplasmic ligands, and the two major enzyme conformations in the 100 ns runs (more than 2.5 μs of simulations in total). We identified two novel cytoplasmic pathways along the pairs of transmembrane helices TM3/TM7 or TM6/TM9 that allow hydration of the CBS or transport of cations from/to the bulk. These findings can provide a structural explanation for previous mutagenesis studies, where mutation of residues that are distal from the CBS resulted in the alteration of the enzyme affinity to the transported cations or change in the enzyme activity.	1,2-oleoylphosphatidylcholine;amino acids;binding sites;cations;embedded system;embedding;gradient;greater than;image resolution;ions;ligands;molecular dynamics;mutation;plasma active;plasma membrane;potassium;processor affinity;scientific publication;sex hormone-binding globulin;simulation;sodium;tac1 wt allele;the 100;transmembrane domain;enzyme activity	Petra Cechová;Karel Berka;Martin Kubala	2016	Journal of chemical information and modeling	10.1021/acs.jcim.6b00353	crystallography;biochemistry;stereochemistry;chemistry	Comp.	9.646249602389876	-62.228853299851856	95721
8a073d51f82ab770bf17c479d35c145d39496860	net-synthesis: a software for synthesis, inference and simplification of signal transduction networks	software;logiciel;signal transduction;bioinformatique;transduccion senal;reseau;red;signal transduction networks;activation induced cell death;large granular lymphocyte;inferencia;logicial;bioinformatica;combinatorial optimization;transduction signal;inference;network;bioinformatics	UNLABELLED We present a software for combined synthesis, inference and simplification of signal transduction networks. The main idea of our method lies in representing observed indirect causal relationships as network paths and using techniques from combinatorial optimization to find the sparsest graph consistent with all experimental observations. We illustrate the biological usability of our software by applying it to a previously published signal transduction network and by using it to synthesize and simplify a novel network corresponding to activation-induced cell death in large granular lymphocyte leukemia.   AVAILABILITY NET-SYNTHESIS is freely downloadable from http://www.cs.uic.edu/~dasgupta/network-synthesis/	causality;cell death;cessation of life;combinatorial optimization;experiment;ibm notes;inference;iteration;large granular lymphocyte;leukemia, large granular lymphocytic;level of detail;mathematical optimization;network synthesis filters;scientific publication;signal transduction;symbolic computation;transduction (machine learning);united states department of agriculture;usability;funding grant;leukemia	Sema Kachalo;Ranran Zhang;Eduardo D. Sontag;Réka Albert;Bhaskar DasGupta	2008	Bioinformatics	10.1093/bioinformatics/btm571	biology;combinatorial optimization;computer science;bioinformatics;artificial intelligence;signal transduction;statistics	Comp.	-3.165859631880661	-55.05152230116457	95751
0bb0b30643224a84089967732d2713f5be20cba0	the yeastract database: an upgraded information system for the analysis of gene and genomic transcription regulation in saccharomyces cerevisiae	dna;genes;software;transcriptional repression;transcriptional activation;information systems;saccharomyces cerevisiae;genome fungal;systems biology;yeasts;gene regulatory networks;saccharomyces cerevisiae proteins;databases genetic;transcription factors;datasets;binding sites;internet;regulon;gene expression regulation fungal;transcription factor;genome;dna fungal;regulatory elements transcriptional;candidate disease gene;transcriptional control	The YEASTRACT (http://www.yeastract.com) information system is a tool for the analysis and prediction of transcription regulatory associations in Saccharomyces cerevisiae. Last updated in June 2013, this database contains over 200,000 regulatory associations between transcription factors (TFs) and target genes, including 326 DNA binding sites for 113 TFs. All regulatory associations stored in YEASTRACT were revisited and new information was added on the experimental conditions in which those associations take place and on whether the TF is acting on its target genes as activator or repressor. Based on this information, new queries were developed allowing the selection of specific environmental conditions, experimental evidence or positive/negative regulatory effect. This release further offers tools to rank the TFs controlling a gene or genome-wide response by their relative importance, based on (i) the percentage of target genes in the data set; (ii) the enrichment of the TF regulon in the data set when compared with the genome; or (iii) the score computed using the TFRank system, which selects and prioritizes the relevant TFs by walking through the yeast regulatory network. We expect that with the new data and services made available, the system will continue to be instrumental for yeast biologists and systems biology researchers.	binding sites;dna binding site;gene ontology term enrichment;genes, vif;information system;mental association;occur (action);regulon;systems biology;transcription factor;transcription (software);transcription repressor/corepressor;transcriptional regulation;yeastract	Miguel C. Teixeira;Pedro T. Monteiro;Joana Fernandes Guerreiro;Joana P. Gonçalves;Nuno P. Mira;Sandra Costa dos Santos;Tânia Rodrigues Cabrito;Margarida Palma;Catarina Costa;Alexandre P. Francisco;Sara C. Madeira;Arlindo L. Oliveira;Ana T. Freitas;Isabel Sá-Correia	2014		10.1093/nar/gkt1015	biology;molecular biology;bioinformatics;genetics;systems biology;transcription factor	Comp.	0.10343559310823193	-60.23315318940005	95759
5bc5fffefaa44c00afb4f5e23846013a6198961e	dissecting the fission yeast regulatory network reveals phase-specific control elements of its cell cycle	budding yeast;schizosaccharomyces;simulation and modeling;regulatory network;saccharomyces cerevisiae;time course;systems biology;gene regulation;signal transduction;physiological cellular and medical topics;models biological;schizosaccharomyces pombe;journal article;cell cycle regulation;computational biology bioinformatics;fission yeast;large scale;cell division cycle;gene expression regulation fungal;transcription factor;post transcriptional regulation;algorithms;cell cycle;gene regulatory network;computer simulation;bioinformatics;cell cycle proteins;fungal proteins	Fission yeast Schizosaccharomyces pombe and budding yeast Saccharomyces cerevisiae are among the original model organisms in the study of the cell-division cycle. Unlike budding yeast, no large-scale regulatory network has been constructed for fission yeast. It has only been partially characterized. As a result, important regulatory cascades in budding yeast have no known or complete counterpart in fission yeast. By integrating genome-wide data from multiple time course cell cycle microarray experiments we reconstructed a gene regulatory network. Based on the network, we discovered in addition to previously known regulatory hubs in M phase, a new putative regulatory hub in the form of the HMG box transcription factor SPBC19G7.04. Further, we inferred periodic activities of several less known transcription factors over the course of the cell cycle, identified over 500 putative regulatory targets and detected many new phase-specific and conserved cis-regulatory motifs. In particular, we show that SPBC19G7.04 has highly significant periodic activity that peaks in early M phase, which is coordinated with the late G2 activity of the forkhead transcription factor fkh2. Finally, using an enhanced Bayesian algorithm to co-cluster the expression data, we obtained 31 clusters of co-regulated genes 1) which constitute regulatory modules from different phases of the cell cycle, 2) whose phase order is coherent across the 10 time course experiments, and 3) which lead to identification of phase-specific control elements at both the transcriptional and post-transcriptional levels in S. pombe. In particular, the ribosome biogenesis clusters expressed in G2 phase reveal new, highly conserved RNA motifs. Using a systems-level analysis of the phase-specific nature of the S. pombe cell cycle gene regulation, we have provided new testable evidence for post-transcriptional regulation in the G2 phase of the fission yeast cell cycle. Based on this comprehensive gene regulatory network, we demonstrated how one can generate and investigate plausible hypotheses on fission yeast cell cycle regulation which can potentially be explored experimentally.	cell cycle control;cell division phases;cellular phone;coherence (physics);conserved sequence;experiment;gene expression regulation;gene regulatory network;hmga1a protein;inference;microarray;mitosis;post-transcriptional regulation;rna;ribosomes;saccharomyces cerevisiae;saccharomycetales;schizosaccharomyces pombe;singlet fission;transcription factor;transcription (software);transcription, genetic;transcriptional regulation;usb hub;algorithm;ribosome biogenesis	Pierre R. Bushel;Nicholas A. Heard;Roee Gutman;Liwen Liu;Shyamal D. Peddada;Saumyadipta Pyne	2009	BMC Systems Biology	10.1186/1752-0509-3-93	computer simulation;biology;cell biology;bioinformatics;cell cycle;genetics;systems biology	Comp.	4.678890571015362	-59.54200904579027	95807
66bed5a97127b126f0239e9d9f837e5c1ae5541e	rethinking transcriptional activation in the arabidopsis circadian clock	dna transcription;genetic oscillators;simulation and modeling;circadian rhythms;transcriptional activation;bioinformatik och systembiologi;gene regulation;transcription factors;arabidopsis thaliana;circadian clocks;gene expression;circadian oscillators;models genetic;arabidopsis;arabidopsis proteins;computational biology	Circadian clocks are biological timekeepers that allow living cells to time their activity in anticipation of predictable daily changes in light and other environmental factors. The complexity of the circadian clock in higher plants makes it difficult to understand the role of individual genes or molecular interactions, and mathematical modelling has been useful in guiding clock research in model organisms such as Arabidopsis thaliana. We present a model of the circadian clock in Arabidopsis, based on a large corpus of published time course data. It appears from experimental evidence in the literature that most interactions in the clock are repressive. Hence, we remove all transcriptional activation found in previous models of this system, and instead extend the system by including two new components, the morning-expressed activator RVE8 and the nightly repressor/activator NOX. Our modelling results demonstrate that the clock does not need a large number of activators in order to reproduce the observed gene expression patterns. For example, the sequential expression of the PRR genes does not require the genes to be connected as a series of activators. In the presented model, transcriptional activation is exclusively the task of RVE8. Predictions of how strongly RVE8 affects its targets are found to agree with earlier interpretations of the experimental data, but generally we find that the many negative feedbacks in the system should discourage intuitive interpretations of mutant phenotypes. The dynamics of the clock are difficult to predict without mathematical modelling, and the clock is better viewed as a tangled web than as a series of loops.	body of uterus;circadian clocks;feedback;gene expression;gene co-expression network;interaction;interpretation process;mathematical model;mathematics;phenotype;production rule representation;scientific publication;text corpus;transcriptional activation;world wide web	Karl Fogelmark;Carl Troein	2014		10.1371/journal.pcbi.1003705	biology;regulation of gene expression;gene expression;bioinformatics;transcription;circadian clock;genetics;circadian rhythm;transcription factor	Comp.	5.456647670231577	-62.15419822050148	95820
a987512e7f4ba0e6b214ba8e624f472139e92552	microarray comparative genomic hybridisation analysis incorporating genomic organisation, and application to enterobacterial plant pathogens	nitrogen fixation;forecasting;chromosome aberrations;experimental method;lactococcus lactis;plant diseases;normal distribution;hidden markov model;comparative genomics;gene transfer horizontal;serveur institutionnel;comparative genomic hybridization;genetic variation;enterobacteriaceae;host range;cluster analysis;hidden markov models;archive institutionnelle;genomic dna;relative abundance;probe hybridization;open access;genome bacterial;horizontal gene transfer;reproducibility of results;plant pathogen;models statistical;plant bacterial pathogens;archive ouverte unige;genomic islands;comparators;cybertheses;computer simulation;institutional repository;multidrug resistance;spatial information;oligonucleotide array sequence analysis;markov chains;microarrays	Microarray comparative genomic hybridisation (aCGH) provides an estimate of the relative abundance of genomic DNA (gDNA) taken from comparator and reference organisms by hybridisation to a microarray containing probes that represent sequences from the reference organism. The experimental method is used in a number of biological applications, including the detection of human chromosomal aberrations, and in comparative genomic analysis of bacterial strains, but optimisation of the analysis is desirable in each problem domain.We present a method for analysis of bacterial aCGH data that encodes spatial information from the reference genome in a hidden Markov model. This technique is the first such method to be validated in comparisons of sequenced bacteria that diverge at the strain and at the genus level: Pectobacterium atrosepticum SCRI1043 (Pba1043) and Dickeya dadantii 3937 (Dda3937); and Lactococcus lactis subsp. lactis IL1403 and L. lactis subsp. cremoris MG1363. In all cases our method is found to outperform common and widely used aCGH analysis methods that do not incorporate spatial information. This analysis is applied to comparisons between commercially important plant pathogenic soft-rotting enterobacteria (SRE) Pba1043, P. atrosepticum SCRI1039, P. carotovorum 193, and Dda3937.Our analysis indicates that it should not be assumed that hybridisation strength is a reliable proxy for sequence identity in aCGH experiments, and robustly extends the applicability of aCGH to bacterial comparisons at the genus level. Our results in the SRE further provide evidence for a dynamic, plastic 'accessory' genome, revealing major genomic islands encoding gene products that provide insight into, and may play a direct role in determining, variation amongst the SRE in terms of their environmental survival, host range and aetiology, such as phytotoxin synthesis, multidrug resistance, and nitrogen fixation.	assumed;chromosome aberrations;comparator device component;connective and soft tissue neoplasm;crossbreeding;enterobacteriaceae;experiment;genomic dna;genomic reference sequence identifier:id:pt:bld/tiss:nom;genus dickeya;hidden markov model;kluyveromyces lactis;lactococcus lactis subsp cremoris;markov chain;mathematical optimization;multi-drug resistance;nitrogen fixation;pectobacterium atrosepticum;pectobacterium chrysanthemi;problem domain;sequence alignment;subspecies;comparative genomic analysis;plant poison	Leighton Pritchard;Hui Liu;Clare Booth;Emma Douglas;Patrice François;Jacques Schrenzel;Peter E. Hedley;Paul R. J. Birch;Ian K. Toth	2009		10.1371/journal.pcbi.1000473	normal distribution;biology;multiple drug resistance;markov chain;relative species abundance;hybridization probe;nitrogen fixation;dna microarray;host;forecasting;bioinformatics;genomic dna;genetic variation;spatial analysis;comparator;horizontal gene transfer;cluster analysis;comparative genomics;comparative genomic hybridization;genetics;hidden markov model	Comp.	4.364446583635036	-61.04727487975742	95884
e9ea5d69006a873641da93bcee4ec44f4cd598b0	stop: searching for transcription factor motifs using gene expression	expression pattern;binding site;gene expression data;computational method;gene expression;position weight matrix;transcription factor;gene order;software package	MOTIVATION Existing computational methods that identify transcription factor (TF) binding sites on a gene's promoter are plagued by significant inaccuracies. Binding of a TF to a particular sequence is assessed by comparing its similarity score, obtained from the TF's known position weight matrix (PWM), to a threshold. If the similarity score is above the threshold, the sequence is considered a putative binding site. Determining this threshold is a central part of the problem, for which no satisfactory biologically based solution exists.   RESULTS We present here a method that integrates gene expression data with sequence-based scoring of TF binding sites, for determining a global score threshold for each TF. We validate our method, STOP (Searching TFs Of Promoters), in several ways: (1) we calculate the average expression values of groups of human putative target genes of each TF, and compare them to similar averages derived for random gene groups. The groups of putative targets show significantly higher relative average expression. (2) We find high consistency between the induced lists of putative targets in human and in mouse. (3) The expression patterns associated with human and mouse genes (ordered by PWM scores for each TF) exhibit high similarity between human and mouse, indicating that our method has firm biological basis. (4) Comparison of results obtained by STOP and PRIMA (Elkon et al., 2003) suggests that determining the score threshold using gene expression, as is done in STOP, is more biologically tuned.   AVAILABILITY Software package will be available for academic users upon request.   SUPPLEMENTARY INFORMATION Supplementary data are available on Bioinformatics online.	binding sites;bioinformatics;gene expression;list of code lyoko episodes;prima1 gene;pokeweed mitogens;position weight matrix;pulse-width modulation;score;transcription factor;transcription (software)	Libi Hertzberg;Shai Izraeli;Eytan Domany	2007	Bioinformatics	10.1093/bioinformatics/btm249	biology;gene expression;bioinformatics;binding site;position weight matrix;data mining;genetics;transcription factor	Comp.	1.7438143544828342	-56.8654234282492	96099
8f119a528b25bb2cd7d23bf4ead0fa45960cf970	module-based biomarker discovery in breast cancer	genomics;reliability;cancer;biological organs;molecular biophysics bioinformatics biological organs cancer genetics genomics gynaecology;gene expression data;genetics;gynaecology;gene expression;large scale;proteins;molecular biophysics;diseases;diseases breast cancer proteins gene expression driver circuits bioinformatics;driver circuits;feature selection;classification accuracy module based biomarker discovery breast cancer genome wide biological network data cancer related complex mechanisms feature selection biological network information gene expression data reliability;genome wide biological network data;module based biomarker discovery;cancer related complex mechanisms;classification accuracy;breast cancer;biological network;bioinformatics;biological network information	The availability of genome-wide biological network data opens up new possibilities to discover novel biomarkers and elucidate cancer-related complex mechanisms at network level. In this paper, we propose a novel module-based feature selection framework, which integrates biological network information and gene expression data to identify biomarkers, not as individual genes but as functional modules. Also, a large-scale analysis of ensemble feature selection concept is presented. The method allows combining features selected from multiple runs with various data subsampling to increase the reliability and classification accuracy of the final set of selected features. The results from four breast cancer studies demonstrate that the identified module biomarkers achieve: i) higher classification accuracy in independent validation datasets; ii) better reproducibility than individual gene biomarkers; iii) improved biological interpretability; and iv) enhanced enrichment in cancer-related “disease drivers”.	biological network;chroma subsampling;feature selection;gene ontology term enrichment	Yuji Zhang;Jianhua Xuan;Robert Clarke;Habtom W. Ressom	2010	2010 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2010.5706590	biology;biological network;genomics;gene expression;computer science;bioinformatics;breast cancer;reliability;feature selection;genetics;cancer;molecular biophysics	Visualization	7.043457020980276	-54.97670375330703	96164
b5195bed9ed992e222fc6f58bbc87455260aa96c	identification of novel splice variants and exons of human endothelial cell-specific chemotaxic regulator (ecscr) by bioinformatics analysis	software;alternative splicing;exon intron boundary;sequence homology;introns;amino acid sequence;est alignment;databases genetic;data mining;polymerase chain reaction;humans;molecular sequence data;sequence alignment;computational biology;protein isoforms;exons;sequence analysis protein;membrane proteins;ecscr ecsm2	Recent discovery of biological function of endothelial cell-specific chemotaxic regulator (ECSCR), previously known as endothelial cell-specific molecule 2 (ECSM2), in modulating endothelial cell migration, apoptosis, and angiogenesis, has made it an attractive molecule in vascular research. Thus, identification of splice variants of ECSCR could provide new strategies for better understanding its roles in health and disease. In this study, we performed a series of blast searches on the human EST database with known ECSCR cDNA sequence (Variant 1), and identified additional three splice variants (Variants 2-4). When examining the ECSCR gene in the human genome assemblies, we found a large unknown region between Exons 9 and 11. By PCR amplification and sequencing, we partially mapped Exon 10 within this previously unknown region of the ECSCR gene. Taken together, in addition to previously reported human ECSCR, we identified three novel full-length splice variants potentially encoding different protein isoforms. We further defined a total of twelve exons and nearly all exon-intron boundaries of the gene, of which only eight are annotated in current public databases. Our work provides new information on gene structure and alternative splicing of the human ECSCR, which may imply its functional complexity. This undoubtedly opens new opportunities for future investigation of the biological and pathological significance of these ECSCR splice variants.		Jia Lu;Chaokun Li;Chunwei Shi;James Balducci;Hanju Huang;Hong-Long Ji;Yongchang Chang;Yao Huang	2012	Computational biology and chemistry	10.1016/j.compbiolchem.2012.10.003	biology;intron;molecular biology;exon;bioinformatics;polymerase chain reaction;alternative splicing;sequence alignment;peptide sequence;membrane protein;genetics	Comp.	2.980656364553528	-60.767765515233044	96359
d515b5694d79d1b44183be7fffc5e8fef454ad5e	phylogenetic comparison of genes using long range correlation patterns in dna sequences	dna;genes;biology computing;fluctuations;phylogeny;evolutionary descent;long range correlation patterns;dna sequences;evolution biological;long range correlation;statistical correlation patterns;genetics;dna correlation encoding phylogeny fluctuations mutual information distance measurement;distance measurement;phylogenetic comparison;evolutionary relationship phylogenetic comparison genes long range correlation patterns dna sequences physical appearance evolutionary descent phylogenetic relationships statistical correlation patterns;phylogenetic relationships;statistical analysis;statistical analysis biology computing dna evolution biological genetics;mutual information;dna phylogeny long range correlation;long range;correlation;phylogenetic relationship;dna sequence;evolutionary relationship;encoding;physical appearance	The diversity of life is staggering which is apparent not only in the large number of species, but also in their heterogeneity. Species share commonalities based on their physical appearance, but the intrinsic similarities lies within their DNA sequences which point towards relationships of evolutionary descent. In the proposed research, the authors have analyzed the phylogenetic relationships between genes of different species using the long-range statistical correlation patterns. It is found that the genes of species which are considered to be evolutionarily related are in fact similar in their long-range correlation patterns which provide a substantial proof of their evolutionary relationship.	phylogenetics	Atulya K. Nagar;Dilbag Sokhi	2008	2008 Second UKSIM European Symposium on Computer Modeling and Simulation	10.1109/EMS.2008.81	biology;bioinformatics;genetics	Theory	3.5002146930844393	-61.694388165529574	96478
3bfba63a8ebad4c88306b576067bfa400cf4f8b3	a kinetic model for rna-interference of focal adhesions	rna interference;sensitivity and specificity;simulation and modeling;extracellular matrix proteins;systems biology;signal transduction;physiological cellular and medical topics;models biological;computational biology bioinformatics;focal adhesions;rna small interfering;algorithms;570;570 life sciences;rho gtp binding proteins;bioinformatics	Focal adhesions are integrin-based cell-matrix contacts that transduce and integrate mechanical and biochemical cues from the environment. They develop from smaller and more numerous focal complexes under the influence of mechanical force and are key elements for many physiological and disease-related processes, including wound healing and metastasis. More than 150 different proteins localize to focal adhesions and have been systematically classified in the adhesome project ( http://www.adhesome.org ). First RNAi-screens have been performed for focal adhesions and the effect of knockdown of many of these components on the number, size, shape and location of focal adhesions has been reported. We have developed a kinetic model for RNA interference of focal adhesions which represents some of its main elements: a spatially layered structure, signaling through the small GTPases Rac and Rho, and maturation from focal complexes to focal adhesions under force. The response to force is described by two complementary scenarios corresponding to slip and catch bond behavior, respectively. Using estimated and literature values for the model parameters, three time scales of the dynamics of RNAi-influenced focal adhesions are identified: a sub-minute time scale for the assembly of focal complexes, a sub-hour time scale for the maturation to focal adhesions, and a time scale of days that controls the siRNA-mediated knockdown. Our model shows bistability between states dominated by focal complexes and focal adhesions, respectively. Catch bonding strongly extends the range of stability of the state dominated by focal adhesions. A sensitivity analysis predicts that knockdown of focal adhesion components is more efficient for focal adhesions with slip bonds or if the system is in a state dominated by focal complexes. Knockdown of Rho leads to an increase of focal complexes. The suggested model provides a kinetic description of the effect of RNA-interference of focal adhesions. Its predictions are in good agreement with known experimental results and can now guide the design of RNAi-experiments. In the future, it can be extended to include more components of the adhesome. It also could be extended by spatial aspects, for example by the differential activation of the Rac- and Rho-pathways in different parts of the cell.	biologic development;bistability;classification;experiment;focal (programming language);focal adhesions;guanosine triphosphate phosphohydrolases;interference (communication);kinetics;pyschological bonding;rna interference;small;tissue adhesions;wound healing;anatomical layer	Max Hoffmann;Ulrich S. Schwarz	2012		10.1186/1752-0509-7-2	biology;extracellular matrix;cell biology;bioinformatics;rna interference;focal adhesion;genetics;systems biology;signal transduction	Comp.	9.209191959930287	-64.68322069738534	96669
e2f91f3c042f1a85d3b3714f2020ea368f1ee577	predicting membrane proteins type using inter-domain linker knowledge	membrane protein	Predicting membrane type is a crucial problem in computational biology. It is closely related to the biological function of the protein and its interaction process with other molecules in a biological system. The function of a membrane protein is closely correlated with the type it belongs to. In this paper we introduce DomMat, a novel method to predict membrane protein types. The method extracts functional domains by removing all the corresponding inter-domain linkers from the membrane protein sequence. A novel matching algorithm is then introduced to measure the sensitivity of the functional domains information to the membrane protein sequences of interest. Two protein sequences are expected to be related if they contain similar functional domain information. DomMat was tested in a highquality benchmark dataset. The dataset consists of eight different membrane protein types collected from the SwissProt database. The results obtained suggested that DomMat is comparable to the state-of-the–art methods and indeed a very useful method in identifying membrane protein types.	algorithm;benchmark (computing);biological system;computational biology;function (biology);inter-domain;linker (computing);peptide sequence;uniprot	Nazar Zaki;Wassim El-Hajj	2010			peripheral membrane protein;vesicle-associated membrane protein 8;transmembrane protein;integral membrane protein;ferm domain;membrane protein;inter-domain;membrane;biology;bioinformatics	Comp.	7.839805833436661	-57.86868596578381	96691
4b861145fd050b1b40d8e076e0d92bcc133e3630	gag-pol processing during hiv-1 virion maturation: a systems biology approach	virions;organism development;proteases;proteolysis;systems biology;virion;data processing;hiv 1;enzymes;drug interactions;genes pol;genes gag;dimers chemical physics;chemical dissociation;viral packaging	Proteolytic processing of Gag and Gag-Pol polyproteins by the viral protease (PR) is crucial for the production of infectious HIV-1, and inhibitors of the viral PR are an integral part of current antiretroviral therapy. The process has several layers of complexity (multiple cleavage sites and substrates; multiple enzyme forms; PR auto-processing), which calls for a systems level approach to identify key vulnerabilities and optimal treatment strategies. Here we present the first full reaction kinetics model of proteolytic processing by HIV-1 PR, taking into account all canonical cleavage sites within Gag and Gag-Pol, intermediate products and enzyme forms, enzyme dimerization, the initial auto-cleavage of full-length Gag-Pol as well as self-cleavage of PR. The model allows us to identify the rate limiting step of virion maturation and the parameters with the strongest effect on maturation kinetics. Using the modelling framework, we predict interactions and compensatory potential between individual cleavage rates and drugs, characterize the time course of the process, explain the steep dose response curves associated with PR inhibitors and gain new insights into drug action. While the results of the model are subject to limitations arising from the simplifying assumptions used and from the uncertainties in the parameter estimates, the developed framework provides an extendable open-access platform to incorporate new data and hypotheses in the future.	antiretroviral therapy;biologic development;endopeptidases;estimated;extensibility;floor and ceiling functions;hiv;interaction;kinetics internet protocol;polyproteins;population parameter;proteolytic processing;rate limiting;systems biology;anatomical layer;negative regulation of protein processing in phagocytic vesicle;pol genes;virus maturation	Balázs Könnyü;S. Kashif Sadiq;Tamás Turányi;Rita Hírmondó;Barbara Müller;Hans-Georg Kräusslich;Peter V. Coveney;Viktor Müller	2013		10.1371/journal.pcbi.1003103	biology;enzyme;data processing;proteases;bioinformatics;virology;systems biology	ML	7.629748834254462	-62.24512649198829	96709
492abe85842429fbe71efa2288c69ec90cdb6149	a visual analytics approach to identifying protein structural constraints	vector subtuples protein structures fine grained computational simulation protein synthesis correlated protein mutations pattern visualization mavl stickwrld statistical protein sequence information analysis visual analytics protein folding;stickwrld;pattern visualization;protein family;statistical protein sequence information analysis;interactive data exploration bioinformatics clustering classification and association rules;correlation protein sequence clouds visual analytics protein engineering;protein sequence;visual design;vector subtuples;mavl;protein synthesis;data visualisation;protein structure;data analysis;protein structures;proteins;statistical analysis;association rule;proteins bioinformatics data analysis data visualisation molecular biophysics;clouds;fine grained computational simulation;molecular biophysics;visual analysis;interactive data exploration;protein folding;correlated protein mutations;correlation;clustering classification and association rules;visual analytics;computer simulation;protein engineering;is research;bioinformatics;parallel coordinates	Predicting protein structures has long been a grand-challenge problem. Fine-grained computational simulation of folding events from a protein's synthesis to its final stable structure remains computationally intractable. Therefore, methods which derive constraints from other sources are attractive. To date, constraints derived from known structures have proven to be highly successful. However, these cannot be applied to molecules with no identifiable neighbors having already-determined structures. For such molecules, structural constraints must be derived in other ways. One popular approach has been the statistical analysis of large families of proteins, with the hope that residues that “change together” (co-evolve) imply that those residues are in contact. Unfortunately, despite repeated attempts to use this data to deduce structural constraints, this approach has met with minimal success. The consensus of current literature concludes that there is simply too little information contained within the correlated mutations of many protein families to reliably and generally predict structural constraints. Recent work in my laboratory challenges this conclusion. For some time we have been developing methods (MAVL/StickWRLD) to visualize the pattern of co-evolved mutations within sequence families. While our analysis of individual correlations agrees with the literature consensus, we have recently discovered that the visualized pattern of correlations is highly suggestive of structural relationships. In our preliminary test cases, human researchers can unambiguously determine many positive structural constraints by visual analysis of statistical sequence information alone, often with no training on interpretation of the visualization results. Herein we report the visualization design that supports this Visual Analytics approach to identifying high-confidence hypotheses about protein folding from protein sequence, and illustrate preliminary results from this research. Our approach entails a higher-dimensional extension of parallel coordinates which illuminates distant shared sub-tuples of the vectors representing each protein sequence when these sub-tuples occur with an over abundance compared to expectations. It simultaneously eliminates all representations of tuples which occur with frequency near the expected norm. The result is a minimally-occluded representation of outlier, and only outlier co-occurrences within the sequence families.	computational complexity theory;grand challenges;parallel coordinates;peptide sequence;protein family;simulation;test case;visual analytics	William C. Ray	2010	2010 IEEE Symposium on Visual Analytics Science and Technology	10.1109/VAST.2010.5650199	protein structure;visual analytics;computer science;bioinformatics;data science;data mining	Comp.	2.489404393730599	-55.90725549076858	96723
4258226e6cac51777223edf28171b7be27f4bec3	discmla: auc-based discriminative motif learning	acceleration silicon;discriminative motif learning;chip seq;auc;genomics bioinformatics;discriminative motif finder auc based discriminative motif learning discmla validity discmla discrimination discmla stability discriminative motif learning problem motifs searching statistical model;chip seq discriminative motif learning auc	The recently proposed family of discriminative motif finders is promising for harnessing the power of large quantities of accumulated high-throughput experimental data, however, they have to sacrifice accuracy by employing simplified statistical models during the learning process. In this paper, we propose a new approach called Discriminative Motif Learning via AUC (DiscMLA) to discover motifs on large-scale datasets. Unlike previous approaches, DiscMLA tries to optimize AUC directly during motifs searching. In addition, based on an observation, some novel processes are designed for accelerating DiscMLA. The experimental results show that our approach substantially outperforms previous methods on discriminative motif learning problems. DiscMLA' stability, discrimination and validity will help to exploit high-throughput datasets and answer many fundamental biological questions.	high-throughput computing;motif;statistical model;throughput	Hongbo Zhang;Lin Zhu;De-shuang Huang	2015	2015 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2015.7359688	biology;computer science;bioinformatics;machine learning;pattern recognition;genetics;chip-sequencing	Vision	9.194819103309127	-53.80495013810409	96821
a34602049b98cb92ee3484e99d7e19937f3c8bf8	knottin: the knottin or inhibitor cystine knot scaffold in 2007	software;060102 bioinformatics;cysteine;disulfides;anatomy regional;internet;proteins;knot surgical;sequence alignment;cystine knot motifs;basic local alignment search tool;sequence analysis protein;cystine;databases protein	The KNOTTIN database provides standardized information on the small disulfide-rich proteins with a knotted topology called knottins or inhibitor cystine knots. Static pages present the essential historical or recent results about knottin discoveries, sequences, structures, syntheses, folding, functions, applications and bibliography. New tools, KNOTER3D and KNOTER1D, are provided to determine or predict if a user query (3D structure or sequence) is a knottin. These tools are now used to automate the database update. All knottin structures and sequences in the database are now standardized according to the knottin nomenclature based on loop lengths between knotted cysteines, and to the knottin numbering scheme. Therefore, the whole KNOTTIN database (sequences and structures) can now be searched using loop lengths, in addition to keyword and sequence (BLAST, HMMER) searches. Renumbered and structurally fitted knottin PDB files are available for download as well as renumbered sequences, sequence alignments and logos. The knottin numbering scheme is used for automatic drawing of standardized two-dimensional Colliers de Perles of any knottin structure or sequence in the database or provided by the user. The KNOTTIN database is available at http://knottin.cbs.cnrs.fr.	anatomy, regional;blast;bibliography;cysteine;cystine;cystine-knot miniproteins;download;hmmer;keyword;knot (unit);knot medical device problem;nomenclature;page (document);protein data bank;question (inquiry);search - action;seizures;sequence alignment	Jérôme Gracy;Dung Le-Nguyen;Jean-Christophe Gelly;Quentin Kaas;Annie Heitz;Laurent Chiche	2008		10.1093/nar/gkm939	biology;the internet;bioinformatics;sequence alignment	DB	-1.7864752906565864	-60.27167630816975	96846
cfc9edba08831543f33d288aed353422b8e4a7d4	design, construction and use of the fish server	bioinformatics and systems biology;protein function;bioinformatik och systembiologi;hidden markov model;protein domains;structure comparison;datavetenskap datalogi;structural classification of proteins;computer science;3d structure	At the core of the FISH (Family Identification with Structure anchored Hidden Markov models, saHMMs) server lies the midnight ASTRAL set. It is a collection of protein domains with low mutual sequence identity within homologous families, according to the structural classification of proteins, SCOP. Here, we evaluate two algorithms for creating the midnight ASTRAL set. The algorithm that limits the number of structural comparisons is about an order of magnitude faster than the allagainst-all algorithm.We therefore choose the faster algorithm, although it produces slightly fewer domains in the set. We use the midnight ASTRAL set to construct the structure-anchored Hidden Markov Model data base, saHMM-db, where each saHMM represents one family. Sequence searches using saHMMs provide information about protein function, domain organization, the probable 2D and 3D structure, and can lead to the discovery of homologous domains in remotely related sequences. The FISH server is accessible at http://babel.ucmp.umu.se/fish/.	algorithm;database;decibel;hidden markov model;homology (biology);markov chain;scop;sequence alignment;server (computing)	Jeanette Tångrot;Lixiao Wang;Bo Kågström;Uwe H. Sauer	2006		10.1007/978-3-540-75755-9_78	computer science;bioinformatics;machine learning;data mining;protein domain;algorithm;hidden markov model;structural classification of proteins database	ML	-2.2440043805938386	-54.15868201062492	96849
66593f9b5fed7037ab1a216246fbd4e8ae74addb	a novel structure-aware sparse learning algorithm for brain imaging genetics	connectome;sensitivity and specificity;quantitative trait loci;brain;genetic predisposition to disease;magnetic resonance imaging;reproducibility of results;artificial intelligence;algorithms;pattern recognition automated;humans;alzheimer disease;polymorphism single nucleotide	Brain imaging genetics is an emergent research field where the association between genetic variations such as single nucleotide polymorphisms (SNPs) and neuroimaging quantitative traits (QTs) is evaluated. Sparse canonical correlation analysis (SCCA) is a bi-multivariate analysis method that has the potential to reveal complex multi-SNP-multi-QT associations. Most existing SCCA algorithms are designed using the soft threshold strategy, which assumes that the features in the data are independent from each other. This independence assumption usually does not hold in imaging genetic data, and thus inevitably limits the capability of yielding optimal solutions. We propose a novel structure-aware SCCA (denoted as S2CCA) algorithm to not only eliminate the independence assumption for the input data, but also incorporate group-like structure in the model. Empirical comparison with a widely used SCCA implementation, on both simulated and real imaging genetic data, demonstrated that S2CCA could yield improved prediction performance and biologically meaningful findings.	eaf2 gene;emergence;genetic polymorphism;hereditary diseases;mental association;neuroimaging;nitroprusside;numerous;protein structure prediction;seattle cancer care alliance;single nucleotide polymorphism;solutions;sparse;tomography, emission-computed, single-photon;algorithm	Lei Du;Jingwen Yan;Sungeun Kim;Shannon L. Risacher;Heng Huang;Mark Inlow;Jason H. Moore;Andrew J. Saykin;Li Shen	2014	Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention	10.1007/978-3-319-10443-0_42	radiology;medicine;pathology;bioinformatics;artificial intelligence;magnetic resonance imaging;connectome;quantitative trait locus	Vision	6.564869020889493	-53.562546436027525	96854
388bc7063b6dec4824df2122a1bc3f79320d00db	intenz, the integrated relational enzyme database	substrate specificity;animals;biochemical phenomena;enzyme;serveur institutionnel;terminology as topic;internet;enzymes;archive institutionnelle;catalysis;molecular biology;open access;humans;archive ouverte unige;cybertheses;information storage and retrieval;biochemistry;institutional repository;databases protein	IntEnz is the name for the Integrated relational Enzyme database and is the official version of the Enzyme Nomenclature. The Enzyme Nomenclature comprises recommendations of the Nomenclature Committee of the International Union of Bio chemistry and Molecular Biology (NC-IUBMB) on the nomenclature and classification of enzyme-catalysed reactions. IntEnz is supported by NC-IUBMB and contains enzyme data curated and approved by this committee. The database IntEnz is available at http://www.ebi.ac.uk/intenz.	gene nomenclature;intenz;nc (complexity);rodent nomenclature name	Astrid Fleischmann;Michael Darsow;Kirill Degtyarenko;Wolfgang Fleischmann;Sinéad Boyce;Kristian B. Axelsen;Amos Bairoch;Dietmar Schomburg;Keith F. Tipton;Rolf Apweiler	2004	Nucleic acids research	10.1093/nar/gkh119	biology;enzyme;bioinformatics	DB	-2.3176064115177564	-61.895798342314805	96982
f85cfb2f506898ddcecd3fa78eadf8f3ba28909f	discovery of significant rules for classifying cancer diagnosis data		METHODS AND RESULTS We introduce a new method to discover many diversified and significant rules from high dimensional profiling data. We also propose to aggregate the discriminating power of these rules for reliable predictions. The discovered rules are found to contain low-ranked features; these features are found to be sometimes necessary for classifiers to achieve perfect accuracy. The use of low-ranked but essential features in our method is in contrast to the prevailing use of an ad-hoc number of only top-ranked features. On a wide range of data sets, our method displayed highly competitive accuracy compared to the best performance of other kinds of classification models. In addition to accuracy, our method also provides comprehensible rules to help elucidate the translation between raw data and useful knowledge.	aggregate data;classification;hoc (programming language);neoplasms;profiling (computer programming);rule (guideline)	Jinyan Li;Huiqing Liu;See-Kiong Ng;Limsoon Wong	2003	Bioinformatics		biology;bioinformatics;data science;machine learning;data mining	ML	6.798614969948682	-52.23957173529232	97055
27c499308342bcb7e5b0d2468d708a5607d31340	prediction of protein secondary structure based on nmr chemical shift data using support vector machines	spectroscopy;chemicals;organisms;protein function;magnetic fields;support vector machines chemical shift living systems molecular biophysics nmr spectroscopy proteins statistical analysis;protein functionality;support vector machines;living systems;nuclear magnetic resonance nmr chemical shift data protein secondary structure detection polypeptide chain protein functionality living organism statistical learning support vector machine machine learning computational molecular biology informative chemical shift data;nuclear magnetic resonance;chemical shift;proteins nuclear magnetic resonance chemicals support vector machines magnetic fields computer networks predictive models organisms machine learning spectroscopy;computational molecular biology;nmr spectroscopy;polypeptide chain;computer networks;support vector machines chemical shift nuclear magnetic resonance protein secondary structure;protein secondary structure;accuracy;statistical learning;proteins;statistical analysis;machine learning;secondary structure;nmr chemical shift data;molecular biophysics;amino acids;predictive models;protein secondary structure detection;informative chemical shift data;support vector machine;living organism	Protein secondary structure detection is an intricate problem which depends on several parameters of a polypeptide chain and its environment and has a great effect on the accurate determination of protein functionality in living organisms. Statistical learning approaches have been used to tackle the problem extensively and many considerable results have been achieved, which encourages the researchers to continue exploring the track. Support vector machines are among the interesting tools of machine learning, which have been used in different fields of computational molecular biology. This paper aims to combine the power of SVMs with the informative chemical shift data to distinguish the secondary structure of the proteins. The results show a good accuracy of the approach regarding different structures, especially in detection of turns and sheets.	information;machine learning;protein structure prediction;support vector machine	Ahmad Sabouri;Adel Ardalan;Reza Shahidi-Nejad	2010	2010 12th International Conference on Computer Modelling and Simulation	10.1109/UKSIM.2010.44	chemistry;bioinformatics;analytical chemistry;nuclear magnetic resonance	Comp.	9.720561343086663	-57.57454567943115	97066
e9221f4d57cf9eb2c01016641f310e7a73cbd7ac	grn2sbml: automated encoding and annotation of inferred gene regulatory networks complying with sbml		UNLABELLED GRN2SBML automatically encodes gene regulatory networks derived from several inference tools in systems biology markup language. Providing a graphical user interface, the networks can be annotated via the simple object access protocol (SOAP)-based application programming interface of BioMart Central Portal and minimum information required in the annotation of models registry. Additionally, we provide an R-package, which processes the output of supported inference algorithms and automatically passes all required parameters to GRN2SBML. Therefore, GRN2SBML closes a gap in the processing pipeline between the inference of gene regulatory networks and their subsequent analysis, visualization and storage.   AVAILABILITY GRN2SBML is freely available under the GNU Public License version 3 and can be downloaded from http://www.hki-jena.de/index.php/0/2/490.   SUPPLEMENTARY INFORMATION General information on GRN2SBML, examples and tutorials are available at the tool's web page.	algorithm;application programming interface;biomart;gnu;gene regulatory network;graphical user interface;inference;markup language;minimum information required in the annotation of models;registries;sbml;soap;systems biology;user interface device component;web page	Sebastian Vlaic;Bianca Hoffmann;Peter Kupfer;Michael Weber;Andreas Dräger	2013	Bioinformatics	10.1093/bioinformatics/btt370	computer science;bioinformatics;data mining;world wide web	Comp.	-3.930316764282379	-59.68577979015094	97084
75ebe102772f738ff062c87c1f800b7f999e90f6	a comparative study of methods for detecting small somatic variants in disease-normal paired next generation sequencing data	genomics small somatic variant detection disease normal paired next generation sequencing data high throughput next generation sequencing technology computational methods matched control search disease specific mutations jointsnvmix samtools somaticsniper strelka varscan disease normal pairs sensitivity false discovery rate algorithm developers single nucleotide polymorphism;sensitivity biology computing diseases genetics genomics macromolecules molecular biophysics molecular configurations polymorphism;variant call single nucleotide polymorphism insertion deletion computational tool next generation sequencing	While high-throughput next generation sequencing technologies are rapidly approaching maturity, computational tools for variant calling have significant room for improvement. The recently emerged computational methods typically compare a disease sample directly with its matched control in order to improve the accuracy of variant calling and search disease specific mutations. In this paper, we performed a comparative study of five methods, JointSNVMix, SAMtools, SomaticSniper, Strelka and VarScan, for simultaneous detection of small somatic variants from disease-normal pairs. This paper evaluates the sensitivity and false discovery rate of these methods, aiming to provide guidelines for users and algorithm developers. The computational efficiency and other issues are also explored.	algorithm;capability maturity model;high-throughput computing;next-generation network;samtools;sensor;throughput	Qingguo Wang;Zhongming Zhao	2012	Proceedings 2012 IEEE International Workshop on Genomic Signal Processing and Statistics (GENSIPS)	10.1109/GENSIPS.2012.6507721	biology;molecular biology;bioinformatics;genetics	Visualization	0.45700666329718664	-54.85505767367048	97140
1b4f68c39b89bb2078c43e90d2b06a8714610aca	a fast and automated solution for accurately resolving protein domain architectures	families;proteine;ucl;protein domains;database;discovery;automatisation;theses;conference proceedings;methode;automatizacion;genomes;recognition;digital web resources;ucl discovery;open access;arquitectura;ucl library;proteina;book chapters;open access repository;protein;sequence;metodo;architecture;method;ucl research;automation	MOTIVATION Accurate prediction of the domain content and arrangement in multi-domain proteins (which make up >65% of the large-scale protein databases) provides a valuable tool for function prediction, comparative genomics and studies of molecular evolution. However, scanning a multi-domain protein against a database of domain sequence profiles can often produce conflicting and overlapping matches. We have developed a novel method that employs heaviest weighted clique-finding (HCF), which we show significantly outperforms standard published approaches based on successively assigning the best non-overlapping match (Best Match Cascade, BMC).   RESULTS We created benchmark data set of structural domain assignments in the CATH database and a corresponding set of Hidden Markov Model-based domain predictions. Using these, we demonstrate that by considering all possible combinations of matches using the HCF approach, we achieve much higher prediction accuracy than the standard BMC method. We also show that it is essential to allow overlapping domain matches to a query in order to identify correct domain assignments. Furthermore, we introduce a straightforward and effective protocol for resolving any overlapping assignments, and producing a single set of non-overlapping predicted domains.   AVAILABILITY AND IMPLEMENTATION The new approach will be used to determine MDAs for UniProt and Ensembl, and made available via the Gene3D website: http://gene3d.biochem.ucl.ac.uk/Gene3D/. The software has been implemented in C++ and compiled for Linux: source code and binaries can be found at: ftp://ftp.biochem.ucl.ac.uk/pub/gene3d_data/DomainFinder3/   CONTACT yeats@biochem.ucl.ac.uk   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	architecture as topic;benchmark (computing);binary file;bioinformatics;c++;cath;conflict (psychology);database;databases, protein;ensembl;evolution, molecular;halt and catch fire;hidden markov model;intelligent platform management interface;linux;markov chain;numerous;position weight matrix;protein domain;question (inquiry);scientific publication;source code;uniprot;web site;mecarzole	Corin Yeats;Oliver Redfern;Christine A. Orengo	2010	Bioinformatics	10.1093/bioinformatics/btq034	biology;method;computer science;bioinformatics;architecture;automation;data mining;sequence;world wide web;genetics	Comp.	-1.0483516404610775	-57.674937812221216	97168
e39d926f0a5c480e6859406cc7d89a1a6815f502	a simple method of identifying symmetric substructures of proteins	pearson s correlation;protein design;drmsd;root mean square deviation;protein evolution;structural symmetry;similarity matrix;correlation analysis	Accurate identifications of internal symmetric substructures of proteins are needed in protein evolution study and protein design. To overcome the difficulties met by previous methods, here we propose a simple quantitative one by using a similarity matrix plus Pearson's correlation analysis. The distance root-mean-square deviation (dRMSD) is used to measure the similarity of two substructures in a protein. We applied this method to the proteins of the beta-propeller, jelly roll, and beta-trefoil families and the results show that this method cannot only detect the internal repetitive structures in proteins effectively, but also can identify their locations easily.	molecular design software;plant roots;similarity measure;staphylococcal protein a;beta thalassemia	Hanlin Chen;Yanzhao Huang;Yi Xiao	2009	Computational biology and chemistry	10.1016/j.compbiolchem.2008.07.026	biology;combinatorics;root-mean-square deviation;similarity matrix;computer science;bioinformatics;mathematics;geometry;protein design	Comp.	9.601501710144094	-58.080794569795366	97287
173c917fc1a558591ad6da46a78c2055132ecfd8	genecluster 2.0: an advanced toolset for bioarray analysis	confocal microscope;bioinformatique;immunohistochemistry;gene expression;neuropeptides;data analysis;software package;tongue;gustatory system;k nearest neighbor;self organized map;bioinformatica;gene selection;clustered data;bioinformatics;permutation test	SUMMARY GeneCluster 2.0 is a software package for analyzing gene expression and other bioarray data, giving users a variety of methods to build and evaluate class predictors, visualize marker lists, cluster data and validate results. GeneCluster 2.0 greatly expands the data analysis capabilities of GeneCluster 1.0 by adding classification, class discovery and permutation test methods. It includes algorithms for building and testing supervised models using weighted voting and k-nearest neighbor algorithms, a module for systematically finding and evaluating clustering via self-organizing maps, and modules for marker gene selection and heat map visualization that allow users to view and sort samples and genes by many criteria. GeneCluster 2.0 is a stand-alone Java application and runs on any platform that supports the Java Runtime Environment version 1.3.1 or greater.   AVAILABILITY http://www.broad.mit.edu/cancer/software	gene expression;heat map;imagery;java programming language;java virtual machine;k-nearest neighbors algorithm;organizing (structure);resampling (statistics);self-organization;self-organizing map;single linkage cluster analysis;statistical cluster	Michael R Reich;K. Ohm;Michael Angelo;Pablo Tamayo;Jill P. Mesirov	2004	Bioinformatics	10.1093/bioinformatics/bth138	immunohistochemistry;gene-centered view of evolution;biology;neuropeptide;gene expression;gustatory system;resampling;computer science;bioinformatics;theoretical computer science;data mining;data analysis;k-nearest neighbors algorithm;genetics;statistics	Comp.	-2.8491713150564735	-57.055978734306706	97431
8fe0220d1ed4566afb254d6cae6500ccfb6cf7d7	an evaluation of the midcop method for imputing allele frequency in genome wide association studies		A genome wide association studies require genotyping DNA sequence of a large sample of individuals with and without the specific disease of interest. The current technologies of genotyping individual DNA sequence only genotype a limited DNA sequence of each individual in the study. As a result, a large fraction of Single Nucleotide Polymorphisms (SNPs) are not genotyped. Existing imputation methods are based on individual level data, which are often time consuming and costly. A new method, the Minimum Deviation of Conditional Probability (MiDCoP), was recently developed that aims at imputing the allele frequencies of the missing SNPs using the allele frequencies of neighboring SNPs without using the individual level SNP information. This article studies the performance of the MiDCoP approach using association analysis based on the imputed allele frequency by analyzing the GAIN Schizophrenia data. The results indicate that the choice of reference sets has strong impact on the performance. The imputation accuracy improves if the case and control data sets are imputed using a separate but better matched reference set, respectively.		Yadu Gautam;Carl Lee;Chin-I Cheng;Carl D. Langefeld	2015		10.1007/978-3-319-10389-1_5	single-nucleotide polymorphism;computer science;machine learning;computational biology;genotyping;artificial intelligence;genome-wide association study;imputation (statistics);allele frequency;dna sequencing;genotype;genetic association	NLP	3.0600304689605418	-52.84839113580473	97642
1fe5532835ba17aa7e1d1fa61efdc9d5c8acb16c	labkey server: an open source platform for scientific data integration, analysis and collaboration	software;software tool;database management systems;data collection;scientific data;heterogeneous data;data type;computational biology bioinformatics;cooperative behavior;data analysis;internet;software development;information dissemination;algorithms;source code;collaborative research;databases factual;combinatorial libraries;computational biology;computer appl in life sciences;open source software;open source;microarrays;bioinformatics	Broad-based collaborations are becoming increasingly common among disease researchers. For example, the Global HIV Enterprise has united cross-disciplinary consortia to speed progress towards HIV vaccines through coordinated research across the boundaries of institutions, continents and specialties. New, end-to-end software tools for data and specimen management are necessary to achieve the ambitious goals of such alliances. These tools must enable researchers to organize and integrate heterogeneous data early in the discovery process, standardize processes, gain new insights into pooled data and collaborate securely. To meet these needs, we enhanced the LabKey Server platform, formerly known as CPAS. This freely available, open source software is maintained by professional engineers who use commercially proven practices for software development and maintenance. Recent enhancements support: (i) Submitting specimens requests across collaborating organizations (ii) Graphically defining new experimental data types, metadata and wizards for data collection (iii) Transitioning experimental results from a multiplicity of spreadsheets to custom tables in a shared database (iv) Securely organizing, integrating, analyzing, visualizing and sharing diverse data types, from clinical records to specimens to complex assays (v) Interacting dynamically with external data sources (vi) Tracking study participants and cohorts over time (vii) Developing custom interfaces using client libraries (viii) Authoring custom visualizations in a built-in R scripting environment. Diverse research organizations have adopted and adapted LabKey Server, including consortia within the Global HIV Enterprise. Atlas is an installation of LabKey Server that has been tailored to serve these consortia. It is in production use and demonstrates the core capabilities of LabKey Server. Atlas now has over 2,800 active user accounts originating from approximately 36 countries and 350 organizations. It tracks roughly 27,000 assay runs, 860,000 specimen vials and 1,300,000 vial transfers. Sharing data, analysis tools and infrastructure can speed the efforts of large research consortia by enhancing efficiency and enabling new insights. The Atlas installation of LabKey Server demonstrates the utility of the LabKey platform for collaborative research. Stable, supported builds of LabKey Server are freely available for download at http://www.labkey.org . Documentation and source code are available under the Apache License 2.0.	biological specimen;cdisc send biospecimens terminology;computational proteomics analysis system;data collection;data table;database validation plan;documentation;download;emoticon;end-to-end encryption;engineering;entity name part qualifier - adopted;genetic heterogeneity;hiv infections;labkey server;libraries;open-source software;organizing (structure);pooled sample;r language;server (computer);software development;source code;spreadsheet;track (course);user (computing);vial device;vii;multiplicity	Elizabeth K. Nelson;Britt Piehler;Josh Eckels;Adam Rauch;Matthew Bellew;Peter Hussey;Sarah Ramsay;Cory Nathe;Karl Lum;Kevin Krouse;David Stearns;Brian Connolly;Tom Skillman;Mark Igra	2010		10.1186/1471-2105-12-71	the internet;dna microarray;data type;computer science;bioinformatics;software development;data mining;data analysis;world wide web;data;source code;data collection	Web+IR	-4.3145221750250995	-60.662347032045446	97691
38d4082e9335c6344fd061ed47abbc5bb02dce1b	systematic analysis of enzyme-catalyzed reaction patterns and prediction of microbial biodegradation pathways	enzyme	The roles of chemical compounds in biological systems are now systematically analyzed by high-throughput experimental technologies. To automate the processing and interpretation of large-scale data it is necessary to develop bioinformatics methods to extract information from the chemical structures of these small molecules by considering the interactions and reactions involving proteins and other biological macromolecules. Here we focus on metabolic compounds and present a knowledge-based approach for understanding reactivity and metabolic fate in enzyme-catalyzed reactions in a given organism or group. We first constructed the KEGG RPAIR database containing chemical structure alignments and structure transformation patterns, called RDM patterns, for 7091 reactant pairs (substrate-product pairs) in 5734 known enzyme-catalyzed reactions. A total of 2205 RDM patterns were then categorized based on the KEGG PATHWAY database. The majority of RDM patterns were uniquely or preferentially found in specific classes of pathways, although some RDM patterns, such as those involving phosphorylation, were ubiquitous. The xenobiotics biodegradation pathways contained the most distinct RDM patterns, and we developed a scheme for predicting bacterial biodegradation pathways given chemical structures of, for example, environmental compounds.		Mina Oh;Takuji Yamada;Masahiro Hattori;Susumu Goto;Minoru Kanehisa	2007	Journal of chemical information and modeling	10.1021/ci700006f	organism;chemical structure;small molecule;macromolecule;bioinformatics;enzyme;chemistry;kegg;rdm;enzyme catalysis	Comp.	4.556617205884433	-60.14801994335845	97701
7afbfc02cf01579f3743a69a45b842e3bb3bf827	a robust two-way semi-linear model for normalization of cdna microarray data	software;data interpretation statistical;computer graphics;placenta;satisfiability;computational biology bioinformatics;microarray data analysis;models genetic;likelihood functions;mean square error;dna complementary;nonlinear dynamics;linear model;semiparametric method;analysis of variance;cdna microarray;models statistical;simulation study;algorithms;regression analysis;humans;differentially expressed gene;combinatorial libraries;computational biology;linear models;reference standards;computer appl in life sciences;calibration;gene expression profiling;oligonucleotide array sequence analysis;microarrays;bioinformatics	Normalization is a basic step in microarray data analysis. A proper normalization procedure ensures that the intensity ratios provide meaningful measures of relative expression values. We propose a robust semiparametric method in a two-way semi-linear model (TW-SLM) for normalization of cDNA microarray data. This method does not make the usual assumptions underlying some of the existing methods. For example, it does not assume that: (i) the percentage of differentially expressed genes is small; or (ii) the numbers of up- and down-regulated genes are about the same, as required in the LOWESS normalization method. We conduct simulation studies to evaluate the proposed method and use a real data set from a specially designed microarray experiment to compare the performance of the proposed method with that of the LOWESS normalization approach. The simulation results show that the proposed method performs better than the LOWESS normalization method in terms of mean square errors for estimated gene effects. The results of analysis of the real data set also show that the proposed method yields more consistent results between the direct and the indirect comparisons and also can detect more differentially expressed genes than the LOWESS method. Our simulation studies and the real data example indicate that the proposed robust TW-SLM method works at least as well as the LOWESS method and works better when the underlying assumptions for the LOWESS method are not satisfied. Therefore, it is a powerful alternative to the existing normalization methods.	dna microarray;dna, complementary;database normalization;itil;linear model;mahdiyar;mean squared error;normalize;semiconductor industry;semiparametric model;simulation;sirolimus	Deli Wang;Jian Huang;Hehuang Xie;Liliana Manzella;Marcelo Bento Soares	2004	BMC Bioinformatics	10.1186/1471-2105-6-14	nonlinear system;computer science;bioinformatics;data science;linear model;data mining	ML	4.680698257250819	-52.68168801041797	97739
459160a598e057a0b3d75546f31c6e3ef772f770	extraction of gene regulatory networks from biological literature	semisupervised setting gene regulatory network extraction biological literature cellular component interaction gene expression activation gene expression inhibition regulatory relationships isolated relationship assembly filtering step ontology based system information retrieval scientific literature document sentences genes of interest ontology annotated textpresso search results xml format pattern scores unlabeled data motivation;biology computing;supervised learning;text mining;training;information filtering;gene regulatory networks;ontology gene regulatory networks supervised learning semi supervised learning natural language processing regular expressions text mining;data mining;semi supervised learning;ontologies artificial intelligence;genetics;proteins;regular expressions;feature extraction;xml biology computing cellular biophysics feature extraction filtering theory genetics information filtering learning artificial intelligence ontologies artificial intelligence pattern classification;dictionaries;xml;pattern classification;learning artificial intelligence;training data mining proteins dictionaries data models;ontology;cellular biophysics;natural language processing;filtering theory;data models	A gene regulatory network (GRN) is a network of interacting cellular components. The components are genes and their products, and the interactions represent regulatory relationships among genes, specifically activation and inhibition of gene expression, under certain conditions. Many regulatory relationships are known in the literature. However, assembling isolated relationships into networks is a challenging, albeit important task. We have developed a system for automatically extracting GRNs from the literature. As a first filtering step, our system makes use of Textpresso (an existing ontology-based system for information retrieval from scientific literature) to identify document sentences that contain genes of interest and regulatory relationships involving those genes. The ontology-annotated Textpresso search results, provided in XML format, are examined for regular expressions that specify regulatory relationships. We use a set of positively labeled relations between genes (equivalently, pairs of genes that exhibit a regulatory relationship) to infer scores for patterns present in such relations. The pattern scores are further used to compute total scores for putative relationships between pairs of genes present in a sentence. Pairs with total score greater than a threshold are assumed to be positive. Availability of very little amounts of labeled relationships along with large amounts of unlabeled data motivated us to study the performance of our approach also in a semi-supervised setting. We show that unlabeled data can, in some cases, improve the performance of our approach.	domain adaptation;gene regulatory network;information retrieval;interaction;primary source;regular expression;scientific literature;semi-supervised learning;semiconductor industry;supervised learning;unsupervised learning;xml	Karthik Tangirala;Doina Caragea	2013	2013 IEEE 3rd International Conference on Computational Advances in Bio and medical Sciences (ICCABS)	10.1109/ICCABS.2013.6629200	data modeling;gene regulatory network;text mining;xml;feature extraction;computer science;bioinformatics;machine learning;ontology;data mining;supervised learning;genetics;regular expression	Comp.	-3.081439826219594	-64.34264015868263	97741
d699e6c6b34040e3733c1732917929905f8a1303	a stochastic model of size control in the budding yeast cell cycle		Cell size is a key characteristic that significantly affects many aspects of cellular physiology. There are specific control mechanisms during cell cycle to maintain the cell size within a range from one generation to another. Such control mechanisms introduce substantial variability to important properties of the cell cycle such as inter-division time. To quantitatively study the effect of such variability in progression through cell cycle, detailed stochastic models are required. In this paper, a new hybrid stochastic model is proposed to study the effect of molecular noise and size control mechanism on the variabilities in cell cycle of the budding yeast Saccharomyces cerevisiae. The proposed model provides an accurate, yet computationally efficient approach for simulation of an intricate system by integrating the deterministic and stochastic simulation schemes.	algorithmic efficiency;cell (microprocessor);cell signaling;color gradient;control system;heart rate variability;simulation;stochastic process	Mansooreh Ahmadian;John J. Tyson;Yang Cao	2018		10.1145/3233547.3233685	stochastic modelling;deterministic system;cell;bioinformatics;budding;saccharomyces cerevisiae;cell cycle;computer science;stochastic simulation;cell physiology	Metrics	7.434539228070384	-65.06562170007855	97746
5529167fd895b4ec5e5aff3551716e26e72ce312	seed-set construction by equi-entropy partitioning for efficient and sensitive short-read mapping	high-throughput short-read data;mapping position;genome mapping;allowable error position;sensitive search;index data;continuous seed;sensitive genome mapping;equi-entropy partitioning;reference genome;sensitive homology search;sensitive short-read mapping;seed-set construction	Spaced seeds have been shown to be superior to continuous seeds for efficient and sensitive homology search based on the seedand-extend paradigm. Much the same is true in genome mapping of high-throughput short-read data. However, a highly sensitive search with multiple spaced patterns often requires the use of a great amount of index data. We propose a novel seed-set construction method for efficient and sensitive genome mapping of short reads with relatively high error rates, which uses only continuous seeds of variable length allowing a few errors. The seed lengths and allowable error positions are optimized on the basis of entropy, which is a measure of ambiguity or repetitiveness of mapping positions. These seeds can be searched efficiently using the Burrows-Wheeler transform of the reference genome. Evaluation using actual biological SOLiD sequence data demonstrated that our method was competitive in speed and sensitivity using much less memory and disk space in comparison to spaced-seed methods.	burrows–wheeler transform;disk space;entropy (information theory);high-throughput computing;homology (biology);programming paradigm;seed;throughput;uk educational evidence portal	Kouichi Kimura;Asako Koike;Kenta Nakai	2011		10.1007/978-3-642-23038-7_14	computer science;bioinformatics;algorithm	Comp.	-0.691421884370874	-54.04803823740858	97870
0f5ed97a79c5194092f2148686532289c4da7e30	distant supervision for cancer pathway extraction from text		Biological pathways are central to understanding complex diseases such as cancer. The majority of this knowledge is scattered in the vast and rapidly growing research literature. To automate knowledge extraction, machine learning approaches typically require annotated examples, which are expensive and time-consuming to acquire. Recently, there has been increasing interest in leveraging databases for distant supervision in knowledge extraction, but existing applications focus almost exclusively on newswire domains. In this paper, we present the first attempt to formulate the distant supervision problem for pathway extraction and apply a state-of-the-art method to extracting pathway interactions from PubMed abstracts. Experiments show that distant supervision can effectively compensate for the lack of annotation, attaining an accuracy approaching supervised results. From 22 million PubMed abstracts, we extracted 1.5 million pathway interactions at a precision of 25%. More than 10% of interactions are mentioned in the context of one or more cancer types, analysis of which yields interesting insights.	abstract summary;database;extraction;gene regulatory network;interaction;machine learning;neoplasms;pubmed;scientific literature;supervised learning	Hoifung Poon;Kristina Toutanova;Chris Quirk	2015	Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing		bioinformatics;kras;zfp36;cancer research;cancer;mlh1;diras3;speech recognition;tmprss2;arid1a;biology;mylip	NLP	-3.1746421371529543	-65.40963624043887	97930
87cadb7c18644aba0ac3e8f9e28e07d384dbd919	the rat genome database pathway portal	animals;rats;signal transduction;gene regulatory networks;male;molecular sequence annotation;databases genetic;internet;prostatic neoplasms;genome;humans	The set of interacting molecules collectively referred to as a pathway or network represents a fundamental structural unit, the building block of the larger, highly integrated networks of biological systems. The scientific community's interest in understanding the fine details of how pathways work, communicate with each other and synergize, and how alterations in one or several pathways may converge into a disease phenotype, places heightened demands on pathway data and information providers. To meet such demands, the Rat Genome Database [(RGD) http://rgd.mcw.edu] has adopted a multitiered approach to pathway data acquisition and presentation. Resources and tools are continuously added or expanded to offer more comprehensive pathway data sets as well as enhanced pathway data manipulation, exploration and visualization capabilities. At RGD, users can easily identify genes in pathways, see how pathways relate to each other and visualize pathways in a dynamic and integrated manner. They can access these and other components from several entry points and effortlessly navigate between them and they can download the data of interest. The Pathway Portal resources at RGD are presented, and future directions are discussed. Database URL: http://rgd.mcw.edu.	biological system;converge;data acquisition;disease phenotype;download;entity name part qualifier - adopted;gene regulatory network;imagery;interaction;large;rgd;synergy;uniform resource locator	Victoria Petri;Mary Shimoyama;G. Thomas Hayman;Jennifer R. Smith;Marek Tutaj;Jeff de Pons;Melinda R. Dwinell;Diane H. Munzenmaier;Simon N. Twigger;Howard J. Jacob	2011		10.1093/database/bar010	biology;gene regulatory network;the internet;bioinformatics;data mining;database;world wide web;genetics;signal transduction;genome	Visualization	-1.67515942655425	-61.24988860941648	98352
cfb3c952dfc880604b4c14c262831460df6acbda	synergistic drug combinations from electronic health records and gene expression	breast cancer;combination therapies;drug discovery;drug interactions;drug repurposing;electronic health records	Objective Using electronic health records (EHRs) and biomolecular data, we sought to discover drug pairs with synergistic repurposing potential. EHRs provide real-world treatment and outcome patterns, while complementary biomolecular data, including disease-specific gene expression and drug-protein interactions, provide mechanistic understanding.   Method We applied Group Lasso INTERaction NETwork (glinternet), an overlap group lasso penalty on a logistic regression model, with pairwise interactions to identify variables and interacting drug pairs associated with reduced 5-year mortality using EHRs of 9945 breast cancer patients. We identified differentially expressed genes from 14 case-control human breast cancer gene expression datasets and integrated them with drug-protein networks. Drugs in the network were scored according to their association with breast cancer individually or in pairs. Lastly, we determined whether synergistic drug pairs found in the EHRs were enriched among synergistic drug pairs from gene-expression data using a method similar to gene set enrichment analysis.   Results From EHRs, we discovered 3 drug-class pairs associated with lower mortality: anti-inflammatories and hormone antagonists, anti-inflammatories and lipid modifiers, and lipid modifiers and obstructive airway drugs. The first 2 pairs were also enriched among pairs discovered using gene expression data and are supported by molecular interactions in drug-protein networks and preclinical and epidemiologic evidence.   Conclusions This is a proof-of-concept study demonstrating that a combination of complementary data sources, such as EHRs and gene expression, can corroborate discoveries and provide mechanistic insight into drug synergism for repurposing.	anti-inflammatory agents;drug interactions;drug synergism;electronic health records;gene expression;gene ontology term enrichment;gonadorelin;interaction;lasso;logistic regression;mammary neoplasms;patients;score	Yen S. Low;Aaron C. Daugherty;Elizabeth A. Schroeder;William Chen;Tina Seto;Susan C. Weber;Michael Lim;Trevor J. Hastie;Maya Mathur;Manisha Desai;Carl Farrington;Andrew A. Radin;Marina Sirota;Pragati Kenkare;Caroline A. Thompson;Peter P. Yu;Scarlett Lin Gomez;George W. Sledge;Allison W. Kurian	2017		10.1093/jamia/ocw161	toxicology;bioinformatics	Comp.	6.509655388766733	-55.42758243943384	98356
85682087e9b4989990044342e2893ce703e593e7	libgs: a matlab software package for gene selection	libgs;feature selection algorithms;selection;gen;algorithme;algorithm;logiciel matlab;software package;gene;progiciel;seleccion;matlab software;gene expression data analysis;gene selection;paquete programa;matlab;algoritmo;programa matlab	Many gene selection algorithms have been applied in gene expression data analysis successfully. To solve different developing environments of these toolkits, such as rankgene (Su et al., 2003), and mRMR (http://research.janelia.org/peng/proj/mrmr/index.htm), perform data analysis and make algorithm comparison more flexible, we have developed a software package LIBGS including: 1) Seven new gene selection algorithms implemented using MATLAB. 2) MATLAB interface for Rankgene. 3) MATLAB interface for LIBSVM and WEKA. 4) Programs for converting data formats. 5) A collection of six popular gene expression data sets. These features make LIBGS a useful tool in gene expression analysis and feature selection.	a library for support vector machines;feature selection;gene expression;ibm notes;inclusion body myositis (disorder);integrated software;interface device component;list of toolkits;lithium;matlab;national institute of general medical sciences (u.s.);nephrogenic systemic fibrosis;united states national institutes of health;weka;algorithm;format	Yi Zhang;Dingding Wang;Tao Li	2010	International journal of data mining and bioinformatics	10.1504/IJDMB.2010.033525	gene-centered view of evolution;biology;selection;computer science;bioinformatics;theoretical computer science;operating system;gene	Comp.	-3.35426891527193	-56.54059567730612	98440
4913cc66321d0277845d9032a2354fbf89a3fee0	functional module-centric interpretation of transcriptomic change between human and chimpanzee cerebral cortex	transcriptome analyses;human brain functional module transcriptome analyses coexpression differential expression;gene expression;sensitivity;human brain specializations functional module centric interpretation transcriptomic change human cerebral cortex chimpanzee cerebral cortex cellular functions human enhanced cognition neurodegenerative disorders psychiatric disorders genes transcriptome analyses human specific modules human specific phenotypes neurobiological processes;proteins;differential expression;cognition;sensitivity proteins biological processes diseases neurons cognition gene expression;rna brain cellular biophysics cognition medical disorders neurophysiology;diseases;neurons;functional module;biological processes;human brain;coexpression	Characterizing the transcriptomic change between human and chimpanzee brains can provide clues for identifying the cellular functions underlying human's enhanced cognition and the increased vulnerability to the neurodegenerative and psychiatric disorders. Despite some successes, previous studies might have limited sensitivity to detect specific cellular functions since the focus has been only on the strong signals appeared by individual genes or pairs. To overcome these limitations, we carried out two functional module-centric transcriptome analyses. We evaluated the coordinated differential expression and the altered coexpression within the various types of functional modules. In our comparative assessment, the functional module-centric coexpression analysis identified the most extensive functional implications, in comparison to the conventional gene-centric and functional module-centric differential expression analyses. Through the functional module-centric coexpression analysis, we detected several human-specific modules associated with human-specific phenotypes related on neurobiological processes. In summary, our results suggest the rearrangement of transcriptional regulation over individual and multiple functional modules as a plausible basis of human brain specializations.	cognition	Kimin Oh;Taeho Hwang;Kihoon Cha;Gwan-Su Yi	2014	2014 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2014.6999146	biology;gene expression;cognition;sensitivity;bioinformatics;biological process;genetics	Visualization	5.670885805943445	-58.303043715729046	98596
794c048acd3d2d35e3248161729fcf142b4966c6	phospho.elm: a database of phosphorylation sites—update 2008	software;serine;animals;peptides;mice;protein sequence;data collection;phosphorylation;amino acid sequence;datasets;tyrosine;phosphoproteins;conserved sequence;phosphoserine;internet;protein conformation;embryonic lethal mutation;threonine;humans;sequence alignment;phosphotyrosine;protein interaction;high throughput;protein kinases;phosphotransferases;phosphothreonine;sequence analysis protein;databases protein	Phospho.ELM is a manually curated database of eukaryotic phosphorylation sites. The resource includes data collected from published literature as well as high-throughput data sets. The current release of Phospho.ELM (version 7.0, July 2007) contains 4078 phospho-protein sequences covering 12 025 phospho-serine, 2362 phospho-threonine and 2083 phospho-tyrosine sites. The entries provide information about the phosphorylated proteins and the exact position of known phosphorylated instances, the kinases responsible for the modification (where known) and links to bibliographic references. The database entries have hyperlinks to easily access further information from UniProt, PubMed, SMART, ELM, MSD as well as links to the protein interaction databases MINT and STRING. A new BLAST search tool, complementary to retrieval by keyword and UniProt accession number, allows users to submit a protein query (by sequence or UniProt accession) to search against the curated data set of phosphorylated peptides. Phospho.ELM is available on line at: http://phospho.elm.eu.org.	accession number (identifier);accession number (bioinformatics);amino acid sequence;blast;bibliographic reference;database;elm;high-throughput computing;hyperlink;keyword;multiple sulfatase deficiency disease;peptide sequence;protein-serine-threonine kinases;pubmed;question (inquiry);smart;string;scientific publication;search engine;staphylococcal protein a;threonine;throughput;tyrosine;uniprot	Holger Dinkel;Claudia Chica;Allegra Via;Cathryn M. Gould;Lars Juhl Jensen;Toby J. Gibson;Francesca Diella	2008		10.1093/nar/gkq1104	phosphorylation;high-throughput screening;biology;biochemistry;protein structure;the internet;bioinformatics;protein sequencing;sequence alignment;sequence database;peptide sequence;conserved sequence;genetics;phosphotyrosine-binding domain;data collection	Comp.	-1.7015322197874394	-60.51722931744377	98608
826c9ab75144418aceadf7a27ce9b96c6c738c9c	minimotif miner 3.0: database expansion and significantly improved reduction of false-positive predictions from consensus sequences	biological models;consensus sequence;amino acid sequence;models biological;proteins genetics;proteins;protein interaction maps;amino acid motifs;sequence analysis protein;databases protein	Minimotif Miner (MnM available at http://minimotifminer.org or http://mnm.engr.uconn.edu) is an online database for identifying new minimotifs in protein queries. Minimotifs are short contiguous peptide sequences that have a known function in at least one protein. Here we report the third release of the MnM database which has now grown 60-fold to approximately 300,000 minimotifs. Since short minimotifs are by their nature not very complex we also summarize a new set of false-positive filters and linear regression scoring that vastly enhance minimotif prediction accuracy on a test data set. This online database can be used to predict new functions in proteins and causes of disease.	consensus sequence;minimotif miner;score;test data	Tian Mi;Jerlin Camilus Merlin;Sandeep Deverasetty;Michael R. Gryk;Travis J. Bill;Andrew W. Brooks;Logan Y. Lee;Viraj Rathnayake;Christian A. Ross;David P. Sargeant;Christy L. Strong;Paula Watts;Sanguthevar Rajasekaran;Martin R. Schiller	2012		10.1093/nar/gkr1189	consensus sequence;biology;bioinformatics;peptide sequence;genetics	Comp.	1.0915524080343733	-54.877065392184356	98628
ad99c4d98a042ae9df3554289b88545da00c470c	application of machine learning in snp discovery	software;genome plant;transcription factor binding site;transcription factors;homozygote;binding sites;genetic variation;polymorphism genetic;computational biology bioinformatics;protein structure;machine learning;genome human;polymorphism;predictive value of tests;prediction accuracy;artificial intelligence;algorithms;sequence tagged sites;humans;molecular sequence data;soybeans;combinatorial libraries;false positive;base sequence;computational biology;computer appl in life sciences;polymorphism single nucleotide;haplotypes;expressed sequence tags;single nucleotide polymorphism;microarrays;bioinformatics	Single nucleotide polymorphisms (SNP) constitute more than 90% of the genetic variation, and hence can account for most trait differences among individuals in a given species. Polymorphism detection software PolyBayes and PolyPhred give high false positive SNP predictions even with stringent parameter values. We developed a machine learning (ML) method to augment PolyBayes to improve its prediction accuracy. ML methods have also been successfully applied to other bioinformatics problems in predicting genes, promoters, transcription factor binding sites and protein structures. The ML program C4.5 was applied to a set of features in order to build a SNP classifier from training data based on human expert decisions (True/False). The training data were 27,275 candidate SNP generated by sequencing 1973 STS (sequence tag sites) (12 Mb) in both directions from 6 diverse homozygous soybean cultivars and PolyBayes analysis. Test data of 18,390 candidate SNP were generated similarly from 1359 additional STS (8 Mb). SNP from both sets were classified by experts. After training the ML classifier, it agreed with the experts on 97.3% of test data compared with 7.8% agreement between PolyBayes and experts. The PolyBayes positive predictive values (PPV) (i.e., fraction of candidate SNP being real) were 7.8% for all predictions and 16.7% for those with 100% posterior probability of being real. Using ML improved the PPV to 84.8%, a 5- to 10-fold increase. While both ML and PolyBayes produced a similar number of true positives, the ML program generated only 249 false positives as compared to 16,955 for PolyBayes. The complexity of the soybean genome may have contributed to high false SNP predictions by PolyBayes and hence results may differ for other genomes. A machine learning (ML) method was developed as a supplementary feature to the polymorphism detection software for improving prediction accuracies. The results from this study indicate that a trained ML classifier can significantly reduce human intervention and in this case achieved a 5–10 fold enhanced productivity. The optimized feature set and ML framework can also be applied to all polymorphism discovery software. ML support software is written in Perl and can be easily integrated into an existing SNP discovery pipeline.	binding sites;bioinformatics;biopolymer sequencing;c4.5 algorithm;chamaecyparis lawsoniana;genetic polymorphism;genome;homozygote;machine learning;nitroprusside;nucleotides;perl;population parameter;snp array;single nucleotide polymorphism;statistical classification;transcription factor;test data;transcription (software);variation (genetics);promoter	Lakshmi K. Matukumalli;John J. Grefenstette;David L. Hyten;Ik-Young Choi;Perry B. Cregan;Curtis P. Van Tassell	2005	BMC Bioinformatics	10.1186/1471-2105-7-4	single-nucleotide polymorphism;biology;polymorphism;protein structure;molecular biology;dna microarray;type i and type ii errors;haplotype;bioinformatics;binding site;predictive value of tests;genetic variation;sequence-tagged site;genetics;dna binding site;expressed sequence tag;transcription factor	Comp.	8.71633584879258	-55.518257545625644	98755
1f3e02c963f9be4efe1081a60944cb63450cd8c6	an integrated machine learning approach for predicting dosr-regulated genes in mycobacterium tuberculosis	transcription genetic;simulation and modeling;rna messenger;normal distribution;time course;systems biology;gene regulation;oxygen;physiological cellular and medical topics;gene expression data;temporal information;computational biology bioinformatics;gene expression;models genetic;first order;machine learning;transcription factor;principal component analysis;gene expression regulation;prediction accuracy;algorithms;gaussian process;biological sciences;computational biology;mrna expression;protein kinases;tumor suppressor protein p53;logistic regression model;dna damage;gene expression profiling;oligonucleotide array sequence analysis;bacterial proteins;tuberculosis;mycobacterium tuberculosis;bioinformatics	DosR is an important regulator of the response to stress such as limited oxygen availability in Mycobacterium tuberculosis. Time course gene expression data enable us to dissect this response on the gene regulatory level. The mRNA expression profile of a regulator, however, is not necessarily a direct reflection of its activity. Knowing the transcription factor activity (TFA) can be exploited to predict novel target genes regulated by the same transcription factor. Various approaches have been proposed to reconstruct TFAs from gene expression data. Most of them capture only a first-order approximation to the complex transcriptional processes by assuming linear gene responses and linear dynamics in TFA, or ignore the temporal information in data from such systems. In this paper, we approach the problem of inferring dynamic hidden TFAs using Gaussian processes (GP). We are able to model dynamic TFAs and to account for both linear and nonlinear gene responses. To test the validity of the proposed approach, we reconstruct the hidden TFA of p53, a tumour suppressor activated by DNA damage, using published time course gene expression data. Our reconstructed TFA is closer to the experimentally determined profile of p53 concentration than that from the original study. We then apply the model to time course gene expression data obtained from chemostat cultures of M. tuberculosis under reduced oxygen availability. After estimation of the TFA of DosR based on a number of known target genes using the GP model, we predict novel DosR-regulated genes: the parameters of the model are interpreted as relevance parameters indicating an existing functional relationship between TFA and gene expression. We further improve the prediction by integrating promoter sequence information in a logistic regression model. Apart from the documented DosR-regulated genes, our prediction yields ten novel genes under direct control of DosR. Chemostat cultures are an ideal experimental system for controlling noise and variability when monitoring the response of bacterial organisms such as M. tuberculosis to finely controlled changes in culture conditions and available metabolites. Nonlinear hidden TFA dynamics of regulators can be reconstructed remarkably well with Gaussian processes from such data. Moreover, estimated parameters of the GP can be used to assess whether a gene is controlled by the reconstructed TFA or not. It is straightforward to combine these parameters with further information, such as the presence of binding motifs, to increase prediction accuracy.	activity recognition;dna binding site;document completion status - documented;experiment;experimental system;f3 wt allele;gaussian process;gene expression profiling;genus mycobacterium;heart rate variability;logistic regression;machine learning;mycobacterium tuberculosis;neoplasms;nonlinear system;normal statistical distribution;order of approximation;oxygen;relevance;scientific publication;transcription factor;transcription (software);transcription, genetic;trifluoroacetic acid;tuberculosis, pulmonary	Yi Zhang;Kim A. Hatch;Joanna Bacon;Lorenz Wernisch	2009		10.1186/1752-0509-4-37	biology;molecular biology;regulation of gene expression;bioinformatics;genetics;systems biology	Comp.	6.899690218667661	-58.59132774397107	98820
9f37c7a51dd86738ea464aee22864e981ec3978f	svm model for virtual screening of lck inhibitors	virtual screening	Lymphocyte-specific protein tyrosine kinase (Lck) inhibitors have treatment potential for autoimmune diseases and transplant rejection. A support vector machine (SVM) model trained with 820 positive compounds (Lck inhibitors) and 70 negative compounds (Lck noninhibitors) combined with 65 142 generated putative negatives was developed for predicting compounds with a Lck inhibitory activity of IC(50) < or = 10 microM. The SVM model, with an estimated sensitivity of greater than 83% and specificity of greater than 99%, was used to screen 168 014 compounds in the MDDR and was found to have a yield of 45.8% and a false positive rate of 0.52%. The model was also able to identify novel Lck inhibitors and distinguish inhibitors from structurally similar noninhibitors at a false positive rate of 0.27%. To the best of our knowledge, the SVM model developed in this work is the first model with a broad applicability domain and low false positive rate, which makes it very suitable for the virtual screening of chemical libraries for Lck inhibitors.		Chin Yee Liew;Xiao Hua Ma;Xianghui Liu;Chun Wei Yap	2009	Journal of chemical information and modeling	10.1021/ci800387z	biology;chemistry;virtual screening;bioinformatics;combinatorial chemistry;computational chemistry;immunology	Comp.	9.458865578775393	-56.506084962492345	98952
5e23ee315257e675d581eeadac22096c5c2eb0c4	effects of promoter leakage on dynamics of gene expression	health research;uk clinical guidelines;biological patents;simulation and modeling;europe pubmed central;systems biology;citation search;physiological cellular and medical topics;computational biology bioinformatics;uk phd theses thesis;life sciences;algorithms;uk research reports;medical journals;europe pmc;biomedical research;bioinformatics	Quantitative analysis of simple molecular networks is an important step forward understanding fundamental intracellular processes. As network motifs occurring recurrently in complex biological networks, gene auto-regulatory circuits have been extensively studied but gene expression dynamics remain to be fully understood, e.g., how promoter leakage affects expression noise is unclear. In this work, we analyze a gene model with auto regulation, where the promoter is assumed to have one active state with highly efficient transcription and one inactive state with very lowly efficient transcription (termed as promoter leakage). We first derive the analytical distribution of gene product, and then analyze effects of promoter leakage on expression dynamics including bursting kinetics. Interestingly, we find that promoter leakage always reduces expression noise and that increasing the leakage rate tends to simplify phenotypes. In addition, higher leakage results in fewer bursts. Our results reveal the essential role of promoter leakage in controlling expression dynamics and further phenotype. Specifically, promoter leakage is a universal mechanism of reducing expression noise, controlling phenotypes in different environments and making the gene produce generate fewer bursts.	assumed;extravasation;gene expression;information leakage;kinetics internet protocol;phenotype;physical inactivity;proteins;spectral leakage;transcription (software)	Lifang Huang;Zhanjiang Yuan;Peijiang Liu;Tianshou Zhou	2015		10.1186/s12918-015-0157-z	biology;medical research;computer science;bioinformatics;physiology;systems biology	Comp.	7.288383880458823	-63.65315929510644	99382
94ac04591789f7d305c4fd9a459cc81040bab16e	mitochondrial genomic variation associated with higher mitochondrial copy number: the cache county study on memory health and aging	electron transport complex iv;animals;female;dna mitochondrial;mitochondria;longevity;amino acid sequence;male;aging;genetic variation;computational biology bioinformatics;dna copy number variations;genome mitochondrial;algorithms;humans;molecular sequence data;sequence alignment;combinatorial libraries;computer appl in life sciences;haplotypes;aged;microarrays;bioinformatics	The mitochondria are essential organelles and are the location of cellular respiration, which is responsible for the majority of ATP production. Each cell contains multiple mitochondria, and each mitochondrion contains multiple copies of its own circular genome. The ratio of mitochondrial genomes to nuclear genomes is referred to as mitochondrial copy number. Decreases in mitochondrial copy number are known to occur in many tissues as people age, and in certain diseases. The regulation of mitochondrial copy number by nuclear genes has been studied extensively. While mitochondrial variation has been associated with longevity and some of the diseases known to have reduced mitochondrial copy number, the role that the mitochondrial genome itself has in regulating mitochondrial copy number remains poorly understood. We analyzed the complete mitochondrial genomes from 1007 individuals randomly selected from the Cache County Study on Memory Health and Aging utilizing the inferred evolutionary history of the mitochondrial haplotypes present in our dataset to identify sequence variation and mitochondrial haplotypes associated with changes in mitochondrial copy number. Three variants belonging to mitochondrial haplogroups U5A1 and T2 were significantly associated with higher mitochondrial copy number in our dataset. We identified three variants associated with higher mitochondrial copy number and suggest several hypotheses for how these variants influence mitochondrial copy number by interacting with known regulators of mitochondrial copy number. Our results are the first to report sequence variation in the mitochondrial genome that causes changes in mitochondrial copy number. The identification of these variants that increase mtDNA copy number has important implications in understanding the pathological processes that underlie these phenotypes.	adenosine triphosphate;body tissue;cell respiration;copy (object);copy number;dna, mitochondrial;genome;genome, mitochondrial;haplogroup;haplotypes;inference;interaction;mitochondria;mitochondrial inheritance;organelles;pathologic processes;phenotype;pierre robin syndrome;randomness;silo (dataset)	Perry G. Ridge;Taylor J. Maxwell;Spencer J. Foutz;Matthew H. Bailey;Christopher D. Corcoran;JoAnn T. Tschanz;Maria C. Norton;Ronald G. Munger;Elizabeth O'Brien;Richard A. Kerber;Richard M. Cawthon;John S. K. Kauwe	2014		10.1186/1471-2105-15-S7-S6	biology;dna microarray;mitochondrion;haplotype;bioinformatics;genetic variation;sequence alignment;peptide sequence;genetics	Comp.	3.481808364376699	-61.83959036862934	99426
cce679bdad94214fd9d1202c9102a86d300fd64d	kfits: a software framework for fitting and cleaning outliers in kinetic measurements		Motivation Kinetic measurements have played an important role in elucidating biochemical and biophysical phenomena for over a century. While many tools for analysing kinetic measurements exist, most require low noise levels in the data, leaving outlier measurements to be cleaned manually. This is particularly true for protein misfolding and aggregation processes, which are extremely noisy and hence difficult to model. Understanding these processes is paramount, as they are associated with diverse physiological processes and disorders, most notably neurodegenerative diseases. Therefore, a better tool for analysing and cleaning protein aggregation traces is required.   Results Here we introduce Kfits, an intuitive graphical tool for detecting and removing noise caused by outliers in protein aggregation kinetics data. Following its workflow allows the user to quickly and easily clean large quantities of data and receive kinetic parameters for assessment of the results. With minor adjustments, the software can be applied to any type of kinetic measurements, not restricted to protein aggregation.   Availability and implementation Kfits is implemented in Python and available online at http://kfits.reichmannlab.com, in source at https://github.com/odedrim/kfits/, or by direct installation from PyPI (`pip install kfits`).   Contact danare@mail.huji.ac.il.   Supplementary information Supplementary data are available at Bioinformatics online.	bioinformatics;biophysical phenomena;cleaning (activity);departure - action;geographic information systems;kinetics internet protocol;neurodegenerative disorders;outlier;physiological processes;plasma cleaning;python package index;quantity;sensor;software framework;tracing (software);weak measurement;mercaptopurine/methotrexate/vincristine	Oded Rimon;Dana Reichmann	2018	Bioinformatics	10.1093/bioinformatics/btx577	data mining;econometrics;kinetic energy;computer science;software framework;outlier	Comp.	-1.8440852196713966	-55.02700393376966	99453
5c32b053f3f0b0b3e51e7efd84796d0e29484998	basplice: bi-direction alignment for detecting splice junctions	splice junctions;c language basplice bidirection alignment splice junction detection rna seq whole transcriptome shotgun sequencing technology high throughput sequencer gene differential expression mapping efficiency splice junction mapping software soapsplice;rna seq;junctions bioinformatics genomics accuracy software bidirectional control conferences;genetics;c language;rna;rna bioinformatics c language genetics;bi direction alignment;bi direction alignment rna seq splice junctions;bioinformatics	RNA-Seq is a revolutionary whole transcriptome shotgun sequencing technology performed by high-throughput sequencers, which provide more comprehensive information on differential expression of genes and benefit on novel splice variants identification. RNA-Seq reads is so short that it's a great challenge on mapping reads back to the reference effectively, especially when they span two or more exons. To improve the mapping efficiency, we introduce here a bi-direction alignment tool - BAsplice, which use RNA-Seq data to detect splice junctions without any additional information. Compare with another splice junction mapping software, SOAPsplice, BAsplice performs better in call rate and running time, but a little worse in accuracy. BAsplice is a free open-source software written in C language. It is available at https://github.com/vlcc/basplice.	high-throughput computing;open-source software;sensor;splice (system call);throughput;time complexity	Jingde Bu;Jiayan Wu;Meili Chen;Jing-Fa Xiao;Jun Yu;Xuebin Chi;Zhong Jin	2012	2012 IEEE 6th International Conference on Systems Biology (ISB)	10.1109/ISB.2012.6314145	rna;rna-seq;bioinformatics	Visualization	-0.39265129854618985	-54.531331288377864	99465
5706d5b5ce4995e67d220c96268bd45b582ab9a0	enhancing hmm-based protein profile-profile alignment with structural features and evolutionary coupling information	evolution molecular;phylogeny;amino acid sequence;computational biology bioinformatics;solvents;proteins;algorithms;sequence alignment;combinatorial libraries;computational biology;computer appl in life sciences;markov chains;microarrays;bioinformatics	Protein sequence profile-profile alignment is an important approach to recognizing remote homologs and generating accurate pairwise alignments. It plays an important role in protein sequence database search, protein structure prediction, protein function prediction, and phylogenetic analysis. In this work, we integrate predicted solvent accessibility, torsion angles and evolutionary residue coupling information with the pairwise Hidden Markov Model (HMM) based profile alignment method to improve profile-profile alignments. The evaluation results demonstrate that adding predicted relative solvent accessibility and torsion angle information improves the accuracy of profile-profile alignments. The evolutionary residue coupling information is helpful in some cases, but its contribution to the improvement is not consistent. Incorporating the new structural information such as predicted solvent accessibility and torsion angles into the profile-profile alignment is a useful way to improve pairwise profile-profile alignment methods.	accessibility;alignment;amino acid sequence;hidden markov model;markov chain;phylogenetics;protein function prediction;protein structure prediction;sequence database;torsion (gastropod)	Xin Deng;Jianlin Cheng	2014		10.1186/1471-2105-15-252	consensus sequence;computational biology;biology;markov chain;structural alignment;dna microarray;multiple sequence alignment;bioinformatics;sequence analysis;sequence alignment;protein structure prediction;peptide sequence;protein function prediction;alignment-free sequence analysis;phylogenetics	Comp.	9.680507284371163	-57.79484573350607	99483
221d44f8886d96229e27e775d7b1917bf095650c	slim: a sliding linear model for estimating the proportion of true null hypotheses in datasets with dependence structures	linear model;dependence structure	MOTIVATION The pre-estimate of the proportion of null hypotheses (π(0)) plays a critical role in controlling false discovery rate (FDR) in multiple hypothesis testing. However, hidden complex dependence structures of many genomics datasets distort the distribution of p-values, rendering existing π(0) estimators less effective.   RESULTS From the basic non-linear model of the q-value method, we developed a simple linear algorithm to probe local dependence blocks. We uncovered a non-static relationship between tests' p-values and their corresponding q-values that is influenced by data structure and π(0). Using an optimization framework, these findings were exploited to devise a Sliding Linear Model (SLIM) to more reliably estimate π(0) under dependence. When tested on a number of simulation datasets with varying data dependence structures and on microarray data, SLIM was found to be robust in estimating π(0) against dependence. The accuracy of its π(0) estimation suggests that SLIM can be used as a stand-alone tool for prediction of significant tests.   AVAILABILITY The R code of the proposed method is available at http://aspendb.uga.edu/downloads for academic use.	algorithm;data dependency;data structure;dependence;distortion;estimated;false discovery rate;linear model;mathematical optimization;microarray;nonlinear system;null value;r language;simulation	Hong-Qiang Wang;Lindsey K. Tuominen;Chung-Jui Tsai	2011	Bioinformatics	10.1093/bioinformatics/btq650	biology;econometrics;linear model;data mining;mathematics;statistics	Comp.	4.272179438156011	-52.71130485881375	99507
e8dcf941d3d01077a2909f8a09f04c97edfa8946	a pathway based model of retinoid dependent growth arrest and differentiation			gene regulatory network	Shobha Gupta;T. K. Basak;S. K. Chaudhary	2010			retinoid;cancer research;biology	EDA	2.46813794429289	-64.03498860626394	99516
a0e7cfa94955ca0d258c85a2d47f8119c783792a	putative chitin synthases from branchiostoma floridae show extracellular matrix-related domains and mosaic structures	discoidin domain;extracellular matrix;chitin synthase;branchiostoma floridae	The transition from unicellular to multicellular life forms requires the development of a specialized structural component, the extracellular matrix (ECM). In Metazoans, there are two main supportive systems, which are based on chitin and collagen/hyaluronan, respectively. Chitin is the major constituent of fungal cell walls and arthropod exoskeleton. However, presence of chitin/chitooligosaccharides has been reported in lower chordates and during specific stages of vertebrate development. In this study, the occurrence of chitin synthases (CHSs) was investigated with a bioinformatics approach in the cephalochordate Branchiostoma floridae, in which the presence of chitin was initially reported in the skeletal rods of the pharyngeal gill basket. Twelve genes coding for proteins containing conserved amino acid residues of processive glycosyltransferases from GT2 family were found and 10 of them display mosaic structures with novel domains never reported previously in a chitin synthase. In particular, the presence of a discoidin (DS) and a sterile alpha motif (SAM) domain was found in nine identified proteins. Sequence analyses and homology modelling suggest that these domains might interact with the extracellular matrix and mediate protein-protein interaction. The multi-domain putative chitin synthases from B. floridae constitute an emblematic example of the explosion of domain innovation and shuffling which predate Metazoans.	amino acids;arthropods;bioinformatics;cell wall;chitin synthase;chordata;dec alpha;extracellular matrix;homologous gene;homology (biology);homology modeling;hyaluronan;infertility;lopes (exoskeleton);lancelets;mosaic organism;numerous;pharyngeal structure;pierre robin syndrome;prostaglandin-e synthases;rod photoreceptors;sequence analysis;sterile alpha motif;structural element;walls of a building;glycosyltransferase;protein protein interaction	Gea Guerriero	2012		10.1016/j.gpb.2012.07.003	biology;extracellular matrix;botany;genetics;anatomy	Comp.	5.58036333280604	-62.57058916380535	99583
bde0961467d83e8b29e596b367894437470e502f	the development of a comparison approach for illumina bead chips unravels unexpected challenges applying newest generation microarrays	databases genetic;computational biology bioinformatics;chip;blood sampling;performance analysis;algorithms;humans;combinatorial libraries;computational biology;computer appl in life sciences;gene expression profiling;oligonucleotide array sequence analysis;t lymphocyte;microarrays;bioinformatics;in silico	The MAQC project demonstrated that microarrays with comparable content show inter- and intra-platform reproducibility. However, since the content of gene databases still increases, the development of new generations of microarrays covering new content is mandatory. To better understand the potential challenges updated microarray content might pose on clinical and biological projects we developed a methodology consisting of in silico analyses combined with performance analysis using real biological samples. Here we clearly demonstrate that not only oligonucleotide design but also database content and annotation strongly influence comparability and performance of subsequent generations of microarrays. Additionally, using human blood samples and purified T lymphocyte subsets as two independent examples, we show that a performance analysis using biological samples is crucial for the assessment of consistency and differences. This study provides an important resource assisting investigators in comparing microarrays of updated content especially when working in a clinical or regulatory setting.	database;lymphocyte subset;mandatory - hl7definedroseproperty;microarray;profiling (computer programming)	Daniela Eggle;Svenja Debey-Pascher;Marc Beyer;Joachim L. Schultze	2008	BMC Bioinformatics	10.1186/1471-2105-10-186	computational biology;chip;biology;molecular biology;dna microarray;computer science;bioinformatics;gene expression profiling	Comp.	4.707259502298163	-55.340313926077776	99616
487f13e6f6bb9c738085154cdbcfe0c65623061c	oncosimulr: genetic simulation with arbitrary epistasis and mutator genes in asexual populations		Summary OncoSimulR implements forward-time genetic simulations of biallelic loci in asexual populations with special focus on cancer progression. Fitness can be defined as an arbitrary function of genetic interactions between multiple genes or modules of genes, including epistasis, restrictions in the order of accumulation of mutations, and order effects. Mutation rates can differ among genes, and can be affected by (anti)mutator genes. Also available are sampling from simulations (including single-cell sampling), plotting the genealogical relationships of clones and generating and plotting fitness landscapes.   Availability and Implementation Implemented in R and C ++, freely available from BioConductor for Linux, Mac and Windows under the GNU GPL license. Version 2.5.9 or higher available from: http://www.bioconductor.org/packages/devel/bioc/html/OncoSimulR.html . GitHub repository at: https://github.com/rdiaz02/OncoSimul.   Contact ramon.diaz@iib.uam.es.   Supplementary information Supplementary data are available at Bioinformatics online.	bioconductor;bioinformatics;color gradient;fitness function;gnu;geographic information systems;il31ra gene;interaction;linux;microsoft windows;mutation;mutator method;population;r programming language;r language;sampling (signal processing);sampling - surgical action;simulation;tree accumulation	Ramón Díaz-Uriarte	2017		10.1093/bioinformatics/btx077	biology;genetics;evolutionary biology	Comp.	-2.289448348300698	-56.33766977344136	99735
ad652d40b1ba6da1da8139c7b0580d52dc068980	rfrcdb-sirna: improved design of sirnas by random forest regression model coupled with database searching	rna interference;non linear regression;phosphoinositide 3 kinase;regression model;quantitative estimation;machine learning;indexation;random forest;gene silencing;support vector machine;random forest regression rfr;database search;nucleic acid;sirna efficacy	Although the observations concerning the factors which influence the siRNA efficacy give clues to the mechanism of RNAi, the quantitative prediction of the siRNA efficacy is still a challenge task. In this paper, we introduced a novel non-linear regression method: random forest regression (RFR), to quantitatively estimate siRNAs efficacy values. Compared with an alternative machine learning regression algorithm, support vector machine regression (SVR) and four other score-based algorithms [A. Reynolds, D. Leake, Q. Boese, S. Scaringe, W.S. Marshall, A. Khvorova, Rational siRNA design for RNA interference, Nat. Biotechnol. 22 (2004) 326-330; K. Ui-Tei, Y. Naito, F. Takahashi, T. Haraguchi, H. Ohki-Hamazaki, A. Juni, R. Ueda, K. Saigo, Guidelines for the selection of highly effective siRNA sequences for mammalian and chick RNA interference, Nucleic Acids Res. 32 (2004) 936-948; A.C. Hsieh, R. Bo, J. Manola, F. Vazquez, O. Bare, A. Khvorova, S. Scaringe, W.R. Sellers, A library of siRNA duplexes targeting the phosphoinositide 3-kinase pathway: determinants of gene silencing for use in cell-based screens, Nucleic Acids Res. 32 (2004) 893-901; M. Amarzguioui, H. Prydz, An algorithm for selection of functional siRNA sequences, Biochem. Biophys. Res. Commun. 316 (2004) 1050-1058) our RFR model achieved the best performance of all. A web-server, RFRCDB-siRNA (http://www.bioinf.seu.edu.cn/siRNA/index.htm), has been developed. RFRCDB-siRNA consists of two modules: a siRNA-centric database and a RFR prediction system. RFRCDB-siRNA works as follows: (1) Instead of directly predicting the gene silencing activity of siRNAs, the service takes these siRNAs as queries to search against the siRNA-centric database. The matched sequences with the exceeding the user defined functionality value threshold are kept. (2) The mismatched sequences are then processed into the RFR prediction system for further analysis.	bare machine;call of duty: black ops;cell nucleus;gene silencing;gene regulatory network;interference (communication);machine learning;mammals;network address translation;nonlinear system;nucleic acids;persicaria sieboldii;phosphatidylinositols;rna interference;rna, small interfering;random forest;regression analysis;server (computing);support vector machine;tei i01800;tomotaka takahashi;total peripheral resistance;web server;algorithm;conversion of ds sirna to ss sirna involved in chromatin silencing by small rna	Peng Jiang;Haonan Wu;Yao Da;Fei Sang;Jiawei Wei;Xiao Sun;Zuhong Lu	2007	Computer methods and programs in biomedicine	10.1016/j.cmpb.2007.06.001	random forest;support vector machine;nucleic acid;database search engine;gene silencing;computer science;bioinformatics;rna interference;machine learning;data mining;regression analysis;nonlinear regression	ML	1.256322042902147	-57.46955272437838	99832
f0872fe27aee8442ed1c63c1a0f38abd21bd752a	repetitive sequences in plant nuclear dna: types, distribution, evolution and function	plants;repetitive sequences;tandem;cell nucleus;concerted evolution;repetitive sequences nucleic acid;review repetitive sequences;biological evolution;dispersed;satellites;dna plant;chromosomes plant;next generation sequencing	"""Repetitive DNA sequences are a major component of eukaryotic genomes and may account for up to 90% of the genome size. They can be divided into minisatellite, microsatellite and satellite sequences. Satellite DNA sequences are considered to be a fast-evolving component of eukaryotic genomes, comprising tandemly-arrayed, highly-repetitive and highly-conserved monomer sequences. The monomer unit of satellite DNA is 150-400 base pairs (bp) in length. Repetitive sequences may be species- or genus-specific, and may be centromeric or subtelomeric in nature. They exhibit cohesive and concerted evolution caused by molecular drive, leading to high sequence homogeneity. Repetitive sequences accumulate variations in sequence and copy number during evolution, hence they are important tools for taxonomic and phylogenetic studies, and are known as """"tuning knobs"""" in the evolution. Therefore, knowledge of repetitive sequences assists our understanding of the organization, evolution and behavior of eukaryotic genomes. Repetitive sequences have cytoplasmic, cellular and developmental effects and play a role in chromosomal recombination. In the post-genomics era, with the introduction of next-generation sequencing technology, it is possible to evaluate complex genomes for analyzing repetitive sequences and deciphering the yet unknown functional potential of repetitive sequences."""	alu elements;base pairing;biological evolution;biopolymer sequencing;cumulative trauma disorders;dna, satellite;genome;genomics;genus (mathematics);massively-parallel sequencing;minisatellite repeats;nuclear deoxyribonucleic acid;phylogenetics;repetitive region;monomer	Shweta Mehrotra;Vinod Goyal	2014		10.1016/j.gpb.2014.07.003	concerted evolution;biology;dna sequencing;cot analysis;bioinformatics;conserved sequence;genetics;satellite;interspersed repeat	Comp.	4.4887564347000986	-62.1901637539408	99936
4e80ad27f34ec3b34a50552771f1333a482b0ddb	update on activities at the universal protein resource (uniprot) in 2013		The mission of the Universal Protein Resource (UniProt) (http://www.uniprot.org) is to support biological research by providing a freely accessible, stable, comprehensive, fully classified, richly and accurately annotated protein sequence knowledgebase. It integrates, interprets and standardizes data from numerous resources to achieve the most comprehensive catalogue of protein sequences and functional annotation. UniProt comprises four major components, each optimized for different uses, the UniProt Archive, the UniProt Knowledgebase, the UniProt Reference Clusters and the UniProt Metagenomic and Environmental Sequence Database. UniProt is produced by the UniProt Consortium, which consists of groups from the European Bioinformatics Institute (EBI), the SIB Swiss Institute of Bioinformatics (SIB) and the Protein Information Resource (PIR). UniProt is updated and distributed every 4 weeks and can be accessed online for searches or downloads.	amino acid sequence;annotation;archive;bioinformatics;classification;consortium;external bus interface;geographic information systems;knowledge bases;knowledge base;metagenomics;peptide sequence;protein information resource;sequence database;service implementation bean;uniprot;universal protein resource	The Uniprot Consortium	2013		10.1093/nar/gks1068		Comp.	-2.7427618341613753	-61.381730077459885	100007
ac2b3ea8a4eded06f6fd69c72b63b78fe0156d6e	regscan: a gwas tool for quick estimation of allele effects on continuous traits and their combinations	data interpretation statistical;genome wide association study;gene frequency;humans;computational biology;linear models	UNLABELLED Genome-wide association studies are becoming computationally more demanding with the growing amounts of data. Combinatorial traits can increase the data dimensions beyond the computational capabilities of the current tools. We addressed this issue by creating an application for quick association analysis that is ten to hundreds of times faster than the leading fast methods. Our tool (RegScan) is designed for performing basic linear regression analysis with continuous traits maximally fast on large data sets. RegScan specifically targets association analysis of combinatorial traits in metabolomics. It can both generate and analyze the combinatorial traits efficiently. RegScan is capable of analyzing any number of traits together without the need to specify each trait individually. The main goal of the article is to show that RegScan can be the preferred analytical tool when large amounts of data need to be analyzed quickly using the allele frequency test.   AVAILABILITY Precompiled RegScan (all major platforms), source code, user guide and examples are freely available at www.biobank.ee/regscan.   REQUIREMENTS Qt 4.4.3 or newer for dynamic compilations.	addresses (publication format);dimensions;disease response domain;eaf2 gene;gene frequency;gene expression profiling;genome-wide association study;health services research;mental association;metabolomics;nih roadmap initiative tag;regression analysis;source code;trait	Toomas Haller;Mart Kals;Tönu Esko;Reedik Mägi;Krista Fischer	2013		10.1093/bib/bbt066	genome-wide association study;biology;simulation;computer science;bioinformatics;allele frequency;linear model;data mining;genetics	Comp.	2.6334307878424648	-53.74674741842786	100174
5390f7f79cbbe03f2103372dee37393f534b5bad	on the asymmetry of the residue compositions of the binding sites on protein surfaces	sequence analysis in binding sites;binding site;protein data bank;ligand binding sites on proteins	"""By screening all the ligand binding sites in the Protein Data Bank, we have found that while it is geometrically possible that a loop, formed from a protein chain with residues ZYX, would """"impersonate"""" another chain-loop with residues XYZ by a simple twisting of either the loop or the bound ligand, it almost never happens. This fact is rather surprising, and implies a notable asymmetry, since (i) loops in the folded proteins sometimes can be flexible enough to be twisted, but (ii) ligands are almost always extremely mobile before binding to the protein, therefore they can turn around and bind to residue-sequence ZYX as well. Data availability: The supplementary Table 3 lists the appearances of the residue-sequences and their inverses in the binding sites of the whole PDB, and is available at http://www.worldscient.com/jbcb/."""	binding sites;composition;polypeptides;protein data bank;scanning;sex hormone-binding globulin;staphylococcal protein a;terabyte;twisted;xyz file format;zyx gene;ligands activity;tertiary	Gábor Iván;Zoltan Szabadka;Vince Grolmusz	2009	Journal of bioinformatics and computational biology	10.1142/S0219720009004394	crystallography;biology;biochemistry;chemistry;protein data bank;bioinformatics;binding site;a-site;cooperative binding;binding protein	Comp.	4.363030951133753	-64.53263159182917	100190
30c93c783c01be78d111c3934d796b9b41d98a7c	an ultrasensitive sorting mechanism for egf receptor endocytosis	simulation and modeling;signaling network;epidermal growth factor egf receptor;binding competitive;coated pits cell membrane;egf receptor;systems biology;epidermal growth factor;signal transduction;physiological cellular and medical topics;models biological;computational biology bioinformatics;transport vesicles;endocytosis;mathematical model;protein binding;algorithms;receptor epidermal growth factor;clathrin;point of view;kinetics;steady state;bioinformatics	The Epidermal Growth Factor (EGF) receptor has been shown to internalize via clathrin-independent endocytosis (CIE) in a ligand concentration dependent manner. From a modeling point of view, this resembles an ultrasensitive response, which is the ability of signaling networks to suppress a response for low input values and to increase to a pre-defined level for inputs exceeding a certain threshold. Several mechanisms to generate this behaviour have been described theoretically, the underlying assumptions of which, however, have not been experimentally demonstrated for the EGF receptor internalization network. Here, we present a mathematical model of receptor sorting into alternative pathways that explains the EGF-concentration dependent response of CIE. The described mechanism involves a saturation effect of the dominant clathrin-dependent endocytosis pathway and implies distinct steady-states into which the system is forced for low vs high EGF stimulations. The model is minimal since no experimentally unjustified reactions or parameter assumptions are imposed. We demonstrate the robustness of the sorting effect for large parameter variations and give an analytic derivation for alternative steady-states that are reached. Further, we describe extensibility of the model to more than two pathways which might play a role in contexts other than receptor internalization. Our main result is that a scenario where different endocytosis routes consume the same form of receptor corroborates the observation of a clear-cut, stimulus dependent sorting. This is especially important since a receptor modification discriminating between the pathways has not been found experimentally. The model is not restricted to EGF receptor internalization and might account for ultrasensitivity in other cellular contexts.	clathrin;computability in europe;countercurrent electrophoresis measurement;egfr protein, human;endocytosis;epidermal growth factor receptor;experiment;extensibility;f factor;gene regulatory network;mathematical model;mathematics;population parameter;sorting	Hannah Schmidt-Glenewinkel;Ivayla Vacheva;Daniela Hoeller;Ivan Dikic;Roland Eils	2007	BMC Systems Biology	10.1186/1752-0509-2-32	clathrin;biology;endocytosis;plasma protein binding;molecular biology;cell biology;bioinformatics;mathematical model;immunology;steady state;systems biology;signal transduction;kinetics	ML	7.701782540284767	-63.79510261305297	100222
06b64ef826c94e6070c4534b47d806ccad6380b0	www.rnaworkbench.com: a new program for analyzing rna interference	software;rna interference;software tool;sirna sequence rules;rna secondary structure;sirna design;short interfering;mrna secondary structures;secondary structure;gene silencing;gene targeting;rna small interfering;algorithms;molecular sequence data;sequence alignment;sequence analysis rna;base sequence	RNA interference (RNAi) has become an important tool to study and utilize gene silencing by introducing short interfering RNA (siRNA). In order to predict the most efficient siRNAs, a new software tool, RNA Workbench (RNAWB), has been designed and is freely available (after registration) on http://www.rnaworkbench.com. In addition to the standard selection rules, RNAWB includes the possibility of statistical analyses of the applied selection rules (criteria). The role of RNA secondary structures in the RNA interference process as well as the application of sequence rules are discussed to show the applicability of the software.	gene silencing;interference (communication);programming tool;rna interference;rna, small interfering;rule (guideline);selection rule;workbench	Radka Svobodová Vareková;Ivan Bradác;Martin Plchút;Michal Skrdla;Michael Wacenovsky;Helmuth Mahr;Georg Mayer;Herbert Tanner;Hermann Brugger;Josef Withalm;Peter Lederer;Heinrich J. Huber;Gerhard Gierlinger;Ronald Graf;Hakim Tafer;Ivo L. Hofacker;Peter Schuster;Martin Polcík	2008	Computer methods and programs in biomedicine	10.1016/j.cmpb.2007.12.001	gene silencing;bioinformatics;rna interference;gene targeting;sequence alignment;nucleic acid secondary structure;protein secondary structure	Comp.	-0.3643891534884405	-57.58110925316095	100276
80f749b75d3aad165e1111455963ff808db96905	computational systems biology and in silico modeling of the human microbiome		The human microbiome is a complex biological system with numerous interacting components across multiple organizational levels. The assembly, ecology and dynamics of the microbiome and its contribution to the development, physiology and nutrition of the host are clearly affected not only by the set of genes or species in the microbiome but also by the way these genes are linked across numerous pathways and by the interactions between the various species. To date, however, most studies of the human microbiome have focused on characterizing the composition of the microbiome and on comparative analyses, whereas significantly less effort has been directed at elucidating, characterizing and modeling these interactions and on studying the microbiome as a complex, interconnected and cohesive system. Here, specifically, I highlight the pressing need for the development of predictive system-level models and for a system-level understanding of the microbiome, and discuss potential computational frameworks for metagenomic-based modeling of the microbiome at the cellular, ecological and supra-organismal level. I review some preliminary attempts at constructing such models and examine the challenges and hurdles that such modeling efforts face. I also discuss possible future applications and research avenues that such metagenomic systems biology and predictive system-level models may facilitate.	biological system;computation;ecology;interaction;metagenomics;microbiome;modelling biological systems;organism;supra, inc.;systems biology;physiological aspects	Elhanan Borenstein	2012	Briefings in bioinformatics	10.1093/bib/bbs022	biology;bioinformatics;ecology	Comp.	6.09423427366338	-60.78548454899528	100387
827b202dd5d1e036f58f2965163be5cfa84998cc	small rna database	world wide web;rna;bacteria	The small RNA database is a compilation of all the small size RNA sequences available to date, including nuclear, nucleolar, cytoplasmic and mitochondria small RNAs from eukaryotic organisms and small RNAs from prokaryotic cells as well as viruses. Currently, approximately 600 small RNA sequences are in our database. It also gives the sources of individual RNAs and their GenBank accession numbers. The small RNA database can be accessed through the WWW (World Wide Web). Our WWW URL address is: http://mbcr.bcm.tmc. edu/smallRNA/smallrna.html . The new small RNA sequences published since our last compilation are listed in this paper (Table 1).		Jian Hua Gu;Yahua Chen;Ram Reddy	1998	Nucleic acids research	10.1093/nar/26.1.160	biology;genbank;the internet;rna;bacteria;bioinformatics;genetics	DB	-1.9578580623135944	-60.34544274171446	100395
09b6647eb9f1e058f81ca65491a3a5909210dfee	the database of the smallest known auto-replicable rna species: viroids and viroid-like rnas	rna;catalysis;viroids;rna viral;databases factual;open reading frames	This is an online database in order to facilitate research on viroid, viroid-like RNAs and human hepatitis delta virus by presenting a large number of sequences and related data in a comprehensive and user-friendly format (e.g., position of their self-catalytic domains, open reading frame, prediction of the most stable secondary structures, etc.). This online database is available on the WWW at http://www.callisto.si. usherb.ca/jpperra	catalytic domain;hepatitis d infection;hepatitis delta virus;open reading frame;rna;reading frames (nucleotide sequence);usability;viroids;www	Martin Pelchat;Patrick Deschênes;Jean-Pierre Perreault	2000	Nucleic acids research	10.1093/nar/28.1.179	open reading frame;biology;catalysis;rna;bioinformatics;virology;genetics	DB	-0.979405181970397	-60.0912123385334	100698
12c9355c811ad1849b83cd029b464042f9e19a03	imap: a database-driven utility to integrate and access the genetic and physical maps of maize	genetique;base relacional dato;representation graphique;base donnee;affichage;spermatophyta;maize;gramineae;angiospermae;visualizacion;genetica;bacterie;user interface;mapa fisico;database;molecular marker;base dato;bioinformatique;genetic map;result;relational database;genetics;zea mays;bacterial artificial chromosome;display;monocotyledones;base donnee relationnelle;grafo curva;resultado;carte physique;bacteria;resultat;bioinformatica;physical map;graphics;bioinformatics	MOTIVATION Because of the unique biological features, a bioinformatic platform for the integrated genetic and physical map of maize is required for storing, integrating, accessing and visualizing the underlying data.   RESULTS The goal of the Maize Mapping Project is to develop a fully integrated genetic and physical map for maize. To display this integrated map, we have developed iMap. iMap has three main components: a relational database (iMapDB), a map graphic browser (iMap Viewer) and a search utility (iMap Search). iMapDB is populated with current genetic and physical map data, describing relationships among genetic loci, molecular markers and bacterial artificial chromosome (BAC) contigs. The database also contains integrated information produced by applying a set of anchoring rules to assign BAC contigs to specific locations on the genetic map. The iMap Viewer and iMap Search functions are combined in the user interface to allow viewing and retrieving many types of genetic and physical map data. The iMap Viewer features side-by-side chromosome-based displays of the genetic map and associated BAC contigs. For each genetic locus, information about marker type or contig can be viewed via pop-up windows that feature links to external data resources. Searches can be conducted for genetic locus, probe or sequence accession number; search results include relevant map positions, anchored BAC contigs and links to the graphical display of relevant chromosomes. iMap can be accessed at http://www.maizemap.org   AVAILABILITY The iMap utility package is available for non-commercial use upon request from the authors.	accession number (identifier);accession number (bioinformatics);bacterial artificial chromosomes;batman: arkham city;bio-informatics;bioinformatics;chromosomes, artificial;genetic loci;graphical user interface;hereditary diseases;infographic;locus;map;microsoft windows;molecular marker;population;relational database;rule (guideline);user interface device component;web search engine	Zhiwei Fang;Karen C. Cone;Hector Sanchez-Villeda;Mary L. Polacco;Michael D. McMullen;Steven G. Schroeder;Jack M. Gardiner;Georgia L. Davis;Seth A. Havermann;Young-Sun Yim;Irie Vroh-Bi;Edward H. Coe	2003	Bioinformatics	10.1093/bioinformatics/btg289	biology;bacteria;relational database;computer science;bioinformatics;graphics;bacterial artificial chromosome;user interface;genetics	Comp.	-2.708676994113315	-59.46572870905643	100818
393a55bd17c1c8046f5c0c93bb45f49d223f38f7	identifying overrepresented concepts in gene lists from literature: a statistical approach based on poisson mixture model	genes;statistical approach;controlled vocabulary;expression pattern;interaction analysis;statistical method;computational biology bioinformatics;large scale;mixture model;models statistical;algorithms;combinatorial libraries;computational biology;computer appl in life sciences;gene expression profiling;microarrays;bioinformatics;gene ontology	Large-scale genomic studies often identify large gene lists, for example, the genes sharing the same expression patterns. The interpretation of these gene lists is generally achieved by extracting concepts overrepresented in the gene lists. This analysis often depends on manual annotation of genes based on controlled vocabularies, in particular, Gene Ontology (GO). However, the annotation of genes is a labor-intensive process; and the vocabularies are generally incomplete, leaving some important biological domains inadequately covered. We propose a statistical method that uses the primary literature, i.e. free-text, as the source to perform overrepresentation analysis. The method is based on a statistical framework of mixture model and addresses the methodological flaws in several existing programs. We implemented this method within a literature mining system, BeeSpace, taking advantage of its analysis environment and added features that facilitate the interactive analysis of gene sets. Through experimentation with several datasets, we showed that our program can effectively summarize the important conceptual themes of large gene sets, even when traditional GO-based analysis does not yield informative results. We conclude that the current work will provide biologists with a tool that effectively complements the existing ones for overrepresentation analysis from genomic experiments. Our program, Genelist Analyzer, is freely available at: http://workerbee.igb.uiuc.edu:8080/BeeSpace/Search.jsp	addresses (publication format);alloy analyzer;annotation;complement system proteins;controlled vocabulary;departure - action;experiment;gene ontology;gene prediction;information;mixture model;primary source	Xin He;Moushumi Sen Sarma;Xu Ling;Brant W. Chee;ChengXiang Zhai;Bruce R. Schatz	2009		10.1186/1471-2105-11-272	biology;controlled vocabulary;dna microarray;computer science;bioinformatics;data science;gene;mixture model;data mining;gene expression profiling	Comp.	3.481322313882308	-55.442614832729774	100889
08135125c00fbf9947f4203763eb763ee3eebf59	structural and energetic determinants of tyrosylprotein sulfotransferase sulfation specificity	static electricity;peptides;sulfotransferases;hiv antibodies;tyrosine;models molecular;protein processing post translational;protein binding;protein unfolding;membrane proteins	MOTIVATION Tyrosine sulfation is a type of post-translational modification (PTM) catalyzed by tyrosylprotein sulfotransferases (TPST). The modification plays a crucial role in mediating protein-protein interactions in many biologically important processes. There is no well-defined sequence motif for TPST sulfation, and the underlying determinants of TPST sulfation specificity remains elusive. Here, we perform molecular modeling to uncover the structural and energetic determinants of TPST sulfation specificity.   RESULTS We estimate the binding affinities between TPST and peptides around tyrosines of both sulfated and non-sulfated proteins to differentiate them. We find that better differentiation is achieved after including energy costs associated with local unfolding of the tyrosine-containing peptide in a host protein, which depends on both the peptide's secondary structures and solvent accessibility. Local unfolding renders buried peptide-with ordered structures-thermodynamically available for TPST binding. Our results suggest that both thermodynamic availability of the peptide and its binding affinity to the enzyme are important for TPST sulfation specificity, and their interplay results into great variations in sequences and structures of sulfated peptides. We expect our method to be useful in predicting potential sulfation sites and transferable to other TPST variants. Our study may also shed light on other PTM systems without well-defined sequence and structural specificities.   AVAILABILITY AND IMPLEMENTATION All the data and scripts used in the work are available at http://dlab.clemson.edu/research/Sulfation.	accessibility;expect;genetic translation process;phentolamine;polynomial texture mapping;post-translational protein processing;processor affinity;rendering (computer graphics);sensitivity and specificity;sequence motif;somatomedins;thermodynamics;tyrosine;unfolding (dsp implementation);molecular modeling;protein protein interaction;sulfotransferase	Praveen Nedumpully-Govindan;Lin Li;Emil Alexov;Mark A. Blenner;Feng Ding	2014	Bioinformatics	10.1093/bioinformatics/btu309	biology;biochemistry;plasma protein binding;static electricity;bioinformatics;unfolded protein response;membrane protein	Comp.	4.0275739715298275	-60.615387182464126	100946
e5634f98315b8536d09a751834f9aff415f2f335	a multi-layer recovery scheme in ason/gmpls networks	microarray data;belief networks;bayesian network;microarray gene expression;discrete data;inferred gene network;gene network;gene expression data;gene interactions inferred gene network cell cycle bayesian network microarray gene expression;genetics;gene expression bayesian methods graphical models organisms biological systems proteins genomics bioinformatics cells biology fungi;gene expression;qa75 electronic computers computer science;biological activity;gene interactions;cell cycle	The explosive growth of Internet traffic has led to a dramatic increase in demand for data transmission capacity, which has spurred tremendous research activities in optical transport networks (OTNs) such as automatically switched optical networks (ASON) and related control protocols. To provide high resilience against failures, OTNs must have an ability to maintain an acceptable level of service during network failures. Fast and resource optimized light- path restoration strategies are urgent requirements for the near future OTN with a generalized multi-protocol label switching (GMPLS) control plane. Our objective in this paper is to presents a multi-layer recovery scheme that guarantees fast and efficient recovery of lightpaths in ASON/GMPLS networks. It includes concepts as well as systematic procedures of the proposed scheme for multilayer recovery in ASON/GMPLS networks.	algorithm;automatically switched optical network;blocking (computing);circuit restoration;control plane;erlang (unit);generalized multi-protocol label switching;internet;interrupt;layer (electronics);multiprotocol label switching;requirement;seamless3d	Hyuncheol Kim;Younghwa Kim;Seong-Jin Ahn;Kwangjoon Kim	2007	2007 International Conference on Computational Science and its Applications (ICCSA 2007)	10.1109/ICCSA.2007.79	microarray analysis techniques;gene regulatory network;gene expression;bioinformatics;cell cycle;biological activity;bayesian network;gene expression profiling	HPC	7.118584091584763	-58.167667424260635	101438
afeb5533f8675ecf8c05bc0f28c9e15af265ed3b	ehpnet: food, drugs and more	software;alternative oxidase;protein family;protein structure secondary;membrane transport proteins;amino acid sequence;binding sites;conserved sequence;article letter to editor;protein structure;models molecular;proteins;sequence homology amino acid;amino acids;algorithms;homology modeling;molecular sequence data;sequence alignment;multiple sequence alignment;vu;computational biology;sequence analysis protein;multiple alignment	Multiple sequence alignments are often used for the identification of key specificity-determining residues within protein families. We present a web server implementation of the Sequence Harmony (SH) method previously introduced. SH accurately detects subfamily specific positions from a multiple alignment by scoring compositional differences between subfamilies, without imposing conservation. The SH web server allows a quick selection of subtype specific sites from a multiple alignment given a subfamily grouping. In addition, it allows the predicted sites to be directly mapped onto a protein structure and displayed. We demonstrate the use of the SH server using the family of plant mitochondrial alternative oxidases (AOX). In addition, we illustrate the usefulness of combining sequence and structural information by showing that the predicted sites are clustered into a few distinct regions in an AOX homology model. The SH web server can be accessed at www.ibi.vu.nl/programs/seqharmwww.	homologous gene;homology (biology);homology modeling;multiple sequence alignment;protein family;score;sensitivity and specificity;server (computing);staphylococcal protein a;subfamily;web server;mapped	K. Anton Feenstra;Walter Pirovano;Klaas Krab;Jaap Heringa	1996	Environmental Health Perspectives	10.1093/nar/gkm406	biology;molecular biology;multiple sequence alignment;bioinformatics;genetics	Comp.	0.5546107464812423	-59.570143048246074	101463
8b709f149586221ec23af9686b8872b84bbd3246	modelling negative feedback networks for activating transcription factor 3 predicts a dominant role for mirnas in immediate early gene regulation	dna transcription;animals;transcriptional activation;phosphorylation;gene regulation;transcription factors;models biological;endnotes;feedback physiological;activating transcription factor 3;mathematical models;myocytes cardiac;gene expression regulation;messenger rna;feedback regulation;pubications;humans;micrornas;computer simulation	Activating transcription factor 3 (Atf3) is rapidly and transiently upregulated in numerous systems, and is associated with various disease states. Atf3 is required for negative feedback regulation of other genes, but is itself subject to negative feedback regulation possibly by autorepression. In cardiomyocytes, Atf3 and Egr1 mRNAs are upregulated via ERK1/2 signalling and Atf3 suppresses Egr1 expression. We previously developed a mathematical model for the Atf3-Egr1 system. Here, we adjusted and extended the model to explore mechanisms of Atf3 feedback regulation. Introduction of an autorepressive loop for Atf3 tuned down its expression and inhibition of Egr1 was lost, demonstrating that negative feedback regulation of Atf3 by Atf3 itself is implausible in this context. Experimentally, signals downstream from ERK1/2 suppress Atf3 expression. Mathematical modelling indicated that this cannot occur by phosphorylation of pre-existing inhibitory transcriptional regulators because the time delay is too short. De novo synthesis of an inhibitory transcription factor (ITF) with a high affinity for the Atf3 promoter could suppress Atf3 expression, but (as with the Atf3 autorepression loop) inhibition of Egr1 was lost. Developing the model to include newly-synthesised miRNAs very efficiently terminated Atf3 protein expression and, with a 4-fold increase in the rate of degradation of mRNA from the mRNA/miRNA complex, profiles for Atf3 mRNA, Atf3 protein and Egr1 mRNA approximated to the experimental data. Combining the ITF model with that of the miRNA did not improve the profiles suggesting that miRNAs are likely to play a dominant role in switching off Atf3 expression post-induction.	approximation algorithm;broadcast delay;cyclic amp-dependent transcription factor atf-3;downstream (software development);elegant degradation;experiment;f factor;gene expression regulation;integrated test facility;mathematical model;medical transcription;micrornas;myocytes, cardiac;negative feedback;processor affinity;tcf3 gene;tff3 gene;transcription (software);transcription, genetic;biological signaling;protein expression	Marcus J. Tindall;Angela Clerk	2014		10.1371/journal.pcbi.1003597	computer simulation;biology;molecular biology;regulation of gene expression;bioinformatics;genetics	Comp.	6.6349433571989715	-64.35427155893784	101472
418bb4cda319bb556db905c7d2b95aeaf53e38da	modeling protein-peptide interactions using protein fragments: fitting the pieces?	computational biology bioinformatics;algorithms;combinatorial libraries;computer appl in life sciences;microarrays;bioinformatics	* Correspondence: peter.vanhee@switch.vib-vub.be VIB SWITCH laboratory, Pleinlaan 2, 1050 Brussels, Belgium Full list of author information is available at the end of the article Figure 1 Relation between intermolecular protein-peptide interface architectures (blue for receptor, green for peptide ligand) and intramolecular protein architectures from our database of monomeric proteins, BriX (red) [4]. Vanhee et al. BMC Bioinformatics 2010, 11(Suppl 10):O1 http://www.biomedcentral.com/1471-2105/11/S10/O1	bmc bioinformatics;brix;intelligent platform management interface;interaction	Peter Vanhee;François Stricher;Lies Baeten;Erik Verschueren;Luis Serrano;Frederic Rousseau;Joost Schymkowitz	2010	BMC Bioinformatics	10.1186/1471-2105-11-S10-O1	computational biology;biology;dna microarray;computer science;bioinformatics	Comp.	-2.727434599765937	-61.601955074987245	101590
354f933670c8897c5c0d24fef0359c39663c6615	cnidaria: fast, reference-free clustering of raw and assembled genome and transcriptome ngs data	animals;genomics;phylogeny;high throughput nucleotide sequencing;sequence analysis dna;computational biology bioinformatics;cluster analysis;internet;genome;algorithms;transcriptome;user computer interface;sequence analysis rna;solanaceae;insects;computer appl in life sciences;microarrays;bioinformatics	Identification of biological specimens is a requirement for a range of applications. Reference-free methods analyse unprocessed sequencing data without relying on prior knowledge, but generally do not scale to arbitrarily large genomes and arbitrarily large phylogenetic distances. We present Cnidaria, a practical tool for clustering genomic and transcriptomic data with no limitation on genome size or phylogenetic distances. We successfully simultaneously clustered 169 genomic and transcriptomic datasets from 4 kingdoms, achieving 100 % identification accuracy at supra-species level and 78 % accuracy at the species level. CNIDARIA allows for fast, resource-efficient comparison and identification of both raw and assembled genome and transcriptome data. This can help answer both fundamental (e.g. in phylogeny, ecological diversity analysis) and practical questions (e.g. sequencing quality control, primer design).	biological specimen;cluster analysis;cnidaria;communications satellite;distance;ecosystem diversity;genome size;primer;phylogenetics;supra, inc.;transcriptome;statistical cluster	Saulo Alves Aflitos;Edouard Severing;Gabino Sanchez-Perez;Sander Peters;Hans de Jong;Dick de Ridder	2015		10.1186/s12859-015-0806-7	biology;genomics;molecular biology;the internet;dna microarray;transcriptome;computer science;bioinformatics;cluster analysis;genetics;genome	Comp.	0.6375399957871426	-56.29449083257345	101619
7f43696b8c649e57c82918ad81fa5f4b1895a300	the nextprot knowledgebase on human proteins: current status	proteome;disease;serveur institutionnel;genetic variation;internet;proteins;archive institutionnelle;open access;humans;archive ouverte unige;proteomics;cybertheses;institutional repository;databases protein;cell line	neXtProt (http://www.nextprot.org) is a human protein-centric knowledgebase developed at the SIB Swiss Institute of Bioinformatics. Focused solely on human proteins, neXtProt aims to provide a state of the art resource for the representation of human biology by capturing a wide range of data, precise annotations, fully traceable data provenance and a web interface which enables researchers to find and view information in a comprehensive manner. Since the introductory neXtProt publication, significant advances have been made on three main aspects: the representation of proteomics data, an extended representation of human variants and the development of an advanced search capability built around semantic technologies. These changes are presented in the current neXtProt update.	access network;application programming interface;bioinformatics;external bus interface;interface device component;knowledge bases;knowledge base;protein information resource;proteomics;swiss-model;server (computing);service implementation bean;stimulation (motivation);switzerland;traceability;uniprot;uniprotkb;universal protein resource;user interface;benefit;eric;nextprot	Pascale Gaudet;Pierre-André Michel;Monique Zahn-Zabal;Isabelle Cusin;Paula D. Duek;Olivier Evalet;Alain Gateau;Anne Gleizes;Mario Pereira;Daniel Teixeira;Lydie Lane;Amos Bairoch	2015		10.1093/nar/gku1178	biology;the internet;bioinformatics;genetic variation;proteome;nextprot;proteomics;genetics;cell culture	Comp.	-2.4854050833425485	-61.57128176963387	101820
d8350bc5f60dad477f8195a850915d16cbae5e42	detection of changes in gene regulatory patterns, elicited by perturbations of the hsp90 molecular chaperone complex, by visualizing multiple experiments with an animation	budding yeast;gene expression profile;health research;uk clinical guidelines;gene deletion;biological patents;regulatory network;protein complex;europe pubmed central;stress response;citation search;data mining and knowledge discovery;serveur institutionnel;genetics;computational biology bioinformatics;gene expression;microarray analysis;archive institutionnelle;uk phd theses thesis;open access;life sciences;protein protein interaction;algorithms;molecular chaperone;archive ouverte unige;cybertheses;uk research reports;medical journals;computer appl in life sciences;gene expression pattern;institutional repository;europe pmc;biomedical research;bioinformatics	To make sense out of gene expression profiles, such analyses must be pushed beyond the mere listing of affected genes. For example, if a group of genes persistently display similar changes in expression levels under particular experimental conditions, and the proteins encoded by these genes interact and function in the same cellular compartments, this could be taken as very strong indicators for co-regulated protein complexes. One of the key requirements is having appropriate tools to detect such regulatory patterns. We have analyzed the global adaptations in gene expression patterns in the budding yeast when the Hsp90 molecular chaperone complex is perturbed either pharmacologically or genetically. We integrated these results with publicly accessible expression, protein-protein interaction and intracellular localization data. But most importantly, all experimental conditions were simultaneously and dynamically visualized with an animation. This critically facilitated the detection of patterns of gene expression changes that suggested underlying regulatory networks that a standard analysis by pairwise comparison and clustering could not have revealed. The results of the animation-assisted detection of changes in gene regulatory patterns make predictions about the potential roles of Hsp90 and its co-chaperone p23 in regulating whole sets of genes. The simultaneous dynamic visualization of microarray experiments, represented in networks built by integrating one's own experimental with publicly accessible data, represents a powerful discovery tool that allows the generation of new interpretations and hypotheses.	acclimatization;anatomical compartments;animation;cluster analysis;experiment;gene expression;gene regulatory network;hsp90 heat-shock proteins;imagery;interpretation process;microarray;molecular chaperones;perturbation theory;requirement;saccharomycetales;protein protein interaction;statistical cluster	Pablo C. Echeverría;Fedor Forafonov;Deo P. Pandey;Guillaume Mühlebach;Didier Picard	2011		10.1186/1756-0381-4-15	protein–protein interaction;fight-or-flight response;chaperone;biology;microarray analysis techniques;gene expression;bioinformatics;multiprotein complex;genetics	Comp.	3.9448757677460966	-58.68685879574612	101826
0772da9c4bd627928a7ee744bd8eed7e5b75d002	a new algorithm for computing similarity between rna structures	ribonucleic acid;nucleotides;edit distance;rna structures;rna structure;pattern matching;molecular biology;secondary structure;similarity;base pair	The primary structure of a ribonucleic acid (RNA) molecule is a sequence of nucleotides (bases) over the four-letter alphabet { A , C , G , U }. The secondary or tertiary structure of an RNA is a set of base-pairs (nucleotide pairs) which form bonds between  A – U  and  C – G . For secondary structures, these bonds have been traditionally assumed to be one-to-one and non-crossing. We consider the edit distance between two RNA structures. This is a notion of similarity, introduced in [Proceedings of the Tenth Symposium on Combinatorial Pattern Matching, Lecture Notes in Computer Science, vol. 1645, Springer, Berlin, 1999, p. 281], between two RNA molecule structures taking into account the primary, the secondary and the tertiary structures. In general this problem is NP-hard for tertiary structures. In this paper, we consider this notion under some constraints. We present an algorithm and then show how to use this algorithm for practical applications.	algorithm	Gregory D. Collins;Shu-Yun Le;Kaizhong Zhang	2001	Inf. Sci.	10.1016/S0020-0255(01)00157-8	nucleic acid structure;nucleotide;rna;base pair;edit distance;similarity;bioinformatics;pattern matching;algorithm;protein secondary structure	DB	-4.213029571484081	-52.496031704931816	101875
2e0027646caee0a873e2c50b673d473d8a3eb627	sbars: fast creation of dotplots for dna sequences on different scales using ga-, gc-content		SUMMARY Structural analysis of long DNA fragments, including chromosomes and whole genomes, is one of the main challenges in modern bioinformatics. Here, we propose an original approach based on spectral methods and its implementation called SBARS (Spectral-Based Approach for Repeats Search. The main idea of our approach is that repeated DNA structures are recognized not within the nucleotide sequence directly but within the function derived from this sequence. This allows us to investigate nucleotide sequences on different scales and decrease time complexity for dotplot creation down to [Formula: see text].   AVAILABILITY AND IMPLEMENTATION Pre-compiled versions for Windows and Linux and documentation are available at http://mpyatkov.github.com/sbars/.	base sequence;bioinformatics;chromosomes;compiler;documentation;dot plot (bioinformatics);genome;linux;microsoft windows;nucleotides;spectral method;structural analysis;time complexity;version	Maxim I. Pyatkov;Anton N. Pankratov	2014	Bioinformatics	10.1093/bioinformatics/btu095		Comp.	-2.8614739523761696	-55.37627533356761	101926
167ca8af81eb03b54bcbc8dcd18403c171506172	"""selecting """"significant"""" differentially expressed genes from the combined perspective of the null and the alternative"""	science general;gene expression;alternative p values;differentially expressed gene;balanced testing	In the search for genes associated with disease, statistical analysis yields a key towards reproducible results. To avoid a plethora of type I errors, classical gene selection procedures strike a balance between magnitude and precision of observed effects in terms of p-values. Protecting false discovery rates recovers some power but still ranks genes according to classical p-values. In contrast, we propose a selection procedure driven by the concern to detect well-specified important alternatives. By summarizing evidence from the perspective of both the null and such an alternative hypothesis, genes line up in a substantially different order with different genes yielding powerful signals. A cutoff point for a measure of relative evidence which balances the standard p-value, p0, with its counterpart, p1, derived from the perspective of the target alternative, determines our gene selection. We find the cutoff point that maximizes an expected specific gain. This yields an optimal decision which exploits gene-specific variances and thus involves different type I and type II errors across genes. We show the dramatic impact of this alternative perspective on the detection of differentially expressed genes in hereditary breast cancer. Our analysis does not rely on parametric assumptions on the data.	breast cancer, familial;chamaecyparis lawsoniana;mammary neoplasms;null (sql);null value;p-value	B. Moerkerke;Els Goetghebeur	2006	Journal of computational biology : a journal of computational molecular cell biology	10.1089/cmb.2006.13.1513	biology;gene expression;bioinformatics;genetics;statistics	Comp.	5.326064494158742	-53.181510871646765	102179
26b4b8f6775e73a7b0214b573b65a770e7e88ea8	new insights into the landscape relationships of host response to bacterial pathogens	genomics;infection disease association landscape relationship host response microbiology biological characterization microorganism host transcriptional response htr network htrn htr similarity human pathogenic bacterial species cellular gene expression profile bacterial communities internal htr signature gene distinct community signatures differential gene expression pattern functional annotation host cell response bacterial infection functional gene cluster community bacterial pathogen dissimilar functional profile gwas disease related gene noninfectious human disease differential community htr bacterial pathogen infection;microorganisms cellular biophysics diseases genetics;community signatures gene expression profile host transcriptional response infection disease association;pathogens microorganisms genomics bioinformatics;microorganisms;bioinformatics;pathogens	Modern understanding of microbiology largely lays foundation in the biological characterization of microorganisms. However, the landscape relationships of host transcriptional response (HTR) to different bacterial pathogens have not yet been systematically explored. Here, we established the first generation of HTR network (HTRN) according to the HTR similarities among 21 different human pathogenic bacterial species by integrating 258 pairs of host cellular gene expression profiles upon infections. Further, the network was dissected into five bacterial communities of more consensus internal HTR. Interestingly, analysis of signature genes across different communities revealed that distinct community signatures (CS) present differential gene expression patterns. Functional annotation suggested a common feature of host cell response to bacterial infections that specific functional gene clusters (BPs and/or signaling pathways) were preferentially elicited or subverted by community bacterial pathogens. Notably, community signatures (especially key associators participating dissimilar functional profiles) were highly enriched of GWAS disease-related genes, which associated bacterial infections with common and specific non-infectious human disease(s). About 40% of the associations were confirmed by literature investigation that further indicated possible/potential association directionality. Our characterization and analysis were the first to feature differential community HTRs upon bacterial pathogen infections and suggested new perspective of understanding infection-disease associations and underlying pathogenesis.	antivirus software	Xiaoyao Yin;Lu Han;Hui Bai;Xiaochen Bo;Yun Bai;Cong Niu;Naiyang Guan;Zhigang Luo	2015	2015 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2015.7280410	genomics;bioinformatics;microorganism	Comp.	4.5775926377733205	-59.74876949047795	102185
59a597336416b4e40a4e8591dbace7de54748a45	proteomic evidence for in-frame and out-of-frame alternatively spliced isoforms in human and mouse	junctions proteins splicing mice databases bioinformatics genomics;biological patents;biomedical journals;text mining;europe pubmed central;citation search;citation networks;research articles;abstracts;open access;life sciences;clinical guidelines;full text;rest apis;protein isoform mass spectrometry dual coding genes exon skipping;orcids;europe pmc;biomedical research;bioinformatics;literature search	In order to find evidence for translation of alternatively spliced transcripts, especially those that result in a change in reading frame, we collected exon-skipping cases previously found by RNA-Seq and applied a computational approach to screen millions of mass spectra. These spectra came from seven human and six mouse tissues, five of which are the same between the two organisms: liver, kidney, lung, heart, and brain. Overall, we detected 4 percent of all exon-skipping events found in RNA-seq data, regardless of their effect on reading frame. The fraction of alternative isoforms detected did not differ between out-of-frame and in-frame events. Moreover, the fraction of identified alternative exon-exon junctions and constitutive junctions were similar. Together, our results suggest that both in-frame and out-of-frame translation may be actively used to regulate protein activity or localization.	body tissue;heart failure;liver carcinoma;open reading frame;protein isoforms;proteomics;rna;reading frames (nucleotide sequence);renal tissue;sequence number;structure of parenchyma of lung;transcript	Rodrigo Fernandes Ramalho;Sujun Li;Predrag Radivojac;Matthew W. Hahn	2018	IEEE/ACM Transactions on Computational Biology and Bioinformatics	10.1109/TCBB.2015.2480068	genomics;rna splicing;gene isoform;computer science;protein activity;bioinformatics	Comp.	5.613928335535996	-63.337554697802176	102197
f2bbe30a81cdc332a1a0f8236e765102615cdda2	detection of protein repeats using the ramanujan filter bank	complexity theory;proteins;heuristic algorithms;amino acids;filter banks;signal processing algorithms;context	Protein repeats are tandemly repeating segments within an amino acid sequence. They induce several important structural and binding properties on the protein. So far, the most successful detection schemes for such repeats have used computationally expensive techniques such as dynamic programming algorithms, HMMs, and so on. Classical DSP tools such as STFT, unfortunately, perform poorly in the presence of mutations. In this work, a novel technique is proposed based on the recently developed Ramanujan Filter Bank. Fast, accurate, and involving only simple integer computations, its performance is demonstrated on several well-known repeat families.1	algorithm;analysis of algorithms;computation;dynamic programming;filter bank;name binding;peptide sequence;short-time fourier transform	Srikanth Venkata Tenneti;Palghat P. Vaidyanathan	2016	2016 50th Asilomar Conference on Signals, Systems and Computers	10.1109/ACSSC.2016.7869058	mathematical optimization;bioinformatics;theoretical computer science;mathematics	Comp.	-1.2839373256546034	-52.491420232955996	102232
17719f6d0a983795035fe8c3465aff5b66b73fda	a comprehensive study of multiple mapping and feature selection for correction strategy in the analysis of small rnas from solid sequencing	expression profile;multiple mapping;correction strategy;feature selection;microrna mirna;high throughput;microrna;small rna;solid sequencing technology	High-throughput sequencing is a powerful tool for discovering and profiling microRNAs (miRNAs) to gain further insights into their biogenesis and function. Due to shorter size, short RNAs from deep sequencing dataset are prone to map to multiple loci with an equal number of mismatches, especially among multicopy miRNA precursors and homologous miRNA genes. Systematic analysis of SOLiD sequencing dataset showed that 37.94% short RNAs could simultaneously map to more than one miRNA precursor, and more short RNAs were found to have multiple genomic loci. Improper selection from candidate loci might lose some mapping information, influence miRNA expression profile or even mislead to identify novel miRNAs. A comprehensive study indicated several potential features for correction strategy: location and distribution of mismatches, quality values, expression profiles of multiple isomiRs (miRNA variants), miRNA* and moRs (miRNA-offset-RNAs) at candidate locus and in its flank sequence. Further studies should develop an approach to correct the widespread phenomenon of multiple mapping based on these features, and improve accuracy of profiling and discovering miRNAs.		Li Guo;Tingming Liang;Zuhong Lu	2011	Bio Systems	10.1016/j.biosystems.2011.01.004	high-throughput screening;biology;molecular biology;computer science;bioinformatics;machine learning;feature selection;genetics;microrna	Comp.	3.2813820152900512	-59.24957219934109	102388
5f12be43b14e6bafee66e0d0d5357bdbb9d32a9e	robust quantitative scratch assay		UNLABELLED The wound healing assay (or scratch assay) is a technique frequently used to quantify the dependence of cell motility-a central process in tissue repair and evolution of disease-subject to various treatments conditions. However processing the resulting data is a laborious task due its high throughput and variability across images. This Robust Quantitative Scratch Assay algorithm introduced statistical outputs where migration rates are estimated, cellular behaviour is distinguished and outliers are identified among groups of unique experimental conditions. Furthermore, the RQSA decreased measurement errors and increased accuracy in the wound boundary at comparable processing times compared to previously developed method (TScratch).   AVAILABILITY AND IMPLEMENTATION The RQSA is freely available at: http://ophid.utoronto.ca/RQSA/RQSA_Scripts.zip The image sets used for training and validation and results are available at: (http://ophid.utoronto.ca/RQSA/trainingSet.zip, http://ophid.utoronto.ca/RQSA/validationSet.zip, http://ophid.utoronto.ca/RQSA/ValidationSetResults.zip, http://ophid.utoronto.ca/RQSA/ValidationSet_H1975.zip, http://ophid.utoronto.ca/RQSA/ValidationSet_H1975Results.zip, http://ophid.utoronto.ca/RQSA/RobustnessSet.zip, http://ophid.utoronto.ca/RQSA/RobustnessSet.zip). Supplementary Material is provided for detailed description of the development of the RQSA.   CONTACT juris@ai.utoronto.ca   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.		Andrea Vargas;Marc Angeli;Chiara Pastrello;Rosanne McQuaid;Han Li;Andrea Jurisicova;Igor Jurisica	2016	Bioinformatics	10.1093/bioinformatics/btv746	real-time computing;simulation;computer science;world wide web	Comp.	-1.3989862804123365	-56.47890646339684	102504
6ffa424be198e984219099ba4464f10e4aed6332	erratum to: circular sequence comparison: algorithms and applications	physiological cellular and medical topics;computational biology bioinformatics;algorithms;bioinformatics	[This corrects the article DOI: 10.1186/s13015-016-0076-6.].	digital object identifier;algorithm	Roberto Grossi;Costas S. Iliopoulos;Robert Mercas;Nadia Pisanti;Solon P. Pissis;Ahmad Retha;Fatima Vayani	2016		10.1186/s13015-016-0084-6	computational biology;computational science;computer science;bioinformatics	DB	0.45634018417467653	-63.82444999987589	102636
126e66b8091b9c3a0fc1d3545c9fbdc0cb0d1592	protein classification into domains of life using markov chain models	markov chain models;sequence probability;training set;protein classification;different organism;test set;eukaryote model;discriminant oligopeptides;functional motif;markov chain;input sequence;eukaryotic origin;molecular biophysics;microorganisms;markov processes;odd ratio;markov chain model;singular value decomposition;proteins;tree of life;probability	It has recently been shown that oligopeptide composition allows clustering proteomes of different organisms into the main domains of life. In this paper, we go a step further by showing that, given a single protein, it is possible to predict whether it has a bacterial or eukaryotic origin with 85% accuracy, and we obtain this result after ensuring that no important homologies exist between the sequences in the test set and the sequences in the training set. To do this, we model the sequence as a Markov chain. A bacterial and an eukaryote model are produced using the training sets. Each input sequence is then classified by calculating the log-odds ratio of the sequence probability for each model. By analyzing the models obtained we extract a set of most discriminant oligopeptides, many of which are part of known functional motifs.	cluster analysis;discriminant;homology (biology);markov chain;test set	M. Francisca Zanoguera;Massimo de Francesco	2004	Proceedings. 2004 IEEE Computational Systems Bioinformatics Conference, 2004. CSB 2004.	10.1109/CSB.2004.1332481	biology;biochemistry;markov chain;bioinformatics;statistics;molecular biophysics	Vision	9.381797875737513	-55.23765051934888	102811
73152afc0173e55130c5979371a0a59a10ce1001	shortran: a pipeline for small rna-seq data analysis	software;genomics;molecular sequence annotation;data mining;rna small untranslated;arabidopsis;sequence analysis rna	UNLABELLED High-throughput sequencing currently generates a wealth of small RNA (sRNA) data, making data mining a topical issue. Processing of these large data sets is inherently multidimensional as length, abundance, sequence composition, and genomic location all hold clues to sRNA function. Analysis can be challenging because the formulation and testing of complex hypotheses requires combined use of visualization, annotation and abundance profiling. To allow flexible generation and querying of these disparate types of information, we have developed the shortran pipeline for analysis of plant or animal short RNA sequencing data. It comprises nine modules and produces both graphical and MySQL format output.   AVAILABILITY shortran is freely available and can be downloaded from http://users-mb.au.dk/pmgrp/shortran/.	biopolymer sequencing;data mining;graphical user interface;mysql;pipeline (computing);profiling (computer programming);rna;sequence number;throughput	Vikas Gupta;Katharina Markmann;Christian N. S. Pedersen;Jens Stougaard;Stig U. Andersen	2012		10.1093/bioinformatics/bts496	biology;genomics;bioinformatics;data mining;world wide web;alignment-free sequence analysis	Comp.	-1.8016739012850433	-58.41187184667699	102883
77a33ceb8b80ec41ceb58c07cba1b48247cdcb9e	de novo identification of repeat families in large genomes	human genome;source code;repetitive sequence;genome sequence	MOTIVATION De novo repeat family identification is a challenging algorithmic problem of great practical importance. As the number of genome sequencing projects increases, there is a pressing need to identify the repeat families present in large, newly sequenced genomes. We develop a new method for de novo identification of repeat families via extension of consensus seeds; our method enables a rigorous definition of repeat boundaries, a key issue in repeat analysis.   RESULTS Our RepeatScout algorithm is more sensitive and is orders of magnitude faster than RECON, the dominant tool for de novo repeat family identification in newly sequenced genomes. Using RepeatScout, we estimate that approximately 2% of the human genome and 4% of mouse and rat genomes consist of previously unannotated repetitive sequence.   AVAILABILITY Source code is available for download at http://www-cse.ucsd.edu/groups/bioinformatics/software.html	algorithm;consensus sequence;de novo transcriptome assembly;de-identification;download;plant seeds;repetitive region;source code;whole genome sequencing;orders - hl7publishingdomain	Alkes L. Price;Neil C. Jones;Pavel A. Pevzner	2005	Bioinformatics	10.1093/bioinformatics/bti1018	biology;variable number tandem repeat;human genome;whole genome sequencing;computer science;bioinformatics;genetics;source code	Comp.	0.8214367853464315	-55.308174958201796	102927
4277ba86fa1f4c2c53cb11edba99e611e66bcfe3	detecting shifts in gene regulatory networks during time-course experiments at single-time-point temporal resolution	time course;diauxic shift;network dynamics;gene regulatory network	Comprehensively understanding the dynamics of biological systems is one of the greatest challenges in biology. Vastly improved biological technologies have provided vast amounts of information that must be understood by bioinformatics and systems biology researchers. Gene regulations have been frequently modeled by ordinary differential equations or graphical models based on time-course gene expression profiles. The state-of-the-art computational approaches for analyzing gene regulations assume that their models are same throughout time-course experiments. However, these approaches cannot easily analyze transient changes at a time point, such as diauxic shift. We propose a score that analyzes the gene regulations at each time point. The score is based on the information gains of information criterion values. The method detects the shifts in gene regulatory networks (GRNs) during time-course experiments with single-time-point resolution. The effectiveness of the method is evaluated on the diauxic shift from glucose to lactose in Escherichia coli. Gene regulation shifts were detected at two time points: the first corresponding to the time at which the growth of E. coli ceased and the second corresponding to the end of the experiment, when the nutrient sources (glucose and lactose) had become exhausted. According to these results, the proposed score and method can appropriately detect the time of gene regulation shifts. The method based on the proposed score provides a new tool for analyzing dynamic biological systems. Because the score value indicates the strength of gene regulation at each time point in a gene expression profile, it can potentially infer hidden GRNs from time-course experiments.		Yoichi Takenaka;Shigeto Seno;Hideo Matsuda	2015	Journal of bioinformatics and computational biology	10.1142/S0219720015430027	biology;gene regulatory network;biotechnology;bioinformatics;network dynamics;data mining;genetics	Comp.	5.276584863077057	-58.905654620913985	102954
ae5c9fe00faa0f6d07f7e129cc699699996a0aa9	induction of wnt-inducible signaling protein-1 correlates with invasive breast cancer oncogenesis and reduced type 1 cell-mediated cytotoxic immunity: a retrospective study	genetic engineering;breast neoplasms;female;rna messenger;retrospective studies;middle aged;signal transduction;neoplasm invasiveness;ccn intercellular signaling proteins;interleukin 12;cluster analysis;proto oncogene proteins;adult;gene expression regulation neoplastic;humans;cell transformation neoplastic;computational biology;carcinogenesis;cohort studies;immunity cellular;aged;aged 80 and over	Innate and type 1 cell-mediated cytotoxic immunity function as important extracellular control mechanisms that maintain cellular homeostasis. Interleukin-12 (IL12) is an important cytokine that links innate immunity with type 1 cell-mediated cytotoxic immunity. We recently observed in vitro that tumor-derived Wnt-inducible signaling protein-1 (WISP1) exerts paracrine action to suppress IL12 signaling. The objective of this retrospective study was three fold: 1) to determine whether a gene signature associated with type 1 cell-mediated cytotoxic immunity was correlated with overall survival, 2) to determine whether WISP1 expression is increased in invasive breast cancer, and 3) to determine whether a gene signature consistent with inhibition of IL12 signaling correlates with WISP1 expression. Clinical information and mRNA expression for genes associated with anti-tumor immunity were obtained from the invasive breast cancer arm of the Cancer Genome Atlas study. Patient cohorts were identified using hierarchical clustering. The immune signatures associated with the patient cohorts were interpreted using model-based inference of immune polarization. Reverse phase protein array, tissue microarray, and quantitative flow cytometry in breast cancer cell lines were used to validate observed differences in gene expression. We found that type 1 cell-mediated cytotoxic immunity was correlated with increased survival in patients with invasive breast cancer, especially in patients with invasive triple negative breast cancer. Oncogenic transformation in invasive breast cancer was associated with an increase in WISP1. The gene expression signature in invasive breast cancer was consistent with WISP1 as a paracrine inhibitor of type 1 cell-mediated immunity through inhibiting IL12 signaling and promoting type 2 immunity. Moreover, model-based inference helped identify appropriate immune signatures that can be used as design constraints in genetically engineering better pre-clinical models of breast cancer.	antivirus software;cell signaling;cellular immunity;cluster analysis;control system;cultured cell line;flow cytometry;gene expression;genes, vif;hierarchical clustering;il12 signaling pathway;immunity, innate;inference;inhibition;interleukin-12;molecular profiling;nsa product types;non-small cell lung carcinoma;patients;promotion (action);reverse phase protein lysate microarray;tissue microarray;triple negative breast neoplasms;tumor immunity;wisp1 gene;wisp1 protein, human;cellular homeostasis;cytokine;invasive breast cancer;paracrine;physical hard work;statistical cluster	David J. Klinke	2014		10.1371/journal.pcbi.1003409	genetic engineering;interleukin 12;biology;cohort study;bioinformatics;retrospective cohort study;immunology;cluster analysis;genetics;signal transduction;carcinogenesis	Comp.	6.394651014792691	-58.50479663267994	102986
36a5de603734ad03715c98f82adde4673c3c3faa	s2cr3um: a solution to the in silico relevance, reliability & reproducibility conundrum			relevance	Sarah B. Putney;Andrew White;Janos Hajagos;Joel H. Saltz;Jonas S. Almeida;Mary M. Saltz	2016			reproducibility;in silico;biology;bioinformatics	NLP	1.1511018547012206	-64.36470087379347	103006
63a7b60daa3324f10d2061a5d97147a545ab34c4	construction of map ol-systems for developmental sequences of plant cell layers	plant morphology;computer simulation;growth analysis	C O N T E N T S 0. Introduction 1. Description and analysis of cell layer development 1.1. Maps and map L-systems 1.2. Modeling approach 2. Construction of sm-systems 2.1. Step 1: Construction of cell systems 2.1.1. Timing of cell divisions 2.1.2. Orientations of cell divisions 2.1.3. Cell systems 2.2. Step 2: Construction of a dm-system from a cell system 2.3. Step 3: Construction of an sm-system from a dm-system 3. Discussion Appendix	acorn eurocard systems;l-system	Martin J. M. de Boer	1990		10.1007/BFb0017386	biology;botany;ecology	Robotics	-0.15216297074571467	-65.62568375078416	103121
10945b9a728f2fa7f8d04d9e889e2587fba7717f	confronting two-pair primer design for enzyme-free snp genotyping based on a genetic algorithm	genotype;enzyme;satisfiability;computational biology bioinformatics;polymerase chain reaction;design method;dna primers;cost effectiveness;algorithms;genetic algorithm;primer design;combinatorial libraries;computer appl in life sciences;polymorphism single nucleotide;single nucleotide polymorphism;microarrays;bioinformatics	Polymerase chain reaction with confronting two-pair primers (PCR-CTPP) method produces allele-specific DNA bands of different lengths by adding four designed primers and it achieves the single nucleotide polymorphism (SNP) genotyping by electrophoresis without further steps. It is a time- and cost-effective SNP genotyping method that has the advantage of simplicity. However, computation of feasible CTPP primers is still challenging. In this study, we propose a GA (genetic algorithm)-based method to design a feasible CTPP primer set to perform a reliable PCR experiment. The SLC6A4 gene was tested with 288 SNPs for dry dock experiments which indicated that the proposed algorithm provides CTPP primers satisfied most primer constraints. One SNP rs12449783 in the SLC6A4 gene was taken as an example for the genotyping experiments using electrophoresis which validated the GA-based design method as providing reliable CTPP primer sets for SNP genotyping. The GA-based CTPP primer design method provides all forms of estimation for the common primer constraints of PCR-CTPP. The GA-CTPP program is implemented in JAVA and a user-friendly input interface is freely available at http://bio.kuas.edu.tw/ga-ctpp/ .	bands;ctpp;computation;electrophoresis;experiment;gallium;genetic algorithm;genotype determination;input device;interface device component;java;nitroprusside;nucleotides;primer;polymerase chain reaction;slc6a4 gene;snp array;single nucleotide polymorphism array;software release life cycle;usability;hemoglobin f bonaire-ga	Cheng-Hong Yang;Yu-Huei Cheng;Li-Yeh Chuang;Hsueh-Wei Chang	2010		10.1186/1471-2105-11-509	single-nucleotide polymorphism;biology;enzyme;molecular biology;molecular inversion probe;genetic algorithm;cost-effectiveness analysis;dna microarray;design methods;bioinformatics;polymerase chain reaction;genotype;snp genotyping;genetics;primer;satisfiability	Comp.	0.501436916741984	-56.461349906582136	103136
15eeb2e387dd17df0064235722dd7b1ac5004f63	phylogenetic inference in protein superfamilies: analysis of sh2 domains	sh2 domain;phylogenetic inference	This work focuses on the inference of evolutionary relationships in protein superfamilies, and the uses of these relationships to identify key positions in the structure, to infer attributes on the basis of evolutionary distance, and to identify potential errors in sequence annotations. Relative entropy, a distance metric from information theory, is used in combination with Dirichlet mixture priors to estimate a phylogenetic tree for a set of proteins. This method infers key structural or functional positions in the molecule, and guides the tree topology to preserve these important positions within subtrees. Minimum-description-length principles are used to determine a cut of the tree into subtrees, to identify the subfamilies in the data. This method is demonstrated on SH2-domain containing proteins, resulting in a new subfamily assignment for Src2-drome and a suggested evolutionary relationship between Nck_human and Drk_drome, Sem5_caeel, Grb2_human and Grb2_chick.	anatomy, regional;gene distance metric;inference;information theory;kullback–leibler divergence;minimum description length;phylogenetic tree;phylogenetics;sh2d3c gene;subfamily;tree (data structure);tree network	Kimmen Sjölander	1998	Proceedings. International Conference on Intelligent Systems for Molecular Biology		biology;sh2 domain;computer science;bioinformatics;pattern recognition;data mining	Comp.	3.9105639528926712	-57.548148447962376	103207
2d6527e7a2072a8ed9110e342feca09d6fb09764	a structural motif of three disulfide bridges and three beta strands in peptides			motif	Qianning Liao;Jingchu Luo;Songping Liang;Xiaocheng Gu	1998			genetics;beta hairpin;structural motif;beta sheet;molecular biology;disulfide bond;biology	NLP	3.741893676892208	-64.15554066182382	103223
bbf90864a47d9cb73e053715f520fc0b34649a4b	marv: a tool for genome-wide multi-phenotype analysis of rare variants	liverpool;computational biology bioinformatics;repository;algorithms;university;computer appl in life sciences;microarrays;bioinformatics	Genome-wide association studies have enabled identification of thousands of loci for hundreds of traits. Yet, for most human traits a substantial part of the estimated heritability is unexplained. This and recent advances in technology to produce high-dimensional data cost-effectively have led to method development beyond standard common variant analysis, including single-phenotype rare variant and multi-phenotype common variant analysis, with the latter increasing power for locus discovery and providing suggestions of pleiotropic effects. However, there are currently no optimal methods and tools for the combined analysis of rare variants and multiple phenotypes. We propose a user-friendly software tool MARV for Multi-phenotype Analysis of Rare Variants. The tool is based on a method that collapses rare variants within a genomic region and models the proportion of minor alleles in the rare variants on a linear combination of multiple phenotypes. MARV provides analyses of all phenotype combinations within one run and calculates the Bayesian Information Criterion to facilitate model selection. The running time increases with the size of the genetic data while the number of phenotypes to analyse has little effect both on running time and required memory. We illustrate the use of MARV with analysis of triglycerides (TG), fasting insulin (FI) and waist-to-hip ratio (WHR) in 4,721 individuals from the Northern Finland Birth Cohort 1966. The analysis suggests novel multi-phenotype effects for these metabolic traits at APOA5 and ZNF259, and at ZNF259 provides stronger support for association (P TG+FI = 1.8 × 10−9) than observed in single phenotype rare variant analyses (P TG = 6.5 × 10−8 and P FI = 0.27). MARV is a computationally efficient, flexible and user-friendly software tool allowing rapid identification of rare variant effects on multiple phenotypes, thus paving the way for novel discoveries and insights into biology of complex traits.	algorithmic efficiency;alleles;apolipoprotein a5 measurement;bayesian information criterion;contraceptive methods;eaf2 gene;locus;metabolic process, cellular;model selection;numerous;phenotype;programming tool;recombinant dna;time complexity;trait;triglycerides;usability;waist-hip ratio;waist–hip ratio;zpr1 gene;insulin, isophane;method development	Marika Kaakinen;Reedik Mägi;Krista Fischer;Jani Heikkinen;Marjo-Riitta Järvelin;Andrew P. Morris;Inga Prokopenko	2017		10.1186/s12859-017-1530-2	biology;dna microarray;computer science;bioinformatics;genetics	Comp.	3.002787396509905	-53.28071968981508	103293
6ef0c51442e9bd8a0bf4aef5fea0b7817cb26a41	molecular phylogenetic study and expression analysis of atp-binding cassette transporter gene family in oryza sativa in response to salt stress	expression profile;molecular evolution;salt stress;atp binding cassette transporter	ATP-binding cassette (ABC) transporter is a large gene superfamily that utilizes the energy released from ATP hydrolysis for transporting myriad of substrates across the biological membranes. Although many investigations have been done on the structural and functional analysis of the ABC transporters in Oryza sativa, much less is known about molecular phylogenetic and global expression pattern of the complete ABC family in rice. In this study, we have carried out a comprehensive phylogenetic analysis constructing neighbor-joining and maximum-likelihood trees based on various statistical methods of different ABC protein subfamily of five plant lineages including Chlamydomonas reinhardtii (green algae), Physcomitrella patens (moss), Selaginella moellendorffii (lycophyte), Arabidopsis thaliana (dicot) and O. sativa (monocot) to explore the origin and evolutionary patterns of these ABC genes. We have identified several conserved motifs in nucleotide binding domain (NBD) of ABC proteins among all plant lineages during evolution. Amongst the different ABC protein subfamilies, 'ABCE' has not yet been identified in lower plant genomes (algae, moss and lycophytes). The result indicated that gene duplication and diversification process acted upon these genes as a major operative force creating new groups and subgroups and functional divergence during evolution. We have demonstrated that rice ABCI subfamily consists of only half size transporters that represented highly dynamic members showing maximum sequence variations among the other rice ABC subfamilies. The evolutionary and the expression analysis contribute to a deep insight into the evolution and diversity of rice ABC proteins and their roles in response to salt stress that facilitate our further understanding on rice ABC transporters.	abc;acclimatization;adenosine triphosphate;algae;angiosperms;automated theorem proving;blue gene;cd4 stimulated atp immune response:mcnc:pt:bld:qn;cardiandra moellendorffii;chlamydomonas reinhardtii;chlorophyta;compact cassette;diversification (finance);experiment;gene duplication abnormality;gene expression profiling;gene family;genome;genome, plant;map overlay and statistical system;membrane transport proteins;microarray;molecular phylogenetics;mosses;neighbor joining;network block device;nucleosome binding domain;nucleotides;oryza (plant);oryza sativa antigen;smart;superfamily;salt (cryptography);sequence homology;subfamily;trees (plant);response to salt;salinity response	Jayita Saha;Atreyee Sengupta;Kamala Gupta;Bhaskar Gupta	2015	Computational biology and chemistry	10.1016/j.compbiolchem.2014.11.005	biology;botany;atp-binding cassette transporter;molecular evolution;genetics	Comp.	4.6677428201360955	-62.957391543225484	103305
52a2a537b578ed01c828af0520ac17e1ae736297	transcription factor and microrna co-regulatory loops: important regulatory motifs in biological processes and diseases	target prediction;cell proliferation;fbls;tf-mirna co-regulatory network;ffls	Transcription factors (TFs) and microRNAs (miRNAs) can jointly regulate target gene expression in the forms of feed-forward loops (FFLs) or feedback loops (FBLs). These regulatory loops serve as important motifs in gene regulatory networks and play critical roles in multiple biological processes and different diseases. Major progress has been made in bioinformatics and experimental study for the TF and miRNA co-regulation in recent years. To further speed up its identification and functional study, it is indispensable to make a comprehensive review. In this article, we summarize the types of FFLs and FBLs and their identified methods. Then, we review the behaviors and functions for the experimentally identified loops according to biological processes and diseases. Future improvements and challenges are also discussed, which includes more powerful bioinformatics approaches and high-throughput technologies in TF and miRNA target prediction, and the integration of networks of multiple levels.	behavior;bioinformatics;biological processes;experiment;feedback;gene expression;gene regulatory network;high-throughput computing;medical transcription;mercury:mcnt:pt:feed:qn;micrornas;transcription factor;throughput	Hongmei Zhang;Shuzhen Kuang;Xushen Xiong;Tianliuyun Gao;Chenglin Liu;An-Yuan Guo	2015	Briefings in bioinformatics	10.1093/bib/bbt085	biology;bioinformatics;genetics	Comp.	5.137402689181871	-58.6289468529464	103352
c1047712eea8c418786cc91cd3973f7357876c6e	mitochondria sequence mapping strategies and practicability of mitochondria variant detection from exome and rna sequencing data	biological patents;biomedical journals;text mining;europe pubmed central;citation search;citation networks;research articles;abstracts;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	The rapid progress in high-throughput sequencing has significantly enriched our capacity for studying the mitochondrial DNA (mtDNA). In addition to performing specific mitochondrial targeted sequencing, an increasingly popular alternative approach is using the off-target reads from exome sequencing to infer mtDNA variants, including single nucleotide polymorphisms (SNPs) and heteroplasmy. However, the effectiveness and practicality of this approach have not been tested. Recently, RNAseq data have also been suggested as a good source for alternative data mining, but whether mitochondrial variants can be detected from RNAseq data has not been validated. We designed a study to evaluate the practicability of mtDNA variant detection using exome and RNA sequencing data. Five breast cancer cell lines were sequenced through mitochondrial targeted, exome, and RNA sequencing. Mitochondrial targeted sequencing was used as the gold standard to compute the validation and false discovery rates of SNP and heteroplasmy detection in exome and RNAseq data. We found that exome and RNA sequencing can accurately detect mitochondrial SNPs. However, the lower false discovery rate makes exome sequencing a better choice for heteroplasmy detection than RNAseq. Furthermore, we examined three alignment strategies and found that aligning reads directly to the mitochondrial reference genome or aligning reads to the nuclear and mitochondrial references genomes simultaneously produced the best results, and that aligning to the nuclear genome first and afterwards to the mitochondrial genome performed poorly. In conclusion, our study provides important guidelines for future studies that intend to use either exome sequencing or RNAseq data to infer mitochondrial SNPs and heteroplasmy.		Pan Zhang;David C. Samuels;Brian D. Lehmann;Thomas Stricker;Jennifer A. Pietenpol;Shyr Yu;Baoming Sun	2016	Briefings in bioinformatics	10.1093/bib/bbv057	biology;molecular biology;text mining;medical research;exome sequencing;cancer genome sequencing;computer science;bioinformatics;exome;genetics;deep sequencing	Comp.	1.4328953808670712	-54.9901743735594	103563
16187475a4d9fec62f4a0b15917d0187a874f643	aagatlas 1.0: a human autoantigen database		Autoantibodies refer to antibodies that target self-antigens, which can play pivotal roles in maintaining homeostasis, distinguishing normal from tumor tissue and trigger autoimmune diseases. In the last three decades, tremendous efforts have been devoted to elucidate the generation, evolution and functions of autoantibodies, as well as their target autoantigens. However, reports of these countless previously identified autoantigens are randomly dispersed in the literature. Here, we constructed an AAgAtlas database 1.0 using text-mining and manual curation. We extracted 45 830 autoantigen-related abstracts and 94 313 sentences from PubMed using the keywords of either 'autoantigen' or 'autoantibody' or their lexical variants, which were further refined to 25 520 abstracts, 43 253 sentences and 3984 candidates by our bio-entity recognizer based on the Protein Ontology. Finally, we identified 1126 genes as human autoantigens and 1071 related human diseases, with which we constructed a human autoantigen database (AAgAtlas database 1.0). The database provides a user-friendly interface to conveniently browse, retrieve and download human autoantigens as well as their associated diseases. The database is freely accessible at http://biokb.ncpsb.org/aagatlas/ We believe this database will be a valuable resource to track and understand human autoantigens as well as to investigate their functions in basic and translational research.	abstract summary;autoantibodies;autoantigens;autoimmune diseases;british informatics olympiad;browsing;digital curation;download;extraction;finite-state machine;homeostasis;interface device component;neoplasms;proteomics;pubmed;randomness;text mining;translational research;usability;sentence;tumor tissue	Dan Wang;Liuhui Yang;Ping Zhang;Joshua LaBaer;Henning Hermjakob;Dong Li;Xiaobo Yu	2017		10.1093/nar/gkw946	genetics;biology;bioinformatics	Comp.	-2.0417383476358033	-63.46592714833158	103602
e8fa03671a6a6d298e5d3817f89aa2bdab19bf2c	metabosignal: a network-based approach for topological analysis of metabotype regulation via metabolic and signaling pathways	08 information and computing sciences;journal article;01 mathematical sciences;06 biological sciences;bioinformatics	Summary MetaboSignal is an R package that allows merging metabolic and signaling pathways reported in the Kyoto Encyclopaedia of Genes and Genomes (KEGG). It is a network-based approach designed to navigate through topological relationships between genes (signaling- or metabolic-genes) and metabolites, representing a powerful tool to investigate the genetic landscape of metabolic phenotypes.   Availability and Implementation MetaboSignal is available from Bioconductor: https://bioconductor.org/packages/MetaboSignal/.   Contact m.dumas@imperial.ac.uk .   Supplementary information Supplementary data are available at Bioinformatics online.	bioconductor;bioinformatics;genome;geographic information systems;kegg;metabolic process, cellular;metabolite;phenotype;r language	Andrea Rodriguez-Martinez;Rafael Ayala;Joram M. Posma;Ana L. Neves;Dominique Gauguier;Jeremy K. Nicholson;Marc-Emmanuel Dumas	2017		10.1093/bioinformatics/btw697	computational biology;biology;applied mathematics;computer science;bioinformatics	Comp.	-0.1808846692279504	-63.2812957162342	103623
962ad4fd765f196f494935080009621cc27acf77	ensembl biomarts: a hub for data retrieval across taxonomic space	animals;search engine;databases genetic;classification;anopheles gambiae;genome;humans;computational biology;information storage and retrieval;polymorphism single nucleotide;open reading frames	For a number of years the BioMart data warehousing system has proven to be a valuable resource for scientists seeking a fast and versatile means of accessing the growing volume of genomic data provided by the Ensembl project. The launch of the Ensembl Genomes project in 2009 complemented the Ensembl project by utilizing the same visualization, interactive and programming tools to provide users with a means for accessing genome data from a further five domains: protists, bacteria, metazoa, plants and fungi. The Ensembl and Ensembl Genomes BioMarts provide a point of access to the high-quality gene annotation, variation data, functional and regulatory annotation and evolutionary relationships from genomes spanning the taxonomic space. This article aims to give a comprehensive overview of the Ensembl and Ensembl Genomes BioMarts as well as some useful examples and a description of current data content and future objectives. Database URLs: http://www.ensembl.org/biomart/martview/; http://metazoa.ensembl.org/biomart/martview/; http://plants.ensembl.org/biomart/martview/; http://protists.ensembl.org/biomart/martview/; http://fungi.ensembl.org/biomart/martview/; http://bacteria.ensembl.org/biomart/martview/.	biomart;data retrieval;ensembl genomes;file spanning;fungi;gene annotation;genome;imagery;metazoa;programming tool;usb hub;protists	Rhoda Kinsella;Andreas Kähäri;Syed Haider;Jorge Zamora;Glenn Proctor;Giulietta Spudich;Jeff Almeida-King;Daniel M. Staines;Paul S. Derwent;Arnaud Kerhornou;Paul J. Kersey;Paul Flicek	2011		10.1093/database/bar030	open reading frame;ensembl;biology;biological classification;computer science;bioinformatics;data mining;database;world wide web;genetics;information retrieval;search engine;genome	Comp.	-2.1474039726693754	-60.44653315167851	103728
172c756ddfcede3f00a6ea8d0a95042747cd2dfc	phylogenetic diversity theory sheds light on the structure of microbial communities	phylogeography;community ecology;habitats;phylogeny;models theoretical;plos computational biology;metagenome;microbiome;humans;microbial ecology;community assembly;phylogenetics;phylogenetic analysis	Microbial communities are typically large, diverse, and complex, and identifying and understanding the processes driving their structure has implications ranging from ecosystem stability to human health and well-being. Phylogenetic data gives us a new insight into these processes, providing a more informative perspective on functional and trait diversity than taxonomic richness alone. But the sheer scale of high resolution phylogenetic data also presents a new challenge to ecological theory. We bring a sampling theory perspective to microbial communities, considering a local community of co-occuring organisms as a sample from a larger regional pool, and apply our framework to make analytical predictions for local phylogenetic diversity arising from a given metacommunity and community assembly process. We characterize community assembly in terms of quantitative descriptions of clustered, random and overdispersed sampling, which have been associated with hypotheses of environmental filtering and competition. Using our approach, we analyze large microbial communities from the human microbiome, uncovering significant variation in diversity across habitats relative to the null hypothesis of random sampling.	community;description;ecosystem;habitat;image resolution;information;large;microbiome;null value;petrosal sinus sampling;phylogenesis;phylogenetics;sampling (signal processing);sampling - surgical action	James P. O'Dwyer;Steven W. Kembel;Jessica L. Green	2012		10.1371/journal.pcbi.1002832	biology;community;habitat;bioinformatics;microbiome;ecology;phylogenetics	ML	2.5810066087922103	-61.54963577754735	103738
bd47778ab476ca578e574c5702c15ed4a5cc54a9	graph accordance of next-generation sequence assemblies	animals;contig mapping;high throughput nucleotide sequencing;sequence analysis dna;chickens;genome;algorithms	MOTIVATION No individual assembly algorithm addresses all the known limitations of assembling short-length sequences. Overall reduced sequence contig length is the major problem that challenges the usage of these assemblies. We describe an algorithm to take advantages of different assembly algorithms or sequencing platforms to improve the quality of next-generation sequence (NGS) assemblies.   RESULTS The algorithm is implemented as a graph accordance assembly (GAA) program. The algorithm constructs an accordance graph to capture the mapping information between the target and query assemblies. Based on the accordance graph, the contigs or scaffolds of the target assembly can be extended, merged or bridged together. Extra constraints, including gap sizes, mate pairs, scaffold order and orientation, are explored to enforce those accordance operations in the correct context. We applied GAA to various chicken NGS assemblies and the results demonstrate improved contiguity statistics and higher genome and gene coverage.   AVAILABILITY GAA is implemented in OO perl and is available here: http://sourceforge.net/projects/gaa-wugi/.   CONTACT lye@genome.wustl.edu	addresses (publication format);communications satellite;ephrin type-b receptor 1, human;gap buffer;glycogen storage disease type ii;graph - visual representation;hl7publishingsubsection <operations>;merge;perl;pierre robin syndrome;question (inquiry);sequence assembly;sourceforge;algorithm	Guohui Yao;Liang Ye;Hongyu Gao;Patrick Minx;Wesley C. Warren;George M. Weinstock	2012	Bioinformatics	10.1093/bioinformatics/btr588	biology;bioinformatics;genetics;genome	Comp.	-0.3462837385694759	-54.62488046014848	103762
da5e9dac65d3cdb1a02ae12a61ff28a54d1ec2fc	the impact of tautomer forms on pharmacophore-based virtual screening	computer programs;virtual screening;computers in chemistry	In the field of in silico screening, many applications do not automatically consider possible tautomeric states of molecules. However, the detection of new compound candidates might rely on correct structural description, which is important for the perfect fit toward the biologically relevant interactions. In this paper, we present a new exhaustive tautomer enumeration approach implemented by means of the CACTVS software package. The approach contains a set of 21 predefined SMIRKS-based transforms and a powerful transformation engine that is capable of generating most tautomers described comprehensively in the literature or found in databases in the field of medicinal chemistry. User-defined tautomer rules applied to specific structural databases or scientific issues can be implemented easily and used instead of the predefined rules. In addition, we describe the impact of tautomer-enriched databases on pharmacophore screening approaches for human matrix metalloproteinase 8 as an example of a protein-based pharmacophore screening scenario and for human cyclin-dependent kinases as an example of a ligand-based pharmacophore screening approach. In both test cases, as a preprocessing step, we have used our new tautomer enumerator tool for the tautomer enrichment of the screening data sets and have used it as a postprocessing step to remove tautomeric duplicates from the results. We could demonstrate that the tautomer-enriched screening data sets show significant advantages compared to their non-enhanced counterparts. The discrimination between hits and nonhits was significantly better in the case of tautomer-enriched databases. Moreover, it has been proved that tautomer-enhanced databases will lead to a higher number of potential hits.	cyclins;database;databases;enumerator polynomial;gene ontology term enrichment;interaction;ligands;lymphocyte activation;matrix metalloproteinases;medicinal chemistry;metalloproteases;pharmacophore;preprocessor;rule (guideline);staphylococcal protein a;test case;virtual screening;tautomer	Frank Oellien;Jörg Cramer;Carsten Beyer;Wolf-Dietrich Ihlenfeldt;Paul M. Selzer	2006	Journal of chemical information and modeling	10.1021/ci060109b	chemistry;virtual screening;bioinformatics;theoretical computer science;combinatorial chemistry;computational chemistry	SE	1.8744970191368169	-56.86475608908672	103791
40061d73d2cff11966b153f27e343fabf04e7567	lebibiqbpp: a set of databases and a webtool for automatic phylogenetic analysis of prokaryotic sequences	health research;software;uk clinical guidelines;biological patents;rna archaeal;phylogeny;archaea;databases nucleic acid;europe pubmed central;citation search;computational biology bioinformatics;rna bacterial;internet;uk phd theses thesis;likelihood functions;life sciences;algorithms;bacteria;sequence analysis rna;combinatorial libraries;rna ribosomal;computational biology;uk research reports;medical journals;computer appl in life sciences;europe pmc;biomedical research;microarrays;bioinformatics	Estimating the phylogenetic position of bacterial and archaeal organisms by genetic sequence comparisons is considered as the gold-standard in taxonomy. This is also a way to identify the species of origin of the sequence. The quality of the reference database used in such analyses is crucial: the database must reflect the up-to-date bacterial nomenclature and accurately indicate the species of origin of its sequences. leBIBIQBPP is a web tool taking as input a series of nucleotide sequences belonging to one of a set of reference markers (e.g., SSU rRNA, rpoB, groEL2) and automatically retrieving closely related sequences, aligning them, and performing phylogenetic reconstruction using an approximate maximum likelihood approach. The system returns a set of quality parameters and, if possible, a suggested taxonomic assigment for the input sequences. The reference databases are extracted from GenBank and present four degrees of stringency, from the “superstringent” degree (one type strain per species) to the loosely parsed degree (“lax” database). A set of one hundred to more than a thousand sequences may be analyzed at a time. The speed of the process has been optimized through careful hardware selection and database design. leBIBIQBPP is a powerful tool helping biologists to position bacterial or archaeal sequence commonly used markers in a phylogeny. It is a diagnostic tool for clinical, industrial and environmental microbiology laboratory, as well as an exploratory tool for more specialized laboratories. Its main advantages, relatively to comparable systems are: i) the use of a broad set of databases covering diverse markers with various degrees of stringency; ii) the use of an approximate Maximum Likelihood approach for phylogenetic reconstruction; iii) a speed compatible with on-line usage; and iv) providing fully documented results to help the user in decision making.	approximation algorithm;arabic numeral 100;bibliographic database;database design;databases;decision making;document completion status - documented;estimated;extraction;genbank;laboratory;nomenclature;nucleotides;online and offline;parsing;phylogenetics;synchronization in telecommunications;taxonomic database;taxonomy	Jean-Pierre Flandrois;Guy Perrière;Manolo Gouy	2015		10.1186/s12859-015-0692-z	biology;zoology;the internet;dna microarray;bacteria;bioinformatics;genetics;archaea;phylogenetics	Comp.	-0.8903443547563132	-57.698160179466846	103871
0a442cc728e86b5cc33662aa2b335f05f23b3cd3	combining peak- and chromatogram-based retention time alignment algorithms for multiple chromatography-mass spectrometry datasets	software;gas chromatography mass spectrometry;metabolomics;triticum;computational biology bioinformatics;algorithms;leishmania;combinatorial libraries;proteomics;computer appl in life sciences;microarrays;bioinformatics	Modern analytical methods in biology and chemistry use separation techniques coupled to sensitive detectors, such as gas chromatography-mass spectrometry (GC-MS) and liquid chromatography-mass spectrometry (LC-MS). These hyphenated methods provide high-dimensional data. Comparing such data manually to find corresponding signals is a laborious task, as each experiment usually consists of thousands of individual scans, each containing hundreds or even thousands of distinct signals. In order to allow for successful identification of metabolites or proteins within such data, especially in the context of metabolomics and proteomics, an accurate alignment and matching of corresponding features between two or more experiments is required. Such a matching algorithm should capture fluctuations in the chromatographic system which lead to non-linear distortions on the time axis, as well as systematic changes in recorded intensities. Many different algorithms for the retention time alignment of GC-MS and LC-MS data have been proposed and published, but all of them focus either on aligning previously extracted peak features or on aligning and comparing the complete raw data containing all available features. In this paper we introduce two algorithms for retention time alignment of multiple GC-MS datasets: multiple alignment by bidirectional best hits peak assignment and cluster extension (BIPACE) and center-star multiple alignment by pairwise partitioned dynamic time warping (CeMAPP-DTW). We show how the similarity-based peak group matching method BIPACE may be used for multiple alignment calculation individually and how it can be used as a preprocessing step for the pairwise alignments performed by CeMAPP-DTW. We evaluate the algorithms individually and in combination on a previously published small GC-MS dataset studying the Leishmania parasite and on a larger GC-MS dataset studying grains of wheat (Triticum aestivum). We have shown that BIPACE achieves very high precision and recall and a very low number of false positive peak assignments on both evaluation datasets. CeMAPP-DTW finds a high number of true positives when executed on its own, but achieves even better results when BIPACE is used to constrain its search space. The source code of both algorithms is included in the OpenSource software framework Maltcms, which is available from http://maltcms.sf.net . The evaluation scripts of the present study are available from the same source.	apache axis;axis vertebra;detectors;distortion;dynamic time warping;ephrin type-b receptor 1, human;execution;experiment;extraction;gucy2c protein, human;gas chromatography;gas chromatography-mass spectrometry;image scanner;large;leishmania sp identified:prid:pt:tiss:nom:if;liquid chromatography mass spectrometry;loudspeaker time alignment;matching;metabolite;metabolomics;multiple sequence alignment;nonlinear system;open-source software;precision and recall;preprocessor;proteomics;scientific publication;silo (dataset);software framework;source code;triticum;algorithm	Nils Hoffmann;Matthias Keck;Heiko Neuweger;Mathias Wilhelm;Petra Högy;Karsten Niehaus;Jens Stoye	2012		10.1186/1471-2105-13-214	biology;dna microarray;computer science;bioinformatics;metabolomics;data mining;proteomics	Comp.	1.3196293001848542	-56.67643711688671	103882
5ec868c23a210e7a21ec343e368f54d4b52c4aa2	module-based subnetwork alignments reveal novel transcriptional regulators in malaria parasite plasmodium falciparum	genomics;escherichia coli;simulation and modeling;systems biology;physiological cellular and medical topics;chromosome mapping;computational biology bioinformatics;chromatin assembly and disassembly;gene expression regulation;plasmodium falciparum;algorithms;regulatory elements transcriptional;sequence alignment;genome protozoan;protein interaction maps;protozoan proteins;bioinformatics	Malaria causes over one million deaths annually, posing an enormous health and economic burden in endemic regions. The completion of genome sequencing of the causative agents, a group of parasites in the genus Plasmodium, revealed potential drug and vaccine candidates. However, genomics-driven target discovery has been significantly hampered by our limited knowledge of the cellular networks associated with parasite development and pathogenesis. In this paper, we propose an approach based on aligning neighborhood PPI subnetworks across species to identify network components in the malaria parasite P. falciparum. Instead of only relying on sequence similarities to detect functional orthologs, our approach measures the conservation between the neighborhood subnetworks in protein-protein interaction (PPI) networks in two species, P. falciparum and E. coli. 1,082 P. falciparum proteins were predicted as functional orthologs of known transcriptional regulators in the E. coli network, including general transcriptional regulators, parasite-specific transcriptional regulators in the ApiAP2 protein family, and other potential regulatory proteins. They are implicated in a variety of cellular processes involving chromatin remodeling, genome integrity, secretion, invasion, protein processing, and metabolism. In this proof-of-concept study, we demonstrate that a subnetwork alignment approach can reveal previously uncharacterized members of the subnetworks, which opens new opportunities to identify potential therapeutic targets and provide new insights into parasite biology, pathogenesis and virulence. This approach can be extended to other systems, especially those with poor genome annotation and a paucity of knowledge about cellular networks.	cessation of life;genomics;homology (biology);malaria vaccines;manifold alignment;million;pixel density;plasmodium falciparum;post-translational protein processing;protein family;subnetwork;transcription, genetic;virulence;whole genome sequencing;chromatin remodeling;protein protein interaction	Hong Cai;Changjin Hong;Jianying Gu;Timothy G. Lilburn;Rui Kuang;Yufeng Wang	2012		10.1186/1752-0509-6-S3-S5	biology;genomics;regulation of gene expression;bioinformatics;sequence alignment;escherichia coli;genetics;systems biology	Comp.	5.495771517022851	-60.23657292775605	103898
3bc4437984af4334612363ab39a9a12fcf1e0413	a model of large-scale proteome evolution	genomics;complex networks;networks;small worlds;statistical mechanics;genome organization;scaling law;complex network;scaling laws;small world;protein network;gene duplication;large scale;protein protein interaction;proteomics;protein networks;small world network;evolution	The next step in the understanding of the genome organization, after the determination of complete sequences, involves proteomics. The proteome includes the whole set of protein-protein interactions, and two recent independent studies have shown that its topology displays a number of surprising features shared by other complex networks, both natural and artificial. In order to understand the origins of this topology and its evolutionary implications, we present a simple model of proteome evolution that is able to reproduce many of the observed statistical regularities reported from the analysis of the yeast proteome. Our results suggest that the observed patterns can be explained by a process of gene duplication and diversification that would evolve proteome networks under a selection pressure, favoring robustness against failure of its individual components.	complex network;diversification (finance);interaction;network topology;proteomics	Ricard V. Solé;Romualdo Pastor-Satorras;Eric Smith;Thomas B. Kepler	2002	Advances in Complex Systems	10.1142/S021952590200047X	biology;genomics;statistical mechanics;bioinformatics;proteomics;genetics;complex network	Comp.	4.424004378666783	-60.15513977211781	103899
fd9acce461bfe8959664b49da99104daa185db79	effectivedb—updates and novel features for a better annotation of bacterial secreted proteins and type iii, iv, vi secretion systems	peptides;host organism;amino acid sequence;molecular sequence annotation;binding sites;type iv secretion systems;bodily secretions;protein sorting signals;protein structure tertiary;genome;genome bacterial;bacteria;type vi secretion systems;protein secretion;type iii secretion systems;bacterial proteins;sequence analysis protein;databases protein	Protein secretion systems play a key role in the interaction of bacteria and hosts. EffectiveDB (http://effectivedb.org) contains pre-calculated predictions of bacterial secreted proteins and of intact secretion systems. Here we describe a major update of the database, which was previously featured in the NAR Database Issue. EffectiveDB bundles various tools to recognize Type III secretion signals, conserved binding sites of Type III chaperones, Type IV secretion peptides, eukaryotic-like domains and subcellular targeting signals in the host. Beyond the analysis of arbitrary protein sequence collections, the new release of EffectiveDB also provides a 'genome-mode', in which protein sequences from nearly complete genomes or metagenomic bins can be screened for the presence of three important secretion systems (Type III, IV, VI). EffectiveDB contains pre-calculated predictions for currently 1677 bacterial genomes from the EggNOG 4.0 database and for additional bacterial genomes from NCBI RefSeq. The new, user-friendly and informative web portal offers a submission tool for running the EffectiveDB prediction tools on user-provided data.	amino acid sequence;annotation;binding sites;cell secretion;collections (publication);genome;genome, bacterial;information;metagenomics;nar 2;ncbi taxonomy;peptide sequence;projection screen;refseq;regulatory submission;usability;cellular targeting	Valerie Eichinger;Thomas Nussbaumer;Alexander Platzer;Marc-André Jehl;Roland Arnold;Thomas Rattei	2016		10.1093/nar/gkv1269	biology;bacteria;bioinformatics;binding site;peptide sequence;secretory protein;genetics;genome	Comp.	-0.9681270768528607	-59.758121541491114	103945
1ea511e78565a298f987a2f1a02d46cd91f0f787	quantification of tumour evolution and heterogeneity via bayesian epiallele detection	epigenetics;heterogeneity;phylogenetics	Epigenetic heterogeneity within a tumour can play an important role in tumour evolution and the emergence of resistance to treatment. It is increasingly recognised that the study of DNA methylation (DNAm) patterns along the genome – so-called ‘epialleles’ – offers greater insight into epigenetic dynamics than conventional analyses which examine DNAm marks individually. We have developed a Bayesian model to infer which epialleles are present in multiple regions of the same tumour. We apply our method to reduced representation bisulfite sequencing (RRBS) data from multiple regions of one lung cancer tumour and a matched normal sample. The model borrows information from all tumour regions to leverage greater statistical power. The total number of epialleles, the epiallele DNAm patterns, and a noise hyperparameter are all automatically inferred from the data. Uncertainty as to which epiallele an observed sequencing read originated from is explicitly incorporated by marginalising over the appropriate posterior densities. The degree to which tumour samples are contaminated with normal tissue can be estimated and corrected for. By tracing the distribution of epialleles throughout the tumour we can infer the phylogenetic history of the tumour, identify epialleles that differ between normal and cancer tissue, and define a measure of global epigenetic disorder. Detection and comparison of epialleles within multiple tumour regions enables phylogenetic analyses, identification of differentially expressed epialleles, and provides a measure of epigenetic heterogeneity. R code is available at github.com/james-e-barrett.	bayesian network;bisulfite sequencing;body tissue;carcinoma of lung;dna microarray;emergence;genetic heterogeneity;inference;neoplasms;phylogenetics;quantitation;r language;density;hydrogen sulfite;study of epigenetics	James E. Barrett;Andrew Feber;Javier Herrero;Miljana Tanić;Gareth A. Wilson;Charles Swanton;Stephan Beck	2017		10.1186/s12859-017-1753-2	biology;bioinformatics;genetics	ML	4.527985087277325	-54.571595175919406	103956
5ce79026755681ab190276164319fa038ca2658f	snpranker 2.0: a gene-centric data mining tool for diseases associated snp prioritization in gwas	genes;software;genotype;disease;genome wide association study;data mining;computational biology bioinformatics;internet;algorithms;humans;combinatorial libraries;computational biology;computer appl in life sciences;polymorphism single nucleotide;microarrays;bioinformatics	The capability of correlating specific genotypes with human diseases is a complex issue in spite of all advantages arisen from high-throughput technologies, such as Genome Wide Association Studies (GWAS). New tools for genetic variants interpretation and for Single Nucleotide Polymorphisms (SNPs) prioritization are actually needed. Given a list of the most relevant SNPs statistically associated to a specific pathology as result of a genotype study, a critical issue is the identification of genes that are effectively related to the disease by re-scoring the importance of the identified genetic variations. Vice versa, given a list of genes, it can be of great importance to predict which SNPs can be involved in the onset of a particular disease, in order to focus the research on their effects. We propose a new bioinformatics approach to support biological data mining in the analysis and interpretation of SNPs associated to pathologies. This system can be employed to design custom genotyping chips for disease-oriented studies and to re-score GWAS results. The proposed method relies (1) on the data integration of public resources using a gene-centric database design, (2) on the evaluation of a set of static biomolecular annotations, defined as features, and (3) on the SNP scoring function, which computes SNP scores using parameters and weights set by users. We employed a machine learning classifier to set default feature weights and an ontological annotation layer to enable the enrichment of the input gene set. We implemented our method as a web tool called SNPranker 2.0 ( http://www.itb.cnr.it/snpranker ), improving our first published release of this system. A user-friendly interface allows the input of a list of genes, SNPs or a biological process, and to customize the features set with relative weights. As result, SNPranker 2.0 returns a list of SNPs, localized within input and ontologically enriched genes, combined with their prioritization scores. Different databases and resources are already available for SNPs annotation, but they do not prioritize or re-score SNPs relying on a-priori biomolecular knowledge. SNPranker 2.0 attempts to fill this gap through a user-friendly integrated web resource. End users, such as researchers in medical genetics and epidemiology, may find in SNPranker 2.0 a new tool for data mining and interpretation able to support SNPs analysis. Possible scenarios are GWAS data re-scoring, SNPs selection for custom genotyping arrays and SNPs/diseases association studies.	annotation;bioinformatics;biological processes;customize;data mining;database design;default;gene ontology term enrichment;genes, vif;genetic polymorphism;genome-wide association study;genotype determination;hereditary diseases;high-throughput computing;machine learning;medical genetics specialty;nitroprusside;onset (audio);scientific publication;score;single nucleotide polymorphism;single-chain antibodies;throughput;usability;web resource;weight	Ivan Merelli;Andrea Calabria;Paolo Cozzi;Federica Viti;Ettore Mosca;Luciano Milanesi	2013		10.1186/1471-2105-14-S1-S9	genome-wide association study;biology;the internet;dna microarray;biotechnology;bioinformatics;gene;genotype;genetics	Comp.	-1.617645906833613	-63.000204369494845	103980
e5b0694d4fcdb7565029c18036367c602a4c3cb5	predicting lysine glycation sites using bi-profile bayes feature extraction	bi-profile bayes;glycation;post-translational modification;support vector machine	Glycation is a nonenzymatic post-translational modification which has been found to be involved in various biological processes and closely associated with many metabolic diseases. The accurate identification of glycation sites is important to understand the underlying molecular mechanisms of glycation. As the traditional experimental methods are often labor-intensive and time-consuming, it is desired to develop computational methods to predict glycation sites. In this study, a novel predictor named BPB_GlySite is proposed to predict lysine glycation sites by using bi-profile bayes feature extraction and support vector machine algorithm. As illustrated by 10-fold cross-validation, BPB_GlySite achieves a satisfactory performance with a Sensitivity of 63.68%, a Specificity of 72.60%, an Accuracy of 69.63% and a Matthew's correlation coefficient of 0.3499. Experimental results also indicate that BPB_GlySite significantly outperforms three existing glycation sites predictors: NetGlycate, PreGly and Gly-PseAAC. Therefore, BPB_GlySite can be a useful bioinformatics tool for the prediction of glycation sites. A user-friendly web-server for BPB_GlySite is established at 123.206.31.171/BPB_GlySite/.		Zhe Ju;Juhe Sun;Yanjie Li;Li Wang	2017	Computational biology and chemistry	10.1016/j.compbiolchem.2017.10.004	bioinformatics;feature extraction;lysine;glycation;bayes' theorem;biology	ML	9.92538616619344	-56.207061566910546	104031
7b99214f832d795769f2acf780fe2bb8168f2ca7	evaluating synteny for improved comparative studies	software;genomics;genome fungal;yeasts;alinhamento de sequencia;genomica;genoma fungico;sintenia;sequence alignment;leveduras;synteny	MOTIVATION Comparative genomics aims to understand the structure and function of genomes by translating knowledge gained about some genomes to the object of study. Early approaches used pairwise comparisons, but today researchers are attempting to leverage the larger potential of multi-way comparisons. Comparative genomics relies on the structuring of genomes into syntenic blocks: blocks of sequence that exhibit conserved features across the genomes. Syntenic blocs are required for complex computations to scale to the billions of nucleotides present in many genomes; they enable comparisons across broad ranges of genomes because they filter out much of the individual variability; they highlight candidate regions for in-depth studies; and they facilitate whole-genome comparisons through visualization tools. However, the concept of syntenic block remains loosely defined. Tools for the identification of syntenic blocks yield quite different results, thereby preventing a systematic assessment of the next steps in an analysis. Current tools do not include measurable quality objectives and thus cannot be benchmarked against themselves. Comparisons among tools have also been neglected-what few results are given use superficial measures unrelated to quality or consistency.   RESULTS We present a theoretical model as well as an experimental basis for comparing syntenic blocks and thus also for improving or designing tools for the identification of syntenic blocks. We illustrate the application of the model and the measures by applying them to syntenic blocks produced by three different contemporary tools (DRIMM-Synteny, i-ADHoRe and Cyntenator) on a dataset of eight yeast genomes. Our findings highlight the need for a well founded, systematic approach to the decomposition of genomes into syntenic blocks. Our experiments demonstrate widely divergent results among these tools, throwing into question the robustness of the basic approach in comparative genomics. We have taken the first step towards a formal approach to the construction of syntenic blocks by developing a simple quality criterion based on sound evolutionary principles.	benchmark (computing);computation;experiment;genome;genomics;large;nucleotides;numerous;robustness (computer science);silo (dataset);spatial variability;synteny;the superficial;theory	Cristina G. Ghiurcuta;Bernard M. E. Moret	2014		10.1093/bioinformatics/btu259	biology;genomics;bioinformatics;sequence alignment;synteny;genetics	Comp.	1.9513009438614746	-55.21974051430483	104254
6dc47019a36f53c1766cd42838e1c28bdce699a8	challenges rising from learning motif evaluation functions using genetic programming	evaluation function;genetic program;motif discovery;gene regulation;transcription factor binding site;model evaluation;competition model;genetic programming gp;high performance;transcription factor binding site tfbs;evaluation model;fitness function;bioinformatics	Motif discovery is an important Bioinformatics problem for deciphering gene regulation. Numerous sequence-based approaches have been proposed employing human specialist motif models (evaluation functions), but performance is so unsatisfactory on benchmarks that the underlying information seems to have already been exploited and have doomed. However, we have found that even a simple modified representation still achieves considerably high performance on a challenging benchmark, implying potential for sequence-based motif discovery. Thus we raise the problem of learning motif evaluation functions. We employ Genetic programming (GP) which has the potential to evolve human competitive models. We take advantage of the terminal set containing specialist-model-like components and have tried three fitness functions. Results exhibit both great challenges and potentials. No models learnt can perform universally well on the challenging benchmark, where one reason may be the data appropriateness for sequence-based motif discovery. However, when applied on different widely-tested datasets, the same models achieve comparable performance to existing approaches based on specialist models. The study calls for further novel GP to learn different levels of effective evaluation models from strict to loose ones on exploiting sequence information for motif discovery, namely quantitative functions, cardinal rankings, and learning feasibility classifications.	benchmark (computing);bioinformatics;fitness function;genetic programming;norm (social);sequence motif	Leung-Yau Lo;Tak-Ming Chan;Kin-Hong Lee;Kwong-Sak Leung	2010		10.1145/1830483.1830515	regulation of gene expression;computer science;bioinformatics;artificial intelligence;machine learning;evaluation function;data mining;fitness function;dna binding site	AI	8.670544480719107	-54.29780251752459	104372
a51c185a71fc277f1691c5b95ded1637285daa92	metagenealyse: analysis of integrated transcriptional and metabolite data	metabolito;metabolomics;analisis datos;methode;result;service;high throughput screening;gene expression;expression genique;data analysis;criblage haut debit;echantillon;preparation echantillon;resultado;analyse donnee;preparacion muestreo;sample;resultat;metabolite;sample preparation;metodo;method;muestra;expresion genetica;servicio	UNLABELLED New techniques in sample preparation allow high throughput analysis of samples on the transcriptional as well as on the metabolic level. We present a service accessible via the web that allows the analysis of integrated data sets that combine gene-expression data and metabolic data. After uploading, data sets can be normalized, clustered by various methods and results can be graphically visualized. All calculations are carried out on a server, so even time- and memory-consuming analyses can be done independently of the performance of the client.   AVAILABILITY The service is accessible via web-interface at http://metagenealyse.mpimp-golm.mpg.de/	interface device component;metabolic process, cellular;server (computer);server (computing);throughput;transcription, genetic;upload;user interface	Carsten O. Daub;Sebastian Kloska;Joachim Selbig	2003	Bioinformatics	10.1093/bioinformatics/btg321	high-throughput screening;biology;method;service;gene expression;sample;computer science;bioinformatics;metabolomics;data mining;data analysis;genetics;statistics	Comp.	-3.1242686586453754	-57.54611056551679	104561
67dab30d837357005207adbe353531b054522966	netcerna: an algorithm for construction of phenotype-specific regulation networks via competing endogenous rnas	indexes breast cancer bioinformatics prediction algorithms rna context;cancer;medical computing cancer internet;cernas;medical computing;internet;tcga netcerna phenotype specific regulation networks competing endogenous rna web based application tracerna disease specific transcriptome data network representation gene expression microrna expression data mirna breast cancer study the cancer genome atlas;micrornas;gene regulatory network;gene regulatory network cernas micrornas	By using the competing endogenous RNA (ceRNA) concept, we implemented a web-based application TraceRNA. TraceRNA allows us to interactively construct a regulation network for a specific phenotype by using a disease-specific transcriptome data. In this work, we further extend the TraceRNA with a novel algorithm implementation where we examined the microRNA expression derived from same disease type. The proposed algorithm, NetceRNA, finds an optimized network representation under a certain phenotype context by iteratively perturbing the network and measuring the network configuration change with respect to the original ceRNA network. The resulting algorithm outputs an improved network together with a ranked list of genes and miRNAs which are characteristic of the specific phenotype. To illustrate the utility of NetceRNA, gene expression and microRNA expression data of breast cancer study from The Cancer Genome Atlas (TCGA) were used.	algorithm;interactivity;web application	Mario Flores;Yufei Huang;Yidong Chen	2013	2013 IEEE International Workshop on Genomic Signal Processing and Statistics	10.1109/GENSIPS.2013.6735921	biology;gene regulatory network;the internet;bioinformatics;data mining;genetics;microrna;cancer	Comp.	-0.036794406988036446	-58.99370744142366	104623
8a45bd4cf94a75005abef05c6f50194bfda35f72	cross-over between discrete and continuous protein structure space: insights into automatic classification and networks of protein structures	cluster algorithm;domain decomposition;articulo;protein domains;amino acid sequence;fold change;models chemical;protein structure;protein evolution;hierarchical classification;cluster analysis;proteins;clustering coefficient;artificial intelligence;algorithms;pattern recognition automated;molecular sequence data;sequence alignment;structural classification of proteins;automatic classification;similarity measure;computer simulation;mammoth;structural similarity;sequence analysis protein	Structural classifications of proteins assume the existence of the fold, which is an intrinsic equivalence class of protein domains. Here, we test in which conditions such an equivalence class is compatible with objective similarity measures. We base our analysis on the transitive property of the equivalence relationship, requiring that similarity of A with B and B with C implies that A and C are also similar. Divergent gene evolution leads us to expect that the transitive property should approximately hold. However, if protein domains are a combination of recurrent short polypeptide fragments, as proposed by several authors, then similarity of partial fragments may violate the transitive property, favouring the continuous view of the protein structure space. We propose a measure to quantify the violations of the transitive property when a clustering algorithm joins elements into clusters, and we find out that such violations present a well defined and detectable cross-over point, from an approximately transitive regime at high structure similarity to a regime with large transitivity violations and large differences in length at low similarity. We argue that protein structure space is discrete and hierarchic classification is justified up to this cross-over point, whereas at lower similarities the structure space is continuous and it should be represented as a network. We have tested the qualitative behaviour of this measure, varying all the choices involved in the automatic classification procedure, i.e., domain decomposition, alignment algorithm, similarity score, and clustering algorithm, and we have found out that this behaviour is quite robust. The final classification depends on the chosen algorithms. We used the values of the clustering coefficient and the transitivity violations to select the optimal choices among those that we tested. Interestingly, this criterion also favours the agreement between automatic and expert classifications. As a domain set, we have selected a consensus set of 2,890 domains decomposed very similarly in SCOP and CATH. As an alignment algorithm, we used a global version of MAMMOTH developed in our group, which is both rapid and accurate. As a similarity measure, we used the size-normalized contact overlap, and as a clustering algorithm, we used average linkage. The resulting automatic classification at the cross-over point was more consistent than expert ones with respect to the structure similarity measure, with 86% of the clusters corresponding to subsets of either SCOP or CATH superfamilies and fewer than 5% containing domains in distinct folds according to both SCOP and CATH. Almost 15% of SCOP superfamilies and 10% of CATH superfamilies were split, consistent with the notion of fold change in protein evolution. These results were qualitatively robust for all choices that we tested, although we did not try to use alignment algorithms developed by other groups. Folds defined in SCOP and CATH would be completely joined in the regime of large transitivity violations where clustering is more arbitrary. Consistently, the agreement between SCOP and CATH at fold level was lower than their agreement with the automatic classification obtained using as a clustering algorithm, respectively, average linkage (for SCOP) or single linkage (for CATH). The networks representing significant evolutionary and structural relationships between clusters beyond the cross-over point may allow us to perform evolutionary, structural, or functional analyses beyond the limits of classification schemes. These networks and the underlying clusters are available at http://ub.cbm.uam.es/research/ProtNet.php.	algorithm;alignment;average linkage cluster analysis;cath;choice behavior;classification;clustering coefficient;domain decomposition methods;linkage (software);polypeptides;protein domain;protein, organized by structure;scop;similarity measure;single linkage cluster analysis;turing completeness;upgma;vertex-transitive graph;genetic linkage;mammoth <mammuthus>;statistical cluster	Alberto Pascual-García;David Abia;Angel R. Ortiz;Ugo Bastolla	2009	PLoS Computational Biology	10.1371/journal.pcbi.1000331	computer simulation;biology;protein structure;bioinformatics;structural similarity;machine learning;sequence alignment;data mining;clustering coefficient;domain decomposition methods;peptide sequence;cluster analysis;protein domain	Comp.	4.110058943287807	-59.7016516346798	104725
53eac2059610d4ad6cbae26b0f8f43f763181341	gemma: a resource for the reuse, sharing and meta-analysis of expression profiling data	software;genomics;database management systems;gene expression profiling annotation;databases genetic;annotation;genomics and proteomics;meta analysis as topic;gene expression profiling	UNLABELLED Gemma is a database, analysis software system and web site for genomics data re-use and meta-analysis. Currently, Gemma contains analyzed data from over 3300 expression profiling studies, yielding hundreds of millions of differential expression results and coexpression patterns (correlated expression) for retrieval and visualization. With optional registration users can save their own data and securely share it with other users. Web services and integration with third-party resources further increase the scope of the tools, which include a Cytoscape plugin.   AVAILABILITY http://chibi.ubc.ca/Gemma, Apache 2.0 license.	cytoscape;database;gemma (invertebrate);gene expression profiling;imagery;molecular profiling;profiling (computer programming);reuse (action);software system;web site;web service;registration - actclass	Anton Zoubarev;Kelsey M. Hamer;Kiran Keshav;E. Luke McCarthy;Joseph Roy C. Santos;Thea Van Rossum;Cameron McDonald;Adam Hall;Xiang Wan;Raymond Lim;Jesse A. Gillis;Paul Pavlidis	2012	Bioinformatics	10.1093/bioinformatics/bts430	biology;genomics;computer science;bioinformatics;data mining;gene expression profiling;world wide web	Visualization	-2.373649741109542	-58.94489261113451	104727
dc5dde7ed5fc33a91ad54f249e4af5e3f21b1843	novel pathway compendium analysis elucidates mechanism of pro-angiogenic synthetic small molecule	mecanismo;tumor necrosis factor alpha;signal transduction;small molecule;bioinformatique;indoles;models biological;angiogenesis inducing agents;cells cultured;angiogenesis;transforming growth factor beta;mechanism;molecule petite;humans;matrix metalloproteinase 14;bioinformatica;endothelial cells;gene expression profiling;oligonucleotide array sequence analysis;molecula pequena;mecanisme;angiogenese;bioinformatics	MOTIVATION Computational techniques have been applied to experimental datasets to identify drug mode-of-action. A shortcoming of existing approaches is the requirement of large reference databases of compound expression profiles. Here, we developed a new pathway-based compendium analysis that couples multi-timepoint, controlled microarray data for a single compound with systems-based network analysis to elucidate drug mechanism more efficiently.   RESULTS We applied this approach to a transcriptional regulatory footprint of phthalimide neovascular factor 1 (PNF1)-a novel synthetic small molecule that exhibits significant in vitro endothelial potency-spanning 1-48 h post-supplementation in human micro-vascular endothelial cells (HMVEC) to comprehensively interrogate PNF1 effects. We concluded that PNF1 first induces tumor necrosis factor-alpha (TNF-alpha) signaling pathway function which in turn affects transforming growth factor-beta (TGF-beta) signaling. These results are consistent with our previous observations of PNF1-directed TGF-beta signaling at 24 h, including differential regulation of TGF-beta-induced matrix metalloproteinase 14 (MMP14/MT1-MMP) which is implicated in angiogenesis. Ultimately, we illustrate how our pathway-based compendium analysis more efficiently generates hypotheses for compound mechanism than existing techniques.	adrenergic beta-antagonists;angiogenic process;compendium;computation;database;exhibits as topic;file spanning;gene regulatory network;metalloproteases;microarray;neoplasms;numerous;phthalimides;sc-3-149;small molecule;software release life cycle;synthetic intelligence;transcription, genetic;transforming growth factor beta;transforming growth factors;trivial graph format;tumor necrosis factors	Kristen A. Wieghaus;Erwin P. Gianchandani;Mikell A. Paige;Milton L. Brown;Edward A. Botchwey;Jason A. Papin	2008	Bioinformatics	10.1093/bioinformatics/btn451	transforming growth factor;biology;small molecule;mechanism;bioinformatics;tumor necrosis factor alpha;gene expression profiling;signal transduction	Comp.	5.575935005375975	-58.91698796857424	104983
e4bf3367c8eb71a6a96c320e77f418feebf0524c	a new method of representing dna sequences which combines ease of visual analysis with machine readability	dna;transcription genetic;software;investigation method;methode etude;computerized processing;tratamiento informatico;repetitive sequences nucleic acid;primary structure;dna viral;estructura primaria;metodo estudio;visual analysis;tecnica;simian virus 40;base sequence;dna sequence;traitement informatique;technique;structure primaire	A new method of representing DNA sequences has been devised which is termed stave projection. Compared with other formats for showing the base sequences of DNA, this method greatly enhances the ease of visual analysis of the sequences of bases and it is also in a machine readable form. Using this method it is possible to identify and annotate all of the functional features found in DNA sequences.	base;human-readable medium;format	J. E. Cowin;C. H. Jellis;D. Rickwood	1986	Nucleic acids research	10.1093/nar/14.1.509	biology;dna sequencing;visual analytics;bioinformatics;protein primary structure;genetics;dna	Comp.	-4.3020033117650955	-56.39648171364859	105020
8eada562425272e0441d4c357156fb223fa2fd4e	understanding sequencing data as compositions: an outlook and review		Motivation Although seldom acknowledged explicitly, count data generated by sequencing platforms exist as compositions for which the abundance of each component (e.g. gene or transcript) is only coherently interpretable relative to other components within that sample. This property arises from the assay technology itself, whereby the number of counts recorded for each sample is constrained by an arbitrary total sum (i.e. library size). Consequently, sequencing data, as compositional data, exist in a non-Euclidean space that, without normalization or transformation, renders invalid many conventional analyses, including distance measures, correlation coefficients and multivariate statistical models.   Results The purpose of this review is to summarize the principles of compositional data analysis (CoDA), provide evidence for why sequencing data are compositional, discuss compositionally valid methods available for analyzing sequencing data, and highlight future directions with regard to this field of study.   Supplementary information Supplementary data are available at Bioinformatics online.	approximation;bioinformatics;bioinformatics;biopolymer sequencing;coefficient;communications satellite;composition;compositional data;count data;database normalization;geographic information systems;iterative method;microsoft outlook for mac;normalize;rna;rendering (computer graphics);sequence number;statistical model;transcript;cell transformation	Thomas P. Quinn;Ionas Erb;Mark F. Richardson;Tamsyn M. Crowley	2018		10.1093/bioinformatics/bty175	data mining;computer science;compositional data;count data;multivariate statistics;statistical model;rna-seq;bioinformatics	Comp.	4.564528526618713	-52.83357178495751	105057
03f7e71437f430db908d72e68cd7e9048665404f	network evaluation from the consistency of the graph structure with the measured data	escherichia coli;simulation and modeling;sample size;generalized extreme value distribution;knowledge bases;normal distribution;confidence intervals;systems biology;research design;gene regulatory networks;physiological cellular and medical topics;databases genetic;models biological;computational biology bioinformatics;sos response genetics;active network;cell physiological phenomena;likelihood functions;reproducibility of results;predictive value of tests;simulation study;algorithms;dna repair;network structure;neural networks computer;protein interaction mapping;adaptation biological;gene regulatory network;molecular interactions;computer simulation;gene expression profiling;oligonucleotide array sequence analysis;bioinformatics;knowledge base	A knowledge-based network, which is constructed by extracting as many relationships identified by experimental studies as possible and then superimposing them, is one of the promising approaches to investigate the associations between biological molecules. However, the molecular relationships change dynamically, depending on the conditions in a living cell, which suggests implicitly that all of the relationships in the knowledge-based network do not always exist. Here, we propose a novel method to estimate the consistency of a given network with the measured data: i) the network is quantified into a log-likelihood from the measured data, based on the Gaussian network, and ii) the probability of the likelihood corresponding to the measured data, named the graph consistency probability (GCP), is estimated based on the generalized extreme value distribution. The plausibility and the performance of the present procedure are illustrated by various graphs with simulated data, and with two types of actual gene regulatory networks in Escherichia coli: the SOS DNA repair system with the corresponding data measured by fluorescence, and a set of 29 networks with data measured under anaerobic conditions by microarray. In the simulation study, the procedure for estimating GCP is illustrated by a simple network, and the robustness of the method is scrutinized in terms of various aspects: dimensions of sampling data, parameters in the simulation study, magnitudes of data noise, and variations of network structures. In the actual networks, the former example revealed that our method operates well for an actual network with a size similar to those of the simulated networks, and the latter example illustrated that our method can select the activated network candidates consistent with the actual data measured under specific conditions, among the many network candidates. The present method shows the possibility of bridging between the static network from the literature and the corresponding measurements, and thus will shed light on the network structure variations in terms of the changes in molecular interaction mechanisms that occur in response to the environment in a living cell.	binding (molecular function);bridging (networking);dna repair;dimensions;estimated;fluorescence;games computers play;gene regulatory network;graph - visual representation;interactome;maxima and minima;mental association;microarray;name;normal statistical distribution;plausibility structure;sampling (signal processing);simulation	Shigeru Saito;Sachiyo Aburatani;Katsuhisa Horimoto	2008	BMC Systems Biology	10.1186/1752-0509-2-84	computer simulation;biology;gene regulatory network;knowledge base;computer science;bioinformatics;machine learning;data mining;genetics;systems biology	Comp.	5.463788514235573	-57.01774593915094	105364
0328daea2939ede3ccf4c6fe15f41f3bd52062c0	utility and limitations of using gene expression data to identify functional associations		Gene co-expression has been widely used to hypothesize gene function through guilt-by association. However, it is not clear to what degree co-expression is informative, whether it can be applied to genes involved in different biological processes, and how the type of dataset impacts inferences about gene functions. Here our goal is to assess the utility and limitations of using co-expression as a criterion to recover functional associations between genes. By determining the percentage of gene pairs in a metabolic pathway with significant expression correlation, we found that many genes in the same pathway do not have similar transcript profiles and the choice of dataset, annotation quality, gene function, expression similarity measure, and clustering approach significantly impacts the ability to recover functional associations between genes using Arabidopsis thaliana as an example. Some datasets are more informative in capturing coordinated expression profiles and larger data sets are not always better. In addition, to recover the maximum number of known pathways and identify candidate genes with similar functions, it is important to explore rather exhaustively multiple dataset combinations, similarity measures, clustering algorithms and parameters. Finally, we validated the biological relevance of co-expression cluster memberships with an independent phenomics dataset and found that genes that consistently cluster with leucine degradation genes tend to have similar leucine levels in mutants. This study provides a framework for obtaining gene functional associations by maximizing the information that can be obtained from gene expression datasets.	annotation;candidate disease gene;cluster analysis;elegant degradation;gene co-expression network;gene expression programming;gene regulatory network;information;large;mental association;phenomics;relevance;silo (dataset);similarity measure;transcript;algorithm;leucine catabolic process;mutant;statistical cluster	Sahra Uygun;Cheng Peng;Melissa D. Lehti-Shiu;Robert L. Last	2016		10.1371/journal.pcbi.1005244	gene expression;genetics;bioinformatics;biology	Comp.	4.603866025945079	-55.13960611762465	105545
48e454f42af19b4fc0bd325a4212ee57b6ee8214	a conceptual database model for genomic research		We describe a conceptual model for genome databases that facilitates the process of building, maintaining, and disseminating physically anchored genetic linkage maps. The model has been implemented as a relational database at the Roman L. Hruska U.S. Meat Animal Research Center (MARC). Development of consensus maps using disparate data from different reference pedigrees or laboratories is supported. The model is of use to quantitative and population geneticists interested in loci that affect phenotypes and marker-assisted selection, and it is sufficiently flexible for centralized, species genome databases facilitating comparative mapping. The MARC genome database is used to assemble, maintain, and disseminate physically anchored genetic linkage maps for cattle, swine, and sheep currently based on more than 100,000 genotypes from 1,000 markers. Integrated with linkage analysis software, this database permits frequent updates of physically anchored genetic linkage maps.		John W. Keele;James E. Wray;D. W. Behrens;Gary A. Rohrer;S. L. F. Sunden;Steven M. Kappes;Michael D. Bishop;R. T. Stone;Leeson J. Alexander;Craig Beattie	1994	Journal of computational biology : a journal of computational molecular cell biology	10.1089/cmb.1994.1.65	bioinformatics;genetics	Comp.	-2.7128937379069247	-61.85670268800351	105635
449fbde6e41cbf586984a4d67ada00f5bd948f05	visualizing the genome: techniques for presenting human genome data and annotations	genes;alternative splicing;introns;database management systems;computer graphics;databases genetic;chromosome mapping;sequence analysis dna;computational biology bioinformatics;semantic zooming;protein structure;proteins;visualization technique;genome human;human genome;software development;human genome project;algorithms;gene structure;humans;interactive graphics;combinatorial libraries;base sequence;computational biology;computer appl in life sciences;high frequency;protein isoforms;exons;genome sequence;microarrays;bioinformatics	"""In order to take full advantage of the newly available public human genome sequence data and associated annotations, biologists require visualization tools (""""genome browsers"""") that can accommodate the high frequency of alternative splicing in human genes and other complexities. In this article, we describe visualization techniques for presenting human genomic sequence data and annotations in an interactive, graphical format. These techniques include: one-dimensional, semantic zooming to show sequence data alongside gene structures; color-coding exons to indicate frame of translation; adjustable, moveable tiers to permit easier inspection of a genomic scene; and display of protein annotations alongside gene structures to show how alternative splicing impacts protein structure and function. These techniques are illustrated using examples from two genome browser applications: the Neomorphic GeneViewer annotation tool and ProtAnnot, a prototype viewer which shows protein annotations in the context of genomic sequence. By presenting techniques for visualizing genomic data, we hope to provide interested software developers with a guide to what features are most likely to meet the needs of biologists as they seek to make sense of the rapidly expanding body of public genomic data and annotations."""	affymetrix;alternative splicing;bioinformatics;color-coding;dna, complementary;data sources;diagram;embedded system;embedding;eric blossom;exons;flowers;graphical user interface;imagery;interpretation process;java;manuscripts;mast/stem cell growth factor receptor kit, human;melissa;open-source software;pierre robin syndrome;programming languages;programming language;protein annotation;protein domain;prototype;rna splicing;sequence alignment;software developer;software development kit;transcript;zooming user interface	Ann E. Loraine;Gregg A. Helt	2002		10.1186/1471-2105-3-19	computational biology;biology;bioinformatics;gene;genetics	Comp.	-2.852897414462268	-58.52019275609329	105739
84e93e73804b3d08c5d7bc9e2941ea32e64d0ee4	molecular dynamics simulation reveals structural and thermodynamic features of kinase activation by cancer mutations within the epidermal growth factor receptor	affinity;free energy landscape;molecular dynamics simulation;domain;inhibitor complexes;epidermal growth factor receptor;mechanism;abl kinase;conformations;protein activation;binding;cancer mutation	The epidermal growth factor receptor (EGFR) is a major target for drugs in treating lung carcinoma as it promotes cell growth and tumor progression. Structural studies have demonstrated that EGFR exists in an equilibrium between catalytically active and inactive forms, and dramatic conformational transitions occur during its activation. It is known that EGFR mutations promote such conformational changes that affect its activation and drug efficacy. The most common point mutation in lung cancer patients is a leucine to arginine substitution at amino acid 834 (L834R). In a recent article, we have studied changes in drug binding affinities due to cancer mutations of EGFR using ensemble molecular dynamics (MD) simulations. Here, we address an enhanced activation mechanism thought to be associated with this mutation. Using extended timescale MD simulations, the structural and energetic properties are studied for both active and inactive conformations of EGFR. The thermodynamic stabilities of these two conformations are characterized by free energy landscapes estimated from molecular mechanics/Poisson-Boltzmann solvent area calculations. Our study reveals that the L834R mutation introduces conformational changes in both states, adjusting the relative stabilities of active and inactive conformations and hence the activation of the EGFR kinase.		Shunzhou Wan;Peter V. Coveney	2011	Journal of computational chemistry	10.1002/jcc.21866	biochemistry;molecular dynamics;molecular biology;chemistry;mechanism;domain	Comp.	8.678472957102413	-63.023892248485765	105750
2a3ce714d7c01d738b8c5019d46a7e6e63b5bbfd	catma, a comprehensive genome-scale resource for silencing and transcript profiling of arabidopsis genes	rna interference;europa continente;genoma de planta;dados de sequencia molecular;rna silencing;program;genome annotation;database management systems;design criteria;qr microbiology;genome plant;proteinas de arabidopsis;database;sequencia de bases;databases genetic;chromosome mapping;transcription factors;bases de dados geneticas;expression;computational biology bioinformatics;design rules;large scale;genomic dna;mapeamento cromossomico;etiquetas de sequencias expressas;sistemas de gerenciamento de base de dados;identification;functional genomics;gene silencing;gene family;algorithms;biology and life sciences;arabidopsis proteins;sequence tags;microarray;molecular sequence data;transcriptional profiling;europe;combinatorial libraries;base sequence;sista;dna sequence;computer appl in life sciences;fatores de transcricao;inativacao genica;expressed sequence tags;microarrays;bioinformatics	The Complete Arabidopsis Transcript MicroArray (CATMA) initiative combines the efforts of laboratories in eight European countries [1] to deliver gene-specific sequence tags (GSTs) for the Arabidopsis research community. The CATMA initiative offers the power and flexibility to regularly update the GST collection according to evolving knowledge about the gene repertoire. These GST amplicons can easily be reamplified and shared, subsets can be picked at will to print dedicated arrays, and the GSTs can be cloned and used for other functional studies. This ongoing initiative has already produced approximately 24,000 GSTs that have been made publicly available for spotted microarray printing and RNA interference. GSTs from the CATMA version 2 repertoire (CATMAv2, created in 2002) were mapped onto the gene models from two independent Arabidopsis nuclear genome annotation efforts, TIGR5 and PSB-EuGène, to consolidate a list of genes that were targeted by previously designed CATMA tags. A total of 9,027 gene models were not tagged by any amplified CATMAv2 GST, and 2,533 amplified GSTs were no longer predicted to tag an updated gene model. To validate the efficacy of GST mapping criteria and design rules, the predicted and experimentally observed hybridization characteristics associated to GST features were correlated in transcript profiling datasets obtained with the CATMAv2 microarray, confirming the reliability of this platform. To complete the CATMA repertoire, all 9,027 gene models for which no GST had yet been designed were processed with an adjusted version of the Specific Primer and Amplicon Design Software (SPADS). A total of 5,756 novel GSTs were designed and amplified by PCR from genomic DNA. Together with the pre-existing GST collection, this new addition constitutes the CATMAv3 repertoire. It comprises 30,343 unique amplified sequences that tag 24,202 and 23,009 protein-encoding nuclear gene models in the TAIR6 and EuGène genome annotations, respectively. To cover the remaining untagged genes, we identified 543 additional GSTs using less stringent design criteria and designed 990 sequence tags matching multiple members of gene families (Gene Family Tags or GFTs) to cover any remaining untagged genes. These latter 1,533 features constitute the CATMAv4 addition. To update the CATMA GST repertoire, we designed 7,289 additional sequence tags, bringing the total number of tagged TAIR6-annotated Arabidopsis nuclear protein-coding genes to 26,173. This resource is used both for the production of spotted microarrays and the large-scale cloning of hairpin RNA silencing vectors. All information about the resulting updated CATMA repertoire is available through the CATMA database http://www.catma.org.	annotation;choose (action);clone cells;experiment;gst gene;gst-nef protein, recombinant;gene family;gene prediction;interference (communication);laboratory;matching;microarray;nuclear proteins;nucleic acid hybridization;primer;pacific symposium on biocomputing;portable software apps;printing;rna interference;rule (guideline);slco6a1 gene;tracer;transcript;glutathione s-transferase pi	Gert Sclep;Joke Allemeersch;Robin Liechti;Björn De Meyer;Jim Beynon;Rishikesh P Bhalerao;Yves Moreau;Wilfried Nietfeld;Jean-Pierre Renou;Philippe Reymond;Martin Kuiper;Pierre Hilson	2007	BMC Bioinformatics	10.1186/1471-2105-8-400	functional genomics;identification;biology;dna sequencing;dna microarray;gene silencing;bioinformatics;rna interference;expression;gene family;genomic dna;rna silencing;microarray;genome project;genetics;expressed sequence tag;transcription factor	Comp.	-0.5322004205399637	-59.46261413510612	105852
6953073720fa559aaf5ed9912537351ae3e5ac65	predicting protein-binding regions in rna using nucleotide profiles and compositions	simulation and modeling;systems biology;physiological cellular and medical topics;computational biology bioinformatics;algorithms;bioinformatics	Motivated by the increased amount of data on protein-RNA interactions and the availability of complete genome sequences of several organisms, many computational methods have been proposed to predict binding sites in protein-RNA interactions. However, most computational methods are limited to finding RNA-binding sites in proteins instead of protein-binding sites in RNAs. Predicting protein-binding sites in RNA is more challenging than predicting RNA-binding sites in proteins. Recent computational methods for finding protein-binding sites in RNAs have several drawbacks for practical use. We developed a new support vector machine (SVM) model for predicting protein-binding regions in mRNA sequences. The model uses sequence profiles constructed from log-odds scores of mono- and di-nucleotides and nucleotide compositions. The model was evaluated by standard 10-fold cross validation, leave-one-protein-out (LOPO) cross validation and independent testing. Since actual mRNA sequences have more non-binding regions than protein-binding regions, we tested the model on several datasets with different ratios of protein-binding regions to non-binding regions. The best performance of the model was obtained in a balanced dataset of positive and negative instances. 10-fold cross validation with a balanced dataset achieved a sensitivity of 91.6%, a specificity of 92.4%, an accuracy of 92.0%, a positive predictive value (PPV) of 91.7%, a negative predictive value (NPV) of 92.3% and a Matthews correlation coefficient (MCC) of 0.840. LOPO cross validation showed a lower performance than the 10-fold cross validation, but the performance remains high (87.6% accuracy and 0.752 MCC). In testing the model on independent datasets, it achieved an accuracy of 82.2% and an MCC of 0.656. Testing of our model and other state-of-the-art methods on a same dataset showed that our model is better than the others. Sequence profiles of log-odds scores of mono- and di-nucleotides were much more powerful features than nucleotide compositions in finding protein-binding regions in RNA sequences. But, a slight performance gain was obtained when using the sequence profiles along with nucleotide compositions. These are preliminary results of ongoing research, but demonstrate the potential of our approach as a powerful predictor of protein-binding regions in RNA. The program and supporting data are available at http://bclab.inha.ac.kr/RBPbinding .	binding sites;composition;cross reactions;cross-validation (statistics);interaction;kerrison predictor;matthews correlation coefficient;negative predictive value of diagnostic test;negative feedback;nucleopolyhedrovirus;nucleotides;organism;position weight matrix;positive predictive value of diagnostic test;rna;rna, messenger;sensitivity and specificity;silo (dataset);support vector machine;triangulation	Daesik Choi;Byungkyu Brian Park;Hanju Chae;Wook Lee;Kyungsook Han	2017		10.1186/s12918-017-0386-4	biology;computer science;bioinformatics;data science;data mining;systems biology	Comp.	9.62329131941999	-56.20196951349897	105887
02c1e0c85a3a8c266f31f20a36f74aa02f88ef91	context-dependent role of mitochondrial fusion-fission in clonal expansion of mtdna mutations	journal article;plos computational biology;drntu science biological sciences genetics	The accumulation of mutant mitochondrial DNA (mtDNA) molecules in aged cells has been associated with mitochondrial dysfunction, age-related diseases and the ageing process itself. This accumulation has been shown to often occur clonally, where mutant mtDNA grow in number and overpopulate the wild-type mtDNA. However, the cell possesses quality control (QC) mechanisms that maintain mitochondrial function, in which dysfunctional mitochondria are isolated and removed by selective fusion and mitochondrial autophagy (mitophagy), respectively. The aim of this study is to elucidate the circumstances related to mitochondrial QC that allow the expansion of mutant mtDNA molecules. For the purpose of the study, we have developed a mathematical model of mitochondrial QC process by extending our previous validated model of mitochondrial turnover and fusion-fission. A global sensitivity analysis of the model suggested that the selectivity of mitophagy and fusion is the most critical QC parameter for clearing de novo mutant mtDNA molecules. We further simulated several scenarios involving perturbations of key QC parameters to gain a better understanding of their dynamic and synergistic interactions. Our model simulations showed that a higher frequency of mitochondrial fusion-fission can provide a faster clearance of mutant mtDNA, but only when mutant-rich mitochondria that are transiently created are efficiently prevented from re-fusing with other mitochondria and selectively removed. Otherwise, faster fusion-fission quickens the accumulation of mutant mtDNA. Finally, we used the insights gained from model simulations and analysis to propose a possible circumstance involving deterioration of mitochondrial QC that permits mutant mtDNA to expand with age.	aging;autophagy;clone;dna binding site;dna, mitochondrial;de novo transcriptome assembly;disease;gain;human mitochondrial molecular clock;interaction;license;mathematical model;mathematics;mitochondrial degradation;mitochondrial diseases;mitochondrial fusion;mitochondrial inheritance;mitochondrial myopathies;mitochondrial turnover;population parameter;selectivity (electronic);simulation;singlet fission;specimen source codes - quality control;synergy;tissue expansion;tree accumulation;negative regulation of protein import into mitochondrial outer membrane	Zhi Yang Tam;Jan Gruber;Barry Halliwell;Rudiyanto Gunawan	2015		10.1371/journal.pcbi.1004183	biology;bioinformatics;mitochondrial fusion;genetics	SE	6.72326717892863	-62.83571183288785	105925
019ea7aa938111c142988810995a3f165b0405aa	a leave-one-out cross-validation sas macro for the identification of markers associated with survival	score selection;survival analysis;sas macro;cross validation;prognostic markers;article;clinical trials	A proper internal validation is necessary for the development of a reliable and reproducible prognostic model for external validation. Variable selection is an important step for building prognostic models. However, not many existing approaches couple the ability to specify the number of covariates in the model with a cross-validation algorithm. We describe a user-friendly SAS macro that implements a score selection method and a leave-one-out cross-validation approach. We discuss the method and applications behind this algorithm, as well as details of the SAS macro.		Christel Rushing;Anuradha Bulusu;Herbert I. Hurwitz;Andrew B. Nixon;Herbert Pang	2015	Computers in biology and medicine	10.1016/j.compbiomed.2014.11.015	econometrics;data mining;mathematics;survival analysis;cross-validation;statistics	SE	6.180671032066097	-52.613680460336894	106071
5ea8e72e0cd0ca6d27beae3c49b6fa88da2b394b	dnaaligneditor: dna alignment editor tool	software;individual sequence;maize;user interface;nucleotides;sequence analysis dna;relational database;nucleotide sequence;computational biology bioinformatics;client server;polymorphism;data access;next generation;algorithms;molecular sequence data;sequence alignment;multiple sequence alignment;user computer interface;combinatorial libraries;base sequence;dna sequence;computer appl in life sciences;polymorphism single nucleotide;word processing;microarrays;bioinformatics;population genetics	With advances in DNA re-sequencing methods and Next-Generation parallel sequencing approaches, there has been a large increase in genomic efforts to define and analyze the sequence variability present among individuals within a species. For very polymorphic species such as maize, this has lead to a need for intuitive, user-friendly software that aids the biologist, often with naïve programming capability, in tracking, editing, displaying, and exporting multiple individual sequence alignments. To fill this need we have developed a novel DNA alignment editor. We have generated a nucleotide sequence alignment editor (DNAAlignEditor) that provides an intuitive, user-friendly interface for manual editing of multiple sequence alignments with functions for input, editing, and output of sequence alignments. The color-coding of nucleotide identity and the display of associated quality score aids in the manual alignment editing process. DNAAlignEditor works as a client/server tool having two main components: a relational database that collects the processed alignments and a user interface connected to database through universal data access connectivity drivers. DNAAlignEditor can be used either as a stand-alone application or as a network application with multiple users concurrently connected. We anticipate that this software will be of general interest to biologists and population genetics in editing DNA sequence alignments and analyzing natural sequence variation regardless of species, and will be particularly useful for manual alignment editing of sequences in species with high levels of polymorphism.	acquired immunodeficiency syndrome;base sequence;client–server model;color-coding;data access;genetics, population;multi-user;naivety;nucleotides;relational database;sequence alignment;server (computer);server (computing);spatial variability;usability;user interface device component;variation (genetics)	Hector Sanchez-Villeda;Steven G. Schroeder;Sherry Flint-Garcia;Katherine E. Guill;Masanori Yamasaki;Michael D. McMullen	2007	BMC Bioinformatics	10.1186/1471-2105-9-154	data access;biology;polymorphism;dna sequencing;nucleotide;dna microarray;multiple sequence alignment;nucleic acid sequence;relational database;computer science;bioinformatics;theoretical computer science;sequence alignment;user interface;population genetics;genetics;client–server model;alignment-free sequence analysis	Comp.	-2.365907870848662	-58.6417579828832	106132
e74c7712fc61dd4303f57c50bea77a7ceca5357b	identification of a small optimal subset of cpg sites as bio-markers from high-throughput dna methylation profiles	lung cancer;sensitivity and specificity;computational method;computational biology bioinformatics;large scale;risk assessment;artificial intelligence;algorithms;dna methylation;feature selection;humans;combinatorial libraries;high throughput;computational biology;lung neoplasms;computer appl in life sciences;genetic markers;cpg islands;microarrays;bioinformatics	DNA methylation patterns have been shown to significantly correlate with different tissue types and disease states. High-throughput methylation arrays enable large-scale DNA methylation analysis to identify informative DNA methylation biomarkers. The identification of disease-specific methylation signatures is of fundamental and practical interest for risk assessment, diagnosis, and prognosis of diseases. Using published high-throughput DNA methylation data, a two-stage feature selection method was developed to select a small optimal subset of DNA methylation features to precisely classify two sample groups. With this approach, a small number of CpG sites were highly sensitive and specific in distinguishing lung cancer tissue samples from normal lung tissue samples. This study shows that it is feasible to identify DNA methylation biomarkers from high-throughput DNA methylation profiles and that a small number of signature CpG sites can suffice to classify two groups of samples. The computational method we developed in the study is efficient to identify signature CpG sites from disease samples with complex methylation patterns.	antivirus software;biological markers;british informatics olympiad;carcinoma of lung;computation;dna methylation;feature selection;high-throughput computing;histocompatibility testing;information;risk assessment;scientific publication;structure of parenchyma of lung;subgroup;throughput;cytidylyl-3'-5'-guanosine	Hailong Meng;Edward Lenn Murrelle;Guoya Li	2008	BMC Bioinformatics	10.1186/1471-2105-9-457	high-throughput screening;risk assessment;biology;molecular biology;differentially methylated regions;dna microarray;computer science;bioinformatics;dna methylation;genetic marker;cpg site;feature selection;genetics;illumina methylation assay	Comp.	6.329568200389884	-55.35949027073759	106180
1e9e15229b6f6986a884bb5af79a307ca4de193a	a simple yet accurate correction for winner's curse can predict signals discovered in much larger genome scans		MOTIVATION For genetic studies, statistically significant variants explain far less trait variance than 'sub-threshold' association signals. To dimension follow-up studies, researchers need to accurately estimate 'true' effect sizes at each SNP, e.g. the true mean of odds ratios (ORs)/regression coefficients (RRs) or Z-score noncentralities. Naïve estimates of effect sizes incur winner's curse biases, which are reduced only by laborious winner's curse adjustments (WCAs). Given that Z-scores estimates can be theoretically translated on other scales, we propose a simple method to compute WCA for Z-scores, i.e. their true means/noncentralities.   RESULTS WCA of Z-scores shrinks these towards zero while, on P-value scale, multiple testing adjustment (MTA) shrinks P-values toward one, which corresponds to the zero Z-score value. Thus, WCA on Z-scores scale is a proxy for MTA on P-value scale. Therefore, to estimate Z-score noncentralities for all SNPs in genome scans, we propose F: DR I: nverse Q: uantile T: ransformation (FIQT). It (i) performs the simpler MTA of P-values using FDR and (ii) obtains noncentralities by back-transforming MTA P-values on Z-score scale. When compared to competitors, realistic simulations suggest that FIQT is more (i) accurate and (ii) computationally efficient by orders of magnitude. Practical application of FIQT to Psychiatric Genetic Consortium schizophrenia cohort predicts a non-trivial fraction of sub-threshold signals which become significant in much larger supersamples.   CONCLUSIONS FIQT is a simple, yet accurate, WCA method for Z-scores (and ORs/RRs, via simple transformations).   AVAILABILITY AND IMPLEMENTATION A 10 lines R function implementation is available at https://github.com/bacanusa/FIQT CONTACT: sabacanu@vcu.edu   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	algorithmic efficiency;arabic numeral 0;bioinformatics;coefficient;congenital central hypoventilation;consortium;estimated;fullmetal alchemist 2: curse of the crimson elixir;hereditary multiple exostoses;large;mental disorders;nitroprusside;odds ratio;sample variance;schizophrenia;simulation;single nucleotide polymorphism;antineoplaston a10;cell transformation;pemetrexed	T. Bernard Bigdeli;Donghyung Lee;Bradley Todd Webb;Brien P. Riley;Vladimir I. Vladimirov;Ayman H. Fanous;Kenneth S. Kendler;Silviu Bacanu	2016		10.1093/bioinformatics/btw303	econometrics;bioinformatics;data mining;mathematics;statistics	Comp.	3.4004456932261946	-52.842081780771004	106187
ff57b16fca9ce4e96a5f4f030f58cdea0a645335	identification and characterization of transcriptional enhancers in the human genome	academic as topic;bioinformatics identification and characterization of transcriptional enhancers in the human genome university of california;molecular biology;dissertations;nathaniel david;san diego bing ren heintzman	Eukaryotic transcriptional regulation requires the integration of complex signals by the transcriptional promoter. Distinct sequence elements, characteristic chromatin modifications and coordinated protein-DNA interactions at these sequences constitute a transcriptional regulatory code that remains poorly understood today. Here, we review recent experimental and computational advances that have enabled the identification and analysis of transcriptional promoters on an unprecedented scale, laying a foundation for systematic determination of the transcriptional regulatory networks in eukaryotic cells. The knowledge gained from these large-scale investigations has challenged some conventional concepts of promoter structure and function, and provided valuable insights into the complex gene regulatory mechanisms in a variety of organisms.	gene regulatory network;interaction	Nathaniel D. Heintzman	2007			biology;bioinformatics;genetics	Comp.	3.396470475657319	-59.41014458817954	106189
2efc878148dcec184b46a5eef061d772272652d3	deterministic effects propagation networks for reconstructing protein signaling networks from multiple interventions	rna interference;breast cancer cells;bayesian network;signaling network;signal transduction;gene regulatory networks;reversed phase;bayes theorem;trastuzumab;protein network;computational biology bioinformatics;proteins;biological systems;algorithms;protein expression;missing data;combinatorial libraries;computational biology;computer appl in life sciences;gene expression profiling;reverse engineering;microarrays;bioinformatics	"""Modern gene perturbation techniques, like RNA interference (RNAi), enable us to study effects of targeted interventions in cells efficiently. In combination with mRNA or protein expression data this allows to gain insights into the behavior of complex biological systems. In this paper, we propose Deterministic Effects Propagation Networks (DEPNs) as a special Bayesian Network approach to reverse engineer signaling networks from a combination of protein expression and perturbation data. DEPNs allow to reconstruct protein networks based on combinatorial intervention effects, which are monitored via changes of the protein expression or activation over one or a few time points. Our implementation of DEPNs allows for latent network nodes (i.e. proteins without measurements) and has a built in mechanism to impute missing data. The robustness of our approach was tested on simulated data. We applied DEPNs to reconstruct the ERBB signaling network in de novo trastuzumab resistant human breast cancer cells, where protein expression was monitored on Reverse Phase Protein Arrays (RPPAs) after knockdown of network proteins using RNAi. DEPNs offer a robust, efficient and simple approach to infer protein signaling networks from multiple interventions. The method as well as the data have been made part of the latest version of the R package """"nem"""" available as a supplement to this paper and via the Bioconductor repository."""	bayesian network;bioconductor;biological system;de novo transcriptome assembly;inference;interference (communication);mammary neoplasms;missing data;rna interference;reverse engineering;reverse phase protein lysate microarray;schema (genetic algorithms);software propagation;statistical imputation;protein expression;trastuzumab	Holger Fröhlich;Özgür Sahin;Dorit Arlt;Christian Bender;Tim Beißbarth	2009	BMC Bioinformatics	10.1186/1471-2105-10-322	biology;gene regulatory network;molecular biology;dna microarray;missing data;bioinformatics;rna interference;bayesian network;gene expression profiling;protein expression;bayes' theorem;genetics;signal transduction;reverse engineering	Comp.	5.930086147476283	-56.560842978300016	106217
ef4d71decf5a76b5cf5fddee66c1d0f4d2a8f5c6	a literature mining-based approach for identification of cellular pathways associated with chemoresistance in cancer	cancer;chemoresistance;chemotherapy;gene;pathway;systems biology	Chemoresistance is a major obstacle to the successful treatment of many human cancer types. Increasing evidence has revealed that chemoresistance involves many genes and multiple complex biological mechanisms including cancer stem cells, drug efflux mechanism, autophagy and epithelial-mesenchymal transition. Many studies have been conducted to investigate the possible molecular mechanisms of chemoresistance. However, understanding of the biological mechanisms in chemoresistance still remains limited. We surveyed the literature on chemoresistance-related genes and pathways of multiple cancer types. We then used a curated pathway database to investigate significant chemoresistance-related biological pathways. In addition, to investigate the importance of chemoresistance-related markers in protein-protein interaction networks identified using the curated database, we used a gene-ranking algorithm designed based on a graph-based scoring function in our previous study. Our comprehensive survey and analysis provide a systems biology-based overview of the underlying mechanisms of chemoresistance.	autophagy;biochemical pathway;cancer stem cells;drug efflux;gene regulatory network;genes;neoplasms;score;scoring functions for docking;systems biology;algorithm;epithelial to mesenchymal transition;protein protein interaction	Jung Hun Oh;Joseph O. Deasy	2016	Briefings in bioinformatics	10.1093/bib/bbv053	bioinformatics	Comp.	6.953038699697168	-60.12725490133002	106261
d39cc2f16ad05618a44a69c0983dc67af8b284f6	bs seeker: precise mapping for bisulfite sequencing	software;genomics;ucla;nucleotides;sulfites;sequence analysis dna;genetic mapping;genomes;computational biology bioinformatics;bisulfites;genome human;human genome;genome;algorithms;dna methylation;humans;sequence alignment;synthetic data;combinatorial libraries;next generation sequencing;base sequence;computer appl in life sciences;microarrays;bioinformatics	Bisulfite sequencing using next generation sequencers yields genome-wide measurements of DNA methylation at single nucleotide resolution. Traditional aligners are not designed for mapping bisulfite-treated reads, where the unmethylated Cs are converted to Ts. We have developed BS Seeker, an approach that converts the genome to a three-letter alphabet and uses Bowtie to align bisulfite-treated reads to a reference genome. It uses sequence tags to reduce mapping ambiguity. Post-processing of the alignments removes non-unique and low-quality mappings. We tested our aligner on synthetic data, a bisulfite-converted Arabidopsis library, and human libraries generated from two different experimental protocols. We evaluated the performance of our approach and compared it to other bisulfite aligners. The results demonstrate that among the aligners tested, BS Seeker is more versatile and faster. When mapping to the human genome, BS Seeker generates alignments significantly faster than RMAP and BSMAP. Furthermore, BS Seeker is the only alignment tool that can explicitly account for tags which are generated by certain library construction protocols. BS Seeker provides fast and accurate mapping of bisulfite-converted reads. It can work with BS reads generated from the two different experimental protocols, and is able to efficiently map reads to large mammalian genomes. The Python program is freely available at http://pellegrini.mcdb.ucla.edu/BS_Seeker/BS_Seeker.html .	align (company);alphabet;bisulfite sequencing;bowtie (sequence analysis);library (computing);mammals;nucleotides;protocols documentation;python;reading (activity);synthetic data;tmem59l gene;video post-processing;whole genome sequencing;cdna library construction;hydrogen sulfite	Pao-Yang Chen;Shawn Cokus;Matteo Pellegrini	2009		10.1186/1471-2105-11-203	biology;genomics;molecular biology;bioinformatics;genetics;genome	Comp.	-0.2581569480209838	-55.217766050883185	106312
2a25d344ad83b9558b7b4ff0fba8f474623f4195	ilses: identification lysine succinylation-sites with ensemble classification	databases;neural networks;computational modeling;proteins;bandwidth;amino acids;predictive models	Lysine succinylation is one of most important types in protein post-translational modification, which is involved in many cellular processes and serious diseases. However, effective recognition of such sites with traditional experiment methods may seem to be treated as time-consuming and laborious. Those methods can hardly meet the need of efficient identification a great deal of succinylated sites at speed. In this work, several physicochemical properties of succinylated sites have been extracted, such as the physicochemical property of the amino acids. Flexible neural tree, which is employed as the classification model, was utilized to integrate above mentioned features for generating a novel lysine succinylation prediction framework named ILSES (identification lysine succinylation-sites with ensemble features classification). Such method owns the ability to combining diverse features to predict lysine succinylation with high accuracy and real time.		Wenzheng Bao;Lin Zhu;De-shuang Huang	2016	2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2016.7822530	biochemistry;computer science;bioinformatics;machine learning;predictive modelling;computational model;artificial neural network;bandwidth	Robotics	9.681147960669698	-55.97020537743933	106415
1d8937d4cbbda93fe65da42c174bc28f12a5b23a	quadratic: scalable gene expression connectivity mapping for repurposing fda-approved therapeutics	biological patents;biomedical journals;drug discovery;text mining;europe pubmed central;citation search;connectivity mapping;citation networks;computational biology bioinformatics;multicore programming;research articles;big data;abstracts;open access;life sciences;clinical guidelines;repurposing;algorithms;full text;computational biology;computer appl in life sciences;rest apis;orcids;europe pmc;biomedical research;microarrays;bioinformatics;literature search	Gene expression connectivity mapping has proven to be a powerful and flexible tool for research. Its application has been shown in a broad range of research topics, most commonly as a means of identifying potential small molecule compounds, which may be further investigated as candidates for repurposing to treat diseases. The public release of voluminous data from the Library of Integrated Cellular Signatures (LINCS) programme further enhanced the utilities and potentials of gene expression connectivity mapping in biomedicine. We describe QUADrATiC ( http://go.qub.ac.uk/QUADrATiC ), a user-friendly tool for the exploration of gene expression connectivity on the subset of the LINCS data set corresponding to FDA-approved small molecule compounds. It enables the identification of compounds for repurposing therapeutic potentials. The software is designed to cope with the increased volume of data over existing tools, by taking advantage of multicore computing architectures to provide a scalable solution, which may be installed and operated on a range of computers, from laptops to servers. This scalability is provided by the use of the modern concurrent programming paradigm provided by the Akka framework. The QUADrATiC Graphical User Interface (GUI) has been developed using advanced Javascript frameworks, providing novel visualization capabilities for further analysis of connections. There is also a web services interface, allowing integration with other programs or scripts. QUADrATiC has been shown to provide an improvement over existing connectivity map software, in terms of scope (based on the LINCS data set), applicability (using FDA-approved compounds), usability and speed. It offers potential to biological researchers to analyze transcriptional data and generate potential therapeutics for focussed study in the lab. QUADrATiC represents a step change in the process of investigating gene expression connectivity and provides more biologically-relevant results than previous alternative solutions.	akka;architecture as topic;biomedicine;comparison of javascript frameworks;computation (action);computer;computers;concurrent computing;electronic signature;gene co-expression network;gene expression profiling;graphical user interface;interface device component;laptop;multi-core processor;programming paradigm;scalability;small molecule;subgroup;therapeutic procedure;transcription, genetic;usability;web service	Paul G. O'Reilly;Qing Wen;Peter Bankhead;Philip D. Dunne;Darragh G. McArt;Suzanne McPherson;Peter Hamilton;Ken I. Mills;Shu-Dong Zhang	2016		10.1186/s12859-016-1062-1	text mining;big data;dna microarray;repurposing;computer science;bioinformatics;data science;data mining;drug discovery	Comp.	-1.7221332334477117	-58.13341534895799	106424
61b8060c69ec8ebd21cfd3135e54a3e8994b55b0	designing for change in laboratory teaching: pharmacology and physiology	design for change			Michael W. Nott;Darren W. Williams;Robert E. Kemm	1994			computational biology;engineering;medicinal chemistry;physiology	HCI	1.6943775980215323	-65.24453415690638	106440
7da6ae9490e3568f9ee0cba4a69080a82392df5f	annotation of metagenome short reads using proxygenes	protein family;genome annotation;protein families;protein sequence;database;relative abundance;clustering method;gene prediction;microbial community	MOTIVATION A typical metagenome dataset generated using a 454 pyrosequencing platform consists of short reads sampled from the collective genome of a microbial community. The amount of sequence in such datasets is usually insufficient for assembly, and traditional gene prediction cannot be applied to unassembled short reads. As a result, analysis of such datasets usually involves comparisons in terms of relative abundances of various protein families. The latter requires assignment of individual reads to protein families, which is hindered by the fact that short reads contain only a fragment, usually small, of a protein.   RESULTS We have considered the assignment of pyrosequencing reads to protein families directly using RPS-BLAST against COG and Pfam databases and indirectly via proxygenes that are identified using BLASTx searches against protein sequence databases. Using simulated metagenome datasets as benchmarks, we show that the proxygene method is more accurate than the direct assignment. We introduce a clustering method which significantly reduces the size of a metagenome dataset while maintaining a faithful representation of its functional and taxonomic content.	amino acid sequence;assembly language;blast;cluster analysis;cog (project);gene prediction;list of biological databases;metagenome;pfam;protein family;pyrosequencing;reading (activity);sampling - surgical action;staphylococcal protein a;web server;statistical cluster	Daniel Dalevi;Natalia N Ivanova;Konstantinos Mavrommatis;Sean D. Hooper;Ernest Szeto;Philip Hugenholtz;Nikos C Kyrpides;Victor M. Markowitz	2008	Bioinformatics	10.1093/bioinformatics/btn276	biology;bioinformatics;data mining;protein family;genetics	Comp.	0.5428831512750208	-56.35716334923731	106578
9e18449405b91d5a099f939a465c869554c4e9fd	pertinent parameters selection for processing of short amino acid sequences	amino acid sequence;parameter selection			Zbigniew Szymanski;Stanislaw Jankowski;Marek Dwulit;Joanna Chodzynska;Lucjan Stanislaw Wyrwicz	2010			computer science;peptide sequence	Theory	1.9446177228638746	-63.53867038274852	106583
bda0f73b4030aa20cd488660b8664c73722326ab	a gibbs sampling strategy applied to the mapping of ambiguous short-sequence tags	sequence tagged site;marcador sts;prelevement;echantillonnage gibbs;gibbs sampling;marqueur sts;samplings;estrategia;sequence analysis dna;toma de muestra;carta de datos;genetic marker;marqueur genetique;dna transposable elements;strategy;chromatin immunoprecipitation;mappage;genome;algorithms;sequence tagged sites;mapping;base sequence;muestreo gibbs;computational biology;strategie;marcador genetico	MOTIVATION Chromatin immunoprecipitation followed by high-throughput sequencing (ChIP-seq) is widely used in biological research. ChIP-seq experiments yield many ambiguous tags that can be mapped with equal probability to multiple genomic sites. Such ambiguous tags are typically eliminated from consideration resulting in a potential loss of important biological information.   RESULTS We have developed a Gibbs sampling-based algorithm for the genomic mapping of ambiguous sequence tags. Our algorithm relies on the local genomic tag context to guide the mapping of ambiguous tags. The Gibbs sampling procedure we use simultaneously maps ambiguous tags and updates the probabilities used to infer correct tag map positions. We show that our algorithm is able to correctly map more ambiguous tags than existing mapping methods. Our approach is also able to uncover mapped genomic sites from highly repetitive sequences that can not be detected based on unique tags alone, including transposable elements, segmental duplications and peri-centromeric regions. This mapping approach should prove to be useful for increasing biological knowledge on the too often neglected repetitive genomic regions.   AVAILABILITY http://esbg.gatech.edu/jordan/software/map   CONTACT king.jordan@biology.gatech.edu   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	antioxidant response elements;base sequence;bioinformatics;biopolymer sequencing;experiment;gibbs sampling;high-throughput computing;inference;map;probability;repetitive region;sampling (signal processing);sampling - surgical action;segmental duplications, genomic;sequence number;tag (metadata);tag cloud;tags (device);throughput;algorithm;mapped	Jianrong Wang;Ahsan Huda;Victoria V. Lunyak;I. King Jordan	2010		10.1093/bioinformatics/btq460	biology;bioinformatics;sequence-tagged site;genetics	Comp.	1.3090358092767194	-55.17655492924159	106739
c006873e2fa488fde51851fa979f5c4ce31000fd	imgt-choreography for immunogenetics and immunoinformatics	superfamily;xml schema;hla;immunoinformatics;immunoglobulin;single chain fragment variable;database;annotation;antibody;web service;three dimensional;t cell receptor;genetics;mhc;phage display;antibody engineering;major histocompatibility complex;polymorphism;knowledge resource;immune system;genome evolution;three dimensional structure;information system;infectious disease;collier de perles;choreography;3d structure;imgt;ontology;immunogenetics;adaptive immunity	IMGT, the international ImMunoGeneTics information system (http://imgt.cines.fr), was created in 1989 at Montpellier, France. IMGT is a high quality integrated knowledge resource specialized in immunoglobulins (IG), T cell receptors (TR), major histocompatibility complex (MHC) of human and other vertebrates, and related proteins of the immune system (RPI) which belong to the immunoglobulin superfamily (IgSF) and MHC superfamily (MhcSF). IMGT provides a common access to standardized data from genome, proteome, genetics and three-dimensional structures. The accuracy and the consistency of IMGT data are based on IMGT-ONTOLOGY, a semantic specification of terms to be used in immunogenetics and immunoinformatics. IMGT-ONTOLOGY has been formalized using XML Schema (IMGT-ML) for interoperability with other information systems. We are developing Web services to automatically query IMGT databases and tools. This is the first step towards IMGT-Choreography which will trigger and coordinate dynamic interactions between IMGT Web services to process complex significant biological and clinical requests. IMGT-Choreography will further increase the IMGT leadership in immunogenetics and immunoinformatics for medical research (repertoire analysis of the IG antibody sites and of the TR recognition sites in autoimmune and infectious diseases, AIDS, leukemias, lymphomas, myelomas), veterinary research (IG and TR repertoires in farm and wild life species), genome diversity and genome evolution studies of the adaptive immune responses, biotechnology related to antibody engineering (single chain Fragment variable (scFv), phage displays, combinatorial libraries, chimeric, humanized and human antibodies), diagnostics (detection and follow up of residual diseases) and therapeutical approaches (grafts, immunotherapy, vaccinology). IMGT is freely available at http://imgt.cines.fr.	acquired immunodeficiency syndrome;biotechnology;cell signaling;cellular phone;chimera organism;combinatorial chemistry;communicable diseases;computational immunology;database;display resolution;humoral immune response;immune system;immunogenetics;immunoglobulins;immunotherapy;information system;interaction;interoperability;libraries;lymphoma;major histocompatibility complex;model of hierarchical complexity;multiple myeloma;question (inquiry);superfamily;specification;t-cell receptor;transplanted tissue;vertebrates;web service;xml schema;leukemia	Marie-Paule Lefranc;Oliver Clément;Quentin Kaas;Elodie Duprat;Patrick Chastellan;Isabelle Coelho;Kora Combres;Chantal Ginestoux;Véronique Giudicelli;Denys Chaume;Gérard Lefranc	2004	In silico biology		biology;immunogenetics;infectious disease;bioinformatics;ontology;antibody;immunology;genetics;major histocompatibility complex	DB	-1.618501041408684	-61.43884652317532	106838
6223654499970c41225365add551801f0b1debc2	optimizing the multivalent binding of the bacterial lectin leca by glycopeptide dendrimers for therapeutic purposes		"""Bacterial lectins are nonenzymatic sugar-binding proteins involved in the formation of biofilms and the onset of virulence. The weakness of individual sugar-lectin interactions is compensated by the potentially large number of simultaneous copies of such contacts, resulting in high overall sugar-lectin affinities and marked specificities. Therapeutic compounds functionalized with sugar residues can compete with the host glycans for binding to lectins only if they are able to take advantage of this multivalent binding mechanism. Glycopeptide dendrimers, featuring treelike topologies with sugar moieties at their leaves, have already shown great promise in this regard. However, optimizing the dendrimers' amino acid sequence is necessary to match the dynamics of the lectin active sites with that of the multivalent ligands. This work combines long-time-scale coarse-grained simulations of dendrimers and lectins with a reasoned exploration of the dendrimer sequence space in an attempt to suggest sequences that could maximize multivalent binding to the galactose-specific bacterial lectin LecA. These candidates are validated by simulations of mixed dendrimer/lectin solutions, and the effects of the dendrimers on lectin dynamics are discussed. This approach is an attractive first step in the conception of therapeutic compounds based on the dendrimer scaffold and contributes to the understanding of the various classes of multivalency that underpin the ubiquitous """"sugar code""""."""	amino acid sequence;amino acids;class;copy (object);dendrimers;galactose;glycopeptides;interaction;ligands;mannose binding lectin;microbial biofilms;onset (audio);optimizing compiler;polysaccharides;simulation;solutions;sugar;virulence	Benjamin Bouvier	2016	Journal of chemical information and modeling	10.1021/acs.jcim.6b00146	biology;biochemistry;stereochemistry;organic chemistry	Comp.	8.60955803176452	-62.36499667905918	106849
cf27bfb2b1eb6284b8a93a4bfa9919240ec44634	interfering contexts of regulatory sequence elements	regulatory element;coded modulation	MOTIVATION Although one would normally expect a given regulatory element to perform best when it fully matches its consensus sequence, this is generally far from being the case. Usually, almost none of the actual sites fits the consensus exactly, and some of those that do fit do not perform well. The main reason for that is the very nature of the sequences and the messages (codes) they contain. Normally, any given stretch of the sequence with one or another regulatory site not only carries this regulatory message, but several more messages of various types as well. These messages overlap with the regulatory element in such a way that the letter (base) which actually appears in any given sequence position simultaneously belongs to one or more additional codes. Apart from numerous individual codes (sequence patterns) specific for a given species or gene, there are many different general (universal) sequence codes all interacting with one another. These are the classical triplet code, DNA shape code, chromatin code, gene splicing code, modulation code and many more, including those that have not yet been discovered. Examples of overlapping of different codes and their interaction are discussed, as well as the role of degeneracy of the codes and the sequence complexity as a function of code density.	code;consensus sequence;degeneracy (graph theory);fits;genetic engineering;interaction;modulation;rna splicing;recombinant dna;triplet state;message	Edward N. Trifonov	1996	Computer applications in the biosciences : CABIOS	10.1093/bioinformatics/12.5.423	biology;bioinformatics;mathematics;algorithm	Theory	0.6742040552190443	-52.16261840562921	106875
52baf112a92a753a82cdeced5027ac7f51507416	the hera database and its use in the characterization of endoplasmic reticulum proteins	base donnee;affichage;proteine;visualizacion;leader peptide;database;base dato;bioinformatique;hombre;peptido senal;result;litterature scientifique;physical characteristic;reticulo endoplasmico;display;endoplasmic reticulum;literatura cientifica;human;resultado;signal peptide;proteina;resultat;bioinformatica;reticulum endoplasmique;peptide signal;protein;scientific literature;exhaustive search;homme;bioinformatics	MOTIVATION Information concerning endoplasmic reticulum (ER) proteins is widely dispersed and cannot be easily and rapidly processed by the biological community. We present a comprehensive database of human ER proteins, called Human ER Aperçu (Hera). The Hera database was constructed by exhaustively searching through public databases and the scientific literature for ER proteins.   RESULTS Hera was used for the analysis of characteristics common to all human ER proteins. Our results show that a high proportion of ER proteins (59%) have at least one transmembrane domain and display physical characteristics consistent with this observation. In addition, one-third of ER proteins contain known ER retrieval or retention signals and 70% of ER proteins contain a signal peptide or anchor. Finally, 85% of ER proteins contain at least one InterPro motif. The most abundant InterPro motifs in ER proteins represent many of the most well-characterized functions of the ER.	database;endoplasmic reticulum;erdős–rényi model;fifty nine;interpro;motif;scientific literature;signal peptides;transmembrane domain	Michelle S. Scott;Guoqing Lu;Michael T. Hallett;David Y. Thomas	2004	Bioinformatics	10.1093/bioinformatics/bth010	biology;computer science;bioinformatics;signal peptide	DB	-4.15011639543161	-56.64391863100397	106979
579b92655c976884146168106dbb99f1bdebe454	thyme: a database for thioester-active enzymes	catalytic domain;selected works;amino acid sequence;enzyme;oxidoreductases;fatty acids;ligases;thiolester hydrolases;protein structure tertiary;hydro lyases;bepress;carbon carbon ligases;macrolides;acyltransferases;databases protein	The ThYme (Thioester-active enzYme; http://www.enzyme.cbirc.iastate.edu) database has been constructed to bring together amino acid sequences and 3D (tertiary) structures of all the enzymes constituting the fatty acid synthesis and polyketide synthesis cycles. These enzymes are active on thioester-containing substrates, specifically those that are parts of the acyl-CoA synthase, acyl-CoA carboxylase, acyl transferase, ketoacyl synthase, ketoacyl reductase, hydroxyacyl dehydratase, enoyl reductase and thioesterase enzyme groups. These groups have been classified into families, members of which are similar in sequences, tertiary structures and catalytic mechanisms, implying common protein ancestry. ThYme is continually updated as sequences and tertiary structures become available.	access network;acyl coenzyme a;acyltransferase;amino acid sequence;amino acids;base excision repair;classification;database;fatty acids;fatty acid biosynthetic process;information source;rodent nomenclature name;thymus vulgaris;transferase;acyl-coa dehydrogenase;polyketide biosynthetic process;tertiary;thioester	David C. Cantu;Yingfei Chen;Matthew L. Lemons;Peter J. Reilly	2011		10.1093/nar/gkq1072	biology;biochemistry;enzyme;botany;peptide sequence	Comp.	4.265202548584019	-63.03702106160721	107002
bbac294f622ceb6b7abde5279022ad6376d61ba9	hepatitis c virus genetic association to rate of liver fibrosis progression	belief networks;genomics;feature selection mathematical modeling predictions co evolution epistasis interaction dependent variables;liver;prosthetics;genetics;medical computing;prosthetics belief networks biochemistry bioinformatics diseases feature extraction genetics genomics liver medical computing molecular biophysics physiological models;viral disease hepatitis c virus genetic association liver fibrosis progression rate status liver transplantation genotype viral infection rapid liver fibrosis progression risk factor hcv genetic heterogeneity liver disease progression hcv 1b core genomic region sequence ns3 genomic region sequence ns5b genomic region sequence hcv sequence transplantation status patient classification rapid fibrosis progression slow fibrosis progression bayesian network model linear projection model nucleotide sequence nucleotide physicochemical properties hydrophobicity polarity dipole moment surface area stacking area polymorphic nucleotide site hcv variant clustering rfp relevant genetic feature identification hcv strain classification hcv genetic marker molecular surveillance hcv related disease;feature extraction;molecular biophysics;diseases;diseases genomics bioinformatics liver diseases feature extraction;physiological models;biochemistry;bioinformatics	Hepatitis C virus (HCV) is a major cause of liver disease world-wide and the leading cause of liver transplantation in developed countries. There are 7 major genotypes divided into >100 subtypes, with genotype 1 being responsible for the majority of infections in the US. Several risk factors predisposing patients to rapid progression of liver fibrosis have been identified. However, to date, there are no conclusive studies supporting the role of HCV genetic heterogeneity in progression of liver disease. Here, consensus sequences of the HCV 1b Core, NS3 and NS5b genomic regions obtained from patients with known rate of fibrosis progression (RFP), who have been identified through a study of cohorts of hepatitis C patients with (n=22) and without (n=20) liver transplantation, were analyzed. All HCV sequences were linked to RFP and transplantation status. Based on RFP all patients were classified into 2 classes with rapid (RP) and slow (SP) progression to fibrosis. A set of Bayesian networks (BN) and linear projection (LP) models was generated using nucleotide (nt) sequences and nt physicochemical properties, such as hydrophobicity, polarity, dipole moment, surface area and stacking area, to examine HCV genetic association to RFP. Both types of models consider inter-relationships among polymorphic nt sites and associate them to RFP. Clustering of HCV variants based on physicochemical properties in LP graphs as well as BN analysis of nt sequences revealed similarity among HCV variants sampled from patients of same RFP class. Especially tight clustering was observed for HCV variants from SP class in LP model. Both models allow for the identification of the most RFP-relevant genetic features of HCV. Models constructed using these features classified HCV strains into 2 RFP classes with the 85%-93% accuracy in validation assays regardless of the transplantation status, thus indicating a significant robustness of the models and suggesting a potential application of the identified genetic features as markers for detection of RFP. This is the first report of HCV genetic markers strongly associated with RFP. The apparent HCV genetic association to yearly RFP in all patients studied here has significant implications for understanding the contribution of HCV genetic diversity to RFP and offers a new framework for molecular surveillance of the HCV-related disease and viral diseases in general.	bayesian network;chromosome (genetic algorithm);cluster analysis;color gradient;consensus sequence;genetic algorithm;rp (complexity);request for proposal;stacking	James Lara;Yuri Khudyakov;F. Xavier López-Labrador;Fernando González-Candelas;Marina Berenguer	2013	2013 IEEE 3rd International Conference on Computational Advances in Bio and medical Sciences (ICCABS)	10.1109/ICCABS.2013.6629225	biology;biochemistry;genomics;feature extraction;computer science;bioinformatics;virology;genetics;molecular biophysics	Comp.	7.4159149278296335	-54.547537663319616	107014
986de850646bd300b953724e0ee1e0ad1266888d	uncovering the nutritional landscape of food	fats;food consumption;food;data interpretation statistical;nutritional requirements;fatty acids;niacin;nutrients;cholines;diet;humans;poultry;nutritive value	Recent progresses in data-driven analysis methods, including network-based approaches, are revolutionizing many classical disciplines. These techniques can also be applied to food and nutrition, which must be studied to design healthy diets. Using nutritional information from over 1,000 raw foods, we systematically evaluated the nutrient composition of each food in regards to satisfying daily nutritional requirements. The nutrient balance of a food was quantified and termed nutritional fitness; this measure was based on the food's frequency of occurrence in nutritionally adequate food combinations. Nutritional fitness offers a way to prioritize recommendable foods within a global network of foods, in which foods are connected based on the similarities of their nutrient compositions. We identified a number of key nutrients, such as choline and α-linolenic acid, whose levels in foods can critically affect the nutritional fitness of the foods. Analogously, pairs of nutrients can have the same effect. In fact, two nutrients can synergistically affect the nutritional fitness, although the individual nutrients alone may not have an impact. This result, involving the tendency among nutrients to exhibit correlations in their abundances across foods, implies a hidden layer of complexity when exploring for foods whose balance of nutrients within pairs holistically helps meet nutritional requirements. Interestingly, foods with high nutritional fitness successfully maintain this nutrient balance. This effect expands our scope to a diverse repertoire of nutrient-nutrient correlations, which are integrated under a common network framework that yields unexpected yet coherent associations between nutrients. Our nutrient-profiling approach combined with a network-based analysis provides a more unbiased, global view of the relationships between foods and nutrients, and can be extended towards nutritional policies, food marketing, and personalized nutrition.	agriculture;amino acid metabolism, inborn errors;body composition;bottleneck (engineering);choline;coherence (physics);complexity;composition;computation;cooking (activity);detailed balance;exercise;fitness function;food;food, fortified;global network;healthy diet;holism;irreducibility;malnutrition;mental association;multilayer perceptron;national origin;nutrient cycle;nutrients;nutrition disorders;nutritional physiological phenomena;nutritional requirements;personalization;policy;raw foods;requirement;synergy;vitamins [va class];alpha-linolenic acid	Seunghyeon Kim;Jaeyun Sung;Mathias Foo;Yong-Su Jin;Pan-Jun Kim	2015		10.1371/journal.pone.0118697	biology;food science;biochemistry;pathology;nutrient;biotechnology;dietary reference intake		6.03106563071174	-61.67459334928191	107155
239848db02d5f44d0827d5372404285264e4ce86	a learned comparative expression measure for affymetrix genechip dna microarrays	dna;false discovery rate;biology computing;support vector machine learned comparative expression measure affymetrix genechip dna microarrays static model gene expression probe level data pattern classification mismatch probe values regression based method rma microarray analysis false discovery rma training mas5 log ratio statistic;support vector machines;learning artificial intelligence genetics biology computing pattern classification support vector machines regression analysis dna;levels of selection;genetics;chip;gene expression;microarray analysis;dna probes bioinformatics support vector machines testing semiconductor device measurement genomics computer science gene expression statistics;differential expression;pattern classification;regression analysis;support vector machine microarrays gene expression;support vector machine;learning artificial intelligence;dna microarray;microarrays;perfect match	"""Perhaps the most common question that a microarray study can ask is, """"Between two given biological conditions, which genes exhibit changed expression levels?"""" Existing methods for answering this question either generate a comparative measure based upon a static model, or take an indirect approach, first estimating absolute expression levels and then comparing the estimated levels to one another. We present a method for detecting changes in gene expression between two samples based on data from Affymetrix GeneChips. Using a library of over 200,000 known cases of differential expression, we create a learned comparative expression measure (LCEM) based on classification of probe-level data patterns as changed or unchanged. LCEM uses perfect match probe data only; mismatch probe values did not prove to be useful in this context. LCEM is particularly powerful in the case of small microarry studies, in which a regression-based method such as RMA cannot generalize, and in detecting small expression changes. At the levels of selectivity that are typical in microarray analysis, the LCEM shows a lower false discovery rate than either MAS5 or RMA trained from a single chip. When many chips are available to RMA, LCEM performs better on two out of the three data sets, and nearly as well on the third. Performance of the MAS5 log ratio statistic was notably bad on all datasets."""	affymetrix genechip operating software;chamaecyparis lawsoniana;dna microarray;estimated;gene expression;mismatch probe;perfect match probe;registered medical assistant (occupation);revolution in military affairs;selectivity (electronic);sensor	Will Sheffler;Eli Upfal;John Sedivy;William Stafford Noble	2005	2005 IEEE Computational Systems Bioinformatics Conference (CSB'05)	10.1109/CSB.2005.5	biology;support vector machine;dna microarray;computer science;bioinformatics;machine learning;data mining;genetics	Comp.	4.329262129258557	-52.27374578557076	107204
0772afdb37c901cee5def113650c741d82230bc5	the presence of highly similar notes within the mimic-iii dataset		one is compiling statistics or training predictive algorithms that model the language or attributes in notes. We developed an algorithm to identify and characterize highly similar notes within the Multiparameter Intelligent Monitoring in Intensive Care (MIMIC-III) dataset. We found that there were multiple instances of exact copies, common outputs, and template notes form the public domain MIMIC-III dataset. Abstract	algorithm;compiler;mimic	Rodney A. Gabriel;Sanjeev Shenoy;Tsung-Ting Kuo;Julian McAuley;Chun-Nan Hsu	2017			biological system;biology	ML	-2.7516800578472616	-62.88447983848182	107235
40b8167fd8b78b6aa4ada6871242fdeec0a199a1	comparison of ligand-based and receptor-based virtual screening of hiv entry inhibitors for the cxcr4 and ccr5 receptors using 3d ligand shape matching and ligand-receptor docking	virtual screening;shape matching	HIV infection is initiated by fusion of the virus with the target cell through binding of the viral gp120 protein with the CD4 cell surface receptor protein and the CXCR4 or CCR5 co-receptors. There is currently considerable interest in developing novel ligands that can modulate the conformations of these co-receptors and, hence, ultimately block virus-cell fusion. This article describes a detailed comparison of the performance of receptor-based and ligand-based virtual screening approaches to find CXCR4 and CCR5 antagonists that could potentially serve as HIV entry inhibitors. Because no crystal structures for these proteins are available, homology models of CXCR4 and CCR5 have been built, using bovine rhodopsin as the template. For ligand-based virtual screening, several shape-based and property-based molecular comparison approaches have been compared, using high-affinity ligands as query molecules. These methods were compared by virtually screening a library assembled by us, consisting of 602 known CXCR4 and CCR5 inhibitors and some 4700 similar presumed inactive molecules. For each receptor, the library was queried using known binders, and the enrichment factors and diversity of the resulting virtual hit lists were analyzed. Overall, ligand-based shape-matching searches yielded higher enrichments than receptor-based docking, especially for CXCR4. The results obtained for CCR5 suggest the possibility that different active scaffolds bind in different ways within the CCR5 pocket.		Violeta I. Pérez-Nueno;David W. Ritchie;Obdulia Rabal;Rosalia Pascual;José I. Borrell;Jordi Teixidó	2008	Journal of chemical information and modeling	10.1021/ci700415g	crystallography;biology;chemistry;virtual screening;bioinformatics;combinatorial chemistry;computational chemistry	Comp.	9.994089068871087	-59.94552701802303	107291
d755cdb089e1cc9b686a134cc1c57d1f29abcb94	stochasticity and networks in genomic data	dna;genes;stochastic processes bayes methods biochemistry biology computing cellular biophysics dna genetics molecular biophysics physiological models proteins;biology computing;bayesian network;cellular processes;genotype;bayes methods;genomic data;gene interaction network;poisson statistics;dna microarrays;genetics;genome sequencing;metabolites;mesoscopic biology stochasticity genomic data biological sciences genes proteins metabolites biological molecules genome sequencing genotype phenotype dna microarrays bayesian network gene interaction network cellular processes gene expression rna transcription poisson statistics;gene expression;stochasticity;proteins;stochastic processes;mesoscopic biology;biological molecules;molecular biophysics;systems biology biological systems data mining laboratories biological system modeling predictive models cells biology technological innovation proteins biological processes;biological sciences;phenotype;physiological models;cellular biophysics;biochemistry;rna transcription	Two trends are driving innovation and discovery in biological sciences: technologies that allow holistic surveys of genes, proteins, and metabolites and a realization that biological processes are driven by complex networks of interacting biological molecules. However, there is a gap between the gene lists emerging from genome sequencing projects and the network diagrams that are essential if we are to understand the link between genotype and phenotype. ‘Omic technologies such as DNA microarrays were once heralded as providing a window into those networks, but so far their success has been limited. Although many techniques have been developed to deal with microarray data, to date their ability to extract network relationships has been limited. We believed that by imposing constraints on the networks, based on associations reported through articles indexed in PubMed, we could more effectively extract biologically relevant results from microarray data and develop testable hypotheses that could then be validated in the laboratory. Using literature networks as constraints on a Bayesian network analysis of microarray data, we show that we are able to recover evidence for a wide range of known networks and pathways, even in experiments not explicitly designed to probe them. With a putative gene-interaction network, the problem of producing viable models of the cell remains. While systems biology approaches that attempt to develop quantitative, predictive models of cellular processes have received great attention, it is surprising to note that the starting point for all cellular gene expression, the transcription of RNA, has not been described and measured in a population of living cells. To address this problem, we propose a simple (and obvious) model for transcript levels based on Poisson statistics and provide supporting experimental evidence for genes known to be expressed at high, moderate, and low levels. Although what we describe as a microscopic process, occurring at the level of an individual cell, the data we provide uses a small number of cells where the echoes of the underlying stochastic processes can be seen. Not only do these data confirm our model, but this general strategy opens up a potential new approach, Mesoscopic Biology, that can be used to assess the natural variability of processes occurring at the cellular level in biological systems.	bayesian network;biological system;complex network;dna microarray;diagram;experiment;gene expression programming;heart rate variability;holism;interaction network;mesoscopic physics;predictive modelling;pubmed;social network analysis;stochastic process;systems biology;transcription (software);whole genome sequencing	John Quackenbush	2007		10.1109/BIBE.2007.4375530	biology;dna sequencing;gene expression;dna microarray;bioinformatics;phenotype;gene;genotype;bayesian network;biomolecule;poisson distribution;stochastic;transcription;genetics;dna;molecular biophysics	Comp.	2.9290663513318167	-55.288187818015814	107332
98c613daebd806b1d55e035a2c2ba596fe90db18	the major transcripts of the kinetoplast dna of trypanosoma brucei are very small ribosomal rnas	transcription genetic;ribosomal;animals;mitochondria;trypanosoma brucei brucei;ribosomal genetics;drug effects;chloramphenicol pharmacology;protein structure secondary;base composition;nucleotides;journal article;genetics;nucleotide sequence;trypanosoma brucei brucei drug effects genetics;non u s gov t;restriction enzyme;56 75 7 chloramphenicol;rna;dna kinetoplast;molecular weight;dna restriction enzymes;transcription;support;secondary structure;chloramphenicol;comparative study;ribosomal rna;nucleic acid conformation;rna ribosomal 16s;ec 3 1 21 dna restriction enzymes;rna ribosomal;drug resistance;base sequence;trypanosoma brucei;nucleic acid;ribosomes;species specificity;0 rna;genetic	The nucleotide sequence has been determined of a 2.2 kb segment of kinetoplast DNA, which encodes the major mitochondrial transcripts (12S and 9S) of Trypanosoma brucei. The sequence shows that the 12S RNA is a large subunit rRNA, although sufficiently unusual for resistance to chloramphenicol to be predicted. The 9S RNA has little homology with other rRNAs, but a possible secondary structure is not unlike that of the 2.5-fold larger E. coli 16S rRNA. We conclude that the 12S RNA (about 1230 nucleotides) and the 9S RNA (about 640 nucleotides) are the smallest homologues of the E. coli 23S and 16S rRNAs yet observed.	12s mitochondrial ribosomal rna;base sequence;chloramphenicol;dna-directed dna polymerase;homologous gene;homology (biology);large;nucleotides;transcript;trypanosoma brucei ab:titr:pt:ser:qn:if;kinetoplast	I. C. Eperon;J. W. Janssen;Jan H. J. Hoeijmakers;Piet Borst	1983	Nucleic acids research	10.1093/nar/11.1.105	biology;intron;molecular biology;rna;ribosomal rna;genetics	Comp.	4.2782389018182885	-61.991682156537465	107385
152e4d466e2c738d65721f0b36c4858f61b65104	identification of a specific base sequence of pathogenic e. coli through a genomic analysis	comparative genomic;sequence type 131;essential genes;pathogenic e coli	E. coli sequence type 131 (ST131) is one of pathogens that causes resistant infections. Comparative genome analyses allow interpretations of the virulence factors of pathogens. Thus, in this study, we analysis the genomic differences between the pathogenic E. coli ST131 and the non-pathogenic E. coli K-12. In this study, we identify the genomic differences between 96 E. coli ST131 strains and the E. coli K-12 in gene elements and their non-coding regulation elements. Using next-generation whole-genome sequencing data, we investigated genetic variations of protein-coding regions and their regulation regions. After the alignment of the sequence reads, large numbers of single nucleotide variants (SNVs) were observed in the regulation and protein-coding sequences. In the regulation regions, we found strong conserved regions, in this case, ribosome binding sites. In the gene regions, we found conserved start and stop codons with the specific position varying commonly in each codon. Except for these well-conserved regions, other variations were randomly distributed in regulation regions. Even a region having well-known conserved sequences such as -10 and -35 in the promoter had a similar level of variation. In this study, we found genomic variations between the pathogenic E. coli ST 131 strain and the non-pathogenic E. coli K-12. In addition, the numbers of sequence variations were determined in both the protein-coding regions and the regulation regions. However, we found that the effects of variations on the protein-coding regions are less significant than those on the regulation regions.	conserved sequence;randomness;whole genome sequencing	Soobok Joe;Hojung Nam	2014		10.1145/2665970.2665981	biology;molecular biology;bioinformatics;genetics	Comp.	4.082170319635978	-61.72727819093885	107397
15c5e39e7ea2c3068bddfa35f7e06b907988105d	rjacgh: bayesian analysis of acgh arrays for detecting copy number changes and recurrent regions	deteccion;methode bayes;bayes theorem;sequence analysis dna;detection;comparative genomic hybridization;analyse;red;copy number;gene dosage;numero copia;reseau arrangement;nombre copie;array;analysis;bayesian analysis;analisis	SUMMARY Several methods have been proposed to detect copy number changes and recurrent regions of copy number variation from aCGH, but few methods return probabilities of alteration explicitly, which are the direct answer to the question 'is this probe/region altered?' RJaCGH fits a Non-Homogeneous Hidden Markov model to the aCGH data using Markov Chain Monte Carlo with Reversible Jump, and returns the probability that each probe is gained or lost. Using these probabilites, recurrent regions (over sets of individuals) of copy number alteration can be found.   AVAILABILITY RJaCGH is available as an R package from CRAN repositories (e.g. http://cran.r-project.org/web/packages).	copy number polymorphism;fits;gain;hidden markov model;leucaena pulverulenta;monte carlo method;probability;r language;repository;reversible-jump markov chain monte carlo;sensor	Oscar M. Rueda;Ramón Díaz-Uriarte	2009		10.1093/bioinformatics/btp307	biology;bioinformatics;analysis;mathematics;genetics;statistics	ML	-2.959273134525696	-55.24760565178006	107492
eedee01ce014a66f6d803aa3f9d3ce11b504a0c6	maizegdb update: new tools, data and interface for the maize model organism database	genes;community;software;plants;maize;metabolic networks and pathways;genome plant;databases genetic;datasets;genetics;genetic variation;gene expression;zea mays;models genetic;genes plant;user computer interface	MaizeGDB is a highly curated, community-oriented database and informatics service to researchers focused on the crop plant and model organism Zea mays ssp. mays. Although some form of the maize community database has existed over the last 25 years, there have only been two major releases. In 1991, the original maize genetics database MaizeDB was created. In 2003, the combined contents of MaizeDB and the sequence data from ZmDB were made accessible as a single resource named MaizeGDB. Over the next decade, MaizeGDB became more sequence driven while still maintaining traditional maize genetics datasets. This enabled the project to meet the continued growing and evolving needs of the maize research community, yet the interface and underlying infrastructure remained unchanged. In 2015, the MaizeGDB team completed a multi-year effort to update the MaizeGDB resource by reorganizing existing data, upgrading hardware and infrastructure, creating new tools, incorporating new data types (including diversity data, expression data, gene models, and metabolic pathways), and developing and deploying a modern interface. In addition to coordinating a data resource, the MaizeGDB team coordinates activities and provides technical support to the maize research community. MaizeGDB is accessible online at http://www.maizegdb.org.	database;informatics (discipline);interface device component;name;numerous;sessile serrated adenoma/polyp;technical support;zea mays;contents - htmllinktype	Carson M. Andorf;Ethalinda K. S. Cannon;John L. Portwood;Jack M. Gardiner;Lisa C. Harper;Mary L. Schaeffer;Bremen L. Braun;Darwin A. Campbell;Abhinav G. Vinnakota;Venktanaga V. Sribalusu;Miranda Huerta;Kyoung Tak Cho;Kokulapalan Wimalanathan;Jacqueline D. Richter;Emily D. Mauch;Bhavani S. Rao	2016		10.1093/nar/gkv1007	biology;community;gene expression;biotechnology;bioinformatics;genetic variation;gene;genetics	DB	-1.9984070683074566	-60.710556858911076	107725
27053079bfbb2bc5a97fa3c8a6565ec5036cb740	bioc: a minimalist approach to interoperability for biomedical text processing	software;data mining;journal article;humans;natural language processing;biomedical research	A vast amount of scientific information is encoded in natural language text, and the quantity of such text has become so great that it is no longer economically feasible to have a human as the first step in the search process. Natural language processing and text mining tools have become essential to facilitate the search for and extraction of information from text. This has led to vigorous research efforts to create useful tools and to create humanly labeled text corpora, which can be used to improve such tools. To encourage combining these efforts into larger, more powerful and more capable systems, a common interchange format to represent, store and exchange the data in a simple manner between different language processing systems and text mining tools is highly desirable. Here we propose a simple extensible mark-up language format to share text documents and annotations. The proposed annotation approach allows a large number of different annotations to be represented including sentences, tokens, parts of speech, named entities such as genes or diseases and relationships between named entities. In addition, we provide simple code to hold this data, read it from and write it back to extensible mark-up language files and perform some sample processing. We also describe completed as well as ongoing work to apply the approach in several directions. Code and data are available at http://bioc.sourceforge.net/. Database URL: http://bioc.sourceforge.net/	annotation;bio-alcamid;biocreative;body of uterus;c++;cations;class;clinical trial source data;common platform;compliance behavior;connector;ephrin type-b receptor 1, human;extensible markup language;functional requirement;global variable;how true feel vigorous right now;interoperability;java programming language;large;manuscripts;minimalism (computing);name;named entity;natural language processing;open-source software;programming languages;reuse (action);source code;text corpus;text mining;tracer;url data type;united states national institutes of health;web page;xml;sentence	Donald C. Comeau;Rezarta Islamaj Dogan;Paolo Ciccarese;K. Bretonnel Cohen;Martin Krallinger;Florian Leitner;Zhiyong Lu;Yifan Peng;Fabio Rinaldi;Manabu Torii;Alfonso Valencia;Karin M. Verspoor;Thomas C. Wiegers;Cathy H. Wu;W. John Wilbur	2013		10.1093/database/bat064	text graph;text mining;medical research;computer science;bioinformatics;data mining;database;world wide web;information retrieval	ML	-3.1064574749473897	-63.2093303913964	107768
220f217805541f9ef28cc88ca6f407340c82f42f	molecular dynamics modeling the synthetic and biological polymers interactions pre-studied via docking	virus internalization;computer aided design;hiv infections;amino acid sequence;hiv envelope protein gp41;molecular dynamics simulation;hiv 1;drug design;humans;molecular sequence data;membrane fusion;polymers;molecular docking simulation;maleates;anti hiv agents	In previous works we reported the design, synthesis and in vitro evaluations of synthetic anionic polymers modified by alicyclic pendant groups (hydrophobic anchors), as a novel class of inhibitors of the human immunodeficiency virus type 1 (HIV-1) entry into human cells. Recently, these synthetic polymers interactions with key mediator of HIV-1 entry-fusion, the tri-helix core of the first heptad repeat regions [HR1]3 of viral envelope protein gp41, were pre-studied via docking in terms of newly formulated algorithm for stepwise approximation from fragments of polymeric backbone and side-group models toward real polymeric chains. In the present article the docking results were verified under molecular dynamics (MD) modeling. In contrast with limited capabilities of the docking, the MD allowed of using much more large models of the polymeric ligands, considering flexibility of both ligand and target simultaneously. Among the synthesized polymers the dinorbornen anchors containing alternating copolymers of maleic acid were selected as the most representative ligands (possessing the top anti-HIV activity in vitro in correlation with the highest binding energy in the docking). To verify the probability of binding of the polymers with the [HR1]3 in the sites defined via docking, various starting positions of polymer chains were tried. The MD simulations confirmed the main docking-predicted priority for binding sites, and possibilities for axial and belting modes of the ligands-target interactions. Some newly MD-discovered aspects of the ligand's backbone and anchor units dynamic cooperation in binding the viral target clarify mechanisms of the synthetic polymers anti-HIV activity and drug resistance prevention.	acclimatization;amino acids;antiviral agents;approximation;attachments;binding sites;biopolymers;boat dock;body cavities;british informatics olympiad;brownian motion;coil device component;coiled-coil domain;contain (action);dental caries;dimensions;distance;docking (molecular);docking -molecular interaction;drug design;ervw-1 gene;evaluation;extrapolation;full scale;gnu nano;hiv infections;hiv-1;immunologic deficiency syndromes;in vitro [publication type];internet backbone;locus;large;ligands;mediator brand of benfluorex hydrochloride;mediator of activation protein;molecular dynamics;multiplication;multipoint ground;mutation;nethack;pendant dosage form;polymers;polypeptides;probability;pyschological bonding;registration;self-organization;sequence motif;simulation;small molecule;stepwise regression;synergetics (fuller);synthetic polymer;synthetic data;synthetic intelligence;tree accumulation;triangular function;trimipramine;utility functions on indivisible goods;verifying specimen;vertebral column;viral envelope proteins;algorithm;biology (field);maleic acid;multiplicity	Vladimir B. Tsvetkov;Alexander V. Serbin	2014		10.1007/s10822-014-9749-8	stereochemistry;molecular dynamics;lipid bilayer fusion;chemistry;searching the conformational space for docking;bioinformatics;computer aided design;organic chemistry;computational chemistry;peptide sequence;nuclear magnetic resonance;drug design	Comp.	9.443255076235138	-62.251472922815005	107830
04e12d56679b570a517f3b00adcd86b784ac2b6d	trade-off between positive and negative design of protein stability: from lattice models to real proteins	mutation analysis;models biological;protein stability;proteins;protein folding;lattice model;mutation	"""Two different strategies for stabilizing proteins are (i) positive design in which the native state is stabilized and (ii) negative design in which competing non-native conformations are destabilized. Here, the circumstances under which one strategy might be favored over the other are explored in the case of lattice models of proteins and then generalized and discussed with regard to real proteins. The balance between positive and negative design of proteins is found to be determined by their average """"contact-frequency"""", a property that corresponds to the fraction of states in the conformational ensemble of the sequence in which a pair of residues is in contact. Lattice model proteins with a high average contact-frequency are found to use negative design more than model proteins with a low average contact-frequency. A mathematical derivation of this result indicates that it is general and likely to hold also for real proteins. Comparison of the results of correlated mutation analysis for real proteins with typical contact-frequencies to those of proteins likely to have high contact-frequencies (such as disordered proteins and proteins that are dependent on chaperonins for their folding) indicates that the latter tend to have stronger interactions between residues that are not in contact in their native conformation. Hence, our work indicates that negative design is employed when insufficient stabilization is achieved via positive design owing to high contact-frequencies."""	greater than;interaction;lattice model (physics);mathematical concepts;mathematics;mutation testing;chaperonin	Orly Noivirt-Brik;Amnon Horovitz;Ron Unger	2009		10.1371/journal.pcbi.1000592	mutation;protein folding;biology;lattice model;bioinformatics;mutation testing;genetics	Comp.	6.827734407028858	-63.51136618051743	107831
6ddb337366b461c0baf12af65e79326ab635df4a	opossum: integrated tools for analysis of regulatory motif over-representation	animals;nf kappa b;caenorhabditis elegans;mice;saccharomyces cerevisiae;databases nucleic acid;transcription factors;binding sites;internet;promoter regions genetic;gene expression regulation;algorithms;humans;computational biology;gene expression profiling	The identification of over-represented transcription factor binding sites from sets of co-expressed genes provides insights into the mechanisms of regulation for diverse biological contexts. oPOSSUM, an internet-based system for such studies of regulation, has been improved and expanded in this new release. New features include a worm-specific version for investigating binding sites conserved between Caenorhabditis elegans and C. briggsae, as well as a yeast-specific version for the analysis of co-expressed sets of Saccharomyces cerevisiae genes. The human and mouse applications feature improvements in ortholog mapping, sequence alignments and the delineation of multiple alternative promoters. oPOSSUM2, introduced for the analysis of over-represented combinations of motifs in human and mouse genes, has been integrated with the original oPOSSUM system. Analysis using user-defined background gene sets is now supported. The transcription factor binding site models have been updated to include new profiles from the JASPAR database. oPOSSUM is available at http://www.cisreg.ca/oPOSSUM/		Shannan J. Ho Sui;Debra L. Fulton;David J. Arenillas;Andrew T. Kwon;Wyeth W. Wasserman	2007		10.1093/nar/gkm427	biology;molecular biology;the internet;regulation of gene expression;nfkb1;bioinformatics;binding site;gene expression profiling;genetics;transcription factor	Comp.	-0.5801406423892007	-59.46408005499134	107885
512a274d1e4831315a474fd5c48077c8f54db4bc	towards a new curation environment for the trembl database			digital curation;uniprot	Kai J. Runte;Henning Hermjakob;Rolf Apweiler	2001			bioinformatics;biology	DB	-1.5346358157922162	-61.602746291724266	108008
6530dcab93f837e028deaee6b2fe78e63dc44c84	phylosim - monte carlo simulation of sequence evolution in the r statistical computing environment	evolution molecular;software;animals;mathematical computing;sequence evolution;phylogeny;selective constraint;simulation framework;computational biology bioinformatics;models genetic;molecular evolution;statistical computing;monte carlo method;algorithms;humans;sequence alignment;combinatorial libraries;base sequence;monte carlo simulation;functional language;simulation tool;computer appl in life sciences;computer simulation;concurrent process;phylogenetic inference;uniform distribution;microarrays;bioinformatics	The Monte Carlo simulation of sequence evolution is routinely used to assess the performance of phylogenetic inference methods and sequence alignment algorithms. Progress in the field of molecular evolution fuels the need for more realistic and hence more complex simulations, adapted to particular situations, yet current software makes unreasonable assumptions such as homogeneous substitution dynamics or a uniform distribution of indels across the simulated sequences. This calls for an extensible simulation framework written in a high-level functional language, offering new functionality and making it easy to incorporate further complexity. PhyloSim is an extensible framework for the Monte Carlo simulation of sequence evolution, written in R, using the Gillespie algorithm to integrate the actions of many concurrent processes such as substitutions, insertions and deletions. Uniquely among sequence simulation tools, PhyloSim can simulate arbitrarily complex patterns of rate variation and multiple indel processes, and allows for the incorporation of selective constraints on indel events. User-defined complex patterns of mutation and selection can be easily integrated into simulations, allowing PhyloSim to be adapted to specific needs. Close integration with R and the wide range of features implemented offer unmatched flexibility, making it possible to simulate sequence evolution under a wide range of realistic settings. We believe that PhyloSim will be useful to future studies involving simulated alignments.	clinical act of insertion;computation (action);computational phylogenetics;computational statistics;evolution, molecular;functional programming;futures studies;gillespie algorithm;high- and low-level;indel mutation;inference;leucaena pulverulenta;monte carlo method;sequence alignment;simulated annealing;simulation	Botond Sipos;Tim Massingham;Gregory E. Jordan;Nick Goldman	2010		10.1186/1471-2105-12-104	computer simulation;biology;computer science;bioinformatics;theoretical computer science;monte carlo molecular modeling;monte carlo method	Comp.	2.095359489195292	-54.51111646880255	108022
1b3c11db9d32769322ebee43065ea226d2b1de88	computational modeling and analysis of iron release from macrophages	intracellular space;iron;models biological;homeostasis;humans;macrophages;computational biology;computer simulation	A major process of iron homeostasis in whole-body iron metabolism is the release of iron from the macrophages of the reticuloendothelial system. Macrophages recognize and phagocytose senescent or damaged erythrocytes. Then, they process the heme iron, which is returned to the circulation for reutilization by red blood cell precursors during erythropoiesis. The amount of iron released, compared to the amount shunted for storage as ferritin, is greater during iron deficiency. A currently accepted model of iron release assumes a passive-gradient with free diffusion of intracellular labile iron (Fe2+) through ferroportin (FPN), the transporter on the plasma membrane. Outside the cell, a multi-copper ferroxidase, ceruloplasmin (Cp), oxidizes ferrous to ferric ion. Apo-transferrin (Tf), the primary carrier of soluble iron in the plasma, binds ferric ion to form mono-ferric and di-ferric transferrin. According to the passive-gradient model, the removal of ferrous ion from the site of release sustains the gradient that maintains the iron release. Subcellular localization of FPN, however, indicates that the role of FPN may be more complex. By experiments and mathematical modeling, we have investigated the detailed mechanism of iron release from macrophages focusing on the roles of the Cp, FPN and apo-Tf. The passive-gradient model is quantitatively analyzed using a mathematical model for the first time. A comparison of experimental data with model simulations shows that the passive-gradient model cannot explain macrophage iron release. However, a facilitated-transport model associated with FPN can explain the iron release mechanism. According to the facilitated-transport model, intracellular FPN carries labile iron to the macrophage membrane. Extracellular Cp accelerates the oxidation of ferrous ion bound to FPN. Apo-Tf in the extracellular environment binds to the oxidized ferrous ion, completing the release process. Facilitated-transport model can correctly predict cellular iron efflux and is essential for physiologically relevant whole-body model of iron metabolism.	angular defect;blood cells;cellular automaton;ceruloplasmin;computation;computer simulation;erythrocytes;erythropoiesis;experiment;ferric;ferritin;ferrous;filtered-popping recursive transition network;fixed-pattern noise;gradient;heme iron;ions;iontophoresis;iron metabolism disorders;iron deficiency;mathematical model;mathematics;mono(adp-ribose) transferases;numerous;phagocytosis;plasma active;plasma membrane;ploidies;reticuloendothelial system;tissue membrane;iron ion homeostasis;metal transporting protein 1;oxidation	Alka A. Potdar;Joydeep Sarkar;Nupur K. Das;Paroma Ghosh;Miklos Gratzl;Paul L. Fox;Gerald M. Saidel	2014		10.1371/journal.pcbi.1003701	computer simulation;biology;biochemistry;homeostasis;iron		9.736396633476417	-64.55688416424256	108097
1b718d78c6b692d41ec56efc4b68f60a8f5fef08	a systematic approach for identifying regulatory interactions in large temporal gene expression datasets from peripheral blood	high throughput;neural nets;biological systems;reverse engineering;throughput;systematics;gene expression;genetics;biological system;neural network;neural networks;dimensionality reduction;bioinformatics;genomics	High throughput genomic techniques produce datasets involving thousands of gene expression profiles. In order to infer biologically meaningful regulatory interactions, a dimensionality reduction must take place to identify genes or groups of genes that are important to the biological system being analyzed. Here we provide a systematic approach to remove dispersible genes from consideration based on their gene expression profiles, and to identify a smaller set of coordinately expressed genes, or metagenes that are biologically related to one and other based on previous biological knowledge. We then apply neural network based reverse engineering techniques to demonstrate that through these dimensionality reduction techniques novel genetic interactions can be identified	artificial neural network;biological system;dimensionality reduction;interaction;peripheral;reverse engineering;throughput	Simon Knott;Parvin Mousavi;Sergio Baranzini	2006	2006 IEEE Symposium on Computational Intelligence and Bioinformatics and Computational Biology	10.1109/CIBCB.2006.330979	high-throughput screening;biology;throughput;molecular biology;gene expression;computer science;bioinformatics;machine learning;systematics;genetics;artificial neural network;reverse engineering;dimensionality reduction	Comp.	4.478987053587742	-57.82228256086532	108173
e07ab781d529562eef012bb1344a0a4efa57ac31	cmap: the comparative genetic map viewer	genetic map	UNLABELLED cMap, a www comparative genetic map graphical utility, has a search capability and provides comparison of two genetic maps within or between species with dynamic links to data resources and text lists of the shared loci, running in a relational database environment. Currently, maps from three species (maize 'Zea mays L.', rice 'Oryza sativa L.', and sorghum 'Sorghum bicolor L.'), representing over 13,800 distinct loci, are available for comparison at http://www.agron.missouri.edu/cMapDB/cMap.html.   AVAILABILITY cMap source code is available without cost on request for non-commercial use.	genetic algorithm;graphical user interface;internet;map;oryza (plant);oryza sativa;relational database;sorghum;source code;world wide web;zea mays	Zhiwei Fang;Mary L. Polacco;Su-Shing Chen;Steven G. Schroeder;D. Hancock;Hector Sanchez-Villeda;Edward H. Coe	2003	Bioinformatics	10.1093/bioinformatics/btg012	biology;bioinformatics;data mining	Web+IR	-2.2556548873091335	-59.419381460872565	108190
934c610f0c81d14d53d381d910d0dc0591131a4d	cida: an integrated software for the design, characterisation and global comparison of microarrays	gene expression profile;microarray data;functional annotation;study design;data fusion;integrated design;genetics;chip;microarray data analysis;transcription factor;human genome;system biology;biological systems;cost effectiveness;immune tolerance;first integral	Microarray technology has had a significant impact in the field of systems biology involving the investigation into the biological systems that regulate human life. Identifying genes of significant interest within any given disease on an individual basis is no doubt time consuming and inefficient when considering the complexity of the human genome. Thus, the genetic profiling of the entire human genome in a single experiment has resulted in microarray technology becoming a widely used experimental tool. However, without the use of tools for several aspects of microarray data analysis the technology is limited. To date, no such tool has been developed that allows the integration of numerous microarray results from different research laboratories as well as the design of customised gene chips in a cost-effective manner. In light of this, we have designed the first integrated and automated software called Chip Integration, Design and Annotation (CIDA) for the cross comparison, design and functional annotation of microarray gene chips. The software provides molecular biologists with the control to cross compare the biological signatures generated from multiple microarray studies, design custom microarray gene chips based on their research requirements and lastly characterise microarray data in the context of immunogenomics. Through the relative comparison of related microarray experiments we have identified 258 genes with common gene expression profiles that are not only upregulated in anergic T cells, but also in cells over-expressing the transcription factor Egr2, that has been identified to play a role in T cell anergy. Using the gene chip design aspect of CIDA we have designed and subsequently fabricate immuno-tolerance gene chips consisting of 1758 genes for further research. The software and database schema is freely available at ftp://ftp.brunel.ac.uk/cspgssk/CIDA/. Additional material is available online at http://www.brunel.ac.uk/about/acad/health/healthres/researchgroups/mi/publications/supp lementary/cida	antivirus software;biological system;dna microarray;database schema;experiment;integrated software;requirement;systems biology;transcription (software)	Sabah Khalid;Mohsin Khan;Alistair L J Symonds;Karl Fraser;Ping Wang;Xiaohui Liu;Suling Li	2007	J. Integrative Bioinformatics	10.2390/biecoll-jib-2007-78	biology;microarray analysis techniques;gene chip analysis;computer science;bioinformatics;data mining;microarray databases;genetics;systems biology	Comp.	0.9909538350356251	-59.36935683890763	108331
1761cf5850a6cb5e91e8a93cd494499bfff5c051	reconstructing gene-regulatory networks from time series, knock-out data, and prior knowledge	simulation and modeling;information loss;normal distribution;systems biology;gene regulation;gene regulatory networks;bayes theorem;physiological cellular and medical topics;models biological;gene network;prior knowledge;gene expression data;computational method;time series;computational biology bioinformatics;gene expression;variable selection;transcription regulation;time factors;knock out;bayesian learning;dynamic bayesian network;transcription factor;gene silencing;protein protein interaction;time series data;algorithms;data quality;synthetic data;network structure;computational biology;gene regulatory network;reverse engineering;bioinformatics	Cellular processes are controlled by gene-regulatory networks. Several computational methods are currently used to learn the structure of gene-regulatory networks from data. This study focusses on time series gene expression and gene knock-out data in order to identify the underlying network structure. We compare the performance of different network reconstruction methods using synthetic data generated from an ensemble of reference networks. Data requirements as well as optimal experiments for the reconstruction of gene-regulatory networks are investigated. Additionally, the impact of prior knowledge on network reconstruction as well as the effect of unobserved cellular processes is studied. We identify linear Gaussian dynamic Bayesian networks and variable selection based on F-statistics as suitable methods for the reconstruction of gene-regulatory networks from time series data. Commonly used discrete dynamic Bayesian networks perform inferior and this result can be attributed to the inevitable information loss by discretization of expression data. It is shown that short time series generated under transcription factor knock-out are optimal experiments in order to reveal the structure of gene regulatory networks. Relative to the level of observational noise, we give estimates for the required amount of gene expression data in order to accurately reconstruct gene-regulatory networks. The benefit of using of prior knowledge within a Bayesian learning framework is found to be limited to conditions of small gene expression data size. Unobserved processes, like protein-protein interactions, induce dependencies between gene expression levels similar to direct transcriptional regulation. We show that these dependencies cannot be distinguished from transcription factor mediated gene regulation on the basis of gene expression data alone. Currently available data size and data quality make the reconstruction of gene networks from gene expression data a challenge. In this study, we identify an optimal type of experiment, requirements on the gene expression data quality and size as well as appropriate reconstruction methods in order to reverse engineer gene regulatory networks from time series data.	data quality;discretization;dynamic bayesian network;estimated;experiment;feature selection;gene expression regulation;gene regulatory network;knock-out;normal statistical distribution;requirement;reverse engineering;synthetic data;transcription factor;time series;transcription (software);transcription, genetic;transcriptional regulation;protein protein interaction	Florian Geier;Jens Timmer;Christian Fleck	2006	BMC Systems Biology	10.1186/1752-0509-1-11	biology;gene regulatory network;computer science;bioinformatics;machine learning;data mining;genetics;systems biology	Comp.	5.569258881074266	-54.209849957328814	108338
e10aa2f2446374b7d47d816597d7448dd18895b8	virgen: a comprehensive viral genome resource	genomics;complete genome;phylogeny;proteome;genome viral;genome organization;comparative genomics;databases genetic;viral proteins;relational database;viral vaccines;data mining;terminology as topic;viruses;host range;internet;phylogenetic tree;antigens viral;sequence alignment;antiviral agents;proteomics;applied research;computational biology;genome sequence;value added	VirGen is a comprehensive viral genome resource that organizes the 'sequence space' of viral genomes in a structured fashion. It has been developed with the objective of serving as an annotated and curated database comprising complete genome sequences of viruses, value-added derived data and data mining tools. The current release (v1.1) contains 559 complete genomes in addition to 287 putative genomes of viruses belonging to eight viral families for which the host range includes animals and plants. Viral genomes in VirGen are annotated using sequence-based Bioinformatics approaches. The genomic data is also curated to identify 'alternate names' of viral proteins, where available. VirGen archives the results of comparisons of genomes, proteomes and individual proteins within and between viral species. It is the first resource to provide phylogenetic trees of viral species computed using whole-genome sequence data. The module of predicted B-cell antigenic determinants in VirGen is an attempt to link the genome to its vaccinome. Comparative genome analysis data facilitate the study of genome organization and evolution of viruses, which would have implications in applied research to identify candidates for the design of vaccines and antiviral drugs. VirGen is a relational database and is available at http://bioinfo. ernet.in/virgen/virgen.html.	antiviral agents;b-lymphocytes;bioinformatics;computer virus;data mining;digital curation;epitopes;genome;name;phylogenetic tree;phylogenetics;proteome;relational database;trees (plant);virus diseases;archive;comparative genomic analysis;viral capsid secondary envelopment	Urmila Kulkarni-Kale;Shriram Bhosle;G. Sunitha Manjari;Ashok S. Kolaskar	2004	Nucleic acids research	10.1093/nar/gkh098	biology;genomics;phylogenetic tree;whole genome sequencing;the internet;host;relational database;bioinformatics;value added;sequence alignment;proteome;genomic organization;proteomics;comparative genomics;genetics	Comp.	-0.7559806289798283	-60.27879718141461	108385
03c194ce213b410895125bd0f83deb228c1cd9b5	some techniques for the measurement of complexity in tierra	experimental analysis;information content;arithmetic function;self organizing system;artificial life	Recently, Adami and coworkers have been able to measure the information content of digital organisms living in their Avida artificial life system. They show that over time, the organisms behave like Maxwell’s demon, accreting information (or complexity) as they evolve. In Avida the organisms don’t interact with each other, merely reproduce at a particular rate (their fitness), and attempt to evaluate an externally given arithmetic function in order win bonus fitness points. Measuring the information content of a digital organism is essentially a process of counting the number of genotypes that give rise to the same phenotype. Whilst Avidan organisms have a particularly simple phenotype, Tierran organisms interact with each other, giving rise to an ecology of phenotypes. In this paper, I discuss techniques for comparing pairs of Tierran organisms to determine if they are phenotypically equivalent. I then discuss a method for computing an estimate of the number of phenotypically equivalent genotypes that is more accurate than the “hot site” estimate used by Adami’s group. Finally, I report on an experimental analysis of	artificial life;avida;backup site;complexity;digital organism;ecology;maxwell (microarchitecture);self-information;tps report;tierra (computer simulation);while	Russell K. Standish	1999		10.1007/3-540-48304-7_16	biology;self-information;computer science;artificial intelligence;arithmetic function;mathematics;ecology;genetics;artificial life;statistics;experimental analysis of behavior	Web+IR	2.9997724593548973	-62.478444159865134	108422
344885fd3c6ea2a573a0b5c87767e993d64588cb	a spatially varying two-sample recombinant coalescent, with applications to hiv escape response	health research;uk clinical guidelines;biological patents;treatment effect;evolutionary model;control group;europe pubmed central;nucleotides;citation search;escape response;uk phd theses thesis;drug therapy;life sciences;uk research reports;medical journals;gene therapy;hierarchical model;europe pmc;biomedical research;bioinformatics	Statistical evolutionary models provide an important mechanism for describing and understanding the escape response of a viral population under a particular therapy. We present a new hierarchical model that incorporates spatially varying mutation and recombination rates at the nucleotide level. It also maintains separate parameters for treatment and control groups, which allows us to estimate treatment effects explicitly. We use the model to investigate the sequence evolution of HIV populations exposed to a recently developed antisense gene therapy, as well as a more conventional drug therapy. The detection of biologically relevant and plausible signals in both therapy studies demonstrates the effectiveness of the method.	crossover (genetic algorithm);hierarchical database model;mutation;nucleotides;population;recombinant dna;recombinants;antisense therapy	Alexander Braunstein;Zhi Wei;Shane T. Jensen;Jon D. McAuliffe	2008	Advances in neural information processing systems		pharmacotherapy;nucleotide;computer science;bioinformatics;escape response;average treatment effect;hierarchical database model;scientific control	ML	5.723557249262028	-61.583939767301615	108493
f6bf81b1e124742d2b201d28c57bb05019d48a71	vsclust: feature-based variance-sensitive clustering of omics data		Motivation Data clustering is indispensable for identifying biologically relevant molecular features in large-scale omics experiments with thousands of measurements at multiple conditions. Optimal clustering results yield groups of functionally related features that may include genes, proteins and metabolites in biological processes and molecular networks. Omics experiments typically include replicated measurements of each feature within a given condition to statistically assess feature-specific variation. Current clustering approaches ignore this variation by averaging, which often leads to incorrect cluster assignments.   Results We present VSClust that accounts for feature-specific variance. Based on an algorithm derived from fuzzy clustering, VSClust unifies statistical testing with pattern recognition to cluster the data into feature groups that more accurately reflect the underlying molecular and functional behavior. We apply VSClust to artificial and experimental datasets comprising hundreds to >80 000 features across 6-20 different conditions including genomics, transcriptomics, proteomics and metabolomics experiments. VSClust avoids arbitrary averaging methods, outperforms standard fuzzy c-means clustering and simplifies the data analysis workflow in large-scale omics studies.   Availability and implementation Download VSClust at https://bitbucket.org/veitveit/vsclust or access it through computproteomics.bmb.sdu.dk/Apps/VSClust.   Supplementary information Supplementary data are available at Bioinformatics online.		Veit Schwämmle;Ole Nørregaard Jensen	2018	Bioinformatics	10.1093/bioinformatics/bty224	data mining;computer science;cluster analysis;bioinformatics;omics	Comp.	4.462093263496568	-54.8820011323359	108507
01998d119d0fe1d5833dc6f67f89dbac6df7694d	a flexible two-stage procedure for identifying gene sets that are differentially expressed	procedimiento;gen;microarray data analysis;differential expression;gene;error rate;procedure	MOTIVATION Microarray data analysis has expanded from testing individual genes for differential expression to testing gene sets for differential expression. The tests at the gene set level may focus on multivariate expression changes or on the differential expression of at least one gene in the gene set. These tests may be powerful at detecting subtle changes in expression, but findings at the gene set level need to be examined further to understand whether they are informative and if so how.   RESULTS We propose to first test for differential expression at the gene set level but then proceed to test for differential expression of individual genes within discovered gene sets. We introduce the overall false discovery rate (OFDR) as an appropriate error rate to control when testing multiple gene sets and genes. We illustrate the advantage of this procedure over procedures that only test gene sets or individual genes.	information;microarray;sensor	Ruth Heller;Elisabetta Manduchi;Gregory R. Grant;Warren J. Ewens	2009	Bioinformatics	10.1093/bioinformatics/btp076	biology;procedure;microarray analysis techniques;word error rate;computer science;bioinformatics;gene;data mining;gene expression profiling;genetics	Comp.	5.283067508141987	-52.4974447220403	108516
b3dd370809e48101370139bb2dbc4d1fa0028eb0	a new method for enhancer prediction based on deep belief network	chip-seq;deep belief network;enhancer prediction	Studies have shown that enhancers are significant regulatory elements to play crucial roles in gene expression regulation. Since enhancers are unrelated to the orientation and distance to their target genes, it is a challenging mission for scholars and researchers to accurately predicting distal enhancers. In the past years, with the high-throughout ChiP-seq technologies development, several computational techniques emerge to predict enhancers using epigenetic or genomic features. Nevertheless, the inconsistency of computational models across different cell-lines and the unsatisfactory prediction performance call for further research in this area. Here, we propose a new Deep Belief Network (DBN) based computational method for enhancer prediction, which is called EnhancerDBN. This method combines diverse features, composed of DNA sequence compositional features, DNA methylation and histone modifications. Our computational results indicate that 1) EnhancerDBN outperforms 13 existing methods in prediction, and 2) GC content and DNA methylation can serve as relevant features for enhancer prediction. Deep learning is effective in boosting the performance of enhancer prediction.	bayesian network;computational model;deep belief network;deep learning;enhancer of transcription;gene expression regulation;gene prediction;histone code;histones;methylation;study of epigenetics	Hongda Bu;Yanglan Gan;Yang Wang;Shuigeng Zhou;Jihong Guan	2017		10.1186/s12859-017-1828-0	regulation of gene expression;enhancer;genetics;deep belief network;gene;computational model;bioinformatics;epigenetics;biology	ML	4.573826799006934	-58.89975864395069	108611
0d2737689e6b63dbb083f3623db283104f09a2b2	rarevar: a framework for detecting low-frequency single-nucleotide variants	somatic mutation;machine learning;low frequency snvs;sequencing error modeling;next generation sequencing	Accurate identification of low-frequency somatic point mutations in tumor samples has important clinical utilities. Although high-throughput sequencing technology enables capturing such variants while sequencing primary tumor samples, our ability for accurate detection is compromised when the variant frequency is close to the sequencer error rate. Most current experimental and bioinformatic strategies target mutations with ≥5% allele frequency, which limits our ability to understand the cancer etiology and tumor evolution. We present an experimental and computational modeling framework, RareVar, to reliably identify low-frequency single-nucleotide variants from high-throughput sequencing data under standard experimental protocols. RareVar protocol includes a benchmark design by pooling DNAs from already sequenced individuals at various concentrations to target variants at desired frequencies, 0.5%-3% in our case. By applying a generalized, linear model-based, position-specific error model, followed by machine-learning-based variant calibration, our approach outperforms existing methods. Our method can be applied on most capture and sequencing platforms without modifying the experimental protocol.	benchmark (computing);bio-informatics;bioinformatics;biopolymer sequencing;computation;computational model;diploid cell;gene frequency;generalized linear model;high-throughput computing;machine learning;microsequencer;mutation;neoplasms;non-small cell lung carcinoma;nucleotides;protocols documentation;sensor;throughput;primary tumor	Yangyang Hao;Xiaoling Xuei;Lang Li;Harikrishna Nakshatri;Howard J. Edenberg;Yunlong Liu	2017	Journal of computational biology : a journal of computational molecular cell biology	10.1089/cmb.2017.0057	biology;dna sequencing;molecular biology;germline mutation;bioinformatics;genetics	Comp.	2.709090248128777	-54.68330606980286	108651
63ef1864f5b4e25154c9a541e19caff3fbdc3da2	tf-centered downstream gene set enrichment analysis: inference of causal regulators by integrating tf-dna interactions and protein post-translational modifications information	dna;post translational modification;gene deletion;expression profile;gene regulatory networks;transcription factors;gene expression data;computational biology bioinformatics;gene expression;large scale;models genetic;protein processing post translational;transcription factor;model integration;gene expression regulation;algorithms;gene set enrichment analysis;combinatorial libraries;computer appl in life sciences;glycerol;gene expression profiling;microarrays;bioinformatics;fermentation	Inference of causal regulators responsible for gene expression changes under different conditions is of great importance but remains rather challenging. To date, most approaches use direct binding targets of transcription factors (TFs) to associate TFs with expression profiles. However, the low overlap between binding targets of a TF and the affected genes of the TF knockout limits the power of those methods. We developed a TF-centered downstream gene set enrichment analysis approach to identify potential causal regulators responsible for expression changes. We constructed hierarchical and multi-layer regulation models to derive possible downstream gene sets of a TF using not only TF-DNA interactions, but also, for the first time, post-translational modifications (PTM) information. We verified our method in one expression dataset of large-scale TF knockout and another dataset involving both TF knockout and TF overexpression. Compared with the flat model using TF-DNA interactions alone, our method correctly identified five more actual perturbed TFs in large-scale TF knockout data and six more perturbed TFs in overexpression data. Potential regulatory pathways downstream of three perturbed regulators— SNF1, AFT1 and SUT1 —were given to demonstrate the power of multilayer regulation models integrating TF-DNA interactions and PTM information. Additionally, our method successfully identified known important TFs and inferred some novel potential TFs involved in the transition from fermentative to glycerol-based respiratory growth and in the pheromone response. Downstream regulation pathways of SUT1 and AFT1 were also supported by the mRNA and/or phosphorylation changes of their mediating TFs and/or “modulator” proteins. The results suggest that in addition to direct transcription, indirect transcription and post-translational regulation are also responsible for the effects of TFs perturbation, especially for TFs overexpression. Many TFs inferred by our method are supported by literature. Multiple TF regulation models could lead to new hypotheses for future experiments. Our method provides a valuable framework for analyzing gene expression data to identify causal regulators in the context of TF-DNA interactions and PTM information.	causal filter;dna binding site;downstream (software development);experiment;gene ontology term enrichment;gene expression profiling;genetic translation process;glycerin;inference;interaction;knockout;layer (electronics);modulation;modulator device component;name binding;numerous;phentolamine;polynomial texture mapping;post-translational protein processing;silo (dataset);transcription factor;tf–idf;transcription (software);translational regulation;response to pheromone	Qi Liu;Yejun Tan;Tao Huang;Guohui Ding;Zhidong Tu;Lei Liu;Yixue Li;Hongyue Dai;Lu Xie	2010		10.1186/1471-2105-11-S11-S5	biology;molecular biology;bioinformatics;genetics;transcription factor	Comp.	5.579797716758385	-59.02366106802638	108702
452d5f6785e3081fd6c0aa11555fcab8cf916603	fast cpu-based dna exact sequence aligner	dna;genomics;sequences;hash indexing method cpu based dna exact sequence aligner small sequence alignment very large sequence biological sequences next generation sequencing reference genome memocode 2012 contest dna sequence matching method human genome burrows wheeler transform bwt;data compression;indexing;bioinformatics genomics optimization memory management humans dna random access memory;sequences bioinformatics data compression dna file organisation genomics indexing;bioinformatics;file organisation	Fast alignment of small sequences to a very large sequence has recently been under attention of many researchers, due to the applications in processing the biological sequences and specially mapping the short reads of Next Generation Sequencing to an already assembled reference genome. The MEMOCODE 2012 contest was aimed to design a very efficient exact DNA sequence matching method to map a huge number of short subsequences of the human genome and to optimize the performance of design: the running time and the cost of the required hardware platform. We designed and implemented two separate solutions, one based on Burrows Wheeler Transform (BWT) with some optimizations to the algorithm that improve its speed significantly, the other one which won the normalized section of the contest uses a hash indexing method.	algorithm;burrows–wheeler transform;central processing unit;hash table;time complexity	Aryan Arbabi;Milad Gholami;Mojtaba Varmazyar;Shervin Daneshpajouh	2012	Tenth ACM/IEEE International Conference on Formal Methods and Models for Codesign (MEMCODE2012)	10.1109/MEMCOD.2012.6292305	data compression;search engine indexing;genomics;computer science;bioinformatics;theoretical computer science;sequence;world wide web;dna;alignment-free sequence analysis	HPC	-1.7998003802883518	-52.632686860390095	108713
f8c783a0bdf2a925765aa5b7410c2de3d7e60275	mutdb: annotating human variation with functionally relevant data	comparative genomics;protein structure;polymorphism;multiple sequence alignment;ucsc;protein level	SUMMARY We have developed a resource, MutDB (http://mutdb.org/), to aid in determining which single nucleotide polymorphisms (SNPs) are likely to alter the function of their associated protein product. MutDB contains protein structure annotations and comparative genomic annotations for 8000 disease-associated mutations and SNPs found in the UCSC Annotated Genome and the human RefSeq gene set. MutDB provides interactive mutation maps at the gene and protein levels, and allows for ranking of their predicted functional consequences based on conservation in multiple sequence alignments.   AVAILABILITY http://mutdb.org/   SUPPLEMENTARY INFORMATION http://mutdb.org/about/about.html	map;multiple sequence alignment;mutation;nucleotides;refseq;single nucleotide polymorphism	Sean D. Mooney;Russ B. Altman	2003	Bioinformatics	10.1093/bioinformatics/btg241	biology;polymorphism;protein structure;molecular biology;multiple sequence alignment;computer science;bioinformatics;comparative genomics;genetics	Comp.	1.617676052694257	-59.6501610012286	108773
2fbc2494af8eaa029513718109604787c41f46fe	structure-based and ligand-based virtual screening of novel methyltransferase inhibitors of the dengue virus	methyltransferases;s adenosylhomocysteine;rna caps;ligands;binding sites;computational biology bioinformatics;viral nonstructural proteins;models molecular;s adenosylmethionine;algorithms;humans;antiviral agents;combinatorial libraries;enzyme inhibitors;computer appl in life sciences;high throughput screening assays;dengue;dengue virus;microarrays;bioinformatics	The dengue virus is the most significant arthropod-borne human pathogen, and an increasing number of cases have been reported over the last few decades. Currently neither vaccines nor drugs against the dengue virus are available. NS5 methyltransferase (MTase), which is located on the surface of the dengue virus and assists in viral attachment to the host cell, is a promising antiviral target. In order to search for novel inhibitors of NS5 MTase, we performed a computer-aided virtual screening of more than 5 million commercially available chemical compounds using two approaches: i) structure-based screening using the crystal structure of NS5 MTase and ii) ligand-based screening using active ligands of NS5 MTase. Structure-based screening was performed using the LIDAEUS (LIgand Discovery At Edinburgh UniverSity) program. The ligand-based screening was carried out using the EDULISS (EDinburgh University LIgand Selection System) program. The selection of potential inhibitors of dengue NS5 MTase was based on two criteria: the compounds must bind to NS5 MTase with a higher affinity than that of active NS5 MTase ligands, such as ribavirin triphosphate (RTP) and S-adenosyl-L-homocysteine (SAH); and the compounds must interact with residues that are catalytically important for the function of NS5 MTase. We found several compounds that bind strongly to the RNA cap site and the S-adenosyl-L-methionine (SAM) binding site of NS5 MTase with better binding affinities than that of RTP and SAH. We analyzed the mode of binding for each compound to its binding site, and our results suggest that all compounds bind to their respective binding sites by interacting with, and thus blocking, residues that are vital for maintaining the catalytic activity of NS5 MTase. We discovered several potential compounds that are active against dengue virus NS5 MTase through virtual screening using structure-based and ligand-based methods. These compounds were predicted to bind into the SAM binding site and the RNA cap site with higher affinities than SAH and RTP. These compounds are commercially available and can be purchased for further biological activity tests.	activity diagram;antiviral agents;arthropods;attachments;binding sites;blocking (computing);chemicals;crystal structure;dna binding site;dengue fever;dengue virus;genetic selection;greater than;hepatitis c virus ns5 ab:prthr:pt:ser:ord:ib;host cell;interaction;ligands;methionine;noonan syndrome 5;pathogenic organism;processor affinity;rna caps;ribavirin;s-adenosylhomocysteine;s-adenosylmethionine;virtual screening;west nile virus ns5 ab:prthr:pt:xxx:ord;betaine-homocysteine methyltransferase;buying;enzyme activity;homocysteine	See Ven Lim;Mohd Basyaruddin Abdul Rahman;Bimo Ario Tejo	2011		10.1186/1471-2105-12-S13-S24	biology;molecular biology;dna microarray;methyltransferase;bioinformatics;binding site;virology;dengue fever;ligand	Comp.	9.244889606017853	-57.5069259668582	108929
288664c9368f90afd41f2e0758d4f953866feac7	fast and sensitive mapping of bisulfite-treated sequencing data	dna methylation;resulting sequencing;available read mapping software;sensitive mapping;mapping hundred;cytosine dna methylation;bisulfite sequencing;bisulfite-treated sequencing data;dna fragment;software segemehl;aberrant methylation;sodium bisulfite	MOTIVATION Cytosine DNA methylation is one of the major epigenetic modifications and influences gene expression, developmental processes, X-chromosome inactivation, and genomic imprinting. Aberrant methylation is furthermore known to be associated with several diseases including cancer. The gold standard to determine DNA methylation on genome-wide scales is 'bisulfite sequencing': DNA fragments are treated with sodium bisulfite resulting in the conversion of unmethylated cytosines into uracils, whereas methylated cytosines remain unchanged. The resulting sequencing reads thus exhibit asymmetric bisulfite-related mismatches and suffer from an effective reduction of the alphabet size in the unmethylated regions, rendering the mapping of bisulfite sequencing reads computationally much more demanding. As a consequence, currently available read mapping software often fails to achieve high sensitivity and in many cases requires unrealistic computational resources to cope with large real-life datasets.   RESULTS In this study, we present a seed-based approach based on enhanced suffix arrays in conjunction with Myers bit-vector algorithm to efficiently extend seeds to optimal semi-global alignments while allowing for bisulfite-related substitutions. It outperforms most current approaches in terms of sensitivity and performs time-competitive in mapping hundreds of millions of sequencing reads to vertebrate genomes.   AVAILABILITY The software segemehl is freely available at http://www.bioinf.uni-leipzig.de/Software/segemehl.	alphabet;biopolymer sequencing;bisulfite sequencing;bit array;computation;computational resource;cytosine;gene expression;genome;genomic imprinting;imprinting (psychology);plant seeds;reading (activity);real life;semiconductor industry;viral sequencing:prid:pt:ser:nom:sequencing;algorithm;hydrogen sulfite;sodium bisulfite;study of epigenetics	Christian Otto;Peter F. Stadler;Steve Hoffmann	2012	Bioinformatics	10.1093/bioinformatics/bts254	biology;molecular biology;bioinformatics;genetics	Comp.	0.20804929472139103	-55.00503446398027	109010
3f96589ce1b30df0d803f7b0c2dcdba03134dc00	the origins of specificity in polyketide synthase protein interactions	evolution molecular;substrate specificity;cross correlation;protein sequence;amino acid sequence;statistical significance;nmr structure;enzyme activation;detection algorithm;protein protein interaction;molecular sequence data;polyketide synthase;computer analysis;protein interaction;protein interaction mapping;physical interaction;polyketide synthases;sequence analysis protein	Polyketides, a diverse group of heteropolymers with antibiotic and antitumor properties, are assembled in bacteria by multiprotein chains of modular polyketide synthase (PKS) proteins. Specific protein-protein interactions determine the order of proteins within a multiprotein chain, and thereby the order in which chemically distinct monomers are added to the growing polyketide product. Here we investigate the evolutionary and molecular origins of protein interaction specificity. We focus on the short, conserved N- and C-terminal docking domains that mediate interactions between modular PKS proteins. Our computational analysis, which combines protein sequence data with experimental protein interaction data, reveals a hierarchical interaction specificity code. PKS docking domains are descended from a single ancestral interacting pair, but have split into three phylogenetic classes that are mutually noninteracting. Specificity within one such compatibility class is determined by a few key residues, which can be used to define compatibility subclasses. We identify these residues using a novel, highly sensitive co-evolution detection algorithm called CRoSS (correlated residues of statistical significance). The residue pairs selected by CRoSS are involved in direct physical interactions in a docked-domain NMR structure. A single PKS system can use docking domain pairs from multiple classes, as well as domain pairs from multiple subclasses of any given class. The termini of individual proteins are frequently shuffled, but docking domain pairs straddling two interacting proteins are linked as an evolutionary module. The hierarchical and modular organization of the specificity code is intimately related to the processes by which bacteria generate new PKS pathways.	amino acid sequence;boat dock;class;docking (molecular);docking -molecular interaction;fundamental interaction;medical device incompatibility problem;national origin;p-value;phylogenetics;polyketides;prostaglandin-endoperoxide synthase;sensitivity and specificity;algorithm;monomer;polyketide synthase;protein protein interaction;subclass	Mukund Thattai;Yoram Burak;Boris I. Shraiman	2007	PLoS Computational Biology	10.1371/journal.pcbi.0030186	protein–protein interaction;biology;biochemistry;bioinformatics;cross-correlation;protein sequencing;statistical significance;peptide sequence;enzyme activator	Comp.	4.692603459648009	-61.083028757754136	109023
28017e4e6208bad1355cc84a1008a5ffea0b68f6	reverse engineering approach in molecular evolution: simulation and case study with enzyme proteins	nucleotide substitutions;comparative genomics;reverse engineering;ds.;dn;enzymes;enzyme;evolutionary theory;molecular evolution	We developed a method of reverse engineering to compare the behaviour the enzyme proteins with the existing standard concepts. Our work is based on the strong assumption from the evolutionary theory, about the rates of nucleotide substitutions; we use this in the reverse engineering approach to verify how far it can be justified. We applied here the simple models of nucleotide substitutions Nei and Gojobori in a more generalized form and used comparative genomic study with human, mouse and rat individually with related enzyme proteins. We then used Jukes and Cantor’s model to find out the corrected substitution rates. This paper describes the findings and the methodology in details.	cantor;evolution;reverse engineering;simulation;substitution model	Sukanya Manna;Cheng-Yuan Liou	2006			reverse engineering;molecular evolution;enzyme;comparative genomics;bioinformatics;biology	Comp.	4.949878367420754	-60.913015495506166	109035
15f70d8876c342c28b988954d39b4699aa666d53	sequence assembly from corrupted shotgun reads	error profiles sequence assembly corrupted shotgun reads dna sequencing shotgun sequencing randomly located fragments assembly algorithm second generation methods third generation methods;dna biology computing;sequential analysis approximation algorithms error analysis dna reconstruction algorithms genetic communication	The prevalent technique for DNA sequencing consists of two main steps: shotgun sequencing, where many randomly located fragments, called reads, are extracted from the overall sequence, followed by an assembly algorithm that aims to reconstruct the original sequence. There are many different technologies that generate the reads: widely-used second-generation methods create short reads with low error rates, while emerging third-generation methods create long reads with high error rates. Both error rates and error profiles differ among methods, so reconstruction algorithms are often tailored to specific shotgun sequencing technologies. As these methods change over time, a fundamental question is whether there exist reconstruction algorithms which are robust, i.e., which perform well under a wide range of error distributions. Here we study this question of sequence assembly from corrupted reads. We make no assumption on the types of errors in the reads, but only assume a bound on their magnitude. More precisely, for each read we assume that instead of receiving the true read with no errors, we receive a corrupted read which has edit distance at most ε times the length of the read from the true read. We show that if the reads are long enough and there are sufficiently many of them, then approximate reconstruction is possible: we construct a simple algorithm such that for almost all original sequences the output of the algorithm is a sequence whose edit distance from the original one is at most O(ε) times the length of the original sequence.	approximation algorithm;edit distance;existential quantification;randomness;robustness (computer science);sequence assembly	Shirshendu Ganguly;Elchanan Mossel;Miklós Z. Rácz	2016	2016 IEEE International Symposium on Information Theory (ISIT)	10.1109/ISIT.2016.7541302	computer science;bioinformatics;theoretical computer science;data mining;hybrid genome assembly	Theory	0.13482498484652428	-53.22340088739903	109063
5081a8875cfbd2d84674ad582f3bd62a02588d9d	rad51p and rad54p, but not rad52p, elevate gene repair in saccharomyces cerevisiae directed by modified single-stranded oligonucleotide vectors	genes;dna repair enzymes;saccharomyces cerevisiae;dna binding proteins;genetic complementation test;rad52 dna repair and recombination protein;genotype;genetic vectors;yeasts;amino acid sequence;saccharomyces cerevisiae proteins;green fluorescent proteins;dna single stranded;genetics;dna helicases;gene expression;single stranded;oligonucleotides;chromosomes;dna repair;rad51 recombinase;recombination genetic;base sequence;luminescent proteins;gene function;wild type;mutation;protein overexpression;fungal proteins	Synthetic single-stranded DNA vectors have been used to correct point and frameshift mutations in episomal or chromosomal targets in the yeast Saccharomyces cerevisiae. Certain parameters, such as the length of the vector and the genetic background of the organism, have a significant impact on the process of targeted gene repair, and point mutations are corrected at a higher frequency than frameshift mutations. Genetic analyses reveal that expression levels of the recombination/repair genes RAD51, RAD52 and RAD54 can affect the frequency of gene repair. Overexpression of RAD51 enhances the frequency 4-fold for correction of an episomal target and 5-fold for correction of a chromosomal target; overexpression of RAD54 is also effective in stimulating gene repair, to the same extent as RAD51 in the chromosomal target. In sharp contrast, RAD52 gene expression serves to reduce gene repair activity in rescue experiments and in experiments where RAD52 is overexpressed in a wild-type strain. This may suggest an antagonist role for Rad52p. Consistent with this notion, the highest level of targeted repair occurs when the RAD51 gene is overexpressed in a strain of yeast deficient in RAD52 gene function.	atrx wt allele;experiment;frameshift mutation function;gene expression;point mutation;rad51 gene;rad52 gene;saccharomyces cerevisiae;stimulation (motivation);synthetic intelligence	Li Liu;Shuqiu Cheng;Anja J. van Brabant;Eric B. Kmiec	2002	Nucleic acids research	10.1093/nar/gkf397	biology;gene dosage;molecular biology;dna repair;bioinformatics;gene targeting;genetics	Comp.	4.870846079442615	-63.41920410656863	109142
a74c15c2a25b1970c91fd94ec889cd700c77e953	towards predicting coiled-coil protein interactions	information retrieval;protein sequence;computational method;protein structure;prosite;pattern matching;protein protein interaction;bit parallelism;cross validation;protein interaction;computational biology;genome sequence;coiled coil	Protein-protein interactions play a central role in many cellular functions, and as whole-genome data accumulates, computational methods for predicting these interactions become increasingly important. Computational methods have already proven to be a useful first step for rapid genome-wide identification of putative protein structure and function, but research on the problem of computationally determining biologically relevant partners for given protein sequences is just beginning. In this paper, we approach the problem of predicting protein-protein interactions by focusing on the 2- stranded coiled-coil motif. We introduce a computational method for predicting coiled-coil protein interactions, and give a novel framework that is able to use both genomic sequence data and experimental data in making these predictions. Cross-validation tests show that the method is able to predict many aspects of protein-protein interactions mediated by the coiled-coil motif, and suggest that this methodology can be used as the basis for genome-wide prediction of coiled-coil protein interactions.	computation;cross-validation (statistics);interaction;motif;peptide sequence	M T Singh;Peter S. Kim	2001		10.1145/369133.369238	protein–protein interaction;biology;protein structure;whole genome sequencing;coiled coil;prosite;computer science;bioinformatics;machine learning;pattern matching;protein sequencing;protein function prediction;protein structure database;genetics;cross-validation	Comp.	2.4543115531399238	-59.08921284057207	109143
ec6123748714ad2ed33ad1bbb6fb6f1c2d05f661	evaluating protein similarity from coarse structures	new macrostructure similarity;protein surface.;protein similarity;protein structure alignment;alternative similarity measure;protein function;protein structure;large-scale structure databases;new score scheme;coarse structures;structure comparison;new method;different protein data set;sequence alignment;sequences;machine learning;data mining;computational biology;protein conformation;optimization;computer simulation;numerical analysis;molecular biophysics;mathematics;proteins;algorithms	To unscramble the relationship between protein function and protein structure, it is essential to assess the protein similarity from different aspects. Although many methods have been proposed for protein structure alignment or comparison, alternative similarity measures are still strongly demanded due to the requirement of fast screening and query in large-scale structure databases. In this paper, we first formulate a novel representation of a protein structure, i.e., feature sequence of surface (FSS). Then, a new score scheme is developed to measure the similarity between two representations. To verify the proposed method, numerical experiments are conducted in four different protein data sets. We also classify SARS coronavirus to verify the effectiveness of the new method. Furthermore, preliminary results of fast classification of the whole CATH v2.5.1 database based on the new macrostructure similarity are given as a pilot study. We demonstrate that the proposed approach to measure the similarities between protein structures is simple to implement, computationally efficient, and surprisingly fast. In addition, the method itself provides a new and quantitative tool to view a protein structure.		Yong Wang;Ling-Yun Wu;Ji-Hong Zhang;Zhong-Wei Zhan;Xiang-Sun Zhang;Luonan Chen	2009	IEEE/ACM Trans. Comput. Biology Bioinform.	10.1145/1671403.1671408	computer simulation;biochemistry;protein structure;computer science;bioinformatics;theoretical computer science;data mining;protein structure database;molecular biophysics	Comp.	8.313354889643362	-57.338070620778055	109195
c4df41b5e2bc67ffc5244d607bcd2ff67bd76f16	an indexing scheme for fast and accurate chemical fingerprint database searching	drug discovery;search method;indexation;database search	Rapid chemical database searching is important for drug discovery. Chemical compounds are represented as long fixed-length bit vectors called fingerprints. The vectors record the presence or absence of particular features or substructures of the corresponding molecules. In a typical drug discovery application, several thousands of query fingerprints are screened for similarity against a database of millions of fingerprints to identify suitable drug candidates. The existing methods of full database scan and range search take considerable amounts of time for such a task. We present a new index-based search method called “ChemDex” (Chemical fingerprint inDexing) for speeding up the fingerprint database search. We propose a novel chain scoring scheme to calculate the Tanimoto (Jaccard) scores of the fingerprints using an early-termination strategy. We tested our proposed method using 1,000 randomly selected query fingerprints on the NCBI PubChem database containing about 19.5 million fingerprints. Experimental results show that ChemDex is up to 109.9 times faster than the full database scan method, and up to 2.1 times faster than the state-of-the-art range search method for memorybased retrieval. For disk-based retrieval, it is up to 145.7 times and 1.7 times faster than the full scan and the range search respectively. The speedup is achieved without any loss of accuracy as ChemDex generates exactly the same results as the full scan and the range search.	bit array;chemdex.com;chemical database;fingerprint;jaccard index;projection screen;pubchem;randomness;range searching;speedup	Zeyar Aung;See-Kiong Ng	2010		10.1007/978-3-642-13818-8_22	database search engine;computer science;data mining;world wide web;information retrieval;drug discovery	Vision	-2.347331443180576	-52.512810040484226	109398
1133f1ea8d9dd1fc3fdb41a4caac553b3f981e8b	controlling e. coli gene expression noise	escherichia coli;gene regulatory networks;models biological;gene expression;noise level;proteins;stochastic processes;stochastic processes biochemistry biological techniques cellular biophysics fluctuations fluorescence genetics microorganisms molecular biophysics proteins statistical distributions;noise level noise proteins protein engineering gene expression mathematical model stochastic processes;gene expression regulation;escherichia coli proteins;mathematical model;weak fluorescence signals e coli gene expression gene expression noise control intracellular protein copy numbers random biological reactions copy number variability gene expression perturbation genetic network noise propagation biochemical networks stochastic control analysis sca sensitivity based analysis framework plasmid encoded synthetic gene expression systems transcription efficiency translation efficiency gamma distribution function chromosomal proteins bursty translation autofluorescence stochastic fluctuations;protein engineering;noise;protein biosynthesis;two state model gene expression noise noise control stochastic control analysis stochasticity synthetic biology	Intracellular protein copy numbers show significant cell-to-cell variability within an isogenic population due to the random nature of biological reactions. Here we show how the variability in copy number can be controlled by perturbing gene expression. Depending on the genetic network and host, different perturbations can be applied to control variability. To understand more fully how noise propagates and behaves in biochemical networks we developed stochastic control analysis (SCA) which is a sensitivity-based analysis framework for the study of noise control. Here we apply SCA to synthetic gene expression systems encoded on plasmids that are transformed into Escherichia coli. We show that (1) dual control of transcription and translation efficiencies provides the most efficient way of noise-versus-mean control. (2) The expressed proteins follow the gamma distribution function as found in chromosomal proteins. (3) One of the major sources of noise, leading to the cell-to-cell variability in protein copy numbers, is related to bursty translation. (4) By taking into account stochastic fluctuations in autofluorescence, the correct scaling relationship between the noise and mean levels of the protein copy numbers was recovered for the case of weak fluorescence signals.	artificial gene synthesis;copy number;dual;fluorescence;gene expression;gene regulatory network;heart rate variability;interferon type ii;plasmids;spatial variability;stochastic control;synthetic intelligence;test scaling;transcription (software)	Kyung Hyuk Kim;Kiri Choi;Bryan Bartley;Herbert M. Sauro	2015	IEEE Transactions on Biomedical Circuits and Systems	10.1109/TBCAS.2015.2461135	stochastic process;gene regulatory network;regulation of gene expression;gene expression;bioinformatics;noise;mathematical model;protein engineering;escherichia coli;protein biosynthesis	Comp.	7.061514409477511	-65.30922887403506	109466
c1d575a03f948c4e3ca2d591c567de6c6c5f522d	cytoasp: a cytoscape app for qualitative consistency reasoning, prediction and repair in biological networks	software;simulation and modeling;saccharomyces cerevisiae;computer graphics;systems biology;gene regulatory networks;physiological cellular and medical topics;computational biology bioinformatics;algorithms;computational biology;bioinformatics	Qualitative reasoning frameworks, such as the Sign Consistency Model (SCM), enable modelling regulatory networks to check whether observed behaviour can be explained or if unobserved behaviour can be predicted. The BioASP software collection offers ideal tools for such analyses. Additionally, the Cytoscape platform can offer extensive functionality and visualisation capabilities. However, specialist programming knowledge is required to use BioASP and no methods exist to integrate both of these software platforms effectively. We report the implementation of CytoASP, an app that allows the use of BioASP for influence graph consistency checking, prediction and repair operations through Cytoscape. While offering inherent benefits over traditional approaches using BioASP, it provides additional advantages such as customised visualisation of predictions and repairs, as well as the ability to analyse multiple networks in parallel, exploiting multi-core architecture. We demonstrate its usage in a case study of a yeast genetic network, and highlight its capabilities in reasoning over regulatory networks. We have presented a user-friendly Cytoscape app for the analysis of regulatory networks using BioASP. It allows easy integration of qualitative modelling, combining the functionality of BioASP with the visualisation and processing capability in Cytoscape, and thereby greatly simplifying qualitative network modelling, promoting its use in relevant projects.	checking (action);consistency model;cytoscape;gene regulatory network;hl7publishingsubsection <operations>;intel core (microarchitecture);multi-core processor;numerous;promotion (action);reasoning;spectinomycin;usability;benefit	Aristotelis Kittas;Amélie Barozet;Jekaterina Sereshti;Niels Grabe;Sophia Tsoka	2015		10.1186/s12918-015-0179-6	biology;gene regulatory network;computer science;bioinformatics;theoretical computer science;data mining;computer graphics;systems biology	AI	-0.45450692089792655	-57.686657854544904	109476
c004995a05d5beb88685b7ffe61e9ce07ba37a05	optimization of minimum set of protein–dna interactions: a quasi exact solution with minimum over-fitting	dna;zinc fingers;optimisation;proteine;optimizacion;interaction moleculaire;molecular interaction;amino acid sequence;exact solution;binding sites;models molecular;interaccion molecular;proteins;protein dna interaction;optimization;proteina;molecular sequence data;base sequence;computational biology;protein;mutation	MOTIVATION A major limitation in modeling protein interactions is the difficulty of assessing the over-fitting of the training set. Recently, an experimentally based approach that integrates crystallographic information of C2H2 zinc finger-DNA complexes with binding data from 11 mutants, 7 from EGR finger I, was used to define an improved interaction code (no optimization). Here, we present a novel mixed integer programming (MIP)-based method that transforms this type of data into an optimized code, demonstrating both the advantages of the mathematical formulation to minimize over- and under-fitting and the robustness of the underlying physical parameters mapped by the code.   RESULTS Based on the structural models of feasible interaction networks for 35 mutants of EGR-DNA complexes, the MIP method minimizes the cumulative binding energy over all complexes for a general set of fundamental protein-DNA interactions. To guard against over-fitting, we use the scalability of the method to probe against the elimination of related interactions. From an initial set of 12 parameters (six hydrogen bonds, five desolvation penalties and a water factor), we proceed to eliminate five of them with only a marginal reduction of the correlation coefficient to 0.9983. Further reduction of parameters negatively impacts the performance of the code (under-fitting). Besides accurately predicting the change in binding affinity of validation sets, the code identifies possible context-dependent effects in the definition of the interaction networks. Yet, the approach of constraining predictions to within a pre-selected set of interactions limits the impact of these potential errors to related low-affinity complexes.   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	bioinformatics;cys2-his2 zinc fingers;coefficient;context-sensitive language;excretory function;experiment;hydrogen;integer (number);integer programming;interaction network;linear programming;lymphoma, mixed-cell, follicular;marginal model;mathematical optimization;mathematics;overfitting;processor affinity;scalability;test set;mutant	Nuri A Temiz;Andrew C. Trapp;Oleg A. Prokopyev;Carlos J. Camacho	2010		10.1093/bioinformatics/btp664	mutation;biology;protein–dna interaction;zinc finger;bioinformatics;binding site;artificial intelligence;peptide sequence;genetics;dna;algorithm	Comp.	10.011118136343066	-60.28227033564199	109545
a74bfba768e9a4dffe1dde3476b8642d3a99cd08	to infinity and beyond.	cell signalling;materials science;nanotechnology;nature;developmental biology;rna;signal transduction;pharmacology;biotechnology;marine biology;cancer;neuroscience;geophysics;systems biology;drug discovery;medicine;physics;earth science;environmental science;evolutionary biology;evolution;bioinformatics;immunology;neurobiology;molecular biology;quantum physics;astronomy;functional genomics;biochemistry;transcriptomics;climate change;dna;metabolomics;palaeobiology;computational biology;proteomics;biology;cell cycle;structural biology;ecology;genomics;medical research;astrophysics;genetics	We prove that if a group generated by a bireversible Mealy automaton contains an element of infinite order, its growth blows up and is necessarily exponential. As a direct consequence, no infinite virtually nilpotent group can be generated by a bireversible Mealy automaton. The study on how (semi)groups grow has been highlighted since Milnor’s question on the existence of groups of intermediate growth (faster than any polynomial and slower than any exponential) in 1968 [12], and the very first example of such a group given by Grigorchuk [5]. Uncountably many examples have followed this first one, see for instance [6]. Bartholdi and Erschler have even obtained results on precise computations of growth, in particular they proved that if a function satisfies some frame property, then there exists a finitely generated group with growth equivalent to it [1]. Besides, for now, intermediate growth and automaton groups, that is groups generated by Mealy automata, seem to have a very strong link, since the only known examples of intermediate growth groups are either automaton groups, or based on such groups. There exists no criterium to test if a Mealy automaton generates a group of intermediate growth and it is not even known if this property is decidable. However, there is no known example in the litterature of a bireversible Mealy automaton generating an intermediate growth group and it is legitimate to wonder if it is possible. This article enter in this scope. We prove that if there exists at least one element of infinite order in a group generated by a bireversible Mealy automaton, then its growth is necessarily exponential. It has been conjuctered, and proved in some cases [4], that an infinite group generated by a bireversible Mealy automaton always has an element of infinite order, which suggests that, indeed, a group generated by a bireversible Mealy automaton either is finite, or has exponential growth. Finally, let us mention the work by Brough and Cain to obtain some criteria to decide if a semigroup is an automaton semigroup [2]. Our work can be seen as partially answering a similar question: can a given group be generated by a bireversible Mealy automaton? A consequence of our result is that no infinite virtually nilpotent group can be. This article is organized as follows. In Section 1, we define the automaton groups and the growth of a group, and give some properties on the connected components of the powers of a Mealy automaton. In Section 2, we study the behaviour of some equivalence classes of words on the state set of a Mealy automaton. Finally, the main result takes place in Section 3.	automaton;computation;connected component (graph theory);mealy machine;polynomial;time complexity;turing completeness	Ines Klimann	2017		10.4230/LIPIcs.ICALP.2018.131	infinity;discrete mathematics;computer science;exponential function;nilpotent group	Logic	5.724401462125959	-64.90181816146095	109559
33087e94e642505ed17add40daf688035c14d202	two sample logo: a graphical representation of the differences between two sets of sequence alignments	nucleotides;statistical significance;graphical representation;sequence alignment;multiple sequence alignment;open source	SUMMARY Two Sample Logo is a web-based tool that detects and displays statistically significant differences in position-specific symbol compositions between two sets of multiple sequence alignments. In a typical scenario, two groups of aligned sequences will share a common motif but will differ in their functional annotation. The inclusion of the background alignment provides an appropriate underlying amino acid or nucleotide distribution and addresses intersite symbol correlations. In addition, the difference detection process is sensitive to the sizes of the aligned groups. Two Sample Logo extends WebLogo, a widely-used sequence logo generator. The source code is distributed under the MIT Open Source license agreement and is available for download free of charge.	amino acids;annotation;composition;download;motif;multiple sequence alignment;nucleotides;open-source license;sequence logo;source code;web application	Vladimir Vacic;Lilia M. Iakoucheva;Predrag Radivojac	2006	Bioinformatics	10.1093/bioinformatics/btl151	biology;nucleotide;multiple sequence alignment;computer science;bioinformatics;theoretical computer science;sequence alignment;statistical significance;world wide web	Comp.	-1.6117256224237237	-58.379263127965054	109647
7f942fe3817edfbddae4ef9fcefebcd7ce32f68e	protein complexes identification based on go attributed network embedding	network embedding;protein complexes identification;protein-protein interaction network	Identifying protein complexes from protein-protein interaction (PPI) network is one of the most important tasks in proteomics. Existing computational methods try to incorporate a variety of biological evidences to enhance the quality of predicted complexes. However, it is still a challenge to integrate different types of biological information into the complexes discovery process under a unified framework. Recently, attributed network embedding methods have be proved to be remarkably effective in generating vector representations for nodes in the network. In the transformed vector space, both the topological proximity and node attributed affinity between different nodes are preserved. Therefore, such attributed network embedding methods provide us a unified framework to integrate various biological evidences into the protein complexes identification process. In this article, we propose a new method called GANE to predict protein complexes based on Gene Ontology (GO) attributed network embedding. Firstly, it learns the vector representation for each protein from a GO attributed PPI network. Based on the pair-wise vector representation similarity, a weighted adjacency matrix is constructed. Secondly, it uses the clique mining method to generate candidate cores. Consequently, seed cores are obtained by ranking candidate cores based on their densities on the weighted adjacency matrix and removing redundant cores. For each seed core, its attachments are the proteins with correlation score that is larger than a given threshold. The combination of a seed core and its attachment proteins is reported as a predicted protein complex by the GANE algorithm. For performance evaluation, we compared GANE with six protein complex identification methods on five yeast PPI networks. Experimental results showes that GANE performs better than the competing algorithms in terms of different evaluation metrics. GANE provides a framework that integrate many valuable and different biological information into the task of protein complex identification. The protein vector representation learned from our attributed PPI network can also be used in other tasks, such as PPI prediction and disease gene prediction.		Bo Xu;Kun Li;Wei Zheng;Xiaoxia Liu;Yijia Zhang;Zhehuan Zhao;Zengyou He	2018		10.1186/s12859-018-2555-x		Comp.	5.09578730341883	-56.365643544494176	109659
b43f469ca71a93c0cfd43c1bb6b5a4a0d43c9c83	sbml-pet: a systems biology markup language-based parameter estimation tool	ordinary differential equation;gene regulation network;systems biology markup language;evolution strategy;parameter estimation	UNLABELLED The estimation of model parameters from experimental data remains a bottleneck for a major breakthrough in systems biology. We present a Systems Biology Markup Language (SBML) based Parameter Estimation Tool (SBML-PET). The tool is designed to enable parameter estimation for biological models including signaling pathways, gene regulation networks and metabolic pathways. SBML-PET supports import and export of the models in the SBML format. It can estimate the parameters by fitting a variety of experimental data from different experimental conditions. SBML-PET has a unique feature of supporting event definition in the SMBL model. SBML models can also be simulated in SBML-PET. Stochastic Ranking Evolution Strategy (SRES) is incorporated in SBML-PET for parameter estimation jobs. A classic ODE Solver called ODEPACK is used to solve the Ordinary Differential Equation (ODE) system.   AVAILABILITY http://sysbio.molgen.mpg.de/SBML-PET/. The website also contains detailed documentation for SBML-PET.	biological evolution;differential diagnosis;documentation;estimation theory;evolution strategy;gene expression regulation;markup language;occupations;polyethylene terephthalate;population parameter;sbml;solver;systems biology	Zhike Zi;Edda Klipp	2006	Bioinformatics	10.1093/bioinformatics/btl443	ordinary differential equation;sbml;computer science;bioinformatics;theoretical computer science;evolution strategy;estimation theory;statistics	Comp.	-3.9593596330240395	-54.461321313065255	109671
7d690a2c02278ee8474722dd6dea72e03c4eedda	reconstructing gene regulatory networks from knock-out data using gaussian noise model and pearson correlation coefficient	gaussian model;pearson correlation coefficient;dream;gene regulatory network;probability and statistics;bioinformatics	A gene regulatory network (GRN) is a large and complex network consisting of interacting elements that, over time, affect each other's state. The dynamics of complex gene regulatory processes are difficult to understand using intuitive approaches alone. To overcome this problem, we propose an algorithm for inferring the regulatory interactions from knock-out data using a Gaussian model combines with Pearson Correlation Coefficient (PCC). There are several problems relating to GRN construction that have been outlined in this paper. We demonstrated the ability of our proposed method to (1) predict the presence of regulatory interactions between genes, (2) their directionality and (3) their states (activation or suppression). The algorithm was applied to network sizes of 10 and 50 genes from DREAM3 datasets and network sizes of 10 from DREAM4 datasets. The predicted networks were evaluated based on AUROC and AUPR. We discovered that high false positive values were generated by our GRN prediction methods because the indirect regulations have been wrongly predicted as true relationships. We achieved satisfactory results as the majority of sub-networks achieved AUROC values above 0.5.		Faridah Hani Mohamed Salleh;Shereena Mohd Arif;Suhaila Zainudin;Mohd Firdaus Raih	2015	Computational biology and chemistry	10.1016/j.compbiolchem.2015.04.012	pearson product-moment correlation coefficient;probability and statistics;biology;gene regulatory network;gaussian network model;bioinformatics;machine learning;data mining;mathematics;statistics	AI	5.561397576251186	-57.00697041333088	109721
3f0bdc9b57fdb20340b39107be0fc6f5097e63ab	babelomics: an integrative platform for the analysis of transcriptomics, proteomics and genomic data with advanced functional profiling	software;genomics;internet;proteomics;gene expression profiling;oligonucleotide array sequence analysis	Babelomics is a response to the growing necessity of integrating and analyzing different types of genomic data in an environment that allows an easy functional interpretation of the results. Babelomics includes a complete suite of methods for the analysis of gene expression data that include normalization (covering most commercial platforms), pre-processing, differential gene expression (case-controls, multiclass, survival or continuous values), predictors, clustering; large-scale genotyping assays (case controls and TDTs, and allows population stratification analysis and correction). All these genomic data analysis facilities are integrated and connected to multiple options for the functional interpretation of the experiments. Different methods of functional enrichment or gene set enrichment can be used to understand the functional basis of the experiment analyzed. Many sources of biological information, which include functional (GO, KEGG, Biocarta, Reactome, etc.), regulatory (Transfac, Jaspar, ORegAnno, miRNAs, etc.), text-mining or protein-protein interaction modules can be used for this purpose. Finally a tool for the de novo functional annotation of sequences has been included in the system. This provides support for the functional analysis of non-model species. Mirrors of Babelomics or command line execution of their individual components are now possible. Babelomics is available at http://www.babelomics.org.	cluster analysis;command-line interface;de novo transcriptome assembly;experiment;functional programming;gene ontology term enrichment;genotype determination;interaction;kegg;open regulatory annotation database;preprocessor;proteomics;stratification;text mining;tissue-specific gene expression;statistical cluster	Ignacio Medina;José Carbonell;Luis Pulido;Sara C. Madeira;Stefan Götz;Ana Conesa;Joaquín Tárraga;Alberto D. Pascual-Montano;Rubén Nogales-Cadenas;Javier Santoyo;Francisco García-García;Martina Marbà;David Montaner;Joaquín Dopazo	2010		10.1093/nar/gkq388	biology;genomics;molecular biology;the internet;bioinformatics;gene expression profiling;proteomics	Comp.	-1.8023633565090251	-58.115178401570745	109731
b2756f97619f9c4b8887236938c32148fbd935cc	compression of whole genome alignments	dna;lempel ziv;biology computing;genomics;evolutionary model;alignement sequence;image coding;image processing;data compression;phylogeny;binary image;statistical analysis biological techniques biology computing data compression dna evolution biological genetics genomics molecular biophysics;evolution biological;procesamiento imagen;lossless compression;algorithme de lempel ziv;probabilistic approach;alineacion secuencia;algoritmo de lempel ziv;traitement image;statistical model;genetics;whole genome alignment;probabilistic model;codage image;compression image;hidden markov models;statistical analysis;image compression;enfoque probabilista;approche probabiliste;molecular biophysics;image binaire;modele statistique;lempel ziv compression dna sequencing statistical evolutionary models lossless binary image compression whole genome alignment compression genomic sequence data lossless compression algorithm;imagen binaria;lossless binary image compression;modelo estadistico;genomics bioinformatics image coding sequences dna databases evolution biology compression algorithms predictive models genetics;humans;sequence alignment;exponential growth;multiple sequence alignment;compression sans perte;compresion dato;biological techniques;compression;lempel ziv algorithm;probabilistic models of evolution;dna sequence;compresion sin perdida;compression donnee;genome sequence;whole genome alignment compression genetics lossless binary image compression multiple sequence alignment probabilistic models of evolution;bioinformatics;compresion imagen	Recent advances in DNA sequencing technology have caused an exponential growth of publicly available genomic sequence data. A particularly voluminous, frequently used static data set are whole genome alignments. The first lossless compression algorithm for such data sets based on well-established statistical evolutionary models and prediction techniques from lossless binary image compression is introduced. The compression rate is improved by a factor of 1.6 compared to the currently used Lempel-Ziv (LZ) compression.	algorithm;binary image;image compression;lz77 and lz78;lempel–ziv–stac;lossless compression;norm (social);singular value decomposition;statistical model;the matrix;time complexity;whole genome sequencing	Pavol Hanus;Janis Dingel;Georg Chalkidis;Joachim Hagenauer	2010	IEEE Transactions on Information Theory	10.1109/TIT.2009.2037052	statistical model;genomics;image processing;computer science;bioinformatics;theoretical computer science;mathematics;algorithm;statistics;molecular biophysics	Comp.	-0.22488740011366634	-52.46462347599881	109803
7c210d377fe74df84ed0e32860f9427435696264	fast thermodynamically constrained flux variability analysis		MOTIVATION Flux variability analysis (FVA) is an important tool to further analyse the results obtained by flux balance analysis (FBA) on genome-scale metabolic networks. For many constraint-based models, FVA identifies unboundedness of the optimal flux space. This reveals that optimal flux solutions with net flux through internal biochemical loops are feasible, which violates the second law of thermodynamics. Such unbounded fluxes may be eliminated by extending FVA with thermodynamic constraints.   RESULTS We present a new algorithm for efficient flux variability (and flux balance) analysis with thermodynamic constraints, suitable for analysing genome-scale metabolic networks. We first show that FBA with thermodynamic constraints is NP-hard. Then we derive a theoretical tractability result, which can be applied to metabolic networks in practice. We use this result to develop a new constraint programming algorithm Fast-tFVA for fast FVA with thermodynamic constraints (tFVA). Computational comparisons with previous methods demonstrate the efficiency of the new method. For tFVA, a speed-up of factor 30-300 is achieved. In an analysis of genome-scale metabolic networks in the BioModels database, we found that in 485 of 716 networks, additional irreversible or fixed reactions could be detected.   AVAILABILITY AND IMPLEMENTATION Fast-tFVA is written in C++ and published under GPL. It uses the open source software SCIP and libSBML. There also exists a Matlab interface for easy integration into Matlab. Fast-tFVA is available from page.mi.fu-berlin.de/arnem/fast-tfva.html.   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	algorithm;biomodels database;bioinformatics;biomass;c++;cerebral palsy;cobra;computation;conflict (psychology);constraint programming;ephrin type-b receptor 1, human;experiment;flux balance analysis;genus mycobacterium;gurobi;helicobacter pylori;interface device component;matlab;mtmc1 protein, methanosarcina barkeri;mycobacterium tuberculosis genotype:prid:pt:isolate:nom;np-hardness;open-source software;propionibacterium acnes;rafivirumab;scip;scientific publication;solutions;solver;spatial variability;staphylococcus aureus;subroutine;thermodynamics;algorithm;libsbml	Arne C. Müller;Alexander Bockmayr	2013	Bioinformatics	10.1093/bioinformatics/btt059	mathematical optimization;computer science;theoretical computer science;flux balance analysis;algorithm	Comp.	0.25771204023249766	-52.214420303995084	109914
9f154e8b469853a6ce9d2d00fa9ea0f862fcf0d0	evolutionary modeling of rate shifts reveals specificity determinants in hiv-1 subtypes	evolution molecular;virus internalization;evolutionary model;life cycle;phylogeny;hiv infections;amino acid sequence;drug resistance multiple viral;bayes theorem;models biological;human immunodeficiency virus;hiv 1;bayesian method;genetic speciation;time factors;humans;drug resistance;proteomics;adaptation biological;rate of evolution;geography	A hallmark of the human immunodeficiency virus 1 (HIV-1) is its rapid rate of evolution within and among its various subtypes. Two complementary hypotheses are suggested to explain the sequence variability among HIV-1 subtypes. The first suggests that the functional constraints at each site remain the same across all subtypes, and the differences among subtypes are a direct reflection of random substitutions, which have occurred during the time elapsed since their divergence. The alternative hypothesis suggests that the functional constraints themselves have evolved, and thus sequence differences among subtypes in some sites reflect shifts in function. To determine the contribution of each of these two alternatives to HIV-1 subtype evolution, we have developed a novel Bayesian method for testing and detecting site-specific rate shifts. The RAte Shift EstimatoR (RASER) method determines whether or not site-specific functional shifts characterize the evolution of a protein and, if so, points to the specific sites and lineages in which these shifts have most likely occurred. Applying RASER to a dataset composed of large samples of HIV-1 sequences from different group M subtypes, we reveal rampant evolutionary shifts throughout the HIV-1 proteome. Most of these rate shifts have occurred during the divergence of the major subtypes, establishing that subtype divergence occurred together with functional diversification. We report further evidence for the emergence of a new sub-subtype, characterized by abundant rate-shifting sites. When focusing on the rate-shifting sites detected, we find that many are associated with known function relating to viral life cycle and drug resistance. Finally, we discuss mechanisms of covariation of rate-shifting sites.	diversification (finance);emergence;evolution;hiv infections;hiv-1;immunologic deficiency syndromes;sensitivity and specificity;sensor;spatial variability;staphylococcal protein a;subtype (attribute)	Osnat Penn;Adi Stern;Nimrod D. Rubinstein;Julien Y Dutheil;Eran Bacharach;Nicolas Galtier;Tal Pupko	2008	PLoS Computational Biology	10.1371/journal.pcbi.1000214	biology;biological life cycle;drug resistance;bayesian probability;bioinformatics;peptide sequence;proteomics;bayes' theorem;genetics;statistics	Comp.	3.7927041688333345	-61.602273946483784	109952
8ead83622d66f3c4f8b814c84686f2ce513182ad	consistent two-dimensional visualization of protein-ligand complex series	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;large data sets;computer applications in chemistry;three dimensional;automatic generation;theoretical and computational chemistry;computational biology bioinformatics;drug design;uk phd theses thesis;graphical representation;visual analysis;life sciences;uk research reports;medical journals;active site;europe pmc;documentation and information in chemistry;biomedical research;bioinformatics	BACKGROUND The comparative two-dimensional graphical representation of protein-ligand complex series featuring different ligands bound to the same active site offers a quick insight in their binding mode differences. In comparison to arbitrary orientations of the residue molecules in the individual complex depictions a consistent placement improves the legibility and comparability within the series. The automatic generation of such consistent layouts offers the possibility to apply it to large data sets originating from computer-aided drug design methods.   RESULTS We developed a new approach, which automatically generates a consistent layout of interacting residues for a given series of complexes. Based on the structural three-dimensional input information, a global two-dimensional layout for all residues of the complex ensemble is computed. The algorithm incorporates the three-dimensional adjacencies of the active site residues in order to find an universally valid circular arrangement of the residues around the ligand. Subsequent to a two-dimensional ligand superimposition step, a global placement for each residue is derived from the set of already placed ligands. The method generates high-quality layouts, showing mostly overlap-free solutions with molecules which are displayed as structure diagrams providing interaction information in atomic detail. Application examples document an improved legibility compared to series of diagrams whose layouts are calculated independently from each other.   CONCLUSIONS The presented method extends the field of complex series visualizations. A series of molecules binding to the same protein active site is drawn in a graphically consistent way. Compared to existing approaches these drawings substantially simplify the visual analysis of large compound series.	diagram;drawings (art);drug design;graphical user interface;imagery;interaction information;ligands;mental orientation;solutions;algorithm	Katrin Stierand;Matthias Rarey	2011		10.1186/1758-2946-3-21	three-dimensional space;visual analytics;medicine;computer science;bioinformatics;data science;active site;data mining;drug design	Graphics	1.153735172604154	-57.53580463164162	109953
3e7713a42bdd6f09da3bc3593485a49b4fccbd22	an integrative method to normalize rna-seq data	transcription genetic;animals;high throughput nucleotide sequencing;computational biology bioinformatics;rna;algorithms;humans;sequence analysis rna;combinatorial libraries;computer appl in life sciences;calibration;gene expression profiling;microarrays;bioinformatics	Transcriptome sequencing is a powerful tool for measuring gene expression, but as well as some other technologies, various artifacts and biases affect the quantification. In order to correct some of them, several normalization approaches have emerged, differing both in the statistical strategy employed and in the type of corrected biases. However, there is no clear standard normalization method. We present a novel methodology to normalize RNA-Seq data, taking into account transcript size, GC content, and sequencing depth, which are the major quantification-related biases. In this study, we found that transcripts shorter than 600 bp have an underestimated expression level, while longer transcripts are even more overestimated that they are long. Second, it was well known that the higher the GC content (>50%), the more the transcripts are underestimated. Third, we demonstrated that the sequencing depth impacts the size bias and proposed a correction allowing the comparison of expression levels among many samples. The efficiency of our approach was then tested by comparing the correlation between normalized RNA-Seq data and qRT-PCR expression measurements. All the steps are automated in a program written in Perl and available on request. The methodology presented in this article identifies and corrects different biases that influence RNA-Seq quantification, and provides more accurate estimations of gene expression levels. This method can be applied to compare expression quantifications from many samples, but preferentially from the same tissue. In order to compare samples from different tissue, a calibration using several reference genes will be required.	biopolymer sequencing;calibration;gene expression;in silico pcr;morphologic artifacts;normalize;perl;quantitation;quantitative reverse transcriptase pcr;rna;sequence number;transcript;viral sequencing:prid:pt:ser:nom:sequencing	Cyril Filloux;Cédric Meersseman;Romain Philippe;Lionel Forestier;Christophe Klopp;Dominique Rocha;Abderrahman Maftah;Daniel Petit	2013		10.1186/1471-2105-15-188	biology;molecular biology;calibration;rna;dna microarray;bioinformatics;gene expression profiling;genetics	Comp.	3.954405131487894	-53.80271434794582	109970
0a8b41119f56711dd9d49f868a02ee020fc9b161	accurate computation of likelihoods in the coalescent with recombination via parsimony	evolutionary history;maximum likelihood;approximation method;statistical method;gene mapping	Understanding the variation of recombination rates across a given genome is crucial for disease gene mapping and for detecting signatures of selection, to name just a couple of applications. A widely-used method of estimating recombination rates is the maximum likelihood approach, and the problem of accurately computing likelihoods in the coalescent with recombination has received much attention in the past. A variety of sampling and approximation methods have been proposed, but no single method seems to perform consistently better than the rest, and there still is great value in developing better statistical methods for accurately computing likelihoods. So far, with the exception of some twolocus models, it has remained unknown how the true likelihood exactly behaves as a function of model parameters, or how close estimated likelihoods are to the true likelihood. In this paper, we develop a deterministic, parsimony-based method of accurately computing the likelihood for multi-locus input data of moderate size. We first find the set of all ancestral configurations (ACs) that occur in evolutionary histories with at most k crossover recombinations. Then, we compute the likelihood by summing over all evolutionary histories that can be constructed only using the ACs in that set. We allow for an arbitrary number of crossing over, coalescent and mutation events in a history, as long as the transitions stay within that restricted set of ACs. For given parameter values, by gradually increasing the bound k until the likelihood stabilizes, we can obtain an accurate estimate of the likelihood. At least for moderate crossover rates, the algorithm-based method described here opens up a new window of opportunities for testing and fine-tuning statistical methods for computing likelihoods.	antivirus software;approximation algorithm;computation;crossover (genetic algorithm);gene expression programming;locus;maximum parsimony (phylogenetics);occam's razor;sampling (signal processing);sensor	Rune B. Lyngsø;Yun S. Song;Jotun Hein	2008		10.1007/978-3-540-78839-3_41	biology;econometrics;mathematical optimization;gene mapping;mathematics;maximum likelihood;likelihood function;quasi-maximum likelihood;statistics	Comp.	2.082485890551839	-52.34424140793605	109987
2451d2b24abbf1718fc10d121e85be7fb73b4656	copy number variation detection from 1000 genomes project exon capture sequencing data	genotype;high throughput nucleotide sequencing;bayes theorem;sequence analysis dna;computational biology bioinformatics;dna copy number variations;exome;genome;algorithms;combinatorial libraries;computer appl in life sciences;polymorphism single nucleotide;exons;microarrays;bioinformatics	DNA capture technologies combined with high-throughput sequencing now enable cost-effective, deep-coverage, targeted sequencing of complete exomes. This is well suited for SNP discovery and genotyping. However there has been little attention devoted to Copy Number Variation (CNV) detection from exome capture datasets despite the potentially high impact of CNVs in exonic regions on protein function. As members of the 1000 Genomes Project analysis effort, we investigated 697 samples in which 931 genes were targeted and sampled with 454 or Illumina paired-end sequencing. We developed a rigorous Bayesian method to detect CNVs in the genes, based on read depth within target regions. Despite substantial variability in read coverage across samples and targeted exons, we were able to identify 107 heterozygous deletions in the dataset. The experimentally determined false discovery rate (FDR) of the cleanest dataset from the Wellcome Trust Sanger Institute is 12.5%. We were able to substantially improve the FDR in a subset of gene deletion candidates that were adjacent to another gene deletion call (17 calls). The estimated sensitivity of our call-set was 45%. This study demonstrates that exonic sequencing datasets, collected both in population based and medical sequencing projects, will be a useful substrate for detecting genic CNV events, particularly deletions. Based on the number of events we found and the sensitivity of the methods in the present dataset, we estimate on average 16 genic heterozygous deletions per individual genome. Our power analysis informs ongoing and future projects about sequencing depth and uniformity of read coverage required for efficient detection.	biopolymer sequencing;circuit complexity;copy number polymorphism;exome;exons;experiment;false discovery rate;gene deletion;genotype determination;high-throughput computing;institute for operations research and the management sciences;nitroprusside;one thousand;sampling - surgical action;sensor;silo (dataset);spatial variability;subgroup;throughput;whole genome sequencing	Jiantao Wu;Krzysztof R. Grzeda;Chip Stewart;Fabian Grubert;Alexander E. Urban;Michael P. Snyder;Gabor T. Marth	2012		10.1186/1471-2105-13-305	biology;molecular biology;exome sequencing;dna microarray;exon;bioinformatics;sequencing;genotype;exome;bayes' theorem;genetics;deep sequencing;genome	Comp.	2.9043293191159667	-53.74936486075991	110080
9738d881d4050d313204e16839a25eb2ff5ed1ca	conformational changes of nucleic acids and poly (d(a-t)-d(a-t)) caused by photoaddition of furocoumarins	dna;radiation effects;conformational change;isomerism;polynucleotides;ultraviolet rays;nucleic acid denaturation;ficusin;binding sites;coumarins;methoxsalen;rna;circular dichroism;nucleic acid conformation;deoxyribonucleotides;nucleic acid	DNA's of various AT content, poly[d(A-T)-d(A-T)], and double-stranded RNA were irradiated with UV light at 365 nm in the presence of linear (xanthotoxin) or angular (angelicin) furocoumarins. The covalent photobinding is strongly dependent on the spatial arrangement of furocoumarin molecules at the polymer conformation. CD measurements demonstrate that the bifunctional photochemical binding of xanthotoxin with double-stranded DNA's and poly[d(A-T)-d(A-T)] is accompanied by conformational changes which involve probably decreasing helical twisting of the double helix. This effect is greatly enhanced with increasing AT content. The formation of A-like structures is very unlikely since the B leads to A transition induced by ethanol addition was found to be strongly suppressed in xanthotoxin photoreacted DNA. The B-type helix appears to be the most sensitive conformation with minor restriction to produce photochemically induced cross-links.	angularjs;cell nucleus;covalent interaction;ethanol;furocoumarins;methoxsalen;nucleic acids;poly a;poly adenosine diphosphate ribose;polymer;rna;rna, double-stranded;ultraviolet therapy	L. Kittler;Christian Zimmer	1976	Nucleic acids research	10.1093/nar/3.1.191	circular dichroism;biology;biochemistry;nucleic acid;rna;binding site;polynucleotide;genetics;dna	EDA	6.221165724296672	-63.668701349788954	110089
54467c9b69a731642c656d5ad0a1ce598a0af9d4	meraculous2: fast accurate short-read assembly of large polymorphic genomes		"""We present Meraculous2, an update to the Meraculous short-read assembler that includes (1) handling of allelic variation using """" bubble """" structures within the de Bruijn graph, (2) improved gap closing, and (3) an improved scaffolding algorithm that produces more complete assemblies without compromising scaffolding accuracy. The speed and bandwidth efficiency of the new parallel implementation have also been substantially improved, allowing the assembly of a human genome to be accomplished in 24 hours on the JGI/NERSC Genepool system. To highlight the features of Meraculous2 we present here the assembly of the diploid human genome NA12878, and compare it with previously published assemblies of the same data using other algorithms. The Meraculous2 assemblies are shown to have better completeness, contiguity, and accuracy than other published assemblies for these data. Practical considerations including pre-assembly analyses of polymorphism and repetitiveness are described."""	algorithm;assembly language;closing (morphology);de bruijn graph;gene pool;spectral efficiency	Jarrod Chapman;Isaac Y. Ho;Eugene Goltsman;Daniel S. Rokhsar	2016	CoRR		computer science;bioinformatics;theoretical computer science;algorithm	Graphics	0.5647207261486841	-54.44484531002858	110204
a7ca443f2fc616def963b521acdbe39b9b160ad3	tbestdb: a taxonomically broad database of expressed sequence tags (ests)	animals;genomics;databases nucleic acid;consensus sequence;fungi;cluster analysis;internet;eukaryota;user computer interface;base sequence;expressed sequence tag;expressed sequence tags	The TBestDB database contains approximately 370,000 clustered expressed sequence tag (EST) sequences from 49 organisms, covering a taxonomically broad range of poorly studied, mainly unicellular eukaryotes, and includes experimental information, consensus sequences, gene annotations and metabolic pathway predictions. Most of these ESTs have been generated by the Protist EST Program, a collaboration among six Canadian research groups. EST sequences are read from trace files up to a minimum quality cut-off, vector and linker sequence is masked, and the ESTs are clustered using phrap. The resulting consensus sequences are automatically annotated by using the AutoFACT program. The datasets are automatically checked for clustering errors due to chimerism and potential cross-contamination between organisms, and suspect data are flagged in or removed from the database. Access to data deposited in TBestDB by individual users can be restricted to those users for a limited period. With this first report on TBestDB, we open the database to the research community for free processing, annotation, interspecies comparisons and GenBank submission of EST data generated in individual laboratories. For instructions on submission to TBestDB, contact tbestdb@bch.umontreal.ca. The database can be queried at http://tbestdb.bcm.umontreal.ca/.	blinded;checking (action);chimerism;cluster analysis;consensus sequence;expressed sequence tags;forty nine;genbank;gene annotation;gene regulatory network;laboratory;phrap;regulatory submission;protists;statistical cluster	Emmet A. O'Brien;Liisa B. Koski;Yue Zhang;LiuSong Yang;Eric Wang;Michael W. Gray;Gertraud Burger;B. Franz Lang	2007		10.1093/nar/gkl770	biology;genomics;bioinformatics;sequence database;expressed sequence tag	DB	-0.34158960846976744	-56.5987577071295	110238
d3b1355ad8f2ec41ea11b53296d1b92e18fdb8b9	watchdog – a workflow management system for the distributed analysis of large-scale experimental data	automated execution;distributed analysis;high-throughput experiments;large-scale datasets;rna-seq;reproducibility;reusability;workflow management system	The development of high-throughput experimental technologies, such as next-generation sequencing, have led to new challenges for handling, analyzing and integrating the resulting large and diverse datasets. Bioinformatical analysis of these data commonly requires a number of mutually dependent steps applied to numerous samples for multiple conditions and replicates. To support these analyses, a number of workflow management systems (WMSs) have been developed to allow automated execution of corresponding analysis workflows. Major advantages of WMSs are the easy reproducibility of results as well as the reusability of workflows or their components. In this article, we present Watchdog, a WMS for the automated analysis of large-scale experimental data. Main features include straightforward processing of replicate data, support for distributed computer systems, customizable error detection and manual intervention into workflow execution. Watchdog is implemented in Java and thus platform-independent and allows easy sharing of workflows and corresponding program modules. It provides a graphical user interface (GUI) for workflow construction using pre-defined modules as well as a helper script for creating new module definitions. Execution of workflows is possible using either the GUI or a command-line interface and a web-interface is provided for monitoring the execution status and intervening in case of errors. To illustrate its potentials on a real-life example, a comprehensive workflow and modules for the analysis of RNA-seq experiments were implemented and are provided with the software in addition to simple test examples. Watchdog is a powerful and flexible WMS for the analysis of large-scale high-throughput experiments. We believe it will greatly benefit both users with and without programming skills who want to develop and apply bioinformatical workflows with reasonable overhead. The software, example workflows and a comprehensive documentation are freely available at www.bio.ifi.lmu.de/watchdog.	bioinformatics;biopolymer sequencing;command-line interface;computer systems;distributed computing;documentation;error detection and correction;experiment;graphical user interface;handling (psychology);high-throughput computing;java programming language;massively-parallel sequencing;overhead (computing);real life;requirements analysis;self-replicating machine;sequence number;throughput;user interface device component;watchdog timer;web map service;williams syndrome	Michael Kluge;Caroline C. Friedel	2018		10.1186/s12859-018-2107-4	experimental data;workflow management system;reusability;biology;bioinformatics;workflow	ML	-2.249908660176722	-56.90706425938842	110245
7bf3ce75790ebace816ea31105952483165c5cf7	identification of the quinolinedione inhibitor binding site in cdc25 phosphatase b through docking and molecular dynamics simulations	binding mode;docking;molecular dynamics;nsc663284;protein flexibility	Cdc25 phosphatase B, a potential target for cancer therapy, is inhibited by a series of quinones. The binding site and mode of quinone inhibitors to Cdc25B remains unclear, whereas this information is important for structure-based drug design. We investigated the potential binding site of NSC663284 [DA3003-1 or 6-chloro-7-(2-morpholin-4-yl-ethylamino)-quinoline-5, 8-dione] through docking and molecular dynamics simulations. Of the two main binding sites suggested by docking, the molecular dynamics simulations only support one site for stable binding of the inhibitor. Binding sites in and near the Cdc25B catalytic site that have been suggested previously do not lead to stable binding in 50 ns molecular dynamics (MD) simulations. In contrast, a shallow pocket between the C-terminal helix and the catalytic site provides a favourable binding site that shows high stability. Two similar binding modes featuring protein-inhibitor interactions involving Tyr428, Arg482, Thr547 and Ser549 are identified by clustering analysis of all stable MD trajectories. The relatively flexible C-terminal region of Cdc25B contributes to inhibitor binding. The binding mode of NSC663284, identified through MD simulation, likely prevents the binding of protein substrates to Cdc25B. The present results provide useful information for the design of quinone inhibitors and their mechanism of inhibition.	1,4-benzoquinone;binding sites;boat dock;box;cdc25b gene;catalytic domain;cluster analysis;crystal structure;dna binding site;docking (molecular);docking -molecular interaction;don woods (programmer);drug design;expectation propagation;hydrogen bonding;ligand binding domain;ligands;molecular dynamics;nsc 663284;natural science disciplines;neoplasms;protein tyrosine phosphatase;protein tyrosine phosphatase, non-receptor type 6;pyschological bonding;quinones;sampling - surgical action;simulation;wood material;cancer therapy;procollagen type i n-terminal peptide	Yushu Ge;Marc van der Kamp;Maturos Malaisree;Dan Liu;Yi Liu;Adrian J. Mulholland	2017	Journal of computer-aided molecular design	10.1007/s10822-017-0073-y	bioinformatics;docking (molecular);cdc25;chemistry;molecular dynamics;quinone;phosphatase;biochemistry;binding site;molecular biology	Comp.	9.271842833498761	-61.97833071113253	110304
5a6d4ddf7335b5350a4456c7f6a3414529257999	compartmental models of immunological tolerance		An administration of large doses of an antigen brings about immunological tolerance (unresponsiveness) to the next challenge with the same antigen. A hypothesis on the mechanism of tolerance to Human Serum Albumin (HSA) induced in chickens was formulated mathematically using compartmental models. By comparison of the modelled and experimental results, the presence of some additional mechanism was demonstrated.	heterogeneous system architecture;multi-compartment model	Petr Klein;Jaroslav Dolezal;Tomás Hraba	1980	Kybernetika		mathematics;mathematical optimization	Robotics	9.839065487911345	-65.27466040899014	110326
93077581bb4d404056e26af0d9ce3da8b05c97aa	development of a quantitative structure-activity relationship model for inhibition of gram-positive bacterial cell growth by biarylamides	quantitative structure activity relationship;cell growth	A set of compounds consisting of a new and diverse collection of biarylamides was examined using quantitative structure-activity relationship techniques for the purpose of developing a model to describe inhibition of gram-positive bacterial growth (minimum inhibition concentration). The model was sought in order to obtain insight for designing new molecules. A detailed analysis of the underlying structure-activity relationship helped provide insight concerning which structural features of the molecules modulated the activity of the compounds against gram-positive organisms.	modulation;quantitative structure–activity relationship;cell growth;gram	David T. Stanton;Prakash J. Madhav;Larry J. Wilson;Timothy W. Morris;Paul M. Hershberger;Christian N. Parker	2004	Journal of chemical information and computer sciences	10.1021/ci034158p	computational chemistry;bacterial growth;bacterial cell structure;cell biology;cell growth;mathematics;quantitative structure–activity relationship;bioinformatics	ML	7.252764302614793	-61.03203780696286	110391
935a5f4096de63521e098294c0f29f24cae7cc16	quantized correlation coefficient for measuring reproducibility of chip-chip data	animals;female;array cgh;male;gene expression data;journal article;computational biology bioinformatics;chip;nucleic acid hybridization;drosophila;chromatin immunoprecipitation;protein dna interaction;algorithms;histone modification;humans;oligonucleotide probes;data quality;combinatorial libraries;correlation coefficient;computer appl in life sciences;dna copy number;gene expression profiling;oligonucleotide array sequence analysis;microarrays;bioinformatics	Chromatin immunoprecipitation followed by microarray hybridization (ChIP-chip) is used to study protein-DNA interactions and histone modifications on a genome-scale. To ensure data quality, these experiments are usually performed in replicates, and a correlation coefficient between replicates is used often to assess reproducibility. However, the correlation coefficient can be misleading because it is affected not only by the reproducibility of the signal but also by the amount of binding signal present in the data. We develop the Quantized correlation coefficient (QCC) that is much less dependent on the amount of signal. This involves discretization of data into set of quantiles (quantization), a merging procedure to group the background probes, and recalculation of the Pearson correlation coefficient. This procedure reduces the influence of the background noise on the statistic, which then properly focuses more on the reproducibility of the signal. The performance of this procedure is tested in both simulated and real ChIP-chip data. For replicates with different levels of enrichment over background and coverage, we find that QCC reflects reproducibility more accurately and is more robust than the standard Pearson or Spearman correlation coefficients. The quantization and the merging procedure can also suggest a proper quantile threshold for separating signal from background for further analysis. To measure reproducibility of ChIP-chip data correctly, a correlation coefficient that is robust to the amount of signal present should be used. QCC is one such measure. The QCC statistic can also be applied in a variety of other contexts for measuring reproducibility, including analysis of array CGH data for DNA copy number and gene expression data.	aquaporin 1;chip-on-chip;coefficient;computer-generated holography;copy number;correlation study;dna microarray chip;data quality;discretization;experiment;gene expression;gene ontology term enrichment;herlitz disease;histones;interaction;nucleic acid hybridization;quantization (signal processing);statistic (data);chromatin immunoprecipitation	Shouyong Peng;Mitzi I. Kuroda;Peter J. Park	2009		10.1186/1471-2105-11-399	chip;biology;protein–dna interaction;molecular biology;chromatin immunoprecipitation;dna microarray;data quality;bioinformatics;histone;gene expression profiling;genetics;nucleic acid thermodynamics	Comp.	4.5191082893142775	-53.33903421956641	110427
45f011bdfef87eaa1555ccf549fdfe8fd720e531	metadisorder: a meta-server for the prediction of intrinsic disorder in proteins	software;computational biology bioinformatics;proteins;protein conformation;structural homology protein;algorithms;combinatorial libraries;computer appl in life sciences;protein unfolding;microarrays;bioinformatics	Intrinsically unstructured proteins (IUPs) lack a well-defined three-dimensional structure. Some of them may assume a locally stable structure under specific conditions, e.g. upon interaction with another molecule, while others function in a permanently unstructured state. The discovery of IUPs challenged the traditional protein structure paradigm, which stated that a specific well-defined structure defines the function of the protein. As of December 2011, approximately 60 methods for computational prediction of protein disorder from sequence have been made publicly available. They are based on different approaches, such as utilizing evolutionary information, energy functions, and various statistical and machine learning methods. Given the diversity of existing intrinsic disorder prediction methods, we decided to test whether it is possible to combine them into a more accurate meta-prediction method. We developed a method based on arbitrarily chosen 13 disorder predictors, in which the final consensus was weighted by the accuracy of the methods. We have also developed a disorder predictor GSmetaDisorder3D that used no third-party disorder predictors, but alignments to known protein structures, reported by the protein fold-recognition methods, to infer the potentially structured and unstructured regions. Following the success of our disorder predictors in the CASP8 benchmark, we combined them into a meta-meta predictor called GSmetaDisorderMD, which was the top scoring method in the subsequent CASP9 benchmark. A series of disorder predictors described in this article is available as a MetaDisorder web server at http://iimcb.genesilico.pl/metadisorder/ . Results are presented both in an easily interpretable, interactive mode and in a simple text format suitable for machine processing.	attention deficit hyperactivity disorder;auditory processing disorder;benchmark (computing);computation;inference;intrinsically disordered proteins;kerrison predictor;machine learning;mood disorders;programming paradigm;protein, organized by structure;score;server (computing);simpletext;threading (protein sequence);web server;caspase-9	Lukasz P. Kozlowski;Janusz M. Bujnicki	2011		10.1186/1471-2105-13-111	biology;protein structure;dna microarray;computer science;bioinformatics;unfolded protein response;machine learning;data mining	Comp.	8.568440161242528	-57.658952607733625	110438
a4fb5f495bcd43cae7f54b5830e4c8389339d3af	large scale features in dna genomic signals	analisis fase;second order;genomique;genomics;nucleotides;amino acid;signal analysis;sequence path;genomica;analisis de senal;genetic code;analyse multiresolution;signal genomique;nucleotide sequence;analyse phase;large scale;genomic signals;representation signal;phase analysis;feature extraction;signal processing;signal representation;extraction caracteristique;complex representation;unwrapped phase;code genetique;multiresolution analysis;analyse signal;analisis multiresolucion	Complex representations of the nucleotides, codons and amino acids derived from the projection of the Genetic Code Tetrahedron on adequately oriented planes are presented. By converting the sequences of nucleotides and polypeptides into digital genomic signals, this approach o2ers the possibility of using signal processing methods for the analysis of genomic information. New tools for genomic signal analysis are introduced at the nucleotide, codon and amino acid levels, in a multiresolution approach. It is shown that some important features of nucleotide sequences can be revealed using these signal representations. The paper reports the existence of large scale and global trends of DNA genomic signals in both eukaryotes and prokaryotes, re6ecting an almost constant second order nucleotide statistics along DNA strands even at the points where the 7rst order nucleotide statistics show marked changes, as it is the case in prokaryotes. ? 2002 Elsevier Science B.V. All rights reserved.	multiresolution analysis;signal processing	Paul Dan Cristea	2003	Signal Processing	10.1016/S0165-1684(02)00477-2	multiresolution analysis;computer vision;nucleotide;amino acid;feature extraction;nucleic acid sequence;computer science;bioinformatics;signal processing;genomic organization;genetic code;second-order logic	Comp.	2.4113517028324583	-63.375608655686094	110736
f15a6ef2ad82075792871367c0cf4b8d4da0746d	scaffold diversity of exemplified medicinal chemistry space	medicinal chemistry 1 including analytical chemistry and in silico chemistry;chemistry pharmaceutical;small molecule libraries	The scaffold diversity of 7 representative commercial and proprietary compound libraries is explored for the first time using both Murcko frameworks and Scaffold Trees. We show that Level 1 of the Scaffold Tree is useful for the characterization of scaffold diversity in compound libraries and offers advantages over the use of Murcko frameworks. This analysis also demonstrates that the majority of compounds in the libraries we analyzed contain only a small number of well represented scaffolds and that a high percentage of singleton scaffolds represent the remaining compounds. We use Tree Maps to clearly visualize the scaffold space of representative compound libraries, for example, to display highly populated scaffolds and clusters of structurally similar scaffolds. This study further highlights the need for diversification of compound libraries used in hit discovery by focusing library enrichment on the synthesis of compounds with novel or underrepresented scaffolds.	chemical library;diversification (finance);gene ontology term enrichment;libraries;map;medicinal chemistry;population;qp state machine frameworks;thrombocytopenia	Sarah R. Langdon;Nathan Brown;Julian Blagg	2011		10.1021/ci2001428	bioinformatics;combinatorial chemistry;nanotechnology	Comp.	0.9484478608999242	-60.49923624253278	110791
399315634da417b0fea52399b67e81f5533ea65c	a sliding window and keyword tree based algorithm for multiple sequence alignment	keyword tree;genomics;text analysis bioinformatics genetics genomics probability string matching;probability;text analysis;reference sequence;sliding windows;genetics;bioinformatics sliding window keyword tree based algorithm multiple sequence alignment msa genetic sequence analysis genome data reference sequence determination substring set matching sequence data probability center sequence complete matching region center star method aligning method;bioinformatics heuristic algorithms genomics educational institutions accuracy complexity theory;sequence analysis;multiple sequence alignment;string matching;sliding windows multiple sequence alignment reference sequence keyword tree;sliding window;bioinformatics	Multiple sequence alignment (MSA) is an important issue in genetic sequence analysis. The increasing volume of genome data requires tools that can quickly and accurately compare and align them. The most important step of MSA is the reference sequence determination. Current alignment methods usually need a huge time to find the reference sequence in long sequences and the accuracy of the determining sequence still need to improve. In this paper, a sliding window and the keyword tree based algorithm is employed to match the substring set of the sequence data and find the reference sequence with the greatest probability. The novel method can accurately find the center sequence and the complete matching regions. Using these regions, our algorithm can align the multiple sequences based on an improved center star method. Following the change of the advanced step value of the slide window, both the running time and the accuracy of our aligning method will change. Experimental results indicate that the improved method is faster and more accurate than others.	algorithm;align (company);computation;dynamic programming;matching (graph theory);multiple sequence alignment;norm (social);sequence analysis;slide rule;substring;time complexity	Yong Sun	2012	2012 9th International Conference on Fuzzy Systems and Knowledge Discovery	10.1109/FSKD.2012.6233880	sliding window protocol;reference genome;genomics;multiple sequence alignment;computer science;bioinformatics;sequence analysis;pattern recognition;probability;data mining;string searching algorithm	Robotics	-1.9080052927195412	-52.533170003934	110814
5d371716f5f09dd58be0d89a01075f02a6216689	application of petri net based analysis techniques to signal transduction pathways	pheromones;saccharomyces cerevisiae;metabolic network;ordinary differential equation;qualitative data;signal transduction;models biological;qualitative analysis;signal transduction pathway;kinetic parameter;computational biology bioinformatics;model validation;discrete model;design method;biological systems;algorithms;network structure;functional unit;combinatorial libraries;high throughput;computational biology;kinetics;petri net;quantitative method;computer appl in life sciences;computer simulation;biological network;microarrays;bioinformatics	Signal transduction pathways are usually modelled using classical quantitative methods, which are based on ordinary differential equations (ODEs). However, some difficulties are inherent in this approach. On the one hand, the kinetic parameters involved are often unknown and have to be estimated. With increasing size and complexity of signal transduction pathways, the estimation of missing kinetic data is not possible. On the other hand, ODEs based models do not support any explicit insights into possible (signal-) flows within the network. Moreover, a huge amount of qualitative data is available due to high-throughput techniques. In order to get information on the systems behaviour, qualitative analysis techniques have been developed. Applications of the known qualitative analysis methods concern mainly metabolic networks. Petri net theory provides a variety of established analysis techniques, which are also applicable to signal transduction models. In this context special properties have to be considered and new dedicated techniques have to be designed. We apply Petri net theory to model and analyse signal transduction pathways first qualitatively before continuing with quantitative analyses. This paper demonstrates how to build systematically a discrete model, which reflects provably the qualitative biological behaviour without any knowledge of kinetic parameters. The mating pheromone response pathway in Saccharomyces cerevisiae serves as case study. We propose an approach for model validation of signal transduction pathways based on the network structure only. For this purpose, we introduce the new notion of feasible t-invariants, which represent minimal self-contained subnets being active under a given input situation. Each of these subnets stands for a signal flow in the system. We define maximal common transition sets (MCT-sets), which can be used for t-invariant examination and net decomposition into smallest biologically meaningful functional units. The paper demonstrates how Petri net analysis techniques can promote a deeper understanding of signal transduction pathways. The new concepts of feasible t-invariants and MCT-sets have been proven to be useful for model validation and the interpretation of the biological system behaviour. Whereas MCT-sets provide a decomposition of the net into disjunctive subnets, feasible t-invariants describe subnets, which generally overlap. This work contributes to qualitative modelling and to the analysis of large biological networks by their fully automatic decomposition into biologically meaningful modules.	biological network;biological system;contain (action);differential diagnosis;disjunctive normal form;ephrin type-b receptor 1, human;flow;gene regulatory network;high-throughput computing;kinetics;maximal set;mobile data terminal;petri net;signal detection (psychology);signal transduction pathways;subnetwork;throughput;transduction (machine learning);response to pheromone	Andrea Sackmann;Monika Heiner;Ina Koch	2006	BMC Bioinformatics	10.1186/1471-2105-7-482	computer simulation;biology;computer science;bioinformatics;theoretical computer science;signal transduction	Comp.	6.646821349131363	-59.203202618185955	110828
0746d2a369657ade0b9e8cac745f8030929b9f95	human immunodeficiency virus type 1, human protein interaction database at ncbi	national library of medicine;computer graphics;viral proteins;human immunodeficiency virus;hiv 1;gag gene products human immunodeficiency virus;proteins;humans;protein interaction;protein interaction mapping;acquired immunodeficiency syndrome;databases protein	The 'Human Immunodeficiency Virus Type 1 (HIV-1), Human Protein Interaction Database', available through the National Library of Medicine at www.ncbi.nlm.nih.gov/RefSeq/HIVInteractions, was created to catalog all interactions between HIV-1 and human proteins published in the peer-reviewed literature. The database serves the scientific community exploring the discovery of novel HIV vaccine candidates and therapeutic targets. To facilitate this discovery approach, the following information for each HIV-1 human protein interaction is provided and can be retrieved without restriction by web-based downloads and ftp protocols: Reference Sequence (RefSeq) protein accession numbers, Entrez Gene identification numbers, brief descriptions of the interactions, searchable keywords for interactions and PubMed identification numbers (PMIDs) of journal articles describing the interactions. Currently, 2589 unique HIV-1 to human protein interactions and 5135 brief descriptions of the interactions, with a total of 14,312 PMID references to the original articles reporting the interactions, are stored in this growing database. In addition, all protein-protein interactions documented in the database are integrated into Entrez Gene records and listed in the 'HIV-1 protein interactions' section of Entrez Gene reports. The database is also tightly linked to other databases through Entrez Gene, enabling users to search for an abundance of information related to HIV pathogenesis and replication.	accession number (identifier);accession number (bioinformatics);database;description;document completion status - documented;entrez;gene prediction;hiv infections;hiv-1;immunologic deficiency syndromes;murine sarcoma viruses;ncbi taxonomy;pierre robin syndrome;protocols documentation;pubmed;refseq;scientific publication;web application;protein protein interaction	William Fu;Brigitte E. Sanders-Beer;Kenneth S. Katz;Donna R. Maglott;Kim D. Pruitt;Roger G. Ptak	2009		10.1093/nar/gkn708	biology;bioinformatics;virology;computer graphics;genetics	Comp.	-1.6300040034869214	-61.130366289258035	110937
10ae10be6acfd0f91a1d7349ae0d8a58bce78d0c	molecular mechanism of hiv-1 integrase-vdna interactions and strand transfer inhibitor action: a molecular modeling perspective	raltegravir;protein dna interactions;molecular dynamics simulation;free energy calculation;hiv 1 integrase	Human immunodeficiency virus type 1 (HIV-1) integrase (IN) is an essential enzyme for splicing a viral DNA (vDNA) replica of its genome into host cell chromosomal DNA (hDNA) and has been recently recognized as a promising therapeutic target for developing anti-AIDS agents. The interaction between HIV-1 IN and vDNA plays an important role in the integration process of the virus. However, a detailed understanding about the mechanism of this interactions as well as the action of the anti-HIV drug raltegravir (RAL, approved by FDA in 2007) targeting HIV-1 IN in the inhibition of the vDNA strand transfer is still absent. In the present work, a molecular modeling study by combining homology modeling, molecular dynamics (MD) simulations with molecular mechanics Poisson-Boltzmann surface area (MM-PBSA), and molecular mechanics Generalized-Born surface area (MM-GBSA) calculations was performed to investigate the molecular mechanism of HIV-1 IN-vDNA interactions and the inhibition action of vDNA strand transfer inhibitor (INSTI) RAL. The structural analysis showed that RAL did not influence the interaction between vDNA and HIV-1 IN, but rather targeted a special conformation of HIV-1 IN to compete with host DNA and block the function of HIV-1 IN by forcing the 3'-OH of the terminal A17 nucleotide away from the three catalytic residues (Asp64, Asp116, and Glu152) and two Mg(2+) ions. Thus, the obtained results could be helpful for understanding of the integration process of the HIV-1 virus and provide some new clues for the rational design and discovery of potential compounds that would specifically block HIV-1 virus replication.	acquired immunodeficiency syndrome;cell (microprocessor);dna binding site;dna, viral;hiv;hiv-1;homology (biology);homology modeling;host cell;immunologic deficiency syndromes;implicit solvation;integrase;interaction;ions;modeling perspective;molecular dynamics;molecular mechanics;nucleic acid strand;nucleotides;poisson–boltzmann equation;rna splicing;simulation;strand (programming language);structural analysis;therapeutic targets database;virus replication;cellular targeting;molecular modeling;raltegravir	Weiwei Xue;Huanxiang Liu;Xiaojun Yao	2012	Journal of computational chemistry	10.1002/jcc.22887	stereochemistry;molecular dynamics;molecular biology;chemistry;computational chemistry;physics;quantum mechanics	Comp.	8.76611896458491	-62.5107935060035	111079
face570e1844daa9d32e7e5f64d9920c4e6593f0	a mismatch pcr-rflp primer design for snp genotyping using genetic algorithm	slc6a4 genetic algorithm polymerase chain reaction restriction fragment length polymorphism primer design;cancer;snp genotyping;genetics;polymerase chain reaction;genetic algorithm ga pcr rflp snp genotyping mutagenic primer restriction enzyme;restriction enzyme;slc6a4;biochemistry clamps gallium bioinformatics genetics genetic algorithms cancer;restriction fragment length polymorphism;pcr rflp;genetic algorithm;polymerase chain reaction restriction fragment length polymorphism;genetic algorithms;primer design;clamps;mutagenic primer;biochemistry;genetics genetic algorithms;gallium;single nucleotide polymorphism;genetic algorithm ga;bioinformatics;in silico	Designing a feasible primer pair is an important work before performing polymerase chain reaction-restriction fragment length polymorphism (PCR-RFLP) for single nucleotide polymorphism (SNP) genotyping. However, in many cases, no restriction enzymes are available to discriminate the target SNP, thus rendering the primer design useless. We propose a method that uses a genetic algorithm (GA) to search for optimal mutagenic PCR-RFLP primers and employ the core of SNP-RFLPing to reliably mine available restriction enzymes. The in silico simulation of the proposed method in the SNPs of the SLC6A4 gene showed that it is capable of designing stable mismatch PCR-RFLP primers which fit the common primer constraints and that it can provide available restriction enzymes.	genetic algorithm;primer;rendering (computer graphics);snp array;simulation;software release life cycle	Cheng-Hong Yang;Yu-Huei Cheng;Li-Yeh Chuang;Hsueh-Wei Chang	2010	9th IEEE International Conference on Cognitive Informatics (ICCI'10)	10.1109/COGINF.2010.5599752	biology;molecular biology;molecular inversion probe;bioinformatics;snp genotyping;genetics	Visualization	0.5309194529924777	-54.37345668813305	111134
01949d4e131f37ca8b6a54409e2b9411dbac3c08	fundamental bounds for sequence reconstruction from nanopore sequencers	insertion deletion channel;random sequences;dna sequencing;sequential analysis nanobioscience dna biological system modeling chemical models random sequences;sticky channel;sticky channel channel models dna sequencing insertion deletion channel random sequences;channel models	Nanopore sequencers are emerging as promising new platforms for high-throughput sequencing. As with other technologies, sequencer errors pose a major challenge for their effective use. In this paper, we present a novel information theoretic analysis of the impact of insertion-deletion (indel) errors in nanopore sequencers. In particular, we consider the following problems: 1) for given indel error characteristics and rate, what is the probability of accurate reconstruction as a function of sequence length and 2) using replicated extrusion (the process of passing a DNA strand through the nanopore), what is the number of replicas needed to accurately reconstruct the true sequence with high probability? Our results provide a number of important insights: 1) the probability of accurate reconstruction of a sequence from a single sample in the presence of indel errors tends quickly (i.e., exponentially) to zero as the length of the sequence increases and 2) replicated extrusion is an effective technique for accurate reconstruction. We show that for typical distributions of indel errors, the required number of replicas is a slow function (polylogarithmic) of sequence length – implying that through replicated extrusion, we can sequence large reads using nanopore sequencers. Moreover, we show that in certain cases, the required number of replicas can be related to information-theoretic parameters of the indel error distributions.	arabic numeral 0;biopolymer sequencing;clinical act of insertion;deletion mutation;high-throughput computing;indel mutation;information theory;insertion mutation;microsequencer;polylogarithmic function;reading (activity);strand (programming language);throughput;with high probability	Abram Magner;Jaroslaw Duda;Wojciech Szpankowski;Ananth Y. Grama	2016	IEEE Transactions on Molecular, Biological and Multi-Scale Communications	10.1109/TMBMC.2016.2630056	biology;dna sequencing;bioinformatics;nanotechnology;genetics	Comp.	0.34045542872332685	-53.31707277363072	111147
590698a4edd4a3ae38a70ea1a1917912005b0775	graph sharpening plus graph integration: a synergy that improves protein functional classification	protein function;proteine;bioinformatique;classification;integration;grafo;integracion;graph;graphe;prediction accuracy;roc curve;proteina;bioinformatica;function prediction;classification accuracy;protein;similarity measure;clasificacion;plus integral;bioinformatics;gene ontology	MOTIVATION Predicting protein function is a central problem in bioinformatics, and many approaches use partially or fully automated methods based on various combination of sequence, structure and other information on proteins or genes. Such information establishes relationships between proteins that can be modelled most naturally as edges in graphs. A priori, however, it is often unclear which edges from which graph may contribute most to accurate predictions. For that reason, one established strategy is to integrate all available sources, or graphs as in graph integration, in the hope that the positive signals will add to each other. However, in the problem of functional prediction, noise, i.e. the presence of inaccurate or false edges, can still be large enough that integration alone has little effect on prediction accuracy. In order to reduce noise levels and to improve integration efficiency, we present here a recent method in graph-based learning, graph sharpening, which provides a theoretically firm yet intuitive and practical approach for disconnecting undesirable edges from protein similarity graphs. This approach has several attractive features: it is quick, scalable in the number of proteins, robust with respect to errors and tolerant of very diverse types of protein similarity measures.   RESULTS We tested the classification accuracy in a test set of 599 proteins with remote sequence homology spread over 20 Gene Ontology (GO) functional classes. When compared to integration alone, graph sharpening plus integration of four vastly different molecular similarity measures improved the overall classification by nearly 30% [0.17 average increase in the area under the ROC curve (AUC)]. Moreover, and partially through the increased sparsity of the graphs induced by sharpening, this gain in accuracy came at negligible computational cost: sharpening and integration took on average 4.66 (+/-4.44) CPU seconds.   AVAILABILITY Software and Supplementary data will be available on http://mammoth.bcm.tmc.edu/	algorithmic efficiency;analysis of algorithms;area under curve;blast;base excision repair;bioinformatics;cpu (central processing unit of computer system);cardiomyopathies;categories;central processing unit;chemical similarity;class;computation;cross reactions;cross-validation (statistics);dna integration;futures studies;gene ontology;graph (discrete mathematics);graph - visual representation;homologous gene;hypothalamic area, lateral;ibm notes;machine learning;mathematical optimization;mike lesser;mod database;motif;nephrogenic systemic fibrosis;pervasive informatics;programming tool;protein domain;protein function prediction;protein structure prediction;protein, organized by function;receiver operator characteristics;receiver operating characteristic;refinement (computing);scalability;sequence homology;sparse matrix;synergy;test set;united states national institutes of health;word lists by frequency	Hyunjung Shin;Andreas Martin Lisewski;Olivier Lichtarge	2007	Bioinformatics	10.1093/bioinformatics/btm511	null model;biological classification;computer science;bioinformatics;machine learning;data mining;mathematics;graph;receiver operating characteristic;statistics	Comp.	3.9929473617662725	-55.30397453728664	111160
38082360fe036ee48578065df97851e07c402f6e	configurable pattern-based evolutionary biclustering of gene expression data	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;physiological cellular and medical topics;computational biology bioinformatics;uk phd theses thesis;life sciences;algorithms;uk research reports;medical journals;europe pmc;biomedical research;bioinformatics	Biclustering algorithms for microarray data aim at discovering functionally related gene sets under different subsets of experimental conditions. Due to the problem complexity and the characteristics of microarray datasets, heuristic searches are usually used instead of exhaustive algorithms. Also, the comparison among different techniques is still a challenge. The obtained results vary in relevant features such as the number of genes or conditions, which makes it difficult to carry out a fair comparison. Moreover, existing approaches do not allow the user to specify any preferences on these properties. Here, we present the first biclustering algorithm in which it is possible to particularize several biclusters features in terms of different objectives. This can be done by tuning the specified features in the algorithm or also by incorporating new objectives into the search. Furthermore, our approach bases the bicluster evaluation in the use of expression patterns, being able to recognize both shifting and scaling patterns either simultaneously or not. Evolutionary computation has been chosen as the search strategy, naming thus our proposal Evo-Bexpa (Evo lutionary B iclustering based in Ex pression Pa tterns). We have conducted experiments on both synthetic and real datasets demonstrating Evo-Bexpa abilities to obtain meaningful biclusters. Synthetic experiments have been designed in order to compare Evo-Bexpa performance with other approaches when looking for perfect patterns. Experiments with four different real datasets also confirm the proper performing of our algorithm, whose results have been biologically validated through Gene Ontology.	algorithm;base;biclustering;compaq evo;evolutionary computation;experiment;gene expression;gene ontology;heuristic;image scaling;microarray;synthetic intelligence	Beatriz Pontes;Raúl Giráldez;Jesús S. Aguilar-Ruiz	2012		10.1186/1748-7188-8-4	biology;medical research;computer science;bioinformatics;data science;data mining	ML	5.024638477301213	-54.59370457509008	111400
8e0d9295e466426a7b63acb7b284eaceb1a7ce44	mirna arm selection and isomir distribution in gastric cancer	stomach neoplasms;high throughput nucleotide sequencing;animal genetics and genomics;life sciences general;humans;microbial genetics and genomics;proteomics;base sequence;micrornas;gene expression profiling;microarrays;plant genetics genomics	MicroRNAs (miRNAs) are small non-protein-coding RNAs. miRNA genes need several biogenesis steps to form function miRNAs. However, the precise mechanism and biology involved in the mature miRNA molecules are not clearly investigated. In this study, we conducted in-depth analyses to examine the arm selection and isomiRs using NGS platform. We sequenced small RNAs from one pair of normal and gastric tumor tissues with Solexa platform. By analyzing the NGS data, we quantified the expression profiles of miRNAs and isomiRs in gastric tissues. Then, we measured the expression ratios of 5p arm to 3p arm of the same pre-miRNAs. And, we used Kolmogorov-Smirnov (KS) test to examine isomiR pattern difference between tissues. Our result showed the 5p arm and 3p arm miRNA derived from the same pre-miRNAs have different tissue expression preference, one preferred normal tissue and the other preferred tumor tissue, which strongly implied that there could be other mechanism controlling mature miRNA selection in addition to the known hydrogen-bonding selection rule. Furthermore, by using the KS test, we demonstrated that some isomiR types preferentially occur in normal gastric tissue but other types prefer tumor gastric tissue. Arm selections and isomiR patterns are significantly varied in human cancers by using deep sequencing NGS data. Our results provided a novel research topic in miRNA regulation study. With advanced bioinformatics and molecular biology studies, more robust conclusions and insight into miRNA regulation can be achieved in the near future.	bioinformatics;body tissue;chromosome 3 short arm;communications satellite;deep sequencing;gastric tissue;hydrogen;kolmogorov complexity;kolmogorov-smirnov test;malignant neoplasms;maxillary right first premolar prosthesis;micrornas;molecular biology;pyschological bonding;selection rule;stomach carcinoma;stomach neoplasms;windows legacy audio components;tumor tissue	Sung-Chou Li;Yu-Lun Liao;Meng-Ru Ho;Kuo-Wang Tsai;Chun-Hung Lai;Wen-chang Lin	2012		10.1186/1471-2164-13-S1-S13	biology;molecular biology;dna microarray;bioinformatics;gene expression profiling;proteomics;genetics;microrna	Comp.	6.9957255113039345	-61.685508355978236	111475
1babfec84c210e69fff1e0fe979408821c24a782	using machine learning to design and interpret gene-expression microarrays	treatment planning;microarray data;new technology;chip;gene expression;biological activity;drug design;machine learning	gene chips, make it possible to simultaneously measure the rate at which a cell or tissue is expressing—translating into a protein—each of its thousands of genes. One can use these comprehensive snapshots of biological activity to infer regulatory pathways in cells; identify novel targets for drug design; and improve the diagnosis, prognosis, and treatment planning for those suffering from disease. However, the amount of data this new technology produces is more than one can manually analyze. Hence, the need for automated analysis of microarray data offers an opportunity for machine learning to have a significant impact on biology and medicine. This article describes microarray technology, the data it produces, and the types of machine learning tasks that naturally arise with these data. It also reviews some of the recent prominent applications of machine learning to gene-chip data, points to related tasks where machine learning might have a further impact on biology and medicine, and describes additional types of interesting data that recent advances in biotechnology allow biomedical researchers to collect.	dna microarray;gene expression profiling;machine learning	Michael Molla;Michael Waddell;David Page;Jude W. Shavlik	2004	AI Magazine		chip;microarray analysis techniques;gene expression;computer science;bioinformatics;data science;biological activity;data mining;drug design	ML	4.033075520661898	-56.37644797282313	111584
1232d498d1ecd2d85f644a9c99808ab90049afb2	complementing computationally predicted regulatory sites in tractor_db using a pattern matching approach	gamma-proteobacterial regulons;comparative genomics;transcriptional regulatory networks;statistical model;pattern matching;binding site;regulon;genome annotation;escherichia coli	Prokaryotic genomes annotation has focused on genes location and function. The lack of regulatory information has limited the knowledge on cellular transcriptional regulatory networks. However, as more phylogenetically close genomes are sequenced and annotated, the implementation of phylogenetic footprinting strategies for the recognition of regulators and their regulons becomes more important. In this paper we describe a comparative genomics approach to the prediction of new gamma-proteobacterial regulon members. We take advantage of the phylogenetic proximity of Escherichia coli and other 16 organisms of this subdivision and the intensive search of the space sequence provided by a pattern-matching strategy. Using this approach we complement predictions of regulatory sites made using statistical models currently stored in Tractor_DB, and increase the number of transcriptional regulators with predicted binding sites up to 86. All these computational predictions may be reached at Tractor_DB (www.bioinfo.cu/Tractor_DB, www.tractor.lncc.br, www.ccg.unam.mx/Computational_Genomics/tractorDB/). We also take a first step in this paper towards the assessment of the conservation of the architecture of the regulatory network in the gamma-proteobacteria through evaluating the conservation of the overall connectivity of the network.	annotation;binding sites;complement system proteins;gene regulatory network;genome;interferon type ii;pattern matching;phylogenetic footprinting;phylogenetics;proteobacteria;regulon;statistical model;subdivision surface;transcription, genetic	Marylens Hernández Guía;Abel González Pérez;Vladimir Espinosa Angarica;Ana Tereza Ribeiro de Vasconcelos;Julio Collado-Vides	2004	In silico biology		bioinformatics;genetics;architecture;phylogenetic tree;gene;genome project;phylogenetic footprinting;computational genomics;biology;regulon;comparative genomics	Comp.	2.2605969727180075	-58.48253014201612	111680
bce412834892366974be0c837540a9091a6bb230	identification of novel phosphodiesterase-4d inhibitors prescreened by molecular dynamics-augmented modeling and validated by bioassay	journal	Phosphodiesterase-4D (PDE4D) has been proved to be a potential therapeutic target against strokes. In the present study, a procedure of integrating pharmacophore, molecular docking, molecular dynamics (MD) simulations, binding free energy calculations, and finally validation with bioassay was developed and described to search for novel PDE4D inhibitors from the SPECS database. Among the 29 compounds selected by our MD-augmented strategy, 15 hits were found with IC50 between 1.9 and 50 μM (a hit rate of 52%) and 6 potent hits showed IC50 less than 10 μM, which suggested that MD simulations can explore the intermolecular interactions of PDE4D-inhibitor complexes more precisely and thus significantly enhanced the hit rate of this screening. The effective and efficient integrated procedures described in this study could be readily applied to screening studies toward other drug targets.	biological assay;cerebrovascular accident;docking (molecular);docking -molecular interaction;drug delivery systems;inhibitory concentration 50;molecular dynamics;pharmacophore;simulation;therapeutic targets database;thrombocytopenia;free energy	Zhe Li;Ying-Hong Cai;Yuen-Kit Cheng;Xiao Lu;Yong-Xian Shao;Xingshu Li;Peiqing Liu;Hai-Bin Luo	2013	Journal of chemical information and modeling	10.1021/ci400063s	chemistry;toxicology;bioinformatics;combinatorial chemistry	Visualization	9.525305742652991	-60.6042483035025	111704
56454ffb97007771fd9a8dbb7bb7965734fdbcc9	structural analysis of in silico mutant experiments of human inner-kinetochore structure	bond mutation;rule based;simulation;inner kinetochore structure;structural analysis;modeling	Large multi-molecular complexes like the kinetochore are lacking of suitable methods to determine their spatial structure. Here, we use and evaluate a novel modeling approach that combines rule-bases reaction network models with spatial molecular geometries. In particular, we introduce a method that allows to study in silico the influence of single interactions (e.g. bonds) on the spatial organization of large multi-molecular complexes and apply this method to an extended model of the human inner-kinetochore. Our computational analysis method encompasses determination of bond frequency, geometrical distances, statistical moments, and inter-dependencies between bonds using mutual information. For the analysis we have extend our previously reported human inner-kinetochore model by adding 13 new protein interactions and three protein geometry details. The model is validated by comparing the results of in silico with reported in vitro single protein deletion experiments. Our studies revealed that most simulations mimic the in vitro behavior of the kinetochore complex as expected. To identify the most important bonds in this model, we have created 39 mutants in silico by selectively disabling single protein interactions. In a total of 11,800 simulation runs we have compared the resulting structures to the wild-type. In particular, this allowed us to identify the interaction Cenp-W-H3 and Cenp-S-Cenp-X as having the strongest influence on the inner-kinetochore's structure. We conclude that our approach can become a useful tool for the in silico dynamical study of large, multi-molecular complexes.		Richard Henze;Jan Huwald;Nelly Mostajo;Peter Dittrich;Bashar Ibrahim	2015	Bio Systems	10.1016/j.biosystems.2014.11.004	rule-based system;biology;systems modeling;bioinformatics;structural analysis	Comp.	9.130147783653166	-60.54702339857678	111719
225d2f25e8d092ae4e397373a356be8e254a082d	gene regulation, protein networks and disease: a computational perspective	disease understanding;complex disease;disease-related data analysis;akshay krishnamurthy;chaim linhart;gene regulation;gideon dror;annelyse thevenin;integrated analysis;igor ulitsky;protein network;utilizing expression profile;computational perspective	Understanding complex disease is one of today's grand challenges. In spite of the rapid advance of biotechnology, disease understanding is still very limited and further computational tools for disease-related data analysis are in dire need. In this talk I will describe some of the approaches that we are developing for these challenges. I will describe methods for utilizing expression profiles of sick and healthy individuals to identify pathways dysregulated in the disease, methods for integrated analysis for expression and protein interactions, and methods for regulatory motif discovery. If time allows, I'll discuss methods for analysis of genome aberrations in cancer. The utility of the methods will be demonstrated on biological examples.#R##N##R##N#Joint work with Igor Ulitsky, Ofer Lavi, Yaron Orenstein, Richard M. Karp, Gideon Dror, Akshay Krishnamurthy, Michal Ozery-Flato, Chaim Linhart, Luba Trakhtenbrot, Shai Izraeli, Annelyse Thevenin and Liat Ein-Dor.	computation	Ron Shamir	2012		10.1007/978-3-642-31265-6_1	bioinformatics;genetics	ML	4.271966586245352	-58.62218869873835	111742
4ad587d72169830d53f06269c66e2944623b4105	cross-platform integration of transcriptomics data		An increasing number of studies have profiled gene expressions in tumor specimens using distinct microarray platforms and analysis techniques. With the accumulating amount of microarray data, one of the most challenging tasks is to develop robust statistical models to integrate the findings. This article reviews some recent studies on the field. We also study the intensity similarities between data sets derived from various platforms, after appropriate rescaling of the measurements. We found that intensity and fold-change variability similarities between different platform measurements can assist the analysis of independent data sets and can produce comparable results with those obtained for the independent data set alone.	categorization;mandelbrot set;microarray;resampling (statistics);sampling (signal processing);spatial variability;statistical model	Georgia Tsiliki;Marina Ioannou;Dimitris Kafetzopoulos	2009			data mining;microarray analysis techniques;transcriptome;statistical model;cross-platform;data set;gene chip analysis;microarray;computer science;bioinformatics	ML	5.286117537102702	-52.43302573581445	111839
77a1c3e9e30b957a3499bba5394c00d90377ae72	a predictive model of the oxygen and heme regulatory network in yeast	integrated approach;machine learning algorithms;up regulation;experimental analysis;regulatory network;saccharomyces cerevisiae;databases nucleic acid;gene regulation;oxygen;gene regulatory networks;transcription factor binding site;transcription factors;models biological;chip;gene expression;down regulation;machine learning;transcription factor;heme;hot temperature;differential expression;sequence motif analysis;algorithms;prediction model;high throughput;computational biology;mrna expression;multigene family;gene expression profiling;regulator genes	Deciphering gene regulatory mechanisms through the analysis of high-throughput expression data is a challenging computational problem. Previous computational studies have used large expression datasets in order to resolve fine patterns of coexpression, producing clusters or modules of potentially coregulated genes. These methods typically examine promoter sequence information, such as DNA motifs or transcription factor occupancy data, in a separate step after clustering. We needed an alternative and more integrative approach to study the oxygen regulatory network in Saccharomyces cerevisiae using a small dataset of perturbation experiments. Mechanisms of oxygen sensing and regulation underlie many physiological and pathological processes, and only a handful of oxygen regulators have been identified in previous studies. We used a new machine learning algorithm called MEDUSA to uncover detailed information about the oxygen regulatory network using genome-wide expression changes in response to perturbations in the levels of oxygen, heme, Hap1, and Co2+. MEDUSA integrates mRNA expression, promoter sequence, and ChIP-chip occupancy data to learn a model that accurately predicts the differential expression of target genes in held-out data. We used a novel margin-based score to extract significant condition-specific regulators and assemble a global map of the oxygen sensing and regulatory network. This network includes both known oxygen and heme regulators, such as Hap1, Mga2, Hap4, and Upc2, as well as many new candidate regulators. MEDUSA also identified many DNA motifs that are consistent with previous experimentally identified transcription factor binding sites. Because MEDUSA's regulatory program associates regulators to target genes through their promoter sequences, we directly tested the predicted regulators for OLE1, a gene specifically induced under hypoxia, by experimental analysis of the activity of its promoter. In each case, deletion of the candidate regulator resulted in the predicted effect on promoter activity, confirming that several novel regulators identified by MEDUSA are indeed involved in oxygen regulation. MEDUSA can reveal important information from a small dataset and generate testable hypotheses for further experimental analysis. Supplemental data are included.	apex1 protein, human;aquaporin 1;binding sites;carbon dioxide;chip-on-chip;cluster analysis;computational problem;cyanea capillata preparation;deletion mutation;experiment;genes, vif;heme;high-throughput computing;hypoxia;medusa4;machine learning;metal gear acid 2;oxygen;pathologic processes;quorum sensing;silo (dataset);transcription factor;throughput;transcription (software);algorithm;statistical cluster	Anshul Kundaje;Xiantong Xin;Changgui Lan;Steve Lianoglou;Mei Zhou;Li Zhang;Christina S. Leslie	2008	PLoS Computational Biology	10.1371/journal.pcbi.1000224	biology;molecular biology;bioinformatics;downregulation and upregulation;genetics;transcription factor	Comp.	4.942646368184439	-58.85931591986847	111860
99a189a17fc666cd1b7f5c93616fce4cf54de5fc	discovery of gene-regulation pathways using local causal search	bayes theorem;algorithms	This paper reports the methods and results of a computer-based algorithm that takes as input the expression levels of a set of genes as given by DNA microarray data, and then searches for causal pathways that represent how the genes regulate each other. The algorithm uses local heuristic search and a Bayesian scoring metric. We applied the algorithm to induce causal networks from a mixture of observational and experimental gene-expression data on genes involved in galactose metabolism in the yeast Saccharomyces cerevisiae. The observational data consisted of gene-expression levels obtained from unmanipulated inverted exclamation mark degrees wild-type inverted exclamation mark +/- cells. The experimental data were produced by deleting ( inverted exclamation mark degrees knocking out inverted exclamation mark +/-) genes and measuring the expression levels of other genes. We used this data to evaluate several variations of the local search method. In each evaluation, causal relationships were predicted for all 36 pairwise combinations of nine key galactose-related genes. These predictions were then compared to the known causal relationships among these genes.	algorithm;causal filter;causality;dna microarray format;galactose metabolism pathway;heuristic;heuristics;local search (optimization);port knocking;saccharomyces cerevisiae;score	Changwon Yoo;Gregory F. Cooper	2002	Proceedings. AMIA Symposium		dna microarray;regulation of gene expression;gene;local search (optimization);bayes' theorem;genetics;pairwise comparison;exclamation mark;bayesian probability;biology	Comp.	5.944611146140779	-54.95160043774039	111884
abc4da4a0cf5db2f889f50158b2b0ab8ac260d89	the impact of gene expression analysis on the classification and prediction of patients' medical conditions	gene expression analysis	Proper analysis and validation of gene expression data is not a trivial task. Most of the existing approaches identify individual or group of markers/signatures where the validation only goes as far as literature and biological experimental validation. In this paper we discuss a framework that could be considered to develop and validate patterns from gene expression data and work towards future clinical test kits.	antivirus software;cross-validation (statistics);test case	Fazel Famili;Sieu Phan;Ziying Liu;Youlian Pan	2010			gene expression;cancer research;biology	Comp.	7.334747014843113	-53.980856336781805	111940
ecad4837f4bc306f173456aafecd9d6b67b62744	regulation of erk-mapk signaling in human epidermis	simulation and modeling;systems biology;phosphorylation;mitogen activated protein kinases;physiological cellular and medical topics;map kinase signaling system;computational biology bioinformatics;epidermis;extracellular signal regulated map kinases;keratinocytes;algorithms;humans;bioinformatics	The skin is largely comprised of keratinocytes within the interfollicular epidermis. Over approximately two weeks these cells differentiate and traverse the thickness of the skin. The stage of differentiation is therefore reflected in the positions of cells within the tissue, providing a convenient axis along which to study the signaling events that occur in situ during keratinocyte terminal differentiation, over this extended two-week timescale. The canonical ERK-MAPK signaling cascade (Raf-1, MEK-1/2 and ERK-1/2) has been implicated in controlling diverse cellular behaviors, including proliferation and differentiation. While the molecular interactions involved in signal transduction through this cascade have been well characterized in cell culture experiments, our understanding of how this sequence of events unfolds to determine cell fate within a homeostatic tissue environment has not been fully characterized. We measured the abundance of total and phosphorylated ERK-MAPK signaling proteins within interfollicular keratinocytes in transverse cross-sections of human epidermis using immunofluorescence microscopy. To investigate these data we developed a mathematical model of the signaling cascade using a normalized-Hill differential equation formalism. These data show coordinated variation in the abundance of phosphorylated ERK-MAPK components across the epidermis. Statistical analysis of these data shows that associations between phosphorylated ERK-MAPK components which correspond to canonical molecular interactions are dependent upon spatial position within the epidermis. The model demonstrates that the spatial profile of activation for ERK-MAPK signaling components across the epidermis may be maintained in a cell-autonomous fashion by an underlying spatial gradient in calcium signaling. Our data demonstrate an extended phospho-protein profile of ERK-MAPK signaling cascade components across the epidermis in situ, and statistical associations in these data indicate canonical ERK-MAPK interactions underlie this spatial profile of ERK-MAPK activation. Using mathematical modelling we have demonstrated that spatially varying calcium signaling components across the epidermis may be sufficient to maintain the spatial profile of ERK-MAPK signaling cascade components in a cell-autonomous manner. These findings may have significant implications for the wide range of cancer drugs which therapeutically target ERK-MAPK signaling components.	apache axis;autonomous robot;behavior;calcium signaling;cascade device component;cell culture techniques;cell signaling;epidermis;experiment;fluorescent antibody technique;gradient;homeostasis;interaction;mathematical model;mathematics;mental association;semantics (computer science);signal transduction;traverse;thickness (graph theory);transduction (machine learning);transverse wave;keratinocyte	Joseph Cursons;Jerry Zeyu Gao;Daniel G. Hurley;Cristin G. Print;P. Dunbar;Marc Jacobs;Edmund J. Crampin	2015		10.1186/s12918-015-0187-6	phosphorylation;biology;cell biology;bioinformatics;epidermis;systems biology	ML	8.483186475442984	-65.56814100654638	112002
6a3224e39b62782507886a17e5a0ebcf82b178b9	phylogenetic reconstruction from arbitrary gene-order data	dna;analytical models;biology computing;genomics;sequences;phylogeny bioinformatics genomics computational modeling analytical models dna sequences biology biological cells computer science;phylogeny;neighbor joining phylogenetic reconstruction arbitrary gene order data grappa arbitrary genomes median chloroplast genomes;phylogenetic reconstruction;biology;trees mathematics;genetics;computational modeling;biological cells;chloroplast genome;computational complexity;arbitrary gene order data;gene order;chloroplast genomes;neighbor joining;computer science;computational complexity biology computing genetics trees mathematics;arbitrary genomes median;grappa;bioinformatics	Phylogenetic reconstruction from gene-order data has attracted attention from both biologists and computer scientists over the last few years. So far, our software suite GRAPPA is the most accurate approach, but it requires that all genomes have identical gene content, with each gene appearing exactly once in each genome. Some progress has been made in handling genomes with unequal gene content, both in terms of computing pair-wise genomic distances and in terms of reconstruction. In this paper, we present a new approach for computing the median of three arbitrary genomes and apply it to the reconstruction of phylogenies from arbitrary gene-order data. We implemented these methods within GRAPPA and tested them on simulated datasets under various conditions as well as on a real dataset of chloroplast genomes; we report the results of our simulations and our analysis of the real dataset and compare them to reconstructions made by using neighbor-joining and using the original GRAPPA on the same genomes with equalized gene contents. Our new approach is remarkably accurate both in simulations and on the real dataset, in contrast to the distance-based approaches and to reconstructions using the original GRAPPA applied to equalized gene contents.	computer scientist;neighbor joining;phylogenetics;simulation;software suite	Jijun Tang;Bernard M. E. Moret;Liying Cui;Claude W. dePamphilis	2004	Proceedings. Fourth IEEE Symposium on Bioinformatics and Bioengineering	10.1109/BIBE.2004.1317396	biology;genomics;computer science;bioinformatics;sequence;neighbor joining;computational complexity theory;computational model;genetics;dna	Comp.	0.8082445044537204	-52.487822313990584	112076
0861bfc6078da63366cd88629a5a6a5fe72db9c9	on application of directons to functional classification of genes in prokaryotes	high resolution;prokaryotes;sequence similarity;genome analysis;genomic neighborhood;gene function;functional classification of genes	Functional classification of genes represents one of the most basic problems in genome analysis and annotation. Our analysis of some of the popular methods for functional classification of genes shows that these methods are not always consistent with each other and may not be specific enough for high-resolution gene functional annotations. We have developed a method to integrate genomic neighborhood information of genes with their sequence similarity information for the functional classification of prokaryotic genes. The application of our method to 93 proteobacterial genomes has shown that (i) the genomic neighborhoods are much more conserved across prokaryotic genomes than expected by chance, and such conservation can be utilized to improve functional classification of genes; (ii) while our method is consistent with the existing popular schemes as much as they are among themselves, it does provide functional classification at higher resolution and hence allows functional assignments of (new) genes at a more specific level; and (iii) our method is fairly stable when being applied to different genomes.		Hongwei Wu;Fenglou Mao;Victor Olman;Ying Xu	2008	Computational biology and chemistry	10.1016/j.compbiolchem.2008.02.007	biology;image resolution;computer science;bioinformatics;genetics	Comp.	2.8112217918715414	-59.04042801196423	112234
69c3b5ba1131cd6f258922c1f37c06b41701230b	automated quantmap for rapid quantitative molecular network topology analysis	software;bioinformatics and systems biology;bioinformatik och systembiologi;bioinformatik;pharmaceutical preparations;protein interaction mapping;databases chemical;bioinformatics	SUMMARY The previously disclosed QuantMap method for grouping chemicals by biological activity used online services for much of the data gathering and some of the numerical analysis. The present work attempts to streamline this process by using local copies of the databases and in-house analysis. Using computational methods similar or identical to those used in the previous work, a qualitatively equivalent result was found in just a few seconds on the same dataset (collection of 18 drugs). We use the user-friendly Galaxy framework to enable users to analyze their own datasets. Hopefully, this will make the QuantMap method more practical and accessible and help achieve its goals to provide substantial assistance to drug repositioning, pharmacology evaluation and toxicology risk assessment.   AVAILABILITY http://galaxy.predpharmtox.org   CONTACT mats.gustafsson@medsci.uu.se or ola.spjuth@farmbio.uu.se   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	adobe streamline;anatomy, regional;bioinformatics;computation;copy (object);e-services;network topology;numerical analysis;pharmacology;published database;risk assessment;usability	Wesley Schaal;Ulf Hammerling;Mats G. Gustafsson;Ola Spjuth	2013		10.1093/bioinformatics/btt390	biology;computer science;bioinformatics;data science;data mining	Comp.	-0.8712417577677879	-60.93478599581595	112276
aebf0fc74c4a5f1cf901a40a32881b91e07cebec	cipro 2.5: ciona intestinalis protein database, a unique integrated repository of large-scale omics data, bioinformatic analyses and curated annotation, with user rating and reviewing functionality	genes;community;animals;genomics;urochordata;proteome;computer graphics;amino acid sequence;molecular sequence annotation;developmental stages;gene expression;genome;user computer interface;proteomics;ciona intestinalis;computational biology;systems integration;ciprofloxacin;gene expression profiling;databases protein;bioinformatics	The Ciona intestinalis protein database (CIPRO) is an integrated protein database for the tunicate species C. intestinalis. The database is unique in two respects: first, because of its phylogenetic position, Ciona is suitable model for understanding vertebrate evolution; and second, the database includes original large-scale transcriptomic and proteomic data. Ciona intestinalis has also been a favorite of developmental biologists. Therefore, large amounts of data exist on its development and morphology, along with a recent genome sequence and gene expression data. The CIPRO database is aimed at collecting those published data as well as providing unique information from unpublished experimental data, such as 3D expression profiling, 2D-PAGE and mass spectrometry-based large-scale analyses at various developmental stages, curated annotation data and various bioinformatic data, to facilitate research in diverse areas, including developmental, comparative and evolutionary biology. For medical and evolutionary research, homologs in humans and major model organisms are intentionally included. The current database is based on a recently developed KH model containing 36,034 unique sequences, but for higher usability it covers 89,683 all known and predicted proteins from all gene models for this species. Of these sequences, more than 10,000 proteins have been manually annotated. Furthermore, to establish a community-supported protein database, these annotations are open to evaluation by users through the CIPRO website. CIPRO 2.5 is freely accessible at http://cipro.ibio.jp/2.5.	annotation;bio-informatics;bioinformatics;ciona intestinalis protein database;databases, protein;galaxy morphological classification;gene expression profiling;greater than;homology (biology);molecular profiling;omics;phylogenetics;polyacrylamide gel electrophoresis;proteomics;review [publication type];scientific publication;sequence database;spectrometry;urochordata;usability;web site	Toshinori Endo;Keisuke Ueno;Kouki Yonezawa;Katsuhiko Mineta;Kohji Hotta;Yutaka Satou;Lixy Yamada;Michio Ogasawara;Hiroki Takahashi;Ayako Nakajima;Mia Nakachi;Mamoru Nomura;Junko Yaguchi;Yasunori Sasakura;Chisato Yamasaki;Miho Sera;Akiyasu C. Yoshizawa;Tadashi Imanishi;Hisaaki Taniguchi;Kazuo Inaba	2011		10.1093/nar/gkq1144	biology;community;genomics;gene expression;developmental stage theories;bioinformatics;gene;proteome;peptide sequence;gene expression profiling;proteomics;computer graphics;genetics;genome;system integration	Comp.	-1.3213736177195217	-60.27368328496124	112373
56205846f36eb8298d28fe3bb2fbf4b1506ce8ca	estimating time of infection using prior serological and individual information can greatly improve incidence estimation of human and wildlife infections	cytomegalovirus infection;excretion;blood;entropy;biomarkers;wildlife;antibodies;pathogens	Diseases of humans and wildlife are typically tracked and studied through incidence, the number of new infections per time unit. Estimating incidence is not without difficulties, as asymptomatic infections, low sampling intervals and low sample sizes can introduce large estimation errors. After infection, biomarkers such as antibodies or pathogens often change predictably over time, and this temporal pattern can contain information about the time since infection that could improve incidence estimation. Antibody level and avidity have been used to estimate time since infection and to recreate incidence, but the errors on these estimates using currently existing methods are generally large. Using a semi-parametric model in a Bayesian framework, we introduce a method that allows the use of multiple sources of information (such as antibody level, pathogen presence in different organs, individual age, season) for estimating individual time since infection. When sufficient background data are available, this method can greatly improve incidence estimation, which we show using arenavirus infection in multimammate mice as a test case. The method performs well, especially compared to the situation in which seroconversion events between sampling sessions are the main data source. The possibility to implement several sources of information allows the use of data that are in many cases already available, which means that existing incidence data can be improved without the need for additional sampling efforts or laboratory assays.	asymptomatic infections;basal ganglia diseases;biological markers;burn-in;column (database);computation;computational biology;cytology;emoticon;empty string;encapsulated postscript;estimated;estimation theory;excretory function;experiment;horseland;ibm pcjr;incidence matrix;infection;infections, arenavirus;integrated circuit layout design protection;matlab;nethack;organ;parametric model;pathogenic organism;population;probability;sample size;sampling (signal processing);sampling - surgical action;semiconductor industry;semiparametric model;seroconversion;simulation;teh;test case;unique identifier;unique key;xfig;zip code	Benny Borremans;Niel Hens;Philippe Beutels;Herwig Leirs;Jonas Reijniers	2016		10.1371/journal.pcbi.1004882	biology;biochemistry;entropy;wildlife;virology;excretion;antibody;immunology;biomarker	ML	2.963422410417957	-52.224818697667374	112421
6964cdc448c6e13aee4a51c588e70c2d8c2a4139	structural alignment of pseudoknotted rna	structure alignment	In this paper, we address the problem of discovering novel non-coding RNA (ncRNA) using primary sequence, and secondary structure conservation, focusing on ncRNA families with pseudoknotted structures. Our main technical result is an efficient algorithm for computing an optimum structural alignment of an RNA sequence against a genomic substring. This algorithm has two applications. First, by scanning a genome, we can identify novel (homologous) pseudoknotted ncRNA, and second, we can infer the secondary structure of the target aligned sequence. We test an implementation of our algorithm (PAL) and show that it has near-perfect behavior for predicting the structure of many known pseudoknots. Additionally, it can detect the true homologs with high sensitivity and specificity in controlled tests. We also use PAL to search entire viral genome and mouse genome for novel homologs of some viral and eukaryotic pseudoknots, respectively. In each case, we have found strong support for novel homologs.	alignment;computation (action);homology (biology);inference;pal;rna;rna, untranslated;sensitivity and specificity;substring;algorithm;non-t, non-b childhood acute lymphoblastic leukemia	Buhm Han;Banu Dost;Vineet Bafna;Shaojie Zhang	2008	Journal of computational biology : a journal of computational molecular cell biology	10.1089/cmb.2007.0214	biology;structural alignment;computer science;bioinformatics	Comp.	2.8413533233722603	-60.75516878060247	112659
169f1926928de0bb79d7156a1aadb21888ff4c04	automated selection of differentially methylated regions in microarray data	dna;biology computing;dna biological cells probes arrays blood genomics bioinformatics;genetics;medical disorders;data analysis;gff differentially methylated region selection microarray data methylation enrichment methylation depletion tissues dmr biomarkers noninvasive prenatal diagnosis aneuploidies trisomy 21 methylation status mask and shift and methodology bit operations masking microarray dataset general feature format methylated dna immunoprecipitation arrays chromosome 13 chromosome 18 chromosome 21 linux windows systems sourceforge ms and;lab on a chip;cellular biophysics;medical disorders biology computing cellular biophysics data analysis dna genetics lab on a chip	Differentially methylated regions (DMRs) are segments or islands of consecutive sequence positions, showing methylation enrichment or depletion compared to each other in different samples or tissues. The identification of DMRs is a crucial first step in the discovery of biomarkers for noninvasive prenatal diagnosis of aneuploidies such as Trisomy 21. In this paper we describe an algorithm to automatically identify the manifestation of DMRs on arrays. Our approach, methylation status mask AND (MS-AND), influenced by the SHIFT-AND methodology, uses bit operations and masking and can be applied to any microarray dataset in General Feature Format (GFF). We show the effectiveness and utilization of our algorithm using data from Methylated DNA Immunoprecipitation arrays for the identification of DMRs in chromosomes 13, 18 and 21. The algorithm runs on Linux and on Windows systems and an implementation is available at sourceforge (http://sourceforge.net/projects/ms-and).	algorithm;algorithmic efficiency;analysis of algorithms;computational complexity theory;depletion region;gene ontology term enrichment;general feature format;linux;machine learning;microarray;microsoft windows;sourceforge;time complexity	Pavlos Antoniou;Spiros Michalakopoulos;Elisavet A. Papageorgiou;Philippos C. Patsalis;Carolina Sismani	2013	13th IEEE International Conference on BioInformatics and BioEngineering	10.1109/BIBE.2013.6701643	biology;molecular biology;lab-on-a-chip;bioinformatics;data analysis;genetics;dna	Visualization	1.4527016682688991	-63.06647987048418	112710
7c5f3c63bb606d7089b5aca25a28fc90e4f83536	short emboss user guide			emboss	Lisa J. Mullan;Alan J. Bleasby	2002	Briefings in Bioinformatics	10.1093/bib/3.1.92	bioinformatics;biology	PL	1.1411776301677	-64.05065995731727	112739
9b67cd25e0d166401817de5b63f048a4f6b1be3f	prioritization of disease micrornas through a human phenome-micrornaome network	breast neoplasms;female;simulation and modeling;human disease;disease;systems biology;computer model;physiological cellular and medical topics;models biological;computational biology bioinformatics;genetic predisposition to disease;reproducibility of results;roc curve;algorithms;humans;computer analysis;computational biology;phenotype;micrornas;microrna;bioinformatics	The identification of disease-related microRNAs is vital for understanding the pathogenesis of diseases at the molecular level, and is critical for designing specific molecular tools for diagnosis, treatment and prevention. Experimental identification of disease-related microRNAs poses considerable difficulties. Computational analysis of microRNA-disease associations is an important complementary means for prioritizing microRNAs for further experimental examination. Herein, we devised a computational model to infer potential microRNA-disease associations by prioritizing the entire human microRNAome for diseases of interest. We tested the model on 270 known experimentally verified microRNA-disease associations and achieved an area under the ROC curve of 75.80%. Moreover, we demonstrated that the model is applicable to diseases with which no known microRNAs are associated. The microRNAome-wide prioritization of microRNAs for 1,599 disease phenotypes is publicly released to facilitate future identification of disease-related microRNAs. We presented a network-based approach that can infer potential microRNA-disease associations and drive testable hypotheses for the experimental efforts to identify the roles of microRNAs in human diseases.	computation;computational model;experiment;inference;mental association;micrornas;parkinson disease;phenome;phenotype;receiver operating characteristic;receptor operated channel	Qinghua Jiang;Yangyang Hao;Guohua Wang;Liran Juan;Tianjiao Zhang;Mingxiang Teng;Yunlong Liu;Yadong Wang	2010		10.1186/1752-0509-4-S1-S2	biology;bioinformatics;genetics;systems biology;microrna	Comp.	7.319992041185328	-60.18296829294349	112795
31ae2c605acf2ed92a1c57e099a85cd774d5f8b6	iwtomics: testing high-resolution sequence-based 'omics' data at multiple locations and scales		Summary With increased generation of high-resolution sequence-based 'Omics' data, detecting statistically significant effects at different genomic locations and scales has become key to addressing several scientific questions. IWTomics is an R/Bioconductor package (integrated in Galaxy) that, exploiting sophisticated Functional Data Analysis techniques (i.e. statistical techniques that deal with the analysis of curves), allows users to pre-process, visualize and test these data at multiple locations and scales. The package provides a friendly, flexible and complete workflow that can be employed in many genomic and epigenomic applications.   Availability and implementation IWTomics is freely available at the Bioconductor website (http://bioconductor.org/packages/IWTomics) and on the main Galaxy instance (https://usegalaxy.org/).   Supplementary information Supplementary data are available at Bioinformatics online.	bioconductor;bioinformatics;epigenomics;functional data analysis;geographic information systems;image resolution;omics;preprocessor;sensor;web site	Marzia A. Cremona;Alessia Pini;Fabio Cumbo;Kateryna D. Makova;Francesca Chiaromonte;Simone Vantini	2018	Bioinformatics	10.1093/bioinformatics/bty090	computer science;omics;bioinformatics	Comp.	-2.5163100883108505	-57.98166877007785	112914
8ab483e5839c28c85903d531a63333bb01b1af4c	permol: restraint-based protein homology modeling using dyana or cns	use;modelizacion;estructura 3 dimensiones;proteine;540 chemie;structure secondaire;structure 3 dimensions;ddc 530;modelisation;utilisation;local structure;estructura secundaria;homology;secondary structure;uso;530 physik;homology modeling;angulo;proteina;estructura local;structure locale;three dimensional structure;protein;homologia;modeling;angle;homologie	SUMMARY PERMOL is a new restraint-based program for homology modeling of proteins. Restraints are generated from the information contained in structures of homologous template proteins. Employing the restraints generated by PERMOL, three-dimensional structures are obtained using MD programs such as DYANA or CNS. In contrast to other programs PERMOL is mainly based on the use of dihedral angle information which is optimally suited to preserve the local secondary structure. The global arrangement of these elements is then facilitated by a small number of distance restraints. Using PERMOL homology, models of high quality are obtained. A key advantage of the proposed method is its flexibility, which allows the inclusion of data from other sources, such as experimental restraints and the use of modern molecular dynamics programs to calculate structures.   AVAILABILITY The software and a detailed manual are available free of charge (http://www.biologie.uni-regensburg.de/Biophysik/Kalbitzer/permol/permol.html)	cns;clinical use template;contain (action);display resolution;homology (biology);homology modeling;molecular dynamics;physical restraint equipment (device)	Andreas Möglich;Daniel Weinfurtner;Wolfram Gronwald;Till Maurer;Hans Robert Kalbitzer	2005	Bioinformatics	10.1093/bioinformatics/bti276	biology;homology;homology modeling;systems modeling;bioinformatics;mathematics;geometry;angle;protein secondary structure	Comp.	-4.148491124381466	-56.0312083202529	112938
6eca71bc06ecda2d06b5042d3e8651e200395d19	comprehensive large-scale assessment of intrinsic protein disorder		MOTIVATION Intrinsically disordered regions are key for the function of numerous proteins. Due to the difficulties in experimental disorder characterization, many computational predictors have been developed with various disorder flavors. Their performance is generally measured on small sets mainly from experimentally solved structures, e.g. Protein Data Bank (PDB) chains. MobiDB has only recently started to collect disorder annotations from multiple experimental structures.   RESULTS MobiDB annotates disorder for UniProt sequences, allowing us to conduct the first large-scale assessment of fast disorder predictors on 25 833 different sequences with X-ray crystallographic structures. In addition to a comprehensive ranking of predictors, this analysis produced the following interesting observations. (i) The predictors cluster according to their disorder definition, with a consensus giving more confidence. (ii) Previous assessments appear over-reliant on data annotated at the PDB chain level and performance is lower on entire UniProt sequences. (iii) Long disordered regions are harder to predict. (iv) Depending on the structural and functional types of the proteins, differences in prediction performance of up to 10% are observed.   AVAILABILITY The datasets are available from Web site at URL: http://mobidb.bio.unipd.it/lsd.   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	bioinformatics;evaluation procedure;experiment;protein data bank;url data type;uniprot	Ian Walsh;Manuel Giollo;Tomás Di Domenico;Carlo Ferrari;Olav Zimmermann;Silvio C. E. Tosatto	2015	Bioinformatics	10.1093/bioinformatics/btu625	simulation;computer science;bioinformatics;data mining	Comp.	2.7025721497830855	-56.116229185091335	113001
427889c789d02a4e8368e9ec695e7f3c238ad0ed	a method for the detection of meaningful and reproducible group signatures from gene expression profiles	drug discovery;data mining;gene expression analysis;bioinformatics	Gene expression microarrays are commonly used to detect the biological signature of a disease or to gain a better understanding of the underlying mechanism of how a group of drugs treat a specific disease. The outcome of such experiments, e.g. the signature, is a list of differentially expressed genes. Reproducibility across independent experiments remains a challenge. We are interested in creating a method that can detect the shared signature of a group of expression profiles, e.g. a group of samples from individuals with the same disease or a group of drugs that treat the same therapeutic indication. We have developed a novel Weighted Influence — Rank of Ranks (WIMRR) method, and we demonstrate its ability to produce both meaningful and reproducible group signatures.	electronic signature;gene co-expression network	Louis Licamele;Lise Getoor	2011	J. Bioinformatics and Computational Biology	10.1142/S0219720011005598	biology;gene expression;computer science;bioinformatics;data mining;genetics;drug discovery	Comp.	5.88498872221327	-55.349114554186535	113070
a1584e46f1bbebeed5bf78df80259f9886410b26	annotation-based distance measures for patient subgroup discovery in clinical microarray studies	gene expression profile;microarray data;cluster algorithm;610 medizin;functional annotation;570 biowissenschaften biologie;expression profile;distance measure;gene cluster;subgroup discovery;ddc 610;clinical study;ddc 570;gene selection;candidate gene	MOTIVATION Clustering algorithms are widely used in the analysis of microarray data. In clinical studies, they are often applied to find groups of co-regulated genes. Clustering, however, can also stratify patients by similarity of their gene expression profiles, thereby defining novel disease entities based on molecular characteristics. Several distance-based cluster algorithms have been suggested, but little attention has been given to the distance measure between patients. Even with the Euclidean metric, including and excluding genes from the analysis leads to different distances between the same objects, and consequently different clustering results.   RESULTS We describe a new clustering algorithm, in which gene selection is used to derive biologically meaningful clusterings of samples by combining expression profiles and functional annotation data. According to gene annotations, candidate gene sets with specific functional characterizations are generated. Each set defines a different distance measure between patients, leading to different clusterings. These clusterings are filtered using a resampling-based significance measure. Significant clusterings are reported together with the underlying gene sets and their functional definition.   CONCLUSIONS Our method reports clusterings defined by biologically focused sets of genes. In annotation-driven clusterings, we have recovered clinically relevant patient subgroups through biologically plausible sets of genes as well as new subgroupings. We conjecture that our method has the potential to reveal so far unknown, clinically relevant classes of patients in an unsupervised manner.   AVAILABILITY We provide the R package adSplit as part of Bioconductor release 1.9 and on http://compdiag.molgen.mpg.de/software.	bioconductor;class;cluster analysis;entity;euclidean distance;gene annotation;microarray;patients;physical object;resampling (statistics);subgroup a nepoviruses;unsupervised learning;algorithm;statistical cluster	Claudio Lottaz;Joern Toedling;Rainer Spang	2006	Bioinformatics	10.1093/bioinformatics/btm322	gene-centered view of evolution;biology;microarray analysis techniques;gene cluster;bioinformatics;pattern recognition;data mining;mathematics;candidate gene;genetics	Comp.	5.342464944247964	-54.997163207937675	113103
aafc43093e4892f52b3c145008be80419aa5fe80	sibelia: a scalable and comprehensive synteny block generation tool for closely related microbial genomes		Comparing strains within the same microbial species has proven effective in the identification of genes and genomic regions responsible for virulence, as well as in the diagnosis and treatment of infectious diseases. In this paper, we present Sibelia, a tool for finding synteny blocks in multiple closely related microbial genomes using iterative de Bruijn graphs. Unlike most other tools, Sibelia can find synteny blocks that are repeated within genomes as well as blocks shared by multiple genomes. It represents synteny blocks in a hierarchy structure with multiple layers, each of which representing a different granularity level. Sibelia has been designed to work efficiently with a large number of microbial genomes; it finds synteny blocks in 31 S. aureus genomes within 31 minutes and in 59 E.coli genomes within 107 minutes on a standard desktop. Sibelia software is distributed under the GNU GPL v2 license and is available at: https://github.com/bioinf/Sibelia. Sibelia’s web-server is available at: http://etool.me/software/sibelia.	de bruijn graph;desktop computer;gnu;iterative method;server (computing);synteny;web server	Ilya Minkin;Anand Patel;Mikhail Kolmogorov;Nikolay Vyahhi;Son K. Pham	2013		10.1007/978-3-642-40453-5_17	biology;bioinformatics;genetics	Comp.	-0.8830423354972103	-58.41903662574743	113120
4b519b63d12ec711cd816b8be505e239c29d7fc9	ioncopy: an r shiny app to call copy number alterations in targeted ngs data	amplicon sequencing;copy number alterations;ngs;r shiny	BACKGROUND Somatic copy number alterations (CNAs) contribute to the clinically targetable aberrations in the tumor genome. For both routine diagnostics and biomarkers research, CNA analysis in a single assay together with somatic mutations is highly desirable.   RESULTS Ioncopy is a validated method and easy-to-use software for CNA calling from targeted NGS data. Copy number and significance of CNA are estimated for each gene in each sample. Copy number gains and losses are called after multiple testing corrections controlling FWER or FDR.   CONCLUSIONS Ioncopy facilitates calling of CNAs in a cohort of tumors tissues with or without using normal (germline) DNA controls.	biological markers;body tissue;certified nurse assistant;communications satellite;copy number;diploid cell;false discovery rate;family-wise error rate;low-copy repeats;neoplasms;netware;somatic mutation	Jan Budczies;Nicole Pfarr;Eva Romanovsky;Volker Endris;Albrecht Stenzinger;Carsten Denkert	2018		10.1186/s12859-018-2159-5	dna microarray;genetics;genome;biology;somatic cell	Comp.	2.5441316448374165	-56.35733538315752	113215
c5ea4cb44d4faede581359e0d34a26341d62c33f	the first enanomapper prototype: a substance database to support safe-by-design	databases;chemicals;nanobioscience;nanomaterials;materials;web services bioinformatics biomedical materials chemical structure data analysis data models nanomedicine ontologies artificial intelligence public domain software semantic web toxicology;ontologies;nanosafety cluster database nanomaterials safety;chemical structure database tools enanomapper prototype substance database safe by design support eu funded enanomapper project computational infrastructure toxicological data management engineered nanomaterials open standards interoperable design european research nanotechnology collaborative safety assessment transparent data sharing data analysis computational toxicology models enanomapper database solution consortium partners diverse data support flexible data storage semantic web technologies open source components web services enm information data models ontology supported data model data sources isa tab oecd harmonized templates custom spreadsheet templates;nanomaterials databases chemicals nanobioscience materials data models ontologies;data models	The EU-funded eNanoMapper project proposes a computational infrastructure for toxicological data management of engineered nanomaterials (ENMs) based on open standards, ontologies and an interoperable design to enable a more effective, integrated approach to European research in nanotechnology. eNanoMapper's goal is to support the collaborative safety assessment for ENMs by creating a modular, extensible infrastructure for transparent data sharing, data analysis, and the creation of computational toxicology models for ENMs. The eNanoMapper database solution builds on previous experience of the consortium partners in supporting diverse data through flexible data storage, semantic web technologies, open source components and web services. A number of opportunities and challenges exist in nanomaterials representation and integration of ENM information, originating from diverse systems. A short summary, highlighting the pros and cons of the existing integration approaches and data models is presented. We demonstrate the approach of adopting an ontology-supported data model, describing the materials and measurements. The data sources supported include diverse formats (ISA-Tab, OECD Harmonized Templates, custom spreadsheet templates, various databases provided by consortia members). Besides retaining the data provenance, the focus on measurements provides insights into how to reuse the chemical structure database tools for nanomaterials characterization and safety.	computer data storage;data model;database;environmental niche modelling;interoperability;ontology (information science);open-source software;prototype;reverse engineering;semantic web;spreadsheet;web service	Nina Jeliazkova;Philip Doganis;Bengt Fadeel;Roland Grafstrom;Janna Hastings;Vedrin Jeliazkov;Pekka Kohonen;Cristian R. Munteanu;Haralambos Sarimveis;Bart Smeets;Georgia Tsiliki;David Vorgrimmler;Egon L. Willighagen	2014	2014 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2014.6999367	data modeling;chemical industry;nanomaterials;computer science;bioinformatics;ontology;data science;data mining;database	DB	-4.008401828899983	-62.34767011988569	113269
b341d027db82735a9de1dae7664923f32d268e30	hardware designs for local alignment of protein sequences	field programmable gate array;diseno circuito;alignement sequence;proteine;protein sequence;circuit design;interrogation base donnee;interrogacion base datos;bioinformatique;alineacion secuencia;red puerta programable;reseau porte programmable;circuit a la demande;fpga implementation;custom circuit;circuito integrato personalizado;hardware design;conception circuit;proteina;sequence alignment;bioinformatica;protein;database query;local alignment;bioinformatics	Local alignment of two protein sequences shows the similar regions between these proteins. Usually, a query protein sequence is aligned with several hundred thousands of protein sequences stored in databases. Since this procedure is computationally demanding, various hardware units are designed to get high quality results in a practically useful time. This paper presents efficient hardware designs that compute the local alignment scores of protein sequences. The presented designs are compared with the reference designs. All designs are implemented using ASIC and FPGA technologies. Syntheses results show that compared to the reference designs the proposed ASIC implementations achieve frequency improvements up to 250 % and hardware gains up to 40 %, and the proposed FPGA implementations achieve frequency improvements up to 29 % and hardware gains up to 48 %.		Mustafa Gök;Çaglar Yilmaz	2006		10.1007/11902140_31	computer science;bioinformatics;theoretical computer science;circuit design;smith–waterman algorithm;protein sequencing;sequence alignment;field-programmable gate array	Logic	-3.6699185361723816	-53.523446203251005	113315
125f996d066346238da184e44c0c7b7a4ded8337	morphogengineering roots: comparing mechanisms of morphogen gradient formation	spatio temporal analysis;indoleacetic acids;simulation and modeling;systems biology;biological transport;plant roots;physiological cellular and medical topics;models biological;computational biology bioinformatics;biophysical processes;arabidopsis;algorithms;kinetics;qh301 biology;bioinformatics	In developmental biology, there has been a recent focus on the robustness of morphogen gradients as possible providers of positional information. It was shown that functional morphogen gradients present strong biophysical constraints and lack of robustness to noise. Here we explore how the details of the mechanism which underlies the generation of a morphogen gradient can influence those properties. We contrast three gradient-generating mechanisms, (i) a source-decay mechanism; and (ii) a unidirectional transport mechanism; and (iii) a so-called reflux-loop mechanism. Focusing on the dynamics of the phytohormone auxin in the root, we show that only the reflux-loop mechanism can generate a gradient that would be adequate to supply functional positional information for the Arabidopsis root, for biophysically reasonable kinetic parameters. We argue that traits that differ in spatial and temporal time-scales can impose complex selective pressures on the mechanism of morphogen gradient formation used for the development of the particular organism.	eaf2 gene;gastroesophageal reflux disease;gradient descent;kinetics;language development disorders;plant growth regulators;plant roots	Verônica A. Grieneisen;Ben Scheres;Paulien Hogeweg;Athanasius F. M. Marée	2011		10.1186/1752-0509-6-37	biology;computer science;bioinformatics;ecology;systems biology;kinetics	AI	7.14537311106459	-64.19029137106169	113366
094b2634d851516c7c8e66dac3900e20ed8b8c61	a wavelet-based method to exploit epigenomic language in the regulatory region	animals;mice;embryonic stem cells;epigenomics;lung;histones;cluster analysis;fibroblasts;gene expression regulation;algorithms;humans;software design;cell line	MOTIVATION Epigenetic landscapes in the regulatory regions reflect binding condition of transcription factors and their co-factors. Identifying epigenetic condition and its variation is important in understanding condition-specific gene regulation. Computational approaches to explore complex multi-dimensional landscapes are needed.   RESULTS To study epigenomic condition for gene regulation, we developed a method, AWNFR, to classify epigenomic landscapes based on the detected epigenomic landscapes. Assuming mixture of Gaussians for a nucleosome, the proposed method captures the shape of histone modification and identifies potential regulatory regions in the wavelet domain. For accuracy estimation as well as enhanced computational speed, we developed a novel algorithm based on down-sampling operation and footprint in wavelet. We showed the algorithmic advantages of AWNFR using the simulated data. AWNFR identified regulatory regions more effectively and accurately than the previous approaches with the epigenome data in mouse embryonic stem cells and human lung fibroblast cells (IMR90). Based on the detected epigenomic landscapes, AWNFR classified epigenomic status and studied epigenomic codes. We studied co-occurring histone marks and showed that AWNFR captures the epigenomic variation across time.   AVAILABILITY AND IMPLEMENTATION The source code and supplemental document of AWNFR are available at http://wonk.med.upenn.edu/AWNFR.	classification;computation;embryonic stem cells;epigenomics;fractal landscape;gene expression regulation;histone code;histones;mixture model;numerous;regulatory sequences, nucleic acid;sampling (signal processing);sampling - surgical action;source code;structure of parenchyma of lung;transcription factor;transcription (software);wavelet;algorithm;nucleosome location;study of epigenetics	Nha Nguyen;An P. N. Vo;Kyoung-Jae Won	2014	Bioinformatics	10.1093/bioinformatics/btt467	epigenomics;biology;regulation of gene expression;bioinformatics;software design;histone;cluster analysis;genetics;cell culture;embryonic stem cell	Comp.	3.097132414125392	-57.37711368005721	113379
a9075ddd7c83a328f0caa2e33a48e0b221b1f5cf	riblast: an ultrafast rna–rna interaction prediction system based on a seed-and-extension approach		Motivation LncRNAs play important roles in various biological processes. Although more than 58 000 human lncRNA genes have been discovered, most known lncRNAs are still poorly characterized. One approach to understanding the functions of lncRNAs is the detection of the interacting RNA target of each lncRNA. Because experimental detections of comprehensive lncRNA-RNA interactions are difficult, computational prediction of lncRNA-RNA interactions is an indispensable technique. However, the high computational costs of existing RNA-RNA interaction prediction tools prevent their application to large-scale lncRNA datasets.   Results Here, we present 'RIblast', an ultrafast RNA-RNA interaction prediction method based on the seed-and-extension approach. RIblast discovers seed regions using suffix arrays and subsequently extends seed regions based on an RNA secondary structure energy model. Computational experiments indicate that RIblast achieves a level of prediction accuracy similar to those of existing programs, but at speeds over 64 times faster than existing programs.   Availability and implementation The source code of RIblast is freely available at https://github.com/fukunagatsu/RIblast .   Contact t.fukunaga@kurenai.waseda.jp or mhamada@waseda.jp.   Supplementary information Supplementary data are available at Bioinformatics online.	bioinformatics;computation;experiment;geographic information systems;greater than;interaction;rna;rna, long untranslated;seed;sensor;source code;suffix array	Tsukasa Fukunaga;Michiaki Hamada	2017		10.1093/bioinformatics/btx287	rna;computer science;ultrashort pulse;bioinformatics	Comp.	2.5063891894418844	-57.69087260259465	113471
2e82bf4d891424e5de05a5f133f969c87d300464	a powerful non-homology method for the prediction of operons in prokaryotes	supplementary information: additional materials and graphs;operon structure.;are available at: http://www.cifn.unam.mx/moreno/ pub/tupredictions/. contact: moreno@cifn.unam.mx keywords: functional genomics;comparative genomics;operon prediction;escherichia coli;functional genomics;base pair	MOTIVATION The prediction of the transcription unit organization of genomes is an important clue in the inference of functional relationships of genes, the interpretation and evaluation of transcriptome experiments, and the overall inference of the regulatory networks governing the expression of genes in response to the environment. Though several methods have been devised to predict operons, most need a high characterization of the genome analysed. Log-likelihoods derived from inter-genic distance distributions work surprisingly well to predict operons in Escherichia coli and are available for any genome as soon as the gene sets are predicted.   RESULTS Here we provide evidence that the very same method is applicable to any prokaryotic genome. First, the method has the same efficiency when evaluated using a collection of experimentally known operons of Bacillus subtilis. Second, operons among most if not all prokaryotes seem to have the same tendencies to keep short distances between their genes, the most frequent distances being the overlaps of four and one base pairs. The universality of this structural feature allows us to predict the organization of transcription units in all prokaryotes. Third, predicted operons contain a higher proportion of genes with related phylogenetic profiles and conservation of adjacency than predicted borders of transcription units.	base pairing;distance;experiment;gene regulatory network;genome;homologous gene;homology (biology);inference;operon;phylogenetics;prokaryote;transcription (software);transcriptome;unit;universality probability	Gabriel Moreno-Hagelsieb;Julio Collado-Vides	2002	Bioinformatics		functional genomics;biology;base pair;bioinformatics;comparative genomics;escherichia coli;genetics	Comp.	3.5228486952059845	-59.67882313853394	113502
407cc1e7aa093bdbd52b0dd8cffed4890e019789	discovering local patterns of co - evolution: computational aspects and biological examples	evolution molecular;positive selection;high resolution;protein complex;phylogeny;computational biology bioinformatics;gene expression;evolutionary trees;phylogenetic tree;rare event;computational complexity;clustering method;biological systems;algorithms;signaling pathway;combinatorial libraries;computational biology;computer appl in life sciences;gene expression profiling;physical interaction;microarrays;bioinformatics	Co-evolution is the process in which two (or more) sets of orthologs exhibit a similar or correlative pattern of evolution. Co-evolution is a powerful way to learn about the functional interdependencies between sets of genes and cellular functions and to predict physical interactions. More generally, it can be used for answering fundamental questions about the evolution of biological systems. Orthologs that exhibit a strong signal of co-evolution in a certain part of the evolutionary tree may show a mild signal of co-evolution in other branches of the tree. The major reasons for this phenomenon are noise in the biological input, genes that gain or lose functions, and the fact that some measures of co-evolution relate to rare events such as positive selection. Previous publications in the field dealt with the problem of finding sets of genes that co-evolved along an entire underlying phylogenetic tree, without considering the fact that often co-evolution is local. In this work, we describe a new set of biological problems that are related to finding patterns of local co-evolution. We discuss their computational complexity and design algorithms for solving them. These algorithms outperform other bi-clustering methods as they are designed specifically for solving the set of problems mentioned above. We use our approach to trace the co-evolution of fungal, eukaryotic, and mammalian genes at high resolution across the different parts of the corresponding phylogenetic trees. Specifically, we discover regions in the fungi tree that are enriched with positive evolution. We show that metabolic genes exhibit a remarkable level of co-evolution and different patterns of co-evolution in various biological datasets. In addition, we find that protein complexes that are related to gene expression exhibit non-homogenous levels of co-evolution across different parts of the fungi evolutionary line. In the case of mammalian evolution, signaling pathways that are related to neurotransmission exhibit a relatively higher level of co-evolution along the primate subtree. We show that finding local patterns of co-evolution is a computationally challenging task and we offer novel algorithms that allow us to solve this problem, thus opening a new approach for analyzing the evolution of biological systems.	algorithm;biological system;cluster analysis;computation;computational complexity theory;correlative study;fundamental interaction;fungi;gene expression profiling;homology (biology);image noise;image resolution;interdependence;mammals;patterns of evolution;phylogenetic tree;phylogenetics;primates;rare events;synaptic transmission;tree (data structure);trees (plant);statistical cluster	Tamir Tuller;Yifat Felder;Martin Kupiec	2009		10.1186/1471-2105-11-43	computational biology;biology;phylogenetic tree;bioinformatics;genetics;phylogenetics	Comp.	4.568917883143746	-58.995896635031336	113539
16e76032f5bb0d1efc086d7e44db5ee3627bd4be	modulation of calmodulin lobes by different targets: an allosteric model with hemiconcerted conformational transitions	amino acid sequence;calcium;allosteric regulation;models molecular;protein conformation;thermodynamics;molecular sequence data;sequence alignment;calmodulin	Calmodulin is a calcium-binding protein ubiquitous in eukaryotic cells, involved in numerous calcium-regulated biological phenomena, such as synaptic plasticity, muscle contraction, cell cycle, and circadian rhythms. It exibits a characteristic dumbell shape, with two globular domains (N- and C-terminal lobe) joined by a linker region. Each lobe can take alternative conformations, affected by the binding of calcium and target proteins. Calmodulin displays considerable functional flexibility due to its capability to bind different targets, often in a tissue-specific fashion. In various specific physiological environments (e.g. skeletal muscle, neuron dendritic spines) several targets compete for the same calmodulin pool, regulating its availability and affinity for calcium. In this work, we sought to understand the general principles underlying calmodulin modulation by different target proteins, and to account for simultaneous effects of multiple competing targets, thus enabling a more realistic simulation of calmodulin-dependent pathways. We built a mechanistic allosteric model of calmodulin, based on an hemiconcerted framework: each calmodulin lobe can exist in two conformations in thermodynamic equilibrium, with different affinities for calcium and different affinities for each target. Each lobe was allowed to switch conformation on its own. The model was parameterised and validated against experimental data from the literature. In spite of its simplicity, a two-state allosteric model was able to satisfactorily represent several sets of experiments, in particular the binding of calcium on intact and truncated calmodulin and the effect of different skMLCK peptides on calmodulin's saturation curve. The model can also be readily extended to include multiple targets. We show that some targets stabilise the low calcium affinity T state while others stabilise the high affinity R state. Most of the effects produced by calmodulin targets can be explained as modulation of a pre-existing dynamic equilibrium between different conformations of calmodulin's lobes, in agreement with linkage theory and MWC-type models.	acoustic lobing;biological phenomena;calcium;calcium-binding proteins;calmodulin 1;cellular phone;circadian rhythms;dendritic spines;dendritic spine;equilibrium;experiment;linkage (software);linker (computing);modulation;multiply-with-carry;muscle contraction;neuron;portable document format;processor affinity;simulation;synaptic package manager;synaptic weight;thermodynamics;vertebral column;genetic linkage;lobe	Massimo Lai;Denis Brun;Stuart J. Edelstein;Nicolas Le Novère	2015		10.1371/journal.pcbi.1004063	biology;biochemistry;calcium;allosteric regulation;bioinformatics;calmodulin;sequence alignment	ML	7.529719390086352	-63.70418787612715	113615
3d6114a1327b2afe0c18aaf5b219c40abffef758	inference of functional networks of condition-specific response--a case study of quiescence in yeast		Analysis of condition-specific behavior under stressful environmental conditions can provide insight into mechanisms causing different healthy and diseased cellular states. Functional networks (edges representing statistical dependencies) inferred from condition-specific expression data can provide fine-grained, network level information about conserved and specific behavior across different conditions. In this paper, we examine novel microarray compendia measuring gene expression from two unique stationary phase yeast cell populations, quiescent and non-quiescent. We make the following contributions: (a) develop a new algorithm to infer functional networks modeled as undirected probabilistic graphical models, Markov random fields, (b) infer functional networks for quiescent, non-quiescent cells and exponential cells, and (c) compare the inferred networks to identify processes common and different across these cells. We found that both non-quiescent and exponential cells have more gene ontology enrichment than quiescent cells. The exponential cells share more processes with non-quiescent than with quiescent, highlighting the novel and relatively under-studied characteristics of quiescent cells. Analysis of inferred subgraphs identified processes enriched in both quiescent and non-quiescent cells as well processes specific to each cell type. Finally, SNF1, which is crucial for quiescence, occurs exclusively among quiescent network hubs, while non-quiescent network hubs are enriched in human disease causing homologs.	algorithm;compendium;emoticon;g1 to g0 transition;gene expression;gene ontology term enrichment;glucose;graph (discrete mathematics);graphical model;high- and low-level;homology (biology);inference;markov chain;markov random field;microarray;population;quiesce;quiescence search;spore;stationary process;exponential;sporulation	Sushmita Roy;Terran Lane;Margaret Werner-Washburne;Diego Martínez	2009	Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing			Comp.	5.600376244211123	-57.6539760116966	113907
d04c3eb4be8ee517a6318e56b5ef52c59a6d9bd3	parametric bootstrapping for biological sequence motifs	computational biology bioinformatics;algorithms;computer appl in life sciences;microarrays;bioinformatics	Biological sequence motifs drive the specific interactions of proteins and nucleic acids. Accordingly, the effective computational discovery and analysis of such motifs is a central theme in bioinformatics. Many practical questions about the properties of motifs can be recast as random sampling problems. In this light, the task is to determine for a given motif whether a certain feature of interest is statistically unusual among relevantly similar alternatives. Despite the generality of this framework, its use has been frustrated by the difficulties of defining an appropriate reference class of motifs for comparison and of sampling from it effectively. We define two distributions over the space of all motifs of given dimension. The first is the maximum entropy distribution subject to mean information content, and the second is the truncated uniform distribution over all motifs having information content within a given interval. We derive exact sampling algorithms for each. As a proof of concept, we employ these sampling methods to analyze a broad collection of prokaryotic and eukaryotic transcription factor binding site motifs. In addition to positional information content, we consider the informational Gini coefficient of the motif, a measure of the degree to which information is evenly distributed throughout a motif’s positions. We find that both prokaryotic and eukaryotic motifs tend to exhibit higher informational Gini coefficients (IGC) than would be expected by chance under either reference distribution. As a second application, we apply maximum entropy sampling to the motif p-value problem and use it to give elementary derivations of two new estimators. Despite the historical centrality of biological sequence motif analysis, this study constitutes to our knowledge the first use of principled null hypotheses for sequence motifs given information content. Through their use, we are able to characterize for the first time differerences in global motif statistics between biological motifs and their null distributions. In particular, we observe that biological sequence motifs show an unusual distribution of IGC, presumably due to biochemical constraints on the mechanisms of direct read-out.	algorithm;bioinformatics;bootstrapping (statistics);boson sampling;centrality;coefficient;computation;dna binding site;frustration;interaction;maximum entropy probability distribution;monte carlo method;nucleic acids;null value;p-value;randomness;sampling (signal processing);sampling - surgical action;self-information;sequence motif;transcription factor;transcription (software);informational	Patrick K. O'Neill;Ivan Erill	2016		10.1186/s12859-016-1246-8	biology;dna microarray;computer science;bioinformatics;data science;data mining	Comp.	2.4172964863905784	-61.451756926897026	113929
09eb2a9d4eb14fc49651648881c85b4b3c19c24b	structural search and retrieval using a tableau representation of protein folding patterns	search and retrieval;refolding;repliegue;proteine;folding;protein domains;bioinformatique;search method;pliage;protein structure;structure comparison;secondary structure;doblado;protein folding;proteina;bioinformatica;integer program;protein;repliement;structured data;bioinformatics	UNLABELLED Comparison and classification of folding patterns from a database of protein structures is crucial to understand the principles of protein architecture, evolution and function. Current search methods for proteins with similar folding patterns are slow and computationally intensive. The sharp growth in the number of known protein structures poses severe challenges for methods of structural comparison. There is a need for methods that can search the database of structures accurately and rapidly. We provide several methods to search for similar folding patterns using a concise tableau representation of proteins that encodes the relative geometry of secondary structural elements. Our first approach allows the extraction of identical and very closely-related protein folding patterns in constant-time (per hit). Next, we address the hard computational problem of extraction of maximally-similar subtableaux, when comparing two tableaux. We solve the problem using Quadratic and Linear integer programming formulations and demonstrate their power to identify subtle structural similarities, especially when protein structures significantly diverge. Finally, we describe a rapid and accurate method for comparing a query structure against a database of protein domains, TableauSearch. TableauSearch is rapid enough to search the entire structural database in seconds on a standard desktop computer. Our analysis of TableauSearch on many queries shows that the method is very accurate in identifying similarities of folding patterns, even between distantly related proteins.   AVAILABILITY A web server implementing the TableauSearch is available from http://hollywood.bx.psu.edu/TabSearch.	computation;computational problem;desktop computer;integer (number);integer programming;mustn1 gene;method of analytic tableaux;protein domain;qip (complexity);query language;question (inquiry);scop;server (computing);thrombocytopenia;web server;xiap gene;protein folding	Arun Siddharth Konagurthu;Peter J. Stuckey;Arthur M. Lesk	2008	Bioinformatics	10.1093/bioinformatics/btm641	protein folding;biology;protein structure;data model;computer science;bioinformatics;theoretical computer science;folding;protein domain;protein structure database;algorithm;protein secondary structure	Comp.	-2.399789302871992	-52.72954648743695	113952
ca2c0265c390c071e07e3b28347e5adce2206e2c	the internal transcribed spacer 2 database—a web server for (not only) low level phylogenetic analyses	software;phylogeny;databases nucleic acid;internal transcribed spacer 2;dna ribosomal spacer;rna structure;internet;secondary structure;structure prediction;nucleic acid conformation;user computer interface;sequence analysis rna;structure alignment	The internal transcribed spacer 2 (ITS2) is a phylogenetic marker which has been of broad use in generic and infrageneric level classifications, as its sequence evolves comparably fast. Only recently, it became clear, that the ITS2 might be useful even for higher level systematic analyses. As the secondary structure is highly conserved within all eukaryotes it serves as a valuable template for the construction of highly reliable sequence-structure alignments, which build a fundament for subsequent analyses. Thus, any phylogenetic study using ITS2 has to consider both sequence and structure. We have integrated a homology based RNA structure prediction algorithm into a web server, which allows the detection and secondary structure prediction for ITS2 in any given sequence. Furthermore, the resource contains more than 25,000 pre-calculated secondary structures for the currently known ITS2 sequences. These can be taxonomically searched and browsed. Thus, our resource could become a starting point for ITS2-based phylogenetic analyses and is therefore complementary to databases of other phylogenetic markers, which focus on higher level analyses. The current version of the ITS2 database can be accessed via http://its2.bioapps.biozentrum.uni-wuerzburg.de.	classification;clinical use template;conserved sequence;database;fiducial marker;generic drugs;greater than;homologous gene;homology (biology);internal transcribed spacer;list of rna structure prediction software;phylogenetics;protein structure prediction;search - action;server (computer);server (computing);spacer device component;web server;algorithm	Jörg Schultz;Tobias Mueller;Marco Achtziger;Philipp N. Seibel;Thomas Dandekar;Matthias Wolf	2006	Nucleic Acids Research	10.1093/nar/gkl129	biology;nucleic acid structure;structural alignment;the internet;bioinformatics;genetics;protein secondary structure;phylogenetics	Comp.	-0.23571225732641826	-59.493249954281154	114427
84a901a2c289d8f186a3114e48e96acc955af6d1	the nucleotide sequence of pathogenesis-related (pr) 1c protein gene of tobacco	genes;spermatophyta;proteine;angiospermae;patogenia;plant pathology;gen;secuencia nucleotido;stimulant plants;nucleotide sequences;pathogenicity;genetics;nucleotide sequence;sequence nucleotide;clonacion molecular;proteins;tobacco;molecular genetics;pathogenesis related;clonage moleculaire;pathogenesis;pathogenesis related proteins;gene;molecular cloning;dicotyledones;genes plant;pathogenie;proteina;molecular sequence data;solanaceae;base sequence;biotechnology;plants toxic;plant proteins	protein was cloned from Nicotiana tabacum cv. Samsun NN TATA-box is underlined. genomic library screening with cDNA clone of PR la protein gene (1). The following nucleotide sequence contains coding and its REFERENCES flanking regions. The nucleotide sequence of PRlc protein gene downstream from 126 resembles that of PRla (2-5). However, '• Matsuoka et al. (1987) Plant Physiol. 85, 942-946. 123 nucleotides fragment (from 164 to 286) is inserted at 157 *; ^^r^^StJ^ti^-St'^ nucleotides upstream from the capping site. Coding region is from 4. payne et al. (1988) Plant Mol. Biol. 11, 89-94. 5. Pfitzner et al. (1988) Mol. Cen. Genet. 211, 290-295. 1 CGGATTCGTC CGGAGAAGTC CCACATTGGG CATAAGCGCT CCCTGACGAA 51 GGCGACTCCA TACCCATGGA CTTGAACCCG AGACCTTTGG TTAAGGATGA 101 ACGAGACTCC GGTGCCAGGT AAAATATTGG TAACTGCTTA TATAAGTTTA 151 ATATGGTAAC CTGAGCCGAA GGTCTATCGG AAACAGACTT TCTGCCCTAT 201 CAGGGTAGGG GTAAGGTCTG CATACACAGT ACCCTCTCCA AACCCCACTT 251 AGTGAGACTT TAGTGGGTAG TTGTTGTTGT TATTGTTATG GTAACCTGGG 301 AAACAGGATA AATAACTATC TATAACAGGA TATATTACAT TGATATTACC 351 ATGTCAAAAA ATTAAGCAAG TACATGAATA ATCGCCGTGA AATCTTCAAG 401 ATTTCTCCTA TAAATACCCT TGGTAGTAAA TCTAGTTTTT CCATTCAAGT 451 ACAACATTTC TCCTATAGTC ATGGAATTTG TTCTCTTTTC ACAAATGTCT 501 TCATTTTTTC TTGTCTCTAC GCTTCTCTTA TTCCTAATAA TATCCCACTC 551 TTGTCATGCT CAAAACTCTC AACAAGACTA TTTGGATGCC CATAACACAG 601 CTCGTGCAGA TGTAGGTGTA GAACCTTTGA CCTGGGACGA CCAGGTAGCA 651 GCCTATGCAC AAAATTATGC TTCCCAATTG GCTGCAGATT GTAACCTCGT 7 01 ACATTCTCAT GGTCAATACG GCGAAAACCT AGCTTGGGGA AGTGGCGATT 7 51 TCTTGACGGC CGCTAAGGCC GTCGAGATGT GGGTCAATGA GAAACAGTAT 801 TATGCCCACG ACTCAAACAC TTGTGCCCAA GGACAGGTGT GTGGACACTA 851 TACTCAGGTG GTTTGGCGTA ACTCGGTTCG TGTTGGATGT GCTAGGGTTC 901 AGTGTAACAA TGGAGGATAT ATTGTCTCTT GCAACTATGA TCCTCCAGGT 951 AATGTTATAG GCAAAAGCCC ATACTAATTG AAAACATATG TCCATTTCAC 10 01 GTTATATATG TGTGGACTTC TGCTTGATAT ATATCAAGAA CTTAAATAAT 1051 TGCGCTAAAA AGCAACTTAT AGTTAAGTAT ATAGTACTAT ATTTGTAATT 1101 CTCTGAAGTG GATATATAAT AAGACCTAGT GCTCTTGATT ATGGGGAAAA 1151 ATATGAATTC	101 mouse;base sequence;clinical act of insertion;clone cells;dna, complementary;downstream (software development);eighty nine;flank (surface region);frequency capping;genets;ku protein;linear algebra;nucleotides;taf1 gene;cyclophosphamide/etoposide/mitoxantrone	Masahiro Ohshima;Naoki Harada;Makoto Matsuoka;Yuko Ohashi	1990	Nucleic acids research	10.1093/nar/18.1.182	molecular genetics;biology;bioinformatics;gene;genetics	Comp.	3.8123051204170633	-63.73188433784446	114468
130e1bdca4a61a471849fb7fe059e68f14ecee14	clustering analysis of the gene chip data for two types of leukemia			cluster analysis;dna microarray	Cai Wu	2014			dna microarray;cluster analysis;computer science;bioinformatics;leukemia	HPC	1.608014388362002	-63.29593435388248	114480
a1e5b294ccc8658a901cad068a61762de19ff291	combining unsupervised and supervised artificial neural networks to predictaquatic toxicity	neural networks;learning artificial intelligence;fusion of classifiers protein surface pseudo amino acid composition;artificial neural network	Most quantitative structure-activity relationship (QSAR) models are linear relationships and significant for only a limited domain of compounds. Here we propose a data-driven approach with a flexible combination of unsupervised and supervised neural networks able to predict the toxicity of a large set of different chemicals while still respecting the QSAR postulates. Since QSAR is applicable only to similar compounds, which have similar biological and physicochemical properties, large numbers of compounds are clustered before building local models, and local models are ensembled to obtain the final result. The approach has been used to develop models to predict the fish toxicity of Pimephales promelas and Tetrahymena pyriformis, a protozoan.	adverse reaction to drug;artificial neural network;gyrodactylus sp. (pimephales promelas) wwab-2002;protozoa;quantitative structure-activity relationship;unsupervised learning	Giuseppina C. Gini;Marian Viorel Craciun;Christoph König;Emilio Benfenati	2004	Journal of chemical information and computer sciences	10.1021/ci0401219	computer science;bioinformatics;artificial intelligence;machine learning;artificial neural network	ML	10.019164079147426	-55.79895143702135	114529
040d10a07ba203f8354383beef41d41928036e02	robustness of circadian clocks to daylight fluctuations: hints from the picoeucaryote ostreococcus tauri	diurnal cycle;gene expression regulation plant;oscillations;light dark;minimal model;system approach;rna messenger;normal distribution;gene regulatory networks;circadian rhythm signaling peptides and proteins;plos computational biology;genetics;light;circadian clocks;feedback physiological;structure and function;feedback loop;chlorophyta;mathematical model;circadian clock;algorithms;quantitative method;gene transcription;oligonucleotide array sequence analysis;biological process	The development of systemic approaches in biology has put emphasis on identifying genetic modules whose behavior can be modeled accurately so as to gain insight into their structure and function. However, most gene circuits in a cell are under control of external signals and thus, quantitative agreement between experimental data and a mathematical model is difficult. Circadian biology has been one notable exception: quantitative models of the internal clock that orchestrates biological processes over the 24-hour diurnal cycle have been constructed for a few organisms, from cyanobacteria to plants and mammals. In most cases, a complex architecture with interlocked feedback loops has been evidenced. Here we present the first modeling results for the circadian clock of the green unicellular alga Ostreococcus tauri. Two plant-like clock genes have been shown to play a central role in the Ostreococcus clock. We find that their expression time profiles can be accurately reproduced by a minimal model of a two-gene transcriptional feedback loop. Remarkably, best adjustment of data recorded under light/dark alternation is obtained when assuming that the oscillator is not coupled to the diurnal cycle. This suggests that coupling to light is confined to specific time intervals and has no dynamical effect when the oscillator is entrained by the diurnal cycle. This intriguing property may reflect a strategy to minimize the impact of fluctuations in daylight intensity on the core circadian oscillator, a type of perturbation that has been rarely considered when assessing the robustness of circadian clocks.	24-hour clock;algae;circadian clocks;cyanobacteria;daylight;elymus tauri;feedback;mammals;mathematical model;mathematics;oscillator device component;sleep disorders, circadian rhythm;transcription, genetic;vector clock	Quentin Thommen;Benjamin Pfeuty;Pierre-Emmanuel Morant;Florence Corellou;François-Yves Bouget;Marc Lefranc	2010		10.1371/journal.pcbi.1000990	biology;bioinformatics;ecology;circadian clock;genetics	Comp.	6.948066030039025	-64.6268097651042	114566
20b2ef8cd38296c592450653b58847ea673b2458	identifiability issues in phylogeny-based detection of horizontal gene transfer	lineage sorting;gene trees;genetics;horizontal gene transfer	Prokaryotic organisms share genetic material across species boundaries by means of a process known as horizontal gene transfer (HGT). Detecting this process bears great significance on understanding prokaryotic genome diversification and unraveling their complexities. Phylogeny-based detection of HGT is one of the most commonly used approaches for this task, and is based on the fundamental fact that HGT may cause gene trees to disagree with one another, as well as with the species phylogeny. Hence, methods that adopt this approach compare gene and species trees, and infer a set of HGT events to reconcile the differences among these trees. In this paper, we address some of the identifiability issues that face phylogeny-based detection of HGT. In particular, we show the effect of inaccuracies in the reconstructed (species and gene) trees on inferring the correct number of HGT events. Further, we show that a large number of maximally parsimonious HGT scenarios may exist. These results indicate that accurate detection of HGT requires accurate reconstruction of individual trees, and necessitates the search for more than a single scenario to explain gene tree disagreements. Finally, we show that disagreements among trees may be a result of not only HGT, but also lineage sorting, and make initial progress on incorporating HGT into the coalescent model, so as to stochastically distinguish between the two and make an accurate reconciliation. This contribution is very significant, particularly when analyzing closely related organisms.	binary tree;diversification (finance);lineage (evolution);occam's razor;phylogenetic tree;phylogenetics;sensor;sorting	Cuong Than;Derek A. Ruths;Hideki Innan;Luay Nakhleh	2006		10.1007/11864127_17	biology;bioinformatics;horizontal gene transfer;genetics	Comp.	1.4725172573105694	-52.33203765620779	114611
8123c8a67ac4014c83baa4f80189a68a8f97a87c	towards automatic discovery of genes related to human placenta		The document collection was retrieved from PubMed® using search filters and the following search terms: placenta, gene, biomarker, polymorphism, enzyme, preeclampsia, hypertension, diabetes, growth restriction. The tailored search returned 428 papers. To identify specific gene mentions from titles and abstracts we used the NLM MetaMap 2014 restricting processing to semantic type Gene. We then manually classified the extracted gene names into: • Specific gene mentions (e.g. CDKN1A ) • General genetic terms (e.g. growth factor gene • Errors (e.g. preeclampsia susceptibility). Our preliminary analysis shows that the placenta literature contains enough specific gene mentions to warrant further text mining on the genes of interest to identify pathways, biomarkers, and relationships between placenta gene expression and maternal and/or fetal diseases, ultimately identifying predictors of diseases that may clinically manifest only later in life.	archive;manifest (transportation);netware loadable module;pubmed;text mining	Laritza M. Rodriguez;Stephanie M. Morrison;Kathleen Greenberg;Dina Demner-Fushman	2016			genetics;gene;placenta;biology	Comp.	-1.8891475656461834	-63.977730346788064	114627
ba8e7c141281060282c40d5fe3a3b86096132554	angle: a sequencing errors resistant program for predicting protein coding regions in unfinished cdna	coding sequence;sequencing errors;adaboost;cdna;est	In the process of making full-length cDNA, predicting protein coding regions helps both in the preliminary analysis of genes and in any succeeding process. However, unfinished cDNA contains artifacts including many sequencing errors, which hinder the correct evaluation of coding sequences. Especially, predictions of short sequences are difficult because they provide little information for evaluating coding potential. In this paper, we describe ANGLE, a new program for predicting coding sequences in low quality cDNA. To achieve error-tolerant prediction, ANGLE uses a machine-learning approach, which makes better expression of coding sequence maximizing the use of limited information from input sequences. Our method utilizes not only codon usage, but also protein structure information which is difficult to be used for stochastic model-based algorithms, and optimizes limited information from a short segment when deciding coding potential, with the result that predictive accuracy does not depend on the length of an input sequence. The performance of ANGLE is compared with ESTSCAN on four dataset each of them having a different error rate (one frame-shift error or one substitution error per 200-500 nucleotides) and on one dataset which has no error. ANGLE outperforms ESTSCAN by 9.26% in average Matthews's correlation coefficient on short sequence dataset (< 1000 bases). On long sequence dataset, ANGLE achieves comparable performance.	angle (software);base;biopolymer sequencing;coefficient;dna, complementary;error-tolerant design;machine learning;morphologic artifacts;nucleotides;one thousand;open reading frames;silo (dataset);algorithm	Kana Shimizu;Jun Adachi;Yoichi Muraoka	2006	Journal of bioinformatics and computational biology	10.1142/S0219720006002260	adaboost;biology;coding region;computer science;bioinformatics;machine learning;data mining;genetics;complementary dna	Comp.	0.6201309396945128	-54.78868380695714	114665
4c5ffc038b5550c02e62cc24433e83732c54e2fd	rna secondary structure prediction using stochastic context-free grammars and evolutionary history	evolutionary history;prediccion;arbre phylogenetique;stochastic context free grammar;evolutionary model;structure secondaire;computerized processing;tratamiento informatico;methode;arbol filogenetico;rna;phylogenetic tree;estructura secundaria;context free grammar;structure moleculaire;secondary structure;algorithme evolutionniste;algoritmo evolucionista;rna secondary structure prediction;evolutionary algorithm;estructura molecular;metodo;traitement informatique;prediction;method;molecular structure	MOTIVATION Many computerized methods for RNA secondary structure prediction have been developed. Few of these methods, however, employ an evolutionary model, thus relevant information is often left out from the structure determination. This paper introduces a method which incorporates evolutionary history into RNA secondary structure prediction. The method reported here is based on stochastic context-free grammars (SCFGs) to give a prior probability distribution of structures.   RESULTS The phylogenetic tree relating the sequences can be found by maximum likelihood (ML) estimation from the model introduced here. The tree is shown to reveal information about the structure, due to mutation patterns. The inclusion of a prior distribution of RNA structures ensures good structure predictions even for a small number of related sequences. Prediction is carried out using maximum a posteriori estimation (MAP) estimation in a Bayesian approach. For small sequence sets, the method performs very well compared to current automated methods.	context-free language;estimation theory;models of dna evolution;mutation;phenylephrine hydrochloride 10 mg oral tablet;phylogenetic tree;phylogenetics;protein structure prediction;rna;stochastic context-free grammar	Bjarne Knudsen;Jotun Hein	1999	Bioinformatics	10.1093/bioinformatics/15.6.446	biology;method;phylogenetic tree;rna;prediction;molecule;computer science;artificial intelligence;machine learning;evolutionary algorithm;mathematics;context-free grammar;stochastic context-free grammar;genetics;algorithm;protein secondary structure	Comp.	-3.2553153408279245	-54.683246375000884	114676
56626c2c8b6109242299af6346f9f6a014df926a	the genetic diversity and differentiation of haliotis ovina by aflp	dna;amplified fragment length polymorphism technique;alleles;genetics aquaculture biotechnology educational institutions polymers sea measurements australia law enforcement laboratories dna;polymorphism biological techniques genetics molecular biophysics;anyou genetic diversity haliotis ovina amplified fragment length polymorphism technique alleles genetic differentiation dendrogram yinzhou yalongwan;anyou;haliotis ovina;data mining;amplified fragment length polymorphism;yinzhou;aquaculture;genetic diversity;genetics;genetic distance;aflp haliotis ovina genetic diversity genetic differentiation;indexes;distance measurement;genetic differentiation;polymorphism;aflp;indexation;molecular biophysics;dendrogram;biological techniques;gene diversity;cultural differences;yalongwan	Amplified fragment length polymorphism technique has been applied to detect the genetic diversity and differentiation of three wild Haliotis ovina populations in Hainan province, China. High level of genetic diversity was detected among the populations. The mean effective number of alleles per locus was from 1.2027+0.3090 to 1.3530+0.3404, with an average of 1.2969+0.3338. The percentage of polymorphic loci ranged from 66.54% to 60.36%, with an average of 76.18%. The mean of Shannon's Information index was 0.2870+0.2422, ranging from 0.2026+0.2403 to 0.3397+0.2440. And the average of gene diversity index was 0.1981+0.1767, ranging from 0.1306+0.1686 to 0.2276+0.1791. In general, the genetic differentiation among the three populations was insignificant, the average genetic distance among the three populations was 0.0201, ranging from 0.0087 to 0.0462. The UPGMA dendrogram showed that Yinzhou and Yalongwan first clustered into a group and then grouped with Anyou.	dendrogram;genetic distance;locus;population;shannon (unit);upgma	Zhongbao Li	2009	2009 International Conference on Environmental Science and Information Application Technology	10.1109/ESIAT.2009.406	amplified fragment length polymorphism;biology;molecular biology;genetics;molecular biophysics	Metrics	3.6702437007490767	-62.602567070257244	114765
487833708d71f41f9f57bfa9f5478358a0f9801e	discrete modelling of the ethylene-pathway	organisms;sequences;information systems;biological system modeling;signal transduction pathway;null;arabidopsis thaliana;plants biology;biological system modeling object oriented modeling sequences bioinformatics biological systems unified modeling language information systems plants biology organisms pathogens;unified modeling language;biological systems;signaling pathway;object oriented modeling;bioinformatics;pathogens	Arabidopsis thaliana is a small flowering plant that is widely used as a model organism in plant biology. We describe here the Ethylene-Response Pathway (Ethylene- Pathway) whose is belong to the signal transduction pathways. The knowledge of the signaling pathways are still incomplete and discrete modelling has been shown to help a better understanding of the underlying mechanisms. In this paper we provide a brief introduction to the Ethylene- Pathway and describe two approaches - UML-Statecharts and Life Sequence Charts (LSC) - in discrete modelling of the signaling pathway.	chart;gene regulatory network;transduction (machine learning);unified modeling language	Claudia Täubner;Till Merker	2005	21st International Conference on Data Engineering Workshops (ICDEW'05)	10.1109/ICDE.2005.212	bioinformatics;signal transduction	DB	-0.43377736348234897	-64.90887755237121	114948
2f16e25167d842d95fb65973a601f5b9b33924d9	modeling of celiac disease immune response and the therapeutic effect of potential drugs	immunological;simulation and modeling;innate;transglutaminases;systems biology;physiological cellular and medical topics;intestine small;antigen presenting cells;interleukin 15;computational biology bioinformatics;celiac disease;peptide fragments;immunity;models immunological;intestine;glutens;reproducibility of results;small;gtp binding proteins;algorithms;humans;enzyme inhibitors;immunity innate;models;adaptive immunity;bioinformatics;antibodies	Celiac disease (CD) is an autoimmune disorder that occurs in genetically predisposed people and is caused by a reaction to the gluten protein found in wheat, which leads to intestinal villous atrophy. Currently there is no drug for treatment of CD. The only known treatment is lifelong gluten-free diet. The main aim of this work is to develop a mathematical model of the immune response in CD patients and to predict the efficacy of a transglutaminase-2 (TG-2) inhibitor as a potential drug for treatment of CD. A thorough analysis of the developed model provided the following results: 1. TG-2 inhibitor treatment leads to insignificant decrease in antibody levels, and hence remains higher than in healthy individuals. 2. TG-2 inhibitor treatment does not lead to any significant increase in villous area. 3. The model predicts that the most effective treatment of CD would be the use of gluten peptide analogs that antagonize the binding of immunogenic gluten peptides to APC. The model predicts that the treatment of CD by such gluten peptide analogs can lead to a decrease in antibody levels to those of normal healthy people, and to a significant increase in villous area. TG-2 inhibitor treatment leads to insignificant decrease in antibody levels, and hence remains higher than in healthy individuals. TG-2 inhibitor treatment does not lead to any significant increase in villous area. The model predicts that the most effective treatment of CD would be the use of gluten peptide analogs that antagonize the binding of immunogenic gluten peptides to APC. The model predicts that the treatment of CD by such gluten peptide analogs can lead to a decrease in antibody levels to those of normal healthy people, and to a significant increase in villous area. The developed mathematical model of immune response in CD allows prediction of the efficacy of TG-2 inhibitors and other possible drugs for the treatment of CD: their influence on the intestinal villous area and on the antibody levels. The model also allows to understand what processes in the immune response have the strongest influence on the efficacy of different drugs. This model could be applied in the pharmaceutical R&D arena for the design of drugs against autoimmune small intestine disorders and on the design of their corresponding clinical trials.	analog;autoimmune diseases;celiac disease;disorder of small intestine;gluten;mathematical model;mathematics;patients	Oleg O. Demin;Sergey V. Smirnov;Victor V. Sokolov;Lourdes Cucurull-Sanchez;César Pichardo-Almarza;M. Victoria Flores;Neil Benson;Oleg V. Demin	2013		10.1186/1752-0509-7-56	biology;antigen-presenting cell;acquired immune system;bioinformatics;virology;antibody;immunology;gtp-binding protein regulators;systems biology;interleukin 15	ML	8.091744988175979	-61.71658752429727	115003
002b73a774dea8da2e254adc15044bce2aba8c00	trade-offs between drug toxicity and benefit in the multi-antibiotic resistance system underlie optimal growth of e. coli	drug resistance bacterial;escherichia coli;simulation and modeling;systems biology;physiological cellular and medical topics;journal article;computational biology bioinformatics;stress physiological;salicylates;drug interactions;drug resistance multiple;algorithms;anti bacterial agents;dose response relationship drug;microbial sensitivity tests;bioinformatics	Efflux is a widespread mechanism of reversible drug resistance in bacteria that can be triggered by environmental stressors, including many classes of drugs. While such chemicals when used alone are typically toxic to the cell, they can also induce the efflux of a broad range of agents and may therefore prove beneficial to cells in the presence of multiple stressors. The cellular response to a combination of such chemical stressors may be governed by a trade-off between the fitness costs due to drug toxicity and benefits mediated by inducible systems. Unfortunately, disentangling the cost-benefit interplay using measurements of bacterial growth in response to the competing effects of the drugs is not possible without the support of a theoretical framework. Here, we use the well-studied multiple antibiotic resistance (MAR) system in E. coli to experimentally characterize the trade-off between drug toxicity (“cost”) and drug-induced resistance (“benefit”) mediated by efflux pumps. Specifically, we show that the combined effects of a MAR-inducing drug and an antibiotic are governed by a superposition of cost and benefit functions that govern these trade-offs. We find that this superposition holds for all drug concentrations, and it therefore allows us to describe the full dose–response diagram for a drug pair using simpler cost and benefit functions. Moreover, this framework predicts the existence of optimal growth at a non-trivial concentration of inducer. We demonstrate that optimal growth does not coincide with maximum induction of the mar promoter, but instead results from the interplay between drug toxicity and mar induction. Finally, we derived and experimentally validated a general phase diagram highlighting the role of these opposing effects in shaping the interaction between two drugs. Our analysis provides a quantitative description of the MAR system and highlights the trade-off between inducible resistance and the toxicity of the inducing agent in a multi-component environment. The results provide a predictive framework for the combined effects of drug toxicity and induction of the MAR system that are usually masked by bulk measurements of bacterial growth. The framework may also be useful for identifying optimal growth conditions in more general systems where combinations of environmental cues contribute to both transient resistance and toxicity.	antibiotic resistance, microbial;blinded;class;drug toxicity;experiment;hereditary multiple exostoses;mathematical induction;noise shaping;numerous;phase diagram;whole earth 'lectronic link;benefit;pump (device)	Kevin B. Wood;Philippe Cluzel	2011		10.1186/1752-0509-6-48	pharmacology;biology;toxicology;biotechnology;bioinformatics;escherichia coli;systems biology	ML	7.675444536796857	-63.60294983429009	115010
e2f4907d17c7a5c2ed8acd0987cdcba3cc3d2470	polymorphism in the ligand binding domain of rage alters its binding affinity towards aβ42 peptides: an in-silico study	srage;42 peptides;amino acid modifications;protein peptide docking;rage polymorphism;alzheimer 39;advanced glycation end product;a 946;simulation;s disease;molecular dynamics;age;ligand binding;alzheimer;binding affinity;aβ;receptor for age;bioinformatics	The study was aimed to understand the influence of RAGE polymorphism G82S, R48Q, R77C on the binding affinity to Aβ42 peptides through an in-silico approach. The structure of RAGE ectodomain 3CJJ was docked with three forms of Aβ42 [monomeric: apolar environment 1IYT, polar environment 1Z0Q and fibrillar 2BEG] using CLUSPRO in antibody mode. Highest binding score was observed with 2BEG indicating enhanced affinity of RAGE towards fibrillar Aβ42. Amino acid modifications were done in RAGE sequence to create variants and their structures were generated using SWISS MODEL followed by molecular dynamics simulation in GROMACS. The lowest energy structures 10 nos. were then docked with Aβ42 peptides. Compared to wtRAGE, G82S variant showed higher affinity whereas R48Q variant showed lesser affinity to all three forms of Aβ42. R77C variant showed significant decrease in affinity compared to wtRAGE when docked with 1IYT, and increased affinity with the other forms. The results of the study indicate that RAGE polymorphisms could modify the affinity of RAGE towards Aβ42.	processor affinity	Sreeram Krishnan;P. Rani	2016	IJBRA	10.1504/IJBRA.2016.078226	biochemistry;molecular dynamics;molecular biology;bioinformatics;ligand	Logic	9.503609761338039	-61.90954292935372	115085
151f9f9f711c7fe38757256cf0f3fdcf92c7cded	correlating overrepresented upstream motifs to gene expression: a computational approach to regulatory element discovery in eukaryotes	5 flanking region;saccharomyces cerevisiae;dna binding proteins;base composition;genome fungal;genes regulator;gene regulation;saccharomyces cerevisiae proteins;regulatory element;transcription factors;eukaryotic cells;computational method;computational biology bioinformatics;gene expression;genes fungal;false positive reactions;sequence homology nucleic acid;gene expression regulation fungal;algorithms;repressor proteins;dna microarray;combinatorial libraries;computational biology;computer appl in life sciences;microarrays;bioinformatics;open reading frames;fungal proteins	Gene regulation in eukaryotes is mainly effected through transcription factors binding to rather short recognition motifs generally located upstream of the coding region. We present a novel computational method to identify regulatory elements in the upstream region of eukaryotic genes. The genes are grouped in sets sharing an overrepresented short motif in their upstream sequence. For each set, the average expression level from a microarray experiment is determined: If this level is significantly higher or lower than the average taken over the whole genome, then the overerpresented motif shared by the genes in the set is likely to play a role in their regulation. The method was tested by applying it to the genome of Saccharomyces cerevisiae, using the publicly available results of a DNA microarray experiment, in which expression levels for virtually all the genes were measured during the diauxic shift from fermentation to respiration. Several known motifs were correctly identified, and a new candidate regulatory sequence was determined. We have described and successfully tested a simple computational method to identify upstream motifs relevant to gene regulation in eukaryotes by studying the statistical correlation between overepresented upstream motifs and gene expression levels.	5' region;computation;dna microarray format;gene expression regulation;motif;open reading frames;regulatory sequences, nucleic acid;transcription factor;transcription (software)	Michele Caselle;Ferdinando Di Cunto;Paolo Provero	2001		10.1186/1471-2105-3-7	biology;molecular biology;dna microarray;bioinformatics;genetics;upstream activating sequence	Comp.	3.974566240936999	-61.00708485943716	115254
3a4c15c5c355db1eb179d4b610bf98c8f1df4664	a multiple information fusion method for predicting subcellular locations of two different types of bacterial protein simultaneously	physicochemical properties;intracellular space;models biological;principal component analysis;期刊论文;support vector machine;computational biology;bacterial proteins;position specific score matrix;gene ontology	"""Subcellular localization prediction of bacterial protein is an important component of bioinformatics, which has great importance for drug design and other applications. For the prediction of protein subcellular localization, as we all know, lots of computational tools have been developed in the recent decades. In this study, we firstly introduce three kinds of protein sequences encoding schemes: physicochemical-based, evolutionary-based, and GO-based. The original and consensus sequences were combined with physicochemical properties. And elements information of different rows and columns in position-specific scoring matrix were taken into consideration simultaneously for more core and essence information. Computational methods based on gene ontology (GO) have been demonstrated to be superior to methods based on other features. Then principal component analysis (PCA) is applied for feature selection and reduced vectors are input to a support vector machine (SVM) to predict protein subcellular localization. The proposed method can achieve a prediction accuracy of 98.28% and 97.87% on a stringent Gram-positive (Gpos) and Gram-negative (Gneg) dataset with Jackknife test, respectively. At last, we calculate """"absolute true overall accuracy (ATOA)"""", which is stricter than overall accuracy. The ATOA obtained from the proposed method is also up to 97.32% and 93.06% for Gpos and Gneg. From both the rationality of testing procedure and the success rates of test results, the current method can improve the prediction quality of protein subcellular localization."""	amino acid sequence;amino acids;bacterial proteins;bioinformatics;column (database);computation;consensus sequence;drug design;drug discovery;entity name part qualifier - adopted;existential quantification;extraction;feature selection;feature vector;gene ontology;jackknife resampling;lithium;numerous;peptide sequence;position weight matrix;principal component analysis;protein domain;protein subcellular localization prediction;rationality;reside;score;server (computing);silo (dataset);statistical classification;support vector machine;true hermaphroditism (disorder);usability;web server;algorithm;gram	Jing Chen;Huimin Xu;Ping-An He;Qi Dai;Yuhua Yao	2016	Bio Systems	10.1016/j.biosystems.2015.12.002	biology;support vector machine;intracellular;computer science;bioinformatics;machine learning;data mining;principal component analysis	Comp.	9.298183604394223	-54.343016299439824	115285
e0afa49e4cd2ff24afbcdbb6fecdb763ab30f0aa	oefinder: a user interface to identify and visualize ordering effects in single-cell rna-seq data		UNLABELLED A recent article identified an artifact in multiple single-cell RNA-seq (scRNA-seq) datasets generated by the Fluidigm C1 platform. Specifically, Leng et al. showed significantly increased gene expression in cells captured from sites with small or large plate output IDs. We refer to this artifact as an ordering effect (OE). Including OE genes in downstream analyses could lead to biased results. To address this problem, we developed a statistical method and software called OEFinder to identify a sorted list of OE genes. OEFinder is available as an R package along with user-friendly graphical interface implementations which allows users to check for potential artifacts in scRNA-seq data generated by the Fluidigm C1 platform.   AVAILABILITY AND IMPLEMENTATION OEFinder is freely available at https://github.com/lengning/OEFinder   CONTACT rstewart@morgridge.org or lengning1@gmail.com   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	base sequence;bioinformatics;downstream (software development);gene expression;graphical user interface;morphologic artifacts;r language;rna;rna, small cytoplasmic;sequence number;sorting algorithm;usability;user interface device component	Ning Leng;Jeea Choi;Li-Fang Chu;James A. Thomson;Christina Kendziorski;Ron M. Stewart	2016	Bioinformatics	10.1093/bioinformatics/btw004	computer science;bioinformatics;data mining;world wide web;statistics	Comp.	-2.6588027438911723	-57.23397956134764	115301
c3096b00a56f1196ee098308cb1c9007be8616e5	splatche2: a spatially explicit simulation framework for complex demography, genetic admixture and recombination	genetique;recombinaison;genetica;simulation;simulation framework;simulacion;spatially explicit;serveur institutionnel;demografia;genetics;archive institutionnelle;open access;recombination;recombinacion;archive ouverte unige;cybertheses;demography;institutional repository;demographie	SUMMARY SPLATCHE2 is a program to simulate the demography of populations and the resulting molecular diversity for a wide range of evolutionary scenarios. The spatially explicit simulation framework can account for environmental heterogeneity and fluctuations, and it can manage multiple population sources. A coalescent-based approach is used to generate genetic markers mostly used in population genetics studies (DNA sequences, SNPs, STRs or RFLPs). Various combinations of independent, fully or partially linked genetic markers can be produced under a recombination model based on the ancestral recombination graph. Competition between two populations (or species) can also be simulated with user-defined levels of admixture between the two populations. SPLATCHE2 may be used to generate the expected genetic diversity under complex demographic scenarios and can thus serve to test null hypotheses. For model parameter estimation, SPLATCHE2 can easily be integrated into an Approximate Bayesian Computation (ABC) framework.   AVAILABILITY AND IMPLEMENTATION SPLATCHE2 is a C++ program compiled for Windows and Linux platforms. It is freely available at www.splatche.com, together with its related documentation and example data.   CONTACT mathias.currat@unige.ch	bayesian analysis;biomarkers, tumor;c++;compiler;computation;crossover (genetic algorithm);demography;documentation;estimation theory;genetic markers;genetics, population;graph - visual representation;linux;microsoft windows;null value;population parameter;recombination, genetic;restriction fragment length polymorphism;simulation;single nucleotide polymorphism;variation (genetics)	Nicolas Ray;Mathias Currat;Matthieu Foll;Laurent Excoffier	2010	Bioinformatics	10.1093/bioinformatics/btq579	biology;simulation;bioinformatics;genetics;recombination	Comp.	-2.556299310710727	-55.87509616872273	115351
ed9ecb300890dc93a3bd9f3b251f034f46c1dc0f	ledpred: an r/bioconductor package to predict regulatory sequences using support vector machines	biological patents;biomedical journals;text mining;europe pubmed central;citation search;citation networks;research articles;abstracts;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	UNLABELLED Supervised classification based on support vector machines (SVMs) has successfully been used for the prediction of cis-regulatory modules (CRMs). However, no integrated tool using such heterogeneous data as position-specific scoring matrices, ChIP-seq data or conservation scores is currently available. Here, we present LedPred, a flexible SVM workflow that predicts new regulatory sequences based on the annotation of known CRMs, which are associated to a large variety of feature types. LedPred is provided as an R/Bioconductor package connected to an online server to avoid installation of non-R software. Due to the heterogeneous CRM feature integration, LedPred excels at the prediction of regulatory sequences in Drosophila and mouse datasets compared with similar SVM-based software.   AVAILABILITY AND IMPLEMENTATION LedPred is available on GitHub: https://github.com/aitgon/LedPred and Bioconductor: http://bioconductor.org/packages/release/bioc/html/LedPred.html under the MIT license.   CONTACT aitor.gonzalez@univ-amu.fr   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.		Denis Seyres;Elodie Darbo;Laurent Perrin;Carl Herrmann;Aitor González	2016	Bioinformatics	10.1093/bioinformatics/btv705	text mining;medical research;computer science;bioinformatics;data science;data mining	Comp.	-2.3349065675966565	-57.93215375652792	115357
d513d86c5f55e768963943ba56bf416073649a50	identifying functional modules in interaction networks through overlapping markov clustering	saccharomyces cerevisiae proteins;cluster analysis;algorithms;protein interaction mapping;markov chains	MOTIVATION In recent years, Markov clustering (MCL) has emerged as an effective algorithm for clustering biological networks-for instance clustering protein-protein interaction (PPI) networks to identify functional modules. However, a limitation of MCL and its variants (e.g. regularized MCL) is that it only supports hard clustering often leading to an impedance mismatch given that there is often a significant overlap of proteins across functional modules.   RESULTS In this article, we seek to redress this limitation. We propose a soft variation of Regularized MCL (R-MCL) based on the idea of iteratively (re-)executing R-MCL while ensuring that multiple executions do not always converge to the same clustering result thus allowing for highly overlapped clusters. The resulting algorithm, denoted soft regularized Markov clustering, is shown to outperform a range of extant state-of-the-art approaches in terms of accuracy of identifying functional modules on three real PPI networks.   AVAILABILITY All data and codes are freely available upon request.   CONTACT srini@cse.ohio-state.edu   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	algorithm;bioinformatics;characteristic impedance;cluster analysis;code;converge;macintosh common lisp;markov chain monte carlo;mass effect trilogy;monte carlo localization;pixel density;proton pump inhibitors;self-tuning;word lists by frequency;negative regulation of ampa glutamate receptor clustering;protein protein interaction;statistical cluster	Yu-Keng Shih;Srinivasan Parthasarathy	2012		10.1093/bioinformatics/bts370	correlation clustering;constrained clustering;markov chain;fuzzy clustering;computer science;bioinformatics;machine learning;cure data clustering algorithm;data mining;cluster analysis;brown clustering;statistics	Comp.	5.2270906682424005	-55.54777532533411	115360
433c860fac4c647438975e52409ab09f77f784aa	mathematical modeling of gata-switching for regulating the differentiation of hematopoietic stem cell	simulation and modeling;cell differentiation;systems biology;gene regulatory networks;physiological cellular and medical topics;models biological;trans activators;computational biology bioinformatics;proto oncogene proteins;stochastic processes;algorithms;hematopoietic stem cells;gata transcription factors;bioinformatics	Hematopoiesis is a highly orchestrated developmental process that comprises various developmental stages of the hematopoietic stem cells (HSCs). During development, the decision to leave the self-renewing state and selection of a differentiation pathway is regulated by a number of transcription factors. Among them, genes GATA-1 and PU.1 form a core negative feedback module to regulate the genetic switching between the cell fate choices of HSCs. Although extensive experimental studies have revealed the mechanisms to regulate the expression of these two genes, it is still unclear how this simple module regulates the genetic switching. In this work we proposed a mathematical model to study the mechanisms of the GATA-PU.1 gene network in the determination of HSC differentiation pathways. We incorporated the mechanisms of GATA switch into the module, and developed a mathematical model that comprises three genes GATA-1, GATA-2 and PU.1. In addition, a novel multiple-objective optimization method was designed to infer unknown parameters in the proposed model by realizing different experimental observations. A stochastic model was also designed to describe the critical function of noise, due to the small copy numbers of molecular species, in determining the differentiation pathways. The proposed deterministic model has successfully realized three stable steady states representing the priming and different progenitor cells as well as genetic switching between the genetic states under various experimental conditions. Using different values of GATA-1 synthesis rate for the GATA-1 protein availability in the chromatin sites during the time period of GATA switch, stochastic simulations for the first time have realized different proportions of cells leading to different developmental pathways under various experimental conditions. Mathematical models provide testable predictions regarding the mechanisms and conditions for realizing different differentiation pathways of hematopoietic stem cells. This work represents the first attempt at using a discrete stochastic model to realize the decision of HSC differentiation pathways showing a multimodal distribution.	allogeneic hematopoietic stem cell transplantation;cell differentiation process;choice behavior;developmental process;gata1 gene;gata1 protein, human;gene regulatory network;hematopoiesis;hematopoietic stem cells;inference;mathematical model;mathematical optimization;mathematics;multi-objective optimization;multimodal interaction;negative feedback;priming exercise;qrsl1 gene;spi1 gene;simulation;transcription factor;transcription (software)	Tianhai Tian;Kate Smith-Miles	2014		10.1186/1752-0509-8-S1-S8	biology;gene regulatory network;cell biology;bioinformatics;systems biology;cellular differentiation	Comp.	6.654654613242173	-61.97932816231326	115399
6a3ca0450c6331b0a1c82d058a4935bc60362e1e	extracting features from gene ontology for the identification of protein subcellular location by semantic similarity measurement	semantic similarity;computational method;satisfiability;data mining;prediction accuracy;protein subcellular location;gene ontology	It is necessary to find a computational method for prediction of protein subcellular location (SCL). Many researches have focused on the topic. Among them, methods incorporated Gene Ontology (GO) achieved higher prediction accuracy. However the former method of extracting features from GO have some disadvantages. In this paper, to increase the accuracy of the prediction, we present a novel method to extract features from GO by semantic similarity measurement, which is hopeful to overcome the disadvantages of former method. Testing on a public available dataset shows satisfied results. And this method can also be used in similar scenarios in other bioinformatics researches or data mining process.	feature extraction;gene ontology;semantic similarity	Guoqi Li;Huanye Sheng	2007		10.1007/978-3-540-77018-3_13	semantic similarity;computer science;bioinformatics;data mining;information retrieval;satisfiability	Comp.	9.114894765259079	-52.996751093240654	115415
023499b96536b1a0dcb04a48578c5ee2533237bc	a hidden markov model for predicting transmembrane helices in protein sequences	maximum likelihood;hidden markov model;protein sequence;cross validation	A novel method to model and predict the location and orientation of alpha helices in membrane-spanning proteins is presented. It is based on a hidden Markov model (HMM) with an architecture that corresponds closely to the biological system. The model is cyclic with 7 types of states for helix core, helix caps on either side, loop on the cytoplasmic side, two loops for the non-cytoplasmic side, and a globular domain state in the middle of each loop. The two loop paths on the non-cytoplasmic side are used to model short and long loops separately, which corresponds biologically to the two known different membrane insertions mechanisms. The close mapping between the biological and computational states allows us to infer which parts of the model architecture are important to capture the information that encodes the membrane topology, and to gain a better understanding of the mechanisms and constraints involved. Models were estimated both by maximum likelihood and a discriminative method, and a method for reassignment of the membrane helix boundaries were developed. In a cross validated test on single sequences, our transmembrane HMM, TMHMM, correctly predicts the entire topology for 77% of the sequences in a standard dataset of 83 proteins with known topology. The same accuracy was achieved on a larger dataset of 160 proteins. These results compare favourably with existing methods.	anatomy, regional;biological system;clinical act of insertion;computation;file spanning;hidden markov model;inference;large;markov chain;silo (dataset);tissue membrane;tmhmm algorithm	Erik L. L. Sonnhammer;Gunnar von Heijne;Anders Krogh	1998	Proceedings. International Conference on Intelligent Systems for Molecular Biology		biology;membrane topology;computer science;bioinformatics;machine learning;protein sequencing;pattern recognition;maximum likelihood;hidden markov model;cross-validation;statistics	Comp.	8.583698587723472	-58.982928982664255	115439
10babd411dfb9cb2e907964949889a5ea224fe85	infrafrontier—providing mutant mouse resources as research tools for the international scientific community	animals;embryonic stem cells;knowledge bases;databases genetic;models animal;internet;phenotype;article;mice mutant strains	The laboratory mouse is a key model organism to investigate mechanism and therapeutics of human disease. The number of targeted genetic mouse models of disease is growing rapidly due to high-throughput production strategies employed by the International Mouse Phenotyping Consortium (IMPC) and the development of new, more efficient genome engineering techniques such as CRISPR based systems. We have previously described the European Mouse Mutant Archive (EMMA) resource and how this international infrastructure provides archiving and distribution worldwide for mutant mouse strains. EMMA has since evolved into INFRAFRONTIER (http://www.infrafrontier.eu), the pan-European research infrastructure for the systemic phenotyping, archiving and distribution of mouse disease models. Here we describe new features including improved search for mouse strains, support for new embryonic stem cell resources, access to training materials via a comprehensive knowledgebase and the promotion of innovative analytical and diagnostic techniques.	archive;clustered regularly interspaced short palindromic repeats;emma;embryonic stem cells;high-throughput computing;international mouse phenotyping consortium;knowledge bases;knowledge base;laboratory mice;therapeutic procedure;throughput	INFRAFRONTIER Consortium	2015		10.1093/nar/gku1193	biology;the internet;biotechnology;bioinformatics;phenotype;genetics;embryonic stem cell	OS	-1.4017855473267584	-61.564642056797666	115493
1e7ef9ac40f16b22e523f076478486f4659b5651	babel's tower revisited: a universal resource for cross-referencing across annotation databases	software;database management systems;databases genetic;eukaryotic promoter database;user computer interface;information storage and retrieval;documentation;gene ontology	MOTIVATION Annotation databases are widely used as public repositories of biological knowledge. However, most of these resources have been developed by independent groups which used different designs and different identifiers for the same biological entities. As we show in this article, incoherent name spaces between various databases represent a serious impediment to using the existing annotations at their full potential. Navigating between various such name spaces by mapping IDs from one database to another is a very important issue which is not properly addressed at the moment.   RESULTS We have developed a web-based resource, Onto-Translate (OT), which effectively addresses this problem. OT is able to map onto each other different types of biological entities from the following annotation databases: Swiss-Prot, TrEMBL, NREF, PIR, Gene Ontology, KEGG, Entrez Gene, GenBank, GenPept, IMAGE, RefSeq, UniGene, OMIM, PDB, Eukaryotic Promoter Database, HUGO Gene Nomenclature Committee and NetAffx. Currently, OT is able to perform 462 types of mappings between 29 different types of IDs from 17 databases concerning 53 organisms. Among these, over 300 types of translations and 15 types of IDs are not currently supported by any other tool or resource. On average, OT is able to correctly map between 96 and 99% of the biological entities provided as input. In terms of speed, sets of approximately 20 000 IDs can be translated in <30 s, in most cases.   AVAILABILITY OT is a part of Onto-Tools, which is freely available at http://vortex.cs.wayne.edu/Projects.html	addresses (publication format);annotation;coherence (physics);cross-reference;databases;entity;entrez;genbank;gene nomenclature;gene ontology;hgnc;identifier;image;kegg;language translations;ninety nine;online mendelian inheritance in man;protein data bank;protein information resource;published database;refseq;rodent nomenclature name;swiss-model;software repository;switzerland;unigene (experimental system);uniprot;web application	Sorin Draghici;Sivakumar Sellamuthu;Purvesh Khatri	2006	Bioinformatics	10.1093/bioinformatics/btl372	documentation;computer science;bioinformatics;data mining;world wide web	Comp.	-2.6050457244639107	-61.18909443835244	115635
108f1a68381ad619460aefe2f2bcddc67e0637c5	chemical markup, xml, and the world wide web. 6. cmlreact, an xml vocabulary for chemical reactions		A set of components (CMLReact) for managing chemical and biochemical reactions has been added to CML. These can be combined to support most of the strategies for the formal representation of reactions. The elements, attributes, and types are formally defined as XMLSchema components, and their semantics are developed. New syntax and semantics in CML are reported and illustrated with 10 examples.	biochemical reaction;current-mode logic;myeloid leukemia, chronic;vocabulary;world wide web;xml	Gemma L. Holliday;Peter Murray-Rust;Henry S. Rzepa	2006	Journal of chemical information and modeling	10.1021/ci0502698	computer science;database;programming language;information retrieval	Web+IR	-4.365508075663525	-64.23630171391547	115669
ee8860df9220d47b0a9b52663254c75ea36f0b85	enhanced reference guided assembly	dna;organisms;genomics;enhanced reference guided assembly;de novo assembly;ngs reference assembly de novo assembly;assembly;artificial neural networks;pipelines;molecular biophysics;assembly artificial neural networks bioinformatics genomics organisms pipelines next generation networking;reference assembly;ngs;de novo assembly enhanced reference guided assembly next generation sequencing genomics;next generation sequencing;next generation networking;molecular biophysics dna genomics;bioinformatics	Next Generation Sequencing has totally changed genomics: we are able to produce huge amounts of data at an incredible low cost if compared to Sanger sequencing. Despite this some old problems have become even more difficult, denovo assembly being on top of this list. In this paper we propose a novel method that aims at improving de-novo assembly in presence of a closely related reference. The idea is to combine de-novo assembly and reference guided assembly in order to obtain an enhanced assembly.		Federica Cattonaro;Alberto Policriti;Francesco Vezzi	2010	2010 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2010.5706540	biology;organism;dna sequencing;genomics;bioinformatics;assembly;pipeline transport;sequence assembly;genetics;dna;molecular biophysics	Robotics	-0.3202725053745747	-54.40522908115302	115752
bf2988051da478aab9304bad077b274630a60010	using expert knowledge in initialization for genome-wide analysis of epistasis using genetic programming	genetic analysis;genetic program;human disease;genetic programming;machine learning;human genome;expert knowledge;human genetics;dna sequence;ge netic programming;initialization;biological network	In human genetics it is now possible to measure large numbers of DNA sequence variations across the human genome. Given current knowledge about biological networks and disease processes it seems likely that disease risk can best be modeled by interactions between biological components, which may be examined as interacting DNA sequence variations. The machine learning challenge is to e.ectively explore interactions in these datasets to identify combinations of variations which are predictive of common human diseases. Genetic programming is a promising approach to this problem. The goal of this study is to examine the role that an expert knowledge aware initializer can play in the framework of genetic programming. We show that this expert knowledge aware initializer outperforms both a random initializer and an enumerative initializer.	genetic programming;initialization (programming);interaction;machine learning	Casey S. Greene;Bill C. White;Jason H. Moore	2008		10.1145/1389095.1389158	genetic programming;initialization;dna sequencing;biological network;human genome;computer science;bioinformatics;artificial intelligence;machine learning;genetic analysis;human genetics	ML	4.904193740103791	-58.291812893889755	115769
8170defb7a748f9e3dc761a393e9540365dd7c33	rohlin distance and the evolution of influenza a virus: weak attractors and precursors	evolution molecular;engineering;influenza a virus h3n2 subtype;hemagglutinin glycoproteins influenza virus;public library of science;sequence analysis dna;biology;physics;dna viral;models genetic;time factors;cluster analysis;influenza a virus;open access;chemistry;inclusive;ante disciplinary;models statistical;algorithms;medicine;influenza a virus h1n1 subtype;plos;computational biology;computer simulation;mutation	"""The evolution of the hemagglutinin amino acids sequences of Influenza A virus is studied by a method based on an informational metrics, originally introduced by Rohlin for partitions in abstract probability spaces. This metrics does not require any previous functional or syntactic knowledge about the sequences and it is sensitive to the correlated variations in the characters disposition. Its efficiency is improved by algorithmic tools, designed to enhance the detection of the novelty and to reduce the noise of useless mutations. We focus on the USA data from 1993/94 to 2010/2011 for A/H3N2 and on USA data from 2006/07 to 2010/2011 for A/H1N1. We show that the clusterization of the distance matrix gives strong evidence to a structure of domains in the sequence space, acting as weak attractors for the evolution, in very good agreement with the epidemiological history of the virus. The structure proves very robust with respect to the variations of the clusterization parameters, and extremely coherent when restricting the observation window. The results suggest an efficient strategy in the vaccine forecast, based on the presence of """"precursors"""" (or """"buds"""") populating the most recent attractor."""	algorithm;amino acids;biological evolution;coherence (physics);distance matrix;epidemiology;influenza a virus;moloney murine sarcoma virus;personality character;point accepted mutation;population;projections and predictions;informational	Raffaella Burioni;Riccardo Scalco;Mario Casartelli	2011		10.1371/journal.pone.0027924	computer simulation;mutation;biology;bioinformatics;virology;cluster analysis;genetics	Theory	3.5015956378735718	-61.925785403233604	115802
5fa1ee80ff277bd0b7834f1902352990404e6b0e	morphogenesis model for systematic simulation of forms' co-evolution with constraints: application to mitosis		We present a new approach to understand forms’ emergence in a cellular system. We set the hypothesis that beyond the influence of mechanical forces and gene expression, constraints applied to the cells over time play a key role in the acquisition of specific shape. We consider that these constraints are the fundamental principles and basic cause of morphogenesis. In our model, it’s due to these constraints that cells choose a particular direction while dividing, migrate or die. Our approach of morphogenesis based on constraints has been used to get effectively for a given form all possible evolutions by growth at latter times. Such work ensures to do some pattern prediction.	die (integrated circuit);emergence;simulation	Abdoulaye Sarr;Alexandra Fronville;Vincent Rodin	2014		10.1007/978-3-319-13749-0_20	biology;cell biology;anatomy	Comp.	6.144758300376631	-65.8480049599987	115863
c96f4243d7614781d2f043e2d390acbb8b35b355	methodologies for systems medicine: time to join the forces of bioengineering and bioinformatics.				Pietro Liò	2013			computational biology;computer science;bioinformatics	DB	1.0067541082842253	-64.23218767016463	115914
6dd1ec5e548b5f0e068a6be3b2135a51e0d85dac	determining sample size for cross-over designs with multiple groups		In clinical research, determining sample size plays an important role. A cross-over design (CD) is widely used to compare multiple groups in order to verify the statistical significance of mean difference among multiple groups, because it has an advantage of removing any factors caused by subject variability. When multi-omics data such as metabolomics data is analysed, we often adopt CD to identify biomarkers that have group effects. While some methods exist for determining the sample size when comparing two groups, no available method allows comparison of more than two treatment groups. In this research, we propose a novel method for determining the sample size of CD with multiple treatment groups. We first propose a method for testing single biomarkers and then a method for a large number of biomarkers while controlling the false discovery rate or the family wise error rate.		Yongjun Jo;Hyojin Lee;Oran Kwon;Taesung Park	2018	IJDMB	10.1504/IJDMB.2018.10013379	false discovery rate;statistics;artificial intelligence;machine learning;computer science;sample size determination;mixed model;bonferroni correction;clinical research;mean difference;statistical significance;treatment and control groups	HCI	6.264788402358191	-52.60166707282616	116018
e1ca660938b6d5466f4f71f682ce063bf5fc5d9e	pysubsim-tree: a package for simulating tumor genomes according to tumor evolution history	tumor subclonal population;tumor genome simulation	Next-generation sequencing (NGS) and the third generation sequencing (TGS) have recently allowed us to develop algorithms to quantitatively dissect the extent of heterogeneity within a tumour, resolve cancer evolution history and identify the somatic variations and aneuploidy events. Simulation of tumor NGS and TGS data serves as a powerful and cost-effective approach for benchmarking these algorithms, however, there is no available tool that could simulate all the distinct subclonal genomes with diverse aneuploidy events and somatic variations according to the given tumor evolution history. We provide a simulation package, Pysubsim-tree, which could simulate the tumor genomes according to their evolution history defined by the somatic variations and aneuploidy events. Pysubsim-tree is free, open source, available at: https://github.com/dustincys/pysubsimtree	algorithm;communications satellite;evolution;open-source software;simulation;the great giana sisters	Yan-Shuo Chu;Ling Wang;Rongjie Wang;Mingxiang Teng;Yadong Wang	2017	2017 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2017.8217998	computer science;bioinformatics;genomics;aneuploidy;genome;somatic cell	Visualization	-1.7637245248631246	-56.42746034724473	116055
66e3b3c25ca74916d4085c3dcf56bb0add937c07	principles of chip-seq data analysis illustrated with examples	dnase i hypersensitive sites;chip seq;transcription factor binding sites;histone marks;bioinformatics analysis	Chromatin immunoprecipitation (ChIP) followed by high-throughput sequencing (ChIP-seq) is a powerful method to determine how transcription factors and other chromatin-associated proteins interact with DNA in order to regulate gene transcription. A single ChIPseq experiment produces large amounts of highly reproducible data. The challenge is to extract knowledge from the data by thoughtful application of appropriate bioinformatics tools. Here we present a concise introduction into ChIP-seq data analysis in the form of a tutorial based on tools developed by our group. We expose biological questions, explain methods and provide guidelines for the interpretation of the results. While this article focuses on ChIP-seq, most of the algorithms and tools we present are applicable to other chromatin profiling assays based on next generation sequencing (NGS) technology as well. AVAILABILITY AND REQUIREMENTS  Project name: ChIP-Seq  Project home page: http://ccg.vital-it.ch/chipseq/  Operating systems: Unix  Programming language: C, Perl  Main dependencies: None  License: GNU GPL v2	algorithm;bioinformatics;communications satellite;next-generation network;transcription (software)	Giovanna Ambrosini;René Dreos;Philipp Bucher	2014			biology;molecular biology;bioinformatics;genetics;chip-sequencing	Comp.	-1.758604625863023	-57.88526559108542	116077
32027d8d538df82183f4ea7cfae0379162a84547	genotype phenotype mapping in rna viruses - disjunctive normal form learning	disjunctive normal form	RNA virus phenotypic changes often result from multiple alternative molecular mechanisms, where each mechanism involves changes to a small number of key residues. Accordingly, we propose to learn genotype-phenotype functions, using Disjunctive Normal Form (DNF) as the assumed functional form. In this study we develop DNF learning algorithms that attempt to construct predictors as Boolean combinations of covariates. We demonstrate the learning algorithm's consistency and efficiency on simulated sequences, and establish their biological relevance using a variety of real RNA virus datasets representing different viral phenotypes, including drug resistance, antigenicity, and pathogenicity. We compare our algorithms with previously published machine learning algorithms in terms of prediction quality: leave-one-out performance shows superior accuracy to other machine learning algorithms on the HIV drug resistance dataset and the UCIs promoter gene dataset. The algorithms are powerful in inferring the genotype-phenotype mapping from a moderate number of labeled sequences, as are typically produced in mutagenesis experiments. They can also greedily learn DNFs from large datasets. The Java implementation of our algorithms will be made publicly available.	assumed;boolean;decision problem;disjunctive normal form;experiment;genotype;greater than;heuristic;heuristics;high-throughput computing;higher-order function;inference;java programming language;kelly criterion;learnability;machine learning;moloney murine sarcoma virus;murine sarcoma viruses;np-completeness;performance;phenotype;relevance;scientific publication;short;signal-to-noise ratio;silo (dataset);statistical model;ted;throughput;tracer;turing completeness;version;explanation	Chuang Wu;Andrew S. Walsh;Ronald Rosenfeld	2011	Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing		rna;genetics;phenotype;disjunctive normal form;moderate number;small number;rna virus;genotype;mathematics;java	Comp.	2.4219641097613263	-52.37353643248724	116080
0453e3751ec87dda96d4db2149f3c1ab2ce7aa03	open science and accelerating discovery in rare and neglected diseases				Rachel J. Harding	2017		10.3233/978-1-61499-769-6-1	world wide web;computer science;computational biology;open science;bioinformatics	Crypto	-4.124692642886928	-61.38346620850693	116238
44e1afda0435c3eba281fa9d65f811319513beb5	corbi: a new r package for biological network alignment and querying	health research;uk clinical guidelines;biological patents;simulation and modeling;europe pubmed central;systems biology;citation search;physiological cellular and medical topics;computational biology bioinformatics;uk phd theses thesis;life sciences;algorithms;uk research reports;medical journals;europe pmc;biomedical research;bioinformatics	In the last decade, plenty of biological networks are built from the large scale experimental data produced by the rapidly developing high-throughput techniques as well as literature and other sources. But the huge amount of network data have not been fully utilized due to the limited biological network analysis tools. As a basic and essential bioinformatics method, biological network alignment and querying have been applied in many fields such as predicting new protein-protein interactions (PPI). Although many algorithms were published, the network alignment and querying problems are not solved satisfactorily. In this paper, we extended CNetQ, a novel network querying method based on the conditional random fields model, to solve network alignment problem, by adopting an iterative bi-directional mapping strategy. The new method, called CNetA, was compared with other four methods on fifty simulated and three real PPI network alignment instances by using four structural and five biological measures. The computational experiments on the simulated data, which were generated from a biological network evolutionary model to validate the effectiveness of network alignment methods, show that CNetA gets the best accuracy in terms of both nodes and networks. For the real data, larger biological conserved subnetworks and larger connected subnetworks were identified, compared with the structural-dominated methods and the biological-dominated methods, respectively, which suggests that CNetA can better balances the biological and structural similarities. Further, CNetQ and CNetA have been implemented in a new R package Corbi ( http://doc.aporc.org/wiki/Corbi ), and freely accessible and easy used web services for CNetQ and CNetA have also been constructed based on the R package. The simulated and real datasets used in this paper are available for downloading at http://doc.aporc.org/wiki/CNetA/	algorithm;alignment;bi-directional text;bioinformatics;biological network;computation;conditional random field;download;experiment;high-throughput computing;interaction;iterative method;large;models of dna evolution;pixel density;proton pump inhibitors;r language;scientific publication;throughput;web service;wiki	Qiang Huang;Ling-Yun Wu;Xiang-Sun Zhang	2013		10.1186/1752-0509-7-S2-S6	biology;medical research;computer science;bioinformatics;data science;data mining;systems biology	Comp.	4.429021647217119	-56.162040708792304	116329
ec0ef5da7c0224b0c996d6aedb08a6c521f091bd	identification of metabolic units induced by environmental signals	saccharomyces cerevisiae;metabolic network;environmental conditions;random networks;environmental change;structured data	MOTIVATION Biological cells continually need to adapt the activity levels of metabolic functions to changes in their living environment. Although genome-wide transcriptional data have been gathered in a large variety of environmental conditions, the connections between the expression response to external changes and the induction or repression of specific metabolic functions have not been investigated at the genome scale.   RESULTS We present here a correlation-based analysis for identifying the expression response of genes involved in metabolism to specific external signals, and apply it to analyze the transcriptional response of Saccharomyces cerevisiae to different stress conditions. We show that this approach leads to new insights about the specificity of the genomic response to given environmental changes, and allows us to identify genes that are particularly sensitive to a unique condition. We then integrate these signal-induced expression data with structural data of the yeast metabolic network and analyze the topological properties of the induced or repressed subnetworks. They reveal significant discrepancies from random networks, and in particular exhibit a high connectivity, allowing them to be mapped back to complete metabolic routes.	activity recognition;flow network;mathematical induction;metabolic process, cellular;repression, psychology;sensitivity and specificity;transcription, genetic	Jose C. Nacher;Jean-Marc Schwartz;Minoru Kanehisa;Tatsuya Akutsu	2006	Bioinformatics	10.1093/bioinformatics/btl202	biology;environmental change;data model;bioinformatics;genetics;metabolic network	Comp.	5.381726993497816	-59.13916701569966	116338
9dd29aea30566786d03dda1c2a0dd3ed6e575d98	pancake: a data structure for pangenomes	004;pangenome data structure core genome comparative genomics	We present a pangenome data structure (“PanCake”) for sets of related genomes, based on bundling similar sequence regions into shared features, which are derived from genome-wide pairwise sequence alignments. We discuss the design of the data structure, basic operations on it and methods to predict core genomes and singleton regions. In contrast to many other pangenome analysis tools, like EDGAR or PGAT, PanCake is independent of gene annotations. Nevertheless, comparison of identified core and singleton regions shows good agreements. The PanCake data structure requires significantly less space than the sum of individual sequence files. 1998 ACM Subject Classification E.2 Data Storage Representations, J.3 Life and Medical Sciences	data structure;sequence alignment	Corinna Ernst;Sven Rahmann	2013		10.4230/OASIcs.GCB.2013.35	biology;bioinformatics;data mining;world wide web	Comp.	0.2282185301397511	-58.61323691247029	116431
62b420ebf4a5ca71c532ece021d48dfcdf026ad2	2db: a proteomics database for storage, analysis, presentation, and retrieval of information from mass spectrometric experiments	animals;software tool;data compression;user interface;database management systems;research design;mass spectrometry;heterogeneous data;automatic generation;computational biology bioinformatics;hot spot;multi dimensional;data analysis;tandem mass spectrometry;graphic user interface;abstracting and indexing as topic;artificial intelligence;algorithms;humans;computer analysis;data handling;user computer interface;information need;combinatorial libraries;proteomics;computer appl in life sciences;mass spectrometric;databases protein;microarrays;bioinformatics;peptide mapping	The amount of information stemming from proteomics experiments involving (multi dimensional) separation techniques, mass spectrometric analysis, and computational analysis is ever-increasing. Data from such an experimental workflow needs to be captured, related and analyzed. Biological experiments within this scope produce heterogenic data ranging from pictures of one or two-dimensional protein maps and spectra recorded by tandem mass spectrometry to text-based identifications made by algorithms which analyze these spectra. Additionally, peptide and corresponding protein information needs to be displayed. In order to handle the large amount of data from computational processing of mass spectrometric experiments, automatic import scripts are available and the necessity for manual input to the database has been minimized. Information is in a generic format which abstracts from specific software tools typically used in such an experimental workflow. The software is therefore capable of storing and cross analysing results from many algorithms. A novel feature and a focus of this database is to facilitate protein identification by using peptides identified from mass spectrometry and link this information directly to respective protein maps. Additionally, our application employs spectral counting for quantitative presentation of the data. All information can be linked to hot spots on images to place the results into an experimental context. A summary of identified proteins, containing all relevant information per hot spot, is automatically generated, usually upon either a change in the underlying protein models or due to newly imported identifications. The supporting information for this report can be accessed in multiple ways using the user interface provided by the application. We present a proteomics database which aims to greatly reduce evaluation time of results from mass spectrometric experiments and enhance result quality by allowing consistent data handling. Import functionality, automatic protein detection, and summary creation act together to facilitate data analysis. In addition, supporting information for these findings is readily accessible via the graphical user interface provided. The database schema and the implementation, which can easily be installed on virtually any server, can be downloaded in the form of a compressed file from our project webpage.	abstract summary;database schema;electronic supplementary materials;exanthema;experiment;generic drugs;graphical user interface;handling (psychology);information needs;map;numerous;proteomics;server (computing);stemming;tandem mass spectrometry;text-based (computing);user interface device component;web page;algorithm	Jens Allmer;Sebastian Kuhlgert;Michael Hippler	2008	BMC Bioinformatics	10.1186/1471-2105-9-302	data compression;tandem mass spectrometry;information needs;dna microarray;mass spectrometry;computer science;bioinformatics;data science;group method of data handling;graphical user interface;proteomics;data analysis;user interface;hot spot;information retrieval	Comp.	-3.5742392192369588	-58.97472530047646	116450
b7977935481ef2e11fcbe28e9c67225eb73fd011	ontology challenges for the stem cell community: towards integrative data mining in the stemformatics atlas.		Stemformatics (www.stemformatics.org) is a web-based pocket dictionary targeted to stem cell biologists with limited knowledge in bioinformatics. It holds a growing collection of manually-curated and high-quality public stem cell datasets. It allows easy visualisation and comparison of gene expression profiles across different platforms from different laboratory sources in mouse and human. Stemformatics hosts >344 public datasets, with >7060 human and >1853 mouse samples. We have a large set of curated data, primarily transcriptome, including microarray and RNAseq, as well as unconventional “omics” platforms such as ChIPSeq, miRNA, proteomics, and metabolomics data. Stem cell metadata fall into two broad categories – (1) the description of endogenous stem cells, isolated using cell surface proteins and characterised on their originating tissue or developmental stage. (2) in vitro derived cells, including a variety of reprogrammed, as well as directed differentiation protocols aimed at recapitulating a specific class of cell. Here, we review the challenges of adapting ontology standards to fit a stem cell framework and implementation in Stemformatics. Our aim is to develop a stem cell ontology that can describe different cell types and provide information of their biological background. Stemformatics has started to standardize specific naming conventions to differentiate several cell types. Building a dictionary of stem cell types and their integration into existing ontology resources will be included in the near future. Annotation of samples metadata is a difficult task when it involves description of synthetic cells whose provenance is hard to capture using existing anatomical ontologies. Induced pluripotent stem cells do not have a developmental equivalent, because these are artificially transformed from mature cell types, such as a skin or blood biopsy. Equally problematic is the description of samples in intermediate states (mid-reprogramming, or middifferentiation) as these include cell states that have not been defined before and do not have a developmental or anatomical equivalent. Our ontologies must capture information about the source, manipulation, characterisation of the starting materials, as well as any transformation to a new cell type in the laboratory. Stemformatics hosts a large amount of primary data, which leads to challenges in data aggregation and downstream analysis if sample annotations are not well standardised. Dealing with several related cell types and cell lines increases the complexity of this problem. Historically, we have had several annotators with different backgrounds who have inadvertently introduced inconsistencies because of a lack of standardised ontology, the rapid pace of change in the field, and a lack of appropriate resources to cross check new samples against existing ontologies. Large-scale gene expression profiling approaches are used by the stem cell community to for the purposes of bench-marking cell types, defining stem cell states, and characterising molecular networks including predictions of cell-cell and molecular relationships. Deep mining of Stemformatics datasets have facilitated the identification of novel cell types, resolved questions about phenotype similarities between stromal subpopulations, and identified genes involved in maintenance of pluripotency and the differentiation to embryonic lineages. Stemformatics facilitates data visualisation including interactive graphs like Yugene, where the ranking of all samples can be visualised across a single gene. Furthermore, the Rohart Mesenchymal Stromal Cells (MSC) test is an example of using well-curated data and metadata to create an algorithm to classify stem cells behaving like MSCs. * To whom correspondence should be addressed: chris.pacheco@unimelb.edu.au	algorithm;bioinformatics;data aggregation;data mining;data visualization;dictionary;downstream (software development);gene expression profiling;item unique identification;metabolomics;microarray;omics;ontology (information science);proteomics;synthetic intelligence;web application	Chris Pacheco Rivera;Rowland Mosbergen;Othmar Korn;Tyrone Chen;Isha Nagpal;Christine A. Wells	2017			stem cell;ontology;bioinformatics;computer science	ML	-0.8633362970890973	-62.31641556549412	116484
24e983f8dc3648a3b4a84f32f489852d7980c11e	analysis of the attachment of replicating dna to a nuclear matrix in mammalian interphase nuclei	dna;animals;nuclear matrix;liver;deoxyribonucleases;aspergillus nuclease s1;cell nucleus;dna replication;nuclease;digestion;cells cultured;molecular weight;cattle;cell cycle;interphase;dna replication fork;mammals	The attachment of replicating DNA to a rapidly sedimenting nuclear structure was investigated by digestion with various nucleases. When DNA was gradually removed by DNase I, pulse label incorporated during either 1 min or during 1 hour in the presence of arabinosylcytosine, remained preferentially attached to the nuclear structure. Single strand specific digestion by nuclease S1 or staphylococcal nuclease at low concentrations caused a release of about 30% of the pulse label, without significantly affecting the attachment of randomly labelled DNA. The released material had a low sedimentation coefficient and contained most of the Okasaki fragments. The remaining pulse label was less accessible to further digestion by double strand specific nuclease activity than the bulk DNA. The results suggest that an attachment of the replication fork to the nuclear structure occurs at sites behind but close to the branch point.	attachments;coefficient;contain (action);cytarabine;deoxyribonuclease i;interphase;mammals;maxima and minima;micrococcal nuclease;nuclear matrix;nuclear structure;protein digestion (research activity);randomness;strand (programming language);nuclease activity;replication fork	P. A. Dijkwel;L. H. Mullenders;F. Wanka	1979	Nucleic acids research	10.1093/nar/6.1.219	biology;molecular biology;digestion;interphase;virology;cell cycle;dna replication;molecular mass;genetics;dna;nuclear matrix	ECom	5.200552005364945	-63.80799651435511	116509
fe113082992bab2ee81be0d43669bdfcd44617a2	ferret: a sentence-based literature scanning system	health research;uk clinical guidelines;biological patents;oafund;europe pubmed central;scientific workflow;citation search;computational biology bioinformatics;gene centric relationships;uk phd theses thesis;sentence retrieval;text retrieval;life sciences;algorithms;uk research reports;medical journals;computer appl in life sciences;sentence ranking;europe pmc;biomedical research;microarrays;bioinformatics	The rapid pace of bioscience research makes it very challenging to track relevant articles in one’s area of interest. MEDLINE, a primary source for biomedical literature, offers access to more than 20 million citations with three-quarters of a million new ones added each year. Thus it is not surprising to see active research in building new document retrieval and sentence retrieval systems. We present Ferret, a prototype retrieval system, designed to retrieve and rank sentences (and their documents) conveying gene-centric relationships of interest to a scientist. The prototype has several features. For example, it is designed to handle gene name ambiguity and perform query expansion. Inputs can be a list of genes with an optional list of keywords. Sentences are retrieved across species but the species discussed in the records are identified. Results are presented in the form of a heat map and sentences corresponding to specific cells of the heat map may be selected for display. Ferret is designed to assist bio scientists at different stages of research from early idea exploration to advanced analysis of results from bench experiments. Three live case studies in the field of plant biology are presented related to Arabidopsis thaliana. The first is to discover genes that may relate to the phenotype of open immature flower in Arabidopsis. The second case is about finding associations reported between ethylene signaling and a set of 300+ Arabidopsis genes. The third case is on searching for potential gene targets of an Arabidopsis transcription factor hypothesized to be involved in plant stress responses. Ferret was successful in finding valuable information in all three cases. In the first case the bZIP family of genes was identified. In the second case sentences indicating relevant associations were found in other species such as potato and jasmine. In the third sentences led to new research questions about the plant hormone salicylic acid. Ferret successfully retrieved relevant gene-centric sentences from PubMed records. The three case studies demonstrate end user satisfaction with the system.	british informatics olympiad;computer user satisfaction;document retrieval;ethylene;experiment;ferret brand of ferrous fumarate;ferrets;gonadorelin;heat map;jasmine;medline;mental association;primary source;prototype;pubmed;query expansion;question (inquiry);salicylic acid;transcription factor;transcription (software);bzip2;citation;sentence	Padmini Srinivasan;Xiao-Ning Zhang;Roxane Bouten;Caren Chang	2015		10.1186/s12859-015-0630-0	biology;dna microarray;computer science;bioinformatics;data science;data mining;information retrieval;algorithm	Comp.	-1.8258822746929304	-63.37567014195631	116536
d8161f24423f7bb8f5b89c20c5a12b5f8f91ba72	functional association networks as priors for gene regulatory network inference	biokemi med inriktning mot bioinformatik;saccharomyces cerevisiae;gene regulatory networks;bioinformatik berakningsbiologi;biochemistry towards bioinformatics;biologiska vetenskaper;biological sciences;biochemistry and molecular biology;gene expression profiling;bioinformatics computational biology;biokemi och molekylarbiologi	MOTIVATION Gene regulatory network (GRN) inference reveals the influences genes have on one another in cellular regulatory systems. If the experimental data are inadequate for reliable inference of the network, informative priors have been shown to improve the accuracy of inferences.   RESULTS This study explores the potential of undirected, confidence-weighted networks, such as those in functional association databases, as a prior source for GRN inference. Such networks often erroneously indicate symmetric interaction between genes and may contain mostly correlation-based interaction information. Despite these drawbacks, our testing on synthetic datasets indicates that even noisy priors reflect some causal information that can improve GRN inference accuracy. Our analysis on yeast data indicates that using the functional association databases FunCoup and STRING as priors can give a small improvement in GRN inference accuracy with biological data.	causal filter;databases;gene regulatory network;graph (discrete mathematics);inference;information theory;interaction information;published database;string;synthetic intelligence;weighted network	Matthew Studham;Andreas Tjärnberg;Torbjörn E. M. Nordling;Sven Nelander;Erik L. L. Sonnhammer	2014		10.1093/bioinformatics/btu285	computational biology;biology;gene regulatory network;bioinformatics;gene expression profiling;genetics	Comp.	5.3012279202052115	-56.044590657311865	116623
e9fa54ddb0c3888fd228d5e6a54d5c98c9f727fc	a comparison of periodicity profile methods for sequence analysis	genes;subspace decomposition;synthetic sequence;period detections;keywords biological sequence data;molecular configurations bioinformatics biological techniques dna molecular biophysics;conference paper;periodicity profile period estimation sequence analysis;signal processing;periodicity profile;sequence analysis;relative strength;estimation period estimation;p falciparum periodicity profile method comparison sequence analysis period detection biological sequence data exploratory period estimation integer period scale dominant period identification period resolution computational complexity synthetic sequences periodic subspace decomposition hybrid autocorrelation ipdft method dna sequence fragment;period estimation	While period detection in biological sequence data has received considerable attention, it is unclear which methods may be best suited to the problem of exploratory period estimation, where the objective is to compare the relative strengths of many periods on a linear-period scale. This paper compares several promising methods for period estimation on an integer-period scale in terms of attributes such as correct identification of dominant periods, period resolution and computational complexity, using synthetic sequences. Different methods reveal very different periodicity profiles, however the exactly periodic subspace decomposition and hybrid autocorrelation-IPDFT methods seem to provide good performance with respect to the above attributes. Finally, the methods are compared for a challenging DNA sequence fragment, from P.falciparum.	autocorrelation;computational complexity theory;quasiperiodicity;sequence analysis;synthetic intelligence	Manas Bellani;Julien Epps;Gavin A. Huttley	2012	Proceedings 2012 IEEE International Workshop on Genomic Signal Processing and Statistics (GENSIPS)	10.1109/GENSIPS.2012.6507731	biology;bioinformatics;sequence analysis;signal processing;gene;relative strength index;genetics;statistics	Vision	2.9980062362945814	-54.885671037935126	116646
cdb73cdc1818a47808858ad21c5279eacfd9c681	network-based target ranking for polypharmacological therapies	drug discovery;target ranking;network based bioinformatics;polypharmacology;ppi network	"""With the growing understanding of complex diseases, the focus of drug discovery has shifted from the well-accepted """"one target, one drug"""" model, to a new """"multi-target, multi-drug"""" model, aimed at systemically modulating multiple targets. In this context, polypharmacology has emerged as a new paradigm to overcome the recent decline in productivity of pharmaceutical research. However, finding methods to evaluate multicomponent therapeutics and ranking synergistic agent combinations is still a demanding task. At the same time, the data gathered on complex diseases has been progressively collected in public data and knowledge repositories, such as protein-protein interaction (PPI) databases. The PPI networks are increasingly used as universal platforms for data integration and analysis. A novel computational network-based approach for feasible and efficient identification of multicomponent synergistic agents is proposed in this paper. Given a complex disease, the method exploits the topological features of the related PPI network to identify possible combinations of hit targets. The best ranked combinations are subsequently computed on the basis of a synergistic score. We illustrate the potential of the method through a study on Type 2 Diabetes Mellitus. The results highlight its ability to retrieve novel target candidates, which role is also confirmed by the analysis of the related literature."""		Francesca Vitali;Francesca Mulas;Pietro Marini;Riccardo Bellazzi	2013	Journal of biomedical informatics	10.1016/j.jbi.2013.06.015	bioinformatics;data science;data mining;drug discovery	ML	6.5505270475516095	-57.175242857055075	116658
74b65276d2b0e482e7fb1df6e62aaa588573d180	rtpdb: a database providing associations between genetic variation or expression and cancer prognosis with radiotherapy-based treatment		In recent years, lots of studies have reported the relationship between genetic variation or expression and cancer prognosis with radiotherapy-based treatment. However, due to limitation in available journals or literature database, inconsistent nomenclature system of genetic variation and cancer and time-consuming investigation on literature searching and reading, considerable researches could hardly get found and cited. In this study, we constructed the Radiotherapy Prognosis Database (RTPDB), which contains a comprehensive resource about genes and related cancer prognosis. It included 775 studies, which consist of 275 Single Nucleotide Polymorphism (SNP) studies with 59 765 patients, 261 genes, 708 SNPs, 16 tumors and 16 treatment types, and 500 expression studies with 55 751 patients, 264 genes, 27 tumors and 15 treatment types. The names of genes and their variants were converted and displayed in the form of the official symbol. The detailed information of the tumor, treatment and prognosis were classified. We hope RTPDB will be a useful resource with great potential for researches on genes, variants and cancer prognosis.	cancer prognosis;classification;fifty nine;forecast of outcome;journal;mental association;neoplasms;nitroprusside;non-small cell lung carcinoma;patients;prognosis:find:pt:^patient:nom;rodent nomenclature name;single nucleotide polymorphism;variation (genetics)	Cheng-Dong Zhang;Yuan Yang;Huan-huan Chen;Ting Zhang;Qiang Wang;Yuan Liang;Liang Zhang;Yan Zhou	2018		10.1093/database/bay118	cancer;genetic variation;bioinformatics;radiation therapy;computer science	Comp.	-1.8782448490722858	-64.15315247225293	116741
5eaa711dccdc4c6fffa89a6dccf878185ca444bc	genome-wide computational identification of micrornas and their targets in the deep-branching eukaryote giardia lamblia	computer program;gene regulation;utr;computational;cds;est;vsps;giardia lamblia;microrna;expressed sequence tag	Using a combined computational program, we identified 50 potential microRNAs (miRNAs) in Giardia lamblia, one of the most primitive unicellular eukaryotes. These miRNAs are unique to G. lamblia and no homologues have been found in other organisms; miRNAs, currently known in other species, were not found in G. lamblia. This suggests that miRNA biogenesis and miRNA-mediated gene regulation pathway may evolve independently, especially in evolutionarily distant lineages. A majority (43) of the predicted miRNAs are located at one single locus; however, some miRNAs have two or more copies in the genome. Among the 58 miRNA genes, 28 are located in the intergenic regions whereas 30 are present in the anti-sense strands of the protein-coding sequences. Five predicted miRNAs are expressed in G. lamblia trophozoite cells evidenced by expressed sequence tags or RT-PCR. Thirty-seven identified miRNAs may target 50 protein-coding genes, including seven variant-specific surface proteins (VSPs). Our findings provide a clue that miRNA-mediated gene regulation may exist in the early stage of eukaryotic evolution, suggesting that it is an important regulation system ubiquitous in eukaryotes.	copy (object);eukaryotic cells;gene expression regulation;gene regulatory network;giardia lamblia;http 404;locus;limited stage (cancer stage);micrornas;pierre robin syndrome;trophozoite;windows rt	Yan-Qiong Zhang;Dong-Liang Chen;Hai-Feng Tian;Baohong Zhang;Jianfan Wen	2009	Computational biology and chemistry	10.1016/j.compbiolchem.2009.07.013	biology;molecular biology;regulation of gene expression;bioinformatics;computation;credit default swap;untranslated region;genetics;microrna;expressed sequence tag	Comp.	3.02769353723712	-61.17175140081627	116821
42e3a5362791665f671d43787c87afff1269af38	analysis and prediction of single-stranded and double-stranded dna binding proteins based on protein sequences	binding specificity;dsbs (double-stranded dna-binding proteins);protein sequence;ssbs (single-stranded dna-binding proteins)	DNA-binding proteins perform important functions in a great number of biological activities. DNA-binding proteins can interact with ssDNA (single-stranded DNA) or dsDNA (double-stranded DNA), and DNA-binding proteins can be categorized as single-stranded DNA-binding proteins (SSBs) and double-stranded DNA-binding proteins (DSBs). The identification of DNA-binding proteins from amino acid sequences can help to annotate protein functions and understand the binding specificity. In this study, we systematically consider a variety of schemes to represent protein sequences: OAAC (overall amino acid composition) features, dipeptide compositions, PSSM (position-specific scoring matrix profiles) and split amino acid composition (SAA), and then we adopt SVM (support vector machine) and RF (random forest) classification model to distinguish SSBs from DSBs. Our results suggest that some sequence features can significantly differentiate DSBs and SSBs. Evaluated by 10 fold cross-validation on the benchmark datasets, our prediction method can achieve the accuracy of 88.7% and AUC (area under the curve) of 0.919. Moreover, our method has good performance in independent testing. Using various sequence-derived features, a novel method is proposed to distinguish DSBs and SSBs accurately. The method also explores novel features, which could be helpful to discover the binding specificity of DNA-binding proteins.	amino acid metabolism, inborn errors;amino acid sequence;amino acids;area under curve;benchmark (computing);categorization;cross reactions;cross-validation (statistics);dna breaks, single-stranded;dna binding site;dna, single-stranded;dipeptides;position weight matrix;pseudo amino acid composition;radio frequency;random forest;score;sensitivity and specificity;support vector machine;synapomorphy	Wei Wang;Lin Yan Sun;Shiguang Zhang;Hongjun Zhang;Jinling Shi;Tianhe Xu;Keliang Li	2017		10.1186/s12859-017-1715-8	genetics;dna;dna microarray;protein sequencing;biology;amino acid;double-stranded dna binding;dipeptide;bioinformatics;binding selectivity	Comp.	9.125656248981521	-56.116309019488185	116868
7e24d9bcd51e7e548234adc690df153e180c8f60	patrocles: a database of polymorphic mirna-mediated gene regulation in vertebrates	software;quantitative trait loci;animals;mice;databases nucleic acid;gene regulation;database;databases genetic;contextual information;copy number;internet;protein structure tertiary;purifying selection;polymorphism;mirna;gene expression regulation;gene silencing;gene;regulation;patrocles;humans;computational biology;dna sequence;polymorphic;micrornas;information storage and retrieval;polymorphism single nucleotide;single nucleotide polymorphism	The Patrocles database (http://www.patrocles.org/) compiles DNA sequence polymorphisms (DSPs) that are predicted to perturb miRNA-mediated gene regulation. Distinctive features include: (i) the coverage of seven vertebrate species in its present release, aiming for more when information becomes available, (ii) the coverage of the three compartments involved in the silencing process (i.e. targets, miRNA precursors and silencing machinery), (iii) contextual information that enables users to prioritize candidate 'Patrocles DSPs', including graphical information on miRNA-target coexpression and eQTL effect of genotype on target expression levels, (iv) the inclusion of Copy Number Variants and eQTL information that affect miRNA precursors as well as genes encoding components of the silencing machinery and (v) a tool (Patrocles finder) that allows the user to determine whether her favorite DSP may perturb miRNA-mediated gene regulation of custom target sequences. To support the biological relevance of Patrocles' content, we searched for signatures of selection acting on 'Patrocles single nucleotide polymorphisms (pSNPs)' in human and mice. As expected, we found a strong signature of purifying selection against not only SNPs that destroy conserved target sites but also against SNPs that create novel, illegitimate target sites, which is reminiscent of the Texel mutation in sheep.	anatomical compartments;antivirus software;digital signal processor;emoticon;expression quantitative trait locus;gene expression regulation;genetic polymorphism;graphical user interface;low-copy repeats;micrornas;mutation;nucleotides;purification of quantum state;relevance;search - action;single nucleotide polymorphism;single-chain antibodies;vertebrates	Samuel Hiard;Carole Charlier;Wouter Coppieters;Michel Georges;Denis Baurain	2010		10.1093/nar/gkp926	biology;molecular biology;regulation of gene expression;bioinformatics;genetics;microrna	Comp.	1.1352222753560042	-60.15148489100641	116873
33b611925a084b82d8ca8f690cfc1e56d7081f81	the urms-rms hybrid algorithm for fast and sensitive local protein structure alignment	protein structure comparison;scop;protein structure alignment;dynamic programming algorithm;protein domains;statistical significance;protein structure;local structure;space use;technical report;root mean square;computer science;hybrid algorithm	We present an efficient and sensitive hybrid algorithm for local structure alignment of a pair of 3D protein structures. The hybrid algorithm employs both the URMS (unit-vector root mean squared) metric and the RMS metric. Our algorithm searches efficiently the transformation space using a fast screening protocol; initial transformations (rotations) are identified using the URMS algorithm. These rotations are then clustered and an RMS-based dynamic programming algorithm is invoked to find the maximal local similarities for representative rotations of the clusters. Statistical significance of the alignments is estimated using a model that accounts for both the score of the match and the RMS. We tested our algorithm over the SCOP classification of protein domains. Our algorithm performs very well; its main advantages are that (1) it combines the advantages of the RMS and the URMS metrics, (2) it searches extensively the transformation space, (3) it detects complex similarities and structural repeats, and (4) its results are symmetric. The software is available for download at biozon.org/ftp/software/urms/.	alignment;data interpretation, statistical;download;dynamic programming;hybrid algorithm;maximal set;protein domain;root mean square;scop;cell transformation	Golan Yona;Klara Kedem	2005	Journal of computational biology : a journal of computational molecular cell biology	10.1089/cmb.2005.12.12	protein structure;mathematical optimization;combinatorics;root mean square;hybrid algorithm;computer science;bioinformatics;technical report;machine learning;dynamic programming;mathematics;statistical significance;protein domain;structural classification of proteins database	Comp.	-3.208698625434814	-53.63769853843457	116883
70ffe9d372689d922096489561ef91e3b5347766	assessing the impact of network depth on the analysis of ppi networks: a case study	network inference;genomics;betweenness centrality;pediatrics;connectivity value;heart;probability density function;cardiology;proteins network topology genomics bioinformatics failure analysis heart cardiac disease cardiovascular diseases size measurement biomarkers;biology;data mining;functional genomic research;network topology;betweenness centrality value network depth effects ppi network analysis protein protein interaction networks functional genomic research network inference software heart failure relevant proteins network topology network node classification connectivity value;heart failure relevant proteins;proteins biocybernetics cardiology cellular biophysics genomics molecular biophysics network theory graphs;biocybernetics;proteins;heart failure;betweenness centrality value;molecular biophysics;protein protein interaction;protein protein interaction networks;ppi network analysis;network depth effects;sampling methods;network theory graphs;network inference software;cellular biophysics;network node classification;support function	Recent years have seen a growing interest in the incorporation of protein-protein interaction (PPI) networks to support functional genomic research. Often a default depth is assumed by network inference software. This case study considers the impact of network depth on the analysis of PPI networks using seven proteins known to be relevant to heart failure as inputs into the analysis. This paper analyses how the characteristics of a PPI network vary according to the level examined, suggesting that the investigation of network topology is an essential first step in PPI analysis. The classification of nodes, in terms of degree and betweenness centrality, within the network is also considered. The effect of network depth is also proved to be significant in the identification of potentially essential proteins with large connectivity and/or high betweenness centrality values.	betweenness centrality;network topology;pixel density	Jaine K. Blayney;Haiying Wang;Huiru Zheng;Francisco Azuaje	2009	2009 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology	10.1109/CIBCB.2009.4925729	protein–protein interaction;support function;sampling;probability density function;genomics;computer science;bioinformatics;dynamic network analysis;machine learning;data mining;biocybernetics;betweenness centrality;heart;network topology;statistics;molecular biophysics	Security	5.754528357001973	-56.82273187001292	116966
dac2659b327305cd96939ceb96d15e8d3a621ead	how powerful are summary-based methods for identifying expression-trait associations under different genetic architectures?		Transcriptome-wide association studies (TWAS) have recently been employed as an approach that can draw upon the advantages of genome-wide association studies (GWAS) and gene expression studies to identify genes associated with complex traits. Unlike standard GWAS, summary level data suffices for TWAS and offers improved statistical power. Two popular TWAS methods include either (a) imputing the cis genetic component of gene expression from smaller sized studies (using multi-SNP prediction or MP) into much larger effective sample sizes afforded by GWAS - TWAS-MP or (b) using summary-based Mendelian randomization - TWAS-SMR. Although these methods have been effective at detecting functional variants, it remains unclear how extensive variability in the genetic architecture of complex traits and diseases impacts TWAS results. Our goal was to investigate the different scenarios under which these methods yielded enough power to detect significant expression-trait associations. In this study, we conducted extensive simulations based on 6000 randomly chosen, unrelated Caucasian males from Geisinger's MyCode population to compare the power to detect cis expression-trait associations (within 500 kb of a gene) using the above-described approaches. To test TWAS across varying genetic backgrounds we simulated gene expression and phenotype using different quantitative trait loci per gene and cis-expression /trait heritability under genetic models that differentiate the effect of causality from that of pleiotropy. For each gene, on a training set ranging from 100 to 1000 individuals, we either (a) estimated regression coefficients with gene expression as the response using five different methods: LASSO, elastic net, Bayesian LASSO, Bayesian spike-slab, and Bayesian ridge regression or (b) performed eQTL analysis. We then sampled with replacement 50,000, 150,000, and 300,000 individuals respectively from the testing set of the remaining 5000 individuals and conducted GWAS on each set. Subsequently, we integrated the GWAS summary statistics derived from the testing set with the weights (or eQTLs) derived from the training set to identify expression-trait associations using (a) TWAS-MP (b) TWAS-SMR (c) eQTL-based GWAS, or (d) standalone GWAS. Finally, we examined the power to detect functionally relevant genes using the different approaches under the considered simulation scenarios. In general, we observed great similarities among TWAS-MP methods although the Bayesian methods resulted in improved power in comparison to LASSO and elastic net as the trait architecture grew more complex while training sample sizes and expression heritability remained small. Finally, we observed high power under causality but very low to moderate power under pleiotropy.	architecture as topic;cardiomyopathies;eaf2 gene;ephrin type-b receptor 1, human;expression quantitative trait locus;gene expression;genome-wide association study;hereditary diseases;large;mental association;nitroprusside;numerous;one thousand;quantitative trait loci;sample size;sampling - surgical action;small;weight	Yogasudha C. Veturi;Marylyn DeRiggi Ritchie	2018			quantitative trait locus;computational biology;genetics;lasso (statistics);genetic architecture;mendelian randomization;genome-wide association study;elastic net regularization;expression quantitative trait loci;biology;population	Comp.	6.339495391794415	-53.35533246249715	117001
a7609a149b66c652cfecab3638992d91a6048150	hierarchical structural component modeling of microrna-mrna integration analysis	generalized structured component analysis (gsca);hierarchical structured component analysis of mirna-mrna integration (hiscom-mimi);integration analysis;mrna;mirna	Identification of multi-markers is one of the most challenging issues in personalized medicine era. Nowadays, many different types of omics data are generated from the same subject. Although many methods endeavor to identify candidate markers, for each type of omics data, few or none can facilitate such identification. It is well known that microRNAs affect phenotypes only indirectly, through regulating mRNA expression and/or protein translation. Toward addressing this issue, we suggest a hierarchical structured component analysis of microRNA-mRNA integration (“HisCoM-mimi”) model that accounts for this biological relationship, to efficiently study and identify such integrated markers. In simulation studies, HisCoM-mimi showed the better performance than the other three methods. Also, in real data analysis, HisCoM-mimi successfully identified more gives more informative miRNA-mRNA integration sets relationships for pancreatic ductal adenocarcinoma (PDAC) diagnosis, compared to the other methods. As exemplified by an application to pancreatic cancer data, our proposed model effectively identified integrated miRNA/target mRNA pairs as markers for early diagnosis, providing a much broader biological interpretation.	dna integration;ductal breast carcinoma;information;micrornas;numerous;omics;pancreatic ductal adenocarcinoma;pancreatic carcinoma;personalization;phenotype;precision medicine;protein biosynthesis;simulation;structural element;super paper mario	Yongkang Kim;Sungyoung Lee;Sungkyoung Choi;Jin-Young Jang;Taesung Park	2018		10.1186/s12859-018-2070-0	personalized medicine;bioinformatics;biology;microrna;omics	Comp.	5.718966930838344	-57.37525107926057	117062
cf60e210dc7cded1eb48227a8430fd2da7332158	quantifying the molecular origins of opposite solvent effects on protein-protein interactions	models chemical;molecular dynamics simulation;solvents;proteins;protein binding;computational biology;glycerol;databases protein	Although the nature of solvent-protein interactions is generally weak and non-specific, addition of cosolvents such as denaturants and osmolytes strengthens protein-protein interactions for some proteins, whereas it weakens protein-protein interactions for others. This is exemplified by the puzzling observation that addition of glycerol oppositely affects the association constants of two antibodies, D1.3 and D44.1, with lysozyme. To resolve this conundrum, we develop a methodology based on the thermodynamic principles of preferential interaction theory and the quantitative characterization of local protein solvation from molecular dynamics simulations. We find that changes of preferential solvent interactions at the protein-protein interface quantitatively account for the opposite effects of glycerol on the antibody-antigen association constants. Detailed characterization of local protein solvation in the free and associated protein states reveals how opposite solvent effects on protein-protein interactions depend on the extent of dewetting of the protein-protein contact region and on structural changes that alter cooperative solvent-protein interactions at the periphery of the protein-protein interface. These results demonstrate the direct relationship between macroscopic solvent effects on protein-protein interactions and atom-scale solvent-protein interactions, and establish a general methodology for predicting and understanding solvent effects on protein-protein interactions in diverse biological environments.	accessible surface area;glycerin;molecular dynamics;national origin;simulation;thermodynamics;protein protein interaction	Vincent Vagenende;Alvin X. Han;Han B. Pek;Bernard L. W. Loo	2013		10.1371/journal.pcbi.1003072	computational biology;biology;biochemistry;plasma protein binding;molecular dynamics	Comp.	8.824221087795454	-62.96208667209124	117071
45eb1d504d096783e10882a6bcba5848a7539ca1	analysis of high dimensional gene data combining correlation principal component regression and additive risk model	analytical models;biology computing;time dependent;diffuse large b cell lymphoma;high dimensionality;survival data;additive risk model;principal component regression;biological system modeling;regression model;gene expression data;additives;gene expression;survival time;regression analysis biology computing data handling principal component analysis;survival data censoring problem;high dimensional gene data;semiparametric additive risk model;additives data models predictive models analytical models correlation gene expression biological system modeling;principal component analysis;survival analysis;correlation principal component regression;predictive models;regression analysis;right censoring correlation principal component regression additive risk model gene expression data;data handling;correlation;model fitting;b cell lymphoma data set;b cell lymphoma data set high dimensional gene data correlation principal component regression gene expression data semiparametric additive risk model survival data censoring problem;right censoring;data models	One problem of interest is to relate genes to survival outcomes of patients for the purpose of building regression models to predict future patientspsila survival based on their gene expression data. Applying semiparametric additive risk model of survival analysis, we propose a new approach to conduct the analysis of gene expression data with the focus on modelpsilas predictive ability. The method modifies the correlation principal component regression to handle the censoring problem of survival data. In addition, we employ the time dependent AUC and RMSEP to assess how well the model predicts the survival time. Furthermore, the proposed method is able to identify significant genes that are related to the disease. Finally, this proposed approach is illustrated by the diffuse large B-cell lymphoma (DLBCL) data set. The results show that the model fits the data set very well.	akaike information criterion;automatic frequency control;bayesian information criterion;cell (microprocessor);censoring (statistics);coefficient;dimensionality reduction;fits;financial risk modeling;gene expression profiling;information theory;model selection;principal component analysis;principal component regression;semiparametric model;utility functions on indivisible goods	Yichuan Zhao;Guoshen Wang	2008	2008 IEEE International Conference on Granular Computing	10.1109/GRC.2008.4664689	econometrics;computer science;machine learning;data mining;mathematics;regression analysis;statistics	ML	6.979920932961875	-52.6304575900627	117111
e2ee2df70f651b09ce67d5d69139eb9c125046b5	nddvd: an integrated and manually curated neurodegenerative diseases variation database		URL : http://bioinf.suda.edu.cn/NDDvarbase/LOVDv.3.0.	endocrine system diseases;uniform resource locator	Yang Yang;Chen Xu;Xingyun Liu;Chao Xu;Yuanyuan Zhang;Li Shen;Mauno Vihinen;Bairong Shen	2018		10.1093/database/bay018	data mining;computer science;bioinformatics	Vision	-0.8237087702406506	-62.16828944666746	117167
f1efe63df1716f153dbfd4c76fdc2c110615a92f	detecting horizontal gene transfer by mapping sequencing reads across species boundaries		MOTIVATION Horizontal gene transfer (HGT) is a fundamental mechanism that enables organisms such as bacteria to directly transfer genetic material between distant species. This way, bacteria can acquire new traits such as antibiotic resistance or pathogenic toxins. Current bioinformatics approaches focus on the detection of past HGT events by exploring phylogenetic trees or genome composition inconsistencies. However, these techniques normally require the availability of finished and fully annotated genomes and of sufficiently large deviations that allow detection and are thus not widely applicable. Especially in outbreak scenarios with HGT-mediated emergence of new pathogens, like the enterohemorrhagic Escherichia coli outbreak in Germany 2011, there is need for fast and precise HGT detection. Next-generation sequencing (NGS) technologies facilitate rapid analysis of unknown pathogens but, to the best of our knowledge, so far no approach detects HGTs directly from NGS reads.   RESULTS We present Daisy, a novel mapping-based tool for HGT detection. Daisy determines HGT boundaries with split-read mapping and evaluates candidate regions relying on read pair and coverage information. Daisy successfully detects HGT regions with base pair resolution in both simulated and real data, and outperforms alternative approaches using a genome assembly of the reads. We see our approach as a powerful complement for a comprehensive analysis of HGT in the context of NGS data.   AVAILABILITY AND IMPLEMENTATION Daisy is freely available from http://github.com/ktrappe/daisy   CONTACT renardb@rki.de   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	antibiotic resistance, microbial;base pairing;bioinformatics;bioinformatics;biopolymer sequencing;communications satellite;complement system proteins;daisy digital talking book;deutsche mark;eaf2 gene;emergence;enrico clementi;gene transfer, horizontal;genome assembly sequence;german research centre for artificial intelligence;hypertext transfer protocol;input/output;kosterlitz–thouless transition;manuscripts;organism;phylogenetic tree;phylogenetics;python;reading (activity);sensor;standard streams;toxin;trees (plant);format	Kathrin Trappe;Tobias Marschall;Bernhard Y. Renard	2016	Bioinformatics	10.1093/bioinformatics/btw423	biology;bioinformatics;genetics	Comp.	-0.835527607215342	-56.59918975810809	117174
76ef6730893870f246725fbc19294f78b964ce38	classification of rna sequences with pseudoknots using features based on partial sequences	rna bioinformatics feature extraction molecular biophysics molecular configurations pattern classification;classification;pseudo knot;classification rna secondary structure prediction pseudo knot;10 fold cross validation rna sequence classification partial sequences bioinformatics rna secondary structures np complete problem pseudoknot free structures o n 3 time partial sequence content validated testing dataset;rna secondary structure prediction;rna partitioning algorithms training periodic structures testing measurement accuracy	Classification on pseudoknots existence is a challenging and meaningful problem in Bioinformatics. As predicting RNA secondary structures with pseudoknots is NP-complete problem while predicting pseudoknot-free structures can be done in O(n3) time, if a preliminary pseudoknots existence classification of RNA sequence can be done before the prediction, the classification result can enhance the efficiency of RNA secondary structure prediction. In this paper, a classification of the existence of pseudoknots in an RNA sequence is presented. A set of features have been chosen by partial sequence content and thousands of RNA sequences with validated structures are used to train the classifier. Using a validated testing dataset, this classification method is shown to achieve a very good performance that the best result get 87% accuracy in 10-fold cross validation and around 75% accuracy in testing data. Moreover it may reveal how partial sequence content can affect the formation of pseudoknots.	bioinformatics;protein structure prediction	Kwok-Kit Tong;Kwan-Yau Cheung;Kin-Hong Lee;Kwong-Sak Leung	2015	2015 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB)	10.1109/CIBCB.2015.7300277	biology;biological classification;bioinformatics;machine learning;data mining	Comp.	9.628538475461589	-55.13133059512806	117238
0e49efbf16cd74308f646a3ffde63349a3cd66c3	alignment of tandem repeats with excision, duplication, substitution and indels (edsi)	dna;genetique;genetic analysis;modelizacion;sequence comparison;alignement sequence;aplicacion medical;genetica;secuencia repetida;sequence repetee;bioinformatique;alineacion secuencia;genetics;modelisation;duplication;duplicacion;tandem repeat;medical application;sequence alignment;bioinformatica;dna sequence;modeling;repeated sequence;staphylococcus aureus;variable number of tandem repeat;application medicale;bioinformatics	Traditional sequence comparison by alignment applies a mutation model comprising two events, substitutions and indels (insertions or deletions) of single positions (SI). However, modern genetic analysis knows a variety of more complex mutation events (e.g., duplications, excisions and rearrangements), especially regarding DNA. With the ever more DNA sequence data becoming available, the need to accurately compare sequences which have clearly undergone more complicated types of mutational processes is becoming critical. Herein we introduce a new model, where in total four mutational events are considered: excision and duplication of tandem repeats, as well as substitutions and indels of single positions (EDSI). Assuming the EDSI model, we develop a new algorithm for pairwisely aligning and comparing DNA sequences containing tandem repeats. To evaluate our method, we apply it to the spa VNTR (variable number of tandem repeats) of Staphylococcus aureus, a bacterium of great medical importance.	algorithm;apply;models of dna evolution;scoring functions for docking;tandem computers;video-in video-out	Michael Sammeth;Thomas Weniger;Dag Harmsen;Jens Stoye	2005		10.1007/11557067_23	biology;dna sequencing;repeated sequence;systems modeling;bioinformatics;direct repeat;sequence alignment;genetics;genetic analysis;dna;tandem repeat;gene duplication	Comp.	-3.1225141664555816	-54.68264057333919	117354
a4d5d41173ae2ebe0d2b142eb193f61e6ea16a2a	structure prediction meta server	structure prediction	UNLABELLED The Structure Prediction Meta Server offers a convenient way for biologists to utilize various high quality structure prediction servers available worldwide. The meta server translates the results obtained from remote services into uniform format, which are consequently used to request a jury prediction from a remote consensus server Pcons.   AVAILABILITY The structure prediction meta server is freely available at http://BioInfo.PL/meta/, some remote servers have however restrictions for non-academic users, which are respected by the meta server.   SUPPLEMENTARY INFORMATION Results of several sessions of the CAFASP and LiveBench programs for assessment of performance of fold-recognition servers carried out via the meta server are available at http://BioInfo.PL/services.html.	cafasp;display resolution;livebench;pl/i;server (computer);server (computing);threading (protein sequence)	Janusz M. Bujnicki;Arne Elofsson;Daniel Fischer;Leszek Rychlewski	2001	Bioinformatics	10.1093/bioinformatics/17.8.750	biology;computer science;data mining;database;world wide web	Comp.	-3.5608119474082685	-59.64096036782713	117424
187a45d74226e90b0036dbffcfdcde1ea5994733	using protein-domain information for multiple sequence alignment	databases;graph theory;proteins bioinformatics database management systems graph theory;database management systems;protein domains;sabmark protein domain information multiple sequence alignment primary sequence information external information sources sequence homologies sequence annotation pfam database dialign graph theoretical approach balibase;hidden markov models;proteins;anchored alignment multiple sequence alignment protein domains;impedance matching;proteins hidden markov models databases bioinformatics cobalt impedance matching;multiple sequence alignment;cobalt;anchored alignment;bioinformatics	Most approaches to multiple sequence alignment rely on primary-sequence information. External sources of information, however, can give valuable hints to possible sequence homologies that may not be obvious from sequence comparison alone. Given the huge amount of sequence annotation that is being produced on a daily basis, integrating such external information into the alignment process can contribute to produce biologically more meaningful alignments. In this paper, we investigate different approaches to use existing information about protein domains for improved multiple alignments. We use the PFAM database to identify possible domains in protein sequences, and we use this information to align protein sequences with DIALIGN and with a recently developed graph-theoretical approach to multiple alignment. Test runs on BAliBASE and SABmark show that this approach leads to improved alignments.	align (company);homology (biology);multiple sequence alignment;peptide sequence;pfam	Layal Al Ait;Eduardo Corel;Burkhard Morgenstern	2012	2012 IEEE 12th International Conference on Bioinformatics & Bioengineering (BIBE)	10.1109/BIBE.2012.6399667	biology;impedance matching;structural alignment;cobalt;multiple sequence alignment;computer science;bioinformatics;graph theory;machine learning;simple modular architecture research tool;sequence analysis;sequence alignment;data mining;conserved domain database;protein domain;protein structure database;alignment-free sequence analysis	Comp.	1.821794663636759	-58.4102323162004	117490
c3fdb2b07d882b7c01a8b84e0c6ce590a977c116	mutscan: fast detection and visualization of target mutations by scanning fastq data	fast detection;mutscan;mutation scan;variant visualization	Some types of clinical genetic tests, such as cancer testing using circulating tumor DNA (ctDNA), require sensitive detection of known target mutations. However, conventional next-generation sequencing (NGS) data analysis pipelines typically involve different steps of filtering, which may cause miss-detection of key mutations with low frequencies. Variant validation is also indicated for key mutations detected by bioinformatics pipelines. Typically, this process can be executed using alignment visualization tools such as IGV or GenomeBrowse. However, these tools are too heavy and therefore unsuitable for validating mutations in ultra-deep sequencing data. We developed MutScan to address problems of sensitive detection and efficient validation for target mutations. MutScan involves highly optimized string-searching algorithms, which can scan input FASTQ files to grab all reads that support target mutations. The collected supporting reads for each target mutation will be piled up and visualized using web technologies such as HTML and JavaScript. Algorithms such as rolling hash and bloom filter are applied to accelerate scanning and make MutScan applicable to detect or visualize target mutations in a very fast way. MutScan is a tool for the detection and visualization of target mutations by only scanning FASTQ raw data directly. Compared to conventional pipelines, this offers a very high performance, executing about 20 times faster, and offering maximal sensitivity since it can grab mutations with even one single supporting read. MutScan visualizes detected mutations by generating interactive pile-ups using web technologies. These can serve to validate target mutations, thus avoiding false positives. Furthermore, MutScan can visualize all mutation records in a VCF file to HTML pages for cloud-friendly VCF validation. MutScan is an open source tool available at GitHub: https://github.com/OpenGene/MutScan	bioinformatics;biopolymer sequencing;bloom filter;communications satellite;deep sequencing;execution;fastq format;genetic screening method;html;imagery;javascript;mapk1ip1l gene;malignant fibrous histiocytoma;marijuana abuse;massively-parallel sequencing;maximal set;mutation;neoplasms;open-source software;page (document);pipeline (computing);reading (activity);rolling hash;search algorithm;variant call format;executing - querystatuscode	Shifu Chen;Tanxiao Huang;Tiexiang Wen;Hong Li;Mingyan Xu;Jia Gu	2018		10.1186/s12859-018-2024-6	raw data;dna microarray;biology;rolling hash;javascript;visualization;fastq format;bioinformatics;mutation;bloom filter	Visualization	-1.3061800809032438	-55.73087489613989	117493
f11b24da742a34b1419f7826b94aded56343b1f4	assembling millions of short dna sequences using ssake	de novo sequencing;nucleotides;nucleotide sequence;dna sequence	UNLABELLED Novel DNA sequencing technologies with the potential for up to three orders magnitude more sequence throughput than conventional Sanger sequencing are emerging. The instrument now available from Solexa Ltd, produces millions of short DNA sequences of 25 nt each. Due to ubiquitous repeats in large genomes and the inability of short sequences to uniquely and unambiguously characterize them, the short read length limits applicability for de novo sequencing. However, given the sequencing depth and the throughput of this instrument, stringent assembly of highly identical sequences can be achieved. We describe SSAKE, a tool for aggressively assembling millions of short nucleotide sequences by progressively searching through a prefix tree for the longest possible overlap between any two sequences. SSAKE is designed to help leverage the information from short sequence reads by stringently assembling them into contiguous sequences that can be used to characterize novel sequencing targets.   AVAILABILITY http://www.bcgsc.ca/bioinfo/software/ssake.	biopolymer sequencing;de novo transcriptome assembly;genome;nucleotides;reading (activity);throughput;trie;viral sequencing:prid:pt:ser:nom:sequencing;orders - hl7publishingdomain	René L. Warren;Granger G. Sutton;Steven J. M. Jones;Robert A. Holt	2007	Bioinformatics	10.1093/bioinformatics/btl629	sequencing by hybridization;massive parallel sequencing;biology;paired-end tag;dna sequencing;nucleotide;2 base encoding;nucleic acid sequence;bioinformatics;sequence analysis;sequence assembly;genetics;deep sequencing;hybrid genome assembly;shotgun sequencing	Comp.	-0.45940098437293514	-55.08181350200541	117549
c26aa67071d4392920fc6d4a027e75271a55e342	semantic-enabled hybrid genetic disease diagnostics in next-generation sequenced data		Next Generation Sequencing is a technology for genome sequencing used in genetics for diseased diagnosis. NGS provides the list of all mutations in a genome, so identifying the one which causes a disease is not trivial. A number of applications for variant prioritization was developed, but the data they provide is rather a suggestion than a diagnosis, moreover they suffer from issues as identifying nonpathogenic variant as a causal one or inability to identify the causal gene. These issues inspired us to create a strategy for variant prioritization which includes the use of Exomiser and OmimExplorer result sets improved by semantic analysis of abstracts and articles freely available from PubMed and PubMed Central databases. For the wider scope of scientific articles Google Scholar repository will be used. Described approach enables to present latest and most accurate information about potential pathogenic variants.		Emilia Zawadzka-Gosk;Krzysztof Wolk	2018	Computer Science (AGH)	10.7494/csci.2018.19.2.2319	gene;computer science;machine learning;artificial intelligence;genome;disease;dna sequencing;prioritization;bioinformatics	Logic	1.3715434478493393	-55.239518402079256	117565
08d78bef210d49bca0dfca115cae61829881ae27	structural role of uracil dna glycosylase for the recognition of uracil in dna duplexes. clues from atomistic simulations		In the first stage of the base excision repair pathway the enzyme uracil DNA glycosylase (UNG) recognizes and excises uracil (U) from DNA filaments. U repair is believed to occur via a multistep base-flipping process, through which the damaged U base is initially detected and then engulfed into the enzyme active site, where it is cleaved. The subtle recognition mechanism by which UNG discriminates between U and the other similar pyrimidine nucleobases is still a matter of active debate. Detailed structural information on the different steps of the base-flipping pathway may provide insights on it. However, to date only two intermediates have been trapped crystallographically thanks to chemical modifications of the target and/or of its complementary base. Here, we performed force-field based molecular dynamics (MD) simulations to explore the structural and dynamical properties of distinct UNG/dsDNA adducts, containing A:U, A:T, G:U, or G:C base pairs, at different stages of the base-flipping pathway. Our simulations reveal that if U is present in the DNA sequence a short-lived extra-helical (EH) intermediate exists. This is stabilized by a water-mediated H-bond network, which connects U with His148, a residue pointed out by mutational studies to play a key role for U recognition and catalysis. Moreover, in this EH intermediate, UNG induces a remarkable overall axis bend to DNA. We believe this aspect may facilitate the flipping of U, with respect to other similar nucleobases, in the latter part of the base-extrusion process. In fact, a large DNA bend has been demonstrated to be associated with a lowering of the free energy barrier for base-flipping. A detailed comparison of our results with partially flipped intermediates identified crystallographically or computationally for other base-flipping enzymes allows us to validate our results and to formulate hypothesis on the recognition mechanism of UNG. Our study provides a first ground for a detailed understanding of the UNG repair pathway, which is necessary to devise new pharmaceutical strategies for targeting DNA-related pathologies.		Duvan Franco;Jacopo Sgrignani;Giovanni Bussi;Alessandra Magistrato	2013	Journal of chemical information and modeling	10.1021/ci4001647	dna;uracil-dna glycosylase;stereochemistry;uracil;combinatorial chemistry;enzyme;pyrimidine;base pair;active site;chemistry;nucleobase	Comp.	9.36821143236937	-62.76788053866886	117621
ac3f7bc11a2aca1c0d74bb6352d25fa622320e1b	a methodology for the structural and functional analysis of signaling and regulatory networks	animals;software tool;regulatory network;metabolic network;proteome;signal transduction;transcription factors;models biological;logistic models;interaction network;receptors antigen t cell;t cell receptor;computational biology bioinformatics;cell physiological phenomena;feedback physiological;functional analysis;structure and function;feedback loop;signal processing;boolean network;gene expression regulation;cellular network;algorithms;humans;neural networks computer;combinatorial libraries;protein interaction mapping;steady state analysis;computer appl in life sciences;logical process;cell signaling;structure analysis;microarrays;bioinformatics;dynamic behavior	Structural analysis of cellular interaction networks contributes to a deeper understanding of network-wide interdependencies, causal relationships, and basic functional capabilities. While the structural analysis of metabolic networks is a well-established field, similar methodologies have been scarcely developed and applied to signaling and regulatory networks. We propose formalisms and methods, relying on adapted and partially newly introduced approaches, which facilitate a structural analysis of signaling and regulatory networks with focus on functional aspects. We use two different formalisms to represent and analyze interaction networks: interaction graphs and (logical) interaction hypergraphs. We show that, in interaction graphs, the determination of feedback cycles and of all the signaling paths between any pair of species is equivalent to the computation of elementary modes known from metabolic networks. Knowledge on the set of signaling paths and feedback loops facilitates the computation of intervention strategies and the classification of compounds into activators, inhibitors, ambivalent factors, and non-affecting factors with respect to a certain species. In some cases, qualitative effects induced by perturbations can be unambiguously predicted from the network scheme. Interaction graphs however, are not able to capture AND relationships which do frequently occur in interaction networks. The consequent logical concatenation of all the arcs pointing into a species leads to Boolean networks. For a Boolean representation of cellular interaction networks we propose a formalism based on logical (or signed) interaction hypergraphs, which facilitates in particular a logical steady state analysis (LSSA). LSSA enables studies on the logical processing of signals and the identification of optimal intervention points (targets) in cellular networks. LSSA also reveals network regions whose parametrization and initial states are crucial for the dynamic behavior. We have implemented these methods in our software tool CellNetAnalyzer (successor of FluxAnalyzer) and illustrate their applicability using a logical model of T-Cell receptor signaling providing non-intuitive results regarding feedback loops, essential elements, and (logical) signal processing upon different stimuli. The methods and formalisms we propose herein are another step towards the comprehensive functional analysis of cellular interaction networks. Their potential, shown on a realistic T-cell signaling model, makes them a promising tool.	abbreviations;algorithm;anatomy, regional;autoimmune diseases;boolean algebra;boolean network;causal filter;causality;cell signaling;cellular phone;chronic lymphocytic leukemia;chronic eosinophilic leukemia;coefficient;color;complex network;complexity;computation (action);concatenation;data table;data-flow analysis;design structure matrix;disjunctive normal form;encode;electrical engineering;endeavour (supercomputer);experiment;feedback;flow;formal system;generalization (psychology);graph - visual representation;hl7publishingsubsection <operations>;hope (emotion);hypergraphy;illness (finding);inline linking;interaction network;interdependence;java community process;kinetics;lss gene;large;logical connective;matlab;manuscripts;max-flow min-cut theorem;metabolic process, cellular;network analysis (electrical circuits);one-to-one (data model);partial;patient transportation request:find:pt:^patient:doc;perturbation theory;preparation;programming tool;requirement;ski combinator calculus;slpi protein, human;signal transduction;signal processing;signature;simulation;sixty nine;social network analysis;steady state;structural analysis;surround sound;web site;biological signaling;citation;emotional dependency;funding grant	Steffen Klamt;Julio Saez-Rodriguez;Jonathan A. Lindquist;Luca Simeoni;Ernst Dieter Gilles	2005	BMC Bioinformatics	10.1186/1471-2105-7-56	interaction network;functional analysis;biology;cellular network;boolean network;regulation of gene expression;dna microarray;cell biology;cell signaling;computer science;bioinformatics;theoretical computer science;signal processing;proteome;feedback loop;structural analysis;steady state;signal transduction;t-cell receptor;metabolic network;transcription factor	AI	6.229906438781324	-59.7494128243403	117722
bb8cdf3f37119e9600d04ee56aa77d60adfc64b1	similarities of ordered gene lists	microarray data;610 medizin;ordered gene lists;meta analysis;ddc 610	MOTIVATION Many applications of microarray technology in clinical cancer studies aim at detecting molecular features for refined diagnosis. In this paper, we follow an opposite rationale: we try to identify common molecular features shared by phenotypically distinct types of cancer using a meta-analysis of several microarray studies. We present a novel algorithm to uncover that two lists of differentially expressed genes are similar, even if these similarities are not apparent to the eye. The method is based on the ordering in the lists.   RESULTS In a meta-analysis of five clinical microarray studies we were able to detect significant similarities in five of the ten possible comparisons of ordered gene lists. We included studies, where not a single gene can be significantly associated to outcome. The detection of significant similarities of gene lists from different microarray studies is a novel and promising approach. It has the potential to improve upon specialized cancer studies by exploring the power of several studies in one single analysis. Our method is complementary to previous methods in that it does not rely on strong effects of differential gene expression in a single study but on consistent ones across multiple studies.		Xinan Yang;Stefan Bentink;Stefanie Scheid;Rainer Spang	2006	Journal of bioinformatics and computational biology	10.1142/S0219720006002120	biology;microarray analysis techniques;meta-analysis;computer science;bioinformatics;data mining;mathematics;genetics	Comp.	6.516529136600269	-55.097013812631715	117724
9cb9c02cd9a3192cf4ac415c7a32fe2efde7322f	the uofl microarray facility: merger and new location	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;computational biology bioinformatics;uk phd theses thesis;life sciences;algorithms;combinatorial libraries;uk research reports;medical journals;computer appl in life sciences;europe pmc;biomedical research;microarrays;bioinformatics	Background The UofL Microarray Facility is centered around the currently most advanced and comprehensive instrumentation for oligonucleotide array platforms by Affymetrix, Inc. and Agilent, Inc., both merged in the new location in CTR 227H-G. These technologies allow determination of global RNA gene expression and SNP (single nucleotide polymorphism) profiles based on hybridization of entire representative mRNA or genomic DNA populations to high-density arrays of gene-specific or mutation-specific oligonucleotide probes. Such global profiles can be obtained for tens of thousands of genes or hundreds of thousands of SNP loci from cell or tissue samples within one time-saving and standardized experiment. Comparative analysis of global gene expression or SNP patterns on biological material will provide crucial information on gene products and/or mutations which are involved in cellular functions, disease mechanisms, and therapy responses. Both cell culture, tissue, or microdissected cell material from human or various animal sources can be used for analyses. The objective of the UofL Microarray Facility is to ensure that investigators can efficiently adopt these state-of-the-art technologies for their basic science, clinical, and translational investigative goals. The Facility is registered as Academic Core Account and receives discounts for arrays and software licenses.	microarray;population;snp array;software license	S. Waigel;Xiaohong Li;Yinlu Chen;Vennila Arumugam;Nigel G. F. Cooper;Wolfgang Zacharias	2010		10.1186/1471-2105-11-S4-P25	biology;dna microarray;computer science;bioinformatics;data science	Comp.	-1.0784134980075213	-61.275550778776015	117732
