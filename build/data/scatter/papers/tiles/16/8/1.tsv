id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
6964edd41be6de269f17efe5fa78a572a5fa2cff	detecting demeanor for healthcare with machine learning		This paper describes a new prototype system for detecting the demeanor of patients in emergency situations using the Intel RealSense camera system [1]. It describes how machine learning, a support vector machine (SVM) and the RealSense facial detection system can be used to track patient demeanour for pain monitoring. In a lab setting, the application has been trained to detect four different intensities of pain and provide demeanour information about the patient's eyes, mouth, and agitation state. Its utility as a basis for evaluating the condition of patients in situations using video, machine learning and 5G technology is discussed.	face detection;intel realsense;machine learning;prototype;sensor;support vector machine	Michael D Healy;Paul Walsh	2017	2017 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2017.8217970	support vector machine;machine learning;computer science;artificial intelligence;health care	Robotics	3.408361740811477	-87.12235975992562	102645
75f1ed0eb071ad26cd9ee021ae34b05755833379	deep learning for continuous multiple time series annotations		Learning from multiple annotations is an increasingly important research topic. Compared with conventional classification or regression problems, it faces more challenges because time-continuous annotations would result in noisy and temporal lags problems for continuous emotion recognition. In this paper, we address the problem by deep learning for continuous multiple time series annotations. We attach a novel crowd layer to the output layer of basic continuous emotion recognition system, which learns directly from the noisy labels of multiple annotators with end-to-end manner. The inputs of the system are multimodal features and the targets are multiple annotations, with the intention of learning an annotator-specific mapping. Our proposed method considers the ground truth as latent variables and multiple annotations are variant of ground truth by linear mapping. The experimental results show that our system can achieve superior performance and capture the reliabilities and biases of different annotators.	acoustic cryptanalysis;annotation;arousal;artificial neural network;deep learning;emotion recognition;end-to-end principle;face;gradient;ground truth;latent variable;long short-term memory;multimodal interaction;neural network simulation;time series;vc dimension	Jian Huang;Ya Feng Li;Jianhua Tao;Zheng Lian;Mingyue Niu;Minghao Yang	2018		10.1145/3266302.3266305	deep learning;emotion recognition;linear map;ground truth;artificial intelligence;computer science;latent variable;pattern recognition	AI	-2.855661570663536	-85.94840484193453	102820
dd04d98837840b56e31d5779428cb55ccd7ddae3	a smart low power r-r-i heartbeat monitor system with contactless uwb sensor		A heartbeat contactless monitor system with the less burden on human body is an effective solution to support the safety car with monitoring driver's condition. This paper shows the smart low power R-R-I heart monitor system with contactless UWB sensor. The measured R-R-I data in the driving space estimate the condition of autonomic nerves/conic body, and detect the physical condition of the drivers, for example sleepiness. We have adopted the noise filtering and the forecasting algorithm using autonomic parameter for breath and body movement to get the accurate R-R-I. Additionally, three times power reduction compare to the conventional power management technique has been achieved.	algorithm;autonomic computing;contactless smart card;power management;ultra-wideband	Kazutami Arimoto;Daichi Yamashita;Nao Igawa;Tomoyuki Yokogawa;Yoichiro Sato;Isao Kayano;Akio Shiratori	2017	2017 International SoC Design Conference (ISOCC)	10.1109/ISOCC.2017.8368828	electronic engineering;power management;computer science;filter (signal processing);heartbeat	EDA	9.230480938497507	-88.47277462395104	102872
f77dafb50e96e74b88e2e9aee5d779402b707191	an intelligent framework for workouts in gymnasium: m-health perspective☆		The Internet of Things (IoT) Technology has the potential to capture real-time health related parameters everywhere. Henceforth, in this paper, the Cloud Centric IoT (CCIoT) Technology is utilized to assess the health related attributes of a trainee during exercise sessions in a gymnasium. The proposed system have the capabilities to predict the probabilistic vulnerability to health parameters of a trainee during workouts. For this purpose, back-propagation based Artificial Neural Network (ANN) technique is used as a prediction model, layered into three stages, i.e. Monitoring, Learning, and Prediction. Also, the probabilistic vulnerability is represented in real-time using color-coded technique, depicting the health state of the trainee. The proposed system has been validated using an experiment in which five people were monitored for six days at different gymnasiums. Results are compared with different state-of-the-art techniques for determining the overall effectiveness of the proposed system. © 2017 Elsevier Ltd. All rights reserved.	artificial neural network;backpropagation;data acquisition;internet of things;real-time clock;real-time locating system;six days in fallujah;software propagation	Munish Bhatia;Sandeep K. Sood	2017	Computers & Electrical Engineering	10.1016/j.compeleceng.2017.07.018	temporal database;probabilistic logic;cloud computing;simulation;computer science;artificial neural network;internet of things;vulnerability	AI	4.572518193854098	-83.29809447974323	102882
2622b1c697c18ced0713bd205a52c0a68424e085	limb movements classification using wearable wireless transceivers	activity index;received signal strength rss;wearable wireless devices classification of human limbs activities k nearest neighbor k nn received signal strength rss support vector machine svm;classification algorithm;wireless devices;classification of human limbs activities;support vector machines;sensors;support vector machine svm;pervasive computing;frequency 2 4 ghz;wearable wireless devices;wireless sensor network;classification algorithms sensors leg support vector machines wireless communication wireless sensor networks transceivers;wireless communication;received signal strength;feasibility study;physical therapy;k nearest neighbor k nn;signal classification;classification algorithms;wireless sensor networks body area networks medical signal processing motion measurement patient treatment signal classification support vector machines transceivers;wearable wireless transceivers;adult algorithms artificial intelligence clothing extremities female humans male monitoring ambulatory movement signal processing computer assisted telemetry;patient treatment;k nearest neighbor;transceivers;small wireless transceivers;support vector machine;frequency 2 4 ghz limb movement classification wearable wireless transceivers small wireless transceivers physical therapy kinesiotherapy activities support vector machine k nearest neighbor methods;limb movement classification;body area networks;motion measurement;medical signal processing;wireless sensor networks;leg;k nearest neighbor methods;kinesiotherapy activities	A feasibility study, where small wireless transceivers are used to classify some typical limb movements used in physical therapy processes is presented. Wearable wireless low-cost commercial transceivers operating at 2.4 GHz are supposed to be widely deployed in indoor settings and on people's bodies in tomorrow's pervasive computing environments. The key idea of this work is to exploit their presence by collecting the received signal strength measured between those worn by a person. The measurements are used to classify a set of kinesiotherapy activities. The collected data are classified by using both support vector machine and K-nearest neighbor methods, in order to recognise the different activities.	classification;hoc (programming language);k-nearest neighbors algorithm;kinesitherapy;limb deformities, congenital;nn304;orthopedics;physical therapy exercises;rss;single linkage cluster analysis;support vector machine;transceiver;ubiquitous computing;wearable computer;limb movement;sensor (device)	Anda R. Guraliuc;Paolo Barsocchi;Francesco Potorti;Paolo Nepa	2011	IEEE Transactions on Information Technology in Biomedicine	10.1109/TITB.2011.2118763	support vector machine;feasibility study;speech recognition;wireless sensor network;telecommunications;computer science;machine learning	HCI	8.49997695785905	-86.93395436769532	103210
795a901398ac16f3c01bc9f23e58ac8bbae5b073	i3dermoscopyapp: hacking melanoma thanks to iot technologies	e health system;health decision making;mobile app;automatic melanoma detection;conference paper	The paper introduces I3DermoscopyApp, a newrndeclination of the Internet of Things (IoT) paradigm,rndesigned to allow the early detection of melanoma.rnEven though artificial intelligence programs cannotrnoutperform the diagnostic accuracy of expertrndermatologists yet, they reveal to be very useful inrnproviding second opinions to physicians with shortrnclinical experience, thus improving significantly theirrndiagnostic performance. Following this trend, anrnoriginal integration of mobile app technology andrnwell-known image processing algorithms allows thernautomatic analysis of pigmented skin lesions to helprnphysicians apply a diagnostic method (Seven PointrnCheck List) based on dermoscopy. The web-basedrnplatform makes the physician able to: i) store digitalrnimages captured by smartphones featured with arndermatoscope; ii) measure morphological andrnchromatic parameters of the skin lesion; iii) make arndiagnostic decision according to the Seven PointrnChecklist method. A detailed description of the adoptedrntechniques, together with the first validation results are reported.		Giuseppe Di Leo;Consolatina Liguori;Vincenzo Paciello;Antonio Pietrosanto;Paolo Sommella	2017		10.24251/HICSS.2017.434	multimedia;internet privacy;computer security	EDA	3.978512528107502	-91.0301813277547	103349
6bc001f9e7111fa8299b7faec47d873a6ab59992	fall detection with wearable sensors--safe (smart fall detection)	training decision trees accuracy gyroscopes acceleration accelerometers angular velocity;gyroscopes;body sensor networks;mems accelerometers body sensor networks machine learning;sensors;decision trees wearable sensors safe smart fall detection robust fall detection systems accelerometers gyroscopes observational analysis fall nonfall situations machine learning adl;machine learning;computerised instrumentation;learning artificial intelligence;decision trees;mems accelerometers;accelerometers;object detection;sensors accelerometers computerised instrumentation decision trees gyroscopes learning artificial intelligence object detection	The high rate of falls incidence among the elderly calls for the development of reliable and robust fall detection systems. A number of such systems have been proposed, with claims of fall detection accuracy of over 90% based on accelerometers and gyroscopes. However, most such fall detection algorithms have been developed based on observational analysis of the data gathered, leading to thresholds setting for fall/non-fall situations. Whilst the fall detection accuracies reported appear to be high, there is little evidence that the threshold based methods proposed generalise well with different subjects and different data gathering strategies or experimental scenarios. Moreover, few attempts appear to have been made to validate the proposed methods in real-life scenarios or to deliver robust fall decisions in real-time. The research here uses machine learning and particularly decision trees to detect 4 types of falls (forward, backward, right and left). When applied to experimental data from 8 male subjects, the accelerometers and gyroscopes based system discriminates between activities of daily living (ADLs) and falls with a precision of 81% and recall of 92%. The performance and robustness of the method proposed has been further analysed in terms its sensitivity to subject physical profile and training set size.	algorithm;angularjs;computational complexity theory;decision tree;gyroscope;incidence matrix;machine learning;real life;real-time locating system;sensor;simulation;test set;velocity (software development);wearable computer;wearable technology;while	Olukunle Ojetola;Elena I. Gaura;James Brusey	2011	2011 Seventh International Conference on Intelligent Environments	10.1109/IE.2011.38	embedded system;electronic engineering;simulation;engineering	Robotics	6.871269135456936	-85.12944861104904	103618
dffd79951eb0e37a7cb3c7efd1c9771f09f70bc2	monitoring respiratory impedance by wearable sensor device: protocol and methodology	respiratory disease;healthcare;closed loop control;cyber physical systems;frequency response;online identification;fractional order impedance;forced oscillation technique;respiratory impedance;wearable sensor;mobile monitoring;protocol	This paper presents an original protocol, method and deploying solution for monitoring respiratory impedance in mobile individuals. The purpose of the follow up study may be either short-term, or long-term. The proposed steps take into account effects of exercise, rest and sleep on the mechanical properties of the respiratory signals and their computed impedance as a function of time and frequency. The end-product is a wearable sensor, which may be linked in a network of sensors, cyber-physical systems containing mobile devices, central data logging archives and possible alarms to medical supervisor. The added value is that given a treatment profile, its efficacy can be measured by evaluation of respiratory impedance on a daily (regular) basis, without the necessity for the patient to come to healthcare units provided with lung function test facilities. The visit to specialist can be then decided based on the follow-up online by the responsible person and treatment adaptation can be performed. Reduction of visits is thus an important factor in reducing healthcare costs and improving patient wellbeing while delivering highly qualitative services.	characteristic impedance;wearable computer	Clara M. Ionescu;Dana Copot	2017	Biomed. Signal Proc. and Control	10.1016/j.bspc.2017.03.018	frequency response;protocol;simulation;computer science;control theory;cyber-physical system	Mobile	8.588156981920399	-88.54150705706601	103924
fbd85f35d0d89dfa7384ef60c0249ea46fcbc575	real-time feedback-centric nurse calling system with archive monitoring using raspberry pi		The relationship between nurse and patient is vital as well as vulnerable on which a significant portion of well-being of patient depends. The recent growth of Internet of Things provides the opportunity to maintain this relationship in a more secure and efficient way. From this point of view, this paper presents a system of real-time nurse calling with focus centered on nurse feedback based on patient condition. The system also includes a robust archive monitoring system for review and trend analysis. In the proposed system, patients are able to call for assistance in time of emergency by pressing a designated button. After this, the device will send a real-time message containing information about the patients bed, room, and floor number to the appropriate nurse station. Nurse will respond as soon as the message is delivered, and optionally call for help by pressing designated buttons in the device. The proposed system reduces the delay in response of nurse. Additionally, the interactions are stored in Raspberry Pi database for future analysis to improve the quality of services. The proposed system uses low-cost hardware like ATMEGA328P microcontroller and ENC28J60 Ethernet controller, and Arduino Uno.	atmega328;archive;arduino;feedback;futures studies;interaction;internet of things;microcontroller;raspberry pi 3 model b (latest version);real-time transcription;uno	Mohammad Sakib Mahmud;Mahbub Arab Majumder;Abdul Kawsar Tushar;Md. Mahtab Kamal;Akm Ashiquzzaman;Md. Rashedul Islam	2017	2017 4th International Conference on Networking, Systems and Security (NSysS)	10.1109/NSYSS2.2017.8267799	microcontroller;pi;control theory;trend analysis;arduino;nursing;ethernet;server;computer science;blowing a raspberry	Visualization	5.4691303695967335	-88.82681415121854	104210
2dcadba581cede8c6d8f9ebcc205ed783abdbc47	recognizing problem behaviors of children with developmental disabilities using smartwatch	feature collection children problem behaviors recognition developmental disabilities 3 axis accelerometer gyroscope microphone sensors smartwatch behavior classification;sensors accelerometers microphones gyroscopes feature extraction conferences;psychology behavioural sciences computing mobile computing pattern classification	We develop a scheme to analyze problem behaviors of children with developmental disabilities by making use of 3-axis accelerometer, gyroscope, and microphone sensors in a smartwatch. It consists of four phases: classification of behaviors, feature collection, classifier construction and behavior recognition. Real measurements show that the recognition accuracy is above 92% for all test cases.	gyroscope;microphone;sensor;smartwatch;statistical classification;test case	Yeongju Lee;Minseok Song	2016	2016 IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)	10.1109/INFCOMW.2016.7562229	computer vision;speech recognition	Vision	8.031338386048105	-86.49075777429653	104277
457705bdb67c1be701a2ad4092d9c0e0ad1344dc	3d convolutional neural networks for cross audio-visual matching recognition		Audio–visual recognition (AVR) has been considered as a solution for speech recognition tasks when the audio is corrupted, as well as a visual recognition method used for speaker verification in multi-speaker scenarios. The approach of AVR systems is to leverage the extracted information from one modality to improve the recognition ability of the other modality by complementing the missing information. The essential problem is to find the correspondence between the audio and visual streams, which is the goal of this paper. We propose the use of a coupled 3D convolutional neural network (3D CNN) architecture that can map both modalities into a representation space to evaluate the correspondence of audio–visual streams using the learned multimodal features. The proposed architecture will incorporate both spatial and temporal information jointly to effectively find the correlation between temporal information for different modalities. By using a relatively small network architecture and much smaller data set for training, our proposed method surpasses the performance of the existing similar methods for audio–visual matching, which use 3D CNNs for feature representation. We also demonstrate that an effective pair selection method can significantly increase the performance. The proposed method achieves relative improvements over 20% on the equal error rate and over 7% on the average precision in comparison to the state-of-the-art method.	artificial neural network;atmel avr;convolutional neural network;information retrieval;multimodal interaction;network architecture;sound card;speaker recognition;speech recognition	Amirsina Torfi;Seyed Mehdi Iranmanesh;Nasser M. Nasrabadi;Jeremy M. Dawson	2017	IEEE Access	10.1109/ACCESS.2017.2761539	audio mining;word error rate;streams;convolutional neural network;architecture;speaker recognition;acoustic model;computer science;feature extraction;machine learning;pattern recognition;artificial intelligence	Vision	-4.008457639791363	-87.08009774612243	104351
13be4838d6eee8bb0640f99a1a08cd54aa6357c1	towards fully automated motion capture of signs - development and evaluation of a key word signing avatar	sprakteknologi sprakvetenskaplig databehandling;virtual characters;sign language;motion capture;augmentative and alternative communication aac;datavetenskap datalogi;language technology computational linguistics;computer science	Motion capture of signs provides unique challenges in the field of multimodal data collection. The dense packaging of visual information requires high fidelity and high bandwidth of the captured data. Even though marker-based optical motion capture provides many desirable features such as high accuracy, global fitting, and the ability to record body and face simultaneously, it is not widely used to record finger motion, especially not for articulated and syntactic motion such as signs. Instead, most signing avatar projects use costly instrumented gloves, which require long calibration procedures. In this article, we evaluate the data quality obtained from optical motion capture of isolated signs from Swedish sign language with a large number of low-cost cameras. We also present a novel dual-sensor approach to combine the data with low-cost, five-sensor instrumented gloves to provide a recording method with low manual postprocessing. Finally, we evaluate the collected data and the dual-sensor approach as transferred to a highly stylized avatar. The application of the avatar is a game-based environment for training Key Word Signing (KWS) as augmented and alternative communication (AAC), intended for children with communication disabilities.	advanced audio coding;avatar (computing);data quality;motion capture;multimodal interaction;wired glove	Simon Alexanderson;Jonas Beskow	2015	TACCESS	10.1145/2764918	motion capture;speech recognition;sign language;computer science;artificial intelligence;linguistics;multimedia;world wide web	HCI	-1.336911507658652	-83.74239366426009	104526
7731c8a1c56fdfa149759a8bb7b81464da0b15c1	recognizing abnormal heart sounds using deep learning		The work presented here applies deep learning to the task of automated cardiac auscultation, i.e. recognizing abnormalities in heart sounds. We describe an automated heart sound classification algorithm that combines the use of time-frequency heat map representations with a deep convolutional neural network (CNN). Given the cost-sensitive nature of misclassification, our CNN architecture is trained using a modified loss function that directly optimizes the trade-off between sensitivity and specificity. We evaluated our algorithm at the 2016 PhysioNet Computing in Cardiology challenge where the objective was to accurately classify normal and abnormal heart sounds from single, short, potentially noisy recordings. Our entry to the challenge achieved a final specificity of 0.95, sensitivity of 0.73 and overall score of 0.84. We achieved the greatest specificity score out of all challenge entries and, using just a single CNN, our algorithm differed in overall score by only 0.02 compared to the top place finisher, which used an ensemble approach.	algorithm;artificial neural network;convolutional neural network;deep learning;heat map;loss function;sensitivity and specificity;time–frequency representation	Jonathan Rubin;Rui Abreu;Anurag Ganguli;Saigopal Nelaturi;Ion Matei;Kumar Sricharan	2017			speech recognition;convolutional neural network;computer science;deep learning;auscultation;abnormal heart sounds;artificial intelligence;heart sounds	ML	-3.0746654532971336	-87.92469550036817	104634
d19104e918b5ecad453e30dc24bcee2a5e9eb12f	the cirdo corpus: comprehensive audio/video database of domestic falls of elderly people	multimodal corpus;ambient assisted living aal;distress situation;audio and video data set;natural language and multimodal interaction	Ambient Assisted Living aims at enhancing the quality of life of older and disabled people at home thanks to Smart Homes. In particular, regarding elderly living alone at home, the detection of distress situation after a fall is very important to reassure this kind of population. However, many studies do not include tests in real settings, because data collection in this domain is very expensive and challenging and because of the few available data sets. The CIRDOcorpus is a dataset recorded in realistic conditions in DOMUS, a fully equipped Smart Home with microphones and home automation sensors, in which participants performed scenarios including real falls on a carpet and calls for help. These scenarios were elaborated thanks to a field study involving elderly persons. Experiments related in a first part to distress detection in real-time using audio and speech analysis and in a second part to fall detection using video analysis are presented. Results show the difficulty of the task. The database can be used as standardized database by researchers to evaluate and compare their systems for elderly person’s assistance.	database;distress (novel);experiment;field research;home automation;microphone;population;real-time clock;sensor;the quality of life;video content analysis;voice analysis	Michel Vacher;Saïda Bouakaz;Marc-Eric Bobillier-Chaumon;Frédéric Aman;Rizwan Ahmed Khan;Salima Body-Bekkadja;François Portet;Erwan Guillou;Solange Rossato;Benjamin Lecouteux	2016			speech recognition;multimedia	HCI	4.75107553628956	-86.26628870431644	104837
eae31f1b10ed45c80ba8dd228c1edd69f71ee79b	a hmm-based fundamental motion synthesis approach for gesture recognition on a nintendo triaxial accelerometer	input device;interactive devices feature extraction gesture recognition hidden markov models image motion analysis;image motion analysis;hidden markov models gesture recognition training data accelerometers feature extraction acceleration topology;hidden markov model;motion synthesis;continuous motion hmm based fundamental motion synthesis gesture recognition nintendo wiimote triaxial accelerometer input device hidden markov model kernel recognition synthesis unit hmm modeling unit feature extraction hmm topology discrete motion;hidden markov models;feature extraction;gesture recognition;interactive devices	In this paper, we show how to use a Nintendo Wiimote triaxial accelerometer as an input device to make a gesture recognition system based on Hidden Markov Model as the kernel recognition algorithm. We adopted a set of basic movements called “Fundamental Motions” as the synthesis units for all the other complex motions. In the preliminary study, we tried to discriminate the digits from ‘0’ to ‘9’. We analyzed this task and found a set of 16 motions are appropriate to be used as HMM modeling units. By using appropriate feature extraction and HMM topology, we can achieve near 98% and 65% accuracy for discrete motions and continuous motions, respectively.	algorithm;feature extraction;gesture recognition;hidden markov model;input device;markov chain;wii	Wei-Cheng Chen;Ren-Yuan Lyu	2011	2011 5th International Conference on Signal Processing and Communication Systems (ICSPCS)	10.1109/ICSPCS.2011.6140869	computer vision;speech recognition;computer science;pattern recognition	Robotics	0.2036440619569926	-88.35094873244958	105026
ea45f5020a8f9de9f76ad2a94f1440b16555fd3a	mobilespiro: portable open-interface spirometry for android	respiratory disease;asthma;real time;android;respiratory;spirometry;patient monitoring;open source	Respiratory diseases such as asthma are becoming more prevalent among both children and adults. Patients increasingly feel the need to monitor themselves and aid their diagnosis with more frequent measurements without the need to visit a clinic. Spirometry and its accurate interpretation are necessary in addressing this issue, and smartphones and other mobile platforms can economically increase access to these valuable measurements. We will demonstrate mobile-Spiro, a multi-configuration Android-based portable spirometer which allows for self-patient monitoring of respiratory conditions. In particular, mobileSpiro takes real-time measurements of lung capacity and assists in monitoring for potential disorders. Additionally, the results of each spirometric maneuver are transmitted to a remote server. As an open-source, open-interface spirometer, the system encourages innovation at a vastly decreased cost of deployment.	android;mobile device;open-source software;real-time clock;server (computing);smartphone;software deployment	Siddharth Gupta;Peter Chang;Nonso Anyigbo;Ashutosh Sabharwal	2011		10.1145/2077546.2077573	simulation;medicine;pathology;physical therapy	Mobile	9.716451644068552	-87.69166504877609	105263
99ece1c34bd85aeeecc3d5a20963883a38412abf	comparing and combining time series trajectories using dynamic time warping	combining;virtual reality;training simulator;trajectory data;dynamic time warping;comparing	This research proposes the application of dynamic time warping (DTW) algorithm to analyse multivariate data from virtual reality training simulators, to assess the skill level of trainees. We present results of DTW algorithm applied to trajectory data from a virtual reality haptic training simulator for epidural needle insertion. The proposed application of DTW algorithm serves two purposes, to enable (i) two trajectories to be compared as a similarity measure and also enables (ii) two or more trajectories to be combined together to produce a typical or representative average trajectory using a novel hierarchical DTW process. Our experiments included 100 expert and 100 novice simulator recordings. The data consists of multivariate time series datastreams including multi-dimensional trajectories combined with force and pressure measurements. Our results show that our proposed application of DTW provides a useful time-independent method for (i) comparing two trajectories by providing a similarity measure and (ii) combining two or more trajectories into one, showing higher performance compared to conventional methods such as linear mean. These results demonstrate that DTW can be useful within virtual reality training simulators to provide a component in an automated scoring and assessment feedback system. © 2016 The Authors. Published by Elsevier B.V. Peer-review under responsibility of KES International.	algorithm;cluster analysis;dynamic time warping;experiment;haptic technology;similarity measure;simulation;time series;timing closure;virtual reality	Neil Vaughan;Bogdan Gabrys	2016		10.1016/j.procs.2016.08.106	computer vision;simulation;computer science;artificial intelligence;machine learning;dynamic time warping;virtual reality	Visualization	6.155775587323734	-81.23851217510146	105277
9c206a6968cefc5ee85215fb60d97e8baaa1d205	a linear regression model with dynamic pulse transit time features for noninvasive blood pressure prediction	pulse transit time;blood pressure;blood pressure oscillations;dynamic feature	Cardiovascular diseases (CVDs) have become the leading cause of death globally (as reported by the World Health Organization, June 2016). An effective method of preventing CVDs is to measure and monitor blood pressure (BP), which serves as a physiological indicator for cardiovascular systems. A previous research has proposed the use of pulse transit time (PTT) information to compute the BP measure. We propose herein a novel method based on a linear regression model that incorporates static and dynamic PTT features to predict BP measures more accurately. Moreover, the proposed model considers the estimated systolic blood pressure (SBP) when estimating the diastolic blood pressure (DBP). Experimental results first show that the proposed method can predict the BP more accurately than conventional methods, with notably higher correlation scores and lower mean square errors. These results confirm the effectiveness of incorporating dynamic PTT features for accurate BP predictions. Next, our experimental results demonstrate that the proposed method attains a better DBP prediction capability, showing that the estimated SBP provides useful information for the DBP prediction.	digital back-propagation;effective method;mean squared error;sbp;tire-pressure monitoring system	Yi-Yen Hsieh;Ching-Da Wu;Shey-Shi Lu;Yu Tsao	2016	2016 IEEE Biomedical Circuits and Systems Conference (BioCAS)	10.1109/BioCAS.2016.7833867	simulation;engineering;artificial intelligence;forensic engineering	Robotics	7.728370372515445	-80.84422552271538	105496
65e5d7f4f51d0db3cddce8e68a105c2838cf2e1b	mobi-cog: a mobile application for instant screening of dementia using the mini-cog test	cognitive screening;mini cog test;dementia	In this paper, we present MOBI-COG which is an application that runs on a mobile device, such as a tablet or a smartphone, and provides an automated and instant dementia screening service. The MOBI-COG App is a complete automation of a widely used 3-minute dementia screening test called the Mini-Cog test, which is administered by primary caregivers for a quick screening of dementia in elderly. Besides asking the patient to remember and then recall a set of three words, the test involves a free-hand clock drawing test. The MOBI-COG App automates all these steps -- including the automatic assessment of the correctness of a clock drawn on the touch screen of a mobile device. We train the MOBI-COG App with over 1000 touch-drawn clocks and show that the system is capable of detecting and recognizing digits in less than 100 ms, in-situ (i.e. without the help of any back-end server), with 99.53% accuracy, and is robust to changes in people, sizes of the drawn digits, and screen sizes of the mobile devices. We perform a usability study of MOBI-COG involving eight healthy human subjects and show that the system is capable of performing all three steps of the test effectively. We also provide a summary of the users' comments on the application.	cog (project);correctness (computer science);mobile app;mobile device;sensor;server (computing);smartphone;tablet computer;touchscreen;usability testing	S. M. Shahriar Nirjon;Ifat Afrin Emi;Md. Abu Sayeed Mondol;Asif Salekin;John A. Stankovic	2014		10.1145/2668883.2668889	embedded system;simulation;computer hardware;engineering	HCI	5.183252239015516	-88.51490350171883	106107
9e4150261f10336ec0e0fbd6d1410101a2a5683b	wearable device based activity recognition and prediction for improved feedforward control		Recognizing and predicting future activity allows current actions based on likely future actions, such as suggesting a restaurant when someone is about to eat, or reminding someone of a potentially missed meeting. In this work, we seek to predict patient activity using wearable devices to improve control of blood glucose levels in people with Type 1 diabetes. We propose an architecture for activity detection and prediction using data from watch and phone based sensors. We further provide results for key components and show that they perform better than simplistic implementations. Using just gyroscope readings gives 63. 7% activity classification accuracy, with a precision of 87.8% for exercise. Prediction error is reduced by ∼66% versus naive implementations.	activity recognition;chomsky hierarchy;feed forward (control);gyroscope;naivety;sensor;wearable technology	Pranesh Navarathna;B. Wayne Bequette;Faye Cameron	2018	2018 Annual American Control Conference (ACC)	10.23919/ACC.2018.8430775	control engineering;architecture;real-time computing;wearable technology;feed forward;computer science;wearable computer;mean squared prediction error;activity recognition;recurrent neural network	HCI	3.937559179122024	-84.19065663050999	106257
231a06cd3a90d16ed47e4a337e22c6a31e461fbc	substitution of motor function of polio survivors who have permanent paralysis of limbs by using cybernic voluntary control	torque;patient rehabilitation diseases handicapped aids medical robotics;patient rehabilitation;joints;bioelectric phenomena calibration torque signal generators knee legged locomotion signal restoration motion control motion detection muscles;medical robotics;handicapped aids;hybrid assistive limb motor function assistance polio survivors permanent paralysis cybernic voluntary control rehabilitation approach hal bioelectrical signal activity preprocessing algorithm assistive torque generation polio viral infection sparse bioelectrical signals roboknee;viral infection;knee;robots;diseases;neurons;motor function;calibration;muscles	There are 10 to 20 millions polio survivors living around the world. Some of them cannot move their limbs by themselves. They feel inconveniences at several situations: climbing stairs; moving in a narrow space; walking. It is very difficult for polio survivors, who have permanent paralysis, to restore motor functions by using conventional rehabilitation approaches. Our aim is the assistance of motor functions of these polio survivors by using HAL. The movement support by using HAL with Cybernic Voluntary Control is possible if electrical signals based on intention of motions can be detected from the polio survivors. However, there are two issues to apply the CVC: First, the bioelectrical signal activity is extremely small and sparse in comparison with unimpaired person's signals. Second, we cannot apply conventional calibration methods to these polio survivors. This paper proposes a specific simplified CVC method for polio survivor with permanent paralysis or severe muscle weakness in their limbs. The method consists of two parts to solve the mentioned issues: a preprocessing algorithm for particular bioelectrical signals and a procedure for assistive torque generation without calibration. We applied the proposed method to the participant who has paralysis due to polio viral infection and confirmed the effectiveness. As a result, the HAL with proposed method generated enough assistive torque to lift up the participant's shank from extremely small and sparse bioelectrical signals. Although the participant's bioelectrical signal activity was extremely small and sparse, and also he could not move the left knee by himself. After we applied the proposed method, the participant was able to move his knee voluntarily. Consequently, we confirmed that the proposed method could assist the basic motor function of paralyzed polio survivor.	algorithm;analysis paralysis;assistive technology;common access card;hal;preprocessor;sparse matrix	Masahiro Shingu;Kiyoshi Eguchi;Yoshiyuki Sankai	2009	2009 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2009.5420698	robot;calibration;simulation;motor skill;computer science;engineering;artificial intelligence;torque	Robotics	9.978608907135692	-83.36958378072153	106327
c7d2c4b5c8c08eebfac1676b3fa3425e291b0b59	feature extraction of radar multiple-target echoes using wavelet packet transform with the best bases	transformation ondelette;methode domaine temps;entropia;caracter manuscrito;manuscript character;extraction forme;metodo dominio tiempo;classification;wavelet packet;time varying system;entropy criterion feature extraction;extraccion forma;methode domaine frequence;wavelet packet transform;frequency domain method;feature extraction;systeme parametre variable;entropie;pattern recognition;entropy criterion;divergence criterion;time domain method;entropy;transformacion ondita;reconnaissance forme;sistema parametro variable;extraction caracteristique;metodo dominio frecuencia;methode domaine temps frequence;reconocimiento patron;distance criterion;caractere manuscrit;pattern extraction;clasificacion;metodo dominio tiempo frecuencia;wavelet transformation;time frequency domain method	"""Extraction of effective features plays a key role in pattern recognition. A large number of patterns, such as speech, radar signals, earthquake signals, handwriting, etc. are of non-stationary signals or exhibit time-varying behavior. The features of these patterns are often located in both the time and frequency domains. The traditional methods fail to extract such kind of features. Fortunately, wavelet packet transform (WPT) can provide an arbitrary time-frequency decomposition for the signals, because a wavelet packet (WP) library contains many WP bases, which can handle the different components of a signal. Therefore, by selecting a suitable basis, which is called """"best basis"""", the effective features can be extracted. In this paper, three criteria are used to select the best WPT basis, namely: (1) distance criterion, (2) divergence criterion and (3) entropy criterion. Three algorithms to implement the above criteria are also provided. Experiments are conducted and the positive results are obtained."""	feature extraction;radar;wavelet packet decomposition	Shouyong Wang;Guangxi Zhu;Yuan Yan Tang	2003	IJPRAI	10.1142/S0218001403002253	entropy;speech recognition;computer science;machine learning;pattern recognition;mathematics;wavelet packet decomposition;algorithm	EDA	-4.4211370386237725	-93.05356634396963	106503
34367ccb417720355c5bf799aa065e26d89a16dd	digital screen detection using a head-mounted color light sensor		The immense growth of digital technology has led people to live in a multi-screen environment. If used for a prolonged time, digital screens (DS) can be considered harmful to the eyes leading to such health issues as computer vision syndrome (CVS). In this paper, we study the problem of Digital Screen Detection (DSD), using a new generation of small color light sensors that can observe four different components of the visible light, including two components of the blue light. To this aim, the sensor outputs are analyzed and different supervised machine learning algorithms are applied and compared to obtain a proper algorithm for DSD providing a trade-off between accuracy and cost. The proposed technique has been tested on 10 subjects performing experiments in three common office tasks. The results show that if the features are selected appropriately, high accuracy, of more than 86 %, can be achieved using Naïve Bayes and Random Forest classifiers.	algorithm;computer vision;concurrent versions system;digital electronics;document structure description;experiment;machine learning;naive bayes classifier;norm (social);random forest;sensor;supervised learning	Tommaso Martire;Payam Nazemzadeh;Alessia Cristiano;Alberto Sanna;Diana Trojaniello	2018	2018 IEEE International Symposium on Medical Measurements and Applications (MeMeA)	10.1109/MeMeA.2018.8438717	naive bayes classifier;computer vision syndrome;photodetector;computer vision;visible spectrum;random forest;ambient intelligence;computer science;artificial intelligence	Mobile	4.878187510269193	-83.99298774600993	106641
b5859722399d23d1004f5542d9e0bd71aeba8f9f	an inferential real-time falling posture reconstruction for internet of healthcare things	internet of healthcare things;bayesian network;sensors;posture reconstruction	This study constructs a approach to reproduce the real-time falls of humans, which uses a triaxial accelerometer and triaxial gyroscope to detect the occurrence of a fall, and an attitude algorithm to estimate the angles of each part of the human body, where internet of healthcare things collects the information of each sensor, and a Bayesian Network deduces the next action. Inferential Bayesian probability could present more complete data of a fall to healthcare providers. Even if the data are damaged by the transmission network or equipment, the next action still could be deduced by Bayesian probability, and because the fall could be reproduced in a 3D Model on the client side, the fall occurrence is shown more intuitively, and could thus serve as reference for first aid.	3d modeling;algorithm;bayesian network;bayesian programming;client-side;gyroscope;inferential programming;inferential theory of learning;internet;kalman filter;maxima and minima;poor posture;real-time clock;real-time locating system;real-time transcription	Chin-Feng Lai;Ying-Hsun Lai;Zhen-Wei Wu;Han-Chieh Chao	2017	J. Network and Computer Applications	10.1016/j.jnca.2017.02.006	client-side;computer science;the internet;accelerometer;simulation;bayesian probability;bayesian network	Vision	5.731460649391808	-82.33213546551485	106921
0a46f3951aca72a80de5594c3f04b57859bf9596	a long-term wearable vital signs monitoring system using bsn	geriatrics;biomedical monitoring;hand held device;quality of life;micromachined electrode;ecg;mems electrode;elderly;real time;wearable computers;saturation of arterial oxygen;wearable;blood pressure;analog front end;wireless communication;physiological signal;monitoring system;physiology;long term wearable vital signs monitoring system;electrocardiography;electrodes;wearable medical device;micromechanical devices;monitoring;zigbee;vital signs;led drive circuit;systolic blood pressure;hand held device long term wearable vital signs monitoring system wearable medical device elderly ecg saturation of arterial oxygen systolic blood pressure led drive circuit micromachined electrode physiological signal;medical device;driver circuits;patient monitoring;wearable computers blood pressure measurement driver circuits electrocardiography geriatrics medical signal processing micromechanical devices patient monitoring physiology;blood pressure measurement;biomedical monitoring electrocardiography body sensor networks pressure measurement blood pressure senior citizens real time systems light emitting diodes circuits electrodes;medical signal processing;cuffless blood pressure;cuffless blood pressure wearable vital signs monitoring mems electrode zigbee	Wearable medical devices provide great convenience to the elderly for the monitoring of vital signs at home. This paper describes a novel long-term wearable vital signs monitoring system which can real-time measure physiological signs such as ECG, SpO2 (saturation of arterial oxygen) and systolic blood pressure. The proposed device is easy to wear, convenient to use and has almost no impact on the quality of life. A miniaturized PCB integrated with the ECG analog front-end and SpO2 LED drive circuit is attached onto the BSN node. By simply wearing the chest band embedded with ECG micromachined electrodes and the ear-probe which incorporates LEDs and photodetector, the measured physiological signals can be wirelessly transmitted to a hand-held device, such as PDA phone, where the heart beat rate, SpO2 and systolic blood pressure are calculated and displayed.	analog front-end;embedded system;mobile device;personal digital assistant;printed circuit board;real-time clock;the quality of life;wearable computer	Ding G. Guo;Francis Eng Hock Tay;Lin Xu;L. M. Yu;Myo Naing Nyan;F. W. Chong;K. L. Yap;B. Xu	2008	2008 11th EUROMICRO Conference on Digital System Design Architectures, Methods and Tools	10.1109/DSD.2008.126	embedded system;computer science;blood pressure;geriatrics	HCI	8.753782906622959	-88.40109356511326	107217
d2b7541ba80b9ff32b2057b9bd96b51f0bbd9866	expression detection based on a novel emotion recognition method	ensemble learning;emotion recognition;data mining;feature selection;facial expression;rough set	As facial expression is an essential way to convey human’s feelings, in this paper, a dynamic selection ensemble learning method is proposed to analyze their emotion automatically. A feature selection algorithm is proposed at first based on rough set and the domain oriented data driven data mining theory, which can get multiple reducts and candidate classifiers. Then the nearest neighborhood of each unseen sample is found in a validation subset and the most accurate classifier is extracted from the candidate classifiers. Finally, the selected classifier is used to recognize unseen samples. Experimental results show that the proposed method is effective and suitable for emotion recognition.		Xun Gong;Yong Yang;Jianhui Lin;Tianrui Li	2011	Int. J. Comput. Intell. Syst.	10.1080/18756891.2011.9727762	rough set;computer science;machine learning;pattern recognition;data mining;ensemble learning;feature selection;facial expression	AI	-4.13815236312429	-85.39213593879899	107391
2a6d26610da3d49930881e425419c26454f261c6	continuous gesture recognition based on hidden markov model		Gesture is a compelling interactive mode, which makes interaction become more active than before. With the development of acceleration sensor, it has played an important role in gesture recognition of human-computer interaction. This paper represents a gesture recognition based on accelerometer, which is modeled by Hidden Markov Model (HMM). For “continuous” gesture recognition, it is a vital problem of how to obtain real valid data in a series of raw gesture data accurately and efficiently. To solve this, we proposed a new gesture detection method based on energy entropy and combined with threshold. Gesture data is analyzed in energy distribution of frequency domain by Short Time Fourier Transform (STFT), which can calculate energy entropy that reflects signal energy distribution. Then an appropriate threshold is set up to determine the start and end of gesture. Through experiments, the proposed method can be proved that it works well in detecting valid gesture data while recognition time and the computation load can be reduced in the case of guaranteeing recognition precision.		Meng Yu;Gang Chen;Zilong Huang;Qiang Wang;Yuan Chen	2016		10.1007/978-3-319-45940-0_1	maximum-entropy markov model;pattern recognition;markov model;hidden markov model;signature recognition	Vision	0.09404652142688598	-88.34553390972619	107426
a899527d7456d69e067cf6dacc23837c73da11e9	a wireless, low-power, smart sensor of cardiac activity for clinical remote monitoring	autonomic nervous system activity;heart rate variability;autonomic nervous system activity wearable sensors body sensors network biomedical electronics biomedical signal processing heart rate heart rate variability;wearable sensors;heart rate;biomedical electronics;biomedical signal processing;body sensors network;patient monitoring biomedical telemetry bluetooth body sensor networks cardiology intelligent sensors;wireless low power smart sensor software method bluetooth low energy radio technology wireless body network remote mobile monitoring clinical applications health data hardware method wireless communication cardiac activity monitoring heart rate assessment clinical remote monitoring cardiac activity;heart rate variability electrocardiography monitoring wireless communication software hardware	This paper presents the development of a wireless wearable sensor for the continuous, long-term monitoring of cardiac activity. Heart rate assessment, as well as heart rate variability parameters are computed in real time directly on the sensor, thus only a few parameters are sent via wireless communication for power saving. Hardware and software methods for heart beat detection and variability calculation are described and preliminary tests for the evaluation of the sensor are presented. With an autonomy of 48 hours of active measurement and a Bluetooth Low Energy radio technology, this sensor will form a part of a wireless body network for the remote mobile monitoring of vital signals in clinical applications requiring automated collection of health data from multiple patients.	beat detection;bluetooth;display resolution;embedded system;half rate;heart rate variability;low-power broadcasting;real-time clock;sensor;smart transducer;smartphone;wearable computer	Bertrand Massot;Tanguy Risset;Gregory Michelet;Eric McAdams	2015	2015 17th International Conference on E-health Networking, Application & Services (HealthCom)	10.1109/HealthCom.2015.7454552	embedded system;electronic engineering;real-time computing;wireless sensor network;engineering;body area network	Mobile	9.523250778557907	-88.36385957658291	107712
abdb39eca25e37893c7705ad26bbc5b8d21e63e7	bayesian identification of fixations, saccades, and smooth pursuits	probabilistic;classification;smooth pursuit;dynamic stimuli;model;eye tracking;online;open source	Smooth pursuit eye movements provide meaningful insights and information on subject’s behavior and health and may, in particular situations, disturb the performance of typical fixation/saccade classification algorithms. Thus, an automatic and efficient algorithm to identify these eye movements is paramount for eye-tracking research involving dynamic stimuli. In this paper, we propose the Bayesian Decision Theory Identification (I-BDT) algorithm, a novel algorithm for ternary classification of eye movements that is able to reliably separate fixations, saccades, and smooth pursuits in an online fashion, even for low-resolution eye trackers. The proposed algorithm is evaluated on four datasets with distinct mixtures of eye movements, including fixations, saccades, as well as straight and circular smooth pursuits; data was collected with a sample rate of 30 Hz from six subjects, totaling 24 evaluation datasets. The algorithm exhibits high and consistent performance across all datasets and movements relative to a manual annotation by a domain expert (recall: μ = 91.42%, σ = 9.52%; precision: μ = 95.60%, σ = 5.29%; specificity μ = 95.41%, σ = 7.02%) and displays a significant improvement when compared to I-VDT, an state-of-the-art algorithm (recall: μ = 87.67%, σ = 14.73%; precision: μ = 89.57%, σ = 8.05%; specificity μ = 92.10%, σ = 11.21%). For the algorithm implementation and annotated datasets, please contact the first author. CR Categories: I.5.1 [Computing Methodologies]: Pattern Recognition – Models; I.6.4 [Computing Methodologies]: Simulation and Modeling – Model Validation and Analysis; J.7 [Computer Applications]: Computers in Other Systems – Real Time;	algorithm;black–derman–toy model;computer terminal;decision theory;eye tracking;sampling (signal processing);sensitivity and specificity;subject-matter expert	Thiago Santini;Wolfgang Fuhl;Thomas C. Kübler;Enkelejda Kasneci	2016		10.1145/2857491.2857512	computer vision;simulation;eye tracking;biological classification;computer science;smooth pursuit;probabilistic logic	Vision	2.5059380182600006	-83.14669269037884	108355
b938ac3e07ebe85f1512ab5793aaf96ca4795a95	using phone sensors and an artificial neural network to detect gait changes during drinking episodes in the natural environment	alcohol;balance;gait;impairment;technology	BACKGROUND Phone sensors could be useful in assessing changes in gait that occur with alcohol consumption. This study determined (1) feasibility of collecting gait-related data during drinking occasions in the natural environment, and (2) how gait-related features measured by phone sensors relate to estimated blood alcohol concentration (eBAC).   METHODS Ten young adult heavy drinkers were prompted to complete a 5-step gait task every hour from 8pm to 12am over four consecutive weekends. We collected 3-axis accelerometer, gyroscope, and magnetometer data from phone sensors, and computed 24 gait-related features using a sliding window technique. eBAC levels were calculated at each time point based on Ecological Momentary Assessment (EMA) of alcohol use. We used an artificial neural network model to analyze associations between sensor features and eBACs in training (70% of the data) and validation and test (30% of the data) datasets.   RESULTS We analyzed 128 data points where both eBAC and gait-related sensor data were captured, either when not drinking (n=60), while eBAC was ascending (n=55) or eBAC was descending (n=13). 21 data points were captured at times when the eBAC was greater than the legal limit (0.08mg/dl). Using a Bayesian regularized neural network, gait-related phone sensor features showed a high correlation with eBAC (Pearson's r>0.9), and >95% of estimated eBAC would fall between -0.012 and +0.012 of actual eBAC.   CONCLUSIONS It is feasible to collect gait-related data from smartphone sensors during drinking occasions in the natural environment. Sensor-based features can be used to infer gait changes associated with elevated blood alcohol content.	12-hour clock;alcohol consumption;artificial neural network;blood alcohol concentration;data point;ecological momentary assessment;ethanol;gyroscope;inference;maxillary right central incisor mesial prosthesis;mental association;mobile app;network model;piezoelectric accelerometer;smartphone;young adult;accelerometers;magnetometers;sensor (device)	Brian Suffoletto;Pedram Gharani;Tammy Chung;Hassan A. Karimi	2018	Gait & posture	10.1016/j.gaitpost.2017.11.019	physical medicine and rehabilitation;psychology;phone;sliding window protocol;gait;artificial neural network;elevated blood-alcohol;accelerometer;machine learning;time point;pattern recognition;artificial intelligence	HCI	8.142981866475127	-85.78514176062312	108596
7cc60e91af2ebc1d71a087f63e0f58a860858622	sleep musicalization: automatic music composition from sleep measurements	113 computer and information sciences;a4 article in conference publication refereed	We introduce data musicalization as a novel approach to aid analysis and understanding of sleep measurement data. Data musicalization is the process of automatically composing novel music, with given data used to guide the process. We present Sleep Musicalization, a methodology that reads a signal from state-of-the-art mattress sensor, uses highly non-trivial data analysis methods to measure sleep from the signal, and then composes music from the measurements. As a result, Sleep Musicalization produces music that reflects the user’s sleep during a night and complements visualizations of sleep measurements. The ultimate goal is to help users improve their sleep and well-being. For practical use and later evaluation of the methodology, we have built a public web service at http://sleepmusicalization.net for users of the sleep sensors.	sensor;sleep (system call);sleep mode;wake-sleep algorithm;web service	Aurora Tulilaulu;Joonas Paalasmaa;Mikko Waris;Hannu Toivonen	2012		10.1007/978-3-642-34156-4_36	simulation;speech recognition;computer science;multimedia	Web+IR	2.7627018541801713	-85.57472542632277	108992
b5793c9251d6313f80cf4cda57a9d1002af651d5	a user-operated test of suprathreshold acuity in noise for adult hearing screening: the sun (speech understanding in noise) test	elderly;suprathreshold acuity in noise;speech in noise;adults;speech recognition;speech understanding;adult hearing screening ahs	A novel, user-operated test of suprathreshold acuity in noise for use in adult hearing screening (AHS) was developed. The Speech Understanding in Noise test (SUN) is a speech-in-noise test that makes use of a list of vowel-consonant-vowel (VCV) stimuli in background noise presented in a three-alternative forced choice (3AFC) paradigm by means of a touch sensitive screen. The test is automated, easy-to-use, and provides self-explanatory results (i.e., 'no hearing difficulties', or 'a hearing check would be advisable', or 'a hearing check is recommended'). The test was developed from its building blocks (VCVs and speech-shaped noise) through two main steps: (i) development of the test list through equalization of the intelligibility of test stimuli across the set and (ii) optimization of the test results through maximization of the test sensitivity and specificity. The test had 82.9% sensitivity and 85.9% specificity compared to conventional pure-tone screening, and 83.8% sensitivity and 83.9% specificity to identify individuals with disabling hearing impairment. Results obtained so far showed that the test could be easily performed by adults and older adults in less than one minute per ear and that its results were not influenced by ambient noise (up to 65dBA), suggesting that the test might be a viable method for AHS in clinical as well as non-clinical settings.		Alessia Paglialonga;Gabriella Tognola;Ferdinando Grandori	2014	Computers in biology and medicine	10.1016/j.compbiomed.2014.06.012	speech recognition;computer science;audiology	SE	-0.15633809266977175	-91.32410946889102	109459
fd5e6131095a04c248aa6bb6f4174a3da5263404	design and preliminary evaluation of a wearable device for mass-screening of sleep apnea	biomedical monitoring;performance evaluation;sleep apnea;monitoring;pressure sensors	Between 7-18 million Americans suffer from sleep disordered breathing (SDB), including those who suffer from obstructive sleep apnea (OSA). Despite this high prevalence and burden of OSA, existing diagnostic techniques remain impractical for widespread screening. In this study, we introduce a new model for OSA screening and describe an at-home wearable sleep mask (named ARAM) that can robustly track the wearers' sleep patterns. This monitoring is achieved using select sensors that enable screening and monitoring in a form-factor that can be easily self-instrumented. Based on feedback from sleep doctors and technicians, we incorporate the most valuable sensors for OSA diagnosis, while maintaining ease-of-use and comfort for the patient. We discuss the results of preliminary field trials, where both our sleep mask and a commercially available device were worn simultaneously to evaluate our device's robustness. Based on these results, we discuss next steps for the design of the screening system, including analyses techniques that would provide more efficient screening than existing systems.	evaluation;form factor (design);immunoreceptor tyrosine-based activation motif;intracranial hypertension;iteration;large;medicine, east asian traditional;name;patients;provider initiated episode new/ongoing;sdb (debugger);sleep apnea syndromes;sleep apnea, obstructive;sleep mode;usability;wearable computer;wearable technology;arylsulfate sulfotransferase activity;sensor (device)	Rohan S. Puri;Athanasios G. Athanassiadis;Niharika Gill;Sai Sri Sathya;Geetanjali Rathod;Akshat Wahi;Guy Satat;Maulik D. Majmudar;Pratik Shah	2016	2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2016.7591085	medicine;physical therapy;pressure sensor;biological engineering;physics;surgery	Visualization	10.001649004422523	-87.76779966746729	109681
549959162ea15b044f1cba85b8b09826791ed15b	using fsr based muscule activity monitoring to recognize manipulative arm gestures	fsr based muscule activity monitoring;muscle activity monitoring;arm mounted force sensitive resistors;muscle activity;force sensors;wearable computers;monitoring muscles force sensors mechanical sensors resistors leg system testing accelerometers arm fingers;manipulative arm gesture recognition;muscle monitoring information;accelerometer fsr based muscule activity monitoring manipulative arm gesture recognition muscle monitoring information arm mounted force sensitive resistors activity recognition muscle activity monitoring leg muscles;monitoring;sensor placement;wearable computers force sensors gesture recognition monitoring resistors;resistors;accelerometer;gesture recognition;leg muscles;activity recognition	We present an experiment that investigates the usefulness of muscle monitoring information from arm mounted force sensitive resistors (FSR) for activity recognition. The paper is motivated by previous work that has demonstrated the feasibility of using FSRs for muscle activity monitoring (on leg muscles) and presented some initial signals related to distinct arm activities. We systematically investigate the performance of an FSR system on 16 different manipulative gestures and 2 subjects. The aim is to test the limits of the system, compare them to established sensing modalities (3D acceleration and gyro), and establish the value of combining FSR with other sensing modalities. We also present a hardware setup that addresses key problems that were identified in previous work: large variations in the attachment force and sensor placement accuracy issues. For all classifiers the overall accuracy of the FSR system is in the middle between the accelerometer (between 5% and 10% better) and the gyro (between 2% and 11% worse). Adding FSRs to another sensor improves the accuracy by 1% to 29%.	activity recognition;attachments;gyro	Georg Ogris;Matthias Kreil;Paul Lukowicz	2007	2007 11th IEEE International Symposium on Wearable Computers	10.1109/ISWC.2007.4373776	embedded system;simulation;engineering;communication	Mobile	8.340625643646764	-85.81867522704418	109683
aafa40264cffb5adc678e31ee8664cfefff72f0d	object detection to assist visually impaired people: a deep neural network adventure		Blindness or vision impairment, one of the top ten disabilities among men and women, targets more than 7 million Americans of all ages. Accessible visual information is of paramount importance to improve independence and safety of blind and visually impaired people, and there is a pressing need to develop smart automated systems to assist their navigation, specifically in unfamiliar healthcare environments, such as clinics, hospitals, and urgent cares. This contribution focused on developing computer vision algorithms composed with a deep neural network to assist visually impaired individual’s mobility in clinical environments by accurately detecting doors, stairs, and signages, the most remarkable landmarks. Quantitative experiments demonstrate that with enough number of training samples, the network recognizes the objects of interest with an accuracy of over 98% within a fraction of a second.	deep learning;object detection	Fereshteh S. Bashiri;Eric LaRose;Jonathan C. Badger;Roshan M. D'Souza;Zeyun Yu;Peggy L. Peissig	2018		10.1007/978-3-030-03801-4_44	artificial intelligence;computer science;computer vision;object detection;doors;human–computer interaction;artificial neural network;urgent cares;stairs;blindness;adventure	Vision	6.537522642888386	-83.39127309569857	110216
bd64ee6096bd5d2180731775df0848278033c9f0	inferring complex human behavior using a non-obtrusive mobile sensing platform		Thanks to the decreasing cost, increasing mobility, and wider use of sensors, a great number of possible applications have recently emerged, including applications that may impact the high-level goals in people’s lives. Applications can be found in many areas ranging from medical devices to consumer devices. Information about activity and context can be inferred from sensors and be used to provide automated recommendations. Previous research has suggested that, using simple sensors, devices can improve human life on an everyday basis. Interesting examples can be found in the area of fluid intake monitoring [2,7]. Also, activity and context recognition from wearable sensors have been investigated [8–11]. Still, many challenges remain open in this area, including how to effectively determine the sensor data that is valuable, how to select sensors and also how to best connect the low-level sensory data with high-level goals that are explicitly or implicitly monitored by a user. As demand for these devices increases it is desired to generalize sensor platforms to monitor a broad set of activities. Moreover, it is desirable to make devices non-obtrusive and more naturally fit into our daily life. This further motivates researchers to design simple devices able to complete complex sensor-supported tasks in real-time. In this paper we:	high- and low-level;real-time clock;sensor;wearable technology	Bruce DeBruhl;Michele Cossalter;Roy Want;Ole J. Mengshoel;Pei Zhang	2010		10.1007/978-3-642-29336-8_18	computer engineering;computer security;activity recognition;computer science;ranging	HCI	4.644036268073046	-86.0462124039014	110389
c5eee715567a5167c2b8ecac904e86109efab9b8	medicament dispensation system with patient supervision	patient care biomedical electronics;patient care;biomedical electronics;not self reliant persons medical electronics medicament dispensation patient supervision safety functions;medicament dispensation system built in gsm module innovative safety features drugs home environments hospital environments patient supervision;prototypes hospitals drugs safety gsm	In this article a safe and affordable system of medicaments dispensation is described. The system can be utilized in both hospital and home environments. The main purpose of the device is medicament dispensation accordingly to doctor prescriptions. As a first element of the system a safe medicament dispenser prototype was built. The device is designed to fulfill the needs of patients forced to take drugs accordingly to prescribed scheme. Innovative safety features include a built-in GSM module. This feature ensure that a patient has taken the medicaments and in case of lack of patient reaction alarms a supervisor. A system to avoid therapy errors can also be applied.	built-in self-test;ccir system a;prototype;requirement;teller assist unit	Piotr Krasinski;Krzysztof Kowalczynski;Bartosz Pekoslawski;Andrzej Napieralski	2013	Proceedings of the 20th International Conference Mixed Design of Integrated Circuits and Systems - MIXDES 2013		medicine;pediatrics;biological engineering	Robotics	7.454304750350865	-89.22582051019783	110566
00cbd9e0f7fe4af5aaa77f638d2104e566e49457	brain computer interface-based smart environmental control system	biomedical monitoring;control systems;rhythm;brain computer interface;medical signal processing brain computer interfaces electroencephalography;smart house;wireless communication;brain modeling;power line communication;electroencephalography signal processing biomedical monitoring wireless communication control systems rhythm brain modeling;electroencephalogram brain computer interface smart house universal plug and play simple control protocol power line communication;signal processing;simple control protocol;universal plug and play;brain computer interfaces;electroencephalography;electroencephalogram;medical signal processing;real time cognitive state detection brain computer interface based smart environmental control system bsecs human physiological state bci universal plug and play upnp smart house applications wireless physiological signal acquisition module embedded signal processing module simple control protocol scp power line communication plc physiological signal acquisition electroencephalogram eeg	A Brain computer interface-based Smart Environmental Control System (BSECS) was proposed in this study. Many environmental control systems have been proposed to improve human life quality recently. However, few researches focused on environment control by using human's physiological state directly. Based on the advantage of our technique on Brain Computer Interface (BCI), we combined BCI technique with Universal Plug and Play (UPnP) home networking for smart house applications. Our BSECS mainly consists of a wireless physiological signal acquisition module, an embedded signal processing module, a Simple Control Protocol (SCP)/ Power Line Communication (PLC) environment controller, and a host system. Here, the physiological signal acquisition module and embedded signal processing module were designed for long-term electroencephalogram (EEG) monitoring and real-time cognitive state detection respectively. The advantages of low-power consumption and small volume of the above modules are suitable for smart house applications in daily life. The proposed BSECS has been verified in a practical demo room, and can be simply extended and integrated with the UPnP home networking for other applications.	brain–computer interface;control system;electroencephalography;embedded system;low-power broadcasting;power-line communication;real-time clock;signal processing;smart house;universal plug and play	Chien-Zhi Ou;Bor-Shyh Lin;Che-Jui Chang;Chin-Teng Lin	2012	2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing	10.1109/IIH-MSP.2012.74	embedded system;brain–computer interface;computer science;signal processing;computer security	Robotics	9.397668612258588	-89.68628781457033	110672
93751b07bd4702979eddcc2e6866d1ad983676ff	activity recognition in planetary navigation field tests using classification algorithms applied to accelerometer data	zero gravity experiments;accelerometry aerospace medicine algorithms electrocardiography heart rate humans models theoretical monitoring ambulatory motor activity signal processing computer assisted skin temperature;feature detection;biomechanics;performance classification accelerometer activity recognition feature detection;performance classification;feature extraction;signal classification;knn algorithm activity recognition planetary navigation field tests classification algorithms subject activity information single accelerometer data astronaut field tests reduced gravity environments accelerometer data features unobtrusive well being monitoring leg movement k nearest neighbors algorithm;accelerometer;aerospace biophysics;accelerometers;zero gravity experiments accelerometers aerospace biophysics biomechanics biomedical measurement feature extraction medical signal processing signal classification;accelerometers classification algorithms feature extraction sensors navigation acceleration accuracy;biomedical measurement;medical signal processing;activity recognition	Accelerometer data provide useful information about subject activity in many different application scenarios. For this study, single-accelerometer data were acquired from subjects participating in field tests that mimic tasks that astronauts might encounter in reduced gravity environments. The primary goal of this effort was to apply classification algorithms that could identify these tasks based on features present in their corresponding accelerometer data, where the end goal is to establish methods to unobtrusively gauge subject well-being based on sensors that reside in their local environment. In this initial analysis, six different activities that involve leg movement are classified. The k-Nearest Neighbors (kNN) algorithm was found to be the most effective, with an overall classification success rate of 90.8%.	activity recognition;classification;extraction;fatigue;k-nearest neighbors algorithm;movement;planetary scanner;reside;stepping level;accelerometers;sensor (device)	Wen Song;Carl Ade;Ryan M Broxterman;Thomas Barstow;Thomas Nelson;Steve Warren	2012	2012 Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/EMBC.2012.6346247	computer vision;simulation;speech recognition;computer science;engineering;biomechanics;machine learning;accelerometer;activity recognition	SE	9.142581670114836	-86.40307166017621	110822
da5a33096cc78ed8a62c535554edbc0b2dd08f46	bed exiting monitoring system with fall detection for the elderly living alone	sensor systems;senior citizens;medical services;monitoring;pressure sensors;infrared sensors;cameras	A bed exiting monitoring system with fall detection function for the elderly living alone is proposed in this paper. By separating the process of exiting or getting on the bed into several significant movements, the sensor system composed of infrared and pressure sensors attached to the bed will correspondingly respond to these movements. Using the finite state machine (FSM) method, the bed exiting state and fall events can be detected according to specific transitions recognized by the sensor system. Experiments with plausible assessment are conducted to find the optimal sensor combination solution and to verify the FSM algorithm, which is demonstrated feasible and effective in practical use.	algorithm;experiment;finite-state machine;sensor	Changchun Lu;Jian Huang;Zhi Lan;Qiang Wang	2016	2016 International Conference on Advanced Robotics and Mechatronics (ICARM)	10.1109/ICARM.2016.7606895	embedded system;simulation;engineering;forensic engineering	Robotics	6.924834334675955	-83.6773865496815	110946
3af4a85f558de6805846e3616863cebad73bc3b2	thermal comfort and physical activity in an office setting		Growing awareness of the health risks associated with sedentary behaviour have raised concerns about the health and safety of office workers who spend as much as 77% of their work hours sedentary and often for prolonged periods. In this research we look at the association between building heating, ventilation and air conditioning (HVAC), and physical activity at work measured using ambient temperature. Two months of Fitbit 1-min step count and heartrate data from 15 office-based workers was used along with desk-based USB temperature loggers capturing 15-minute temperature data over the collection period. Preliminary results identify a strongly significant correlation between one-minute interval step count, temperature and heartrate data were found (P > 0.000). Further research on the relationship between physical activity and thermal activity is warranted, using data from building management systems to capture data not only temperature but other measures of thermal comfort such as humidity and air flow.		Yasmin F. van Kasteren;Stephanie Champion;Lua Perimal-Lewis	2019		10.1145/3290688.3290733		HCI	7.759718842560777	-85.69645748712054	111416
b320a29e43b836d2089faa1e3e840d8d3e0f8459	crowdsourcing empathetic intelligence: the case of the annotation of emma database for emotion and mood recognition	affective annotation;multimodal database;emotion recognition;mood recognition;crowdsourcing	Unobtrusive recognition of the user's mood is an essential capability for affect-adaptive systems. Mood is a subtle, long-term affective state, often misrecognized even by humans. The challenge to train a machine to recognize it from, for example, a video of the user, is significant, and already begins with the lack of ground truth for supervised learning. Existing affective databases consist mainly of short videos, annotated in terms of expressed emotions rather than mood. In very few cases, we encounter perceived mood annotations, of questionable reliability, however, due to the subjectivity of mood estimation and the small number of coders involved. In this work, we introduce a new database for mood recognition from video. Our database contains 180 long, acted videos, depicting typical daily scenarios, and subtle facial and bodily expressions. The videos cover three visual modalities (face, body, Kinect data), and are annotated in terms of emotions (via G-trace) and mood (via the Self-Assessment Manikin and the AffectButton). To annotate the database exhaustively, we exploit crowdsourcing to reach out to an extensive number of nonexpert coders. We validate the reliability of our crowdsourced annotations by (1) adopting a number of criteria to filter out unreliable coders, and (2) comparing the annotations of a subset of our videos with those collected in a controlled lab setting.	adaptive system;affective computing;categorical variable;content-control software;control system;crowdsourcing;database;emma;emotion recognition;ground truth;kinect;microsoft outlook for mac;poor posture;supervised learning	Christina Katsimerou;Joris Albeda;Alina Huldtgren;Ingrid Heynderickx;Judith Redi	2016	ACM TIST	10.1145/2897369	computer science;multimedia;world wide web;crowdsourcing	AI	-0.10940461039290408	-83.85428232015134	112047
7e74252e62307e539c4e1630988fc5d5dd3dd308	system for posture evaluation and correction - development of a second prototype for an intelligent chair		The sitting position has become one of the most common postures in developed countries. However, assuming a poor sitting posture leads to several health problems, namely back, shoulder and neck pain. In a previous work, an intelligent chair was developed and was shown to classify and correct the seating position. This work describes improvements on this intelligent chair prototype culminating with the development of a new prototype. The improvements of this new prototype are presented, resulting in new studies for posture identification. Pressure maps for 12 sitting postures were gathered in order to automatically detect user’s posture through a neural network algorithm, obtaining an overall posture classification of around 81%.	algorithm;artificial neural network;map;poor posture;prototype	Hugo Pereira;Leonardo Martins;Rui Almeida;Bruno Ribeiro;Cláudia Quaresma;Adelaide Ferreira;Pedro Vieira	2015			embedded system;simulation;computer hardware	HCI	8.93870196175409	-85.08074825548468	112324
97b930a4fa4670a609b6ee8811409090fe55b313	integrating gaze tracking and head-motion prediction for mobile device authentication: a proof of concept	authentication;gaze tracking;head motions;neural networks;smart mobile devices	We introduce a two-stream model to use reflexive eye movements for smart mobile device authentication. Our model is based on two pre-trained neural networks, iTracker and PredNet, targeting two independent tasks: (i) gaze tracking and (ii) future frame prediction. We design a procedure to randomly generate the visual stimulus on the screen of mobile device, and the frontal camera will simultaneously capture head motions of the user as one watches it. Then, iTracker calculates the gaze-coordinates error which is treated as a static feature. To solve the imprecise gaze-coordinates caused by the low resolution of the frontal camera, we further take advantage of PredNet to extract the dynamic features between consecutive frames. In order to resist traditional attacks (shoulder surfing and impersonation attacks) during the procedure of mobile device authentication, we innovatively combine static features and dynamic features to train a 2-class support vector machine (SVM) classifier. The experiment results show that the classifier achieves accuracy of 98.6% to authenticate the user identity of mobile devices.	area striata structure;artificial neural network;authentication;eye movements;eye tracking;frame (physical object);image resolution;mobile device;motion;movement;neural network simulation;randomness;smart device;support vector machine;trusted platform module	Zhuo Ma;Xinglong Wang;Rui Ma;Zhuzhu Wang;Jianfeng Ma	2018		10.3390/s18092894	electronic engineering;gaze;proof of concept;theoretical computer science;engineering;mobile device;authentication	HCI	1.6335765054502676	-82.6231379530544	112341
c797ceb8d1a69a64ba63aa72d5c40afff4b35ca4	point-of-care monitoring and diagnostics for autoimmune diseases	dna;patient diagnosis;autoimmune disease point of care monitoring;genomics;rheumatoid arthritis management;pocemon platform;autoimmune disease diagnostics;intelligent diagnosis algorithms;diagnostic lab on chip device;autoimmune disease;point of care diagnostics;genetics;chip;patient monitoring biomedical electronics biomems biotechnology genomics integrated circuits lab on a chip microfluidics patient diagnosis;primary health care;information and communication technology;biomedical electronics;microfluidics;immune system;chronic multiple sclerosis management;autoimmune disease early prognosis;monitoring diseases multiple sclerosis genomics bioinformatics medical services europe immune system arthritis communications technology;diseases;lab on a chip;patient monitoring;hla typing;microelectronics;multiple sclerosis;biotechnology;intelligent diagnosis algorithms autoimmune disease point of care monitoring autoimmune disease diagnostics pocemon platform autoimmune disease early prognosis diagnostic lab on chip device genomic microarrays hla typing point of care diagnostics immune system status monitoring chronic multiple sclerosis management rheumatoid arthritis management microfluidics microelectronics;integrated circuits;point of care;rheumatoid arthritis;biomems;medical diagnostic imaging;genomic microarrays;immune system status monitoring;bioinformatics	In this paper we present the POCEMON platform, a platform aiming to the early prognosis and diagnosis of autoimmune diseases at any point of care, even the primary. The objective of the POCEMON platform is the development of a diagnostic lab-on-chip device based on genomic microarrays of HLA-typing. The POCEMON is going to advance and promote the primary health care across Europe by supporting a) point-of-care diagnostics, b) monitoring of immune system status and c) management of the chronic multiple sclerosis (MS) and rheumatoid arthritis (RA) autoimmune diseases. The platform combines high-end Information and Communication Technologies based on microfluidics, microelectronics, microarrays and intelligent diagnosis algorithms.	algorithm;emoticon;microarray	Fanis G. Kalatzis;Themis P. Exarchos;Nikolaos Giannakeas;Sofia Markoula;Elisavet Hatzi;Panagiotis Rizos;Ioannis Georgiou;Dimitrios I. Fotiadis	2008	2008 8th IEEE International Conference on BioInformatics and BioEngineering	10.1109/BIBE.2008.4696778	chip;information and communications technology;genomics;microfluidics;point of care;immune system;lab-on-a-chip;bioinformatics;point-of-care testing;remote patient monitoring;primary health care;immunology;genetics;bio-mems;microelectronics;dna;human leukocyte antigen	Robotics	0.9706621897370077	-80.4379350498257	112581
ac40221a6859a7af8457c1b8e8735bc00c75645d	keystroke recognition		Keystroke recognition is a behavioral biometric which authenticates (verifies the claimed identity) or identifies an individual (recognizes a valid user) based on their unique typing rhythm. Unlike physiological biometrics, such as fingerprint or iris, where specialized sensors are necessary to collect data, keystroke biometrics utilizes off-theshelf physical keyboards or virtual keyboards in smartphones or PDAs. Thus, keystroke recognition offers a low-cost authentication and is easily deployed in a variety of scenarios. Two events constitute a keystroke event: key down and key up. The key down occurs when the typist presses a key. The key up is associated with the event that occurs when the pressed key is released. Using these two events, a set of intra-key and inter-key features commonly called hold times, delay times and key down-key down times can be extracted. Hold times constitute the finite amount of time a particular key is pressed. Delay times constitute the latency between the release of the current key and the pressing of the next key. Delay times may be negative given that individuals can press the next key prior to releasing the current key. Finally, key down-key down time represents the finite amount of time between successive key down events. While other keystroke events can be extracted (such as key pressure and location of a particular Shift key and special keys such as Alt, Ctrl, etc.), these features are not commonly used as their collection from commercially available keyboards is not straightforward. Keystroke data can come either from a predetermined body of text (fixed-text analysis) or from any unrestricted text (free-text analysis). Fixed-text analysis from strings similar to passwords can be used for one-time authentication. On the other hand, free-text analysis can allow more complex usage scenarios. Given sufficient corpus of user activity, it can support continual user authentication and ensure that an impostor has not gained control of the device. Similar to other behavioral biometrics, keystroke recognition exhibits a phase in which the individual learns the motor skills required to enter text entries. For the fixed text, habituation phase includes the cognitive activity related to string memorization as well as the adaptation of motor	alt attribute;authentication;biometrics;downtime;encryption;event (computing);fingerprint;keystroke dynamics;password;personal digital assistant;sensor;smartphone;text corpus;virtual keyboard	Sean Banerjee;Zahid Syed;Nick Bartlow;Bojan Cukic	2015		10.1007/978-1-4899-7488-4_205		Security	-2.865180235568737	-81.75969708958735	112823
4cd688a3a1bb134ea0c6c32e0386ec9e7add7086	dual-frequency active rfid solution for tracking patients in a children's hospital. design method, test procedure, risk analysis, and technical solution	analyse risque;children hospital intensive care unit;patient management;object recognition;pediatrics;identificacion por radiofrecuencia;intensive care unit;securite;patients tracking;risk analysis;gestion risque;risk management;hospitals;multicouche;radiofrequency identification active rfid tags pediatrics hospitals design methodology testing risk analysis risk management nonhomogeneous media process design;identification par radiofrequence;multiple layer;patient management dual frequency active rfid solution radio frequency identification patients tracking children hospital intensive care unit clinical risk management process failure modes and effects analysis method risk analysis multilayer method;clinical risk management process;analisis riesgo;medical services;design method;dual frequency active rfid solution;capa multiple;risk analysis design methodology medical services;specification tests;failure mode and effect analysis;safety;multilayer method;poursuite cible;defaillance;antennas;failure modes and effects analysis method;radio frequency identification;coherence;patient safety;gestion riesgo;failures;coherencia;functional requirement;target tracking;multiple frequency;seguridad;fallo;radiofrequency identification;tracking;frequence multiple;tracking hospitals radiofrequency identification risk analysis;frecuencia multiple;design methodology	This work addresses the problem of reliable identification and tracking of children in an intensive care unit in a children's hospital. Tracking and identification of patients are critical for the clinical risk management process, particularly for a children's hospital intensive care unit where patients' identities can easily be confused. This work offers a multilayer approach to the design of the process of identification and tracking; it gives an active radio-frequency identification (RFID) solution that best fits all the given constraints. The paper is divided in the following sections: design (where a multilayer method is provided, including project aims, functional requirements, and technical constraints); risk analysis [a failure modes and effects analysis (FMEA) method is used to assess the risks of each stage of the process of patient management]; technical solution with a specific test phase and a review of the risk analysis results. As a result of the proposed approach, we got a strong coherence between the initial aims and the technical solution, improving patient safety and reducing the clinical risk in the process of tracking and identifying patients.	fits;failure mode and effects analysis;functional requirement;it risk management;radio frequency;radio-frequency identification	Guido Biffi Gentili;Fabrizio Dori;Ernesto Iadanza	2010	Proceedings of the IEEE	10.1109/JPROC.2010.2053330	simulation;design methods;risk management;biological engineering;physics	EDA	0.6963111047328167	-81.41003834727174	113565
11531bdc13c1939a5d22f66b5ec05a1497303156	smartphone-based hearing screening in noisy environments	health research;uk clinical guidelines;biological patents;europe pubmed central;audiometer;citation search;ubiquitous healthcare;uk phd theses thesis;life sciences;smartphone;application;uk research reports;medical journals;hearing;europe pmc;biomedical research;bioinformatics	It is important and recommended to detect hearing loss as soon as possible. If it is found early, proper treatment may help improve hearing and reduce the negative consequences of hearing loss. In this study, we developed smartphone-based hearing screening methods that can ubiquitously test hearing. However, environmental noise generally results in the loss of ear sensitivity, which causes a hearing threshold shift (HTS). To overcome this limitation in the hearing screening location, we developed a correction algorithm to reduce the HTS effect. A built-in microphone and headphone were calibrated to provide the standard units of measure. The HTSs in the presence of either white or babble noise were systematically investigated to determine the mean HTS as a function of noise level. When the hearing screening application runs, the smartphone automatically measures the environmental noise and provides the HTS value to correct the hearing threshold. A comparison to pure tone audiometry shows that this hearing screening method in the presence of noise could closely estimate the hearing threshold. We expect that the proposed ubiquitous hearing test method could be used as a simple hearing screening tool and could alert the user if they suffer from hearing loss.	audiometry;audiometry, pure-tone;headphone device component;headphones;hearing loss, mixed conductive-sensorineural;hearing tests;high-throughput satellite;how true feel alert right now;hypotrichosis simplex of scalp;microphone device component;noise (electronics);saline solution, hypertonic;selective calling;shift jis;smartphone;algorithm;hearing impairment	Youngmin Na;Hyo Sung Joo;Hyejin Yang;Soojin Kang;Sung Hwa Hong;Jihwan Woo	2014		10.3390/s140610346	medical research;speech recognition;acoustics;computer science;bioinformatics;engineering	HCI	-0.05641604972929672	-91.33859759118306	113647
5e0ed8212356af8a9810b88984463b3088ec8289	a real-time wireless brain–computer interface system for drowsiness detection	biofeedback;biomedical monitoring;brain computer interface bci drowsiness detection electroencephalogram eeg;traffic accident;road accidents;brain computer interface;personal computer;drowsiness detection;real time drowsiness monitoring;human cognitive state;real time;brain computer interface bci;real time wireless brain computer interface;eeg monitoring;biological control systems;patient monitoring brain computer interfaces electroencephalography neurophysiology;computerized monitoring;eeg monitoring real time wireless brain computer interface drowsiness detection electroencephalogram drowsy driving real time drowsiness monitoring traffic accident human cognitive state biofeedback physiological signal acquisition module;physiological signal acquisition module;signal processing;detection algorithm;patient monitoring;humans;drowsy driving;neurophysiology;brain computer interfaces;electroencephalography;electroencephalogram eeg;real time systems electroencephalography computerized monitoring signal processing biomedical monitoring brain computer interfaces road accidents microcomputers humans biological control systems;electroencephalogram;article;microcomputers;real time systems	A real-time wireless electroencephalogram (EEG)-based brain-computer interface (BCI) system for drowsiness detection has been proposed. Drowsy driving has been implicated as a causal factor in many accidents. Therefore, real-time drowsiness monitoring can prevent traffic accidents effectively. However, current BCI systems are usually large and have to transmit an EEG signal to a back-end personal computer to process the EEG signal. In this study, a novel BCI system was developed to monitor the human cognitive state and provide biofeedback to the driver when drowsy state occurs. The proposed system consists of a wireless physiological signal-acquisition module and an embedded signal-processing module. Here, the physiological signal-acquisition module and embedded signal-processing module were designed for long-term EEG monitoring and real-time drowsiness detection, respectively. The advantages of low owner consumption and small volume of the proposed system are suitable for car applications. Moreover, a real-time drowsiness detection algorithm was also developed and implemented in this system. The experiment results demonstrated the feasibility of our proposed BCI system in a practical driving application.	biofeedback;bluetooth;brain–computer interface;causality;chimeric antigen receptor;computation;electroencephalography;embedded system;embedding;feel drowsy;interface device component;ions;lithium;memory management controller;mitomycin;personal computer;preparation;real-time clock;real-time transcription;rechargeable battery;scalability;signal processing;socket device component;software design;somnolence;tire-pressure monitoring system;traffic accidents;unsupervised learning;wearable computer;alertness;algorithm;disease transmission;electrode;midline cell component	Chin-Teng Lin;Che-Jui Chang;Bor-Shyh Lin;Shao-Hang Hung;Chih-Feng Chao;I-Jan Wang	2010	IEEE Transactions on Biomedical Circuits and Systems	10.1109/TBCAS.2010.2046415	embedded system;brain–computer interface;neuroscience;simulation;computer science;signal processing;neurophysiology	Embedded	9.319793168119823	-89.56867433233457	114102
8b7670dbe0ed006887cd8e8de5da9bd31fec4ea3	implementation of context aware e-health environments based on social sensor networks	biological patents;biomedical journals;wireless body area networks;text mining;social sensors;europe pubmed central;citation search;citation networks;research articles;abstracts;open access;life sciences;clinical guidelines;full text;back office;rest apis;orcids;europe pmc;biomedical research;deterministic radio planning;bioinformatics;literature search	In this work, context aware scenarios applied to e-Health and m-Health in the framework of typical households (urban and rural) by means of deploying Social Sensors will be described. Interaction with end-users and social/medical staff is achieved using a multi-signal input/output device, capable of sensing and transmitting environmental, biomedical or activity signals and information with the aid of a combined Bluetooth and Mobile system platform. The devices, which play the role of Social Sensors, are implemented and tested in order to guarantee adequate service levels in terms of multiple signal processing tasks as well as robustness in relation with the use wireless transceivers and channel variability. Initial tests within a Living Lab environment have been performed in order to validate overall system operation. The results obtained show good acceptance of the proposed system both by end users as well as by medical and social staff, increasing interaction, reducing overall response time and social inclusion levels, with a compact and moderate cost solution that can readily be largely deployed.	atm adaptation layer;appliance;autonomy;behaviorial habits;bluetooth;british informatics olympiad;centralized computing;data acquisition;deploy;digitorenocerebral syndrome;distributed computing;entity name part qualifier - adopted;exhibits as topic;heart rate variability;heating;input/output;large-signal model;light;living lab;mhealth;mental disorders;microcontroller;numerous;output device;prototype;requirement;response time (technology);server (computing);signal processing;social work (discipline);systems architecture;transceiver device component;transmitter;usability;user experience;water consumption;sensor (device)	Erik Aguirre;Santiago Led;Peio López-Iturri;Leyre Azpilicueta;Luis Serrano;Francisco Falcone	2016	Sensors	10.3390/s16030310	embedded system;text mining;medical research;telecommunications;computer science;bioinformatics;engineering;electrical engineering;data science;data mining;world wide web	Mobile	8.87661841819488	-89.33254019495797	114105
f7d01ab6363e0f6ad5b25feb973a951447f514cb	robotic automated external defibrillator ambulance for emergency medical service in smart cities	smart cities cardiology defibrillators medical robotics mobile robots patient treatment;smart cities robotic automated external defibrillator ambulance emergency medical service smart service emergency treatment aed cardiac arrest;automated external defibrillator;cardiac arrest;robotic automated external defibrillator ambulance emergency medical service smart service emergency treatment aed cardiac arrest smart cities;robots intelligent vehicles smart cities intelligent vehicles cardiac arrest automated external defibrillator emergency services;smart cities;emergency management smart healthcare smart cities;intelligent vehicles;robots;smart healthcare smart cities emergency management;cardiology defibrillators medical robotics mobile robots patient treatment smart cities;emergency services	Smart cities essentially require the state-of-the-art technologies that can provide smart service in various aspects, and robotic systems are one of the key solutions for such requirements. Time is a critical issue when dealing with people who experience a sudden cardiac arrest that unfortunately could die due to inaccessibility of the emergency treatment. Therefore, an immediate treatment using automated external defibrillator (AED) must be administered to the victim within a few minutes after collapsing. Hence, we have designed and developed the ambulance robot, which brings along an AED in a sudden event of cardiac arrest and facilitates various modes of operation from manual to autonomous functioning to save someones lives in smart cities. The details of the design and development of such robot are presented in this paper.	autonomous robot;block cipher mode of operation;die (integrated circuit);requirement;smart city	Hooman Aghaebrahimi Samani;Rongbo Zhu	2016	IEEE Access	10.1109/ACCESS.2016.2514263	robot;simulation;computer science;artificial intelligence;computer security	Robotics	6.814605981851716	-89.69159277601223	114959
859d8e54f6a67fb5a7b46e77083d9b73af2f98bf	home automation: hmm based fuzzy rule engine for ambient intelligent smart space		in this paper, we proposed a new type of decisionmaking system to achieve the intelligent goal for automated smart environments. The artificial intelligence techniques, used as building blocks to understand inhabitant activity patterns. The collected information fused to a central inference engine based on Hidden Markov model and Fuzzy rules for taking appropriate actions to communicate and control various home appliances. We proposed a novel CASH (cognitive automated smart home) architecture, based on the Hidden Markov Model and the fuzzy rule based system. The Hidden Markov Model and fuzzy rules are well equipped to address the spatio-temporal activity pattern recognition problem and to trigger appropriate task execution rules. Keywords— home automation; rule mining; smart home; artificial intelligence; expert system; cyber physical system.	artificial intelligence;business rules engine;cash;expert system;fuzzy rule;hidden markov model;home automation;inference engine;markov chain;pattern recognition;rule-based system;smart environment	Gopal Jamnal;Xiaodong Liu;Lu Fan	2017		10.18293/SEKE2017-116	computer engineering;real-time computing;hidden markov model;computer science;home automation;fuzzy rule;control engineering	AI	2.2750496277242505	-86.5510692148941	115250
7093f28ada0a728cea54e0dc9169d5e217826cb3	a cloud based bluetooth low energy tracking system for dementia patients	tracker;telemedicine bluetooth cloud computing global positioning system low power electronics medical disorders smart phones;location system cloud based bluetooth low energy tracking system location based services dementia patients safety water proof bluetooth low energy tag ble tag cr2302 battery ble technology smartphones cloud services google;location based service;dementia google bluetooth batteries educational institutions cloud computing mobile computing;bluetooth low energy;cloud services;cloud services location based service tracker bluetooth low energy	Location based services of trackers can keep dementia patients safe, but traditional GPS tracker or smartphone based solution device need to be removed for recharging or when taking bath. A water-proof Bluetooth Low Energy (BLE) tag with a CR2302 battery can be used over a year so that it can be worn all the time. By combining BLE technology, smartphones and cloud services provided by Google, we can build a practical location and tracking system with minimal cost.	bluetooth;cloud computing;global positioning system;smartphone;tracking system	Yaw-Jen Lin;Heng-Shuen Chen;Mei-Ju Su	2015	2015 Eighth International Conference on Mobile Computing and Ubiquitous Networking (ICMU)	10.1109/ICMU.2015.7061043	embedded system;engineering;hybrid positioning system;computer security;computer network	Mobile	5.9528586048843914	-88.18631350431953	115375
e7f3e255e886cac7ae8ad9cf0f513c5e9f6a81b7	probabilistic novelty detection for acoustic surveillance under real-world conditions	anomaly;transformation ondelette;national security;modelizacion;acustica audio;traitement signal;interfase usuario;detection acoustique;decomposition domaine;frecuencia audible;media technology;audio signal processing;frequence audible;acoustic properties;domain decomposition;standards;smart home;nouveaute;securite;user interface;signal audio;authorisation;surveillance;hidden markov model;acoustics;electrical and electronic engineering;localization;public safety;audio signal;mesure acoustique;novelty;descomposicion dominio;novedad;speech;office corridor probabilistic novelty detection acoustic surveillance real world conditions machine learning authorization life property loss multidomain feature vector audio signals smart home environment open public space;novelty detection;intelligence artificielle;localizacion;systeme ouvert;probabilistic approach;anomalie;wavelet packet;parametre acoustique;data model;user assistance;network intrusion detection;anomalia;modelisation;feature vector;office;hidden markov models speech acoustics adaptation model asynchronous transfer mode security data models;adaptation model;oficina;vigilancia;localisation;hidden markov models;neural net;assistance utilisateur;machine learning;monitoring;enfoque probabilista;approche probabiliste;signal processing;asistencia usuario;safety;norma;recurrent events;audiofrequency;deteccion acustica;signal acoustique;public space;probabilistic novelty detection;wavelet packets audio signal processing mpeg 7 standard probabilistic novelty detection public safety;artificial intelligence;interface utilisateur;medida acustica;acoustic signal;inteligencia artificial;monitorage;transformacion ondita;learning artificial intelligence;wavelet packets;propiedad acustica;surveillance alarm systems audio signal processing authorisation emergency services home automation learning artificial intelligence national security;alarm systems;monitoreo;mpeg 7 standard;open systems;sistema abierto;mechanical systems	Novelty detection in the machine learning context refers to identifying unknown/novel data, i.e., data which vary greatly from the ones that the system was trained with. This paper explores this technique as applied to acoustic surveillance of abnormal situations. The ultimate goal of the system is to help an authorized person towards taking the appropriate actions for preventing life/property loss. A wide variety of acoustic parameters is employed towards forming a multidomain feature vector, which captures diverse characteristics of the audio signals. Subsequently the feature coefficients are fed to three probabilistic novelty detection methodologies. Their performance is computed using two measures which take into account misdetections and false alarms. Out dataset was recorded under real-world conditions including three different locations where various types of normal and abnormal sound events were captured. A smart-home environment, an open public space, and an office corridor were used. The results indicate that probabilistic novelty detection can provide an accurate analysis of the audio scene to identify abnormal events.	acoustic cryptanalysis;authorization;charge-coupled device;coefficient;experiment;feature vector;home automation;machine learning;novelty detection;prism (surveillance program);sensor;time-domain reflectometer	Stavros Ntalampiras;Ilyas Potamitis;Nikos Fakotakis	2011	IEEE Transactions on Multimedia	10.1109/TMM.2011.2122247	home automation;computer vision;simulation;speech recognition;telecommunications;computer science;artificial intelligence;machine learning;hidden markov model	ML	-4.480285351717483	-93.09695995720706	115389
6fff67c2014fac54130107f190c5e9551c2dc78b	hmm based handwritten text recognition using biometrical data acquisition pen	word recognition hidden markov models handwritten text recognition biometrical data acquisition pen graphical input devices human computer interaction electronic pen;input device;human computer interaction;handwriting recognition;hidden markov model;computer graphic equipment;light pens;hidden markov models;computer graphic equipment hidden markov models data acquisition handwriting recognition human computer interaction speech recognition light pens;word recognition;speech recognition;data acquisition;hidden markov models text recognition bioinformatics character recognition writing handwriting recognition data acquisition computer science data engineering signal design	Development of new text and graphical input devices is considered to be important part of human-computer interaction by many researchers worldwide. The paper presents our experience with the text recognition methods that we have developed for a new designed electronic pen that produces signals corresponding to the movement of the pen on paper. Signals are described by a set of primitives and hidden Markov models are used for word recognition. Results of tests are discussed as well as other possible application areas of our electronic pen.	data acquisition;hidden markov model;optical character recognition	Pen Ondrej Rohlik;Pavel Mautner;Václav Matoušek;Jürgen Kempf	2003		10.1109/CIRA.2003.1222307	natural language processing;speaker recognition;speech recognition;word recognition;intelligent character recognition;computer science;intelligent word recognition;pattern recognition;handwriting recognition;data acquisition;optical character recognition;sketch recognition;hidden markov model;input device;signature recognition	Robotics	-3.232423936683465	-82.81628551432371	115421
c27868c7345ca262b7cfd39d5e1f2af5a7fc36f2	design of a instrumentation module for monitoring ingestive behavior in laboratory studies	video recording bioacoustics biomedical ultrasonics medical computing medical disorders patient monitoring strain sensors user interfaces;sensor phenomena and characterization;instruments;bioacoustics;streaming media synchronization instruments monitoring data acquisition sensor phenomena and characterization;data collection;time synchronization;medical disorders;medical computing;strain sensors;monitoring;streaming media;auscultation eating equipment design equipment failure analysis feeding behavior humans male monitoring ambulatory reproducibility of results sensitivity and specificity signal processing computer assisted transducers pressure video recording young adult;synchronization;system integration;eating disorder;labview based interface instrumentation module design ingestive behavior monitoring obesity eating disorder noninvasive monitoring food ingestion acoustical sensor swallowing sensor strain sensor chewing detection self report button data collection system time synchronous video footage;video recording;patient monitoring;strain sensor;data acquisition;user interfaces;biomedical ultrasonics	The development of accurate and objective tools for monitoring of ingestive behavior (MIB) is one of the most important needs facing studies of obesity and eating disorders. This paper presents the design of an instrumentation module for non-invasive monitoring of food ingestion in laboratory studies. The system can capture signals from a variety of sensors that characterize ingestion process (such as acoustical and other swallowing sensors, strain sensor for chewing detection and self-report buttons). In addition to the sensors, the data collection system integrates time-synchronous video footage that can be used for annotation of subject's activity. Both data and video are simultaneously and synchronously acquired and stored by a LabVIEW-based interface specifically developed for this application. This instrumentation module improves a previously developed system by eliminating the post-processing stage of data synchronization and by reducing the risks of operator's error.	annotation;chewing;data collection;data synchronization;digital camera;feeding and eating disorders;feeding behaviors;high-throughput computing;instrumentation (attribute);interface device component;labview;mebibyte;modal logic;numerous;real-time clock;silo (dataset);throughput;video post-processing;sensor (device)	Juan M. Fontana;Paulo Lopez-Meyer;Edward S. Sazonov	2011	2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/IEMBS.2011.6090534	embedded system;synchronization;computer hardware;telecommunications;computer science;engineering;remote patient monitoring;biological engineering;data acquisition;user interface;physics;bioacoustics;statistics;system integration;data collection	Embedded	8.358925836342392	-88.04707833120457	115628
88c699fb91d5e6eb56d909e03bcce5d253d5de76	analysis of pulmonary and hemodynamic parameters for the weaning process by using fuzzy logic based technology		This study aims to achieve accurate weaning process which is very important for patient under mechanical ventilation. The developed weaning algorithm was designed on LabVIEW software and fuzzy system designer part of LabVIEW software was used during to develop that algorithm. The developed weaning algorithm has six input parameters which are maximum inspiratory pressure (MIP), tidal volume on spontaneous breathing (TVS), minute ventilation (VE), heart rate, respiration per minute (RPM) and body temperature. 20 clinical scenarios were generated by using Monte-Carlo simulations and Gaussian distribution method to evaluate performance of the developed algorithm. An expert clinician was involved to this process to evaluate the each generated clinic scenario to determine weaning probability for the each patient. Student t-test for p u003c 0.05 was used to show statistical difference between the developed algorithm and clinician’s evaluation. According to student t-test, there is no statistical difference for 98.2 % probability between the developed algorithm and the clinician’s evaluation of weaning probability.	fuzzy logic;hemodynamics	Ugur Kilic;Mehmet Tahir Gulluoglu;Hasan Guler;Turgay Kaya	2016		10.1007/978-3-319-46254-7_10	intensive care medicine	EDA	6.082388277374103	-80.35395275664878	116082
30877ec8e4d4438b5671d30a61f3026dce1460da	unifying and analysing activities of daily living in extra care homes		This work presents the unification and formal analysis of occurring Activities of Daily Living (ADLs) identified by an intelligent well-being monitoring system used for elderly residents in extra care homes. The ADLs considered in this paper are: i) personal grooming and toilet, ii) preparation of breakfast, iii) preparation of lunch, iv) preparation of evening meal and v) sleep. These ADLs are examined as they exhibit multiple or similar occurrences during a typical day. The novelty of this work lies in the introduction of a unification approach that could help for the detection of normal and abnormal behaviour based on the execution of the ADLs from elders in extra care homes equipped with different types of sensors. To unify and detect these types of behaviour, temporal aspects of the ADLs' execution like their duration and time of day are scrutinised. Moreover, the formal analysis of the identified ADLs is conducted, using Petri Nets for the modelling of these activities and model checking for their verification. Finally, the verification results are used to indicate whether an abnormal behaviour takes places during an activity, which could be used as a measure for spotting potential health issues regarding the elders that reside in the monitored homes.	emoticon;model checking;sensor;simulation;stochastic petri net;time series;unification (computer science)	Alexandros Konios;Yanguo Jing;Mark Eastwood;Bo Tan	2018	2018 IEEE 16th Intl Conf on Dependable, Autonomic and Secure Computing, 16th Intl Conf on Pervasive Intelligence and Computing, 4th Intl Conf on Big Data Intelligence and Computing and Cyber Science and Technology Congress(DASC/PiCom/DataCom/CyberSciTech)	10.1109/DASC/PiCom/DataCom/CyberSciTec.2018.00094	novelty;model checking;activities of daily living;personal grooming;toilet;petri net;human–computer interaction;formal verification;computer science;unification	SE	6.437488315779828	-86.44297468688197	116343
1336921ed4f15042da8c2b93075b4ac0ebb72364	a novel near-infrared spectroscopy based spatiotemporal cognition study of the human brain using clustering	brain hemispheres;concept–color association;one-way clustering;big data	In this study, we investigate how the two hemispheres of the brain are involved spatiotemporally in a cognitive-based setup when people relate different colors with different concepts (for example, the color ‘blue’ associated with the word ‘dependable’ or ‘cheap’) objectively or subjectively. We developed an experimental setup using a 17-channel near-infrared spectroscopy (NIRS) device to measure the changes in brain hemoglobin concentration during a concept–color association task in a block design paradigm. The channel-wise activation data were recorded for 10 male students; after cleansing, the data were clustered using an indigenous clustering technique to identify channels having similar spatiotemporal activity. Data mining was imperative because of the big data generated by NIRS (ca. 0.1+ MB textual data captured per sec involving high volume and veracity), for which the traditional statistical techniques for data analysis could have failed to discover the patterns of interest. The results showed that it was possible to associate brain activities in the two hemispheres to study the association among linguistic concepts and colors, with most neural activity taking place in the right hemisphere of the brain characterized with intuition, subjectivity, etc. Thus, the study suggests novel application areas of neural activity analysis, such as color as marketing cue, response of obese versus lean to food intake, traditional versus neural data validation.	big data;brain–computer interface;circa;cluster analysis;cognition;color;conceptual schema;data mining;data validation;experiment;human body weight;imperative programming;one-way function;programming paradigm;pure function;text corpus;velocity (software development);veracity	Ahsan Abdullah;Imtiaz Hussain Khan;Abdullah Basuhail;Amir Hussain	2015	Cognitive Computation	10.1007/s12559-015-9358-4	psychology;artificial intelligence;machine learning;communication;social psychology	ML	6.312871120589884	-82.12634883827864	116914
c310e5a3c8eef8f49a6d5a24d96995438e1ac381	universal background modeling for acoustic surveillance of urban traffic	hidden markov model;intelligent transportation systems;acoustic signal processing;generalized sound recognition;wavelet packets;universal background modeling	Traffic congestion in modern cities is an increasing problem having significant consequences in our daily lives. This work proposes a non-intrusive, passive monitoring framework based on the acoustic modality which can be used either autonomously or as a part of a multimodal system and provide valuable information to an intelligent transportation system. We consider a large number of audio classes which are typically encountered in urban areas. We introduce a combination of a powerful audio representation mechanism based on time, frequency and wavelet domain features with universal background modeling which leads to higher recognition accuracies and detection rates (in terms of false alarm and miss probability rates) with respect to commonly employed methodologies. The basic advantage of a class-specific model derived using the universal background modeling logic is its tolerance to data which belong to other sound classes. Another important feature of the proposed system is its ability to detect crash incidents, which apart from their catastrophic impact on human life and property, have negative consequences on the traffic flow. Our experiments are based on the concurrent usage of professional sound effect collections which include audio recordings of high quality. We thoroughly examine the performance of the proposed system on isolated sound events as well as continuous audio streams using confusion matrices and detection error trade-off curves.	acoustic cryptanalysis;antivirus software;closed-circuit television;hidden surface determination;microphone;modality (human–computer interaction);prism (surveillance program);sensor;smart city;source tracking;statistical model;velocity (software development)	Stavros Ntalampiras	2014	Digital Signal Processing	10.1016/j.dsp.2014.05.003	computer vision;intelligent transportation system;simulation;speech recognition;computer science;machine learning;wavelet packet decomposition;hidden markov model;statistics	Mobile	1.0271377332424831	-87.09661298660721	116977
a72e8286160f26025b4ced69d32852febbf7a4c2	a method for simplified hrqol measurement by smart devices		Health-related quality of life (HRQOL) is a useful indicator that rates a person’s activities in various physical, mental and social domains. Continuously measuring HRQOL can help detect the early signs of declines in these activities and lead to steps to prevent such declines. However, it is difficult to continuously measure HRQOL by conventional methods, since its measurement requires each user to answer burdensome questionnaires. In this paper, we propose a simplified HRQOL measurement method for a continuous HRQOL measurement which can reduce the burden of questionnaires. In our method, sensor data from smart devices and the questionnaire scores of HRQOL are collected and used to construct a machine-learning model that estimates the score for each HRQOL questionnaire item. Our experiment result showed our method’s potential and found effective features for some questions.	smart device	Chishu Amenomori;Teruhiro Mizumoto;Hirohiko Suwa;Yutaka Arakawa;Keiichi Yasumoto	2017		10.1007/978-3-319-98551-0_11	reliability engineering;business;quality of life	ECom	5.53591173447854	-86.64907984085879	117008
9632d52a1ef4618c9de300ac5463c5a89193f3d8	modeling the synchrony between interacting people: application to role recognition		The study of social interactions has attracted increasing attentions. The role recognition is one of its possible applications and the core of this study. This article proposes some approaches to automatically recognize the role of the participants of a meeting by modeling the synchrony of temporal nonverbal audio features. In our approache the Influence Model (IM), a Hidden Markov Model (HMM)-like, is used to model this synchrony and to extract from input data a feature vector that contains both information about temporal transitions (intra-personal data) and interaction between participants (inter-personal data). This modeling of the meeting is used as input of a Random Forests (RFs) for the role recognition task. The experiments are performed on 138 meetings (approximately 45 hours of recordings) from Augmented Multiparty Interaction (AMI) Corpus. Accuracy scores show that this combination of generative (IM) and discriminative (RFs) approaches permits to outperform state-of-the-art role recognition rates.	data descriptor;experiment;feature vector;hidden markov model;interaction;markov chain;multimodal interaction;performance;personally identifiable information;random forest;the matrix	Sheng Fang;Catherine Achard;Séverine Dubuisson	2016	Multimedia Tools and Applications	10.1007/s11042-016-4267-4	speech recognition;computer science;machine learning;world wide web	HCI	-3.304199453202965	-85.06255521814076	117727
25354beda5f75e49f6dc26e9e30c5c10f731d06b	dual camera motion capture for serious games in stroke rehabilitation	serious games;thermal tracking serious games stroke rehabilitation motion tracking;motor skills;rehabilitation;image motion analysis;patient rehabilitation cameras computer games feature extraction gesture recognition image motion analysis medical image processing object tracking;stroke rehabilitation;color;skin;patient rehabilitation;skin temperature;temperature feature dual camera motion capture serious games stroke upper limb rehabilitation exercise 3d games post stroke motor skills markerless motion capture technology hand movement hand gesture human low level motion identification optical camera thermal camera robust tracking performance;games image color analysis tracking skin cameras color gesture recognition;motion tracking;motion capture;camera motion;upper limb;image color analysis;feature extraction;medical image processing;games;object tracking;computer games;institutional repository research archive oaister;serious game;gesture recognition;cameras;tracking;stroke;thermal tracking	Typically, stroke upper limb rehabilitation exercises consist of repeated movements, which when tracked can form the basis of inputs to games. Markerless motion capture technologies can be used to enable such serious game control. This has the advantage that patients do not need to hold or wear any controls or devices, which may be difficult and restrictive for them. This research introduces a set of 3D games which require the sorts of repeated movements considered effective in the reacquisition of post-stroke motor skills. A system that uses markerless motion capture technologies to track and identify human low-level motion, i.e. the movement of hands and hand gesture to control the games, is described. The system uses dual cameras, an optical camera and a thermal camera which measures skin temperature, to obtain robust tracking performance. Moreover, the temperature features can also be used to monitor patients' physical status when they play games. Evaluation of the system is discussed.	high- and low-level;motion capture	Lindsay J. Evett;Andy Burton;Steven Battersby;David J. Brown;Nasser Sherkat;Gareth Ford;Hao Liu;Penny J. Standen	2011	2011 IEEE 1st International Conference on Serious Games and Applications for Health (SeGAH)	10.1109/SeGAH.2011.6165460	computer vision;simulation;computer science;multimedia	Robotics	8.432400813214391	-83.21501099006687	117958
7511f3094d6c0406205f2e5e8f5b151be52a8919	community similarity networks	community guided learning;smartphone sensing;activity recognition	Sensor-enabled smartphones are opening a new frontier in the development of mobile sensing applications. The recognition of human activities and context from sensor data using classification models underpins these emerging applications. However, conventional approaches to training classifiers struggle to cope with the diverse user populations routinely found in large-scale popular mobile applications. Differences between users (e.g., age, sex, behavioral patterns, lifestyle) confuse classifiers, which assume everyone is the same. To address this, we propose Community Similarity Networks (CSN), which incorporates inter-person similarity measurements into the classifier training process. Under CSN, every user has a unique classifier that is tuned to their own characteristics. CSN exploits crowd-sourced sensor data to personalize classifiers with data contributed from other similar users. This process is guided by similarity networks that measure different dimensions of inter-person similarity. Our experiments show CSN outperforms existing approaches to classifier training under the presence of population diversity.	behavioral pattern;cell signaling;crowdsourcing;experiment;mobile app;mobile device;personalization;population;smartphone;statistical classification	Nicholas D. Lane;Ye Xu;Hong Lu;Shaohan Hu;Tanzeem Choudhury;Andrew T. Campbell	2013	Personal and Ubiquitous Computing	10.1007/s00779-013-0655-1	computer science;artificial intelligence;machine learning;data mining;activity recognition	HCI	2.9960103616581995	-83.02016451887297	118268
c756445a80de089ebb7a7cb0891bd247565b7b48	assessment of attentional and mnesic processes through gaze tracking analysis: inferences from comparative search tasks embedded in vr serious games		The impairment of basic cognitive functions such as attention and visual working memory can have a significant negative impact in our ability to adapt to the permanent changes in the environment. VR Serious Games are being used as a new tool for both assessment, stimulation and rehabilitation of such impaired functions. Even though the results of these novel applications seem to be promising, some of the assessments based in these solutions use indirect measures to evaluate attentional and mnesic performance (e.g. number of errors, task completion time). Gaze tracking (GT) can provide more accurate and direct indicators of these cognitive processes. On a sample of 46 non-clinical participants (33 Female; 71.7%), with an age average of 27.96 years old (SD = 11.92), ocular movements were recorded in two different comparative visual search tasks (CVSTs) that are an integrant part of the cognitive assessment protocol of the Systemic Lisbon Battery (SLB). Number of visits and total fixations differed based on the assessment with the Mini-mental state examination test (MMSE). These results highlight the possibility of combining both the data from the GT and the results of the “spot the differences” tasks in SLB, adding an unobtrusive and reliable solution for cognitive assessment in clinical and non-clinical settings.		Pedro J. Rosa;Diogo Morais;Jorge Oliveira;Pedro Gamito;Olivia Smyth;Matthew Pavlovic	2015		10.1007/978-3-319-69694-2_3	basic cognitive functions;cognitive psychology;working memory;gaze;rehabilitation;fixation (psychology);multimedia;psychology;cognition;eye movement;cognitive assessment system	HCI	9.572973381117361	-91.24863703461342	118693
3978e7e053c649e1d632dbf8774cb035ea78438f	"""intra-operative """"real-time"""" navigation system updated with open mri"""			real-time transcription	Kosaku Amano;Yoshihiro Muragaki;Hiroshi Iseki;Takashi Maruyama;Madoka Sugiura;Masayuki Yamato;Ryuuiti Matida;Tomokatsu Hori;Kintomo Takakura	2001				Robotics	5.2573382204250585	-92.79180330463778	119219
c8b4520011e457a819ce6e26a06516353f1d6203	dirac: detection and identification of rare audio-visual events	psi_visics	The DIRAC project was an integrated project that was carried out between January 1st 2006 and December 31st 2010. It was funded by the European Commission within the Sixth Framework Research Programme (FP6) under contract number IST-027787. Ten partners joined forces to investigate the concept of rare events in machine and cognitive systems, and developed multi-modal technology to identify such events and deal with them in audio-visual applications.		Jörn Anemüller;Barbara Caputo;Hynek Hermansky;Frank W. Ohl;Tomás Pajdla;Misha Pavel;Luc Van Gool;Rufin Vogels;Stefan Wabnik;Daphna Weinshall	2012		10.1007/978-3-642-24034-8_1	speech recognition;word error rate;dirac (video compression format);rare events;novelty detection;superior temporal sulcus;computer science;cognition	Vision	-3.6895350373469857	-84.26240230915035	119241
fb6135bf1982bb7b9e1171d386ba59a6c6df6193	an incontinence alarm solution utilizing rfid based sensor technology	geriatrics;moisture sensor;moisture sensor incontinence alarm solution rfid based sensor technology geriatric care applications passive sensor functionality safe measurement robust measurement unobtrusive sensor device design standard rfid inlays smart diaper;radiofrequency identification geriatrics materials antennas moisture pediatrics;moisture measurement;radiofrequency identification biomedical communication capacitive sensors geriatrics moisture measurement;engineering and technology;teknik och teknologier;capacitive sensors telemetry moisture sensor;telemetry;radiofrequency identification;capacitive sensors;biomedical communication	The current work addresses the challenge of measuring urine volume in diapers primarily targeting geriatric care applications. There are number of incontinence alarm innovations suggested and described in patents and scientific reports. However, there are hardly any reports of such systems in permanent use in the hospital care market. One reason might be the challenging system requirements of such applications. According to our own experiences and requirements reported in the literature those are truly demanding. We need meter long communication range, passive sensor functionality, robust and safe measurement, unobtrusive sensor device design (patient) and a convenient reader and user interface (care personal). The list of specifications can be added to, a very low price adding only a small fraction to the over all diaper cost. Finally the system should improve the comfort of the patient and increase diaper management efficiency, reducing the costs of the care provider. The recent progress and usage of RFID technology have reduced the cost levels for inlays and readers. Thus, standard RFID inlays may be a candidate providing the targeted functionality in a smart diaper. In this work we evaluate the possibility to use the RFID antenna as the sensor element when detecting when a diaper has reached a certain degree of urine saturation. The evaluation has been done in a laboratory setup, with real test persons providing authentic readout scenarios.	experience;radio-frequency identification;requirement;sensor web;system requirements;user interface	Hans-Erik Nilsson;Johan Siden;Mikael Gulliksson	2011	2011 IEEE International Conference on RFID-Technologies and Applications	10.1109/RFID-TA.2011.6068662	embedded system;electronic engineering;telecommunications;computer science;engineering;electrical engineering;telemetry;capacitive sensing;biological engineering;geriatrics	Mobile	8.495754433756384	-89.10852100510614	119398
bcf7b7c919de0b5844ada2c48933ab3795a2e056	on the improvement of multimodal voice activity detection		As mobile devices, intelligent displays, and home entertainment systems permeate digital markets, the desire for users to interact through spoken and visual modalities similarly grows. Previous interactive systems limit voice activity detection (VAD) to the acoustic domain alone, but the incorporation of visual features has shown great improvement in performance accuracy. When employing both acoustic and visual (AV) information the central recurring question becomes “how does one efficiently fuse modalities”. This work investigates the effects of different features (from multiple modalities), different classifiers, and different fusion techniques for the task of AV-VAD on data with varying acoustic noise. Furthermore we present a novel multitier classifier that combines traditional approaches, feature fusion and decision fusion, with independent modality classifiers and combined intermediary decisions with raw features as inputs to a second stage classifier. Our augmented multi-tier classification system concatenates the output of a set of base classifiers with the original fused features for a final classifier. Experiments over various noise conditions show average relative improvements of 5.0% and 4.1% on the CUAVE [1] dataset and 2.6% and 11.1% on the MOBIO [2] dataset over majority voters and LDA respectively.	av-test;acoustic cryptanalysis;mobile device;modality (human–computer interaction);multimodal interaction;multitier architecture;voice activity detection	Matt Burlick;Dimitrios Dimitriadis;Eric Zavesky	2013			voice activity detection;speech recognition;pattern recognition;artificial intelligence;computer science	HCI	-2.190291663070151	-84.7932540792705	119585
f4b8fceb7a250b2ed558cbb157b07e1eef4ab59d	modeling of dynamic cardiovascular responses during g-transition-induced orthostatic stress in pitch and roll rotations	second order;acceleration aerospace medicine algorithms blood pressure canada cluster analysis computer simulation dizziness female fuzzy logic gravitation humans hypergravity hypogravity hypotension orthostatic male military medicine military personnel models cardiovascular posture reproducibility of results rotation sensitivity and specificity space flight stress mechanical torque;cardiology stress predictive models high definition video military aircraft acceleration arterial blood pressure aerodynamics aircraft propulsion cardiovascular system;haemodynamics;biomechanics;discrete time;cluster validity index;time series;indexing terms;fuzzy scatter matrix;arterial blood pressure;fuzzy logic;hypogravity;roll rotations dynamic cardiovascular responses modeling fuzzy models g transition induced orthostatic stress gigahertz acceleration transitions fighter jet pilot operational recommendations design split s tactical maneuver modern combat aircraft fuzzy logic models more g tolerant operational flight regimes man rated tilt table pitch rotations;indexation;scattering matrix;time series data;cardiovascular system;prediction model;cluster validity;aerospace biophysics;rotation;physiological models;hypergravity;fuzzy logic aerospace biophysics cardiovascular system rotation biomechanics time series physiological models haemodynamics;fuzzy model;split s	Dynamic and fuzzy models for a typical subject's cardiovascular response to the orthostatic stress have been developed based on experimental data. In our original study (Cheung et al., 1999), arterial blood pressure (BP) time-series data were obtained using a man-rated tilt table that applies gigahertz-acceleration transitions from +0.861 Gz [head-up (HU)] to -0.707 G [head-down (HD)] and back to +0.861 Gz (HU) using either pitch or roll rotations (Cheung et al., 1999). G transitions of different duration and onset rates are common in fighter maneuvers. Based on these data, two types of predictive models have been developed in this paper: 1) second-order discrete-time models that predict BP dynamics during pitch and roll rotations and 2) fuzzy logic models that predict important variations in a subject's cardiovascular dynamics induced by HU-to-HD and HD-to-HU transitions. These two types of models assist in providing an operationally important predictive view on the characteristics of BP responses to orthostatic stress induced by pitch and roll rotations of a fighter jet pilot. The new models are being currently utilized in the design of operational recommendations for more G-tolerant operational flight regimes (e.g., split-S tactical maneuver) than the ones currently in use for modern combat aircraft.	fuzzy logic;onset (audio);predictive modelling;rating (action);time series	William W. Melek;Ziren Lu;Alex Kapps;Bob Cheung	2002	IEEE Transactions on Biomedical Engineering	10.1109/TBME.2002.803555	structural engineering;control engineering;simulation;computer science;engineering;electrical engineering;biomechanics;time series;mathematics;biological engineering;physics;quantum mechanics;statistics	ML	7.465272543687088	-81.42102915593595	119792
1c0891fa67c19c462ba04ddc9ef51da51c24405b	transportation mode recognition based on smartphone embedded sensors for carbon footprint estimation	sensors;acceleration;vegetation;global positioning system;feature extraction;transportation;accelerometers	Thanks to the increase in processing power and in the number of sensors present in today's mobile devices, context-aware applications have gained a renewed interest. This paper focuses on a particular type of context, the transportation mode used by a person for carbon footprint estimation and it summarizes a method for automatically classifying different transportation modes with a smartphone. The method was evaluated with real data presenting promising results: a performance of around 94% was obtained when classifying 7 different classes with a random forest followed by a Discrete Hidden Markov Model (DHMM) filtering and accelerometer and magnetometer based features while the addition of the GPS improved the performance up to 96%.	bluetooth;decision tree;discriminant;embedded system;global positioning system;hidden markov model;markov chain;microphone;mobile device;performance;plasma cleaning;radio frequency;random forest;sensor;smartphone;video post-processing	Oana Lorintiu;Andrea Vassilev	2016	2016 IEEE 19th International Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2016.7795875	embedded system;simulation;engineering;remote sensing	Robotics	5.0372850006578815	-85.09309493320626	119951
322aba0c9c4d9a2d7147b5efd932db060651005b	towards a mobile assistive technology for monitoring and assessing cognitive fatigue in individuals with acquired brain injury	databases;mobile assistive technology fatigue evaluation smartphone application clinical environment cognitive impairments acquired brain injury cognitive fatigue assessment cognitive fatigue monitoring;fatigue;brain injuries;testing;sleep;smart phones assisted living mobile computing patient monitoring;mobile communication;fatigue mobile communication brain injuries testing sleep throughput databases;throughput;mobile cognitive fatigue fatigue reaction time psychomotor vigilance task spatial span smartphone	Those living with an acquired brain injury often have issues with fatigue due to factors resulting from the injury. Cognitive impairments such as lack of memory, concentration and planning have a great impact on an individual's ability to carry out general everyday tasks, which subsequently has the effect of inducing cognitive fatigue. Moreover, there is difficulty in assessing cognitive fatigue, as there are no real biological markers that can be measured. Rather, it is a very subjective effect that can only be diagnosed by the individual. Consequently, the traditional way of assessing cognitive fatigue is to use a self-assessment questionnaire that is able to determine contributing factors. State of the art methods to evaluate cognitive fatigue employ cognitive tests in order to analyse performance on predefined tasks. However, one primary issue with such tests is that they are typically carried out in a clinical environment, therefore do not have the ability to be utilized in situ within everyday life. This paper presents a smartphone application for the evaluation of fatigue, which can be used daily to track cognitive performance in order to assess the influence of fatigue.	assistive technology;cognition;cognitive science;cognitive tutor;mobile app;smartphone	Edward Price;George Moore;Leo Galway;Mark Linden	2015	2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing	10.1109/CIT/IUCC/DASC/PICOM.2015.222	throughput;simulation;mobile telephony;computer science;software testing;sleep	HCI	7.945579282502462	-87.00831528398399	119961
646fda224def3651e3d31c419f49aaa6a90686ac	a multimodal execution monitor with anomaly classification for robot-assisted feeding		Activities of daily living (ADLs) are important for quality of life. Robotic assistance offers the opportunity for people with disabilities to perform ADLs on their own. However, when a complex semi-autonomous system provides real-world assistance, occasional anomalies are likely to occur. Robots that can detect, classify and respond appropriately to common anomalies have the potential to provide more effective and safer assistance. We introduce a multimodal execution monitor to detect and classify anomalous executions when robots operate near humans. Our system builds on our past work on multimodal anomaly detection. Our new monitor classifies the type and cause of common anomalies using an artificial neural network. We implemented and evaluated our execution monitor in the context of robot-assisted feeding with a general-purpose mobile manipulator. In our evaluations, our monitor outperformed baseline methods from the literature. It succeeded in detecting 12 common anomalies from 8 able-bodied participants with 83% accuracy and classifying the types and causes of the detected anomalies with 90% and 81% accuracies, respectively. We then performed an in-home evaluation with Henry Evans, a person with severe quadriplegia. With our system, Henry successfully fed himself while the monitor detected, classified the types, and classified the causes of anomalies with 86%, 90%, and 54% accuracy, respectively.	anomaly detection;artificial neural network;autonomous system (internet);baseline (configuration management);general-purpose markup language;high- and low-level;mobile manipulator;multimodal interaction;norm (social);robot;semiconductor industry;sensor;web application	Daehyung Park;Hokeun Kim;Yuuna Hoshi;Zackory M. Erickson;Ariel Kapusta;Charles C. Kemp	2017	2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2017.8206437	artificial intelligence;artificial neural network;anomaly detection;real-time computing;computer vision;computer science;mobile manipulator;robot;activities of daily living	Robotics	3.6568499485380674	-87.43702535603457	120202
c26d6458698b7d2e0b108253c51b044c1f76a3a3	soft fall detection using machine learning in wearable devices	wearable computers accelerometers android operating system learning artificial intelligence pattern recognition vectors;machine learning algorithms;knime wearable machine learning pattern recognition fall detection decision tree ensemble linear accelerometer android smart watch;linear accelerometer;sensors;training;knime;wearable;decision trees accelerometers machine learning algorithms sensors training robustness acceleration;fall detection;android;acceleration;smart watch;machine learning;android platform soft fall detection machine learning wearable devices wearable watches linear acceleration information pattern recognition linear accelerometers robust vector;pattern recognition;robustness;decision trees;accelerometers;decision tree ensemble	"""Wearable watches provide very useful linear acceleration information that can be use to detect falls. Howeverfalls not from a standing position are difficult to spot amongother normal activities. This paper describes methods, basedon pattern recognition using machine learning, to improve thedetection of """"soft falls"""". The values of the linear accelerometersare combined in a robust vector that will be presented as inputto the algorithms. The performance of these different machinelearning algorithms is discussed and then, based on the bestscoring method, the size of the time window fed to the systemis studied. The best experiments lead to results showing morethan 0.9 AUC on a real dataset. In a second part, a prototypeimplementation on an Android platform using the best resultsobtained during the experiments is described."""	algorithm;experiment;machine learning;pattern recognition;wearable computer	Dominique Genoud;Vincent Cuendet;Julien Torrent	2016	2016 IEEE 30th International Conference on Advanced Information Networking and Applications (AINA)	10.1109/AINA.2016.124	acceleration;embedded system;simulation;computer science;operating system;machine learning;robustness;android	Robotics	5.161359112567606	-84.94119064097168	120342
83bb7da383bc54d8cb22561324afdf96f57b2de4	advanced vehicular sensing of road artifacts and driver behavior	traffic engineering computing controller area networks mobile computing road traffic smart phones;sensor systems;can bus;vehicular sensing;road artifacts can bus vehicular sensing obd ii driver behavior;obd ii;vehicle can bus advanced vehicular sensing road artifact detection driver behavior detection smartphone only system built in vehicle sensor obd dongles road conditions monitoring system;monitoring;accidents;roads;vehicles roads monitoring wheels sensor systems accidents;road artifacts;vehicles;driver behavior;wheels	The use of smartphone-only systems has relatively low accuracy, high computational complexity, and high battery consumption. Utilizing built-in vehicle sensors via OBD dongles can enable a more comprehensive road conditions monitoring system with lower computational cost and higher accuracy. This paper presents a system that utilizes the vehicle's CAN-Bus, as a source of sensory data, and a smartphone, as the processing unit of the mentioned data, to detect road artifacts and monitor driver behavior. Preliminary results of the proposed system reveal a maximum of 92%, with an average of 84%, in detection of road artifacts. Similarly, in a well-defined environment, driver behavior detection approaches 100%.	algorithmic efficiency;antivirus software;artifact (software development);built-in self-test;can bus;computation;computational complexity theory;dongle;global positioning system;sensor;smartphone;steering wheel;vehicle identification number	Najah AbuAli	2015	2015 IEEE Symposium on Computers and Communication (ISCC)	10.1109/ISCC.2015.7405452	embedded system;can bus;computer science;operating system;computer security	Mobile	5.939474764853087	-85.55884020720129	120511
9ce4d5a8e2e83850552af2fed61dc76f7fcd98bc	sisfall: a fall and movement dataset	pedestrian safety;poison control;injury prevention;safety literature;fall detection;traffic safety;injury control;mobile health care;home safety;injury research;safety abstracts;human factors;occupational safety;wearable devices;safety;safety research;accident prevention;violence prevention;bicycle safety;triaxial accelerometer;poisoning prevention;falls;ergonomics;sisfall;suicide prevention	Research on fall and movement detection with wearable devices has witnessed promising growth. However, there are few publicly available datasets, all recorded with smartphones, which are insufficient for testing new proposals due to their absence of objective population, lack of performed activities, and limited information. Here, we present a dataset of falls and activities of daily living (ADLs) acquired with a self-developed device composed of two types of accelerometer and one gyroscope. It consists of 19 ADLs and 15 fall types performed by 23 young adults, 15 ADL types performed by 14 healthy and independent participants over 62 years old, and data from one participant of 60 years old that performed all ADLs and falls. These activities were selected based on a survey and a literature analysis. We test the dataset with widely used feature extraction and a simple to implement threshold based classification, achieving up to 96% of accuracy in fall detection. An individual activity analysis demonstrates that most errors coincide in a few number of activities where new approaches could be focused. Finally, validation tests with elderly people significantly reduced the fall detection performance of the tested features. This validates findings of other authors and encourages developing new strategies with this new dataset as the benchmark.	accidental falls;activities of daily living (activity);benchmark (computing);feature extraction;gyroscope;silo (dataset);smartphone;wearable technology;accelerometers	Angela Sucerquia;José David López;Jesus Francisco Vargas Bonilla	2017		10.3390/s17010198	simulation;engineering;suicide prevention;human factors and ergonomics;injury prevention;forensic engineering;computer security	HCI	7.181121886305191	-85.5154738355794	120694
289a6be27ab45d5f047fc980d63d32699e36ca51	a classification scheme based on directed acyclic graphs for acoustic farm monitoring		Intelligent farming as part of the green revolution is advancing the world of agriculture in such a way that farms become evolving, with the scope being the optimization of animal production in an eco-friendly way. In this direction, we propose exploiting the acoustic modality for farm monitoring. Such information could be used in a stand-alone or complimentary mode to monitor constantly animal population and behavior. To this end, we designed a scheme classifying the vocalizations produced by farm animals. More precisely, we propose a directed acyclic graph, where each node carries out a binary classification task using hidden Markov models. The topological ordering follows a criterion derived from the Kullback-Leibler divergence. During the experimental phase, we employed a publicly available dataset including vocalizations of seven animals typically encountered in farms, where we report promising recognition rates outperforming state of the art classifiers.		Stavros Ntalampiras	2018	2018 23rd Conference of Open Innovations Association (FRUCT)	10.23919/FRUCT.2018.8588077	task analysis;topological sorting;theoretical computer science;binary classification;feature extraction;directed acyclic graph;classification scheme;hidden markov model;population;computer science	ML	-2.9140822207254917	-89.08099610936242	121217
930febe940f525b9f41bea6daf79cd0f4c43e176	a baseline for large-scale bird species identification in field recordings		The LifeCLEF bird identifcation task poses a difficult challenge in the domain of acoustic event classification. Deep learning techniques have greatly impacted the field of bird sound recognition in recent years. We discuss our attempt of large-scale bird species identification using the 2018 BirdCLEF baseline system.	acoustic cryptanalysis;baseline (configuration management);deep learning	Stefan Kahl;Thomas Wilhelm-Stein;Holger Klinck;Danny Kowerko;Maximilian Eibl	2018				AI	-3.298842341660879	-88.79740930052321	121501
6084b8ba0ebf4d70973678c6008c886fb69273c0	transfer learning in long-text keystroke dynamics		Conventional machine learning algorithms based on keystroke dynamics build a classifier from labeled data in one or more sessions but assume that the dataset at the time of verification exhibits the same distribution. Ideally, the keystroke data collected at a session is expected to be an invariant representation of an individual's behavioral biometrics. In real applications, however, the data is sensitive to several factors such as emotion, time of the day and keyboard layout. A user's typing characteristics may gradually change over time and space. Therefore, a traditional classifier may perform poorly on another dataset that is acquired under different environmental conditions. In this paper, we apply two transfer learning techniques on long-text data to update a classifier according to the changing environmental conditions with minimum amount of re-training. We show that by using adaptive techniques, it is possible to identify an individual at a different time by acquiring only a few samples from another session, and at the same time obtain up to 19% higher accuracy relative to the traditional classifiers. We make a comparative analysis among the proposed algorithms and report the results with and without the knowledge transfer. At the end, we conclude that adaptive classifiers exhibit a higher start by a good approximation and perform better than the classifiers trained from scratch.	adaptive filter;adaptive grammar;algorithm;approximation;asymptote;authentication;biometrics;computation;elegant degradation;enhanced entity–relationship model;event (computing);experiment;keystroke dynamics;machine learning;open-source software;plover;qualitative comparative analysis;support vector machine;text corpus;verification and validation	Hayreddin Çeker;Shambhu J. Upadhyaya	2017	2017 IEEE International Conference on Identity, Security and Behavior Analysis (ISBA)	10.1109/ISBA.2017.7947710	transfer of learning;typing;support vector machine;scratch;feature extraction;keystroke logging;machine learning;knowledge transfer;artificial intelligence;pattern recognition;computer science;keystroke dynamics	ML	-0.5893846799075161	-85.48026842678368	121613
015aa3f7ce55ceb2674cb3e2f9ccb8063e9c0b11	developing mobile intelligent system for cattle disease diagnosis and first aid action suggestion	cattle deaseases;fuzzy neural network;fuzzy neural network mobile intelligent software cattle deaseases diagnosis android;fuzzy neural nets;mobile intelligent software;smart phones;android;agricultural safety;dairy products;food safety;rule base knowledge representation mobile intelligent system cattle disease diagnosis agricultural development revitalization indonesia domestic products meat products dairy products imported products animal husbandry revitalization production growth cattle diseases diagnosis first aid action suggestion system intelligent engine fuzzy neural network smartphones user interface mobile application android operating system real world cattle diagnosis medical data set;operating system kernels;knowledge representation;mobile computing;cows diseases fuzzy neural networks mobile communication knowledge representation;diagnosis;smart phones agricultural safety dairy products food safety fuzzy neural nets knowledge based systems knowledge representation mobile computing operating system kernels;knowledge based systems	Animal husbandry is one of main concerns of agricultural development revitalization in Indonesia. The domestic products from this sector are yet to meet the domestics' demands of meat and dairy products. Therefore, instead of continuously dependent on imported products, efforts on animal husbandry revitalization to stimulate the production growth from this sector are critically needed. The aim of this paper is to present the work of developing mobile intelligent system for cattle diseases diagnosis and first aid action suggestion system. The core intelligent engine of the system is developed using fuzzy neural network. In the sense of ubiquity of smartphones, the user interface is developed as mobile application under Android operating system. System testing over real-world cattle diagnosis medical data set and expert verification showed that the systems could diagnose correctly with validity 100% and average accuracy 96.37%. The experimental results also showed that frame base knowledge representation outperformed rule base knowledge representation.	android;artificial intelligence;artificial neural network;knowledge representation and reasoning;mobile app;neuro-fuzzy;operating system;rule-based system;smartphone;system testing;user interface	Wiwik Anggraeni;A. Muklason;A. F. Ashari;A. Wahyu;Darminto	2013	2013 Seventh International Conference on Complex, Intelligent, and Software Intensive Systems	10.1109/CISIS.2013.27	simulation;engineering;operations management	Robotics	6.242111302227843	-87.63037517683257	121661
fa1bec5cc1dbe8a441194f3903a31797835200e6	towards multimodal deep learning for activity recognition on mobile devices	multimodal sensing;mobile sensing;deep learning;context detection;activity recognition	Current smartphones and smartwatches come equipped with a variety of sensors, from light sensor and inertial sensors to radio interfaces, enabling applications running on these devices to make sense of their surrounding environment. Rather than using sensors independently, combining their sensing capabilities facilitates more interesting and complex applications to emerge (e.g., user activity recognition). But differences between sensors ranging from sampling rate to data generation model (event triggered or continuous sampling) make integration of sensor streams challenging. Here we investigate the opportunity to use deep learning to perform this integration of sensor data from multiple sensors. The intuition is that neural networks can identify nonintuitive features largely from cross-sensor correlations which can result in a more accurate estimation. Initial results with a variant of a Restricted Boltzmann Machine (RBM), show better performance with this new approach compared to classic solutions.	activity recognition;artificial neural network;convolution;deep learning;mobile device;multimodal interaction;neural networks;requirement;restricted boltzmann machine;sampling (signal processing);sensor;smartphone;smartwatch	Valentin Radu;Nicholas D. Lane;Sourav Bhattacharya;Cecilia Mascolo;Mahesh K. Marina;Fahim Kawsar	2016		10.1145/2968219.2971461	computer vision;simulation;computer science;machine learning;deep learning;activity recognition	Mobile	3.166729482863679	-84.31658141629501	121903
fda05e3813e2a37daec6dc716a9a2f13bc163ded	multi-sensor exercise-based interactive games for fall prevention and rehabilitation		According to statistics, one in every three adults ageing 65 or older falls every year. Every fall may lead to long-term consequences due to fractures or even neurological damages. These consequences have severe impact in their quality of life, independence and confidence, ultimately increasing the risk of early death. Moreover, the risk of falling increases as age advances. Fortunately, several studies reveal that specific exercise programmes may help in reducing the risk of falling if performed correctly and frequently. However, user engagement and adherence to these programmes are still low mainly due to motivational factors, since interventions are usually long, unadapted and unchallenging. In this paper, a new solution is presented, which uses the concept of interactive games using motion sensors to tackle low adherence (through gaming motivation) and help in physical rehabilitation and reduce fall risk on elderly people by improving balance, muscle strength and mobility. It is intended to be used in community or domestic unsupervised contexts and supports relatively inexpensive sensing equipment (currently Kinect®, Leap Motion®, Orbotix Sphero® and Smartphones) and common platforms (desktop and mobile). Tests were already undertaken with several individuals ageing 65 or more and the results were analysed and discussed, being generally positive, despite some issues in the movement detection algorithms.	desktop computer;genetic algorithm;kinect;sensor;smartphone;wii	António Santos;Vânia Guimarães;Nuno Matos;João Cevada;Carlos Ferreira;Inês Sousa	2015	2015 9th International Conference on Pervasive Computing Technologies for Healthcare (PervasiveHealth)		simulation;computer science;multimedia;natural user interface	HCI	7.07451724413444	-84.89115647620036	122116
d1d9da0130bfa81132578bec0bb62b506b00059a	an interoperable pillbox system for smart medication adherence	radio equipment biomedical communication gesture recognition medical computing;computers radiofrequency identification monitoring photodiodes real time systems temperature sensors zigbee;medication intake interoperable pillbox system smart medication adherence computer application custom made wristband caregiver hand gesture refilling purpose bench top scenarios	We have designed and fabricated an interoperable system for medication adherence. The system is composed of a pillbox that wirelessly communicates with a computer application and a custom-made wristband. The system receives the information of taking specific medication from the user or caregiver, reminds the user to take the medication, monitors the user's hand gesture during the medication intake and monitors the compartments of the pillbox for refilling purpose. The performance of the developed system was examined in various bench-top scenarios. The system has the potential to improve the existing systems by reminding the user to take the medication through the wristband, automatically collecting user's hand gestures during the medication intake, and providing detailed information about the exisexistencetence of medication in the compartments of the pillbox.	anatomical compartments;interoperability	Jiajia Li;Shaun J. Peplinski;Sarah Mostafa Nia;Aydin Farajidavar	2014	2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/EMBC.2014.6943858	embedded system;real-time computing;simulation;engineering	Robotics	7.531274214892609	-88.65846650804319	122343
9aa0e85995f030f7bf78910c1ff86d4f55c66f3b	model-based location tracking of an a priori unknown number of inhabitants in smart homes	sensor systems;instruments;location tracking;smart home;expert in the loop improvement procedure smart homes online model based location tracking inhabitant location tracking finite automata comprehensive evaluation method simulation based procedure;intelligent sensors smart homes automata instruments estimation sensor systems;object tracking finite automata home automation;automata;estimation;finite automata;discrete event systems;smart home discrete event systems finite automata location tracking;intelligent sensors;smart homes	In this paper, we propose an approach for online model-based location tracking of inhabitants in Smart Homes. Based on our previous solution for a fixed and predefined number of inhabitants using finite automata, we generalize the approach to handle an a priori unknown number of inhabitants. The online algorithms to detect the number of inhabitants and to track their location are given, and a comprehensive evaluation method is defined. It consists of an analytical and a simulation-based procedure as well and is able to predict the tracking performance for real Smart Homes by a normalized measure. Throughout the paper, previous and new results are illustrated by a realistic case study and illustrative scenarios are given. Tracking the location of several inhabitants in a Smart Home using only ambient, noninvasive, low-cost sensors is a challenge. In this paper, we propose specific evaluation approaches as well as an expert-in-the-loop improvement procedure to help the expert setting up a satisfying instrumentation using only such sensors. We also detail the algorithm for online Location Tracking of any inhabitants in a Smart Home and explain this algorithm with an illustrative scenario.	automata theory;fits;fault detection and isolation;fault-tolerant computer system;finite-state machine;home automation;microsoft outlook for mac;online algorithm;sensor;simulation;wearable computer	Mickaël Danancher;Jean-Jacques Lesage;Lothar Litz	2016	IEEE Transactions on Automation Science and Engineering	10.1109/TASE.2015.2477558	control engineering;embedded system;estimation;simulation;computer science;engineering;artificial intelligence;automaton;finite-state machine;statistics;intelligent sensor	Robotics	4.379967998597052	-88.59958962126747	122574
3fcc24e73b0bd679c6fa742f833140056b65a399	determining athlete's injury with wireless body area sensor network-based overhead squat testing	wireless body area sensor network wbasn;body sensor networks;foot;wireless communication;functional movement screening fms;pressure measurement;injuries;ad hoc networks;patient monitoring;overhead squat;motion measurement;mobile computing	Wireless technologies employing small sensors are particularly useful since they allow monitoring of kinetic and physiological data without affecting any individual in motion. The primary objective of this collaborative research between the Department of Electrical Engineering and Computing Sciences and the Department of Athletes at the University of Cincinnati is to build a wireless system using a wireless body area sensor network (WBASN) for the overhead squat in assessing one element of human movement and its relationship to the kinematic lower extremity movement and injuries. This research can provide an objective analysis of the pilot data for movement of the human body during regular athletic exercises.	computer science;electrical engineering;overhead (computing);sensor;squatting attack	Suryadip Chakraborty;Anagha Jamthe;Saibal K. Ghosh;Dharma P. Agrawal	2013	2013 IEEE 10th International Conference on Mobile Ad-Hoc and Sensor Systems	10.1109/MASS.2013.96	wireless ad hoc network;embedded system;simulation;telecommunications;pressure measurement;computer science;operating system;remote patient monitoring;mobile computing;wireless;foot	Robotics	6.008812584623704	-89.99379157577899	123402
05db79d0cd732f85c6e324c56eb1258bbf70a736	trailsense: a crowdsensing system for detecting risky mountain trail segments with walking pattern analysis		Trail surface information is critical in preventing from the mountain accidents such as falls and slips. In this paper, we propose a new mobile crowdsensing system that automatically infers whether trail segments are risky to climb by using sensor data collected from multiple hikers’ smartphones. We extract cyclic gait-based features from walking motion data to train machine learning models, and multiple hikers’ results are then aggregated for robust classification. We evaluate our system with two real-world datasets. First, we collected data from 14 climbers for a mountain trail which includes 13 risky segments. The average accuracy of individuals is approximately 80%, but after clustering the results, our system can accurately identify all the risky segments. We then collected an additional dataset from five climbers in two different mountain trails, which have 10 risky segments in total. Our results show that the model trained in one trail can be used to accurately identify all the risky segments in the other trail, which documents the generalizability of our system.	cluster analysis;crowdsensing;machine learning;sensor;smartphone	Keunseo Kim;Hengameh Zabihi;Heeyoung Kim;Uichin Lee	2017	IMWUT	10.1145/3131893	crowdsensing;simulation;gait;generalizability theory;cluster analysis;climb;artificial intelligence;geography;pattern recognition	HCI	6.457896995108454	-84.77431887989819	123459
81a4183d5042a93356bc59cda54ede3283efe583	people identification using gait via floor pressure sensing and analysis	high resolution;biometrics;false alarm rate;gait recognition;stride length;fisher linear discriminant;pressure analysis;center of foot pressure	This paper presents an approach to people identification using gait based on floor pressure data. By using a large area high resolution pressure sensing floor, we were able to obtain 3D trajectories of the center of foot pressures over a footstep which contain both the 1D pressure profile and 2D position trajectories of the COP. Based on the 3D COP trajectories a set of features are then extracted and used for people identification together with other features such as stride length and cadence. The Fisher linear discriminant is used as the classifier. Encouraging results have been obtained using the proposed method with an average recognition rate of 94% and false alarm rate of 3% using pair-wise footstep data from 10 subjects.	ibm notes;image resolution;linear classifier;linear discriminant analysis;linear separability	Gang Qian;Jiqing Zhang;Assegid Kidané	2008		10.1007/978-3-540-88793-5_7	simulation;speech recognition;image resolution;computer science;constant false alarm rate;biometrics	HCI	8.290474461474648	-86.46263776171338	123666
84abd8f9860e870b958b2bf7d16cd9a4cae851a2	event detection in wireless body area networks using kalman filter and power divergence		The collected data by biomedical sensors must be analyzed for automatic detection of physiological changes. The early identification of an event in collected data is required to trigger an alarm upon detection of patient health degradation. Such alarms inform healthcare professionals and allow them to quickly react by taking appropriate actions. However, events result from physiological change or faulty measurements, and lead to false alarms and unnecessary medical intervention. In this paper, we propose a framework for automatic detection of events from collected data by biomedical sensors. The proposed approach is based on the Kalman filter to forecast the current measurement and to derive the baseline of the time series. The power divergence is used to measure the distance between the forecasted and measured values. When a change occurs, this metric significantly deviates from past values. To distinguish emergency events from faulty measurements, we exploit the spatial correlation between the monitored attributes. We conduct experiments on real physiological data set and our results show that our proposed framework achieves a good detection accuracy with a low false alarm rate. Its simplicity and processing speed make our proposed framework efficient and effective for real-world deployment.	baseline (configuration management);elegant degradation;experiment;kalman filter;sensor;software deployment;time series	Osman Salem;Ahmed Serhrouchni;Ahmed Mehaoua;Raouf Boutaba	2018	IEEE Transactions on Network and Service Management	10.1109/TNSM.2018.2842195	wireless sensor network;real-time computing;spatial correlation;software deployment;wireless;kalman filter;divergence;distributed computing;constant false alarm rate;exploit;computer science	Mobile	9.978257317120876	-87.26623694225616	123798
97e5b28bdee42d84e2dd2c33a3468f35e110ecb9	a modular software architecture for miniature capsule robots based on tinyos	energy;mobile sensing;audio;co processor;dsp	Minimally invasive surgical techniques are becoming popular due to their enhanced patient benefits. Less invasive procedures can be achieved with the use of wireless Medical Capsule Robots (MCRs). MCRs are low powered and small in size and can be used for physiological parameter monitoring, therapy delivery, and biopsy sampling. Designing MCRs from the ground up is a costly and time consuming process. In this work, we present a flexible modular architecture to facilitate the design of MCRs and propose using TinyOS as the operating system. To assess the architecture and validate the feasibility of TinyOS, we implement a closed-loop control of a sensor-actuator system and compare the results with a traditional MCR built based on an 8051 microcontroller (MCU) programmed in plain C. Similar performances from the two approaches lead us to conclude that TinyOS is a valid option to implement a modular architecture for designing MCRs.	arm architecture;control theory;intel mcs-51;memory card reader;microcontroller;modular programming;operating system;performance;robot;sampling (signal processing);software architecture;tinyos	Addisu Taddese;Péter Völgyesi;Ákos Lédeczi;Marco Beccani;Ekawahyu Susilo;Pietro Valdastri	2014		10.1145/2668332.2668363	embedded system;real-time computing;energy;computer hardware;computer science;digital signal processing;coprocessor	Robotics	9.512996094885175	-89.38536933320253	123965
6a06a9cbb07e7b10690cbc6d1d814ffe7db301e8	voice quality assessment and visualization	human voice assessment;medical diagnosis system;standards;speech processing;medical disorders;data visualization;human voice;medical data visualization medical diagnosis system human voice assessment voice parameters;graphical media voice quality assessment voice quality visualization voice analysis systems speech disorders human voice voice signals jitter shimmer harmonic to noise ratio otolaryngology;correlation;jitter;voice parameters;speech processing medical disorders medical signal processing;medical data visualization;jitter standards data visualization correlation human voice noise medical diagnostic imaging;medical signal processing;medical diagnostic imaging;noise	Commercial voice analysis systems are expensive and complicated. These equipments are only available at medical centers and need to be operated by well trained physicians. Thus the treatment costs of speech disorders are usually high. To improve this situation, we develop a software system dedicated to the assessment of human voice qualities. Our system is implemented in an ordinary personal computer. High precision electronic devices are not required for acquiring and analyzing voices. Therefore, the installation costs are low. Our system relies on four voice parameters to evaluate the qualities of voice signals. These parameters are fundamental frequency, jitter, shimmer, and harmonic-to-noise ratio. These measurements are widely used in otolaryngology to assess the pitch, variation of frequency, perturbation of amplitude, and harmony of human voice. Our system extracts these information from voice data and displays them by using graphical media. Consequently, the qualities of voice are more comprehensible. Users with little training and background knowledge can operate this system in their living rooms to assess their voices.	graphical user interface;personal computer;pitch (music);praat;sammon mapping;software system;usability;voice analysis	S. K. Ueng;C. M. Luo;T. Y. Tsai;H. Chang	2012	2012 Sixth International Conference on Complex, Intelligent, and Software Intensive Systems	10.1109/CISIS.2012.62	speech recognition;acoustics;engineering;communication	Visualization	-0.6664321547403268	-90.26701316673528	124231
397f1877a28c00a01b5cc8d05d0b2b395e36641e	classifier subset selection for the stacked generalization method applied to emotion recognition in speech	databases;female;emotions;speech emotion recognition;male;speech;info eu repo semantics article;features;machine learning;pattern recognition automated;humans;models;affective computing;bayesian networks	In this paper, a new supervised classification paradigm, called classifier subset selection for stacked generalization (CSS stacking), is presented to deal with speech emotion recognition. The new approach consists of an improvement of a bi-level multi-classifier system known as stacking generalization by means of an integration of an estimation of distribution algorithm (EDA) in the first layer to select the optimal subset from the standard base classifiers. The good performance of the proposed new paradigm was demonstrated over different configurations and datasets. First, several CSS stacking classifiers were constructed on the RekEmozio dataset, using some specific standard base classifiers and a total of 123 spectral, quality and prosodic features computed using in-house feature extraction algorithms. These initial CSS stacking classifiers were compared to other multi-classifier systems and the employed standard classifiers built on the same set of speech features. Then, new CSS stacking classifiers were built on RekEmozio using a different set of both acoustic parameters (extended version of the Geneva Minimalistic Acoustic Parameter Set (eGeMAPS)) and standard classifiers and employing the best meta-classifier of the initial experiments. The performance of these two CSS stacking classifiers was evaluated and compared. Finally, the new paradigm was tested on the well-known Berlin Emotional Speech database. We compared the performance of single, standard stacking and CSS stacking systems using the same parametrization of the second phase. All of the classifications were performed at the categorical level, including the six primary emotions plus the neutral one.	acoustic cryptanalysis;black and burst;cascading style sheets;classification;coffin-siris syndrome;emotion recognition;ensemble learning;estimation of distribution algorithm;experiment;feature extraction;focus stacking;generalization (psychology);genetic selection;learning classifier system;machine learning;numerous;programming paradigm;silo (dataset);subgroup;supervised learning;whole earth 'lectronic link	Aitor Álvarez;Basilio Sierra;Andoni Arruti;Juan Miguel López;Nestor Garay-Vitoria	2015	Sensors	10.3390/s16010021	random subspace method;speech recognition;emotion;computer science;speech;machine learning;pattern recognition;bayesian network;affective computing	Vision	-4.148776961904034	-88.86158386800409	124541
54f83d9db83a87059e6ebde6304493a2953877a9	deep learning approach for active classification of electrocardiogram signals	active learning al;deep neural network dnn;ecg signal classification;feature learning;denoising autoencoder dae	In this paper, we propose a novel approach based on deep learning for active classification of electrocardiogram (ECG) signals. To this end, we learn a suitable feature representation from the raw ECG data in an unsupervised way using stacked denoising autoencoders (SDAEs) with sparsity constraint. After this feature learning phase, we add a softmax regression layer on the top of the resulting hidden representation layer yielding the so-called deep neural network (DNN). During the interaction phase, we allow the expert at each iteration to label the most relevant and uncertain ECG beats in the test record, which are then used for updating the DNN weights. As ranking criteria, the method relies on the DNN posterior probabilities to associate confidence measures such as entropy and Breaking-Ties (BT) to each test beat in the ECG record under analysis. In the experiments, we validate the method on the well-known MIT-BIH arrhythmia database as well as two other databases called INCART, and SVDB, respectively. Furthermore, we follow the recommendations of the Association for the Advancement of Medical Instrumentation (AAMI) for class labeling and results presentation. The results obtained show that the newly proposed approach provides significant accuracy improvements with less expert interaction and faster online retraining compared to state-of-the-art methods.	deep learning	Mohamad Mahmoud Al Rahhal;Yakoub Bazi;Haikel Salem Alhichri;Naif Alajlan;Farid Melgani;Ronald R. Yager	2016	Inf. Sci.	10.1016/j.ins.2016.01.082	feature learning;speech recognition;computer science;artificial intelligence;machine learning;pattern recognition	AI	-2.531601725252998	-87.05039213848178	124590
4d9f89e8d43800a3a1c7001cbf57b199fb421e26	visualizing running races through the multivariate time-series of multiple runners	biomedical monitoring;cardiology;haemodynamics;heating;time series;medical computing;data visualisation;physiology;monitoring;time series cardiology data visualisation haemodynamics medical computing physiology sport;image color analysis;data visualization;races time series;sport;data visualization heating biomedical monitoring monitoring image color analysis heart beat;heart beat;races;visualization design running race visualization multivariate time series multiple runners heart rate monitor body response measurement speed geolocation fitness level cardiovascular diseases physical injury high heartbeat frequency exercise physiology	The recent widespread of heart rate (HR) monitors is allowing people to measure body response during and after exercise, which produces a collection of time-series on multivariate aspects, such as heartbeat, speed, geolocation, etc. Such monitoring can be extremely important for people with low fitness levels, since they are susceptible to cardiovascular diseases or other physical injuries when exercising at high heartbeat frequencies. Even though most monitors provide tools to export and display this information for each individual, the ability to visualize the collection of multiple runners in a given running race is mostly unexplored. In this work, we present a design study that aims to support analysis and answer several questions raised by an expert on exercise physiology about a given running race. We describe each visualization design and how they individually, or in collaboration, can be used to reveal interesting aspects of the data. We illustrate our results with use cases that provide evaluation and feedback about the visualization designs proposed.	geolocation;mike lesser;race condition;time series	Guilherme N. Oliveira;João Luiz Dihl Comba;Rafael P. Torchelsen;Maristela Padilha;Cláudio T. Silva	2013	2013 XXVI Conference on Graphics, Patterns and Images	10.1109/SIBGRAPI.2013.23	simulation;engineering;biological engineering;computer graphics (images)	HCI	9.504187127264997	-85.76657017219944	124716
58a2a8529df348fa7a8ff0585b64067bdf7016c1	integrated medical analysis system	biomedical monitoring;control theory;cardiology;real time;distributed computing;computer architecture;data analysis;system integration;medical device;functional model;mathematical model;humans;technical report;medical treatment;data analysis medical diagnostic imaging biomedical monitoring humans cardiology computer architecture distributed computing real time systems mathematical model medical treatment;medical diagnostic imaging;dynamic analysis;real time systems	This paper describes the Integrated Medical Analysis System. This evolving system consists of an integrated suite of models and tools providing quantitative and dynamic analysis from physiological function models, clinical care patient input, medical device data, and Northrop Grumman medical products. The System is being developed for requirements definition, testing, validation, control theory, and real-time diagnostic insights. Unique system integration of components is achieved. The current prototype emphasizes cardiovascular and pulmonary physiological functions and integration of patient device data. An overview of the project and preliminary findings are introduced.	computer architecture;control theory;data validation;decision support system;distributed computing;graphics;prototype;real-time clock;requirement;simulation;software testing;system integration	Susan L. Mabry;Samuel L. Rodriquez;James D. Heffernan	1997		10.1145/268437.268754	simulation;computer science;function model;technical report;mathematical model;dynamic program analysis;biological engineering;data analysis;statistics;system integration	SE	7.203117338410564	-89.62247177208245	125375
6ffc467f2f0915e265c95843fd8337b63e7a0d93	the development of an in-vivo active pressure monitoring system		Medical examinations often extract localized symptoms rather than systemic observations and snap shots rather than continuous monitoring. Using these methodologies, one cannot discretely analyze how a patient’s lifestyle affects his/her physiological conditions and if additional symptoms occur under various stimuli. We present a minimally invasive implantable pressure sensing system that actively monitors long-term physiological changes in real-time. Specifically, we investigate pressure changes in the upper urinary tract per degree of obstruction. Our system integrates three components: a miniaturized sensor module, a lightweight embedded central processing unit with battery, and a PDA. Our tether-free system measures pressure continuously for forty-eight hours and actively transmits an outgoing signal from an implanted sensor node to a remote PDA twenty feet away. The software in this in-vivo system is remotely reconfigurable and can be updated when needed. Preliminary experimental results of the in-vivo pressure system demonstrate how it can wirelessly transmit pressure readings measuring 0 to 1 PSI with an accuracy of 0.02 PSI. The challenges in biocompatible packaging, transducer drift, power management, and in-vivo signal transmission are discussed. This research brings researchers a step closer to continuous, real-time systemic monitoring that will allow one to analyze the dynamic human physiology.	video-in video-out	Chihkang Lin;David Jea;Foad Dabiri;Tammara Massey;Robert Tan;Majid Sarrafzadeh;Mani B. Srivastava;Peter G. Schulam;Jacob Schmidt;Carlos Montemagno	2007		10.1007/978-3-540-70994-7_18	embedded system;computer science;snap;power management;transmission (telecommunications);biocompatible material;continuous monitoring;sensor node;transducer	Robotics	8.800691606184664	-87.87961860540294	125473
d5de000eb5dd11266cf4a45f87b0e888f0ae1e4e	ant+ medical health kit for older adults	ant;dissertacao;sensores sem fios;kit medico de saude para idosos	This paper describes the research made on current mobile health monitoring systems targeting the elderly and the development of an elderly-oriented solution, serving as a proof-of-concept of the research done. It provides a scientific contribution by specifying a system with characteristics never combined before, when applied to the health monitoring of older adults. Also, a prototype for that system was developed and evaluated with its end users – the elderly. The proof of concept solution allows the patient to measure his weight and blood pressure with ANT+ sensors connected to his Android smartphone. The measured data is stored on the mobile device for later reading and sent through the network, to a medical entity. This entity can, whenever desired, analyse that information and give an appropriate feedback to the patient through a web application.	android;feedback;mhealth;mobile device;prototype;sensor;smartphone;web application	Ricardo Belchior;Diogo Júnior;António Monteiro	2012		10.1007/978-3-642-37893-5_3	gerontology;medicine;cartography	HCI	5.280325474041272	-89.36999999516703	125559
3a8437286942a145ee1bfb075fd6eb17548916f2	a neural network model extracting features from speech signals	modelizacion;sound recognition;traitement signal;learning;reconocimiento palabra;intelligence artificielle;reconocimiento sonido;aprendizaje;modelisation;apprentissage;signal processing;reconnaissance son;signal acoustique;speech recognition;artificial intelligence;acoustic signal;inteligencia artificial;reconnaissance parole;neural network model;red neural;procesamiento senal;modeling;senal acustica;reseau neural;neural network	A feature-extracting model for the auditory nervous system was constructed using neurons with nonlinear inhibitory mechanisms as the elements. The operation was verified by computer simulation. The model is composed of the bandpass filters corresponding to basilar membrane, the halfwave rectifiers corresponding to the hair cells, and the feature-extracting neurons. The feature detector is a multilayered network, where several neural layers composed of a one-dimensional array of neurons of the same response are connected in cascade. Each neuron performs the spatio-temporal addition for the excitatory and inhibitory inputs through spatial connections in the input-side layer and the first-order delay. Then, the neuron produces an output through the nonlinear inhibitory mechanism (shunt inhibition) and the analog threshold characteristics. Considering the physiological knowledge and characters of the speech, three kinds of feature-detecting neural groups were constructed. These are: CF group to detect the interval where the frequency is kept constant; FM group to detect the interval where the frequency is varying; and the fricative noise group to detect the fricative noise. These three correspond to the features of the vowel formant, the transition from consonant to vowel or the contracted sound, and the features of most of the consonants, respectively. Computer simulation was performed with actual speech input, and it was verified that the proposed model correctly extracts the various features contained in the speech.	array data structure;artificial neural network;computer simulation;fm broadcasting;feature extraction;first-order predicate;network model;neuron;nonlinear system;rectifier;sensor	Takayuki Ito;Kunihiko Fukushima	1988	Systems and Computers in Japan	10.1002/scj.4690190304	speech recognition;systems modeling;computer science;artificial intelligence;machine learning;artificial neural network	ML	-3.5604124376976256	-91.49526897191724	125891
849514806d33db1761326fe0c65efe09619837dd	a multimodal distributed intelligent environment for a safer home		This paper presents an ambient intelligence system aimed at increasing the security of elderly people in their living environment. The proposed system processes both video and audio signals to detect dangerous events and trigger automatic warnings. The system is implemented through a software middleware for multimedia streaming and processing in which the information is processed in several, distributed software nodes. This paper focuses on the fall detection video processing node and on the sound classification and localization audio processing node. The system has been tested both in a laboratory and in a real-world scenario, demonstrating high performance levels.	algorithm;ambient intelligence;audio signal processing;authentication;authorization;distributed computing;framing (world wide web);home automation;intelligent environment;middleware;motion detector;multimodal interaction;pan–tilt–zoom camera;performance;sensor;video processing	Salvatore Maria Anzalone;Stefano Ghidoni;Emanuele Menegatti;Enrico Pagello	2012		10.1007/978-3-642-33926-4_74	simulation;transport engineering;computer security	Mobile	3.5631081653940297	-86.94010651266017	126050
ab5a88468a4c9bda2e2ed7e11b47090ef6d7c694	computer vision-based gait velocity from non-obtrusive thermal vision sensors		Gait velocity is an important measure of independence and functional ability to those within the older population. Detecting changes in gait velocity can aid to provide interventions to avoid hospitalisation, currently gait velocity is assessed in a clinical setting, where the patient is timed over a measured distance between 3–6 metres by a clinician, however, this is time consuming, subjective, and not possible to carry out frequently over time. An unobtrusive method of monitoring gait velocity, frequently, over extended periods of time, would therefore be advantageous when developing interventions. This paper proposes an unobtrusive computer vision-based method of continuously monitoring an occupants gait velocity within their own home. This is achieved through the use of a low cost thermal vision sensor. The system was benchmarked against the clinical standard method of being timed by a stopwatch. Results show a high correlation between the gait velocity measured by the thermal vision sensor and the measured stopwatch velocity (R=0.941, p=0.02).	aerial photography;benchmark (computing);computer vision;convolutional neural network;neural networks;real-time clock;real-time computing;real-time locating system;sensor;through-silicon via;velocity (software development)	Javier Medina Quero;Colin Shewell;Ian Cleland;Joseph Rafferty;Chris D. Nugent;Macarena Espinilla	2018	2018 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops)	10.1109/PERCOMW.2018.8480174	stopwatch;computer science;population;gait;distortion;computer vision;artificial intelligence	Robotics	8.426656939900194	-84.47194645149926	126180
461c50a3efc72d22281445ee6262a47c4cf705e0	convolutional recurrent neural networks for music classification		We introduce a convolutional recurrent neural network (CRNN) for music tagging. CRNNs take advantage of convolutional neural networks (CNNs) for local feature extraction and recurrent neural networks for temporal summarisation of the extracted features. We compare CRNN with three CNN structures that have been used for music tagging while controlling the number of parameters with respect to their performance and training time per sample. Overall, we found that CRNNs show a strong performance with respect to the number of parameter and training time, indicating the effectiveness of its hybrid structure in music feature extraction and feature summarisation.	artificial neural network;convolutional neural network;feature extraction;recurrent neural network	Keunwoo Choi;George Fazekas;Mark B. Sandler;Kyunghyun Cho	2017	2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2017.7952585	speech recognition;computer science;machine learning;pattern recognition;deep learning	Vision	-4.083817272826566	-87.0566366937476	126195
ca20abdd6f02cff0cc488dea50baeeeac2acb171	d.r.e.a.m.s. (digital rehabilitation environment-altering medical system)	vr;new media;rehabilitation;therapy	In project D.R.E.A.M.S., we propose to develop and assess the feasibility of a novel and intelligent delirium-prevention system to address depression, pain, sleep, activity patterns and emotional states using the Emotiv Epoc+ | 14 Channel EEG, and HTC Vive VR set.	delirium;depressive disorder;electroencephalography;emotiv systems;htc vive;pain;vr - veterans rand health survey	Marko Suvajdzic;Azra Bihorac;Parisa Rashidi	2017	2017 IEEE 5th International Conference on Serious Games and Applications for Health (SeGAH)	10.1109/SeGAH.2017.7939293	real-time computing;simulation;headphones;rehabilitation;signal processing;computer science;communication channel	Robotics	8.12337470399394	-90.98279916854196	126230
c45c99b717587bf9cdc3cae55c81024b0eb85cc3	the mind as a reliable switch: challenges of rapidly controlling devices without prior learning	rapidly controlling devices;reliable switch	Activity within the brain causes electrical potentials to exist on the scalp. The study of these potentials is generally referred to as electroencephalography (EEG). EEG is widely used in medical diagnosis and in biofeedback studies in which a person can learn to control some element of their EEG spectrum, usually in response to some visual stimulus. This paper reports the control of the alpha component of the EEG spectrum which does not require the learning that biofeedback demands. We show that participants can achieve rapid and reliable remote control of electrical devices using increase in alpha wave activity associated with reduced visual input. The physiological basis, technical achievements and challenges, and applications will be discussed.	mind	Ashley Craig;Les Kirkup;Paul McIsaac;Andrew Searle	1997			artificial intelligence	HCI	8.525971190649646	-91.77154056814436	126356
04f6189268a78f07b80cdb89b829079bf21a61b6	modeling dominance in group conversations using nonverbal activity cues	social network services;modelizacion;nonverbal communication;group meetings;image motion analysis;social computing;social interaction;interaction sociale;data compression;support vector machines;dominance modeling;classification non supervisee;surexposition;speaking;speech processing;overexposure;speech;sobreexposicion;microfono;joints;indexing terms;support vector machines data compression feature extraction image motion analysis natural language processing pattern classification social sciences computing speech processing speech recognition;modelisation;visualization;power system modeling data mining psychology pattern analysis sensor phenomena and characterization social network services humans context information management computer science;evaluation subjective;audiovisual integration;interaccion social;social sciences computing;feature extraction;compressed domain;nonverbal communication audiovisual activity cues dominance modeling group meetings;clasificacion no supervisada;signal classification;audiovisual activity cues;pattern classification;integracion audiovisual;meetings;classification signal;unsupervised classification;speech recognition;audio visual;copper;audiovisual integration group conversations nonverbal activity cues dominance social interaction sensor data social computing;subjective evaluation;modeling;power;natural language processing;data models;integration audiovisuelle;microphone;evaluacion subjetiva	Dominance - a behavioral expression of power - is a fundamental mechanism of social interaction, expressed and perceived in conversations through spoken words and audiovisual nonverbal cues. The automatic modeling of dominance patterns from sensor data represents a relevant problem in social computing. In this paper, we present a systematic study on dominance modeling in group meetings from fully automatic nonverbal activity cues, in a multi-camera, multi-microphone setting. We investigate efficient audio and visual activity cues for the characterization of dominant behavior, analyzing single and joint modalities. Unsupervised and supervised approaches for dominance modeling are also investigated. Activity cues and models are objectively evaluated on a set of dominance-related classification tasks, derived from an analysis of the variability of human judgment of perceived dominance in group discussions. Our investigation highlights the power of relatively simple yet efficient approaches and the challenges of audiovisual integration. This constitutes the most detailed study on automatic dominance modeling in meetings to date.	microphone;social computing;spatial variability;unsupervised learning	Dinesh Babu Jayagopi;Hayley Hung;Chuohao Yeo;Daniel Gatica-Perez	2009	IEEE Transactions on Audio, Speech, and Language Processing	10.1109/TASL.2008.2008238	natural language processing;computer vision;speech recognition;computer science;speech;machine learning;speech processing;social computing	HCI	-4.313912814145369	-81.81640074568594	127084
ff2d1ca63f6d61212a08da146f61596d4e986906	embedded classification of the perceived fatigue state of runners: towards a body sensor network for assessing the fatigue state during running	biomechanics body sensors sensor network fatigue classification embedded classification;microcontrollers;fatigue;embedded classification;body sensor networks;heart rate variability;sensors;cardiology;training;biomechanics;footwear;sensor network;fatigued athlete embedded classification fatigue state biomechanical data physiological data heart rate variability feature stride frequency feature selection fatigue level embedded microcontroller body sensor network wearable classification system;heart rate;microcontrollers biomechanics biomedical equipment body sensor networks cardiology fatigue;body sensors;fatigue classification;fatigue sensors heart rate biomechanics footwear feature extraction training;feature extraction;human body;classification system;feature selection;biomedical equipment;body sensor network	This paper presents methods for collecting and analyzing biomechanical and physiological data from several body sensors during recreational runs in order to classify an athlete's perceived fatigue state. Heart rate, heart rate variability, running speed, stride frequency and biomechanical data were recorded continuously from 431 runners during a free one-hour outdoor run. During the activity the sportsmen answered questions about their perceived fatigue state in 5 min intervals. The data were analyzed using specifically designed features computed for each of the 5 min intervals. The features were used to train different classifiers, which were able to distinguish two levels of the runner's fatigue state with an accuracy of 88.3 % across multiple study participants. Feature selection evidenced that a heart rate variability feature and two biomechanical features were best suited for classification of the perceived fatigue level. Therefore, the classification system needs the information from various sensors on the human body. The resulting classifier was implemented on an embedded microcontroller to show that it would be feasible to integrate it directly into a body sensor network. Such a wearable classification system for fatigue can be used to support sportsmen, for example by changing their training plan or by adapting their equipment to the specific needs of a fatigued athlete.	embedded system;feature selection;heart rate variability;maxima and minima;microcontroller;sensor;wearable computer	Bjoern M. Eskofier;Patrick Kugler;Daniel Melzer;Pascal Kuehner	2012	2012 Ninth International Conference on Wearable and Implantable Body Sensor Networks	10.1109/BSN.2012.4	microcontroller;embedded system;human body;heart rate variability;simulation;wireless sensor network;feature extraction;computer science;sensor;biomechanics;machine learning;feature selection	Mobile	8.494651262275818	-86.64316610841	127145
1f630fae491e5331400ab4186506787895a1c29a	you're driving and texting: detecting drivers using personal smart phones by leveraging inertial sensors	texive;classification;smartphone	In this work, we address a critical task of detecting the user behavior of driving and texting simultaneously using smartphones. We propose, design, and implement TEXIVE which achieves the goal of distinguishing drivers and passengers, and detecting texting operations during driving utilizing irregularities and rich micro-movements of users. Without relying on any external infrastructures and additional devices, and no need to bring any modification to vehicles, TEXIVE is able to successfully detect dangerous operations with good sensitivity, specificity and accuracy. We conduct experimental study of TEXIVE with the help of a number of volunteers using various vehicles and smartphones. Our results indicate that TEXIVE has a classification accuracy of 87.18%, and precision of 96.67%.	experiment;sensitivity and specificity;sensor;smartphone	Cheng Bo;Xuesi Jian;Xiang-Yang Li;XuFei Mao;Yu Wang;Fan Li	2013		10.1145/2500423.2504575	embedded system;simulation;biological classification;computer security	HCI	5.895962461812931	-84.63533537060968	127433
7f2ed2bfca988cdc25bb4e034cf796f11e8caf6b	complex activity recognition using context-driven activity theory and activity signatures	context awareness;complex activity;test bed;interleaved activities;context driven activity theory;evaluation;experimentation;prototype;activity recognition;concurrent activities	In pervasive and ubiquitous computing systems, human activity recognition has immense potential in a large number of application domains. Current activity recognition techniques (i) do not handle variations in sequence, concurrency and interleaving of complex activities; (ii) do not incorporate context; and (iii) require large amounts of training data. There is a lack of a unifying theoretical framework which exploits both domain knowledge and data-driven observations to infer complex activities. In this article, we propose, develop and validate a novel Context-Driven Activity Theory (CDAT) for recognizing complex activities. We develop a mechanism using probabilistic and Markov chain analysis to discover complex activity signatures and generate complex activity definitions. We also develop a Complex Activity Recognition (CAR) algorithm. It achieves an overall accuracy of 95.73% using extensive experimentation with real-life test data. CDAT utilizes context and links complex activities to situations, which reduces inference time by 32.5% and also reduces training data by 66%.	activity recognition;algorithm;antivirus software;concurrency (computer science);electronic signature;exploit (computer security);forward error correction;markov chain;pervasive informatics;real life;software testing controversies;test data;ubiquitous computing	Saguna;Arkady B. Zaslavsky;Dipanjan Chakraborty	2013	ACM Trans. Comput.-Hum. Interact.	10.1145/2490832	simulation;computer science;artificial intelligence;evaluation;operating system;prototype;management;activity recognition;testbed	HCI	1.2892611888350871	-84.49454620410263	127630
091961a94aca33471ed959fcad3f0c14aedbd145	a photoplethysmograph based practical heart rate estimation algorithm for wearable platforms		We propose a practical Heart Rate Estimation algorithm utilizing wrist-based photoplethysmography (PPG) signals for continuous health monitoring of crane workers who spend long hours in an isolated cabin in the harsh factory environment. Our novelty lies in devising a low footprint algorithm that can reliably estimate Heart Rate in presence of motion artefact as well as offers the feasibility of deploying on a wearable platform. More particularly, our solution addresses two fundamental issues: a) correcting weak wrist PPG signal from frequent motion artefacts and b) identifying signal processing techniques that can be practically implemented on an embedded platform with limited resources in terms of memory and CPU. Experimental results demonstrate the validity of such algorithm and exhibit a great potential to be employed in the real field.	algorithm;beam propagation method;central processing unit;computational complexity theory;email;embedded system;emoticon;random forest;signal processing;software deployment;usability;wearable computer	Shalini Mukhopadhyay;Nasim Ahmed;Dibyanshu Jaiswal;Arijit Sinharay;Avik Ghose;Tapas Chakravarty;Arpan Pal	2017		10.1145/3089351.3089354	wearable computer;novelty;factory environment;signal processing;random forest;heart rate monitoring;real-time computing;footprint;algorithm;photoplethysmogram;engineering	Mobile	6.094444263599466	-83.15566383288363	127853
32f14a9b6e8dfd341c9b58178b74cd962de34009	ali: an assisted living system for persons with mild cognitive impairment	personalized notification assisted living system mild cognitive impairment daily life activity human behavior theory decision making framework human activity centric point of view possibilistic argumentation theory;possibility theory assisted living cognition decision support systems medical disorders;decision making cognition sensors legged locomotion semantics abstracts mobile handsets;medical disorders;assisted living;datalogi;cognition;decision support systems;datavetenskap datalogi;possibility theory;computer science	We introduce the Assisted Living system ALI, which is a novel approach to providing assistance and support in activities of daily life. We integrate a human behavior theory with a default reasoning decision making framework. This integration allows us to model a decision making problem from a human activity centric point of view and at the same time, formalize these elements using a possibilistic argumentation theory. ALI sends personalized notifications suggesting the most suitable activities to perform and determines what activities were performed during a time period.	ali corporation;default logic;living systems;personalization	Esteban Guerrero;Juan Carlos Nieves;Helena Lindgren	2013	Proceedings of the 26th IEEE International Symposium on Computer-Based Medical Systems	10.1109/CBMS.2013.6627861	possibility theory;cognition;decision support system;computer science;artificial intelligence;machine learning	Robotics	2.2015970578844293	-87.25590546658783	127980
56fd4c05869e11e4935d48aa1d7abb96072ac242	openface 2.0: facial behavior analysis toolkit		Over the past few years, there has been an increased interest in automatic facial behavior analysis and understanding. We present OpenFace 2.0 - a tool intended for computer vision and machine learning researchers, affective computing community and people interested in building interactive applications based on facial behavior analysis. OpenFace 2.0 is an extension of OpenFace toolkit and is capable of more accurate facial landmark detection, head pose estimation, facial action unit recognition, and eye-gaze estimation. The computer vision algorithms which represent the core of OpenFace 2.0 demonstrate state-of-the-art results in all of the above mentioned tasks. Furthermore, our tool is capable of real-time performance and is able to run from a simple webcam without any specialist hardware. Finally, unlike a lot of modern approaches or toolkits, OpenFace 2.0 source code for training models and running them is freely available for research purposes.	affective computing;algorithm;computer vision;list of toolkits;machine learning;real-time clock;real-time web;webcam	Tadas Baltrusaitis;Amir Zadeh;Yao Chong Lim;Louis-Philippe Morency	2018	2018 13th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2018)	10.1109/FG.2018.00019	source code;affective computing;computer vision;eye tracking;pose;computer science;artificial intelligence	Vision	-0.20681948067145556	-83.43538422818216	128339
033308a7a8ad89b47e26d81fe6fa826a9b5d4e34	development of the obstacle detection system combining orientation sensor of smartphone and distance sensor	ultrasonic variables measurement acoustics legged locomotion bluetooth accuracy mathematical model instruments;distance sensor obstacle detection system orientation sensor walking support system visually impaired person smartphone high performance portable information terminal;smart phones biomedical equipment distance measurement handicapped aids medical computing	In the existing walking support system, the range of detection is limited, and it is very difficult to detect obstacles such as a step or a hollow. Therefore, we aim at the development of a new walking support system for a visually-impaired person detecting neighboring obstacles by making use of a smartphone which is a high-performance portable information terminal. In this study, we have developed a walking support system combining the orientation sensor of the smartphone and a small distance sensor at the first stage. When we investigated its precision in detecting an obstacle, it was found that the system could detect obstacles which disturbed the walking of a visually-impaired person such as a step and a wall. We will find an appropriate key to detection to improve the detection precision of the system and make further improvements in the system by trial experiments in the future.	cns disorder;experiment;sensor;smartphone;stage level 1;support system	Yutaka Tange;Shunsuke Takeno;Junichi Hori	2015	2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2015.7319929	embedded system;computer vision;simulation;engineering	Robotics	8.41400593701926	-84.80549985038475	128357
708b67999af5291c163750cace682e5f0ad36d43	voice disorder identification by using machine learning techniques		Nowadays, the use of mobile devices in the healthcare sector is increasing significantly. Mobile technologies offer not only forms of communication for multimedia content (e.g. clinical audio-visual notes and medical records) but also promising solutions for people who desire the detection, monitoring, and treatment of their health conditions anywhere and at any time. Mobile health systems can contribute to make patient care faster, better, and cheaper. Several pathological conditions can benefit from the use of mobile technologies. In this paper we focus on dysphonia, an alteration of the voice quality that affects about one person in three at least once in his/her lifetime. Voice disorders are rapidly spreading, although they are often underestimated. Mobile health systems can be an easy and fast support to voice pathology detection. The identification of an algorithm that discriminates between pathological and healthy voices with more accuracy is necessary to realize a valid and precise mobile health system. The key contribution of this paper is to investigate and compare the performance of several machine learning techniques useful for voice pathology detection. All analyses are performed on a dataset of voices selected from the Saarbruecken voice database. The results obtained are evaluated in terms of accuracy, sensitivity, specificity, and receiver operating characteristic area. They show that the best accuracy in voice diseases detection is achieved by the support vector machine algorithm or the decision tree one, depending on the features evaluated by using opportune feature selection methods.	algorithm;decision tree;feature selection;mhealth;machine learning;mobile device;receiver operating characteristic;sensitivity and specificity;support vector machine	Laura Verde;Giuseppe De Pietro;Giovanna Sannino	2018	IEEE Access	10.1109/ACCESS.2018.2816338	support vector machine;feature selection;feature extraction;voice disorder;mobile technology;decision tree;computer science;mobile device;health care;machine learning;artificial intelligence	Mobile	5.707829137938733	-86.55823007084376	128577
59e59bcb7f8a1b5a99a5e30ff8145baf92d96c8e	gesture spotting with body-worn inertial sensors to detect user activities	traitement signal;methode section divisee;partition method;signal continu;reconnaissance geste;niveau activite;body worn equipment;hidden markov model;senal continua;implementation;data stream;modele markov variable cachee;event detection;segmentation;probabilistic approach;similitude;captador medida;detection mouvement;measurement sensor;capteur mesure;methode partition;hidden markov models;monitoring;estudio caso;appareil corporel;gesture spotting;enfoque probabilista;approche probabiliste;signal processing;similarity;systeme inertiel;etude cas;deteccion movimiento;automatic dietary monitoring;metodo particion;continuous signal;monitorage;activity levels;similitud;0707d;inertial systems;implementacion;monitoreo;procesamiento senal;motion detection;gesture recognition;inertial sensor;similarity search;segmentacion;natural gesture segmentation;activity recognition;multistage method	We present a method for spotting sporadically occurring gestures in a continuous data stream from body-worn inertial sensors. Our method is based on a natural partitioning of continuous sensor signals and uses a two-stage approach for the spotting task. In a first stage, signal sections likely to contain specific motion events are preselected using a simple similarity search. Those preselected sections are then further classified in a second stage, exploiting the recognition capabilities of hidden Markov models. Based on two case studies, we discuss implementation details of our approach and show that it is a feasible strategy for the spotting of various types of motion events. 2007 Elsevier Ltd. All rights reserved.	activity recognition;continuous signal;hidden markov model;markov chain;microsoft outlook for mac;real life;rejection sampling;sensor;similarity search;switzerland	Holger Junker;Oliver Amft;Paul Lukowicz;Gerhard Tröster	2008	Pattern Recognition	10.1016/j.patcog.2007.11.016	computer vision;speech recognition;similarity;computer science;artificial intelligence;similitude;machine learning;continuous signal;implementation;segmentation;hidden markov model	AI	-4.517235965805735	-93.0206060577124	129017
1e2495452820827bba5f3dbe5a134807cb636e08	a sensor-based method for occupational heat stress estimation		Occupational Heat Stress (OHS) happens when a worker is physically active in hot environments. OHS can produce a strain on the body which leads to discomfort and eventually to heat illness and even death. Related ISO standards contain methods to estimate OHS and to ensure the safety and health of workers, but, they are subjective, impersonal, performed a posteriori, and even invasive. We hypothesize that a real time automated method is more effective and objective estimating OHS if it fuses data from environmental sensors, unobtrusive physiological body sensors, and takes into account the user profile. We propose a personalized method based on ergonomic calculations to offer a solution. We found that our method allows estimating the personalized effort levels, energy expenditure and drudgery of work for each worker and enables to take informed decisions to control OHS. We think that ISO standards could consider technological advances to propose real-time personalized methods.	human factors and ergonomics;oracle http server;personalization;real-time computing;real-time transcription;sensor;user profile	Pablo Pancardo;Francisco D. Acosta;José Adán Hernández-Nolasco;Miguel A. Wister;Diego López-de-Ipiña	2014		10.1007/978-3-319-13102-3_41	human–computer interaction;heat illness;computer science;reliability engineering;human factors and ergonomics;user profile	HCI	6.02213805569192	-87.63767868768407	129236
b45af1f091557a1288a29f43f7a4b1269dbaa817	real-time gait phase detection using wearable sensors	phase detection;real time;pollution measurement;foot;footwear;gait phases;flexible printed circuits real time systems foot phase detection pollution measurement accelerometers footwear;ankle angle;flex sensors;flex sensors real time gait phases ankle angle;accelerometers;feedback control system real time gait phase detection wearable sensor intelligent assistive device powered actuator lower limb pathology minimal hardware flex sensor ankle angle measurement initial contact detection serial interface;phase measurement angular measurement gait analysis intelligent actuators intelligent sensors;flexible printed circuits;real time systems	Intelligent assistive devices using powered actuators are used to restore the gait patterns of amputees or patients with lower limb pathologies. These devices use feedback systems to drive actuators accurately at the right instances during gait. As such, information about gait phases in real-time is necessary to diagnose and/or to provide feedback to assistive devices. This paper presents a method to detect the gait phases in real-time using minimal hardware. A flex sensor that was mounted on a leather shoe was used to accurately measure the ankle angles as well as for the detection of the initial contact and toe-off events during a gait cycle. The data was sent to the software via serial interface and plotted to validate the results-which shows that the technique is feasible to be employed as an integral part of a feedback control system for a powered assistive device.	assistive technology;feedback;floor and ceiling functions;fuzzy control system;fuzzy logic;laptop;microprocessor development board;real-time clock;real-time transcription;sensor;serial communication;shoe size;wearable computer;wearable technology	Osama Mazhar;Abu Zeeshan Bari;Ahmad 'Athif Mohd Faudzi	2015	2015 10th Asian Control Conference (ASCC)	10.1109/ASCC.2015.7244853	embedded system;electronic engineering;simulation;engineering	Robotics	9.74865243333835	-88.45085424670498	129307
d2a31955c80ddfdccc3f107ff5110dcb5ee9ec56	cues: cueing for upper limb rehabilitation in stroke	dr thomas ploetz;professor patrick olivier;amey holden;wearable;lived experience;eprints newcastle university;open access;home;roisin mcnaney;nils hammerla;cueing;lianne brkic;stroke rehabilitation adherence;dan jackson;dr madeline balaam;dr christopher price	Upper limb weakness is one of the most distressing, long-term consequences of stroke and can be difficult to rehabilitate due to an overreliance on the opposing limb in everyday life. Previous studies have shown potential for cueing to improve upper limb rehabilitation, although these have been conducted in clinical settings. In this paper we describe CueS, a wrist worn cueing device which prompts the wearer to move their upper limb more frequently in their day to day lives. We conducted two, week-long 'in the wild' deployments of CueS with seven participants to obtain reflections and experiences around using the device. All participants reported increased general activity levels from wearing CueS and objective data showed increased levels of activity following cue provision. We reflect upon the potential of wearable cueing devices for upper limb rehabilitation after stroke.	amiga reflections;experience;teleprompter;wearable computer	Amey Holden;Roisin McNaney;Madeline Balaam;Robin Thompson;Nils Y. Hammerla;Thomas Plötz;Daniel Jackson;Christopher Price;Lianne Brkic;Patrick Olivier	2015		10.1145/2783446.2783576	psychology;physical therapy;surgery	HCI	7.9479255458290945	-91.2204044594814	129320
3d2cff2f490e4f11004463a46bea9b62f52a4ea3	in-home assistive system for traumatic brain injury patients	biomedical monitoring;wireless sensor;2 axis wearable wireless accelerometer sensor;gaussian mixture models in home assistive system traumatic brain injury patients fixed wireless home sensors 2 axis wearable wireless accelerometer sensor;traumatic brain injury patients;sensor systems;brain injuries;cognitive impairment;traumatic brain injury;wireless sensors;gaussian processes;wrist;frequency domain analysis;wearable sensors;classification;gaussian mixture model;handicapped aids;false positive rate;in home assistive system;wireless sensor networks gaussian processes handicapped aids;fixed wireless home sensors;gaussian mixture models;system integration;intelligent systems;wireless sensors activities of daily living classification gaussian mixture model;time domain;activity of daily living;frequency domain;activities of daily living;accelerometers;wireless sensor networks;intelligent sensors;brain injuries biomedical monitoring wireless sensor networks wearable sensors intelligent systems sensor systems accelerometers wrist frequency domain analysis intelligent sensors	We describe a system for assisting patients in a home setting who suffer from cognitive impairments due to traumatic brain injury. The system integrates fixed wireless home sensors and wearable wireless sensors. We focus on the task of classifying activities of daily living. We locate and track the subjects with the help of home sensors and capture the details of an executed activity with a 2-axis wearable wireless accelerometer sensor attached to the right wrist. We extract time domain and frequency domain features for each task and classify them with Gaussian mixture models followed by a majority voter. The majority voter provides low false positive rates while continuously tracking the tasks. The experimental results from 2 subjects in recognizing 4 distinct daily activity tasks are promising.	mixture model;sensor;wearable computer	Nuri Firat Ince;Cheol-Hong Min;Ahmed H. Tewfik	2007	2007 IEEE International Conference on Acoustics, Speech and Signal Processing - ICASSP '07	10.1109/ICASSP.2007.366298	embedded system;simulation;activities of daily living;intelligent decision support system;computer science;mixture model;frequency domain;statistics	Robotics	8.203658561540037	-86.95945108300133	129403
ec3abcd6f9e5934a818ed43ac40156ede3b0d028	vital sign and sleep monitoring using millimeter wave	healthcare;smart home;60 ghz;vital signs;human finding;signal reflection and blockage;millimeter wave	Continuous monitoring of human’s breathing and heart rates is useful in maintaining better health and early detection of many health issues. Designing a technique that can enable contactless and ubiquitous vital sign monitoring is a challenging research problem. This article presents mmVital, a system that uses 60GHz millimeter wave (mmWave) signals for vital sign monitoring. We show that the mmWave signals can be directed to human’s body and the Received Signal Strength (RSS) of the reflections can be analyzed for accurate estimation of breathing and heart rates. We show how the directional beams of mmWave can be used to monitor multiple humans in an indoor space concurrently. mmVital also provides sleep monitoring with sleeping posture identification and detection of central apnea and hypopnea events. It relies on a novel human finding procedure where a human can be located within a room by reflection loss-based object/human classification. We evaluate mmVital using a 60GHz testbed in home and office environment and show that it provides the mean estimation error of 0.43 breaths per minute (Bpm; breathing rate) and 2.15 beats per minute (bpm; heart rate). Also, it can locate the human subject with 98.4% accuracy within 100ms of dwell time on reflection. We also demonstrate that mmVital is effective in monitoring multiple people in parallel and even behind a wall.	contactless smart card;poor posture;rss;reflection (computer graphics);testbed;words per minute	Zhicheng Yang;Parth H. Pathak;Yunze Zeng;Xixi Liran;Prasant Mohapatra	2017	TOSN	10.1145/3051124	computer science;hypopnea;real-time computing;rss;breathing;home automation;respiratory rate;testbed;continuous monitoring;dwell time	HCI	9.81627247819692	-87.06734668433059	129423
345ea9b5765561faf53aaddfc811a2564e6d62ee	smart surface: rfid-based gesture recognition using k-means algorithm		Elder adults may have some dependence on performing common activities like zapping on the television through a remote control (i.e. due to possible hand mobility problems). The Internet of Things (IoT), including the Radio Frequency Identification (RFID), interconnects devices to provide a higher variety of services. Together, and by applying intelligence through Machine Learning (ML) techniques, advanced applications can be implemented improving people's life. We present the Smart Surface system, relying on state of the art RFID equipment. It uses the unsupervised machine learning technique K-means clustering to detect and trigger actions by means of simple gestures, in real time and in a non-intrusive way. We implemented and evaluated a prototype of the Smart Surface system achieving an accuracy of 100% gesture recognition.	algorithm;cluster analysis;electrical connection;gesture recognition;internet of things;k-means clustering;machine learning;prototype;radio frequency;radio-frequency identification;remote control	Raúl Parada;Kamruddin Nur;Joan Melià-Seguí;Rafael Pous	2016	2016 12th International Conference on Intelligent Environments (IE)	10.1109/IE.2016.25	embedded system;simulation;engineering;artificial intelligence	Robotics	5.154630496325276	-85.67109845566469	129637
66449f6eb492864c86ab80e81417b5003a76a36b	video emotion recognition in the wild based on fusion of multimodal features	late fusion;multimodal features;video emotion recognition;cnn	In this paper, we present our methods to the Audio-Video Based Emotion Recognition subtask in the 2016 Emotion Recognition in the Wild (EmotiW) Challenge. The task is to predict one of the seven basic emotions for the characters in the video clips extracted from movies or TV shows. In our approach, we explore various multimodal features from audio, facial image and video motion modalities. The audio features contain statistical acoustic features, MFCC Bag-of-Audio-Words and MFCC Fisher Vectors. For image related features, we extract hand-crafted features (LBP-TOP and SPM Dense SIFT) and learned features (CNN features). The improved Dense Trajectory is used as the motion related features. We train SVM, Random Forest and Logistic Regression classifiers for each kind of feature. Among them, MFCC fisher vector is the best acoustic features and the facial CNN feature is the most discriminative feature for emotion recognition. We utilize late fusion to combine different modality features and achieve a 50.76% accuracy on the testing set, which significantly outperforms the baseline test accuracy of 40.47%.	acoustic cryptanalysis;acoustic fingerprint;baseline (configuration management);emotion recognition;fisher information;local binary patterns;logistic regression;modality (human–computer interaction);multimodal interaction;personalization;random forest;super paper mario;video clip	Shizhe Chen;Xinrui Li;Qin Jin;Shilei Zhang;Yong Qin	2016		10.1145/2993148.2997629	computer vision;speech recognition;pattern recognition	Vision	-3.4761985615234305	-84.99768983995352	129671
071cb281d1d4754f74745626c4a240e18a766ade	ultra low power asic for r-r interval extraction on wearable health monitoring system	geriatrics;microcontrollers;electrocardiography application specific integrated circuits monitoring power demand heart rate variability clocks data mining;electrocardiography;ultralow power asic ecg feature extraction power consumption power hungry device ecg waveform microcontroller unit battery limitation elderly people quality of life human society continuous human monitoring system electrocardiogram ultralow power application specific integrated circuit wearable health monitoring system r r interval extraction;application specific integrated circuits;feature extraction;asic health monitoring system pastable device heart rate variability hrv fuzzy logic;patient monitoring;waveform analysis application specific integrated circuits biomedical equipment electrocardiography feature extraction geriatrics medical signal processing microcontrollers patient monitoring;waveform analysis;medical signal processing;biomedical equipment	This study shows a development of an ultra low power application specific integrated circuit (ASIC) that extracts R-R intervals from electrocardiogram (ECG) data on a human monitoring system. The continuous human monitoring is substantially useful to realize a high quality of life human society especially for elderly people who live alone. However, it is difficult to realize such a system that can operate longtime without maintenances because of its battery limitation. A micro controller unit (MCU) has to be continuously operated to samples the ECG waveform, which is known as one of a power hungry device in the system. In order to reduce the power consumption of the MCU, an ultra low power ASIC for ECG feature extraction is developed for replace a role of MCU to extract the R-R intervals of ECG feature values.	application-specific integrated circuit;display resolution;feature extraction;microcontroller;waveform;wearable computer	Takayuki Fujita;Tomoya Tanaka;Koji Sonoda;Kensuke Kanda;Kazusuke Maenaka	2013	2013 IEEE International Conference on Systems, Man, and Cybernetics	10.1109/SMC.2013.645	microcontroller;embedded system;feature extraction;computer science;machine learning;remote patient monitoring;application-specific integrated circuit;geriatrics	EDA	9.33257169487315	-88.6915064500733	129677
de9e9c71e00040339bad47bc4b0948a6eb031039	comparison of nearest neighbour and neural network based classifications of patient's activity	neural network;neural nets;ubiquitous computing;backpropagation;classification;accuracy;accelerometers	This paper presents a comparison of 1-nearest neighbour (1-NN) and neural network based classification of patient activity. The data for classification was acquired from two 6 degree-of-freedom accelerometers deployed at the wrists of a patient. Instead of calculating statistical values, we studied the use of data samples acquired from 200ms time window. The best results were achieved with the 1-nearest neighbour algorithm. The overall accuracy of the 1-NN method was nearly 100%. The learning method for neural network used was the backpropagation with momentum. According to our experiments, the results of classification were more accurate with 1-NN in comparison with the result of neural network (93.4%).	artificial neural network;backpropagation;experiment;k-nearest neighbors algorithm	Matti Pouke;Risto T. Honkanen	2011	2011 5th International Conference on Pervasive Computing Technologies for Healthcare (PervasiveHealth) and Workshops		biological classification;computer science;artificial intelligence;backpropagation;machine learning;data mining;accuracy and precision;accelerometer;artificial neural network	Robotics	7.589792612746091	-84.1738394925754	129760
878ff3ef901f36275dd2e5d18013fb6e2db92b8a	standing hypotension prediction based on smartwatch heart rate variability data: a novel approach	heart rate variability;smartwatch;regression;blood pressure drop	The number of wearable and smart devices which are connecting every day in the Internet of Things (IoT) is continuously growing. We have a great opportunity though to improve the quality of life (QoL) standards by adding medical value to these devices. Especially, by exploiting IoT technology, we have the potential to create useful tools which utilize the sensors to provide biometric data. This novel study aims to use a smartwatch, independent from other hardware, to predict the Blood Pressure (BP) drop caused by postural changes. In cases that the drop is due to orthostatic hypotension (OH) can cause dizziness or even faint factors, which increase the risk of fall in the elderly but, as well as, in younger groups of people. A mathematical prediction model is proposed here which can reduce the risk of fall due to OH by sensing heart rate variability (data and drops in systolic BP after standing in a healthy group of 10 subjects. The experimental results justify the efficiency of the model, as it can perform correct prediction in 86.7% of the cases, and are encouraging enough for extending the proposed approach to pathological cases, such as patients with Parkinson's disease, involving large scale experiments.	biometrics;experiment;heart rate variability;internet of things;sensor;smart device;smartwatch;syncope (medicine);the quality of life;wearable computer	Dimitrios Iakovakis;Leontios J. Hadjileontiadis	2016		10.1145/2957265.2970370	heart rate variability;simulation;regression;computer science;smartwatch	HCI	7.52878171421263	-86.03468971079525	129865
78f66262f06ee3313c4427cfd7c5f0add7fc8b4f	an intelligent remote monitoring system for artificial heart	quality of life;database system;information retrieval;real time;telemedicine;database;flow estimation;internet;medical information systems;computerised monitoring artificial organs internet information retrieval medical information systems patient monitoring telemedicine;data access;unsupervised classification;simulation study;patient monitoring;remote monitoring;artificial organs;computerised monitoring;decision support systems clinical diagnosis computer assisted equipment failure analysis expert systems heart artificial humans internet monitoring physiologic online systems telemedicine therapy computer assisted user computer interface;automatic classification;unsupervised classification artificial heart database flow estimation remote monitoring;intelligent systems artificial intelligence remote monitoring artificial heart deductive databases animals database systems implants hospitals patient monitoring;unsupervised classification intelligent remote monitoring system artificial heart web based database system artificial heart implant continuous remote monitoring system life support device web based data access system intelligent diagnosis algorithm module blood pump automatic classification data generation emulator remote facilities flow estimation;artificial heart	A web-based database system for intelligent remote monitoring of an artificial heart has been developed. It is important for patients with an artificial heart implant to be discharged from the hospital after an appropriate stabilization period for better recovery and quality of life. Reliable continuous remote monitoring systems for these patients with life support devices are gaining practical meaning. The authors have developed a remote monitoring system for this purpose that consists of a portable/desktop monitoring terminal, a database for continuous recording of patient and device status, a web-based data access system with which clinicians can access real-time patient and device status data and past history data, and an intelligent diagnosis algorithm module that noninvasively estimates blood pump output and makes automatic classification of the device status. The system has been tested with data generation emulators installed on remote sites for simulation study, and in two cases of animal experiments conducted at remote facilities. The system showed acceptable functionality and reliability. The intelligence algorithm also showed acceptable practicality in an application to animal experiment data.	data collection;data access;database;desktop computer;emulator;estimated;experiment;heart;heart, artificial;medical algorithm;name;patients;real-time clock;real-time transcription;real-time web;remote control;simulation;television;vad i protocol;voice activity detection;web application;life support	Jaesoon Choi;J. W. Park;Jinhan Chung;B. G. Min	2005	IEEE Transactions on Information Technology in Biomedicine	10.1109/TITB.2005.855534	data access;the internet;simulation;quality of life;computer science;remote patient monitoring;data mining;database;rmon	Robotics	7.456620427114108	-88.38135052939099	130203
097cc5ed43cec19a144884e3a7a17723948ac244	signal processing for assisted living: developments and open problems [from the guest editors]	signal processing assisted living;sensing modality signal processing assisted living;special issues and sections assisted living assistive technology senior citizens wearable computing signal processing research and development telecommunication services	The old-age dependency ratio, which is defined as the ratio of the population age 65 and over to the population age between 15 and 64, has been rising in many countries all over the world. According to the United Nations estimates for the “more developed regions,” this ratio is anticipated to exceed 30% in 2020 and reach 40% by 2030, largely as a result of an accelerating increase in the aged population. This implies that those of working age, and, subsequently, the overall economy, will face a greater burden in supporting the aging population. In addition, the demand and trend are upward for continued independent living, in both more and less developed regions. As such, there is a growing interest in assisted living technologies that enable self-dependent living within homes and residences for the elderly, in particular those homes that will ensure an elderly person more years of life in good health. Remote monitoring capabilities, such as fall risk assessment, fall detection, and detection of small changes from predefined baselines in health conditions and motor functional abilities of the elderly, will address the challenges associated with self-dependent living. All of the aforementioned capabilities are rooted in fundamental signal processing problems related to signal capturing, analysis, and interpretation. More specifically, these entail signal detection and enhancement in the presence of noise and interference; signal representation in a domain that is conducive to capturing a rich set of features for vital signs estimation, human activity detection, localization, and health and well-being classification; the use of single and multiple sensors; centralized and distributed data fusion; and change or anomaly detection for risk assessments; to name but a few. Contributions in signal processing for assisted living technologies have not only been driven by recent developments in signal analysis and interpretation but also important revisits to “classical” approaches for exploiting the underlying phenomenology and the specificities of the problem at hand.	anomaly detection;centralized computing;detection theory;interference (communication);risk assessment;sensor;signal processing	Fauzia Ahmad;A. Enis Çetin;K. C. Ho;John Nelson	2016	IEEE Signal Process. Mag.	10.1109/MSP.2016.2514718	computer science;electrical engineering;multimedia		9.512555558305868	-87.11465225594158	130211
4c6a9c76e98ee56532bd3abea4cd088ca431e9d2	a surveillance system for preventing suicide attempts in urban metro stations	emotion recognition;smart cities;system architecture;surveillance systems;affective computing	Focusing on the research results of psychologists and epistemologists it is an open issue whether people who commit suicide do so as a result of free will or if they suffer from chronic or occasional depression. During the decision making process of a potential suicide the facial features, the voice frequencies and the body movement gestures express the depressive emotional state of a specific individual. In metro stations and other public space there are surveillance systems which can capture facial expressions, body movement and speech recognition of an individual. In this paper it is proposed a design of an information system architecture which can predict whether an individual intends to commit a suicide in an urban metro station or not, in a critical period of time.	information system;speech recognition;systems architecture	Theodoros Anagnostopoulos	2014		10.1145/2645791.2645806	simulation;computer science;artificial intelligence;affective computing;computer security	Robotics	7.229137320749474	-92.18827790860959	130320
050c5a57cf2c9605708db6e8b5dbcb88b7228f60	a software assistant for user-centric calibration of a wireless body sensor	medical signal processing biosensors electrocardiography health care;faulty operation reduction user centric calibration health promotion daily life kinematic signal quality user compliance human user software assistant wireless body sensor ecg respiration sensor accelerometer;calibration software heart rate electrocardiography accelerometers acceleration wireless sensor networks	Body sensors have a promising contribution to health promotion in many areas of daily life (telemedicine, corporate health care or recreational sports). However, the valid measurement of vital signs and kinematic data strongly depends on the signals' quality and the users' compliance (proper usage). Although, there is a lot of research work concerning accuracy and calibration of wireless body sensors the human user is typically not involved. Thus, in this work, we present a software assistant (wizard) that guides users during the process of attaching and setting up a wireless body sensor. Furthermore, insights of the implemented software as well as the utilized quality measures and calibration steps are given (ECG, respiration sensor and accelerometer). With the proposed software assistant, the users are instructed to correctly attach the body sensor and calibrate or verify the operability of the various sensor elements. The primary goal is to encourage compliance and the users' sense of control. In this way, we want to reduce faulty operation and ensure optimal signal quality.	operability;sensor;wizard (software)	Timm Hormann;Marc Hesse;Michael Adams;Ulrich Rückert	2016	2016 IEEE 13th International Conference on Wearable and Implantable Body Sensor Networks (BSN)	10.1109/BSN.2016.7516256	embedded system;simulation	Robotics	8.476990032822448	-88.78654532086497	130440
65e09f983e09af6d6aa0f37918573d734fac22aa	recognition of piano pedalling techniques using gesture data		This paper presents a study of piano pedalling technique recognition on the sustain pedal utilising gesture data that is collected using a novel measurement system. The recognition is comprised of two separate tasks: onset/offset detection and classification. The onset and offset time of each pedalling technique was computed through signal processing algorithms. Based on features extracted from every segment when the pedal is pressed, the task of classifying the segments by pedalling technique was undertaken using machine learning methods. We exploited and compared a Support Vector Machine (SVM) and a hidden Markov model (HMM) for classification. Recognition results can be represented by customised pedalling notations and visualised in a score following system.	algorithm;hidden markov model;machine learning;markov chain;offset time;onset (audio);signal processing;statistical classification;support vector machine;system of measurement;volume rendering	Beici Liang;György Fazekas;Mark B. Sandler	2017		10.1145/3123514.3123535	piano;score following;support vector machine;hidden markov model;signal processing;offset (computer science);speech recognition;gesture;computer science	ML	0.20314137083319697	-88.44873941435746	130653
08d051b8f49e65ca597e42d8faa170eb4c3f1f5e	elderly daily activity habits or lifestyle in their natural environments	smart home;lifestyle;habits;elderly;activity;data collection;monitoring system;research and development;natural environment	A research and development innovation project partly funded by the French company EDF was conducted for the advancement of smart homes. The aim is to help elderly to live at home in safe conditions. The experiments were carried out in a long-term setting in Orléans (France). As part of the project, the monitoring system aims to assess daily activity habits or lifestyle at home (fall, restlessness, fainting, running away....) through individual mobility data collection and analysis. This paper describes the architecture of the multisensor monitoring system used to collect individual mobility data, and presents the software used to assess the daily activity habits or lifestyle. Some preliminary results are given.	earliest deadline first scheduling;experiment;individual mobility;syncope (medicine)	Marie Chan;Daniel Estève;Eric Campo	2011		10.1145/2141622.2141654	simulation;habit;natural environment;statistics;data collection	HCI	7.139620215757759	-86.7996715786443	130819
917ecacc5950db959745448d0d98318d8507d8a0	detection of outbreaks from time series data using wavelet transform	sensitivity and specificity;mathematical computing;auto regressive;models biological;wavelet transform;long term trend;roc curve;time series data;algorithms;humans;multi resolution;disease outbreak;disease outbreaks	In this paper, we developed a new approach to detection of disease outbreaks based on wavelet transform. It is capable of dealing with two problems found in real-world time series data, namely, negative singularity and long-term trends, which may degrade the performance of current approaches to outbreak detection. To test this approach, we introduced artificail disease outbreaks and negative singularities into a real world dataset and applied it and two other algorithms-autoregressive (AR) and Multi-resolution Wavelet Auto-regressive (MWAR) - to this dataset. We compared the performance of these algorithms in terms of sensitivity, specificity and timeliness. The results showed that our approach had similar sensitivity and specificity and slightly better timeliness compared to the other two algorithms. When we introduced negative singularities, its performance did not degrade as much as the other two algorithms' performance. We conclude that our approach to detection, when compared to traditional approaches, may not be as susceptible to degradation of performance caused by negative singularities.	algorithm;autoregressive model;elegant degradation;parkinson disease;regular expression;sensitivity and specificity;silo (dataset);time series;wavelet transform	Jun Zhang;Fu-Chiang Tsui;Michael M. Wagner;William R. Hogan	2003	AMIA ... Annual Symposium proceedings. AMIA Symposium		econometrics;engineering;machine learning;statistics	Embedded	8.084067512088478	-80.393935037466	130881
d430a8d055f74869393ebfbf13acadec1413334d	identi-wheez — a device for in-home diagnosis of asthma	biomedical monitoring;stethoscope;pediatrics;lungs;noise measurement;position measurement;signal to noise ratio	Asthma is the most common chronic illness among children. The skills required to diagnose it make it an even greater concern. In this work, we present a child-friendly wearable device, which allows in-home diagnosis of asthma. The device acquires simultaneous measurements from multiple stethoscopes. The recordings are then sent to a specialist who uses assistive diagnosis algorithms that enable auscultation (listening to lung sounds with a stethoscope) at any location in the lungs volume by sound refocusing. The specialist is also presented with a sound “heat map” which shows the location of sound sources in the lungs. We present design considerations of our device, as well as the algorithms for assistive diagnosis and their analysis which demonstrate reduction of ambient and measurement noise by over 10dB.	assistive technology;auscultation;chronic disease;heat map;lung diseases;respiratory sounds;stethoscopes;structure of parenchyma of lung;wearable technology;algorithm	Guy Satat;Krithika Ramchander;Ramesh Raskar	2016	2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2016.7591696	intensive care medicine;medicine;pathology;computer science;noise measurement;biological engineering;signal-to-noise ratio	Visualization	9.654141944181179	-88.28312812934678	130925
22cb5dc70bd3f14f0b254e1e16234dcf204e15a5	automatic tagging using deep convolutional neural networks		We present a content-based automatic music tagging algorithm using fully convolutional neural networks (FCNs). We evaluate different architectures consisting of 2D convolutional layers and subsampling layers only. In the experiments, we measure the AUC-ROC scores of the architectures with different complexities and input types using the MagnaTagATune dataset, where a 4-layer architecture shows state-of-the-art performance with mel-spectrogram input. Furthermore, we evaluated the performances of the architectures with varying the number of layers on a larger dataset (Million Song Dataset), and found that deeper models outperformed the 4-layer architecture. The experiments show that mel-spectrogram is an effective time-frequency representation for automatic tagging and that more complex models benefit from more training data.	algorithm;artificial neural network;chroma subsampling;convolutional neural network;experiment;performance;spectrogram;time–frequency representation	Keunwoo Choi;György Fazekas;Mark B. Sandler	2016			computer science;theoretical computer science;machine learning;data mining	NLP	-4.1171754809965915	-87.23556970019294	130956
22fcb65d0873d2aefb6f0b1a6dc4939d9500717a	semi-markov conditional random fields for accelerometer-based activity recognition	wearable sensors;conditional random fields crf;hidden markov model hmm;accelerometer;activity recognition	Activity recognition is becoming an important research area, and finding its way to many application domains ranging from daily life services to industrial zones. Sensing hardware and learning algorithms are two important components in activity recognition. For sensing devices, we prefer to use accelerometers due to low cost and low power requirement. For learning algorithms, we propose a novel implementation of the semi-Markov Conditional Random Fields (semi-CRF) introduced by Sarawagi and Cohen. Our implementation not only outperforms the original method in terms of computation complexity (at least 10 times faster in our experiments) but also is able to capture the interdependency among labels, which was not possible in the previously proposed model. Our results indicate that the proposed approach works well even for complicated activities like eating and driving a car. The average precision and recall are 88.47% and 86.68%, respectively, which are higher than results obtained by using other methods such as Hidden Markov Model (HMM) or Topic Model (TM).	activity recognition;algorithm;computation;conditional random field;experiment;hidden markov model;information retrieval;interdependence;machine learning;markov chain;precision and recall;semiconductor industry;topic model	La The Vinh;Sungyoung Lee;Le Xuan Hung;Hung Quoc Ngo;Hyoung-Il Kim;Manhyung Han;Young-Koo Lee	2010	Applied Intelligence	10.1007/s10489-010-0216-5	simulation;speech recognition;computer science;artificial intelligence;machine learning;accelerometer;activity recognition	AI	3.6873961465445655	-84.72314976953359	130961
8cae56e4d8898b4e1f0cd03e560eef9e7fa0586f	making sense of personal data in clinical settings	medical signal processing electrocardiography medical signal detection;ecg;clinical grade monitoring;electrocardiography packet loss noise accelerometers monitoring wireless sensor networks;packet loss mitigation;clinical grade monitoring signal processing ecg packet loss mitigation motion artifacts;motion artifacts;signal processing;wearable form factors personal data clinical data healthcare delivery cost reduction quality of care improvement clinical quality requirements clinical workflows signal processing electrocardiogram signal acquisition ecg signal acquisition gold standards state ecg quality resting wired ecg quality enabling packet losses motion artifacts sensor power	This contribution addresses clinical data, but acquired outside hospital walls, to improve the quality of care and/or to reduce the cost of healthcare delivery. Such data must meet the clinical quality requirements for one to leverage current best practices with minimal changes to clinical workflows. We present signal-processing solutions for acquiring electrocardiogram (ECG) signals outside hospital walls and validate them against current gold standards in clinical settings. We show that the proposed approaches enable wired ECG quality and resting state ECG quality in the presence of packet losses and motions artifacts, with low sensor power to enable wearable form factors.	best practice;computer form factor;network packet;personally identifiable information;requirement;resting state fmri;signal processing;wearable computer	Harinath Garudadri	2014	2014 48th Asilomar Conference on Signals, Systems and Computers	10.1109/ACSSC.2014.7094841	embedded system;electronic engineering;engineering;biological engineering	Mobile	10.015284237385293	-88.44925008346497	132239
2bcd19b4cfd9946145dd48a7d387a4a46ff92e9f	user daily activity pattern learning: a multi-memory modeling approach	learning artificial intelligence assisted living geriatrics;parameter settings user daily activity pattern learning multimemory modeling approach adlart model activities of daily living adl human multiple memory system episodic memory semantic memory working memory;vectors subspace constraints semantics hidden markov models senior citizens data structures pattern recognition	In this paper, we propose a multi-memory model, ADLART model, to discover the daily activity pattern of a sensor monitored user from his/her activities of daily living (ADL). The proposed model mimics the human multiple memory system which comprises a working memory, an episodic memory, and a semantic memory. Through encoding user's daily activities patterns in episodic memory and extracting the regularities of activity routines in semantic memory, the ADLART system is able to learn, recognize, compare, and retrieve daily ADL patterns of the user. Experiments are presented to show the performance of the ADLART model using different parameter settings and its performance is discussed in details.	experiment;memory model (programming);simulation	Shan Gao;Ah-Hwee Tan	2014	2014 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2014.6889908	simulation;computer science;artificial intelligence;machine learning	Vision	1.6359650760354174	-86.210596414663	132420
686b14ce7f02516730de03f459cadb223a03765f	generating an event timeline about daily activities from a semantic concept stream		Recognizing activities of daily living (ADLs) in the real world is an important task for understanding everyday human life. However, even though our life events consist of chronological ADLs with the corresponding places and objects (e.g., drinking coffee in the living room after making coffee in the kitchen and walking to the living room), most existing works focus on predicting individual activity labels from sensor data. In this paper, we introduce a novel framework that produces an event timeline of ADLs in a home environment. The proposed method combines semantic concepts such as action, object, and place detected by sensors for generating stereotypical event sequences with the following three realworld properties. First, we use temporal interactions among concepts to remove objects and places unrelated to each action. Second, we use commonsense knowledge mined from a language resource to find a possible combination of concepts in the real world. Third, we use temporal variations of events to filter repetitive events, since our daily life changes over time. We use cross-place validation to evaluate our proposed method on a daily-activities dataset with manually labeled event descriptions. The empirical evaluation demonstrates that our method using real-world properties improves the performance of generating an event timeline over diverse	commonsense knowledge (artificial intelligence);interaction;mined;sensor;timeline	Taiki Miyanishi;Junichiro Hirayama;Takuya Maekawa;Motoaki Kawanabe	2018			machine learning;data mining;timeline;artificial intelligence;computer science;activities of daily living	AI	1.958791875711448	-85.23278304714498	132430
dfafc146245154e13a66483e55647cce4f28b0ac	instrumented insole system for ambulatory and robotic walking assistance: first advances		Current research highlights the emergent need for the development of wearable, calibrated, and accurate sensory systems for ambulatory human gait analysis. The purpose of this work is to develop a lightweight and calibrated instrumented insole system for the real-time monitoring of gait events in healthy, pathological and robotic-assisted gait. We designed the insole with four force sensing resistors (FSRs) to detect four gait events. We also implemented an electronic interface for the data acquisition and processing and the wireless transmission with the motherboard and the user interface. The validation involved 3 healthy female subjects, which reported that this prototype is flexible, lightweight and comfortable for daily usage. Results showed a maximal error of 6.02±3.02% in the detection of foot flat due to the small sensing area of FSRs placed on the first and fifth metatarsus. Future challenges comprise aesthetic and functional improvements and a more comprehensive validation.	assistive technology;benchmark (computing);data acquisition;emergence;gait analysis;maximal set;motherboard;prototype;real-time clock;robot;user interface;wearable computer	Joana Figueiredo;César Ferreira;Luis Costa;João Sepúlveda;Luís Paulo Reis;Juan C. Moreno;Cristina P. Santos	2017	2017 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC)	10.1109/ICARSC.2017.7964062	wearable computer;gait;data acquisition;motherboard;embedded system;user interface;gait (human);computer science	Robotics	8.679472971825172	-86.34405733798361	132486
a8227ed444afa6661d80b5a0a0e3ae0ffaec00dc	automatic segmentation of audio signals for bird species identification	databases;manuals;bird species identification signal processing pattern recognition machine learning;support vector machines;support vector machines audio databases audio signal processing feature extraction learning artificial intelligence pattern classification signal classification;accuracy;svm classifier bird species identification automatic audio signal segmentation audio recorded songs bird plane collisions prevent airports noise removal feature extraction procedures decision procedures machine learning algorithms ml algorithms standard classification scenario labeled bird song database southern atlantic coast south america;birds;machine learning;feature extraction;signal processing;bird species identification;pattern recognition;birds databases feature extraction accuracy manuals support vector machines signal processing algorithms;signal processing algorithms	The identification of bird species from their audio recorded songs are nowadays used in several important applications, such as to monitor the quality of the environment and to prevent bird-plane collisions near airports. The complete identification cycle involves the use of: (a) recording devices to acquire the songs, (b) audio processing techniques to remove the noise and to select the most representative elements of the signal, (c) feature extraction procedures to obtain relevant characteristics, and (d) decision procedures to make the identification. The decision procedures can be obtained by Machine Learning (ML) algorithms, considering the problem in a standard classification scenario. One key element is this cycle is the selection of the most relevant segments of the audio for identification purposes. In this paper we show that the use of short audio segments with high amplitude - called pulses in our work - outperforms the use of the complete audio records in the species identification task. We also show how these pulses can be automatically obtained, based on measurements performed directly on the audio signal. The employed classifiers are trained using a previously labeled database of bird songs. We use a database that contains bird song recordings from 75 species which appear in the Southern Atlantic Coast of South America. Obtained results show that the use of automatically obtained pulses and a SVM classifier produce the best results, all the necessary procedures can be installed in a dedicated hardware, allowing the construction of a specific bird identification device.	acoustic cryptanalysis;algorithm;audio signal processing;computation;database;decision problem;emoticon;experiment;feature extraction;machine learning	Thiago L. F. Evangelista;Thales M. Priolli;Carlos Nascimento Silla;Bruno Augusto Angélico;Celso A. A. Kaestner	2014	2014 IEEE International Symposium on Multimedia	10.1109/ISM.2014.46	support vector machine;computer vision;speech recognition;feature extraction;computer science;machine learning;signal processing;pattern recognition;accuracy and precision	AI	-3.4062030358983124	-89.9686194879635	133023
edb56d36876ab9e4616dea453e6e6831421fcb52	leveraging smart-phone cameras and image processing techniques to classify mosquito species		Mosquito borne diseases continue to pose grave dangers to global health. An important step in combating their spread in any area is to identify the type of species prevalent there. To do so, trained personnel lay local mosquito traps, and after collecting trapped specimens, they visually inspect each specimen to identify the species type and log their counts. This process takes hours and is cognitively very demanding. In this paper, we design a smart-phone based system that allows anyone to take images of a still mosquito that is either alive or dead (but still retaining its physical form) and automatically classifies the species type. Our system integrates image processing, feature selection, unsupervised clustering, and an SVM based machine learning algorithm for classification. Results with a total of 101 mosquito specimens spread across nine different vector carrying species (that were captured from a real outdoor trap in Tampa, Florida) demonstrate high accuracy in species identification. When implemented as a smart-phone application, the latency and energy consumption were minimal. With our system, the currently manual process of species identification and recording can be sped up, while also minimizing the ensuing cognitive workload of personnel. Secondly, ordinary citizens can use our system in their own homes for self-awareness and information sharing with public health agencies.		Mona Minakshi	2018		10.1145/3286978.3286998	workload;image processing;phone;support vector machine;cluster analysis;energy consumption;information sharing;feature selection;computer science;machine learning;distributed computing;artificial intelligence	AI	4.684685906046314	-86.41395074101628	133241
3624da93d1ebc1f76769488361bc4bb16476f7d2	an estimation of wheelchair user's muscle fatigue by accelerometers on smart devices	personal sensing;falling accident;machine learning;pushing wheel;accessibility map	This paper introduces an automatic road accessibility information collecting system inspired by human action sensing technologies of wheelchair users. The system aims to estimate a road accessibility caused by environmental factors, e.g. curbs and gaps, which directly influence wheelchair bodies, and also physiological factors, e.g. the wheelchair user's fatigue resulted by the environmental factors. We report that wheelchair user's fatigue influences wheelchair's action data sensed by accelerometer mounted on iPod touch. This paper contributes to discovering patterns of accelerations each of wheelchair user's fatigue and non-fatigue by clustering pushing wheel action data.	accessibility;cluster analysis;smart device;ipod	Koya Nagamine;Yusuke Iwasawa;Yutaka Matsuo;Ikuko Eguchi Yairi	2015		10.1145/2800835.2800864	embedded system;simulation;computer science;machine learning	HCI	6.594190498436712	-85.14867939695343	133561
c34c4de9d6ddf42637a85f0d35fb05f845fcf029	moving target selection: a cue integration model		This paper investigates a common task requiring temporal precision: the selection of a rapidly moving target on display by invoking an input event when it is within some selection window. Previous work has explored the relationship between accuracy and precision in this task, but the role of visual cues available to users has remained unexplained. To expand modeling of timing performance to multimodal settings, common in gaming and music, our model builds on the principle of probabilistic cue integration. Maximum likelihood estimation (MLE) is used to model how different types of cues are integrated into a reliable estimate of the temporal task. The model deals with temporal structure (repetition, rhythm) and the perceivable movement of the target on display. It accurately predicts error rate in a range of realistic tasks. Applications include the optimization of difficulty in game-level design.		Byungjoo Lee;Sunjun Kim;Antti Oulasvirta;Jong-In Lee;Eun Ji Park	2018		10.1145/3173574.3173804	human–computer interaction;maximum likelihood;word error rate;sensory cue;accuracy and precision;probabilistic logic;computer science;pattern recognition;artificial intelligence	HCI	-0.532900015389517	-84.58370946226067	133673
6fbbeb1ace89577f0f9027c3adff89ef7349a904	multimodal sparsity-eager support vector machines for music classification	support vector machines information retrieval multimedia computing music;public dataset multimodal sparsity eager support vector machines music classification multimedia information retrieval systems data modalities usability radio stations music tv channels gigabytes music files world wide web large scale multimodal datasets supervised methods svm classifier fusion multimodal audio lyrics data single modality classification limitations sparse methods classification accuracy fusion classifier genre classification task;support vector machines;training;classification;accuracy;multiple signal classification;vectors;audio;multimedia communication;training vectors accuracy music support vector machines multiple signal classification multimedia communication;multimodal;audio classification multimodal;music	As the demand for multimedia grows, the development of information retrieval systems utilizing all available data modalities becomes of paramount importance. The provision of multiple modalities is motivated by usability, presence of noise in one modality and non-universality of a single modality. Radio stations and music TV channels hold archives of millions of music tapes and lyrics. Gigabytes of music files are also spread over the web along with the lyrics and metadata for each file. Searching and organizing large scale multimodal datasets is a challenging task. Supervised methods such as support vector machine (SVM) achieve state of the art performance for music classification on single modality, but suffer from over-fitting on training examples and limitations of single modality approaches. In this paper, we introduce a classifier fusion of multimodal audio and lyrics data to address these single modality classification limitations. We introduce the multimodal l1-SVM classifier, that utilizes sparse methods to deal with over-fitting for music classification. We compare the classification accuracy of the fusion classifier for a genre classification task in a large public dataset with single modality l1-SVM.	archive;basis function;coefficient;daubechies wavelet;eager learning;gigabyte;information retrieval;modality (human–computer interaction);modulation;multimodal interaction;organizing (structure);overfitting;sparse matrix;supervised learning;support vector machine;universality probability;usability	Kamelia Aryafar;Ali Shokoufandeh	2014	2014 13th International Conference on Machine Learning and Applications	10.1109/ICMLA.2014.72	speech recognition;computer science;multiple signal classification;machine learning;pattern recognition;music;multimedia;statistics	ML	-3.395967582469807	-86.96390100190042	134097
c836691dee27498cfea1eb6a7cdc7442bfb43169	energy saving using scenario based sensor selection on medical shoes	medical diagnostic imaging footwear measurement pressure sensors medical services legged locomotion wireless sensor networks;mobile computing biomedical equipment embedded systems energy conservation health care;wireless health applications energy saving scenario based sensor selection medical shoes medical embedded systems wireless medical devices	Cost and energy have become the bottleneck of many medical embedded systems. It is mainly due to the fact that wireless medical devices used in wireless health applications normally employ a large number of sensors, which are both expensive as well as consuming a considerable amount of energy. In this paper, we have developed a cost and energy saving scheme by reducing the number of required sensors in the medical devices. We have used a popular medical shoe with 99 pressure sensors for demonstration. With the goal of reducing the number of required sensors without influencing the diagnose accuracy, we have proposed algorithms to select only a small subset of the sensors while still maintaining an almost same diagnostic performance compared to using all the 99 sensors. Our results indicate that on average, our sensor selection can save as much as 88% of the total sensors. We also analyze the effect of using the medical shoes under different scenarios on the results of sensor selection. For example, we have analyzed the scenarios of walking, jumping, running and slow walking. Based on our sensor selection algorithm, it turns out that there exists different subsets of sensors to best recover the diagnostic performances for different scenarios.	embedded system;ibm notes;iterative method;performance;selection algorithm;sensor;shoes	Teng Xu;Miodrag Potkonjak	2015	2015 International Conference on Healthcare Informatics	10.1109/ICHI.2015.56	embedded system;simulation;engineering;key distribution in wireless sensor networks;biological engineering	Mobile	8.46007874491907	-88.74118488589953	134285
6766ef47f91593f58ad8f775c78cef228ddbf659	sign languages recognition based on neural network architecture		In the last years, many steps forward have been made in speech and natural languages recognition and were developed many virtual assistants such as Apple’s Siri, Google Now and Microsoft Cortana. Unfortunately, not everyone can use voice to communicate to other people and digital devices. Our system is a first step for extending the possibility of using virtual assistants to speech impaired people by providing an artificial sign languages recognition based on neural network architecture.		Manuele Palmeri;Filippo Vella;Ignazio Infantino;Salvatore Gaglio	2017		10.1007/978-3-319-59480-4_12	natural language processing;deep learning;natural language;time delay neural network;artificial neural network;architecture;recurrent neural network;american sign language;artificial intelligence;computer science	Robotics	-1.9795841666711491	-82.3127800080057	134554
3472f5f5ba23fe50a224ec7639f5dcad96dca028	classification of perceived running fatigue in digital sports	fatigue;heart rate variability;footwear;interval data;distance measurement;heart rate;magnetic field measurement;feature extraction;pattern recognition;shoe heel compression digital sports biomechanical data gps position;fatigue footwear heart rate heart rate variability psychology pattern recognition mobile handsets intelligent sensors embedded system pattern analysis	This paper presents methods for collecting and analyzing physiological and biomechanical data during recreational runs in order to classify an athletepsilas perceived fatigue state. Heart rate and its variability, running speed and stride frequency, GPS position and shoe heel compression were recorded continuously while runners moved freely outdoors. During their activity the sportsmen answered questions about their fatigue state in five-minute-intervals. Data from 84 one-hour-runs was collected for analysis. The data was analyzed using features computed for each step of the athlete to distinguish three levels of the runnerpsilas fatigue state with an accuracy of 75.3% across multiple study participants and 91.8% in the intraindividual case. The results show that for most participating runners, a heart rate variability periodogram feature and a step duration feature are best suited for classification of the perceived fatigue level. This information can be used to support sportsmen, for example by adapting their equipment to the specific needs of a fatigued athlete.	global positioning system;heart rate variability;pattern recognition;sensor;smart shoe;spectral density estimation	Bjoern M. Eskofier;Florian Hönig;Pascal Kuehner	2008	2008 19th International Conference on Pattern Recognition	10.1109/ICPR.2008.4761204	heart rate variability;simulation;feature extraction;computer science;machine learning	HCI	8.466081407268994	-86.47019735450128	134885
ff8a62a41b966868a67d6200a0edf1ada378c25f	the energy efficient mechanism of a location estimation sensor for silver-care	sensor dispatch device;energy efficient;location estimation;energy efficiency aging dementia energy consumption sensor systems accidents acceleration silver ultrasonic imaging data communication;electric sensing devices biomedical communication diseases;sensor network;acceleration sensors;acceleration sensors energy efficient mechanism location estimation sensor silver care position tracking services aged dementia patients sensor dispatch device position tracking sensor;silver care;energy efficient mechanism;diseases;position tracking services;position tracking sensor;aged dementia patients;electric sensing devices;biomedical communication;location estimation sensor	In sensor network environment, there exists position tracking services as a part of the silver-care system for aged dementia patients. There have been frequent accidental reports of aged dementia patients, and we can prevent these accidents from occurring through the position tracking devices. However, this application requires the adoption of sensor dispatch device on patients, making it necessary to develop portal and small sized sensor devices for this application. In this paper, we propose a new position tracking sensor using acceleration sensors in order to overcome the limitations of existing models, and develop an energy-efficient position tracking sensor for silver-care service.	dynamic dispatch;error-tolerant design;sensor	Young-Shin Kim;Ga-Won Lee;Kyu-Jin Kim;Eui-nam Huh	2009	2009 International Conference on Information Networking		embedded system;simulation;wireless sensor network;computer science;key distribution in wireless sensor networks;efficient energy use;visual sensor network	Robotics	6.585888108383052	-88.15859242494973	135275
33b88f7fb737c796c93a105e6fd008ca783ee5b4	ubiquitous sensor network-based rehabilitation center	rehabilitation;seung joong shin;한국정보통신학회;bart jarochowski;dae hyun ryu;wireless communication;hyungjun kim;journal of information and communication convergence engineering 제5권 제1호;zigbee;ubiquitous sensor network;ubiquitous sensor network based rehabilitation center;the korea institute of information and communication engineering;vol 5 no 1	This paper discusses the implementation of a rehabilitation center based on a ubiquitous sensor network. This paper discusses the implementation of a rehabilitation center based on a ubiquitous sensor network. We recognize that certain mild conditions requiring rehabilitation may be treated with minimal human supervision. In place of this constant human supervision, a variety of sensors are used to monitor the patient and rehabilitation progress. These sensors send data through a wireless Zigbee network to a server which stores the data and makes it available to a rehabilitation expert for analysis. This rehabilitation expert also issues rehabilitation prescriptions which are created based on the expert's determination of the patient's condition. By having the ability to control the rehabilitation equipment used, strictly enforce the assigned prescription, and constantly monitor the patient for any warning signs, the system ensures a safe and optimal rehabilitation session.		Bart Jarochowski;Hyungjun Kim;DaeHyun Ryu;Seung-Jung Shin	2007	J. Inform. and Commun. Convergence Engineering		embedded system;simulation;engineering;computer security	AI	6.158823215224442	-89.32142932992518	135555
22a939c4c433d23d38d694de7d5cffe6c722a096	memswear - incorporating mems technology into smart shirt for geriatric healthcare	fall detection system;mems;wireless communication;geriatric healthcare;vital signs monitoring	Current vital signs monitoring system used by hospitals are bulky and usually for measurement of one or two vital signs specifically. These devices are inconvenient for home use and too technical to layman. With a comprehensive vital sings monitor in the form of a garment, MEMS Wear, the hassle of hanging cables and bulky equipment can be eliminated. MEMSWear will benefit the elderly by improving the overall standard of the healthcare system and reducing the costs of in-house monitoring and hospitalization. This paper presents the vision and methodology of the MEMSWear project. In addition, the development of a novel human fall detection system using MEMS technology is discussed. Finally, some preliminary results of the vital signs monitoring are presented.	android wear;e-textiles;microelectromechanical systems;sensor	Kwong-Luck Tan;Francis Eng Hock Tay	2003	International Journal of Computational Engineering Science	10.1142/S1465876303001101	nanotechnology;microelectromechanical systems;biological engineering;forensic engineering;wireless	Robotics	8.438359422450127	-88.91699451477876	135655
6c0b64ef8dd71937989ecb27b42a558f2662aa9c	using neuromuscular electrical stimulation for pseudo-haptic feedback	biofeedback;3d user interface;electric stimulation;neuroelectrical stimulation;user testing;3d user interfaces;haptic feedback	This paper focuses at the usage of neuromuscular electrical stimulation (NMES) for achieving pseudo-haptic feedback. By stimulating the motor nerves, muscular contractions can be triggered that can be matched to a haptic event. Reflecting an initial user test, we will explain how this process can be realized, by investigating the physiological processes involved. Relating the triggered feedback to general haptics, its potential in future interfaces will be identified and laid out in a development roadmap.	functional electrical stimulation;haptic technology	Ernst Kruijff;Dieter Schmalstieg;Steffi Beckhaus	2006		10.1145/1180495.1180558	simulation;computer science;artificial intelligence;haptic technology	Robotics	9.148158410328808	-92.09317201463291	136071
43463366a3cd9ed6d0406755aa29a081d9e76eb0	identifying and visualizing relevant deviations in longitudinal sensor patterns for care professionals	cognition;computerised monitoring;data visualisation;health care;medical information systems;personnel;sensors;adl monitoring;care professionals;cognitive decline;deviation identification;deviation visualization;disease symptom recognition;elderly activities of daily living;longitudinal sensor patterns;medical specialisms;medical specialists;monthly bar graph;nurses;physical decline;sensor technology	Sensor technology is increasingly applied for the purpose of monitoring elderly's Activities of Daily Living (ADL), a set of activities used by physicians to benchmark physical and cognitive decline. Visualizing deviations in ADL can help medical specialists and nurses to recognize disease symptoms at an early stage. This paper presents possible visualizations for identifying such deviations. These visualizations have been iteratively explored and developed with three different medical specialists to better understand which deviations are relevant according to the different medical specialisms and explore how these deviations should be best presented. The study results suggest that the participants found a monthly bar graph in which activities are represented by colours as the most suitable from the ones presented. Although the visualizations of every ADL was found to be more or less relevant by the different medical specialists, the preference for focusing on specific ADL's varied from specialist to specialist.	benchmark (computing);color;sensor web	Saskia Robben;Mario Boot;Marije Kanis;Ben J. A. Kröse	2013	2013 7th International Conference on Pervasive Computing Technologies for Healthcare and Workshops		psychology;simulation;cognition;medicine;computer science;sensor;physical therapy;nursing;data mining;biological engineering;data visualization;health care;statistics	HCI	8.067752854341	-86.94813535606775	136379
015ce854fdd3587005c04df0efa4df500bf4c39f	a wearable assistant for gait training for parkinson's disease with freezing of gait in out-of-the-lab environments	gait impairment;freezing of gait;wearable assistant;system s acceptance;user centered;on body sensors;out of the lab studies	People with Parkinson’s disease (PD) suffer from declining mobility capabilities, which cause a prevalent risk of falling. Commonly, short periods of motor blocks occur during walking, known as freezing of gait (FoG). To slow the progressive decline of motor abilities, people with PD usually undertake stationary motor-training exercises in the clinics or supervised by physiotherapists. We present a wearable system for the support of people with PD and FoG. The system is designed for independent use. It enables motor training and gait assistance at home and other unsupervised environments. The system consists of three components. First, FoG episodes are detected in real time using wearable inertial sensors and a smartphone as the processing unit. Second, a feedback mechanism triggers a rhythmic auditory signal to the user to alleviate freeze episodes in an assistive mode. Third, the smartphone-based application features support for training exercises. Moreover, the system allows unobtrusive and long-term monitoring of the user’s clinical condition by transmitting sensing data and statistics to a telemedicine service.  We investigate the at-home acceptance of the wearable system in a study with nine PD subjects. Participants deployed and used the system on their own, without any clinical support, at their homes during three protocol sessions in 1 week. Users’ feedback suggests an overall positive attitude toward adopting and using the system in their daily life, indicating that the system supports them in improving their gait. Further, in a data-driven analysis with sensing data from five participants, we study whether there is an observable effect on the gait during use of the system. In three out of five subjects, we observed a decrease in FoG duration distributions over the protocol days during gait-training exercises. Moreover, sensing data-driven analysis shows a decrease in FoG duration and FoG number in four out of five participants when they use the system as a gait-assistive tool during normal daily life activities at home.	feedback;observable;sensor;smartphone;stationary process;transmitter;unobtrusive javascript;wearable computer	Sinziana Mazilu;Ulf Blanke;Moran Dorfman;Eran Gazit;Anat Mirelman;Jeffrey M. Hausdorff;Gerhard Tröster	2015	TiiS	10.1145/2701431	simulation	HCI	9.308462731685829	-90.81787463947059	137204
30253acfb41a61c346d04dd62728f87ed59aa191	use of personality profile in predicting academic emotion based on brainwaves signals and mouse behavior	mouse;personality affective computing academic emotion brainwaves mouse;mathematics computing;academic emotion;personality;behavioural sciences computing;intelligent tutoring systems;pattern classification;mouse controllers computers;electroencephalography;c4 5 personality profile academic emotion prediction brainwaves signals mouse behavior eeg data math tutoring system mouse click activities emotiv eeg device extroversion inquisitiveness accommodation emotional stability orderliness classifiers knn;pattern classification behavioural sciences computing electroencephalography intelligent tutoring systems mathematics computing mouse controllers computers;brainwaves;systems engineering and theory knowledge engineering;affective computing	"""The academic emotion of learners is difficult to predict using EEG data, unless these brainwaves data undergo some extensive pre-processing operations. However, we show some evidence that it can be predicted somewhat more accurately for certain personality profiles. Twenty-five (25) college students were asked to use a math tutoring system while their brainwaves signals and mouse-click activities were being captured. Brainwaves signals were recorded using an Emotiv EEG device while the mouse behavior was based on the number of clicks, the duration of each click and the distance traveled by the mouse. The personality of the learners was evaluated based on the Big-Five Personality Test of Extroversion, Inquisitiveness, Accommodation, Emotional Stability and Orderliness. For each group based on personality type, the frequency of each self-reported academic emotion of confidence, excitement, frustration and interest was recorded and two classifiers, kNN and C4.5, were trained for each personality type. The accuracy rate of the classifiers built using only data instances from those assessed to be """"low"""" in """"orderliness"""", as well as only from those assessed to be """"high"""" in """"orderliness"""", performed significantly better compared to the classifiers that were trained for all personality types combined. The experiments also revealed that for almost all the 5 personality types, the percentage of instances where the learners reported themselves to be confident or frustrated differed significantly depending on whether they were assessed as """"low"""" or """"high"""" in the five personality types."""	c4.5 algorithm;electroencephalography;emotiv systems;experiment;neural oscillation;preprocessor	Judith J. Azcarraga;John Francis Ibanez;Ianne Robert Lim;Nestor Lumanas	2011	2011 Third International Conference on Knowledge and Systems Engineering	10.1109/KSE.2011.45	electroencephalography;artificial intelligence;machine learning;affective computing;personality	SE	10.02922652468721	-92.1801917715102	137388
54e988bc0764073a5db2955705d4bfa8365b7fa9	emotion recognition in the wild challenge (emotiw) challenge and workshop summary	emotion recognition in the wild	The Emotion Recognition In The Wild Challenge and Workshop (EmotiW) 2013 Grand Challenge consists of an audio-video based emotion classification challenge, which mimics real-world conditions. In total, 27 teams participated in the challenge. The database in the 2013 challenge is the Acted Facial Expression in the Wild (AFEW), which has been collected from movies showing close-to-real-world conditions.	emotion recognition	Abhinav Dhall;Roland Goecke;Jyoti Joshi;Michael Wagner;Tamás D. Gedeon	2013		10.1145/2522848.2531749	computer science;artificial intelligence	AI	-3.696801774693418	-84.46786266767805	137446
50e04ba8c0a9ccc315948724c65c8445553683f1	an expert system for generation of anti-g control schedule for jet fighter pilots	decision support;aviation medicine;knowledge based system;g acceleration;jet fighter;adverse effect;pressure breathing;scheduling;expert knowledge;anthropometric data;article;loss of consciousness;physiologic data;expert system	The high maneuverability of modern jet fighters often subjects the pilots to high  G   z   acceleration. One of the adverse effects of  G   z   acceleration is the  G -induced loss of consciousness. The current protection scheme includes a pressure mask that supplies the pilots with nominal positive pressure breathing and a nominal pressurized  G -suit. This paper presents a novel approach based on a combination of expert knowledge, pilots' anthropometric and physiologic data to generate control schedules of the  G -suit and mask pressures of jet fighter pilots.	expert system	John T. W. Yeow;V. Askari;Ziren Lu;Alex Kapps;W. Fraser;Andrew A. Goldenberg	2002	Expert Syst. Appl.	10.1016/S0957-4174(01)00059-8	simulation;adverse effect;computer science;artificial intelligence;aviation medicine;scheduling;expert system	Robotics	5.003213725360224	-80.43430506278911	138296
7caed2923acb93b77cc1a7356930d9600f972335	wearable systems for monitoring mobility-related activities in chronic disease: a systematic review	chronic disease;rehabilitation;walking;healthcare;mobility;locomotion;randomized controlled trials as topic;movement analysis;motor activity;humans;monitoring physiologic;biosensors;feasibility studies	The use of wearable motion sensing technology offers important advantages over conventional methods for obtaining measures of physical activity and/or physical functioning in individuals with chronic diseases. This review aims to identify the actual state of applying wearable systems for monitoring mobility-related activity in individuals with chronic disease conditions. In this review we focus on technologies and applications, feasibility and adherence aspects, and clinical relevance of wearable motion sensing technology. PubMed (Medline since 1990), PEdro, and reference lists of all relevant articles were searched. Two authors independently reviewed randomised trials systematically. The quality of selected articles was scored and study results were summarised and discussed. 163 abstracts were considered. After application of inclusion criteria and full text reading, 25 articles were taken into account in a full text review. Twelve of these papers evaluated walking with pedometers, seven used uniaxial accelerometers to assess physical activity, six used multiaxial accelerometers, and two papers used a combination approach of a pedometer and a multiaxial accelerometer for obtaining overall activity and energy expenditure measures. Seven studies mentioned feasibility and/or adherence aspects. The number of studies that use movement sensors for monitoring of activity patterns in chronic disease (postural transitions, time spent in certain positions or activities) is nonexistent on the RCT level of study design. Although feasible methods for monitoring human mobility are available, evidence-based clinical applications of these methods in individuals with chronic diseases are in need of further development.	abstract summary;body part;body position;chronic disease;energy metabolism;exercise;game controller;medline;paper;pedometer;poor posture;pubmed;real life;reference implementation;relevance;score;signal-to-noise ratio;systematic review;unsupervised learning;wearable computer;accelerometers;sensor (device)	Lara Allet;Ruud H. Knols;Kei Shirato;Eling D. de Bruin	2010		10.3390/s101009026	feasibility study;computer science;nanotechnology;biological engineering;mobile computing;biosensor	HCI	9.223194837618315	-84.5697597687837	138461
79c1df02510d3e571efe736d29e9487f8a274b2b	a cyber-physical system based framework for motor rehabilitation after stroke	motor rehabilitation;data processing;cyber physical systems;wireless sensor network;functional recovery;cyber physical system;information fusion;networked systems;wireless sensor networks	Cyber-physical system (CPS) is conveyed as a networked systems which can interact with people in a higher level through more modalities with integration of computation, communication and control. This paper presents a novel framework, based on CPS concept, for a networked interactive home based intelligent motor rehabilitation system to facilitate functional recovery post-stroke. A hierarchical architecture is proposed in this framework. Patients use proper rehabilitation appliances to conduct continuous, repetitive rehabilitation trainings while wireless sensor networks (WSN) collect data related to the patients' functional activities. Higher level devices do data processing and exchange information with networked therapists and other patients on latest available therapies, valuable experts' experiences, and experience generated in the therapy process. Within this framework, it is expected that important information and resources can be utilized in the rehabilitation stages more efficiently for an individual subject. The design, implementation and future work about this CPS-based framework are discussed in this paper.	computation;cyber-physical system;experience	Xuan Ma;Xikai Tu;Jian Huang;Jiping He	2011		10.1145/2185216.2185294	embedded system;simulation;engineering;communication	Mobile	6.857666289930548	-90.03539324029938	138827
29c6d4cf165f5d9ca4f85e45700f5fd445ca9cb6	home telehealth by internet of things (iot)	sensors;telehealth environment algorithm home based telehealth human computer interaction technology sensing technology imaging technology communication technology patient monitoring patient treatment patient diagnosis lifestyle quality medical sensing technologies medical sensing device medical communication device medical analytics device real time monitoring internet enabled patient physiological conditions internet of things network iot network system synchronisation health care personal nods ns2 simulator;telemedicine health care internet internet of things patient diagnosis patient monitoring patient treatment sensors;wireless communication;computer architecture;data analysis;medical services real time systems sensors computer architecture signal processing algorithms data analysis wireless communication;medical services;cloud telehealth telemedicine technology iot;signal processing algorithms;real time systems	Home based Telehealth is a combination of communications, imaging, sensing and human computer interaction technologies targeted at diagnosis, treatment and monitoring patients without disturbing the quality of lifestyle. This paper proposes development of a low cost medical sensing, communication and analytics device that is real-time monitoring internet enabled patients physiological conditions. Internet of Things (IoT) network will provide active and real-time engagement of patient, hospitals, caretaker and doctors. Massaging and synchronising the system has been the based focus in this paper, where it applies the suggested algorithm to predict the minimum time period that separates two consecutive bursts of messages and measures the minimum queue sizes for the health care personals nods, to manage the traffic and avoid the dropping of messages. NS2 simulator was employed to simulate the Telehealth environment algorithm.	algorithm;data modeling;human computer;human–computer interaction;internet of things;real-time locating system;real-time transcription;simulation	Salah S. Al-Majeed;Intisar Al-Mejibli;Jalal Karam	2015	2015 IEEE 28th Canadian Conference on Electrical and Computer Engineering (CCECE)	10.1109/CCECE.2015.7129344	simulation;computer science;sensor;multimedia;data analysis;computer security;wireless;computer network	Robotics	7.513953568148048	-88.4015250763298	139311
421eaebda2d4ac6140cd5edcfa20851fda9435bb	supervised and unsupervised transfer learning for activity recognition from simple in-home sensors	transfer learning;device free activity recognition;home sensor dataset	In this paper, we propose an approach to improve the accuracy of home activity estimation using device-free sensors in the home. This is achieved by transferring existing training data to a new household considering the differences between households. We assumed two scenarios in which we only have training data from other households with labels and we also have training labels for our own household, and proposed the method to compose supervised transfer between labeled data and unsupervised transfer between labeled unlabeled data for each scenario. To evaluate in realistic settings, we developed the system which consists of an application for use on tablet terminals, which continuously collect light and any optional sensor data, and a Web-based server system that stores the sensor data, estimates activities, provides visualization on users’ Web browsers, and enables users to edit the activity labels. Using the system, we gathered subjects from open called households during a period of approximately four months, and obtained approximately 11,745 activity inputs, approximately 7.14GB of sensor data, and power consumption data of 237,280 hours from 35 households. As a result of evaluation, our method outperformed naive methods, both in the first and second scenarios.	activity recognition;activity tracker;gigabyte;sensor;server (computing);tablet computer;unsupervised learning	Sozo Inoue;Xincheng Pan	2016		10.1145/2994374.2994400	semi-supervised learning;unsupervised learning;transfer of learning;computer science;machine learning;pattern recognition;data mining	HCI	3.194508901897868	-85.65088398984504	139362
710d9ae65a0db5728c1941a405d31c064380ab42	can sequence mining improve your morning mood? toward a precise non-invasive smart clock	sleep cycles;data mining;sequence mining;natural alarm clock;wearable sensor	The aim of this paper is to present our preliminary approach and work in progress in the design of sequence mining techniques for a new smart clock alarm. This clock alarm will ring the user at the most physiological opportune moment in a predefined time frame. We rely on a wearable biosensor collecting various signals (ECG, movement, temperature) and on algorithms that dynamically mine into the sequences of heterogeneous data to identify sleep cycles. The system will be less intrusive and more accurate than others. This paper presents the underlying domains, the method and the experiments we are implementing.	algorithm;experiment;sequential pattern mining;wearable computer	Zakaria M. Djedou;Fabrice Muhlenbach;Pierre Maret;Guillaume Lopez	2014		10.1145/2637064.2637099	embedded system;real-time computing;telecommunications;engineering	AI	5.363747210680557	-86.52817170968375	139654
ceda9f3986b6c2ff243eb605cd12f45309701b83	detecting exceptional actions using wearable sensors' data for developing life-log database of visually impaired people	life log;visually impaired people;time series analysis;human action recognition	This paper proposes our approach to develop a system supporting visually impaired people with life-log. Visually impaired people face daily problems because of lack of information about road conditions. To find the uncomfortable and dangerous points, detecting their exceptional actions, such as tumbling down and getting lost, is effective. In the experiments, we used two units of iPod touch as wearable devices, and measured visually impaired people’s walking as acceleration patterns. As a result, several useful actions appear in acceleration patterns.	experiment;hidden markov model;sensor;speech corpus;support vector machine;wearable computer;wearable technology;ipod	Yusuke Iwasawa;Hidetaka Suzuki;Ikuko Eguchi Yairi	2013			computer vision;simulation;computer science;time series;multimedia;lifelog	HCI	6.281426888187589	-85.08206667140571	139683
dad58628834572e085c815b2601171187602e3b4	multimodal prediction of affective dimensions via fusing multiple regression techniques.		This paper presents a multimodal approach to predict affective dimensions, that makes full use of features from audio, video, Electrodermal Activity (EDA) and Electrocardiogram (ECG) using three regression techniques such as support vector regression (SVR), partial least squares regression (PLS), and a deep bidirectional long short-term memory recurrent neural network (DBLSTM-RNN) regression. Each of the three regression techniques performs multimodal affective dimension prediction followed by a fusion of different models on features of four modalities using a support vector regression. A support vector regression is also applied for a final fusion of the three regression systems. Experiments show that our proposed approach obtains promising results on the AVEC 2015 benchmark dataset for prediction of multimodal affective dimensions. For the development set, the concordance correlation coefficient (CCC) achieves results of 0.856 for arousal and 0.720 for valence, which increases 3.88 % and 4.66 % of the top-performer of AVEC 2015 in arousal and valence, respectively.	artificial neural network;benchmark (computing);coefficient;concordance (publishing);experiment;long short-term memory;multimodal interaction;partial least squares regression;random neural network;recurrent neural network;support vector machine	D.-Y. Huang;Wan Ding;Mingyu Xu;Huaiping Ming;Minghui Dong;Xinguo Yu;Haizhou Li	2017		10.21437/Interspeech.2017-1088	pattern recognition;affect (psychology);linear regression;computer science;machine learning;artificial intelligence	AI	-3.4031946114801075	-86.61449739787543	139987
2ab039bc13c2e37da68eae60da127177e71284b4	a vr environment for assessing dental surgical expertise	surgical skills training and assessment;intelligent tutoring system;haptic device;data collection;dental student;virtual reality environment	Traditional methods of dental surgical skills training and assessment are being challenged by complications such as unavailability of expert supervision and the subjective manner of surgical skills assessment. This paper presents a dental surgical skills training system that provides a virtual reality environment with a haptic device for dental students to practice tooth preparation procedures. The system monitors important features of the procedures, objectively assesses the quality of the performed procedure and provides objective feedback on the user’s performance for each stage in the procedure. We evaluated the accuracy of the skill assessment with data collected from novice dental students as well as experienced dentists. The experimental results show high accuracy in classifying users into novice and expert. The evaluation of the system’s generated feedback also indicated a high acceptance rate.	haptic technology;unavailability;virtual reality	Phattanapon Rhienmora;Peter Haddawy;Siriwan Suebnukarn;Matthew N. Dailey	2009		10.3233/978-1-60750-028-5-746	simulation;computer science;artificial intelligence;multimedia;haptic technology;statistics;data collection	HCI	3.2198387829119843	-80.44061940257996	140253
6b80e5364ae9852c6bdaad1ad7323295bcc6ee2a	combined convolutional neural network for high frequency restoration in acoustic impedance images		Domain-specific methods for deblurring particular sorts of objects have gained increasing attention due to the ineffectiveness of generic methods. We present a simple and effective convolutional neural network that deblurs synthetic acoustic impedance images. The architecture of our model is divided into two basic structures: convolutional layers and regression unit. The convolutional layers highlight edges and contours related to interfaces between rock layers whereas the regression layer performs a non-linear estimation of acoustic impedance values. We consider a training dataset composed by wedge shaped images, positioned at four different angles. In our work, we adopt a strong supervised learning that exploit the dataset of artificially blurred and high resolution images. We also present an analysis comparing the frequency band-width among the latent, blurry, and deblurred images. We additionally address the requirement of deep learning for the huge amount of training examples by inserting rectified linear units (ReLU) and keeping the network architecture simple. Experimental results on synthetic test images demonstrate the efficacy of the proposed method.	acoustic coupler;acoustic cryptanalysis;artificial neural network;characteristic impedance;circuit restoration;convolutional neural network;deblurring;deep learning;domain-specific language;frequency band;image resolution;network architecture;network model;neural networks;nominal impedance;nonlinear system;rectifier (neural networks);supervised learning;synthetic intelligence;turing test	Jason Billinghurst;Mauro Roisenberg;Jon Argandona;Leandro Passos de Figueiredo;Bruno Rodrigues	2018	2018 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2018.8489672	supervised learning;convolutional neural network;architecture;deep learning;acoustic impedance;pattern recognition;deblurring;rectifier (neural networks);image resolution;artificial intelligence;computer science	ML	-2.2646909267854336	-90.20416513166518	141153
2dc0743704e14191459b40fae6925cd19e6f0c8b	design of the multi-channel electroencephalography-based brain-computer interface with novel dry sensors	cognitive neuroscience applications multichannel eeg based bci design electroencephalography brain computer interface dry sensors wireless bci system wearable bci system multichannel eeg based bci system wireless eeg data acquisition device dry spring loaded sensors metal conductors size adjustable soft cap;blinking brain computer interfaces electroencephalography equipment design humans signal processing computer assisted wireless technology;brain computer interface bci;electroencephalography eeg;size adjustable soft cap;electroencephalography sensor systems wireless sensor networks wireless communication probes scalp;data acquisition device;dry sensor;proceedings paper;size adjustable soft cap electroencephalography eeg brain computer interface bci dry sensor data acquisition device;wireless sensor networks biomedical communication biomedical electrodes brain computer interfaces electroencephalography;biomedical electrodes;brain computer interfaces;electroencephalography;wireless sensor networks;biomedical communication	The traditional brain-computer interface (BCI) system measures the electroencephalography (EEG) signals by the wet sensors with the conductive gel and skin preparation processes. To overcome the limitations of traditional BCI system with conventional wet sensors, a wireless and wearable multi-channel EEG-based BCI system is proposed in this study, including the wireless EEG data acquisition device, dry spring-loaded sensors, a size-adjustable soft cap. The dry spring-loaded sensors are made of metal conductors, which can measure the EEG signals without skin preparation and conductive gel. In addition, the proposed system provides a size-adjustable soft cap that can be used to fit user's head properly. Indeed, the results are shown that the proposed system can properly and effectively measure the EEG signals with the developed cap and sensors, even under movement. In words, the developed wireless and wearable BCI system is able to be used in cognitive neuroscience applications.	brain neoplasms;brain-computer interfaces;brain–computer interface;cognition disorders;computational neuroscience;data acquisition;electroencephalography;interface device component;neuroscience discipline;numerous;soft capsule dosage form;wearable computer;sensor (device)	Shang-Lin Wu;Lun-De Liao;Chang-Hong Liou;Shi-An Chen;Li-Wei Ko;Bo-Wei Chen;Po-Sheng Wang;Sheng-Fu Chen;Chin-Teng Lin	2012	2012 Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/EMBC.2012.6346298	brain–computer interface;electronic engineering;neuroscience;wireless sensor network;electroencephalography;engineering;biological engineering;communication	Robotics	9.33617190304925	-90.22868888904353	141294
7329f38855a67b994fe133319a68bf72f8538268	design and implementation of an e-health system for depression detection	support vector machines;accuracy;sensitivity;servers;medical services;feature extraction;mobile handsets;mobile devices e health system design e health system implementation cost effective e health system automatic depression detection client server architecture;photoplethysmography biomedical communication client server systems health care medical disorders medical signal detection mobile computing;servers feature extraction accuracy support vector machines medical services mobile handsets sensitivity	We present the design and implementation of a cost-effective e-Health system for automatic depression detection. The system is based on a client-server architecture, where clients are popular mobile devices. For practical deployment, various factors that affect the accuracy and speed of depression detection are discussed and evaluated with extensive experiments.	client–server model;experiment;mobile device;server (computing);software deployment	Truong Cong Thang;Huyen T. T. Tran;Vo D. Trong;Duc V. Nguyen;Hung T. Le;Tuan D. Pham	2015	2015 IEEE International Conference on Consumer Electronics (ICCE)	10.1109/ICCE.2015.7066324	embedded system;support vector machine;real-time computing;sensitivity;feature extraction;computer science;engineering;operating system;accuracy and precision;computer security;server	Robotics	5.001370474161662	-88.61345623167801	141793
65fcc524b6c1eb379511226f5519ccd582ef290a	implantable ultralow pulmonary pressure monitoring system for fetal surgery	animals;prostheses and implants;fetal monitoring;biomedical measurements;sheep;ultralow pressure sensing data logger fetal surgery;lungs;transducers pressure;lung;fetus;surgery biomedical equipment biomedical transducers biomedical ultrasonics lung patient monitoring pressure measurement pressure sensors;biomedical transducers;pressure measurement;physiology;biomedical engineering;ultralow pressure sensing;surgery;patient monitoring;pressure sensors;implantable biomedical devices;frequency 256 hz implantable ultralow pulmonary pressure monitoring system fetal surgery fetal pulmonary tree gestation in vivo fetal lamb recording pressure transducer time 21 day;fetal surgery;titanium;biomedical ultrasonics;lungs physiology fetus implantable biomedical devices titanium biomedical measurements;biomedical equipment;data logger	Congenital pulmonary hypoplasia is a devastating condition affecting fetal and newborn pulmonary physiology, resulting in great morbidity and mortality. The fetal lung develops in a fluid-filled environment. In this paper, we describe a novel, implantable pressure sensing and recording device which we use to study the pressures present in the fetal pulmonary tree throughout gestation. The system achieves 0.18 cm H 2O resolution and can record for 21 days continuously at 256 Hz. Sample tracings of in vivo fetal lamb recordings are shown.	analog;analogue electronics;arabic numeral 0;ct pulmonary angiogram;circuit design;data logger;fill;hertz (hz);implants;infant, newborn;lung diseases;morbidity - disease rate;physiological sexual disorders;power management;pulmonary subvalvular stenosis;pulmonary hypoplasia;secure digital;uterus;video-in video-out;physiological aspects	Mozziyar Etemadi;J. Alex Heller;Samuel C. Schecter;Eveline H. Shue;Doug Miniati;Shuvo Roy	2012	IEEE Transactions on Information Technology in Biomedicine	10.1109/TITB.2012.2207399	titanium;medicine;pathology;pressure measurement;pressure sensor;data logger;remote patient monitoring;physiology;quantum mechanics;surgery;fetus	Visualization	9.732841510198266	-88.16243529169826	142028
a227d49654679fe17b95d575b222e5eec7312f84	recognizing human activities from multi-modal sensors	human interaction;multi modal sensors;legged locomotion;humans multimodal sensors wireless sensor networks magnetic sensors social network services iris patient monitoring testing global positioning system accelerometers;behavioural sciences computing;physical activity;wireless sensor networks behavioural sciences computing social networking online;data mining;acceleration;human behavior;wireless sensor network;social network;accuracy;social networking online;human interactions;writing;humans;iris;human activities monitoring;human activities detection;human activity;human behaviors;wireless sensor networks;wireless sensor network multi modal sensors human activities monitoring human activities detection human behaviors human interactions social network	This paper describes a method of detecting and monitoring human activities which are extremely useful for understanding human behaviors and recognizing human interactions in a social network. By taking advantage of current wireless sensor network technologies, physical activities can be recognized through classifying multi-modal sensors data. The result shows that high recognition accuracy on a dataset of 6 daily activities of one carrier can be achieved by using suitable classifiers.	interaction;modal logic;sensor;social network;statistical classification	Shu Chen;Yan Huang	2009	2009 IEEE International Conference on Intelligence and Security Informatics	10.1109/ISI.2009.5137308	simulation;wireless sensor network;computer science;artificial intelligence;human behavior	Robotics	5.67433341799346	-85.80286982663127	142137
7d1b2a95dfed9f151ce0be8323dfd4bb3167474b	a more acceptable endoluminal implantation for remotely monitoring ingestible sensors anchored to the stomach wall	hydrogen ion concentration;animals;capsule endoscopes;zigbee bluetooth body sensor networks electrocardiography endoscopes health care medical signal processing near field communication patient monitoring phantoms surgery telemedicine;portable device endoluminal implantation remotely monitoring ingestible sensors stomach wall implant devices healthcare telemedicine systems physiological parameters surgery battery wearable devices vital parameters round the clock monitoring daily lives endoluminal approach therapeutic capsule endoscopy nfc zigbee bluetooth inductive extracorporeal power feeding phantom swine gastric mucosa electrocardiogram ph wireless communication ic internet;gastric fundus;monitoring sensors batteries wireless communication stomach biomedical monitoring implants;gastric mucosa;phantoms imaging;capsule endoscopy;humans;smartphone;wireless technology;monitoring physiologic;swine	Several types of implant devices have been proposed and introduced into healthcare and telemedicine systems for monitoring physiological parameters, sometimes for very long periods of time. To our disappointment, most of the devices are implanted invasively and by surgery. We often have to surgically remove such devices after they have finished their mission or before the battery becomes worn out. Wearable devices have the possibility to become new modalities for monitoring vital parameters less-invasively. However, for round-the-clock monitoring of data from sensors over long periods of time, it would be better to put them inside the body to avoid causing inconvenience to patients in their daily lives. This study tested a less invasive endoluminal approach and innovative tools (developed during our research into therapeutic capsule endoscopy) for remotely anchoring ingestible sensors to the stomach wall. Preliminary investigations are also described about wireless communication (NFC, ZigBee, and Bluetooth) for low power consumption and inductive extracorporeal power feeding wirelessly to the circuits in a phantom lined with swine gastric mucosa. Electrocardiogram and pH were monitored and those parameters were successfully transmitted by wireless communication ICs to the Internet via a portable device.	bluetooth;electrocardiography;gastric mucosa;imaging phantom;implants;integrated circuit;internet;ion implantation;mobile device;near field communication;operative surgical procedures;patients;phantoms, imaging;telemedicine;disease transmission;sensor (device)	Hidetoshi Ohta;Shintaro Izumi;Masahiko Yoshimoto	2015	2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2015.7319293	medicine;pathology;biological engineering;surgery	EDA	9.215998010917348	-88.32392717631683	142488
3cbfe817ea4cec40fe704eb6bcc4a127e629d478	ehdc: an energy harvesting modeling and profiling platform for body sensor networks		Energy harvesting is a promising solution to the limited battery lifetimes of body sensor nodes. Self-powered sensor systems capable of quasi-perpetual operation enable the possibility of truly continuous monitoring of patients beyond the clinic. However, the discontinuous and dynamic characteristics of harvesting in real-world scenarios—and their implications for the design and operation of self-powered systems—are not yet well understood. This paper presents a mobile energy harvesting and data collection (EHDC) platform designed to provide a deeper understanding of energy harvesting dynamics. The EHDC platform monitors and records the instantaneous usable power generated by body-worn harvesters, while also collecting human activity and environmental data to provide a comprehensive real-world evaluation of two energy harvesting modalities common to body sensor networks: solar and thermoelectric. The platform was initially validated with benchtop tests and later with real-world deployments on two subjects. 7-h-long multimodal energy harvesting profiles were generated, and the environmental and behavioral data were used to expand upon previously developed Kalman filter based mathematical models for energy harvesting prediction. Results confirm the validity of the EHDC platform and harvesting models, establishing the potential for longer term monitoring of energy harvesting characteristics; thus, informing the design and operation of self-powered body sensor networks.	data collection;human activities;kalman filter;mathematical model;mathematics;multimodal interaction;patients;photon correlation spectroscopy;power (psychology);reporting	Dawei Fan;Luis Lopez Ruiz;Jiaqi Gong;John C. Lach	2018	IEEE Journal of Biomedical and Health Informatics	10.1109/JBHI.2017.2733549	artificial intelligence;computer vision;data collection;wireless sensor network;data modeling;control engineering;profiling (computer programming);energy harvesting;computer science;continuous monitoring	Mobile	7.607017033822913	-86.28411980220979	142826
e1e239cd825040da30db158d8e3e1edffac154aa	earable tempo: a novel, hands-free input device that uses the movement of the tongue measured with a wearable ear sensor	ear canal;hand-free controller;non-invasive;optical measurement;tongue	"""In this study, an earphone-type interface named """"earable TEMPO"""" was developed for hands-free operation, wherein the user can control the device by simply pushing the tongue against the roof of the mouth for about one second. This interface can be used to start and stop the music from a portable audio player. The earable TEMPO uses an earphone-type sensor equipped with a light emitting diode (LED) and a phototransistor to optically measure shape variations that occur in the external auditory meatus when the tongue is pressed against the roof of the mouth. To evaluate the operation of the earable TEMPO, experiments were performed on five subjects (men and women aged 22-58) while resting, chewing gum (representing mastication), and walking. The average accuracy was 100% while resting and chewing and 99% while walking. The precision was 100% under all conditions. The average recall value of the five subjects was 92%, 90%, and 48% while resting, masticating, and walking, respectively. All subjects were reliably able to perform the action of pressing the tongue against the roof of the mouth. The measured shape variations in the ear canal were highly reproducible, indicating that this method is suitable for various applications such as controlling a portable audio player."""	acoustic cryptanalysis;audio media;chewing gum (food);experiment;external auditory canal structure;foot;futures studies;gingiva;headphones;image noise;input device;interface device component;laplink cable;light emitting diode device component;name;neurofibromatosis 2;ninety nine;noise-induced hearing loss;oral cavity;papaverine;password authentication protocol;phototransistor device component;rest;right ear structure;sensor;shape context;transmitter;vibration - physical agent;wearable computer;disease transmission;earphones	Kazuhiro Taniguchi;Hisashi Kondo;Mami Kurosawa;Atsushi Nishikawa	2018		10.3390/s18030733	ear canal;input device;computer hardware;electronic engineering;meatus;engineering;wearable computer;tongue;mastication	HCI	7.161263047405351	-93.78523727378958	143171
5e33b0f9e3263891373467679c2ed2dab4c20748	analysis of regional group health persona based on image recognition		Peopleu0027s health status is related to disease control, personal health, etc., so more attention has been paid on it. Stepping into era of Internet of Things (IoT), because of the emerging of all kinds of intelligent devices and prevalence of social media, peopleu0027s health data can be accessed more easily. In this paper, a framework for analyzing regional group health persona is designed. And a prototype system is implemented. In addition, we did an experiment and collected vital individual health information from the participantsu0027 smart device and environment data from their social networks. Specifically, we use deep learning method to recognize and label their food image to measure their dietary status, and then classify them into groups by clustering their individual data with these dietary data. And analysis on their social environment is also given.		Lei Wang;Ling Li;Hongming Cai;Lida Xu;Boyi Xu;Lihong Jiang	2018	2018 Sixth International Conference on Enterprise Systems (ES)	10.1109/ES.2018.00033	world wide web;persona;social environment;smart device;deep learning;cluster analysis;social media;social network;disease;computer science;artificial intelligence	HCI	5.032300423466882	-87.26598191526863	143539
151cda58150cda0523d2a1eeb50a7945d1f6cdf8	ionizing radiation measurement solution in a hospital environment	dosimetry solution;evaluation;gamma radiation;healthcare workers safety;verification	Ionizing radiation is one of the main risks affecting healthcare workers and patients worldwide. Special attention has to be paid to medical staff in the vicinity of radiological equipment or patients undergoing radioisotope procedures. To measure radiation values, traditional area meters are strategically placed in hospitals and personal dosimeters are worn by workers. However, important drawbacks inherent to these systems in terms of cost, detection precision, real time data processing, flexibility, and so on, have been detected and carefully detailed. To overcome these inconveniences, a low cost, open-source, portable radiation measurement system is proposed. The goal is to deploy devices integrating a commercial Geiger-Muller (GM) detector to capture radiation doses in real time and to wirelessly dispatch them to a remote database where the radiation values are stored. Medical staff will be able to check the accumulated doses first hand, as well as other statistics related to radiation by means of a smartphone application. Finally, the device is certified by an accredited calibration center, to later validate the entire system in a hospital environment.	calibration;detectors;dosimeter, device;dynamic dispatch;geiger-mueller counters;hospitals;ionizing radiation;mobile app;muller automaton;open-source software;patients;radioisotopes;remote database access;smartphone;system of measurement	Antonio-Javier García-Sánchez;Enrique Angel Garcia Angosto;Pedro Antonio Moreno Riquelme;Alfredo Serna Berna;David Ramos-Amores	2018		10.3390/s18020510	electronic engineering;calibration;real-time computing;engineering;certification;radiation;ionizing radiation;dosimeter	DB	7.320396956160876	-89.03545627328751	143669
a956ce78284d654215f6404c26052b7ffb83aa6b	enssat: wearable technology application for the deaf and hard of hearing		A large number of people around the globe experience hearing difficulties of varying degrees. Therefore, recent research has focused on developing applications and systems to aid the Deaf and Hard of Hearing (DHH). Wearable devices have significant potential in assistive applications owing to their low cost and lightweight. Wearable devices help the DHH perform their daily activities easily without requiring assistance from others. We present Enssat, a bilingual (Arabic/English) smartphone-based hearing aid application that uses Google Glass to assist DHH individuals. The application performs important tasks: real-time transcription, real-time translation, and alert management. A user study was performed to evaluate the application. In this study, 10 DHH users evaluated the processes of transcription, translation, and alerting and 15 non-DHH users evaluated the translation function of the system. All of them evaluated the usability and effectiveness of the Enssat application. The results demonstrated the ease of use and utility of the application.	assistive technology;glass;real-time transcription;smartphone;transcription (software);usability testing;wearable technology	Shurug Al-Khalifa;Muna Al-Razgan	2018	Multimedia Tools and Applications	10.1007/s11042-018-5860-5	computer vision;arabic;artificial intelligence;wearable technology;human–computer interaction;computer science;hearing aid;activities of daily living;wearable computer;usability	HCI	-0.9574807387370877	-83.86879819527549	143825
dab14573d56b407642a98f43cef209828a29a2ef	popular music representation: chorus detection & emotion recognition	rhythm;verse;chorus;emotion;popular music;adaboost;mfccs	This paper proposes a popular music representation strategy based on the song’s emotion. First, a piece of popular music is decomposed into chorus and verse segments through the proposed chorus detection algorithm. Three descriptive features: intensity, frequency band and rhythm regularity are extracted from the structured segments for emotion detection. A hierarchical Adaboost classifier is employed to recognize the emotion of a piece of popular music. The general emotion of the music is classified according to Thayer’s model into four emotions: happy, angry, depressed and relaxed. Experiments conducted on a 350-popular-music database show the average recall and precision of our proposed chorus detection are approximately 95 % and 84 %, respectively; and the average precision rate of emotion detection is 92 %. Additional tests are performed on songs with cover versions in different lyrics and languages, and the resultant precision rate is 90 %. The proposes approaches have been tested and proven by the professional online music company, KKBOX Inc. and show promising performance for effectively and efficiently identifying the emotions of a variety of popular music.	adaboost;algorithm;chorusos;cluster analysis;color image;color space;emotion recognition;experiment;frequency band;information retrieval;list of online music databases;online music store;precision and recall;resultant;statistical classification;verse protocol	Chia-Hung Yeh;Wen-Yu Tseng;Chia-Yen Chen;Yu-Dun Lin;Yi-Ren Tsai;Hsuan-I Bi;Yu-Ching Lin;Ho-Yi Lin	2013	Multimedia Tools and Applications	10.1007/s11042-013-1687-2	adaboost;popular music;speech recognition;emotion;computer science;artificial intelligence;rhythm;machine learning	AI	-4.13660008597771	-85.20538309640429	143932
824aa4e786344a260822a1dbe687c42c673ae21e	fall risk assessment and prevention using wearables	fall risk awareness protocol;wearable sensors;fall prevention tool;fall prevention;daily living;fall risk assessment	Each year about 1/3 of elderly aged 65 or older experience a fall. Many of these falls may have been avoided if fall risk assessment and prevention tools where available in a daily living situation. We identify what kind of information is relevant to do fall risk assessment using wearable sensors in a daily living environment by investigating current research. Based on our findings we propose a fall risk awareness protocol as a fall prevention tool.	risk assessment;wearable computer	Asbjørn Danielsen;Bernt A. Bremdal;Hans Olofsen	2015		10.1007/978-3-319-26410-3_18	simulation;computer security	HCI	6.8427325112511435	-87.65712464640806	144151
d9794724fd792f22a499f27f7b995574f4159398	accessing tele-services using a hybrid bci approach		Brain Computer Interface (BCI) technology has achieved limited success outside of laboratory conditions. This technology is hindered by practical considerations of set up, lack of robustness and low Information Transfer Rate (ITR). There are two interfaces in a BCI system: the brain’s interface with the computer and the computer-environment interface, which provides access to applications for the user. Three user services were implemented: control of the smart home, entertainment and communication. These may be accessed through a graphical user interface controlled by a BCI. The paper contrasts the performance of an SSVEP based system with a hybrid BCI comprising eye gaze and muscle response (measured at the scalp). The hybrid developed utilizes the EPOC for recording electrical potential and an EyeTribe gaze tracker; these can be combined to provide more robust interaction with applications. Average ITR for the eye tracker and hybrid approaches (190-200 bpm) are higher than for our SSVEP approach (approx. 15 bpm), for the same applications. The poor performance of our SSVEP system was due to the temporal duration of the stimulation (7s) and partly because not all participants could achieve an accuracy of greater than 50%. The current challenge is the replacement of the scalp recorded muscle component with a reliable user modifiable EEG measure.	approximation;assistive technology;brain–computer interface;control point (mathematics);epoc (operating system);electroencephalography;emotiv systems;eye tracking;frequency band;graphical user interface;home automation;mesa;openvibe;programming paradigm;refresh rate;software deployment;television;transcranial magnetic stimulation;usability	Chris P. Brennan;Paul J. McCullagh;Gaye Lightbody;Leo Galway;Diana Feuser;José Luis González;Suzanne Martin	2015		10.1007/978-3-319-19258-1_10	simulation;computer science;artificial intelligence	HCI	9.700845751959458	-90.83173762196562	144528
0168d80a4ef3e840a0d36b12df1fcac85ceffe94	wearable computing support for objective assessment of function in older adults		Naturalistic Action Test (NAT) is a diagnostic tool that involves a participant completing a common, everyday task under the observation of a trained clinician. The clinician can identify and quantify the severity of an individuals cognitive impairments based on the his or her actions while carrying out the task. Individuals with cognitive impairments have been shown to commit errors such as performing an incorrect sequence of steps when completing a task at greater rates than individuals without cognitive impairments. This paper describes our initial experiences in developing a wearable computing-based system to support NATs. The system’s objective is to eventually help the clinician streamline the analysis of NATs by processing of the smartwatch collected sensor values to try and identify episodes that resemble errors.	wearable computer	Theodore Hauser;James Klein;Philip Coulomb;Sarah M. Lehman;Takehiko Yamaguchi;Tania Giovannetti;Chiu C. Tan	2017		10.1007/978-3-319-58524-6_19	wearable computer;cognitive psychology;psychology;smartwatch;commit;cognition	HCI	9.377013536111425	-91.35428581455102	144982
b0f510d234fe6d68f15e3162dcec54a74787ec4f	impress: a machine learning approach to soundscape affect classification for a music performance environment		Soundscape composition in improvisation and performance contexts involves many processes that can become overwhelming for a performer, impacting on the quality of the composition. One important task is evaluating the mood of a composition for evoking accurate associations and memories of a soundscape. We present a new system called Impress that uses supervised machine learning for the acquisition and realtime feedback of soundscape a↵ect. We used an audio features vector of audio descriptors to represent an audio signal for fitting multiple regression models to predict soundscape a↵ect. A model of soundscape a↵ect is created by users entering evaluations of audio environments using a mobile device. The same device then provides feedback to the user of the predicted mood of other audio environments. The evaluation of the Impress system suggests the tool is e↵ective in predicting soundscape a↵ect.	feedback;machine learning;mobile device;supervised learning	Miles Thorogood;Philippe Pasquier	2013			soundscape;human–computer interaction;multimedia;computer science	HCI	-0.44303765442202503	-84.7779417511108	145125
3129e0fc0c3797a423ea2a36052129b2f3b33e75	detecting pedestrian flocks by fusion of multi-modal sensors in mobile phones	mobile sensing;crowd behavior sensing;signal strength based methods;pattern recognition	Previous work on the recognition of human movement patterns has mainly focused on movements of individuals. This paper addresses the joint identification of the indoor movement of multiple persons forming a cohesive whole - specifically a flock - with clustering approaches operating on features derived from multiple sensor modalities of modern smartphones. Automatic detection of flocks has several important applications, including evacuation management and socially aware computing. The novelty of this paper is, firstly, to use data fusion techniques to combine several sensor modalities (WiFi, accelerometer and compass) to improve recognition accuracy over previous unimodal approaches. Secondly, improve the recognition of flocks using hierarchical clustering. We use a dataset comprising 16 subjects forming one to four flocks walking in a building on single and multiple floors. With the best settings, we achieve a F-score accuracy of up to 87 percent an improvement of up to twelve percent points over existing approaches.	cluster analysis;f1 score;flock;flocking (behavior);hierarchical clustering;mobile phone;modal logic;sensor;smartphone	Mikkel Baun Kjærgaard;Martin Wirz;Daniel Roggen;Gerhard Tröster	2012		10.1145/2370216.2370256	computer vision;simulation;computer science	HCI	5.489877123148338	-85.08535120600847	145301
c37b74b222fa803524a8e3d1cd437adf1518e895	a wireless eeg monitor system based on bsn node	wsn device;eeg monitor design;zigbee technology;wireless sensor network;tinyos operating system;monitoring system;wireless eeg monitor system;operating system;portable wireless electroencephalogram monitor;tinyos;bsn node;eeg;eeg signal;electroencephalogram;body sensor network	Due to the recent active research activities in the area of Wireless Sensor Networks (WSN), the development and realization of a portable wireless electroencephalogram (EEG) monitor has become feasible. In this paper, we propose an EEG monitor design based on a commercially available WSN device, Body Sensor Networks node (BSN node). The device utilizes Zigbee technology and operates on TinyOS operating system. The EEG signal from subjects is detected and radioed to a PC for monitoring. This study validates our approach and suggests the feasibility of future enhancements.	electroencephalography;electromyography;operating system;personal computer;sampling (signal processing);tinyos;transmitter	Gang Li;Haifeng Chen;Jungtae Lee	2010	2011 24th International Symposium on Computer-Based Medical Systems (CBMS)	10.1145/1882992.1883107	embedded system;real-time computing;engineering;key distribution in wireless sensor networks;computer network	Embedded	9.351109114036575	-89.27132292990122	145561
900dddb0ae83971bc04b8fcc764d62b9c2373bd3	motion recognition in wearable sensor system using an ensemble artificial neuro-molecular system		This paper proposes an ensemble artificial neuro-molecular system for motion recognition for a wearable sensor system with 3-axis accelerometers. Human motions can be distinguished through classification algorithms for the wearable sensor system of two 3-axis accelerometers attached to both forearms. Raw data from the accelerometers are pre-processed and forwarded to the classification algorithm designed using the proposed ensemble artificial neuro-molecular(ANM) system. The ANM system is a kind of bio-inspired algorithm like neural network. It is composed of many artificial neurons that are linked together according to a specific network architecture. For comparison purpose, other algorithms such as artificial neuro-molecular system, artificial neural networks support vector machine, k-nearest neighbor algorithm and k-means clustering, are tested. In experiments, eight kinds of motions are randomly selected in a daily life to test the performance of the proposed system and to compare its performance with that of existing algorithms.	artificial neural network;artificial neuron;british informatics olympiad;cluster analysis;experiment;k-means clustering;k-nearest neighbors algorithm;network architecture;randomness;sensor;statistical classification;support vector machine;wearable computer	Si-Jung Ryu;Jong-Hwan Kim	2011		10.1007/978-3-642-23147-6_10	wearable computer;cluster analysis;accelerometer;support vector machine;artificial neural network;network architecture;artificial intelligence;statistical classification;both forearms;engineering	AI	5.186472816588043	-85.16266323422505	145581
e304e516fd4e1499b616f120795600eb688fa93e	people and vehicles in danger - a fire and flood detection system in social media		This paper presents a novel warning system framework for detecting people and vehicles in danger. The system was tested in several images compiled from Flickr and other social media sources and is highly suggested to get integrated in future warning surveillance and safety systems for preventing or solving crisis events. The proposed framework recruits State-of-the-Art deep learning technologies so as to solve a series of image processing and machine learning challenges and provides a near real-time localization solution for detecting and scoring severity safety levels of people and vehicles in flood and fire images.	compiler;decision support system;deep learning;flickr;image processing;machine learning;real-time computing;real-time locating system;sensor;social media	Panagiotis Giannakeris;Konstantinos Avgerinakis;Anastasios Karakostas;Stefanos Vrochidis;Yiannis Kompatsiaris	2018	2018 IEEE 13th Image, Video, and Multidimensional Signal Processing Workshop (IVMSP)	10.1109/IVMSPW.2018.8448732	system safety;image processing;flood myth;image segmentation;deep learning;social media;scoring severity;machine learning;artificial intelligence;warning system;computer science	Mobile	3.416009588530348	-87.0558612162048	145674
19ce34e1f5436ef17be134166e0d138d686a20e3	comparative analysis of artificial hydrocarbon networks and data-driven approaches for human activity recognition	tecnologias	In recent years computing and sensing technologies advances contribute to develop effective human activity recognition systems. In context-aware and ambient assistive living applications, classification of body postures and movements, aids in the development of health systems that improve the quality of life of the disabled and the elderly. In this paper we describe a comparative analysis of data-driven activity recognition techniques against a novel supervised learning technique called artificial hydrocarbon networks (AHN). We prove that artificial hydrocarbon networks are suitable for efficient body postures and movements classification, providing a comparison between its performance and other well-known supervised learning methods.	activity recognition	Hiram Ponce-Espinosa;María de Lourdes Martínez-Villaseñor;Luis Miralles Pechuán	2015		10.1007/978-3-319-26401-1_15	computer science;artificial intelligence	HCI	5.20185992826866	-85.50396864269331	145916
f5832e83cf140bc7723ae1a1b4779704b315e22f	smart collaborative system using the sensors of mobile devices for monitoring disabled and elderly people	disabled people;sensors;smart network;elderly people smart network colaborative algorithm sensors disabled people;colaborative algorithm;reduced size devices smart collaborative system sensors mobile devices disabled and elderly people monitoring statistics data quality of life;handicapped aids;mobile radio;elderly people;senior citizens mobile handsets intelligent sensors sensor systems monitoring collaboration;intelligent sensors;mobile radio handicapped aids intelligent sensors	According to statistics data, the population of many countries is aging. Moreover, there is also a small sector of the population that is affected by disabilities. Researchers should develop systems to improve their quality of life. In recent years, the development of smartphones and reduced size devices, but with high processing capacity, has increased dramatically. We can take profit of the sensors and applications embedded in the smartphones in order to monitor disabled and elderly people. In this paper, we describe a smart collaborative system based on the sensors placed in the mobile devices, which allow us to monitor the status of a person based on what is happening in the group people. The network algorithm and the smart system protocol is described and simulated in order to show the performance of our proposal.	algorithm;embedded system;mobile device;sensor;smart system;smartphone	Sandra Sendra;Emilio Granell;Jaime Lloret Mauri;Joel Jos&#x00E9; P. C. Rodrigues	2012	2012 IEEE International Conference on Communications (ICC)	10.1109/ICC.2012.6364935	embedded system;simulation;sensor;computer security;intelligent sensor	Mobile	6.072564774209207	-87.99779104449208	146802
f8ef485bb6569f64c177902a4ad11c00768b4de6	microwave breast cancer detection via cost-sensitive ensemble classifiers: phantom and patient investigation	biomedical monitoring;clinical trial;ensemble selection;sensor fusion;microwave breast cancer detection	Microwave breast screening has been proposed as a complementary modality to the current standard of X-ray mammography. In this work, we design three ensemble classification structures that fuse information from multiple sensors to detect abnormalities in the breast. A principled Neyman-Pearson approach is developed to allow control of the trade-off between false positive rate and the false negative rate. We evaluate performance using data derived from measurements of heterogeneous breast phantoms. We also use data collected in a clinical trial that monitored 12 healthy patients monthly over an eight-month period. In order to assess the efficacy of the proposed algorithms we model scans of breasts with malignant lesions by artificially adding simulated tumour responses to existing scans of healthy volunteers. Tumour responses are constructed based on measured properties of breast tissues and real breast measurements, thus the simulation model takes into account the heterogeneity of the breast tissue. The algorithms we present take advantage of breast scans from other patients or tissue-mimicking breast phantoms to learn about breast content and what constitutes a “tumour-free” and “tumour-bearing” set of measurements. We demonstrate that the ensemble selection-based algorithm, which constructs an ensemble of the most informative classifiers, significantly outperforms other detection techniques for the clinical trial data set.	algorithm;information;microwave;phantom reference;sensor;simulation;x-ray (amazon kindle)	Yunpeng Li;Emily Porter;Adam Santorelli;Milica Popovic;Mark Coates	2017	Biomed. Signal Proc. and Control	10.1016/j.bspc.2016.09.003	computer vision;medicine;pathology;computer science;clinical trial;sensor fusion;surgery	AI	8.588641583329498	-80.29554638355663	146815
2607341452607c94416f7d06b1609a6249196b2e	qualitative risk of falling assessment based on gait abnormalities	geriatrics;mechanoception;neural nets;visual perturbations;computational modeling visualization analytical models data models biological system modeling footwear sensors;footwear;medical disorders;assisted living;statistical analysis;gait analysis;statistical analysis assisted living footwear gait analysis geriatrics mechanoception medical disorders neural nets;visual perturbations risk of falling gait analysis;clinical gait analysis fall risk assessment gait abnormality classification walking frail seniors balance statistical model artificial neural network noninvasive augmented shoes mobile technology visual disturbances user on site assistance;risk of falling	Walking in an unfamiliar environment may include some risks of falling. For frail seniors, these risks can be significantly increased according to their ability to maintain balance. Among several factors, the user's balance can be affected by several risks including the characteristics of the user's gait. To evaluate this issue, this paper presents three methods. The first uses a statistical model while the two others exploit an Artificial Neural Network (ANN). The latter two can be differentiated by the use of constraints applied onto the raw data. Centered on non-invasive augmented shoes, our proposed system uses mobile technology to provide an on-site assistance to users, replacing the bulky equipment usually needed for clinical gait analysis. The experimental framework is based on visual disturbances to induce variation in the parameters of the user's gait. Preliminary results obtained from this framework suggest that our models enable a risk level classification.	algorithm;artificial neural network;experiment;gait analysis;human factors and ergonomics;real-time clock;sensor;shoes;statistical classification;statistical model	David Gagnon;Bob-Antoine Jerry Ménélas;Martin J.-D. Otis	2013	2013 IEEE International Conference on Systems, Man, and Cybernetics	10.1109/SMC.2013.677	simulation;gait analysis;machine learning;geriatrics;artificial neural network;statistics	Robotics	8.462301811235044	-85.88944468324621	147063
5eefce250990578590de1c0b36833b25cc67d9d7	myconverse: recognising and visualising personal conversations using smartphones	speaker identification;real time smartphone sensing	MyConverse is a personal conversation recogniser and visualiser for smartphones. MyConverse uses the smartphone's microphone to continuously recognise the user's conversations during daily life. While it recognises pre-trained speakers, unknown speakers are detected and subsequently trained for future identification. Based on the recognition, MyConverse visualises user's social interactions on the smartphone. An extensive system parameter evaluation has been done based on a freely available dataset. Additionally, MyConverse was tested in different real-life environments and in a full-day evaluation study. The speaker recognition system reached an identification accuracy of 75% for 24 speakers in meeting room conditions. In other daily life situations MyConverse reached accuracies from 60% to 84%.	interaction;microphone;real life;smartphone;speaker recognition	Mirco Rossi;Oliver Amft;Sebastian Feese;Christian Käslin;Gerhard Tröster	2013		10.1145/2494091.2497281	speech recognition;computer science;multimedia	HCI	-0.06181674068236394	-84.85842081845556	147093
c2a5650266bd970898d544a617bc303ef50a9cad	classifying drivers' cognitive load using eeg signals	case-based reasoning (cbr);cognitive load;electroencephalogram (eeg)	A growing traffic safety issue is the effect of cognitive loading activities on traffic safety and driving performance. To monitor drivers' mental state, understanding cognitive load is important since while driving, performing cognitively loading secondary tasks, for example talking on the phone, can affect the performance in the primary task, i.e. driving. Electroencephalography (EEG) is one of the reliable measures of cognitive load that can detect the changes in instantaneous load and effect of cognitively loading secondary task. In this driving simulator study, 1-back task is carried out while the driver performs three different simulated driving scenarios. This paper presents an EEG based approach to classify a drivers' level of cognitive load using Case-Based Reasoning (CBR). The results show that for each individual scenario as well as using data combined from the different scenarios, CBR based system achieved approximately over 70% of classification accuracy.	case-based reasoning;classification;driving simulator;electroencephalography phase synchronization;mental state;reasoning - publishing subsection;simulators;speech	Shaibal Barua;Mobyen Uddin Ahmed;Shahina Begum	2017	Studies in health technology and informatics	10.3233/978-1-61499-761-0-99	cognitive psychology;data mining;electroencephalography;social psychology;cognition;medicine;cognitive load;mental state	HCI	9.69011209606547	-91.87023650494599	147487
a76b81314880610d41288c675f668e473d5eea56	neural network-based user-independent physical activity recognition for mobile devices		Activity recognition using sensors of mobile devices is a topic of interest of many research efforts. It has been established that user-specific training gives good accuracy in accelerometer-based activity recognition. In this paper we test a different approach: offline user-independent activity recognition based on pretrained neural networks with Dropout. Apart from satisfactory recognition accuracy that we prove in our tests, we foresee possible advantages in removing the need for users to provide labeled data and also in the security of the system. These advantages can be the reason for applying this approach in practice, not only in mobile phones but also in other embedded devices.	activity recognition;artificial neural network;mobile device	Bojan Kolosnjaji;Claudia Eckert	2015		10.1007/978-3-319-24834-9_44	machine learning;labeled data;deep learning;computer science;activity recognition;artificial neural network;mobile device;accelerometer;artificial intelligence	HCI	4.025656592083189	-84.24951737896762	147666
98d55d440cb2291732f298265dbe0bab56093f0f	study on monitoring methods of nitrogen nutrition in cotton leaves based on android platform			android	Yanqun Wang;Guoliang Li;Zhenqi Fan;Luz Adriana Pichardo-Macías	2018	JCP			Mobile	0.0036443138241222996	-80.69798451818394	147671
49362ee669a85048f20b1b2e14188af4316e82dd	emotional affect estimation using video and eeg data in deep neural networks		We present a multimodel system for independent affect recognition using deep neural networks. Using the DEAP data set, features are extracted from EEG and other physiological signals, as well as videos of participant faces. We introduce both a novel way of extracting video features using sum-product networks, and a unique method of creating extra training examples from data that would have otherwise been lost in downsampling. Deep neural networks are used for estimating the emotional dimensions of arousal, valence, and dominance, along with favourability and familiarity. This work lays the foundation for future work in estimating emotional responses from physiological measurements.	deep learning;electroencephalography;neural networks	Arvid Frydenlund;Frank Rudzicz	2015		10.1007/978-3-319-18356-5_24	computer vision;machine learning	HCI	-3.1560358939349675	-86.48981218077952	148370
d1d16390b4cb8be51383ea20bc3c03ce6b7ee170	complex activity recognition using polyphonic sound event detection		In this paper, we propose a method for recognizing the complex activity using audio sensors and the machine learning techniques. To do so, we will look for the patterns of combined monophonic sounds to recognize complex activity. At this time, we use only audio sensors and the machine learning techniques like Deep Neural Network (DNN) and Support Vector Machine (SVM) to recognize complex activities. And, we develop the novel framework to support overall procedures. Through the implementation of this framework, the user can support to increase quality of life of elders’.	activity recognition	Jaewoong Kang;Jooyeong Kim;Kunyoung Kim;Mye M. Sohn	2018		10.1007/978-3-319-93554-6_66	computer network;computer science;support vector machine;artificial neural network;machine learning;activity recognition;artificial intelligence;polyphony	Vision	4.573785541506058	-86.05708248482465	148599
51d6815f0f658ad3bb03b61f38a8212c863027cf	sensitivity analysis of wearable textiles for ecg sensing		Rapid advances in material science and mobile technology bring the new generation of wearable electrocardiogram (ECG) sensing systems. In particular, sensing textiles have been widely used in cardiac monitoring due to its high flexibility and reusability. Unlike conventional gel electrodes, sensing textiles are non-adhesive, which provide comfortable and stress-free experience. However, the quality of textile-based ECG sensing is more sensitive to external factors (such as sensor placement and contact pressure). There is an urgent need to investigate how the quality of ECG sensing is influenced by these factors and improve the design of wearable textiles. In the literature, little has been reported on the sensitivity analysis of textile-based ECG sensing. In this study, we experimentally investigate the sensitivity of textile-based ECG sensing to four factors, i.e., contact pressure, textile placement, user's activity, and muscle activity. Specifically, ECG signals are collected using sensing textiles under these four factors. Then, heart rate and ECG morphology are characterized from the obtained ECG signals and compared with true signals (obtained from standard gel electrodes). Experimental results show that the quality of textile-based ECG sensing is not sensitive to the contact pressure as long as it is >6N. When the patient is walking, nevertheless, the sensing quality can be strongly influenced by the textile placement. Furthermore, textiles placed on areas with fewer muscles achieve better signal quality. This study shows strong potentials of textile materials for the design of wearable ECG systems to empower smart and connected cardiac health.	experiment;mathematical morphology;wearable computer;wearable technology	Wenxin Tong;Chen Kan;Hui Yang	2018	2018 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI)	10.1109/BHI.2018.8333393	embedded system;wearable computer;cardiac monitoring;computer science	HCI	9.15849454360039	-85.43296028276859	148902
25a66fa9b12d0a10a34cccb6e7f94d033665ee59	effect of wearable sensor dynamics on physical activity estimates: a comparison between sci vs. healthy individuals	biomedical monitoring;temperature sensors;monitoring;statistics;temperature measurement;sociology	Accuracy of physical activity estimates predicted by activity monitoring technologies may be affected by device location, analysis algorithms, type of technology (i.e. wearable/stickable) and population demographics (disability) being studied. Consequently, the main purpose of this investigation was to study such sensor dynamics (i.e. effect of device location, type and population demographics on energy expenditure estimates) of two commercial activity monitors. It was hypothesized that device location, population studied (disability), choice of proprietary algorithm and type of technology used will significantly impact the accuracy of the predicted physical activity metrics. 10 healthy controls and eight individuals with spinal cord injury (SCI) performed structured activities in a laboratory environment. All participants wore, (i) three ActiGraph-G3TX's one each on their wrist, waist & ankle, (ii) a stickable activity monitor (Metria-IH1) on their upper-arm and (3) a Cosmed-K4B2 metabolic unit, while performing sedentary (lying), low intensity (walk 50 steps at self-speed) and vigorous activity (a 6 minute walk test). To validate the hypothesis, the energy expenditures (EE) predicted by ActiGraph-GT3X and Metria-IH1 were benchmarked with estimated EE per Cosmed K4B2 metabolic unit. To verify the step count accuracy predicted by ActiGraph-GT3X's and Metria-IH1, the manually calculated step count during the low intensity activity were compared to estimates from both devices. Results suggest that Metria-IH1 out-performed ActiGraph-GT3X in estimating EE during sedentary activity in both groups. The device location and population demographics, significantly affected the accuracy of predicted estimates. In conclusion, selecting activity monitor locations, analysis algorithm and choice of technology plays based on the movement threshold of population being studied can pave a better way for reliable healthcare decisions and data analytics in population with SCI.	activity tracker;demography;energy metabolism;estimated;exercise;how true feel vigorous right now;metabolic process, cellular;metria;spinal cord injuries;telling untruths;wearable computer;algorithm	Chandrasekaran Jayaraman;Chaithanya Krishna Mummidisetty;Arun Jayaraman	2016	2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2016.7591429	simulation;temperature measurement;engineering;physical therapy;physics;statistics	HCI	9.352618334611646	-85.64850122630529	149003
00ce881ca0e4c63689c7f7ffe450fdb3fd3f27ea	mots audio-visuels joints pour la détection de scènes violentes dans les vidéos		This paper presents an audio-visual data representation for violent scenes detection in Hollywood movies. Existing works in this field consider either the audio or the visual information; or their shallow fusion. None has yet explored their joint dependence for violent scenes detection. We propose a feature which provides strong multimodal audio and visual cues by first joining the audio and the visual features and then revealing statistically the joint multimodal patterns. Experimental validation was conducted in the context of the “Violent Scenes Detection” task of the MediaEval 2013 Multimedia benchmark. The obtained results show the potential of the proposed approach in comparison to methods using audio and visual feature separately and other fusion methods. MOTS-CLÉS : Indéxation sémantique, Analyse de contenu, Fusion audio-visuelle, Multimédia, MediaEval.	benchmark (computing);data (computing);hollywood;linear algebra;multimodal interaction;oracle fusion architecture	Nadia Derbas;Georges Quénot	2014		10.24348/sdnri.2014.CORIA-8	performance art;art	AI	-3.5120076999591547	-84.40444234059963	149079
92adaae798be98f6b1dc4a29cd18de9498b05bf0	a healthcare system for detection and analysis of daily activity based on wearable sensor and smartphone	databases;healthcare;senior citizens;activity detection;medical services senior citizens monitoring cameras servers wireless communication databases;information sharing;wireless communication;living support;servers;medical services;monitoring;smart phones assisted living data analysis geriatrics health care;wearable sensor elderly citizens independent living support healthcare services healthcare system daily activities finger worn device information sharing supporter smartphone action recognition activity attribute analysis information delivery living status detection person healthcare sharing;attributes analysis;information sharing healthcare living support activity detection attributes analysis;cameras	The growing number of elderly citizens living alone increases demands on healthcare and independent living support. An effective and convenient activity detection system plays an important role in healthcare services. In this research, a system of learning living status is provided through detecting daily activities using a finger-worn device and sharing information to supporter's smartphone. Three main issues are discussed in the research including action recognition, activity attributes analysis, and information delivery. Five actions and ten kinds of daily activities are defined and analyzed by the system. Experimental results show the effectiveness and convenience of the system in living status detection and sharing for person healthcare.	information theory;sensor;smartphone;wearable computer	Yinghui Zhou;Dido Vongsa;Yiming Zhou;Zixue Cheng;Lei Jing	2015	2015 IEEE 12th Intl Conf on Ubiquitous Intelligence and Computing and 2015 IEEE 12th Intl Conf on Autonomic and Trusted Computing and 2015 IEEE 15th Intl Conf on Scalable Computing and Communications and Its Associated Workshops (UIC-ATC-ScalCom)	10.1109/UIC-ATC-ScalCom-CBDCom-IoP.2015.203	computer science;operating system;multimedia;internet privacy;computer security;wireless;server	Mobile	5.576020254715751	-87.5446115448155	149270
ddede2c8e2ccf90f1f377bf0f86a249e10148cac	elderly-falling detection using distributed direction-sensitive pyroelectric infrared sensor arrays	distributed sensing;elderly health care;fall detection;hmms;pyroelectric infrared sensors;pyroelectric infrared sensors;fall detection;distributed sensing;elderly health care;hmms	This paper presents a new distributed direction-sensitive infrared sensing approach for fall detection in elderly healthcare applications. Pyroelectric infrared (PIR) sensors are employed in sensing human activities. For capturing the characteristics of human normal and abnormal activities, three modules of a direction-sensitive PIR sensor are organized using a distributed sensing structure. The advantage of using the distributed sensing paradigm is that the synergistic motion patterns of head, upper-limb and lower-limb can be efficiently encoded and thus the more discriminative features can be captured. This is the new consideration of using PIR sensors in building a full detection system. In addition, a two-layer hidden Markov model is developed for recognizing a fall event based on the multidimensional signals of the distributed infrared sensing system. Experimental studies are conducted to validate the proposed method.		Tong Liu;Xuemei Guo;Guoli Wang	2012	Multidim. Syst. Sign. Process.	10.1007/s11045-011-0161-4	embedded system	Vision	7.081608334802867	-86.7308341576348	149838
659e649dca825400749a317620b81076d5d8ce69	classification of developmental disorders from speech signals using submodular feature selection		We present our system for the Interspeech 2013 Computational Paralinguistics Autism Sub-challenge. Our contribution focuses on improving classification accuracy of developmental disorders by applying a novel feature selection technique to the rich set of acoustic-prosodic features provided for this purpose. Our feature selection approach is based on submodular function optimization. We demonstrate significant improvements over systems using the full feature set and over a standard feature selection approach. Our final system outperforms the official Challenge baseline system significantly on the development set for both classification tasks, and on the test set for the Typicality task. Finally, we analyze the subselected features and identify the most important ones.	acoustic cryptanalysis;baseline (configuration management);computation;feature selection;mathematical optimization;submodular set function;test set	Katrin Kirchhoff;Yuzong Liu;Jeff A. Bilmes	2013			submodular set function;machine learning;pattern recognition;data mining;feature	ML	-4.376166135703089	-88.14958120511857	150017
301faac3fc9d6dc137c71038f40c95e899b4fbe6	a development of design prototype of smart healthcare clothing for silver generation based on bio-medical sensor technology	futures market;respiratory disease;smart clothing for health care;real time monitoring;rfid tag;design prototype;research and development;vital signs;medical history;bio medical sensor;usability;health care	"""Recently, """"Smart Clothing"""" technology, along with a rapid change of lifestyle and customers' needs, has been studied and developed for various applications such as Entertainment, Business, and Health Care and Sports areas. Among the number of types in """"Smart Clothing"""" technologies, """"Smart Clothing"""" for health care is anticipated as one of the highly demanded products in future market.The demand of """"Smart Clothing"""" based on bio-medical sensor technology will increase due to the entry of an aging society where a high demand of development in both medical industry and medical welfare rises. This trend is related to the new condition of technological and social transition built through the rapid development of Ubiquitous environment. On the view of customers' demand, """"Smart Clothing"""" technology coincides with the macroflow of customers' general demand on clothing product. In domestic market, however, the research and development of """"Smart Clothing"""" based on a biomedical sensor technology are insufficient. In this research, with a consideration in clothing suitability and prevalence rate, a prototype of """"Smart Clothing"""" is firstly developed for diagnosing basic vital signs of cardiac disorder and respiratory disease. A prototype of smart healthcare clothing developed in this research, maintaining similar appearance to common clothing, is equipped with textile-based sensors and other devices which senses and transmits vital signs, while keeping comfortable fits of clothing. When a person having it on, sensed vital signals are transmitted to computer in hospital through wireless transaction for a real-time monitoring process. It is also designed to send back alarm command to the wearer's cellular phone when emergent condition is detected in his body. The RFID tag, equipped on the inside of """"Smart Clothing,"""" stores wearer's medical history and personal data, so that a rescuer can collect the data in emergency case and send them to hospital for faster and efficient treatment for the rescue. An evaluation on usability and comfort of the firstly derived prototype in this research were evaluated. Based on the result from evaluation on the two aspects, the design prototype of sensor-based smart healthcare clothing was revised."""		Hakyung Cho;Joohyeon Lee	2007		10.1007/978-3-540-73107-8_117	radio-frequency identification;simulation;usability;human–computer interaction;computer science;medical history;computer security;health care	EDA	7.656888731312638	-89.26201218310362	150034
8c22a5749f51e73acf913b8393b84728fc1752a8	snore sounds excitation localization by using scattering transform and deep neural networks		In this paper, we propose an algorithm for snoring sounds classification based on Deep Scattering Spectrum (SCAT), Gaussian Mixture Models (GMM) Supervectors and Deep Neural Networks (DNN). The task consists in the identification of the type of snoring among four target classes representing the snore sounds' excitation location, which can be highly useful for a successful medical treatment of the habitual snorer or patient afflicted with Obstructive Sleep Apnea. The SCAT is computed from excerpt the acoustic signals, then a GMM Supervector is calculated by adapting the GMM model of the acoustic space with the Maximum a Posteriori (MAP) algorithm and concatenating the mean values of the Gaussians. Resulting supervectors are used to feed the multiclass DNN classifier. The performance of the algorithm has been assessed on the Munich-Passau Snore Sound Corpus (MPSSC), composed of recordings of Drug-Induced Sleep Endoscopy (DISE) examinations. The results are expressed in terms of Unweighted Average Recall (UAR) and a remarkable improvement with respect to the state-of-the-art performance has been registered, achieving a score up to 67.14% and 67.71% respectively on the devel and test datasets.	acoustic cryptanalysis;algorithm;coefficient;concatenation;convolutional neural network;deep learning;experiment;google map maker;long short-term memory;memory-level parallelism;microsoft outlook for mac;mixture model;neural networks;support vector machine;test set	Fabio Vesperini;Andrea Galli;Leonardo Gabrielli;Emanuele Principi;Stefano Squartini	2018	2018 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2018.8489576	mixture model;sleep endoscopy;acoustic space;maximum a posteriori estimation;artificial intelligence;artificial neural network;pattern recognition;classifier (linguistics);scattering;computer science	ML	-3.5285463051564334	-87.7619612352	150074
2fae73f4310ed13f0bbe0b5ce1655c2d9f225d59	jlr heart: employing wearable technology in non-intrusive driver state monitoring. preliminary study	tl motor vehicles aeronautics astronautics;vehicles biomedical monitoring heart rate variability roads physiology;jlr heart heart rate variability complexity driving tasks heart activity tracking smartwatch heart activity metrics private vehicle consumers road safety medical equipment drivers wearable consumer electronic device nonintrusive driver state monitoring wearable technology;wearable computers behavioural sciences computing consumer electronics	This paper presents the results from a preliminary study where a wearable consumer electronic device was used to assess driver's state by capturing human physiological response in non-intrusive manner. Majority of state of the art studies have employed medical equipment drivers' state evaluation. Despite the potential gain in road safety this method of measuring physiology is unlikely to be accepted by private vehicle consumers due to its invasiveness, complexity, and high cost. This study was aiming to investigate possibility of employing a consumer grade wearable device to measure physiological parameters related to cognitive workload in real-time while driving i.e., drivers' heart rate. Furthermore, validity of captured heart activity metrics was analyzed to determine if wearable devices could be embedded into driving at its current technological state. The driving context was reproduced in desktop driving simulator, with 14 participants agreeing to take part in the study (μ = 28, σ = 8.5 years). Drivers were exposed to various road types, including pure Motorway, Rural, and Urban scenario modes. An accident was simulated in order to generate sudden cognitive arousal and capture participants' physiological response to the generated distress. It was found that a smartwatch is capable of reliable heart activity tracking in driving context. The results, supporting the relationship between cognitive workload level, generated by various complexity driving tasks, and Heart Rate Variability, were also presented.	activity recognition;desktop computer;distress (novel);driving simulator;embedded system;heart rate variability;real-time clock;simulation;smartwatch;wearable technology	Vadim Melnicuk;Stewart A. Birrell;Panos Konstantopoulos;Elizabeth Crundall;Paul A. Jennings	2016	2016 IEEE Intelligent Vehicles Symposium (IV)	10.1109/IVS.2016.7535364	embedded system;simulation;engineering;forensic engineering	HCI	7.7509599831149565	-85.43085663612268	150216
3036a2d3d570a435db56c1d622bbd7334bc9ac55	epidemic control based on fused body sensed and social network information	social network services;epidemic control;body sensor;body sensor networks;prediction algorithms;smart phones;algorithm;social network;estimation;medical information systems;model;diseases;predictive models;diseases social network services estimation predictive models educational institutions prediction algorithms smart phones;evaluation;critical network;evaluation epidemic control body sensor social network critical network model algorithm;epidemics;health condition epidemic control fused body sensed network information social network information social interaction information system epic epidemic condition prediction vital signs body sensor network;medical information systems body sensor networks epidemics health care;health care	Epidemic control becomes more difficult and challenging than ever due to increased population density and close social interactions. In this paper, we introduce a new information system named EPIC to predict epidemic conditions based on the continually collected vital signs of individuals from body sensor networks in a community and their social network. The core of EPIC is a critical network that models health conditions and social interactions of individuals. Facilitated by critical network, our prediction algorithms can cost-effectively determine quarantine strategies. The effectiveness of EPIC is evaluated through simulation.	algorithm;computation;information system;interaction;quarantine (computing);real-time transcription;simulation;social network	Zhaoyang Zhang;Ken C. K. Lee;Honggang Wang;Dong Xuan;Hua Fang	2012	2012 32nd International Conference on Distributed Computing Systems Workshops	10.1109/ICDCSW.2012.85	estimation;simulation;prediction;computer science;evaluation;data mining;predictive modelling;computer security;health care;statistics;social network	Robotics	3.12083212012055	-88.40864971775343	150259
a01d35ebadb93a27a0ae3a7f6ebfe49a1dfdf283	design, implementation and testing of mobile phone application for pleasant wake up	sound signal;microphones;multi threading;audio signal processing;network operating systems;sound signal mobile phone application testing body function deep sleep phase mild sleep stage microphone intelligent alarm application multithread real time application net compact framework platform c language filtration algorithm math library;testing;fft analysis wake up windows mobile user adaptive system;mobile phone;sleep;mild sleep stage;windows mobile;user adaptive system;c language;mobile phone application testing;deep sleep phase;detection algorithm;mobile communication;adaptive system;real time systems audio signal processing c language microphones mobile handsets multi threading network operating systems;mobile handsets;math library;multithread real time application;body function;intelligent alarm application;sleep mobile handsets testing mobile communication algorithm design and analysis microphones;fft analysis;real time application;mobile application;algorithm design and analysis;filtration algorithm;wake up;microphone;net compact framework platform;real time systems;mobile user	Human life is divided into day periods as a main periods which consist of a day and night phase. Most of humans need to sleep a eight hours in a minimum to have their body and all the body function ready in day phase of a day. The second very important thing (instead of 8 hour sleep) is a phase of sleep in which a human is wake up. Waking up of a human in deep sleep phase lead to a very “unhappy” morning and not so nice spend of day. We are trying to develop algorithms to detect mild sleep stages which are the most suitable to human wake up. Actually we use microphone input to record and process sound near the monitored user. All the knowledge is implemented to mobile phone (windows mobile based device) as an intelligent alarm application. Whole application is designed as multithread Real-Time application based on. NET Compact Framework platform in C# language. Filtration and detection algorithms used special Math library Math. NET to process a recorded sound signal. This paper consists of several chapters which describes design, implementation and testing phases of this mobile application development. Actual testing results shows that our developed application detect correctly more than 70 % of mild sleep stages of all tested persons.	algorithm;bonjour sleep proxy;day and night (cellular automaton);humans;microphone;microsoft windows;mobile app;mobile phone;real-time transcription;thread (computing);windows mobile	Ondrej Krejcar;Jakub Jirka	2011	2011 Sixth IEEE International Symposium on Electronic Design, Test and Application	10.1109/DELTA.2011.51	embedded system;algorithm design;real-time computing;simulation;multithreading;mobile telephony;telecommunications;audio signal processing;computer science;engineering;electrical engineering;adaptive system;operating system;audio signal;software testing;sleep	Mobile	6.334875797240453	-86.90011218716242	150671
d95c635bb3e96c39bb9a80181463fbeb789b3457	a collaborative brain-computer interface	quality of life;human performance;go nogo decision making brain computer interface bci collaborative computing electroencephalogram eeg human performance;brain computer interface;medical signal processing brain computer interfaces decision making electroencephalography group decision support systems medical expert systems;human behavior;medical expert systems;collaboration electroencephalography accuracy humans brain computer interfaces servers decision making;group decision support systems;brain activation;brain computer interfaces;electroencephalography;classification accuracy;communication channels;collaborative computing;electroencephalogram;go nogo decision prediction classification accuracy collaborative bci brain computer interface electroencephalogram eeg based bci motor disability patients bci performance eeg technical limits go nogo decision making experiment collaborative computing techniques;medical signal processing;human brain	Electroencephalogram (EEG) based brain-computer interfaces (BCI) have been studied for several decades since the 1970s. Current BCI research mainly aims to provide a new communication channel to patients with motor disabilities to improve their quality of life. The BCI technology can also benefit normal healthy users; however, little progress has been made in real-world practices due to low BCI performance caused by technical limits of EEG. To overcome this bottleneck, this study uses a collaborative BCI to improve overall performance through integrating information from multiple users. A dataset involving 15 subjects participating in a Go/NoGo decision-making experiment was used to evaluate the collaborative method. Using collaborative computing techniques, the classification accuracy for predicting a Go/NoGo decision was enhanced substantially from 75.8% to 91.4%, 97.6%, and 99.1% as the number of subjects increased from 1 to 5, 10, and 15, respectively. These results suggest that a collaborative BCI can effectively fuse brain activities of a group of people to improve human behavior.	brain–computer interface;channel (communications);collaborative software;electroencephalography;multi-user	Yijun Wang;Yu-Te Wang;Tzyy-Ping Jung;Xiaorong Gao;Shangkai Gao	2011	2011 4th International Conference on Biomedical Engineering and Informatics (BMEI)	10.1109/BMEI.2011.6098286	brain–computer interface;human–computer interaction;computer science;artificial intelligence;human behavior	HCI	9.75648076154808	-91.882666537027	151353
8d2c6b37197f3d3ad28820d566acf4f933103d27	supervised learning approach to remote heart rate estimation from facial videos	remote heart rate estimation rmse root mean squared error confidence metric off the shelf webcam ambient light human face bvp blood volume pulse signal discriminative statistical model hr remote video based heart rate estimation supervised machine learning approach facial videos;computational modeling;feature extraction;face;face videos feature extraction noise heart beat computational modeling;heart beat;noise;videos;video signal processing cardiology face recognition learning artificial intelligence mean square error methods patient monitoring telemedicine	A supervised machine learning approach to remote video-based heart rate (HR) estimation is proposed. We demonstrate the possibility of training a discriminative statistical model to estimate the Blood Volume Pulse signal (BVP) from the human face using ambient light and any off-the-shelf webcam. The proposed algorithm is 120 times faster than state of the art approach and returns a confidence metric to evaluate the HR estimates plausibility. The algorithm was evaluated against the state-of-the-art on 120 minutes of face videos, the largest video-based heart rate evaluation to date. The evaluation results showed a 53% decrease in the Root Mean Squared Error (RMSE) compared to state-of-the-art.	algorithm;channel (digital image);discriminative model;high-level programming language;machine learning;mean squared error;pixel;plausibility structure;pulse;statistical model;supervised learning;webcam	Ahmed Osman;Jay Turcot;Rana El Kaliouby	2015	2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG)	10.1109/FG.2015.7163150	computer vision;speech recognition;computer science;pattern recognition	Vision	2.4776067817181495	-87.8281740267599	151618
e081604eb310b57da4fb14f25d854241943a9b1c	syncope detection in toilet environments using wi-fi channel state information		Syncope and strokes in toilets can lead to severe injuries, and even pose life threats to patients. However, owing to privacy concerns, vision-based fall detection cannot be applied in such a scenario. In this poster, we propose ToiFall, a prototype for syncope detection in toilet environments. ToiFall collects Channel State Information (CSI) of commodity Wi-Fi devices. Different human movements form various textures on CSI images, and such textures can be used for feature extraction and classification. Experimental results show an accuracy of over 98% for fall detection with satisfying reliability.	channel state information;feature extraction;prototype;syncope (medicine)	Ziqi Wang;Z. G. Cynthia Gu;Junwei Yin;Zhe Chen;Yuedong Xu	2018		10.1145/3267305.3267650	multimedia;real-time computing;channel state information;feature extraction;toilet;computer science	Mobile	6.204466750935768	-83.40405655395492	151635
e26ab81b29f0ff4e0e5870c9ca1f8d256d14e0fc	transforming musical signals through a genre classifying convolutional neural network		Convolutional neural networks (CNNs) have been successfully applied on both discriminative and generative modeling for music-related tasks. For a particular task, the trained CNN contains information representing the decision making or the abstracting process. One can hope to manipulate existing music based on this “informed” network and create music with new features corresponding to the knowledge obtained by the network. In this paper, we propose a method to utilize the stored information from a CNN trained on musical genre classification task. The network was composed of three convolutional layers, and was trained to classify five-second song clips into five different genres. After training, randomly selected clips were modified by maximizing the sum of outputs from the network layers. In addition to the potential of such CNNs to produce interesting audio transformation, more information about the network and the original music could be obtained from the analysis of the generated features since these features indicate how the network “understands” the music.	artificial neural network;convolutional neural network;generative modelling language;randomness	S. Geng;Guowen Ren;M. Ogihara	2017	CoRR		machine learning;generative grammar;discriminative model;speech recognition;computer science;clips;convolutional neural network;artificial intelligence;pattern recognition	ML	-4.235602105685428	-87.09473753680004	152188
9c021ce576d5835f787f34eb1a54db68aa497841	swimming stroke kinematic analysis with bsn	kinematics biosensors wearable sensors accelerometers motion analysis body sensor networks acceleration monitoring eye protection feature extraction;body sensor networks;kinematic analysis;swimming biomechanics;biomechanics;swimming performance monitoring swimming stroke kinematic analysis bsn body sensor networks single unobtrusive head worn inertial sensor biomotion goggles nonintrusive practical deployment wearable sensors;sport monitoring;feature extraction;body sensor networks bsn;sport;sport biomechanics body sensor networks;swimming performance;sport monitoring swimming biomechanics body sensor networks bsn;inertial sensor;body sensor network	The recent maturity of body sensor networks has enabled a wide range of applications in sports, well-being and healthcare. In this paper, we hypothesise that a single unobtrusive head-worn inertial sensor can be used to infer certain biomotion details of specific swimming techniques. The sensor, weighing only seven grams is mounted on the swimmer's goggles, limiting the disturbance to a minimum. Features extracted from the recorded acceleration such as the pitch and roll angles allow to recognise the type of stroke, as well as basic biomotion indices. The system proposed represents a non-intrusive, practical deployment of wearable sensors for swimming performance monitoring.	capability maturity model;goggles;grams;pitch (music);roll-to-roll processing;sensor;software deployment;wearable computer	Julien Pansiot;Benny P. L. Lo;Guang-Zhong Yang	2010	2010 International Conference on Body Sensor Networks	10.1109/BSN.2010.11	embedded system;simulation;telecommunications;feature extraction;computer science;biomechanics;sport;machine learning	Robotics	8.610849876505835	-86.00512323905025	152653
b86af368949b9a09ff794901959ca64f4a1b9dca	generative, discriminative, and ensemble learning on multi-modal perceptual fusion toward news video story segmentation	entropy;statistical analysis;learning artificial intelligence;svm;posterior probability;boosting;statistics;support vector machine;support vector machines;broadcasting;database indexing;ensemble learning;indexing;image retrieval;discriminative model;machine learning;maximum entropy;iterative methods;probability	News video story segmentation is a critical task for automatic video indexing and summarization. Our prior work has demonstrated promising performance by using a generative model, called maximum entropy (ME), which models the posterior probability given the multi-modal perceptual features near the candidate points. In this paper, we investigate alternative statistical approaches based on discriminative models, i.e. support vector machine (SVM), and ensemble learning, i.e. boosting. In addition, we develop a novel approach, called BoostME, which uses the ME classifiers and the associated confidence scores in each boosting iteration. We evaluated these different methods using the TRECVID 2003 broadcast news data set. We found that SVM-based and ME-based techniques both outperformed the pure boosting techniques, with the SVM-based solutions achieving even slightly higher accuracy. Moreover, we summarize extensive analysis results of error sources over distinctive news story types to identify future research opportunities	discriminative model;ensemble learning;generative model;iteration;modal logic;principle of maximum entropy;support vector machine	Winston H. Hsu;Shih-Fu Chang	2004	2004 IEEE International Conference on Multimedia and Expo (ICME) (IEEE Cat. No.04TH8763)		support vector machine;image retrieval;computer science;machine learning;pattern recognition;data mining;ensemble learning;statistics	Vision	-3.9299503279932635	-86.1764988037325	152695
c8f6e295142b65f76c0015fd5b23890e02087959	context-sensitive bayesian classifiers and application to mouse pressure pattern classification	user identity modeling context sensitive bayesian classifiers gaussian mixture model context sensitive learning mouse pressure pattern classification bayesian learning algorithm online learning algorithm expectation propagation;user modelling;mouse pressure pattern classification;mice;bayesian classifier;support vector machines;gaussian processes;approximation algorithms;real time systems user interface management systems user modelling pattern classification mouse controllers computers bayes methods learning artificial intelligence gaussian processes;bayes methods;bayesian learning algorithm;bayesian methods;testing;online learning;gaussian mixture model;user identity modeling;context sensitive bayesian classifiers;bayesian learning;expectation propagation;pattern classification;error rate;support vector machine classification;mixture of gaussians;mouse controllers computers;online learning algorithm;user interface management systems;bayesian methods mice pattern classification support vector machines support vector machine classification context modeling testing switches approximation algorithms gaussian distribution;context sensitive learning;learning artificial intelligence;switches;context modeling;gaussian distribution;real time systems	In this paper, we propose a new context-sensitive Bayesian learning algorithm. By modeling the distributions of data locations by a mixture of Gaussians, the new algorithm can utilize different classifier complexities for different contexts/locations and, at the same time, keep the optimality of Bayesian solutions. This algorithm is also an online learning algorithm, efficient in training, and easy for incorporating new knowledge from data sets available in the future. We apply this algorithm to detecting computeruser mouse pressure patterns during episodes likely to be frustrating to the user. By modeling user identity as hidden context, this algorithm achieves on average 10.6% userindependent test error rate.	adaptive system;bayesian network;context-sensitive grammar;data model;hierarchical database model;k-nearest neighbors algorithm;locality of reference;machine learning;mixture model;naive bayes classifier;sensor;statistical classification	Yuan Qi;Rosalind W. Picard	2002		10.1109/ICPR.2002.1047973	wake-sleep algorithm;weighted majority algorithm;computer science;machine learning;pattern recognition;mixture model;data mining;fsa-red algorithm;approximation algorithm;statistics;population-based incremental learning	ML	1.0657076453489096	-91.50417540309853	152822
5300314cc1854e37bd3fcb996ff53c28fdde9cdb	development of diagnostic performance & visual processing in different types of radiological expertise		The aim of this research was to compare visual patterns while examining radiographs in groups of people with different levels and different types of expertise. Introducing the latter comparative base is the original contribution of these studies. The residents and specialists were trained in medical diagnosing of X-Rays and for these two groups it was possible to compare visual patterns between observers with different level of the same expertise type. On the other hand, the radiographers who took part in the examination - due to specific of their daily work - had experience in reading and evaluating X-Rays quality and were not trained in diagnosing. Involving this group created in our research the new opportunity to explore eye movements obtained when examining X-Ray for both medical diagnosing and quality assessment purposes, which may be treated as different types of expertise. We found that, despite the low diagnosing performance, the radiographers eye movement characteristics were more similar to the specialists than eye movement characteristics of the residents. It may be inferred that people with different type of expertise, yet after gaining a certain level of experience (or practise), may develop similar visual patterns which is the original conclusion of the research.	radiology	Pawel Kasprowski;Katarzyna Harezlak;Sabina Kasprowska	2018		10.1145/3204493.3204562	visual processing;applied psychology;eye tracking;medicine;eye movement	ML	3.029928949597433	-80.47870750026264	152897
9009cd4742d2f0b45054b3c30448142ad93cbb18	personalized human activity recognition using wearables: a manifold learning-based knowledge transfer		Human activity recognition (HAR) is an important component in health-care systems. For example, it can enable context-aware applications such as elderly care and patient monitoring. Relying on a set of training data, supervised machine learning algorithms form the core intelligence of most existing HAR systems. Meanwhile, the accuracy of an HAR model highly depends on the similarity between the training and the operating context. Therefore, there is a need for developing machine learning algorithms that can easily adapt to the operating context at hand. In this paper, we propose a cross-subject transfer learning algorithm that links source and target subjects by constructing manifolds from feature-level representation of the source subject(s). Our algorithm assigns labels to the unlabeled data in the current context using the manifold learned from the source subject(s). The newly labeled data is used to develop a personalized HAR model for the current context (i.e., target subject). We demonstrate the efficacy of the algorithm using a publicly available dataset on HAR. We show that the proposed framework improves the accuracy of activity recognition by up to 24%.	activity recognition;algorithm;alpha-1,3-galactosyltransferase-expressing allogeneic renal cell carcinoma vaccine;human activities;machine learning;map;nonlinear dimensionality reduction;patient monitoring;personalization;silo (dataset);supervised learning;tracer;wearable computer;algorithm;manifold	Ramyar Saeedi;Keyvan Sasani;Skyler Norgaard;Assefaw H. Gebremedhin	2018	2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2018.8512533	labeled data;transfer of learning;computer vision;feature extraction;wearable computer;machine learning;nonlinear dimensionality reduction;training set;artificial intelligence;activity recognition;knowledge transfer;computer science	AI	3.7769185739740503	-83.3425971907545	153029
6fa290f2c545729f549ba5bf1711b4e18f8c22cb	a device-free number gesture recognition approach based on deep learning	band pass filters;wireless communication;machine learning;feature extraction;ieee 802 11 standard;gesture recognition;wireless sensor networks	Number gestures play essential parts in our daily communication and have attracted academic interests in developing Human-Computer Interface. In this paper, we resort to the fine-grained Channel State Information (CSI) in the 802.11n standard to recognize number gestures. The intuition is that certain gestures can affect wireless environment in a specific formation and thus generate unique features. Unfortunately, the majority of CSI-based technologies only extracted coarse grained features to recognize macro-movements. Besides, it can be time-consuming to select the most discriminative feature as salient evidence. In this paper, we present a device-free number gesture recognition approach based on deep learning, named DeNum. First, we explore the sensibility of both the amplitude and phase information of de-noised CSI values to action transitions. Then the amplitude difference is utilized to detect the finishing points of actions through multiple sliding windows. To extract discriminative features from both the amplitude and phase information over three antennas, a 4-layer deep learning model is adopted after obtaining number gesture information. Finally, a Support Vector Machine (SVM) algorithm is applied for gesture classification. We conduct extensive experiments on commercial Wi-Fi devices with different experimental parameters. Experimental results demonstrate the presented approach can achieve the average accuracy of 94% in current office scenario.	algorithm;channel state information;deep learning;experiment;feature vector;gesture recognition;human–computer interaction;microsoft windows;password;support vector machine	Qizhen Zhou;Jianchun Xing;Juelong Li;Qiliang Yang	2016	2016 12th International Conference on Computational Intelligence and Security (CIS)	10.1109/CIS.2016.0022	computer vision;speech recognition;wireless sensor network;feature extraction;computer science;artificial intelligence;machine learning;gesture recognition;band-pass filter;wireless	AI	5.232497848841699	-83.44505183603778	153121
7583313f99d05c4d774a708332220e37b74b9d0e	a novel monitoring system for fall detection in older people		Each year, more than 30% of people over 65 years-old suffer some fall. Unfortunately, this can generate physical and psychological damage, especially if they live alone and they are unable to get help. In this field, several studies have been performed aiming to alert potential falls of the older people by using different types of sensors and algorithms. In this paper, we present a novel non-invasive monitoring system for fall detection in older people who live alone. Our proposal is using very-low-resolution thermal sensors for classifying a fall and then alerting to the care staff. Also, we analyze the performance of three recurrent neural networks for fall detections: long short-term memory (LSTM), gated recurrent unit, and Bi-LSTM. As many learning algorithms, we have performed a training phase using different test subjects. After several tests, we can observe that the Bi-LSTM approach overcome the others techniques reaching a 93% of accuracy in fall detection. We believe that the bidirectional way of the Bi-LSTM algorithm gives excellent results because the use of their data is influenced by prior and new information, which compares to LSTM and GRU. Information obtained using this system did not compromise the user’s privacy, which constitutes an additional advantage of this alternative.	algorithm;artificial neural network;long short-term memory;machine learning;privacy;recurrent neural network;sensor	Carla Taramasco;Tomas Rodenas;Felipe Martinez;Paola Fuentes;Roberto Munoz;Rodrigo Olivares;Victor Hugo C. Albuquerque;Jacques Demongeot	2018	IEEE Access	10.1109/ACCESS.2018.2861331	distributed computing;artificial neural network;recurrent neural network;computer science;machine learning;artificial intelligence;compromise	HCI	4.754132605824139	-83.20255525210632	153234
a60a028e60bb2270fa78c00ab3ed93e50025a67c	multimodal platform for continuous monitoring of elderly and disabled	biomedical monitoring;detectors;sensors computerised monitoring diseases handicapped aids health care home automation;sensors;temperature sensors;handicapped aids;current measurement;monitoring;home environment monitoring continuous monitoring disabled person health monitoring care older people disease universal design home platform sensor based multimodal platform elderly person central workstation data acquisition data analysis;monitoring temperature sensors temperature measurement biomedical monitoring detectors current measurement;diseases;temperature measurement;computerised monitoring;home automation;health care	Health monitoring at home could be an important element of care and support environment for older people. Diversity of diseases and different needs of users require universal design of a home platform. We present our work on a sensor-based multimodal platform that is trained to recognize the activities elderly person on their home. Two specific problems were investigated: configuration and functionality of central workstation as a module for data acquisition and analysis and second problem is devoted to user's home environment monitoring.	data acquisition;multimodal interaction;sensor;workstation	Mariusz Kaczmarek;Jacek Ruminski;Adam Bujnowski	2011	2011 Federated Conference on Computer Science and Information Systems (FedCSIS)		embedded system;home automation;detector;simulation;temperature measurement;computer science;sensor;health care	HCI	7.467374970694767	-88.40617287447762	153245
7f40ce0f935251a03b7f4c011706285d124dc4f8	artificial neural networks based symbolic gesture interface	artificial neural network	The purpose of the developed system is the realization of a gesture recognizer, applied to a user interface. We tried to get fast and easy software for user, without leaving out reliability and using instruments available to common user: a PC and a webcam. The gesture detection is based on well-known artificial vision techniques, as the tracking algorithm by Lucas and Kanade. The paths, opportunely selected, are recognized by a double layered architecture of multilayer perceptrons. The realized system is efficiency and has a good robustness, paying attention to an adequate learning of gesture vocabulary both for the user and	algorithm;artificial neural network;autonomous robot;computation;computer vision;experiment;finite-state machine;gesture recognition;graphical user interface;multilayer perceptron;neural networks;personal computer;real-time transcription;test set;time complexity;usability;user interface;vocabulary;webcam	C. Iacopino;Anna Montesanto;Paola Baldassarri;Aldo Franco Dragoni;Paolo Puliti	2008			natural language processing;artificial intelligence;machine learning	Robotics	-1.7675852069504832	-82.2447742844927	153494
3473751287f3bbc8938f2a495d84aaf718a1ddd9	real-time medical emergency response system: exploiting iot and big data for public health	big data;hadoop ecosystem;healthcare;intelligent building;iot	Healthy people are important for any nation’s development. Use of the Internet of Things (IoT)-based body area networks (BANs) is increasing for continuous monitoring and medical healthcare in order to perform real-time actions in case of emergencies. However, in the case of monitoring the health of all citizens or people in a country, the millions of sensors attached to human bodies generate massive volume of heterogeneous data, called “Big Data.” Processing Big Data and performing real-time actions in critical situations is a challenging task. Therefore, in order to address such issues, we propose a Real-time Medical Emergency Response System that involves IoT-based medical sensors deployed on the human body. Moreover, the proposed system consists of the data analysis building, called “Intelligent Building,” depicted by the proposed layered architecture and implementation model, and it is responsible for analysis and decision-making. The data collected from millions of body-attached sensors is forwarded to Intelligent Building for processing and for performing necessary actions using various units such as collection, Hadoop Processing (HPU), and analysis and decision. The feasibility and efficiency of the proposed system are evaluated by implementing the system on Hadoop using an UBUNTU 14.04 LTS coreTMi5 machine. Various medical sensory datasets and real-time network traffic are considered for evaluating the efficiency of the system. The results show that the proposed system has the capability of efficiently processing WBAN sensory data from millions of users in order to perform real-time responses in case of emergencies.	anytime algorithm;apache hadoop;big data;body dysmorphic disorders;decision making;economic development;ecosystem;emergencies [disease/finding];emergency medical service;first aid;genetic heterogeneity;health care;human body;internet of things;long-term survivors;man-machine systems;memory disorders;network architecture;network traffic control;online and offline;real-time clock;real-time computing;real-time locating system;real-time transcription;spark;suppository;anatomical layer;sensor (device)	M. Mazhar Rathore;Awais Ahmad;Anand Paul;Jiafu Wan;Daqiang Zhang	2016	Journal of Medical Systems	10.1007/s10916-016-0647-6	simulation;artificial intelligence;operating system;data mining;computer security	Robotics	5.072552447414612	-87.25387818608428	153555
abc8172eab77d22e90c6bd85d28e7c3222a8ea11	massha: an agent-based approach for human activity simulation in intelligent environments		Abstract Human activity recognition has the potential to become a real enabler for ambient assisted living technologies. Research on this area demands the execution of complex experiments involving humans interacting with intelligent environments in order to generate meaningful datasets, both for development and validation. Running such experiments is generally expensive and troublesome, slowing down the research process. This paper presents an agent-based simulator for emulating human activities within intelligent environments: MASSHA. Specifically, MASSHA models the behaviour of the occupants of a sensorised environment from a single-user and multiple-user point of view. The accuracy of MASSHA is tested through a sound validation methodology, providing examples of application with three real human activity datasets and comparing these to the activity datasets produced by the simulator. Results show that MASSHA can reproduce behaviour patterns that are similar to those registered in the real datasets, achieving an overall accuracy of 93.52% and 88.10% in frequency and 98.27% and 99.09% in duration for the single-user scenario datasets; and a 99.3% and 88.25% in terms of frequency and duration for the multiple-user scenario.		Oihane Kamara Esteban;Gorka Azkune;Ander Pijoan;Cruz E. Borges;Ainhoa Alonso-Vicario;Diego López-de-Ipiña	2017	Pervasive and Mobile Computing	10.1016/j.pmcj.2017.07.007	activity recognition;computer science;data mining	Robotics	1.4713032985335543	-84.43327982934521	154039
8194db035511b88adbc7a173a30c12656752316f	emergency response	can render your sense of smell olfac;h 2 s with pro- longed exposure;paint thinners;co is colorless;propane;ponents of natural gas;known as the silent killer;to name a few of many. carbon monoxide;etc.;a colorless gas with a characteristic odor like rotten eggs. however;odorless and a by-product of incomplete combustion. it is invisible to the human senses. carbon monoxide is a toxic asphyxiant which means it reduces the oxygen-transporting properties of the blood. hydrogen sulfide	❒ Contact school nurse at__________________________ ❒ Call 911 for transport to __________________________ ❒ Notify parent or emergency contact ❒ Administer emergency medications as indicated below ❒ Notify doctor ❒ Other ________________________________________ Basic Seizure First Aid • Stay calm & track time • Keep child safe • Do not restrain • Do not put anything in mouth • Stay with child until fully conscious • Record seizure in log For tonic-clonic seizure: • Protect head • Keep airway open/watch breathing • Turn child on side	tonic - clonic seizures;tonic-clonic epilepsy;notification	Robert J. Dachs	2003	American family physician	10.1007/978-3-319-17885-1_100349		HCI	-0.000474062133591579	-80.59647384478964	154728
da3fbd35e91f166f73dab41c80f5f7dd6d51f5e3	lippass: lip reading-based user authentication on smartphones leveraging acoustic signals		To prevent usersu0027 privacy from leakage, more and more mobile devices employ biometric-based authentication approaches, such as fingerprint, face recognition, voiceprint authentications, etc., to enhance the privacy protection. However, these approaches are vulnerable to replay attacks. Although state-of-art solutions utilize liveness verification to combat the attacks, existing approaches are sensitive to ambient environments, such as ambient lights and surrounding audible noises. Towards this end, we explore liveness verification of user authentication leveraging usersu0027 lip movements, which are robust to noisy environments. In this paper, we propose a lip reading-based user authentication system, LipPass, which extracts unique behavioral characteristics of usersu0027 speaking lips leveraging build-in audio devices on smartphones for user authentication. We first investigate Doppler profiles of acoustic signals caused by usersu0027 speaking lips, and find that there are unique lip movement patterns for different individuals. To characterize the lip movements, we propose a deep learning-based method to extract efficient features from Doppler profiles, and employ Support Vector Machine and Support Vector Domain Description to construct binary classifiers and spoofer detectors for user identification and spoofer detection, respectively. Afterwards, we develop a binary tree-based authentication approach to accurately identify each individual leveraging these binary classifiers and spoofer detectors with respect to registered users. Through extensive experiments involving 48 volunteers in four real environments, LipPass can achieve 90.21% accuracy in user identification and 93.1% accuracy in spoofer detection.	acoustic cryptanalysis;authentication;binary classification;binary tree;biometrics;deep learning;doppler effect;experiment;facial recognition system;fingerprint;liveness;mobile device;replay attack;sensor;shading;smartphone;spectral leakage;statistical classification;support vector machine	Li Lu;Jiadi Yu;Yingying Chen;Hongbo Liu;Yanmin Zhu;Yunfei Liu;Minglu Li	2018	IEEE INFOCOM 2018 - IEEE Conference on Computer Communications	10.1109/INFOCOM.2018.8486283	real-time computing;replay attack;deep learning;distributed computing;feature extraction;mobile device;biometrics;facial recognition system;computer science;liveness;artificial intelligence;authentication	Mobile	1.9975169247003006	-81.8630050807577	154841
327c4e4281b0cf83794bed07e88519bb90810cc8	self-esteem conditioning for learning conditioning	biomedical monitoring;learning performance;learning process;self esteem condition;sensors;particle measurements;skin;skin biosensors electroencephalography intelligent tutoring systems physiology;psychology;subliminal priming;learning conditioning;indexes;skin conductance;physiology;subliminal priming method;sensor;self esteem;blood volume pulse sensors self esteem condition learning conditioning tutoring system subliminal priming method biofeedback device physiological sensors electroencephalogram skin conductance;blood volume pulse sensors;intelligent tutoring systems;biomedical monitoring sensors electroencephalography indexes artificial intelligence psychology particle measurements;blood volume pulse;physiological sensors;learner affect;artificial intelligence;learner affect subliminal priming self esteem learning performance sensor;electroencephalography;electroencephalogram;tutoring system;biosensors;biofeedback device	In this paper, we propose to introduce the self-esteem component within learning process. More precisely, we explore the effects of learner self-esteem conditioning in a tutoring system. Our approach is based on a subliminal priming method aiming at enhancing implicit self-esteem. An experiment was conducted while participants were outfitted with biofeedback device. Three physiological sensors were used to continuously monitor learners’ affective reactions namely electroencephalogram, skin conductance and blood volume pulse sensors. The purpose of this work is to analyze the impact of self-esteem conditioning on learning performance on one hand and learners’ emotional and mental states on the other hand.	conductance (graph);electroencephalography;experiment;interaction;mental state;pulse;sensor;subliminal channel	Imene Jraidi;Maher Chaouachi;Claude Frasson	2010	2010 10th IEEE International Conference on Advanced Learning Technologies	10.1109/ICALT.2010.154	computer science;sensor;artificial intelligence	Robotics	9.23995191725816	-93.18337935030188	154907
e197c904aeda8d897f9533f0c2872a0a161692f7	data-driven smart home system for elderly people based on web technologies		The proportion of elderly people over 65 years old has rapidly increased, and social costs related to aging population problems have grown globally. The governments want to reduce these social costs through advanced technologies. The physician or medical center evaluates health conditions from the reports of elderly people. However, self-reports are often inaccurate, and sometimes reports by family or caregivers can be more accurate. To solve these problems, an evaluated objective method based on sensor data is needed. In this paper, we propose a data-driven smart home system that uses web technologies for connecting sensors and actuators. The proposed system provides a method of monitoring elderly people’s daily activities using commercial sensors to register recognizable activities easily. In addition, it controls actuators in the home by using user-defined rules and shows a summary of elderly people’s activities to monitor them.	home automation	Daeil Seo;Byounghyun Yoo;Heedong Ko	2016		10.1007/978-3-319-39862-4_12	world wide web	HCI	5.267290970026449	-88.61960929046855	155123
f295fcac3cce2c90d331a608be7777942b2ca7b0	auditory representations of acoustic signals	proyeccion;appareil auditif;acoustic spectrum;procesamiento informacion;natural speech sounds;low bit rate data compression acoustic signals analytically tractable framework neural processing auditory system acoustic spectrum wavelet representations multiresolution processing method of convex projections natural speech sounds spectral enhancements noise suppression perceptual correlates automatic speech recognition;systeme nerveux central;data compression;voie auditive;auditory pathway;reconocimiento palabra;neural processing;method of convex projections;auditory system;acoustic signals;signal processing systems;hombre;acoustic signal processing;noise suppression;spectre acoustique;auditory system signal resolution automatic speech recognition wavelet transforms signal processing inspection acoustic noise data compression humans;espectro acustico;multiresolution processing;inspection;low bit rate data compression;algorithme;wavelet transforms;algorithm;automatic speech recognition;sistema nervioso central;modelo;convex projections;corteza auditiva;wavelet transform;cortex auditif;auditory cortex;signal processing;acoustic noise;projection;information processing;transforms acoustic signal processing hearing speech recognition;human;transforms;perceptual correlates;signal acoustique;spectral enhancements;signal resolution;speech recognition;organ of hearing;via auditiva;analytically tractable framework;modele;wavelet representations;humans;acoustic signal;technical report;reconnaissance parole;traitement information;communication;models;hearing;central nervous system;senal acustica;aparato auditivo;homme;algoritmo	AbstructAn analytically tractable framework is presented to describe mechanical and neural processing in the early stages of the auditory system. Algorithms are developed to assess the integrity of the acoustic spectrum at all processing stages. The algorithms employ wavelet representations, multiresolution processing, and the method of convex projections to construct a close replica of the input stimulus. Reconstructions using natural speech sounds demonstrate minimal loss of information along the auditory pathway. Furthermore, close inspection of the final auditory patterns reveal spectral enhancements and noise suppression that have close perceptual correlates. Finally, the functional significance of the various auditory processing stages are discussed in light of the model, together with their potential applications in automatic speech recognition and low bit-rate data compression.	acoustic cryptanalysis;algorithm;cobham's thesis;data compression;gene regulatory network;natural language;speech recognition;wavelet;zero suppression	Xiaowei Yang;Kuansan Wang;Shihab A. Shamma	1992	IEEE Trans. Information Theory	10.1109/18.119739	speech recognition;information processing;computer science;signal processing;mathematics;computational auditory scene analysis;auditory scene analysis;wavelet transform	ML	-4.284713061411309	-91.3478137716928	155163
5d5ec3dd4c8b0c33ed2933711b0d5091ddb1d4b5	capture and analysis of sensor data for asthma patients				Nikolai Bock;Matthias Scholz;Gunther Piller;Klaus Böhm	2016			knowledge management;computer engineering;simulation;asthma;computer science	Robotics	5.9653223197310945	-89.29188086743373	155807
9d58e8ab656772d2c8a99a9fb876d5611fe2fe20	beyond temporal pooling: recurrence and temporal convolutions for gesture recognition in video	technology and engineering;deep neural networks;gesture recognition	Recent studies have demonstrated the power of recurrent neural networks for machine translation, image captioning and speech recognition. For the task of capturing temporal structure in video, however, there still remain numerous open research questions. Current research suggests using a simple temporal feature pooling strategy to take into account the temporal aspect of video. We demonstrate that this method is not sufficient for gesture recognition, where temporal information is more discriminative compared to general video classification tasks. We explore deep architectures for gesture recognition in video and propose a new end-to-end trainable neural network architecture incorporating temporal convolutions and bidirectional recurrence. Our main contributions are twofold; first, we show that recurrence is crucial for this task; second, we show that adding temporal convolutions leads to significant improvements. We evaluate the different approaches on the Montalbano gesture recognition dataset, where we achieve state-of-the-art results.	artificial neural network;convolution;end-to-end principle;gesture recognition;high- and low-level;machine translation;network architecture;open research;recurrent neural network;speech recognition;vocabulary	Lionel Pigou;Aäron van den Oord;Sander Dieleman;Mieke Van Herreweghe;Joni Dambre	2016	International Journal of Computer Vision	10.1007/s11263-016-0957-7	computer vision;speech recognition;computer science;machine learning;gesture recognition	Vision	-4.074088537519135	-86.7512871319219	156008
1e0fdbe9aae8d6864f7e99bcb54c46bfef4e0ec4	australian sign language recognition using moment invariants	moment;dynamic hand gestures;moment invariants;invariants;recognition;australian;australian sign language;language	Human Computer Interaction is geared towards seamless human machine integration without the need for LCDs, Keyboards or Gloves. Systems have already been developed to react to limited hand gestures especially in gaming and in consumer electronics control. Yet, it is a monumental task in bridging the well-developed sign languages in different parts of the world with a machine to interpret the meaning. One reason is the sheer extent of the vocabulary used in sign language and the sequence of gestures needed to communicate different words and phrases. Auslan the Australian Sign Language is comprised of numbers, finger spelling for words used in common practice and a medical dictionary. There are 7415 words listed in Auslan website. This research article tries to implement recognition of numerals using a computer using the static hand gesture recognition system developed for consumer electronics control at the University of Wollongong in Australia. The experimental results indicate that the numbers, zero to nine can be accurately recognized with occasional errors in few gestures. The system can be further enhanced to include larger numerals using a dynamic gesture recognition system.		Prashan Premaratne;Shuai Yang;ZhengMao Zou;Peter James Vial	2013		10.1007/978-3-642-39482-9_59	natural language processing;speech recognition;computer science;artificial intelligence;invariant;gesture recognition;mathematics;moment;language;gesture	Vision	-2.708833976004901	-82.52721947167096	156813
1e3f3130575d20f5f5fbf9ed9013fb1aa63e0c94	a proposal for bio-synchronized transmission of eeg/erp data	signal image and speech processing;information systems applications incl internet;communications engineering networks	Acquisition of event-related potentials (ERPs) requires a nearly perfect synchronization between the stimulus player and the EEG acquisition unit that clinical systems implement at hardware level by means of a wired link. Out of clinical context, current brain-computer interface technology offers wireless and wearable EEG headsets that provide ubiquitous EEG acquisition. However, they are not adequate for ERPs acquisition since they lack the physical wire with the stimulus player. In this paper, we propose a novel technique devoted to provide a solution to this problem by means of a bio-synchronization approach. This technique adds to the stimulus data, a tagged audio preamble for synchronization (TAP-S) that embeds a synchronization mechanism in its physiological response based on pseudo random sequences. In this way, the EEG data elicited by the preamble and the stimulus are recorded together and the stimulus onset can be directly extracted from the EEG data by preamble detection. TAP-S is tailored to work with any low-cost multimedia player and wireless EEG headsets. Our preliminary results reveal TAP-S as a first, promising, and low-cost approach that, after further improvement, could enable remote processing of ERPs with wireless acquisition with application in telemedicine, ambient assisted living, or brain-computer interfaces.	brain–computer interface;british informatics olympiad;erp;electroencephalography;onset (audio);pseudorandomness;wearable computer	Miguel Angel Lopez-Gordo;Pablo Padilla;Francisco Pelayo Valle	2016	EURASIP J. Wireless Comm. and Networking	10.1186/s13638-016-0550-3	real-time computing;speech recognition;telecommunications;computer science	HCI	9.047711911592202	-90.64283083988394	156939
39d8cfb7ba79dcbdd26b3a6b9e4322b5f01afa8a	identifying elderlies at risk of becoming more depressed with internet-of-things		Depression in the elderly is common and dangerous. Current methods to monitor elderly depression, however, are costly, time-consuming and inefficient. In this paper, we present a novel depression-monitoring system that infers an elderly’s changes in depression level based on his/her activity patterns, extracted from wireless sensor data. To do so, we build predictive models to learn the relationship between depression level changes and behaviors using historical data. We also deploy the system for a group of elderly, in their homes, and run the experiments for more than one year. Our experimental study gives encouraging results, suggesting that our IoT system is able to correctly identify u003e80% of the elderly at risk of becoming more depressed, with a very low false positive rate.		Jiajue Ou;Huiguang Liang;Hwee-Xian Tan	2018		10.1007/978-3-319-92037-5_26	false positive rate;data mining;business;internet of things	NLP	5.177631893728464	-86.3320280454856	157383
4e555315a2f7cba1e1f5d6c9c0b5dea77534774a	smartstep 2.0 - a completely wireless, versatile insole monitoring system	wireless charging;firmware upgrade;low power system smartstep 2 0 base station wireless charging firmware upgrade;low power system;monitoring biomedical monitoring batteries wireless sensor networks wireless communication wires microcontrollers;smartstep 2 0;base station;wireless sensor networks biomedical electronics footwear gait analysis patient monitoring;battery charging smartstep 2 0 wireless insole monitoring system versatile insole monitoring system insole based wearable sensor gait monitoring physical activity monitoring energy expenditure estimation biofeedback fall risk shoe based wearable system smartstep monitor wireless gait data acquisition device wireless charging feature free living condition wfd feature wireless firmware upgrade	Insole based wearable sensors are becoming popular in applications such as gait and physical activity monitoring, energy expenditure estimation, in providing biofeedback, fall risk and others. In the existing systems, the insole needs to be taken out of the shoe to recharge the battery, which is not a convenient task. The existing systems are application specific and can be used for a limited purpose. However, the desired system functionality for the shoe based wearable systems depends on factors such as the targeted age group of the individuals and laboratory set up vs free living conditions. We attempt to fill these gaps in this work, as we present the recent advancements in SmartStep monitors - SmartStep 2.0, making it a completely wireless, versatile gait data acquisition device. We discuss the implementation of the seamless wireless charging feature to resolve the battery charging problems, along with the implementation of the base station for charging purposes. In making the SmartStep 2.0 a versatile insole monitor, we discuss the implementation of the Wireless Firmware Upgrade (WFD) feature, which allows the same insole system to be used in different application scenarios. Two example application scenarios for wireless gait data acquisition are discussed, along with the power consumption figures in different modes. Results suggest that the SmartStep 2.0 can potentially be used in the ambulatory monitoring of physical activity and gait in laboratory as well as in free living conditions.	battery charger;data acquisition;firmware;rechargeable battery;seamless3d;sensor;wearable computer	Nagaraj Hegde;Edward S. Sazonov	2015	2015 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2015.7359779	embedded system;simulation;computer science;base station	Mobile	8.614693870946244	-88.746282428606	157513
0b5a441e4aba09c1f983bd5881c7eac35bd27ba4	technical verification of integrating wearable sensors into bsn-based telemedical monitoring system	body sensor networks;telemedicine;skin;temperature sensors;humidity sensors;assisted living systems;assisted living;technical verification body sensor network healthcare services multisensor human health monitoring wireless wearable monitoring system real time data analysis remote web based graphical user interface transmission protocol remote medical server clothes network gateway accelerometer skin humidity sensor temperature sensor ecg sensor bluetooth module body central unit human physiological signal analysis human physiological signal monitoring health monitoring system daily life activity miniaturized pervasive health monitoring devices bsn based telemedical monitoring system wearable sensor integration;wearable computing body sensor networks bsn telemedicine assisted living systems;physiology;electrocardiography;bsn;graphical user interfaces;web services;internetworking;ubiquitous computing;clothing;patient monitoring;bluetooth;sensor fusion;wearable computing;monitoring biomedical monitoring medical services temperature sensors skin wireless communication temperature measurement;web services accelerometers assisted living bluetooth body sensor networks clothing electrocardiography graphical user interfaces humidity sensors internetworking patient monitoring physiology sensor fusion skin telemedicine temperature sensors ubiquitous computing;accelerometers	With recent advances in electronics, wireless communication and computer science it is possible to develop miniaturized pervasive health monitoring devices that are capable of monitoring physiological signals during daily life activities. The aim of the research is to implement and test health monitoring system to monitor and analyze humans physiological signals. System consists of body central unit with Blue tooth module and wearable sensors: ECG sensor, temperature sensor, skin humidity sensor and accelerometers placed on the human body or integrated with clothes and network gateway to forward data to remote medical server. The system includes specially designed transmission protocol and remote web-based graphical user interface for real time data analysis. Experimental results for a group of human who performed various activities (ex. working, running etc.) are compared to certified medical devices. The results are promising and indicate that developed wireless wearable monitoring system faces challenges of multi-sensor human health monitoring during performing daily activities and open new opportunities in developing novel healthcare services.	computer science;gateway (telecommunications);graphical user interface;pervasive informatics;sensor;server (computing);wearable computer;wearable technology;web application	Eliasz Kantoch	2013	2013 12th International Conference on Machine Learning and Applications	10.1109/ICMLA.2013.192	web service;embedded system;simulation;wearable computer;computer science;clothing;remote patient monitoring;body area network;graphical user interface;sensor fusion;skin;bluetooth;ubiquitous computing;accelerometer	Robotics	7.386776515185947	-88.55702809578248	157569
2501b5c2fa0ec7224c8abbea52d70eb5280afb39	mars: a personalised mobile activity recognition system	mars;informatica;model deployment;learning process;mobile device;model personalisation;device resources;training;smart phones;data mining;computing;ubiquitous knowledge discovery;user profile;centralised repository;activity profile;model building;data privacy;classification model;data stream mining;mobile communication;ubiquitous knowledge discovery mobile activity recognition data stream mining;mars data models mobile communication adaptation models training smart phones;mobile activity recognition;pattern classification;sensory data;quick model adaptation;smart phones data mining data privacy mobile computing pattern classification;mobile computing;adaptation models;classification techniques;android platform;personalised mobile activity recognition system;device resources mars personalised mobile activity recognition system mobile user sensory data smart phones classification techniques learning process centralised repository model building classification model model deployment mobile device data stream mining model personalisation data privacy activity profile quick model adaptation android platform user profile;data models;mobile user	Mobile activity recognition focuses on inferring the current activities of a mobile user by leveraging the sensory data that is available on today's smart phones. The state of the art in mobile activity recognition uses traditional classification techniques. Thus, the learning process typically involves: i) collection of labelled sensory data that is transferred and collated in a centralised repository, ii) model building where the classification model is trained and tested using the collected data, iii) a model deployment stage where the learnt model is deployed on-board a mobile device for identifying activities based on new sensory data. In this paper, we demonstrate the Mobile Activity Recognition System (MARS) where for the first time the model is built and continuously updated on-board the mobile device itself using data stream mining. The advantages of the on-board approach are that it allows model personalisation and increased privacy as the data is not sent to any external site. Furthermore, when the user or its activity profile changes MARS enables quick model adaptation. One of the stand out features of MARS is that training/updating the model takes less than 30 seconds per activity. MARS has been implemented on the Android platform to demonstrate that it can achieve accurate mobile activity recognition. Moreover, we can show in practice that MARS quickly adapts to user profile changes while at the same time being scalable and efficient in terms of consumption of the device resources.	activity recognition;android;centralisation;data stream mining;mobile device;on-board data handling;personalization;scalability;smartphone;software deployment;user profile	João Bártolo Gomes;Shonali Krishnaswamy;Mohamed Medhat Gaber;Pedro A. C. Sousa;Ernestina Menasalvas Ruiz	2012	2012 IEEE 13th International Conference on Mobile Data Management	10.1109/MDM.2012.33	computing;mobile search;model building;mobile database;computer science;operating system;data mining;mobile device;database;internet privacy;data stream mining;mobile computing;world wide web	Mobile	3.2908957903935576	-85.68486250426567	157748
bb75d52c60f3452caf122eed2adc816be29c7b31	healthcare shoe system for gait monitoring and foot odor detections	zigbee biomedical electronics biomedical equipment body sensor networks computer mediated communication electronic noses footwear force sensors gait analysis health care human computer interaction patient monitoring resistors sensor arrays;human computer interaction;body sensor networks;force sensors;wearing time duration healthcare shoe system gait monitoring foot odor detections smart technologies user friendliness point of care usability affordability socialability human gait patterns motion pattern foot odor measurement systems force sensitive resistors bending sensors chemical gas sensors zigbee technology data communication usb connected receiver computer consumer friendly compact size low cost technologies wearable device;footwear foot medical services gas detectors legged locomotion chemical sensors;footwear;zigbee;food odor data shoe wearable electronics zigbee gait pattern;biomedical electronics;computer mediated communication;gait analysis;resistors;patient monitoring;electronic noses;sensor arrays;biomedical equipment;health care	Recently, we are living in an era filled with unprecedentedly growing senior population. Nowadays, smart technologies for healthcare have been increasingly interested by general consumers due to their numerous advantages such as affordability, user-friendliness, point-of-care usability and social-ability. In this paper, we have developed a smart shoe system with ability to observe human gait patterns and foot odor. The motion pattern and foot odor measurement systems were installed inside the shoes using force sensitive resistors (FRSs), bending sensors and chemical gas sensors. Thereby the FRSs and bending-sensor were installed beneath the foot while chemical gas sensor array was installed inside the tongue of the shoes. In addition, zigbee technology was used as data communication between all sensors with a receiver USB-connected to a computer. This system was developed to be consumer-friendly having a compact size and using low-cost technologies. It was demonstrated that this wearable device could classify different types of human gait patterns and foot odors during the duration of wearing time.	sensor;shoes;smart shoe;system of measurement;usb;usability;wearable technology	Treenet Thepudom;Thara Seesaard;Wathang Donkrajang;Teerakiat Kerdcharoen	2013	2013 IEEE 2nd Global Conference on Consumer Electronics (GCCE)	10.1109/GCCE.2013.6664932	embedded system;electronic engineering;simulation;engineering	Robotics	7.929241353181678	-88.16269949889477	157791
e9ff993138f0f4bc41261a5ce00cf3de4e18dd68	assessing cognitive state with multiple physiological measures: a modular approach	neuroergonomics;physiological measures;adaptive system;augmented cognition	The purpose of this effort is to introduce a novel approach which can be used to determine how multiple minimally intrusive physiological sensors can be used together and validly applied to areas such as Augmented Cognition and Neuroergonomics. While researchers in these fields have established the utility of many physiological measures for informing when to adapt systems, the use of such measures together remains limited. Specifically, this effort will provide a contextual explanation of cognitive state, workload, and the measurement of both; provide a brief discussion on several relatively noninvasive physiological measures; explore what a modular cognitive state gauge should consist of; and finally, propose a framework based on the previous items that can be used to determine the interactions of the various measures in relation to the change of cognitive state.		Lee W. Sciarini;Denise M. Nicholson	2009		10.1007/978-3-642-02812-0_62	psychology;simulation;artificial intelligence;social psychology	HCI	8.170036507075379	-92.5603002470367	158046
fbbcb1682391fe855dad2f71d8c0a22b69be0fcb	monitoring behavioral transitions in cognitive rehabilitation with multi-model, multi-window stream mining	personalized emailing system;software;quality metric;cognitive systems;electronic mail;behavioral transitions monitoring;behavioural sciences computing;quality metrics;patient rehabilitation;cognitive rehabilitation via emailing;sequential segments;data mining;diseases computerized monitoring information systems computer science brain injuries neoplasms epilepsy dementia aging medical diagnostic imaging;patient rehabilitation behavioural sciences computing cognitive systems data mining electronic mail patient monitoring;multimodel multiwindow stream mining;accuracy;behavioral transitions monitoring quality metrics stream mined models personalized emailing system sequential segments logged user email commands user behavior cognitive rehabilitation via emailing multimodel multiwindow stream mining;monitoring;logged user email commands;predictive models;patient monitoring;user behavior;stream mined models;cognitive rehabilitation;data models	This paper describes how quality metrics over stream-mined models can identify potential changes in user goal attainment, as a user learns a personalized emailing system. A sequence of mined models is generated from sequential segments of logged user email commands. When the quality of some models varies significantly from nearby models - as defined by quality metrics - then the user's behavior is flagged as a potentially significant change. This paper describes how this technique works in its application on a case study of cognitive rehabilitation via emailing.	email;mined;personalization;stream processing	William N. Robinson;Arash Akhlaghi	2010	2010 43rd Hawaii International Conference on System Sciences	10.1109/HICSS.2010.279	data modeling;simulation;cognitive rehabilitation therapy;computer science;artificial intelligence;remote patient monitoring;data mining;database;accuracy and precision;predictive modelling;world wide web	SE	7.636890476761632	-87.06559981461847	158167
86d5101db086055ec9f84b4c7f2ba242d42c2081	towards using similarity measure for automatic detection of significant behaviors from continuous data		This paper presents our method based on similarity measure between contiguous pairs of sequences to yield automatic detection of significant behaviors from raw and continuous traces. The traces, produced by a simulation-based Intelligent Tutoring System dedicated to percutaneous orthopedic surgery, are related to perceptual-gestural behavior and ill-defined tasks involved in this domain. Preliminary qualitative evaluations have been conducted on real data from five simulation sessions and showed the relevancy of our method and adjustments that need to be realized for further experiments.	experiment;relevance;similarity measure;simulation;tracing (software)	Ben-Manson Toussaint;Vanda Luengo;Jérôme Tonetti	2014			artificial intelligence;machine learning;computer science;qualitative evaluations;similarity measure;data mining;intelligent tutoring system	Robotics	3.1479834615100524	-80.33392044500526	158413
1e2655501141063d5c18b0fe1c61a6fb6e8183ef	diagnosing internal illnesses using pervasive healthcare computing and neural networks	mobile device;personal digital assistant;information technology;wireless communication;healthcare system;time use;artificial neural network;neural network	This paper presents a novel distributed pervasive healthcare system for diagnosing internal illnesses using pervasive healthcare computing and artificial neural networks (ANNs) and reporting healthcare results to the patients. Mobile wireless communication and information technologies have been used in new healthcare systems. The new advances in wireless communications and small mobile devices such as personal digital assistants (PDAs) and new improvements in PDA’s CPU, memory and I/O components provide a particularly promising platform for pervasive healthcare applications due to PDA’s central role in people’s lives. Patients having internal diseases need to have many tests at hospitals, and a typical test report in some cases may have more than a hundred test results. It becomes a difficult, time consuming and error prone process for a doctor to diagnose the internal illnesses using such long reports. In this study we have been developing a distributed pervasive healthcare system which uses the hospital’s main database. An ANN classifier at the hospital’s server diagnoses internal illnesses and the simplified and understandable results are reported to the patients. The patients learn their analysis results anywhere and at any time using their PDA. Furthermore this system also provides the patients to learn their old and new analysis results. Our purpose in this study is not only to facilitate the work of doctors but also to provide freedom of movement for patients.	artificial neural network;central processing unit;client–server model;cognitive dimensions of notations;input/output;mobile device;personal digital assistant;pervasive informatics;server (computing)	Canan Bayraktar;Oguz Karan;Halûk Gümüskaya	2011		10.1016/j.procs.2010.12.097	embedded system;simulation;computer science;machine learning;data mining;mobile device;computer security;artificial neural network;wireless	HCI	5.958542891035835	-88.52076908472662	158883
4241cf81fce2e4a4cb486f8221c8c33bbaabc426	security and privacy issues in wireless sensor networks for healthcare applications	healthcare systems;telemedicina;computer communication networks;seguranca computacional;tecnologia de sensoriamento remoto;monitorizacao ambulatorial;telemedicine;redes de comunicacao de computadores;confidencialidade;humanos;interface usuario computador;confidentiality;computer security;monitoring ambulatory;ban;humans;remote sensing technology;user computer interface;wireless technology;tecnologia sem fio;security;wireless sensor networks;privacy	The use of wireless sensor networks (WSN) in healthcare applications is growing in a fast pace. Numerous applications such as heart rate monitor, blood pressure monitor and endoscopic capsule are already in use. To address the growing use of sensor technology in this area, a new field known as wireless body area networks (WBAN or simply BAN) has emerged. As most devices and their applications are wireless in nature, security and privacy concerns are among major areas of concern. Due to direct involvement of humans also increases the sensitivity. Whether the data gathered from patients or individuals are obtained with the consent of the person or without it due to the need by the system, misuse or privacy concerns may restrict people from taking advantage of the full benefits from the system. People may not see these devices safe for daily use. There may also possibility of serious social unrest due to the fear that such devices may be used for monitoring and tracking individuals by government agencies or other private organizations. In this paper we discuss these issues and analyze in detail the problems and their possible measures.	care-of address;collegehumor;continuous sphygmomanometers;government agencies;neuronal calcium-sensor proteins;patients;phobia, social;privacy;regulation;rule (guideline);unrest;benefit	Moshaddique Al Ameen;Jingwei Liu;Kyung Sup Kwak	2010		10.1007/s10916-010-9449-4	simulation;wireless sensor network;confidentiality;telecommunications;computer science;information security;body area network;privacy;computer security	Mobile	6.838972741848529	-88.80852415739771	159251
2544b966e0355a24609a421600327ad4efd5c027	a warning system based on the rfid technology for running-out of injection fluid	data transmission rfid technology injection fluid automatic warning system intravenous drip lan local area network;data transmission;radiofrequency;fluids;tag antenna;dipole antennas;rfid reader;hospitals;rfid tag;data communication;medical computing;clinical alarms equipment design equipment failure analysis infusions intravenous microwaves patient safety pharmaceutical preparations point of care systems radar radio frequency identification device reproducibility of results sensitivity and specificity;monitoring;rfid;intravenous drip lan local area network rfid tag antenna rfid reader;patient treatment;radiofrequency identification monitoring hospitals fluids dipole antennas;alarm systems;radiofrequency identification;local area networks;local area network;radiofrequency identification alarm systems data communication local area networks medical computing patient treatment;intravenous drip lan local area network	For providing an automatic warning system of running-out of injection fluid, RFID technology is applied in this work to propose an infrastructure with low cost to help nurses and patient's company. Specially, a RFID tag is designed and attached on a bag of intravenous drip to demonstrate the benefits in the present system. The main idea of this system is that, tag is disabled when the bag is not empty because of the EM loading due to the liquid contained. The bag can be any kind in the current market and be without any electronic attachment or modification. LAN (Local Area Network) is also applied as a part of this infrastructure for data transmission.	attachments;contain (action);disabled persons;electron microscopy;local area networks;patients;radio frequency identification device;tracer;benefit;negative regulation of endoplasmic reticulum tubular network organization	Chi-Fang Huang;Jen-Hung Lin	2011	2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/IEMBS.2011.6090418	local area network;radio-frequency identification;embedded system;telecommunications;computer science;engineering;computer security;fluid mechanics	Visualization	7.116346347396844	-88.88244384185883	159317
3842b1ba6dec94e6e2498518f3f79bfb53f8f022	learning context models for the recognition of scenarios	hidden markov model;context model;error rate;incremental algorithm;ubiquitous computing environment	This paper addresses the problem of automatic learning of scenarios. A ubiquitous computing environment must have the ability to perceive its occupants and their activities in order to recognize a context and to provide appropriate services. A context (a scenario) can be modeled as a temporal sequence of situations. Hard coding contexts by hand is a complex task. Our goal is to learn these context models based on a set of videos showing actors playing predefined scenarios. Once these models are learned, we can use them to classify new scenarios. Hidden Markov Models (HMMs) are particularly well suited for problems with a strong temporal structure; they are easily adaptable to variability of input and robust to noise. But two problems need to be addressed: how many HMMs do we need for all possible scenarios and how many states for each HMM. We propose in this paper an approach based on an incremental algorithm addressing these two problems. Under the best conditions we obtained the minimal error rate of 1.96% (2 errors in 102 validation entries).	algorithm;hard coding;heart rate variability;hidden markov model;markov chain;probabilistic turing machine;regular expression;ubiquitous computing	Sofia Zaidenberg;Oliver Brdiczka;Patrick Reignier;James L. Crowley	2006		10.1007/0-387-34224-9_11	simulation;word error rate;computer science;machine learning;data mining;context model;hidden markov model	Vision	0.5979320454613262	-84.59871170552282	159721
faadfdac539494ce41bc718696f5e6bfa1d63d69	a calorie count application for a mobile phone based on mets value	context aware computing;acceleration sensor reading;energy expenditure;sensors;information science;nonexercise activity thermogenesis;skin;radiation detectors;temperature sensors;mobile phone handset;thermal sensors;calorimeters;acceleration;mobile phone;counting circuits;heart rate;estimation;energy measurement;user posture inference;sensors accelerometers calorimeters mobile handsets;3 axis accelerometer;mobile handsets;mobile handsets accelerometers temperature sensors counting circuits energy measurement acceleration thermal sensors skin heart rate information science;mets value;calorie consumption;nonexercise activity thermogenesis calorie count application mets value 3 axis accelerometer mobile phone handset user posture inference acceleration sensor reading calorie consumption context aware computing energy expenditure neat;accelerometers;calorie count application;neat	This paper shows a methodology of estimating a user's everyday energy expenditure using a 3-axis accelerometer of a mobile phone handset. We first infer the user's posture based on the acceleration sensor reading and calculate METS value, which is considered as a measure for estimating calorie consumption for daily activities. The experimental result shows that our application is as accurate as a reference device.	metadata encoding and transmission standard;mobile phone;poor posture	Nanami Ryu;Yoshihiro Kawahara;Tohru Asami	2008	2008 5th Annual IEEE Communications Society Conference on Sensor, Mesh and Ad Hoc Communications and Networks	10.1109/SAHCN.2008.77	acceleration;calorimeter;embedded system;estimation;real-time computing;information science;sensor;operating system;energy homeostasis;skin;particle detector;accelerometer;statistics	Mobile	8.87636424122005	-86.29904362379108	160377
6b909e4d7c41605e7195f7f1f6514d9ebed914b1	a real-time fractal-based brain state recognition from eeg and its applications		EEG-based immersion is a new direction in research and development on human computer interfaces. It has attracted recently more attention from the research community and industry as wireless EEG reading devices became easily available on the market. EEG-based technology has been applied in anaesthesiology, psychology, serious games or even in marketing. As EEG signal is considered to have a fractal nature, we proposed and developed a novel spatio-temporal fractal based approach to the brain state quantification. The real-time algorithms of emotion recognition and concentration level recognition were implemented and integrated in human-computer interfaces of EEG-enable applications. In this paper, EEG-based “serious” games for concentration training and emotion-enable applications including emotion-based music therapy on the Web were proposed and implemented.	algorithm;digital media;electroencephalography;emotion markup language;emotion recognition;fractal dimension;human computer;human reliability;immersion (virtual reality);machine learning;personalization;real-time clock;real-time transcription;spaces;world wide web	Olga Sourina;Qiang Wang;Yisi Liu;Minh Khoa Nguyen	2011			eeg-fmri	AI	8.206570748009238	-91.15143084062585	160595
6f574d37d0e11b1d8ffa6226b0744846e70a740d	deductive refinement of species labelling in weakly labelled birdsong recordings	conference proceeding	Many approaches have been used in bird species classification from their sound in order to provide labels for the whole of a recording. However, a more precise classification of each bird vocalization would be of great importance to the use and management of sound archives and bird monitoring. In this work, we introduce a technique that using a two step process can first automatically detect all bird vocalizations and then, with the use of ‘weakly’ labelled recordings, classify them. Evaluations of our proposed method show that it achieves a correct classification of 75.4% when used in a synthetic dataset.	archive;deductive language;refinement (computing);synthetic intelligence	Veronica Morfi;Dan Stowell	2017	2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2017.7952237	speech recognition;computer science;artificial intelligence;machine learning	Visualization	-3.279716331594205	-89.2034953278108	161713
5842bf21f20ba9e622cc95ee7e5403f57b73840b	what's on your mind?: mental task awareness using single electrode brain computer interfaces	reading;bci;general knowledge;eeg;wearable computing	Recognizing and summarizing persons' activities have proven to be effective for increasing self-awareness and enable to improve habits. Reading improves one's language skills and periodic relaxing improves one's health. Recognizing these activities and conveying the time spent would enable to ensure that users read and relax for an adequate time. Most previous attempts in activity recognition deduce mental activities by requiring expensive/bulky hardware or by monitoring behavior from the outside. Not all mental activities can, however, be recognized from the outside. If a person is sleeping, relaxing, or intensively thinks about a problem can hardly be differentiated by observing carried-out reactions. In contrast, we use simple wearable off-the-shelf single electrode brain computer interfaces. These devices have the potential to directly recognize user's mental activities. Through a study with 20 participants, we collect data for five representative activities. We describe the dataset collected and derive potential features. Using a Bayesian classifier we show that reading and relaxing can be recognized with 97% and 79% accuracy. We discuss how sensory tasks associated with different brain lobes can be classified using a single dry electrode BCI.	activity recognition;bayesian network;brain–computer interface;mind;naive bayes classifier;regular language description for xml;self-awareness;wearable computer	Alireza Sahami Shirazi;Mariam Hassib;Niels Henze;Albrecht Schmidt;Kai Kunze	2014		10.1145/2582051.2582096	simulation;computer science;artificial intelligence;communication	HCI	5.0501194690237625	-86.02259202979255	162159
dee1def9ceca8f0144077df10571674700eafbf6	mindbeagle — a new system for the assessment and communication with patients with disorders of consciousness and complete locked-in syndrom		Patients with disorders of consciousness (DOC) cannot reply to questions or clinical assessments using voluntary motor control, and therefore it is very difficult to assess their cognitive capabilities and conscious awareness. Patients who are locked-in (LIS) are instead fully conscious, and they can communicate with their preserved eye movements. However, when the residual oculomotor activity is also lost (e.g., patients with amyotrophic lateral sclerosis disease of very long duration), the locked-in status becomes complete (CLIS). In CLIS patients, detection of conscious awareness may become very challenging, similarly to the subjects with DOC. mindBEAGLE has a physiological testing battery that uses auditory, vibro-tactile and motor imagery paradigms and brain-computer interface (BCI) technology to assess these patients and even provide communication for some of them. The current study presents results from 5 DOC and 3 LIS patients. The auditory evoked potential (AEP) assessement led to classification accuracies between 0 and 90 %, the vibro-tactile P300 paradigms led to 0 % to 100 % accuracy and the motor imagery paradigms led to accuracies up to 83.3 %. Three of the eight patients could succcessfully establish communication with the mindBEAGLE system. The results show that an assessment battery with auditory, vibro-tactile and motor imagery paradigms is able to identify cognitive functions of DOC and LIS patients. Patients showed substantial fluctuations in EEG measures, assessment results and communication reliability across different days and runs. Therefore, it is important to have a system available that can quickly and easily determine the status of a patient. Successful communication with these patients is also important.	asymptotic equipartition property;auditory processing disorder;brain–computer interface;cognition;disorders of consciousness;electroencephalography;lateral thinking;microsoft word for mac	Christoph Guger;Brendan Z. Allison;Rossella Spataro;Vincenzo La Bella;Andrea Kammerhofer;Florian Guttmann;Tim J. von Oertzen;Jitka Annen;Steven Laureys;Alexander Heilinger;Rupert Ortner;Woosang Cho	2017	2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)	10.1109/SMC.2017.8123086	machine learning;audiology;brain–computer interface;electroencephalography;artificial intelligence;motor imagery;consciousness;evoked potential;motor control;cognition;computer science;eye movement	Visualization	9.598571911640724	-91.44674354972122	162433
23c91a47127312dc701891acc1bfe4332c288af9	a survey of physical activity monitoring and assessment using internet of things technology	reviews biomechanics diseases internet of things learning artificial intelligence medical computing mobile computing patient care patient monitoring;biomedical monitoring;sensor phenomena and characterization;internet of things physical activity;wearable sensors;monitoring;feature extraction;monitoring biomedical monitoring wireless sensor networks feature extraction wearable sensors sensor phenomena and characterization;wireless sensor networks;iot architecture physical activity monitoring technologies chronic diseases wearable sensors machine learning algorithms wearable devices mobile apps internet of things environment physical activity assessment technologies review pama technologies	As a key health indictor, daily physical activity (PA) data has great significance on diagnosis and treatment of many chronic diseases. Numerous studies have been carried out for accurately monitoring and assessing physical activity. Most attentions of these studies focus on designing standalone highly accurate wearable sensors or investigating advance machine learning algorithms to train these PA data in a controlled environment. But the wide use of cost-effective wearable devices and mobile apps makes it possible to monitor and access PA into a more open and connective Internet of Things (IoT) environment. Yet, it still lacks of a systemic survey on how to effectively transfer classic PA monitoring and assessment (PAMA) technologies into a heterogeneous device connected IoT environment. In an effect to understand the development of IoT technologies in PAMA, this paper reviews current research of PAMA technologies from an IoT layer-based perspective, and also identifies research challenges and future trends. A main contribution of this review paper is that it is first attempt to categorize classic PAMA technologies into an IoT architecture systematically.	algorithm;categorization;internet of things;lifelog;logical connective;machine learning;mobile app;physical computing;real life;sensor;uncontrolled format string;wearable computer;wearable technology	Jun Qi;Po Yang;Dina Fan;Zhikun Deng	2015	2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing	10.1109/CIT/IUCC/DASC/PICOM.2015.348	embedded system;simulation;wireless sensor network;feature extraction;computer science;machine learning	HCI	7.1624114583874015	-85.73167364714216	162560
115de569643135973e8ef0aca500cf2c96489f55	indoor pedestrian navigation using foot-mounted imu and portable ultrasound range sensors	computers;facility design and construction;indoor localization;walking;pedestrian safety;poison control;injury prevention;acoustics;foot;safety literature;motion;traffic safety;injury control;home safety;signal processing computer assisted;ultrasound range sensors;equipment design;injury research;safety abstracts;human factors;inertial tracking;occupational safety;safety;reproducibility of results;models statistical;safety research;self help devices;accident prevention;violence prevention;bicycle safety;ultrasonics;poisoning prevention;falls;ergonomics;suicide prevention;model based navigation	Many solutions have been proposed for indoor pedestrian navigation. Some rely on pre-installed sensor networks, which offer good accuracy but are limited to areas that have been prepared for that purpose, thus requiring an expensive and possibly time-consuming process. Such methods are therefore inappropriate for navigation in emergency situations since the power supply may be disturbed. Other types of solutions track the user without requiring a prepared environment. However, they may have low accuracy. Offline tracking has been proposed to increase accuracy, however this prevents users from knowing their position in real time. This paper describes a real time indoor navigation system that does not require prepared building environments and provides tracking accuracy superior to previously described tracking methods. The system uses a combination of four techniques: foot-mounted IMU (Inertial Motion Unit), ultrasonic ranging, particle filtering and model-based navigation. The very purpose of the project is to combine these four well-known techniques in a novel way to provide better indoor tracking results for pedestrians.	navigation;online and offline;particle filter;power supply;pre-installed software;solutions;ultrasonics (sound);sensor (device)	Gabriel Girard;Stéphane Côté;Sisi Zlatanova;Yannick Barette;Johanne St-Pierre;Peter van Oosterom	2011		10.3390/s110807606	embedded system;simulation;engineering;suicide prevention;human factors and ergonomics;injury prevention;motion;transport engineering;computer security;mobile robot navigation;physics;quantum mechanics;foot	HCI	8.462699185658193	-84.55245072779884	162760
2a0c68c134bcabd3f739f70ec555c76c93cc8788	real-time augmented reality for image-guided interventions			augmented reality;real-time transcription	Sebastian Vogt	2009			simulation;augmented reality;psychological intervention;computer science	HCI	5.225606319970954	-92.75479300188752	162820
0f82f4f3829d75bc53f73494dbe36226efe3adea	metabolic.care: a hardware and software platform to monitor and assess diabetic foot condition	patient monitoring diseases infrared imaging medical image processing open systems patient diagnosis;standards;diabetes;foot;interoperability of medical data medical image processing;interoperability metabolic care hardware platform software platform diabetic foot condition assessment diabetic foot condition monitoring patient diagnosis warning generation image processing;dicom;foot diabetes dicom monitoring standards;monitoring	This paper describes Metabolic.Care, a sub-project that integrates hardware and software with the main goal of implementing a solution that generates warnings for the diagnosis on patients with diabetic foot. This paper also describes the adopted strategies and best practices found to solve the problems.	best practice;computer hardware;dicom;health level 7;interoperability;upload	Daniel Arcuschin de Oliveira;Paula Sousa;Virginie Felizardo;Nuno C. Garcia;Celina Alexandre;Nuno M. Garcia	2014	2014 IEEE 16th International Conference on e-Health Networking, Applications and Services (Healthcom)	10.1109/HealthCom.2014.7001867	embedded system;engineering;biological engineering;diabetes mellitus	Robotics	7.412725838801787	-89.12937215508938	163070
37027737068e1d46e2f2d439c1fa323ea562305a	preselection of neurostimulation waveforms for visual prostheses using genetic algorithms	genetic algorithm	Among the variety of approaches for developing therapies for the blind, electrical neurostimulation of the visual pathways seems to be a promising choice. Delivering bi-phasic bioelectric pulses to the nerves implies the selection of values for a number of parameters within a wide range. This needs to be done for every implanted electrode, and for every patient. Nowadays, electrode arrays can include up to one hundred channels, and we expect to raise to thousands of them in a near future. This unavoidable task becomes extremely timeconsuming both for the researcher and for the patient. Therefore, in order to reduce the number of tests to be carried out in vivo, we propose the use of multi-objective genetic algorithms that can provide a limited set of candidate waveforms to be tried.	genetic algorithm;mathematical optimization;neuroprosthetics;neurostimulation;simulation software;video-in video-out;visual prosthesis	Samuel F. Romero;Alberto Guillén;Cristóbal J. Carmona;Christian A. Morillas;Francisco J. Pelayo;Héctor Pomares	2010			engineering;genetic algorithm;biomedical engineering;neurostimulation;waveform	Graphics	9.731415784348444	-81.39940762340552	163228
3f77a506bd1e81d15bf2e4ac75375392e466af52	opinion recognition on movie reviews by combining classifiers		In this paper we present a combined opinion recognition scheme based on discriminative algorithms, decision trees and probabilistic algorithms. The proposed scheme takes advantage of the information provided from each of the recognition models in decision level, in order to provide refined and more accurate opinion recognition results. The experimental results showed that the proposed combined scheme achieved an overall recognition performance of 87.90 %, increasing the accuracy of our best-performing opinion recognition model by 3.5 %.		Athanasia Koumpouri;Iosif Mporas;Vasileios Megalooikonomou	2015		10.1007/978-3-319-23132-7_38	discriminative model;sentiment analysis;probabilistic analysis of algorithms;decision tree;artificial intelligence;pattern recognition;computer science	NLP	-3.1922591779144445	-85.2682223957981	163586
ae818858a88299090748446b8662e68628612c65	analysis of expressiveness of portuguese sign language speakers	dissertacao;ciencias da engenharia e tecnologias	Nowadays, there are several communication gaps that isolate deaf people in several social activities. The breakthroughs made so far in the area of reading nonverbal behaviour are crucial and constitute a strong motivation to direct research efforts towards studying this population. This master thesis is part of a unique project that intends to study the differences among two populations: deaf people and hearing people. The ultimate goal is to move towards a better understanding of emotional and behaviour patterns, through face and body expressions analysis, in both deaf and hearing people. The hereby presented work, in particular, is a first step towards that ultimate goal in which the expressiveness of gestures in Portuguese Sign Language speakers is accessed in several different ways. One of the main contributions of this work to the scientific community, that served as support to the work itself, was the construction of a video database of a very specific context (duo-interaction between deaf and hearing people). This database served as starting point for the development of a feature-based computer vision framework with the purpose of finding answers to the following problems: differentiate the deaf population from the hearing one, identifying based on body expressiveness different conversation topics, trying to identify through feature analysis different levels of mastery in Portuguese Sign Language. The approaches followed to answer these research questions were based on the use of machine learning classifiers in supervised and unsupervised ways. The results of the classification revealed that it was possible with the features considered to distinguish deaf from hearing people and also to distinguish different conversation topics featured in the videos of the database. The attempt of stratifying the subjects considered in levels of expertise of sign language was not achieved with the same success due to the abstractness of this issue which may be dependent on several other factor that are exterior to our approach such as the life experience of each subject. The final outcomes of this study are very interesting and encouraging to carry on with further research on: discovering and studying the main differences of the considered populations and also to explore their body and facial expressions on several scenarios as well as their interactions.	computer vision;interaction;machine learning;population;unsupervised learning	Ines V. Rodrigues;Eduardo Marques Pereira;Luís F. Teixeira	2015		10.1007/978-3-319-19390-8_79	speech recognition;computer science	Web+IR	1.3041475011622616	-89.3814072270629	163682
31d03a4c3139e429e5d7714728c39a23834cb0fd	wearable chemical sensors: opportunities and challenges	biomedical monitoring;chemicals;data analytics chemical homeostatis glucose measurement interstitial fluid lactate saliva electrolytes building wearable chemical biosensors biosensor functionalization flexible material engineering bioelectronic integration;chemical sensors biosensors;electrochemical sensors wearables biosensors;electrodes;biosensors;biosensors biomedical monitoring chemicals chemical sensors electrodes;chemical sensors	Wearable systems show considerable promise in monitoring and assessing the real-time performance of athletes, the health status of patients, or the general well-being of interested users. Most wearables today focus on monitoring physical parameters (e.g., activity, respiration rate, etc.), or electrophysiology (e.g., ECG, EEG, etc.). In order to augment the richness of collected data, the next-generation of wearables will also be capable of monitoring underlying chemical homeostatis of the user, for example through measurement of glucose in interstitial fluid, lactate in saliva, or electrolytes in sweat. This paper discusses the challenges of building wearable chemical biosensors, including biosensor functionalization, flexible material engineering, bioelectronic integration, and data analytics.	electroencephalography;interstitial webpage;real-time clock;sensor;wearable computer;wearable technology	Somayeh Imani;Patrick P. Mercier;Amay J. Bandodkar;Jayoung Kim;Joseph Wang	2016	2016 IEEE International Symposium on Circuits and Systems (ISCAS)	10.1109/ISCAS.2016.7527442	chemical industry;electrical engineering;electrode;biological engineering;biosensor	Embedded	8.324298847020865	-89.71433794047638	163749
20e7878e05b226b3aff0129809f695174e4045be	shakra: tracking and sharing daily activity levels with unaugmented mobile phones	pilot study;context aware;hidden markov model;clinical trial;mobile phone;task modelling;mobile phones;health promotion;daily activity levels;cell signaling;artificial neural network;activity recognition	This paper explores the potential for use of an unaugmented commodity technology—the mobile phone— as a health promotion tool. We describe a prototype application that tracks the daily exercise activities of people, using an Artificial Neural Network (ANN) to analyse GSM cell signal strength and visibility to estimate a user’s movement. In a short-term study of the prototype that shared activity information amongst groups of friends, we found that awareness encouraged reflection on, and increased motivation for, daily activity. The study raised concerns regarding the reliability of ANN-facilitated activity detection in the ‘real world’. We describe some of the details of the pilot study and introduce a promising new approach to activity detection that has been developed in response to some of the issues raised by the pilot study, involving Hidden Markov Models (HMM), task modelling and unsupervised calibration. We conclude with our intended plans to develop the system further in order to carry out a longer-term clinical trial.	activity recognition;adaptive system;artificial neural network;attachments;categorization;cell signaling;computer monitor;global positioning system;hidden markov model;inference engine;markov chain;maxima and minima;mobile phone;multimodal interaction;multistage interconnection networks;prototype;real-time transcription;resultant;sensor;stationary process;unsupervised learning;video post-processing	Ian Anderson;Julie Maitland;Scott Sherwood;Louise Barkhuus;Matthew Chalmers;Malcolm Hall;Barry A. T. Brown;Henk L. Muller	2007	MONET	10.1007/s11036-007-0011-7	simulation;health promotion;cell signaling;telecommunications;computer science;clinical trial;multimedia;artificial neural network;hidden markov model;activity recognition	HCI	3.665680482304678	-86.01866787597956	164065
86945e23644a55d5bbfec7211b76a223dbe0fe0f	out-of-home activity recognition from gps data in schizophrenic patients	out ofhome mobility;out of home mobility;smart phones;global positioning system geology pipelines clustering algorithms smart phones classification algorithms monitoring;social functioning;smart phones diseases global positioning system medical computing medical disorders mobile computing patient diagnosis pattern classification;schizophrenia;place type classification out of home activity recognition gps data schizophrenic patient psychotic relapse risk social functioning sf smart phone time based method density based method semantic enrichment;geology;monitoring;global positioning system;pipelines;classification algorithms;social functioning smartphone global positioning system out of home mobility schizophrenia;clustering algorithms;smartphone	Risk of psychotic relapse in schizophrenic patients is commonly measured by social functioning (SF), which focuses on patients' daily activities. Monitoring of SF usually relies on infrequent clinic visits, limiting the capacity to detect sudden changes. GPS data that is passively collected with smartphones introduce new opportunities to monitor SF. We conducted a five-day pilot study with five schizophrenic patients to assess the feasibility of this approach. Participants used a smartphone to continuously record their GPS location, and completed a paper-based SF diary to register out-of-home activities. We implemented a time-based method and a density-based method to identify the geolocations visited and then we clustered geolocations visited in places visited. Finally, we used semantic enrichment to classify places types and associated activities. We evaluated the performance of the two approaches by comparing the activities detected from the GPS data with those recorded in the SF diary. Recall was better for the density-based method, ranging from 0.686 (Standard Deviation [SD] 0.168) to 0.771 (SD 0.264) while precision was better for the time-based method (0.722 (SD 0.197) to 0.954 (SD 0.093)). To conclude, using routinely collected GPS data and relatively simple analytical methods we detected patients' out-of-home activities with moderate recall, more sophisticated analytical methods may obtain better performance.	activity recognition;gene ontology term enrichment;global positioning system;smartphone	Sonia Difrancesco;Paolo Fraccaro;Sabine van der Veer;Bader Alshoumr;John D. Ainsworth;Riccardo Bellazzi;Niels Peek	2016	2016 IEEE 29th International Symposium on Computer-Based Medical Systems (CBMS)	10.1109/CBMS.2016.54	statistical classification;embedded system;simulation;global positioning system;computer science;machine learning;schizophrenia;computer security	SE	8.227877255449405	-86.31491296430455	164175
29f39cf8163b4931db9ebb4c94811a95d6d706cb	strength training: a fitness application for indoor based exercise recognition and comfort analysis		Mobile and Wearable health applications are playing a key role in monitoring user fitness data. Current Wearable devices like Fitbit, Jawbone, and Samsung Gear provide solutions for outdoor fitness activities. However a lot of people prefer to do indoor exercises but there are limited auto activity tracking solutions. Existing solutions are not concentrated on the ease at which a user is able to perform an exercise. This work provides automatic indoor exercise recognition for both in gym and home usage scenarios. Activities under consideration are Biceps curl, Chest fly, Row, Push up, Sit up, Squat and Triceps curl. Accuracy of 95.3% and 99.4% is achieved for activity recognition and repetition count respectively. Along with activity recognition this work targets at analyzing comfort and measuring calorie burnt during the exercise. We introduce Comfort factor, which is the state of physical ease during workout. Comfort factor is predicted using the relation devised between Resting Heart Rate (RHR), Maximum Heart Rate (MHR), Real-time heart rate value and hand tremor at exercise exhaustion limit of the user. With this comfort factor, user can decide whether to go for more weights or reduce weights in weight training activities.	activity recognition;algorithm;real-time transcription;samsung gear;squatting attack;wearable computer;curl	Dipankar Das;Shiva Murthy Busetty;Vishal Bharti;Prakhyath Kumar Hegde	2017	2017 16th IEEE International Conference on Machine Learning and Applications (ICMLA)	10.1109/ICMLA.2017.00012	strength training;artificial intelligence;machine learning;activity recognition;wearable computer;human–computer interaction;sit-up;biceps curl;computer science;push-up;squat;wearable technology	HCI	6.525041866165825	-85.09735090660644	164192
b11f8d30175707487f4a9f78ba92a7387dbcfde3	text-tracking wearable camera system for visually-impaired people	quality of life;filtering;wearable computers;cameras layout video sequences speech synthesis prototypes discrete cosine transforms filtering robustness particle tracking system testing;text analysis;tracking filters;wearable computers discrete cosine transforms feature extraction handicapped aids image sequences natural scenes particle filtering numerical methods text analysis tracking filters video cameras;handicapped aids;image edge detection;video cameras;particle filter;discrete cosine transforms;feature extraction;robots;visual impairment;text detection;character recognition;cameras;natural scenes;particle filtering numerical methods;discrete cosine transform text tracking wearable camera system visually impaired people visual text reading disability visually disabled people natural scene video sequence homogeneous text region extraction head mounted video camera particle filtering dct feature;image sequences	Disability of visual text reading has a huge impact on the quality of life for visually disabled people. One of the most anticipated devices is a wearable camera capable of finding text regions in natural scenes and translating the text into another representation such as sound or braille. In order to develop such a device, text tracking in video sequences is required as well as text detection. We need to group homogeneous text regions to avoid multiple and redundant speech syntheses or braille conversions. We have developed a prototype system equipped with a head-mounted video camera. Text regions are extracted from the video frames using a revised DCT feature. Particle filtering is employed for fast and robust text tracking. We have tested the performance of our system using 1,000 video frames of a hall way with eight signboards. The number of text candidate images is reduced to 0.98%.	discrete cosine transform;filter (signal processing);frame (video);particle filter;prototype;signage;speech synthesis;the quality of life;wearable computer	Makoto Tanaka;Hideaki Goto	2008	2008 19th International Conference on Pattern Recognition	10.1109/ICPR.2008.4761548	filter;robot;computer vision;text mining;speech recognition;quality of life;particle filter;wearable computer;feature extraction;computer science;machine learning;noisy text analytics;video tracking;multimedia	Vision	-1.9821285564713813	-81.15570008226459	164598
85ee84a2939de175abb288941da3da309d977a4d	accuracy of a markerless acquisition technique for studying speech articulators		The main disadvantages of the existing methods for studying speech articulators (such as electromagnetic and optoelectronic systems) are the high cost and the discomfort to participants or patients. The aim of this work is to introduce a completely markerless low-cost 3D tracking technique in the context of speech articulation, and then compare it with a wellestablished marker-based one to evaluate the performances. A Kinect-like device was used in conjunction with an existing face tracking algorithm to track lips movements in 3D without markers. The method was tested on two subjects uttering 200 words and 100 sentences. For most of points of the lips the RMSE ranged between 1 and 3 mm. Although the image resolution used in this experiment was low, these results are very promising. Nevertheless, further studies should consider higher video resolutions in order to obtain better results.	algorithm;biconnected component;image resolution;kinect;performance	Andrea Bandini;Slim Ouni;Piero Cosi;Silvia Orlandi;Claudia Manfredi	2015			speech recognition;acquisition technique;computer science	HCI	8.99883636222563	-83.55012029902655	165028
5a7b6c59b3f0a3c07df1b6b9bf3de54b015d4945	cost effective ultrasound imaging training mentor for use in developing countries		This paper reports on a low cost system for training ultrasound imaging techniques. The need for such training is particularly acute in developing countries where typically ultrasound scanners remain idle due to the lack of experienced sonographers. The system described below is aimed at a PC platform but uses interface components from the Nintendo Wii games console. The training software is being designed to support a variety of patient case studies, and also supports remote tutoring over the internet.	imaging techniques;interface device component;medical ultrasound;patients;personal computer;wii remote plus	Llyr ap Cenydd;Nigel W. John;Franck Patrick Vidal;Derek Gould;Elizabeth Joekes;Peter Littler	2009	Studies in health technology and informatics	10.3233/978-1-58603-964-6-49	the internet;simulation;software;ultrasound;developing country;medicine;idle	HCI	9.77004390546169	-87.75686117645944	165088
bf515303ff287628f3b9bbfb699e16fe7d7d2640	ubiband: a framework for music composition with bsns	software;music composition;body sensor networks;software platform;real time;wearable sensors tracking body sensor networks wireless sensor networks hardware application software software prototyping cameras sensor systems signal mapping;mapping rules;conceptual framework;wireless communication;ubiband;three dimensional displays;motion generated music application;wireless sensor networks music real time systems;feature extraction;body sensor networks motion based music composition ubiband;sensor enabled music generation;motion based music composition;accelerometers;music;initial software prototype;wireless sensor networks;real time percussion kit;real time percussion kit ubiband music composition body sensor networks software platform sensor enabled music generation motion generated music application initial software prototype mapping rules;body sensor network;real time systems	This paper presents a conceptual framework, as well as a software platform for assisting the development of sensor enabled music generation using Body Sensor Networks (BSNs). It provides a summary of key considerations that should be taken into account during the development of a motion-generated music application and presents the initial software prototype. A set of mapping rules for real-time BSN-based percussion kit has been proposed and used to demonstrate the practical value of the proposed framework design.	data acquisition;interactivity;prototype;real-time transcription;software prototyping	Sarit Chantasuban;Surapa Thiemjarus	2009	2009 Sixth International Workshop on Wearable and Implantable Body Sensor Networks	10.1109/BSN.2009.9	embedded system;real-time computing;simulation;feature extraction;computer science;operating system;music;conceptual framework;musical composition	Mobile	2.3779231756298183	-89.83794479583386	165308
f145db3ffca5ae00b09eb94efdacf8a6f7bf73f9	a novel method for inferring rfid tag reader recordings into clinical events	intensive care unit;proximity sensing;active radio frequency identification;nosocomial infections	BACKGROUND Nosocomial infections (NIs) are among the important indicators used for evaluating patients' safety and hospital performance during accreditation of hospitals. NI rate is higher in Intensive Care Units (ICUs) than in the general wards because patients require intense care involving both invasive and non-invasive clinical procedures. The emergence of Superbugs is motivating health providers to enhance infection control measures. Contact behavior between health caregivers and patients is one of the main causes of cross infections. In this technology driven era remote monitoring of patients and caregivers in the hospital setting can be performed reliably, and thus is in demand. Proximity sensing using radio frequency identification (RFID) technology can be helpful in capturing and keeping track on all contact history between health caregivers and patients for example.   OBJECTIVES This study intended to extend the use of proximity sensing of radio frequency identification technology by proposing a model for inferring RFID tag reader recordings into clinical events. The aims of the study are twofold. The first aim is to set up a Contact History Inferential Model (CHIM) between health caregivers and patients. The second is to verify CHIM with real-time observation done at the ICU ward.   METHOD A pre-study was conducted followed by two study phases. During the pre-study proximity sensing of RFID was tested, and deployment of the RFID in the Clinical Skill Center in one of the medical centers in Taiwan was done. We simulated clinical events and developed CHIM using variables such as duration of time, frequency, and identity (tag) numbers assigned to caregivers. All clinical proximity events are classified into close-in events, contact events and invasive events. During the first phase three observers were recruited to do real time recordings of all clinical events in the Clinical Skill Center with the deployed automated RFID interaction recording system. The observations were used to verify the CHIM recordings. In second phase the first author conducted 40 h of participatory observation in the ICU, and observed values that were used as golden standard to validate CHIM.   RESULTS There were a total of 193 events to validate the CHIM in the second phase. The sensitivity, specificity, and accuracy of close-in events were 73.8%, 83.8%, and 81.6%; contact events were 81.4%, 78.8%, and 80.7%; and invasive events were 90.9%, 98.0%, and 97.5% respectively.   CONCLUSION The results of the study indicated that proximity sensing of the RFID detects proximity events effectively, and the CHIM can infer proximity events accurately. RFID technology can be used for recording complete clinical contact history between caregivers and patients thus assisting in tracing cause of NIs. Since this model could infer the ICU activities accurately, we are convinced that the CHIM can also be applied in other wards and can be used for additional purposes.		Yung-Ting Chang;Syed Abdul Shabbir;Chung-You Tsai;Yu-Chuan Li	2011	International journal of medical informatics	10.1016/j.ijmedinf.2011.09.006	simulation;medicine;telecommunications	HCI	6.645018841447309	-86.31971224019352	165389
ae6832e83a414b5e69d7785324a886c9f9869984	chord detection using deep learning		In this paper, we utilize deep learning to learn high-level features for audio chord detection. The learned features, obtained by a deep network in bottleneck architecture, give promising results and outperform state-of-the-art systems. We present and evaluate the results for various methods and configurations, including input pre-processing, a bottleneck architecture, and SVMs vs. HMMs for chord classification.	deep learning;high- and low-level;preprocessor	Xinquan Zhou;Alexander Lerch	2015			deep learning;machine learning;speech recognition;chord (music);computer science;artificial intelligence	ML	-4.1963397969363125	-87.30191969562014	165614
17607254afb68fe838595863e7e26b4a0b050130	more data matters: improving cgm prediction via ubiquitous data and deep learning		Diabetes mellitus is a common disease in today's population, where the insulin control system fails. It can be harmful for the patient when not treated appropriately with insulin injections. The complex functionality of the human body paired with very individual circumstances make this a hard task, even for committed patients. Modern sensor technology and personal monitoring equipment such as smartphones can help us retrieve more information about the patients blood glucose level and their habits regarding food intake and physical activities. Based on this information, we propose an assisting system giving the patient helpful advice by predicting the blood glucose level for the near future and incorporating their activities and heart rate. Deep convolutional neural networks will be used for learning the glucose level predictor. In our evaluation we see moderate improvements towards existing systems, which we think can be further improved when using more data.	activity tracker;artificial neural network;control system;convolutional neural network;cyclic redundancy check;deep learning;job control (unix);kerrison predictor;mean squared error;norm (social);population;smartphone;time series	Jens Heuschkel;Sebastian Kauschke	2018		10.1145/3267305.3274132	convolutional neural network;human–computer interaction;health care;disease;artificial neural network;deep learning;insulin;computer science;population;artificial intelligence;diabetes mellitus	HCI	4.899744066668638	-82.97208980482846	165784
22cd72c126029ed350bd060c45d4f79c39a9f15b	wireless black box using mems accelerometer and gps tracking for accidental monitoring of vehicles	microcontrollers;wireless devices;tracking system;computer crashes;cellular radio;real time;mobile handsets accelerometers accidents cellular radio emergency services global positioning system microcontrollers micromechanical devices;hospitals;acceleration;mobile phone;accuracy;real world application;micromechanical devices;accidents;global positioning system;airplanes;mobile handsets;emergency medical service;accelerometers;normal ride detection wireless black box mems accelerometer gps tracking system vehicle accidental monitoring cooperative components microcontroller unit gps device gsm module wireless device mobile phone vehicle position emergency medical service ems threshold algorithm motorcycle speed bicycles linear fall detection nonlinear fall detection;acceleration accidents accelerometers computer crashes accuracy hospitals airplanes;emergency services	In this work, wireless black box using MEMS accelerometer and GPS tracking system is developed for accidental monitoring. The system consists of cooperative components of an accelerometer, microcontroller unit, GPS device and GSM module. In the event of accident, this wireless device will send mobile phone short massage indicating the position of vehicle by GPS system to family member, emergency medical service (EMS) and nearest hospital. The threshold algorithm and speed of motorcycle are used to determine fall or accident in real-time. The system is compact and easy to install under rider seat. The system has been tested in real world applications using bicycles. The test results show that it can detect linear fall, non-linear fall and normal ride with high accuracy.	algorithm;black box;error-tolerant design;gps navigation device;gps tracking unit;global positioning system;microcontroller;microelectromechanical systems;mobile phone;nonlinear system;poor posture;real-time transcription;tracking system	Natthapol Watthanawisuth;Tanom Lomas;Adisorn Tuantranont	2012	Proceedings of 2012 IEEE-EMBS International Conference on Biomedical and Health Informatics	10.1109/BHI.2012.6211718	embedded system;simulation;engineering;assisted gps;computer security;gps tracking server	Robotics	7.130359636266484	-88.25465804699088	165955
df8dba6f8c1c08ab631ea447722d325b768a1a49	fall detector based on neural networks	neural network	Falls are one of the biggest concerns of elderly people. This paper addresses a fall detection system which uses an accelerometer to collect body accelerations, ZigBee to send relevant data when a fall might have happened and a neural network to recognize fall patterns. This method presents improved performance compared to traditional basic-threshold systems. Main advantage is that fall detection ratio is higher on neural network based systems. Another important issue is the high immunity to events not being falls, but with similar patterns (e.g. sitting in a sofa abruptly), usually confused with real falls. Minimization of these occurrences has big influence on the confidence the user has on the system.	asymmetric digital subscriber line;embedded system;entity–relationship model;field-programmable gate array;memory-level parallelism;microcontroller;mobile device;neural networks	Rubén Blasco Marín;Roberto Casas;Álvaro Marco;Victorián Coarasa;Yolanda Garrido;Jorge L. Falcó	2008			probabilistic neural network;types of artificial neural networks;computer science;machine learning;physical neural network;time delay neural network;artificial neural network	Robotics	4.650258841877284	-83.83553533967202	166109
b9605e06f62d254767ca1cf3023a2726cd6ef086	defining adherence: making sense of physical activity tracker data		Increasingly, people are collecting detailed personal activity data from commercial trackers. Such data should be able to give important insights about their activity levels. However, people do not wear or carry tracking devices all day, every day and this means that tracker data is typically incomplete. This paper aims to provide a systematic way to take account of this incompleteness, by defining adherence, a measure of data completeness, based on how much people wore their tracker. We show the impact of different adherence definitions on 12 diverse datasets, for 753 users, with over 77,000 days with data, interspersed with over 73,000 days without data. For example, in one data set, one adherence measure gives an average step count of 6,952 where another gives 9,423. Our results show the importance of adherence when analysing and reporting activity tracker data. We provide guidelines for defining adherence, analysing its impact and reporting it along with the results of the tracker data analysis. Our key contribution is the foundation for analysis of physical activity data, to take account of data incompleteness.	activity tracker;aggregate data	Lie Ming Tang;Jochen Meyer;Daniel A. Epstein;Kevin Bragg;Lina Engelen;Adrian Bauman;Judy Kay	2018	IMWUT	10.1145/3191769	data mining;bittorrent tracker;activity tracker;computer science	HCI	7.706635955120951	-84.91375160010482	166597
918425e219bd53099496322b1aaf6b5c8e098990	sensor fusion for remote health assessment of first responders	timely detection;automated anomaly detection;cardiac patient;improved performance;application find;remote physiological monitoring;multiple physiological parameter;overall performance;novel sensor fusion software;remote health assessment;commercial physiological monitoring system;susceptible senior population;commercial physiological monitoring hardware;harmful cardiac event;anomaly detection;sensor fusion;signal processing;software integration	Remote physiological monitoring of first responders can become instrumental in the quick and timely detection of the onset of harmful cardiac events. This application finds use not only for first responders but for the physically susceptible senior population and recovering cardiac patients. Fusion of multiple physiological parameters has the potential to improve the overall performance of automated anomaly detection. In this demonstration, we demonstrate the improved performance achieved through the use of novel sensor fusion software integrated with a commercial physiological monitoring hardware system.	anomaly detection;onset (audio);sensor web	Tejaswi Tamminedi;Lei Zhang;Priya Ganapathy	2011		10.1145/2077546.2077581	engineering;biological engineering;computer security;remote sensing	Mobile	9.239522334829834	-87.79730503333494	166706
7e896b81a403c2df02fad53b14df7b76f76a72b3	cognitive load measurement - a methodology to compare low cost commercial eeg devices	cognitive load low cost eeg neurosky emotiv;electroencephalography brain computer interfaces cognition;cognitive load detection cognitive load measurement eeg signals brain computer interfacing technology low cost commercial eeg devices medical grade eeg devices low cost wireless eeg headsets bci emotiv neurosky;electroencephalography usability wireless communication performance evaluation indexes frequency modulation	Use of EEG signals in measuring cognitive load is a widely practiced area and falls under Brain-Computer-Interfacing (BCI) technology. However this technology uses medical grade EEG devices that are expensive as well as not user-friendly for regular use. Recent launch of low cost wireless EEG headsets from different companies opens up the possibility for commercialization of BCI and thus drew attention of the research community all over the world. While there are numerous studies on BCI with the use of medical grade devices there are limited numbers of papers reported on those using low cost devices. Moreover, reports on evaluating relative performance of these commercially available EEG devices based on a specific BCI experiment are minuscule. This paper attempts to fill this gap and presents a methodology to compare with various aspects between two widely used low cost wireless EEG devices namely Emotiv and Neurosky for application in cognitive load detection.	brain–computer interface;computation;computational complexity theory;electroencephalography;emotiv systems;informatics;usability	Rajat Das;Debatri Chatterjee;Diptesh Das;Arijit Sinharay;Aniruddha Sinha	2014	2014 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2014.6968528	electronic engineering;simulation;computer science	Mobile	8.714206886422675	-90.88178807057545	166745
d7c279661dcb2c83ee63f149db3be7f0771237f5	3d head pose and gaze tracking and their application to diverse multimodal tasks	hci;speech;hri;hhi;head pose tracking;gaze estimation	In this PhD thesis the problem of 3D head pose and gaze tracking from minimal user cooperation is addressed. By exploiting characteristics of RGB-D sensors, contributions have been made related to consequent problems of the lack of cooperation: in particular, head pose and inter-person appearance variability; in addition to low resolution handling. The resulting system enabled diverse multimodal applications. In particular, recent work combined multiple RGB-D sensors to detect gazing events in dyadic interactions.  The research plan consists of: i) Improving the robustness, accuracy and usability of the head pose and gaze tracking system; ii) To use additional multimodal cues, such as speech and dynamic context, to train and adapt gaze models in an unsupervised manner; iii) To extend the application of 3D gaze estimation to diverse multimodal applications. This includes visual focus of attention tasks involving multiple visual targets, e.g.~people in a meeting-like setup.	dyadic transformation;eye tracking;heart rate variability;image resolution;multimodal interaction;sensor;tracking system;unsupervised learning;usability	Kenneth Alberto Funes Mora	2013		10.1145/2522848.2532192	computer vision;simulation;computer science;speech;linguistics	Robotics	-0.6316839356689472	-84.25891740705043	166936
310f61e506e28b7af222d46ca24f2661a19aa135	an operantly conditioned looking task for assessing infant auditory processing ability	operant conditioning;early assessment;auditory processing;infant computer interaction;eye movement;language impairment;eye tracking	In this paper, we describe the design and evaluation of a gaze-driven interface for the assessment of rapid auditory processing abilities in infants aged 4 to 6 months. A cross-modal operant conditioning procedure is used to reinforce anticipatory eye movements in response to changes in a continuous auditory stream. Using this procedure, we hope to develop a clinical tool that will enable early identification of individuals at risk for language-based learning impairments. Some of the unique opportunities and challenges inherent to designing for infant-computer interaction are discussed.	modal logic;streaming media	Jason Nawyn;Cynthia Roesler;Teresa Realpe-Bonilla;Naseem Choudhury;April A. Benasich	2007		10.1145/1296843.1296869	eye tracking;operant conditioning;eye movement	ML	8.700077368330277	-91.93761865509849	167255
e867aa457b42b6ca9e8f2b63dbd09880e174d7e7	clustering of physical activities for quantified self and mhealth applications	biomedical monitoring;sensors;pattern clustering accelerometers cardiology feature extraction feature selection medical computing mobile computing;frequency domain analysis;accelerometers biomedical monitoring monitoring feature extraction frequency domain analysis data mining sensors;data mining;qa75 electronic computers computer science;monitoring;feature extraction;heart rate quantified self mhealth physical activity clustering;accelerometers;hca method quantified self applications m health applications wearable sensing devices physical activity clustering accelerometer heart rate data wearable devices heart rate monitor data preprocessing feature selection feature extraction hierarchical clustering analysis k means clustering analysis	The explosion of smaller and more powerful wearable sensing devices has allowed us to continually record and quantify our lives. Undertaking such activities is becoming very popular and has grown into a community called the Quantified Self (QS). Utilizing this outlet has the potential to benefit many aspects of our lives and is gaining momentum within the health sector. However, whilst we can easily collect data, interpreting this information is more challenging. Without extensive data analysis, this information is essentially meaningless in its raw form. This paper posits an approach to quantify and cluster levels of physical activity from accelerometer and heartrate data, which has been obtained from four wearable devices (3 accelerometers and 1 hear rate monitor). The approach details our method for pre-processing the data, extracting and selecting the features and a comparison between hierarchical clustering analysis (HCA) and k-means. The results illustrate that, whilst both methods are capable of successfully separating the data, the k-means approach out-performed the HCA method at clustering the data.	cluster analysis;hierarchical clustering;k-means clustering;mhealth;preprocessor;quantified self;wearable computer;wearable technology;while	Chelsea Dobbins;Reza Rawassizadeh	2015	2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing	10.1109/CIT/IUCC/DASC/PICOM.2015.213	embedded system;feature extraction;computer science;sensor;data science;machine learning;data mining;frequency domain;accelerometer	Visualization	7.295828715410405	-86.87331987534972	167652
b3b98cb2e893bc1aeb74468650fb7f69a30c74a0	physiological data stream from monitoring system in intensive care unit		In this paper, we propose a new system that takes profits of data stream technology. It aims to collect and store data arriving from monitoring system in intensive care unit (ICU). Then, it makes it available for the medical staff to analyze data and take the appropriate treatment for patients. In fact, monitoring system in ICU provides a large amount of data rapidly and continuously. Most of devices work with a very limited storage capacity which can make data available for only a limited time. To avoid loosing data, medical staff takes note from monitoring devices each time interval then, stores it using computer. However, the decisions taken by doctors can be influenced by the level of consistency of the collected data. In some cases, these decisions can be inaccurate especially if important information are not saved and ignored. Our proposed system improves the quality of monitoring by processing the monitor data at real time. It collects and stores all data reported from the monitoring devices avoiding the loss of important information. The new system will make data available for medical staff in order to provide a better care for patients.	granada;international components for unicode	Fahmi Ben Rejab;Kaouther Nouira;Bilel Amri	2014			embedded system;real-time computing;medicine;data mining	ML	5.6520031605374195	-88.40219734979638	167734
8ee1a65075ccaf064631f3b1e321a9c386b08066	the motion influence on respiration rate estimation from low-resolution thermal sequences during attention focusing tasks		Global aging has led to a growing expectancy for creating home-based platforms for indoor monitoring of elderly people. A motivation is to provide a non-intrusive technique, which does not require special activities of a patient but allows for remote monitoring of elderly people while assisting them with their daily activities. The goal of our study was to evaluate motion performed by a person focused on a specific task and check if this motion disrupts estimation of respiration rate. The preliminary results show that it is possible to reliable estimate respiration rate by focusing attention of a patient on a certain activity. The respiratory rate analyzed for silent reading task was estimated with mean error 0.27 breaths per minute (bpm), while for reading aloud task with 1.18 bpm. The observed head motion during the reading aloud task was 1.5 higher that for silent reading and about two times smaller for a case in which subjects were not focused on any task.	patients;portion of respiratory air;respiratory rate;think aloud protocol;twice (numerical qualifier);breaths per minute	Alicja Kwasniewska;Jacek Ruminski;Jerzy Wtorek	2017	2017 39th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2017.8037100	speech recognition;focusing attention;computer vision;simulation;respiration rate;respiratory rate;computer science;artificial intelligence;activities of daily living;expectancy theory	Visualization	9.278718848631506	-86.47838201474043	168196
3470ff86bfe43ef0cf240d68af06c1546b24cf1e	a probabilistic approach for detection and analysis of cognitive flow		A performer may undergo a task with varying difficulty level. It is important to know the mental state in order to maintain the optimum level of performance. The mental state of an individual varies according to their IQ levels, task difficulties or other psychological or environmental reasons. We have tried to measure the cognitive state of individuals, while they are performing tasks of various complexity levels, using physiological responses like brain activation, heart rate variability and galvanic skin response. In this paper we have proposed a Bayesian network based model to probabilistically evaluate the cognitive state of an individual from the difficulty levels of the tasks, IQ level of the individual and observations made using the physiological sensing. Twenty subjects with various IQ levels are asked to play a modified Tower of London (TOL) game having three complexity levels: low, medium and high. The sensor data collected have been used to train the Bayesian model for generating the conditional probability distribution for the desired cognitive state. Results show that it can be used as a tool to determine the current cognitive state of any individual, provided we know their IQ score. In case of any contradiction between the desired cognitive state (obtained from prior knowledge) and the observed cognitive state (obtained during testing), the personal insights of a performer is	bayesian network;electroencephalography;experiment;galvanic isolation;graphical model;heart rate variability;mental state	Debatri Chatterjee;Aniruddha Sinha;Meghamala Sinha;Sanjoy Kumar Saha	2016			machine learning;probabilistic logic;computer science;artificial intelligence;cognition	HCI	1.0255367189646603	-86.05879500713574	168258
f063801ad33913f849c904ceb0f67aa04bf08656	indoor anti-collision alarm system based on wearable internet of things for smart healthcare		Smart healthcare, instead of traditional healthcare, has attracted tremendous attention all over the world, and calls for integrated design bringing together interdisciplinary technological approaches and solutions with the aim of supporting affordable and high-quality patient care. With the increasing number of visually impaired people, including the blind, the elderly, and patients with eye diseases, it is vital to help them explore their outside environment with the assistance of smart technologies so that they can adapt to the environment more easily. The smart indoor anti-collision system is one typical application. Previous works normally use video monitors or deployed sensors to provide outside environment information for visually impaired people. However, these methods suffer from privacy disclosure and inconvenience. In this article, we present IAAS, a smart indoor anti-collision system based on RFID, which identifies and tracks passive RFID tags by analyzing the received backscatter signals. We extract RSSI based on the LWLR algorithm and phase profiles as fingerprints to help the user guide from obstacles without observations of eyes. Experiments are conducted to verify our system, and results show that IAAS could achieve high accuracy of 94 percent in obstacle avoidance.	algorithm;cloud computing;display device;experiment;fingerprint;internet of things;obstacle avoidance;radio-frequency identification;sensor	Fu Xiao;Qianwen Miao;Xiaohui Xie;Lijuan Sun;Ruchuan Wang	2018	IEEE Communications Magazine	10.1109/MCOM.2018.1700706	collision;computer network;wearable computer;integrated design;human–computer interaction;remote patient monitoring;health care;computer science;alarm;obstacle avoidance;internet of things	HCI	4.701587850998357	-88.4781633372671	168514
4129f632822668ae352cdf66566905abf2af2100	at the flick of a switch: detecting and classifying unique electrical events on the residential power line (nominated for the best paper award)	vision system;power line;system performance;machine learning;active sensing;home automation	Activity sensing in the home has a variety of important applications, including healthcare, entertainment, home automation, energy monitoring and post-occupancy research studies. Many existing systems for detecting occupant activity require large numbers of sensors, invasive vision systems, or extensive installation procedures. We present an approach that uses a single plug-in sensor to detect a variety of electrical events throughout the home. This sensor detects the electrical noise on residential power lines created by the abrupt switching of electrical devices and the noise created by certain devices while in operation. We use machine learning techniques to recognize electrically noisy events such as turning on or off a particular light switch, a television set, or an electric stove. We tested our system in one home for several weeks and in five homes for one week each to evaluate the system performance over time and in different types of houses. Results indicate that we can learn and classify various electrical events with accuracies ranging from 85-90%.	home automation;machine learning;network switch;noise (electronics);plug-in (computing);sensor;software deployment;television set	Shwetak N. Patel;Thomas Robertson;Julie A. Kientz;Matthew S. Reynolds;Gregory D. Abowd	2007		10.1007/978-3-540-74853-3_16	embedded system;home automation;simulation;machine vision;computer science;operating system;machine learning;computer performance;computer security	HCI	3.6507420235414973	-86.84008836736506	169496
d92c1d5f6677f21f6d6affbead06f86801304c34	indoor activity recognition by combining one-vs.-all neural network classifiers exploiting wearable and depth sensors	one vs all binary classifier fusion;smart home;wireless sensors;artificial neural networks;depth sensors;activity recognition	Activity recognition has recently gained a lot of interest and appears to be a promising approach to help the elderly population pursue an independent living. There already exist several methods to detect human activities based either on wearable sensors or on cameras but few of them combine the two modalities. This paper presents a strategy to enhance the robustness of indoor human activity recognition by combining wearable and depth sensors. To exploit the data captured by those sensors, we used an ensemble of binary one-vs-all neural network classifiers. Each activity-specific model was configured to maximize its performance. The performance of the complete system is comparable to lazy learning methods (k-NN) that require the whole dataset.	activity recognition;artificial neural network;sensor;wearable computer	Benoît Delachaux;Julien Rebetez;Andrés Pérez-Uribe;Héctor Fabio Satizábal Mejia	2013		10.1007/978-3-642-38682-4_25	home automation;computer science;artificial intelligence;machine learning;data mining;artificial neural network;activity recognition	HCI	4.211275628115618	-84.44620171204905	169528
6f7616aa37dbda73c34336b6f47acfff12be4964	system for monitoring and supporting the treatment of sleep apnea using iot and big data		Abstract Sleep apnea has become in the sleep disorder that causes greater concern in recent years due to its morbidity and mortality, higher medical care costs and poor people quality of life. Some proposals have addressed sleep apnea disease in elderly people, but they have still some technical limitations. For these reasons, this paper presents an innovative system based on fog and cloud computing technologies which in combination with IoT and big data platforms offers new opportunities to build novel and innovative services for supporting the sleep apnea and to overcome the current limitations. Particularly, the system is built on several low-power wireless networks with heterogeneous smart devices (i.e, sensors and actuators). In the fog, an edge node (Smart IoT Gateway) provides IoT connection and interoperability and pre-processing IoT data to detect events in real-time that might endanger the elderly’s health and to act accordingly. In the cloud, a Generic Enabler Context Broker manages, stores and injects data into the big data analyzer for further processing and analyzing. The system’s performance and subjective applicability are evaluated using over 30 GB size datasets and a questionnaire fulfilled by medicals specialist, respectively. Results show that the system data analytics improve the health professionals’ decision making to monitor and guide sleep apnea treatment, as well as improving elderly people’s quality of life.	big data;sleep mode	Diana C. Yacchirema;David Sarabia-Jacome;Carlos E. Palau;Manuel Esteve	2018	Pervasive and Mobile Computing	10.1016/j.pmcj.2018.07.007	computer network;wireless network;interoperability;big data;sleep disorder;cloud computing;sleep apnea;data analysis;default gateway;computer science	Mobile	4.576586970578236	-87.92364231592869	169585
e50e76e8a00dacf9d62172116440857d4c915520	a smart safety helmet using imu and eeg sensors for worker fatigue detection	imu;risk analysis accident prevention biomedical electrodes brain cameras electroencephalography haptic interfaces injuries man machine systems medical signal detection medical signal processing;human machine interaction smart safety helmet imu eeg sensors worker fatigue detection head gesture brain activity human behaviors accident camera injuries ssh system nonintrusive system noninvasive system nonvision based system inertial measurement unit dry eeg electrodes haptic device vibrotactile motor risk level computed head motion recognition;safety;electroencephalography accidents sensors safety fatigue magnetic heads acceleration;eeg;head motion recognition;accident avoidance;human machine interaction safety head motion recognition imu eeg accident avoidance;human machine interaction	It is known that head gesture and brain activity can reflect some human behaviors related to a risk of accident when using machine-tools. The research presented in this paper aims at reducing the risk of injury and thus increase worker safety. Instead of using camera, this paper presents a Smart Safety Helmet (SSH) in order to track the head gestures and the brain activity of the worker to recognize anomalous behavior. Information extracted from SSH is used for computing risk of an accident (a safety level) for preventing and reducing injuries or accidents. The SSH system is an inexpensive, non-intrusive, non-invasive, and non-vision-based system, which consists of an Inertial Measurement Unit (IMU) and dry EEG electrodes. A haptic device, such as vibrotactile motor, is integrated to the helmet in order to alert the operator when computed risk level (fatigue, high stress or error) reaches a threshold. Once the risk level of accident breaks the threshold, a signal will be sent wirelessly to stop the relevant machine tool or process.	algorithm;artificial intelligence;electroencephalography;haptic technology;optic axis of a crystal;robot;sensor	Ping Li;Ramy Meziane;Martin J.-D. Otis;Hassan Ezzaidi;Philippe Cardou	2014	2014 IEEE International Symposium on Robotic and Sensors Environments (ROSE) Proceedings	10.1109/ROSE.2014.6952983	embedded system;computer vision;simulation;engineering	Robotics	9.72935035166332	-86.0438377703537	169598
157acab47583d2ddd71507df7159e18a1d04d0ec	an efficient method for sign language recognition from image using convolutional neural network		Recognition of the sign language is one of the most important milestone in image recognition field. Such systems can help deaf people to communicate with the world. We feel privileged to present a new method which translates from American Sign Language (ASL) fingerspelling into a letter using Convolutional Neural Network and transfer learning. The method is using Google pre-trained model named MobileNet V1 which was trained on the ImageNet image database. Our model was trained on the dataset from Surrey University. We developed a useful model not only for desktop computers but it is also possible to apply it into mobile systems, because of low memory consumption.	convolutional neural network;language identification	Sebastian Kotarski;Bernadetta Maleszka	2018		10.1007/978-3-319-98678-4_12	convolutional neural network;speech recognition;transfer of learning;deep learning;fingerspelling;american sign language;sign language;computer science;artificial intelligence	Vision	-1.9469152579898448	-82.3235772861128	169656
286407b3b497aa0cef25f5eb254f7a73064eb478	analyzing human behavioral data to interact with restaurant server agents	cognitive system;pattern extraction	In this paper, we consider a problem of analyzing human behavioral data to predict the human cognitive states and generate corresponding actions of sever-agent. Specifically, we aim at predicting human cognitive states during meal time and generating relevant dining services for the human. For this study, we collect behavioral data using 2 kinds of wearable devices, which are an eye tracker and a watch type EDA device, during meal time. We focus on the characteristics of the behavioral data, which are heterogeneous, noisy and temporal, and suggest a novel machine learning algorithm which can analyze the data integrally. Suggested model has hierarchical structure: the bottom layer combines the multi-modal behavioral data based on causal structure of the data and extracts the feature vector. Using the extracted feature vectors, the upper layer predicts the cognitive states based on temporal correlation between feature vectors. Experimental results show that the suggested model can analyze the behavioral data efficiently and predict the human cognitive states correctly.	algorithm;causal filter;eye tracking;feature vector;machine learning;modal logic;wearable technology	Eun-Sol Kim;Kyoung-Woon On;Byoung-Tak Zhang	2015		10.1145/2814940.2815013	simulation;computer science;data mining;communication	ML	1.7533918038450693	-86.08462891228224	169663
23472258e48cfa005d24a6cabf5a2c3cd485d452	physical activity classification meets daily life: review on existing methodologies and open challenges	accelerometers three dimensional displays observers protocols monitoring gold standards;smart phones accelerometers biomems body sensor networks gait analysis health care medical signal processing patient monitoring signal classification;real life conditions physical activity classification mems devices miniature motion capturing devices smartphones personal health care physical activity monitoring daily life settings wearable accelerometers objective measure pa classification system	Recent advances in the MEMS devices make it happen to wirelessly integrate miniature motion capturing devices with Smartphones and to use them in personal health care and physical activity monitoring in daily life. There is no ground truth, though, to measure the physical activity (PA) in daily life and because of this, there is no common validation procedure adapted by the researchers for benchmarking the performance of algorithms for PA classification. The major issue in the existing studies for PA classification is the utilization of structured protocol in a controlled setting or simulated daily environment, which limits their implementation in real life conditions where activities are unplanned and unstructured, both in occurrence and in duration. This study provides a critical review on the validation procedures used for PA classification, types of activities classified and limitations in the exiting studies to implement them in daily life settings. Only those studies are considered which classify PA based on wearable accelerometers as an objective measure. The pros and cons of existing methodologies are highlighted and future possibilities are addressed for the development of a robust PA classification system which is feasible under real life conditions.	algorithm;exercise;ground truth;health care;medication event monitoring system;microelectromechanical systems;motion capture;physical symbol system;real life;smartphone;statistical classification;wearable computer;accelerometers	Muhammad Awais;Sabato Mellone;Lorenzo Chiari	2015	2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2015.7319526	embedded system;simulation;engineering;biological engineering	SE	7.723054578184225	-85.35794290137663	169789
4a4de6d788a1077a78883d87f5e1158b79126bee	perceptual and bitrate-scalable coding of haptic surface texture signals	video coding audio coding codecs data compression haptic interfaces;codecs;speech coding;surface texture;perceptual coding data compression haptic textures;bit rate;bitrate scalable haptic texture codec haptic surface texture signals bitrate scalable coding perceptual coding contact based haptic media video streams audio streams audio data compression wideband vibrotactile signals;haptic interfaces codecs noise bit rate surface texture speech coding;haptic interfaces;noise	Applications involving indirect interpersonal communication, such as collaborative design/assembly/exploration of physical objects, can benefit strongly from the transmission of contact-based haptic media, in addition to the more traditional audiovisual media. Inclusion of haptic media has been shown to improve immersiveness, task performance, and the overall experience of task execution. While several decades of research have been dedicated to the acquisition, processing, coding, and display of audio and video streams, similar aspects for haptic streams have been addressed only recently. Simultaneous masking is a perceptual phenomenon widely exploited in the compression of audio data. In the first part of this paper, to the best of our knowledge, we present first-time empirical evidence for masking in the perception of wideband vibrotactile signals. Our results show that this phenomenon for haptics is very similar to its auditory analog. Signals closer in frequency to a powerful masker ( 25 dB above detection threshold) are masked more strongly (peak threshold-shifts of up to 28 dB) than those away from the masker (threshold-shifts of 15-20 dB). The masking curves approximately follow the masker's spectral profile. In the second part of this paper, we present a bitrate scalable haptic texture codec, which incorporates the masking model and describe its subjective and objective performance evaluation. Experiments show that we can drive down the codec output bitrate to a very low value of 2.3 kbps, without the subjects being able to reliable discriminate between the codec input and distorted output texture signals.	codec;data rate units;distortion;experiment;haptic technology;performance evaluation;scalability;streaming media;unsharp masking	Rahul Gopal Chaudhari;Clemens Schuwerk;Mojtaba Danaei;Eckehard G. Steinbach	2015	IEEE Journal of Selected Topics in Signal Processing	10.1109/JSTSP.2014.2374574	surface finish;sub-band coding;computer vision;codec;computer science;noise;speech coding;multimedia	Visualization	2.641106118703422	-94.0789214415497	169879
6ec398d64a732f0dc25af5628f8859ebba1dc36f	prevent cooking risks in kitchen of elderly people: adaptable reasoning engine based on fuzzy logic for smart oven	senior citizens;elderly people reasoning engine fuzzy logic risk hazard cooking safety;temperature sensors;monitoring;ovens;cognition;risk severity cooking risk prevention adaptable reasoning engine smart oven kitchen safety elderly people cooking safe system fuzzy logic based reasoning engine risk situation detection;fires;fires senior citizens ovens temperature sensors monitoring cognition;risk analysis assisted living domestic safety fuzzy reasoning geriatrics ovens	Enabling kitchen safety is crucial for elderly people independent living. Cooking, usually, is accompanied with several risks particularly for elderly people, due to aging associated impairments. Therefore, cooking-safe environment is required to enhance safety of elderly people. This is the motivation behind our research work on building a cooking-safe system. In this paper, we present the fuzzy-logic based reasoning engine used for our cooking-safe system. The reasoning engine manages the detection of risk situations and determines their severity levels according to the contextual information around oven. In this study, we have considered three levels of risk severity based on experimentally determined threshold values.	experiment;fuzzy logic;semantic reasoner	Bessam Abdulrazak;Rami Yared	2015	2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing	10.1109/CIT/IUCC/DASC/PICOM.2015.321	simulation;cognition	Vision	6.897761173794776	-83.64688401804933	169930
566ccd6e79632e5ae116c1e3969240163c9ee413	verification of daily activities of older adults: a simple, non-intrusive, low-cost approach	verification;sensors;pervasive computing;routines;signal detection theory;older adults;activities of daily living;activity recognition	This paper presents an approach to verifying the activities of daily living of older adults at their home. We verify activities, instead of inferring them, because our monitoring approach is driven by routines, initially sketched by users in their environment. Monitoring is supported by a lightweight sensor infrastructure, comprising non-intrusive, low-cost, wireless devices. Verification is performed by applying a simple formula to sensor log data, for each activity of interest. The result value determines whether an activity has been performed.  We have conducted an experimental study to validate our approach. To do so, four participants have been monitored during five days at their home, equipped with sensors. When applied to the log data, our formulas were able to automatically verify that a list of activities were performed. They produced the same interpretations, using Signal Detection Theory, as a third party, manually analyzing the log data.	detection theory;experiment;sensor;verification and validation	Loïc Caroux;Charles Consel;Lucile Dupuy;Hélène Sauzéon	2014		10.1145/2661334.2661360	embedded system;real-time computing;verification;simulation;activities of daily living;computer science;sensor;ubiquitous computing;detection theory;activity recognition	HCI	4.890954096745308	-87.09550207405265	170269
3719890994009cbdbf261a5e1474a89090798881	sensory cues guided rehabilitation robotic walker realized by depth image-based gait analysis	robot sensing systems;time 3 day sensory cue guided rehabilitation robotic walker depth image based gait analysis parkinson disease 3d leg pose tracking depth camera gait improvement visual cue gait rehabilitation mechanism motion capture system gait analyzer smart robotic walker stride length gait velocity rhythmic auditory cue walking assistance;robot sensing systems legged locomotion three dimensional displays diseases visualization tracking;legged locomotion;visualization;three dimensional displays;patient rehabilitation diseases gait analysis geriatrics medical robotics;robotic walker parkinson disease rehabilitation;diseases;tracking	In this paper, we propose a sensory cues guided robotic walker for improving gaits of Parkinson Disease (PD) patients. A completely non-intrusive, 3D real-time leg pose tracking and gait analysis are proposed by using a depth camera mounted on the rear of the robotic walker. It has been studied that the sensory cues can serve as effective stimuli to the PD patients for gait improvement. In our work, the sensory cues including visual and auditory cues are incorporated into the robotic walker. More specifically, both sensory cues are gait-adaptive, of which the visual cue in particular is projected onto the ground by a projector installed on the walker, in order to stimulate patients walking gait more easily. Since the adjustable cues can improve patients gaits and reduce their uncomfortableness simultaneously, the hereby developed robotic walker serves as a gait rehabilitation mechanism. To demonstrate the performance of the developed walker, several real experiments have been conducted. First, the accuracy of the proposed 3D leg pose tracking is verified by a standard motion capture system. Next, seven participants (4PD patients and 3 healthy elders) are recruited to test the system three days for verifying the effectiveness of participants gait improvement. The experimental results confirm the potential of the walker serving as a rehabilitation device for PD patients. Note to Practitioners-We proposed a completely non-intrusive, relatively inexpensive and real-time gait analyzer integrated with sensory cues guided rehabilitation system on an active robotic walker. Our goal is to provide a smart robotic walker with safety, reliability, and with rehabilitation function for elders whoever suffered from chronic disease or health problem. In this work, a reliable 3D leg pose tracking is proposed. Then, a gait analysis for acquiring spatio-temporal gait parameters such as stride length and gait velocity is proposed based on the tracking to analyze the walking gait of the patients. On the other hand, improving Parkinson disease patients gaits by using sensory cues which are known to have remarkable effects for Parkinson disease patients is in many research. Therefore, we concentrate on the sensory cues include visual cue and a rhythmic auditory cue cooperating with the robotic walker which aimed to stimulate and provide walkingassistance in their ambulation. For the sensory cues, an adaptive gait mechanism is proposed to improve patients gait based on their personal gait pattern as well as to reduce uncomfortableness of them by doing the rehabilitation. The experimental results confirm the potential of the walker serving as a rehabilitation device for Parkinson disease patients. We hope the new invention of this kind assistive robotic walker will become more popular and may provide more living aid facilities to elders.	alloy analyzer;amiga walker;baseline (configuration management);expect;experiment;gait analysis;motion capture;particle filter;real-time clock;robot;sampling (signal processing);velocity (software development);verification and validation;video projector	Chung Dial Lim;Chia-Ming Wang;Ching-Ying Cheng;Yen Chao;Shih-Huan Tseng;Li-Chen Fu	2016	IEEE Transactions on Automation Science and Engineering	10.1109/TASE.2015.2494067	computer vision;simulation;visualization;computer science;engineering;tracking	Robotics	9.434971160224464	-83.560054183018	170298
aeb18a20338d562df935ca74afad665a88306a06	capturing and using emotion-based bci signals in experiments: how subject's effort can influence results	stress;bci;emotional response;attention;stroop;concentration;meditation	This study uses minimally invasive technology to monitor the emotional response of a subject during stress inducing psychological tasks. The goal of these tasks is to investigate the possibility of measuring and subsequently categorising the subject’s level of stress using biosignal devices. If a consistent metric of stress can be determined it may be used for many forms of human-machine interaction in areas such as assessment and training. Two separate psychological tests were conducted, The Stroop Colour Word Interference Test (20 subjects), and The Towers of Hanoi (17 subjects). These tests examine directed attention, and sustained, consistent attention respectively. NeuroSky’s Mindset device was used to record the stress and attention level of each subject. We examined the subject’s attention while undertaking these tasks, and assessed any correlation between this and their level of stress during the task.	brain–computer interface;experiment;human–computer interaction;interference (communication);tower of hanoi	Katie Crowley;Aidan Sliney;Ian Pitt;Dave Murphy	2011			psychology;cognitive psychology;communication;social psychology	HCI	8.872897092670808	-92.55679088281174	170504
b0f964d97ae0a538d7531448aa87abd1f4579f2c	human head modeling and personal head protective equipment: a literature review	design process;computed tomography;goggles;magnetic resonance image;human body;finite element model;literature review;respirators;medical device;headform;helmets;biomechanical model;high speed	Human head is the most important but fragile part of human body. In order to design the head-gear and study the sophisticated capabilities of human head, the head models have been developing for decades. There are two types of human head models: digital headform and finite element model (biomechanical head model). The complexity of head structure makes these attempts very difficult until the invention of the high-speed computers and the modern medical devices like computed tomography (CT) or magnetic resonance imaging (MRI). Head modeling also has widely potential use in the design process of personal head and face protective equipment (PHFPE). Hazards of processes or environment, chemical hazards, radiological hazards, or mechanical irritants are encountered daily for workers. Those hazards are capable of causing injury or illness through absorption, inhalation, or physical contact. PHFPE includes helmets, masks, eye protection and hearing protection. This study attempts to review different kinds of head models and PHFPE, such as respirators, helmets and goggles. It mainly focuses on the historical developments.		Jingzhou Yang;Jichang Dai;Ziqing Zhuang	2009		10.1007/978-3-642-02809-0_70	engineering;biological engineering;forensic engineering;surgery	HCI	8.599902547139246	-81.90583939033914	171360
2e703c7f8d80928fe37eaf43ef65ea16f5fda04a	remote monitoring using smartphone based plantar pressure sensors: unimodal and multimodal activity detection	measurement;performance;algorithm;design;remote monitoring	Automatic activity detection is important for remote monitoring of elderly people or patients, for context-aware applications, or simply to measure one’s activity level. Recent studies have started to use accelerometers of smart phones. Such systems require users to carry smart phones with them which limit the practical usability of these systems as people place their phones in various locations depending on situation, activity, location, culture and gender. We developed a prototype for shoe based activity detection system that uses pressure data of shoe and showed how this can be used for remote monitoring. We also developed a multimodal system where we used pressure sensor data from shoes along with accelerometers and gyroscope data from smart phones to make a robust system. We present the details of our novel activity detection system, its architecture, algorithm and evaluation.	multimodal interaction;pedobarography;sensor;smartphone;tire-pressure monitoring system	Ferdaus Ahmed Kawsar;Sheikh Iqbal Ahamed;Richard Love	2014		10.1007/978-3-319-14424-5_15	embedded system;design;simulation;performance;computer science;measurement	Mobile	6.982764576378898	-86.88570388941875	171381
2f7e1eac716c4485af66be0a6f44635f4ce576b2	listen to your footsteps: wearable device for measuring walking quality	physical activity tracker;context awareness;walking style;ankle;footstep sound;walking quality;wearable device;microphone	In this paper, we present a low-cost context-aware technique for determining a user's walking quality. This is achieved by filtering and analyzing the acoustic signal generated when users walk. To extract the acoustic values of footsteps, we implemented a simple wearable device attached on the user's ankle. To verify our approach, we conducted a preliminary test using several pattern classification algorithms. The results show that our system achieves an 89.6% average for three different walking styles (best, good, and bad) and 86.9% for four different real-world ground sets (carpet, asphalt, sand, and wood). We believe that our technique can be applied to existing context-aware techniques as well as various unexplored domains in wearable devices.	acoustic cryptanalysis;acoustic fingerprint;algorithm;filter (signal processing);wearable technology	Sungjae Hwang;Junghyeon Gim	2015		10.1145/2702613.2732734	embedded system;simulation	HCI	5.827408356093726	-84.52724771054882	171686
476380f6a05a50d46369544401b64d49b7f4a06d	a smart carpet design for monitoring people with dementia		People suffering from dementia or loss of brain cognitive ability due to aging can make a judgmental error and therefore have to be constantly monitored. In this paper we present a smart-carpet that employs sensing technology to automatically and unobtrusively monitor a person, detect fall and alert the caregiver by his phone or PC. In contrast to existing solutions our design is effective yet inexpensive, easy to install and maintain. We discuss the proposed design, present its prototype implementation and results of empirical evaluation.		Osamu Tanaka;Toshin Ryu;Akira Hayashida;Vasily G. Moshnyaga;Koji Hashimoto	2014		10.1007/978-3-319-08422-0_92	human–computer interaction;computer science;control engineering;phone;cognition;dementia	HCI	5.791165594913766	-87.60749072711084	172446
e329486b38af5519d4c3d2d78e1b4ef76b7be107	towards automatic cognitive load measurement from speech analysis	task performance;speech analysis;speech;feature extraction;working memory;cognitive load	Cognitive Load, as an indicator of pressure on working memory during task performing, attracts more and more research interests in recent years. By correctly measuring cognitive load levels, the system can adjust task procedure to maintain the cognitive load in an acceptable range; therefore, the subject can execute tasks more accurately and efficiently. Among many different cognitive load measuring approaches, speech-based measurement is effective due to its non-intrusive nature and possibility of online measurement. Most existing research on speech-based cognitive load measurement is based on manually extracted features, which prevent practical use. In this paper, some potential speech features, such as rate of pauses and rate of pitch peaks are investigated and proved to be effective. All feature extraction is based on automatic algorithm.		Bo Yin;Fang Chen	2007		10.1007/978-3-540-73105-4_111	speech recognition;feature extraction;computer science;speech;working memory;cognitive load	NLP	-0.7867982970175799	-87.6109921783089	173041
70d6df47589ab9b74db41c043db6b5194c56ce0d	evaluation on step counting performance of wristband activity monitors in daily living environment		Wristband-placed physical activity monitors, as a convenient means for counting walking steps, assessing movement, and estimating energy expenditure, are widely used in daily life. There are many consumer-based wristband monitors on the market, but there is not an unified method to compare their performance. In this paper, we designed a series of experiments testing step counting performance under different walking conditions to evaluate these wristband activity monitors. Seven popular brands, including Huawei B1, Mi Band, Fitbit Charge, Polar Loop, Garmin Vivofit2, Misfit Shine, and Jawbone Up, were selected and evaluated with the proposed experiment method in this paper. These experiments include four parts, which are walking in a field at a different walking speed with and without arm swing, walking along a specified complex path, walking on a treadmill, and walking up and down stairs. Experiment results and analysis with nine healthy subjects were reported to show the step counting performance of these seven monitors.	computer monitor;experiment;huawei e220	Lei Wang;Tao Liu;Yihui Wang;Qingguo Li;Jingang Yi;Yoshio Inoue	2017	IEEE Access	10.1109/ACCESS.2017.2721098	preferred walking speed;treadmill;embedded system;computer science;stairs	SE	8.996653353118619	-86.02950823868917	173200
7701e39aee453fc31a81b9bded9ce3a8de2c9192	wrist-worn fall detection device - development and preliminary evaluation		Falls are the most important cause of accidents for elderly people and often result in serious physical and psychological consequences. The rapid growth of the elderly population increases the magnitude of the problem as well as the generated costs. In order to take care of old people living by themselves or in care centres and to reduce the consequences of a fall, various technological solutions have been studied, however none led to a commercial product fulfilling user requirements. In this work we present an automatic fall detector in the form of a wrist watch which could lead to better life conditions for the elderly. Our device implements functionalities such as wireless communication, automatic fall detection, manual alarm triggering, data storage, and simple user interface. Even though the wrist is probably the most difficult measurement location on the body to discern a fall event, the proposed detection algorithm shows encouraging results (90% sensitivity, 97% specificity) with the signals of our database.	algorithm;care-of address;computer data storage;population;requirement;sensitivity and specificity;signal processing;user interface;user requirements document	Mattia Bertschi;Leopoldo Rossini	2009			engineering;overcurrent;electronic engineering;electrical engineering;waveform;tripping	HCI	8.723658450632971	-88.46834896752405	173628
564633bc327842c7f3394a96eca5f4f6d9df9972	portable real time emotion detection system for the disabled	facial expressions;real time;swinburne;principal component analysis;feature integration;facial expression;face detection;real time image processing;eigenface	This paper discusses the development of a portable real time emotion detection system for the use of disabled. This system allows the user to train the system with his/her profile comprising of expressions shown on the faces when different emotions occur. With a trained profile that can be updated flexibly, a user can detect his/her behaviour on real time basis. It utilizes the state of the art of face detection and recognition algorithms. The combination of Viola-Jones is used to detect frontal face from video which integrates Haar like features, integral image and AdaBoost learning rule. Principal Component Analysis that uses Eigenfaces to detect emotion shown on the faces is applied. For portability, it requires only a laptop or palmtop with built in camera and speaker that can be mounted on wheelchair easily. It works well in both indoor and outdoor environment day and night.	emotion recognition	Bee Theng Lau	2010	Expert Syst. Appl.	10.1016/j.eswa.2010.02.130	computer vision;face detection;speech recognition;computer science;facial expression	AI	-1.7940118692322147	-82.37139182403526	173715
964955a4adf71531e53e330f852c733a04134d3f	sensors and clinical mastitis—the quest for the perfect alert	cows;sensitivity and specificity;animals;dairy farm;female;sensor system;study design;automatic milking system;milking;mastitis bovine;sensors;biosensing techniques;data collection;time window;satisfiability;cattle diseases;milk;cattle;dairy cattle;clinical mastitis;bovine mastitis;milking machines;algorithms;electrical conductivity;dairying;dairy cows;models	When cows on dairy farms are milked with an automatic milking system or in high capacity milking parlors, clinical mastitis (CM) cannot be adequately detected without sensors. The objective of this paper is to describe the performance demands of sensor systems to detect CM and evaluats the current performance of these sensor systems. Several detection models based on different sensors were studied in the past. When evaluating these models, three factors are important: performance (in terms of sensitivity and specificity), the time window and the similarity of the study data with real farm data. A CM detection system should offer at least a sensitivity of 80% and a specificity of 99%. The time window should not be longer than 48 hours and study circumstances should be as similar to practical farm circumstances as possible. The study design should comprise more than one farm for data collection. Since 1992, 16 peer-reviewed papers have been published with a description and evaluation of CM detection models. There is a large variation in the use of sensors and algorithms. All this makes these results not very comparable. There is a also large difference in performance between the detection models and also a large variation in time windows used and little similarity between study data. Therefore, it is difficult to compare the overall performance of the different CM detection models. The sensitivity and specificity found in the different studies could, for a large part, be explained in differences in the used time window. None of the described studies satisfied the demands for CM detection models.	automatic milking;data collection;eighty;microsoft windows;ninety nine;paper;scientific publication;sensitivity and specificity;algorithm;sensor (device)	Henk Hogeveen;Claudia Kamphuis;Wilma Steeneveld;Herman Mollenhorst	2010		10.3390/s100907991	engineering;sensor;clinical study design;electrical resistivity and conductivity;statistics;satisfiability;data collection	Metrics	8.57342796389372	-80.9433515409681	174117
a84f47bc2825183e6f25989add5d6b2739f431d0	alarm: a novel fall detection algorithm based on personalized threshold	personalized threshold;fall detection;accuracy;accelerometer	Since threshold-based fall detection has been widely studied by many research groups, accuracy is still a main limitation affected by personal factors. To this end, a personalized threshold extraction approach being adapted for the fall detection usage for different individual is proposed to increase the fall detection accuracy. Moreover, we also implement a fall detection algorithm called ALARM to verify the feasibility of the proposed threshold extraction approach. Results of comprehensive evaluation show it has high accuracy of 96.76% for fall detection, while the sensitivity and the specificity are 92.01% and 99.13%, respectively, based on the data collected from 8 volunteers.	algorithm;architecture description language;artificial intelligence;personalization;sensitivity and specificity	Lingmei Ren;Weisong Shi;Zhifeng Yu;Jie Cao	2015	2015 17th International Conference on E-health Networking, Application & Services (HealthCom)	10.1109/HealthCom.2015.7454535	simulation;engineering;data mining;computer security	Robotics	6.6099317938747895	-85.94365475050446	174197
854c5d37c59ba25c5721250a17c02337c87f59ab	assessing affective experience of in-situ environmental walk via wearable biosensors for evidence-based design		Abstract In environmental psychology research, the most commonly used methods are phenomenological interviews and psychometric scales. Recently, with the development of wearable bio-sensing devices, a new approach based on bio-sensing data is becoming possible. In this study, we examined the feasibility of using wearable biosensors to document affective experience during in-situ walk. An eight-channelled Procomp multi-bio-sensing devices (EKG, EEG, skin conductance, temperature, facial EMG, respiration) were used, in addition with a GPS tracker, to measure the in situ physiological affective responses to environmental stimuli. This pilot experiment revealed consistent results between bio-sensing measures and two traditional methods, i.e. phenomenological interviews and psychological Likert scale rating, which indicated that mobile bio-sensing could be a promising method in measuring in-situ affective responses to environmental stimuli as well as diagnosing potential environmental stressor. This new bio-sensory method, as exemplified in this paper, could help identifying negative stressful stimuli and providing evidence-based diagnosis to support design strategies.	wearable computer	Zheng Chen;S. Schulz;Ming Qiu;Wen Yang;Xiaofan He;Zhuo Wang;Ling Yang	2018	Cognitive Systems Research	10.1016/j.cogsys.2018.09.003	likert scale;machine learning;evidence-based design;applied psychology;wearable computer;assisted gps;psychology;environmental stressor;artificial intelligence;facial electromyography;environmental psychology;affect (psychology)	HCI	8.539375197972376	-92.85447549242636	175060
c0deb95b2eabfb58ab17f8828dfc9bc3cbfb8c3e	distributed wireless sensors on the human body	communication devices;wearable systems;wireless sensor;collaborative signal processing;optimal sensor positioning;individual differences;mobile health care monitoring;age subjects;biomechanics;age subjects distributed wireless sensors human body sensing devices computing devices communication devices on body monitoring mobile health care monitoring collaborative signal processing physical movement monitoring motion sensors preprocessing feature extraction signal classification graph model wearable systems mobile systems optimal sensor positioning physical activity individual differences;physical activity;distributed wireless sensors;on body monitoring;wireless sensor networks biomechanics biosensors health care patient monitoring position sensitive particle detectors signal processing;feature extraction;signal processing;human body;position sensitive particle detectors;signal classification;wireless sensor networks humans signal processing mobile communication monitoring collaboration sensor phenomena and characterization wearable sensors physics computing feature extraction;computing devices;patient monitoring;physical environment;graph model;individual difference;mobile systems;preprocessing;motion sensors;wireless sensor networks;physical movement monitoring;biosensors;health care;sensing devices	"""Advances in technology have led to development of various sensing, computing and communication devices that can be woven into the physical environment of our daily lives. Such systems enable on-body and mobile health-care monitoring, can integrate information from different sources, and can initiate actions or trigger alarms when needed. In this talk, we describe a collaborative signal processing scheme for physical movement monitoring with motion sensors. The signal processing consists of preprocessing, feature extraction and classification. We define a measure on feature """"significance"""" as well as features' correlations. We characterize a graph model for collaborative signal processing based on the aforementioned measures, and illustrate how this model can be utilized to efficiently synthesize computation and communication for highly resource constrained wearable and mobile systems. We are examining the optimal positioning of sensors on the body for given physical activities, and focus on the segmentation and classification problem of the analysis of the continuous measurements of the observations obtained from the sensors. We have experimental data from different age subjects and show the individual differences amongst subjects."""	computation;feature extraction;mhealth;preprocessor;sensor;signal processing;statistical classification;wearable computer	Ruzena Bajcsy	2007	2007 IEEE 7th International Symposium on BioInformatics and BioEngineering	10.1109/BIBE.2007.4375767	embedded system;human body;wireless sensor network;feature extraction;computer science;biomechanics;signal processing;remote patient monitoring;physical fitness;preprocessor;health care;biosensor	Embedded	7.758440575932346	-87.12995612592071	175294
724ce098c510a4c5f6acc1266c55956093df3314	computer vision and the internet of things ecosystem in the connected home		An automatic food replenishment system for fridges may help people with cognitive and motor impairments to have a constant food supply at home. More even, sane people may benefit from this system because it is difficult to know accurately and precisely which goods are present in the fridge every day. This system has been a wish and a major challenge for both white good companies and food distributors for decades. It is known that this system requires two things: a sensing module for food stock tracking and another actuating module for food replenishment. The last module can be easily addressed since nowadays there exist many smartphone applications for food delivering, in fact, many food distributors allow their end-users to schedule food replenishment. On the contrary, food stock tracking is not that easy since this requires artificial intelligence to determine not only the different type of goods present in the fridge but also their quantity and quality. In this work, we address the problem of food detection in the fridge by a supervised computer vision algorithm based on Fast Region-based Convolutional Network and an internet of things ecosystem architecture in the connected home for getting high performance on training and deployment of the proposed method. We have tested our method on a data set of images containing sixteen types of goods in the fridge, built with the aid of a fridge-cam. Preliminary results suggest that it is possible to detect different goods in the fridge with good accuracy and that our method may rapidly scale.	computer vision;ecosystem;internet of things	Carlos Lopez-Castaño;Carlos Ferrin-Bolaños;Luis Castillo-Ossa	2018		10.1007/978-3-319-94649-8_26	real-time computing;software deployment;architecture;computer vision;artificial intelligence;internet of things;computer science;cognition	Metrics	4.0572992851381	-83.40101238832709	175307
6a2332b70a29c2496b2f1061cd84fd802e6b9e70	scalable classification of repetitive time series through frequencies of local polynomials	histograms;time series analysis polynomials time frequency analysis histograms least squares approximations indexes;least squares approximations;symbolic polynomials;polynomials;indexes;time series analysis;time series computational complexity pattern classification polynomials;time series bag of words repetitive time series scalable classification local polynomial functions linear running time complexity equi area discretizations symbolic polynomial words;time series classification;bag of words;time frequency analysis	Time-series classification has attracted considerable research attention due to the various domains where time-series data are observed, ranging from medicine to econometrics. Traditionally, the focus of time-series classification has been on short time-series data composed of a few patterns exhibiting variabilities, while recently there have been attempts to focus on longer series composed of multiple local patrepeating with an arbitrary irregularity. The primary contribution of this paper relies on presenting a method which can detect local patterns in repetitive time-series via fitting local polynomial functions of a specified degree. We capture the repetitiveness degrees of time-series datasets via a new measure. Furthermore, our method approximates local polynomials in linear time and ensures an overall linear running time complexity. The coefficients of the polynomial functions are converted to symbolic words via equi-area discretizations of the coefficients' distributions. The symbolic polynomial words enable the detection of similar local patterns by assigning the same word to similar polynomials. Moreover, a histogram of the frequencies of the words is constructed from each time-series' bag of words. Each row of the histogram enables a new representation for the series and symbolizes the occurrence of local patterns and their frequencies. In an experimental comparison against state-of-the-art baselines on repetitive datasets, our method demonstrates significant improvements in terms of prediction accuracy.	bag-of-words model;baseline (configuration management);coefficient;polynomial;time complexity;time series	Josif Grabocka;Martin Wistuba;Lars Schmidt-Thieme	2015	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2014.2377746	database index;combinatorics;discrete mathematics;time–frequency analysis;computer science;bag-of-words model;machine learning;time series;histogram;mathematics;algorithm;statistics;polynomial	DB	-2.572590732325608	-93.74695250363317	175579
7db0976469c3c48824e92358f8f785b2396a3864	toward personalized and context-aware prompting for smartphone-based intervention	smart phones;data mining;motion segmentation;time factors;feature extraction;data models;timing	Intervention strategies can help individuals with cognitive impairment to increase adherence to instructions, independence, and activity engagement and reduce errors on everyday instrumental activities of daily living (IADLs) and caregiver burden. However, to be effective, intervention prompts should be given at a time that does not interrupt other important user activities and is more convenient. In this paper, we propose an intelligent personalized intervention system for smartphones. In our approach, we use context and activity awareness to time prompts when they will most likely be viewed and used. Our result based on real data collected using smartphone motion sensors demonstrate that the proposed approach can detect the time-frame of a user response with an average accuracy of 65% and reduce the inefficiency by 39%, on average, compared to different static time interventions which shows the possibilities and advantages of the proposed system to increase user satisfaction and response rate.	cognition disorders;crisis intervention;home automation;hyperprolactinemia;interrupt;large;machine learning;personalization;silo (dataset);smartphone;smartphone;algorithm;sensor (device)	Ramin Fallahzadeh;Samaneh Aminikhanghahi;Ashley Nichole Gibson;Diane J. Cook	2016	2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2016.7592098	data modeling;simulation;feature extraction;computer science;engineering;multimedia;computer security	HCI	7.165022555093416	-86.80749304318606	175733
429853935de773fdc58b44649cc09f4c40cc41a4	motion detection using rf signals for the first responder in emergency operations: a phaser project	telecommunication computing biomedical telemetry body area networks medical signal detection patient monitoring radiotelemetry signal classification support vector machines;support vector machines;medical signal detection;telecommunication computing;radiotelemetry;support vector machines feature extraction monitoring biomedical monitoring receiving antennas motion detection;signal classification;biomedical telemetry;roc curves motion detection rf signal classification phaser project first responder emergency operations real time health monitoring system body area network fire fighters on body monitoring network support vector machine svm classifier sensor locations receiver operating characteristics;patient monitoring;body area networks	The real-time health monitoring system is a promising body area network application to enhance the safety of fire fighters when they are working in harsh and dangerous environment. Except for monitoring the physiological status of the fire fighters, on-body monitoring network can be also regarded as a candidate solution of motion detection and classification. In this paper, a novel Support Vector Machine (SVM) classifier has been implemented using RF signals as classification features. The classifier is capable of detecting and classifying seven frequently appeared motions of fire fighters including standing, walking, running, lying, crawling, climbing and running up stairs. The average true classification rate of our classifier reaches 87.9175% and the effects of different human motions and sensor locations have been analyzed by plotting Receiver Operating Characteristics (ROC) curves.	algorithm;artificial neural network;motion detector;radio frequency;real-time clock;real-time operating system;real-time transcription;receiver operating characteristic;sensor;statistical classification;supervised learning;support vector machine	Yishuang Geng;Jin Chen;Kaveh Pahlavan	2013	2013 IEEE 24th Annual International Symposium on Personal, Indoor, and Mobile Radio Communications (PIMRC)	10.1109/PIMRC.2013.6666161	embedded system;support vector machine;telecommunications;computer science;remote patient monitoring;data mining;computer security	Mobile	8.572208861744393	-86.82352887795737	175972
32decdd4863ea46b42fbf18e8404b02adf296aa5	classifying perceptual experience of tone-mapped high dynamic range videos through eeg	electroencephalography eeg;quality of experience qoe;gamma band;high dynamic range hdr	High dynamic range (HDR) imaging has potential for providing immersive experience of multimedia contents. HDR contents are expected to have better perceptual quality than conventional low dynamic range (LDR) contents, but the perceptual difference in the brain between HDR and LDR contents has not been adequately studied. In this paper, we investigate perceptual experience of tone-mapped HDR videos based on electroencephalography (EEG) classification. A support vector machine (SVM) classification system is constructed using the acquired EEG signals to explore implicitly measured perceptual difference between tone-mapped HDR and LDR videos. As a result, average accuracies of 82.14% and 42.86% are obtained in a subject-dependent scenario and a subject-independent scenario, respectively. This shows that it is possible to distinguish perceptual responses for tone-mapped HDR and LDR videos in a subject-dependent manner. Further, features selected for classification are investigated in each classification scenario. Although the spatial position of the features on the scalp varies across subjects, gamma band powers are generally effective for classification.	electroencephalography;high dynamic range;high-dynamic-range rendering;ldraw;statistical classification;support vector machine;tone mapping	Seong-Eun Moon;Jong-Seok Lee	2014		10.1145/2662996.2663010	computer vision;speech recognition;computer science;multimedia	AI	2.6370714542030345	-93.96694172517225	176494
4a45680fd26bb57916ee6a966a9a8550233e5cef	human factors affecting the patient's acceptance of wireless biomedical sensors	quality of life;ambulatory monitoring;clinical trial;human factors;arrhythmia;quality of data;everyday life	In monitoring arrhythmia, the quality of medical data from the ECG sensors may be enhanced by being based on everyday life situations. Hence, the development of wireless biomedical sensors is of growing interest, both to di- agnose the heart patient, as well as to adjust the regimen. However, human fac- tors such as emotional barriers and stigmatization, may affect the patient's behavior while wearing the equipment, which in turn may influence quality of data. The study of human factors and patient acceptance is important both in re- lation to the development of such equipment, as well as in evaluating the qual- ity of data gathered from the individual patient. In this paper, we highlight some important aspects in patient acceptance by comparing results from a preliminary clinical trial with patients using a wireless ECG sensor for three days out-of- hospital service, to available published results from telehomecare projects, and discuss important aspects to be taken into account in future investigations.	human factors and ergonomics;sensor	Rune Werner Fensli;Egil Boisen	2008		10.1007/978-3-540-92219-3_30	quality of life;medicine;human factors and ergonomics;clinical trial	Mobile	7.989999368596721	-89.18396449408955	176500
eaea3f24ba50519aac708bc626c6ca61de092628	motorbrain: a mobile app for the assessment of users' motor performance in neurology	motor skills;data collection;neurology;aging;mobile applications	BACKGROUND AND OBJECTIVE Human motor skills or impairments have been traditionally assessed by neurologists by means of paper-and-pencil tests or special hardware. More recently, technologies such as digitizing tablets and touchscreens have offered neurologists new assessment possibilities, but their use has been restricted to a specific medical condition, or to stylus-operated mobile devices. The objective of this paper is twofold. First, we propose a mobile app (MotorBrain) that offers six computerized versions of traditional motor tests, can be used directly by patients (with and without the supervision of a clinician), and aims at turning millions of smartphones and tablets available to the general public into data collection and assessment tools. Then, we carry out a study to determine whether the data collected by MotorBrain can be meaningful for describing aging in human motor performance.   METHODS A sample of healthy participants (N= 133) carried out the motor tests using MotorBrain on a smartphone. Participants were split into two groups (Young, Old) based on their age (less than or equal to 30 years, greater than or equal to 50 years, respectively). The data collected by the app characterizes accuracy, reaction times, and speed of movement. It was analyzed to investigate differences between the two groups.   RESULTS The app does allow measuring differences in neuromotor performance. Data collected by the app allowed us to assess performance differences due to the aging of the neuromuscular system.   CONCLUSIONS Data collected through MotorBrain is suitable to make meaningful distinctions among different kinds of performance, and allowed us to highlight performance differences associated to aging. MotorBrain supports the building of a large database of neuromotor data, which can be used for normative purposes in clinical use.		Andrea Vianello;Luca Chittaro;Stefano Burigat;Riccardo Budai	2017	Computer methods and programs in biomedicine	10.1016/j.cmpb.2017.02.012	neurology;simulation;motor skill;medicine;artificial intelligence;statistics;data collection	ML	9.22051378608661	-85.23286776911401	176672
2ca025b9255606562a221f06b9eb7eedbb115f32	experimental validation of human pathological gait analysis for an assisted living intelligent robotic walker	lasers;robot sensing systems;legged locomotion;hidden markov models;sensors assisted living gait analysis handicapped aids intelligent robots laser ranging medical robotics mobile robots;legged locomotion hidden markov models robot sensing systems tracking pathology lasers;pathology;tracking;sensor human pathological gait analysis assisted living intelligent robotic walker gait analysis functionality assistance mobility robot elderly persons mobility disabilities gaitrite system motion disabilities laser range finder	A robust and effective gait analysis functionality is an essential characteristic for an assistance mobility robot dealing with elderly persons. The aforementioned functionality is crucial for dealing with mobility disabilities which are widespread in these parts of the population. In this work we present experimental validation of our in house developed system. We are using real data, collected from an ensemble of different elderly persons with a number of pathologies, and we present a validation study by using a GaitRite System. Our system, following the standard literature conventions, characterizes the human motion with a set of parameters which subsequently can be used to assess and distinguish between possible motion disabilities, using a laser range finder as its main sensor. The initial results, presented in this work, demonstrate the applicability of our framework in real test cases. Regarding such frameworks, a crucial technical question is the necessary complexity of the overall tracking system. To answer this question, we compare two approaches with different complexity levels. The first is a static rule based system acting on filtered laser data, while the second system utilizes a Hidden Markov Model for gait cycle estimation, and extraction of the gait parameters. The results demonstrate that the added complexity of the HMM system is necessary for improving the accuracy and efficacy of the system.	amiga walker;gait analysis;hidden markov model;kinesiology;markov chain;robot;rule-based system;test case;tracking system	Xanthi S. Papageorgiou;Georgia Chalvatzaki;Konstantinos-Nektarios Lianos;Christian Werner;Klaus Hauer;Costas S. Tzafestas;Petros Maragos	2016	2016 6th IEEE International Conference on Biomedical Robotics and Biomechatronics (BioRob)	10.1109/BIOROB.2016.7523776	computer vision;simulation;engineering;communication	Robotics	7.514749032369225	-85.03867535960795	176756
1163d3576bd1b326eeeaf39634401945eb09b582	an e-health study case environment enhanced by the utilization of a quality of context paradigm		Nowadays, it is a common ground to find an ehealth environment flooded by a large amount of data, which comes from several mobile devices/sensors, and could not represent hundred percent of useful information. In other words, a process to enhance this data scenario is an essential effort. Therefore, in this paper, we present an approach oriented to the context which targets to provide more dynamic and personalized services in an e-health environment. The proposal adopts a Quality of Context (QoC) paradigm which was conceived to improve an e-health IoT environment. The scenario was characterized by supporting the care of people with special needs (elderly or with health problems) thus improving their quality of life. Thereby, the objective was to demonstrate the use of the proposed QoC evaluation, appraising some parameters. Experiments considered the use of diverse types of sensors, such as pulse and oxygen in the blood, body temperature, blood pressure, patient’s position and falls, environment temperature and humidity. Results indicate the success of the proposal.	atm adaptation layer;algorithm;backup;care-of address;experiment;mobile device;personal digital assistant;personalization;programming paradigm;sensor	Débora Cabral Nazário;Mario A. R. Dantas;Douglas Dyllon Jeronimo de Macedo	2018	2018 IEEE Symposium on Computers and Communications (ISCC)	10.1109/ISCC.2018.8538529	real-time computing;ehealth;special needs;distributed computing;computer science;mobile device;internet of things	SE	4.364305912816459	-88.10217026176606	176992
86e951e190586b84c530f9f03504f9ad70cc650a	learning features from music audio with deep belief networks		Feature extraction is a crucial part of many MIR tasks. In this work, we present a system that can automatically extract relevant features from audio for a given task. The feature extraction system consists of a Deep Belief Network (DBN) on Discrete Fourier Transforms (DFTs) of the audio. We then use the activations of the trained network as inputs for a non-linear Support Vector Machine (SVM) classifier. In particular, we learned the features to solve the task of genre recognition. The learned features perform significantly better than MFCCs. Moreover, we obtain a classification accuracy of 84.3% on the Tzanetakis dataset, which compares favorably against state-of-the-art genre classifiers using frame-based features. We also applied these same features to the task of auto-tagging. The autotaggers trained with our features performed better than those that were trained with timbral and temporal features.	bayesian network;deep belief network;discrete fourier transform;feature extraction;mir (computer);nonlinear system;support vector machine	Philippe Hamel;Douglas Eck	2010			speech recognition;computer science;machine learning;pattern recognition	ML	-4.204809363347663	-87.22810680367643	177251
6a3566330f1bb909deb92edf3d25736c818c4c24	the quantified self and physical therapy: the application of motion sensing technologies		The quantified self and in particular motion sensing applications have the potential to advance the practice of physical therapy by allowing a patient themselves and/or their physical therapist to measure the patient's performance in carrying out prescribed rehabilitation exercises. As the patient carries out such exercises at home they have the potential to measure, quantify and record their performance and progress digitally. This information can also be provided to the physical therapist, either asynchronously or in real-time. In this review paper we address the latest developments and research in relation to how such motion sensing technologies can support the quantified self in the domain of physical therapy including emerging directions.	quantified self;real-time transcription	Tim Levene;Robert Steele	2017		10.1145/3093241.3093272	physical therapy;rehabilitation;biomedical engineering;health informatics;medicine	HCI	8.104827633107352	-89.55018605473403	177438
fc92f41faf10bf98f6c0275f408ca1e7d36e2ed5	development and usability of a personalized sensor-based system for pervasive healthcare	please select value;sensing devices system development system usability personalized sensor based system pervasive healthcare remote health monitoring systems chronic conditions patient needs personalization requirement mobile health system smartphone portable sensors wearable sensors patient physiological parameters measurement back end platforms health professionals patient condition monitoring monitoring plans prototype system service oriented architecture;wearable computers health care medical computing mobile computing patient monitoring service oriented architecture smart phones telemedicine;monitoring usability biomedical monitoring medical services sensor systems heart rate	Although a plethora of remote health monitoring systems have been proposed for chronic conditions, the challenge posed by the changing patient needs and the requirement for personalization in health monitoring to move beyond proprietary, difficult to extend, and unsustainable solutions still pertains. In this direction, we describe a mobile health system based on a smartphone, portable/wearable sensors for measuring the patient's physiological parameters, and back-end platforms for the health professionals to monitor the patient condition and configure monitoring plans in an individualized manner. A prototype system was developed based on a Service-oriented Architecture and integrating commercially available sensing devices. An experimental study has been conducted with 53 patients in order to investigate the usability of the proposed system. The patients were able to perform the majority of the target tasks successfully (Success Rate = 77%), while the perceived usability using the System Usability Scale (SUS) was found to be above average (SUS score = 73%), indicating that the patients overall perceived the system as both easy to use and useful.	experiment;mobile health;patients;personalization;pervasive development disorder;pervasive informatics;prototype;service-oriented architecture;service-oriented device architecture;smartphone;system usability scale;wearable computer;sensor (device)	Andreas K. Triantafyllidis;Vassilis Koutkias;Ioanna Chouvarda;Nicos Maglaveras	2014	2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/EMBC.2014.6945146	embedded system;engineering;biological engineering;computer security	HCI	5.149006266152238	-88.65340563029102	177932
4bd950afa2f2ecca112a3a48b5b2128f51498943	mining emerging sequential patterns for activity recognition in body sensor networks	and data mining;human activity recognition;wireless body sensor networks	Wireless Body Sensor Networks offer many promising applications in healthcare, well-being and entertainment. One of the emerging applications is recognizing activities of daily living. This task is particularly challenging because in real life people often preform activities in not only a simple (i.e., sequential), but also complex (i.e., interleaved and concurrent) manner. Existing solutions typically require proper training for building the models for interleaved and concurrent activities, hence they may not be  exible to real-life deployment. In this paper, we build a wireless body sensor network to investigate this challenging problem, and introduce a knowledge pattern named Emerging Sequential Pattern (ESP) - a sequential pattern that discovers the signi cant differences - between activity classes. Leveraging on ESPs, we build our complex activity models directly upon the sequential model, eliminating the training process. We conduct a real-world trace collection using our wireless body sensor network in a smart home, and conduct comprehensive empirical studies to evaluate and compare our solution with the state-of-the-art solutions. The results demonstrate that our system achieves an overall accuracy of 91.89% for recognizing sequential, interleaved and concurrent activities, outperforming existing solutions.		Tao Gu;Liang Wang;Hanhua Chen;Guimei Liu;XianPing Tao;Jian Lu	2010		10.1007/978-3-642-29154-8_9	embedded system;real-time computing;simulation;telecommunications;operating system;data mining;computer security;computer network	Mobile	4.674071341353071	-85.99483339811177	177983
1ae3d1240fea3af82013873c91e9322fdadbeb75	smartmind: activity tracking and monitoring for patients with alzheimer's disease	context aware computing;health informatics;joints servers monitoring hip databases biomedical imaging diseases;pervasive computing;dementia;dementia pervasive computing health informatics context aware computing motion detection;daily health status estimation smartmind system alzheimer disease patient activity tracking alzheimer disease patient monitoring activity tracking system monitoring system independent ad patient living living room emergent help ad patient support ad patient daily activity capture ad patient family ad patient caregiver ad patient confidence healthy ad patient life memory degeneration rate reduction normal living habit indicator nlh indicator nlh checking ad patient health status estimation;motion detection;tracking biomechanics biomedical optical imaging biomedical telemetry cognition diseases image motion analysis medical disorders medical image processing neurophysiology patient care patient monitoring telemedicine	In this paper, we introduce SmartMind, an activity tracking and monitoring system to help Alzheimer's diseases (AD) patients to live independently within their living rooms while providing emergent help and support when necessary. Allowing AD patients to handle their daily activities not only can release some of the burdens on their families and caregivers, but also is highly important to help them regain confidence towards a healthy life and reduce the degeneration rates of their memories. The daily activities of a patient captured from SmartMind can also serve as important indicators to describe his/her normal living habit (NLH). By checking with NLH, the patient's current health status can be estimated on a daily basis.	activity tracker;alzheimer's disease neuroimaging initiative;care-of address;emergence	Kam-yiu Lam;Nelson Wai-Hung Tsang;Song Han;Joseph Kee-Yin Ng;Sze-Wei Tam;Ajit Nath	2015	2015 IEEE 29th International Conference on Advanced Information Networking and Applications	10.1109/AINA.2015.221	health informatics;simulation;computer science	Visualization	8.079475975651329	-86.9969505290219	178194
82f432b837d2720c47dd5c2e19ff069bfcd02cbb	learning to detect sepsis with a multitask gaussian process rnn classifier		We present a scalable end-to-end classifier that uses streaming physiological and medication data to accurately predict the onset of sepsis, a life-threatening complication from infections that has high mortality and morbidity. Our proposed framework models the multivariate trajectories of continuous-valued physiological time series using multitask Gaussian processes, seamlessly accounting for the high uncertainty, frequent missingness, and irregular sampling rates typically associated with real clinical data. The Gaussian process is directly connected to a black-box classifier that predicts whether a patient will become septic, chosen in our case to be a recurrent neural network to account for the extreme variability in the length of patient encounters. We show how to scale the computations associated with the Gaussian process in a manner so that the entire system can be discriminatively trained end-to-end using backpropagation. In a large cohort of heterogeneous inpatient encounters at our university health system we find that it outperforms several baselines at predicting sepsis, and yields 19.4% and 55.5% improved areas under the Receiver Operating Characteristic and Precision Recall curves as compared to the NEWS score currently used by our hospital.	artificial neural network;backpropagation;baseline (configuration management);black box;computation;computer multitasking;discriminative model;end-to-end encryption;end-to-end principle;gaussian process;heart rate variability;missing data;onset (audio);random neural network;receiver operating characteristic;recurrent neural network;sampling (signal processing);scalability;septic equation;time series	Joseph Futoma;Sanjay Hariharan;Katherine A. Heller	2017			precision and recall;missing data;artificial intelligence;machine learning;sampling (statistics);computer science;receiver operating characteristic;pattern recognition;backpropagation;recurrent neural network;multivariate statistics;gaussian process	ML	4.13482918519663	-81.81694829839901	178391
097d67695799faf6cf10554b36d502bb899aefba	cross-modal health state estimation		Individuals create and consume more diverse data about themselves today than any time in history. Sources of this data include wearable devices, images, social media, geo-spatial information and more. A tremendous opportunity rests within cross-modal data analysis that leverages existing domain knowledge methods to understand and guide human health. Especially in chronic diseases, current medical practice uses a combination of sparse hospital based biological metrics (blood tests, expensive imaging, etc.) to understand the evolving health status of an individual. Future health systems must integrate data created at the individual level to better understand health status perpetually, especially in a cybernetic framework. In this work we fuse multiple user created and open source data streams along with established biomedical domain knowledge to give two types of quantitative state estimates of cardiovascular health. First, we use wearable devices to calculate cardiorespiratory fitness (CRF), a known quantitative leading predictor of heart disease which is not routinely collected in clinical settings. Second, we estimate inherent genetic traits, living environmental risks, circadian rhythm, and biological metrics from a diverse dataset. Our experimental results on 24 subjects demonstrate how multi-modal data can provide personalized health insight. Understanding the dynamic nature of health status will pave the way for better health based recommendation engines, better clinical decision making and positive lifestyle changes.	conditional random field;cybernetics;fitness function;geonetwork opensource;kerrison predictor;modal logic;open-source software;personalization;social media;source data;sparse matrix;wearable technology	Nitish Nag;Vaibhav Pandey;Preston J. Putzel;Hari Bhimaraju;Srikanth Krishnan;Ramesh Jain	2018		10.1145/3240508.3241913	knowledge management;modal;source data;domain knowledge;cybernetics;wearable technology;wearable computer;health informatics;social media;computer science	HCI	4.183306994127041	-81.61210642175254	178595
338593d552192e6a3838c5594818568a221c75fe	automatic stress detection in working environments from smartphones’ accelerometer data: a first step	stress;statistical analysis acceleration measurement accelerometers ambient intelligence biomedical equipment body sensor networks occupational stress patient monitoring power consumption smart phones;stress data models accelerometers accuracy feature extraction adaptation models smart phones;time 8 week automatic stress detection smartphone accelerometer data occupational stress human psychological dynamics diverse aspect monitoring human behavior psychological state subject stress levels accelerometer sensor video audio recording low power consumption wearable devices fitness trackers real working environments perceived stress levels statistical models self reported stress level classification user specific models similar users models;smart phones;accuracy;feature extraction;adaptation models;accelerometers;well being smartphones accelerometer ambient intelligence automatic stress detection health monitoring health;data models	Increase in workload across many organizations and consequent increase in occupational stress are negatively affecting the health of the workforce. Measuring stress and other human psychological dynamics is difficult due to subjective nature of selfreporting and variability between and within individuals. With the advent of smartphones, it is now possible to monitor diverse aspects of human behavior, including objectively measured behavior related to psychological state and consequently stress. We have used data from the smartphone's built-in accelerometer to detect behavior that correlates with subjects stress levels. Accelerometer sensor was chosen because it raises fewer privacy concerns (e.g., in comparison to location, video, or audio recording), and because its low-power consumption makes it suitable to be embedded in smaller wearable devices, such as fitness trackers. About 30 subjects from two different organizations were provided with smartphones. The study lasted for eight weeks and was conducted in real working environments, with no constraints whatsoever placed upon smartphone usage. The subjects reported their perceived stress levels three times during their working hours. Using combination of statistical models to classify selfreported stress levels, we achieved a maximum overall accuracy of 71% for user-specific models and an accuracy of 60% for the use of similar-users models, relying solely on data from a single accelerometer.	audio media;canonical account;embedded system;embedding;fitness trackers;heart rate variability;low-power broadcasting;mental state;post-traumatic stress disorder;small;smartphone;statistical model;wearable technology;accelerometers	Enrique Garcia-Ceja;Venet Osmani;Oscar Mayora-Ibarra	2016	IEEE Journal of Biomedical and Health Informatics	10.1109/JBHI.2015.2446195	embedded system;data modeling;real-time computing;simulation;feature extraction;computer science;machine learning;accuracy and precision;stress;accelerometer;statistics	HCI	8.05480512636864	-86.58104553687772	178622
709a7a0d8452062aa9658e107b25a2776c46b55c	deep neural network based learning and transferring mid-level audio features for acoustic scene classification		Deep Neural Network (DNN) based transfer learning has been shown to be effective in Visual Object Classification (VOC) for complementing the deficit of target domain training samples by adapting classifiers that have been pre-trained for other large-scaled DataBase (DB). Although there exists an abundance of acoustic data, it can also be said that datasets of specific acoustic scenes are sparse for training Acoustic Scene Classification (ASC) models. By exploiting VOC DNN's ability of learning beyond its pre-trained environments, this paper proposes DNN based transfer learning for ASC. Effectiveness of the proposed method is demonstrated on the database of IEEE DCASE Challenge 2016 Task 1 and home surveillance environment via representative experiments. Its improved performance is verified by comparing it to prominent conventional methods.	acoustic cryptanalysis;database;deep learning;experiment;sparse matrix;ti advanced scientific computer	Seongkyu Mun;Suwon Shon;Wooil Kim;David K. Han;Hanseok Ko	2017	2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2017.7952265	artificial intelligence;transfer of learning;pattern recognition;artificial neural network;convolution;speech recognition;machine learning;computer science;home surveillance	Vision	-4.214460439057039	-87.44072242674841	178796
357ad53bb7a270fb21b58c75af681482ef711850	airwriting: a wearable handwriting recognition system	handwriting recognition;hidden markov models;wearable computing;gesture recognition;inertial sensors	We present a wearable input system which enables interaction through 3D handwriting recognition. Users can write text in the air as if they were using an imaginary blackboard. The handwriting gestures are captured wirelessly by motion sensors applying accelerometers and gyroscopes which are attached to the back of the hand. We propose a two-stage approach for spotting and recognition of handwriting gestures. The spotting stage uses a support vector machine to identify those data segments which contain handwriting. The recognition stage uses hidden Markov models (HMMs) to generate a text representation from the motion sensor data. Individual characters are modeled by HMMs and concatenated to word models. Our system can continuously recognize arbitrary sentences, based on a freely definable vocabulary. A statistical language model is used to enhance recognition performance and to restrict the search space. We show that continuous gesture recognition with inertial sensors is feasible for gesture vocabularies that are several orders of magnitude larger than traditional vocabularies for known systems. In a first experiment, we evaluate the spotting algorithm on a realistic data set including everyday activities. In a second experiment, we report the results from a nine-user experiment on handwritten sentence recognition. Finally, we evaluate the end-to-end system on a small but realistic data set.	algorithm;concatenation;end system;end-to-end principle;experiment;gesture recognition;handwriting recognition;hidden markov model;imaginary time;input device;language model;markov chain;mobile device;motion detector;sensor;speech recognition;support vector machine;vocabulary;wearable computer;word error rate	Christoph Amma;Marcus Georgi;Tanja Schultz	2013	Personal and Ubiquitous Computing	10.1007/s00779-013-0637-3	inertial measurement unit;computer vision;speech recognition;wearable computer;intelligent character recognition;computer science;gesture recognition;handwriting recognition	HCI	-2.1336929779316414	-83.8725969512082	178819
00f9eb09804af396fa5e45676e2defbcbe40a83a	vision-based engagement detection in virtual reality	user biometric data streams vision based engagement detection virtual reality user engagement modeling vision based interfaces midas touch problem gesture recognition system daia finite state transducer fst;sensors;torso;virtual reality;transducers;hidden markov models;three dimensional displays;feature extraction;three dimensional displays sensors transducers hidden markov models torso feature extraction virtual reality;virtual reality computer vision finite state machines gesture recognition;finite state machine gesture recognition systems user engagement detection human activity recognition vision based interface virtual reality	User engagement modeling for manipulating actions in vision-based interfaces is one of the most important case studies of user mental state detection. In a Virtual Reality environment that employs camera sensors to recognize human activities, we have to know were user intend to perform an action and when he/she is disengaged. Without a proper algorithm for recognizing engagement status, any kind of activities could be interpreted as manipulating actions, called “Midas Touch” problem. Baseline approach for solving this problem is activating gesture recognition system using some focus gestures such as waiving or raising hand. However, a desirable natural user interface should be able to understand user's mental status automatically. In this paper, a novel multi-modal model for engagement detection, DAIA 1, is presented. using DAIA, the spectrum of mental status for performing an action is quantized in a finite number of engagement states. For this purpose, a Finite State Transducer (FST) is designed. This engagement framework shows how to integrate multi-modal information from user biometric data streams such as 2D and 3D imaging. FST is employed to make the state transition smoothly using combination of several boolean expressions. Our FST true detection rate is 92.3% in total for four different states. Results also show FST can segment user hand gestures more robustly.	algorithm;biometrics;boolean expression;finite-state transducer;gesture recognition;mental state;modal logic;natural user interface;quantization (signal processing);sensor;smoothing;state transition table;virtual reality	Ghassem Tofighi;Kaamran Raahemifar;Maria Frank;Haisong Gu	2016	2016 Digital Media Industry & Academic Forum (DMIAF)	10.1109/DMIAF.2016.7574933	computer vision;simulation;transducer;torso;feature extraction;computer science;sensor;machine learning;virtual reality	HCI	0.6503719202687	-88.26232164787784	179021
3ef498403722f53746736395b0dcaf05f3f596a7	combining accelerometer and video camera: reconstruction of bow velocity profiles	sprakteknologi sprakvetenskaplig databehandling;bowed string;video tracking;violin;bow velocity;bowing gestures;datavetenskap datalogi;accelerometer;language technology computational linguistics;computer science;velocity profile	A cost-effective method was developed for the estimation of the bow velocity in violin playing, using an accelerometer on the bow in combination with point tracking using a standard video camera. The video data are used to detect the moments of bow direction changes. This information is used for piece-wise integration of the accelerometer signal, resulting in a drift-free reconstructed velocity signal with a high temporal resolution. The method was evaluated using a 3D motion capturing system, providing a reliable reference of the actual bow velocity. The method showed good results when the accelerometer and video stream are synchronized. Additional latency and jitter of the camera stream can importantly decrease the performance of the method, depending on the bow stroke type.	effective method;motion capture;streaming media;velocity (software development)	Erwin Schoonderwaldt;Nicolas H. Rasamimanana;Frédéric Bevilacqua	2006			computer vision;simulation;speech recognition;acoustics;computer science;operating system;video tracking;accelerometer;violin	Vision	3.4070516906559836	-94.14681355404089	179601
585e54c2b3129c8de8f4f7878551413c581331cb	position-sensing technologies for movement analysis in stroke rehabilitation	quality of life;human movement;rehabilitation;stroke rehabilitation;position sensing;motion tracking;kinetic analysis;movement analysis;inertial sensor;inertial sensors	Research has focused on improvement of the quality of life of stroke patients. Gait detection, kinematics and kinetics analysis, home-based rehabilitation and telerehabilitation are the areas where there has been increasing research interest. The paper reviews position-sensing technologies and their application for human movement tracking and stroke rehabilitation. The review suggests that it is feasible to build a home-based telerehabilitation system for sensing and tracking the motion of stroke patients.	cerebrovascular accident;kinetics (discipline);kinetics internet protocol;patients;review [publication type];stroke rehabilitation;telerehabilitation;the quality of life	Huiru Zheng;Norman David Black;Nigel D. Harris	2005	Medical and Biological Engineering and Computing	10.1007/BF02344720	inertial measurement unit;simulation;quality of life;medicine;physical medicine and rehabilitation;engineering;physical therapy;reaction progress kinetic analysis	HCI	9.624643804973465	-84.33343947664075	179697
09bdc3d508379ae7fb0c86e4995603a3ec03eb56	a hands-on course teaching bioinstrumentation through the design and construction of a benchtop cardiac pacemaker	myocardium;hands on course teaching;instruments;control system algorithms;heart;medical signal detection;sensors;cardiology;pacemakers myocardium sensors heart instruments testing electrocardiography;pacemakers;electrophysiology;stimulation electronics;testing;student skills;electrocardiography;educational courses;north american bullfrogs;bioinstrumentation design hands on course teaching benchtop cardiac pacemaker bioinstrumentation course biomedical device sensing circuitry data acquisition data processing code control system algorithms stimulation electronics cardiac anatomy electrophysiology north american bullfrogs hands on learning student skills;biomedical education;teaching bioelectric phenomena biomedical education biomedical equipment cardiology data acquisition educational courses medical control systems medical signal detection medical signal processing pacemakers;bioelectric phenomena;hands on learning;data processing code;benchtop cardiac pacemaker;bioinstrumentation design;sensing circuitry;data acquisition;medical signal processing;biomedical equipment;bioinstrumentation course;teaching;cardiac anatomy;medical control systems;biomedical device	We have developed a bioinstrumentation course that emphasizes practical application of engineering and biological concepts by having students focus on the development of a single biomedical device: a cardiac pacemaker. In creating their benchtop pacemaker, students learn about and design sensing circuitry, data acquisition and processing code, control system algorithms, and stimulation electronics. They also gain an understanding of cardiac anatomy and electrophysiology. The separate elements of the pacemaker created throughout the semester will be repeatedly tested, re-designed, and integrated with one another, culminating in an emulated pacemaker whose efficacy will be tested on North American bullfrogs. It is hypothesized that the hands-on learning in this course, coupled with the practical application of concepts in the context of a single biomedical device, will enhance students' skills in bioinstrumentation design.	algorithm;anatomic structures;artificial cardiac pacemaker;control system;data acquisition;electronic circuit;electrophysiology (science);emulator;hands-on computing;rana catesbeiana	Matthew B. Bouchard;Matthew E. Downs;David C. Jangraw;Aaron M. Kyle	2013	2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2013.6610209	education;electrophysiology;electronic engineering;neuroscience;engineering;sensor;electrical engineering;software testing;biological engineering;data acquisition;heart;experiential education	Robotics	9.856229220870185	-82.66193135396402	179948
30d4d2ce9b88ff74859752281d9464b92b3578fe	neuro-fuzzy closed-loop control of depth of anaesthesia	fuzzy controller;depth of anaesthesia;qc physics;closed loop control;back propagation neural network;fuzzy logic;rd surgery;neuro fuzzy;anaesthesia;general anaesthesia;electroencephalogram;tk electrical engineering electronics nuclear engineering;neural network;auditory evoked potential	The utility of the auditory evoked potential (AEP) is under investigation as a feedback signal for the automatic closed-loop control of general anaesthesia using neural networks and fuzzy logic. The AEP is a signal derived from the electroencephalogram (EEG) in response to auditory stimulation, which may be useful as an index of the 'depth' of anaesthesia. A simple back-propagation neural network can learn the AEP and provides a satisfactory input to a fuzzy logic infusion controller for the administration of anaesthetic drugs, but the problem remains that of reliable signal acquisition.		Robert Allen;David K Smith	2001	Artificial intelligence in medicine	10.1016/S0933-3657(00)00084-1	fuzzy logic;computer science;neuro-fuzzy;machine learning;artificial neural network	ML	9.535008204056757	-82.31097553558162	180045
00719f3f12b647a49a3a3c78793800279e2199f7	user specific adaptation in automatic transcription of vocalised percussion		The goal of this work is to develop an application that enables music producers to use their voice to create drum patterns when composing in Digital Audio Workstations (DAWs). An easy-to-use and user-oriented system capable of automatically transcribing vocalisations of percussion sounds, called LVT Live Vocalised Transcription, is presented.1 LVT is developed as a Max for Live device which follows the “segment-and-classify” methodology for drum transcription, and includes three modules: i) an onset detector to segment events in time; ii) a module that extracts relevant features from the audio content; and iii) a machine-learning component that implements the k-Nearest Neighbours (kNN) algorithm for the classification of vocalised drum timbres. Due to the wide differences in vocalisations from distinct users for the same drum sound, a user-specific approach to vocalised transcription is proposed. In this perspective, a given end-user trains the algorithm with their own vocalisations for each drum sound before inputting their desired pattern into the DAW. The user adaption is achieved via a new Max external which implements Sequential Forward Selection (SFS) for choosing the most relevant features for a given set of input drum sounds. The evaluation of LVT addresses two objectives. First, to investigate the improvement in performance with user-specific training, and second, to assess if LVT can provide an optimised workflow for music production in Ableton Live when compared to existing drum transcription algorithms. Obtained results demonstrate that both objectives are met.	ableton live;automatic control;clustered file system;digital audio workstation;k-nearest neighbors algorithm;machine learning;max;medical transcription;onset (audio);stepwise regression;transcription (software)	António Ramires;Rui Penha;Matthew E. P. Davies	2018	CoRR			ML	-2.0267424066841904	-91.00383936350758	180584
794a19de736b6169c8b86ac30317606590638354	an ultra low power granular decision making using cross correlation: minimizing signal segments for template matching	biomedical monitoring;microcontrollers;ultra low power;healthcare;body sensor networks;cross correlation;wearable computers;embedded system;computer architecture;embedded systems;power aware computing;power optimization embedded systems healthcare body sensor networks signal processing;monitoring;signal processing;wearable computers body area networks body sensor networks decision making health care power aware computing signal classification;signal classification;power optimization;signal processing decision making biomedical monitoring microcontrollers correlation monitoring computer architecture;intelligent processing architecture cross correlation signal segments minimization template matching wearable sensor platforms healthcare screening classifier optimization problem minitemplates ultralow power granular decision making architecture cyber physical systems classification decision power consumption;correlation;body area networks;template matching;body sensor network;health care	Wearable sensor platforms have proved effective in a large variety of new application domains including wellness and healthcare, and are perfect examples of cyber physical systems. A major obstacle in realization of these systems is the amount of energy required for sensing, processing and communication, which can jeopardize small battery size and wear ability of the entire system. In this paper, we propose an ultra low power granular decision making architecture, also called screening classifier, that can be viewed as a tiered wake up circuitry. This processing model operates based on simple template matching. Ideally, the template matching is performed with low sensitivity but at very low power. Initial template matching removes signals that are obviously not of interest from the signal processing chain keeping the rest of processing modules inactive. If the signal is likely to be of interest, the sensitivity and the power of the template matching blocks are gradually increased and eventually the microcontroller is activated. We pose and solve an optimization problem to realize our screening classifier and improve the accuracy of classification by dividing a full template into smaller bins, called mini-templates, and activating optimal number of bins during each classification decision. Our experimental results on real data show that the power consumption of the system can be reduced by more than 70% using this intelligent processing architecture. The power consumption of the proposed granular decision making module is six orders of magnitude smaller than state-of-the-art low power microcontrollers.	algorithm;central processing unit;cross-correlation;electronic circuit;embedded system;mathematical optimization;microcontroller;naive bayes classifier;optimization problem;power optimization (eda);signal processing;template matching;wearable computer	Hassan Ghasemzadeh;Roozbeh Jafari	2011	2011 IEEE/ACM Second International Conference on Cyber-Physical Systems	10.1109/ICCPS.2011.26	embedded system;electronic engineering;real-time computing;template matching;telecommunications;computer science;engineering;electrical engineering;operating system;machine learning;signal processing;correlation;power optimization;health care;computer network	EDA	9.25959492257204	-88.92708038225717	181048
4f3316e1dcafd702871b2968bda3eac3b40a35de	short-segment heart sound classification using an ensemble of deep convolutional neural networks		This paper proposes a framework based on deep convolutional neural networks (CNNs) for automatic heart sound classification using short-segments of individual heart beats. We design a 1D-CNN that directly learns features from raw heart-sound signals, and a 2D-CNN that takes inputs of twodimensional time-frequency feature maps based on Mel-frequency cepstral coefficients (MFCC). We further develop a time-frequency CNN ensemble (TF-ECNN) combining the 1D-CNN and 2D-CNN based on score-level fusion of the class probabilities. On the large PhysioNet CinC challenge 2016 database, the proposed CNN models outperformed traditional classifiers based on support vector machine and hidden Markov models with various hand-crafted timeand frequency-domain features. Best classification scores with 89.22% accuracy and 89.94% sensitivity were achieved by the ECNN, and 91.55% specificity and 88.82% modified accuracy by the 2D-CNN alone on the test set.	artificial neural network;baseline (configuration management);best practice;coefficient;convolutional neural network;deep learning;hidden markov model;long short-term memory;markov chain;mel-frequency cepstrum;network architecture;recurrent neural network;sensitivity and specificity;support vector machine;test set	Jos&#xE9; Gonz&#xE1;lez Enr&#xED;quez;Chee-Ming Ting;Sheikh Hussain Shaikh Salleh;Hernando Ombao	2018	CoRR		speech recognition;convolutional neural network;support vector machine;mel-frequency cepstrum;pattern recognition;artificial intelligence;hidden markov model;computer science;test set	AI	-3.7338555845656973	-87.60269429396926	181149
063fa8afba655cb4c6adb4e6fa37310086427a31	subject-independent human activity recognition using smartphone accelerometer with cloud support	context awareness;android platforms;mobile cloud computing;smartphone accelerometer;smartphones;user information;data storage;ubiquitous computing;subject independent;human activity recognition;cloud support	Human activity recognition is an important task in providing contextual user information. In this study, we present a methodology to achieve human activity recognition using a Smartphone accelerometer independent of a subject compared with other user-dependent solutions. The proposed system is composed of four components; a data collector, a data storage cloud, a workstation module and an activity recogniser. The data collector extracts a unique set of defined features from raw data and sends them to the data storage cloud. The workstation module receives the training data from the cloud and generates classification models. The activity recogniser determines the user's current activity based on up-to-date available classifier from the cloud. A prototype is implemented on an android platform to recognise a set of basic daily living activities by placing the Smartphone in different positions to the user and evaluated for offline and online testing to show the scalability and effectiveness.		Muhammad Arshad Awan;Guangbin Zheng;Hiecheol Kim;Shin-Dug Kim	2015	IJAHUC	10.1504/IJAHUC.2015.073170	embedded system;real-time computing;human–computer interaction;computer science;operating system;computer data storage;world wide web;ubiquitous computing	HCI	3.5423334084059444	-86.06968562714182	181313
cb5ff19c0b3bc06de53f4a0df05b4273b8a57e3e	automated video analysis of handwashing behavior as a potential marker of cognitive health in older adults	hand;fractals;mini mental state exam;dementia feature extraction monitoring correlation trajectory fractals;video analysis;smart home monitoring;computer;hand washing;computer vision;trajectory;monitoring;mmse;feature extraction;dementia;machine learning automated video analysis handwashing behavior cognitive health cognitive impairment older adults minimental state exam correlation analysis;neurophysiology cognition computer vision geriatrics learning artificial intelligence;correlation;article post print;pervasive health	The identification of different stages of cognitive impairment can allow older adults to receive timely care and plan for the level of caregiving. People with existing diagnosis of cognitive impairment go through episodic phases of dementia requiring different levels of care at different times. Monitoring the cognitive status of existing patients is, thus, critical to deciding the level of care required by older adults. In this paper, we present a system to assess the cognitive status of older adults by monitoring a common activity of daily living, namely handwashing. Specifically, we extract features from handwashing trials of participants diagnosed with different levels of dementia ranging from cognitively intact to severe cognitive impairment, as assessed by the mini-mental state exam (MMSE). Based on videos of handwashing trials, we extract two classes of features: one characterizing the occupancy of different sink regions by the participant, and the other capturing the path tortuosity of the motion trajectory of participant's hands. We perform correlation analysis to assess univariate capacity of individual features to predict MMSE scores. To assess multivariate performance, we use machine learning methods to train models that predict the cognitive status (aware, mild, moderate, severe), as well as the MMSE scores. We present results demonstrating that features derived from hand washing behavior can be potential surrogate markers of a person's dementia, which can be instrumental in developing automated tools for continuously monitoring the cognitive status of older adults.	class;cognition disorders;dementia;handwashing;machine learning;mental disorders;mental state;patients;rem sleep behavior disorder;surrogate model;wash (cleansing action)	Ahmed Bilal Ashraf;Babak Taati	2016	IEEE Journal of Biomedical and Health Informatics	10.1109/JBHI.2015.2413358	computer vision;simulation;fractal;feature extraction;computer science;trajectory;correlation	HCI	8.07141681690841	-86.90823618840152	181443
c6c2c2d9f17b4219f81a4562d38cde6f78185cb2	high dimensional time series generators		Multidimensional time series are sequences of real valued vectors. They occur in different areas, for example handwritten characters, GPS tracking, and gestures of modern virtual reality motion controllers. Within these areas, a common task is to search for similar time series. Dynamic Time Warping (DTW) is a common distance function to compare two time series. The Edit Distance with Real Penalty (ERP) and the Dog Keeper Distance (DK) are two more distance functions on time series. Their behaviour has been analyzed on 1-dimensional time series. However, it is not easy to evaluate their behaviour in relation to growing dimensionality. For this reason we propose two new data synthesizers generating multidimensional time series. The first synthesizer extends the well known cylinder-bell-funnel (CBF) dataset to multidimensional time series. Here, each time series has an arbitrary type (cylinder, bell, or funnel) in each dimension, thus for d-dimensional time series there are 3d different classes. The second synthesizer (RAM) creates time series with ideas adapted from Brownian motions which is a common model of movement in physics. Finally, we evaluate the applicability of a 1-nearest neighbor classifier using DTW on datasets generated by our synthesizers.	bell's theorem;brownian motion;cylinder seal;dynamic time warping;erp;edit distance;gps tracking unit;global positioning system;image warping;keeper (password manager);motion controller;random-access memory;time series;virtual reality;whole earth 'lectronic link	Jörg P. Bachmann;Johann-Christoph Freytag	2018	CoRR		edit distance;metric (mathematics);machine learning;cylinder;global positioning system;brownian motion;artificial intelligence;dynamic time warping;gesture;curse of dimensionality;mathematics	DB	-0.9467944303254499	-92.7842639120749	181859
e67f268dde0bb4623c7b2ef24d3be0f5d7a83f02	wavelet-based intelligent system for recognition of power quality disturbance signals	transformation ondelette;interruption;caracteristique courant tension;phenomene transitoire;systeme intelligent;harmonic distortion;power system monitoring;power quality;forme onde;surveillance;reponse transitoire;sistema inteligente;armonica;voltage sag;caracteristica corriente tension;harmonic;intelligence artificielle;analyse multiresolution;classification;tension electrique;transient response;respuesta transitoria;vigilancia;cuantificacion vectorial;wavelet transform;forma onda;vector quantization;harmonique;monitoring;interrupcion;voltage;fenomeno transitorio;intelligent system;voltage current curve;artificial intelligence;waveform;inteligencia artificial;monitorage;transformacion ondita;transients;reseau neuronal;voltaje;monitoreo;multiresolution analysis;clasificacion;red neuronal;wavelet transformation;analisis multiresolucion;learning vector quantization;neural network;quantification vectorielle	Recognition of power quality events by analyzing the voltage and current waveform disturbances is a very important task for the power system monitoring. This paper presents a new approach for the recognition of power quality disturbances using wavelet transform and neural networks. The proposed method employs the wavelet transform using multiresolution signal decomposition techniques working together with multiple neural networks using a learning vector quantization network as a powerful classifier. Various transient events are tested, such as voltage sag, swell, interruption, notching, impulsive transient, and harmonic distortion show that the classifier can detect and classify different power quality signal types efficiency.	artificial intelligence;artificial neural network;distortion;electric power quality;ibm power systems;interrupt;learning vector quantization;prototype;statistical classification;system monitor;waveform;wavelet transform	Suriya Kaewarsa;Kitti Attakitmongcol;Wichai Krongkitsiri	2006		10.1007/11760023_199	voltage;telecommunications;computer science;machine learning;artificial neural network	EDA	-4.304914461449814	-93.10557201872423	182492
d817776590c8586b344dfc8628bb7676ab2d8c32	time-elastic generative model for acceleration time series in human activity recognition	generative models for training deep learning algorithms;accelerometer sensors;human activity recognition;auto encoders	Body-worn sensors in general and accelerometers in particular have been widely used in order to detect human movements and activities. The execution of each type of movement by each particular individual generates sequences of time series of sensed data from which specific movement related patterns can be assessed. Several machine learning algorithms have been used over windowed segments of sensed data in order to detect such patterns in activity recognition based on intermediate features (either hand-crafted or automatically learned from data). The underlying assumption is that the computed features will capture statistical differences that can properly classify different movements and activities after a training phase based on sensed data. In order to achieve high accuracy and recall rates (and guarantee the generalization of the system to new users), the training data have to contain enough information to characterize all possible ways of executing the activity or movement to be detected. This could imply large amounts of data and a complex and time-consuming training phase, which has been shown to be even more relevant when automatically learning the optimal features to be used. In this paper, we present a novel generative model that is able to generate sequences of time series for characterizing a particular movement based on the time elasticity properties of the sensed data. The model is used to train a stack of auto-encoders in order to learn the particular features able to detect human movements. The results of movement detection using a newly generated database with information on five users performing six different movements are presented. The generalization of results using an existing database is also presented in the paper. The results show that the proposed mechanism is able to obtain acceptable recognition rates (F = 0.77) even in the case of using different people executing a different sequence of movements and using different hardware.	activity recognition;algorithm;classification;database;deep learning;dominant hand;elasticity (data store);encoder;f1 score;generalization (psychology);generative model;ground truth;machine learning;microsoft windows;movement;overfitting;point of interest;precision and recall;speed (motion);time series;wearable computer;window function;accelerometers;anatomical layer;executing - querystatuscode;sensor (device)	Mario Muñoz Organero;Ramona Ruiz-Blazquez	2017		10.3390/s17020319	computer vision;simulation;computer science;machine learning	ML	3.797279711993997	-84.84231668531956	182662
b04742d02c3d9ca213b9de6e25fe31acc57f5170	behaviour state analysis through brain computer interface using wearable eeg devices: a review		In recent years, a vast research is concentrated towards the development of electroencephalography (EEG) based human computer interface in order to enhance the quality of life for medically as well as non-medical applications. Industry and community of research have been attracted by wireless EEG reading devices and they are easily available in the market. Such technology can be incorporated into psychology, anesthesiology, and for real-time patients monitoring. A brain computer interface (BCI) is a direct communication channel between the human brain and the digital computer. In this paper, we present a review on characteristics and specification of EEG-based human computer interfaces for real-time applications using wearable or wireless EEG devices.	brain–computer interface;electroencephalography;wearable computer	Sravanth Kumar Ramakuri;Sanchita Ghosh;Bharat Gupta	2017	EG	10.1504/EG.2017.10006979	brain–computer interface;human–computer interaction;wireless;computer science;wearable computer;electroencephalography;communication channel	HCI	8.352212963063259	-90.95046124879632	182817
bdfc859df1e97dba885b1e45c1625c2598a3daa7	phasebeat: exploiting csi phase data for vital sign monitoring with commodity wifi devices		Vital signs, such as respiration and heartbeat, are useful to health monitoring since such signals provide important clues of medical conditions. Effective solutions are needed to provide contact-free, easy deployment, low-cost, and long-term vital sign monitoring. In this paper, we present PhaseBeat to exploit channel state information (CSI) phase difference data to monitor breathing and heartbeat with commodity WiFi devices. We provide a rigorous analysis of the CSI phase difference data with respect to its stability and periodicity. Based on the analysis, we design and implement the PhaseBeat system with off-the-shelf WiFi devices, and conduct an extensive experimental study to validate its performance. Our experimental results demonstrate the superior performance of PhaseBeat over existing approaches in various indoor environments.	channel state information;discrete wavelet transform;experiment;quasiperiodicity;software deployment;subcarrier	Xuyu Wang;Chao Yang;Shiwen Mao	2017	2017 IEEE 37th International Conference on Distributed Computing Systems (ICDCS)	10.1109/ICDCS.2017.206	channel state information;computer network;software deployment;vital signs;computer science;commodity;exploit;heartbeat;orthogonal frequency-division multiplexing	EDA	5.669670649593616	-83.23856250338368	182970
b9e46fce2dc4b0163d280a56e856a033ebefe0d5	facial recognition: an enabling technology for augmented cognition applications	biometrics;situation awareness;facial recognition;augmented cognition;environmental monitoring	"""Research in Augmented Cognition (AugCog) investigates computational methods, technologies, and non-invasive neurophysiological tools to adapt computational systems to the changing cognitive state of human operators to improve task performance. Closed-loop AugCog systems contain four components: 1) operational or simulated environment, 2) automated sensors to monitor and assess cognitive state via behavior and/or physiology, 3) adaptive interface, and 4) computational decision architecture that directs AugCog adaptations. Since cognitive state is influenced by environment, a critical challenge for AugCog systems is capture of situational awareness (SA) within the decision architecture. Previously, AugCog systems have been demonstrated within simulated environments that provide SA and ground truth data to drive intelligent decision architecture. In live operating environments, electronic C4 systems (i.e., communications), provide a limited model of operator """"state,"""" but emerging facial recognition/analysis technology can provide detection, identification, and tracking of humans in the environment to increase the accuracy of the AugCog system's SA."""	augmented cognition;facial recognition system	Denise M. Nicholson;Christine Podilchuk;Kathleen Bartlett	2011		10.1007/978-3-642-21852-1_13	computer vision;simulation;engineering;communication	HCI	7.356090215549322	-85.43066399017131	184255
c50e0f2fbf7c7586a0cbed75c90f1318a76b90e9	wearable heart rate monitoring as stress response indicator in children with neurodevelopmental disorder		In this paper, a wearable sensor system embedded in a belt for monitoring cardio-respiratory activity in children with neurodevelopmental disorder is presented. The sensors are integrated, using a micro-controller with a wireless interface, in a network that is able to transmit the monitored parameters to a data collection station. The data are acquired, processed and stored using a virtual instrument developed in the LabVIEW environment. The aim of the study is to evaluate the effectiveness of cardio-respiratory frequency, observed in structured and non0-structured situations of interactive session, as a possible indicator of stress response in children affected by autism spectrum disorder and by pre-school language disorders. Preliminary results evidence a correlation between specifically designed activities and the corresponding heart rate.	embedded system;labview;microcontroller;sensor;virtual instrumentation;wearable computer	Erika Pittella;Emanuele Piuzzi;Emanuele Rizzuto;Zaccaria Del Prete;Francesca Fioriello;Andrea Maugeri;Carla Sogos	2018	2018 IEEE International Symposium on Medical Measurements and Applications (MeMeA)	10.1109/MeMeA.2018.8438805	data collection;physical medicine and rehabilitation;wearable computer;autism spectrum disorder;wireless network interface controller;fight-or-flight response;heart rate monitoring;heart rate;computer science;neurodevelopmental disorder	Embedded	8.418110894312326	-87.90738721145185	184478
ee0699b802ea98083b213d011b795119d648e931	human activity recognition using radial basis function neural network trained via a minimization of localized generalization error		Human activity recognition is a crucial component of applications in the areas of pervasive computing in healthcare. Human activity recognition approaches which adopt a data-driven approach are challenged by handling uncertainty in the data. These uncertainties arise due to sensor unreliability, natural noise and variance introduced by those performing the underlying activities. In this paper we propose an approach to human activity recognition based on Radial Basis Function Neural Networks (RBFNN) trained via a minimization of Localized Generalization Error in an effort to minimize the effects of uncertainty in the data. The proposed approach minimizes the generalization error taking into consideration both the training error and the stochastic sensitivity measure, which subsequently results in an improved generalization capability and improved tolerance to the uncertainty in the data. The approached developed was evaluated using data collected from the IESim smart environment simulation tool. Eleven activities were performed in a simulated environment, with uncertainty in the data stemming from user variance in completing the activities and the sensor placements in the environment. Classification accuracy of 98.86% was achieved demonstrating that the proposed RBFNN approach is robust to minor differences in unseen samples, many of which are caused by data uncertainty, following training which offers good generalization capability.		Shuai Zhang;Daniel S. Yeung;Jianjun Zhang;Chris D. Nugent	2017		10.1007/978-3-319-67585-5_50	ubiquitous computing;generalization error;artificial neural network;minification;activity recognition;computer science;radial basis function network;radial basis function;machine learning;smart environment;artificial intelligence;pattern recognition	ML	3.402373622231568	-84.0345292394279	184814
4524dd9c81e84fafcb69cd34fda1dd56fb5cb682	sober-drive: a smartphone-assisted drowsy driving detection system	neural nets;sensors;smart phones;gaze tracking;android smart phones sober drive system smartphone drowsy driving detection system sleepiness accidents percentage of closure of eyelid perclos blink time blink rate neural network;sleep;face recognition;monitoring;smart phones face recognition gaze tracking monitoring neural nets sensors sleep;training vehicles smart phones fatigue accuracy neural networks algorithm design and analysis;personalized training drowsiness detection eye detection neural network	Drowsy driving, a combination of sleepiness and driving, has become a worldwide problem that often leads to tragic accidents and outcomes. Existing research findings have shown that the percentage of closure of eyelid (a.k.a PERCLOS) is an effective indicator to evaluate the driver's drowsiness. We present the Sober-Drive system, which leverages PERCLOS for on-vehicle drowsy driving detection using smart phones. Specifically, Sober-Drive is built upon a number of indicators that are discrete-approximated from PERCLOS, blink time and blink rate, and it exploits the Neural Network to classify the eye “open/close” states. We developed a Sober-Drive prototype on Android smart phones, and we conducted extensive real-world experiments to evaluate its performance, the results of which show that Sober-Drive has a high detection rate of more than 90% for drowsy driving behaviors.	android;application programming interface;approximation algorithm;artificial neural network;experiment;mathematical optimization;personalization;principle of good enough;prototype;smartphone	Lunbo Xu;Shunyang Li;Kaigui Bian;Tong Zhao;Wei Yan	2014	2014 International Conference on Computing, Networking and Communications (ICNC)	10.1109/ICCNC.2014.6785367	embedded system;simulation;engineering;computer security	Mobile	5.157706526858202	-84.91326596996039	185297
007cb086d793a8a93848712a34d784960383bc73	harke: human activity recognition from kinetic energy harvesting data in wearable devices	biomedical monitoring;accelerometers;batteries;power demand;kinetic energy;activity recognition	Kinetic energy harvesting (KEH) may help combat battery issues in wearable devices. While the primary objective of KEH is to generate energy from human activities, the harvested energy itself contains information about human activities that most wearable devices try to detect using motion sensors. In principle, it is therefore possible to use KEH both as a power generator and a sensor for human activity recognition (HAR), saving sensor-related power consumption. Our aim is to quantify the potential of human activity recognition from kinetic energy harvesting (HARKE). We evaluate the performance of HARKE using two independent datasets: (i) a public accelerometer dataset converted into KEH data through theoretical modeling; and (ii) a real KEH dataset collected from volunteers performing activities of daily living while wearing a data-logger that we built of a piezoelectric energy harvester. Our results show that HARKE achieves an accuracy of 80 to 95 percent, depending on the dataset and the placement of the device on the human body. We conduct detailed power consumption measurements to understand and quantify the power saving opportunity of HARKE. The results demonstrate that HARKE can save 79 percent of the overall system power consumption of conventional accelerometer-based HAR.	activity recognition;data logger;motion detector;piezoelectricity;sensor;wearable technology	Sara Khalifa;Guohao Lan;Mahbub Hassan;Aruna Seneviratne;Sajal K. Das	2018	IEEE Transactions on Mobile Computing	10.1109/TMC.2017.2761744	kinetic energy;computer network;embedded system;wearable technology;activity recognition;accelerometer;computer science	Mobile	7.604104463998704	-85.99448831901415	185393
bb9a962c272abc7bd934649f581ae7cab7ea5d0c	a convolutional neural network-based sensor fusion system for monitoring transition movements in healthcare applications		This paper presents a convolutional neural network-based sensor fusion system to monitor six transition movements as well as falls in healthcare applications by simultaneously using a depth camera and a wearable inertial sensor. Weighted depth motion map images and inertial signal images are fed as inputs into two convolutional neural networks running in parallel, one for each sensing modality. Detection and thus monitoring of the transition movements and falls are achieved by fusing the movement scores generated by the two convolutional neural networks. The results obtained for both subject-generic and subject-specific testing indicate the effectiveness of this sensor fusion system for monitoring these transition movements and falls.	artificial neural network;convolutional neural network;laptop;modality (human–computer interaction);sensor web;wearable computer	Neha Dawar;Nasser Kehtarnavaz	2018	2018 IEEE 14th International Conference on Control and Automation (ICCA)	10.1109/ICCA.2018.8444326	convolutional neural network;control engineering;wearable computer;sensor fusion;engineering	Robotics	4.784910533280998	-85.39478575368081	185728
5a84d1fb7bc51d320e6b257546c82484ddb3cbd5	a pilot study on bsn-based ubiquitous energy expenditure monitoring	whole body;pilot study;energy expenditure;wrist;standard deviation;wearable body sensor network;acceleration accelerometers body sensor networks biomedical monitoring wrist abdomen wearable sensors mechanical variables measurement content addressable storage biology;biomechanics;wireless sensor networks acceleration measurement biomechanics biomedical measurement body area networks patient monitoring;data mining;acceleration;weight measurement;ankle;estimation;monitoring;whole body weighted acceleration value wearable body sensor network dynamic body energy expenditure monitoring wrist abdomen ankle acceleration signals;acceleration signals;abdomen;patient monitoring;whole body weighted acceleration value;correlation;acceleration measurement;body area networks;dynamic body energy expenditure monitoring;biomedical measurement;wireless sensor networks;body sensor network	This paper presented a wearable body sensor network (BSN) that could be potentially employed for dynamic body energy expenditure monitoring. Three compact BSN nodes were deployed at wrist, abdomen and ankle, respectively. Acceleration signals from the multiple body sites were used to calculate a whole body weighted acceleration value. Preliminary results indicated that the standard deviation of the whole body value was smaller than that from any individual body site. There was a strong linear correlation between the whole body weighted acceleration value and the speed, but this correlation was highly subject-dependant. The pilot study presented the first several steps towards a pervasive approach for body energy expenditure monitoring.	pervasive informatics;wearable computer	S. J. Lin;L. Wang;B. Y. Huang;Yaqin Zhang;X. M. Wu;J. P. Zhao	2009	2009 Sixth International Workshop on Wearable and Implantable Body Sensor Networks	10.1109/BSN.2009.56	acceleration;embedded system;estimation;simulation;wireless sensor network;biomechanics;remote patient monitoring;energy homeostasis;standard deviation;correlation;statistics	HCI	8.913229323225991	-86.66012673640621	186068
cc1a82884761675df94e03193cb7e54c48478fd7	wearable solutions using bioimpedance for cardiac monitoring			wearable computer	Mark Ulbrich;Jens Mühlsteff;Harald Reiter;Christian Meyer;Steffen Leonhardt	2015		10.3233/978-1-61499-597-5-30	wearable computer;biomedical engineering;cardiac monitoring;computer science	Robotics	9.178177238717284	-88.25423043283837	186193
b1c7a6e7a28a33ba9c6d05d3fb02dcbd77ff3fa3	an emotional expression monitoring tool for facial videos		The proliferation of mobile devices and the ubiquitous nature of cameras today serve to increase the importance of Emotionally Aware Computational Devices. We present a tool to help clinicians and mental health professionals to monitor and assess patients by providing an automated appraisal of a patient’s mood as determined from facial expressions. The App takes video as input from a patient and creates an annotated, configurable record for the clinician as output accessible from mobile devices, Internet or IoT devices.	accessibility;computation;emotion recognition;mobile device;prototype	Indrani Mandal;Terry Ferguson;Gabriel De Pace;Kunal Mankodiya	2017		10.1007/978-3-319-67585-5_77	mental health;multimedia;mood;the internet;human–computer interaction;computer science;mobile device;emotional expression;facial expression;internet of things	HCI	4.581047594248677	-89.83794844952837	186489
e4a8db050e40d69fc7e6c362c0d3314a29acfd9d	effects of fingertip orientation and flash location in smartphone photoplethysmography	smart phones blood medical signal processing photoplethysmography physiology;signal quality fingertip orientation flash location smartphone reflective photoplethysmography ppg blood capillaries physiological sensing;heart cameras lenses artificial intelligence	Smartphone based reflective Photoplethysmography (PPG) measures reflected light from blood capillaries, typically from the fingertip of a user. It has gained popularity as a means of unobtrusive affordable physiological sensing. The orientation and relative distance between smartphone flash and camera; fingertip placement direction etc. highly influences the captured PPG signal quality, and hence affects the estimation quality of physiological parameters. In this paper, the frames captured by smartphone camera are divided into smaller blocks and all the blocks are compared for heart rate estimation. Results indicate that the best fingertip video is captured when the finger is pointing towards the flash. It is also demonstrated that the blocks having similar distance to the flash yield similar quality PPG. The observation is validated against two popular off-the-shelf smartphones, having different flash position with respect to the camera.	algorithmic efficiency;computation;smartphone;unobtrusive javascript	Aishwarya Visvanathan;Rohan Banerjee;Aditi Misra;Anirban Dutta Choudhury;Arpan Pal	2014	2014 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2014.6968536	embedded system;computer vision;engineering;computer graphics (images)	Mobile	9.168855029487062	-85.27505218623148	186705
ba6c3e6dcb0cb28ac8caec727b2974a761e41898	audio-to-score alignment at the note level for orchestral recordings		In this paper we propose an offline method for refining audio-to-score alignment at the note level in the context of orchestral recordings. State-of-the-art score alignment systems estimate note onsets with a low time resolution, and without detecting note offsets. For applications such as score-informed source separation we need a precise alignment at note level. Thus, we propose a novel method that refines alignment by determining the note onsets and offsets in complex orchestral mixtures by combining audio and image processing techniques. First, we introduce a note-wise pitch salience function that weighs the harmonic contribution according to the notes present in the score. Second, we perform image binarization and blob detection based on connectivity rules. Then, we pick the best combination of blobs, using dynamic programming. We finally obtain onset and offset times from the boundaries of the most salient blob. We evaluate our method on a dataset of Bach chorales, showing that the proposed approach can accurately estimate note onsets and offsets.	blob detection;dynamic programming;image processing;offset (computer science);online and offline;onset (audio);sensor;source separation	Marius Miron;Julio J. Carabias-Orti;Jordi Janer	2014			computer vision;speech recognition;artificial intelligence	Vision	-3.160272056735962	-90.20706663720296	187031
a7983cff644a57f5087f57c670524166f3b9e929	using a smartwatch to detect stereotyped movements in children with developmental disabilities	gyroscopes;accelerometers activity recognition gyroscopes training windows;training;windows;activity recognition assisted living machine learning;accelerometers;activity recognition	It is important to determine when and why stereotyped movements indicative of developmental disabilities occur in order to provide timely medical treatment. However, these behaviors are unpredictable, which renders their automatic detection very useful. In this paper, we propose a machine learning system that runs on a smartwatch and a smartphone to recognize stereotyped movements in children with developmental disabilities. We train a classifier by tagging data from an accelerometer and a gyroscope in a smartwatch to one of six stereotyped movements made by children and recognized by special educational needs teachers. This classifier can then recognize when a child wearing a smartwatch is making one of the stereotyped movements. These schemes were implemented as a suite of apps used by parents and caregivers. In tests on children and young people with developmental disabilities, the system achieved an average recognition accuracy of 91% when individual training data was used.	gyroscope;machine learning;rendering (computer graphics);smartphone;smartwatch	Yeongju Lee;Minseok Song	2017	IEEE Access	10.1109/ACCESS.2017.2689067	simulation;speech recognition;gyroscope;computer science;operating system;accelerometer;activity recognition	HCI	6.174857925825849	-87.0678959253778	187032
a3383f42f1476081c1e139da12b402c89d0dc72a	automatic fall detection system with a rgb-d camera using a hidden markov model		Falls in the elderly is a major public health problem because of their frequency and their medical and social consequences. New smart assistive technologies and Health Telematics make it possible to provide elderly with more security and well being at home. A smart home can automatically monitor home activities for early warning in health changes or detecting dangerous situations. One of our objectives is to design an automatic system to detect fall at home, which in its final version will be made up of a network of RGB-D sensors. In this paper, we present a simple and robust method based on the identification and tracking of the center of mass of people evolving in an indoor environment. Using a simple Hidden Markov Model whose observations are the position of the center of mass, its velocity and the general shape of the body, we can surprisingly monitor the activity of a person with high accuracy and thus detect falls with very good accuracy without false positives. An experimental study, that is reported here, has been driven in our smart apartment lab. 26 subjects were asked to perform a predefined scenario in which they realized a set of eight postures. 2 hours of video (216 000 frames) were recorded for the evaluation, half of it being used for the training of the model. The system detected the falls without false positives. This result encourages us to use this system in real situation for a better study of its efficiency.	algorithm;assistive technology;experiment;hidden markov model;home automation;markov chain;rgd;regular expression;sensor;telematics;velocity (software development)	Amandine Dubois;François Charpillet	2013		10.1007/978-3-642-39470-6_33	embedded system;computer vision;simulation;computer security	HCI	6.5926792464763935	-85.14156432342239	187320
02287a6841ce0a23e6e232a22e2aeaaefdf6b080	sensiblesleep: a bayesian model for learning sleep patterns from smartphone events	circadian rhythms;learning;cell phones;sleep;probability distribution;algorithms;behavior;accelerometers	We propose a Bayesian model for extracting sleep patterns from smartphone events. Our method is able to identify individuals' daily sleep periods and their evolution over time, and provides an estimation of the probability of sleep and wake transitions. The model is fitted to more than 400 participants from two different datasets, and we verify the results against ground truth from dedicated armband sleep trackers. We show that the model is able to produce reliable sleep estimates with an accuracy of 0.89, both at the individual and at the collective level. Moreover the Bayesian model is able to quantify uncertainty and encode prior knowledge about sleep patterns. Compared with existing smartphone-based systems, our method requires only screen on/off events, and is therefore much less intrusive in terms of privacy and more battery-efficient.	appendiceal neoplasms;appendix;bayesian network;conceptualization (information science);dvb-s2;data curation;digital curation;encode;estimated;f1 score;greater than;ground truth;heterojunction;inference;interaction;network analyzer (ac power);portable document format;sl (complexity);seizures;sleep polysomnography domain;sleep mode;smartphone;unix time;user identifier;zip code	Andrea Cuttone;Per Baekgaard;Vedran Sekara;Håkan Jonsson;Jakob Eg Larsen;Sune Lehmann	2017		10.1371/journal.pone.0169901	probability distribution;biology;sleep;behavior	Web+IR	2.274336386722684	-85.27599935862946	187561
35ec5c47b41b97ca204ffcd3ae1bc6bebb326b0a	a smartphone based method to enhance road pavement anomaly detection by analyzing the driver behavior	driver behaviour;smartphone sensing;anomaly detection;road monitoring	This paper introduces a method to detect road anomalies by analyzing driver behaviours. The analysis is based on the data and the features extracted from smartphone inertial sensors to calculate the angle of swerving and also based on distinctive states of a driver behaviour event. A novel approach is introduced to deal with the gyroscope drift, reducing the average angle estimation error for curves up to 2° and the overall average angle error up to 5°. Using a simple machine learning approach and a clustering algorithm, the method can detect 70% of the swerves and 95% of the turns on the road.	algorithm;anomaly detection;clock drift;cluster analysis;gyroscope;machine learning;sensor;smartphone	Fatjon Seraj;Kyle Zhang;Okan Turkes;Nirvana Meratnia;Paul J. M. Havinga	2015		10.1145/2800835.2800981	embedded system;anomaly detection;simulation;computer science;machine learning;computer security	Mobile	5.721985497075765	-85.31002119713516	187597
d8c3c2e40129a6e6ef97e55f910a9d9ca516a428	magnetic field as a characterization of wide and narrow spaces in a real challenging scenario using dynamic time warping		This paper presents a study of indoor positioning in public zones of the Parc Taulí Hospital in Sabadell. It is a challenging scenario because: 1) it combines wide spaces with middle sized and narrow spaces; 2) it is a shielded zone where no signals are available, and therefore, no WiFi signal can be used for positioning; and 3) it is not possible to deploy beacons for positioning. The goal of this work is to test whether it is possible to get indoor positioning in a real and challenging scenario by using only the magnetic field. The positioning precision requires to locate the part of the hospital where the user is. The proposed solution defines “virtual corridors” to improve positioning in wide areas. To validate the work, magnetic field data have been recorded from the scenario, using different smartphones and by different persons. The obtained magnetic data curves have been compared by using dynamic time warping distance. Results show that it is possible to characterize every path with the magnetic field. The main contributions of the present paper are: 1) defining “virtual corridors” as a way to position using magnetic field in 2D spaces; and 2) showing that even in wide spaces, like the hall of a hospital, it is possible to find magnetic anomalies linked to positions.	dynamic time warping;smartphone;spaces	Antoni Pérez-Navarro;Raúl Montoliu;Joaquín Torres-Sospedra;Jordi Conesa	2018	2018 International Conference on Indoor Positioning and Indoor Navigation (IPIN)	10.1109/IPIN.2018.8533741		Robotics	6.394240043558018	-85.84178650846007	187658
9d9958a09f3fbf67b81e91599e13c8cce13e86bf	audiovisual spatial-audio analysis by means of sound localization and imaging: a multimedia healthcare framework in abdominal sound mapping	biomedical monitoring;contemporary multimedia audiovisual spatial audio analysis imaging multimedia health care framework abdominal sound mapping sound field localization sound field visualization technique content description content management gim topographic analysis gim mapping gastro intestinal motility gim physiology patterns as source localization method sound level distribution image audio description audio management audiovisual summarization audiovisual highlighting psychophysiological parameters bioacoustics;multimedia communication medical services monitoring medical diagnostic imaging visualization biomedical monitoring;visualization;medical services;monitoring;sound localization abdominal sounds as audiovisual content management multimedia based healthcare multimodal monitoring spatial audio analysis sound imaging;multimedia communication;medical signal processing acoustic signal processing health care;medical diagnostic imaging	This paper presents the novel sound-field localization and visualization techniques for audiovisual spatial audio analysis, content description, and management. The method focuses on topographic analysis and mapping of gastro-intestinal motility (GIM) through multichannel recording of abdominal sounds (AS). Related research has attempted to study GIM physiology patterns and diagnose specific abnormalities or diseases. In this context, a new AS source localization method is implemented and evaluated. Sound imaging and spatiotemporal mapping utilities are deployed next by means of sound level distribution images. Novel audio description and management is introduced for the analysis automation of prolonged AS recordings, facilitating smart content browsing with audiovisual summarization and highlighting. The proposed modalities can be utilized in multimedia healthcare applications, where multimodal monitoring of GIM and other psychophysiological parameters can be combined for the study of human digestive patterns and their relation to other factors (i.e., subjects' medical history, nutrition, medication, psychological state, and others). The adopted methodology of spatial audio analysis introduces a generic framework that can be efficiently applied to various sound localization and imaging tasks, which are encountered both in bioacoustics and in contemporary multimedia involving multichannel/3D audio.	audio description;mental state;multimodal interaction;sound card;surround sound;topography	Charalampos Dimoulas	2016	IEEE Transactions on Multimedia	10.1109/TMM.2016.2594148	computer vision;speech recognition;visualization;telecommunications;computer science;multimedia	Visualization	3.523309223214023	-90.34848212819055	187666
e2d5565a505b91df96df178b4f81d57c795af877	a framework for hand gesture recognition based on accelerometer and emg sensors	sign language recognition;decision tree;sensors;hidden markov models hmms acceleration electromyography hand gesture recognition;hidden markov model;real time;gesture based interaction hand gesture recognition emg sensor three axis accelerometer multichannel electromyography sensor emg signal decision tree multistream hidden markov model sign language recognition chinese sign language words gesture based control virtual rubiks cube game;chinese sign language;acceleration;medical signal processing accelerometers biosensors decision trees electromyography gesture recognition hidden markov models;electromyography hidden markov models gesture recognition sensors acceleration decision trees;hidden markov models;interactive system;hidden markov models hmms;electromyography;information fusion;hand gesture recognition;decision trees;accelerometers;gesture recognition;medical signal processing;biosensors	This paper presents a framework for hand gesture recognition based on the information fusion of a three-axis accelerometer (ACC) and multichannel electromyography (EMG) sensors. In our framework, the start and end points of meaningful gesture segments are detected automatically by the intensity of the EMG signals. A decision tree and multistream hidden Markov models are utilized as decision-level fusion to get the final results. For sign language recognition (SLR), experimental results on the classification of 72 Chinese Sign Language (CSL) words demonstrate the complementary functionality of the ACC and EMG sensors and the effectiveness of our framework. Additionally, the recognition of 40 CSL sentences is implemented to evaluate our framework for continuous SLR. For gesture-based control, a real-time interactive system is built as a virtual Rubik's cube game using 18 kinds of hand gestures as control commands. While ten subjects play the game, the performance is also examined in user-specific and user-independent classification. Our proposed framework facilitates intelligent and natural control in gesture-based interaction.	apache axis;decision tree;electromyography;experiment;gesture recognition;hidden markov model;interactivity;markov chain;poor posture;real-time clock;real-time locating system;sensor	Xu Zhang;Xiang Chen;Yun Li;Vuokko Lantz;Kongqiao Wang;Jihai Yang	2011	IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans	10.1109/TSMCA.2011.2116004	speech recognition;computer science;machine learning;decision tree;pattern recognition;gesture recognition;hidden markov model	Robotics	0.5899482530226388	-88.28568695145343	187770
c8efcb36da07bc83d04d31345e551be38469d44c	objective characterization of human behavioural characteristics for qoe assessment: a pilot study on the use of electroencephalography features	speech;human behavioural characteristics speech quality levels beta coupling delta coupling negative behavioral characteristics beta eeg delta eeg speech stimulus qoe metrics neurophysiological insights overall behavioral systems human emotions human cognition neuronal activity neurophysiological monitoring tools human behavioral states human centric paradigm quality of experience electroencephalography features qoe assessment;electrodes;electroencephalography couplings electrodes speech correlation quality of service conferences;correlation;electroencephalography;couplings;quality of service;speech processing electroencephalography medical signal processing neurophysiology quality of experience;conferences	Quality of Experience (QoE) is a human-centric paradigm which produces the blue print of human behavioral states such as perception, emotion, cognition and expectation. Recent advances in neurophysiological monitoring tools have facilitated the study of frequency, time and location of neuronal activity to an unprecedented degree, as well as opened doors to a better understanding of human cognition, emotions and overall behavioral systems. These neurophysiological insights may provide more accurate and objective characterization of QoE metrics. This paper seeks to investigate neuronal activity generated by three different quality levels of a speech stimulus using electroencephalography (EEG). To this end, an electroencephalography (EEG) feature was computed based on the coupling between so-called delta and beta EEG frequency bands, which has previously been linked with negative behavioral characteristics (anxiety, frustration, dissatisfaction). The result indicates an increase in delta and beta coupling with a decrease in the speech quality levels. Additionally, neural correlates of a subjective affective scores (arousal and valence) were also computed and shown to be inversely proportional with EEG feature. These preliminary findings corroborate that emotions play a significant role in human quality and QoE perception.	blueprint;cognition;consciousness;electroencephalography;frequency band;programming paradigm	Khalil ur Rehman Laghari;Rishabh Gupta;Jan-Niklas Antons;Robert Schleicher;Sebastian Möller;Tiago H. Falk	2013	2013 IEEE Globecom Workshops (GC Wkshps)	10.1109/GLOCOMW.2013.6825151	quality of service;electroencephalography;computer science;speech;electrode;coupling;correlation	HCI	1.3948316130526672	-92.82288085248116	187876
00b1267e841a66e4640ee9614f11cfbd33cccf7f	wearable technologies: one step closer to gait rehabilitation in parkinson's patients		Wearable computing has the potential to fundamentally alter healthcare by enabling long-term patient monitoring and rehabilitation outside of the lab.	wearable computer;wearable technology	Sinziana Mazilu;Gerhard Tröster	2014	ACM Crossroads	10.1145/2676578	internet privacy;rehabilitation;wearable technology;wearable computer;remote patient monitoring;human–computer interaction;gait;computer science	HCI	7.659215962294624	-90.09039052872308	188128
98ab6934bba7e391158fe5cd7873b7d283f51b52	a real-time human stress monitoring system using dynamic bayesian network	performance measure;biomedical monitoring;stress;mice;real time;bayesian methods;psychology;data mining;physics computing;computer vision;real time systems stress bayesian methods human factors data mining biomedical monitoring mice physics computing computer vision psychology;monitoring system;human factors;dynamic bayesian network;eye movement;active sensing;facial expression;user interaction;real time systems	We present a real time non-invasive system that infers user stress level from evidences of different modalities. The evidences include physical appearance (facial expression, eye movements, and head movements) extracted from video via visual sensors, physiological conditions collected from an emotional mouse, behavioral data from user interaction activities with the computer, and performance measures. We provide a Dynamic Bayesian Network (DBN) framework to model the user stress and these evidences. We describe the computer vision techniques we used to extract the visual evidences, the DBN model for modeling stress and the associated factors, and the active sensing strategy to collect the most informative evidences for efficient stress inference. Our experiments show that the inferred user stress level by our system is consistent with that predicted by psychological theories.	computer vision;dynamic bayesian network;experiment;information;real-time transcription;sensor;theory	Wenhui Liao;Weihong Zhang;Zhiwei Zhu;Qiang Ji	2005	2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05) - Workshops	10.1109/CVPR.2005.394	computer vision;simulation;bayesian probability;computer science;human factors and ergonomics;machine learning;data mining;stress;facial expression;dynamic bayesian network;eye movement	Vision	7.499696147149956	-86.8521209771621	188488
36a5080ab1d5c5ba00804ff1e364870da0eb803b	a driver fatigue detection method based on multi-sensor signals	fatigue;support vector machines cameras fatigue feature extraction image fusion pattern classification safety;support vector machines;iris recognition;visualization;fatigue vehicles feature extraction support vector machines visualization iris recognition cameras;feature extraction;fatigue transitional process driver fatigue detection method multisensor signal transportation safety driver safety long time driving kinect 2 0 camera ppg pulse sensor training classifier feature extraction feature fusion sample labelling svm classifier designing;vehicles;cameras	Fatigue during long-time driving threatens the safety of drivers and transportation. In this paper, we provide an effective method based on multi-sensor signals collected from Kinect2.0 camera and PPG pulse sensor to build a driver fatigue detection system. Unlike most traditional works, we define the transitional process of fatigue and elaborate its effect on training classifiers. The simulation experiments are then designed and 15 groups of data are collected. Our method works in the following steps: 1) feature extraction and fusion, 2) sample labelling and 3) SVM classifier designing. The 10-fold cross-validation accuracy of the classifier is 90.10% and the test accuracy is 83.82%. Experimental results verify that our method to deal with samples in transitional process is universal and more accurate than traditional methods. Moreover, our method based on multi-sensor works better than those dealing with single-sensor.	cross-validation (statistics);effective method;experiment;feature extraction;sensor;simulation	Hao Yin;Yuanqi Su;Yuehu Liu;Danchen Zhao	2016	2016 IEEE Winter Conference on Applications of Computer Vision (WACV)	10.1109/WACV.2016.7477672	support vector machine;computer vision;speech recognition;visualization;feature extraction;computer science;machine learning;pattern recognition;iris recognition	Vision	5.868249650037647	-84.64538873935183	188941
6847e41af5b01b0822c3fca6d1b246401c142405	movement analysis for the assessment of hearing in patients with cognitive impairment: a preliminary study		Patients with severe cognitive impairment are not capable of interacting with the audiologist during an audiology test. However, these patients often show gestural reaction to the auditory stimuli that can be interpreted by audiologists with comprehensive experience in this type of case. In this study, we analyze the area around the eyes and the movements that occur within it, since is in this area where most of gestural reactions take place for these patients.		A. Fernández-Arias;Marcos Ortega;B. Cancela-Barizo;Luz M. Gigirey	2013		10.1007/978-3-642-53862-9_18	machine learning;computer science;artificial intelligence;stimulus (physiology);audiologist;audiology;cognition	ML	9.151036350759199	-91.90588903372353	189309
fc4f3c20ee8b59ff8e9149683aff8abe325a172f	classification methods based on bayes and neural networks for human activity recognition	libraries;neural networks;sensors;training;graphical user interfaces;accelerometers;java	The Human Activity Recognition is a context awareness application, which has, for example, sports, security and health monitoring applications. As a way to acquire the human activity data, there are external approaches (e.g. cameras data) and embedded approaches (e.g. accelerometer data). In this area, we can find solutions using multiple sensors simultaneously supporting the real time data acquisition. In the other hand, there are researchers focusing in an optimized and accurate way to classify the activity based on large amount of data. In this paper the Bayes Network and Neural Network classifiers were used. They were built from a public dataset regarding data acquired from accelerometers worn by a set of people. Considering the Data Mining classification steps, the attributes selection, the building and training, the validation tests were done, resulting in the Confusion Matrix, the accuracy rate and the processing time. The goal is to compare different classification methods using different building and training techniques, matching the dataset specifications and quirks, assessing the performance and accuracy rates impacts. A Java program was implemented using the Data Mining public library called Weka. With smaller processing times than the Bayes Network, the implemented Neural Networks had excellent results. The Bayes Network requires a further investigation on configuration and validation techniques, it had the largest processing times, and reached the best results using the k-fold cross-validation technique.	activity recognition;bayesian network;confusion matrix;context awareness;cross-validation (statistics);data acquisition;data mining;embedded system;java;neural networks;public library;sensor;weka	Leopoldo Marchiori Rodrigues;Mário Mestria	2016	2016 12th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)	10.1109/FSKD.2016.7603339	computer science;sensor;artificial intelligence;data science;machine learning;data mining;graphical user interface;java;accelerometer;artificial neural network;statistics	ML	4.118699640347945	-85.58143687556266	189339
6d9a7ef65b70431e78440dc21df998df24975071	smartphone based fall prevention exercises	geriatrics;dissertacao;smart phones;inertial sensors fall prevention smartphone android exercises falls older people;smart phones geriatrics health care;engenharia electrotecnica electronica e informatica;built in inertial sensors smartphone fall prevention exercises older adults ict based fall prevention solution fall prevention exercise programme portuguese population smartphone processing capabilities;sensors androids humanoid robots games gravity accelerometers senior citizens;health care	Falling is a very serious problem for our society, as it affects one out of three older adults. Currently, this is a well-known problem and therefore multiple ICT-based solutions for falls management exist. In addition, a small part of them are said to help preventing falls, but most of the reviewed solutions doesn't seem to have their focus in reducing specific fall risk factors like loss of muscle mass or a poor balance. The proposed ICT-based fall prevention solution is based on an existing fall prevention exercise programme specifically designed for the Portuguese population. It takes advantage of the smartphone processing capabilities as well as its built-in inertial sensors to evaluate the movements performed during the execution of specific exercises. Using only a simple smartphone it is possible to provide a friendly and inexpensive solution capable of increasing seniors' adherence to fall prevention exercises as well as raise their motivation to properly execute the exercises in their home environment.	canonical account;population;risk factor (computing);sensor;smartphone	Bruno Chaves Ferreira;Vânia Guimarães;Hugo Sereno Ferreira	2013	2013 IEEE 15th International Conference on e-Health Networking, Applications and Services (Healthcom 2013)	10.1109/HealthCom.2013.6720755	embedded system;simulation;engineering;physical therapy	Visualization	5.8504807805435615	-89.11910741862904	190078
ecdecb0a4408d7c332f11f54a79b524e78b55232	analyzing feature trajectories for event detection	gaussian mixture;inverse document frequency;gaussian;event detection;time series;feature categorization;time series data;spectral analysis;frequency domain;dft;document frequency	We consider the problem of analyzing word trajectories in both time and frequency domains, with the specific goal of identifying important and less-reported, periodic and aperiodic words. A set of words with identical trends can be grouped together to reconstruct an event in a completely un-supervised manner. The document frequency of each word across time is treated like a time series, where each element is the document frequency - inverse document frequency (DFIDF) score at one time point. In this paper, we 1) first applied spectral analysis to categorize features for different event characteristics: important and less-reported, periodic and aperiodic; 2) modeled aperiodic features with Gaussian density and periodic features with Gaussian mixture densities, and subsequently detected each feature's burst by the truncated Gaussian approach; 3) proposed an unsupervised greedy event detection algorithm to detect both aperiodic and periodic events. All of the above methods can be applied to time series data in general. We extensively evaluated our methods on the 1-year Reuters News Corpus [3] and showed that they were able to uncover meaningful aperiodic and periodic events.	categorization;greedy algorithm;spectrum analyzer;supervised learning;tf–idf;time series	Qi He;Kuiyu Chang;Ee-Peng Lim	2007		10.1145/1277741.1277779	speech recognition;machine learning;time series;pattern recognition;statistics	Web+IR	-2.6233872027749356	-93.7490872370095	190150
0589257ffd8a2f40ff354b20917547605c61e11f	wearable health monitoring using capacitive voltage-mode human body communication		Rapid miniaturization and cost reduction of computing, along with the availability of wearable and implantable physiological sensors have led to the growth of human Body Area Network (BAN) formed by a network of such sensors and computing devices. One promising application of such a network is wearable health monitoring where the collected data from the sensors would be transmitted and analyzed to assess the health of a person. Typically, the devices in a BAN are connected through wireless (WBAN), which suffers from energy inefficiency due to the high-energy consumption of wireless transmission. Human Body Communication (HBC) uses the relatively low loss human body as the communication medium to connect these devices, promising order(s) of magnitude better energy-efficiency and built-in security compared to WBAN. In this paper, we demonstrate a health monitoring device and system built using Commercial-Off-The-Shelf (COTS) sensors and components, that can collect data from physiological sensors and transmit it through a) intra-body HBC to another device (hub) worn on the body or b) upload health data through HBC-based human-machine interaction to an HBC capable machine. The system design constraints and signal transfer characteristics for the implemented HBC-based wearable health monitoring system are measured and analyzed, showing reliable connectivity with >8× power savings compared to Bluetooth low-energy (BTLE).	bluetooth;built-in self-test;computation (action);emoticon;human-based computation;human–computer interaction;implants;low sodium diet;mental suffering;miniaturization;monitoring device;systems design;usb hub;upload;wearable computer;disease transmission;sensor (device);voltage	Shovan Maity;Debayan Das;Shreyas Sen	2017	2017 39th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2017.8036748	computer network;wearable computer;wireless;capacitive sensing;miniaturization;systems design;embedded system;computer science;body area network;bluetooth;upload	Mobile	9.093567508280469	-89.18822638542365	190165
e6556a463c21cc3b114ac63b02b1667a73ff7d2c	learning environmental sounds with multi-scale convolutional neural network		Deep learning has dramatically improved the performance of sounds recognition. However, learning acoustic models directly from the raw waveform is still challenging. Current waveform-based models generally use time-domain convolutional layers to extract features. The features extracted by single size filters are insufficient for building discriminative representation of audios. In this paper, we propose multi-scale convolution operation, which can get better audio representation by improving the frequency resolution and learning filters cross all frequency area. For leveraging the waveform-based features and spectrogram-based features in a single model, we introduce twophase method to fuse the different features. Finally, we propose a novel end-to-end network called WaveMsNet based on the multi-scale convolution operation and two-phase method. On the environmental sounds classification datasets ESC-10 and ESC-50, the classification accuracies of our WaveMsNet achieve 93.75% and 79.10% respectively, which improve significantly from the previous methods.	acoustic cryptanalysis;acoustic model;convolution;convolutional neural network;deep learning;end-to-end principle;spectrogram;teaching method;two-phase locking;waveform	Boqing Zhu;Changjian Wang;Feng Liu;Jin Lei;Zhen Huang;Yuxing Peng;Fei Li	2018	2018 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2018.8489641	machine learning;discriminative model;convolutional neural network;task analysis;time–frequency analysis;pattern recognition;deep learning;artificial intelligence;feature extraction;computer science;convolution;waveform	Vision	-4.229460572200046	-87.41700085972741	190484
27fe2d3214d7837fd191b6c06b9a89faa48cb8e6	multi-label classifier chains for bird sound		Bird sound data collected with unattended microphones for automatic surveys, or mobile devices for citizen science, typically contain multiple simultaneously vocalizing birds of different species. However, few works have considered the multi-label structure in birdsong. We propose to use an ensemble of classifier chains combined with a histogram-ofsegments representation for multi-label classification of birdsong. The proposed method is compared with binary relevance and three multi-instance multi-label learning (MIML) algorithms from prior work (which focus more on structure in the sound, and less on structure in the label sets). Experiments are conducted on two real-world birdsong datasets, and show that the proposed method usually outperforms binary relevance (using the same features and base-classifier), and is better in some cases and worse in others compared to the MIML algorithms.	algorithm;citizen science;classifier chains;experiment;microphone;mobile device;multi-label classification;multiclass classification;relevance	Forrest Briggs;Xiaoli Z. Fern;Jed Irvine	2013	CoRR		speech recognition;computer science;machine learning	AI	-3.7122929289663404	-88.46468058478149	190507
6c28001150db1020bad0df1486ca33ff73a95499	personalization and adaptation to the medium and context in a fall detection system	intelligent sensor;geriatrics;chronic disease;pedestrian safety;detection algorithms;poison control;injury prevention;distributed processing;daily living activities;biomechanics;safety literature;fall detection;firmware;personalization;traffic safety;smart sensor;injury control;design space;acceleration;medical computing;design for all;home safety;injury research;safety abstracts;human factors;biomedical engineering;monitoring;acceleration accidental falls activities of daily living adult algorithms artificial intelligence feasibility studies female humans male monitoring ambulatory reproducibility of results signal processing computer assisted telemetry wireless technology;personalization daily living activities distributed processing dynamic adaptation fall detection;occupational safety;safety;detection algorithm;diseases;safety research;medical computing biomechanics biomedical engineering diseases distributed processing firmware geriatrics intelligent sensors;acceleration optimization intelligent sensors monitoring detection algorithms accelerometers;accident prevention;violence prevention;optimization;bicycle safety;activity of daily living;poisoning prevention;dynamic adaptation;accelerometers;falls;ergonomics;suicide prevention;intelligent sensors;adaption mechanism fall detection system distributed processing architecture optimization module remote firmware update smart sensors elderly patients chronic diseases adl level classification	"""The main objective of this paper is to present a distributed processing architecture that explicitly integrates capabilities for its continuous adaptation to the medium, the context, and the user. This architecture is applied to a falling detection system through: (1) an optimization module that finds the optimal operation parameters for the detection algorithms of the system devices; (2) a distributed processing architecture that provides capabilities for remote firmware update of the smart sensors. The smart sensor also provides an estimation of activities of daily living (ADL), which results very useful in monitoring of the elderly and patients with chronic diseases. The developed experiments have demonstrated the feasibility of the system and specifically, the accuracy of the proposed algorithms and procedures (100% success for impact detection, 100% sensitivity and 95.68% specificity rates for fall detection, and 100% success for ADL level classification). Although the experiments have been developed with a cohort of young volunteers, the personalization and adaption mechanisms of the proposed architecture related to the concepts of """"design for all"""" and """"design space"""" will significantly ease the adaptation of the system for its application to the elderly."""	accidental falls;acclimatization;algorithm;channel capacity;chronic disease;day care, medical;distributed computing;energy metabolism;experiment;firmware;mathematical optimization;movement;obstruction;patch (computing);patients;personalization;preparation;sensitivity and specificity;smart transducer;specification;stage level 1;supervised learning;systems design;usability;sensor (device)	David Naranjo-Hernández;Laura M. Roa;Javier Reina-Tosina;Miguel A. Estudillo-Valderrama	2012	IEEE Transactions on Information Technology in Biomedicine	10.1109/TITB.2012.2185851	embedded system;simulation;activities of daily living;medicine;computer science;human factors and ergonomics;computer security;intelligent sensor	Mobile	7.559185886372894	-87.84840381521751	190609
fa1c0a0c360dcd1baae6e02168777f435b260c80	instant learning sound sensor for ubiquitous computing	context information;acoustic sensors ubiquitous computing intelligent sensors sensor systems event detection signal processing algorithms sensor phenomena and characterization temperature sensors microphones algorithm design and analysis;time series;smart sensor;pressure sensor;signal processing method instant learning sound sensor ubiquitous computing smart sound sensor time series signal context aware system ubiquitous service;ubiquitous computing intelligent sensors signal processing time series;signal processing;ubiquitous computing;context aware systems;intelligent sensors	We propose a smart sound sensor for ubiquitous computing that can learn and detect events from various sensor information with a time series signal. Using the smart sensor, a developer of a context-aware system and ubiquitous service can easily utilize a real world sound as a context information without a signal processing programming. The signal processing method can be extended for the other sensors such as accelerometer and directional sensor, pressure sensor, etc. By the experiment, we evaluate the feasibility of the instant learning sound sensor	algorithm;fast fourier transform;microcomputer;prototype;sensor;signal processing;smart transducer;time series;ubiquitous computing	Yuya Negishi;Nobuo Kawaguchi	2007	2007 International Symposium on Applications and the Internet Workshops	10.1109/SAINT-W.2007.52	sensor web;embedded system;real-time computing;sensor node;soft sensor;computer science;pressure sensor;signal processing;time series;ubiquitous robot;ubiquitous computing;statistics;intelligent sensor;visual sensor network	Mobile	5.208796911581921	-86.91782389201627	190763
84fa87bb0cf9baf7f72c03e43204c3f95d57ce38	a hierarchical approach to onset detection	time window;support vector;onset detection	Onset detection in vocal music and many other instruments is complicated by the possibility of soft transitions between notes. Most systems try to identify onsets within a short-time window as it is easier to define transition functions over a restricted space. However, it may not be possible to detect soft onsets without considering a long-time window, for which defining and computing the transition function can be hard and computationally costly. We present a method which looks for onsets between locations of increasing distance and is able to capture such onsets without considering all the points within the window. For the onset identification function we use both a simple manual function and support vector machines trained using a labelled corpus.	onset (audio);support vector machine	Emir Kapanci;Avi Pfeffer	2004			support vector machine;computer science;artificial intelligence;pattern recognition	AI	-3.17526946051761	-90.0244859922668	190834
ca07e7d14ea3b55f3ffe8df92d5cd467012cd77f	data decision and transmission based on mobile data health records on sensor devices in wireless networks		The contradiction between a large population and limited and unevenly distributed medical resources is a serious problem in many developing countries. This problem not only affects human health but also leads to the occurrence of serious infection if treatment is delayed. With the development of wireless communication network technology, patients can acquire real-time medical information through wireless network equipment. Patients can have the opportunity to obtain timely medical treatment, which may alleviate the shortage of medical resources in developing countries. This study establishes a new method that can decide and transmit effective data based on sensor device mobile health in wireless networks. History data, collection data, and doctor-analyzed data could be computed and transmitted to patients using sensor devices. According to probability analysis, patients and doctors may confirm the possibility of certain diseases.		Jia Wu;Zhi-gang Chen	2016	Wireless Personal Communications	10.1007/s11277-016-3438-y	data mining;computer security;computer network	Mobile	6.001247557373649	-88.39929937395142	191181
98debdc7c6a151d949eb782c610de65fa4c56a77	health score prediction using low-invasive sensors	instrumental adl;machine learning;sensor	Scores of health state for elderly people are regarded as important in nursing or medical fields. On the other hand, gaining the scores needs nurses to execute questionnaires. Owing to this, the execution rate for the health assessment is still low in ordinary homes. To solve this problem, we propose a method to predict the health score by using low-invasive sensors. We adopt regression as the prediction method and construct features to absorb the individual difference. As a part of feasibility study of social participation for elderly people, we execute the survey of health state using questionnaires by a nurse and install low-invasive sensors in real life simultaneously. Experimental result in the feasibility study shows a promise of the score prediction from sensor data. In addition, the result suggests that the extraction of features related to living behaviors improves the accuracy compared to using raw sensor data.	gene prediction;real life;sensor	Masamichi Shimosaka;Shinya Masuda;Kazunari Takeichi;Rui Fukui;Tomomasa Sato	2012		10.1145/2370216.2370439	simulation;computer science;sensor;artificial intelligence;data mining	HCI	5.579606520828493	-86.40696169301037	191438
ddcc6dc5736dc6f65913d955e236e3f59cb38a62	implementation of a wearable sensor vest for the safety and well-being of children	sensor;wearable computing	This paper presents a prototype wearable vest for improving the safety and well-being of children in nurseries, daycare centres and primary schools. The safety vest is built around the LilyPad Arduino and Adafruit Flora platforms with Xbee radio module, GPS, temperature and accelerometer sensors. The vest will automatically gather and provide information about the location and well-being of the children. Teachers are able to receive alerts and notifications, e.g., when a child moves across certain restricted outdoor or indoor area. All the information gathered by the vest is made available through the web utilising Sensor Web Enablement (SWE) services to guarantee a standardised way to manage the data coming from multiple sources. The vest is part of a larger framework to provide digital safety applications and services for parents and teachers. c © 2014 The Authors. Published by Elsevier B.V. Selection and peer-review under responsibility of Elhadi M. Shakshuki.	arduino;context awareness;global positioning system;internet safety;point of view (computer hardware company);prototype;real-time computing;real-time transcription;sensor web;socialization;wearable computer	Mirjami Jutila;Helena Rivas;Pekka Karhula;Susanna Pantsar-Syväniemi	2014		10.1016/j.procs.2014.05.507	embedded system;simulation;computer security	Mobile	5.082636962858643	-89.26899212974665	191459
d2fba6a7daabe9c84e4b4518dddd7830bbcc6f57	investigating the feasibility of vehicle telemetry data as a means of predicting driver workload	tl motor vehicles aeronautics astronautics	Driving﻿is﻿a﻿safety﻿critical﻿task﻿that﻿requires﻿a﻿high﻿level﻿of﻿attention﻿from﻿the﻿driver.﻿Although﻿drivers﻿ have﻿limited﻿attentional﻿resources,﻿they﻿often﻿perform﻿secondary﻿tasks﻿such﻿as﻿eating﻿or﻿using﻿a﻿mobile﻿ phone.﻿When﻿performing﻿multiple﻿tasks﻿in﻿the﻿vehicle,﻿the﻿driver﻿can﻿become﻿overloaded﻿and﻿the﻿ risk﻿of﻿a﻿crash﻿is﻿increased.﻿If﻿a﻿vehicle﻿is﻿aware﻿that﻿the﻿driver﻿is﻿currently﻿under﻿high﻿workload,﻿the﻿ vehicle﻿functionality﻿can﻿be﻿changed﻿in﻿order﻿to﻿minimise﻿any﻿further﻿demand.﻿Traditionally,﻿workload﻿ is﻿measured﻿using﻿physiological﻿sensors﻿that﻿require﻿often﻿intrusive﻿and﻿expensive﻿equipment.﻿Another﻿ approach﻿may﻿be﻿to﻿use﻿vehicle﻿telemetry﻿data﻿as﻿a﻿performance﻿measure﻿for﻿workload.﻿In﻿this﻿paper,﻿ the﻿authors﻿present﻿the﻿Warwick-JLR﻿Driver﻿Monitoring﻿Dataset﻿(DMD)﻿and﻿analyse﻿it﻿to﻿investigate﻿ the﻿feasibility﻿of﻿using﻿vehicle﻿telemetry﻿data﻿for﻿determining﻿the﻿driver﻿workload.﻿They﻿perform﻿ a﻿statistical﻿analysis﻿of﻿subjective﻿ratings,﻿physiological﻿data,﻿and﻿vehicle﻿telemetry﻿data﻿collected﻿ during﻿a﻿track﻿study.﻿A﻿data﻿mining﻿methodology﻿is﻿then﻿presented﻿to﻿build﻿predictive﻿models﻿using﻿ this﻿data,﻿for﻿the﻿driver﻿workload﻿monitoring﻿problem. KeyWoRDS CAN-Bus, Data Collection, Driver Monitoring, ECG, EDA		Phillip W Taylor;Nathan Griffiths;Abhir Bhalerao;Zhou Xu;Adam Gelencser;Thomas Popham	2017	IJMHCI	10.4018/ijmhci.2017070104	monitoring problem;human–computer interaction;workload;computer science;real-time computing;mobile phone;telemetry;cognition	HCI	7.714794005129008	-90.43966219235828	191690
a54eed9b105e04bde43000fbd7967043a9ebcaa0	electronic monitor for monitoring tv viewing time - description and significance		Sedentary behaviour is related to adverse cardiometabolic risk profiles and premature mortality. Television (TV) viewing time is the most predominant sedentary behaviour. There are also adverse associations between TV viewing time and a number of cardiovascular risk factors such as the metabolic syndrome, obesity, and abnormal glucose metabolism. Few measurement tools, such as direct observation and videotaping, have been utilized to objectively monitor TV watching. Unfortunately, these measurements have shortcomings as they invade the personal privacy and are impractical in large-scale research studies. Therefore, there is a need for alternative objective measures. Therefore, the main aim of this paper is to design an electronic device to objectively monitor TV viewing. This device uses Radio-frequency identification (RFID) technology that transfers data using tracking tag that is attached to a child's wrist like a watch. This data will be collected by the RFID Reader which is connected to a main electronic board that is designed to measure TV viewing time in minutes. The current research is expected to produce a novel wireless electronic tool that can monitor TV viewing without intrusion to the person privacy and can be widely used as an objective method of assessing TV viewing time.	privacy;radio-frequency identification;television	Mohammad Ali Alahmadi	2013		10.5220/0004636600910094	real-time computing;multimedia;computer graphics (images)	HCI	6.73292306751511	-88.12807085990718	191800
b1114968aff00d62631464393e9d7af4d21f83ad	zzzoo pillows: sense of sleeping alongside somebody	entertainment system;multiplexing infrared light;shadow	Sleep is essential to human life and is one of the three primitive desires, along with appetite for food and sexual desire. However, in recent years, there are many people who suffer from sleep deprivation. [Song and Nishino 2008] reported that sleep deprivation is not only harmful to health but also a cause of daytime fatigue, sleepiness, feelings of discomfort, deterioration in memory, and poor concentration. Secondarily, it can lead to mental and physical illness, various accidents, absence from work and poor productivity, and an increase in medical expenses.		Shunsuke Yanaka;Takayuki Kosaka;Motofumi Hattori	2013		10.1145/2542284.2542301	shadow;computer science	HCI	8.511531231149393	-81.95484890503944	192073
317b7d36b063a3be0d2599d4743aa285571efa36	u-healthcare system for pre-diagnosis of parkinson's disease from voice signal		"""With the ageing and growth of the population, some chronic diseases, such as Parkinson's disease (PD), urge the society to a health-conscious looking for better health system designs. Some recent research endeavour has been supported by solutions grounded in ubiquitous healthcare (u-Health) coupling telemedicine, context awareness and decision support capabilities. In this work, we propose a u-healthcare system to pre-diagnose PD based on the speech signal of people under voice call. The speech stream is sampled as well as processed to support the pre-diagnose using machine learning (ML). Experiments were conducted over a PD voice dataset composed of 40 individuals by using five different ML algorithms. Based on a linear Support Vector Machine (SVM) model, a false negative rate of 10% was obtained when classifying the locution of number """"three""""."""		Sylvio Barbon Junior;Victor G. Turrisi da Costa;Shi-Huang Chen;Rodrigo Capobianco Guido	2018	2018 IEEE International Symposium on Multimedia (ISM)	10.1109/ISM.2018.00039	support vector machine;speech recognition;artificial intelligence;parkinson's disease;feature extraction;pattern recognition;computer science;health care;context awareness;decision support system;population;telemedicine	Arch	5.3721545195402465	-86.40437505572618	192257
137ac4cab2fa7d07a44b0647e466c2001d5c1237	a cloud based type-2 diabetes mellitus lifestyle self-management system	wireless sensor networks wsns;type 2 diabetes mellitus;machine to machine m2m;u health;cloud computing	In this paper, we designed a patient-centric cloud based diabetes lifestyle management system. It is composed of three layers namely sensing, communication and user interface. The goal of this cloud based diabetes lifestyle management system is to provide Type-2 diabetes mellitus patients useful information to remind user's blood sugar level. The function of the sensor networks in this framework is to collect the data from human body and human activity as well as environmental information that may have effects on the healthy statement of the diabetes patients. The communication and central server part will handle the data exchange and data analysis that help to generate a final decision data and sent to user interface to remind the user of valuable information. Different from traditional e-health system, due to the diabetes patients are prone to effect by weather and environment varying. Therefore, the presented approach provide a rule algorithm which enables the rescue decision in the cloud server and transmit through the communication level, and finally provide a integrated user interface for diabetes users. An early warningi¾?user interface for diabetes patents has been designed and presented in this paper.	management system;self-management (computer science)	Shih-Hao Chang;Chih-Ning Li	2015		10.1007/978-3-319-25660-3_8	simulation;human–computer interaction;cloud computing;computer science;world wide web	Robotics	5.6194444760187015	-88.77065427738583	192303
3ea7106ed40fcf7c7f1b440f4e292190471e1ad6	a beverage intake tracking system based on machine learning algorithms, and ultrasonic and color sensors: poster abstract		We present a novel approach for monitoring beverage intake. Our system is composed of an ultrasonic sensor, an RGB color sensor, and machine learning algorithms. The system not only measures beverage volume but also detects beverage types. The sensor unit is lightweight that can be mounted on the lid of any drinking bottle. Our experimental results demonstrate that the proposed approach achieves more than 97% accuracy in beverage type classification. Furthermore, our regression-based volume measurement has a nominal error of 3%.	algorithm;machine learning;sensor;tracking system	Mahdi Pedram;Seyed Ali Rokni;Ramin Fallahzadeh;Hassan Ghasemzadeh	2017		10.1145/3055031.3055065	embedded system;computer vision;real-time computing	ML	5.369141577985471	-84.90865689959527	192552
9382f20c2139ec32ee9037a5685222932ca7f3ca	a tracking system for laboratory mice to support medical researchers in behavioral analysis	automated video tracking software laboratory mice behavioral analysis biology toxicology pharmacology movement analysis sensing technology animal behavior analysis radiofrequency identification technology ultrahigh frequency band web oriented solution 2d tracking information 3d tracking information;tracking behavioural sciences biomedical communication internet medical computing radiofrequency identification;mice radiofrequency identification correlation tracking software animal behavior	The behavioral analysis of laboratory mice plays a key role in several medical and scientific research areas, such as biology, toxicology, pharmacology, and so on. Important information on mice behavior and their reaction to a particular stimulus is deduced from a careful analysis of their movements. Moreover, behavioral analysis of genetically modified mice allows obtaining important information about particular genes, phenotypes or drug effects. The techniques commonly adopted to support such analysis have many limitations, which make the related systems particularly ineffective. Currently, the engineering community is working to explore innovative identification and sensing technologies to develop new tracking systems able to guarantee benefits to animals' behavior analysis. This work presents a tracking solution based on passive Radio Frequency Identification Technology (RFID) in Ultra High Frequency (UHF) band. Much emphasis is given to the software component of the system, based on a Web-oriented solution, able to process the raw tracking data coming from a hardware system, and offer 2D and 3D tracking information as well as reports and dashboards about mice behavior. The system has been widely tested using laboratory mice and compared with an automated video-tracking software (i.e., EthoVision). The obtained results have demonstrated the effectiveness and reliability of the proposed solution, which is able to correctly detect the events occurring in the animals' cage, and to offer a complete and user-friendly tool to support researchers in behavioral analysis of laboratory mice.	animals, laboratory;bands;component-based software engineering;diagnostic service section id - toxicology;dimensions;entity name part qualifier - adopted;graphics;ion implantation;movement;new foundations;pharmacology;phenotype;radio frequency identification device;radio-frequency identification;reading (activity);solutions;tracking system;ultra high frequency;usability;benefit	Simone Macrì;Luca Mainetti;Luigi Patrono;Stefano Pieretti;Andrea Secco;Ilaria Sergi	2015	2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2015.7319501	simulation;computer science;multimedia;biological engineering	SE	7.052980539710816	-90.8378815390816	192751
175ad7a23fecaa53045ec726199e5c970c8017ab	smartphone-based walking speed estimation for stroke mitigation	stroke mitigation;legged locomotion;sensors;pervasive computing;gravity;smart phone;acceleration;feedback loop smartphone based walking speed estimation stroke mitigation stroke recovery gait velocity pervasive devices walking speed measurement inertial sensors high pass filter accelerator;multimedia computing;estimation;legged locomotion sensors accelerometers acceleration estimation gravity portable media players;velocity measurement accelerometers biomedical equipment biomedical measurement gait analysis high pass filters medical computing mobile computing sensors smart phones;data analytics;portable media players;accelerometers;stroke mitigation pervasive computing multimedia computing smart phone data analytics	Each year, 15 million people suffer stroke worldwide. Among them, 5 million die and another 5 million are permanently disabled. Stroke recovery is a lifelong process. Clinical research have shown that gait velocity (a.k.a, walking speed) is a very powerful indicator of function and prognosis after stroke. In this paper, we focus on developing new algorithms to estimate the walking speed using pervasive devices, such as smartphone. While there are existing techniques to measure walking speed using inertial sensors, very little research has specifically involved smartphone, due to some unique challenges caused by pervasive devices, such as placement of the sensor and sensor drifting. We propose new practical algorithms based on high pass filter, integration of accelerator's reminder, and feedback loop. We evaluate our proposed approach with real world data and present a through analysis on the results. The experimental results have indicated that proposed approach is a promising practical approach for gait speed estimation.	algorithm;die (integrated circuit);feedback;pervasive informatics;sensor;smartphone;velocity (software development)	Jeffrey Cox;Yu Cao;Guanling Chen;Jianbiao He;Degui Xiao	2014	2014 IEEE International Symposium on Multimedia	10.1109/ISM.2014.71	acceleration;embedded system;estimation;simulation;gravity;computer science;sensor;data analysis;ubiquitous computing;accelerometer;statistics	Robotics	7.330154797086506	-87.71613832072019	192897
b790ec6f6940d03c9fbfa4e4d962bbd1c92e60cc	auracle: detecting eating episodes with an ear-mounted sensor		In this paper, we propose Auracle, a wearable earpiece that can automatically recognize eating behavior. More specifically, in free-living conditions, we can recognize when and for how long a person is eating. Using an off-the-shelf contact microphone placed behind the ear, Auracle captures the sound of a person chewing as it passes through the bone and tissue of the head. This audio data is then processed by a custom analog/digital circuit board. To ensure reliable (yet comfortable) contact between microphone and skin, all hardware components are incorporated into a 3D-printed behind-the-head framework. We collected field data with 14 participants for 32 hours in free-living conditions and additional eating data with 10 participants for 2 hours in a laboratory setting. We achieved accuracy exceeding 92.8% and F1 score exceeding 77.5% for eating detection. Moreover, Auracle successfully detected 20-24 eating episodes (depending on the metrics) out of 26 in free-living conditions. We demonstrate that our custom device could sense, process, and classify audio data in real time. Additionally, we estimate Auracle can last 28.1 hours with a 110 mAh battery while communicating its observations of eating behavior to a smartphone over Bluetooth.	3d printing;analog signal;bluetooth;digital electronics;f1 score;microphone;printed circuit board;sensor;smartphone;wearable computer	Shengjie Bi;Tao Wang;Nicole Tobias;Maialen Barrero;Shang Wang;Olumide Ayodeji Ilesanmi;Sougata Sen;Ronald A. Peterson;Kofi Odame;Kelly Caine;Ryan J. Halter;Jacob Sorber;David Kotz	2018	IMWUT	10.1145/3264902	f1 score;digital electronics;computer vision;wearable computer;activity recognition;bluetooth;microphone;contact microphone;computer science;artificial intelligence	HCI	9.048400876462287	-88.03081573199614	193298
ff87f209ab3a15f9d2c761b326bec1b5f0fd50b5	a preliminary study on early diagnosis of illnesses based on activity disturbances		Recently, the human stroke is gathering the focus as one of the diseases with higher mortality and social impact. In addition, it has a long-term treatment and high rehabilitation costs. Therefore, the early diagnosis of stroke can take advantage in avoiding the stroke itself or highly reducing its effects. Up to our knowledge, no previous study on stroke early diagnosis has been published in the literature. This study deals with the early detection of the stroke based on accelerometers and mobile devices. First, a discussion on the problem is presented and the design of the approach is outlined. In a first stage, it is necessary to determine what is the subject doing at any moment; thus, human activity recognition is performed. Afterwards, once the current activity is estimated, the detection of anomalous movements is proposed. Nevertheless, as there is no data available to learn the problem, a realistic proposal for simulating stroke episodes is presented, which lead us to draw the conclusions.		Silvia González;José Ramón Villar;Javier Sedano;Camelia Chira	2013		10.1007/978-3-319-00551-5_62	computer science;data mining;artificial intelligence;machine learning;activity recognition;rehabilitation;stroke	HCI	9.846877676036971	-86.38084436510404	193768
98e2560557d319109cf948ae0724e0b6b159b038	using temporal patterns (t-patterns) to derive stress factors of routine tasks	stress factors;temporal patterns;data collection;time window;t patterns;knowledge worker;temporal pattern;routine tasks;pattern analysis;statistical techniques	We describe the use of a statistical technique called T-pattern analysis to derive and characterize the routineness of tasks. T-patterns provide significant advantages over traditional sequence analyses by incorporating time. A T-pattern is characterized by a significant time window (critical interval) that describes the duration of this pattern. Our analysis is based on data collected from shadowing 10 knowledge workers over a total of 29 entire work days. We report on the statistics of detected T-patterns and derived correlations with participant perceptions of workload, autonomy, and productivity.	autonomy;pattern recognition	Oliver Brdiczka;Norman Makoto Su;James Begole	2009		10.1145/1520340.1520621	simulation;computer science;data science;data mining;data collection	HCI	6.86863064110389	-82.42002955740541	194121
230cfbf82629db251af0f6cbc5d12b8e14bb7631	pervasive eating habits monitoring and recognition through a wearable acoustic sensor	eating habit;feature extraction;knn;svm	Eating habits provide clinical diagnosis evidences of lifestyle related diseases, such as dysphagia and indigestion. However, it is costly to obtain eating habit information of common people in terms of both time and expenses. This paper presents a pervasive approach for eating habit monitoring and recognition by a necklace-like device and a smartphone communicating via bluetooth. The necklace-like device acquires acoustic signals from the throat, and the data are processed in the smartphone to recognize important features. With complex acoustic signals collected from the throat, our method comprehensively analyzes and recognizes different events including chewing, swallowing, and breathing in the smartphone. Experiments show that the proposed approach can recognize different acoustic events effectively, and the recognition accuracy with K-Nearest Neighbor (KNN) and Support Vector Machine (SVM) is 86.82% and 98.35%, respectively. Finally, a real eating case study is conducted to validate the proposed approach.	acoustic cryptanalysis;bluetooth;experiment;k-nearest neighbors algorithm;pervasive informatics;smartphone;support vector machine;wearable computer	Yin Bi;Wenyao Xu;Nan Guan;Yangjie Wei;Wang Yi	2014			support vector machine;simulation;feature extraction;computer science;artificial intelligence;machine learning;k-nearest neighbors algorithm	HCI	5.564230540387133	-86.19210490233492	194195
1e9d546f6b4b358582b78ca61fd44ee92006774c	designing toys with automatic play characterization for supporting the assessment of a child's development	toy design;objectplay;multimodal wireless sensing;object play;activity recognition	In this paper, we describe the design considerations and implementation of the Child'sPlay system, a technology for supporting the automatic recording, recognition, and quantification of a child's object play behaviors for retrospective analysis. Our prototype system consists of six varieties of toys augmented with wireless sensing capabilities and a mobile computing platform which uses statistical pattern recognition techniques to automatically classify sensed play behaviors. This paper discusses our choices in toy design both in form factor as well as sensing capabilities. In addition, we also describe the play activities the system supports and provide an overview of our initial recognition algorithms.	algorithm;mobile computing;pattern recognition;prototype;toys	Tracy L. Westeyn;Julie A. Kientz;Thad Starner;Gregory D. Abowd	2008		10.1145/1463689.1463726	simulation;engineering;multimedia;communication	HCI	2.125432936206653	-89.47335697060328	194516
970798b4a74e29681b8aed1d47e41e948b0f7b1a	mobbed: a computational data infrastructure for handling large collections of event-rich time series datasets in matlab	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;database;time series;multi scale;big data;uk phd theses thesis;events;life sciences;provenance;eeg;uk research reports;medical journals;matlab;pipeline;europe pmc;biomedical research;bioinformatics;eeglab	Experiments to monitor human brain activity during active behavior record a variety of modalities (e.g., EEG, eye tracking, motion capture, respiration monitoring) and capture a complex environmental context leading to large, event-rich time series datasets. The considerable variability of responses within and among subjects in more realistic behavioral scenarios requires experiments to assess many more subjects over longer periods of time. This explosion of data requires better computational infrastructure to more systematically explore and process these collections. MOBBED is a lightweight, easy-to-use, extensible toolkit that allows users to incorporate a computational database into their normal MATLAB workflow. Although capable of storing quite general types of annotated data, MOBBED is particularly oriented to multichannel time series such as EEG that have event streams overlaid with sensor data. MOBBED directly supports access to individual events, data frames, and time-stamped feature vectors, allowing users to ask questions such as what types of events or features co-occur under various experimental conditions. A database provides several advantages not available to users who process one dataset at a time from the local file system. In addition to archiving primary data in a central place to save space and avoid inconsistencies, such a database allows users to manage, search, and retrieve events across multiple datasets without reading the entire dataset. The database also provides infrastructure for handling more complex event patterns that include environmental and contextual conditions. The database can also be used as a cache for expensive intermediate results that are reused in such activities as cross-validation of machine learning algorithms. MOBBED is implemented over PostgreSQL, a widely used open source database, and is freely available under the GNU general public license at http://visual.cs.utsa.edu/mobbed. Source and issue reports for MOBBED are maintained at http://vislab.github.com/MobbedMatlab/	algorithm;archive;cache;collections (publication);computation;cross reactions;cross-validation (statistics);data infrastructure;database;electroencephalography;experiment;eye tracking;feature vector;frame (physical object);gnu;handling (psychology);heart rate variability;matlab;machine learning;motion capture;open-source software;postgresql;silo (dataset);time series	Jeremy Cockfield;Kyungmin Su;Kay A. Robbins	2013		10.3389/fninf.2013.00020	big data;computer science;bioinformatics;data science;time series;data mining;world wide web;pipeline;eeglab;statistics	DB	2.289459784235298	-85.59004284565225	195166
69ed03af4ee83660ca2309de44becddebd031bf0	time-series averaging using constrained dynamic time warping with tolerance		Averaging of time-series of different lengths.Introducing constraints and tolerance to DBA (DTW Barycenter Averaging).Application on a time-series classification task. In this paper, we propose an innovative averaging of a set of time-series based on the Dynamic Time Warping (DTW). The DTW is widely used in data mining since it provides not only a similarity measure, but also a temporal alignment of time-series. However, its use is often restricted to the case of a pair of signals. In this paper, we propose to extend its application to a set of signals by providing an average time-series that opens a wide range of applications in data mining process. Starting with an existing well-established method called DBA (for DTW Barycenter Averaging), this paper points out its limitations and suggests an alternative based on a Constrained Dynamic Time Warping. Secondly, an innovative tolerance is added to take into account the admissible variability around the average signal. This new modeling of time-series is evaluated on a classification task applied on several datasets and results show that it outperforms state of the art methods.	algorithm;archive;computation;current differencing buffered amplifier;database;dynamic time warping;heart rate variability;similarity measure;time series;whole earth 'lectronic link	Marion Morel;Catherine Achard;Richard Kulpa;Séverine Dubuisson	2018	Pattern Recognition	10.1016/j.patcog.2017.08.015	machine learning;artificial intelligence;dynamic time warping;similarity measure;pattern recognition;computer science	NLP	-2.1548039507188097	-92.77294881763535	195394
cfacee20104e7a8b33bda0f7eabcf468a930ac93	gathering large scale human activity information using mobile sensor devices	large scale human activity information;histograms;mobile sensors;sensors data acquisition mobile radio;sensors;three axis accelerration sensor component human activity information human activity gathering system mobile sensor device;component;activity information gathering system;elevators;mobile handsets elevators histograms bicycles humans mobile communication acceleration;mobile sensor devices;activity information gathering system large scale human activity information mobile sensor devices;acceleration;information gathering;large scale;human activity information;specific activity;bicycles;mobile radio;mobile communication;mobile handsets;mobile sensor device;three axis accelerration sensor;humans;data acquisition;human activity gathering system;human activity;health care	In this paper, we show current status of gathering large scale human activity information using mobile sensor devices. If human activity can be objectively measured, we can expect various applications, such as health care and agriculture. We developed an activity information gathering system using mobile sensor devices with three axis accelerometers, and gathered about 10,000 activity data of 170 people during 5 months so far. As a result, we found specific activities which are easily gathered and ones which are not. Moreover, we found some problems of motivation measures.	apache axis;sensor	Yuichi Hattori;Sozo Inoue;Takemori Masaki;Go Hirakawa;Osamu Sudoh	2010	2010 International Conference on Broadband, Wireless Computing, Communication and Applications	10.1109/BWCCA.2010.159	acceleration;embedded system;simulation;mobile telephony;sensor;specific activity;component;histogram;data acquisition;health care	HCI	8.275950088970122	-86.2235445779161	195449
340ff825827c86139fb5f4e23006a30eef3beeb9	a network of collaborative sensors for the monitoring of copd patients in their daily life	oximetry wireless body sensor networks bluetooth copd patients actimetry;body sensor networks;telemedicine blood bluetooth body sensor networks data acquisition diseases oximetry patient monitoring;telemedicine;oximetry;supervised medical exams collaborative sensor network copd patient monitoring daily life chronic obstructive pulmonary disease airflow lungs dyspnea physical exercises blood saturation monitoring multiple wirelessly interconnected medical sensors master device medical data acquisition;blood;monitoring bluetooth sensors biomedical monitoring diseases wireless communication wireless sensor networks;diseases;patient monitoring;bluetooth;data acquisition	Chronic Obstructive Pulmonary Disease (COPD) reduces airflow in and out of the lungs, causing dyspnea during physical exercises. Therefore it is interesting to monitor the blood saturation during a physical exercise. Such monitoring can benefit from a network of collaborative sensors. But to monitor the patient in his daily life, it is mandatory that the system can be used autonomously at the patient's home. We therefore propose a system composed of multiple wirelessly interconnected medical sensors, and a master device to acquire medical data in daily life or in supervised medical exams.	android;autonomous robot;autonomy;bluetooth;ct pulmonary angiogram;scott continuity;sensor;tablet computer	Bruno Perriot;Jerome Argod;Jean Louis Pépin;Norbert Noury	2013	2013 IEEE 15th International Conference on e-Health Networking, Applications and Services (Healthcom 2013)	10.1109/HealthCom.2013.6720689	intensive care medicine;medicine;physical therapy;biological engineering	Robotics	7.38112610784812	-88.79294605474777	195522
777d6c52f8affe6711e6ba40b1629035b9077de7	activity recognition in naturalistic environments using body-worn sensors		Faculty of Science, Agriculture and Engineering School of Computing Science Doctor of Philosophy Activity Recognition in Naturalistic Environments using Body-Worn Sensors by Nils Yannick Hammerla The research presented in this thesis investigates how deep learning and feature learning can address challenges that arise for activity recognition systems in naturalistic, ecologically valid surroundings such as the private home. One of the main aims of ubiquitous computing is the development of automated recognition systems for human activities and behaviour that are sufficiently robust to be deployed in realistic, in-the-wild environments. In most cases, the targeted application scenarios are people’s daily lives, where systems have to abide by practical usability and privacy constraints. We discuss how these constraints impact data collection and analysis and demonstrate how common approaches to the analysis of movement data effectively limit the practical use of activity recognition systems in every-day surroundings. In light of these issues we develop a novel approach to the representation and modelling of movement data based on a data-driven methodology that has applications in activity recognition, behaviour imaging, and skill assessment in ubiquitous computing. A number of case studies illustrate the suitability of the proposed methods and outline how study design can be adapted to maximise the benefit of these techniques, which show promising performance for clinical applications in particular.	activity recognition;backpropagation;computation;cone;cross-validation (statistics);deep learning;denial-of-service attack;developmental robotics;ecology;experiment;feature extraction;feature learning;gradient;greedy algorithm;hartley (unit);horner's method;modality (human–computer interaction);overfitting;population;quorum sensing;reliability engineering;requirement;sensor;socialization;software propagation;statistical classification;triangular function;ubiquitous computing;unsupervised learning;usability;word lists by frequency	Nils Y. Hammerla	2015			communication;activity recognition;psychology	HCI	2.769989732884446	-84.40312361127559	195816
cea298207be4b2a48d3ce9516d344b73e53a86de	detecting changes in elderly's mobility using inactivity profiles	aal;mobility;elderly;inactivity profiles	Abnormal inactivity indicates situations, where elderly need assistance. Systems detecting the need for help models the amount of inactivity using inactivity profiles. Depending on the analysis of the profiles, events (e.g. falls) or long-term changes (decrease of mobility) are detected. Until now, inactivity profiles are only used to detect abnormal behavior on the short-term (e.g. fall, illness), but not on the long-term. Hence, this work introduces an approach to detect significant changes on mobility using long-term inactivity profiles, since these changes indicate enhanced or decreased mobility of elderly. Preliminary results are obtained by the analysis of the motion data of an elderly couple over the duration of 100 days and illustrates the feasibility of this approach.		Rainer Planinc;Martin Kampel	2013		10.1007/978-3-319-03092-0_15	simulation;computer science;operating system;mobile computing	HCI	7.2823045612514195	-86.15168013722933	195905
bb2d97eee0bf2658b427d8283c01836263e8968a	hidden markov modeling of human pathological gait using laser range finder for an assisted living intelligent robotic walker	robot sensing systems;legged locomotion;state estimation assisted living gait analysis handicapped aids hidden markov models intelligent robots laser ranging mobile robots motion control;foot;acceleration;hidden markov models;hidden markov modeling context aware robot mobility assistant walking pathologies cognitive behavior based robot control system human data analysis gait patterns recognition state estimation hmm human legs tracking human legs detection laser range finder sensor pathological human walking gait pattern noninvasive framework consecutive gait phases cyclic motion intelligent active mobility assistance robot elderly person walking pattern patient walking pattern intelligent robotic walker assisted living;legged locomotion hidden markov models robot sensing systems foot pathology acceleration;pathology	The precise analysis of a patient's or an elderly person's walking pattern is very important for an effective intelligent active mobility assistance robot. This walking pattern can be described by a cyclic motion, which can be modeled using the consecutive gait phases. In this paper, we present a completely non-invasive framework for analyzing and recognizing a pathological human walking gait pattern. Our framework utilizes a laser range finder sensor to detect and track the human legs, and an appropriately synthesized Hidden Markov Model (HMM) for state estimation, and recognition of the gait patterns. We demonstrate the applicability of this setup using real data, collected from an ensemble of different elderly persons with a number of pathologies. The results presented in this paper demonstrate that the proposed human data analysis scheme has the potential to provide the necessary methodological (modeling, inference, and learning) framework for a cognitive behavior-based robot control system. More specifically, the proposed framework has the potential to be used for the classification of specific walking pathologies, which is needed for the development of a context-aware robot mobility assistant.	amiga walker;cognitive robotics;control system;gait analysis;hidden markov model;machine learning;markov chain;norm (social);particle filter;robot control;tracking system;wearable technology	Xanthi S. Papageorgiou;Georgia Chalvatzaki;Costas S. Tzafestas;Petros Maragos	2015	2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2015.7354283	acceleration;computer vision;simulation;computer science;engineering;hidden markov model;foot	Robotics	7.474048169509123	-85.04023377323267	195965
eb143c0df97fbe61a68103dbc7e512ba95482d69	inertial navigation with mobile devices: a robust step count model		Navigation is an essential feature for smartphones, even indoors. Having a robust step count algorithm is the cornerstone for building an inertial navigator based on accelerometer sensors. However, accelerometer data is very sensitive to body movements, so separating noise from real steps is not a trivial issue. Our main hypothesis is that Mean Squared Error (MSE) measured between predicted and real signal gives a clear distinction between ideal steps, noisy steps and pure noise. In this paper we propose a combination of techniques to obtain a robust step count model for smartphones. Using the vertical component of the acceleration, Support Vector Regression (SVR) for modeling user’s activity and an algorithm that combines peak-valley detection with high MSE steps filtering, we achieve a computational efficient and robust model for detecting steps.	algorithm;computation;inertial navigation system;mean squared error;sensor;smartphone;support vector machine	Jacobo Lopez-Fernandez;Roberto Iglesias;Carlos V. Regueiro;Fernando E. Casado	2017		10.1007/978-3-319-70833-1_54	acceleration;simulation;support vector machine;computer vision;artificial intelligence;inertial frame of reference;accelerometer;inertial navigation system;filter (signal processing);computer science;mobile device;control engineering;mean squared error	ML	5.441449199578517	-84.51343895458513	196108
c59da431534b726669949f39cbf32686353c73d3	a robust realtime reading-skimming classifier	real time;reading;skimming;machine learning;detection algorithm;eye tracking;classification accuracy;reaction time	Distinguishing whether eye tracking data reflects reading or skimming already proved to be of high analytical value. But with a potentially more widespread usage of eye tracking systems at home, in the office or on the road the amount of environmental and experimental control tends to decrease. This in turn leads to an increase in eye tracking noise and inaccuracies which are difficult to address with current reading detection algorithms. In this paper we propose a method for constructing and training a classifier that is able to robustly distinguish reading from skimming patterns. It operates in real time, considering a window of saccades and computing features such as the average forward speed and angularity. The algorithm inherently deals with distorted eye tracking data and provides a robust, linear classification into the two classes read and skimmed. It facilitates reaction times of 750ms on average, is adjustable in its horizontal sensitivity and provides confidence values for its classification results; it is also straightforward to implement. Trained on a set of six users and evaluated on an independent test set of six different users it achieved a 86% classification accuracy and it outperformed two other methods.	algorithm;eye tracking;linear classifier;statistical classification;test set;tracking system	Ralf Biedert;Jörn Hees;Andreas Dengel;Georg Buscher	2012		10.1145/2168556.2168575	computer vision;simulation;speech recognition;computer science	ML	2.579557911806668	-83.28525578504943	196902
675f676156ad2b7920a51e8f631c076589706880	analysis of elderly drivers' performance using large-scale test data			test data	Yasuhiko Nakano;Haruki Kawanaka;Koji Oguri	2016	IEICE Transactions			Visualization	9.575595323646303	-84.69913250949699	196919
c1866c151f295fa4ba236323675a3c433ab8b6c2	adaptation of models for food intake sound recognition using maximum a posteriori estimation algorithm	sound recognition;food intake monitoring;on body sensor system chewing sound food intake monitoring hidden markov models model adaptation maximum a posteriori estimation user adaptation;adaptation models accuracy hidden markov models classification algorithms vectors nickel acoustics;sensor system;classification algorithm;automatic food intake recognition algorithms;maximum a posteriori estimation algorithm;hidden markov model;nickel;acoustics;model adaptation;on body sensor system;user adaptation;acoustic signal processing;maximum likelihood estimation;maximum a posteriori estimation;estimation algorithm;user unspecific algorithm;healthcare challenges;accuracy;adaptive algorithm;sound classification;hidden markov models;vectors;overweight;signal classification;classification algorithms;obesity;map estimation;chewing sound;signal classification acoustic signal processing maximum likelihood estimation medical signal processing;adaptation set;data logging;individual difference;adaptation set sound recognition maximum a posteriori estimation algorithm obesity overweight healthcare challenges automatic food intake recognition algorithms data logging user unspecific algorithm;classification accuracy;adaptation models;food intake;medical signal processing	Obesity and overweight are big healthcare challenges in the world's population. Automatic food intake recognition algorithms based on analysis of food intake sounds offer the potential of being a useful tool for simplifying data logging of consumed food. High inter-individual differences of the users' food intake sounds decrease the classification accuracy achieved with a user-unspecific algorithm. To overcome this problem, the Maximum a Posteriori (MAP) estimation is implemented and tested on one user consuming eight types of food. The dependency of the classification enhancement from the size of the adaptation set is investigated. Overall recognition accuracy can be increased from 48 % to around 79 % using records of 10 intake cycles for every food type of one subject. An increase by 7.5 % can be shown for a second subject. This shows the usability of the MAP adaptation algorithm at food intake sound classification tasks. The algorithm provides a suitable way for adapting models to a user, thereby, enhancing the performance of food intake classification.	acoustic cryptanalysis;algorithm;data logger;online and offline;population;speech recognition;usability	Sebastian Päßler;Wolf-Joachim Fischer;Ivan Kraljevski	2012	2012 Ninth International Conference on Wearable and Implantable Body Sensor Networks	10.1109/BSN.2012.2	nickel;obesity;speech recognition;computer science;maximum a posteriori estimation;machine learning;pattern recognition;hidden markov model;statistics	Mobile	5.677411656818074	-86.31792049373972	197371
69f94acb80473e0eb49cc1c3ee86fb880d6f4e57	a micropower integrated platform for wireless multichannel recording of ecog activity	front end;dorsal premotor cortex;real time;terms design;emotion recognition;voice intonation analysis;real time data;health monitoring;facial expression analysis;human subjects;low noise;multi modal probabilistic information fusion;body posture analysis;electromyography;brain activation;persistent and non invasive personal health monitoring	Electrocorticography (ECoG), the recording of electrical signals from the surface of cortex, is widely used for monitoring and analysis of epileptic brain activity. However, current ECoG recording methods require tethering of the patient causing discomfort and impeding his or her mobility. We demonstrate a system for wireless multichannel recording of ECoG activity. The system is comprised of a custom made VLSI neural front end, transceiver modules, battery and a custom software written in LabView for real-time data monitoring and storage. The system offers programmable gain, bandwidth and ADC setting while maintaining low noise performance and drawing less than 6.7mA of current from 3.7V battery. We have validated this system by recording micro-ECoG signal from the dorsal premotor cortex region of a primate performing reach to grasp movements. In our demonstration, we will show the wireless operation of the system, transmitting pre-recorded ECoG signals from primates through a saline solution. We will also show real-time recording of electromyography (EMG) signals from a human subject performing motor movements. Our system offers a new platform for wireless health monitoring system in epilepsy units.	electrocorticography;electroencephalography;electromyography;labview;real-time clock;real-time data;real-time transcription;salineos;transceiver;transmitter;very-large-scale integration	Mohsen Mollazadeh;Elliot Greenwald;Marc H. Schieber;Nitish V. Thakor;Gert Cauwenberghs	2011		10.1145/2077546.2077579	speech recognition;telecommunications;engineering;communication	Mobile	9.866618072944707	-89.55784591769148	197796
4d78c0e4886659c276f2c4fa7c265b89ac01f0c2	multi-purpose mobile monitoring system based on automatic extraction of rule-sets	multipurpose mobile monitoring system fall detection apnea monitoring healthcare edf files european data format files mobile device wearable sensors dss rule based mobile decision support system knowledge offline automatic extraction multiparametric telemonitoring system rule sets automatic extraction;wearable computers computerised monitoring decision support systems health care knowledge acquisition knowledge based systems mobile computing patient monitoring;monitoring databases biomedical monitoring mobile communication medical services real time systems testing	Real-time tele-monitoring technology is very useful for remotely monitoring patients' vital parameters and for ensuring mobility of both patient and doctor. In this paper a multi-purpose and multi-parametric tele-monitoring system is described. This system is based on the offline automatic extraction of knowledge from databases expressed as a set of IF...THEN rules that are used by a rule-based mobile Decision Support System (DSS) embedded in the presented system. Vital parameters are collected by wearable sensors, sent to a mobile device, and processed in real-time. If a rule is activated, the system produces an alarm for a well-timed medical intervention. Finally all monitored parameters are saved in European Data Format (EDF) files that could be used for further analysis. Two practical applications of the system are presented with reference to two important healthcare issues, namely apnea monitoring and fall detection.	database;decision support system;earliest deadline first scheduling;embedded system;european data format;logic programming;mobile device;multi-purpose viewer;online and offline;real-time clock;real-time transcription;sensor;television;wearable computer	Giovanna Sannino;Ivanoe De Falco;Giuseppe De Pietro	2014	IEEE-EMBS International Conference on Biomedical and Health Informatics (BHI)	10.1109/BHI.2014.6864443	embedded system;engineering;data mining;computer security	Robotics	6.147626532408316	-88.49539124219633	198326
10f2b8188c745d43c1580f5ee6de71ad8d538b4d	affect recognition using key frame selection based on minimum sparse reconstruction	video summarization;emotion recognition;emotiw 2015 challenge;affect recognition;affective computing	In this paper, we present the methods used for Bahcesehir University team's submissions to the 2015 Emotion Recognition in the Wild Challenge. The challenge consists of categorical emotion recognition in short video clips extracted from movies based on emotional keywords in the subtitles. The video clips mostly contain expressive faces (single or multiple) and also audio which contains the speech of the person in the clip as well as other human voices or background sounds/music. We use an audio-visual method based on video summarization by key frame selection. The key frame selection uses a minimum sparse reconstruction approach with the goal of representing the original video in the best possible way. We extract the LPQ features of the key frames and average them to determine a single feature vector that will represent the video component of the clip. In order to represent the temporal variations of the facial expression, we also use the LBP-TOP features extracted from the whole video. The audio features are extracted using OpenSMILE or RASTA-PLP methods. Video and audio features are classified using SVM classifiers and fused at the score level. We tested eight different combinations of audio and visual features on the AFEW 5.0 (Acted Facial Expressions in the Wild) database provided by the challenge organizers. The best visual and audio-visual accuracies obtained on the test set are 45.1% and 49.9% respectively, whereas the video-based baseline for the challenge is given as 39.3%.	baseline (configuration management);emotion recognition;face (geometry);feature vector;key frame;local binary patterns;pl/p;sparse matrix;support vector machine;test set;video clip	Mehmet Kayaoglu;Cigdem Eroglu Erdem	2015		10.1145/2818346.2830594	computer vision;speech recognition;computer science;artificial intelligence;affective computing;multimedia	Vision	-3.8319755250126133	-84.76817171491822	198434
be5cdf763c6f607c90cf00a03b04a6491b0266ad	multimodal human-computer interfaces based on advanced video and audio analysis	patient diagnosis;lateralization multimodal interface dyslexia eyetracking;hearing aids;audio signal processing;video signal processing;virtual reality;computers speech mouth training auditory system software face;virtual reality audio signal processing brain computer interfaces computer interfaces diseases gesture recognition handicapped aids hearing aids multimedia systems patient diagnosis video signal processing;multimedia systems;handicapped aids;diseases;brain computer interfaces;vtp multimodal human computer interfaces audio analysis interactive electronic whiteboard video image analysis education software mouth gestures audio interface speech stretching hearing impairment stuttering people smart pen dyslexia eye gaze tracking system cyber eye multimedia system department visual activity vegetative state polysensoric stimulation process parkinson s disease diagnosis updrs unified parkinson disease rating scale virtual touchpad;computer interfaces;gesture recognition	Multimodal interfaces development history is reviewed briefly in the introduction. Examples of applications of multimodal interfaces to education software and for the disabled people are presented, including interactive electronic whiteboard based on video image analysis, application for controlling computers with mouth gestures and the audio interface for speech stretching for hearing impaired and stuttering people. The Smart Pen providing a tool for supporting therapy of developmental dyslexia is presented and results achieved with its application are discussed. The eye-gaze tracking system named “Cyber-Eye” developed at the Multimedia Systems Department employed to many kinds of experiments is presented including analysis of visual activity of patients remaining in vegetative state and their awareness evaluation. The scent emitting multimodal computer interface provides an important supplement of the polysensoric stimulation process, playing an essential role in education and therapy of children with certain developmental disorders. A new approach to diagnosing Parkinson's disease is shown. The progression of the disease can be measured employing the UPDRS (Unified Parkinson Disease Rating Scale) scale which is used to evaluate motor and behavioral symptoms of Parkinson's disease, based on the multimodal interface called Virtual-Touchpad (VTP) used for supporting medical diagnosis. The paper is concluded with some general remarks concerning the role of multimodal computer interfaces applied to learning, therapy and everyday usage of computerized devices.	color gradient;computer;experiment;image analysis;interactive whiteboard;multimodal interaction;persistent vegetative state;rating scale;touchpad;tracking system;transcranial magnetic stimulation	Andrzej Czyzewski;Piotr Dalka;Lukasz Kosikowski;Bartosz Kunka;Adam Kupryjanow;Michal Lech;Piotr Odya	2013	2013 6th International Conference on Human System Interactions (HSI)	10.1109/HSI.2013.6577797	speech recognition;computer science;multimedia;communication	HCI	8.294499499457148	-91.4571499673027	198890
53b8766a86782535ba9d6b4c18f7cefce86f745c	insights into audio-based multimedia event classification with neural networks	context windows;neural networks;web video;hidden markov models;audio;multimedia event detection;multimedia event classification;video	Multimedia Event Detection (MED) aims to identify events-also called scenes-in videos, such as a flash mob or a wedding ceremony. Audio content information complements cues such as visual content and text. In this paper, we explore the optimization of neural networks (NNs) for audio-based multimedia event classification, and discuss some insights towards more effectively using this paradigm for MED. We explore different architectures, in terms of number of layers and number of neurons. We also assess the performance impact of pre-training with Restricted Boltzmann Machines (RBMs) in contrast with random initialization, and explore the effect of varying the context window for the input to the NNs. Lastly, we compare the performance of Hidden Markov Models (HMMs) with a discriminative classifier for the event classification. We used the publicly available event-annotated YLI-MED dataset. Our results showed a performance improvement of more than 6% absolute accuracy compared to the latest results reported in the literature. Interestingly, these results were obtained with a single-layer neural network with random initialization, suggesting that standard approaches with deep learning and RBM pre-training are not fully adequate to address the high-level video event-classification task.	artificial neural network;debian-med;deep learning;discriminative model;hidden markov model;high- and low-level;medline;markov chain;mathematical optimization;pattern recognition;programming paradigm;restricted boltzmann machine	Mirco Ravanelli;Benjamin Elizalde;Julia Bernd;Gerald Friedland	2015		10.1145/2814815.2814816	speech recognition;computer science;machine learning;data mining	ML	-3.555224795653928	-86.06430249731193	198951
0a000e91e3508894c0f1069ed3ff71dcaf15ce23	recurrent neural network-based user authentication for freely typed keystroke data		Keystroke dynamics-based user authentication (KDA) based on long and freely typed text is an enhanced user authentication method that can not only identify the validity of current users during login but also continuously monitors the consistency of typing behavior after the login process. Previous long and freely typed text-based KDA methods had difficulty incorporating the key sequence information and handling variable lengths of keystrokes, which in turn resulted in lower authentication performance compared to KDA methods based on short and fixed-length text. To overcome these limitations, we propose a recurrent neural network (RNN)-based KDA model. As the RNN model can process an arbitrary length of input and target sequences, our proposed model takes two consecutive keys as the input sequence and actual typing time for the corresponding key sequence as the target sequence. Based on experimental results involving 120 participants, our proposed RNN– KDA model yielded the best authentication performance for all training and test length combinations in terms of equal error rate (EER). It achieved a 5%–6% EER using only 10 test keystrokes while the EERs of other benchmark methods were above 20%. In addition, its performance steadily and more rapidly improves compared to the benchmark methods when the length of training keystrokes increases.	artificial neural network;authentication;benchmark (computing);computer keyboard;concatenation;enhanced entity–relationship model;event (computing);experiment;input device;keystroke dynamics;login;one-hot;random neural network;recurrent neural network;smartphone;text-based (computing);unique user;urban dictionary	Junhong Kim;Pilsung Kang	2018	CoRR		typing;theoretical computer science;word error rate;computer science;keystroke logging;recurrent neural network;artificial intelligence;authentication;pattern recognition;keystroke dynamics;login	NLP	-2.8954021882639025	-81.71337717360898	199452
b29d806cc8bb794b4d49de5a2df358e77387a120	open architecture software platform for biomedical signal analysis	signal simulation biomedical signal analysis physiological status human body relevant information extraction biomedical data open architecture software platform jbios signal load signal display plugins multimethod analysis signal preprocessing;public domain software;physiology;feature extraction;software java heart rate variability signal analysis physiology electrocardiography;public domain software feature extraction medical signal processing physiology;medical signal processing	Biomedical signals are very important reporters of the physiological status in human body. Therefore, great attention is devoted to the study of analysis methods that help extracting the greatest amount of relevant information from these signals. There are several free of charge softwares which can process biomedical data, but they are usually closed architecture, not allowing addition of new functionalities by users. This paper presents a proposal for free open architecture software platform for biomedical signal analysis, named JBioS. Implemented in Java, the platform offers some basic functionalities to load and display signals, and allows the integration of new software components through plugins. JBioS facilitates validation of new analysis methods and provides an environment for multi-methods analysis. Plugins can be developed for preprocessing, analyzing and simulating signals. Some applications have been done using this platform, suggesting that, with these features, JBioS presents itself as a software with potential applications in both research and clinical area.	component-based software engineering;java programming language;multiple dispatch;name;numerous;open architecture;open-source software;plug-in (computing);preprocessor;signal processing;simulation;simulators;web site	Juliano J. Duque;Luiz E. V. Silva;Luiz Otávio Murta	2013	2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2013.6609943	feature extraction;computer science;bioinformatics;data science;machine learning;data mining;physiology;public domain software	SE	9.4828860642583	-89.74961366887536	199597
29758d2d6264a628f487b5d8b78308954b9e95e3	robust human activity recognition using lesser number of wearable sensors		In recent years, research on the recognition of human physical activities solely using wearable sensors has received more and more attention. Compared to other types of sensory devices such as surveillance cameras, wearable sensors are preferred in most activity recognition applications mainly due to their non-intrusiveness and pervasiveness. However, many existing activity recognition applications or experiments using wearable sensors were conducted in the confined laboratory settings using specifically developed gadgets. These gadgets may be useful for a small group of people in certain specific scenarios, but probably will not gain their popularity because they introduce additional costs and they are unusual in everyday life. Alternatively, commercial devices such as smart phones and smart watches can be better utilized for robust activity recognitions. However, only few prior studies focused on activity recognitions using multiple commercial devices. In this paper, we present our feature extraction strategy and compare the performance of our feature set against other feature sets using the same classifiers. We conduct various experiments on a subset of a public dataset named PAMAP2. Specifically, we only select two sensors out of the thirteen used in PAMAP2. Experimental results show that our feature extraction strategy performs better than the others. This paper provides the necessary foundation towards robust activity recognition using only the commercial wearable devices.	activity recognition;activity tracker;closed-circuit television;cross-validation (statistics);embedded system;experiment;feature extraction;information;mike lesser;sensor;smartphone;smartwatch;wearable computer;wearable technology	Di Wang;Edwin Candinegara;Junhui Hou;Ah-Hwee Tan;Chunyan Miao	2017	2017 International Conference on Security, Pattern Analysis, and Cybernetics (SPAC)	10.1109/SPAC.2017.8304292	support vector machine;smartwatch;human–computer interaction;accelerometer;wearable technology;feature extraction;wearable computer;robustness (computer science);activity recognition;computer science	HCI	4.741024497678869	-84.50787889477012	199848
b844e9f0e1120e5712c2a282ebd14d291c7dcf2a	exploring the relationship between learner eeg mental engagement and affect	response time;learning environment;healthy subjects;affective state;its;emotion;indexation;eeg;mental engagement;electroencephalography;human brain;problem solving	This paper studies the influence of learner’s affective states on the well established EEG-mental engagement index during a problem solving task. The electrical activity of the human brain, known as electroencephalography or EEG was registered according to an acquisition protocol in a learning environment specifically constructed for emotional elicitation. Data were gathered from 35 healthy subjects using 8 biosensors and two video cameras. The effect of learners’ emotional states on the engagement index was analyzed as well as their impact on response time variability and performance. Results showed that the engagement index was strongly influenced by emotional states and that the former can be used in an educational setting to reliably assess learner’s engagement.	artificial intelligence;calm technology;electroencephalography;heart rate variability;learner-generated context;online and offline;personalization;problem solving;problem solving environment;response time (technology);sensor;spatial variability;systems design;whole earth 'lectronic link	Maher Chaouachi;Claude Frasson	2010		10.1007/978-3-642-13437-1_48	electroencephalography	HCI	8.633573301287615	-92.93290476641212	199874
