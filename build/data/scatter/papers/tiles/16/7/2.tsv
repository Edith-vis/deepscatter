id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
2759976e7d8a27c788fb52a24830fc63ce0de570	why neural translations are the right length		We investigate how neural, encoder-decoder translation systems output target strings of appropriate lengths, finding that a collection of hidden units learns to explicitly implement this functionality.	encoder	Xing Shi;Kevin Knight;Deniz Yuret	2016			artificial intelligence;natural language processing;machine learning;computer science	NLP	-17.574679401478697	-74.91974915126725	52502
db210d54830c07dfd80248ec6d624a0255d18164	non-finality and pre-finality in bari italian intonation: a preliminary account		In this paper, a preliminary account of intonational strategies used by Bari Italian speakers in signal non-finality and prefinality in discourse organisation is presented and discussed. Results obtained from auditory and instrumental analysis of speech material elicited with different methods (Map Task dialogues and monologues, lists readings) show that a rich inventory of intonational choices is available to Bari Italian speakers for conveying subordination relationships within a sequence of information (in a route describing task, this is normally a sequence of instructions and/or explanations), but also for signalling in advance the end of the sequence. Moreover, these results represent a further contribution to the development of an autosegmental-metrical account of the Bari Italian intonation system.		Michelina Savino	2001			speech recognition;computer science	NLP	-11.255846524624953	-79.18560973717778	52515
36918b2ef6b20ffb8cffe458c0067742500c6149	"""""""look, some green circles!"""": learning to quantify from images"""		In this paper, we investigate whether a neural network model can learn the meaning of natural language quantifiers (no, some and all) from their use in visual contexts. We show that memory networks perform well in this task, and that explicit counting is not necessary to the system’s performance, supporting psycholinguistic evidence on the acquisition of quantifiers.	artificial neural network;memory cell (binary);natural language;network model;quantifier (logic)	Ionut Sorodoc;Angeliki Lazaridou;Gemma Boleda;Aurélie Herbelot;Sandro Pezzelle;Raffaella Bernardi	2016			natural language processing;computer science;artificial intelligence;communication	AI	-13.597459958237643	-74.31449208160494	52518
733966ee11461746822b10f0a0af2c0aa04572ca	subgram: extending skip-gram word representation with substrings		"""Skip-gram (word2vec) is a recent method for creating vector representations of words (""""distributed word representations"""") using a neural network. The representation gained popularity in various areas of natural language processing, because it seems to capture syntactic and semantic information about words without any explicit supervision in this respect. We propose SubGram, a refinement of the Skip-gram model to consider also the word structure during the training process, achieving large gains on the Skip-gram original test set."""	artificial neural network;natural language processing;refinement (computing);skip list;substring;test set;word2vec	Tom Kocmi;Ondrej Bojar	2016		10.1007/978-3-319-45510-5_21	natural language processing;word2vec;machine learning;computer science;artificial intelligence;syntax;gram;artificial neural network;popularity;substring	NLP	-18.78057121114444	-74.11699704720458	52614
536b0d1275eefb245a0fb7dbb50ec6a86cfa9e4f	mental representation of verb meaning: behavioral and electrophysiological evidence	potentiel evoque cognitif;representacion mental;naming;language use;comportement;event evoked potential;systeme nerveux central;verbe;lenguaje;semantics;hombre;representation mentale;langage;electrophysiology;encefalo;semantica;semantique;mental representation;sistema nervioso central;conducta;encephale;denomination;human;potencial evocado cognitivo;verbo;denominacion;electrofisiologia;encephalon;language;event related potential erp;behavior;sentence processing;electrophysiologie;computational semantics;central nervous system;homme;verb	Previous psycholinguistic research has debated the nature of the mental representation of verbs and the access of relevant verb information in sentence processing. In this study, we used behavioral and electrophysiological methods to examine the representation of verbs in and out of sentence contexts. In five experiments, word naming and event-related potential (ERP) components were used to measure the speed and the amplitude, respectively, associated with different verb-object combinations that result in different degrees of fit between the verb and its object. Both naming speed and ERP amplitudes (N400) are proven to be sensitive indices of the degree of fit, varying as a function of how well the object fits the verb in terms of selectional restrictions. The results suggest that the semantic features of the verb's arguments are an integral part of the mental representation of verbs, and such information of the verb is accessed and used on-line during sentence processing. Implications of these results are discussed in light of recent computational semantic models that view the lexicon through high-order lexical co-occurrences in language use.	erp;experiment;fits;floor and ceiling functions;lexicon;mental representation;online and offline;psycholinguistics	Xuesong Li;Hua Shu;Youyi Liu;Ping Li	2006	Journal of Cognitive Neuroscience	10.1162/jocn.2006.18.10.1774	psychology;electrophysiology;reflexive verb;predicate;central nervous system;mental representation;semantics;linguistics;language;communication;computational semantics;behavior	NLP	-9.113313064739026	-77.40207299849739	52953
d2bd379685f456ecc9d0484bcc094613fdf902e4	cyberbullying detection based on semantic-enhanced marginalized denoising auto-encoder	word embedding cyberbullying detection text mining representation learning stacked denoising autoencoders;semantics noise reduction numerical models feature extraction media robustness analytical models	As a side effect of increasingly popular social media, cyberbullying has emerged as a serious problem afflicting children, adolescents and young adults. Machine learning techniques make automatic detection of bullying messages in social media possible, and this could help to construct a healthy and safe social media environment. In this meaningful research area, one critical issue is robust and discriminative numerical representation learning of text messages. In this paper, we propose a new representation learning method to tackle this problem. Our method named semantic-enhanced marginalized denoising auto-encoder (smSDA) is developed via semantic extension of the popular deep learning model stacked denoising autoencoder (SDA). The semantic extension consists of semantic dropout noise and sparsity constraints, where the semantic dropout noise is designed based on domain knowledge and the word embedding technique. Our proposed method is able to exploit the hidden feature structure of bullying information and learn a robust and discriminative representation of text. Comprehensive experiments on two public cyberbullying corpora ( Twitter and MySpace) are conducted, and the results show that our proposed approaches outperform other baseline text representation learning methods.	autoencoder;baseline (configuration management);cyberbullying;deep learning;dictionary attack;dropout (neural networks);encoder;experiment;feature learning;machine learning;noise reduction;numerical analysis;social media;sparse matrix;text corpus;text-based (computing);word embedding	Rui Zhao;Kezhi Mao	2017	IEEE Transactions on Affective Computing	10.1109/TAFFC.2016.2531682	machine learning;word embedding;artificial intelligence;autoencoder;robustness (computer science);semantics;deep learning;feature extraction;feature learning;text mining;computer science	AI	-18.22547233031796	-68.18931198691469	53050
ea93bd39f7d78ea8abcb7a5847bace5b9d97f09f	a semantic study of modal words in mandarin chinese		Generating Chinese sentences require three kinds of words, including object words (lexical item), attribute words and relational words. Modal words (modal auxiliaries) are nature words which express a speaker’s attitude. They help to generate modal sentences and express modal meanings. In terms of modal meanings, modal words can be divided into three categories, expressing necessity, expectation, and disjunction respectively. Different types of modal words can be discovered by data mining and their semantic strength can be calculated. In the use of modal words the relationship between speaker’s identity and power should be considered.	super robot monkey team hyperforce go!	Jianshe Zhou;Narentuya;Jinsheng Shi	2015		10.1007/978-3-319-27194-1_17	mandarin chinese;modal;mathematics;pattern recognition;artificial intelligence;modal verb;lexical item	NLP	-14.712399789662578	-78.5854017119797	53407
871776e29749edfd19ccc71eea71c031ba9e81fb	an experimental comparison of formal measures of rhythmic syncopation		Rhythmic syncopation is one of the most fundamental features that can be used to characterize music. Therefore it can be applied in a variety of domains such as music information retrieval and style analysis. During the past twenty years a score of different formal measures of rhythmic syncopation have been proposed in the music literature. Here we compare eight of these measures with each other and with human judgements of rhythmic complexity. A data set of 35 rhythms ranked by human subjects was sorted using the eight syncopation measures. A Spearman rank correlation analysis of the rankings was carried out, and phylogenetic trees were calculated to visualize the resulting matrix of coefficients. The main finding is that the measures based on perception principles agree well with human judgements and very well with each other. The results also yield several surprises and open problems for further research.	coefficient;graph coloring;information retrieval;phylogenetic tree;phylogenetics	Francisco Gómez;Eric Thul;Godfried T. Toussaint	2007			style analysis;music information retrieval;rhythm;spearman's rank correlation coefficient;artificial intelligence;ranking;pattern recognition;mathematics;syncopation	ML	-6.2352847263832825	-79.82228587242847	53489
3525f6d6437bbeacc94a9482ae5fa14d34c62389	emotion in deceptive language		Deception involves emotions of fear and guilt. These negative emotions are expressed in language in terms of psychological distance from the deception object. The psychological distance and emotional experience reflect an attempt to control the negative mental representation. More especifically emotional distance is represented in deceptive language by means of cues of reference, verb tense and detail avoidance. Then, hints of emotions of fear and guilt should be displayed in language.The present work analyses emotional language cues for deception detection by means of Machine Learning(ML) techniques and Linguistic Inquiry and Word Count (LIWC). Results show that Support Vector Machines (SVM) best represents the discrimination between true and false information (up to 74.15 % of accuracy rates) based only on the effect of emotion in deceptive speech.	mental representation;support vector machine	Iraide Zipitria;Basilio Sierra;Imanol Sopena-Garaikoetxea	2017			cognitive psychology;psychology	NLP	-13.591460132750257	-78.208417215432	53571
020c110cf4df2c3a09ad59454363c7987ec75ff1	the role played by intralayer and interlayer feedback connections in recurrent neural networks used for planning	recurrent neural network	This paper proposes five partially recurrent neural networks architectures to evaluate the different roles played by interlayer and intralayer feedback connections in planning a temporal sequence of states. The first model has only one-to-one feedback connections from the output towards the input layer. This topology is taken as the reference one. The other models have interlayer and/or intralayer all-to-all feedback connections added to them. All feedback connections, but the one-to-one feedback links, are trainable. The models yield a sequence which take four blocks from an initial to a goal state, when these states are presented to the network. The models showed good performance for planning in different levels of complexity. The results suggest that the models have poor generalization power.	recurrent neural network	Aluizio F. R. Araújo;Hélio D'Arbo	1997	J. Braz. Comp. Soc.		computer science;artificial intelligence;recurrent neural network;machine learning	AI	-15.106403362724201	-73.845152925831	53777
2ef3364a8086af2aeb78cb4325dede9f3bfce84f	gc-lstm: graph convolution embedded lstm for dynamic link prediction.		Dynamic link prediction is a research hot in complex networks area, especially for its wide applications in biology, social network, economy and industry. Compared with static link prediction, dynamic one is much more difficult since network structure evolves over time. Currently most researches focus on static link prediction which cannot achieve expected performance in dynamic network. Aiming at low AUC, high Error Rate, add/remove link prediction difficulty, we propose GC-LSTM, a Graph Convolution Network (GC) embedded Long Short Term Memory network (LTSM), for end-to-end dynamic link prediction. To the best of our knowledge, it is the first time that GCN embedded LSTM is put forward for link prediction of dynamic networks. GCN in this new deep model is capable of node structure learning of network snapshot for each time slide, while LSTM is responsible for temporal feature learning for network snapshot. Besides, current dynamic link prediction method can only handle removed links, GC-LSTM can predict both added or removed link at the same time. Extensive experiments are carried out to testify its performance in aspects of prediction accuracy, Error Rate, add/remove link prediction and key link prediction. The results prove that GC-LSTM outperforms current state-of-art method.		Jinyin Chen;Xuanheng Xu;Yangyang Wu;Haibin Zheng	2018	CoRR		artificial intelligence;snapshot (computer storage);machine learning;computer science;dynamic network analysis;complex network;word error rate;social network;convolution;feature learning;graph	ML	-10.843209070836075	-67.55309138758231	53872
0611e87cc5ca9ea0f6538995a91671625be9b762	learning of relational categories as a function of higher-order structure	social and behavioral sciences	Higher-order relations are important for various cognitive tasks, such as analogical transfer. The current study tested people’s ability to learn new relational categories, using a learning test of pure higher-order relations. Each stimulus consisted of 4 objects varying on 3 dimensions. Each category was defined by three binary relations between pairs of objects, producing six logically different conditions. Every category was composed of the same number of relations, but differed in the manner that the relations were linked (i.e., by operating on shared objects). Various learning models were compared and the significance of their performance on the experimental task is discussed. The current findings may advance understanding of the cognitive mechanisms involved in relational learning and the manner in which people naturally represent higher-order relational structures.	linker (computing)	Daniel Corral;Matt Jones	2012			psychology;cognitive psychology;computer science;artificial intelligence;mathematics;sociology;communication;social psychology;cognitive science	AI	-8.330083541578343	-76.38712612123096	54037
a342d3d1e464455c15097bea30cc0cb1788a6f75	disease diagnosis in crops using content based image retrieval	image retrieval content based retrieval crops expert systems image matching;expert systems;image matching;intelligent systems decision support systems;crops;content based retrieval;early detection content based image retrieval crops expert system single picture image matching auto color correlogram fcth cedd automatic image based disease diagnosis image infestation;image retrieval	Farmers always need satisfactory and easy advice from experts. To get the advice from an expert system, it should have enough knowledge about the domain. Gathering enough knowledge and representing it in a machine understandable format is time consuming and difficult job. Also, representing each and every kind of knowledge is still a research issue. Since, a single picture is worth a thousand words, it will be a good idea to acquire knowledge also in images rather than only text. Image is an easy way of communication without any boundary of language. Hence there is a need for building an expert system with content based image retrieval which could acquire and deliver the knowledge by searching the image having the similar features that is searched by the user. In the presented work, a system is developed to diagnose diseases in crops by matching the uploaded image of a diseased plant from the corpus of images. Three techniques viz. CEDD, Auto Color Correlogram and FCTH are tested and the result is presented. The automatic image based disease diagnosis in crops may help farmers in early detection of diseases and losses due to the image infestation can be reduced.	a picture is worth a thousand words;content-based image retrieval;expert system;text corpus;viz: the computer game	Sudeep Marwaha;Subhash Chand;Arijit Saha	2012	2012 12th International Conference on Intelligent Systems Design and Applications (ISDA)	10.1109/ISDA.2012.6416627	crop;computer vision;visual word;image retrieval;computer science;data mining;automatic image annotation;information retrieval	AI	-5.2010534125560985	-70.5987194113226	54154
ff4b351dccb970f13a345adf0647ffe8c2021f1f	query-guided regression network with context policy for phrase grounding		Given a textual description of an image, phrase grounding localizes objects in the image referred by query phrases in the description. State-of-the-art methods address the problem by ranking a set of proposals based on the relevance to each query, which are limited by the performance of independent proposal generation systems and ignore useful cues from context in the description. In this paper, we adopt a spatial regression method to break the performance limit, and introduce reinforcement learning techniques to further leverage semantic context information. We propose a novel Query-guided Regression network with Context policy (QRC Net) which jointly learns a Proposal Generation Network (PGN), a Query-guided Regression Network (QRN) and a Context Policy Network (CPN). Experiments show QRC Net provides a significant improvement in accuracy on two popular datasets: Flickr30K Entities and Referit Game, with 14.25% and 17.14% increase over the state-of-the-arts respectively.		Kan Chen;Rama Kovvuri;Ramakant Nevatia	2017	2017 IEEE International Conference on Computer Vision (ICCV)	10.1109/ICCV.2017.95	leverage (finance);machine learning;visualization;artificial intelligence;semantics;pattern recognition;regression;reinforcement learning;phrase;computer science;ranking	Vision	-15.237910794694889	-69.63820102983084	54449
f0e626ae39ba9b3478bfc1e15189606aeb794795	story cloze evaluator: vector space representation evaluation by predicting what happens next		The main intrinsic evaluation for vector space representation has been focused on textual similarity, where the task is to predict how semantically similar two words or sentences are. We propose a novel framework, Story Cloze Evaluator, for evaluating vector representations which goes beyond textual similarity and captures the notion of predicting what should happen next given a context. This evaluation methodology is simple to run, scalable, reproducible by the community, non-subjective, 100% agreeable by human, and challenging to the state-of-theart models, which makes it a promising new framework for further investment of the representation learning community.	commonsense knowledge (artificial intelligence);commonsense reasoning;crowdsourcing;feature learning;inferential theory of learning;interpreter (computing);machine learning;natural language processing;natural language understanding;scalability	Nasrin Mostafazadeh;Lucy Vanderwende;Wen-tau Yih;Pushmeet Kohli;James F. Allen	2016		10.18653/v1/W16-2505	natural language processing;computer science;theoretical computer science;data mining	NLP	-16.267478902088165	-69.17435701508306	54476
0c49eb69e07339881d71c76ee9c0fec528f0fcf4	deep reinforcement learning for mention-ranking coreference models		Coreference Resolution September 2015 Present Kevin Clark, Christopher Manning Stanford University Developed coreference systems that build up coreference chains with agglomerative clustering. These models are much more expressive than the mention-pair systems commonly used in prior work. Developed neural coreference systems that do not require the large number of complex hand-engineered features commonly found in statistical coreference systems. Applied imitation and reinforcement learning to directly optimize coreference systems for evaluation metrics instead of relying on hand-tuned heuristic loss functions. Made substantial advancements to the current state-of-the-art on English and Chinese coreference. Publicly released all models through Stanford’s CoreNLP.	cluster analysis;heuristic;loss function;reinforcement learning	Kevin Clark;Christopher D. Manning	2016			natural language processing;computer science;artificial intelligence;machine learning	NLP	-18.8751772025024	-75.0131029537076	54726
783f5a1f1cbb7874b0f1c7dad2159553d2e8d1f3	multiple kernel learning for ontology instance matching		This paper proposes to apply Multiple Kernel Learning and Indefinite Kernels (IK) to combine and tune Similarity Measures within the context of Ontology Instance Matching. We explain why MKL can be used in parameter selection and similarity measure combination; argue that IK theory is required in order to use MKL within this context; propose a configuration that makes use of both concepts; and present, using the IIMB bechmark, results of a prototype to show the feasibility of this idea in comparison with other matching tools.	algorithm;benchmark (computing);kernel (operating system);math kernel library;multiple kernel learning;prototype;separation kernel;similarity measure;unbalanced circuit	Diego Ardila;José Abásolo;Fernando Lozano	2010			instance-based learning;machine learning;pattern recognition;data mining;ontology-based data integration;tree kernel;polynomial kernel	NLP	-17.889180428648174	-66.35602562049625	54880
2b30a6dd4157046e8c03d02354af2d8e3a1f01ec	predicting the performance in decision-making tasks: from individual cues to group interaction	group performance analysis social computing multimodal interaction;support vector machines decision making feature extraction group theory hidden markov models pattern classification;feature extraction decision making hidden markov models psychology social computing visualization computational modeling;hmm decision making tasks group interaction decision making groups group attributes predictive power automatically extracted features perception related cues group hierarchical structure group level task performances support vector machines model based novel classifier hidden markov model	This paper addresses the problem of predicting the performance of decision-making groups. Towards this goal, we evaluate the predictive power of group attributes and discussion dynamics by using automatically extracted features, such as group members' aural and visual cues, interaction between team members, and influence of each team member, as well as self-reported features such as personality- and perception-related cues, hierarchical structure of the group, and individual- and group-level task performances. We tackle the inference problem from two angles depending on the way that features are extracted: 1) a holistic approach based on the entire meeting, and 2) a sequential approach based on the thin slices of the meeting. In the former, key factors affecting the group performance are identified and the prediction is achieved by support vector machines. As for the latter, we compare and contrast the classification performance of an influence model-based novel classifier with that of hidden Markov model (HMM). Experimental results indicate that the group looking cues and the influence cues are major predictors of group performance and the influence model outperforms the HMM in almost all experimental conditions. We also show that combining classifiers covering unique aspects of data results in improvement in the classification performance.	hidden markov model;holism;markov chain;performance;support vector machine	Umut Avci;Oya Aran	2016	IEEE Transactions on Multimedia	10.1109/TMM.2016.2521348	computer science;artificial intelligence;machine learning;pattern recognition	Vision	-11.275714009782906	-71.09150576647116	55009
27b2ba68c8cfa55786c29133a3f6cba114ef4859	the 2014 icsi/tu delft location estimation system		In this paper, we describe the ICSI/TU Delft video location estimation system presented at the MediaEval 2014 Placing Task. We describe two text-based approaches based on spatial variance and graphical model framework, a visualcontent-based geo-visual ranking approach, and a multi-modal approach that combines the text and visual-based algorithms.	algorithm;graphical model;modal logic;text-based (computing)	Jaeyoung Choi;Xinchao Li	2014			simulation;speech recognition;computer science;cartography	ML	-8.406767608968718	-69.72514156110633	55104
440ee428b5ddf73256bad60486270f5f78b93b6f	event structure as a basis of semantic processing of familiar metaphors		Abstract In this paper I propose a model of metaphor interpretation that would account for the possibility that semantic processing of familiar metaphors no longer go through the sequential steps of alignment and projection, but may rather be established upon schematic semantic units allowing faster processing. The proposition is grounded on the notion that metaphors are formed based on peoples’ perception of what is typically associated with entities. It is suggested that in its most abstract form, these associations are essentially events, analyzed in terms of event structure.		Andrew P. L. Tobing	2018	Cognitive Systems Research	10.1016/j.cogsys.2017.10.002	natural language processing;cognitive science;theoretical computer science;psychology;semantic memory;perception;proposition;metaphor;event structure;schematic;artificial intelligence	Robotics	-9.006794292860214	-76.9476702337923	55173
474a02ffa5398439b3645bf11393304430e3cc9b	generating continuous representations of medical texts		We present an architecture that generates medical texts while learning an informative, continuous representation with discriminative features. During training the input to the system is a dataset of captions for medical X-Rays. The acquired continuous representations are of particular interest for use in many machine learning techniques where the discrete and high-dimensional nature of textual input is an obstacle. We use an Adversarially Regularized Autoencoder to create realistic text in both an unconditional and conditional setting. We show that this technique is applicable to medical texts which often contain syntactic and domain-specific shorthands. A quantitative evaluation shows that we achieve a lower model perplexity than a traditional LSTM generator.	autoencoder;baseline (configuration management);discrete mathematics;information;long short-term memory;machine learning;natural language generation;perplexity	Graham Spinks;Marie-Francine Moens	2018			architecture;natural language processing;discriminative model;perplexity;autoencoder;shorthands;obstacle;computer science;artificial intelligence;syntax	NLP	-16.342065946891317	-74.47317801750502	55676
48fb9ed93a8b23c54635ef0a161f8eff09479e22	classification using link prediction		Link prediction in a graph is the problem of detecting the missing links that would be formed in the near future. Using a graph representation of the data, we can convert the problem of classification to the problem of link prediction which aims at finding the missing links between the unlabeled data (unlabeled nodes) and their classes. To our knowledge, despite the fact that numerous algorithms use the graph representation of the data for classification, none are using link prediction as the heart of their classifying procedure. In this work, we propose a novel algorithm called CULP (Classification Using Link Prediction) which uses a new structure namely Label Embedded Graph or LEG and a link predictor to find the class of the unlabeled data. Different link predictors along with Compatibility Score a new link predictor we proposed that is designed specifically for our settings has been used and showed promising results for classifying different datasets. This paper further improved CULP by designing an extension called CULM which uses a majority vote (hence the M in the acronym) procedure with weights proportional to the predictions’ confidences to use the predictive power of multiple link predictors and also exploits the low level features of the data. Extensive experimental evaluations shows that both CULP and CULM are highly accurate and competitive with the cutting edge graph classifiers and general classifiers.		Yasuyuki Hashiguchi;Maryam Amir Haeri	2018	CoRR		machine learning;graph (abstract data type);artificial intelligence;mathematics;graph	AI	-10.53401955902043	-67.4075677556988	55885
768eb193b8009f30d3d56dec9559466f46e26f0d	categorization ability, but not theory of mind, contributes to children's developing understanding of expertise		Children as young as age 3 understand that different people have different areas of expertise (i.e., the division of cognitive labor) and they choose information sources accordingly (e.g., Lutz & Keil, 2002). However, it is unclear whether this understanding depends primarily on social cognitive skills, such as an appreciation of others’ mental states, or non-social cognitive skills, such as the ability to categorize different types of entities. To address this question, children ages 3 to 5 (n=63) completed tasks measuring social and non-social cognitive skills, and made inferences about what two unfamiliar experts would know. The results demonstrate that developmental differences in children’s understanding of expertise are mediated through concomitant differences in categorization ability, but not theory of mind.	categorization;entity;jack lutz;mental state	Judith H Danovitch;Nicholaus S. Noles	2014				HCI	-8.061675238390025	-78.08146996251575	56201
19427b856c3add53aaa533b4726ada952b6c4440	alternation across semantic fields: a study of mandarin verbs of emotion	keh jiann;判解;huang;法律詞典;論文;conference paper;li li;大陸法學;法規;chang;月旦法學;chu ren;法律題庫;裁判時報;月旦知識庫;法學資料庫;tssci;mandarin verbs of emotion;教學;chen	In this paper we will explore the consistent contrast between VV-compounds and non-Wcompounds across seven subgroups of verbs of emotion. The distinctive syntactic features for the contrast include the distribution of the grammatical functions, the cooccrrence restrictions with head nouns and head verbs, the compatibilities with the imperative and evaluative constructions, the aspect, and the transitivity. We conclude that the contrast is motivated by event structure properties. To describe a state-type event, the speaker could choose to focus on the inchoative stage or the homogeneous stage of the event. In addition, since VV compounding has the function of type-lifting an event to a referential term, or to refer to its generic properties, it is natural to predict that VV compounding is a predominant source for the verbs of indicating homogeneity.	imperative programming;lambda lifting;super robot monkey team hyperforce go!;verification and validation;vertex-transitive graph	Li-Li Chang;Keh-Jiann Chen;Chu-Ren Huang	1999			psychology;natural language processing;modal verb;linguistics;communication	NLP	-11.609802294014449	-79.83050806465661	56310
27eba11d57f7630b75fb67644ff48087472414f3	do rnns learn human-like abstract word order preferences?		RNN language models have achieved state-ofthe-art results on various tasks, but what exactly they are representing about syntax is as yet unclear. Here we investigate whether RNN language models learn humanlike word order preferences in syntactic alternations. We collect language model surprisal scores for controlled sentence stimuli exhibiting major syntactic alternations in English: heavy NP shift, particle shift, the dative alternation, and the genitive alternation. We show that RNN language models reproduce human preferences in these alternations based on NP length, animacy, and definiteness. We collect human acceptability ratings for our stimuli, in the first acceptability judgment experiment directly manipulating the predictors of syntactic alternations. We show that the RNNs’ performance is similar to the human acceptability ratings and is not matched by an n-gram baseline model. Our results show that RNNs learn the abstract features of weight, animacy, and definiteness which underlie soft constraints on syntactic alternations. The best-performing models for many natural language processing tasks in recent years have been recurrent neural networks (RNNs) (Elman, 1990; Sutskever et al., 2014; Goldberg, 2017), but the black-box nature of these models makes it hard to know exactly what generalizations they have learned about their linguistic input: Have they learned generalizations stated over hierarchical structures, or only dependencies among relatively local groups of words (Linzen et al., 2016; Gulordava et al., 2018; Futrell et al., 2018)? Do they represent structures analogous to syntactic dependency trees (Williams et al., 2018), and can they represent complex relationships such as filler–gap dependencies (Chowdhury and Zamparelli, 2018; Wilcox et al., 2018)? In order to make progress with RNNs, it is crucial to determine what RNNs actually learn given currently standard practices; then we can design network architectures, objective functions, and training practices to build on strengths and alleviate weaknesses (Linzen, 2018). In this work, we investigate whether RNNs trained on a language modeling objective learn certain syntactic preferences exhibited by humans, especially those involving word order. We draw on a rich literature from quantitative linguistics that has investigated these preferences in corpora and experiments (e.g., McDonald et al., 1993; Stallings et al., 1998; Bresnan et al., 2007; Rosenbach, 2008). Word order preferences are a key aspect of human linguistic knowledge. In many cases, they can be captured using local co-occurrence statistics: for example, the preference for subject–verb– object word order in English can often be captured directly in short word strings, as in the dramatic preference for I ate apples over I apples ate. However, some word order preferences are more abstract and can only be stated in terms of higherorder linguistic units and abstract features. For example, humans exhibit a general preference for word orders in which words linked in syntactic dependencies are close to each other: such sentences are produced more frequently and comprehended more easily (Hawkins, 1994; Futrell et al., 2015; Temperley and Gildea, 2018). We are interested in whether RNNs learn abstract word order preferences as a way of probing their syntactic knowledge. If RNNs exhibit these preferences for appropriately controlled stimuli, then on some level they have learned the abstractions required to state them. Knowing whether RNNs show human-like word order preferences also bears on their suitability as language generation systems. White and Rajkumar (2012) have shown that language gener-		Richard Futrell;Roger P. Levy	2018	CoRR		machine learning;word order;definiteness;artificial intelligence;language model;animacy;syntax;alternation (linguistics);sentence;heavy np shift;computer science	NLP	-11.473267111657238	-75.4363626417836	56326
82eed3fdfe8a9173157583cf40a514479f598f0a	mathematical models for balkan phonological convergence	mathematical model;balkan phonological convergence	The high structuring of phonology, the obvious classes of sounds, and the classes of their classes, have made phonological typologies a not too rare proposal. And even where typologies were not claimed as such, they were often implicit in the statements made. Both phonetic and phonemic, acoustic and articulatory, structural and non-structural, have all been proposed and have evoked discussions, critiques and applications. One can mention works by the Prague linguists culminating in the writings of, among others, Skali~ka, Kramsky, and no=ably Trubetzkoy and Jakobson. In America, we have work by Greenberg, Hockett, Saporta and Voegelin as well as numerous followers and critics. Among other European contributions the acoustic typologies by Menzerath and Meyer-Eppler. 0.i Mathematical models and mathematlcal (more precisely statistical) techniques of analysis have also been elaborated. Classification , distribution and frequency characteristics of various sound patterns have been a particular concern and represent the bulk of numerical phonological typologies, especially in the U.S, I Often, again, the subject is classification of inventories and particular types (articulatory) of phonemeS. Such is, for instance, Pierce~s	acoustic cryptanalysis;bernard greenberg;inventory;ka band;numerical analysis;pierce oscillator	Evangelos A. Afendras	1969			computer science;theoretical computer science;mathematical model	Web+IR	-13.370918604662018	-79.97844252092712	56405
4aa9f5150b46320f534de4747a2dd0cd7f3fe292	semi-supervised sequence learning		We present two approaches that use unlabeled data to improve sequ nce learning with recurrent networks. The first approach is to predict wha t comes next in a sequence, which is a conventional language model in natural language processing. The second approach is to use a sequence autoencoder, which r eads the input sequence into a vector and predicts the input sequence again. T hese two algorithms can be used as a “pretraining” step for a later supervised seq uence learning algorithm. In other words, the parameters obtained from the unsu pervised step can be used as a starting point for other supervised training model s. In our experiments, we find that long short term memory recurrent networks after b eing pretrained with the two approaches are more stable and generalize bette r. With pretraining, we are able to train long short term memory recurrent network s up to a few hundred timesteps, thereby achieving strong performance in ma ny text classification tasks, such as IMDB, DBpedia and 20 Newsgroups.	algorithm;autoencoder;dbpedia;document classification;experiment;internet movie database (imdb);language model;long short-term memory;natural language processing;recurrent neural network;semi-supervised learning;semiconductor industry	Andrew M. Dai;Quoc V. Le	2015			computer science;artificial intelligence;machine learning;pattern recognition	ML	-18.1417148668537	-74.92507360821966	56591
b852f821260d27e59d1df10f0bbb4c0719e29144	considering cross-cultural context in the automatic recognition of emotions		Automatic recognition of emotions remains an ongoing challenge and much effort is being invested towards developing a system to solve this problem. Although several systems have been proposed, there is still none that considers the cultural context for emotion recognition. It remains unclear whether emotions are universal or culturally specific. A study on how culture influences the recognition of emotions is presented. For this purpose, a multicultural corpus for cross-cultural emotion analysis is constructed. Subjects from three different cultures—American, Asian and European—are recruited. The corpus is segmented and annotated. To avoid language artifacts, the emotion recognition model considers facial expressions, head movements, body motions and dimensional emotions. Three training and testing paradigms are carried out to compare cultural effects: intra-cultural, cross-cultural and multicultural emotion recognition. Intra-cultural and multicultural emotion recognition paradigms raised the best recognition results; cross-cultural emotion recognition rates were lower. These results suggest that emotion expression varies by culture, representing a hint of emotion specificity.		Maria Alejandra Quiros-Ramirez;Takehisa Onisawa	2015	Int. J. Machine Learning & Cybernetics	10.1007/s13042-013-0192-2	psychology;developmental psychology;affective science;communication;social psychology	NLP	-8.373541817144632	-80.21175576070127	56911
0a11eb84021374fe1ae566ec80ad61d2f9518099	deep model for dropout prediction in moocs		Dropout prediction research in MOOCs aims to predict whether students will drop out from the courses instead of completing them. Due to the high dropout rates in current MOOCs, this problem is of great importance. Current methods rely on features extracted by feature engineering, in which all features are extracted manually. This process is costly, time consuming, and not extensible to new datasets from different platforms or different courses with different characters. In this paper, we propose a model that can automatically extract features from the raw MOOC data. Our model is a deep neural network, which is a combination of Convolutional Neural Networks and Recurrent Neural Networks. Through extensive experiments on a public dataset, we show that the proposed model can achieve results comparable to feature engineering based methods.	artificial neural network;convolutional neural network;deep learning;dropout (neural networks);experiment;feature engineering;long short-term memory;massive open online course;neural networks;one-hot;random neural network;recurrent neural network	Wei Wang;Han Yu;Chunyan Miao	2017		10.1145/3126973.3126990	convolutional neural network;deep learning;artificial neural network;machine learning;feature engineering;recurrent neural network;artificial intelligence;engineering	AI	-17.844535156374643	-70.64499967685327	56925
63c490f2a3330e3685e7df50973278296905f63b	a fixed-size encoding method for variable-length sequences with its application to neural network language models		In this paper, we propose the new fixedsize ordinally-forgetting encoding (FOFE) method, which can almost uniquely encode any variable-length sequence of words into a fixed-size representation. FOFE can model the word order in a sequence using a simple ordinally-forgetting mechanism according to the positions of words. In this work, we have applied FOFE to feedforward neural network language models (FNN-LMs). Experimental results have shown that without using any recurrent feedbacks, FOFE based FNNLMs can significantly outperform not only the standard fixed-input FNN-LMs but also the popular recurrent neural network (RNN) LMs.	artificial neural network;encode;feedforward neural network;language model;random neural network;recurrent neural network	Shiliang Zhang;Hui Jiang;Mingbin Xu;Junfeng Hou;Li-Rong Dai	2015	CoRR		natural language processing;computer science;artificial intelligence;machine learning	NLP	-17.472811245834027	-74.85385991941357	56960
786afa791e2b83beb497db45f0d3633170a074e9	learning words and their meanings from unsegmented child-directed speech	child directed speech	Most work on language acquisition treats word segmentation—the identification of linguistic segments from continuous speech— and word learning—the mapping of those segments to meanings—as separate problems. These two abilities develop in parallel, however, raising the question of whether they might interact. To explore the question, we present a new Bayesian segmentation model that incorporates aspects of word learning and compare it to a model that ignores word meanings. The model that learns word meanings proposes more adult-like segmentations for the meaning-bearing words. This result suggests that the non-linguistic context may supply important information for learning word segmentations as well as word meanings.	bayesian network;galaxy morphological classification;interaction;syllable;synergy;text segmentation;unsupervised learning;word lists by frequency	Bevan K. Jones;Mark Johnson;Michael C. Frank	2010			natural language processing;speech recognition;word recognition;computer science;word lists by frequency;linguistics	NLP	-10.972366819815013	-77.72757672156227	57162
9c0fa7bf477b13f5e49feea336e1a8d5c47fbd53	network public opinion emotion classification based on joint deep neural network		The analysis of the emotional tendency of public opinion data in the network can help to grasp the dynamics of public opinion in a timely and accurate way, and extract the trend of public opinions. At present, the neural network model has been proved to have a good performance in sentiment classification. Therefore, according to the characteristics of public opinion information, this paper proposes a joint deep neural network to extract high-dimensional features of word-level through convolutional neural network (CNN), and then input it into the long short term memory network (LSTM) to learning sequence characteristics. This model was used to emotionally categorize the Weibo commentary data of “Yulin Maternal Jumping Event” and obtained high classification accuracy.	deep learning	Xiaoling Xia;Wenjie Wang;Guohua Yang	2018		10.1007/978-3-030-00006-6_64	convolutional neural network;computer science;long short term memory;artificial neural network;emotion classification;categorization;machine learning;grasp;public opinion;distributed computing;artificial intelligence	NLP	-18.259396631657882	-70.5096960915059	57269
9563d6fafb6ba09c082a57e8d9b31494029a45ac	building a large-scale multimodal knowledge base for visual question answering		The complexity of the visual world creates significant challenges for comprehensive visual understanding. In spite of recent successes in visual recognition, a lack of common sense knowledge and the insufficiencies of joint reasoning still leave a large gap between computer vision models and their human counterparts for higher-level tasks such as question answering (QA). In this work, we build a multimodal knowledge base (KB) incorporating visual, textual and structured data, as well as their diverse relations for visual QA. Such a general-purpose approach presents major challenges in terms of scalability and quality. Our approach is to cast large-scale MRFs into a KB representation, and introduce a scalable knowledge base construction system by leveraging database techniques. We unify several visual QA tasks in a principled query language. Our KB achieves competitive results compared to purpose-built models, while exhibiting greater flexibility in visual QA.	commonsense knowledge (artificial intelligence);computer vision;general-purpose modeling;knowledge base;knowledge representation and reasoning;multimodal interaction;query language;question answering;scalability;software quality assurance	Yuke Zhu;Ce Zhang;Christopher Ré;Li Fei-Fei	2015	CoRR		natural language processing;question answering;data mining;information retrieval	AI	-14.746098502519828	-68.10494937158012	57588
1f4e629e5124128f64be1aee025c48347ab335ff	affective state prediction of contextualized concepts		Most studies on affective analysis of text focus on the sentiment or emotion expressed by a whole sentence or document. In this paper, we propose a novel approach to predict the affective states of a described event through the predictions of the corresponding subject, action and object involved in the described event. Rather than using a sentiment label or discrete emotion categories, the affective state is represented using the three dimensional evaluation-potency-activity (EPA) model. The main idea is to use automatically obtained word embedding as word representation and to use the Long Short-Term Memory (LSTM) network as the prediction model. Compared to the linear model used in the Affective Control Theory which uses manually annotated EPA lexicon, our proposed LSTM learning method using word embedding outperforms the linear model and word embedding also performs better than EPA lexicon. Most importantly, our work shows that automatically obtained word embedding outperforms manually constructed affective lexicons.	control theory;experiment;lexicon;linear model;long short-term memory;word embedding	Minglei Li;Qin Lu;Yunfei Long;Lin Gui	2017			affect (psychology);computer science;knowledge management	NLP	-15.634232383167365	-71.9045701615148	57752
febb8e9e1dd582dc5f9da970d22f4dbd229083b9	memory indexing of sequential symptom processing in diagnostic reasoning	spatial indexing;belief updating;situated cognition;diagnostic reasoning;eye tracking;process tracing	In diagnostic reasoning, knowledge about symptoms and their likely causes is retrieved to generate and update diagnostic hypotheses in memory. By letting participants learn about causes and symptoms in a spatial array, we could apply eye tracking during diagnostic reasoning to trace the activation level of hypotheses across a sequence of symptoms and to evaluate process models of diagnostic reasoning directly. Gaze allocation on former locations of symptom classes and possible causes reflected the diagnostic value of initial symptoms, the set of contending hypotheses, consistency checking, biased symptom processing in favor of the leading hypothesis, symptom rehearsal, and hypothesis change. Gaze behavior mapped the reasoning process and was not dominated by auditorily presented symptoms. Thus, memory indexing proved applicable for studying reasoning tasks involving linguistic input. Looking at nothing revealed memory activation because of a close link between conceptual and motor representations and was stable even after one week.	case-based reasoning;checking (action);class;eye tracking;indexes;linguistics;reasoning - publishing subsection	Georg Jahn;Janina Braatz	2012	Cognitive Psychology	10.1016/j.cogpsych.2013.11.002	psychology;developmental psychology;eye tracking;verbal reasoning;situated cognition;linguistics;communication;social psychology;cognitive science	AI	-6.657200162464326	-77.09417186699523	57759
8b826ba3c9d1ef613fcd3e537055f813ae8a379b	attention to endpoints: a cross-linguistic constraint on spatial meaning	universaux linguistiques;kinesthetic perception;english language;cognitive psychology;spatial motion;semantics;attention;motion;semantique;localisation spatiale;spatial localization;arabic;anglais;bias;distinctive features language;spatial language;psychologie cognitive;semitic languages;language universals;perception visuelle;visual perception;english;arabe;chinois;chinese;attentional bias;language and thought;context effect;semantic universals;linguistics	We investigate a possible universal constraint on spatial meaning. It has been proposed that people attend preferentially to the endpoints of spatial motion events, and that languages may therefore make finer semantic distinctions at event endpoints than at event beginnings. We test this proposal. In Experiment 1, we show that people discriminate the endpoints of spatial motion events more readily than they do event beginnings-suggesting a non-linguistic attentional bias toward endpoints. In Experiment 2, speakers of Arabic, Chinese, and English each described a set of spatial events displayed in video clips. Although the spatial systems of these languages differ, speakers of all three languages made finer semantic distinctions at event endpoints, compared to event beginnings. These findings are consistent with the proposal that event endpoints are privileged over event beginnings, in both language and perception.	homophobia;languages;linguistics;machine perception;video clip	Terry Regier;Mingyu Zheng	2007	Cognitive science	10.1080/15326900701399954	psychology;cognitive psychology;english;semantics;linguistics;communication;cognitive science	HCI	-8.493893916663575	-77.17704742102794	57847
d4a3eb0d1b3a1558b98865b6870b6b0684909e5b	predication drives verb cortical signatures		Verbs and nouns are fundamental units of language, but their neural instantiation remains poorly understood. Neuropsychological research has shown that nouns and verbs can be damaged independently of each other, and neuroimaging research has found that several brain regions respond differentially to the two word classes. However, the semantic–lexical properties of verbs and nouns that drive these effects remain unknown. Here we show that the most likely candidate is predication: a core lexical feature involved in binding constituent arguments (boy, candies) into a unified syntactic–semantic structure expressing a proposition (the boy likes the candies). We used functional neuroimaging to test whether the intrinsic “predication-building” function of verbs is what drives the verb–noun distinction in the brain. We first identified verb-preferring regions with a localizer experiment including verbs and nouns. Then, we examined whether these regions are sensitive to transitivity—an index measuring its tendency to select for a direct object. Transitivity is a verb-specific property lying at the core of its predication function. Neural activity in the left posterior middle temporal and inferior frontal gyri correlates with transitivity, indicating sensitivity to predication. This represents the first evidence that grammatical class preference in the brain is driven by a word's function to build predication structures.	candy;class;electronic signature;functional neuroimaging;intrinsic drive;substitution (logic);telling untruths;vertex-transitive graph	Mireia Hernández;Scott L. Fairhall;Alessandro Lenci;Marco Baroni;Alfonso Caramazza	2014	Journal of Cognitive Neuroscience	10.1162/jocn_a_00598	psychology;linguistics;communication	NLP	-9.521147688039486	-77.35784498719167	57969
0b544dfe355a5070b60986319a3f51fb45d1348e	learning phrase representations using rnn encoder--decoder for statistical machine translation		In this paper, we propose a novel neural network model called RNN Encoder– Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder–Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.	artificial neural network;bleu;beta encoder;language model;linear model;log-linear model;natural language;network architecture;network model;random neural network;recurrent neural network;speech synthesis;statistical machine translation;string (computer science);transcription (software);well-formed formula	Kyunghyun Cho;Bart van Merrienboer;Çaglar Gülçehre;Dzmitry Bahdanau;Fethi Bougares;Holger Schwenk;Yoshua Bengio	2014		10.3115/v1/D14-1179	natural language processing;computer science;machine learning;pattern recognition	NLP	-17.73005998297795	-74.96236666108682	58049
03db6467062f38e5992a3e0853b50e92e97788d2	learning style compatibility for furniture		When judging style, a key question that often arises is whether or not a pair of objects are compatible with each other. In this paper we investigate how Siamese networks can be used efficiently for assessing the style compatibility between images of furniture items. We show that the middle layers of pretrained CNNs can capture essential information about furniture style, which allows for efficient applications of such networks for this task. We also use a joint image-text embedding method that allows for the querying of stylistically compatible furniture items, along with additional attribute constraints based on text. To evaluate our methods, we collect and present a large scale dataset of images of furniture of different style categories accompanied by text attributes.		Divyansh Aggarwal;Elchin Valiyev;Fadime Sener;Angela Yao	2018	CoRR			Vision	-15.129593444275157	-69.15787013816653	58088
cfbccc86ae733cdc3b0a22cea4c0fb5225377647	multimodal language acquisition based on motor learning and interaction	robot learning;humanoid robot;jamforande sprakvetenskap och lingvistik;vocal tract;robotics;language acquisition;general language studies and linguistics;fonetik;robotteknik och automation;phonetics;motor learning	In this work we propose a methodology for language acquisiti on n humanoid robots that mimics that in children. Language acquisition is a comp lex rocess that involves mastering several different tasks, such as producing speec h sounds, learning how to group different sounds into a consistent and manageable n umber of classes or speech units, grounding speech, and recognizing the speech sounds when uttered by other persons. While it is not known to which extent those abil ities are learned or written in our genetic code, this work aims at two intertwine d goals: (i) to investigate how much of linguistic structure that can be derived directl y from the speech signal directed to infants by (ii) designing, building and testing biological plausible models for language acquisition in a humanoid robot. We have theref ore chosen to avoid implementing any pre-programmed linguistic knowledge, su ch as phonemes, into these models. Instead we rely on general methods such as patt ern matching and hierarchical clustering techniques, and show that it is pos sible to acquire important linguistic structures directly from the speech signal thro ugh the interaction with a caregiver. We also show that this process can be facilitated hrough the use of motor learning. The interaction between an adult caregiver and a human infan t is very different from the interaction between two adults. Speech directed to infants is highly structured and characterized by what seems like physically motiv ated tricks to maintain the communicative connection to the infant, actions th at at the same time also may enhance linguistically relevant important aspects of t he signal. Also, whereas	bus mastering;cluster analysis;hierarchical clustering;humanoid robot;information systems research;lex (software);multimodal interaction;olami–feder–christensen model;sensor;ws-coordination	Jonas Hörnstein;Lisa Gustavsson;José Santos-Victor;Francisco Lacerda	2010		10.1007/978-3-642-05181-4_20	natural language processing;robot learning;speech recognition;computer science;communication	ML	-6.601135139391119	-78.83365910661209	58186
2ff156ecd40e65b61cf10323ec1d11daac88530a	technicolor/inria team at the mediaeval 2013 violent scenes detection task		This paper presents the work done at Technicolor and INRIA regarding the MediaEval 2013 Violent Scenes Detection task, which aims at detecting violent scenes in movies. We participated in both the objective and the subjective subtasks.	sensor	Cédric Penet;Claire-Hélène Demarty;Guillaume Gravier;Patrick Gros	2013			computer vision;simulation;optics;physics	AI	-7.357393125909471	-69.30896835802466	58304
a5e92a90bb56bb07722633fdd5412d2bc046875c	musical expression generation reflecting user's impression by kansei space and fuzzy rules	musical expression;kansei space;fuzzy inference;impression;adjective			Mio Suzuki;Takehisa Onisawa	2012	JACIII	10.20965/jaciii.2012.p0227	artificial intelligence;multimedia	HCI	-15.552758946296278	-79.9439372909421	58371
c795c035d563231782711f931e264e629c52de44	attention-based convolutional neural network for semantic relation extraction		Nowadays, neural networks play an important role in the task of relation classification. In this paper, we propose a novel attention-based convolutional neural network architecture for this task. Our model makes full use of word embedding, part-of-speech tag embedding and position embedding information. Word level attention mechanism is able to better determine which parts of the sentence are most influential with respect to the two entities of interest. This architecture enables learning some important features from task-specific labeled data, forgoing the need for external knowledge such as explicit dependency structures. Experiments on the SemEval-2010 Task 8 benchmark dataset show that our model achieves better performances than several stateof-the-art neural network models and can achieve a competitive performance just with minimal feature engineering.	artificial neural network;asch conformity experiments;benchmark (computing);convolutional neural network;end-to-end principle;entity;feature engineering;feature extraction;network architecture;ontology components;part-of-speech tagging;performance;relationship extraction;semeval;word embedding	Yatian Shen;Xuanjing Huang	2016			artificial intelligence;convolutional neural network;natural language processing;deep learning;time delay neural network;relationship extraction;pattern recognition;computer science;machine learning	NLP	-18.45028090202445	-71.67255235005946	58490
388169738137b1698a24c34f89c0d6d69ad15ea0	a probabilistic computational model of cross-situational word learning	cognitive ability;learning;cross situational learning;building block;young children;computer model;lenguaje;hombre;langage;proceso adquisicion;acquisition process;enfant;aprendizaje;probabilistic model;apprentissage;child language acqusition;computational modeling;nino;lexical acquisition;cognition;human;modele simulation;palabra;modele probabiliste;child;cognicion;word learning;word;language learning;modelo simulacion;language;simulation model;processus acquisition;mot;homme;modelo probabilista	Words are the essence of communication: They are the building blocks of any language. Learning the meaning of words is thus one of the most important aspects of language acquisition: Children must first learn words before they can combine them into complex utterances. Many theories have been developed to explain the impressive efficiency of young children in acquiring the vocabulary of their language, as well as the developmental patterns observed in the course of lexical acquisition. A major source of disagreement among the different theories is whether children are equipped with special mechanisms and biases for word learning, or their general cognitive abilities are adequate for the task. We present a novel computational model of early word learning to shed light on the mechanisms that might be at work in this process. The model learns word meanings as probabilistic associations between words and semantic elements, using an incremental and probabilistic learning mechanism, and drawing only on general cognitive abilities. The results presented here demonstrate that much about word meanings can be learned from naturally occurring child-directed utterances (paired with meaning representations), without using any special biases or constraints, and without any explicit developmental changes in the underlying learning mechanism. Furthermore, our model provides explanations for the occasionally contradictory child experimental data, and offers predictions for the behavior of young word learners in novel situations.	cognition;computation;computational model;increment;language disorders;learning disorders;mental association;theory;vocabulary;explanation	Afsaneh Fazly;Afra Alishahi;Suzanne Stevenson	2010	Cognitive science	10.1111/j.1551-6709.2010.01104.x	psychology;computer simulation;cognitive psychology;natural language processing;cognition;computer science;linguistics;communication;cognitive science	ML	-10.648709144818907	-76.15647164498007	58513
7719679e6255c51d157116fcfbc858b7e7dfdb59	coreference resolution in a modular, entity-centered model	semantic representation;generic model;levels of abstraction;coreference resolution	Coreference resolution is governed by syntactic, semantic, and discourse constraints. We present a generative, model-based approach in which each of these factors is modularly encapsulated and learned in a primarily unsupervised manner. Our semantic representation first hypothesizes an underlying set of latent entity types, which generate specific entities that in turn render individual mentions. By sharing lexical statistics at the level of abstract entity types, our model is able to substantially reduce semantic compatibility errors, resulting in the best results to date on the complete end-to-end coreference task.	end-to-end encryption;entity;generative model;lexicon	Aria Haghighi;Dan Klein	2010			natural language processing;computer science;data mining	NLP	-18.266948820216236	-73.46051828882939	58568
098dd914adccc3b1351af161c62d80b56487e139	early embedding and late reranking for video captioning	sentence reranking;tag embedding;universiteitsbibliotheek;msr video to language challenge	This paper describes our solution for the MSR Video to Language Challenge. We start from the popular ConvNet + LSTM model, which we extend with two novel modules. One is early embedding, which enriches the current low-level input to LSTM by tag embeddings. The other is late reranking, for re-scoring generated sentences in terms of their relevance to a specific video. The modules are inspired by recent works on image captioning, repurposed and redesigned for video. As experiments on the MSR-VTT validation set show, the joint use of these two modules add a clear improvement over a non-trivial ConvNet + LSTM baseline under four performance metrics. The viability of the proposed solution is further confirmed by the blind test by the organizers. Our system is ranked at the 4th place in terms of overall performance, while scoring the best CIDEr-D, which measures the human-likeness of generated captions.	baseline (configuration management);convolutional neural network;experiment;high- and low-level;long short-term memory;relevance	Jianfeng Dong;Xirong Li;Weiyu Lan;Yujia Huo;Cees Snoek	2016		10.1145/2964284.2984064	speech recognition;computer science;world wide web	NLP	-16.430867708738727	-70.51293868909119	58571
52da6e41b069221e03822b8839a2a77e88666e53	uts submission to google youtube-8m challenge 2017		In this paper, we present our solution to Google YouTube-8M Video Classification Challenge 2017. We leveraged both video-level and frame-level features in the submission. For video-level classification, we simply used a 200-mixture Mixture of Experts (MoE) layer, which achieves GAP 0.802 on the validation set with a single model. For frame-level classification, we utilized several variants of recurrent neural networks, sequence aggregation with attention mechanism and 1D convolutional models. We achieved GAP 0.8408 on the private testing set with the ensemble model. The source code of our models can be found in https://github.com/ffmpbgrnn/yt8m.	artificial neural network;multiscale modeling;recurrent neural network;signal-to-noise ratio;uts	Linchao Zhu;Yanbin Liu;Yi Yang	2017	CoRR		artificial intelligence;machine learning;mixture of experts;computer science;data mining;source code;ensemble forecasting;recurrent neural network	ML	-16.385166294752914	-70.53360909947695	58786
bc80d702c6b7bb8f7990ee2e82cc4f01a25ae539	approximate computing for long short term memory (lstm) neural networks		Long Short Term Memory (LSTM) networks are a class of recurrent neural networks that are widely used for machine learning tasks involving sequences, including machine translation, text generation, and speech recognition. Large-scale LSTMs, which are deployed in many real-world applications, are highly compute intensive. To address this challenge, we propose AxLSTM, an application of approximate computing to improve the execution efficiency of LSTMs. An LSTM is composed of cells, each of which contains a cell state along with multiple gating units that control the addition and removal of information from the state. The LSTM execution proceeds in timesteps, with a new symbol of the input sequence processed at each timestep. AxLSTM consists of two techniques—Dynamic Timestep Skipping (DTS) and Dynamic State Reduction (DSR). DTS identifies, at runtime, input symbols that are likely to have little or no impact on the cell state and skips evaluating the corresponding timesteps. In contrast, DSR reduces the size of the cell state in accordance with the complexity of the input sequence, leading to a reduced number of computations per timestep. We describe how AxLSTM can be applied to the most common application of LSTMs, viz., sequence-to-sequence learning. We implement AxLSTM within the TensorFlow deep learning framework and evaluate it on 3 state-of-the-art sequence-to-sequence models. On a 2.7 GHz Intel Xeon server with 128 GB memory and 32 processor cores, AxLSTM achieves  $ {1.08\times -1.31 \times }$  speedups with minimal loss in quality, and  $ {1.12 \times -1.37 \times }$  speedups when moderate reductions in quality are acceptable.	ansi escape code;approximate computing;computation;deep learning;long short-term memory;machine learning;machine translation;natural language generation;neural networks;recurrent neural network;run time (program lifecycle phase);server (computing);speech recognition;tensorflow;viz: the computer game	Sanchari Sen;Anand Raghunathan	2018	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2018.2858362	computer science;real-time computing;artificial neural network;xeon;deep learning;multi-core processor;computation;logic gate;recurrent neural network;artificial intelligence;approximate computing	ML	-15.72194527901877	-76.88263008684572	59004
09743d8dea5b5ef5545f5627d8994c84e9199f46	utterance-initial elements in japanese: a comparison among fillers, conjunctions, and topic phrases		Speakers need to plan the following part of speech under the pressure of a temporal imperative at utterance-initial positions. Each language seems to have some devices to solve this problem, which we callutterance-initial elements(UIEs). We investigated effects of two factors, boundary strengths and complexity of the following constituents, on the durations of possible UIEs, such as fillers, conjunctions, and topic phrases. We found that the last mora of filler e, as well aswa-marked topic phrases, became longer as the complexity increased in certain conditions. Possible interpretations for the results are discussed.	imperative programming;star filler	Michiko Watanabe;Yasuharu Den	2010			speech recognition;computer science;linguistics;communication	NLP	-12.133806200364408	-79.78715664975621	59188
5ca428ead22e14b310c592846d04ab3e9a03b979	a state-transition framework to answer complex questions over knowledge base		Although natural language question answering over knowledge graphs have been studied in the literature, existing methods have some limitations in answering complex questions. To address that, in this paper, we propose a State Transition-based approach to translate a complex natural language question N to a semantic query graph (SQG) Q , which is used to match the underlying knowledge graph to find the answers to question N . In order to generate Q , we propose four primitive operations (expand, fold, connect and merge) and a learning-based state transition approach. Extensive experiments on several benchmarks (such as QALD, WebQuestions and ComplexQuestions) with two knowledge bases (DBpedia and Freebase) confirm the superiority of our approach compared with stateof-the-arts.		Sen Hu;Lei Zou;Xinbo Zhang	2018			natural language processing;artificial intelligence;computer science;knowledge base	NLP	-16.360198085784596	-67.01206323858568	59653
2a0dc32b329c9dc9c9e0b7e9e378edef79718da5	remembering a conversation - a conversational memory architecture for embodied conversational agents	episodic memory;embodied conversational agents;chatterbots;conversational agents;conversational memory;chatbots;episodic memory architecture		embodied agent	Miguel Elvir;Avelino J. Gonzalez;Christopher Walls;Bryan Wilder	2017	J. Intelligent Systems	10.1515/jisys-2015-0094	cognitive psychology;natural language processing;communication	NLP	-8.488005343869373	-78.743927405421	59811
40b5cff2407eaf53ba173d516024503a17a543ad	qualitative modeling of spatial prepositions and motion expressions	motion verb;information retrieval;spatial description;compositional semantics;spatial primitive;motion expression;spatial relation;spatial preposition;qualitative modeling;natural language;enhanced information extraction	The ability to understand spatial prepositions and motion in natural language will enable a variety of new applications involving systems that can respond to verbal directions, map travel guides, display incident reports, etc., providing for enhanced information extraction, question-answering, information retrieval, and more principled text to scene rendering. Until now, however, the semantics of spatial relations and motion verbs has been highly problematic. This tutorial presents a new approach to the semantics of spatial descriptions and motion expressions based on linguistically interpreted qualitative reasoning. Our approach allows for formal inference from spatial descriptions in natural language, while leveraging annotation schemes for time, space, and motion, along with machine learning from annotated corpora. We introduce a compositional semantics for motion expressions that integrates spatial primitives drawn from qualitative calculi. No previous exposure to the semantics of spatial prepositions or motion verbs is assumed. The tutorial will sharpen cross-linguistic intuitions about the interpretation of spatial prepositions and motion constructions. The attendees will also learn about qualitative reasoning schemes for static and dynamic spatial information, as well as three annotation schemes: TimeML, SpatialML, and ISO-Space, for time, space, and motion, respectively. While both cognitive and formal linguistics have examined the meaning of motion verbs and spatial prepositions, these earlier approaches do not yield precise computable representations that are expressive enough for natural languages. However, the previous literature makes it clear that communication of motion relies on imprecise and highly abstract geometric descriptions, rather than Euclidean ones that specify the coordinates and shapes of every object. This property makes these expressions a fit target for the field of qualitative spatial reasoning in AI, which has developed a rich set of geometric primitives for representing time, space (including distance, orientation, and topological relations), and motion. The results of such research have yielded a wide variety of spatial and temporal reasoning logics and tools. By reviewing these calculi and resources, this tutorial aims to systematically connect qualitative reasoning to natural language. Tutorial Schedule:	computable function;euclidean distance;formal grammar;information extraction;information retrieval;machine learning;natural language;question answering;regular expression;spatial–temporal reasoning;text corpus;timeml	Inderjeet Mani;James Pustejovsky	2012			natural language processing;computer vision;computer science	AI	-8.182047152143923	-75.33542240733414	60032
bef5ea4e13e9e22de3cdf716aed3947123e799ad	using semantic maps for robust natural language interaction with robots	settore ing inf 05 sistemi di elaborazione delle informazioni	Modern robotic architectures are equipped with sensors enabling a deep analysis of the environment. In this work, we aim at demonstrating that such perceptual information (here modeled through semantic maps) can be effectively used to enhance the language understanding capabilities of the robot. A robust lexical mapping function based on the Distributional Semantics paradigm is here proposed as a basic model of grounding language towards the environment. We show that making such information available to the underlying language understanding algorithms improves the accuracy throughout the entire interpretation process.	algorithm;distributional semantics;map;natural language understanding;programming paradigm;robot;semantic mapper;sensor	Emanuele Bastianelli;Danilo Croce;Roberto Basili;Daniele Nardi	2015			natural language processing;speech recognition;computer science;artificial intelligence;machine learning;linguistics	Robotics	-14.45381252376043	-68.44162787925781	60788
735b908b669f8e1433d4b80d9dd94ac3c2a6a56e	arbitrary category labels can change similarity judgments of human faces	social and behavioral sciences	In two experiments, participants were presented with a triad of morphed White and Hispanic faces paired with pseudoword labels. The meanings of these labels were manipulated to represent categorical information about the face. Labels were said to represent either the person’s belief, the food s/he ate, the disease s/he had, or the person’s last name. The results indicated that categorical information affects our judgments of faces. Information categories such as belief, food, and diseases were particularly strong in modifying the participants’ similarity judgment of faces, whereas information characterized with last names of faces were least powerful. Previous research focuses on race face perception being affected primarily by racial indicators or racial information. Our results provide that how we perceptually analyze faces is not confined to obvious racial cues, but by non-racial semantic information as well, suggesting that category-relevant information by itself provides a strong basis for inductive generalization.	experiment;face perception	Frankie Lara;Amanda C Hahn;Na-Yung Yu;Takashi Yamauchi	2012			psychology;cognitive psychology;communication;social psychology	AI	-7.630884166554276	-76.67732448401019	61019
386e0cfc82bb2b790df5f316f0ad0a7deda95b74	learning to generate structured queries from natural language with indirect supervision		Generating structured query language (SQL) from natural language is an emerging research topic. This paper presents a new learning paradigm from indirect supervision of the answers to natural language questions, instead of SQL queries. This paradigm facilitates the acquisition of training data due to the abundant resources of question-answer pairs for various domains in the Internet, and expels the difficult SQL annotation job. An endto-end neural model integrating with reinforcement learning is proposed to learn SQL generation policy within the answerdriven learning paradigm. The model is evaluated on datasets of different domains, including movie and academic publication. Experimental results show that our model outperforms the baseline models.	baseline (configuration management);comparator;internet;natural language;programming paradigm;query language;reinforcement learning;sql;structured prediction	Ziwei Bai;Bo Yu;Bowen Wu;Zhuoran Wang;Baoxun Wang	2018	CoRR		natural language processing;machine learning;the internet;reinforcement learning;sql;natural language;artificial intelligence;computer science;training set;annotation	NLP	-18.017708819749902	-67.60223739063997	61383
7e563d13eed1e2eb448e52a499c3a3589bf9e133	"""framenet as a """"net"""""""		While FrameNet does not record the range of semantic relations found in thesaurus-style lexical resources like WordNet, it does provide a number of ways in which lexical units (LUs) can be seen as related to each other. This paper characterizes and motivates the networks of frame-to-frame relations that are being built on FrameNet’s frames, and introduces additional representational mechanisms needed for showing similarities among LUs that are independent of frame membership. LU-to-LU relationships are shown by shared membership in a single frame, by membership in frames that are themselves related to each other, and by shared semantic type information.	framenet;thesaurus;wordnet	Charles J. Fillmore;Collin F. Baker;Hiroaki Sato	2004			natural language processing;artificial intelligence;computer science;wordnet;framenet	AI	-18.36666418164531	-72.70943972474059	61432
c34eb32c0d5ba67ec2afb810209213e73013c477	towards an intonation module for a portuguese tts system.		In this paper, a correlation between the linguistic structure of the written text and the real intonation behavior of the read speech in European Portuguese language (EP) is presented. It is our belief that intonation behavior in EP can be strongly predicted from two main coordinates: the syntactic structure of the sentence and its pragmatic communicative function, in one way, combined with the phonological and syntactic nature of the words, in the other way. The purpose of our work is to identify in real speech the main intonation elements, which are relevant to speech naturalness as well as to analyze the factors that determine them. This work addresses the cases of declarative/imperative, interrogative and enumerative phrases. Basic categorizations of the intonation elements, in correlation with the underlying factors are presented. General regularities and correlations as well as the resulting rules, that may be a starting point for practical implementation of an intonation module, are presented and demonstrated, under a Fujisaki’s phonetic/physiological approach. The methodology was based on the observation and modeling of a significant prosodic corpus where different intonation patterns occur in a diversity of text structures. It is our goal to contribute with practical techniques and experience in order to perform a more accurate intonation modeling of Text-to-Speech (TTS) applications, using a rule-based approach.	categorization;expectation propagation;imperative programming;logic programming;netware file system;speech synthesis	Diamantino Freitas;Daniela Braga	2002			speech recognition;computer science;portuguese	NLP	-11.830609499791157	-79.59319414364961	61927
a49cf860731e4d2a1850634fe5666da95911844c	the data retrieval optimization from the perspective of evidence-based medicine	databases;drugs;support vector machines;training;medycyna;testing;biology;data analysis;analiza danych;medicine;entropy	The paper is devoted to classification of MEDLINE abstracts into categories that correspond to types of medical interventions - types of patient treatments. This set of categories was extracted from Clinicaltrials.gov web site. Few classification algorithms were tested includingMultinomial Naive Bayes, Multinomial Logistic Regression, and Linear SVM implementations from sklearn machine learning library. Document marking was based on the consideration of abstracts containing links to the Clinicaltrials.gov Web site. As the result of an automatical marking 3534 abstracts were marked for training and testing the set of algorithms metioned above. Best result of multinomial classification was achieved by Linear SVM with macro evaluation precision 70.06%, recall 55.62% and F-measure 62.01%, and micro evaluation precision 64.91%, recall 79.13% and F-measure 71.32%.	algorithm;computation;data retrieval;experiment;f1 score;item unique identification;linear programming;medline;machine learning;mathematical optimization;multinomial logistic regression;naive bayes classifier;nonlinear system	Vladimir Dobrynin;Julia Balykina;Michael Kamalov;Alexey Kolbin;Elena Verbitskaya;Munira Kasimova	2015	2015 Federated Conference on Computer Science and Information Systems (FedCSIS)	10.15439/2015F130	support vector machine;entropy;computer science;artificial intelligence;data science;machine learning;pattern recognition;data mining;database;software testing;data analysis;algorithm;statistics	Web+IR	-4.931009598281578	-68.40142632866848	62037
57279c03ea1ec89b4c99a608c703620e46858e50	integrating bidirectional lstm with inception for text classification		A novel neural network architecture, BLSTM-Inception v1, is proposed for text classification. It mainly consists of the BLSTM-Inception module, which has two parts, and a global max pooling layer. In the first part, forward and backward sequences of hidden states of BLSTM are concatenated as double channels, rather than added as single channel. The second part contains parallel asymmetric convolutions of different scales to extract nonlinear features of multi-granular n-gram phrases from double channels. The global max pooling is used to convert variable-length text into a fixed-length vector. The proposed architecture achieves excellent results on four text classification tasks, including sentiment classifications, subjectivity classification, and especially improves nearly 1.5% on sentence polarity dataset from Pang and Lee compared to BLSTM-2DCNN.		Wei Jiang;Zhong Jin	2017	2017 4th IAPR Asian Conference on Pattern Recognition (ACPR)	10.1109/ACPR.2017.113	architecture;task analysis;artificial neural network;pooling;feature extraction;concatenation;communication channel;artificial intelligence;pattern recognition;sentence;computer science	ML	-18.34120416170595	-72.00589306662863	62623
13f3045805cbd0a58f3abf6c9ad52515d6c10aeb	comics on the brain: structure and meaning in sequential image comprehension		Just as syntax differentiates coherent sentences from scrambled word strings, sequential images must also use a cognitive system to distinguish coherent narratives from random strings of images. We conducted experiments analogous to two classic psycholinguistic studies to examine structure and semantics in sequential images. We compared Normal comic strips with both structure and meaning to sequences with Semantics Only, Structure Only, or randomly Scrambled panels. Experiment 1 used a target-monitoring paradigm, and found that RTs were slowest to target panels in Scrambled sequences, intermediate in Structural Only and Semantic Only sequences, and fastest in Normal sequences. Experiment 2 measured ERPs to the same strips. The largest N400 appeared in Scrambled and Structural Only sequences, intermediate in Semantic Only sequences and smallest in Normal sequences. Together, these findings suggest that sequential image comprehension is guided by an interaction between a structure and meaning, broadly analogous to syntax and semantics in language.	artificial intelligence;coherence (physics);enterprise resource planning;experiment;fastest;list comprehension;programming paradigm;randomness;strips	Neil Cohn;Martin Paczynski;Phillip J. Holcomb;Ray Jackendoff;Gina R. Kuperberg	2011			semantic field;generative grammar;cognitive science;comics;cognitive psychology;syntax;linguistics;psychology;semantics;narrative;comprehension;sentence	AI	-8.660050384173966	-77.20370219129154	62676
56d8ae3740c8b9ef35e259dea786859c022d76bb	learning diphone-based segmentation	unsupervised learning;learning;habla;lenguaje;hombre;speech;langage;theoreme bayes;segmentation;infant;proceso adquisicion;acquisition process;desarrollo verbal;verbal perception;aprendizaje;bayesian;language acquisition;word segmentation;apprentissage;percepcion verbal;cognition;language development;human;modele simulation;palabra;developpement verbal;cognicion;word;parole;modelo simulacion;language;nourrisson;computational model;simulation model;lactante;segmentacion;processus acquisition;mot;homme;perception verbale	This paper reconsiders the diphone-based word segmentation model of Cairns, Shillcock, Chater, and Levy (1997) and Hockema (2006), previously thought to be unlearnable. A statistically principled learning model is developed using Bayes' theorem and reasonable assumptions about infants' implicit knowledge. The ability to recover phrase-medial word boundaries is tested using phonetic corpora derived from spontaneous interactions with children and adults. The (unsupervised and semi-supervised) learning models are shown to exhibit several crucial properties. First, only a small amount of language exposure is required to achieve the model's ceiling performance, equivalent to between 1 day and 1 month of caregiver input. Second, the models are robust to variation, both in the free parameter and the input representation. Finally, both the learning and baseline models exhibit undersegmentation, argued to have significant ramifications for speech processing as a whole.	baseline (configuration management);interaction;medial graph;population parameter;semi-supervised learning;semiconductor industry;speech processing;spontaneous order;text corpus;text segmentation;unsupervised learning;biologic segmentation	Robert Daland;Janet B. Pierrehumbert	2011	Cognitive science	10.1111/j.1551-6709.2010.01160.x	psychology;language acquisition;unsupervised learning;text segmentation;speech recognition;cognition;developmental psychology;bayesian probability;computer science;speech;simulation modeling;word;linguistics;language;communication;computational model;segmentation	NLP	-10.827052411495764	-76.92600882008632	63290
238e1028511dca1798ec0bd75ff6678e866dcf93	the effect of left-hand gestures on metaphor explanation		Research suggests that gestures influence cognitive processes, but the exact mechanism is not clear. Additionally, it has been shown that when a linguistic task (metaphor explanation) involves the right brain hemisphere, the left hand becomes more gesturally active. We hypothesized that gestures with a particular hand activate cognitive processes in the contralateral hemisphere. We examined whether gestures with the left hand enhance metaphoricity in verbal responses. Results showed participants produced more metaphoric explanations when instructed to produce gestures with their left hand as compared to the right hand or not gesture at all. In addition, we measured the mouth asymmetry during metaphorical speech to determine individual differences in righthemisphere involvement in metaphor processing. The leftside mouth dominance, indicating stronger right-hemisphere involvement, positively correlated with the left-hand-overright-hand advantage in gestural facilitation of metaphorical speech. We concluded that left-hand gestures enhance metaphorical thinking in the right hemisphere.		Paraskevi Argyriou;Sotaro Kita	2013			cognitive science;psychology;conceptualization;lateralization of brain function;cognitive psychology;literal and figurative language;metaphor;cognition;mental image;speech production;gesture	HCI	-7.800190754902082	-79.05891339334379	63310
09ccba4404669089bbcc9ffd361e2d72794a494a	learning latent personas of film characters		We present two latent variable models for learning character types, or personas, in film, in which a persona is defined as a set of mixtures over latent lexical classes. These lexical classes capture the stereotypical actions of which a character is the agent and patient, as well as attributes by which they are described. As the first attempt to solve this problem explicitly, we also present a new dataset for the text-driven analysis of film, along with a benchmark testbed to help drive future work in this area.	benchmark (computing);character encoding;curve fitting;framing (world wide web);latent variable;null character;persona (user experience);personalization;real life;testbed	David Bamman;Brendan T. O'Connor;Noah A. Smith	2013			natural language processing;simulation;computer science;artificial intelligence;machine learning	NLP	-13.725041843449977	-71.36054420509949	63738
870749ba074e98494e9e8aecda45ed60d9c56a55	semantic underspecification in language processing	language processing	Abstract#R##N##R##N#It is commonly assumed that when we encounter a word in a text, we automatically and immediately activate specific, detailed semantic information associated with that word and instantly integrate this information in the unfolding interpretation of the text. On-line evidence of how we process polysemous words, that is, words with multiple semantically related interpretations or senses, suggests that instead of accessing a specific sense, language users initially activate a word's meaning that is semantically underspecified. Context can then help to make this meaning more specific, if there is a need for it. I will present an overview of the available evidence for this view, including new work that indicates that the type of task can influence how quickly we home-in on a specific sense, address evidence that, at first sight, seems to contradict the underspecification view, and outline a number of issues that require further attention.		Steven Frisson	2009	Language and Linguistics Compass	10.1111/j.1749-818X.2008.00104.x	psychology;natural language processing;computer science;linguistics;sociology;communication	NLP	-9.149543717064143	-76.64123945201514	63820
aabb7da370f1c6fabad6125ef3ba5d2481ada7cc	cross-modal common representation learning by hybrid transfer network		DNN-based cross-modal retrieval is a research hotspot to retrieve across different modalities as image and text, but existing methods often face the challenge of insufficient cross-modal training data. In single-modal scenario, similar problem is usually relieved by transferring knowledge from largescale auxiliary datasets (as ImageNet). Knowledge from such single-modal datasets is also very useful for cross-modal retrieval, which can provide rich general semantic information that can be shared across different modalities. However, it is challenging to transfer useful knowledge from single-modal (as image) source domain to cross-modal (as image/text) target domain. Knowledge in source domain cannot be directly transferred to both two different modalities in target domain, and the inherent cross-modal correlation contained in target domain provides key hints for cross-modal retrieval which should be preserved during transfer process. This paper proposes Cross-modal Hybrid Transfer Network (CHTN) with two subnetworks: Modalsharing transfer subnetwork utilizes the modality in both source and target domains as a bridge, for transferring knowledge to both two modalities simultaneously; Layer-sharing correlation subnetwork preserves the inherent cross-modal semantic correlation to further adapt to cross-modal retrieval task. Cross-modal data can be converted to common representation by CHTN for retrieval, and comprehensive experiments on 3 datasets show its effectiveness.		Xin Huang;Yuxin Peng;Mingkuan Yuan	2017		10.24963/ijcai.2017/263	artificial intelligence;modalities;machine learning;computer science;hotspot (wi-fi);subnetwork;training set;feature learning	AI	-14.95838514947019	-68.73143811360632	63973
31e59e6c365f0cb9293336fd039045b126011c34	the acquisition of verb morphology in polish and finnish: model and experiment		Usage-based approaches suggest that language acquisition is a function of the statistical properties of the input. We compare predictions from neural network models with results of two elicited-production experiments on verb inflection with children in the morphologically complex languages Polish and Finnish. Three-layer neural networks were trained to produce person/number-inflected present-tense verb forms in Polish and Finnish from phoneme representations of verb stems using frequency information from child-directed speech corpora. Simulated acquisition in both languages was affected by token frequency and phonological neighbourhood density (PND) as well as an interaction such that low-frequency forms benefited more from PND than high-frequency forms. Suffix errors showed overgeneralisation and substitutions of low-frequency forms with higher-frequency forms. The model predictions are consistent with our empirical findings, except for the frequency X PND interaction. We discuss the experimental and simulated data and their implications.	artificial neural network;experiment;galaxy morphological classification;multitier architecture;text corpus	Felix Engelmann;Joanna Kolak;Sonia Granlund;Ben Ambridge;Julian M. Pine;Anna L. Theakston;Elena Lieven	2017			morphology (linguistics);cognitive psychology;psychology;verb	NLP	-12.230754274242939	-79.39917974261122	64192
9e76177793703eb7bb310b483ae7a077d4cd953d	thinking like psychologist: learning to predict personality by using features from portrait and social media	personality prediction;psychology;portrait image;social media	It is interesting but challenging to infer people's personality from multimedia data. This paper resolving this problem by jointly considered both human appearances from portrait image and behavior representative data from social media, where features are designed and selected separately inspired by psychology theory. Best features are selected for four personality categories respectively depending on classification performance. Experiment demonstrated that: by adding social media features, our method achieves an average improvement of 24.95% in true positive rate than the state of the art. Meanwhile, by introducing features inspired by psychology theory, our portrait features outperformed the baseline method by increasing 11.69% in true positive rate.	baseline (configuration management);sensitivity and specificity;social media;statistical classification	Jie Nie;Lei Huang;Zhen Li;Chenxi Wei;Bowei Hong;Wenwu Zhu	2016	2016 4th International Conference on Cloud Computing and Intelligence Systems (CCIS)	10.1109/CCIS.2016.7790218	social media;computer science	Robotics	-12.318053353230864	-70.09067781484686	64578
0dc054f65e4e62b3777a4edcaed67b3c6d0185ed	methodology for designing reasonably expressive mechanisms with application to ad auctions	expected gain;brand advertiser;expressive variant;ad auction;custom tree search technique;efficiency loss;search mechanism;expressive mechanism;greater level;economic efficiency;different form;extra bid	We introduce a new kernel for Support Vector Machine learning in a natural language setting. As a case study to incorporate domain knowledge into a kernel, we consider the problem of resolving Prepositional Phrase attachment ambiguities. The new kernel is derived from a distance function that proved to be succesful in memory-based learning. We start with the Simple Overlap Metric from which we derive a Simple Overlap Kernel and extend it with Information Gain Weighting. Finally, we combine it with a polynomial kernel to increase the dimensionality of the feature space. The closure properties of kernels guarantee that the result is again a kernel. This kernel achieves high classification accuracy and is efficient in both time and space usage. We compare our results with those obtained by memory-based and other learning methods. They make clear that the proposed kernel achieves a higher classification accuracy.	attachments;experiment;feature vector;information gain in decision trees;instance-based learning;kernel (operating system);kullback–leibler divergence;machine learning;named-entity recognition;natural language;overlap–add method;polynomial kernel;space–time tradeoff;support vector machine	Michael Benisch;Norman M. Sadeh;Tuomas Sandholm	2003			artificial intelligence	AI	-17.490846583973468	-69.18272165351091	64748
3b880dc00b3b8c1fd99c254593103a647b8fde75	semantic relation extraction based on semi-supervised learning	unlabeled data;multi view learning;information extraction;semi supervised learning;relation extraction;semantic relations;natural language processing	Many tasks of information extraction or natural language processing have a property that the data naturally consist of several views—disjoint subsets of features. Specifically, a semantic relationship can be represented with some entity pairs or contexts surrounding the entity pairs. For example, the PersonBirthplace relation can be recognized from the entity pair view, such as (Albert Einstein, Ulm), (Pablo Picasso, Malaga) and so on. On the other side, this relation can be identified with some contexts, such as “A was born in B”, “B, the birth place of A” and so on. To leverage the unlabeled data in the training stage, semi-supervised learning has been applied to relation extraction task. In this paper, we propose a multiview semi-supervised learning algorithm, Co-Label Propagation, to combine the ‘information’ from both the entity pair view and the context view. In propagation process, the label scores of classes are spread not only in the entity pair view and the context view, but also between the two views. The proposed algorithm is evaluated using semantic relation classification tasks. The experiment results validate its effectiveness.	cluster hypothesis;information extraction;label propagation algorithm;natural language processing;ontology components;relationship extraction;semi-supervised learning;semiconductor industry;software propagation;supervised learning	Haibo Li;Yutaka Matsuo;Mitsuru Ishizuka	2010		10.1007/978-3-642-17187-1_26	semi-supervised learning;natural language processing;unsupervised learning;relationship extraction;semantic computing;computer science;machine learning;pattern recognition;information extraction	NLP	-16.957106887821762	-66.44487970816252	64791
fc9e8aae33bbd88b68917cb89690a66d98f565ae	optical character recognition system for nepali language using convnet		This paper describes the implementation of CNN (Convolution Neural Network) based Optical Character Recognition System for Nepali Language, a commonly spoken language in Nepal. The system has been developed in python using Keras[1] library on top of Theano[2] and numpy[3]. The system has been trained using a set of real world[4] and synthesized data sets considering various noise conditions. The tests have also been carried out in a similar setup. This paper details the experiment by discussing the concept, implementation details and overall interpretation of the system.	artificial neural network;convolution;convolutional neural network;optical character recognition;python	Manish K. Sharma;Bidhan Bhattarai	2017		10.1145/3055635.3056635	artificial intelligence;machine learning;convolutional neural network;optical character recognition;deep learning;python (programming language);computer science;theano;spoken language;text segmentation;speech recognition;numpy	AI	-16.73479795322258	-77.06652403853047	65445
6ed38b0cb510fa91434eb63ab464bee66c9323c6	a multilayer convolutional encoder-decoder neural network for grammatical error correction		We improve automatic correction of grammatical, orthographic, and collocation errors in text using a multilayer convolutional encoder-decoder neural network. The network is initialized with embeddings that make use of character Ngram information to better suit this task. When evaluated on common benchmark test data sets (CoNLL-2014 and JFLEG), our model substantially outperforms all prior neural approaches on this task as well as strong statistical machine translation-based systems with neural and task-specific features trained on the same data. Our analysis shows the superiority of convolutional neural networks over recurrent neural networks such as long short-term memory (LSTM) networks in capturing the local context via attention, and thereby improving the coverage in correcting grammatical errors. By ensembling multiple models, and incorporating an N-gram language model and edit features via rescoring, our novel method becomes the first neural approach to outperform the current state-of-the-art statistical machine translation-based approach, both in terms of grammaticality and fluency.	artificial neural network;benchmark (computing);collocation;convolutional code;convolutional neural network;encoder;error detection and correction;feedback;language model;long short-term memory;n-gram;orthographic projection;recurrent neural network;statistical machine translation;test data;text corpus;tier 2 network	Shamil Chollampatt;Hwee Tou Ng	2018			convolutional neural network;machine translation;computer science;machine learning;error detection and correction;artificial intelligence;encoder;artificial neural network;grammaticality;language model;recurrent neural network	AI	-17.956765241846025	-74.46290708718324	65675
d8b851d9863779d1a971173df7c91b4a6f179ba6	cross-situational learning of minimal word pairs	oral language;consonants;associative learning;learning processes;phonologically minimal pairs;statistical learning;phonology;vocabulary development;statistics;word learning;cognitive processes;cross situational statistical learning;vowels;phonemes	Cross-situational statistical learning of words involves tracking co-occurrences of auditory words and objects across time to infer word-referent mappings. Previous research has demonstrated that learners can infer referents across sets of very phonologically distinct words (e.g., WUG, DAX), but it remains unknown whether learners can encode fine phonological differences during cross-situational statistical learning. This study examined learners' cross-situational statistical learning of minimal pairs that differed on one consonant segment (e.g., BON-TON), minimal pairs that differed on one vowel segment (e.g., DEET-DIT), and non-minimal pairs that differed on two or three segments (e.g., BON-DEET). Learners performed above chance for all pairs, but performed worse on vowel minimal pairs than on consonant minimal pairs or non-minimal pairs. These findings demonstrate that learners can encode fine phonetic detail while tracking word-referent co-occurrence probabilities, but they suggest that phonological encoding may be weaker for vowels than for consonants.	bisphosphonate-associated osteonecrosis;directory information tree;encode;inference;machine learning;physical object;probability;recurrent word;diethyltoluamide;vowels	Paola Escudero;Karen E. Mulak;Haley A. Vlach	2016	Cognitive science	10.1111/cogs.12243	psychology;natural language processing;speech recognition;cognition;computer science;linguistics;phonology;vocabulary development	ML	-10.21406979597887	-77.80851720834367	65947
978ef38de45888060c6ca1f5bd63849a2edd582e	bert: pre-training of deep bidirectional transformers for language understanding		We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT representations can be fine-tuned with just one additional output layer to create state-of-theart models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE benchmark to 80.4% (7.6% absolute improvement), MultiNLI accuracy to 86.7% (5.6% absolute improvement) and the SQuAD v1.1 question answering Test F1 to 93.2 (1.5 absolute improvement), outperforming human performance by 2.0.	benchmark (computing);bi-directional text;encoder;human reliability;natural language processing;natural language understanding;question answering;transformers	Jacob Devlin;Ming-Wei Chang;Kenton Lee;Kristina Toutanova	2018	CoRR		machine learning;encoder;natural language processing;artificial intelligence;constructed language;architecture;question answering;inference;computer science;glue;left and right	NLP	-18.163694539667013	-74.42141853232071	66202
2e6fd04e3a57a7bde009a4276cb9d80fe9cc2c28	effects of anaphoric dependencies and semantic representations on pronoun interpretation	semantic representation;mental representation;cognitive process;levels of abstraction;discourse coherence;pronoun interpretation;eye tracking;priming;anaphoric dependencies;psycholinguistics	We describe three experiments that use priming methodology to investigate the nature of the abstract mental representations activated during pronoun resolution, in order to contribute to our understanding of how structural representations and semantic coherence representations influence pronoun interpretation. The results of Experiment 1 suggest that there exists a level of abstract anaphoric dependency representations. Experiments 2 and 3 indicate that general coherence representations are activated during pronoun interpretation and thus provide direct evidence for the existence of shared abstract representations between (non-pronominal) coherence-related inferencing andpronoun resolution processes.Moreover, Experiment 3has implications for our understanding of the connections between linguistic and non-linguistic cognitive processes.	anaphora (linguistics);cognition;experiment	Elsi Kaiser	2009		10.1007/978-3-642-04975-0_10	natural language processing;cognition;eye tracking;mental representation;linguistics;psycholinguistics;priming	NLP	-9.4100481461401	-77.39810443826887	66483
4a07f0920fccb340ed46e719047a50bcb2fb1d4d	neural phrase-based machine translation.		In this paper, we propose Neural Phrase-based Machine Translation (NPMT). Our method explicitly models the phrase structures in output sequences through Sleep-WAke Networks (SWAN), a recently proposed segmentationbased sequence modeling method. To alleviate the monotonic alignment requirement of SWAN, we introduce a new layer to perform (soft) local reordering of input sequences. Our experiments show that NPMT achieves state-of-the-art results on IWSLT 2014 German-English translation task without using any attention mechanisms. We also observe that our method produces meaningful phrases in the output language.	experiment;machine translation	Po-Sen Huang;Chong Wang;Dengyong Zhou;Li Deng	2017	CoRR		machine translation;natural language processing;synchronous context-free grammar;artificial intelligence;transfer-based machine translation;phrase;computer science;rule-based machine translation;example-based machine translation	NLP	-18.62667855049439	-75.09364658876875	66647
5379cef4a1e4d85ccc289a1c25e895d72c8fcf4d	gesture in style	embodied conversational agent;markup language	The strength of the first two studies was to examine vocal style and interpretation, and how these changed during the 20 century in a systematic and objective manner. The inclusion of both performing style and the microstructure of performance gave the unexpected insight that the microstructures of performances have been much more stable over time than performing styles. This suggests relative generality of the generative processes responsible for expressive performance of music (Sloboda, 1983; Clarke, 1988) as well as cultural constraints on performing style.	edmund m. clarke;interpretation (logic);performance	Han Noot;Zsófia Ruttkay	2003		10.1007/978-3-540-24598-8_30	natural language processing;embodied agent;linguistics;communication	Web+IR	-8.849462896456627	-78.59515551141084	67165
bdd9a87b9f9437fa0285116d6c6af3cc7086ebe4	treeconnect: a sparse alternative to fully connected layers		We present a generally applicable tree-like sparse multilayer architecture that has a balanced connection from all input neurons to all output neurons. If the ratio between input and output neurons is fixed, the parameters required by our architecture scale with O(n^1.5) as compared to O(n^2) in a fully connected layer, where n is the number of input neurons. Our sparse 2-layer architecture performs similar and/or superior when compared to its fully connected 1-layer and 2-layer counter parts on the IMDB review sentiment classification task, the Reuters news categorization task and the CIFAR-10 image classification task.		Oliver Richter;Roger Wattenhofer	2018	2018 IEEE 30th International Conference on Tools with Artificial Intelligence (ICTAI)	10.1109/ICTAI.2018.00143	architecture;task analysis;artificial neural network;categorization;deep learning;contextual image classification;information technology;input/output;pattern recognition;computer science;artificial intelligence	Robotics	-10.720153628066805	-67.4943448174504	68166
fdaef1f364c665b98fe49fc6f3f44a25e1b2aa34	a joint model for sentence semantic similarity learning		Sentence similarity is a fundamental task to measure the degree of the likelihood between two sentences. It plays an important role in both NLP and IR communities. The current sentence semantic similarity measurements can be divided into two categories: the model based on feature engineering and the model based on deep learning. These two categories all have their own advantages and disadvantages. The feature captured based on deep learning may not get the deep meaning of the sentence. And the feature exacted based on feature engineering may not be comprehensive. The algorithm proposed recently usually use one of these two models. In this paper, we proposed a new model that combine the deep learning model and the feature engineering model together. Our model enables two methods to complement each other, making the feature extraction more comprehensive: not only take the global semantic information into account, but also further refine the semantic information at the word level. The experiment shows that our model performs better than models only use one category.	algorithm;deep learning;experiment;feature engineering;feature extraction;natural language processing;semantic similarity;similarity learning	Di Wu;Jiuming Huang;Shuqiang Yang	2017	2017 13th International Conference on Semantics, Knowledge and Grids (SKG)	10.1109/SKG.2017.00027	data mining;semantic similarity;artificial neural network;feature extraction;semantics;deep learning;machine learning;computer science;convolution;feature engineering;sentence;artificial intelligence	NLP	-17.60453274936236	-70.87622461542514	68271
a9caaa9b25723ece09dfd532b7287f465ea84f05	some evidence on the phonetics and phonology of prosodic phrasing in russian		This paper treats the issue of prosodic segmentation into phrasing domains in Russian and is framed in the prosodic phonology paradigm. Distributions of prosodic boundaries are obtained in a perception experiment and the results are further explored to advance the hypotheses about the levels of prosodic constituency in Russian. The temporal organisation of the perceived domains and the eurhythmic constraints on phrasing are investigated. Particularly, the empirical data suggest that beyond the level of intonational units, there are two other levels, a level of metrical domain and one of phonological phrase, relevant in the perception of phrasing patterns.	experiment;programming paradigm	Irina Nesterenko;Pavel A. Skrelin	2007			experimental phonetics;phonology;speech recognition;natural language processing;theoretical linguistics;phonetics;linguistics;computer science;artificial intelligence	NLP	-11.820299497449737	-80.19058730473476	68496
eddfa197f28c89e31b02fd5e32b54ee404ab18da	hiclass: hyper-interactive text classification by interactive supervision of document and term labels	busqueda informacion;sistema interactivo;teoria cognitiva;analisis contenido;analisis estadistico;analisis datos;information retrieval;hombre;cognitive theory;data mining;classification;theorie cognitive;systeme conversationnel;text classification;data analysis;sound classification;content analysis;statistical analysis;fouille donnee;interactive system;recherche information;decouverte connaissance;analyse statistique;proceedings paper;human;descubrimiento conocimiento;analyse donnee;cognitive load;analyse contenu;article;busca dato;clasificacion;homme;knowledge discovery	We present the HIClass (Hyper Interactive text Classification) system, an interactive text classification system which combines the cognitive power of humans with the power of automated learners to make statistically sound classification decisions. HIClass is based on active learning principles and has aids for detailed analysis and fine tuning of text classifiers while exerting a low cognitive load on the user.	document classification	Shantanu Godbole;Abhay Harpale;Sunita Sarawagi;Soumen Chakrabarti	2004		10.1007/978-3-540-30116-5_61	speech recognition;content analysis;biological classification;computer science;artificial intelligence;data mining;cognitive load;knowledge extraction;data analysis	HCI	-7.15615026564424	-71.04673763323294	68679
50bffdec632028c5cd5fba021995159df9315565	is lexical access driven by temporal order or perceptual salience? evidence from british sign language		While processing spoken language, people look towards relevant objects, and the time course of their gaze(s) can inform us about online language processing (Tanenhaus et al, 1995). Here, we investigate lexical recognition in British Sign Language (BSL) using a visual world paradigm, the first such study using a signed language. Comprehension of spoken words and signs could be driven by temporal constraints regardless of modality (“first in, first processed”), or by perceptual salience which differs for speech (auditorialy perceived) and sign (visually perceived). Deaf BSL signers looked more often to semantically related distracter pictures than to unrelated pictures, replicating studies using acoustically-presented speech. For phonologically related pictures, gaze increased only for those sharing visually salient phonological features (i.e., location and movement features). Results are discussed in the context of language processing in different modalities. Overall, we conclude that lexical processing for both speech and sign is likely driven by perceptual salience and that potential differences in processing emerge from differences between visual and auditory systems.	ampersand;boost;list comprehension;modality (human–computer interaction);programming paradigm;word lists by frequency	Robin L. Thompson;David P. Vinson;Neil Fox;Gabriella Vigliocco	2013			cognitive psychology;psychology;cued speech;phonology;linguistics;spoken language;semantics;sign language;british sign language;utterance;lexical item	NLP	-8.117349829511431	-79.1629379644819	69006
263cf95dcd30c900b7c8617523ab47b31ca822e4	mining unexpected patterns using decision trees and interestingness measures: a case study of endometriosis	domain driven data mining;treatment comparison;interestingness measures;unexpected patterns	Because clinical research is carried out in complex environments, prior domain knowledge, constraints, and expert knowledge can enhance the capabilities and performance of data mining. In this paper we propose an unexpected pattern mining model that uses decision trees to compare recovery rates of two different treatments, and to find patterns that contrastwith the prior knowledge of domain users. In the proposed model we define interestingness measures to determine whether the patterns found are interesting to the domain.By applying the concept of domain-drivendata mining, we repeatedly utilize decision trees and interestingness measures in a closed-loop, in-depth mining process to find unexpected and interesting patterns. We use retrospective data from transvaginal ultrasound-guided aspirations to show that the proposed model can successfully compare different treatments using a decision tree, which is a new usage of that tool. We believe that unexpected, interesting patterns Communicated by V. Loia. B Rui-Dong Chiang 081863@mail.tku.edu.tw Ming-Yang Chang mychang@adm.cgmh.org.tw Shih-Jung Wu wushihjung@mail.tku.edu.tw Chien-Hui Chan emmacc@gmail.com 1 Department of Obstetrics and Gynecology, Chang Gung Memorial Hospital, Taipei, Taiwan, ROC 2 Department of Computer Science and Information Engineering, Tamkang University, New Taipei City, Taiwan, ROC 3 Department of Innovative Information and Technology, Tamkang University, Yilan County, Taiwan, ROC may provide clinical researchers with different perspectives for future research.	algorithm;computer science;data mining;decision tree;flickr;information engineering;yang	Ming-Yang Chang;Rui-Dong Chiang;Shih-Jung Wu;Chien-Hui Chan	2016	Soft Comput.	10.1007/s00500-015-1735-0	artificial intelligence;data science;data mining	ML	-7.462951086128084	-66.2988660584924	69265
c626faf324fe5aa48e20382007acd45724ed763c	a complexity approach for identifying aesthetic composite landscapes		The present paper describes a series of features related to complexity which may allow to estimate the complexity of an image as a whole, of all the elements integrating it and of those which are its focus of attention. Using a neural network to create a classifier based on those features an accuracy over 85% in an aesthetic composition binary classification task is achieved. The obtained network seems to be useful for the purpose of assessing the Aesthetic Composition of landscapes. It could be used as part of a media device for facilitating the creation of images or videos with a more professional aesthetic composition.	artificial neural network;binary classification;complexity;image	Adrián Carballal;Rebeca Perez;Antonino Santos;Luz Castro	2014		10.1007/978-3-662-44335-4_5	computer science	AI	-7.007870117797555	-67.88928499263052	69376
017bdeaf8b7bddce95f39434c9df47c9a4bf5d26	grounding styles of aged dyads - an exploratory study		This paper reports an exploratory study of the grounding styles of older dyads, namely, the characteristic ways in which they mutually agree to have shared a piece of information in dialogue. On the basis of Traum's classification of grounding acts, we conducted an exploratory comparison of dialogue data on older and younger dyads, and found that a fairly clear contrast holds mainly in the types of acknowledgement utterances used by the two groups. We will discuss the implications of this contrast, concerning how some of the negative stereotypes about conversations with older people may arise from this difference in grounding styles.	general-purpose modeling	Atsue Takeoka;Atsushi Shimojima	2002			psychology;developmental psychology;communication;social psychology	HCI	-9.303551207146686	-78.28087874169705	69394
f18dd68cc0108ae52789f5518fbf5a2e8806bfaa	sister: a flexible system for image retrieval	image retrieval		image retrieval	Monica Mordonini;Agostino Poggi	1999	Informatica (Slovenia)		machine learning;visual word;automatic image annotation;sister;computer vision;computer science;image retrieval;artificial intelligence	Vision	-8.971580474384062	-69.65320086542519	69508
dae789688b1002862660eaf10240358b4fc31ae2	evolving musical sequences with n-gram based trainable fitness functions	evolutionary computation humans multiple signal classification stochastic processes differential equations genetics bars stochastic systems natural language processing training data;genetic operator;evolutionary computation;sequence oriented genetic operators musical sequences n gram based trainable fitness functions automatic music composition interactive approach evolutionary algorithm trainable music evaluation n gram language model;music evolutionary computation;n gram model;automatic generation;evolutionary algorithm;classification accuracy;music;language model;fitness function	Conventionally, automatic music composition is done by evolving music sequences whose fitness is evaluated by a human listener. This interactive approach has led to interesting results but is very time consuming. Here we propose a system that is capable of automatically generating music using an evolutionary algorithm (EA), replacing the human evaluation process with a trainable music evaluation algorithm. This algorithm can be trained on existing music samples, such as Mozart compositions for example. This kind of system could provide a fast and cheap music composition tool. The current evaluation system is implemented with an N-Gram language model. This paper discusses the system in two parts. Firstly, it describes the performance of the proposed music evaluation algorithm. Secondly, it discusses the impacts of different sequence-oriented genetic operators in the evolutionary algorithm. Part one of the experimental results show that the N-Gram model is able to distinguish the composer of piano compositions by Mozart, Beethoven and Chopin with up to 81.9% accuracy. Part two of the results show that some of the sequence-oriented operators increased the fitness of the generated melodies, but some operators did not. The impacts of these operators are discussed in the experimental results section. Significantly, the results also show that better classification accuracy does not necessarily lead to better evolved music, suggesting that perceptual relevance is also an important factor.	automatic sounding;converge;evolutionary algorithm;fitness function;genetic algorithm;genetic operator;grams;language model;n-gram;pitch (music);relevance feedback	Man Yat Lo;Simon M. Lucas	2006	2006 IEEE International Conference on Evolutionary Computation	10.1109/CEC.2006.1688365	evolutionary music;speech recognition;interactive evolutionary computation;computer science;artificial intelligence;genetic operator;machine learning;evolutionary algorithm;music;fitness function;language model;evolutionary computation	Robotics	-16.399954781188583	-79.72412244584014	69559
27041656e77765cfa7d305bb37a7819129348852	no need to laugh out loud: predicting humor appraisal of comic strips based on physiological signals in a realistic environment		We explore electroencephalography (EEG), electrodermal activity (EDA), and electrocardiography (ECG) as valid sources to infer humor appraisal in a realistic environment. We report on an experiment in which 25 participants browsed a popular user-generated humorous content website while their physiological responses were recorded. We build predictive models to infer the participants’ appraisal of the humorousness of the content and demonstrate that the fusion of several physiological signals can lead to classification performances up to 0.73 in terms of the area under the ROC curve (AUC). We identify that the most discriminative changes in physiological signals happen at the later stages of the information consumption process, reflected in changes on the upper EEG frequency bands, higher levels of EDA, and heart-rate acceleration. Additionally, we present a comprehensive analysis by benchmarking the predictive power of each of the physiological signals separately, and by comparing them to state-of-the-art facial recognition algorithms based on facial video recordings. The classification performance ranges from 0.88 (in terms of AUC) when combining physiological signals and video recordings, to 0.55 when using ECG signals alone.	algorithm;electroencephalography;facial recognition system;frequency band;performance;predictive modelling;receiver operating characteristic;strips;user-generated content	Oswald Barral;Ilkka Kosunen;Giulio Jacucci	2017	ACM Trans. Comput.-Hum. Interact.	10.1145/3157730	speech recognition;human–computer interaction;discriminative model;benchmarking;electroencephalography;humorousness;facial recognition system;comic strips;computer science	AI	-6.367626106524986	-72.76007969191022	69580
78a412ed529bcbc6135318c475389b223b0b641d	exploiting temporal relations in mining hepatitis data	relational data;temporal patterns;data mining;temporal abstraction;temporal relations;temporal pattern;viral hepatitis;hepatitis study	Various data mining methods have been developed last few years for hepatitis study using a large temporal and relational database given to the research community. In this work we introduce a novel temporal abstraction method to this study by detecting and exploiting temporal patterns and relations between events in viral hepatitis such as “event A slightly happened before event B and B simultaneously ended with event C”. We developed algorithms to first detect significant temporal patterns in temporal sequences and then to identify temporal relations between these temporal patterns. Many findings by data mining methods applied to transactions/graphs of temporal relations shown to be significant by physician evaluation and matching with published in Medline.	algorithm;data mining;happened-before;medline;relational database;sensor	Tu Bao Ho;Canh Hao Nguyen;Saori Kawasaki;Si Quang Le;Katsuhiko Takabayashi	2007	New Generation Computing	10.1007/s00354-007-0016-6	relational database;computer science;data science;data mining;database	DB	-5.088388665722069	-67.01000156240357	69772
42d46d46eb75173fdb3c9891d10b3143cb43b380	language expansion in text-based games		Text-based games are suitable test-beds for designing agents that can learn by interaction with the environment in the form of natural language text. Very recently, deep reinforcement learning based agents have been successfully applied for playing text-based games. In this paper, we explore the possibility of designing a single agent to play several text-based games and of expanding the agent’s vocabulary using the vocabulary of agents trained for multiple games. To this extent, we explore the application of recently proposed policy distillation method for video games to the text-based game setting. We also use text-based games as a test-bed to analyze and hence understand policy distillation approach in detail.	experiment;long short-term memory;natural language;reinforcement learning;testbed;text-based (computing);text-based game;vocabulary	Ghulam Ahmed Ansari;P SagarJ.;A. P. Sarath Chandar;Balaraman Ravindran	2018	CoRR		natural language processing;artificial intelligence;machine learning;reinforcement learning;natural language;computer science;vocabulary	AI	-17.197980295981054	-68.48760012640601	69814
1a756e8c9ebc0665dd7723ffd89299379f137b78	color categories are diverse in thought as well as language: evidence from new guinea and africa	categorisation;learning;color;lenguaje;langage;aprendizaje;apprentissage;categorizacion;couleur;language;new guinea;categorization	Following recent findings of cultural and linguistic relativity in other fields of categorization (e.g. shape, number, space) we report a series of cross-cultural studies of color categorization in adults and young children that address the particular question of whether and to what extent color categories are learned, and free to vary, or innate and universal. Adult speakers of different languages were found to show different patterns of discrimination and memory for the same set of colors and their cognitive representations of color categories appeared to be isomorphic with their linguistic categories. Longitudinal studies of two groups of children in Africa (children from the semi-nomadic Himba tribe in Namibia) and the UK examined the extended process of both lexical and non-lexical color category acquisition. Gradual category acquisition was observed in both groups, rather than all-or-nothing performance and even with intensive adult input (for the English children) color category acquisition appeared to be universally slow and effortful.	color	Debi D. Roberson	2004		10.1117/12.538842	language;categorization	NLP	-8.18718095670751	-77.46682801892374	70167
703d23d9cec787c87afe5c1b3db40fd1a6b6bc99	combining pattern-based crfs and weighted context-free grammars		We consider two models for the sequence labeling (tagging) problem. The first one is a Pattern-Based Conditional Random Field (PB), in which the energy of a string (chain labeling) x = x1 . . . xn ∈ D is a sum of terms over intervals [i, j] where each term is non-zero only if the substring xi . . . xj equals a prespecified word w ∈ Λ. The second model is a Weighted Context-Free Grammar (WCFG) frequently used for natural language processing. PB and WCFG encode local and non-local interactions respectively, and thus can be viewed as complementary. We propose a Grammatical Pattern-Based CRF model (GPB) that combines the two in a natural way. We argue that it has certain advantages over existing approaches such as the Hybrid model of Bened́ı and Sanchez that combines N -grams and WCFGs. The focus of this paper is to analyze the complexity of inference tasks in a GPB such as computing MAP. We present a polynomial-time algorithm for general GPBs and a faster version for a special case that we call Interaction Grammars.	algorithm;conditional random field;context-free language;encode;existential quantification;general-purpose modeling;interaction;lr parser;map;natural language processing;petabyte;protocol buffers;sequence labeling;substring;time complexity;weighted context-free grammar	Rustem Takhanov;Vladimir Kolmogorov	2014	CoRR		computer science;machine learning;pattern recognition;mathematics;programming language;algorithm	NLP	-18.46207713458407	-77.43160621437757	70626
965b0b3454d6b70085f7581690716e251cbe45bf	bigvid at mediaeval 2016: predicting interestingness in images and videos		Despite growing research interest, the tasks of predicting the interestingness of images and videos remain as an open challenge. The main obstacles come from both the diversity and complexity of video content and highly subjective and varying judgements of interestingness of different persons. In the MediaEval 2016 Predicting Media Interestingness Task, our team of BigVid@Fudan had submitted five runs exploring various methods of extraction, and modeling the low-level features (from visual and audio modalities) and hundreds of high-level semantic attributes; and fusing these features for classification. We not only investigated the use of the SVM (Support Vector Machine) model; but the recent deep learning methods were explored as well. We had submitted 5 runs using SVM/Ranking-SVM (Run1, Run3 and Run4) and Deep Neural Networks (Run2 and Run5) respectively. We achieved a mean average precision of 0.23 for the image subtask and 0.15 for the video subtask. Furthermore, our experiments revealed some insights of this task which are interesting and potential useful. For example, our results show that the visual features and high-level attributes are complementary to each other.	complexity;deep learning;digital video;experiment;flickr;high- and low-level;information retrieval;neural networks;ranking svm;support vector machine	Baohan Xu;Yanwei Fu;Yu-Gang Jiang	2016			computer science	AI	-12.22134192230572	-70.07620715260683	70982
d1fdb2b995e65cbbc489e817e622edd9187e56f4	the interaction of politeness systems in korean learners of french		This paper investigates how the French second person pronouns, tu and vous, are acquired by Korean learners of French. This is specifically approached from an interlanguage pragmatics research viewpoint, focusing upon the status of the learners’ pragmalinguistic and sociopragmatic knowledge (whether they are explicit or implicit). It is hypothesized that Korean learners of French will face difficulties acquiring vous, but not with tu due to the similarities between French and Korean second person pronoun use in requests, mediated by their implicit/explicit knowledge. Using a discourse completion task and an error correction task, the findings support the hypothesis, showing the interplay between language transfer and their second language developmental status. Moreover, this was detectible by using a combination of tasks which allows pinpointing of knowledge used. The implications for explicit/implicit knowledge status in relation to the use of pragmatic knowledge are discussed against the degree of control learners have over tu and vous.	error detection and correction	Darcy Sperlich;Jaiho Leem;Eui-Jeen Ahn	2016			politeness;linguistics;political science;communication	HCI	-10.023396736692122	-78.12247661612058	71154
69dc6abb5556b3efe4e69d34a8dc78debacb6bb3	minimally-supervised learning of domain-specific causal relations using an open-domain corpus as knowledge base	information extraction;text mining;causal relations causality;natural language processing;knowledge management applications	We propose a novel framework for overcoming the challenges in extracting causal relations from domain-specific texts. Our technique is minimally-supervised, alleviating the need for manually-annotated, expensive training data. As our main contribution, we show that open-domain corpora can be exploited as knowledge bases to overcome data sparsity issues posed by domain-specific relation extraction, and that they enable substantial performance gains. We also address longstanding challenges of extant minimally-supervised approaches. To suppress the negative impact of semantic drift, we propose a technique based on the Latent Relational Hypothesis. In addition, our approach discovers both explicit (e.g. ''to cause'') and implicit (e.g. ''to destroy'') causal patterns/relations. Unlike existing minimally-supervised techniques, we adopt a principled seed selection strategy, which enables us to discover a more diverse set of causal patterns/relations. Our experiments reveal that our approach outperforms a state-of-the-art baseline in discovering causal relations from a real-life, domain-specific corpus.	causal filter;knowledge base;supervised learning	Ashwin Ittoo;Gosse Bouma	2013	Data Knowl. Eng.	10.1016/j.datak.2013.08.004	natural language processing;text mining;computer science;artificial intelligence;machine learning;data mining;database;information extraction	NLP	-18.28660022631845	-66.39138810362083	71193
9c4e484f288770a9b747de2c8bfcd8eaf0ee4587	the effect of labels on categorization: is attention to relevant features a good index of infants' category learning?		Shifting attention to category relevant features has been demonstrated in adults to be a successful strategy for categorizing novel objects. The current experiment was aimed at exploring whether infants would use a similar strategy for category learning when objects were presented with and without labels. Using an eye tracker, 6to 8-month-old infants were familiarized and tested with a novel visual category where only half of the features were relevant for category membership. There was some evidence that infants learned the target category only when objects were not labeled. Furthermore, infants who learned the target category did not appear to optimize their attention to the category relevant features. In addition, contrary to some theoretical accounts, there was no evidence that labels facilitated categorization by highlighting category relevant features.	categorization;concept learning;eye tracking	Catherine A. Best;Christopher W. Robinson;Vladimir M. Sloutsky	2011			psychology;machine learning;pattern recognition;social psychology	HCI	-7.126899590681546	-75.93218666641164	71352
37b3f17d7125a22208040f0fcad984ec4810ab30	natural scene statistics mediate the perception of image complexity	randomness;algorithmic complexity;visual complexity;visual perception	Humans are sensitive to complexity and regularity in patterns (Yamada, Kawabe & Miyazaki, 2013; Falk & Konold, 1997). The subjective perception of pattern complexity is correlated to algorithmic (or Kolmogorov-Chaitin) complexity as defined in computer science (Li & Vitanyi, 2008), but also to the frequency of naturally occurring patterns (Hsu, Griffiths & Schreiber, 2010). However, the possible mediational role of natural frequencies in the perception of algorithmic complexity remains unclear. Here we reanalyze Hsu et al. (2010) through a mediational analysis, and complement their results in a new experiment. We conclude that human perception of complexity seems partly shaped by natural scenes statistics, thereby establishing a link between the perception of complexity and the effect of natural scene statistics.	analysis of algorithms;computational complexity theory;computer science;humans;kolmogorov complexity;patterns in nature;rule 184;scene statistics	Nicolas Gauvrit;Fernando Soler-Toscano	2014	CoRR	10.1080/13506285.2014.950365	psychology;visual perception;communication;social psychology;randomness;cognitive science	Logic	-5.496513895390434	-78.35733162061038	71457
3000e5bae7f9a3bcead52b6343eae3e33dd6612b	examining referential uncertainty in naturalistic contexts from the child's view: evidence from an eye-tracking study with infants		Young infants are prolific word learners even though they are facing the challenge of referential uncertainty (Quine, 1960). Many laboratory studies have shown that human infants are skilled at inferring the correct referent of an object from ambiguous contexts (Swingley, 2009). However, little is known regarding how children visually attend to and select the target object among many other objects in view when parents name it during free play interactions. In the current study, we explored the looking pattern of 12-month-old infants using naturalistic first person images with varying degrees of referential ambiguity. Our data suggest that infants’ attention is selective and they tend to only select a small subset of objects to attend to at each learning instance despite the complexity of the data existed in the real world. This work allows us to better understand how perceptual properties of objects in infants’ view influence their visual attention, which is also related to how they select candidate objects to build word-object mappings.	eye tracking;first-person (video games);interaction;quine (computing)	Yayun Zhang;Chen Yu	2016			cognitive psychology;naturalism;psychology;eye tracking	HCI	-7.030706612291565	-76.2292352862801	71494
e209b9c1896960266244d9dc91c4ab3e71407181	approach for machine-printed arabic character recognition: the-state-of-the-art deep-learning method		Optical character recognition (OCR) automatically recognizes texts in an image and converts them into machine codes such as ASCII or Unicode. Compared to many research studied on OCR for other languages, recognizing Arabic language is still a challenging problem due to character connection and segmentation issues. In this work, we propose a deep-learning framework of recognizing Arabic characters based on the multidimensional bi-direction long short-term memory (MD-BLSTM) with connectionist temporal classification (CTC). To train this framework, we generate over one-million Arabic text-line images dataset that contains Arabic digits, basic Arabic forms with isolated shape and connected forms. To compare the results, we also measure the performance of other OCR software such as Tesseract made by Hewlett-Packard and Google Inc. Tesseract version 3 and version 4 are used. Results show that deep-learning method outperforms the conventional methods in terms of recognition error rate, although the Tesseract_3.0 system was faster.	algorithm;code;comparison of optical character recognition software;connectionism;cross-validation (statistics);deep learning;experiment;long short-term memory;molecular dynamics;open-source software;printing;sensor;tesseract;unicode;word error rate	Daegun Ko;Changhyung Lee;Donghyeop Han;Hyeongsu Ohk;Kimin Kang;Seongwook Han	2018		10.2352/ISSN.2470-1173.2018.2.VIPC-176	natural language processing;arabic;deep learning;artificial intelligence;computer science	Vision	-16.780079967246856	-77.03155701976284	71510
8c9f8805e5463e92011ea32ad7cc3f35f812e522	an interpretable reasoning network for multi-relation question answering		Multi-relation Question Answering is a challenging task, due to the requirement of elaborated analysis on questions and reasoning over multiple fact triples in knowledge base. In this paper, we present a novel model called Interpretable Reasoning Network that employs an interpretable, hop-by-hop reasoning process for question answering. The model dynamically decides which part of an input question should be analyzed at each hop; predicts a relation that corresponds to the current parsed results; utilizes the predicted relation to update the question representation and the state of the reasoning process; and then drives the next-hop reasoning. Experiments show that our model yields state-of-the-art results on two datasets. More interestingly, the model can offer traceable and observable intermediate predictions for reasoning analysis and failure diagnosis, thereby allowing manual manipulation in predicting the final answer.	entity;experiment;freebase;hop-by-hop transport;kilobyte;knowledge base;natural language generation;observable;pq tree;parsing;question answering;software diagnosis;software quality assurance;traceability;wikianswers	Mantong Zhou;Minlie Huang;Xiaoyan Zhu	2018			natural language processing;machine learning;hop (networking);question answering;computer science;knowledge base;artificial intelligence;parsing;observable	NLP	-16.65685167215109	-72.16700347109175	71809
9ad18a1ee9f691fd96c339ccc353a927910f5238	source error-projection for sample selection in phrase-based smt for resource-poor languages		The unavailability of parallel training corpora in resource-poor languages is a major bottleneck in cost-effective and rapid deployment of statistical machine translation (SMT) technology. This has spurred significant interest in active learning for SMT to select the most informative samples from a large candidate pool. This is especially challenging when irrelevant outliers dominate the pool. We propose two supervised sample selection methods, viz. greedy selection and integer linear programming (ILP), based on a novel measure of benefit derived from error analysis. These methods support the selection of diverse and high-impact, yet relevant batches of source sentences. Comparative experiments on multiple test sets across two resource-poor language pairs (English-Pashto and English-Dari) reveal that the proposed approaches achieve BLEU scores comparable to the full system using a very small fraction of all available training data (ca. 6% for E-P and 13% for E-D). We further demonstrate that the ILP method supports global constraints of significant practical value.	bleu;circa;error analysis (mathematics);experiment;greedy algorithm;information;integer programming;linear programming;relevance;software deployment;statistical machine translation;text corpus;unavailability;viz: the computer game	Sankaranarayanan Ananthakrishnan;Shiv Naga Prasad Vitaladevuni;Rohit Prasad;Premkumar Natarajan	2011			speech recognition;computer science;machine learning;data mining;algorithm	NLP	-18.927411774416875	-78.00158448273544	72158
82580fe4c429ac76f94c514c1ffc066844b13192	determining event durations: models and error analysis		This paper presents models to predict event durations. We introduce aspectual features that capture deeper linguistic information than previous work, and experiment with neural networks. Our analysis shows that tense, aspect and temporal structure of the clause provide useful clues, and that an LSTM ensemble captures relevant context around the event.	artificial neural network;emoticon;error analysis for the global positioning system;long short-term memory;neural ensemble;temporal logic	Alakananda Vempala;Eduardo Blanco;Alexis Palmer	2018			support vector machine;artificial neural network;machine learning;computer science;artificial intelligence	NLP	-16.87845511624055	-72.09302223935312	72220
be941a3a47beea6e8ac2a6ab5b1b6bcfa3899419	learnability of embedded syntactic structures depends on prosodic cues	aprendizaje estadistico;syntax;habla;etude experimentale;lenguaje;hombre;speech;langage;syntaxe;proceso adquisicion;acquisition process;artificial grammar learning;implicit learning;hierarchical structures;aprendizaje implicito;gramatica artificial;statistical learning;grammaire artificielle;prosodie;cognition;artificial grammar;human;apprentissage statistique;cognicion;apprentissage implicite;parole;language;sintaxis;prosody;estudio experimental;processus acquisition;prosodia;homme	The ability to process center-embedded structures has been claimed to represent a core function of the language faculty. Recently, several studies have investigated the learning of center-embedded dependencies in artificial grammar settings. Yet some of the results seem to question the learnability of these structures in artificial grammar tasks. Here, we tested under which exposure conditions learning of center-embedded structures in an artificial grammar is possible. We used naturally spoken syllable sequences and varied the presence of prosodic cues. The results suggest that mere distributional information does not suffice for successful learning. Prosodic cues marking the boundaries of the major relevant units, however, can lead to learning success. Thus, our data are consistent with the hypothesis that center-embedded syntactic structures can be learned in artificial grammar tasks if language-like acoustic cues are provided.		Jutta L. Mueller;Jörg Bahlmann;Angela D. Friederici	2010	Cognitive science	10.1111/j.1551-6709.2009.01093.x	psychology;natural language processing;cognition;syntax;computer science;speech;linguistics;language;prosody;communication	NLP	-10.723938547245897	-76.97956811584882	72266
d839bb2d092d6fa23ed4f82549f103bd8a123b81	tonal consonance parameters expose a hidden order in music		Consonance is related to the perception of pleasantness arising from the combination of sounds and has been approached quantitatively using mathematical relations, physics, information theory and psychoacoustics. Tonal consonance is present in timbre, musical tuning, harmony and melody, and it is used for conveying sensations and emotions in music. It involves the physical properties of sound waves and is used to study melody and harmony through musical intervals and chords. From the perspective of complexity, the macroscopic properties of a system with many parts frequently rely on statistical properties of its constituent elements. Here we show that melody in musical pieces can be described in terms of the physical properties of melodic intervals and the existence of an entropy extremalization principle in music with psychoacoustic macroscopic constraints given by conserved quantities with musical meaning. This result connects human perception with human creativity through the physical properties of the musical stimulus. Pythagoras found that two sounds emitted simultaneously by vibrating strings of equal tension and density produce a pleasant sensation when the ratio between their lengths corresponds to the ratio between two small natural numbers n m ⁄ . This sensation is formally defined as consonance and it is present in melody, harmony, timbre and musical tuning. Many authors relate consonance with conveying musical information as emotions and meaning. From the perspective of the nature of tonality, consonance and dissonance give rise to emotions through tension and relaxation in passages from satisfaction to dissatisfaction and again to satisfaction. A starting point for studying consonance is the superposition of pure tones or harmonic sound waves with frequency fi . Musical instruments produce complex tones that can be represented by a superposition of pure tones; the set of frequencies with their corresponding amplitudes is the spectrum and characterizes the timbre of the instrument. Pitch is a subjective quality of sound that judges its height and depends strongly on the lowest frequency of the spectrum, the fundamental. Reinier Plomp and Willem Levelt found that the consonance level of pairs of simultaneous pure tones is related to the beats produced by fluctuations in the peak intensity of the resulting sound waves (Supplemental Note 1). This approach to consonance is known as tonal or sensory because it depends on the physical properties of the stimulus regardless of the cultural context of listeners. William Sethares assigned a level of tonal consonance to timbre using the spectrum of the emitted sound and connected timbre with musical tuning. Musical tuning refers to adjusting a set of pitches to a musical scale using a fixed pitch of reference. Usually, a musical scale is a set of mathematical relations among the fundamental frequencies of pitches. Pairs of pitches in a musical scale define musical intervals with length L given by the number of pitches between them. In musical theory the level of consonance assigned to a musical interval usually depends on its length and is frequently used to analyze harmony. Since musicians tend to apply the same rules for judging the consonance level of simultaneous and successive pitches (harmonic and melodic intervals respectively), and the short-term persistence of pitch in auditoriums may give rise to consonance sensations for successive pitches, then tonal consonance is suitable for analyzing melody. The New Grove Dictionary of Music and Musicians defines melody as “pitched sounds arranged in musical time in accordance with given cultural conventions and constraints” . A definition that encompasses music and speech was given by Aniruddh Patel: “an organized sequence of pitches that conveys a rich variety of information to a listener”. George Kingsley Zipf reported that the frequency of occurrence of melodic intervals in masterpieces of Western tonal music is inversely proportional to their length. From the information theory perspective, Güngör Gündüz and Ufuk Gündüz measured the probability of occurrence of musical notes during the progress of melodies and found that entropy grows until a limiting value smaller than the entropy of a random melody. Psychoacoustic representation of consonance The approach of Plomp and Levelt to tonal consonance of complex tones is independent of musical scales. They found that an interval of a given length might be more or less consonant depending on its timbre and location in the register and that this variation through the register is continuous and soft. They used two quantities for parametrizing the tonal consonance level of complex tones: The lowest fundamental frequency of the pair of pitches and the ratio between the fundamental frequencies fj fi ⁄ . This set of parameters is equivalent to one with the same ratio fj fi ⁄ and the absolute value of the difference between the fundamental frequencies |fj − fi| (Supplemental Note 2). For scales based on the Pythagorean rule the difference of fundamental frequencies is related with their sum fj − fi = [(n −m)/(n + m)](fi + fj). (1) For the Just and the Pythagorean scales the quantity (n − m)/(n + m) depends on the length L ≡ L(fi, fj) of the corresponding interval and for fj ≠ fi (i.e. L ≠ 0) this relation can be expressed as (Figure 1) fj + fi = (−1) a L (fj − fi) (2) with h = 0 for fj > fi and h = 1 for fj < fi. Up to three octaves, as melodic intervals in musical pieces usually do not exceed this length, the fit parameters to a power law for the Pythagorean scale are a = 30.801 ± 0.184 and b = 0.918 ± 0.006, with R = 0.9988, and for the Just scale are a = 31.176 ± 0.149 and b = 0.925 ± 0.005, with R = 0.9992. Equation (2) does not hold for tempered scales, however since pitches in the Twelve-Tone Equal-Tempered scale are given by fi = f1 √2i 12 , where f1 is a reference frequency, then fj fi ⁄ = √2 (j−i) 12 = √2L 12 , with fj > fi (3) and for fj ≠ fi fj + fi = 2 + 1 2L/12 − 1 (fj − fi) = (−1) a L(fj − fi) (4) In this case the fit parameters are a = 34.456 ± 0.139 and b = 0.979 ± 0.004, with R = 0.9994, see Figure 1. Figure 1 | Relation between musical scale parameters and the interval length for Just, Pythagorean, and Twelve-Tone EqualTempered scales. Interval length from one to thirty-six semitones. n > m and L > 0. Musical scale parameters are presented in Supplemental Table 1. Hence, for these scales, the sum of the fundamental frequencies contains information about the height of pitches and, from equations (2) and (4), about the tonal consonance parameter |fj − fi| per unit of interval length, as b ≅ −1. Since each ratio fj fi ⁄ corresponds to a length L and it depends on the ratio (fj − fi)/(fj + fi), then a complete description of tonal consonance can be made using the sum and the difference of the fundamental frequencies. Additionally, the set of these two quantities distinguishes each pair of pitches as there are two equations with two variables, therefore relating the use of tonal consonance in a musical piece with the selection of pitches made by the composer. A quantity that combines the two parameters selected for describing tonal consonance for complex tones is fj 2 − fi 2 = (fi + fj)(fj − fi). For scales with unique values fj 2 − fi 2 for each pair of pitches, such as the Twelve-Tone Equal-Tempered scale and in practically all cases of the Just and the Pythagorean scales (Supplemental Note 3 and Supplemental Figure 1), this quantity allows reconstructing both parameters, (fi + fj) and (fj − fi), as well as assigning a tonal consonance level to each pair of pitches. If both sound waves propagate in the same medium (with density ρ) and their amplitudes T and phases are assumed to be equal then the quantity fj 2 − fi 2 is proportional to the difference of the average density of the total energy carried by the two waves 〈εj〉 − 〈εi〉 = 2π ρT(fj 2 − fi ) . This relation holds for pure tones and for complex tones it corresponds to the difference of the average of the energy density carried by the fundamental components. The magnitudes of fj − fi and fj 2 − fi 2 distinguish intervals of equal length played in different parts of the register and between intervals of different length, especially those between one and thirty-six semitones except for unisons fj = fi with degenerated value 0, see Figure 2 for fj 2 − fi 2 and Supplemental Figure 2 for fj − fi. Figure 2 | Relation between the quantity fj 2 − fi 2 and the interval length in semitones for an eighty-eight key piano. The quantity fj 2 − fi 2 distinguishes intervals of equal length played in different parts of the register and between intervals of different length, especially those between one and thirty-six semitones. The upper branch comes from j = 88 (highest pitch) and i varies from 88 to 1. The tuning comes from the frequency relation for the Twelve-Tone Equal-Tempered scale with A = 440Hz. Finally, this model uses the fundamental for parametrizing pitch and timbre that can be included through consonance curves for complex tones, such as those produced by Plomp and Levelt. Use of tonal consonance in real melodic lines We study the use of tonal consonance regarding the selection made by the composer of melodic intervals characterized by their length and position in the register. For this purpose, we study the probability distribution of the physical quantities fj − fi and fj 2 − fi . If i indicates the chronological order of appearance of pitches in a melody, then the quantities fi+1 − fi and fi+1 2 − fi 2 can be used to study tonal consonance with the sign distinguishing between ascending (fi+1 > fi) and descending (fi+1 < fi) transitions . We analyze vocal and instrumental pieces of the Baroque and Classical periods played in the Twelve-Tone EqualTempered scale with A = 440Hz. The selected pieces contain melodic lines characterized by their long length, internal coherence and rich variety of instrume	baroque;complexity;database tuning;dictionary;evert willem beth;hash table;inferring horizontal gene transfer;information theory;kingsley (youtube);linear programming relaxation;musical keyboard;persistence (computer science);psychoacoustics;quantum superposition;zipf's law	Jorge Eduardo Useche;Rafael Germán Hurtado	2016	CoRR		melody;speech recognition;acoustics;musical development;musical acoustics;music theory;music and emotion	ML	-12.011563506286851	-78.63157469406853	72355
a5531b5626c1ee3b6f9aed281a98338439d06d12	multichannel attention network for analyzing visual behavior in public speaking		We investigate the importance of human centered visual cues for predicting the popularity of a public lecture. We construct a large database of more than 1800 TED talk videos and leverage the corresponding (online) viewers' ratings from YouTube for a measure of popularity of the TED talks. Visual cues related to facial and physical appearance, facial expressions, and pose variations are learned using convolutional neural networks (CNN) connected to an attention-based long short-term memory (LSTM) network to predict the video popularity. The proposed overall network is end-to-end-trainable, and achieves state-of-the-art prediction accuracy indicating that the visual cues alone contain highly predictive information about the popularity of a talk. We also demonstrate qualitatively that the network learns a human-like attention mechanism, which is particularly useful for interpretability, i.e. how attention varies with time, and across different visual cues as a function of their relative importance.	acoustic cryptanalysis;artificial neural network;behavior model;convolutional neural network;database;dual total correlation;end-to-end principle;experiment;graphics processing unit;integrated information theory;latent variable;long short-term memory;semantic prosody;titan (supercomputer)	Rahul Sharma;Tanaya Guha;Gaurav Sharma	2018	2018 IEEE Winter Conference on Applications of Computer Vision (WACV)	10.1109/WACV.2018.00058	sensory cue;task analysis;artificial intelligence;visualization;convolutional neural network;human physical appearance;pattern recognition;computer science;popularity;facial expression;interpretability	Vision	-12.301970232566804	-70.94210757574854	72661
269ed5ba525519502123b58472e069d77c5bda14	non-sentential question resolution using sequence to sequence learning.		An interactive Question Answering (QA) system frequently encounters non-sentential (incomplete) questions. These non-sentential questions may not make sense to the system when a user asks them without the context of conversation. The system thus needs to take into account the conversation context to process the incomplete question. In this work, we present a recurrent neural network (RNN) based encoder decoder network that can generate a complete (intended) question, given an incomplete question and conversation context. RNN encoder decoder networks have been show to work well when trained on a parallel corpus with millions of sentences, however it is extremely hard to obtain conversation data of this magnitude. We therefore propose to decompose the original problem into two separate simplified problems where each problem focuses on an abstraction. Specifically, we train a semantic sequence model to learn semantic patterns, and a syntactic sequence model to learn linguistic patterns. We further combine syntactic and semantic sequence models to generate an ensemble model. Our model achieves a BLEU score of 30.15 as compared to 18.54 using a standard RNN encoder decoder model.	abstract data type;artificial neural network;bleu;encoder;parallel text;question answering;random neural network;recurrent neural network;software quality assurance;vocabulary	Vineet Kumar;Sachindra Joshi	2016			artificial intelligence;natural language processing;computer science;pattern recognition;sequence learning	NLP	-17.641196396674268	-74.1719237261778	72907
65ae4873ebbd907a0a2a8b34cc77fd643fc37bea	aspect level sentiment classification with attention-over-attention neural networks		Aspect-level sentiment classification aims to identify the sentiment expressed towards some aspects given context sentences. In this paper, we introduce an attention-over-attention (AOA) neural network for aspect level sentiment classification. Our approach models aspects and sentences in a joint way and explicitly captures the interaction between aspects and context sentences. With the AOA module, our model jointly learns the representations for aspects and sentences, and automatically focuses on the important parts in sentences. Our experiments on laptop and restaurant datasets demonstrate our approach outperforms previous LSTM-based architectures.	angle of arrival;baseline (configuration management);error analysis (mathematics);experiment;laptop;long short-term memory;network model;neural networks;programming idiom;semeval	Binxuan Huang;Yanglan Ou;Kathleen M. Carley	2018		10.1007/978-3-319-93372-6_22	natural language processing;machine learning;artificial neural network;artificial intelligence;computer science	NLP	-17.874918281353917	-71.86522835540417	75033
176c30e168f62e5a6eead8558a22a11792cc0a09	individual differences in mental rotation: what does gesture tell us?	female;adolescent;male;gestures;adult;neuropsychological tests;reproducibility of results;mental processes;individuality;humans;photic stimulation;young adult;rotation;space perception	Gestures are common when people convey spatial information, for example, when they give directions or describe motion in space. Here, we examine the gestures speakers produce when they explain how they solved mental rotation problems (Shepard and Meltzer in Science 171:701–703, 1971). We asked whether speakers gesture differently while describing their problems as a function of their spatial abilities. We found that low-spatial individuals (as assessed by a standard paper-and-pencil measure) gestured more to explain their solutions than high-spatial individuals. While this finding may seem surprising, finer-grained analyses showed that low-spatial participants used gestures more often than high-spatial participants to convey “static only” information but less often than high-spatial participants to convey dynamic information. Furthermore, the groups differed in the types of gestures used to convey static information: high-spatial individuals were more likely than low-spatial individuals to use gestures that captured the internal structure of the block forms. Our gesture findings thus suggest that encoding block structure may be as important as rotating the blocks in mental spatial transformation.	marlyn meltzer	Tilbe Göksun;Susan Goldin-Meadow;Nora S. Newcombe;Thomas F. Shipley	2013	Cognitive Processing	10.1007/s10339-013-0549-1	psychology;developmental psychology;individualism;young adult;rotation;communication;gesture;social psychology	HCI	-6.542334246987249	-78.35279145515207	75276
9cbb1df07eed4c8c2bd26fe02a3310a4f11a6dac	improv chat: second response generation for chatbot		Existing research on response generation for chatbot focuses on First Response Generation which aims to teach the chatbot to say the first response (e.g. a sentence) appropriate to the conversation context (e.g. the user’s query). In this paper, we introduce a new task Second Response Generation, termed as Improv chat, which aims to teach the chatbot to say the second response after saying the first response with respect the conversation context, so as to lighten the burden on the user to keep the conversation going. Specifically, we propose a general learning based framework and develop a retrieval based system which can generate the second responses with the users’ query and the chatbot’s first response as input. We present the approach to building the conversation corpus for Improv chat from public forums and social networks, as well as the neural networks based models for response matching and ranking. We include the preliminary experiments and results in this paper. This work could be further advanced with better deep matching models for retrieval base systems or generative models for generation based systems as well as extensive evaluations in real-life applications.	artificial neural network;experiment;generative model;lotus improv;real life;social network	Furu Wei	2018	CoRR		generative grammar;machine learning;artificial intelligence;chatbot;natural language processing;conversation;artificial neural network;computer science;social network;sentence;ranking	NLP	-17.58714611757183	-68.55805681188667	75593
aef93f38419b6ed605130298106509c76349cf97	engagement recognition in spoken dialogue via neural network by aggregating different annotators' models		This paper addresses engagement recognition based on four multimodal listener behaviors backchannels, laughing, eyegaze, and head nodding. Engagement is an indicator of how much a user is interested in the current dialogue. Multiple third-party annotators give ground truth labels of engagement in a human-robot interaction corpus. Since perception of engagement is subjective, the annotations are sometimes different between individual annotators. Conventional methods directly use integrated labels, such as those generated through simple majority voting, and do not consider each annotator’s recognition. We propose a two-step engagement recognition where each annotator’s recognition is modeled and the different annotators’ models are aggregated to recognize the integrated label. The proposed neural network consists of two parts. The first part corresponds to each annotator’s model which is trained with the corresponding labels independently. The second part aggregates the different annotators’ models to obtain one integrated label. After each part is pre-trained, the whole network is fine-tuned through back-propagation of prediction errors. Experimental results show that the proposed network outperforms baseline models which directly recognize the integrated label without considering differing annotations.	artificial neural network;backpropagation;baseline (configuration management);ground truth;human–robot interaction;multimodal interaction;software propagation	Koji Inoue;Divesh Lala;Katsuya Takanashi;Tatsuya Kawahara	2018		10.21437/Interspeech.2018-2067	speech recognition;artificial neural network;machine learning;computer science;artificial intelligence	AI	-12.478104758327525	-71.58486923083821	75736
7d8a2efc4bc280d177780afba547e43a1bd9a5c4	type of iconicity matters: bias for action-based signs in sign language acquisition	social and behavioral sciences;sign language;sound symbolism;action;acquisition;perception;iconicity;article in monograph or in proceedings	Early studies investigating sign language acquisition claimed that signs whose structures are motivated by the form of their referent (iconic) are not favoured in language development. However, recent work has shown that the first signs in deaf children’s lexicon are iconic. In this paper we go a step further and ask whether different types of iconicity modulate learning sign-referent links. Results from a picture description task indicate that children and adults used signs with two possible variants differentially. While children signing to adults favoured variants that map onto actions associated with a referent (action signs), adults signing to another adult produced variants that map onto objects’ perceptual features (perceptual signs). Parents interacting with children used more action variants than signers in adult-adult interactions. These results are in line with claims that language development is tightly linked to motor experience and that iconicity can be a communicative strategy in parental input.	action potential;interaction;lexicon	Gerardo Ortega;Beyza Sümer;Asli Özyürek	2014			psychology;sign language;sound symbolism;linguistics;iconicity;communication;perception;cognitive science	HCI	-7.894254885018641	-78.92275984274525	76000
ca9698bccde3c13a3b32facebcb49401d97c2eac	do speaker's emotions influence their language production? studying the influence of disgust and amusement on alignment in interactive reference		The influence of emotion on (the early stages of) speech production processes, notably content selection has received little scholarly attention. Goudbeek & Krahmer (2012) found evidence for alignment at the conceptual level: speakers may start using a dispreferred attribute over a preferred attribute in their referring expressions when they are primed by a prerecorded female voice in a preceding interaction. The current study aimed to assess the role of emotion (using amusement and disgust) in alignment, while simultaneously replicating this finding in a more naturalistic setting involving two human participants in naturalistic dialogue. Our results replicate the findings by Goudbeek & Krahmer (2012), generalizing their findings to a much more naturalistic setting. In addition, we found that amused, but not disgusted speakers tend to use the preferred attribute more to describe objects to their conversational partner.	self-replicating machine	Charlotte Out;Martijn Goudbeek;Emiel Krahmer	2017			language production;amusement;psychology;social psychology;cognitive psychology;disgust;speech production	HCI	-8.476148884081221	-79.70288125874302	76215
10aa35986a0d58500b631ad8529e1afd0da531c1	saivt-admrg @ mediaeval 2014 social event detection		This paper outlines the approach taken by the Speech, Audio, Image and Video Technologies laboratory, and the Applied Data Mining Research Group (SAIVT-ADMRG) in the 2014 MediaEval Social Event Detection (SED) task. We participated in the event based clustering subtask (subtask 1), and focused on investigating the incorporation of image features as another source of data to aid clustering. In particular, we developed a descriptor based around the use of super-pixel segmentation, that allows a low dimensional feature that incorporates both colour and texture information to be extracted and used within the popular bag-of-visualwords (BoVW) approach.	cluster analysis;data mining;pixel;sound card	Simon Denman;David Dean;Clinton Fookes;Sridha Sridharan	2014			computer vision;speech recognition;computer science;multimedia	ML	-7.690517336822868	-69.29469221547883	76263
397b3cde0a434cd6019fab086735ce34d5571495	an application of array grammars to clustering analysis for syntactic patterns	analyse amas;grammaire tableau;classification;grammaire cf;analyse syntaxique;cluster analysis;context free grammar;syntactic analysis;pattern analysis;clasificacion;analyse forme;distance;procedure	"""-A new syntactic approach for clustering analysis using array grammars is introduced. Th,~ distance between an array and a core grammar characterizing a class of patterns is defined. It turns out this definition of distance is more satisfactory than a direct measurement between two arrays through error transformations. A 2-pass clustering procedure is proposed. This procedure does not require 2-dimensional arrays to be encoded into l-dimensional strings and it can obtain less confusion and more accurate results than some other methods in the literature. An example of classifying a set of English handwritten characters is illustrated. Finally, several interesting future research topics and open problems are discussed. Clustering analysis Array grammar Context-free array grammar Error transformation Pattern recognition Parsing Distance I. I N T R O D U C T I O N During the past decade there have appeared two approaches in dealing with pattern recognition problems, namely (i) the statistical approach ~t~ and (ii) the syntactic approach. ~2~*~ In the statistical (or decisiontheoretic, discriminant) approach, a pattern is represented by a vector called a feature vector. The similarity between two patterns can usually be expressed by a distance. Cluster analysis can be performed on a set of patterns on the basis of a selected similarity measure. The result of cluster analysis can then be used directly for pattern classification. In the syntactic (or linguistic, structural) approach, a pattern is represented by a sentence in a language. The sentence could be a string, a tree, a graph of pattern primitives and relations or an array. The emphasis of such a representation is on the structure of patterns, which is, in turn, described by the syntax or grammar of the language. Similar approaches can also be applied to the representation of linguistic sources and databases. A similarity measure between two syntactic patterns (represented as sentences) must include the similarities of both their structures and primitives. In Fu and Lu, ~ the use of a similarity measure for syntactic patterns in terms of grammar transformations is proposed and a nearest neighborhood rule and a clustering procedure are described. This clustering procedure is quite successful for 2-dimensional pattern analysis, especially for English characters. However, in this procedure, every character should be first encoded into a l-dimensional stringvia Freeman's chain code ~°~ and Shaw's PDL, 17~ and pattern 47 ~ is not accurately classified into group 2, D, even though weighted transformations are used with a threshold value as high as 3. In Lu (81 a tree-to-tree distance measurement algorithm is proposed and is applied to clustering analysis for 2-dimensional patterns. Again, in this algorithm, every pattern should be first encoded into a tree representation and, further, there are some confusions between A s ( A ) and E5 ( ~ ) and between E , ( ~ ) and C5 ( C' ). In this paper, we introduce a 2-pass clustering procedure using isometric context-free array grammars (ICFAG), (9-t t) which overcome the above mentioned problems. An array grammar, first proposed by Kirsch,tt 2i is a pattern generating device, which can be considered as an extended Chomsky phrase structure grammar (t'31 such that each rewriting rule is 2dimensional and isometric (i.e. geometrically identical). A survey of array grammar, its history and development can be found in Rosenfeld. c1°) An application of the proposed procedure to 2-dimensional pattern clustering analysis is illustrated through an example. We adapt the definitions and notations from Cook and Wang, (9) Hopcroft and Ullman """"3) and Wang."""" ~) 2. D E F I N I T I O N S AND N O T A T I O N S Definition 2.1 An isometric array grammar ~9~ is a quintuple G = (V ~, V r, P, S, #), where V x is a finite nonempty set of nonterminal symbols, V.r is a finite nonempty set of terminal symbols, V N c~ V.v = 0and # ~(VN w V-r)is the background or blank symbol. P is a finite nonempty .set of rewriting rules of the form a~[3, where arrays ~ and ~ are geometrically identical over VNwV,r • {#} : c t not all # 's. S e N is the starting symbol. We say that array x directly generates array y, 441 442 PATRICK SHI~N-PEI WANG denoted x ~ y, if there is a rewriting rule ~t --* fl, x contains ~t as a subarray and y is identical to x except that the subarray ct is replaced with the corresponding symbols of the array ft. Let * be the reflexive transitive closure of =:-. The language generated by an array grammar G, denoted L(G), is the set of all arrays of terminal symbols and # ' s that can be generated from the starting symbol S in a field of #'s. Definition 2.2 Let G = (V~, V~ P, S, # ) be an isometric array grammar. (1) G is of Type 0 if there are no restrictions on P. (2) G is of Type 1 or monotonic if both sides of each rule are connected and the image ofeach left-side symbolin VN u V r is in VN u Vr; i.e. # ' s cannot be created. (3) G is Type 2 or context-free if the right side of each rule is connected, the left side contains exactly one nonterminal symbol in a field of # ' s and the image of every symbol is in V N u V r. (4) G is of Type 3 or regular ifevery rewriting rule is of the form # B A a # B , ~ B , A ,a , # A ~ Ba, A # --* aB, A a # A a # A B # --*B , A ~ a ~ o r A ~ a # B ' a where A and B are nonterminal symbols and a is a terminal symbol. Let IAG, IAL, IMAG, IMAL, ICFAG, ICFAL, IRAG and IRAL denote the isometric, isometric monotonic, isometric context-free and isometric regular array grammars and languages, respectively. Example 2.1. Le t G = ({S, S~, $2, Sa}, {a}, P, S, # ) S a Where P 1. -,.I. # S~"""	algol 58;array data structure;chain code;chomsky hierarchy;cluster analysis;context-free grammar;context-free language;database;discriminant;feature vector;formal grammar;graph coloring;iag;isometric projection;lu decomposition;language primitive;louis rosenfeld;parsing expression grammar;pattern recognition;perl data language (pdl);phrase structure grammar;phrase structure rules;rewriting;sethi–ullman algorithm;similarity measure;string (computer science);terminal and nonterminal symbols;the sentence;transitive closure;tree (data structure)	Patrick Shen-Pei Wang	1984	Pattern Recognition	10.1016/0031-3203(84)90073-6	natural language processing;procedure;speech recognition;biological classification;computer science;machine learning;parsing;pattern recognition;cluster analysis;context-free grammar;distance;algorithm	NLP	-15.013236923433032	-78.87933604639323	76381
a05bbb60c5cb29f429859201bc4ae5b75432c06d	label ranking forests		Expert Systems 2016; 1–8 Abstract The problem of Label Ranking is receiving increasing attention from several research communities. The algorithms that have been developed/adapted to treat rankings of a fixed set of labels as the target object, including several different types of decision trees (DT). One DT‐based algorithm, which has been very successful in other tasks but which has not been adapted for label ranking is the Random Forests (RF) algorithm. RFs are an ensemble learning method that combines different trees obtained using different randomization techniques. In this work, we propose an ensemble of decision trees for Label Ranking, based on Random Forests, which we refer to as Label Ranking Forests (LRF). Two different algorithms that learn DT for label ranking are used to obtain the trees. We then compare and discuss the results of LRF with standalone decision tree approaches. The results indicate that the method is highly competitive.		Cláudio Rebelo de Sá;Carlos Soares;Arno J. Knobbe;Paulo Cortez	2017	Expert Systems	10.1111/exsy.12166	data mining;computer science;internationalization;science, technology and society;operations research;european regional development fund;random forest;decision tree;functional testing (manufacturing);portuguese;ranking	ML	-9.372511985984222	-67.42206547365845	76485
f04b3954724300e0ce1bc83ca840fe0324682bec	estimating user interest from open-domain dialogue		Dialogue personalization is an important issue in the field of open-domain chatoriented dialogue systems. If these systems could consider their users’ interests, user engagement and satisfaction would be greatly improved. This paper proposes a neural network-based method for estimating users’ interests from their utterances in chat dialogues to personalize dialogue systems’ responses. We introduce a method for effectively extracting topics and user interests from utterances and also propose a pre-training approach that increases learning efficiency. Our experimental results indicate that the proposed model can estimate user’s interest more accurately than baseline approaches.	artificial neural network;baseline (configuration management);dialog system;encoder;experiment;informatics;personalization;statistical classification	Michimasa Inaba;Kenichi Takahashi	2018			natural language processing;artificial intelligence;computer science	NLP	-15.588210859708875	-71.74406531064226	76567
e050cd9cec5eed73bd56cb2c9726ea85e985384b	incremental sentence compression using lstm recurrent networks	sentence compression;text analysis data compression recurrent neural nets;long short term memory sentence compression recurrent neural network;transduction model incremental sentence compression technique lstm recurrent networks dependency tree representation long short term memory recurrent neural networks rnn parameters;recurrent neural network;speech recurrent neural networks training real time systems logic gates training data speech recognition;long short term memory	Many of the current sentence compression techniques attempt to produce a shortened form of a sentence by relying on syntactic structure such as dependency tree representations. While the performance of sentence compression has been improving, these approaches require a full parse of the sentence before performing sentence compression, making it difficult to perform compression in real time. In this paper, we examine the possibilities of performing incremental sentence compression using long short-term memory (LSTM) recurrent neural networks (RNN). The decision of whether to remove a word is done at each time step, without waiting for the end of the sentence. Various RNN parameters are investigated, including the number of layers and network connections. Furthermore, we also propose using a pretraining method in which the network is pretrained as an autoencoder. Experimental results reveal that our method obtains compression rates similar to human references and a better accuracy than the state-of-the-art tree transduction models.	artificial neural network;autoencoder;long short-term memory;parsing;random neural network;recurrent neural network;transduction (machine learning)	Sakriani Sakti;Faiz Ilham;Graham Neubig;Tomoki Toda;Ayu Purwarianti;Satoshi Nakamura	2015	2015 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU)	10.1109/ASRU.2015.7404802	natural language processing;speech recognition;computer science;recurrent neural network;machine learning;long short term memory	NLP	-17.447034320445177	-74.82271463846608	76630
01e38e1824b4fc5da2801d32b185a93a08581e34	constructing information networks using one single model		In this paper, we propose a new framework that unifies the output of three information extraction (IE) tasks entity mentions, relations and events as an information network representation, and extracts all of them using one single joint model based on structured prediction. This novel formulation allows different parts of the information network fully interact with each other. For example, many relations can now be considered as the resultant states of events. Our approach achieves substantial improvements over traditional pipelined approaches, and significantly advances state-of-the-art end-toend event argument extraction.	ace;information extraction;programming paradigm;resultant;sparse matrix;structured prediction	Qi Li;Heng Ji;Yu Hong;Sujian Li	2014		10.3115/v1/D14-1198	natural language processing;computer science;theoretical computer science;machine learning;data mining	NLP	-18.128033479520987	-71.73421785554302	76699
7c1576b96a1e246d77b30f7b80cec63be96fa698	making neural qa as simple as possible but not simpler		Recent development of large-scale question answering (QA) datasets triggered a substantial amount of research into end-toend neural architectures for QA. Increasingly complex systems have been conceived without comparison to simpler neural baseline systems that would justify their complexity. In this work, we propose a simple heuristic that guides the development of neural baseline systems for the extractive QA task. We find that there are two ingredients necessary for building a high-performing neural QA system: first, the awareness of question words while processing the context and second, a composition function that goes beyond simple bag-of-words modeling, such as recurrent neural networks. Our results show that FastQA, a system that meets these two requirements, can achieve very competitive performance compared with existing models. We argue that this surprising finding puts results of previous systems and the complexity of recent QA datasets into perspective.	artificial neural network;bag-of-words model;baseline (configuration management);complex systems;heuristic;question answering;recurrent neural network;requirement	Dirk Weissenborn;Georg Wiese;Laura Seiffe	2017		10.18653/v1/K17-1028	interrogative word;natural language processing;artificial intelligence;computer science;complex system;machine learning;question answering;recurrent neural network;heuristic	NLP	-18.00329314088783	-72.57571679396017	76856
7862150ab228b45d804bd9b46cef48b184f0ca30	semi-supervised and transfer learning approaches for low resource sentiment classification		Sentiment classification involves quantifying the affective reaction of a human to a document, media item or an event. Although researchers have investigated several methods to reliably infer sentiment from lexical, speech and body language cues, training a model with a small set of labeled datasets is still a challenge. For instance, in expanding sentiment analysis to new languages and cultures, it may not always be possible to obtain comprehensive labeled datasets. In this paper, we investigate the application of semi- supervised and transfer learning methods to improve performances on low resource sentiment classification tasks. We experiment with extracting dense feature representations, pre-training and manifold regularization in enhancing the performance of sentiment classification systems. Our goal is a coherent implementation of these methods and we evaluate the gains achieved by these methods in matched setting involving training and testing on a single corpus setting as well as two cross corpora settings. In both the cases, our experiments demonstrate that the proposed methods can significantly enhance the model performance against a purely supervised approach, particularly in cases involving a handful of training data.	2.5d;coherence (physics);computer multitasking;cross-validation (statistics);domain adaptation;experiment;manifold regularization;matrix regularization;parsing expression grammar;performance;semi-supervised learning;semiconductor industry;sentiment analysis;sparse matrix;statistical classification;supervised learning;text corpus	Rahul Gupta;Saurabh Sahu;Carol Y. Espy-Wilson;Shrikanth (Shri) Narayanan	2018	2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2018.8461414	task analysis;body language;transfer of learning;sentiment analysis;feature extraction;small set;artificial intelligence;training set;data modeling;pattern recognition;computer science	NLP	-17.702415018408637	-69.20235043813825	76988
88a38c33d2207524e3c42203f46c2fd2e77edd49	overview of the epigenetics and post-translational modifications (epi) task of bionlp shared task 2011	dna modification event;shared task;post-translational modifications;speculatively stated event instance;main task;bionlp shared task;task concern;epi task;core event argument;post-translational modification;full task	This paper presents the preparation, resources, results and analysis of the Epigenetics and Post-translational Modifications (EPI) task, a main task of the BioNLP Shared Task 2011. The task concerns the extraction of detailed representations of 14 protein and DNA modification events, the catalysis of these reactions, and the identification of instances of negated or speculatively stated event instances. Seven teams submitted final results to the EPI task in the shared task, with the highest-performing system achieving 53% F-score in the full task and 69% F-score in the extraction of a simplified set of core event arguments.	biomedical text mining;f1 score	Tomoko Ohta;Sampo Pyysalo;Jun'ichi Tsujii	2011			real-time computing;simulation;computer science;communication	NLP	-6.476409758357	-66.88025755559993	77009
d1cdc32e8fff6c3c1f62951c906279930a7ee790	reproducing a neural question answering architecture applied to the squad benchmark dataset: challenges and lessons learned		Reproducibility is one of the pillars of scientific research. This study attempts to reproduce the Gated Self-Matching Network, which is the basis of one of the best performing models on the SQuAD dataset. We reimplement the neural network model and highlight ambiguities in the original architectural description. We show that due to uncertainty about only two components of the neural network model and no precise description of the training process, it is not possible to reproduce the experimental results obtained by the original implementation. Finally we summarize what we learned from this reproduction process about writing precise neural network architecture descriptions, providing our implementation as a basis for future exploration.	benchmark (computing);question answering	Alexander Dür;Andreas Rauber;Peter Filzmoser	2018		10.1007/978-3-319-76941-7_8	data mining;artificial neural network;architecture;scientific method;computer science;question answering	AI	-14.759526017123399	-73.37051466673792	77028
ccc814f0adff047f47f50bde92f59653a969f56f	feel between the lines: implied emotion in sentence comprehension	article letter to editor	This study investigated the brain regions for the comprehension of implied emotion in sentences. Participants read negative sentences without negative words, for example, “The boy fell asleep and never woke up again,” and their neutral counterparts “The boy stood up and grabbed his bag.” This kind of negative sentence allows us to examine implied emotion derived at the sentence level, without associative emotion coming from word retrieval. We found that implied emotion in sentences, relative to neutral sentences, led to activation in some emotion-related areas, including the medial prefrontal cortex, the amygdala, and the insula, as well as certain language-related areas, including the inferior frontal gyrus, which has been implicated in combinatorial processing. These results suggest that the emotional network involved in implied emotion is intricately related to the network for combinatorial processing in language, supporting the view that sentence meaning is more than simply concatenating the meanings of its lexical building blocks.	amygdaloid structure;concatenation;frontal lobe gyrus;inferior frontal gyrus;insula of reil;list comprehension;medial graph;prefrontal cortex;sentence	Vicky Tzuyin Lai;Roel M. Willems;Peter Hagoort	2015	Journal of Cognitive Neuroscience	10.1162/jocn_a_00798	psychology;cognitive psychology;linguistics;communication	NLP	-9.21590081350322	-77.93464834539435	77101
272ac3cd83b70daf1ab0812f741996bd285ea9df	r.h. stetson, motor phonetics: a study of speech movements in action, 2nd ed., amsterdam, north holland publishing co., 1951		The study of the interplay between speech and pausing for breathing has been a matter of investigation for several decades since the pioneering work by Stetson (1951). In spite of the amount of research accomplished over the decades, the issue of the coordination of speech rhythm and breathing has not been satisfactorily and exhaustively addressed by now. However, with the availability for the speech community, since the seventies, of less invasive techniques for tracking breath movements (Hixon et al., 1976; Gelfer et al., 1986), new research possibilities opened up to explore breathing patterns in deeper ways. Due to the availability of equipments, a regain of interest in studying the interplay between speech and pausing for breathing is taking place. Among the claims and findings of research works exploring breathing patterns in the last few decades, some are worth mentioning because they provide evidence of the evolution of thinking about the issue. In the sixties, Henderson et al. (1965) claimed that “reading breaths are taken exclusively at grammatical junctures” and that “pauses in reading serve a different function from pauses in spontaneous speech” (p. 242). This suggests that the preplanning of the respiratory activity would be dictated by the linguistic-prosodic organization of the utterance and that this preplanning is potentially different for distinct speaking styles. In the seventies, Grosjean and Collins (1979) confirmed, in a more elaborate experimental design, that “at slow and normal rates, speakers accommodate their need to inhale to the preplanned pause patterns” (p. 98). More recently, a study by Fuchs et al. (2008) showed that inhalation is not the only movement that explains the coordination between speech and breathing movements. They claim that “thoracic/abdominal volume change during sentence production is only partly anticipated via inhalation depth” (p. 80). In other words, thoracic/abdominal volume changes also depend on factors such as emphasis degree on a lexical item, final lengthening among others. They also conclude that some speakers make use of the expiratory reserve volume for producing longer sentences, suggesting that “there are some limits on how many words/syllables can be anticipated in a preceding pause” Phonetica 2017;74:255–258 DOI: 10.1159/000477624	chest;design of experiments;digital object identifier;eighty;expiration, function;halitosis;inspiration function;linguistics;movement;neuritis, autoimmune, experimental;phonetics;portion of respiratory air;speaking (activity);speech synthesis;spontaneous order;syllable;word lists by frequency;sentence	Plínio A. Barbosa	2017	Phonetica	10.1159/000477624	speech recognition;cognitive science;linguistics;psychology;publishing;phonetics	NLP	-10.105714215329062	-79.85119150933106	77244
9fd3ebabba15d6191d662d29c3b53f2555bea49d	a hassle-free unsupervised domain adaptation method using instance similarity features		We present a simple yet effective unsupervised domain adaptation method that can be generally applied for different NLP tasks. Our method uses unlabeled target domain instances to induce a set of instance similarity features. These features are then combined with the original features to represent labeled source domain instances. Using three NLP tasks, we show that our method consistently outperforms a few baselines, including SCL, an existing general unsupervised domain adaptation method widely used in NLP. More importantly, our method is very easy to implement and incurs much less computational cost than SCL.	algorithmic efficiency;computation;domain adaptation;natural language processing;structured text;unsupervised learning	Jianfei Yu;Jing Jiang	2015			machine learning;pattern recognition	NLP	-17.661946401148132	-66.71580520808044	77350
256da4dee1258d8a128262c9a1bb9aaa7f385696	limsi submission for wmt'17 shared task on bandit learning		This paper describes LIMSI participation to the WMT’17 shared task on Bandit Learning. The method we propose to adapt a seed system trained on out-domain data to a new, unknown domain relies on two components. First, we use a linear regression model to exploit the weak and partial feedback the system receives by learning to predict the reward a translation hypothesis will get. This model can then be used to score hypotheses in the search space and translate source sentences while taking into account the specificities of the in-domain data. Second, we use the UCB1 algorithm to choose which of the ‘adapted’ or ‘seed’ system must be used to translate a given source sentence in order to maximize the cumulative reward. Results on the development and train sets show that the proposed method does not succeed in improving the seed system. We explore several hypotheses to explain this negative result.	algorithm	Guillaume Wisniewski	2017			natural language processing;knowledge management;artificial intelligence;computer science	NLP	-16.004164199132607	-74.69935806196891	77526
05233d2226237bab2d4cb670443863514ed61fea	the role of conversation context for sarcasm detection in online interactions		Computational models for sarcasm detection have often relied on the content of utterances in isolation. However, speaker’s sarcastic intent is not always obvious without additional context. Focusing on social media discussions, we investigate two issues: (1) does modeling of conversation context help in sarcasm detection and (2) can we understand what part of conversation context triggered the sarcastic reply. To address the first issue, we investigate several types of Long Short-Term Memory (LSTM) networks that can model both the conversation context and the sarcastic response.1 We show that the conditional LSTM network (Rocktäschel et al., 2015) and LSTM networks with sentence level attention on context and response outperform the LSTM model that reads only the response. To address the second issue, we present a qualitative analysis of attention weights produced by the LSTM models with attention and discuss the results compared with human performance on the task.	darpa grand challenge;human reliability;interaction;long short-term memory;social media	Debanjan Ghosh;Alexander Richard Fabbri;Smaranda Muresan	2017			machine learning;artificial intelligence;conversation;natural language processing;computer science;sarcasm;computational model;social media;sentence	NLP	-15.331204918691471	-72.41444861083139	77680
a2aae7232ad516e6ad356c10ce20956f2e9380bc	deep collective inference		Moore, John A. MS, Purdue University, December 2016. Deep Collective Inference. Major Professor: Jennifer Neville. Collective inference is widely used to improve classification in network datasets. However, despite recent advances in deep learning and the successes of recurrent neural networks (RNNs), researchers have only just recently begun to study how to apply RNNs to heterogeneous graph and network datasets. There has been recent work on using RNNs for unsupervised learning in networks (e.g., graph clustering, node embedding) and for prediction (e.g., link prediction, graph classification), but there has been little work on using RNNs for node-based relational classification tasks. In this paper, we provide an end-to-end learning framework using RNNs for collective inference. Our main insight is to transform a node and its set of neighbors into an unordered sequence (of varying length) and use an LSTM-based RNN to predict the class label as the output of that sequence. We develop a collective inference method, which we refer to as Deep Collective Inference (DCI), that uses semi-supervised learning in partially-labeled networks and two label distribution correction mechanisms for imbalanced classes. We compare to several alternative methods on seven network datasets. DCI achieves up to a 12% reduction in error compared to the best alternative and a 25% reduction in error on average over all methods, for all label proportions.	artificial neural network;cluster analysis;data, context and interaction;deep learning;digitally controlled impedance;end-to-end principle;long short-term memory;random neural network;recurrent neural network;relational data mining;semi-supervised learning;semiconductor industry;supervised learning;unsupervised learning	John Moore;Jennifer Neville	2017			long short term memory;machine learning;artificial intelligence;applied science;computer science;deep learning;statistical relational learning;inference	AI	-10.638095085566583	-67.48174342317131	77932
5accbcb88b28bd2a6d807302924009c7e8eb9508	developmental stages of perception and language acquisition in a perceptually grounded robot	grammatical construction;robotics;language acquisition;spatial relation;machine learning;event perception;language learning;language;neural network	The objective of this research is to develop a system for language learning based on a ‘‘minimum’’ of pre-wired language-specific functionality, that is compatible with observations of perceptual and language capabilities in the human developmental trajectory. In the proposed system, meaning (in terms of descriptions of events and spatial relations) is extracted from video images based on detection of position, motion, physical contact and their parameters. Meaning extraction requires attentional mechanisms that are implemented from low-level perceptual primitives. Mapping of sentence form to meaning is performed by learning grammatical constructions, i.e., sentence to meaning mappings as defined by Goldberg [Goldberg, A. (1995). Constructions. Chicago and London: Univ. of Chicago Press]. These are stored and retrieved from a ‘‘construction inventory’’ based on the constellation of grammatical function words uniquely identifying the target sentence structure. The resulting system displays robust acquisition behavior that reproduces certain observations from developmental studies, with very modest ‘‘innate’’ language specificity. 2004 Published by Elsevier B.V.	high- and low-level;natural language processing;robot;sensitivity and specificity	Peter Ford Dominey;Jean-David Boucher	2005	Cognitive Systems Research	10.1016/j.cogsys.2004.11.005	language acquisition;cognitive psychology;natural language processing;computer science;artificial intelligence;machine learning;linguistics;robotics;communication;artificial neural network;cognitive science	NLP	-5.786997154908243	-77.08883726911698	78245
4e5ea97fb238c2741feab112fbd1e4fb34745b5e	university of texas at austin kbp 2013 slot filling system: bayesian logic programs for textual inference		This document describes the University of Texas at Austin 2013 system for the Knowledge Base Population (KBP) English Slot Filling (SF) task. The UT Austin system builds upon the output of an existing relation extractor by augmenting relations that are explicitly stated in the text with ones that are inferred from the stated relations using probabilistic rules that encode commonsense world knowledge. Such rules are learned from linked open data and are encoded in the form of Bayesian Logic Programs (BLPs), a statistical relational learning framework based on directed graphical models. In this document, we describe our methods for learning these rules, estimating their associated weights, and performing probabilistic and logical inference to infer unseen relations. In the KBP SF task, our system was able to infer several unextracted relations, but its performance was limited by the base level extractor.	commonsense knowledge (artificial intelligence);encode;graphical model;knowledge base;linked data;randomness extractor;statistical relational learning	Yinon Bentor;Amelia Harrison;Shruti Bhosale;Raymond J. Mooney	2013			data mining;probabilistic logic;computer science;natural language processing;knowledge base;linked data;artificial intelligence;statistical relational learning;population;inference;graphical model;bayesian probability	NLP	-14.306119949473846	-66.51463327649321	78309
ad8d0432bdc1fcefbd7ebc8badea8aceec16fbdf	video captioning with semantic guiding		Video captioning is to generate descriptions of videos. Most existing approaches adopt the encoder-decoder architecture, which usually use different kinds of visual features, such as temporal features and motion features, but they neglect the abundant semantic information in the video. To address this issue, we propose a framework that jointly explores visual features and semantic attributions named Semantic Guiding Long Short-Term Memory (SG-LSTM). The proposed SG-LSTM has two semantic guiding layers, both of them use three types of semantic - global semantic, object semantic and verb semantic - attributes to guide language model to use the most relevant representation to generate sentences. We evaluate our method on the public available challenging Youtube2Text dataset. Experimental results shown that our framework outperforms the state-of-the-art methods.	encoder;language model;long short-term memory;suicidegirls;video	Jin Yuan;Chunna Tian;Xiangnan Zhang;Yuxuan Ding;Wei Wei	2018	2018 IEEE Fourth International Conference on Multimedia Big Data (BigMM)	10.1109/BigMM.2018.8499357	natural language processing;architecture;feature extraction;visualization;language model;semantics;verb;closed captioning;computer science;artificial intelligence	Vision	-15.15883683080223	-69.38288044318642	78752
a00a3880d248442eda0329815d676f8a1e5f638c	domain specific feature transfer for hybrid domain adaptation		Heterogeneous domain adaptation needs supplementary information to link up domains. However, this supplementary information is unavailable in many real cases. In this paper, a new problem setting called hybrid domain adaptation is investigated. It is a special case of heterogeneous domain adaptation in which different domains share some common features, but also have their own domain specific features. In this case, it can be efficiently solved without any supplementary information by using the common features to link up the domains in adaptation. We propose a domain specific feature transfer (DSFT) method, which can link up different domains using the common features and simultaneously reduce domain divergences. Specifically, we first learn the translations between the common features and the domain specific features. Then we cross-use the learned translations to transfer the domain specific features of one domain to another domain. Finally, we compose a homogeneous space in which the domain divergences are minimized. Extensive experiments verify the effectiveness of our proposed method.	domain adaptation;domain-specific language	Pengfei Wei;Yiping Ke;Chi-Keong Goh	2017		10.1109/ICDM.2017.133	sentiment analysis;kernel (linear algebra);artificial intelligence;machine learning;computer science;homogeneous space;domain adaptation;linear programming;special case	NLP	-17.127541219173164	-66.75648575013129	79248
afa692db6844852d2566cfa65f24428745248a65	sequential attention: a context-aware alignment function for machine reading		In this paper we propose a neural network model with a novel Sequential Attention layer that extends soft attention by assigning weights to words in an input sequence in a way that takes into account not just how well that word matches a query, but how well surrounding words match. We evaluate this approach on the task of reading comprehension (on the Who did What and CNN datasets) and show that it dramatically improves a strong baseline—the Stanford Reader—and is competitive with the state of the art.	artificial neural network;baseline (configuration management);bilinear filtering;machine translation;natural language understanding;network model;random neural network;search engine optimization;smith–waterman algorithm;software release life cycle;squad	Sebastian Brarda;Philip Yeres;Samuel R. Bowman	2017			artificial intelligence;natural language processing;machine learning;artificial neural network;computer science;reading comprehension	NLP	-18.445989930920977	-72.62419174179779	79347
109125ea7af29df7aa86903069d247ccba98f408	field-effect natural language semantic mapping	natural language interfaces;front end;natural languages acceleration robots containers impedance humans machine learning multimedia systems information systems distributed computing;computational linguistics natural languages natural language interfaces knowledge based systems learning artificial intelligence;rule based;natural language semantics;natural languages;semantic mapping;machine learning;random process;natural language;computational linguistics field effect natural language mapping semantic mapping process rule based randomization semantic normalization robots lift container grab container learning;normal form;computational linguistics;learning artificial intelligence;knowledge based systems	This paper addresses the problem of mapping natural language to its semantics. It presupposes that the input is in random (compressed) form and proceeds to detail a methodology for extracting the semantics from that normal form. The idea is to enumerate contextual cues and learn to associate those cues with meaning. The process is inherently fuzzy and for this reason is also inherently adaptive in nature. It is shown that the influence of context on meaning grows exponentially with the length of a word sequence. This suggests that rule-based randomization plays a key role in rendering a field-effect natural language semantic mapping tractable. An example of rule-based randomization for semantic normalization is as follows. Suppose that two commands to a robot are deemed to be equivalent; namely, “Grasp and pick up the glass” and “Hold the cup and raise it”. Their mutual normalization might then be, “Grab container. Lift container.” Clearly, the randomization process can be effected by rules. Also, the normalized syntax makes the result of any semantic mapping process – such as detailed herein – more efficient. A natural language front-end is described, which is designed to reduce the impedance mismatch between the human and the machine. Most significantly, the effective translation of natural language semantics is shown to critically depend on an accelerated capability for learning.	characteristic impedance;cobham's thesis;computing with words and perceptions;context-sensitive grammar;data compression;effective method;enumerated type;impedance matching;logic programming;natural language;natural language understanding;robot;semantic mapper	Stuart Harvey Rubin;Shu-Ching Chen;Mei-Ling Shyu	2003		10.1109/ICSMC.2003.1244256	natural language processing;semantic role labeling;semantic similarity;computer science;artificial intelligence;computational linguistics;machine learning;semantic compression;natural language	AI	-10.450347103090055	-72.46043366643947	79608
38ac0030ad65ceedb83a5b4e1d9b6b4a55a5b837	multimodal computational attention for scene understanding			computation;multimodal interaction	Boris Schauerte	2014				ML	-8.423999973353014	-69.92762028953294	79670
778211c0111968a8cebd9e1a1802465cdd9b66a0	modeling cue phrases in turkish: a case study	cued speech;noun;noun phrase;text summarization;tratamiento lenguaje;langage parle complete;language processing;turc;traitement langage;natural language processing	Cue phrases are lexical units that carry various signals within discourse to phenomena such as discourse relation detection. Their characterization have been found to be helpful in practical Natural Language Processing systems including dialogue planning agents and text summarizers.#R##N##R##N#A corpus based study of cue phrases in Turkish is to be presented. The results show that there is no significant tendency in sentences with cue phrases that have a noun full noun phrase subject to be followed by sentences with null subject sentences. Variations of this result is explained in the article.		Bilge Say	1999		10.1007/3-540-48239-3_62	natural language processing;noun;cued speech;noun phrase;speech recognition;computer science;automatic summarization;specifier;linguistics	NLP	-12.120285879644891	-79.93332960862281	79759
e09796ffe643a716697beada353c10dd60163ab8	context-aware answer sentence selection with hierarchical gated recurrent neural networks		In this paper, we study the task of reading comprehension style answer sentence selection that aims to select the best sentence from a given passage to answer a question. Unlike most previous works that match the question and each candidate sentence separately, we observe that the context information among sentences in the same passage plays a vital role in this task. We propose modeling context information with hierarchical gated recurrent neural networks. Specifically, we first apply a word level recurrent neural network to model the context independent matching between the question and each candidate sentence. We then employ a sentence level recurrent neural network to incorporate the context information among all candidate sentences. Moreover, we introduce the gate mechanism to select matching information before feeding into recurrent neural networks at both word and sentence level. Experiments on the WikiQA and SQuAD datasets show that our model outperforms state-of-the-art methods.	artificial neural network;experiment;neural networks;recurrent neural network	Chuanqi Tan;Furu Wei;Qingyu Zhou;Nan Yang;Bowen Du;Weifeng Lv;Ming Zhou	2018	IEEE/ACM Transactions on Audio, Speech, and Language Processing	10.1109/TASLP.2017.2785283	artificial intelligence;computer science;pattern recognition;semantics;recurrent neural network;logic gate;context model;sentence;reading comprehension	NLP	-16.5710868871899	-71.38615995714359	79979
f5480bcd2c76c7a369b499b2ca07706c57722fcf	learning api suggestion via single lstm network with deterministic negative sampling			long short-term memory	Jinpei Yan;Yong Qi;Qifan Rao;Hui He	2018		10.18293/SEKE2018-193	data mining;sampling (statistics);computer science	Vision	-16.07980113823316	-74.92732313735337	80072
20d90871bc0dc7956bf2557d91d8d96deb0a4520	question selection for crowd entity resolution	question selection;approximation technique;best question;highest expected accuracy;expected accuracy;high er accuracy;clustering record;er accuracy;entity resolution;crowd entity resolution;accurate result;best question algorithm	We study the problem of enhancing Entity Resolution (ER) with the help of crowdsourcing. ER is the problem of clustering records that refer to the same real-world entity and can be an extremely di cult process for computer algorithms alone. For example, figuring out which images refer to the same person can be a hard task for computers, but an easy one for humans. We study the problem of resolving records with crowdsourcing where we ask questions to humans in order to guide ER into producing accurate results. Since human work is costly, our goal is to ask as few questions as possible. We propose a probabilistic framework for ER that can be used to estimate how much ER accuracy we obtain by asking each question and select the best question with the highest expected accuracy. Computing the expected accuracy is #P-hard, so we propose approximation techniques for e cient computation. We evaluate our best question algorithms on real and synthetic datasets and demonstrate how we can obtain high ER accuracy while significantly reducing the number of questions asked to humans.	algorithm;approximation;approximation algorithm;cluster analysis;computation;computer;crowdsourcing;erdős–rényi model;humans;p (complexity);polynomial;sharp-p;synthetic intelligence;time complexity;wisdom of the crowd	Steven Euijong Whang;Peter Lofgren;Hector Garcia-Molina	2013	PVLDB	10.14778/2536336.2536337	computer science;artificial intelligence;data science;data mining;database	DB	-13.328144560942556	-66.21866675880737	80129
11c4d055b6b36599aee584b531d26627614f1667	why no mere mortal has ever flown out to center field	grammar;representation;critical study;noun;connectionism;etude experimentale;conexionismo;estructura;lenguaje;semantics;langage;etude critique;semantica;semantique;lexicons;estudio critico;connexionnisme;modelo;phonology;grammaire;cognition;cognicion;fonologia;modele;phonologie;language;lexico;estudio experimental;structure;models;gramatica;representacion;lexique	The English past tense system has recently been used to argue that formal grammatical categories (such as root. rule, and lexical item) may not be necessary to explain the acquisition and knowledge of language. Rumelhart and McClelland (1986) devised a connectionist model relying solely on phonological information; it is often suggested that any deficiencies of such a model can be remedied by supplying it with semantic information. These proposals are incorrect: Grammatical categories and abstract morphological structure are indispensable and cannot be replaced with semantics while preserving the patterns of psychological generalization in the system. Linguists have noted that irregular past tense mappings (e.g., fly/flew; stick/stuck) apply only when a verb’s root is marked in the lexicon as having an irregular past. Because nouns are never so marked, verbs with noun roots-denominal verbs-are regular even if they are phonologically identical to irregular verbs, hence: flied out/‘flew auf to center field; h/gh-sficked/*highstuck the goalie. Experiment 1 shows that adult subjects are highly sensitive to this principle when rating regular and irregular past tense forms of navel versions of irregular sounding verbs: New verbs formed from nouns were judged as better with a regular past tense (e.g., line-drived was the preferred past of “to hit a line drive”); new verbs formed from verbs were judged as better with an irregular post tense (e.g.. line-drove was the preferred past of “to drive along a line”).	automatic sounding;connectionism;lexicon	John J. Kim;Steven Pinker;Alan Price;Sandeep Prasada	1991	Cognitive Science	10.1207/s15516709cog1502_1	psychology;natural language processing;noun;structure;connectionism;cognition;modal verb;grammar;mathematics;semantics;linguistics;language;communication;representation;phonology	NLP	-11.49606452743931	-76.28362329135858	80145
c983aebcf622d79dc012e4a6fcaed25bc9d4fb17	inducing semantic micro-clusters from deep multi-view representations of novels		Automatically understanding the plot of novels is important both for informing literary scholarship and applications such as summarization or recommendation. Various models have addressed this task, but their evaluation has remained largely intrinsic and qualitative. Here, we propose a principled and scalable framework leveraging expert-provided semantic tags (e.g., mystery, pirates) to evaluate plot representations in an extrinsic fashion, assessing their ability to produce locally coherent groupings of novels (micro-clusters) in model space. We present a deep recurrent autoencoder model that learns richly structured multi-view plot representations, and show that they i) yield better microclusters than less structured representations; and ii) are interpretable, and thus useful for further literary analysis or labelling of the emerging micro-clusters.	autoencoder;cluster analysis;coherence (physics);digital humanities;encode;expression (computer science);holism;loss function;optimization problem;parallels desktop for mac;preprocessor;scalability;technical support;verification and validation	Lea Frermann;György Szarvas	2017			computer science;natural language processing;artificial intelligence;machine learning;cluster (physics)	NLP	-16.611109143083738	-69.85989566534894	80196
11644d18e2541a722ccbc24e3dad6e370ad56d44	eyes never lie!: hand eye coordination patterns analysis for text-graph separation		Free-form handwritten documents contain a high diversity of content. The task of separating text from non-text strokes is of crucial importance towards interpretation of such documents. We investigated the hand eye interaction by focusing on the instantaneous distance between each sketch-gaze pair, as well as the distribution, aggregation of gaze points, in the condition of drawing text or non-text, in order to propose an innovative approach to helping the text-graph separation. The experimental result showed that three different hand-eye coordination patterns truly exist between text and non-text drawings, which suggested a novel way for text-graph separation.	interpretation (logic);sketch recognition;text graph;verification and validation;vertex (graph theory)	Xiaoyan Zhao;Beibei Chao;Wei Hu;Guihuan Feng;Bing Luo	2017		10.1145/3080631.3080641	eye–hand coordination;gaze;text graph;artificial intelligence;computer vision;handwriting;computer science	ML	-10.138505897874568	-68.62513437511231	80256
d691e1c19379d62a88309bf6bfe6cd8fa85b6d14	a semantic relevance based neural network for text summarization and text simplification		ive text summarization has achieved successful performance thanks to the sequence-to-sequence model (Sutskever, Vinyals, and Le 2014) and attention mechanism (Bahdanau, Cho, and Bengio 2014). Rush, Chopra, and Weston (2015) first used an attention-based encoder to compress texts and a neural network language decoder to generate summaries. Following this work, recurrent encoder was introduced to text summarization, and gained better performance (Lopyrev 2015; Chopra, Auli, and Rush 2016). Towards Chinese texts, Hu, Chen, and Zhu (2015) built a large corpus of Chinese short text summarization. To deal with unknown word problem, Nallapati et al. (2016) proposed a generator-pointer model so that the decoder is able to generate words in source texts. Gu et al. (2016) also solved this issue by incorporating copying mechanism. Besides, Ayana et al. (2016) proposes a minimum risk training method which optimizes the parameters with the target of rouge scores. Zhu, Bernhard, and Gurevych (2010) constructs a wikipedia dataset, and proposes a treebased simplification model, which is the first statistical simplification model covering splitting, dropping, reordering and substitution integrally. Woodsend and Lapata (2011) introduces a datadriven model based on quasi-synchronous grammar, which captures structural mismatches and complex rewrite operations. Wubben, van den Bosch, and Krahmer (2012) presents a method for text simplification using phrase based machine translation with re-ranking the outputs.	artificial neural network;automatic summarization;benchmark (computing);copying mechanism;encoder;entity–relationship model;experiment;holographic principle;level of detail;machine translation;network model;pointer (computer programming);rouge (metric);recurrent neural network;relevance;rewrite (programming);teaching method;text corpus;text simplification;wikipedia	Shuming Ma;Xu Sun	2017	CoRR		encoder;natural language processing;automatic summarization;artificial intelligence;source text;computer science;semantic similarity;information retrieval;text graph;linguistic sequence complexity;text simplification;text mining	NLP	-18.806287800919627	-74.12711488384276	80326
f79a1ab802be2ca879ddb7b813028da61134f30f	unsupervised person clustering in videos with cross-modal communication	unsupervised learning;metric learning;deep learning;person identification;multimodal clustering	In the existing person identification solutions, multi-modal learning is able to gain a plausible person identification accuracy in TV Content since supervised information is applied to train an identification model by explicitly customized labels or implicitly derived labels from the transcripts. However, explicit and implicit information is unavailable in various scenes. To tackle this problem, an unsupervised audio-visual person clustering scheme is proposed via exploring the inherent links of speech and faces. Firstly, deep features for individual audio and visual information are designed with metric criteria for neural networks, to provide powerful representations for person identification. Furthermore, an audio-visual cross-modal communication is built to achieve multi-modal clustering based on the same person concepts. The experiments conducted on TV Content demonstrate the effectiveness and superiority of the proposed solution.	algorithm;artificial neural network;cluster analysis;experiment;modal logic;text corpus;unsupervised learning	Changlong Miao;Jianwei Feng;Yu Ding;Yu Kyung Yang;Xiaogang Chen;Xiangyang Ji	2016	2016 Visual Communications and Image Processing (VCIP)	10.1109/VCIP.2016.7805581	unsupervised learning;computer vision;computer science;machine learning;deep learning;conceptual clustering	AI	-15.167199907886914	-68.48891421805803	80487
8c3754f43d604dfe6d149a051eeaff8c2237f217	a brief review on multi-task learning		Multi-task learning (MTL), which optimizes multiple related learning tasks at the same time, has been widely used in various applications, including natural language processing, speech recognition, computer vision, multimedia data processing, biomedical imaging, socio-biological data analysis, multi-modality data analysis, etc. MTL sometimes is also referred to as joint learning, and is closely related to other machine learning subfields like multi-class learning, transfer learning, and learning with auxiliary tasks, to name a few. In this paper, we provide a brief review on this topic, discuss the motivation behind this machine learning method, compare various MTL algorithms, review MTL methods for incomplete data, and discuss its application in deep learning. We aim to provide the readers with a simple way to understand MTL without too many complicated equations, and to help the readers to apply MTL in their applications.	algorithm;artificial neural network;code;computer multitasking;computer vision;deep learning;machine learning;map;medical imaging;modality (human–computer interaction);multi-task learning;natural language processing;speech recognition;springer (tank)	Kimhan Thung;Chong-Yaw Wee	2018	Multimedia Tools and Applications	10.1007/s11042-018-6463-x	transfer of learning;deep learning;computer science;pattern recognition;multi-task learning;machine learning;artificial intelligence;data processing	ML	-10.056378099096458	-66.21808670920869	80540
669e5407d8a5fd68fa5d6e901d515199daa3dbd7	justification of printed music	printing;spacing;espacement;text editor;justification;espaciamiento;implementation;text processing;musical note;musica;computational method;ejecucion;musique;nota musical;note musique;editor texto;impression;editeur texte;justificacion;impresion;music	There is increasing interest in the use of computer systems for editing and printing sheet music [3, 19]. Music processing lags far behind text processing because of the complexities of music notation. Most music published today is still laid out by hand; while computers may be used, decisions about music-symbol placement are made by people. Much research remains to be done into computational methods of encoding the myriad rules of music notation. Individual rules are not difficult to formulate; it is the complex interaction among rules which is difficult to describe and control. In this article we focus on one aspect of music notation: the horizontal spacing of music to produce a right- and left- justified result.	computer;printing	Dorothea Blostein;Lippold Haken	1991	Commun. ACM	10.1145/102868.102874	speech recognition;computer science;artificial intelligence;music;mathematics;multimedia;pop music automation;programming language;implementation;management;musicality;algorithm	Web+IR	-9.268600650554525	-72.92914415165004	80603
71ef496cf93a56f76e07f48400389001e0bcb7d6	zero-shot learning of classifiers from natural language quantification		Humans can efficiently learn new concepts using language. We present a framework through which a set of explanations of a concept can be used to learn a classifier without access to any labeled examples. We use semantic parsing to map explanations to probabilistic assertions grounded in latent class labels and observed attributes of unlabeled data, and leverage the differential semantics of linguistic quantifiers (e.g., ‘usually’ vs ‘always’) to drive model training. Experiments on three domains show that the learned classifiers outperform previous approaches for learning with limited data, and are comparable with fully supervised classifiers trained from a small number of labeled examples.	experiment;humans;natural language;parsing;semantic analysis (machine learning);semi-supervised learning;statistical classification;supervised learning	Tom M. Mitchell;Shashank Srivastava;Igor Labutov	2018			natural language processing;machine learning;artificial intelligence;computer science;natural language	NLP	-15.93551545675426	-70.31696397813974	80617
83f49a9dcab78298be1f607f1e18c12c79aac47d	measuring abstract mindsets through syntax: improvements in automating the linguistic category model		The Linguistic Category Model (LCM) was developed as a manual coding scheme for quantifying abstract mindsets in human language. Previous attempts to computationally automate the LCM have relied primarily on pre-coded semantic features, which fail to incorporate important contextual information integral to the LCM coding scheme. In this paper, we introduce Syntax-LCM, a novel method for automating LCM coding using syntax and dependency tree features as predictors of construal level. We compare the accuracy of Syntax-LCM to that of two previously used automated methods: LIWC LCM and Brysbaert concreteness ratings. We find support that the Syntax-LCM approximates the hand-coded LCM with higher accuracy compared to both the Brysbaert and the LIWC LCM. We also provide evidence that the syntactic features accounted for by Syntax-LCM mirror the inclusion criteria in the original coding manual and support theoretical relationships between distance and abstract thinking.	latent class model	Kate M. Johnson;Reihane Boghrati;Cheryl Wakslak;Morteza Dehghani	2017			cognitive psychology;psychology;syntax	NLP	-12.86129642416101	-73.90623749847921	80749
5141cf2e59fb2ec9bb489b9c1832447d3cd93110	learning person trajectory representations for team activity analysis		Activity analysis in which multiple people interact across a large space is challenging due to the interplay of individual actions and collective group dynamics. We propose an end-to-end approach for learning person trajectory representations for group activity analysis. The learned representations encode rich spatio-temporal dependencies and capture useful motion patterns for recognizing individual events, as well as characteristic group dynamics that can be used to identify groups from their trajectories alone. We develop our deep learning approach in the context of team sports, which provide well-defined sets of events (e.g. pass, shot) and groups of people (teams). Analysis of events and team formations using NHL hockey and NBA basketball datasets demonstrate the generality of our approach.	deep learning;encode;end-to-end principle;interaction;linear temporal logic;nba hangtime;testbed	Nazanin Mehrasa;Yatao Zhong;Frederick Tung;Luke Bornn;Greg Mori	2017	CoRR		artificial intelligence;pattern recognition;machine learning;computer science;deep learning;social group;basketball;generality;trajectory	ML	-11.02791131032519	-69.97671701637607	80759
202384bee69aae6307bb24473c5d6fa99d90fb35	self-monitoring is the main cause of lexical bias in phonological speech errors	erreur;psychologie du langage;traitement mental;speech fluency;production de la parole;mental processing;theorie du moniteur;discours spontane;feedback;side effect;retroaction;fluidite verbale;error;psychology of language;spontaneous speech;experimentation;monitoring theory;speech production;psycholinguistique;psycholinguistics	In this paper I present new evidence, stemming both from an experiment and from spontaneous speech, demonstrating that (a) lexical bias is caused by self-monitoring of inner speech, as proposed by Levelt et al. [6], and (b) that there is phoneme-toword feedback in the mental programming of speech, as supposed by Dell [2] and Stemberger [10]. It is argued here that possibly phoneme-to-word feedback is an unavoidable side-effect of self-monitoring of inner speech.	emoticon;spontaneous order;stemming	Sieb G. Nooteboom	2003			psychology;speech recognition;linguistics;speech error;communication	NLP	-9.558453295296978	-79.8737274637488	80864
657e1ee470a0df0aacb05a9c03744d169ba239d8	listen, attend, and walk: neural mapping of navigational instructions to action sequences	natural language semantics;direction following;natural language processing	We propose a neural sequence-to-sequence model for direction following, a task that is essential to realizing effective autonomous agents. Our alignment-based encoder-decoder model with long short-term memory recurrent neural networks (LSTM-RNN) translates natural language instructions to action sequences based upon a representation of the observable world state. We introduce a multi-level aligner that empowers our model to focus on sentence “regions” salient to the current world state by using multiple abstractions of the input sentence. In contrast to existing methods, our model uses no specialized linguistic resources (e.g., parsers) or taskspecific annotations (e.g., seed lexicons). It is therefore generalizable, yet still achieves the best results reported to-date on a benchmark single-sentence dataset and competitive results for the limited-training multi-sentence setting. We analyze our model through a series of ablations that elucidate the contributions of the primary components of our model.	artificial neural network;autonomous robot;benchmark (computing);encoder;lexicon;long short-term memory;natural language;observable;parsing;random neural network;recurrent neural network	Hongyuan Mei;Mohit Bansal;Matthew R. Walter	2016			natural language processing;computer science;artificial intelligence;machine learning;linguistics;programming language	AI	-16.013460019479204	-74.38104719912899	80966
2dac4fbeb70b658bbe8a9b10a9ee45ba35144eb4	from hard to soft: towards more human-like emotion recognition by modelling the perception uncertainty		Over the last decade, automatic emotion recognition has become well established. The gold standard target is thereby usually calculated based on multiple annotations from different raters. All related efforts assume that the emotional state of a human subject can be identified by a u0027hardu0027 category or a unique value. This assumption tries to ease the human observeru0027s subjectivity when observing patterns such as the emotional state of others. However, as the number of annotators cannot be infinite, uncertainty remains in the emotion target even if calculated from several, yet few human annotators. The common procedure to use this same emotion target in the learning process thus inevitably introduces noise in terms of an uncertain learning target. In this light, we propose a u0027softu0027 prediction framework to provide a more human-like and comprehensive prediction of emotion. In our novel framework, we provide an additional target to indicate the uncertainty of human perception based on the inter-rater disagreement level, in contrast to the traditional framework which is merely producing one single prediction (category or value). To exploit the dependency between the emotional state and the newly introduced perception uncertainty, we implement a multi-task learning strategy. To evaluate the feasibility and effectiveness of the proposed soft prediction framework, we perform extensive experiments on a time- and value-continuous spontaneous audiovisual emotion database including late fusion results. We show that the soft prediction framework with multi-task learning of the emotional state and its perception uncertainty significantly outperforms the individual tasks in both the arousal and valence dimensions.	algorithm;computer multitasking;deep learning;emotion recognition;experiment;machine learning;multi-task learning;programming paradigm;random neural network;recommender system;spontaneous order	Jing Han;Zixing Zhang;Maximilian Schmitt;Maja Pantic;Björn W. Schuller	2017		10.1145/3123266.3123383	long short term memory;computer vision;perception;observer (quantum physics);arousal;emotion recognition;machine learning;multi-task learning;exploit;computer science;subjectivity;artificial intelligence	AI	-15.349849210137846	-71.53455678341338	81002
668af7a62818902ed2227a244fc6619eb7d1b201	listeners integrate speech, gesture, and discourse structure to interpret the temporal structure of complex events		Human communication has a remarkable capacity to describe events that occurred elsewhere and at other times. In particular, when describing complex narratives, speakers must communicate temporal structure using a mixture of words (e.g., “after”), gestures (e.g., pointing rightward for a later event), and discourse structure (e.g., mentioning earlier events first). How do listeners integrate these sources of temporal information to make sense of complex narratives? In two experiments, we systematically manipulated gesture, speech, and orderof-mention to investigate their respective impacts on comprehension of temporal structure. Gesture had a significant effect on interpretations of temporal order. This influence of gesture, however, was weaker than the influence of both speech and order-of-mention. Indeed, in some cases, order-of-mention trumped explicit descriptions in speech; for instance, if ‘earlier’ events were mentioned second, they were sometimes thought to have occurred second. Listeners integrate multiple sources of information to interpret what happened when.	experiment;pointing device	Andrea Nishimi;Esther Walker;Benjamin Bergen;Tyler Marghetis	2017			cognitive psychology;psychology;gesture	NLP	-7.876303312712105	-78.07024610761553	81041
bfc4606d65317b78e7ed12781b37a472e74b3112	estimation and categorization of errors in error recovery using task stratification and error classification		We proposed an approach to error recovery that uses the concepts of task stratification and error classification. In our method, errors are classified according to the estimated cause into several categories, such as modeling and planning errors. When an error is classified correctly, this increases the probability that the most suitable recovery is performed. In this paper, we describe a procedure for error categorization.		Akira Nakamura;Kazuyuki Nagata;Kensuke Harada;Natsuki Yamanobe	2017	JRNAL	10.2991/jrnal.2017.4.2.13	categorization;machine learning;artificial intelligence;bayes error rate;pattern recognition;computer science	ML	-4.81653508618445	-72.60193427630787	81330
9ba13b553eb6c2019d09c78e637dc145ed04f89c	adversarial structured prediction for multivariate measures		Many predicted structured objects (e.g., sequences, matchings, trees) are evaluated using the F-score, alignment error rate (AER), or other multivariate performance measures. Since inductively optimizing these measures using training data is typically computationally difficult, empirical risk minimization of surrogate losses is employed, using, e.g., the hinge loss for (structured) support vector machines. These approximations often introduce a mismatch between the learner’s objective and the desired application performance, leading to inconsistency. We take a different approach: adversarially approximate training data while optimizing the exact F-score or AER. Structured predictions under this formulation result from solving zerosum games between a predictor seeking the best performance and an adversary seeking the worst while required to (approximately) match certain structured properties of the training data. We explore this approach for word alignment (AER evaluation) and named entity recognition (F-score evaluation) with linear-chain constraints.		Hong Wang;Ashkan Rezaei;Brian D. Ziebart	2017	CoRR			NLP	-12.334582641100894	-67.70313913793721	81516
1a04083cb355e3ad433d7ea1ddcd95a3ff0ce448	towards a neural network approach to abstractive multi-document summarization		Till now, neural abstractive summarization methods have achieved great success for single document summarization (SDS). However, due to the lack of large scale multi-document summaries, such methods can be hardly applied to multi-document summarization (MDS). In this paper, we investigate neural abstractive methods for MDS by adapting a state-of-the-art neural abstractive summarization model for SDS. We propose an approach to extend the neural abstractive model trained on large scale SDS data to the MDS task. Our approach only makes use of a small number of multi-document summaries for fine tuning. Experimental results on two benchmark DUC datasets demonstrate that our approach can outperform a variety of base-	artificial neural network;automatic summarization;benchmark (computing);encoder;multi-document summarization;upsampling	Jianmin Zhang;Jiwei Tan;Xiaojun Wan	2018	CoRR		automatic summarization;artificial intelligence;machine learning;fine-tuning;artificial neural network;small number;multi-document summarization;computer science	AI	-17.143657672715765	-74.47479364266586	81887
3f6f384a7662a7d32f516d577e0d37ecbcdda663	temporal views as abstract relations	temporal locations;prepositions;natural languages temporal logic computational linguistics temporal reasoning;ieee entities;temporal views;history;temporal logic;temporal entities;logic;abstract relations;physical entities;natural languages;data mining;physics computing;temporal logic temporal views abstract relations natural languages prepositions physical entities spatial locations temporal entities temporal locations temporal reasoning abstract entities;spatial locations;eyes;physics computing natural languages logic dictionaries artificial intelligence history eyes data mining ieee entities concrete;natural language;dictionaries;artificial intelligence;computational linguistics;abstract entities;temporal reasoning;concrete	Many natural languages use prepositions to mark relations between entities of various kinds – between physical entities and their spatial locations, between temporal entities and their temporal locations, between abstract entities of various kinds (e.g. between ideas and their ‘mental locations’). In the current paper I will show that the consequences of using prepositions to relate temporal entities emerge naturally from the basic interpretations of the prepositions themselves together with a very weak logic of events, where I take it that prepositions denote abstract relations whose significance only emerges when properties of the related items are taken into consideration. 1. Prepositions as abstract relations “in: preposition expressing inclusion or position within limits of space, time, circumstance, etc.” Pocket Oxford Dictionary of Current English, 1970 Consider the following sets of sentences: (1) a. He drove from London to Paris.1 1(1a) to (1c) are taken from [1]. b. He drove from dawn to dusk. c. He copied it from his hard drive to a floppy. d. I got the RAE results from the Guardian2. (2) a. I saw a man in the park. b. I saw him in January. c. I’ve got an idea for a paper about time in my mind, but I don’t know how it will work out. d. I’ve got 230 people in my AI class next term. (3) a. I saw him at the station. b. I saw him at two o’clock. c. He seemed to be at his wits’ end. All of these, apart perhaps from the very last one, seem to be entirely natural. The prepositions that appear in them, however, clearly link very different kinds of things. In the (a) examples the ground for the relation denoted by the PP is a physical location, in the (b) examples it is a temporal location, in the (c) and (d) examples it seems to be some sort of abstract entity. Is one of these relations primary, with the others as some kind of metaphorical extension, or is there some common element which gets extended in different ways depending on the nature of the ground? This is not, in this paper, a question about the history of prepositions, either over the evolution of the language across the centuries or within each language learner. It may be that, at least historically, the spatial interpretations of some of these prepositions come first, but there is very little evidence that the spatial readings predominate in the language as it is used today (see Appendix A for an extract from the first 9000 noun-in-noun triples in the BNC. There is very little indication here that spatial or temporal uses of ‘in’ are particularly common3). The aim of the current paper is to see whether it is possible to provide a single uniform account of the meaning of prepositions like the ones in (1)–(3) which shows how the contribution they make to the meaning of the sentence, and in particular to the temporal structure of the reported event, arises from a simple core meaning for the preposition in conjunction with the key properties of the entities being related. 2because they ranked UMIST higher than anyone else did! 3The process of extracting these was not sensitive to the possibility that the PP modifies a VP rather than a nominal, but in any case it is the nature of the ground that has most effect on the type of relation, and there will not be much wrong with the choice of ground in these examples.	dictionary;emoticon;entity;floppy disk;hard disk drive;mind;natural language	Allan Ramsay	2002		10.1109/TIME.2002.1027484	natural language processing;computer science;theoretical computer science;data mining	NLP	-9.976519928063455	-73.79803515895239	82060
4d2a91d941effa1fa04a4b55a4d9053b92773877	opinion expression detection via deep bidirectional c-grus		The ability to accurately detect opinion expression in a document is an essential and fundamental task in opinion mining. In this work, we consider opinion expression detection as a sequence labeling task. We describe deep neural network frameworks that consist of convolutional neural networks (CNNs) and bidirectional gated units (Bi-GRUs). CNNs are capable of capturing local features in a sequence, while Bi-GRUs, a type of recurrent neural network (RNN) variant, are able to extract features from sequence data. The properties of these two networks provide the framework to effectively detect opinion expression. Experimental results show that our methods significantly outperform traditional methods like conditional random field (CRF) and previous state-of-the-art deep RNN methods.	artificial neural network;conditional random field;convolutional neural network;deep learning;random neural network;recurrent neural network;semiconductor industry;sentiment analysis;sequence labeling	Xiaoxia Xie	2017	2017 28th International Workshop on Database and Expert Systems Applications (DEXA)	10.1109/DEXA.2017.40	sequence labeling;artificial neural network;computer science;sentiment analysis;convolutional neural network;data mining;machine learning;feature extraction;conditional random field;recurrent neural network;artificial intelligence;pattern recognition	ML	-18.435107378666398	-71.57530072435472	82279
0da670c018862ac4a91dde1464510a3e92c95411	decoupling temporal dynamics for naturalistic affect recognition in a two-stage regression framework		Automatic continuous affect recognition from multiple modalities is one of the most active research areas in affective computing. In addressing this regression problem, the advantages of a model, such as Support Vector Regression (SVR), or a model that can capture temporal dependencies within a predefined time window, such as Time Delay Neural Network (TDNN), Long Short-Term Memory (LSTM) or Kalman Filter (KF), have been frequently explored, but in an isolated way. The motivation is towards decoupling temporal information from its features at the semantic level, in order to exploit the slow-changing emotional property at decision level. This paper explores and proposes 2-stage regression framework where SVR, that has been regarded as the baseline approach on affective recognition task, is concatenated together with subsequent models. Extensive experiments have been carried out on a naturalistic emotion dataset, using eight modalities present in RECOLA database. The results shows the proposed framework can capture temporal information at the prediction level, and outperform state-of-theart approaches in continuous affective recognition.	affective computing;baseline (configuration management);concatenation;coupling (computer programming);emotion recognition;experiment;kalman filter;long short-term memory;modality (human–computer interaction);support vector machine;time delay neural network	Yona Falinie A. Gaus;Hongying Meng;Asim Jan	2017	2017 3rd IEEE International Conference on Cybernetics (CYBCON)	10.1109/CYBConf.2017.7985772	support vector machine;modalities;time delay neural network;regression;affect (psychology);affective computing;kalman filter;exploit;machine learning;psychology;artificial intelligence	Vision	-11.987652447918489	-71.1212710703735	82320
8cdd241b474bf7b0632162403ac2a3c4799252ad	best of both worlds: transferring knowledge from discriminative learning to a generative visual dialog model		We present a novel training framework for neural sequence models, particularly for grounded dialog generation. The standard training paradigm for these models is maximum likelihood estimation (MLE), or minimizing the cross-entropy of the human responses. Across a variety of domains, a recurring problem with MLE trained generative neural dialog models (G) is that they tend to produce ‘safe’ and generic responses (‘I don’t know’, ‘I can’t tell’). In contrast, discriminative dialog models (D) that are trained to rank a list of candidate human responses outperform their generative counterparts; in terms of automatic metrics, diversity, and informativeness of the responses. However, D is not useful in practice since it can not be deployed to have real conversations with users. Our work aims to achieve the best of both worlds – the practical usefulness of G and the strong performance of D – via knowledge transfer from D to G. Our primary contribution is an end-to-end trainable generative visual dialog model, where G receives gradients from D as a perceptual (not adversarial) loss of the sequence sampled from G. We leverage the recently proposed Gumbel-Softmax (GS) approximation to the discrete distribution – specifically, a RNN augmented with a sequence of GS samplers, coupled with the straight-through gradient estimator to enable end-to-end differentiability. We also introduce a stronger encoder for visual dialog, and employ a self-attention mechanism for answer encoding along with a metric learning loss to aid D in better capturing semantic similarities in answer responses. Overall, our proposed model outperforms state-of-the-art on the VisDial dataset by a significant margin (2.67% on recall@10). The source code can be downloaded from https://github.com/jiasenlu/visDial.pytorch		Jiasen Lu;Anitha Kannan;Jianwei Yang;Devi Parikh;Dhruv Batra	2017			computer science;discriminative model;encoder;machine learning;probability distribution;generative grammar;encoding (memory);estimator;source code;dialog box;artificial intelligence	ML	-14.250274135657937	-72.47966143727973	82459
2fcda4260ed6dc9148eea6638e20d344760a609b	transfer joint embedding for cross-domain named entity recognition	named entity recognition;transfer learning;multiclass classification	Named Entity Recognition (NER) is a fundamental task in information extraction from unstructured text. Most previous machine-learning-based NER systems are domain-specific, which implies that they may only perform well on some specific domains (e.g., Newswire) but tend to adapt poorly to other related but different domains (e.g., Weblog). Recently, transfer learning techniques have been proposed to NER. However, most transfer learning approaches to NER are developed for binary classification, while NER is a multiclass classification problem in nature. Therefore, one has to first reduce the NER task to multiple binary classification tasks and solve them independently. In this article, we propose a new transfer learning method, named Transfer Joint Embedding (TJE), for cross-domain multiclass classification, which can fully exploit the relationships between classes (labels), and reduce domain difference in data distributions for transfer learning. More specifically, we aim to embed both labels (outputs) and high-dimensional features (inputs) from different domains (e.g., a source domain and a target domain) into a unified low-dimensional latent space, where 1) each label is represented by a prototype and the intrinsic relationships between labels can be measured by Euclidean distance; 2) the distance in data distributions between the source and target domains can be reduced; 3) the source domain labeled data are closer to their corresponding label-prototypes than others. After the latent space is learned, classification on the target domain data can be done with the simple nearest neighbor rule in the latent space. Furthermore, in order to scale up TJE, we propose an efficient algorithm based on stochastic gradient descent (SGD). Finally, we apply the proposed TJE method for NER across different domains on the ACE 2005 dataset, which is a benchmark in Natural Language Processing (NLP). Experimental results demonstrate the effectiveness of TJE and show that TJE can outperform state-of-the-art transfer learning approaches to NER.	ace;algorithm;benchmark (computing);binary classification;blog;euclidean distance;information extraction;machine learning;multiclass classification;named entity;named-entity recognition;natural language processing;prototype;stochastic gradient descent	Sinno Jialin Pan;Zhiqiang Toh;Jian Su	2013	ACM Trans. Inf. Syst.	10.1145/2457465.2457467	transfer of learning;computer science;artificial intelligence;machine learning;multiclass classification;pattern recognition;data mining	AI	-17.217110707537067	-66.55624507204377	82830
22ba1943b04611779547ed14666fc71ad853357c	towards inference-oriented reading comprehension: parallelqa		In this paper, we investigate the tendency of end-to-end neural Machine Reading Comprehension (MRC) models to match shallow patterns rather than perform inference-oriented reasoning on RC benchmarks. We aim to test the ability of these systems to answer questions which focus on referential inference. We propose ParallelQA, a strategy to formulate such questions using parallel passages. We also demonstrate that existing neural models fail to generalize well to this setting.	end-to-end principle;list comprehension	Soumya Wadhwa;Varsha Embar;Matthias Grabmair;Eric Nyberg	2018	CoRR		artificial intelligence;machine learning;natural language processing;computer science;inference;reading comprehension	NLP	-16.927604747413035	-73.17082693952926	82908
a8f25e526ede72bc1bc3c21f8f2793065677b401	cues and control in expert-client dialogues	cue word;empirical analysis;discourse structure;expert-client dialogue;utterance type;discourse goal;certain type;control criterion	"""We conducted an empirical analysis into the relation between control and discourse structure. We applied control criteria to four dialognes and identified 3 levels of discourse structure. We investigated the mechanism for changing control between these structures and found that utterance type and not cue words predicted shifts of control. Participants used certain types of signals when discourse goals were proceeding successfully but resorted to interruptions when they were not. 1 I n t r o d u c t i o n A number of researchers have shown that there is organisation in discourse above the level of the individual utterance (5, 8, 9, 10), The current exploratory study uses control as a parameter for identifying these higher level structures. We then go on to address how conversational participants co-ordinate moves between these higher level units, in particular looking at the ways they use to signal the beginning and end of such high level units. Previous research has identified three means by which speakers signal information about discourse structure to listeners: Cue words and phrases (5, 10); Intonation (7); Pronominalisation (6, 2). In the cue words approach, Reichman'(10) has claimed that phrases like """"because"""", """"so"""", and """"but"""" offer explicit information to listeners about how the speaker's current contribution to the discourse relates to what has gone previously. For example a speaker might use the expression """"so"""" to signal that s/he is about to conclude what s/he has just said. Grosz and Sidner (5) relate the use of such phrases to changes in attentional state. An example would be that """"and"""" or """"but"""" signal to the listener that a new topic and set of referents is being introduced whereas """"anyway"""" and """"in any case"""" indicate a return to a previous topic and referent set. A second indirect way of signalling discourse structure is intonation. Hirschberg and Pierrehumbert (7) showed that intonational contour is closely related to discourse segmentation with new topics being signalled by changes in intonational contour. A final more indirect cue to discourse structure is the speaker's choice of referring expressions and grammatical structure. A number of researchers (4, 2, 6, 10) have given accounts of how these relate to the continuing, retaining or shifting of focus. The above approaches have concentrated on particular surface linguistic phenomena and then investigated what a putative cue serves to signal in a number of dialogues. The problem"""	high-level programming language;hirschberg's algorithm	Steve Whittaker;Phil Stenton	1988			natural language processing;computer science;linguistics	NLP	-10.63847748106751	-80.03573844054095	83049
08a906112754cef903b26acf6824cd6aa3c7d69b	phonetic information in audiovisual speech is more important for adults than for infants; preliminary findings		Infants and adults are able to match auditory and visual speech but the cues on which they rely may differ. Here we provide an initial assessment of the relative contribution of temporaland phonetic cues available in the AV signal. Adults (N=52) and infants (N=18) matched 2 trisyllabic speech sounds, either natural speech or SWS, with visual speech information. Adults saw two articulating faces and matched a sound to one of these, while infants were presented with the same stimuli in a preferential looking paradigm. Adults’ performance was almost flawless with natural speech, but was significantly less accurate with SWS. In contrast, infants matched the sound to the articulating face, irrespective of whether it was natural speech or SWS. We propose that infants matched the AV signal based on temporal cues whereas adults relied more heavily on phonetic cues. This is in line with the idea that lipreading improves with age.	natural language;programming paradigm;sinewave synthesis	Martijn Baart;Jean Vroomen;Kathleen E. Shaw;Heather Bortfeld	2013			communication;psychology;preferential looking	ML	-8.01872477532425	-80.12890627528202	83056
f527a5aec23aacdd3bdfacb72b22e587466e49d9	concreteness and corpora: a theoretical and practical study		An increasing body of empirical evidence suggests that concreteness is a fundamental dimension of semantic representation. By implementing both a vector space model and a Latent Dirichlet Allocation (LDA) Model, we explore the extent to which concreteness is reflected in the distributional patterns in corpora. In one experiment, we show that that vector space models can be tailored to better model semantic domains of particular degrees of concreteness. In a second experiment, we show that the quality of the representations of abstract words in LDA models can be im-words in LDA models can be improved by supplementing the training data with information on the physical properties of concrete concepts. We conclude by discussing the implications for computational systems and also for how concrete and abstract concepts are represented in the mind	latent dirichlet allocation;text corpus	Felix Hill;Douwe Kiela;Anna Korhonen	2013			cognitive psychology;speech recognition;communication	NLP	-14.160934340123978	-68.49498794459258	83222
54dcc30da39cac8f3fd93d273f12c4fd270bc952	feature selection using multiple streams	supervised learning;perforation;gene expression data;word sense disambiguation;part of speech;gene family;feature selection	Feature selection for supervised learning can be greatly improved by making use of the fact that features often come in classes. For example, in gene expression data, the genes which serve as features may be divided into classes based on their membership in gene families or pathways. When labeling words with senses for word sense disambiguation, features fall into classes including adjacent words, their parts of speech, and the topic and venue of the document the word is in. We present a streamwise feature selection method that allows dynamic generation and selection of features, while taking advantage of the different feature classes, and the fact that they are of different sizes and have different (but unknown) fractions of good features. Experimental results show that our approach provides significant improvement in performance and is computationally less expensive than comparable “batch” methods that do not take advantage of the feature classes and expect all features to be known in advance.	algorithm;algorithmic efficiency;computation;data mining;david ungar;elastic net regularization;entity–relationship model;feature extraction;feature model;feature selection;gene family;international conference on machine learning;journal of machine learning research;least-angle regression;matlab;model selection;nips;overfitting;overhead (computing);relevance;supervised learning;venue (sound system);word sense;word-sense disambiguation	Paramveer S. Dhillon;Dean P. Foster;Lyle H. Ungar	2010			natural language processing;part of speech;computer science;gene family;machine learning;pattern recognition;supervised learning;feature selection	ML	-18.62017958564445	-76.75263036163525	83262
a6a1aae1823d151a28b4295199108c0f900aa66f	gated recursive neural network for chinese word segmentation		Recently, neural network models for natural language processing tasks have been increasingly focused on for their ability of alleviating the burden of manual feature engineering. However, the previous neural models cannot extract the complicated feature compositions as the traditional methods with discrete features. In this paper, we propose a gated recursive neural network (GRNN) for Chinese word segmentation, which contains reset and update gates to incorporate the complicated combinations of the context characters. Since GRNN is relative deep, we also use a supervised layer-wise training method to avoid the problem of gradient diffusion. Experiments on the benchmark datasets show that our model outperforms the previous neural network models as well as the state-of-the-art methods.	artificial neural network;benchmark (computing);experiment;feature engineering;gradient;natural language processing;neuron;recursion (computer science);recursive neural network;sequence labeling;simulation;teaching method;text segmentation	Xinchi Chen;Xipeng Qiu;Chenxi Zhu;Xuanjing Huang	2015			natural language processing;speech recognition;pattern recognition	NLP	-17.84141513124727	-75.22249166935289	83293
0b6384062fc35f566ff4ab8f84a5b45d68b078e7	enhancing first-pass attachment prediction	supervised learning;recursive neural networks;natural language;prediction accuracy;cognitive model	This paper explores the convergence between cognitive modeling and engineering solutions to the parsing problem in NLP. Natural language presents many sources of ambiguity, and several theories of human parsing claim that ambiguity is resolved by using past (linguistic) experience. In this paper we analyze and refine a connectionist paradigm (Recursive Neural Networks) capable of processing acyclic graphs to perform supervised learning on syntactic trees extracted from a large corpus of parsed sentences. Following a widely accepted hypothesis in psycholinguistics, we assume an incremental parsing process (one word at a time) that keeps a connected partial parse tree at all times. By implementing a parsing simulation procedure, we collect a large amount of data that shows the viability of the RNN as informant of a disambiguation process. We analyze what kind of information is exploited by the connectionist system in order to resolve different sources of ambiguity, and we see how the generalization performance of the system is affected by the tree complexity and the frequency of specific subtrees. We finally propose some enhancements to the architecture in order to achieve a better prediction accuracy.	artificial neural network;attachments;brown corpus;cognitive model;connectionism;directed acyclic graph;heuristic (computer science);natural language processing;neural network software;parse tree;parsing;programming paradigm;random neural network;recursion (computer science);recursive neural network;simulation;supervised learning;symbol (formal);theory;tree (data structure);visual basic;word-sense disambiguation	Fabrizio Costa;Paolo Frasconi;Vincenzo Lombardo;Patrick Sturt;Giovanni Soda	2002			natural language processing;cognitive model;parser combinator;computer science;bottom-up parsing;artificial intelligence;machine learning;s-attributed grammar;supervised learning;natural language;top-down parsing	NLP	-17.162403867170713	-73.92590281450177	83325
e1deea3d3dc80017a28ebcb7ac2db0d1d6a2034c	hyperarticulation aids learning of new vowels in a developmental speech acquisition model		Many studies emphasize the importance of infant-directed speech: stronger articulated, higher-quality speech helps infants to better distinguish different speech sounds. This effect has been widely investigated in terms of the infant's perceptual capabilities, but few studies examined whether infant-directed speech has an effect on articulatory learning. In earlier studies, we developed a model that learns articulatory control for a 3D vocal tract model via goal babbling. Exploration is organized in the space of outcomes. This so called goal space is generated from a set of ambient speech sounds. Similarly to how speech from the environment shapes infant's speech perception, the data from which the goal space is learned shapes the later learning process: it determines which sounds the model is able to discriminate, and thus, which sounds it can eventually learn to produce. We investigate how speech sound quality in early learning affects the model's capability to learn new vowel sounds. The model is trained either on hyperarticulated (tense) or on hypoarticulated (lax) vowels. Then we retrain the model with vowels from the other set. Results show that new vowels can be acquired although they were not included in early learning. There is, however, an effect of learning order, showing that models first trained on the stronger articulated tense vowels easier accommodate to new vowel sounds later on.	cognitive science;sound quality;speech acquisition;tract (literature)	Anja Kristina Philippsen;René Felix Reinhart;Britta Wrede;Petra Wagner	2017	2017 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2017.7965833	speech recognition;linguistics;communication	ML	-7.625905964247283	-79.47487391560922	83387
5ee8b40e58b7392177e29663017049b6d2ecba22	improving lstm-based video description with linguistic knowledge mined from text		This paper investigates how linguistic knowledge mined from large text corpora can aid the generation of natural language descriptions of videos. Specifically, we integrate both a neural language model and distributional semantics trained on large text corpora into a recent LSTM-based architecture for video description. We evaluate our approach on a collection of Youtube videos as well as two large movie description datasets showing significant improvements in grammaticality while modestly improving descriptive quality.	audio description;distributional semantics;ibm notes;kde applications;language model;long short-term memory;mined;natural language;text corpus	Subhashini Venugopalan;Lisa Anne Hendricks;Raymond J. Mooney;Kate Saenko	2016			natural language processing;computer science;machine learning;multimedia;information retrieval	NLP	-16.688538444997427	-70.97072810811514	83416
32d41b379b3d6b59ddf00cbc9a7c60ba6f3cf95a	finding good sequential model structures using output transformations		In Sequential Viterbi Models, such as HMMs, MEMMs, and Linear Chain CRFs, the type of patterns over output sequences that can be learned by the model depend directly on the model’s structure: any pattern that spans more output tags than are covered by the models’ order will be very difficult to learn. However, increasing a model’s order can lead to an increase in the number of model parameters, making the model more susceptible to sparse data problems. This paper shows how the notion of output transformation can be used to explore a variety of alternative model structures. Using output transformations, we can selectively increase the amount of contextual information available for some conditions, but not for others, thus allowing us to capture longer-distance consistencies while avoiding unnecessary increases to the model’s parameter space. The appropriate output transformation for a given task can be selected by applying a hill-climbing approach to heldout data. On the NP Chunking task, our hill-climbing system finds a model structure that outperforms both first-order and secondorder models with the same input feature set. 1 Sequence Prediction A sequence prediction task is a task whose input is a sequence and whose output is a corresponding sequence. Examples of sequence prediction tasks include part-of-speech tagging, where a sequence of words is mapped to a sequence of part-of-speech tags; and IOB noun phrase chunking, where a sequence of words is mapped to a sequence of labels, I, O, and B, indicating whether each word is inside a chunk, outside a chunk, or at the boundary between two chunks, respectively. In sequence prediction tasks, we are interested in finding the most likely output sequence for a given input. In order to be considered likely, an output value must be consistent with the input value, but it must also be internally consistent. For example, in part-of-speech tagging, the sequence “prepositionverb” is highly unlikely; so we should reject an output value that contains that sequence, even if the individual tags are good candidates for describing their respective words. 2 Sequential Viterbi Models This intuition is captured in many sequence learning models, including Hidden Markov Models (HMMs), Maximum Entropy Markov Models (MEMMs), and Linear Chain Conditional Random Fields (LCCRFs), by including terms corresponding to pieces of output structure in their scoring functions. (Sha and Pereira, 2003; Sutton and McCallum, 2006; McCallum et al., 2000; Alpaydin, 2004) Each of these Sequential Viterbi Models defines a set of scoring functions that evaluate fixed-size pieces of the output sequence based on fixed-size pieces of the input sequence.1 The overall score for For HMMs and MEMMs, the local scores are negative log probabilities. For LC-CRFs, the local scores do not have any direct probabilistic interpretation.	conditional random field;first-order predicate;hidden markov model;hill climbing;inside outside beginning;log probability;markov chain;negative feedback;parameter (computer programming);part-of-speech tagging;phrase chunking;scoring functions for docking;shallow parsing;sparse matrix	Edward Loper	2007			artificial intelligence;machine learning;algorithm;statistics	ML	-17.25206790116389	-75.91909082001972	83522
4ba8b3924ad09277fdd8f02efcd6616e0497c253	acoustic model training based on node-wise weight boundary model for fast and small-footprint deep neural networks		Our goal for this study is to enable the development of discrete deep neural networks (NNs), some parameters of which are discretized, as small-footprint and fast NNs for acoustic models. Three essential requirements should be met for achieving this goal; 1) the reduction in discretization errors, 2) implementation for fast processing and 3) node-size reduction of DNNs. We propose a weight-parameter model and its training algorithm for 1), an implementation scheme using a look-up table on general-purpose CPUs for 2), and a layer-biased node-pruning method for 3). The first proposed method can set proper boundaries of discretization at each NN node, resulting in reduction in discretization errors. The second method can reduce the memory usage of NNs within the cache size of the CPU by encoding the parameters of NNs. The last method can reduce the network size of the quantized DNNs by measuring the activity of each node at each layer and pruning them with a layer-dependent score. Experiments with 2-bit discrete NNs showed that our training algorithm maintained almost the same word accuracy as with 8-bit discrete NNs. We achieved a 95% reduction of memory usage and a 74% increase in speed of an NN’s forward calculation.	acoustic cryptanalysis;acoustic model;artificial neural network;deep learning	Ryu Takeda;Kazuhiro Nakadai;Kazunori Komatani	2017	Computer Speech & Language	10.1016/j.csl.2017.02.002	machine learning;computer science;artificial intelligence;cpu cache;speech recognition;artificial neural network;acoustic model;discretization;quantization (signal processing);encoding (memory);central processing unit	NLP	-15.566981750076625	-77.02547437921645	83683
ac3c721ba04d535d1cedfd41c77bcc43896de11c	a post-processing procedure for improving music tempo estimates using supervised learning		Tempo estimation is a fundamental problem in music information retrieval and has been researched extensively. One problem still unsolved is the tendency of tempo estimation algorithms to produce results that are wrong by a small number of known factors (so-called octave errors). We propose a method that uses supervised learning to predict such tempo estimation errors. In a post-processing step, these predictions can then be used to correct an algorithm’s tempo estimates. While being simple and relying only on a small number of features, our proposed method significantly increases accuracy for state-of-the-art tempo estimation methods.	approximation algorithm;information retrieval;supervised learning;video post-processing	Hendrik Schreiber;Meinard Müller	2017			supervised learning;machine learning;speech recognition;artificial intelligence;computer science	ML	-18.5794075188376	-78.25136634250627	83973
1d142221b889bc909bf3500a9116ae130b50e503	weighted domain translation for online news comments emotion tagging		"""This paper studies an emotion classification problem, which aims to classify online news comments to one of fine-grained emotion categories, e.g. happy, sad, and angry, etc. Neural networks have been widely used and achieved great success in sentiment classification. However, there must be sufficient labeled comments available for training neural networks, which usually requires labor-intensive and time-consuming manual labeling. One of the most effective solutions is to apply transfer learning, which uses abundant labeled comments from a source news domain to help the classification for another target domain with limited amount of labeled data. Still, the comments from different domains can have very different word distributions, which makes it difficult to transfer knowledge from one domain to another. In this paper, we accomplish cross-domain emotion tagging based on an advanced neural network BLSTM (bidirectional long short-term memory) with """"domain translation'', which can overcome the difference between domains. A weighted linear transformation is utilized to """"translate'' knowledge from source to target domain. An extensive set of experimental results on four datasets from popular online news services demonstrates the effectiveness of our proposed models."""	internationalized domain name;long short-term memory;neural networks;statistical classification	Ying Zhang;Li Yu;Xue Zhao;Xiaojie Yuan;Lei Xu	2017		10.1145/3077136.3080653	information retrieval;computer science;transfer of learning;labeled data;artificial neural network;emotion classification;machine learning;artificial intelligence	AI	-18.21346416582998	-70.75597974371	84202
4e4dde320a64a9d717f608ae67c72a3a8f5d3a5a	biomedical event trigger detection based on hybrid methods integrating word embeddings		Trigger detection as the preceding task is of great importance in biomedical event extraction. By now, most of the state-of-the-art systems have been based on single classifiers, and the words encoded by one-hot are unable to represent the semantic information. In this paper, we utilize hybrid methods integrating word embeddings to get higher performance. In hybrid methods, first, multiple single classifiers are constructed based on rich manual features including dependency and syntactic parsed results. Then multiple predicting results are integrated by set operation, voting and stacking method. Hybrid methods can take advantage of the difference among classifiers and make up for their deficiencies and thus improve performance. Word embeddings are learnt from large scale unlabeled texts and integrated as unsupervised features into other rich features based on dependency parse graphs, and thus a lot of semantic information can be represented. Experimental results show our method outperforms the state-of-the-art systems.	microsoft word for mac	Lishuang Li;Meiyue Qin;Degen Huang	2016		10.1007/978-981-10-3168-7_7	theoretical computer science;machine learning;pattern recognition;mathematics	AI	-19.012734410946987	-71.83007762024748	84706
e2902d6d7dd118b8c7040ce5b75b7f950e9b4da3	question answering by reasoning across documents with graph convolutional networks		Most research in reading comprehension has focused on answering questions based on individual documents or even single paragraphs. We introduce a method which integrates and reasons relying on information spread within documents and across multiple documents. We frame it as an inference problem on a graph. Mentions of entities are nodes of this graph where edges encode relations between different mentions (e.g., withinand cross-document co-references). Graph convolutional networks (GCNs) are applied to these graphs and trained to perform multi-step reasoning. Our Entity-GCN method is scalable and compact, and it achieves state-of-the-art results on the WIKIHOP dataset (Welbl et al., 2017).	encode;entity;graphics core next;question answering;scalability	Nicola De Cao;Wilker Aziz;Ivan Titov	2018	CoRR		natural language processing;machine learning;scalability;artificial intelligence;inference;computer science;question answering;reading comprehension;graph	NLP	-17.092408551016636	-71.65180955470275	84726
c023062d8ccae9d77b089429bd3bb1527e8ec65d	reference resolution challenges for intelligent agents: the need for knowledge	lenguaje natural;machine tractable knowledge;knowledge rich approach reference resolution intelligent agent natural language processing speech context nlp reference phenomena machine tractable knowledge deep semantic text processing knowledge lean approach;ai;knowledge rich approach;text processing;langage naturel;text analysis;reference resolution;tratamiento lenguaje;intelligence artificielle;ieee intelligent systems;data mining;reference phenomena;text analysis computational linguistics natural language processing software agents;software agents;deep semantic text processing;language processing;agent intelligent;natural language;cognition;traitement langage;ai linguistics natural language ieee intelligent systems human level intelligence;intelligent system;intelligent agent;human level intelligence;artificial intelligence;ontologies;humans;agente inteligente;computational linguistics;inteligencia artificial;intelligent agent natural languages natural language processing humans speech processing fingers radio access networks cognitive science memory management text processing;coreference resolution;natural language processing;context;nlp;knowledge lean approach;mental model;films;speech context;linguistics	"""Natural language processing (NLP) is as yet far from achieving human levels of sophistication. This isn't surprising if we consider that people are amazing processors of language who leverage all of their knowledge of language, the speech context and the world in every language situation. A domain in which the divergence between the abilities of people and the abilities of machines is particularly manifest is reference resolution. Reference resolution is best defined as interpreting the meaning of each referring expression in a language input - like my finger, JFK, them, ran - and anchoring it in the mental model (memory) of the intelligent agent processing that input. This semantics-oriented, memory-oriented view of reference resolution is inspired by what people seem to accomplish when resolving reference. It stands in contrast to the more widely pursued NLP task of coreference resolution, whose final goal is to match coreferential text strings (words and phrases) with each other, typically with little or no connection to text meaning or memory population and management. This article provides an example-oriented overview of reference phenomena that are difficult for intelligent agents to process, as well as the types of knowledge, rendered machine tractable, that seem to be required to process them. We begin with a short introduction to """"deep semantic"""" text processing, an approach to NLP that is currently not widely pursued but seems necessary to tackle problems like advanced reference resolution. Next comes an extended example that provides a concrete picture of the problem space in question. Then the full scope of reference phenomena is juxtaposed with the much narrower scope of phenomena that has been treated in systems to date. Comparisons are drawn between the primarily knowledge-lean approach, which has dominated the field so far, and the primarily knowledge-rich approach, which seems necessary for difficult phenomena. Following that are seven high-level questions and their answers that highlight some key challenges faced by reference resolving agents. The article concludes with some thoughts about what to do next in order to make significant progress on reference resolution. The organizational style - example-driven and Q&A - was selected to provide a more engaging introduction to the topic than would a formal, linguistically motivated classification."""	central processing unit;cobham's thesis;high- and low-level;intelligent agent;knowledge management;mental model;natural language processing;problem domain	Marjorie McShane	2009	IEEE Intelligent Systems	10.1109/MIS.2009.79	natural language processing;cognition;computer science;ontology;artificial intelligence;computational linguistics;software agent;natural language;intelligent agent	NLP	-10.82311276152245	-73.0567737290644	84842
fb47d57ae306426e70a12afa971ef47d7dd4719c	see: syntax-aware entity embedding for neural relation extraction		Distant supervised relation extraction is an efficient approach to scale relation extraction to very large corpora, and has been widely used to find novel relational facts from plain text. Recent studies on neural relation extraction have shown great progress on this task via modeling the sentences in low-dimensional spaces, but seldom considered syntax information to model the entities. In this paper, we propose to learn syntax-aware entity embedding for neural relation extraction. First, we encode the context of entities on a dependency tree as sentencelevel entity embedding based on tree-GRU. Then, we utilize both intra-sentence and inter-sentence attentions to obtain sentence set-level entity embedding over all sentences containing the focus entity pair. Finally, we combine both sentence embedding and entity embedding for relation classification. We conduct experiments on a widely used real-world dataset and the experimental results show that our model can make full use of all informative instances and achieve state-of-the-art performance of relation extraction.		Zhengqiu He;Wenliang Chen;Zhenghua Li;Meishan Zhang;Wei Zhang;Min Zhang	2018			machine learning;artificial intelligence;computer science;relationship extraction;syntax;embedding;plain text;sentence	NLP	-17.912867080962002	-71.85189654083145	85007
ee9b266b519c2d851cc51b33c40609a4a84a79d3	a generative context model for semantic music annotation and retrieval	audio signal processing;information retrieval;acoustics;context modeling semantics context rocks acoustics vocabulary correlation;vocabulary;semantics;dirichlet mixture models;polynomials;music information retrieval audio annotation and retrieval context modeling dirichlet mixture models;context model;mixture model;music information retrieval;audio annotation and retrieval;rocks;correlation;song annotation generative context model semantic music annotation semantic music retrieval semantic associations audio clips direct auditory cues automatic music annotation auto taggers model contextual relationship modeling dirichlet mixture model semantic multinomial tag vocabulary;context modeling;music;context;polynomials audio signal processing information retrieval music;semantic association	While a listener may derive semantic associations for audio clips from direct auditory cues (e.g., hearing “bass guitar”) as well as from “context” (e.g., inferring “bass guitar” in the context of a “rock” song), most state-of-the-art systems for automatic music annotation ignore this context. Indeed, although contextual relationships correlate tags, many auto-taggers model tags independently. This paper presents a novel, generative approach to improve automatic music annotation by modeling contextual relationships between tags. A Dirichlet mixture model (DMM) is proposed as a second, additional stage in the modeling process, to supplement any auto-tagging system that generates a semantic multinomial (SMN) over a vocabulary of tags when annotating a song. For each tag in the vocabulary, a DMM captures the broader context the tag defines by modeling tag co-occurrence patterns in the SMNs of songs associated with the tag. When annotating songs, the DMMs refine SMN annotations by leveraging contextual evidence. Experimental results demonstrate the benefits of combining a variety of auto-taggers with this generative context model. It generally outperforms other approaches to modeling context as well.	auto-tune;beneath a steel sky;concatenation;digital molecular matter (dmm);high- and low-level;java annotation;mixture model;multinomial logistic regression;smn theorem;vocabulary	Riccardo Miotto;Gert R. G. Lanckriet	2012	IEEE Transactions on Audio, Speech, and Language Processing	10.1109/TASL.2011.2172423	natural language processing;speech recognition;acoustics;computer science;mathematics;semantics;context model	Vision	-18.664669507322923	-77.11691630524703	85020
080470aefd714d68aa8f3c529d54e233bffeb636	how everyday visual experience prepares the way for learning object names	object recognition;image coding;dogs;visualization;head;cameras;concrete	Infants learn their first object names by linking heard names to scenes. A core theoretical problem is how infants select the right referent from cluttered and ambiguous scenes. Here we show how the distributional properties of objects in young infants' visual experiences may help solve this core problem in early word learning. Infant perspective scenes of mealtimes were collected using head cameras worn by 9-month-old infants (147 mealtimes from 8 infants). The frequency distribution of objects was extremely skewed with the most frequent visual objects corresponding to the normatively first learned object names in English.	experience;visual objects	Elizabeth M. Clerkin;Elizabeth Hart;James M. Rehg;Chen Yu;Linda B. Smith	2016	2016 Joint IEEE International Conference on Development and Learning and Epigenetic Robotics (ICDL-EpiRob)	10.1109/DEVLRN.2016.7846803	computer vision;computer science;multimedia;communication	Robotics	-6.020769745319699	-75.7111132982727	85181
02c1abca74834eabf18b1b7aa535d770a3cd07b3	an optimization framework for remapping and reweighting noisy relevance labels	ir theory;consensus models;learning to rank	Relevance labels is the essential part of any learning to rank framework. The rapid development of crowdsourcing platforms led to a significant reduction of the cost of manual labeling. This makes it possible to collect very large sets of labeled documents to train a ranking algorithm. However, relevance labels acquired via crowdsourcing are typically coarse and noisy, so certain consensus models are used to measure the quality of labels and to reduce the noise. This noise is likely to affect a ranker trained on such labels, and, since none of the existing consensus models directly optimizes ranking quality, one has to apply some heuristics to utilize the output of a consensus model in a ranking algorithm, e.g., to use majority voting among workers to get consensus labels. The major goal of this paper is to unify existing approaches to consensus modeling and noise reduction within a learning to rank framework. Namely, we present a machine learning algorithm aimed at improving the performance of a ranker trained on a crowdsourced dataset by proper remapping of labels and reweighting of samples. In the experimental part, we use several characteristics of workers/labels extracted via various consensus models in order to learn the remapping and reweighting functions. Our experiments on a large-scale dataset demonstrate that we can significantly improve state-of-the-art machine-learning algorithms by incorporating our framework.	algorithm;crowdsourcing;experiment;heuristic (computer science);learning to rank;machine learning;noise reduction;relevance	Yury Ustinovsky;Valentina Fedorova;Gleb Gusev;Pavel Serdyukov	2016		10.1145/2911451.2911501	international relations theory;computer science;machine learning;pattern recognition;data mining;learning to rank	AI	-16.553775452322775	-68.08968967984605	85513
74d3eae6802abe20c4cd1baa61ad1602bc01d3c4	resolving abstract anaphora implicitly in conversational assistants using a hierarchically stacked rnn		Recent proliferation of conversational systems has resulted in an increased demand for more natural dialogue systems, capable of more sophisticated interactions than merely providing factual answers. This is evident from usage pattern of a conversational system deployed within our organization. Users not only expect it to perform co-reference resolution of anaphora, but also of the antecedent or posterior facts presented by users with respect to their query. Presence of such facts in a conversation sometimes modifies the answer of main query, e.g., answer to u0027how many sick leave do I get?u0027 would be different when a fact u0027I am on contractu0027 is also present. Sometimes there is a need to collectively resolve three or four such facts. In this paper, we propose a novel solution which uses hierarchical neural network, comprising of BiLSTM layer and a maxpool layer that is hierarchically stacked to first obtain a representation of each user utterance and then to obtain a representation for sequence of utterances. This representation is used to identify usersu0027 intention. We also improvise this model by using skip connections in the second network to allow better gradient flow. Our model, not only a)~resolves the antecedent and posterior facts, but also b)~performs better even on self-contained queries. It is also c)~faster to train, making it the most promising approach for use in our environment where frequent training and tuning is needed. It slightly outperforms the benchmark on a publicly available dataset, and e)~performs better than obvious baselines approaches on our datasets.	anaphora (linguistics);artificial neural network;baseline (configuration management);benchmark (computing);dialog system;gradient;interaction;random neural network	Prerna Khurana;Puneet Agarwal;Gautam Shroff;Lovekesh Vig	2018		10.1145/3219819.3219915	artificial intelligence;computer science;machine learning;conversation;baseline (configuration management);artificial neural network;utterance	NLP	-15.758384914374824	-73.57519069533046	85997
0da32cd7fa9b9df789660452a1245d0a7fa6c18c	multimodal grounding for sequence-to-sequence speech recognition		Humans are capable of processing speech by making use of multiple sensory modalities. For example, the environment where a conversation takes place generally provides semantic and/or acoustic context that helps us to resolve ambiguities or to recall named entities. Motivated by this, there have been many works studying the integration of visual information into the speech recognition pipeline. Specifically, in our previous work, we propose a multistep visual adaptive training approach which improves the accuracy of an audio-based Automatic Speech Recognition (ASR) system. This approach, however, is not end-to-end as it requires fine-tuning the whole model with an adaptation layer. In this paper, we propose novel end-to-end multimodal ASR systems and compare them to the adaptive approach by using a range of visual representations obtained from state-of-the-art convolutional neural networks. We show that adaptive training is effective for S2S models leading to an absolute improvement of 1.4% in word error rate. As for the end-to-end systems, although they perform better than baseline, the improvements are slightly less than adaptive training, 0.8 absolute WER reduction in singlebest models. Using ensemble decoding, end-to-end models reach a WER of 15% which is the lowest score among all systems.	acoustic cryptanalysis;artificial neural network;automated system recovery;baseline (configuration management);bit error rate;convolutional neural network;end-to-end principle;humans;multimodal interaction;named entity;speech recognition;word error rate	Ozan Caglayan;Ramon Sanabria;Shruti Palaskar;Loïc Barrault;Florian Metze	2018	CoRR		natural language processing;convolutional neural network;conversation;word error rate;stimulus modality;artificial intelligence;decoding methods;speech recognition;ground;recall;computer science	NLP	-17.788101999736405	-78.10965530242633	86003
e494e28d8f2c6fb35cb6303114ff6408489d0ef8	a bayesian-network approach to lexical disambiguation	grammar;tratamiento paralelo;simulation ordinateur;language comprehension;bayesian network;syntax;traitement parallele;perforation;stochastic simulation;lenguaje;semantics;hombre;context free;langage;reseau;syntaxe;semantica;semantique;lexicons;simulation stochastique;red;algorithme;probabilistic model;algorithm;simulacion estocastica;grammaire;network model;cognition;human;modele probabiliste;reseau bayesien;cognicion;ambiguity;comprension lenguaje;comprehension langage;simulacion computadora;language;lexico;sintaxis;ambiguedad;computer simulation;gramatica;parallel processing;network;ambiguite;homme;modelo probabilista;algoritmo;lexique	lexical ambiguity can be syntactic If it involves mare than one grammatical category for a single word, or semantic If more than one meoning con be associated with a word. In thls article we discuss the application of o Boyesion-network model In the resolutlon of lexical ambiguities of both types. The network we propose comprises a parsing subnetwork, which can be constructed automatlcolly for any context-free grommar, and a subnetwork for semontlc analysis, which, In the spirit of Fillmore’s (1968) case grammars, seeks to fulfill the required cases of all condidotes for verb of the sentence. Solving for the highest /olnt probability of the variables conditloned upon the evidences to the network yields the most likely candidate with its meaning, along with Its cases and respective meanings. This Is achieved by flxlng the values of oil evidence nodes concurrently, and then performing a stochastic simulation in which the remaining nodes are updated proboblllstlcally with a high degree of porallellsm. The process of dlsomblguatlon Is directed neither by the syntax nor the semantics, but rather by the Interrelation between the two subnetworks. The use of a Bayeslan-network model allows us to express this Interrelation between the two subnetworks and among their constituents in a rather direct and rigorous way that, In connection with the convergence properties of the stochastic simulation, reveals a very robust model.	bayesian network;context-free language;naruto shippuden: clash of ninja revolution 3;network model;parsing;simulation;subnetwork;word-sense disambiguation	Leila M. R. Eizirik;Valmir Carneiro Barbosa;Sueli Bandeira Teixeira Mendes	1993	Cognitive Science	10.1207/s15516709cog1702_3	computer simulation;natural language processing;statistical model;parallel processing;cognition;syntax;computer science;network model;bayesian network;stochastic simulation;grammar;semantics;linguistics;language;communication	NLP	-10.55407874748432	-76.41610643092098	86221
05c6b2a59b021f2d5e5a580ded1681f8a1ae2a50	discovering binary codes for documents by learning deep generative models	cognitive science;restricted boltzmann machines;generic model;binary codes;semantic hashing;deep learning;document retrieval;auto encoders	We describe a deep generative model in which the lowest layer represents the word-count vector of a document and the top layer represents a learned binary code for that document. The top two layers of the generative model form an undirected associative memory and the remaining layers form a belief net with directed, top-down connections. We present efficient learning and inference procedures for this type of generative model and show that it allows more accurate and much faster retrieval than latent semantic analysis. By using our method as a filter for a much slower method called TF-IDF we achieve higher accuracy than TF-IDF alone and save several orders of magnitude in retrieval time. By using short binary codes as addresses, we can perform retrieval on very large document sets in a time that is independent of the size of the document set using only one word of memory to describe each document.	addresses (publication format);binary code;content-addressable memory;ephrin type-b receptor 1, human;generative model;graph (discrete mathematics);inference;latent semantic analysis;tf–idf;top-down and bottom-up design;anatomical layer;orders - hl7publishingdomain	Geoffrey E. Hinton;Ruslan Salakhutdinov	2011	Topics in cognitive science	10.1111/j.1756-8765.2010.01109.x	document retrieval;boltzmann machine;binary code;document clustering;computer science;artificial intelligence;theoretical computer science;machine learning;pattern recognition;deep learning;deep belief network	ML	-17.05398283955828	-71.86384227859475	86246
ba84f92181e78dfd30165525b924204563268cdc	using multi-label classification for improved question answering		A plethora of diverse approaches for question answering over RDF data have been developed in recent years. While the accuracy of these systems has increased significantly over time, most systems still focus on particular types of questions or particular challenges in question answering. What is a curse for single systems is a blessing for the combination of these systems. We show in this paper how machine learning techniques can be applied to create a more accurate question answering metasystem by reusing existing systems. In particular, we develop a multi-label classification-based metasystem for question answering over 6 existing systems using an innovative set of 14 question features. The metasystem outperforms the best single system by 14% F-measure on the recent QALD-6 benchmark. Furthermore, we analyzed the influence and correlation of the underlying features on the metasystem quality.	benchmark (computing);feature selection;machine learning;meta-system;multi-label classification;overfitting;question answering;software quality assurance;web service	Ricardo Usbeck;Michael Hoffmann;Michael Röder;Jens Lehmann;Axel-Cyrille Ngonga Ngomo	2017	CoRR		computer science;rdf;data mining;multi-label classification;question answering	Web+IR	-19.01783195717644	-66.56606382028302	86316
69bec88aaadfbcc343d50a7314df65252145f8b8	memory-based model with multiple attentions for multi-turn response selection		In this paper, we study the task of multi-turn response selection in retrieval-based dialogue systems. Previous approaches focus on matching response with utterances in the context to distill important matching information, and modeling sequential relationship among utterances. This kind of approaches do not take into account the position relationship and inner semantic relevance between utterances and query (i.e., the last utterance). We propose a memory-based network (MBN) to build the effective memory integrating position relationship and inner semantic relevance between utterances and query. Then we adopt multiple attentions on the memory to learn representations of context with multiple levels, which is similar to the behavior of human that repetitively think before response. Experimental results on a public data set for multi-turn response selection show the effectiveness of our MBN model.		Xingwu Lu;Man Lan;Yuanbin Wu	2018		10.1007/978-3-030-04179-3_26	natural language processing;machine learning;artificial neural network;computer science;artificial intelligence;utterance	Vision	-16.040132628863702	-71.52684579743126	86632
e45dc9025b304731652cbc5ba072088a97a36d97	a sequence level latent topic modeling method for sentiment analysis via cnn based diversified restrict boltzmann machine	sentiment analysis boltzmann machines feature extraction learning artificial intelligence;analytical models;cybernetics;nlpcc 2014 dataset sequence level latent topic modeling method sentiment analysis diversified restrict boltzmann machine diversified rbm deep learning based methods convolutional neural network cnn sentence mapping sequence level feature space latent topic features coae 2014 dataset;neural networks;data mining;training data;feature extraction;sentiment analysis;feature extraction sentiment analysis neural networks training data analytical models cybernetics data mining;convolutional neural networks sentiment analysis topic modeling diversified restrict boltzmann machine	Recently, the deep learning based methods, especially the ones based on convolutional neural network (CNN), achieved remarkable progresses in sentiment analysis. However, the CNN based methods do not take the latent topic in text into consideration. In this paper, we propose a CNN based Diversified Restrict Boltzmann Machine (RBM) method to model the sequence level latent topics in the sentences for sentiment analysis. The basic idea is to use CNN mapping the sentences into a sequence level feature space, and then utilize the Diversified RBM to model the latent topics in text. The obtained latent topic features are embedding to improve the performance of sentiment analysis. The evaluations on COAE 2014 and NLPCC 2014 datasets show that our proposed method outperforms the state-of-the-art methods in sentiment analysis. Furthermore, based on our knowledge, this is the first attempt to employ the Diversified RBM in sentiment analysis.	artificial neural network;convolutional neural network;deep learning;feature vector;restricted boltzmann machine;sentiment analysis;topic model	Yu Zhou;Ruifeng Xu;Lin Gui	2016	2016 International Conference on Machine Learning and Cybernetics (ICMLC)	10.1109/ICMLC.2016.7860927	training set;speech recognition;cybernetics;feature extraction;computer science;artificial intelligence;machine learning;pattern recognition;artificial neural network;sentiment analysis	AI	-17.90756163158788	-70.94250082745249	86990
76eb4b689479341eb8a92a08ccf949e78d98885b	effective online learning implementation for statistical machine translation		Online learning has been an active research area in statistical machine translation. However, as we have identified in our research, the implementation of successful online learning capabilities in the Moses SMT system can be challenging. In this work, we show how to use open source and freely available tools and methods in order to successfully implement online learning for SMT systems that allow improving translation quality. In our experiments, we compare the baseline implementation in Moses to an improved implementation utilising a two-step tuning strategy. We show that the baseline implementation achieves unstable performance (from −6 to (+)6 BLEU points in online learning scenarios and over −6 BLEU points in translation scenarios, i.e., when post-edits were not returned to the SMT system). However, our devised two-step tuning strategy is able to successfully utilise online learning capabilities and is able to improve MT quality in the online learning scenario by up to (+)12 BLEU points.	statistical machine translation	Toms Miks;Marcis Pinnis;Matiss Rikters;Rihards Krislauks	2018		10.1007/978-3-319-97571-9_24	machine translation;bleu;machine learning;artificial intelligence;computer science	NLP	-15.194607183119505	-75.5260648907613	87099
12eb9edf0f6ab439f8bbbb6ee373443776be6567	utilizing linguistically enhanced keystroke dynamics to predict typist cognition and demographics	stylometry;keystroke dynamics;demography recognition;typing production;cognitive load recognition	"""Entering information on a computer keyboard is a ubiquitous mode of expression and communication. We investigate whether typing behavior is connected to two factors: the cognitive demands of a given task and the demographic features of the typist. We utilize features based on keystroke dynamics, stylometry, and """"language production"""", which are novel hybrid features that capture the dynamics of a typists linguistic choices. Our study takes advantage of a large data set (~350 subjects) made up of relatively short samples (~450 characters) of free text. Experiments show that these features can recognize the cognitive demands of task that an unseen typist is engaged in, and can classify his or her demographics with better than chance accuracy. We correctly distinguish High vs. Low cognitively demanding tasks with accuracy up to 72.39%. Detection of non-native speakers of English is achieved with F1=0.462 over a baseline of 0.166, while detection of female typists reaches F1=0.524 over a baseline of 0.442. Recognition of left-handed typists achieves F1=0.223 over a baseline of 0.100. Further analyses reveal that novel relationships exist between language production as manifested through typing behavior, and both cognitive and demographic factors. HighlightsRecognition of cognitive task with linguistic and keystroke features with accuracy of 72.39%.Recognition of gender, handedness, and native-language from short unconstrained text at F1=.462, 0.223, and 0.524, respectively.Developed novel Language Production features hybridizing keystroke dynamics and stylometry."""	cognition;event (computing);keystroke dynamics	David Guy Brizan;Adam Goodkind;Patrick Koch;Kiran S. Balagani;Vir V. Phoha;Andrew Rosenberg	2015	Int. J. Hum.-Comput. Stud.	10.1016/j.ijhcs.2015.04.005	speech recognition;keystroke dynamics;computer science;artificial intelligence;linguistics;stylometry	NLP	-13.62240327590904	-78.38921853913119	87255
39cea183f286986c05b9877bc33fe34ee97c1e88	learning from the crowd with neural network	machine learning crowdsourcing neural network;consensus algorithm neural network supervised learning crowdsourced data machine learning;machine learning;neural nets learning artificial intelligence;crowdsourcing correlation biological neural networks bicmos integrated circuits noise measurement labeling;crowdsourcing;neural network	In general, the first step for supervised learning from crowdsourced data is integration. To obtain training data as traditional machine learning, the ground truth for each example in the crowdsourcing dataset must be integrated with consensus algorithms. However, some information and correlations among labels in the crowdsourcing dataset have discarded after integration. In order to study whether the information and correlations are useful for learning, we proposed three types of neural networks. Experimental results show that i) all the three types of neural networks have abilities to predict labels for future unseen examples, ii) when labelers have lower qualities, the information and correlations in crowdsourcing datasets, which are discarded by integration, does improve the performance of neural networks significantly, iii) when labelers have higher label qualities, the information and correlations have little impact on improving accuracy of neural networks.	algorithm;artificial neural network;crowdsourcing;ground truth;machine learning;supervised learning	Jingjing Li;Victor S. Sheng;Zhenyu Shu;Yanxia Cheng;Yuqin Jin;Yuan-feng Yan	2015	2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)	10.1109/ICMLA.2015.14	unsupervised learning;types of artificial neural networks;computer science;data science;online machine learning;machine learning;data mining;time delay neural network;deep learning;competitive learning;crowdsourcing;artificial neural network	ML	-17.639403077044204	-68.0696535600952	87320
101cd13f098395580891cd6281d73f1e28b1d884	measuring semantic similarity between sentences using a siamese neural network		The task of measure semantic redundancy between sentences demands a thorough interpretation from the reader because phrase meaning may be ambiguous. Detecting semantic similarity is a difficult problem because natural language, besides ambiguity, offers almost infinite possibilities to express the same idea. This paper adapts a siamese neural network architecture trained to measure the semantic similarity between two sentences through metric learning. The resulting solution should help in writing more efficient and informative text.	artificial neural network;dimensionality reduction;information;natural language;network architecture;recurrent neural network;semantic similarity;word embedding	Sigrid Mac Donald;Felipe Meneguzzi;Duncan Dubugras Alcoba Ruiz	2018	2018 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2018.8489433	artificial intelligence;architecture;semantic similarity;semantics;artificial neural network;ambiguity;natural language;machine learning;recurrent neural network;phrase;computer science	NLP	-18.08924948354034	-71.85659716565398	87397
22bbde633c8858321b45ab2b671ab3768f98c31c	unsupervised cross-domain word representation learning		Meaning of a word varies from one domain to another. Despite this important domain dependence in word semantics, existing word representation learning methods are bound to a single domain. Given a pair of source-target domains, we propose an unsupervised method for learning domain-specific word representations that accurately capture the domainspecific aspects of word semantics. First, we select a subset of frequent words that occur in both domains as pivots. Next, we optimize an objective function that enforces two constraints: (a) for both source and target domain documents, pivots that appear in a document must accurately predict the co-occurring non-pivots, and (b) word representations learnt for pivots must be similar in the two domains. Moreover, we propose a method to perform domain adaptation using the learnt word representations. Our proposed method significantly outperforms competitive baselines including the state-of-theart domain-insensitive word representations, and reports best sentiment classification accuracies for all domain-pairs in a benchmark dataset.	benchmark (computing);domain adaptation;emoticon;feature learning;loss function;machine learning;named-entity recognition;optimization problem;relationship extraction;unsupervised learning	Danushka Bollegala;Takanori Maehara;Ken-ichi Kawarabayashi	2015			natural language processing;speech recognition;computer science;machine learning;pattern recognition	NLP	-17.398188556300866	-66.89987079659097	87441
e8666594aa530a4561270140b570f3e6b813ec55	improvements to training an rnn parser		Many parsers learn sparse class distributions over trees to model natural language. Recursive Neural Networks (RNN) use much denser representations, yet can still achieve an F-score of 92.06% for right binarized sentences up to 15 words long. We examine an RNN model by comparing it with an abstract generative probabilistic model using a Deep Belief Network (DBN). The DBN provides both an upwards and downwards pointing conditional model, drawing a connection between RNN and Charniak type parsers, while analytically predicting average scoring parameters in the RNN. In addition, we apply the RNN to longer sentences and develop two methods which, while having negligible effect on short sentence parsing, are able to improve the parsing F-Score by 0.83% on longer sentences.	artificial neural network;deep belief network;discriminative model;natural language;parsing;random neural network;recursion (computer science);recursive neural network;sparse matrix;statistical model	Richard Billingsley;James Thomas Curran	2012			natural language processing;speech recognition	NLP	-17.47959233726312	-75.68006100763795	87477
27e0bf010d14f6d662bc537bdd42591677d86dd3	neural lattice language models		In this work, we propose a new language modeling paradigm that has the ability to perform both prediction and moderation of information flow at multiple granularities: neural lattice language models. These models construct a lattice of possible paths through a sentence and marginalize across this lattice to calculate sequence probabilities or optimize parameters. This approach allows us to seamlessly incorporate linguistic intuitions — including polysemy and the existence of multiword lexical items — into our language model. Experiments on multiple language modeling tasks show that English neural lattice language models that utilize polysemous embeddings are able to improve perplexity by 9.95% relative to a word-level baseline, and that a Chinese model that handles multi-character tokens is able to improve perplexity by 20.94% relative to a character-level baseline.		Jacob Buckman;Graham Neubig	2018	Transactions of the Association for Computational Linguistics	10.1162/tacl_a_00036	machine learning;artificial intelligence;computer science;perplexity;natural language processing;information flow (information theory);constructed language;lattice (order);moderation;language model;lexical item;intuition	NLP	-19.11970415303535	-74.02512398424143	87940
6c0ec9b57c2a39070e82b0b6fbd6b27ae3c00c5b	an analysis of disfluencies in the actor's speech for character design				Seung Suk Nam;Hye Rhang Cho;Sook Whan Cho	2012			psychology;cognitive psychology	HCI	-8.765532104866436	-79.12297376474494	88500
ceb934c405cf83c60464cddbab6de0d4981da7c1	the social evolution and communicative function of noun classification		A central goal of typological research is to characterize linguistic features in terms of both their functional role and their fit to social and cognitive systems. One longstanding puzzle concerns why certain languages employ grammatical gender, which assigns nouns to distinct classes and marks neighboring words for agreement. While historically noun classification has been viewed as a useless ornament with little apparent rhyme or reason, there is an accumulating body of evidence that native speakers use determiners to guide lexical access. Here, we compare the communicative function of gender marking in German (a deterministic system) to that of prenominal adjective use in English (a probabilistic one), finding that despite their differences, both systems efficiently smooth information over discourse, making upcoming nouns more equally predictable in context. We hypothesize that evolutionary pressures may favor one system over another on account of how easy they are for children and adults to acquire.	artificial intelligence;gender hci;item unique identification;lexicon;useless rules	Michael Ramscar;Melody Dye;Petar Milin;Richard Futrell	2015			noun;cognitive psychology;psychology;social evolution	NLP	-8.755351291688807	-77.44095690855745	88525
4bbdf47d0db6f8a3450478d01bab1a72f50a8125	the placement of the head that maximizes predictability. an information theoretic approach		The minimization of the length of syntactic dependencies is a well-stablished principle of word order and the basis of a mathematical theory of word order. Here we complete that theory from the perspective of information theory, adding a competing word order principle: the maximization of predictability of a target element. These two principles are in conflict: to maximize the predictability of the head, the head should appear last, which maximizes the costs with respect to dependency length minimization. The implications of such a broad theoretical framework to understand the optimality, diversity and evolution of the six possible orderings of subject, object and verb are reviewed.	expectation–maximization algorithm;information theory	Ramon Ferrer-i-Cancho	2017	Glottometrics		mathematical optimization;simulation;theoretical computer science	NLP	-9.303531736319306	-74.8850844719815	88624
38f17696b684070f15d6d07d5e0ffa4631e5661d	neural utterance ranking model for conversational dialogue systems		In this study, we present our neural utterance ranking (NUR) model, an utterance selection model for conversational dialogue agents. The NUR model ranks candidate utterances with respect to their suitability in relation to a given context using neural networks; in addition, a dialogue system based on the model converses with humans using highly ranked utterances. Specifically, the model processes word sequences in utterances and utterance sequences in context via recurrent neural networks. Experimental results show that the proposed model ranks utterances with higher precision relative to deep learning and other existing methods. Furthermore, we construct a conversational dialogue system based on the proposed method and conduct experiments on human subjects to evaluate performance. The experimental result indicates that our system can offer a response that does not provoke a critical dialogue breakdown with a probability of 92% and a very natural response with a probability of 58%.	artificial neural network;deep learning;dialog system;dialog tree;experiment;knowledge management;naive bayes classifier;question answering;recurrent neural network;tsd	Michimasa Inaba;Kenichi Takahashi	2016			artificial intelligence;natural language processing;computer science;speech recognition;adjacency pairs;utterance;ranking	NLP	-16.264102479932422	-72.80954286456037	89078
e9112d1f7220a8a44b004f74ba4041a80842f133	preliminary exploration of formula embedding for mathematical information retrieval: can mathematical formulae be embedded like a natural language?		While neural network approaches are achieving breakthrough performance in the natural language related elds, there have been few similar aempts at mathematical language related tasks. In this study, we explore the potential of applying neural representation techniques to Mathematical Information Retrieval (MIR) tasks. In more detail, we rst briey analyze the characteristic dierences between natural language and mathematical language. en we design a “symbol2vec” method to learn the vector representations of formula symbols (numbers, variables, operators, functions, etc.) Finally, we propose a “formula2vec” based MIR approach and evaluate its performance. Preliminary experiment results show that there is a promising potential for applying formula embedding models to mathematical language representation and MIR tasks.	artificial neural network;embedded system;information retrieval;natural language	Liangcai Gao;Zhuoren Jiang;Yue Yin;Ke Yuan;Zuoyu Yan;Zhi Tang	2017	CoRR		language of mathematics;information retrieval;computer science;artificial neural network;operator (computer programming);theoretical computer science;natural language;embedding	ML	-11.767088488263752	-68.09715670673886	89224
36bd0df6c7e5c5ddb7c7fd25df8ddfdd84a74e42	multi-task learning for argumentation mining in low-resource settings		We investigate whether and where multitask learning (MTL) can improve performance on NLP problems related to argumentation mining (AM), in particular argument component identification. Our results show that MTL performs particularly well (and better than single-task learning) when little training data is available for the main task, a common scenario in AM. Our findings challenge previous assumptions that conceptualizations across AM datasets are divergent and that MTL is difficult for semantic or higher-level tasks.	computer multitasking;multi-task learning;natural language processing	Claudia Schulz;Steffen Eger;Johannes Daxenberger;Tobias Kahse;Iryna Gurevych	2018			natural language processing;artificial intelligence;machine learning;argumentation theory;computer science;multi-task learning;training set	ML	-17.424921181608084	-68.97055578603785	89297
3566fa92a3a57ca4592e4f86e6537be5faae39c0	could both be right? children's and adults' sensitivity to subjectivity in language		While some word meanings, like “spotted,” depend on intersubjectively accessible properties of the world, others like “pretty” invoke speakers’ subjective beliefs. We explored children and adults’ sensitivity to the subjectivity of a range of adjectives, including words like “spotted” and “pretty,” but also words like “tall,” which are evaluated relative to a standard. Participants saw two speakers who had independently experienced sets of exemplars of a novel object kind disagree about whether a critical exemplar was, e.g., “tall,” “pretty,” and “spotted.” In Experiments 1 and 3, speakers had seen distinct sets of exemplars, while in Experiments 2 and 4, the sets were identical. Adults always judged disagreements over words like “pretty” as faultless—indicating that both speakers “could be right”—and permitted less faultless disagreement for ones like “tall” when the speakers had experienced identical sets of exemplars. Strikingly, children did not respond in an adult-like manner until age 8 or 9, but their explanations for speakers’ conflicting assertions suggested some sensitivity to the kinds of knowledge relevant for evaluating different adjectives.	experiment	Ruthe Foushee;Mahesh Srinivasan	2017			cognitive psychology;psychology;subjectivity	NLP	-8.01987348419934	-76.90053391575876	89799
6119418ebd2ebdbf642e62d746ea3d5d06d42b48	a stochastic approach to parsing	stochastic approach	I. Simulated annealing (e.g. Kirkpatrick et alo 1983, Bridle & Moore 1984, Ackley et al. 1985) is a stochastic computational technique for finding optimal solutions to combinatorial problems for which the combinatorial explosion phenomenon rules out the possibility of systematically examining each alternative. It is currently being applied to the practical problem of optimizing the physical design of computer circuitry, and to the theoretical problems of resolving patterns of auditory and visual stimulation into meaningful arrangements of phonemes and three-dimensional objects. Grammatical parsing -resolving unanalysed linear sequences of words into meaningful grammatical structures -can be regarded as a perception problem logically analogous to those just cited, and simulated annealing holds great promise as a parsing technique.	computation;electronic circuit;parsing;physical design (electronics);simulated annealing	Geoffrey Sampson	1986			natural language processing;parser combinator;bottom-up parsing;top-down parsing	AI	-9.169579905966943	-73.68894346398896	90027
402ea2014002a23700a50afd1edb49376cc7a8d8	k-ffnn: a priori knowledge infused feed-forward neural networks		Recurrent neural network (RNN) are being extensively used over feed-forward neural networks (FFNN) because of their inherent capability to capture temporal relationships that exist in the sequential data such as speech. This aspect of RNN is advantageous especially when there is no a priori knowledge about the temporal correlations within the data. However, RNNs require large amount of data to learn these temporal correlations, limiting their advantage in low resource scenarios. It is not immediately clear (a) how a priori temporal knowledge can be used in a FFNN architecture (b) how a FFNN performs when provided with this knowledge about temporal correlations (assuming available) during training. The objective of this paper is to explore k-FFNN, namely a FFNN architecture that can incorporate the a priori knowledge of the temporal relationships within the data sequence during training and compare k-FFNN performance with RNN in a low resource scenario. We evaluate the performance of k-FFNN and RNN by extensive experimentation on MediaEval 2016 audio data (Emotional Impact of Movies task). Experimental results show that the performance of k-FFNN is comparable to RNN, and in some scenarios k-FFNN performs better than RNN when temporal knowledge is injected into FFNN architecture. The main contributions of this paper are (a) fusing a priori knowledge into FFNN architecture to construct a k-FFNN and (b) analyzing the performance of k-FFNN with respect to RNN for different size of training data.	convolutional neural network;emoticon;feedforward neural network;neural networks;random neural network;recurrent neural network	Sri Harsha Dumpala;Rupayan Chakraborty;Sunil Kumar Kopparapu	2017	CoRR		computer science;artificial intelligence;machine learning;data mining	ML	-14.127046750073857	-73.10948308589943	90646
f8e267d9883bc34d7c04cf47f818a2082514b1cf	incorporating knowledge into neural network for text representation		Abstract Text representations is a key task for many natural language processing applications such as document classification, ranking, sentimental analysis and so on. The goal of it is to numerically represent the unstructured text documents so that they can be computed mathematically. Most of the existing methods leverage the power of deep learning to produce a representation of text. However, these models do not consider about the problem that text itself is usually semantically ambiguous and reflects limited information. Due to this reason, it is necessary to seek help from external knowledge base to better understand text. In this paper, we propose a novel framework named Text Concept Vector which leverages both the neural network and the knowledge base to produce a high quality representation of text. Formally, a raw text is primarily conceptualized and represented by a set of concepts through a large taxonomy knowledge base. After that, a neural network is used to transform the conceptualized text into a vector form which encodes both the semantic information and the concept information of the original text. We test our framework on both the sentence level task and the document level task. The experimental results illustrate the effectiveness of our work.	artificial neural network	Yiming Li;Baogang Wei;Yonghuai Liu;Liang Yao;Hui Chen;Jifang Yu;Wenhao Zhu	2018	Expert Syst. Appl.	10.1016/j.eswa.2017.11.037	sentiment analysis;machine learning;time delay neural network;deep learning;artificial neural network;knowledge base;natural language processing;feature learning;artificial intelligence;computer science;sentence;document classification	NLP	-18.045096658845065	-67.89698251911953	91177
5a3a8e0a3ee8711ca9e7df7d1a22e532680c78ed	ensemble distillation for neural machine translation		Knowledge distillation describes a method for training a student network to perform better by learning from a stronger teacher network. In this work, we run experiments with different kinds of teacher networks to enhance the translation performance of a student Neural Machine Translation (NMT) network. We demonstrate techniques based on an ensemble and a best BLEU teacher network. We also show how to benefit from a teacher network that has the same architecture and dimensions of the student network. Furthermore , we introduce a data filtering technique based on the dissimilarity between the forward translation (obtained during knowledge distillation) of a given source sentence and its target reference. We use TER to measure dissimilarity. Finally, we show that an ensemble teacher model can significantly reduce the student model size while still getting performance improvements compared to the baseline student network.	bleu;baseline (configuration management);experiment;neural machine translation	Markus Freitag;Yaser Al-Onaizan;Baskaran Sankaran	2017	CoRR		natural language processing;speech recognition;computer science;artificial intelligence;machine learning	NLP	-15.24996853958295	-74.82117156367833	91236
608634cc2a5e9a2f3fc49aa10cb4572801462d07	of crowds and corpora: a marriage of measures		We discuss the relationship between a word's corpus frequency and its prevalence –the proportion of people who know the word– and show that they are complementary measures. We show that adding word prevalence as a predictor of lexical decision reaction time in the Dutch lexicon project increases explained variance by more than 10%. In addition, we show that, for the same dataset, word prevalence is the best independent predictor of word processing time.	kerrison predictor;lexicon;text corpus	Emmanuel Keuleers;Pawel Mandera;Michaël A. Stevens;Marc Brysbaert	2015			crowds;lexicon;psychology;explained variation;social psychology;lexical decision task	NLP	-13.153462441818425	-78.9017147579681	91434
462fe97ce53e58c8e2cb01c925b46bcf3bb53eda	how features of the human face affect recognition: a statistical comparison of three face recognition algorithms	empirical evidence;facial expression;statistical model;regression analysis;principal component analysis;face recognition;graph matching;principle component analysis;image classification;logistic regression	Recognition difficulty is statistically linked to 11 subject covariate factors such as age and gender for three face recognition algorithms: principle components analysis, an interpersonal image difference classifier, and an elastic bunch graph matching algorithm. The covariates assess race, gender, age, glasses use, facial hair, bangs, mouth state, complexion, state of eyes, makeup use, and facial expression. We use two statistical models. First, an ANOVA relates covariates to normalized similarity scores. Second, logistic regression relates subject covariates to probability of rank one recognition. These models have strong explanatory power as measured by R/sup 2/ and deviance reduction, while providing complementary and corroborative results. Some factors, like changes to the eye status, affect all algorithms similarly. Other factors, such as race, affect different algorithms differently. Tabular and graphical summaries of results provide a wealth of empirical evidence. Plausible explanations of many results can be motivated from knowledge of the algorithms. Other results are surprising and suggest a need for further study.	algorithm;elastic matching;facial recognition system;generalized linear model;graphical user interface;information;logistic regression;principal component analysis;statistical model;table (information)	Geof H. Givens;J. Ross Beveridge;Bruce A. Draper;Patrick Grother;P. Jonathon Phillips	2004	Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004.	10.1109/CVPR.2004.126	facial recognition system;computer vision;computer science;machine learning;pattern recognition;mathematics;statistics;principal component analysis	Vision	-6.097074075974846	-74.70180260411794	91829
167847f5364b250fe13b0eee4ed4cd8a1495e5d0	coreference resolution using competition learning approach	preference relationship;candidate filter;competition criterion;antecedent candidate;coreference resolution;computational cost;data noise;muc-7 data;single-candidate model;preferred candidate;competitive learning	In this paper we propose a competition learning approach to coreference resolution. Traditionally, supervised machine learning approaches adopt the singlecandidate model. Nevertheless the preference relationship between the antecedent candidates cannot be determined accurately in this model. By contrast, our approach adopts a twin-candidate learning model. Such a model can present the competition criterion for antecedent candidates reliably, and ensure that the most preferred candidate is selected. Furthermore, our approach applies a candidate filter to reduce the computational cost and data noises during training and resolution. The experimental results on MUC-6 and MUC-7 data set show that our approach can outperform those based on the singlecandidate model.	algorithm;algorithmic efficiency;anaphora (linguistics);baseline (configuration management);computation;computational complexity theory;context-free grammar;loose coupling;machine learning;parallel computing;supervised learning	Xiaofeng Yang;Guodong Zhou;Jian Su;Chew Lim Tan	2003			semi-supervised learning;unsupervised learning;computer science;artificial intelligence;online machine learning;machine learning;pattern recognition;stability;competitive learning;computational learning theory;active learning;generalization error	AI	-18.026685606725923	-68.53578795365527	91879
fb12857edff6ff4cf976cad0e502fdf1fdc9635e	inferring generative model structure with static analysis		Obtaining enough labeled data to robustly train complex discriminative models is a major bottleneck in the machine learning pipeline. A popular solution is combining multiple sources of weak supervision using generative models. The structure of these models affects training label quality, but is difficult to learn without any ground truth labels. We instead rely on these weak supervision sources having some structure by virtue of being encoded programmatically. We present Coral, a paradigm that infers generative model structure by statically analyzing the code for these heuristics, thus reducing the data required to learn structure significantly. We prove that Coral's sample complexity scales quasilinearly with the number of heuristics and number of relations found, improving over the standard sample complexity, which is exponential in n for identifying nth degree relations. Experimentally, Coral matches or outperforms traditional structure learning approaches by up to 3.81 F1 points. Using Coral to model dependencies instead of assuming independence results in better performance than a fully supervised model by 3.07 accuracy points when heuristics are used to label radiology data without ground truth labels.	coral - body part;discriminative model;experiment;generative model;ground truth;heuristics;inference;interaction;machine learning;programming languages;programming language;programming paradigm;radiology;sample complexity;static program analysis;test set;tracer;emotional dependency;exponential	Paroma Varma;Bryan D. He;Payal Bajaj;Imon Banerjee;Nishith Khandwala;Daniel L. Rubin;Christopher Ré	2017	Advances in neural information processing systems		generative grammar;discriminative model;artificial intelligence;labeled data;machine learning;generative model;computer science;heuristics;ground truth;static analysis;bottleneck	ML	-15.41022484441278	-70.32533272572162	92045
224d10923aea7b12af6b441fb79e640cb727b502	semi-supervised nmf with time-frequency annotations for single-channel source separation		We formulate a novel extension of nonnegative matrix factorization (NMF) to take into account partial information on source-specific activity in the spectrogram. This information comes in the form of masking coefficients, such as those found in an ideal binary mask. We show that state-ofthe-art results in source separation may be achieved with only a limited amount of correct annotation, and furthermore our algorithm is robust to incorrect annotations. Since in practice ideal annotations are not observed, we propose several supervision scenarios to estimate the ideal masking coefficients. First, manual annotations by a trained user on a dedicated graphical user interface are shown to provide satisfactory performance although they are prone to errors. Second, we investigate simple learning strategies to predict the Wiener coefficients based on local information around a given time-frequency bin of the spectrogram. Results on single-channel source separation show that time-frequency annotations allow to disambiguate the source separation problem, and learned annotations open the way for a completely unsupervised learning procedure for source separation with no human intervention.	algorithm;coefficient;graphical user interface;non-negative matrix factorization;pattern matching;semi-supervised learning;semiconductor industry;simple features;source separation;spectrogram;time–frequency representation;unsupervised learning;variable shadowing	Augustin Lefèvre;Francis R. Bach;Cédric Févotte	2012				ML	-17.346433608567892	-79.36449409515117	92103
fd4a23990114bb86c149c35c0feff5c055cd9c11	text classification with heterogeneous information network kernels	text classification;document modeling;heterogeneous information networks	Text classification is an important problem with many applications. Traditional approaches represent text as a bagof-words and build classifiers based on this representation. Rather than words, entity phrases, the relations between the entities, as well as the types of the entities and relations carry much more information to represent the texts. This paper presents a novel text as network classification framework, which introduces 1) a structured and typed heterogeneous information networks (HINs) representation of texts, and 2) a meta-path based approach to link texts. We show that with the new representation and links of texts, the structured and typed information of entities and relations can be incorporated into kernels. Particularly, we develop both simple linear kernel and indefinite kernel based on metapaths in the HIN representation of texts, where we call them HIN-kernels. Using Freebase, a well-known world knowledge base, to construct HIN for texts, our experiments on two benchmark datasets show that the indefinite HIN-kernel based on weighted meta-paths outperforms the state-of-theart methods and other HIN-kernels.	benchmark (computing);commonsense knowledge (artificial intelligence);document classification;encode;entity;experiment;freebase;kernel (operating system);knowledge base;similarity measure;statistical classification	Chenguang Wang;Yangqiu Song;Haoran Li;Ming Zhang;Jiawei Han	2016			natural language processing;computer science;machine learning;data mining	AI	-18.937128433811093	-66.23931679332941	92201
78ecfa8f578109c1be0bcf85d89c68e5fb7a8c70	a neural multi-task learning framework to jointly model medical named entity recognition and normalization		State-of-the-art studies have demonstrated the superiority of joint modeling over pipeline implementation for medical named entity recognition and normalization due to the mutual benefits between the two processes. To exploit these benefits in a more sophisticated way, we propose a novel deep neural multi-task learning framework with explicit feedback strategies to jointly model recognition and normalization. On one hand, our method benefits from the general representations of both tasks provided by multi-task learning. On the other hand, our method successfully converts hierarchical tasks into a parallel multi-task setting while maintaining the mutual supports between tasks. Both of these aspects improve the model performance. Experimental results demonstrate that our method performs significantly better than state-of-theart approaches on two publicly available medical literature datasets.		Sendong Zhao;Ting Liu;Sicheng Zhao;Fei Wang	2018	CoRR		machine learning;artificial intelligence;normalization (statistics);named-entity recognition;exploit;multi-task learning;computer science	NLP	-17.277834387954336	-70.3524464220739	92280
119322b273db8c5610af01d69766cd96d1681550	deep-belief-network based rescoring approach for handwritten word recognition	handwriting recognition;hmm handwriting recognition deep belief network;rimes dataset deep belief network based rescoring handwritten word recognition handwriting recognition systems word hypotheses rescoring dbn recurrent neural network sequential text recognition system n best recognition hypotheses word images verification approach mlp based rescoring;training;hmm;deep belief network;accuracy;hidden markov models;text analysis belief networks formal verification handwriting recognition image processing recurrent neural nets;hidden markov models character recognition training text recognition handwriting recognition accuracy recurrent neural networks;recurrent neural networks;text recognition;character recognition	This paper presents a novel verification approach towards improvement of handwriting recognition systems using a word hypotheses rescoring scheme by Deep Belief Networks (DBNs). A recurrent neural network based sequential text recognition system is used at first to provide the N-best recognition hypotheses of word images. Word hypotheses are aligned with the word image to obtain the character boundaries. Then, a verification approach using a DBN classifier is performed for each character segments. DBNs are recently proved to be very effective for a variety of machine learning problems. The character probabilities obtained from DBNs are next combined with the base recognition system. Finally, the N-best recognition hypotheses list is reranked according to the new score. We have compared our proposed approach with an MLP based rescoring approach on the Rimes dataset. The results obtained show that the verification approach using DBNs outperforms that of MLP systems.	artificial neural network;bayesian network;deep belief network;experiment;handwriting recognition;machine learning;memory-level parallelism;optical character recognition;quad flat no-leads package;recurrent neural network	Partha Pratim Roy;Youssouf Chherawala;Mohamed Cheriet	2014	2014 14th International Conference on Frontiers in Handwriting Recognition	10.1109/ICFHR.2014.91	speech recognition;intelligent character recognition;computer science;recurrent neural network;intelligent word recognition;machine learning;pattern recognition;accuracy and precision;hidden markov model	AI	-17.990402786875006	-79.30609888844275	92294
00982b90cb085bb78bfd95b9524dff46dde3b4ed	brain electric microstate and perception of simultaneously audiovisual presentation	microstate;brain;cognition;visual features;audiovisual perception;audio visual;event related potential erp	Associations between letters and speech sounds form the basis of reading. Learning the correspondences between them is a crucial step in reading acquisition. Chinese and Korean subjects were presented with Mandarin Chinese tones (auditory: A), letters (visual: V), and simultaneous tones and character (audiovisual: AV). The neural basis of this interaction was investigated by subtracting the event-related potentials (ERPs) to the A and the V stimuli alone from the ERP to the combined AV stimuli (i.e. interaction = AV – (A+V)). The Korean group showed larger mean interaction amplitude and longer in time than the Chinese group. This reveals that language experience influences the early cortical automatic processing of linguistically relevant suprasegmental pitch contour in lexical tone. These results suggest that efficient processing of associations between letters and speech sounds relies on neural mechanisms similar to those naturally evolved for integrating audiovisual speech.	erp;super robot monkey team hyperforce go!	Wichian Sittiprapaporn;Jun Soo Kwon	2009		10.1007/978-3-642-04274-4_36	computer vision;speech recognition;cognition;microstate	ML	-9.083282800417507	-80.02593319962935	92449
7442a18a55f257a68f21d0cbb8b1395f8915a452	jointly predicting predicates and arguments in neural semantic role labeling		Recent BIO-tagging-based neural semantic role labeling models are very high performing, but assume gold predicates as part of the input and cannot incorporate span-level features. We propose an endto-end approach for jointly predicting all predicates, arguments spans, and the relations between them. The model makes independent decisions about what relationship, if any, holds between every possible word-span pair, and learns contextualized span representations that provide rich, shared input features for each decision. Experiments demonstrate that this approach sets a new state of the art on PropBank SRL without gold predicates.1		Luheng He;Kenton Lee;Omer Levy;Luke S. Zettlemoyer	2018			machine learning;predicate (grammar);computer science;artificial intelligence;propbank;natural language processing;semantic role labeling	NLP	-18.152052548458855	-72.69836939508869	93207
2f46f153242e4308881eaa519fc99c5a850f92d2	function, geometry and spatial prepositions: three experiments	spatial prepositions;geometry;function;spatial language;in;spatial representation	In this paper the results of three experiments are reported which address the issue of the relative extent to which functional relations versus geometric relations affect spatial language. The experiments examine the role of a discourse context on the use and rating of the prepositionin to describe a visual scene where the constraint of spatial containment between figure (object located) and ground (reference object) does not hold. All three experiments demonstrate that in is used more and rated to be significantly more appropriate in a functional context than in a no context condition. The implications of these studies for spatial language and spatial representation are discussed.	experiment	Kenny R. Coventry	1999	Spatial Cognition & Computation	10.1023/A:1010064926058	natural language processing;computer vision;computer science;mathematics;geometry;communication;function	NLP	-8.298791253822765	-76.02937500497983	93971
bfec06adf9ba39cb5a3c6d7c90cce827a4aefea2	role of featural and configural information in familiar and unfamiliar face recognition	integrable model;computer vision;human subjects;face recognition;spatial relation	Using psychophysics we investigated to what extent human face recognition relies on local information in parts (featural information) and on their spatial relations (configural information). This is particularly relevant for biologically motivated computer vision since recent approaches have started considering such featural information. In Experiment 1 we showed that previously learnt faces could be recognized by human subjects when they were scrambled into constituent parts. This result clearly indicates a role of featural information. Then we determined the blur level that made the scrambled part versions impossible to recognize. This blur level was applied to whole faces in order to create configural versions that by definition do not contain featural information. We showed that configural versions of previously learnt faces could be recognized reliably. In Experiment 2 we replicated these results for familiar face recognition. Both Experiments provide evidence in favor of the view that recognition of familiar and unfamiliar faces relies on featural and configural information. Furthermore, the balance between the two does not differ for familiar and unfamiliar faces. We propose an integrative model of familiar and unfamiliar face recognition and discuss implications for biologically motivated computer vision algorithms for face recognition.	algorithm;computer vision;experiment;facial recognition system;gaussian blur	Adrian Schwaninger;Janek S. Lobmaier;Stephan M. Collishaw	2002		10.1007/3-540-36181-2_64	psychology;computer vision;communication;social psychology	Vision	-6.303579540073458	-75.78011788944399	93972
65c287ec6efcab46aede129fa221578372b04d6a	the need of structured data: introducing the okgraph project		Although many computational problems can be approached using Deep Learning, in this position paper we argue that in the case of Information Retrieval tasks this is not mandatory and even detrimental whenever alternatives exist. Instead of learning (by training) how to solve the full problem, we suggest to split it into two sub-problems: a) producing structured data (specifically knowledge graphs) out of the corpora, and b) providing usable tools (including natural language) to querying such structured data. Motivated by this two-step approach and its need of structured data, we introduce the Open Knowledge Graph (OKgraph) project, an initiative recently funded by Regione Autonoma della Sardegna aiming at providing insights on the first part of the problem: a general way of generating knowledge graphs from text corpora, unsupervisedly.	computation;computational problem;data model;deep learning;emoticon;information retrieval;knowledge graph;natural language;open knowledge;text corpus	Maurizio Atzori	2017			data mining;data model;computer science;unsupervised learning;structured systems analysis and design method	AI	-17.186004589834408	-68.16025437582822	94043
4e0aab95fc3d443b20a7f0509b6953ed30c78e5a	two improved continuous bag-of-word models		Data representation is a fundamental task in machine learning, which affects the performance of the whole machine learning system. In the past few years, with the rapid development of deep learning, the models for word embedding based on neural networks have brought new inspiration to the research of natural language processing. In this paper, two kinds of schemes for improving the Continuous Bag-of-Words (CBOW) model are proposed. On one hand, the relative positions of adjacent words are taken as weights for the input layer of the model; on the other hand, the context is considered, and which can take part in the training course when the prediction of next target word is to be made. Experimental results show that our proposed models outperform the classical CBOW model.	artificial neural network;backpropagation;bag-of-words model;computation;deep learning;ising model;machine learning;mathematical model;natural language processing;software propagation;text simplification;vii;word embedding	Qi Wang;Jungang Xu;Hong Chen;Ben He	2017	2017 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2017.7966208	machine learning;word embedding;artificial intelligence;pattern recognition;artificial neural network;semantics;deep learning;computer science;external data representation;context model	ML	-16.985089194969387	-72.5265190858038	94051
dd639736c0e73bb07d1b0daf3502ebaa9a1eee57	the suitable timing of visual sensing in error recovery using task stratification and error classification		Judgment of errors for recovery is performed during execution of the system. Ideally, it is desirable for the judgment to be performed at several times. However, in that case, many sensors would be needed and it would lead to disturbing the workflow. Therefore, it is important to be able to judge an error efficiently in the most suitable timing and within a few attempts. This paper describes a method for efficient timing of visual sensing for error recovery.	sensor	Akira Nakamura;Kazuyuki Nagata;Kensuke Harada;Natsuki Yamanobe	2017	JRNAL	10.2991/jrnal.2017.4.2.6	machine learning;artificial intelligence;computer science;pattern recognition	HCI	-4.796254337397182	-72.61113282631483	94128
04164d7a30491c0c7fd4c2351e1a65111b331dab	towards an hpsg analysis of object shift in danish	danish;yiddish;hpsg;german	This paper develops an analysis of object shift in Danish. We suggest that object shift is best analyzed lexically as an alternative mapping from the arg-st list to spr and comps. We treet shifted objects as specifiers, while non-shifted objects are treated as complements. Complex fronting cases with stranded shifted pronouns are explained by argument attraction of the specifiers from the fronted projection as is common for HPSG analyses of partial frontings in German where it is assumed that complements of the fronted verbs are attracted. Hence, our analysis not just gets the language specific facts right but also provides an account that extends nicely to cover crosslinguistic generalizations with the same mechansims.	head-driven phrase structure grammar;lexicon;super robot monkey team hyperforce go!	Stefan Müller;Bjarne Ørsnes	2012		10.1007/978-3-642-39998-5_5	computer science;yiddish;head-driven phrase structure grammar;danish;linguistics;german	NLP	-12.249369976721118	-79.84578849066479	94250
6bc9c050bd7503dd695e8d3b613bd85efb3e1592	record2vec: unsupervised representation learning for structured records		Structured records - data with a fixed number of descriptive fields (or attributes) - are often represented by one-hot encoded or term frequency-inverse document frequency (TF-IDF) weighted vectors. These vectors are typically sparse and long, and are inefficient in representing structured records. Here, we introduce Record2Vec, a framework for generating dense embeddings of structured records by training associations between attributes within record instances. We build our embedding from a simple premise that structured records have attributes that are associated, and therefore we can train the embedding of an attribute based on other attributes (or context), much like how we train embeddings for words based on their surrounding context. Because this embedding technique is general and does not assume the availability of any labeled data, it is extendable across different domains and fields. We demonstrate its utility in the context of clustering, record matching, movie rating and movie genre prediction.		Adelene Y. L. Sim;Andrew Borthwick	2018	2018 IEEE International Conference on Data Mining (ICDM)	10.1109/ICDM.2018.00165	machine learning;task analysis;premise;computer science;cluster analysis;unsupervised learning;artificial intelligence;feature learning;data modeling;embedding;vocabulary	DB	-16.470242770063702	-68.00461984730751	94348
48139a9e11c8fceaa1a801832e4aa1df7a336183	a deep learning architecture for de-identification of patient notes: implementation and evaluation		De-identification is the process of removing 18 protected health information (PHI) from clinical notes in order for the text to be considered not individually identifiable. Recent advances in natural language processing (NLP) has allowed for the use of deep learning techniques for the task of de-identification. In this paper, we present a deep learning architecture that builds on the latest NLP advances by incorporating deep contextualized word embeddings and variational drop out Bi-LSTMs. We test this architecture on two gold standard datasets and show that the architecture achieves state-of-the-art performance on both data sets while also converging faster than other systems without the use of dictionaries or other knowledge sources.	de-identification;deep learning;dictionary;natural language processing;protected health information;variational principle	Yasser A Ghobara;Philipp Burckhardt;Rema Padman	2018	CoRR		machine learning;architecture;natural language processing;deep learning;de-identification;protected health information;computer science;data set;artificial intelligence	NLP	-16.16611726133624	-74.28215897262525	94418
3085671f6232aac4492ad861d09334b8f3a7e2a7	movie fill in the blank with adaptive temporal attention and description update		Recently, a new type of video understanding task called Movie-Fill-in-the-Blank (MovieFIB) has attracted many research attentions. Given a pair of movie clip and description with one blank word as input, MovieFIB aims to automatically predict the blank word. Because of the advantage in processing sequence data, Long-Short Term Memory (LSTM) has been used as a key component in existing MovieFIB methods to generate representations of videos and descriptions. However, most of these methods fail to emphasize the salient parts of videos. To address this problem, in this paper we propose to use a novel LSTM network called LSTM with Linguistic gate (LSTMwL), which exploits adaptive temporal attention for MovieFIB. Specifically, we first use LSTM to produce video features, which are then used to update the text representation. Finally, we put the updated text into two opposite directional LSTMwL layers to infer the blank word. Experimental results demonstrate that our approach outperforms state-of-the-art models for MovieFIB.	frame (video);long short-term memory;norm (social);question answering;video clip	Jie Chen;Jie Shao;Fumin Shen;Chengkun He;Lianli Gao;Heng Tao Shen	2017		10.1145/3132847.3132922	information retrieval;data mining;computer science;blank;question answering;exploit	AI	-15.01339648640304	-69.52140521284267	94538
420f2b9981e00f395dd3620e7682725f4ea265e4	the semantic organization of the animal category: evidence from semantic verbal fluency and network theory	human memory;categorisation;semantic memory;red semantica;etude experimentale;semantic network;lenguaje;semantics;langage;switching clustering;semantica;semantique;statistical model;animal;fluence verbale;organizacion memoria;reseau semantique;categorizacion;semantic information;theory;network model;cognition;teoria;organisation memoire;modele statistique;cognicion;modelo estadistico;network theory;memory organization;language;memoire semantique;estudio experimental;theorie;categorization;memoria semantica;fluidez verbal;verbal fluency	Semantic memory is the subsystem of human memory that stores knowledge of concepts or meanings, as opposed to life-specific experiences. How humans organize semantic information remains poorly understood. In an effort to better understand this issue, we conducted a verbal fluency experiment on 200 participants with the aim of inferring and representing the conceptual storage structure of the natural category of animals as a network. This was done by formulating a statistical framework for co-occurring concepts that aims to infer significant concept–concept associations and represent them as a graph. The resulting network was analyzed and enriched by means of a missing links recovery criterion based on modularity. Both network models were compared to a thresholded co-occurrence approach. They were evaluated using a random subset of verbal fluency tests and comparing the network outcomes (linked pairs are clustering transitions and disconnected pairs are switching transitions) to the outcomes of two expert human raters. Results show that the network models proposed in this study overcome a thresholded co-occurrence approach, and their outcomes are in high agreement with human evaluations. Finally, the interplay between conceptual structure and retrieval mechanisms is discussed.	childhood onset fluency disorder;cluster analysis;evaluation;experience;graph - visual representation;inference;mental association;network theory;subgroup;statistical cluster	Joaquín Goñi;Gonzalo Arrondo;Jorge Sepulcre;Iñigo Martincorena;Nieves Vélez de Mendizábal;Bernat Corominas-Murtra;Bartolomé Bejarano;Sergio Ardanza-Trevijano;Herminia Peraita;Dennis P. Wall;Pablo Villoslada	2010	Cognitive Processing	10.1007/s10339-010-0372-x	network theory;psychology;natural language processing;statistical model;cognition;semantic memory;artificial intelligence;network model;semantics;linguistics;language;memory organisation;semantic network;memory;communication;verbal fluency test;theory;cognitive science;categorization	AI	-10.0645440037561	-76.51601105464779	94623
51bec0d829ac2763d2f127d0ca14e1b7232e2356	style detection for free verse poetry from text and speech		Modern and post-modern free verse poems feature a large and complex variety in their poetic prosodies that falls along a continuum from a more fluent to a more disfluent and choppy style. As the poets of modernism overcame rhyme and meter, they oriented themselves in these two opposing directions, creating a free verse spectrum that calls for new analyses of prosodic forms. We present a method, grounded in philological analysis and current research on cognitive (dis)fluency, for automatically analyzing this spectrum. We define and relate six classes of poetic styles (ranging from parlando to lettristic decomposition) by their gradual differentiation. Based on this discussion, we present a model for automatic prosodic classification of spoken free verse poetry that uses deep hierarchical attention networks to integrate the source text and audio and predict the assigned class. We evaluate our model on a large corpus of German author-read postmodern poetry and find that classes can reliably be differentiated, reaching a weighted f-measure of 0.73, when combining textual and phonetic evidence. In our further analyses, we validate the model’s decision-making process, the philologically hypothesized continuum of fluency and investigate the relative importance of various features.	apache continuum;f1 score;text corpus;triune continuum paradigm;verse protocol	Timo Baumann;Hussein Hussein;Burkhard Meyer-Sickendiek	2018			literature;computer science;free verse;natural language processing;artificial intelligence;poetry	NLP	-12.585446837655349	-80.01116415201238	94804
6356a18fe5136c448f14af8d1775ead09d39adac	dynamic transfer learning for named entity recognition		State-of-the-art named entity recognition (NER) systems have been improving continuously using neural architectures over the past several years. However, many tasks including NER require large sets of annotated data to achieve such performance. In particular, we focus on NER from clinical notes, which is one of the most fundamental and critical problems for medical text analysis. Our work centers on effectively adapting these neural architectures towards lowresource settings using parameter transfer methods. We complement a standard hierarchical NER model with a general transfer learning framework consisting of parameter sharing between the source and target tasks, and showcase scores significantly above the baseline architecture. These sharing schemes require an exponential search over tied parameter sets to generate an optimal configuration. To mitigate the problem of exhaustively searching for model optimization, we propose the Dynamic Transfer Networks (DTN), a gated architecture which learns the appropriate parameter sharing scheme between source and target datasets. DTN achieves the improvements of the optimized transfer learning framework with just a single training setting, effectively removing the need for exponential search.		Parminder Bhatia;Kristjan Arumae;Busra Celikkaya	2018	CoRR			ML	-17.105894939773037	-72.22784220338286	95182
c0b62315a0c61ec8159b18bb198ea7a5af2acb14	handwriting recognition by attribute embedding and recurrent neural networks		Handwriting recognition consists in obtaining the transcription of a text image. Recent word spotting methods based on attribute embedding have shown good performance when recognizing words. However, they are holistic methods in the sense that they recognize the word as a whole (i.e. they find the closest word in the lexicon to the word image). Consequently, these kinds of approaches are not able to deal with out of vocabulary words, which are common in historical manuscripts. Also, they cannot be extended to recognize text lines. In order to address these issues, in this paper we propose a handwriting recognition method that adapts the attribute embedding to sequence learning. Concretely, the method learns the attribute embedding of patches of word images with a convolutional neural network. Then, these embeddings are presented as a sequence to a recurrent neural network that produces the transcription. We obtain promising results even without the use of any kind of dictionary or language model.	ascii art;artificial neural network;benchmark (computing);convolutional neural network;dictionary;experiment;handwriting recognition;holism;identity management;language model;lexicon;neural networks;optical character recognition;random neural network;recurrent neural network;transcription (software);vocabulary	J. Ignacio Toledo;Sounak Dey;Alicia Fornés;Josep Lladós	2017	2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR)	10.1109/ICDAR.2017.172	convolutional neural network;pattern recognition;artificial intelligence;speech recognition;computer science;lexicon;feature extraction;sequence learning;handwriting recognition;language model;embedding;recurrent neural network	Vision	-18.949904840669127	-73.70553153546751	95351
52a08919efb7a1d0f28eda82bacd9d495639a6b3	neighbourhood watch: referring expression comprehension via language-guided graph attention networks		The task in referring expression comprehension is to localise the object instance in an image described by a referring expression phrased in natural language. As a language-to-vision matching task, the key to this problem is to learn a discriminative object feature that can adapt to the expression used. To avoid ambiguity, the expression normally tends to describe not only the properties of the referent itself, but also its relationships to its neighbourhood. To capture and exploit this important information we propose a graph-based, language-guided attention mechanism. Being composed of node attention component and edge attention component, the proposed graph attention mechanism explicitly represents inter-object relationships, and properties with a flexibility and power impossible with competing approaches. Furthermore, the proposed graph attention mechanism enables the comprehension decision to be visualisable and explainable. Experiments on three referring expression comprehension datasets show the advantage of the proposed approach.		Peng Wang;Qi Wu;Jiewei Cao;Chunhua Shen;Lianli Gao;Anton van den Hengel	2018	CoRR			AI	-15.453468474791705	-67.82288189829019	95565
221cf7b15aa771f9f9f8c0dc21899e22cd736fb8	zoneout: regularizing rnns by randomly preserving hidden activations		We propose zoneout, a novel method for regularizing RNNs. At each timestep, zoneout stochastically forces some hidden units to maintain their previous values. Like dropout, zoneout uses random noise to train a pseudo-ensemble, improving generalization. But by preserving instead of dropping hidden units, gradient information and state information are more readily propagated through time, as in feedforward stochastic depth networks. We perform an empirical investigation of various RNN regularizers, and find encouraging results: zoneout gives significant performance improvements across tasks, yielding state-ofthe-art results in character-level language modeling on the Penn Treebank dataset and competitive results on word-level Penn Treebank and permuted sequential MNIST classification tasks.	dropout (neural networks);feedforward neural network;gradient descent;language model;mnist database;noise (electronics);random neural network;randomness;treebank	David Krueger;Tegan Maharaj;János Kramár;Mohammad Pezeshki;Nicolas Ballas;Nan Rosemary Ke;Anirudh Goyal;Yoshua Bengio;Hugo Larochelle;Aaron C. Courville;Christopher Joseph Pal	2016	CoRR		speech recognition;computer science;artificial intelligence;machine learning	ML	-17.287118318403486	-75.58154657366761	95638
c31d24ababb8fc49b80f0a0d3e6994ea40b7bc47	on sequence encodings for positional reasoning task with deep neural networks		This paper addresses the problem of encoding natural language in neural networks for the task of question answering on positional facts. Current state of the art works use many different ways to encode their inputs in natural language. Most of them separate each fact and their interaction with the question is independent. Another common issue is that, when encoding is not based on bags of words, sequence of words is considered, but the effect of alignment has not been particularly studied. In this paper we propose representing the intermediate states of a Recurrent Neural Network (Particularly a Long Short Term Memory network) as a matrix, and then using a convolutional layer on it. This architecture allows to experiment with different strategies of word alignment, as well as different modes of interaction between facts and questions, including a 3D convolution to combine word alignments and interaction of all facts and the question to be answered. We apply this model to the Positional Reasoning Task of bAbI to evaluate our proposed models. We found that alignment does not play a very important role in this task, but allowing interaction between all facts and question simultaneously is important to improve performance.	artificial neural network;bitext word alignment;character encoding;computer performance;convolution;deep learning;encode;long short-term memory;natural language;question answering;recurrent neural network	Hiram Calvo;Ari Reyes	2017	Research in Computing Science		machine learning;artificial neural network;computer science;artificial intelligence	NLP	-17.652075710349635	-73.36468234762326	95896
1d5d75e97d92859e01917bbfb3033a4b09a91f6e	play with me — measuring a child's engagement in a social interaction	pediatrics;support vector machines;multimodal dyadic behaviour dataset social interaction child engagement measurement automatic child behaviour observation automatic high level feature extraction hand gestures head poses low level optical flow based features optical flow based hidden structure behaviour learning child engagement level hidden conditional random fields svm based model learning hidden state marginals;conference paper;accuracy;computational modeling;hidden markov models;support vector machines behavioural sciences computing feature extraction image sequences learning artificial intelligence;computational modeling videos accuracy hidden markov models predictive models pediatrics support vector machines;predictive models;videos	Due to the challenges in automatically observing child behaviour in a social interaction, an automatic extraction of high-level features, such as head poses and hand gestures, is difficult and noisy, leading to an inaccurate model. Hence, the feasibility of using easily obtainable low-level optical flow based features is investigated in this work. A comparative study involving high-level features, baseline annotations of multiple modalities and the low-level features is carried out. Optical flow based hidden structure learning of behaviours is strongly discriminatory in predicting a child's engagement level in a social interaction. A two-stage approach of discovering the hidden structures using Hidden Conditional Random Fields, followed by learning an SVM-based model on the hidden state marginals is proposed. This is validated by conducting experiments on the Multimodal Dyadic Behaviour Dataset and the results indicate a state of the art classification performance. The insights drawn from this study indicate the robustness of the low-level feature approach towards engagement behaviour modelling and can be a good substitute in the absence of accurate high-level features.	baseline (configuration management);conditional random field;dyadic transformation;experiment;high- and low-level;multimodal interaction;optical flow	Shyam Sundar Rajagopalan;O. V. Ramana Murthy;Roland Goecke;Agata Rozga	2015	2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG)	10.1109/FG.2015.7163129	speech recognition;computer science;artificial intelligence;machine learning	Vision	-11.195726157008144	-70.91225072581848	95998
a8e2bed81c3a3cfb16cf5fed9949e471e4de6cb7	error prediction with partial feedback	user feedback;error modeling;binary classification;em	Abstract. In this paper, we propose a probabilistic framework for predicting the root causes of errors in data processing pipelines made up of several components when we only have access to partial feedback; that is, we are aware when some error has occurred in one or more of the components, but we do not know which one. The proposed error model enables us to direct the user feedback to the correct components in the pipeline to either automatically correct errors as they occur, retrain the component with assimilated training examples, or take other corrective action. We present the model and describe an Expectation Maximization (EM)-based algorithm to learn the model parameters and predict the error configuration. We demonstrate the accuracy and usefulness of our method first on synthetic data, and then on two distinct tasks: error correction in a 2-component opinion summarization system, and phrase error detection in statistical machine translation.	active learning (machine learning);error detection and correction;expectation–maximization algorithm;feedback;named-entity recognition;natural language processing;nonlinear system;pipeline (computing);postediting;randomness;statistical machine translation;synthetic data	William Darling;Cédric Archambeau;Shachar Mirkin;Guillaume Bouchard	2013		10.1007/978-3-642-40991-2_6	binary classification;computer science;error bar;machine learning;round-off error;pattern recognition;data mining;em;statistics	ML	-15.333417285034619	-72.02571892671195	96425
8a859ec895d00de68327b07d7e48dfa031e44ad1	a methodology to extract emotions and add expressions in speech synthesis	emotional state value;emotion self assessment test;speech synthesis;emotional state value speech synthesis emotion extraction emotion self assessment test pleasure arousal and dominance;probability density function;information technology;virtual reality;emotion recognition;emotion extraction;data mining;speech synthesis information technology virtual reality decision support systems;decision support systems;speech synthesis emotion recognition;pleasure arousal and dominance	This paper presents the methodology to extract emotion from the text at real time and add the expression to the documents contents during speech synthesis. To understand the existence of emotions self assessment test was carried out on set of documents and preliminary rules were formulated for three basic emotions: Pleasure, Arousal and Dominance. These rules are used in an automated procedure that assigns emotional state values to document contents. These values are then used by speech synthesizer to add emotions to speech. The system is language independent and content free.	speech synthesis	M. B. Chandak;Rajiv V. Dharaskar	2009	2009 Sixth International Conference on Information Technology: New Generations	10.1109/ITNG.2009.337	probability density function;two-factor theory of emotion;computer science;emotion classification;virtual reality;speech synthesis;information technology;statistics	SE	-15.516700724517293	-80.02081805601112	96695
3a1597dff7763a87e76c1af8df6911d4bce87355	double dip map-reduce for processing cross validation jobs	aws;machine learning;k fold;map reduce;cross validation;cloud computing	Cross validation is fundamental to machine learning as it provides a reliable way in which to evaluate algorithms and the overall quality of the corpora in use. In typical cross validation, the corpus is initially divided into learning and training segments, then crossed-over in successive rounds, so that each data segment is validated against the remaining ones. This process is prohibitively time and effort consuming, and often brushed off for computationally cheaper ones, such as heuristics. In this paper we introduce a cloud-based architecture for running cross validation jobs. Our solution makes heavy use of computational resources in the cloud by proposing a strategy in which there are two distinct, subsequent, map-reduce cycles: the first to perform the algorithmic target computation, and the second to provide cross validation data to retrofit the machine learning process. We demonstrate the feasibility of the proposed approach, with the implementation of a web segmentation algorithm.	algorithm;cloud computing;computation;computational resource;cross-validation (statistics);data segment;heuristic (computer science);machine learning;mapreduce;text corpus	Danilo Moret;Karin K. Breitman;Evelin Amorim;Jose Talavera;Ruy Luiz Milidiú;José Viterbo Filho	2012		10.1145/2245276.2245367	simulation;cloud computing;computer science;artificial intelligence;operating system;machine learning;database;world wide web;cross-validation	ML	-8.259962970949905	-67.49356103164395	96698
398bb5cb5738789262d09a8577146723644cff58	temporal hierarchical dictionary with hmm for fast gesture recognition		In this paper, we propose a novel temporal hierarchical dictionary with hidden Markov model (HMM) for gesture recognition task. Dictionaries with spatio-temporal elements have been commonly used for gesture recognition. However, the existing spatio-temporal dictionary based methods need the whole pre-segmented gestures for inference, thus are hard to deal with nonstationary sequences. The proposed method combines HMM with Deep Belief Networks (DBN) to tackle both gesture segmentation and recognition by the inference at the frame level. Besides, we investigate the redundancy in dictionaries and introduce the relative entropy to measure the information richness of a dictionary. Furthermore, when inferring an element, a temporal hierarchy-flat dictionary will be searched entirely every time in which the temporal structure of gestures isn't utilized sufficiently. The proposed temporal hierarchical dictionary is organized in HMM states and can limit the search range to distinct states. Our framework includes three key novel properties: (1) a temporal hierarchical structure with HMM, which makes both the HMM transition and Viterbi decoding more efficient; (2) a relative entropy model to compress the dictionary with less redundancy; (3) an unsupervised hierarchical clustering algorithm to build a hierarchical dictionary automatically. Our method is evaluated on two gesture datasets and consistently achieves state-of-the-art performance. The results indicate that the dictionary redundancy has a significant impact on the performance which can be tackled by a temporal hierarchy and an entropy model.		Haoyu Chen;Xin Liu;Guoying Zhao	2018	2018 24th International Conference on Pattern Recognition (ICPR)	10.1109/ICPR.2018.8546245	redundancy (engineering);viterbi decoder;artificial intelligence;gesture recognition;deep belief network;hierarchical clustering;hidden markov model;inference;pattern recognition;gesture;computer science	Vision	-13.894859410387896	-73.20135882987677	97072
1faa173ab7eb371942042d984800175f91151402	using sparse semantic embeddings learned from multimodal text and image data to model human conceptual knowledge		Distributional models provide a convenient way to model semantics using dense embedding spaces derived from unsupervised learning algorithms. However, the dimensions of dense embedding spaces are not designed to resemble human semantic knowledge. Moreover, embeddings are often built from a single source of information (typically text data), even though neurocognitive research suggests that semantics is deeply linked to both language and perception. In this paper, we combine multimodal information from both text and image-based representations derived from state-of-the-art distributional models to produce sparse, interpretable vectors using Joint Non-Negative Sparse Embedding. Through indepth analyses comparing these sparse models to human-derived behavioural and neuroimaging data, we demonstrate their ability to predict interpretable linguistic descriptions of human ground-truth semantic knowledge.	algorithm;distance matrix;ground truth;information source;machine learning;molecular dynamics;multimodal interaction;rsa (cryptosystem);semantic similarity;sparse matrix;text corpus;unsupervised learning	Steven Derby;Paul Miller;Brian Murphy;Barry Devereux	2018			machine learning;natural language processing;perception;unsupervised learning;neurocognitive;semantic memory;artificial intelligence;semantics;computer science;embedding	NLP	-14.143219819392087	-68.3449161809194	97082
b3cf063c3e25b2ab30e44ba49920b811d40f7702	multi-scale multi-task fcn for semantic page segmentation and table detection		"""Page segmentation and table detection play an important role in understanding the structure of documents. We present a page segmentation algorithm that incorporates state-of-the-art deep learning methods for segmenting three types of document elements: text blocks, tables, and figures. We propose a multi-scale, multi-task fully convolutional neural network (FCN) for the tasks of semantic page segmentation and element contour detection. The semantic segmentation network accurately predicts the probability at each pixel of the three element classes. The contour detection network accurately predicts instance level """"edges"""" around each element occurrence. We propose a conditional random field (CRF) that uses features output from the semantic segmentation and contour networks to improve upon the semantic segmentation network output. Given the semantic segmentation output, we also extract individual table instances from the page using some heuristic rules and a verification network to remove false positives. We show that although we only consider a page image as input, we produce comparable results with other methods that relies on PDF file information and heuristics and hand crafted features tailored to specific types of documents. Our approach learns the representative features for page segmentation from real and synthetic training data. %, and produces good results on real documents. The learning-based property makes it a more general method than existing methods in terms of document types and element appearances. For example, our method reliably detects sparsely lined tables which are hard for rule-based or heuristic methods."""	algorithm;artificial neural network;computer multitasking;conditional random field;convolutional neural network;deep learning;document layout analysis;heuristic (computer science);ibm notes;logic programming;microsoft customer care framework;pixel;portable document format;synthetic intelligence	Dafang He;Scott Cohen;Brian L. Price;Daniel Kifer;C. Lee Giles	2017	2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR)	10.1109/ICDAR.2017.50	task analysis;computer science;convolutional neural network;artificial intelligence;market segmentation;image segmentation;deep learning;feature extraction;pattern recognition;conditional random field;heuristic	Vision	-14.040767982719593	-71.8286242462966	97125
7f867eab2c202a46d2c2d5ec1bba0817b47ece22	active learning with partial feedback		While many active learning papers assume that the learner can simply ask for a label and receive it, real annotation often presents a mismatch between the form of a label (say, one among many classes), and the form of an annotation (typically yes/no binary feedback). To annotate examples corpora for multiclass classification, we might need to ask multiple yes/no questions, exploiting a label hierarchy if one is available. To address this more realistic setting, we propose active learning with partial feedback (ALPF), where the learner must actively choose both which example to label and which binary question to ask. At each step, the learner selects an example, asking if it belongs to a chosen (possibly composite) class. Each answer eliminates some classes, leaving the learner with a partial label. The learner may then either ask more questions about the same example (until an exact label is uncovered) or move on immediately, leaving the first example partially labeled. Active learning with partial labels requires (i) a sampling strategy to choose (example, class) pairs, and (ii) learning from partial labels between rounds. Experiments on Tiny ImageNet demonstrate that our most effective method improves 26% (relative) in top-1 classification accuracy compared to i.i.d. baselines and standard active learners given 30% of the annotation budget that would be required (naively) to annotate the dataset. Moreover, ALPF-learners fully annotate TinyImageNet at 42% lower cost. Surprisingly, we observe that accounting for per-example annotation costs can alter the conventional wisdom that active learners should solicit labels for hard examples.	baseline (configuration management);benchmark (computing);effective method;electromagnetically induced grating;epoch (reference date);error detection and correction;experiment;feedback;imagenet;multiclass classification;oracle advanced queuing;sampling (signal processing);text corpus;tiny basic;tiny tiny rss	Peiyun Hu;Zachary Chase Lipton;Anima Anandkumar;Deva Ramanan	2018	CoRR		machine learning;artificial intelligence;active learning;drill down;computer science;sampling (statistics);data annotation;effective method;binary number;hierarchy;annotation	ML	-12.665652404782943	-67.44406315218819	97154
745f6a29f42db9ffe58e02964d947f25bf91df48	intelligent word embeddings of free-text radiology reports.		Radiology reports are a rich resource for advancing deep learning applications in medicine by leveraging the large volume of data continuously being updated, integrated, and shared. However, there are significant challenges as well, largely due to the ambiguity and subtlety of natural language. We propose a hybrid strategy that combines semantic-dictionary mapping and word2vec modeling for creating dense vector embeddings of free-text radiology reports. Our method leverages the benefits of both semantic-dictionary mapping as well as unsupervised learning. Using the vector representation, we automatically classify the radiology reports into three classes denoting confidence in the diagnosis of intracranial hemorrhage by the interpreting radiologist. We performed experiments with varying hyperparameter settings of the word embeddings and a range of different classifiers. Best performance achieved was a weighted precision of 88% and weighted recall of 90%. Our work offers the potential to leverage unstructured electronic health record data by allowing direct analysis of narrative clinical notes.	body of uterus;deep learning;dictionary [publication type];electronic health records;experiment;f1 score;futures studies;hemorrhage;intracranial hemorrhages;linear function;maxima and minima;mutual information;natural language;neoplasms;note (document);prospective search;radiology;semantic mapping (statistics);subtlety score;unsupervised learning;vocabulary;word embedding;word2vec;benefit;funding grant;likelihood ratio	Imon Banerjee;Sriraman Madhavan;Roger Eric Goldman;Daniel L. Rubin	2017	AMIA ... Annual Symposium proceedings. AMIA Symposium		information retrieval;word2vec;computer science;radiology;deep learning;natural language processing;hyperparameter;ambiguity;natural language;unsupervised learning;recall;artificial intelligence	NLP	-15.880594448132623	-74.34267182639736	97388
ee9ea1803e9e5a89c6bb42a5b703f79885824dfc	online handwritten mongolian word recognition using a novel sliding window method with recurrent neural networks		Because of the conglutinated characteristic of Mongolian words, it's difficult to realize online handwritten Mongolian word recognition with high recognition accuracy based on segmentation-based strategy. Meanwhile, as the vocabulary of Mongolian words is large, using a segmentation-free method with deep bidirectional long short term memory(DBLSTM) network is more suitable. We design a 5 bidirectional hidden level DBLSTM network for online handwritten Mongolian word recognition. This paper mainly proposes a novel sliding window method which selects frames with different intervals to enhance recognition rate. The novel method can generate hundreds of sequence data for each sample, while only one sequence data is generated using ordinary sliding window method. More sequence data and more abundant sequence information are helpful to raise the recognition rate. We evaluated the recognition performance on our online handwritten Mongolian database with 925 classes. The proposed method achieves the word level recognition rate of 89.24% with PCA feature extractor and best path decoding, compared to that of 88.45% using ordinary sliding window method. Further, several well trained DBLSTM models based on the proposed method are combined to vote the output, finally, the word-level recognition raises to 90.35%.	convolution;experiment;feature extraction;language model;long short-term memory;neural networks;preprocessor;randomness extractor;recurrent neural network;vocabulary;window function	Ji Liu;Long-Long Ma;Jian Wu	2017	2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR)	10.1109/ICDAR.2017.39	artificial intelligence;computer science;sliding window protocol;word recognition;pattern recognition;feature extraction;handwriting recognition;recurrent neural network;hidden markov model;decoding methods;vocabulary	Vision	-15.958329358231392	-77.68484776009636	97939
4145e9105ac1f36304fc16d5de06777de1d38f58	unconsciously deciphering handwriting: subliminal invariance for handwritten words in the visual word form area	right hemisphere;handwritten word recognition;visual word form area	Expert readers exhibit a remarkable ability to recognize handwriting, in spite of enormous variability in character shape-a competence whose cerebral underpinnings are unknown. Subliminal priming, combined with neuroimaging, can reveal which brain areas automatically compute an invariant representation of visual stimuli. Here, we used behavioral and fMRI priming to study the areas involved in invariant handwritten word recognition. Compared to printed words, easily readable handwritten words caused additional activity in ventral occipitotemporal cortex, particularly in the right hemisphere, while difficult handwriting also mobilized an attentional parietofrontal network. Remarkably, however, subliminal repetition effects were observed across printed and handwritten styles, whether easy or difficult to read, both behaviorally and in the activation of the left visual word form area (VWFA). These results indicate that the left inferotemporal VWFA possesses an unsuspected degree of fast and automatic visual invariance for handwritten words, although surprisingly this invariance can be reflected both as repetition suppression and as repetition enhancement.	area striata structure;heart rate variability;human-readable medium;neuroimaging;priming exercise;printing;resting state fmri;speech repetition;subliminal channel;visual word;word recognition;zero suppression	Emilie Qiao;Fabien Vinckier;Marcin Szwed;Lionel Naccache;Romain Valabrègue;Stanislas Dehaene;Laurent Cohen	2010	NeuroImage	10.1016/j.neuroimage.2009.09.034	cognitive psychology;speech recognition;communication	ML	-7.1866644283701175	-79.64923702220584	98204
1a29fc669ea54346ce525d14a89ef3a39b655dd2	niche as a determinant of word fate in online groups	word frequency;time scale;longitudinal analysis;model system;models theoretical;social identity;terminology as topic;online systems;social groups;humans;human activity	Patterns of word use both reflect and influence a myriad of human activities and interactions. Like other entities that are reproduced and evolve, words rise or decline depending upon a complex interplay between their intrinsic properties and the environments in which they function. Using Internet discussion communities as model systems, we define the concept of a word niche as the relationship between the word and the characteristic features of the environments in which it is used. We develop a method to quantify two important aspects of the size of the word niche: the range of individuals using the word and the range of topics it is used to discuss. Controlling for word frequency, we show that these aspects of the word niche are strong determinants of changes in word frequency. Previous studies have already indicated that word frequency itself is a correlate of word success at historical time scales. Our analysis of changes in word frequencies over time reveals that the relative sizes of word niches are far more important than word frequencies in the dynamics of the entire vocabulary at shorter time scales, as the language adapts to new concepts and social groupings. We also distinguish endogenous versus exogenous factors as additional contributors to the fates of words, and demonstrate the force of this distinction in the rise of novel words. Our results indicate that short-term nonstationarity in word statistics is strongly driven by individual proclivities, including inclinations to provide novel information and to project a distinctive social identity.	community;endogeneity (econometrics);entity;interaction;microsoft word for mac;niche blogging;vocabulary;word lists by frequency	Eduardo G. Altmann;Janet B. Pierrehumbert;Adilson E. Motter	2011		10.1371/journal.pone.0019009	social group;social identity theory;word lists by frequency	Web+IR	-5.918967084619713	-71.6765714533317	98791
d35267a0fa48a472c20745164527cd91f7423a77	a hidden semi-markov model for chart pattern matching in financial time series		Many pattern matching approaches have been applied in financial time series to detect chart patterns and predict price trends. In this paper, we propose an extended hidden semi-Markov model for chart pattern matching (HSMM-CP). In our approach, a hidden semi-Markov model is trained and a Viterbi algorithm is used to detect chart patterns. The proposed approach not only simplifies the traditional way of training an HSMM, but also reduces potential biases in parameter initialisation. We compare the proposed model with current approaches on a set of templates selected from 53 chart patterns. Experiments on a synthetic dataset show that the proposed approach has the highest average accuracy and recall among other pattern matching approaches. Specifically, the HSMM-CP approach achieves highest accuracy for “Triangles, Ascending”, “Head-and-Shoulders Tops”, “Triple Tops” and “Cup with Handle” patterns. Moreover, experiments results show that the HSMM-CP performs significantly better than other approaches in distinguishing patterns with similar shapes such as “Head-and-Shoulders Tops” and “Triple Tops”. Experiments are also conducted on a real dataset comprising the historical prices of several stocks.	hidden semi-markov model;markov chain;pattern matching;semiconductor industry;time series	Yuqing Wan;Yain-Whar Si	2018	Soft Comput.	10.1007/s00500-017-2703-7	machine learning;viterbi algorithm;pattern matching;computer science;hidden semi-markov model;similarity (geometry);finance;chart;artificial intelligence;chart pattern;pattern recognition	ML	-9.691478773347935	-71.50782657203648	98919
dd3e7becee90c337945dd7e1b1defd0e2fc9353a	japanese subjects and information structure : a constraint-based approach	conference paper	This paper is concerned with how topic/focus articulation should be optimally integrated into Japanese grammar. Based on Engdahl and Vallduvı́’s (1996) Information Structure, we propose an analysis with the following characteristics: (i) information structure is an integral part of Japanese grammar and interacts in principled ways with both syntax and phonology, (ii) the representations of topic/focus in the information structure and its interactions with the particles wa/ga show one-to-many relation, and (iii) the ordering of grammatical functions and its interactions with other grammatical parts play an important role in determining the focus domain.	biconnected component;data structure;floor and ceiling functions;interaction;one-to-many (data model)	Akira Ohtani;Yuji Matsumoto	2004			computer science;artificial intelligence;operations management	NLP	-13.326395195570267	-77.28993503731465	98937
86e9a62bd12c69472c334eab16390c37dd4e2382	a measure of the number of true analogies between chunks in japanese	japanese language;structure of language;chunks;poverty of the stimulus;true analogies	This study relates to the assessment of the argument of the poverty of the stimulus in that we conducted a measure of the number of true proportional analogies between chunks in a language with case markers, Japanese. On a bicorpus of 20,000 sentences, we show that at least 96% of the analogies of form between chunks are also analogies of meaning, thus reporting the presence of at least two million true analogies between chunks in this corpus. As the number of analogies between chunks overwhelmingly surpasses the number of analogies between sentences by three orders of magnitude for this size of corpora, we conclude that proportional analogy is an efficient and undeniable structuring device between Japanese chunks.		Yves Lepage;Julien Migeot;Erwan Guillerm	2007		10.1007/978-3-642-04235-5_14	natural language processing;mathematics;linguistics;communication	NLP	-10.964253639481603	-79.45996933131799	99908
1f2f1dc1af6ddc04ac9e73b5d2aa340f6a9dc07a	verbal plurality of frequency adverbs in mandarin chinese: the case of cháng and chángcháng		This paper looks at the similarities and differences between two frequency adverbs, chang and changchang, which have been often confused with each other in the Sinologist literature. Since both denote a multiplicity of ‘occasions’, they can be treated as markers of verbal plurality operating at the occasion-level in the sense of Cusic (1981). They present differences in two aspects: (i) the sentence types that they can occur in (respectively, characterizing vs. particular sentences) and (ii) their semantic functions (respectively, the expression of habituality vs. iterativity).	super robot monkey team hyperforce go!	Hua-Hung Yuan;Daniel Kwang Guan Chan	2016		10.1007/978-3-319-49508-8_46	reduplication;mandarin chinese;natural language processing;linguistics;artificial intelligence;mathematics;sentence	NLP	-11.7502949469883	-79.95924410933647	100616
5f96d05df744ef3284c25e20a0b48e7dbce6b03f	an architecture for a universal lexicon: a case study on shared syntactic information in japanese, hindi, bengali, greek, and english	shared syntactic information;universal lexicon;case study	Naoyuki Nomura, Douglas A. Jones, Robert C. Berwick Massachusetts Institute of Technology, NE43-802 Artificial Intelligence Laboratory nomura@ai.mit.edu Introduction. Given the prominence of the lexicon in most current linguistic theories (LFG, HPSG, GB), the inventory of language particular information left in the lexicon deserves special attention. Constructing large computerized lexicons remains a difficult problem, building a large array of apparently arbitrary information. This paper shows that this arbitrariness can be constrained more than might have been previously thought. In particular, arbitrariness of argument structure, word sense, and paraphrasability will be shown not only to be constrained, but also to be integrally related. Our (radical) view is that variation of lexical behavior across languages is exactly like lexical variation within languages, specifically, the difference lies in the presence or absence of certain morphemes. For example, the fact that Japanese has richer possibilities in certain verbal patterns is derived solely from its morphological inventory.1 Put another way, language parameters simply are the presence or absence of lexical material in the morphological component. Observed language variation patterns reflect morphological systematicity. The generative machinery for producing argument structure positions is fixed across languages. Linguistic Motivation. A striking example underscoring universality of argument structure is the familiar Spray/Load alternation2, shown in (1). Despite the many surface differences in these data across languages, they share several essential properties. (1) a. b. John loaded the hay on the wagon. John loaded the wagon with the hay. Japanese (2) a. taroo-wa teepu-o boo-ni maita. Taro-NOM tape-ACC stick-DAT wrap-PRF 'Taro wrapped the tape around the stick.'	artificial intelligence;boo;circumscription (logic);essence;head-driven phrase structure grammar;intel dynamic acceleration;jones calculus;lexical functional grammar;lexicon;machine translation;martin kay;primitive recursive function;programming paradigm;universal turing machine;word sense	Naoyuki Nomura;Douglas A. Jones;Robert C. Berwick	1994			natural language processing;speech recognition;linguistics;bengali grammar	NLP	-11.217066010302338	-78.65614310182313	101138
32906da60c8c39856a396164766f88ec05161969	a systematic review of hindi prosody		Prosody describes both form and function of a sentence using the suprasegmental features of speech. Prosody phenomena are explored in the domain of higher phonological constituents such as word, phonological phrase and intonational phrase. The study of prosody at the word level is called word prosody and above word level is called sentence prosody. Word Prosody describes stress pattern by comparing the prosodic features of its constituent syllables. Sentence Prosody involves the study on phrasing pattern and intonatonal pattern of a language. The aim of this study is to summarize the existing works on Hindi prosody carried out in different domain of language and speech processing. The review is presented in a systematic fashion so that it could be a useful resource for one who wants to build on the existing works.	artificial neural network;computational model;decision tree learning;microsoft word for mac;modulation;pattern language;semantic prosody;speech processing;syllable;systematic review	Somnath Roy	2017	CoRR		natural language processing;speech recognition;linguistics;prosody	NLP	-12.397365593419972	-79.95207009872681	101442
0d356807cd84ab3767d80e31350a815b82283563	metaphor detection with topic transition, emotion and cognition in context		Metaphor is a common linguistic tool in communication, making its detection in discourse a crucial task for natural language understanding. One popular approach to this challenge is to capture semantic incohesion between a metaphor and the dominant topic of the surrounding text. While these methods are effective, they tend to overclassify target words as metaphorical when they deviate in meaning from its context. We present a new approach that (1) distinguishes literal and non-literal use of target words by examining sentence-level topic transitions and (2) captures the motivation of speakers to express emotions and abstract concepts metaphorically. Experiments on an online breast cancer discussion forum dataset demonstrate a significant improvement in metaphor detection over the state-of-theart. These experimental results also reveal a tendency toward metaphor usage in personal topics and certain emotional contexts.	cognition;effective method;interface metaphor;literal (mathematical logic);natural language understanding	Hyeju Jang;Yohan Jo;Qinlan Shen;Michael Z. Miller;Seungwhan Moon;Carolyn Penstein Rosé	2016			natural language processing;linguistics	NLP	-16.520390753167252	-68.77995167004393	101648
b19d26e97b1a1c6f4dc51d8415d809df31a57d08	identification of emergent leaders in a meeting scenario using multiple kernel learning	social signal processing;multiple kernel learning;body activity;head activity;head pose;emergent leadership	In this paper, an effective framework for detection of emergent leaders in small group is presented. In this scope, the combination of different types of nonverbal visual features; the visual focus of attention, head activity and body activity based features are utilized. Using them together ensued significant results. For the first time, multiple kernel learning (MKL) was applied for the identification of the most and the least emergent leaders. Taking the advantage of MKL's capability to use different kernels which corresponds to different feature subsets having different notions of similarity, significantly improved results compared to the state of the art methods were obtained. Additionally, high correlations between the majority of the features and the social psychology questionnaires which are designed to estimate the leadership or dominance were demonstrated.	emergence;kernel (operating system);math kernel library;multiple kernel learning	Cigdem Beyan;Francesca Capozzi;Cristina Becchio;Vittorio Murino	2016		10.1145/3005467.3005469	computer science;artificial intelligence;machine learning;communication	AI	-10.855129292435684	-71.21691265365234	101874
49d386f7cecc91f7e1e317b3c0c31e096b80cdd3	enhancing the lexvec distributed word representation model using positional contexts and external memory		In this paper we take a state-of-the-art model for distributed word representation that explicitly factorizes the positive pointwise mutual information (PPMI) matrix using window sampling and negative sampling and address two of its shortcomings. We improve syntactic performance by using positional contexts, and solve the need to store the PPMI matrix in memory by working on aggregate data in external memory. The effectiveness of both modifications is shown using word similarity and analogy tasks.	aggregate data;approximation;auxiliary memory;computer data storage;downstream (software development);intrinsic dimension;pointwise mutual information;sampling (signal processing);text corpus;window function;word embedding	Alexandre Salle;Marco Idiart;Aline Villavicencio	2016	CoRR		natural language processing;speech recognition;computer science;artificial intelligence;machine learning	NLP	-15.157245702868849	-66.62384038418763	102279
ece935eb4dd68ae8ee86949cee887506893a61d5	attentive and pre-attentive processes in multiple object tracking: a computational investigation		The rich literature on multiple object tracking (MOT) conclusively demonstrates that humans are able to visually track a small number of objects. There is considerably less agreement on what perceptual and cognitive processes are involved. While it is clear that MOT is attentionally demanding, various accounts of MOT performance centrally involve pre-attentional mechanisms as well. In this paper we present an account of object tracking in the ARCADIA cognitive system that treats MOT as dependent upon both preattentive and attention-bound processes. We show that with minimal addition this model replicates a variety of core phenomena in the MOT literature and provides an algorithmic explanation of human performance limitations.	algorithm;artificial intelligence;computation;human reliability	Paul Bello;Will Bridewell;Christina Wasylyshyn	2016			cognitive psychology;psychology;video tracking	AI	-5.326668104447229	-75.60504966301271	102338
09a6d7e831cf496fb5fb2903415eab4c73235715	programming with a differentiable forth interpreter		Given that in practice training data is scarce for all but a small set of problems, a core question is how to incorporate prior knowledge into a model. In this paper, we consider the case of prior procedural knowledge for neural networks, such as knowing how a program should traverse a sequence, but not what local actions should be performed at each step. To this end, we present an end-to-end differentiable interpreter for the programming language Forth which enables programmers to write program sketches with slots that can be filled with behaviour trained from program input-output data. We can optimise this behaviour directly through gradient descent techniques on user-specified objectives, and also integrate the program into any larger neural computation graph. We show empirically that our interpreter is able to effectively leverage different levels of prior program structure and learn complex behaviours such as sequence sorting and addition. When connected to outputs of an LSTM and trained jointly, our interpreter achieves state-of-the-art accuracy for end-to-end reasoning about quantities expressed in natural language stories.	artificial neural network;computation;end-to-end principle;forth;gradient descent;long short-term memory;natural language;programmer;programming language;sorting;structured programming;traverse	Sebastian Riedel;Matko Bosnjak;Tim Rocktäschel	2017			computer science;artificial intelligence;theoretical computer science;machine learning;algorithm	ML	-13.885041531669225	-73.86086705798239	102486
171042ba12818238e3c0994ff08d71f8c28d4134	learning to describe e-commerce images from noisy online data		Recent study shows successful results in generating a proper language description for the given image, where the focus is on detecting and describing the contextual relationship in the image, such as the kind of object, relationship between two objects, or the action. In this paper, we turn our attention to more subjective components of descriptions that contain rich expressions to modify objects – namely attribute expressions. We start by collecting a large amount of product images from the online market site Etsy, and consider learning a language generation model using a popular combination of a convolutional neural network (CNN) and a recurrent neural network (RNN). Our Etsy dataset contains unique noise characteristics often arising in the online market. We first apply natural language processing techniques to extract high-quality, learnable examples in the real-world noisy data. We learn a generation model from product images with associated title descriptions, and examine how e-commerce specific meta-data and fine-tuning improve the generated expression. The experimental results suggest that we are able to learn from the noisy online data and produce a product description that is closer to a man-made description with possibly subjective attribute expressions.	artificial neural network;convolutional neural network;deep learning;e-commerce;etsy;natural language generation;natural language processing;parsing;random neural network;recurrent neural network;sensor;signal-to-noise ratio;tag (metadata)	Takuya Yashima;Naoaki Okazaki;Kentaro Inui;Kota Yamaguchi;Takayuki Okatani	2016		10.1007/978-3-319-54193-8_6	data science;machine learning;pattern recognition	AI	-18.0928710628487	-70.24600805717733	102532
399790217357cfb0bcd4ef2559055017bf302559	communication and strong compositionality	composition;substitution;semantics;langage;expression;semantique;hodges w;meaning;language of thought;signification;westerstahl d;language;speaker;universal algebra;communication;locuteur	1. Cognitive and epistemic asymmetry Suppose that you are given the task of translating ten words from English to Swedish. You know English and you don’t know Swedish, but you have an English-Swedish dictionary. Given the dictionary, you easily accomplish what was asked for. But then you are given a more difficult task. You are now to translate ten new words from Swedish to English, say ‘låtsas’, ‘dimma’, ‘ofog’, ‘färdig’, ‘dumheter’, ‘glömska’, ‘om’, ‘springa’, ‘tryck’, and ‘tillbringare’. The reason this is more difficult is that you have to do it with the same tool as last time, the English-Swedish dictionary. The dictionary contains all translation pairs you need, but they are listed alphabetically according to the English members of the pairs. So you know where to find any English word in the list, but you don’t know where to find the Swedish words (unless you already know the translation, which you don’t). So in order to find the translation of ‘ofog’ you simply have to search through the dictionary, in whatever order you prefer, until you happen to find the word. You don’t know how long it will take. Because of this, the dictionary translation method is cognitively asymmetric. It defines a relation between the Swedish and English vocabularies, but it provides an efficient (e.g. as measured by average time needed) method only for one direction, not for the other. The hypothesis that a bilingual speaker’s translation capacity is subserved by a mental English-Swedish dictionary can explain the speaker’s ability of English-Swedish translation, but it cannot explain his ability of Swedish-English translation. We can make things worse by two changes to this scenario. Suppose, first, that the list of words is infinite1, and, second, that the strings of letters you are served need not be part of the vocabulary. In the English-to-Swedish task the increase in difficulty is not great. Given an arbitrary string of letters you know where to find it: if there is no such string at the determined position, it isn’t a word in the English vocabulary. Hence, you have a decision method for determining wordhood, and what the translation is, if the word exists. By contrast, in the Swedish-to-English task, where you don’t know where in the list to find the string, you only know that if there is a word, and you search systematically, you will sooner or later find it, even though not when. If the string (e.g. ‘bab’)	dictionary;protologism;statistical machine translation;vocabulary	Peter Pagin	2003	J. Philosophical Logic	10.1023/A:1024258529030	composition;universal algebra;philosophy;epistemology;computer science;expression;mathematics;semantics;linguistics;language;meaning;algorithm;principle of compositionality	NLP	-12.407926159368172	-78.70421330622419	102591
1d191ff0c8905e25625520cd68c2b615f84c9b9e	a model of the distribution of the distances of alike elements in dialogical communication	probability distribution;information theory	In this paper we describe a model of the distribution of alike elements in dialogical communication. Our starting point is the interactive approach to alignment which views priming as a basic mechanism of verbal interaction. As this mechanism predicts short distances of the occurrences of primes on the one hand primed units on the other we concentrate on the distance effect induced by priming. The present paper focuses on prerequisites of measuring this effect. Thus, it can be seen as a starting point of operationalising the notion of alignment in terms of information theory.	information theory;randomness	Alexander Mehler	2008			combinatorics;pure mathematics;mathematics	Theory	-8.534188534277982	-75.66540234826593	102783
6db9af10d375aa89a41772b09019ec1763a1d28d	a neural question answering model based on semi-structured tables		Most question answering (QA) systems are based on raw text and structured knowledge graph. However, raw text corpora are hard for QA system to understand, and structured knowledge graph needs intensive manual work, while it is relatively easy to obtain semi-structured tables from many sources directly, or build them automatically. In this paper, we build an end-to-end system to answer multiple choice questions with semi-structured tables as its knowledge. Our system answers queries by two steps. First, it finds the most similar tables. Then the system measures the relevance between each question and candidate table cells, and choose the most related cell as the source of answer. The system is evaluated with TabMCQ dataset, and gets a huge improvement compared to the state of the art.	decision table;end system;end-to-end principle;experiment;feedback;knowledge graph;log-structured file system;mathematical induction;question answering;relevance;semiconductor industry;table (information);text corpus;wang tile	Hao Wang;Xiaodong Zhang;Shuming Ma;Xu Sun;Houfeng Wang;Mengxiang Wang	2018			artificial intelligence;computer science;natural language processing;question answering	NLP	-16.759144313254456	-73.65750947111563	102791
fd08b7820007be33f3f266ebb7b0a578f29b9409	oracle-free detection of translation issue for neural machine translation		Neural Machine Translation (NMT) has been widely adopted over recent years due to its advantages on various translation tasks. However, NMT systems can be error-prone due to the intractability of natural languages and the design of neural networks, bringing issues to their translations. These issues could potentially lead to information loss, wrong semantics, and low readability in translations, compromising the usefulness of NMT and leading to potential non-trivial consequences. Although there are existing approaches, such as using the BLEU score, on quality assessment and issue detection for NMT, such approaches face two serious limitations. First, such solutions require oracle translations, i.e., reference translations, which are often unavailable, e.g., in production environments. Second, such approaches cannot pinpoint the issue types and locations within translations. To address such limitations, we propose a new approach aiming to precisely detect issues in translations without requiring oracle translations. Our approach focuses on two most prominent issues in NMT translations by including two detection algorithms. Our experimental results show that our new approach could achieve high effectiveness on real-world datasets. Our successful experience on deploying the proposed algorithms in both the development and production environments of WeChat, a messenger app with over one billion of monthly active users, helps eliminate numerous defects of our NMT model, monitor the effectiveness on real-world translation tasks, and collect in-house test cases, producing high industry impact.	algorithm;artificial neural network;bleu;cognitive dimensions of notations;deployment environment;natural language;neural machine translation;oracle database;sensor;test case	Wujie Zheng;Wenyu Wang;Dian Liu;Changrong Zhang;Qinsong Zeng;Yuetang Deng;Tao Xie	2018	CoRR		readability;artificial neural network;machine translation;oracle;semantics;natural language processing;natural language;test case;computer science;artificial intelligence	NLP	-13.739970149792585	-72.5502622196303	102893
e7240d11872af602aabb103c4f2f307006250a0f	audio visual scene-aware dialog (avsd) challenge at dstc7		Scene-aware dialog systems will be able to have conversations with users about the objects and events around them. Progress on such systems can be made by integrating state-of-the-art technologies from multiple research areas including end-to-end dialog systems visual dialog,and video description. We introduce the Audio Visual SceneAware Dialog (AVSD) challenge and dataset. In this challenge, which is one track of the 7th Dialog System Technology Challenges (DSTC7) workshop1, the task is to build a system that generates responses in a dialog about an input video.	audio description;dialog system;end-to-end encryption	Huda AlAmri;Vincent Cartillier;Raphael Gontijo Lopes;Abhishek Das;Jue Wang;Irfan Essa;Dhruv Batra;Devi Parikh;Anoop Cherian;Tim K. Marks;Chiori Hori	2018	CoRR		artificial intelligence;natural language processing;dialog box;computer science;dialog system	HCI	-12.227839395043679	-72.32228660876723	103007
14d2c03b0b5ffb00badf5ba8de37e70802d47810	some facts about centers, indexicals, and demonstratives	demonstrative pronoun;local center;certain pronoun context;discourse relevance;universe of discourse;indexation	Certain pronoun contexts are argued to establish a local center (LC), i.e., a conventionalized indexical similar to l s t /2nd pers. pronouns. Demonstrat ive pronouns, also indexicals, are shown to access entities that are not LCs because they lack discourse relevance or because they are not yet in the universe of discourse. 1 I n t r o d u c t i o n Referring expressions in discourse are multifunctional and dual-faced. Besides functioning to specify referents, they also indicate the status of their referents in the evolving discourse model, such as the informational status of being given or new [Pri81], or maintain the at tentional status of being in focus [Sid83] [Gro77]. They are dual-faced in that the surface form of a referring expression is constrained by the prior discourse context, and then increments the context, serving to constrain subsequent utterances [Isa75]. As a consequence of this latter property, the communicative effect of many referring forms, especially pronouns, is relative to specific types of discourse contexts. The discourse reference functions of a few types of pronouns are examined, taking into account their multifunctionality and their dual nature, in order to clarify their processing requirements in dialogic natural language systems. In particular, a comparison of the conversational usage of it with two types of indexical pronouns indicates that certain uses of it, referred to as local centering, resemble what Kaplan [Kap89] refers to as pure indexicals. Several functions of lhat are also identified and shown to contrast with local centering with respect to their preconditions and effects. Third person, definite (3d) pronouns contrast with indexical pronouns because the referents of the former are arbitrary, and must be actively established as part of the current universe of discourse in order for the intended referent to be 1 This paper was written under the support of DARPA grant N000039-84-C-0165 and NSF grant IRT-84-51438. I am grateful to Kathy McKeown for her generous support. identified. In contrast, the referents of indexicals such as I and you (i.e., the speaker and addressee) are necessary components of the discourse circumstances. 2 Indexical pronouns can be further classified into pure indexicals versus demonstratives, 8 depending on how the current discourse circumstances provide their referents. The referent of a pure indexical is fully determined by the semantic rules and a context, which together pick out a unique referent for each use. Thus I refers to the person who utters it (assuming that I is used to refer). A pure indexical cannot refer to alternative entities, nor can any other expression pick out the relevant ent i ty via the same type of referring function. Pure indexicals do not add entities to a context, or change the at tent ional status of their referents. In contrast, the referent of a demonstrat ive pronoun is not completely determined by the context plus the semantic rules. An accompanying demonstration is required, such as a physical or vocal gesture to something in the immediate discourse circumstances. Further, demonstratives can refer to anything in the context tha t can be demonstrated. In the cases of discourse deixis discussed by Webber [Web90], e.g., demonstrat ive pronouns are used to refer to discourse segments. Webber notes that in these cases, the demonstrat ion consists in the intention to refer signalled by the use of the demonstrative, plus the semantics of the containing clause, plus at tent ional constraints on which discourse segments can be demonstrated. 4 Thus, 3d pronouns, pure indexical pronouns, and demonstratives all differ with respect to the set of contextual elements that are available referents, and the manner in which the referent is related to the referring expression. Investigating their distinct discourse functions leads to extensions to the tri2The term indexical includes devices whose meaning pertalns to the time, the place and the perceived environment of a discourse context, e.g., tense, deictic adverbs (here, there) and deictic pronouns (this, that) [Pei35]. 3The view of indexicals presented here is largely drawn from Kaplan [Kap89]. 4Webber [Weh90] argues that only segments on the right frontier are available referents.	domain of discourse;entity;ibm notes;kaplan–meier estimator;multi-function printer;natural language;nick mckeown;precondition;regular expression;relevance;requirement	Rebecca J. Passonneau	1991			computer science;domain of discourse;linguistics	NLP	-9.127574110670434	-76.00866123401856	103368
5ff55ce68cc088d6a962941e67c372025d7cee0f	modeling bilingual word associations as connected monolingual networks		Word associations are a common tool in research on the mental lexicon. Studies report that bilinguals produce different word associations in their non-native language than monolinguals, and propose at least three mechanisms responsible for this difference: bilinguals may rely on their native associations (through translation), on collocational patterns, and on the phonological similarity between words. In this paper, we first test the differences between monolingual and bilingual responses, showing that these differences are consistent and significant. Second, we present a computational model of bilingual word associations, implemented as a semantic network paired with a retrieval mechanism. Our model predicts bilingual word associations better than monolingual baselines, and translation is the main mechanism explaining its success, while collocational and phonological associations do not improve the model.	baseline (configuration management);computational model;lexicon;microsoft word for mac;semantic network	Yevgen Matusevych;Amir Ardalan Kalantari Dehaghi;Suzanne Stevenson	2018			computer science	NLP	-16.259304221024486	-75.83248361388449	103373
7d7032754112ec80c788955c07eccad06b37badc	building a location dependent dictionary for speech translation systems		Mis-translation or dropping of proper nouns reduces the quality of machine translation output or speech recognition output as input of a dialog system. In this paper, we propose an automatic method of building a location dependent dictionary for speech recognition and speech translation systems. The method consists of two parts: location dependent word extraction and word classification. The first part extracts the word by using micro blog data based on Akaike’s information criteria. The second part classifies the words by using the Convolutional Neural Net (CNN) trained on crawled data. According to the experimental results, the method extracted around 2,000 location dependent words in the Tokyo area with 75% accuracy.	dictionary	Keiji Yasuda;Panikos Heracleous;Akio Ishikawa;Masayuki Hashimoto;Kazunori Matsumoto;Fumiaki Sugaya	2017		10.1007/978-3-319-77116-8_36	artificial intelligence;machine translation;speech translation;artificial neural network;akaike information criterion;computer science;proper noun;pattern recognition;dialog system	NLP	-17.2536339061427	-77.29929130701694	103542
3ea84258552f1a68910ce3eb4f6e2989cdf1d4dc	characterizing the difference between learning about adjacent and non-adjacent dependencies		Many studies of human sequential pattern learning demonstrate that learners detect adjacent and non-adjacent dependencies in many kinds of sequences. However, it is often assumed that the computational mechanisms behind extracting these dependencies are the same. We replicate the seminal finding that adults are capable of learning dependencies between non-adjacent words (Gómez, 2002). When we eliminate the positional information about the statistical structures by embedding the structure in phrases, learners can no longer learn the dependencies. Our methods allow us to study the learning mechanisms that are more representative of the patterns in natural languages, and show that when directly compared, adjacent and non-adjacent dependencies are not equally learnable. We suggest that learning non-adjacent dependencies in language involves a different computational mechanism from learning adjacent dependencies.	graph (discrete mathematics);model of computation;natural language;self-replication	Felix Hao Wang;Toben H. Mintz	2015			psychology;cognitive psychology;machine learning;replicate;natural language;artificial intelligence;embedding	ML	-10.358805375474232	-76.79943170009622	103752
343c02a01a03ab06a6f2bcbd2a8038410cc42371	bootstrapping into filler-gap: an acquisition story		Analyses of filler-gap dependencies usually involve complex syntactic rules or heuristics; however recent results suggest that filler-gap comprehension begins earlier than seemingly simpler constructions such as ditransitives or passives. Therefore, this work models filler-gap acquisition as a byproduct of learning word orderings (e.g. SVO vs OSV), which must be done at a very young age anyway in order to extract meaning from language. Specifically, this model, trained on part-of-speech tags, represents the preferred locations of semantic roles relative to a verb as Gaussian mixtures over real numbers. This approach learns role assignment in filler-gap constructions in a manner consistent with current developmental findings and is extremely robust to initialization variance. Additionally, this model is shown to be able to account for a characteristic error made by learners during this period (A and B gorped interpreted as A gorped B).	heuristic (computer science);osv;part-of-speech tagging;sparse voxel octree;star filler	Marten Van Schijndel;Micha Elsner	2014		10.3115/v1/P14-1102	natural language processing;speech recognition;computer science;machine learning;linguistics;statistics	NLP	-10.994669204629325	-77.18085679790123	104508
05d537d86f14d41e851c3275306a3d17226cebb9	on the generalizability of panini's pratyahara-technique to other languages	formal concept analysis.;sound classes;panini;sivasutras;phonological features;formal concept analysis	Pān. ini defines the sound classes involved in grammatical rules by pratyāhāras, i.e., a two-letter code based on the order of the sounds in the Śivasūtras. In the present paper we demonstrate that Pān. ini’s pratyāhāra method is generalizable to the description of the phonological systems of other languages by applying it to the sound classes and phonological alternations of German. Furthermore, we compare Pān. ini’s pratyāhāra technique with the technique of describing phonological classes by phonological features, which is more common in Western phonology. It turns out that pratyāhāras perform better than features for the description of our sample of German phonological processes if one considers the quality criterion for class-description devices proposed by Kornai (1993) which is based on the ratio of describable to actual classes.		Wiebke Petersen;Silke Hamann	2010		10.1007/978-3-642-17528-2_2	phonology;generalizability theory;natural language processing;phonological rule;artificial intelligence;linguistics;formal concept analysis;german;computer science	SE	-12.537514315208728	-79.944821445802	104787
48bd3d16e44fca0853d08c573f40ec0ce67034b0	phrase similarity in humans and machines		Computational models of semantics have emerged as powerful tools for natural language processing. Recent work has developed models to handle compositionality, but these models have typically been evaluated on large, uncontrolled corpora. In this paper, we constructed a controlled set of phrase pairs and collected phrase similarity judgments, revealing novel insights into human semantic representation. None of the computational models that we considered were able to capture the pattern of human judgments. The results of a second experiment, using the same stimuli with a transformational judgment task, support a transformational account of similarity, according to which the similarity between phrases is inversely related to the number of edits required to transform one mental model into another. Taken together, our results indicate that popular models of compositional semantics do not capture important facets of human semantic representation.	computation;computational model;mental model;natural language processing;terminator 2: judgment day;text corpus;uncontrolled format string	Samuel J Gershman;Joshua B. Tenenbaum	2015			psychology;principle of compositionality;transformational leadership;natural language processing;semantics;computational model;artificial intelligence;phrase	NLP	-12.381905154458583	-73.18828835146478	104998
e64a75c32828f77fcdb0134deaec7f4163b9d83f	representing time in terms of space: directions of mental timelines in norwegian		People often use spatial vocabulary to describe tem poral relations, and this has increasingly motivated attempts to map spatial frames of reference (FoRs) onto time. How p eople assign FRONT to time and to temporal entities depends on cultural conventions, and is crucial for diagnosing wh ich temporal FoR a person actually adopts. Here, we report findings from a survey with speakers of Norwegian that aimed at assessing the cultural conventions involved in FRONT assignment. Data on temporal movements of events, on the temporal order of events, and on explicit FRONT assignments to events, time units, and “time itself” suggest that particip ants use different principles for describing fixed relations (s tatic time) versus moving events (dynamic time).	entity;i/o controller hub;timeline;vocabulary	Andrea Bender;Kristin Sjåfjell;Annelie Rothe-Wulf;Sieghard Beller	2017			cognitive psychology;psychology;norwegian;timeline	HCI	-7.550171082601706	-78.02633892479588	105019
3aa476da544399f68888083a3111416f5b77de52	generating references in naturalistic face-to-face and phone-mediated dialog settings	mediated communication;common ground;dialog;bf psychology;naturalistic experimental settings;accessibility in memory	During dialog, references are presented, accepted, and potentially reused (depending on their accessibility in memory). Two experiments were conducted to examine reuse in a naturalistic setting (a walk in a familiar environment). In Experiment 1, where the participants interacted face to face, self-presented references and references accepted through verbatim repetition were reused more. Such biases persisted after the end of the interaction. In Experiment 2, where the participants interacted over the phone, reference reuse mainly depended on whether the participant could see the landmarks being referred to, although this bias seemed to be only transient. Consistent with the memory-based approach to dialog, these results shed light on how differences in accessibility in memory (due to how these references were initially added to the common ground or the media used) affect the unfolding of the interaction.		Dominique Knutsen;Christine Ros;Ludovic Le Bigot	2016	Topics in cognitive science	10.1111/tops.12218	psychology;dialog box;computer science;artificial intelligence;communication;social psychology;cognitive science	HCI	-7.194050126064375	-78.16677202896912	105131
f2878233a78978f91ae4594b1b916d7ff2fc971a	anticipatory and locally coherent lexical activation varies as a function of language proficiency		Interpreting sentences spoken in a second language can be demanding and plagued with uncertainty, especially for lower proficiency listeners. While native language listeners use numerous information sources to anticipate upcoming words accurately, the pattern of anticipation may be different for second language users. We explore this issue in bilinguals with varying English proficiency by recording anticipatory eyemovements as participants listened to sentences (e.g., “The pirate chases the ship”) for which the object and three distractors (agent-related, action-related, unrelated) appeared in the concurrently presented images. Higher proficiency participants were faster than lower proficiency participants. Fixations to action-related distractors after onset of the action also varied by proficiency, with lower proficiency participants showing greater tendency to fixate this locally coherent actionrelated distractor. This final effect is supported by a trial level analysis, but appears to be unrelated to the effect of proficiency on anticipation speed.	coherent;list of code lyoko episodes;onset (audio)	Ryan Peters;Theres Grüter;Arielle Borovsky	2015			psychology;cognitive psychology;first language;social psychology;language proficiency;anticipation	HCI	-7.495376554307194	-78.3594626213453	105194
bc9f32af666e0682fa21603b18f5157e70d15524	knowledge graph embedding via entities' type mapping matrix		Knowledge graph (KG) is the most popular method for presenting knowledge in search engines and other natural-language processing (NLP) applications. However, KG remains incomplete, inconsistent, and not completely accurate. To deal with the challenges of KGs, many state-of-the-art models, such as TransE, TransH, and TransR, have been proposed. TransE and TransH use one semantic space for entities and relations, whereas TransR uses two different semantic spaces in its embedding model. An issue is that these proposed models ignore the category-specific projection of entities. For example, the entity “Washington” could belong to the person or location category depending on its context or relationships. An entity may therefore involve multiple types or aspects. Considering all entities in just one semantic space is therefore not a logical approach to building an effective model. In this paper, we propose TransET, which maps each entity based on its type. We can then apply any other existing translation-distance-based embedding models such as TransE or TransR. We evaluated our model using two tasks that involve link prediction and triple classification. Our model achieved a significant and consistent improvement over other state-of-the-art models.		Md. Mostafizur Rahman;Atsuhiro Takasu	2018		10.1007/978-3-030-04182-3_11	graph embedding;machine learning;search engine;matrix (mathematics);artificial intelligence;theoretical computer science;computer science;monad (category theory);embedding;graph	NLP	-16.752955341350873	-66.54900666463321	105272
f902ce46b2e1307fe4d0895e2a99ad8399f47d40	an empirical study of adequate vision span for attention-based neural machine translation		Recently, the attention mechanism plays a key role to achieve high performance for Neural Machine Translation models. However, as it computes a score function for the encoder states in all positions at each decoding step, the attention model greatly increases the computational complexity. In this paper, we investigate the adequate vision span of attention models in the context of machine translation, by proposing a novel attention framework that is capable of reducing redundant score computation dynamically. The term “vision span” means a window of the encoder states considered by the attention model in one step. In our experiments, we found that the average window size of vision span can be reduced by over 50% with modest loss in accuracy on EnglishJapanese and German-English translation tasks.	computation;computational complexity theory;encoder;experiment;neural machine translation;text-based (computing);window function	Raphael Shu;Hideki Nakayama	2017			natural language processing;computer science;machine learning;artificial intelligence;machine translation;encoder;empirical research;decoding methods;computational complexity theory;computation	AI	-17.841409108244772	-76.10972125475226	105350
6f67ec661b747aee86c26f58e9a4f4294eda00b6	spell once, summon anywhere: a two-level open-vocabulary language model		We show how the spellings of known words can help us deal with unknown words in open-vocabulary NLP tasks. The method we propose can be used to extend any closedvocabulary generative model, but in this paper we specifically consider the case of neural language modeling. Our Bayesian generative story combines a standard RNN language model (generating the word tokens in each sentence) with an RNNbased spelling model (generating the letters in each word type). These two RNNs respectively capture sentence structure and word structure, and are kept separate as in linguistics. By invoking the second RNN to generate spellings for novel words in context, we obtain an open-vocabulary language model. For known words, embeddings are naturally inferred by combining evidence from type spelling and token context. Comparing to baselines (including a novel strong baseline), we beat previous work and establish state-of-the-art results on multiple datasets.	baseline (configuration management);generative model;language model;natural language processing;random neural network;vocabulary	Sebastian J. Mielke;Jason Eisner	2018	CoRR		machine learning;generative grammar;natural language processing;computer science;artificial intelligence;language model;spell;spelling;recurrent neural network;vocabulary;sentence;bayesian probability	NLP	-18.33711689162005	-74.17114292268539	105423
ccbcd91b83925a1337be5cb25d4b97bdfa7e7041	on learning context-free and context-sensitive languages	second order;cascaded networks long short term memory neural network context sensitive language recurrent neural network context free languages;context free languages;computer science artificial intelligence;context free;engineering and technology;teknik och teknologier;state space methods recurrent neural networks testing neural networks context modeling gold information science information technology australia read only memory;context sensitive languages;recognizers;recurrent neural nets;language;learning artificial intelligence;learning artificial intelligence recurrent neural nets context free languages context sensitive languages;engineering electrical electronic;computer science theory methods;prediction;long short term memory;neural network;recurrent neural network rnn;computer science hardware architecture;dynamic behavior	The long short-term memory (LSTM) is not the only neural network which learns a context sensitive language. Second-order sequential cascaded networks (SCNs) are able to induce means from a finite fragment of a context-sensitive language for processing strings outside the training set. The dynamical behavior of the SCN is qualitatively distinct from that observed in LSTM networks. Differences in performance and dynamics are discussed.	artificial neural network;biological neural networks;context-free grammar;context-free language;context-sensitive language;languages;long short-term memory;structure of suprachiasmatic nucleus;test set	Mikael Bodén;Janet Wiles	2002	IEEE transactions on neural networks	10.1109/72.991436	natural language processing;prediction;computer science;artificial intelligence;machine learning;context-free language;language;second-order logic;artificial neural network;long short term memory	Visualization	-14.778391029124482	-76.587501001719	105778
86bbfc4831c21dfdc6a8acfb7faf128a0060c786	d-page: diverse paraphrase generation		In this paper, we investigate the diversity aspect of paraphrase generation. Prior deep learning models employ either decoding methods or add random input noise for varying outputs. We propose a simple method Diverse Paraphrase Generation (D-PAGE), which extends neural machine translation (NMT) models to support the generation of diverse paraphrases with implicit rewriting patterns. Our experimental results on two real-world benchmark datasets demonstrate that our model generates at least one order of magnitude more diverse outputs than the baselines in terms of a new evaluation metric Jeffrey’s Divergence. We have also conducted extensive experiments to understand various properties of our model with a focus on diversity.	baseline (configuration management);benchmark (computing);decoding methods;deep learning;experiment;neural machine translation;rewriting	Qiongkai Xu;Juyan Zhang;Lizhen Qu;Lexing Xie;Richard Nock	2018	CoRR		artificial intelligence;order of magnitude;machine learning;machine translation;deep learning;decoding methods;computer science;rewriting;paraphrase	AI	-18.099516034143594	-74.61691364287742	105833
013dfc95172f1043e162fe2411cec165f02d662f	syntactic alignment is an index of affective alignment: an information-theoretical study of natural dialogue		We present an analysis of a treebank of spontaneous English dyadic conversations, investigating whether the degree of syntactic priming found across speakers is a function of the degrees of affective alignment and overall positivity of the speakers. We use information theory to measure the proportion of overlap between the syntactic structures of the speakers. The affective state of the speakers is indexed by aggregated measures of the affective valences of the words they use. We find that there is a positive relation between syntactic priming and affective alignment, over and above any lexical repetition effects. This constitutes evidence for the percolation of inter-speaker alignment across multiple levels of representation. This also illustrates the indexical value of syntactic alignment, as has been proposed in modern functional theories of grammar such as Dialogic Syntax.	data structure alignment;dyadic transformation;functional theories of grammar;information theory;percolation;spontaneous order;syntactic predicate;treebank	Fermín Moscoso del Prado Martín;John W. Du Bois	2015			psychology;priming (psychology);treebank;functional theories of grammar;syntax;affect (psychology);communication;dialogic;information theory;natural language processing;artificial intelligence;indexicality	NLP	-11.41170248571039	-79.8720998221057	105855
81c10915b3b774e950ecca468fb39ba0052d030c	discovering morphological paradigms from plain text using a dirichlet process mixture model	string edit;inflectional principle;plain text;unobserved form;inference procedure;graphical model;morphological paradigm;inference algorithm;inflectional paradigm;string tuples;dirichlet process mixture model;bayesian generative model;structured inflectional paradigm	We present an inference algorithm that organizes observed words (tokens) into structured inflectional paradigms (types). It also naturally predicts the spelling of unobserved forms that are missing from these paradigms, and discovers inflectional principles (grammar) that generalize to wholly unobserved words. Our Bayesian generative model of the data explicitly represents tokens, types, inflections, paradigms, and locally conditioned string edits. It assumes that inflected word tokens are generated from an infinite mixture of inflectional paradigms (string tuples). Each paradigm is sampled all at once from a graphical model, whose potential functions are weighted finitestate transducers with language-specific parameters to be learned. These assumptions naturally lead to an elegant empirical Bayes inference procedure that exploits Monte Carlo EM, belief propagation, and dynamic programming. Given 50–100 seed paradigms, adding a 10million-word corpus reduces prediction error for morphological inflections by up to 10%.	algorithm;belief propagation;dynamic programming;generative model;graphical model;mixture model;monte carlo method;programming paradigm;software propagation;transducer	Markus Dreyer;Jason Eisner	2011			natural language processing;speech recognition;computer science;machine learning;linguistics;statistics	NLP	-18.279572858437106	-77.2763428134155	105918
7bf59d4ca905616e4b9fea600c27500431085fee	finding component state transition model elements using neural networks: an empirical study		Use cases are popular for writing specifications of a system. However, despite their semi-structured nature, it is often time consuming and error-prone to generate component state transition diagrams from use case documents as it is done manually. While attempts to automate model generation from requirements have increased with the advent of deep neural networks (DNNs), there are limited studies in which a neural network architecture successfully extracts information used to construct a component state transition diagram from use cases. In this paper, we investigate the effectiveness of four different neural network architectures using glove and dependency embeddings to find model elements of component state transition diagrams from use case descriptions. Our results from the study show that we may achieve performance equivalent to humans with F1-scores greater than 0.80 for each model element on test data.	cognitive dimensions of notations;deep learning;network architecture;neural networks;requirement;semiconductor industry;state diagram;state transition table;test data	Kaushik Madala;Shraddha Piparia;Hyunsook Do;Renée C. Bryce	2018	2018 5th International Workshop on Artificial Intelligence for Requirements Engineering (AIRE)	10.1109/AIRE.2018.00014	task analysis;unified modeling language;state diagram;artificial neural network;natural language;theoretical computer science;use case;test data;data modeling;computer science	SE	-17.10402219991788	-74.02092264613032	105960
0334a8862634988cc684dacd4279c5c0d03704da	facenet2expnet: regularizing a deep face recognition net for expression recognition		Relatively small data sets available for expression recognition research make the training of deep networks very challenging. Although fine-tuning can partially alleviate the issue, the performance is still below acceptable levels as the deep features probably contain redundant information from the pretrained domain. In this paper, we present FaceNet2ExpNet, a novel idea to train an expression recognition network based on static images. We first propose a new distribution function to model the high-level neurons of the expression network. Based on this, a two-stage training algorithm is carefully designed. In the pre-training stage, we train the convolutional layers of the expression net, regularized by the face net; In the refining stage, we append fully-connected layers to the pre-trained convolutional layers and train the whole network jointly. Visualization results show that the model trained with our method captures improved high-level expression semantics. Evaluations on four public expression databases, CK+, Oulu- CASIA, TFD, and SFEW demonstrate that our method achieves better results than state-of-the-art.	algorithm;append;database;facial recognition system;high- and low-level;high-level programming language;neuron;teaching method;vii	Hui Ding;Shaohua Kevin Zhou;Rama Chellappa	2017	2017 12th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2017)	10.1109/FG.2017.23	computer vision;computer science;artificial intelligence;machine learning;pattern recognition;data mining	Vision	-16.56173920755626	-71.98699077442073	106192
d4db99796a41f9cfa9e7918619c3f9a8c9209d37	low latency rnn inference with cellular batching		"""Performing inference on pre-trained neural network models must meet the requirement of low-latency, which is often at odds with achieving high throughput. Existing deep learning systems use batching to improve throughput, which do not perform well when serving Recurrent Neural Networks with dynamic dataflow graphs. We propose the technique of cellular batching, which improves both the latency and throughput of RNN inference. Unlike existing systems that batch a fixed set of dataflow graphs, cellular batching makes batching decisions at the granularity of an RNN """"cell"""" (a subgraph with shared weights) and dynamically assembles a batched cell for execution as requests join and leave the system. We implemented our approach in a system called BatchMaker. Experiments show that BatchMaker achieves much lower latency and also higher throughput than existing systems."""	algorithm;artificial neural network;computation;dataflow;deep learning;natural language;parsing;random neural network;recurrent neural network;tensorflow;throughput	Pin Gao;Lingfan Yu;Yongwei Wu;Jinyang Li	2018		10.1145/3190508.3190541	real-time computing;latency (engineering);throughput;artificial neural network;computer science;distributed computing;dataflow;latency (engineering);deep learning;recurrent neural network;inference;artificial intelligence	OS	-14.756587869244798	-73.86706788145183	106350
c7a465438d4dcd4bdc3b0e1b5ee3b4935c261796	adversarial over-sensitivity and over-stability strategies for dialogue models		We present two categories of model-agnostic adversarial strategies that reveal the weaknesses of several generative, task-oriented dialogue models: Should-Not-Change strategies that evaluate over-sensitivity to small and semantics-preserving edits, as well as Should-Change strategies that test if a model is over-stable against subtle yet semantics-changing modifications. We next perform adversarial training with each strategy, employing a max-margin approach for negative generative examples. This not only makes the target dialogue model more robust to the adversarial inputs, but also helps it perform significantly better on the original inputs. Moreover, training on all strategies combined achieves further improvements, achieving a new state-of-the-art performance on the original task (also verified via human evaluation). In addition to adversarial training, we also address the robustness task at the model-level, by feeding it subword units as both inputs and outputs, and show that the resulting model is equally competitive, requires only 1/4 of the original vocabulary size, and is robust to one of the adversarial strategies (to which the original model is vulnerable) even without adversarial training.	substring;vocabulary	Tong Niu;Mohit Bansal	2018			machine learning;generative grammar;adversarial system;artificial intelligence;robustness (computer science);computer science;vocabulary	NLP	-16.496393177075852	-77.84933017930328	106474
7f1726ab3525084e06e44ca0d1a207d03501cd3b	generation of action description from classification of motion and object	object recognition;action description;human motion	This paper presents a novel approach to learning of relations among motions, objects, and language, and to generating sentences that describe human actions. Our approach categorizes human motions and the objects acted on those motions, and subsequently integrates the motion categories and object categories with their descriptive sentences. The integration consists of two steps. The first step stochastically learns the relations among the motions, objects, and words in the sentences. The second step stochastically learns the order of words in the sentences as the sentence structures. The model derived in the first step is referred to as “action language” model and that derived in the second step as “natural language” model. This framework for integrating an action language model with a natural language model can be applied to generating descriptive sentences from human actions, where each action is recognized as a pair containing a motion category and an object category, the words relevant to the action are generated via the contained motion and object categories, and the words to be arranged result in a descriptive sentence. More theoretically, our approach searches for multiple words likely to be generated from the motion and object categories by using the action language model; and subsequently searches for a sequence of these words that is likely to be generated from the obtained words, using the natural language model. We tested our proposed approach for sentence generation by applying it to human action data captured by an RGB-D sensor, and demonstrated its validity.	action language;action potential;bleu;crowdsourcing;language model;natural language;scalability	Wataru Takano;Yoshihiko Yamada;Yoshihiko Nakamura	2017	Robotics and Autonomous Systems	10.1016/j.robot.2017.02.003	natural language processing;speech recognition;computer science;cognitive neuroscience of visual object recognition	AI	-13.51225883717981	-69.32495003957845	106479
16e3ff2268c5698d84d165e6ca0c5af9d549278a	hhu at semeval-2018 task 12: analyzing an ensemble-based deep learning approach for the argument mining task of choosing the correct warrant		This paper describes our participation in the SemEval-2018 Task 12 Argument Reasoning Comprehension Task which calls to develop systems that, given a reason and a claim, predict the correct warrant from two opposing options. We decided to use a deep learning architecture and combined 623 models with different hyperparameters into an ensemble. Our extensive analysis of our architecture and ensemble reveals that the decision to use an ensemble was suboptimal. Additionally, we benchmark a support vector machine as a baseline. Furthermore, we experimented with an alternative data split and achieved more stable results.	baseline (configuration management);benchmark (computing);deep learning;list comprehension;support vector machine	Matthias Liebeck;Andreas Funke;Stefan Conrad	2018			natural language processing;deep learning;warrant;semeval;machine learning;artificial intelligence;computer science	AI	-16.481065123775583	-69.68378017033162	106525
aea8f3fdaf789ac52db7b7e27e8c12f0ea0f6a5e	a personalized counseling system using case-based reasoning with neural symbolic feature weighting (cansy)	case base reasoning;rule based;personalization;data mining;machine learning;it adoption;feature weighting;case based reasoning;value difference metric;use case;neural network	In this article, we introduce a personalized counseling system based on context mining. As a technique for context mining, we have developed an algorithm called CANSY. It adopts trained neural networks for feature weighting and a value difference metric in order to measure distances between all possible values of symbolic features. CANSY plays a core role in classifying and presenting most similar cases from a case base. Experimental results show that CANSY along with a rule base can provide personalized information with a relatively high level of accuracy, and it is capable of recommending appropriate products or services.	case-based reasoning;personalization	Kwang Hyuk Im;Sung Ho Ha	2007	Applied Intelligence	10.1007/s10489-007-0113-8	rule-based system;use case;case-based reasoning;computer science;artificial intelligence;machine learning;pattern recognition;data mining;personalization;artificial neural network	AI	-7.639699951846681	-66.19922149400438	106612
3741122650837776e4ea217b46705a05c39fab52	treenet: learning sentence representations with unconstrained tree structure		Recursive neural network (RvNN) has been proved to be an effective and promising tool to learn sentence representations by explicitly exploiting the sentence structure. However, most existing work can only exploit simple tree structure, e.g., binary trees, or ignore the order of nodes, which yields suboptimal performance. In this paper, we proposed a novel neural network, namely TreeNet, to capture sentences structurally over the raw unconstrained constituency trees, where the number of child nodes can be arbitrary. In TreeNet, each node learns from its left sibling and right child in a bottom-up left-to-right order, thus enabling the net to learn over any tree. Furthermore, multiple soft gates and a memory cell are employed in implementing the TreeNet to determine to what extent it should learn, remember and output, which proves to be a simple and efficient mechanism for semantic synthesis. Moreover, TreeNet significantly suppresses convolutional neural networks (CNN) and Long Short-Term Memory (LSTM) with fewer parameters. It improves the classification accuracy by 2%-5% with 42% of the best CNN’s parameters or 94% of standard LSTM’s. Extensive experiments demonstrate TreeNet achieves the state-of-the-art performance on all four typical text classification tasks.		Zhou Cheng;Chun Yuan;Jiancheng Li;Haiqin Yang	2018		10.24963/ijcai.2018/557	artificial intelligence;machine learning;tree structure;computer science;sentence	AI	-17.344675830441076	-73.7135853696527	106789
2ed947bb71897350f09e6b795b1fe50e2eb01854	taskonomy: disentangling task transfer learning		Do visual tasks have a relationship, or are they unrelated? For instance, could having surface normals simplify estimating the depth of an image? Intuition answers these questions positively, implying existence of a structure among visual tasks. Knowing this structure has notable values; it is the concept underlying transfer learning and provides a principled way for identifying redundancies across tasks, e.g., to seamlessly reuse supervision among related tasks or solve many tasks in one system without piling up the complexity. We proposes a fully computational approach for modeling the structure of space of visual tasks. This is done via finding (first and higher-order) transfer learning dependencies across a dictionary of twenty six 2D, 2.5D, 3D, and semantic tasks in a latent space. The product is a computational taxonomic map for task transfer learning. We study the consequences of this structure, e.g. nontrivial emerged relationships, and exploit them to reduce the demand for labeled data. We provide a set of tools for computing and probing this taxonomical structure including a solver users can employ to find supervision policies for their use cases.		Amir Roshan Zamir;Alexander Sax;William B. Shen;Leonidas J. Guibas;Jitendra Malik;Silvio Savarese	2018	2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition	10.1109/CVPR.2018.00391	machine learning;labeled data;transfer of learning;task analysis;artificial intelligence;reuse;computer science;exploit;use case;solver;intuition	Vision	-15.690851859770982	-67.22040186665573	106853
04ce8781710071a89eca9a2ca0899fdeaafd4ab1	interactions between hemispheres when disambiguating ambiguous homograph words during silent reading		"""A model of certain aspects of the cortex related to reading is developed corresponding to ongoing exploration of psychophysical and computational experiments on how the two hemispheres work in humans. The connectivity arrangements between modelled areas of orthography, phonology and semantics are according to the theories of Eviatar and Peleg, in particular with distinctions between the connectivity in the right and left hemisphere. The two hemispheres are connected and interact both in training and testing in a reasonably """"natural"""" way. We found that the RH (right hemisphere) serves to maintain alternative meanings under this arrangement longer than the LH for homophones. This corresponds to the usual theories (about homographs) while, surprisingly, the LH maintains alternative meanings longer then the RH for heterophones. This allows the two hemispheres, working together to resolve ambiguities regardless of when the disambiguating information arrives. Human experiments carried out subsequent to these results bear this surprising result out."""	competitive analysis (online algorithm);computation;experiment;humans;interaction;lh (complexity);simulation;theory;word-sense disambiguation	Zohar Eviatar;Hananel Hazan;Larry M. Manevitz;Orna Peleg;Rom Timor	2010			natural language processing;linguistics	ML	-9.065667311700533	-76.41596844451034	107346
b9cc408823b2a7a64da142cead94ffd3f172314d	"""""""no better, but no worse, than people"""""""	surface structure;language use;linear order;tree adjoining grammar;information flow;natural language understanding;natural language;natural language generation;text generation	It might also be in the modularity of the underlying system's information: Is it propositional and easily mapped onto kernel clauses and noun phrases, or does it have some drastically different organization? Generation research today has the lion's share of the important computational linguistics problems. As more and more people work in it, it will quickly become the cutting edge, forcing extensions on understanding and knowledge representation if they are to match it as a source of insight into the nature of language and thought in the human mind. There is no appropriate goal for generation research short of matching human performance, part of which entails coming to understand the limits on that performance. We don't really know how good people are at using language; our experiments with mechanical speakers may someday tell us.	computation;computational linguistics;experiment;human reliability;knowledge representation and reasoning;mind	David D. McDonald	1987		10.3115/980304.980354	natural language processing;computer science;linguistics;natural language;communication	NLP	-10.822100972806659	-73.06255979923958	107503
066347ce6ab883f4f211c051a8434d3acc70fb46	efficient classification with conjunctive features	特集 情報爆発時代におけるit基盤技術	This paper proposes a method that speeds up a classifier trained with many conjunctive features: combinations of (primitive) features. The key idea is to precompute as partial results the weights of primitive feature vectors that represent fundamental classification problems and appear frequently in the target task. A prefix tree (trie) compactly stores the primitive feature vectors with their weights, and it enables the classifier to find for a given feature vector its longest prefix feature vector whose weight has already been computed. Experimental results on base phrase chunking and dependency parsing demonstrated that our method speeded up the svm and llm classifiers by a factor of 1.8 to 10.6.	feature vector;phrase chunking;shallow parsing;statistical classification;trie	Naoki Yoshinaga;Masaru Kitsuregawa	2012	JIP	10.2197/ipsjjip.20.228	speech recognition;computer science;machine learning;pattern recognition	ML	-15.060342145661847	-66.82318055361327	107776
fbedf063b6c5e1e92d1d89dec14e20074df8e01a	k-nearest neighbor augmented neural networks for text classification		In recent years, many deep-learning based models are proposed for text classification. This kind of models well fits the training set from the statistical point of view. However, it lacks the capacity of utilizing instance-level information from individual instances in the training set. In this work, we propose to enhance neural network models by allowing them to leverage information from k-nearest neighbor (kNN) of the input text. Our model employs a neural network that encodes texts into text embeddings. Moreover, we also utilize k-nearest neighbor of the input text as an external memory, and utilize it to capture instance-level information from the training set. The final prediction is made based on features from both the neural network encoder and the kNN memory. Experimental results on several standard benchmark datasets show that our model outperforms the baseline model on all the datasets, and it even beats a very deep neural network model (with 29 layers) in several datasets. Our model also shows superior performance when training instances are scarce, and when the training set is severely unbalanced. Our model also leverages techniques such as semi-supervised training and transfer learning quite well.	baseline (configuration management);benchmark (computing);deep learning;document classification;encoder;fits;k-nearest neighbors algorithm;network model;neural networks;point of view (computer hardware company);semi-supervised learning;semiconductor industry;test set;unbalanced circuit	Zhiguo Wang;Wael Hamza;Linfeng Song	2017	CoRR		encoder;artificial intelligence;auxiliary memory;transfer of learning;natural language processing;machine learning;training set;artificial neural network;computer science;k-nearest neighbors algorithm;pattern recognition	AI	-17.614918190468913	-73.58810129738295	107820
22ee2b83855ac5dda67d17483431b760bd2ff365	a correlational encoder decoder architecture for pivot based sequence generation		Interlingua based Machine Translation (MT) aims to encode multiple languages into a common linguistic representation and then decode sentences in multiple target languages from this representation. In this work we explore this idea in the context of neural encoder decoder architectures, albeit on a smaller scale and without MT as the end goal. Specifically, we consider the case of three languages or modalities X , Z and Y wherein we are interested in generating sequences in Y starting from information available in X . However, there is no parallel training data available between X and Y but, training data is available between X & Z and Z & Y (as is often the case in many real world applications). Z thus acts as a pivot/bridge. An obvious solution, which is perhaps less elegant but works very well in practice is to train a two stage model which first converts from X to Z and then from Z to Y . Instead we explore an interlingua inspired solution which jointly learns to do the following (i) encodeX and Z to a common representation and (ii) decode Y from this common representation. We evaluate our model on two tasks: (i) bridge transliteration and (ii) bridge captioning. We report promising results in both these applications and believe that this is a right step towards truly interlingua inspired encoder decoder architectures.	artificial neural network;baseline (configuration management);compiler;encode;machine translation;non-monotonic logic;pivot animator;priority encoder;software quality assurance;vocabulary	Amrita Saha;Mitesh M. Khapra;A. P. Sarath Chandar;Janarthanan Rajendran;Kyunghyun Cho	2016			natural language processing;speech recognition;computer science;artificial intelligence;theoretical computer science;machine learning;programming language	NLP	-17.855964427695035	-74.55675699730463	107860
f2997065a71ade335eca074ce1343a64bc0c0291	an alternative phrase structure account of symmetric coordination	natural extension	Our SCC approach naturally overcomes the three basic problems hitherto encountered with non-constituent coordination, i.e., the problems arising from assuming, firstly, raising and secondly deletion, and thirdly from failing to provide an adequate input structure for semantic rules on LF. The proposed phrase structure account, according to which any coordination structure is licensed by the existence of coordinated heads (i.e., an Ordered List of heads), presents itself as a natural extension of the ¯X-scheme for simplex sentences. It not only equally accounts for the generation of any type of symmetric coordination. We, moreover, presented a generalized ¯X-scheme which uniformly covers the syntactic structures from simplex sentences (where only Factors are involved), over shared constituent coordination (involving Ordered Lists and Factors), up to non-shared constituent coordination (in which we find Ordered Lists only). In this respect, the proposed phrase structure account is a valid contribution to a general theory of sentence grammar.		Birgit Wesche	1991		10.1007/3-540-54594-8_62	natural language processing;computer science;algorithm	NLP	-12.602119157672364	-76.23837436376013	108219
093888607ea309de94db70140c54a37656032aa9	online learning via dynamic reranking for computer assisted translation	adaptacion;ridge regression;computer assisted translation;aprendizaje online;machine traslation;online learning;adaptation;quality measures;capitulo de libro;tesis de master;traduccion asistida por ordenador	New techniques for online adaptation in computer assisted translation are explored and compared to previously existing approaches. Under the online adaptation paradigm, the translation system needs to adapt itself to real-world changing scenarios, where training and tuning may only take place once, when the system is set-up for the first time. For this purpose, post-edit information, as described by a given quality measure, is used as valuable feedback within a dynamic reranking algorithm. Two possible approaches are presented and evaluated. The first one relies on the well-known perceptron algorithm, whereas the second one is a novel approach using the Ridge regression in order to compute the optimum scaling factors within a state-of-the-art SMT system. Experimental results show that such algorithms are able to improve translation quality by learning from the errors produced by the system on a sentence-by-sentence basis.	computer-assisted translation	Pascual Martínez-Gómez;Germán Sanchis-Trilles;Francisco Casacuberta	2011		10.1007/978-3-642-19437-5_8	computer-assisted translation;simulation;speech recognition;computer science;machine learning;tikhonov regularization;adaptation	Vision	-15.048964795022437	-75.37547070045193	108253
0fbe82f54c32cce66af28827dcfde0ffab3077bf	end-to-end argumentation mining in student essays		Understanding the argumentative structure of a persuasive essay involves addressing two challenging tasks: identifying the components of the essay’s argument and identifying the relations that occur between them. We examine the under-investigated task of end-toend argument mining in persuasive student essays, where we (1) present the first results on end-to-end argument mining in student essays using a pipeline approach; (2) address error propagation inherent in the pipeline approach by performing joint inference over the outputs of the tasks in an Integer Linear Programming (ILP) framework; and (3) propose a novel objective function that enables F-score to be maximized directly by an ILP solver. We evaluate our joint-inference approach with our novel objective function on a publiclyavailable corpus of 90 essays, where it yields an 18.5% relative error reduction in F-score over the pipeline system.	approximation error;baseline (configuration management);end-to-end principle;integer programming;linear programming;loss function;optimization problem;propagation of uncertainty;software propagation;solver	Isaac Persing;Vincent Ng	2016			natural language processing;computer science	NLP	-15.218651390846674	-71.99314207241692	108340
eb1b05051536a29139529653ab428c7c734508ec	lexicons, contexts, events, and images: commentary on elman (2009) from the perspective of dual coding theory	coding theory	Elman (2009) proposed that the traditional role of the mental lexicon in language processing can largely be replaced by a theoretical model of schematic event knowledge founded on dynamic context-dependent variables. We evaluate Elman's approach and propose an alternative view, based on dual coding theory and evidence that modality-specific cognitive representations contribute strongly to word meaning and language performance across diverse contexts which also have effects predictable from dual coding theory.	coding theory;context-sensitive language;dct gene;description;discrete cosine transform;dual;image;lexicon;modality (human–computer interaction);multimodal interaction;published comment;schematic	Allan Paivio;Mark Sadoskib	2011	Cognitive science	10.1111/j.1551-6709.2010.01146.x	psychology;natural language processing;artificial intelligence;linguistics;communication	NLP	-9.552864199389841	-77.69433300322976	108526
f8daab1e4f63051b78eb43e98ab723f6c425a6b5	speaker naming in movies		We propose a new model for speaker naming in movies that leverages visual, textual, and acoustic modalities in an unified optimization framework. To evaluate the performance of our model, we introduce a new dataset consisting of six episodes of the Big Bang Theory TV show and eighteen full movies covering different genres. Our experiments show that our multimodal model significantly outperforms several competitive baselines on the average weighted F-score metric. To demonstrate the effectiveness of our framework, we design an end-to-end memory network model that leverages our speaker naming model and achieves state-of-the-art results on the subtitles task of the MovieQA 2017 Challenge.	acoustic cryptanalysis;bang file;context-free grammar;end-to-end principle;experiment;f1 score;mathematical optimization;multimodal interaction;network model	Mahmoud Azab;Mingzhe Wang;Max Smith;Noriyuki Kojima;Jia Deng;Rada Mihalcea	2018			machine learning;network model;computer science;artificial intelligence	NLP	-14.182663000662851	-71.23797403445877	108808
0a8b38bccd527699a5da39c949e2c8c35cad5df0	monitoring in language perception: mild and strong conflicts elicit different erp patterns	nouns;syntax;figurative language;noun;conflict;linguistic theory;diagnostic tests;article letter to editor;language processing;language production;brain hemisphere functions;error patterns	In the language domain, most studies of error monitoring have been devoted to language production. However, in language perception, errors are made as well and we are able to detect them. According to the monitoring theory of language perception, a strong conflict between what is expected and what is observed triggers reanalysis to check for possible perceptual errors, a process reflected by the P600. This is at variance with the dominant view that the P600 reflects syntactic reanalysis or repair, after syntactic violations or ambiguity. In the present study, the prediction of the monitoring theory of language perception was tested, that only a strong conflict between expectancies triggers reanalysis to check for possible perceptual errors, reflected by the P600. Therefore, we manipulated plausibility, and hypothesized that when a critical noun is mildly implausible in the given sentence (e.g., “The eye consisting of among other things a pupil, iris, and eyebrow …”), a mild conflict arises between the expected and unexpected event; integration difficulties arise due to the unexpectedness but they are resolved successfully, thereby eliciting an N400 effect. When the noun is deeply implausible however (e.g., “The eye consisting of among other things a pupil, iris, and sticker …”), a strong conflict arises; integration fails and reanalysis is triggered, eliciting a P600 effect. Our hypothesis was confirmed; only when the conflict between the expected and unexpected event is strong enough, reanalysis is triggered.	conflict (psychology);erp;formal language;il13 wt allele;iris (eye);mcgurk effect;meteorological reanalysis;plausibility structure;precipitating factors;pupil;sample variance	Nan van de Meerendonk;Herman H. J. Kolk;Constance Th. W. M. Vissers;Dorothee J. Chwilla	2010	Journal of Cognitive Neuroscience	10.1162/jocn.2008.21170	psychology;cognitive psychology;noun;linguistics;communication;cognitive science	NLP	-8.222342676542294	-79.05577382894155	109529
3751e88244dab5b8ea6f69ae5056ffecb1856e71	using relational operators to structure long-term memory	relational operations;information retrieval;long term memory;predicate;question answering system;relation;memory	"""(nouns) in natural language passages. The other class, denoted Q> , consists of words that are logical connectives: most of them are conjunc­ tions which, in traditional grammar, connect sen­ tences. The relational operators, g' , bind sentences into larger semantic units. This paper describes a system for """"remember­ ing"""" a story or passage in English and for the subsequent retrieval of responses to questions. Although it functions as an information retrie­ val system, it is also intended as a model for long-term human memory. Information is stored in the form of predicates and property lists. In translating from natural language, the system carries out a transformational analysis of each sentence and identifies its deep structure inter­ pretation. This grammatical analysis is essential to the identification of the predicates as well as relationships among them. The first two subsystems carry out the gramma­ tical analysis. A third identifies the predi­ cates and property lists, determines a time and priority structure, forms a logical map of rela­ tionships among predicates, and eliminates some predicates based on an assignment of priority. The fourth subsystem is used to answer inquiries about the stored information. The method is illustrated with references to one story that has been processed and with ex­ amples of questions that might be asked. This paper describes an information retrieval system although it may also be interpreted as a simulation of long-term memory. More specifical­ ly, the system simulates the ability to read a story or some form of connected material written in English, to store a representation of that story, and later to be able to answer questions about it based on the ability to recall. In designing this system, we have been influ­ enced by some related studies which have used an intermediate formalism for the storage.of infor­ mation. Hillman. The relative success of these efforts indicates that an intermediate formalism is an important part of the simulation. In addition, each of these systems accepts natural language (English) inputs. The system described in this paper also allows natural language inputs and usee relational operators as an intermediate for­ malism. A relational operator connects two entities in a qualitative manner. Two classes of rela­ tional operators are used in constructing the model. The first class is denoted e and con­ sists of verbs, which usually join entities The first level formalism of a predicate logic is used to represent …"""	entity;first-class function;information retrieval;information theory;logical connective;natural language;predicate (mathematical logic);property list;relational operator;semantics (computer science);simulation	Alan L. Tharp;Gilbert K. Krulee	1969			natural language processing;long-term memory;question answering;predicate;computer science;relation;database;linguistics;memory;algorithm	AI	-8.723166153713429	-74.63712679524681	109678
7c4494e3b628c2a450e99594c9943dc7f0c6fa16	automatic recognition of learner groups in exploratory learning environments	unsupervised learning;metodo adaptativo;computer assisted teaching;base de connaissances;algorithme k moyenne;k means;methode adaptative;ensenanza asistida por computador;apprentissage non supervise;learning environment;data mining;classification;user assistance;automatic recognition;assistance utilisateur;fouille donnee;interaction pattern;adaptive method;asistencia usuario;base conocimiento;algoritmo k media;k means algorithm;educacion;busca dato;clasificacion;k means clustering;enseignement assiste ordinateur;reconocimiento automatico;reconnaissance automatique;knowledge base	In this paper, we present the application of unsupervised learning techniques to automatically recognize behaviors that may be detrimental to learning during interaction with an Exploratory Learning Environment (ELE). First, we describe how we use the k-means clustering algorithm for off-line identification of learner groups with distinguishing interaction patterns who also show similar learning improvements with an ELE. We then discuss how a kmeans on-line classifier, trained with the learner groups detected off-line, can be used for adaptive support in ELEs. We aim to show the value of a data-based approach for recognizing learners as an alternative to knowledge-based approaches that tend to be complex and time-consuming even for domain experts, especially in highly unstructured ELEs.	cluster analysis;constraint satisfaction;expectation–maximization algorithm;experiment;exploratory testing;eye tracking;k-means clustering;online and offline;unsupervised learning	Saleema Amershi;Cristina Conati	2006		10.1007/11774303_46	unsupervised learning;knowledge base;speech recognition;computer science;artificial intelligence;machine learning;k-means clustering	ML	-7.104231729081303	-70.94378016773172	109743
788b5cf66a344deb5051317ab8456399ebdfb0a7	aesthetic perception of visual textures: a holistic exploration using texture analysis, psychological experiment, and perception modeling	biological patents;psychological experiment;biomedical journals;text mining;europe pubmed central;citation search;citation networks;texture analysis;dimensionality reduction;research articles;model building;aesthetic emotion;abstracts;layered model architecture;期刊论文;open access;life sciences;clinical guidelines;perception modeling;full text;rest apis;orcids;europe pmc;biomedical research;visual texture;bioinformatics;literature search	Modeling human aesthetic perception of visual textures is important and valuable in numerous industrial domains, such as product design, architectural design, and decoration. Based on results from a semantic differential rating experiment, we modeled the relationship between low-level basic texture features and aesthetic properties involved in human aesthetic texture perception. First, we compute basic texture features from textural images using four classical methods. These features are neutral, objective, and independent of the socio-cultural context of the visual textures. Then, we conduct a semantic differential rating experiment to collect from evaluators their aesthetic perceptions of selected textural stimuli. In semantic differential rating experiment, eights pairs of aesthetic properties are chosen, which are strongly related to the socio-cultural context of the selected textures and to human emotions. They are easily understood and connected to everyday life. We propose a hierarchical feed-forward layer model of aesthetic texture perception and assign 8 pairs of aesthetic properties to different layers. Finally, we describe the generation of multiple linear and non-linear regression models for aesthetic prediction by taking dimensionality-reduced texture features and aesthetic properties of visual textures as dependent and independent variables, respectively. Our experimental results indicate that the relationships between each layer and its neighbors in the hierarchical feed-forward layer model of aesthetic texture perception can be fitted well by linear functions, and the models thus generated can successfully bridge the gap between computational texture features and aesthetic texture properties.	area striata structure;black box;computation;computational neuroscience;decision tree;desktop computer;emotions;eureqa;feature selection;feature vector;fuzzy control system;high- and low-level;holism;human-readable medium;linear iga bullous dermatosis;linear function;maximal set;name mangling;neuroscience discipline;nonlinear system;published comment;rule (guideline);seizures;semantic differential;subgroup;trees (plant);visual evoked cortical potential;weight;anatomical layer;cell transformation	Jianli Liu;Edwin Lughofer;Xianyi Zeng	2015		10.3389/fncom.2015.00134	psychology;computer vision;text mining;model building;computer science;bioinformatics;machine learning;multimedia;dimensionality reduction	AI	-7.010115156727006	-67.89857055495916	110253
53653636ce66cf50fe97a6d45efd270c4f140153	intonation based sentence modality classifier for czech using artificial neural network	intonation;non linear model;temporal pattern classification;sentence modality;neural network	This paper presents an idea and first results of sentence modality classifier for Czech based purely on intonational information. This is in contrast with other studies which usually use more features (including lexical features) for this type of classification. As the sentence melody (intonation) is the most important feature, all the experiments were done on an annotated sample of Czech audiobooks library recorded by Czech leading actors. A non-linear model implemented by artificial neural network (ANN) was chosen for the classification. Two types of ANN are considered in this work in terms of temporal pattern classifications classical multi-layer perceptron (MLP) network and Elman’s network, results for MLP are presented. Pre-processing of temporal intonational patterns for use as ANN inputs is discussed. Results show that questions are very often misclassified as statements and exclamation marks are not detectable in current data set.	artificial neural network;audiobook;experiment;layer (electronics);linear model;memory-level parallelism;modality (human–computer interaction);multilayer perceptron;nonlinear system;quad flat no-leads package;statistical classification	Jan Bartosek;Václav Hanzl	2011		10.1007/978-3-642-25020-0_21	natural language processing;speech recognition;computer science;machine learning;pattern recognition;artificial neural network	AI	-16.474576863689446	-77.15588289100101	110353
e55ea424bea40642879c64026853a5575e3178a7	operation-guided neural networks for high fidelity data-to-text generation		Recent neural models for data-to-text generation are mostly based on data-driven end-toend training over encoder-decoder networks. Even though the generated texts are mostly fluent and informative, they often generate descriptions that are not consistent with the input structured data. This is a critical issue especially in domains that require inference or calculations over raw data. In this paper, we attempt to improve the fidelity of neural data-to-text generation by utilizing pre-executed symbolic operations. We propose a framework called Operationguided Attention-based sequence-to-sequence network (OpAtt), with a specifically designed gating mechanism as well as a quantization module for operation results to utilize information from pre-executed operations. Experiments on two sports datasets show our proposed method clearly improves the fidelity of the generated texts to the input structured data.	artificial neural network;encoder;executable;experiment;information;lexical choice;natural language generation;neural network software;symbolic computation	Feng Nie;Jinpeng Wang;Jin-Ge Yao;Rong Pan;Chin-Yew Lin	2018				AI	-17.175291988856713	-74.45547572490402	110781
856fe866bcce5e7a540655bea6ecc7406bdcfcba	generalization without systematicity: on the compositional skills of sequence-to-sequence recurrent networks		Humans can understand and produce new utterances effortlessly, thanks to their compositional skills. Once a person learns the meaning of a new verb “dax,” he or she can immediately understand the meaning of “dax twice” or “sing and dax.” In this paper, we introduce the SCAN domain, consisting of a set of simple compositional navigation commands paired with the corresponding action sequences. We then test the zero-shot generalization capabilities of a variety of recurrent neural networks (RNNs) trained on SCAN with sequence-to-sequence methods. We find that RNNs can make successful zero-shot generalizations when the differences between training and test commands are small, so that they can apply “mix-and-match” strategies to solve the task. However, when generalization requires systematic compositional skills (as in the “dax” example above), RNNs fail spectacularly. We conclude with a proof-of-concept experiment in neural machine translation, suggesting that lack of systematicity might be partially responsible for neural networks’ notorious training data thirst.	artificial neural network;humans;neural machine translation;recurrent neural network	Brenden M. Lake;Marco Baroni	2018			natural language processing;machine translation;machine learning;artificial intelligence;artificial neural network;verb;computer science;generalization;recurrent neural network;training set	NLP	-14.049472423514732	-74.94291916492556	110830
0c804c58485a5d34ef932fa90b5927feefd58ea5	sequence encoders enable large-scale lexical modeling: reply to bowers and davis (2009)	orthographe;ortografia;health research;large scale modeling;uk clinical guidelines;biological patents;distributed representation;critical study;connectionism;learning;sequence encoder;europe pubmed central;conexionismo;lexicon;citation search;lenguaje;hombre;langage;orthography;etude critique;proceso adquisicion;wordforms;acquisition process;aprendizaje;estudio critico;connexionnisme;large scale;codificacion;apprentissage;phonology;uk phd theses thesis;cognition;coding;human;life sciences;modele simulation;cognicion;fonologia;phonologie;modelo simulacion;language;lexico;reseau neuronal;uk research reports;medical journals;simulation model;red neuronal;processus acquisition;europe pmc;biomedical research;codage;homme;neural network;bioinformatics;lexique	Sibley, Kello, Plaut, and Elman (2008) proposed the sequence encoder as a model that learns fixed-width distributed representations of variable-length sequences. In doing so, the sequence encoder overcomes problems that have restricted models of word reading and recognition to processing only monosyllabic words. Bowers and Davis (in press) recently claimed that the sequence encoder does not actually overcome the relevant problems, and hence is not a useful component of large-scale word reading models. In this reply, it is noted that the sequence encoder has facilitated the creation of large-scale word reading models. The reasons for this success are explained, and stand as counterarguments to claims made by Bowers and Davis.	encoder device component;width	Daragh E. Sibley;Christopher T. Kello;David C. Plaut;Jeffrey L. Elman	2009	Cognitive science	10.1111/j.1551-6709.2009.01064.x	psychology;cognitive psychology;connectionism;speech recognition;cognition;philosophy;orthography;computer science;artificial intelligence;simulation modeling;linguistics;sociology;language;coding;communication;cognitive science;phonology	NLP	-11.515983708323425	-76.06950263715746	110983
7247bbd25f2dcd7e5af514bfb7c6ffd60aa6f543	do not forget: full memory in memory-based learning of word pronunciation	radio program task based learning task based model l2 learners native like pronunciation language learning system;educational technology humans learning systems context history stability video recording dictionaries computer science education;natural languages;education natural languages radio applications;language learning;radio applications;task based learning	Memory-based learning, keeping full memory ofleaxning material, appeaxs a viable approach to learning N-~ tasks, and is often superior in genera~sation accuracy to eager learning approaches that abstract from learning materiaL Here we investigate three pa~'tial memorybased learning approaches which remove from memory specific task instance types estimated to be exceptional. The three approaches each implement one heuristic function for estimating exceptiona]ity of instance types: (i) typicatty, (ii) class prediction strength, and (fii) friencfly-neighbourhood size. Experiments are performed with the memory-based learning algorithm IBI-IG trained on English word pronunciatlon. We find that removing instance types with low prediction strength (il) is the only tested method which does not seriously harm generallsation accuracy. We conclude that keeping full memory of types rather than tokens, and excluding minority ambiguities appear to be the only performance-preserving optimi~tions of memory-based leaxning.	algorithm;eager learning;genera;heuristic (computer science);instance-based learning	Antal van den Bosch;Walter Daelemans	1998		10.1109/CIE.2002.1186316	natural language processing;computer science;multimedia;natural language;pedagogy	NLP	-10.446020190841573	-75.21639863676253	111097
2c8534207d6e455d88f6b708e805508bec8828d8	multimodal computing and interaction - robust, efficient and intelligent processing of text, speech, visual data and high dimensional representations			multimodal interaction	Hans-Peter Seidel	2009			natural language processing;artificial intelligence;computer vision;computer science	HCI	-8.52330527667392	-70.02128886510197	111328
8229ca1ac283c240d9625c6776ea254d779a8553	learning joint representation for community question answering with tri-modal dbm	semantic similarity;query understanding;deep boltzmann machine;community question answering	One of the main research tasks in Community question answering (CQA) is to find most relevant questions for a given new query, thereby providing useful knowledge for the users. Traditionally used methods such as bag-of-words or latent semantic models consider queries, questions and answers in a same feature space. However, the correlations among queries, questions and answers imply that they lie in different feature spaces. In light of these issues, we proposed a tri-modal deep boltzmann machine (tri-DBM) to extract unified representation for query, question and answer. Experiments on Yahoo! Answers dataset reveal using these unified representation to train a classifier judging semantic matching level between query and question outperforms models using bag-of-words or LSA representation significantly.	bag-of-words model in computer vision;boltzmann machine;dbm;feature vector;google questions and answers;modal logic;question answering;semantic matching;triangular function	Baolin Peng;Wenge Rong;Yuanxin Ouyang;Chao Li;Zhang Xiong	2014		10.1145/2567948.2577341	natural language processing;semantic similarity;computer science;data mining;information retrieval	Web+IR	-17.23699848951057	-68.64661375875798	111550
1e6a9b7277ab523d35d47b4d1d12477b6bde1246	the role of difference-detection in learning contrastive categories		Prior research has found that comparison fosters abstraction and transfer of concepts (e.g., categories, solution methods). These learning benefits are often explained by virtue of comparison’s ability to highlight common relational structure between cases. Here we explore the role of comparison in identifying critical differences. Participants compared contrastive cases, listed differences between them, and completed a classification task. We found that carrying out a structural alignment prior to listing differences influenced the kinds of differences people noticed. Further, the kinds of differences people noticed predicted their subsequent classification performance.		Linsey A. Smith;Dedre Gentner	2014			salience (language);cognitive psychology;social psychology;structural alignment;psychology;goldstone;abstraction;analogy;learning effect	HCI	-7.420155665418813	-75.7256886958587	111558
c788d04293e129c7b21206ebb33a7980e5414f81	generalized hebbian algorithm for incremental latent semantic analysis	latent semantic analysis;batch process;information retrieval;human performance;language model	The Generalized Hebbian Algorithm is shown to be equivalent to Latent Semantic Analysis, and applicable to a range of LSAstyle tasks. GHA is a learning algorithm which converges on an approximation of the eigen decomposition of an unseen frequency matrix given observations presented in sequence. Use of GHA allows very large datasets to be processed.	approximation;eigen (c++ library);generalized hebbian algorithm;hebbian theory;latent semantic analysis;qr decomposition	Genevieve Gorrell;Brandyn Webb	2005			artificial intelligence;oxide;intermetallic;dissolution;microstructure;solubility;pattern recognition;computer science;soldering;generalized hebbian algorithm;earth (classical element)	ML	-18.35368654070976	-76.7320802335964	111601
c5511b1db2e375a93ccd90d07b304875872d894b	thinking in ways we don't speak: evidence for a universal preference in semantic granularity		Language-like Optimal Linguistic universals: speakers share a universal conceptual repertoire, considering and categorizing spatial relations in a similar way, regardless of language. Coarse-grainedness (partition height) N a tu ra ln e s s ( p a rt it io n s il h o u e tt e ) Comparing across theoretically optimal k-term partitions, we take the system with the most tightly clustered categories to be the optimal system overall. The granularity of the optimal system matches the granularity at which speakers across languages tend to sort	categorization;disk partitioning;logico-linguistic modeling;master boot record	Alexandra Carstensen;Grace Neveu;Lev Michael;Terry Regier	2013			social psychology;psychology;cognitive psychology;granularity	NLP	-8.29981528512792	-76.76314267727726	111738
e89ec98f2bd587b8a5301475372118eb9b544b20	dynamic time-aware attention to speaker roles and contexts for spoken language understanding		Spoken language understanding (SLU) is an essential component in conversational systems. Most SLU component treats each utterance independently, and then the following components aggregate the multi-turn information in the separate phases. In order to avoid error propagation and effectively utilize contexts, prior work leveraged history for contextual SLU. However, the previous model only paid attention to the content in history utterances without considering their temporal information and speaker roles. In the dialogues, the most recent utterances should be more important than the least recent ones. Furthermore, users usually pay attention to 1) self history for reasoning and 2) others utterances for listening, the speaker of the utterances may provides informative cues to help understanding. Therefore, this paper proposes an attention-based network that additionally leverages temporal information and speaker role for better SLU, where the attention to contexts and speaker roles can be automatically learned in an end-to-end manner. The experiments on the benchmark Dialogue State Tracking Challenge 4 (DSTC4) dataset show that the time-aware dynamic role attention networks significantly improve the understanding performance1.	aggregate data;benchmark (computing);end-to-end principle;experiment;information;natural language understanding;propagation of uncertainty;software propagation	Po-Chun Chen;Ta-Chung Chi;Shang-Yu Su;Yun-Nung Chen	2017	2017 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)	10.1109/ASRU.2017.8268985	natural language processing;computer science;deep learning;communication;active listening;spoken language;artificial intelligence;utterance	NLP	-15.610264363496036	-72.58037417994504	111755
857c52a22454f72a8613c76ab7dc3e7ca5030397	knowledge based automatic composition and variation of melodies for minuets in early classical style	minuet composition;programmed typesetting;composition;composicion;informatisation;musical note;musica;base connaissance;composicion programada;computerization;musique;nota musical;note musique;composition programmee;piano;base conocimiento;informatizacion;microstructures;music;macroestructura;macrostructure;melody;knowledge base	Composition of piano minuets in early classical style takes an intermediate position between restricted and free computerized composition problems. One of its distinct features is that microstructure (i.e. relations between notes), macrostructure (i.e. relations between larger parts) and their interdependences have to be dealt with. In this paper, we give an overview of the process of composition which consists of the subtasks planning of macrostructure, construction of melody and rhythm, variation of melodic motives, and addition of bass and middle voices. We then present a knowledge-based approach with strategies and results for note by note construction of melody and methods for melody variation.		Mathis Löthe	1999		10.1007/3-540-48238-5_13	composition;melody;knowledge base;speech recognition;computer science;artificial intelligence;music;piano	AI	-12.239276500971366	-79.98565430720062	111778
9868db4bd854ea90855abdb1d845c4ecc0327a19	conversational analysis using utterance-level attention-based bidirectional recurrent neural networks		Recent approaches for dialogue act recognition have shown that context from preceding utterances is important to classify the subsequent one. It was shown that the performance improves rapidly when the context is taken into account. We propose an utterance-level attention-based bidirectional recurrent neural network (Utt-Att-BiRNN) model to analyze the importance of preceding utterances to classify the current one. In our setup, the BiRNN is given the input set of current and preceding utterances. Our model outperforms previous models that use only preceding utterances as context on the used corpus. Another contribution of our research is a mechanism to discover the amount of information in each utterance to classify the subsequent one and to show that context-based learning not only improves the performance but also achieves higher confidence in the recognition of dialogue acts. We use characterand wordlevel features to represent the utterances. The results are presented for character and word feature representations and as an ensemble model of both representations. We found that when classifying short utterances, the closest preceding utterances contribute to a higher degree.		Chandrakant Bothe;Sven Magg;Cornelius Weber;Stefan Wermter	2018		10.21437/Interspeech.2018-2527	artificial intelligence;machine learning;pattern recognition;recurrent neural network;ensemble forecasting;computer science;utterance	NLP	-15.681938895646326	-72.87621406327561	111870
da1cbd48bd63a03834f6def1ca8e08d420e1871f	information density as a factor for variation in the embedding of relative clauses		In German, relative clauses can be positioned in-situ or extraposed. A potential factor for the variation might be information density. In this study, this hypothesis is tested with a corpus of 17 th century German funeral sermons. For each referent in the relative clauses and their matrix clauses, the attention state was determined (first calculation). In a second calculation, for each word the surprisal values were determined, using a bi-gram language model. In a third calculation, the surprisal values were accommodated as to whether it is the first occurrence of the word in question or not. All three calculations pointed in the same direction: With in-situ relative clauses, the rate of new referents was lower and the average surprisal values were lower, especially the accommodated surprisal values, than with extraposed relative clauses. This indicated that information density is a factor governing the choice between in-situ and extraposed relative clauses. The study also sheds light on the intrinsic relationship between the information theoretic concept of information density and information structural concepts such as givenness which are used under a more linguistic perspective.	information design;language model;self-information;text corpus;theory	Augustin Speyer;Robin Lemke	2017	CoRR		arithmetic;discrete mathematics;mathematics;algorithm	NLP	-12.357661029681552	-77.96052992740464	111876
77a85bc1cff997a7c2ca915dc2101b5953ec7d53	improving neural question generation using answer separation		Neural question generation (NQG) is the task of generating a question from a given passage with deep neural networks. Previous NQG models suffer from a problem that a significant proportion of the generated questions include words in the question target, resulting in the generation of unintended questions. In this paper, we propose answer-separated seq2seq, which better utilizes the information from both the passage and the target answer. By replacing the target answer in the original passage with a special token, our model learns to identify which interrogative word should be used. We also propose a new module termed keyword-net, which helps the model better capture the key information in the target answer and generate an appropriate question. Experimental results demonstrate that our answer separation method significantly reduces the number of improper questions which include answers. Consequently, our model significantly outperforms previous state-of-the-art NQG models.	artificial neural network;deep learning	Yanghoon Kim;Hwanhee Lee;Joongbo Shin;Kyomin Jung	2018	CoRR		machine learning;security token;artificial neural network;artificial intelligence;interrogative word;computer science	NLP	-16.547117525151563	-76.37971974872376	111986
5aa1d92777a7aa29e279ef1dc9f25864aaa43a12	lip reading sentences in the wild		The goal of this work is to recognise phrases and sentences being spoken by a talking face, with or without the audio. Unlike previous works that have focussed on recognising a limited number of words or phrases, we tackle lip reading as an open-world problem &#x2013; unconstrained natural language sentences, and in the wild videos. Our key contributions are: (1) a Watch, Listen, Attend and Spell (WLAS) network that learns to transcribe videos of mouth motion to characters, (2) a curriculum learning strategy to accelerate training and to reduce overfitting, (3) a Lip Reading Sentences (LRS) dataset for visual speech recognition, consisting of over 100,000 natural sentences from British television. The WLAS model trained on the LRS dataset surpasses the performance of all previous work on standard lip reading benchmark datasets, often by a significant margin. This lip reading performance beats a professional lip reader on videos from BBC television, and we also demonstrate that if audio is available, then visual information helps to improve speech recognition performance.	automated lip reading;batch processing;benchmark (computing);call of duty: black ops;constrained optimization;convolutional neural network;discriminative model;encoder;expectation propagation;long short-term memory;natural language;network model;online and offline;open world;overfitting;random neural network;recurrence relation;sigmoid function;speech recognition	Joon Son Chung;Andrew W. Senior;Oriol Vinyals;Andrew Zisserman	2017	2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	10.1109/CVPR.2017.367	overfitting;natural language processing;computer science;visualization;natural language;spell;speech recognition;artificial intelligence	Vision	-17.017592590862304	-76.20971020621721	112043
0ffe950218f28882d4d9458dced346370280bcec	multiplicative tree-structured long short-term memory networks for semantic representations		Tree-structured LSTMs have shown advantages in learning semantic representations by exploiting syntactic information. Most existing methods model tree structures by bottomup combinations of constituent nodes using the same shared compositional function and often making use of input word information only. The inability to capture the richness of compositionality makes these models lack expressive power. In this paper, we propose multiplicative tree-structured LSTMs to tackle this problem. Our model makes use of not only word information but also relation information between words. It is more expressive, as different combination functions can be used for each child node. In addition to syntactic trees, we also investigate the use of Abstract Meaning Representation in tree-structured models, in order to incorporate both syntactic and semantic information from the sentence. Experimental results on common NLP tasks show the proposed models lead to better sentence representation and AMR brings benefits in complex tasks.	adaptive multi-rate audio codec;expressive power (computer science);internet backbone;long short-term memory;natural language processing;syntactic predicate;tree (data structure)	Nam Khanh Tran;Weiwei Cheng	2018			long short term memory;natural language processing;machine learning;multiplicative function;artificial intelligence;computer science	NLP	-18.480775419759826	-74.23837678229178	112236
f123e8b48eba9089128679c58d1922c3a65013dd	empty category and the effect of teaching in sentence processing	conference paper	"""Different syntactic frameworks have different ways to deal with dislocation constructions. One major disagreement is whether or not empty categories should be assumed. Researchers have been working on this issue on the ground of """"psychological reality"""" (of empty categories), yet have not come to an agreement. The first aim of this paper is to propose an experimental scheme to settle the issue of empty categories. Our second aim is to propose that the application of the experiment to L2 is beneficial to see the teaching effect in L2 acquisition. If native speakers' result supports no-empty-category analysis, yet, L2 learners exhibit the different result, L2 teaching of """"wh-movement"""" created a category which is not in native speakers' mental grammar."""		Takako Kawasaki;Kiyoshi Ishikawa	2003			natural language processing;speech recognition;linguistics	NLP	-9.992127992769834	-75.97593593435177	112371
70237f913174afb28bad43710683c4d0f9e0e201	production of morphologically complex words as revealed by a typing task: morphological influences on keystroke dynamics		In a production by typing task, with extraneous factors (e.g., length) controlled, measures such as latency to initial keystroke as well as mean inter keystroke interval typically vary systematically according to the word’s lexical properties. Conventionally, lexical effects in production tasks get interpreted as evidence of cascaded processing between central and peripheral levels. We compare mean and distribution of keystroke latencies within the same stem as it undergoes affixation in sets such as DEPRESS, DEPRESSION, DEPRESSIVE. Novel is the comparison of stems that differ with respect to number of affixes like SUPER, SUPERIOR, SUPERIORITY. Results provide new insights into the ways in which morphological structure can influence purportedly peripheral motor processing.	event (computing);keystroke dynamics;peripheral	Laurie Feldman;Rick Dale;Jacolien van Rij;David W. Vinson	2017			cognitive psychology;typing;psychology;keystroke dynamics	NLP	-10.146978152620711	-79.50321369439786	112921
688d8718e662d931d8c0ab1bfd03314c2ba711af	gated neural networks for targeted sentiment analysis	targeted sentiment analysis;neural network	Targeted sentiment analysis classifies the sentiment polarity towards each target entity mention in given text documents. Seminal methods extract manual discrete features from automatic syntactic parse trees in order to capture semantic information of the enclosing sentence with respect to a target entity mention. Recently, it has been shown that competitive accuracies can be achieved without using syntactic parsers, which can be highly inaccurate on noisy text such as tweets. This is achieved by applying distributed word representations and rich neural pooling functions over a simple and intuitive segmentation of tweets according to target entity mentions. In this paper, we extend this idea by proposing a sentencelevel neural model to address the limitation of pooling functions, which do not explicitly model tweet-level semantics. First, a bi-directional gated neural network is used to connect the words in a tweet so that pooling functions can be applied over the hidden layer instead of words for better representing the target and its contexts. Second, a three-way gated neural network structure is used to model the interaction between the target mention and its surrounding contexts. Experiments show that our proposed model gives significantly higher accuracies compared to the current best method for targeted sentiment analysis.	artificial neural network;experiment;interaction;noisy text;parse tree;parsing;sentiment analysis;syntactic predicate	Meishan Zhang;Yue Zhang;Duy-Tin Vo	2016			natural language processing;computer science;artificial intelligence;machine learning;data mining;artificial neural network	NLP	-18.264430867097303	-72.09667770247076	112925
19600dd3021169e162790d07ccf31e5938d0ddbf	jointly learning word representations and composition functions using predicate-argument structures		We introduce a novel compositional language model that works on PredicateArgument Structures (PASs). Our model jointly learns word representations and their composition functions using bagof-words and dependency-based contexts. Unlike previous word-sequencebased models, our PAS-based model composes arguments into predicates by using the category information from the PAS. This enables our model to capture longrange dependencies between words and to better handle constructs such as verbobject and subject-verb-object relations. We verify this experimentally using two phrase similarity datasets and achieve results comparable to or higher than the previous best results. Our system achieves these results without the need for pretrained word vectors and using a much smaller training corpus; despite this, for the subject-verb-object dataset our model improves upon the state of the art by as much as ∼10% in relative performance.	empirical methods in natural language processing;experiment;language model;word embedding	Kazuma Hashimoto;Pontus Stenetorp;Makoto Miwa;Yoshimasa Tsuruoka	2014			natural language processing;speech recognition;computer science;machine learning	NLP	-19.065568938256337	-74.02072872734973	112937
1dd7e4d01b6852ae421de3fdcf3cd710960461e9	knowledge graph completion by embedding with bi-directional projections		Knowledge graph (KG) completion aims at predicting the unknown links between entities and relations. In this paper, we focus on this task through embedding a KG into a latent space. Existing embedding based approaches such as TransH usually perform the same operation on head and tail entities in a triple. Such way could ignore the different roles of head and tail entities in a relation. To resolve this problem, this paper proposes a novel method for KGs embedding by preforming bi-directional projections on head and tail entities. In this way, the different information of an entity could be elaborately captured when it plays different roles for a relation. The experimental results on multiple benchmark datasets demonstrate that our method significantly outperforms state-of-the-art methods.	bi-directional text;knowledge graph	Wenbing Luo;Jiali Zuo;Zhengxia Gao	2016		10.1007/978-3-319-42297-8_71	computer science;artificial intelligence;machine learning;theoretical computer science;monad (category theory);embedding;graph	AI	-16.36136115183447	-66.72495405993419	113043
491b765b180ab85209b1850a1029dba65c5e9c66	online handwritten kanji recognition based on inter-stroke grammar	online handwritten kanji recognition;inter-stroke grammar;kanji substrokes;important kanji;distinct kanji category;handwritten kanji character;non-trained kanji;recognition rate;kanji character gen;kanji character;online handwritten kanji database;kanji sim;context free grammars;hidden markov model;stochastic processes;natural languages;stochastic context free grammar;hidden markov models;science and technology	This paper presents a new approach to online recognition of handwritten Kanji characters focusing on their hierarchical structure. Stochastic context-free grammar (SCFG) is introduced to represent the Kanji character generating process in combination with Hidden Markov Models (HMM) representing Kanji substrokes and to improve the recognition accuracy of important and frequently used Kanji characters in which inter-stroke relative positions play important roles. Combining the stroke likelihood and the relative-position likelihood between character-parts in the parsing process is expected to compensate their ambiguities. By modeling relative positions and share the models across distinct Kanji categories, a small training data can yield effective results and enables us to recognize Kanji simply by defining the SCFG rules to represent their structures without training data. Experimental results on an online handwritten Kanji database from JAIST (Japan Advanced Institute of Science and Technology) showed significant improvements in the recognition rates of some important Kanji with relatively fewer strokes and also showed little difference between the trained- and the non-trained Kanji in recognition rates.	context-free language;hidden markov model;markov chain;parsing;stochastic context-free grammar;unified framework	Ikumi Ota;Ryo Yamamoto;Shinji Sako;Shigeki Sagayama	2007	Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)	10.1109/ICDAR.2007.202	natural language processing;speech recognition;computer science;machine learning;pattern recognition;natural language;context-free grammar;stochastic context-free grammar;hidden markov model;science, technology and society	Vision	-18.147343816945792	-79.38944800837197	113452
7075991e542d890d653b23a3c707da98fd073812	re-representation in comparison: building an empirical case	comparison;knowledge representation and reasoning;analogy;re representation;knowledge representation;structure alignment	relation (monotonic increase across a series of geometric shapes) on the basis of a progressive alignment procedure. By first establishing two contextually limited forms of the relationship, it became possible to extend to the more general form. Gentner et al. (1995) describe this pattern of results with an emphasis on the explanatory value of the re-representation hypothesis. Specifically, the authors suggest that learners in these studies achieved a representational shift from relational predicates such as larger-than, to the more abstract form greater-than(size). Both predicates capture the meaning of the stimulus, but one explicitly encodes the semantic content in a form that allows identical matching to a broad range of greater-than predicates. The account suggests that repeated mapping experience allows the learner to derive the common semantic constituent between larger-than and darker-than, and perhaps to apply the more uniform representational vocabulary subsequently. An online, process-based measure of re-representation was used by Gentner and Kurtz (submitted) to test whether analogical evaluation of simple sentence pairs with non-identical, but related verbs would take longer to complete than sentence pairs with synonymous or identical (conceptually matching) verbs. Processing times were on the order of one-half of a second longer on a task that required about 2 seconds to complete. In addition, it was found that participants used verbal re-descriptions of the critical relational terms when justifying judgments of analogical acceptance. Clement et al. (1994) suggest re-representation as the basis by which analogical retrieval can succeed in generating relational remindings based on semantically near, but contextually distinct relational terms. The data show greater success in generating relational remindings between cases expressed in manifestly similar relational terms (e.g. robbing vs stealing—lexical items that, according to Gentner’s framework, might well be encoded using the same relational predicate) than between cases with a latent relational match. The implication is that an initial process of re-representation (i.e. during encoding) can serve to promote access of analogs. However, the overall rarity of spontaneous analogical retrieval does little to suggest routine re-representation activity. A common methodology for assessing representation change has been similarity ratings either before/after or with/without a processing manipulation. In investigations of the influence of classification learning in altering item perception (Livingston et al. 1998, Goldstone et al. 2001) and item construal (Kurtz and Smith in preparation), similarity has been the dominant measure. Goldstone and colleagues have also tested perceptual learning in terms of discrimination ability (e.g. Goldstone 1994). Motivated in part by these findings, Boroditsky (in press) conducted a series of studies showing a clear influence of comparison on rated similarity. The results are interpreted as evidence that comparison processes work to tune and shape conceptual organization. 6. The inference probe paradigm The new approach to studying re-representation is quite straightforward. The idea is to assess the form of a mental representation by eliciting evaluations of possible Re-representation in comparison 453	information retrieval;mental representation;programming paradigm;relational algebra;relational model;shift jis;spontaneous order;vocabulary	Kenneth J. Kurtz	2005	J. Exp. Theor. Artif. Intell.	10.1080/09528130500324255	natural language processing;knowledge representation and reasoning;structural alignment;analogy;computer science;artificial intelligence;machine learning;structure mapping engine	NLP	-8.420794728438606	-76.67122883339083	113453
c8f71575e501642d21b689cadde3af50318fb848	computational modeling as a methodology for studying human language learning		The nature and amount of information needed for learning a natural language, and the underlying mechanisms involved in this process, are the subject of much debate: how is the knowledge of language represented in the human brain? Is it possible to learn a language from usage data only, or is some sort of innate knowledge and/or bias needed to boost the process? Are di↵erent aspects of language learned in order? These are topics of interest to (psycho)linguists who study human language acquisition, as well as to computational linguists who develop the knowledge sources necessary for large-scale natural language processing systems. Children are the ultimate subjects of any study of language learnability. They learn language with ease, in a short period of time and their acquired knowledge of language is flexible and robust. Human language acquisition has been studied for centuries, but using computational modeling for such studies is a relatively recent trend. However, computational approaches to language learning have become increasingly popular, mainly due to advances in developing machine learning techniques, and the availability of large collections of experimental data on child language learning and child-adult interaction. Many of the existing computational models attempt to study the complex task of learning a language under cognitively plausible criteria (such as memory and processing limitations that humans face), and to explain the developmental stages observed in children. By simulating the process of child language learning, computational models can show us which linguistic representations are learnable from the input that children have access to in a reasonable amount of time, and which mechanisms yield the same patterns of behaviour that children exhibit during this process. In doing so, computational modeling provides insight into the plausible	computation;computational model;computer simulation;learnability;machine learning;natural language processing;robustness (computer science);usage data	Thierry Poibeau;Aline Villavicencio;Anna Korhonen;Afra Alishahi	2013		10.1007/978-3-642-31863-4_1	natural language processing;algorithmic learning theory;computer science;machine learning;modeling language;computational learning theory	ML	-10.827068198579013	-75.76563416186909	113538
8a576d2d2c001937c71542a2c0053f9fac5a9969	assessing sparse information extraction using semantic contexts	semantic context;semantic network;semantic relationship;sparse information extraction	One important assumption of information extraction is that extractions occurring more frequently are more likely to be correct. Sparse information extraction is challenging because no matter how big a corpus is, there are extractions supported by only a small amount of evidence in the corpus. A pioneering work known as REALM learns HMMs to model the context of a semantic relationship for assessing the extractions. This is quite costly and the semantics revealed for the context are not explicit. In this work, we introduce a lightweight, explicit semantic approach for sparse information extraction. We use a large semantic network consisting of millions of concepts, entities, and attributes to explicitly model the context of semantic relationships. Experiments show that our approach improves the F-score of extraction by at least 11.2% over state-of-the-art, HMM based approaches while maintaining more efficiency.	entity;hidden markov model;information extraction;semantic network;sparse matrix	Pei-Pei Li;Haixun Wang;Hongsong Li;Xindong Wu	2013		10.1145/2505515.2505598	natural language processing;relationship extraction;semantic similarity;semantic computing;semantic integration;explicit semantic analysis;semantic grid;computer science;machine learning;data mining;semantic compression;database;semantic network;information retrieval	AI	-18.10901826225854	-66.17848299506477	113669
8b5b8db6a2a2880c14894140ea70ceb5f96c3b9b	learning a text-video embedding from incomplete and heterogeneous data		Joint understanding of video and language is an active research area with many applications. Prior work in this domain typically relies on learning text-video embeddings. One difficulty with this approach, however, is the lack of large-scale annotated video-caption datasets for training. To address this issue, we aim at learning text-video embeddings from heterogeneous data sources. To this end, we propose a Mixture-of-Embedding-Experts (MEE) model with ability to handle missing input modalities during training. As a result, our framework can learn improved text-video embeddings simultaneously from image and video datasets. We also show the generalization of MEE to other input modalities such as face descriptors. We evaluate our method on the task of video retrieval and report results for the MPII Movie Description and MSR-VTT datasets. The proposed MEE model demonstrates significant improvements and outperforms previously reported methods on both text-to-video and video-to-text retrieval tasks. Code: https://github.com/antoine77340/Mixture-of-Embedding-Experts	document retrieval;facial recognition system;flickr;microsoft research;stream (computing)	Antoine Miech;Ivan Laptev;Josef Sivic	2018	CoRR		modalities;pattern recognition;machine learning;computer science;artificial intelligence;embedding	ML	-14.924654171685638	-68.04523360319965	113722
13fcf5f635010194fc34f15a96e2ed5a13b2ee69	when high pitches sound low: children's acquisition of space-pitch metaphors	article in monograph or in proceedings	Some languages describe musical pitch in terms of spatial height; others in terms of thickness. Differences in pitch metaphors also shape adults’ nonlinguistic space-pitch representations. At the same time, 4-month-old infants have both types of space-pitch mappings available. This tension between prelinguistic space-pitch associations and their subsequent linguistic mediation raises questions about the acquisition of space-pitch metaphors. To address this issue, 5-year-old Dutch children were tested on their linguistic knowledge of pitch metaphors, and nonlinguistic spacepitch associations. Our results suggest 5-year-olds understand height-pitch metaphors in a reversed fashion (high pitch = low). Children displayed good comprehension of a thickness-pitch metaphor, despite its absence in Dutch. In nonlinguistic tasks, however, children did not show consistent space-pitch associations. Overall, pitch representations do not seem to be influenced by linguistic metaphors in 5-year-olds, suggesting that effects of language on musical pitch arise rather late during development.	cognition;pitch (music);thickness (graph theory)	Sarah Dolscheid;Sabine Hunnius;Asifa Majid	2015			psychology;natural language processing;linguistics;communication	NLP	-9.15211395316197	-78.87956317816729	113849
8e7fba35e67820f81acb85ae0994b5843de53845	arabic morphology in the neural language system	grammar;morphology languages;morphemes;functional properties;semantics;internal structure;role;diagnostic tests;language processing;semitic languages;temporal cortex;lateral dominance;neurological organization;correlation;brain hemisphere functions;neural network	There are two views about morphology, the aspect of language concerned with the internal structure of words. One view holds that morphology is a domain of knowledge with a specific type of neurocognitive representation supported by specific brain mechanisms lateralized to left fronto-temporal cortex. The alternate view characterizes morphological effects as being a by-product of the correlation between form and meaning and where no brain area is predicted to subserve morphological processing per se. Here we provided evidence from Arabic that morphemes do have specific memory traces, which differ as a function of their functional properties. In an MMN study, we showed that the abstract consonantal root, which conveys semantic meaning (similarly to monomorphemic content words in English), elicits an MMN starting from 160 msec after the deviation point, whereas the abstract vocalic word pattern, which plays a range of grammatical roles, elicits an MMN response starting from 250 msec after the deviation point. Topographically, the root MMN has a symmetric fronto-central distribution, whereas the word pattern MMN lateralizes significantly to the left, indicating stronger involvement of left peri-sylvian areas. In languages with rich morphologies, morphemic processing seems to be supported by distinct neural networks, thereby providing evidence for a specific neuronal basis for morphology as part of the cerebral language machinery.	artificial neural network;languages;mathematical morphology;mystery meat navigation;neural network simulation;temporal lobe;tracing (software);neurocognitive	Sami Boudelaa;Friedemann Pulvermüller;Olaf Hauk;Yury Shtyrov;William D. Marslen-Wilson	2010	Journal of Cognitive Neuroscience	10.1162/jocn.2009.21273	psychology;morpheme;role;mismatch negativity;grammar;semantics;semitic languages;linguistics;communication;correlation;diagnostic test	NLP	-9.81563508730075	-78.81756031114575	113877
f653074a48a605b32ea4da59f06ec3c7cc0b05ae	schematizing the treatment of dissonance in 16th-century counterpoint.		We describe a computational project concerning labeling of dissonance treatments – schematic descriptions of the uses of dissonances. We use automatic score annotation and database methods to develop schemata for a large corpus of 16th-century polyphonic music. We then apply structural techniques to investigate coincidence of schemata, and to extrapolate from found structures to unused possibilities.	computation;extrapolation;schematic	Andie Sigler;Jon Wild;Eliot Handelman	2015			cognitive psychology;speech recognition;cognitive dissonance;counterpoint;computer science	NLP	-12.522699366006893	-77.79020135643425	114182
01e624fbdee6a565ba9678ab9f3beba9d09686b1	do gestures serve an interpersonal function?		Some researchers argue that gestures serve an interpersonal function, such as making the intended message clear (e.g., Gallagher & Frith, 2003; cf. Kita, 2000). In this study, we tested whether gestures serve an interpersonal function, specifically predicting that the higher participants’ autism spectrum quotient, the less frequently they would gesture. Participants completed the Autism Spectrum Quotient questionnaire (Baron-Cohen, Wheelwright, Skinner, Martin, & Clubley, 2001). To elicit gestures, participants did two tasks. In one, they explained spatial and social concepts. In another, they told the story of a cartoon. The dependent variable is the gesture rate (gestures per word), to account for individual differences in volubility. Participants completed a standardized vocabulary test. The initial results show no correlation between gesture rate in either task and ASQ scores. There is a negative correlation between ASQ and vocabulary scores. These results are inconsistent with the argument that gestures serve an important interpersonal function.	spectrum analyzer;vocabulary	Yiwei Chen;Robyn Enns;Elena Nicoladis	2016				HCI	-7.867427541781025	-79.05679887032228	114257
9b8d2b9ccd30e21dca0b89c853af0f9c946d8a42	comparing predictions of lexical norm data obtained using word associations and word collocation	semantics;word associations	We compared the quality of prediction of word variables based on a Dutch word association and text corpus. We derived estimates for: valence, arousal, dominance, concreteness and age of acquisition (AoA) for 2831 words. Based on the similarity between words we: (1) used projections on a dimension identified as the variable in question in a multidimensional representation, (2) used the k-nearest neighbors values, weighted according to their proximity. Estimates prevailed when based on word associations. Differences between the predictions of the two methods were small. Based on the word association corpus it yielded correlations of .92, .85, and .85, for valence, arousal, and dominance, respectively. Its corresponding correlations based on the text corpus were .80, .74, and .67. For concreteness and AoA, both the association and the text corpus yielded correlations of .88 and .73, respectively. This suggests word associations are better at capturing human ratings of affective word variables.	collocation;k-nearest neighbors algorithm;text corpus	Hendrik Vankrunkelsven;Steven Verheyen;Simon De Deyne;Gerrit Storms	2016			natural language processing;speech recognition;linguistics	NLP	-13.32416058533111	-78.86400470846353	114297
e42057e03578bd058f38b1a8a46b470f3841bc14	using prosodic and lexical information for learning utterance-level behaviors in psychotherapy		In this paper, we present an approach for predicting utterance level behaviors in psychotherapy sessions using both speech and lexical features. We train long short term memory (LSTM) networks with an attention mechanism using words, both manually and automatically transcribed, and prosodic features, at the word level, to predict the annotated behaviors. We demonstrate that prosodic features provide discriminative information relevant to the behavior task and show that they improve prediction when fused with automatically derived lexical features. Additionally, we investigate the weights of the attention mechanism to determine words and prosodic patterns which are of importance to the behavior prediction task.	long short-term memory	Karan Singla;Zhuohao Chen;Nikolaos Flemotomos;James Gibson;Dogan Can;David C. Atkins;Shrikanth (Shri) Narayanan	2018		10.21437/Interspeech.2018-2551	speech recognition;communication;utterance;computer science	NLP	-15.709214091264085	-71.99347388207369	114330
3ac2c116eeb4c3ebb4c867c1e18214a437d79a56	broadcast news story segmentation using conditional random fields and multimodal features	conditional random fields	In this paper, we propose integration of multimodal features using conditional random fields (CRFs) for the segmentation of broadcast news stories. We study story boundary cues from lexical, audio and video modalities, where lexical features consist of lexical similarity, chain strength and overall cohesiveness; acoustic features involve pause duration, pitch, speaker change and audio event type; and visual features contain shot boundaries, anchor faces and news title captions. These features are extracted in a sequence of boundary candidate positions in the broadcast news. A linear-chain CRF is used to detect each candidate as boundary/non-boundary tags based on the multimodal features. Important interlabel relations and contextual feature information are effectively captured by the sequential learning framework of CRFs. Story segmentation experiments show that the CRF approach outperforms other popular classifiers, including decision trees (DTs), Bayesian networks (BNs), naive Bayesian classifiers (NBs), multilayer perception (MLP), support vector machines (SVMs) and maximum entropy (ME) classifiers. key words: story segmentation, conditional random fields	acoustic cryptanalysis;bayesian network;cohesion (computer science);conditional random field;decision tree;experiment;memory-level parallelism;multimodal interaction;principle of maximum entropy;support vector machine	Xiaoxuan Wang;Lei Xie;Mimi Lu;Bin Ma;Chng Eng Siong;Haizhou Li	2012	IEICE Transactions		speech recognition;computer science;theoretical computer science;machine learning;conditional random field;information retrieval	NLP	-18.321875583811718	-69.6944763074835	114405
0d406275af277ea94dd10f024bf76ca5c513906e	end-task oriented textual entailment via deep explorations of inter-sentence interactions		This work deals with SCITAIL, a natural entailment challenge derived from a multi-choice question answering problem. The premises and hypotheses in SCITAIL were generated with no awareness of each other, and did not specifically aim at the entailment task. This makes it more challenging than other entailment data sets and more directly useful to the end-task – question answering. We propose DEISTE (deep explorations of inter-sentence interactions for textual entailment) for this entailment task. Given word-to-word interactions between the premise-hypothesis pair (P , H), DEISTE consists of: (i) a parameter-dynamic convolution to make important words in P and H play a dominant role in learnt representations; and (ii) a position-aware attentive convolution to encode the representation and position information of the aligned word pairs. Experiments show that DEISTE gets ≈5% improvement over prior state of the art and that the pretrained DEISTE on SCITAIL generalizes well on RTE-5.1		Wenpeng Yin;Dan Roth;Hinrich Schütze	2018				NLP	-14.970768790821282	-70.37074950922646	114457
4ed06a32b6197760600272633ea47ebda1f0d2e4	investigating automatic dominance estimation in groups from visual attention and speaking activity	dominance modeling;audio visual feature extraction;visual focus of attention;focus of attention;meetings;audio visual;social psychology;visual attention	We study the automation of the visual dominance ratio (VDR); a classic measure of displayed dominance in social psychology literature, which combines both gaze and speaking activity cues. The VDR is modified to estimate dominance in multi-party group discussions where natural verbal exchanges are possible and other visual targets such as a table and slide screen are present. Our findings suggest that fully automated versions of these measures can estimate effectively the most dominant person in a meeting and can match the dominance estimation performance when manual labels of visual attention are used.	vdr	Hayley Hung;Dinesh Babu Jayagopi;Sileye O. Ba;Jean-Marc Odobez;Daniel Gatica-Perez	2008		10.1145/1452392.1452441	computer vision;visual search	HCI	-8.027298311779894	-80.05369701560349	114549
e442bea7fbca634a73911f43af101048566b1009	convolutional neural network for automatic detection of sociomoral reasoning level		We propose a model that employs convolutional neural networks (CNN) to evaluate sociomoral reasoning maturity, a key social ability, necessary for adaptive social functioning. Our model is used in a serious game to evaluate learners. It uses pre-annotated textual data (verbatims) and a coding scheme (SoMoral) applied by experts in psychology. State of the art text classification algorithms (Support Vector Machine, Naïve Bayes, etc.) achieved low results in our context in contrary to the CNN that achieved best results with little fine tuning on the input data representation. We use a simple but efficient input data vectors representation learnt directly from the dataset without loosing the sentences ‘semantic’. We present a series of experiments with 5 baseline text classification algorithms and 4 baseline data representation. The results show that our model can predict the level of sociomoral reasoning with about 92% of accuracy. Our findings allow not only to advance the textmining field but also the user modeling in highly social adaptive systems.	adaptive system;algorithm;artificial neural network;baseline (configuration management);capability maturity model;convolutional neural network;data (computing);document classification;experiment;naive bayes classifier;support vector machine;text corpus;text mining;user modeling	Ange Adrienne Nyamen Tato;Roger Nkambou;Aude Dufresne	2017			machine learning;artificial intelligence;computer science;convolutional neural network	AI	-18.85149426004767	-69.9577032980077	114697
2ad7d42ab5c3b442ff8cdb61e5db9b5ed046f9a5	state-of-the-art kernels for natural language processing	syntactic tree;salient feature;data representation problem;ml algorithm;data mining;powerful ml tool;structured input;natural language processing;explicit feature vector;structured data;state-of-the-art kernel;nlp system	In recent years, machine learning (ML) has been used more and more to solve complex tasks in different disciplines, ranging from Data Mining to Information Retrieval or Natural Language Processing (NLP). These tasks often require the processing of structured input, e.g., the ability to extract salient features from syntactic/semantic structures is critical to many NLP systems. Mapping such structured data into explicit feature vectors for ML algorithms requires large expertise, intuition and deep knowledge about the target linguistic phenomena. Kernel Methods (KM) are powerful ML tools (see e.g., (Shawe-Taylor and Cristianini, 2004)), which can alleviate the data representation problem. They substitute feature-based similarities with similarity functions, i.e., kernels, directly defined between training/test instances, e.g., syntactic trees. Hence feature vectors are not needed any longer. Additionally, kernel engineering, i.e., the composition or adaptation of several prototype kernels, facilitates the design of effective similarities required for new tasks, e.g., (Moschitti, 2004; Moschitti, 2008).	algorithm;data (computing);data mining;feature vector;information retrieval;kernel (operating system);kernel method;machine learning;natural language processing;prototype;syntactic predicate	Alessandro Moschitti	2012			natural language processing;computer science;machine learning;pattern recognition	ML	-18.814478554064603	-67.69874125065073	114950
c9bd18d3ff538efdf459b8f0d63a96340694765a	identifying latent attributes from video scenes using knowledge acquired from large collections of text documents	text;mental state inference;information extraction;information science;information retrieval;electronic dissertation;computer vision;computer science identifying latent attributes from video scenes using knowledge acquired from large collections of text documents the university of arizona paul r cohen tran;anh xuan;artificial intelligence;computer science;natural language processing	. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 CHAPTER		Anh Xuan Tran	2014			natural language processing;computer science;data science;information retrieval	Vision	-14.334932173796272	-66.41929547396798	115112
5c6739f9b9270756bcbecfb7bb5d398a9102ce0d	predicting cognitively salient modifiers of the constitutive parts of concepts	characteristic property;cognitively salient modifier;target concept;simple method;long ear;composite property;constitutive part;best performance	When subjects describe concepts in terms of their characteristic properties, they often produce composite properties, e. g., rabbits are said to have long ears, not just ears. We present a set of simple methods to extract the modifiers of composite properties (in particular: parts) from corpora. We achieve our best performance by combining evidence about the association between the modifier and the part both within the context of the target concept and independently of it. We show that this performance is relatively stable across languages (Italian and German) and for production vs. perception	machine perception;modifier key;text corpus	Gerhard Kremer;Marco Baroni	2010			engineering;artificial intelligence;communication;engineering drawing	NLP	-11.858190483441685	-79.9499828300488	115166
e5bfebd3774c44580463cda8e611487ae3639cd7	conditional image-text embedding networks		This paper presents an approach for grounding phrases in images which jointly learns multiple text-conditioned embeddings in a single end-to-end model. In order to differentiate text phrases into semantically distinct subspaces, we propose a concept weight branch that automatically assigns phrases to embeddings, whereas prior works predefine such assignments. Our proposed solution simplifies the representation requirements for individual embeddings and allows the underrepresented concepts to take advantage of the shared representations before feeding them into concept-specific layers. Comprehensive experiments verify the effectiveness of our approach across three phrase grounding datasets, Flickr30K Entities, ReferIt Game, and Visual Genome, where we obtain a (resp.) 4%, 3%, and 4% improvement in grounding performance over a strong region-phrase embedding baseline (Code: https://github.com/BryanPlummer/cite).		Bryan A. Plummer;Paige Kordas;M. Hadi Kiapour;Shuai Zheng;Robinson Piramuthu;Svetlana Lazebnik	2018		10.1007/978-3-030-01258-8_16	linear subspace;artificial intelligence;machine learning;discriminative model;computer science;pattern recognition;embedding;phrase	Vision	-17.91903281650975	-72.8796267172996	115227
6faaeedd1bf554a73182cb4f7918855d92a565b4	prosody contour prediction with long short-term memory, bi-directional, deep recurrent neural networks		Deep Neural Networks (DNNs) have been shown to provide state-of-the-art performance over other baseline models in the task of predicting prosodic targets from text in a speechsynthesis system. However, prosody prediction can be affected by an interaction of shortand long-term contextual factors that a static model that depends on a fixed-size context window can fail to properly capture. In this work, we look at a recurrent formulation of neural networks (RNNs) that are deep in time and can store state information from an arbitrarily large input history when making a prediction. We show that RNNs provide improved performance over DNNs of comparable size in terms of various objective metrics for a variety of prosodic streams (notably, a relative reduction of about 6% in F0 mean-square error accompanied by a relative increase of about 14% in F0 variance), as well as in terms of perceptual quality assessed through mean-opinion-score listening tests.	baseline (configuration management);long short-term memory;mean squared error;neural networks;recurrent neural network;semantic prosody	Raul Fernandez;Asaf Rendel;Bhuvana Ramabhadran;Ron Hoory	2014			speech recognition;computer science;machine learning	NLP	-16.31130233046116	-75.81828890426863	115651
1142b876e31f9fc8c9314aa56fb6ceef628f3e0c	a hybrid learning scheme for chinese word embedding		To improve word embedding, subword information has been widely employed in state-of-the-art methods. These methods can be classified to either compositional or predictive models. In this paper, we propose a hybrid learning scheme, which integrates compositional and predictive model for word embedding. Such a scheme can take advantage of both models, thus effectively learning word embedding. The proposed scheme has been applied to learn word representation on Chinese. Our results show that the proposed scheme can significantly improve the performance of word embedding in terms of analogical reasoning and is robust to the size of training data.	baseline (configuration management);information;predictive modelling;substring;text corpus;word embedding	Weiguo Sheng	2018			word embedding;natural language processing;machine learning;computer science;artificial intelligence	AI	-18.940946588728735	-74.36021455561068	115934
29f351f64bc14cc210cd830f444a226fb8bef14f	beauty-in-averageness and its contextual modulations: a bayesian statistical account		Understanding how humans perceive the likability of high-dimensionalrnobjectsu0027u0027 such as faces is an important problem in both cognitive science and AI/ML. Existing models of human preferences generally assume these preferences to be fixed. However, human assessment of facial attractiveness have been found to be highly context-dependent. Specifically, the classical Beauty-in-Averageness (BiA) effect, whereby a face blended from two original faces is judged to be more attractive than the originals, is significantly diminished or reversed when the original faces are recognizable, or when the morph is mixed-race/mixed gender and the attractiveness judgment is preceded by a race/gender categorization. This effect, dubbed Ugliness-in-Averageness (UiA), has previously been attributed to a disfluency account, which is both qualitative and clumsy in explaining BiA. We hypothesize, instead, that these contextual influences on face processing result from the dependence of attractiveness perception on an element of statistical typicality, and from an attentional mechanism that restricts face representation to a task-relevant subset of features, thus redefining typicality within that subspace. Furthermore, we propose a principled explanation of why statistically atypical objects are less likable: they incur greater encoding or processing cost associated with a greater prediction error, when the brain uses predictive coding to compare the actual stimulus properties with those expected from its associated categorical prototype. We use simulations to show our model provides a parsimonious, statistically grounded, and quantitative account of contextual dependence of attractiveness. We also validate our model using experimental data from a gender categorization task. Finally, we make model predictions for a proposed experiment that can disambiguate the previous disfluency account and our statistical typicality theory.	artificial intelligence;categorization;cognitive science;context-sensitive language;definition;efficient coding hypothesis;face;occam's razor;physical object;simulation;subgroup;terminator 2: judgment day	Chaitanya K. Ryali	2018			machine learning;computer science;artificial intelligence;experimental data;categorization;attractiveness;categorical variable;perception;encoding (memory);averageness;bayesian probability;pattern recognition	ML	-7.205853581267807	-76.30954049679416	116126
13348c00f3dad6d47cb6298bd25035fe2aee57b5	a topic-based reordering model for statistical machine translation		Reordering models are one of essential components of statistical machine translation. In this paper, we propose a topic-based reordering model to predict orders for neighboring blocks by capturing topic-sensitive reordering patterns. We automatically learn reordering examples from bilingual training data, which are associated with document-level and word-level topic information induced by LDA topic model. These learned reordering examples are used as evidences to train a topic-based reordering model that is built on a maximum entropy (MaxEnt) classifier. We conduct large-scale experiments to validate the effectiveness of the proposed topic-based reordering model on the NIST Chinese-to-English translation task. Experimental results show that our topic-based reordering model achieves significant performance improvement over the conventional reordering model using only lexical information.	baseline (configuration management);experiment;linear discriminant analysis;principle of maximum entropy;statistical machine translation;topic model	Xing Wang;Deyi Xiong;Min Zhang;Yu Hong;Jianmin Yao	2014		10.1007/978-3-662-45924-9_37	machine translation;natural language processing;artificial intelligence;computer science	NLP	-18.802508187005554	-72.44767423167212	116355
332e338c6bcf12fec34b5fb4d6025e8bd61ccddf	exploring rich expressive information from audiobook data using cluster adaptive training		Audiobook data is a freely available source of rich expressi ve speech data. To accurately generate speech of this form, exp ressiveness must be incorporated into the synthesis system. Th is paper investigates two parts of this process: the represent atio of expressive information in a statistical parametric spee ch synthesis system; and whether discrete expressive state label s can sufficiently represent the full diversity of expressive spe ech. Initially a discrete form of expressive information was used. A new form of expressive representation, where each conditio maps to a point in an expressive speech space, is described. This cluster adaptively trained (CAT) system is compared to incorporating information in the decision tree construction and a transform based system using CMLLR and CSMAPLR. Experimental results indicate that the CAT system outperformed t he contrast systems in both expressiveness and voice quality. The CAT-style representation yields a continuous expressive s pe ch space. Thus, it is possible to treat utterance-level expres siv ness as a point in this continuous space, rather than as one of a set of discrete states. This continuous-space representat ion outperformed discrete clusters, indicating limitations of di screte labels for expressiveness in audiobook data.	audiobook;decision tree;exptime;earthbound;expressive power (computer science);map	Langzhou Chen;Mark J. F. Gales;Vincent Wan;Javier Latorre;Masami Akamine	2012			speech recognition;computer science	AI	-18.532779103398507	-79.90314793768052	117115
c0d5fa2e57646f2cc7dbb9633261af7d20f8a51e	joint global and co-attentive representation learning for image-sentence retrieval		In image-sentence retrieval task, correlated images and sentences involve different levels of semantic relevance. However, existing multi-modal representation learning paradigms fail to capture the meaningful component relation on word and phrase level, while the attention-based methods still suffer from component-level mismatching and huge computation burden. We propose a Joint Global and Co-Attentive Representation learning method (JGCAR) for image-sentence retrieval. We formulate a global representation learning task which utilizes both intra-modal and inter-modal relative similarity to optimize the semantic consistency of the visual/textual component representations. We further develop a co-attention learning procedure to fully exploit different levels of visual-linguistic relations. We design a novel softmax-like bi-directional ranking loss to learn the co-attentive representation for image-sentence similarity computation. It is capable of discovering the correlative components and rectifying inappropriate component-level correlation to produce more accurate sentence-level ranking results. By joint global and co-attentive representation learning, the latter benefits from the former by producing more semantically consistent component representation, and the former also benefits from the latter by back-propagating the contextual information. Image-sentence retrieval is performed as a two-step process in the testing stage, inheriting advantages on both effectiveness and efficiency. Experiments show that JGCAR outperforms existing methods on MSCOCO and Flickr30K image-sentence retrieval tasks.	computation;feature learning;machine learning;modal logic;rectifier;relevance;softmax function	Shuhui Wang;Yangyu Chen;Junbao Zhuo;Qingming Huang;Qi Tian	2018		10.1145/3240508.3240535	natural language processing;computer vision;computation;correlative;phrase;correlation;exploit;ranking;feature learning;computer science;sentence;artificial intelligence	Web+IR	-15.37144457826381	-69.40676834171559	117556
10e696045fac4b8e24f2f28fbf715bc847482c55	feature decay algorithms for fast deployment of accurate statistical machine translation systems	information retrieval;machine translating;artificial intelligence;algorithms;computational linguistics;feature decay algorithms	We use feature decay algorithms (FDA) for fast deployment of accurate statistical machine translation systems taking only about half a day for each translation direction. We develop parallel FDA for solving computational scalability problems caused by the abundance of training data for SMT models and language models and still achieve SMT performance that is on par with using all of the training data or better. Parallel FDA runs separate FDA models on randomized subsets of the training data and combines the instance selections later. Parallel FDA can also be used for selecting the LM corpus based on the training set selected by parallel FDA. The high quality of the selected training data allows us to obtain very accurate translation outputs close to the top performing SMT systems. The relevancy of the selected LM corpus can reach up to 86% reduction in the number of OOV tokens and up to 74% reduction in the perplexity. We perform SMT experiments in all language pairs in the WMT13 translation task and obtain SMT performance close to the top systems using significantly less resources for training and development.	display resolution;experiment;perplexity;randomized algorithm;relevance;scalability;simultaneous multithreading;software deployment;statistical machine translation;test set	Ergun Biçici	2013			natural language processing;computer science;theoretical computer science;computational linguistics;machine learning;data mining	NLP	-18.986179946712724	-77.88019925032964	117626
835e510fcf22b4b9097ef51b8d0bb4e7b806bdfd	unsupervised learning of sequence representations by autoencoders		Sequence data is challenging for machine learning approaches, because the lengths of the sequences may vary between samples. In this paper, we present an unsupervised learning model for sequence data, called the Integrated Sequence Autoencoder (ISA), to learn a fixed-length vectorial representation by minimizing the reconstruction error. Specifically, we propose to integrate two classical mechanisms for sequence reconstruction which takes into account both the global silhouette information and the local temporal dependencies. Furthermore, we propose a stop feature that serves as a temporal stamp to guide the reconstruction process, which results in a higher-quality representation. The learned representation is able to effectively summarize not only the apparent features, but also the underlying and high-level style information. Take for example a speech sequence sample: our ISA model can not only recognize the spoken text (apparent feature), but can also discriminate the speaker who utters the audio (more high-level style). One promising application of the ISA model is that it can be readily used in the semi-supervised learning scenario, in which a large amount of unlabeled data is leveraged to extract high-quality sequence representations and thus to improve the performance of the subsequent supervised learning tasks on limited labeled data.	align (company);autoencoder;basic stamp;high- and low-level;machine learning;noise reduction;semi-supervised learning;semiconductor industry;supervised learning;unsupervised learning	Wenjie Pei;David M. J. Tax	2018	CoRR		silhouette;pattern recognition;autoencoder;machine learning;unsupervised learning;computer science;artificial intelligence	ML	-13.882302520637955	-73.15723984517383	117665
2c9ddd47da2f519bb7f2f5b4a275e7f4af6c2773	"""special issue on """"soft biometrics"""""""		h 0 The focus of this thematic special issue of the Pattern Recogniion Letters is the emerging and challenging topic of “Soft Biometrics”. ubmissions to this special issue are the result of an open call for paers. Some of the articles are extended versions of papers presented t the “1st International Workshop on Soft Biometrics,” which was eld in conjunction with the European Computer Vision Conference ECCV 2014) in Zurich on September 7th 2014 and promoted by the uropean COST Action IC1106 “Integrating Biometrics and Forensics for he Digital Age.” Soft biometrics are human characteristics that provide categorial information about people. They include age, gender, ethnicity, faial hair, whether the person wears glasses, eye and hair color, length f arms and legs, height, weight, skin/hair color, gait and gestures, ccent, ear shape, etc. In contrast to “hard” biometrics, which inlude face, fingerprint, retina, iris, voice etc. and are generally unique nd permanent personal characteristics, soft biometrics provide vague hysical or behavioral information that is not necessarily permanent r distinctive. Such soft biometric traits are generally easy to capture rom a distance and often do not require cooperation from the subects. Whilst they may not provide the means for robust authenticaion, they can be used for improving the verification performance of iometric recognition systems. Research on soft biometrics is still in ts infancy despite the vast potential applications, including access ontrol, human–machine interaction, content based image and video etrieval, person re-identification, etc. We received 34 submissions for this issue. Following thorough reiews, 16 papers were finally selected. The guest editors of this speial issue thank all the authors who submitted their work. We also xtend much gratitude to the reviewers for their efforts during the eview process and to the PRL editorial board who kindly accepted he organization of this special issue and supported us during the reiew and publication processes. The special issue features a review paper entitled “On Soft Bioetrics,” written by experts in soft biometrics research. The article rovides an introduction to the topic and an overview of the history nd achievements in the extraction and use of soft biometrics traits. new definition of the term is also presented: “the estimation or use	coat of arms;computer forensics;european conference on computer vision;fingerprint;human–computer interaction;pattern recognition letters;soft biometrics;vagueness;while	Paulo Lobato Correia;Abdenour Hadid;Thomas B. Moeslund	2015	Pattern Recognition Letters	10.1016/j.patrec.2015.08.005		Vision	-5.3703491181010525	-76.13392090163121	117811
954f90d93a39d2c8e2ff4068c3f47370f16c1bac	shef-lite 2.0: sparse multi-task gaussian processes for translation quality estimation		We describe our systems for the WMT14 Shared Task on Quality Estimation (subtasks 1.1, 1.2 and 1.3). Our submissions use the framework of Multi-task Gaussian Processes, where we combine multiple datasets in a multi-task setting. Due to the large size of our datasets we also experiment with Sparse Gaussian Processes, which aim to speed up training and prediction by providing sensible sparse approximations.	adobe flash lite;approximation;computer multitasking;gaussian process;sparse matrix	Daniel Edward Robert Beck;Kashif Shah;Lucia Specia	2014			computer science;machine learning;sparse approximation;data mining;statistics	ML	-12.685518642128224	-68.16229217228036	118496
a40117bb772c0b1c988a23418212f923ee2b6bd7	a computational theory of the function of clue words in argument understanding	exceptional transmission strategy;argument dialogue;argument understanding;complex form;clue word;computational theory;main conclusion;interpretation rule;coherent transmission;argument structure;special word;computability theory	This paper examines the use of clue words in argument dialogues. These are special words and phrases directly indicating the structure of the argument to the hearer. Two main conclusions are drawn: I) clue words can occur in conjunction with coherent transmissions, to reduce processing of the hearer 2) clue words must occur with more complex forms of transmission, to facilitate recognition of the argument structure. Interpretation rules to process clues are proposed. In addition, a relationship between use of clues and complexity of processing is suggested for the case of exceptional transmission strategies.	coherence (physics);computation	Robin Cohen	1984			theoretical physics;theory of computation;mathematics	NLP	-9.047404480569542	-75.90569006609327	119227
b154c89aa4d3178baa0b1e9f6664f40d3946febe	pied-piping: comparing two recent approaches		Abstract#R##N##R##N#The term ‘pied-piping’ is used by linguists to refer to structures where a movement operation applies to a constituent that is in some sense ‘larger than expected’. More precisely, pied-piping occurs when a movement operation that usually targets expressions of a particular type (e.g. wh-words) instead targets a phrase that contains an expression of that type. Pied-piping structures have long been a deep and difficult puzzle for formal syntactic theory. This is the second of two articles that present and compare two recent approaches to pied-piping, those of Heck (2008, 2009) and Cable (2010a,b). These works offer two very different perspectives on the nature of pied-piping, and thus yield rather different analyses of specific sub-phenomena. Nevertheless, there is much overlap in their general predictions and in several core assumptions. In this article, I compare the empirical predictions of Heck’s and Cable’s accounts, noting especially those areas where both approaches are challenged. The phenomena we will examine include (i) the locality constraints on pied-piping, (ii) Heck’s ‘Edge Generalization’, (iii) the apparent optionality of some pied-piping structures, and (iv) so-called ‘massive pied-piping’.		Seth Cable	2013	Language and Linguistics Compass	10.1111/lnc3.12004	psychology;biology;computer science;artificial intelligence;communication;algorithm	NLP	-9.489787358736164	-75.44958996194539	119270
1ea7039553c23caa82ac97b4159c61be39cb7273	where agreement merges with disagreement: fmri evidence of subject–verb integration	subject–verb agreement;angular gyrus;unagreement;left middle frontal gyrus;fmri	"""Language comprehension is incremental, involving the integration of information from different words together with the need to resolve conflicting cues when unexpected information occurs. The present fMRI design seeks to segregate the neuro-anatomical substrates of these two processes by comparing well-formed and ill-formed sentences during subject-verb agreement computation. Our experiment takes advantage of a particular Spanish feature, the Unagreement phenomenon: a subject-verb agreement mismatch that results in a grammatical sentence (""""Los pintores trajimos…"""" [The painters3.pl (we)brought1.pl…]). Comprehension of this construction implies a shift in the semantic interpretation of the subject from 3rd-person to 1st-person, enabling the phrase """"The painters"""" to be re-interpreted as """"We painters"""". Our results include firstly a functional dissociation between well-formed and ill-formed sentences with Person Mismatches: while Person Mismatches recruited a fronto-parietal network associated to monitoring operations, grammatical sentences (both Unagreement and Default Agreement) recruited a fronto-temporal network related to syntactic-semantic integration. Secondly, there was activation in the posterior part of the left middle frontal gyrus for both Person Mismatches and Unagreement, reflecting the evaluation of the morpho-syntactic match between agreeing constituents. Thirdly, the left angular gyrus showed increased activation only for Unagreement, highlighting its crucial role in the comprehension of semantically complex but non-anomalous constructions. These findings point to a central role of the classic fronto-temporal network, plus two additional nodes: the posterior part of the left middle frontal gyrus and the left angular gyrus; opening new windows to the study of agreement computation and language comprehension."""	angularjs;artificial neural network;computation (action);conflict (psychology);design of experiments;electronic circuit;formal language;fragmented object;frontal lobe gyrus;hl7publishingsubsection <operations>;increment;interactivity;left middle frontal gyrus;list comprehension;microsoft windows;middle frontal gyrus structure;mismatch repair;semantic integration;semantic interpretation;structure of angular gyrus;well-formed petri net;well-formed formula;fmri;sentence	Ileana Quiñones;Nicola Molinaro;Simona Mancini;Juan Andrés Hernández;Manuel Carreiras	2014	NeuroImage	10.1016/j.neuroimage.2013.11.038	psychology;communication;social psychology	NLP	-8.965152439954698	-77.39438599493177	119363
3118942850a75fd91779abb05e593df049544f8c	on the evolution of word usage of classical chinese poetry		The hierarchy of classical Chinese poetry has been broadly acknowledged by a number of studies in Chinese literature. However, quantitative investigations about the evolution of classical Chinese poetry are limited. The primary goal of this study is to provide quantitative evidence of the evolutionary linkages, with emphasis on word usage, among different period genres for classical Chinese poetry. Specifically, various statistical analyses were performed to find and compare the patterns of word usage in the poems of nine period genres, including shi jing, chu ci, Han shi , Jin shi, Tang shi, Song shi, Yuan shi, Ming shi, and Qing shi. The result of analysis indicates that each of nine period genres has unique patterns of word usage, with some Chinese characters being preferably used by the poems of a particular period genre. The analysis on the general pattern of word preference implies a decreasing trend in the use of ancient Chinese characters along the timeline of dynastic types of classical Chinese poetry. The phylogenetic analysis based on the distance matrix suggests that the evolution of different types of classical Chinese poetry is congruent with their chronological order, suggesting that word frequencies contain useful phylogenetic information and thus can be used to infer evolutionary linkages among various types of classical Chinese poetry. The statistical analyses conducted in this study can be applied to the data sets of general Chinese literature. Such analyses can provide quantitative insights about the evolution of general Chinese literature. SUBJECT	distance matrix;evolution;han unification;jing;phylogenetics;stan shih;timeline;word lists by frequency	Liang Liu	2015	CoRR		mathematics;poetry;word usage;hierarchy;timeline;linguistics;chinese characters;classical chinese poetry;chinese literature;word lists by frequency	NLP	-12.665574094801224	-77.94380948660118	119813
d511ffbadaac467828187860247ee01d0190c54d	dual rectified linear units (drelus): a replacement for tanh activation functions in quasi-recurrent neural networks		In this paper, we introduce a novel type of Rectified Linear Unit (ReLU), called a Dual Rectified Linear Unit (DReLU). A DReLU, which comes with an unbounded positive and negative image, can be used as a drop-in replacement for a tanh activation function in the recurrent step of Quasi-Recurrent Neural Networks (QRNNs) (Bradbury et al., 2017). Similar to ReLUs, DReLUs are less prone to the vanishing gradient problem, they are noise robust, and they induce sparse activations. We independently reproduce the QRNN experiments of Bradbury et al. (2017) and compare our DReLU-based QRNNs with the original tanh-based QRNNs and Long Short-Term Memory networks (LSTMs) on sentiment classification and word-level language modeling. Additionally, we evaluate on character-level language modeling, showing that we are able to stack up to eight QRNN layers with DReLUs, thus making it possible to improve the current state-of-the-art in character-level language modeling over shallow architectures based on LSTMs.	activation function;arabic numeral 0;architecture as topic;backpropagation;drop-in replacement;dual;experiment;exponential map (discrete dynamical systems);language model;linear iga bullous dermatosis;long short-term memory;neural networks;perplexity;rectifier (neural networks);recurrent neural network;sparse matrix;stacking;surgical replantation;time complexity;vanishing gradient problem;word lists by frequency;anatomical layer	Fr'ederic Godin;Jonas Degrave;Joni Dambre;Wesley De Neve	2018	Pattern Recognition Letters	10.1016/j.patrec.2018.09.006	mathematics;pattern recognition;artificial intelligence;artificial neural network;hyperbolic function;rectifier (neural networks);vanishing gradient problem;recurrent neural network;language model;activation function	NLP	-17.203277038094395	-75.5741132342999	119943
32e7f0863e7c56cfced89abedaee46e2288bc127	pacrr: a position-aware neural ir model for relevance matching		In order to adopt deep learning for information retrieval, models are needed that can capture all relevant information required to assess the relevance of a document to a given user query. While previous works have successfully captured unigram term matches, how to fully employ position-dependent information such as proximity and term dependencies has been insufficiently explored. In this work, we propose a novel neural IR model named PACRR aiming at better modeling position-dependent interactions between a query and a document. Extensive experiments on six years’ TREC Web Track data confirm that the proposed model yields better results under multiple benchmarks.	deep learning;experiment;information retrieval;interaction;n-gram;relevance	Kai Hui;Andrew Yates;Klaus Berberich;Gerard de Melo	2017			information retrieval;natural language processing;computer science;machine learning;deep learning;artificial intelligence	NLP	-18.333547539928816	-67.66679546515172	120329
e69bb00d24764fd0fad6226f7f7e42c6a923916e	implicit elicitation of attitudinal character in the owa operator				Eun Young Kim;Byeong Seok Ahn	2018	Int. J. Intell. Syst.	10.1002/int.21930		DB	-15.537471693626864	-79.80988271258583	120382
8dbd733060f5ef80b0e140e80d27a2cd0a98eef0	learning and thinking strategy for training sequence generation models		In order to alleviate the exposure bias problem caused by the discrepancy between training and testing strategies, we propose an Inverse Reinforcement Learning (IRL) based learning and thinking strategy for sequence generation. First, a task-agnostic reward is learned to evaluate the appropriateness of the generated tokens at each time step with the knowledge of ground truth token and current RNN models. With this reward, a deep SARSA network is then designed to meditate among the whole space. Therefore, it can fill in the space that has not been exposed during training with a better policy than the original RNN model. Sequence generation experiments on various text corpus show significant improvements over strong baseline and demonstrate the effectiveness of our method.	bleu;baseline (configuration management);discrepancy function;experiment;ground truth;norm (social);random neural network;reinforcement learning;state-action-reward-state-action;text corpus;treebank	Yu Li;Sheng Tang;Min Lin;Junbo Guo;Jintao Li;Shuicheng Yan	2018			artificial intelligence;computer science;pattern recognition;machine learning	NLP	-16.5222516445047	-74.23947654795671	120955
4287831564f99d3e9af102d451a3087c20171490	cnn is all you need		CNNs have been successfully used in audio, image and text classification, analysis and generation [12,17,18], whereas the RNNs with LSTM cells [5,6] have been widely adopted for solving sequence transduction problems such as language modeling and machine translation [19,3,5]. The RNN models typically align the element positions of the input and output sequences to steps in computation time for generating the sequenced hidden states, with each depending on the current element and the previous hidden state. Such operations are inherently sequential which precludes parallelization and becomes the performance bottleneck. This situation has motivated researchers to extend the easily parallelizable CNN models for more efficient sequence-to-sequence mapping. Once such efforts can deliver satisfactory quality, the usage of CNN in deep learning would be significantly broadened.	align (company);computation;deep learning;document classification;input/output;language model;long short-term memory;machine translation;parallel computing;random neural network;time complexity;transduction (machine learning)	Qiming Chen;Ren Wu	2017	CoRR		encoder;bleu;machine learning;convolutional neural network;sequence transformation;computer science;parallelizable manifold;deep learning;recurrent neural network;bottleneck;artificial intelligence	NLP	-17.550193065845214	-75.72186034070039	121067
27e4b65121d3c88643d86dc91a9bdafdf223b988	abstractive text summarization using sequence-to-sequence rnns and beyond		In this work, we model abstractive text summarization using Attentional Encoder-Decoder Recurrent Neural Networks, and show that they achieve state-of-the-art performance on two different corpora. We propose several novel models that address critical problems in summarization that are not adequately modeled by the basic architecture, such as modeling key-words, capturing the hierarchy of sentence-to-word structure, and emitting words that are rare or unseen at training time. Our work shows that many of our proposed models contribute to further improvement in performance. We also propose a new dataset consisting of multi-sentence summaries, and establish performance benchmarks for further research.	automatic summarization;benchmark (computing);network address;pointer (computer programming);thomas j. watson research center;watson (computer)	Ramesh Nallapati;Bowen Zhou;Cícero Nogueira dos Santos;Çaglar Gülçehre;Bing Xiang	2016		10.18653/v1/K16-1028	natural language processing;computer science;artificial intelligence;data science;automatic summarization;machine learning;data mining;world wide web	NLP	-16.657646527607277	-73.50623723587658	121108
ea61405b42ef71add90ee0a54a23667d27cff51a	towards a computational assessment of freewriting quality	freewriting;text quality;natural language processing	This study examines the linguistic features of freewrites and how those features relate to human scores of freewrite quality. Freewriting is a common prewriting strategy that has received little attention by researchers, particularly in terms of the linguistic features of good and poor freewrites. To address this issue, we developed a scoring rubric to assess the qualities of freewrites and how they are correlated with linguistic features. The results showed that many linguistic features positively correlated with human scores (e.g., referential cohesion, syntactic complexity, lexical difficulty), but the only significant predictors in a regression analysis were, number of words and noun overlap. Better freewrites are longer ones with lexical overlap between sentences. While these results fail to conclusively exclude other potentially important features of higher quality freewrites, this study is a first step toward computationally defining freewrite	cohesion (computer science);computation	Jennifer L. Weston;Scott A. Crossley;Danielle S. McNamara	2010			natural language processing;speech recognition;computer science	NLP	-12.047948319684956	-78.95283991046654	121317
7f7f2a84f0fc1393e92fc1a9fc30d92ca034962f	trimming and improving skip-thought vectors		The skip-thought model has been proven to be effective at learning sentence representations and capturing sentence semantics. In this paper, we propose a suite of techniques to trim and improve it. First, we validate a hypothesis that, given a current sentence, inferring the previous and inferring the next sentence provide similar supervision power, therefore only one decoder for predicting the next sentence is preserved in our trimmed skip-thought model. Second, we present a connection layer between encoder and decoder to help the model to generalize better on semantic relatedness tasks. Third, we found that a good word embedding initialization is also essential for learning better sentence representations. We train our model unsupervised on a large corpus with contiguous sentences, and then evaluate the trained model on 7 supervised tasks, which includes semantic relatedness, paraphrase detection, and text classification benchmarks. We empirically show that, our proposed model is a faster, lighter-weight and equally powerful alternative to the original skip-thought model.	document classification;encoder;feature learning;machine learning;nonlinear system;semantic similarity;unsupervised learning;word embedding	Shuai Tang;Hailin Jin;Chen Fang;Zhaowen Wang;Virginia R. de Sa	2017	CoRR		trimming;encoder;word embedding;semantic similarity;initialization;semantics;computer science;artificial intelligence;paraphrase;sentence;pattern recognition	NLP	-18.078861644119048	-73.86934693814052	121371
e6c7171651901605367ba41f6f6cfabb0254102d	learning from exemplars and prototypes in machine learning and psychology.		This paper draws a parallel between similarity-based categorisation models developed in cognitive psychology and the nearest neighbour classifier (1-NN) in machine learning. Conceived as a result of the historical rivalry between prototype theories (abstraction) and exemplar theories (memorisation), recent models of human categorisation seek a compromise in-between. Regarding the stimuli (entities to be categorised) as points in a metric space, machine learning offers a large collection of methods to select a small, representative and discriminative point set. These methods are known under various names: instance selection, data editing, prototype selection, prototype generation or prototype replacement. The nearest neighbour classifier is used with the selected reference set. Such a set can be interpreted as a data-driven categorisation model. We juxtapose the models from the two fields to enable cross-referencing. We believe that both machine learning and cognitive psychology can draw inspiration from the comparison and enrich their repertoire of similarity-based models.		Julian Zubek;Ludmila I. Kuncheva	2018	CoRR		machine learning;repertoire;artificial intelligence;discriminative model;computer science;metric space;rivalry;data editing;classifier (linguistics);compromise;abstraction	AI	-7.433705468767992	-74.97773536056971	121389
1c3862ada9643f9afc18d56447bf3626ce9e3c54	learning perceptual causality from video	causal induction;perceptual causality;information projection	Perceptual causality is the perception of causal relationships from observation. Humans, even as infants, form such models from observation of the world around them [Saxe and Carey 2006]. For a deeper understanding, the computer must make similar models through the analogous form of observation: video. In this article, we provide a framework for the unsupervised learning of this perceptual causal structure from video. Our method takes action and object status detections as input and uses heuristics suggested by cognitive science research to produce the causal links perceived between them. We greedily modify an initial distribution featuring independence between potential causes and effects by adding dependencies that maximize information gain. We compile the learned causal relationships into a Causal And-Or Graph, a probabilistic and-or representation of causality that adds a prior to causality. Validated against human perception, experiments show that our method correctly learns causal relations, attributing status changes of objects to causing actions amid irrelevant actions. Our method outperforms Hellinger’s χ2-statistic by considering hierarchical action selection, and outperforms the treatment effect by discounting coincidental relationships.	action selection;causality;cognitive science;compiler;experiment;greedy algorithm;heuristic;humans;information gain in decision trees;kullback–leibler divergence;relevance;sensor;unsupervised learning;video	Amy Sue Fire;Song-Chun Zhu	2013	ACM TIST	10.1145/2809782	artificial intelligence;machine learning;statistics	AI	-7.513063404719421	-74.1477726002181	121498
61a183000332ff2c9234bd684064bcfc0280d626	gake: graph aware knowledge embedding		Knowledge embedding, which projects triples in a given knowledge base to d-dimensional vectors, has attracted considerable research efforts recently. Most existing approaches treat the given knowledge base as a set of triplets, each of whose representation is then learned separately. However, as a fact, triples are connected and depend on each other. In this paper, we propose a graph aware knowledge embedding method (GAKE), which formulates knowledge base as a directed graph, and learns representations for any vertices or edges by leveraging the graph’s structural information. We introduce three types of graph context for embedding: neighbor context, path context, and edge context, each reflects properties of knowledge from different perspectives. We also design an attention mechanism to learn representative power of different vertices or edges. To validate our method, we conduct several experiments on two tasks. Experimental results suggest that our method outperforms several state-of-art knowledge embedding models.	benchmark (computing);directed graph;entity;experiment;knowledge graph;knowledge base;vertex (geometry);wang and landau algorithm;wikipedia	Jun Feng;Minlie Huang;Yang Yang;Xiaoyan Zhu	2016			natural language processing;artificial intelligence;theoretical computer science;computer science;embedding;graph	AI	-16.22223113161184	-66.45617583839308	121524
8de4d249360f91d9cb6e3799a58fc391e78281c6	roles of interjectory utterances in spoken discourse.		analysis of Japanese interjectory responses in everyday dialogue. Interjectory responses (IRs) in Japanese are utterances such as hai, ee, and un, corresponding roughly to `yes' or `uh-huh' in English. They are typically used in response to yes-no questions and requests or are interjected, as feed-backs, between the interlocutor's utterances to keep the dialogue owing smoothly. Although IRs are among the most frequently used expressions in spoken dialogue, a proper analysis of their semantic/pragmatic contents as well as their exact discourse	smoothing;web feed	Masahito Kawamori;Akira Shimazu;Kiyoshi Kogure	1994			linguistics	NLP	-14.053062681825901	-79.93488457123868	121767
f1195a93b1f100b383ad59113e21b6a4ea2d5335	generating prosodic attitudes in french: data, model and evaluation	perceptual choice;modelizacion;morphologie;prosodic attitudes;syntactic parsing;syntax;phonotactism;prosodic movement expansion;speech synthesis;learning;etude theorique;speech processing;fonotactismo;tratamiento palabra;automatic training;traitement parole;choix perceptif;syntaxe;data model;aprendizaje;modelisation;morphology;apprentissage;prosodic model;phonotactisme;prosodie;gating;estudio teorico;corpus design;actitud;theoretical study;speaker;morfologia;sintaxis;prosody;locutor;perceptual evaluation;modeling;f0 and macrorhythm generation;seleccion perceptual;attitude;gating experiment;locuteur;prosodia	"""The majority of research in the analysis and generation of prosody for use in speech synthesis systems has focused on prosodic features that ease the syntactic parsing of an utterance or highlight certain parts of it. It is well-known that prosody-and especially final lengthening in French – may reflect very fine and complex attributes of the syntactic structure (Gee and Grosjean 1981) and also indicates short and long-term relations between constituents. This paper focuses on the latter property of prosodic signals and proposes an encoding of long-term relations via global contours that should not be confused with local salient events connected by phonological constructs. To demonstrate, we consider here situations involving interaction between speaker and listener where prosodic contrasts are coextensive with the whole message. Numerous descriptive studies (Fónagy 1984; Bolinger 1989) have in fact proposed that speakers use global prosodic patterns to convey their attitude regarding the message and the interlocutor or their emotional state (expressive function). Our aim here is to study prosodic attitudes and to identify and model their prosodic correlates. The reader will find more data on production, analysis and perception of emotional states in Scherer (1996) and recent progress in synthesis is described in Murray, Ar-nott and Rohwer (1996). Following Ohala (1996: 1815), we, however, distinguish attitudes from other fundamental communicative expressions more connected with the physiological state of the signaler: """" (Attitudes are) probably acquired, i.e., learned. Thus they are likely to vary considerably from culture to culture and perhaps even from one individual to another. """" ."""	data model;global optimization;jakobson's functions of language;parsing;semantic prosody;speech synthesis	Yann Morlec;Gérard Bailly;Véronique Aubergé	2001	Speech Communication	10.1016/S0167-6393(00)00065-0	attitude;speech recognition;syntax;morphology;data model;computer science;gating;speech processing;linguistics;prosody;speech synthesis	NLP	-11.45518874455908	-76.68803167655012	121966
e51614b1cbbc7c26b07bc26d2d98b6e2503d0e8e	temporal expressions in speech and gesture		People use spatial metaphors to talk about temporal concepts. They also gesture frequently during speech. The characteristics of these gestures give information regarding the mental timelines people form to experience time. The present study investigates the expression of temporal concepts on a natural setting with Turkish speakers. We found that Turkish speakers used more metaphoric temporal phrases (e.g., short period, time flies quickly) than words referring to time without spatial content (e.g., today, nowadays) in a session where they talked about people’s fortune. Spontaneous gestures were mainly classified as metaphoric and beat gestures and were mostly produced on the sagittal axis, which contradicts with the previous findings. Yet, we also found that people used vertical axis to represent current and future events. These findings suggest that lateral axis may not always be the most common direction for co-speech temporal gesture use, and the pragmatic constraints of the environment may influence the spatial conceptualization of time.	apache axis;conceptualization (information science);lateral thinking;optic axis of a crystal;spontaneous order;temporal expressions;timeline	Idil Bostan;Ahmet Börütecene;Oguzhan Özcan;Tilbe Göksun	2016			cognitive psychology;psychology;expression (mathematics);gesture	HCI	-7.671229376015702	-78.25067316852476	122160
aed717dcb4ffc400b815bfe846ce4e046c989389	exploiting shared information for multi-intent natural language sentence classification		Multi-intent natural language sentence classification aims at identifying multiple user goals in a single natural language sentence (e.g., “find Beyonce’s movie and music” → find movie, find music). The main motivation of this work is to exploit the shared intents across different intent combinations rather than treating the combination as an atomic label. We propose to achieve this by (1) adding class features, and (2) adding hidden variables to identify segments belonging to each intent. Experimental results demonstrate significant gains in classification accuracy over the baseline methods across a number of training conditions (3%-8% absolute on multi-intent sentences, 2%-3% absolute on single intent sentences).	baseline (configuration management);hidden variable theory;natural language	Puyang Xu;Ruhi Sarikaya	2013			natural language processing;pattern recognition;linguistics	NLP	-19.047503012627708	-70.16721061456605	122258
78c0464c33894ce08db9df8d4e49c6c5c64c07cd	the role of iconic gestures in production and comprehension of language: evidence from brain and behavior	brain;gestural interface;cospeech gesture;language processing;semantic processing;interface;motor imagery;conversational agent;production;iconic;behavior;article in monograph or in proceedings;comprehension	Speakers in all cultures and ages use gestures as they speak (i.e., cospeech gestures). There have been different views in the literature with regard to whether and how a specific type of gestures speakers use, i.e., iconic gestures, interacts with language processing. Here I review evidence showing that iconic gestures are not produced merely from the spatial and/or motoric imagery but from an in interface representation of imagistic and linguistic representation during online speaking Similarly, for comprehension, neuroimaging and behavioral studies indicate that speech and gesture influences semantic processing of each other during online comprehension. These findings show overall that processing of information in both modalities interacts during both comprehension and production of language arguing against models that propose independent processing of each modality. They also have implications for AI models that aim to simulate cospeech gesture use in conversational	consciousness;dialog system;ibm notes;list comprehension;modal logic;modality (human–computer interaction);simulation	Asli Özyürek	2009		10.1007/978-3-642-12553-9_1	natural language processing;computer science;linguistics;communication	NLP	-8.3810253790316	-78.93303003346003	122370
ecc5e27148fe2dbfc9caaacee64b53b257e71996	representing covert movements by delimited continuations	covert movement;delimited continuation	In phenomena which have been claimed to require “covert movements” in generative terms, a relevant lexical item seems to require a means to somehow refer to the meaning of its surroundings in order for the meaning of the whole sentence to be properly computed. This has motivated generative/transformational grammars to adopt a movement of the relevant item to the position where its scope contains surroundings that influence its meaning, while it remains as an issue to be solved for categorial/Lambek-style grammars, namely, grammars without movements.	delimited continuation;delimiter	Daisuke Bekki;Kenichi Asai	2009		10.1007/978-3-642-14888-0_16	generative grammar;natural language processing;transformational leadership;delimited continuation;lambda calculus;rule-based machine translation;mathematics;lexical item;covert;artificial intelligence;sentence	PL	-12.470570511790172	-76.72898389717744	122560
535f39b77289c527988149d48e10ff47a4ed9358	optimizing policy via deep reinforcement learning for dialogue management		In this paper, we propose a dialogue manager model based on Deep Reinforcement Learning, which automatically optimizes a dialogue policy. The policy is trained within deep Q-learning algorithm, which efficiently approximates value of actions given a large space of dialogue state. Evaluation processes are conducted by comparing the performance of the proposed model to a rule-based one on the dialogue corpora of DSTC2 and 3 under three different levels of error rate in Spoken Language Understanding. Experimental results prove that given certain level of SLU error, the dialogue manager with self-learned policy shows higher completion rate and the robustness to SLU error. Overcoming the drawbacks of rule-based approach such as limited flexibility and high maintenance cost, our model shows the strength of self-learning algorithm in optimizing policy of dialogue manager without any hand-crafted features.	algorithm;dialog system;logic programming;optimizing compiler;q-learning;reinforcement learning;text corpus	Guanghao Xu;Hyungjung Lee;Myoung-Wan Koo;Jungyun Seo	2018	2018 IEEE International Conference on Big Data and Smart Computing (BigComp)	10.1109/BigComp.2018.00101	robustness (computer science);reinforcement learning;ontology (information science);word error rate;completion rate;spoken language;machine learning;artificial intelligence;computer science	Robotics	-18.784583171635052	-76.40252854235467	122688
3e4dcfbd8595ef2dec4651cf8a837b956874ef45	a neural generative autoencoder for bilingual word embeddings		Bilingual word embeddings (BWEs) have been shown to be useful in various cross-lingual natural language processing tasks. To accurately learn BWEs, previous studies often resort to discriminative approaches which explore semantic proximities between translation equivalents of different languages. Instead, in this paper, we propose a neural generative bilingual autoencoder (NGBAE) which introduces a latent variable to explicitly induce the underlying semantics of bilingual text. In this way, NGBAE is able to obtain better BWEs from more robust bilingual semantics by modeling the semantic distributions of bilingual text. In order to facilitate scalable inference and learning, we utilize deep neural networks to perform the recognition and generation procedures, and then employ stochastic gradient variational Bayes algorithm to optimize them jointly. We validate the proposed model via both extrinsic (cross-lingual document classification and translation probability modeling) and intrinsic (word embedding analysis) evaluations. Experimental results demonstrate the effectiveness of NGBAE on learning BWEs. © 2017 Elsevier Inc. All rights reserved.	algorithm;artificial neural network;autoencoder;deep learning;document classification;gradient;latent variable;microsoft word for mac;natural language processing;scalability;variational principle;word embedding	Jinsong Su;Shan Wu;Biao Zhang;Changxing Wu;Yue Qin;Deyi Xiong	2018	Inf. Sci.	10.1016/j.ins.2017.09.070	machine learning;autoencoder;discriminative model;generative grammar;word embedding;semantics;artificial neural network;inference;artificial intelligence;pattern recognition;latent variable;computer science	AI	-18.663651460279276	-73.57753169537156	123620
6ab3a2e6bcbd8df28a18c5ab3b40463f5c67f9a0	overtensing and the effect of regularity	morphologie;cognitive science;errors;past;activation function;temps grammatical;past tense;verbe;dual mechanism models;production de la parole;tense;error analysis;analyse d erreurs;morphology;anglais;adult;activation functions;passe;language production;speech production;psycholinguistique;psycholinguistics;adulte;verb	Regularly inflected forms often behave differently in language production than irregular forms. These differences are often used to argue that irregular forms are listed in the lexicon but regular forms are produced by rule. Using an experimental speech production task with adults, it is shown that overtensing errors, where a tensed verb is used in place of an infinitive, predominantly involve irregular forms, but that the differences may be due to phonological confounds, not to regularity pe se. Errors involve vowel-changing irregular forms more than suffixing inflected forms, with at best a small difference between regular ed and irregular en. Frequency effects on overtensing errors require a model in which the past-tense and base forms of the verb are in competition and in which activation functions are nonlinear, and rule out models with specialized subnetworks for past-tense forms. Implications for theories of language production are discussed. © 2002 Cognitive Science Society, Inc. All rights reserved.	activation function;cognitive science;lexicon;nonlinear system;theory	Joseph Paul Stemberger	2002	Cognitive Science	10.1207/s15516709cog2606_2	psychology;natural language processing;speech production;morphology;linguistics;psycholinguistics;activation function;communication	NLP	-11.073349720704933	-78.84795304049612	123690
609ba2fbe6458560bd35b90fcfb9366fa4928b17	autosense model for word sense induction		Word sense induction (WSI), or the task of automatically discovering multiple senses or meanings of a word, has three main challenges: domain adaptability, novel sense detection, and sense granularity flexibility. While current latent variable models are known to solve the first two challenges, they are not flexible to different word sense granularities, which differ very much among words, from aardvark with one sense, to play with over 50 senses. Current models either require hyperparameter tuning or nonparametric induction of the number of senses, which we find both to be ineffective. Thus, we aim to eliminate these requirements and solve the sense granularity problem by proposing AutoSense, a latent variable model based on two observations: (1) senses are represented as a distribution over topics, and (2) senses generate pairings between the target word and its neighboring word. These observations alleviate the problem by (a) throwing garbage senses and (b) additionally inducing fine-grained word senses. Results show great improvements over the stateof-the-art models on popular WSI datasets. We also show that AutoSense is able to learn the appropriate sense granularity of a word. Finally, we apply AutoSense to the unsupervised author name disambiguation task where the sense granularity problem is more evident and show that AutoSense is evidently better than competing models. We share our data and code here: https://github.com/rktamplayo/ AutoSense.	aardvark;emoticon;experiment;flaw hypothesis methodology;garbage collection (computer science);latent variable model;performance tuning;requirement;semeval;wafer-scale integration;word sense;word-sense disambiguation;word-sense induction	Reinald Kim Amplayo;Seung-won Hwang;Min Song	2018	CoRR			NLP	-18.309047422294636	-72.42667013232395	123717
d9c1c1033752b0aaf7343a8258eb114eb9f670b1	ri-match: integrating both representations and interactions for deep semantic matching		Existing deep matching methods can be mainly categorized into two kinds, i.e. representation focused methods and interaction focused methods. Representation focused methods usually focus on learning the representation of each sentence, while interaction focused methods typically aim to obtain the representations of different interaction signals. However, both sentence level representations and interaction signals are important for the complex semantic matching tasks. Therefore, in this paper, we propose a new deep learning architecture to combine the merits of both deep matching approaches. Firstly, two kinds of word level matching matrices are constructed based on word identities and word embeddings, to capture both exact and semantic matching signals. Secondly, a sentence level matching matrix is constructed, with each element stands for the interaction between two sentence representations at corresponding positions, generated by a bidirectional long short term memory (Bi-LSTM). In this way, sentence level representations are well captured in the matching process. The above matrices are then fed into a spatial recurrent neural network (RNN), to generate the high level interaction representations. Finally, the matching score is produced by a k-Max pooling and a multilayer perceptron (MLP). Experiments on paraphrasing identification shows that our model outperforms traditional state-of-the art baselines significantly.	interaction;rs-232;semantic matching	Lijuan Chen;Yanyan Lan;Liang Pang;Jiafeng Guo;Jun Xu;Xueqi Cheng	2018		10.1007/978-3-030-03520-4_9	information retrieval;semantic matching;deep learning;architecture;pooling;computer science;recurrent neural network;matrix (mathematics);multilayer perceptron;sentence;artificial intelligence;pattern recognition	Vision	-18.298057629650124	-71.56169181068606	124256
b486fc3ce31f8bfbb28a5f75d0b907b1ce8bd82a	spatial gestures point the way: a broader understanding of the gestural referent		We investigated the use of iconic and deictic gestures during the communication of spatial information. Expert structural geologists were asked to explain one portion of a geologic map. Spatial gestures used in each expert’s response were coded as deictic (indicating an object in the conversational space), iconic (depicting an aspect of an object or event), or both deictic and iconic (indicating an object in the conversational space by depicting an aspect of that object). Speech paired with each gesture was coded for whether or not it referred to complex spatial properties (e.g. shape and orientation of an object). Results indicated that when communicating spatial information, people occasionally use gestures that are both deictic and iconic, and that these gestures tend to occur when complex spatial information is not provided in speech. These results suggest that existing classifications of gesture are not exclusive, especially for spatial discourse.	geographic information system;tag (game)	Kinnari Atit;Ilyse Resnick;Thomas F. Shipley;Carol Ormand;Cathryn Manduca;Tilbe Göksun;Basil Tikoff	2013			cognitive psychology;referent;psychology;social psychology;gesture	HCI	-7.782475843894052	-77.66092245455229	124688
6f11c247df91a81a08e10c83d2b4914dfaf9d40c	question answering and question generation as dual tasks		We study the problem of joint question answering (QA) and question generation (QG) in this paper. Our intuition is that QA and QG have intrinsic connections and these two tasks could improve each other. On one side, the QA model judges whether the generated question of a QG model is relevant to the answer. On the other side, the QG model provides the probability of generating a question given the answer, which is a useful evidence that in turn facilitates QA. In this paper we regard QA and QG as dual tasks. We propose a training framework that trains the models of QA and QG simultaneously, and explicitly leverages their probabilistic correlation to guide the training process of both models. We implement a QG model based on sequence-to-sequence learning, and a QA model based on recurrent neural network. As all the components of the QA and QG models are differentiable, all the parameters involved in these two models could be conventionally learned with back propagation. We conduct experiments on three datasets. Empirical results show that our training framework improves both QA and QG tasks. The improved QA model performs comparably with strong baseline approaches on all three datasets.	artificial neural network;backpropagation;baseline (configuration management);experiment;question answering;recurrent neural network;software propagation;software quality assurance	Duyu Tang;Nan Duan;Tao Qin;Ming Zhou	2017	CoRR		differentiable function;artificial intelligence;machine learning;natural language processing;computer science;question answering;probabilistic logic;backpropagation;recurrent neural network;intuition	NLP	-16.792265115225867	-73.39616219547791	124701
46f639cbe1c4dc5ed851b4ba79c5a3667916903c	learning multiview embeddings of twitter users		Low-dimensional vector representations are widely used as stand-ins for the text of words, sentences, and entire documents. These embeddings are used to identify similar words or make predictions about documents. In this work, we consider embeddings for social media users and demonstrate that these can be used to identify users who behave similarly or to predict attributes of users. In order to capture information from all aspects of a user’s online life, we take a multiview approach, applying a weighted variant of Generalized Canonical Correlation Analysis (GCCA) to a collection of over 100,000 Twitter users. We demonstrate the utility of these multiview embeddings on three downstream tasks: user engagement, friend selection, and demographic attribute prediction.	attribute grammar;computer multitasking;deep learning;display resolution;downstream (software development);generalized canonical correlation;ibm notes;kernel principal component analysis;multiview video coding;nonlinear dimensionality reduction;nonlinear system;scalability;singular value decomposition;social media;social network;word lists by frequency	Adrian Benton;Raman Arora;Mark Dredze	2016			computer science;artificial intelligence;natural language processing;friend selection;machine learning;generalized canonical correlation;social media	NLP	-13.200647275901071	-70.21426424347591	125254
6432594d1b6cab449e29f2038fe15b68d1211d98	tracking the temporal course of counterfactual understanding		This paper explores the dual meaning of counterfactual conditionals, such as ‘if there had been gloves, then there would have been scarves’, by tracking the temporal course to envisage the possibility corresponding to the conjecture ‘there were gloves and there were scarves’ and the presupposed facts, ‘there were no gloves and there were no scarves’. To test this, we used the visual world paradigm, in which counterfactual and indicative conditionals were heard while four images corresponding to the conjecture, such as an image of gloves and scarves, and the presupposed facts, such as an image of no gloves and no scarves, and two distractors were shown on the screen and eye movements were monitored. We found that people looked at the affirmative image in the indicative conditional, and both types of images (affirmative and negative) in the counterfactual conditional. Results support the dual meaning of counterfactuals.	counterfactual conditional;programming paradigm;wired glove	Isabel Orenes;Juan Antonio Garcia-Madruga;Isabel Gómez-Veiga;Orlando Espino;Ruth Byrne	2017			cognitive psychology;counterfactual thinking;psychology;social psychology	Vision	-6.393462789330732	-76.967918296953	125371
916a3a4f88983a9497e58db533823c3c61579c60	processing of cognates in croatian as l1 and german as l2		Cognates are defined as words similar in form and meaning across two languages. Similarity in form may range from full orthographic overlap, as in English film – German Film, to partial overlap, as in English chapel – German Kapelle. Some pairs of cognate words developed historically from a common ancestor word, whereas others emerge when languages come into contact and loan each other words. Language users are typically unaware of such diachronic pressures. When acquiring a second language (L2) they can only perceive shared elements between L1 and L2. Cognates help explain the nature of lexical processing and the manner in which elements from the two languages interact. Different measures have been used to explore cognate processing and representation, including ERP (Midgley et al., 2011; Peeters et al., 2013; Strijkers et al., 2009), latencies in single word (Dijkstra et al., 2010; Lemhöfer and Dijkstra, 2004), and primed lexical decision (De Groot and Nas, 1991), eyemovements (Mulder et al., 2011; Rosselli et al., 2012), and scores on standardized tests (Kelley and Kohnert, 2012; Pérez et al., 2010). Taken together, empirical findings support the claim that cognates are processed differently from noncognate words. Despite the fact that the aforementioned experimental measures and techniques diverge, the conclusion is similar both in language production and in language comprehension (Dijkstra et al., 2010, for an overview). Nevertheless, results do differ with respect to a range of details, including the direction as well as the magnitude of the cognate effect. Specifically, most studies find facilitation in the processing of cognates in L2 (Dijkstra et al., 1999; Lemhöfer and Dijkstra, 2004; Van Hell and De Groot, 2008), but results are less clear when it comes to the effect of cognates in L1. For example, Van Hell and Dijkstra (2002) and Duyck (2005) reported cognates facilitation in the dominant language, while Kroll et al. (2002) reported small cognate inhibition in an L1 naming task, and Caramazza and Brones (1979) failed to find such an effect at all. In the present study we sought to examine the influence of cognates on lexical processing in a visual lexical decision task, using L1/L2 language pairs that belong to different subgroups of IndoEuropean languages: Slavic L1 and Germanic L2. The aim was to carefully replicate recent findings from a study by Radanović, Feldman, and Milin (2014). Crucially, their study showed quite a complex pattern of effects that included a threeway interaction of language (Serbian L1 vs. English L2) by cognate status (cognate vs. noncognate) by word frequency (as a numerical predictor – covariate). Cognates were processed faster than noncognates in L2, but, surprisingly, significantly slower than noncognates in L1. Furthermore, the size of the effect was greater when word frequency was low. Because this pattern of effects differs from what is typically reported in the literature, we designed a replication of the Radanović et al. study and followed their method and design, this time using another contrasting pair of languages: Croatian (L1) and German (L2).	access time;cpu cache;chapel;dijkstra's algorithm;erp;formal language;kerrison predictor;numerical analysis;orthographic projection;replication (computing);self-replicating machine;word lists by frequency	Maja Andel;Jelena Radanovic;Laurie Feldman;Petar Milin	2015			language production;replicate;linguistics;comprehension;slavic languages;cognate;psychology;word lists by frequency;german;lexical decision task	NLP	-10.722488026484847	-79.88311776986608	125538
32fc61eb5cc0567737974877de01c0e468383459	learning discriminative representations for semantic cross media retrieval		Heterogeneous gap among different modalities emerges as one of the critical issues in modern AI problems. Unlike traditional uni-modal cases, where raw features are extracted and directly measured, the heterogeneous nature of cross modal tasks requires the intrinsic semantic representation to be compared in a unified framework. This paper studies the learning of different representations that can be retrieved across different modality contents. A novel approach for mining cross-modal representations is proposed by incorporating explicit linear semantic projecting in Hilbert space. The insight is that the discriminative structures of different modality data can be linearly represented in appropriate high dimension Hilbert spaces, where linear operations can be used to approximate nonlinear decisions in the original spaces. As a result, an efficient linear semantic down mapping is jointly learned for multimodal data, leading to a common space where they can be compared. The mechanism of ”feature up-lifting and down-projecting” works seamlessly as a whole, which accomplishes crossmodal retrieval tasks very well. The proposed method, named as shared discriminative semantic representation learning (SDSRL), is tested on two public multimodal dataset for both withinand intermodal retrieval. The experiments demonstrate that it outperforms several state-of-the-art methods in most scenarios. Aiwen Jiang NICTA, London Circuit 7, ACT, Australia E-mail: Aiwen.Jiang@nicta.com.au Yi Li NICTA, London Circuit 7, ACT, Australia Hanxi Li, Mingwen Wang Jiangxi Normal University, China	approximation algorithm;computation;experiment;feature learning;hilbert space;lambda lifting;machine learning;maxima and minima;modal logic;modality (human–computer interaction);multimodal interaction;newton;nonlinear system;quadratic function;randomness;unified framework	Aiwen Jiang;Hanxi Li;Yi Li;Mingwen Wang	2015	CoRR		natural language processing;computer vision;computer science;machine learning	AI	-14.029507212953268	-68.22473015041955	125872
d5bd615d39d663f8205d5de02f5b01e1d05b61bc	a neural words encoding model	encoding neurons training training data decoding biological neural networks data models;data compression neural word encoding model learning algorithm decryption word based compression deep belief networks multilayer restricted boltzmann machines word set reconstruction code layer representation code english words american national corpus neural words encoding model text encryption;text analysis belief networks boltzmann machines cryptography data compression learning artificial intelligence	This paper proposes a neural network model and learning algorithm that can be applied to encode words. The model realizes the function of words encoding and decoding which can be applied to text encryption/decryption and word-based compression. The model is based on Deep Belief Networks (DBNs) and it differs from traditional DBNs in that it is asymmetric structured and the output of it is a binary vector. With pre-training of multi-layer Restricted Boltzmann Machines (RBMs) and fine-tuning to reconstruct word set, the output of code layer can be used as a kind of representation code of words. We can change the number of neurons of code layer to control the length of representation code for different applications. This paper reports on experiments using English words of American National Corpus to train a neural words encoding model which can be used to encode/decode English words, realizing text encryption and data compression.	algorithm;american national corpus;artificial neural network;bayesian network;bit array;code;data compression;encode;encryption;experiment;layer (electronics);natural language;network model;neuron;nonlinear system;restricted boltzmann machine	Dayiheng Liu;Jian Cheng Lv;Xiaofeng Qi;Jiangshu Wei	2016	2016 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2016.7727245	natural language processing;speech recognition;types of artificial neural networks;computer science;machine learning;deep learning;incremental encoding	NLP	-17.33458129567137	-74.95342806258355	126185
7d988676871fc3c248029beb37079085c3fb8587	improving frame semantic parsing with hierarchical dialogue encoders		Conversational Language Understanding (CLU) is a key component of goal oriented dialogue systems that would parse user utterances into semantic frame representations. Traditionally CLU does not utilize the dialogue history beyond the previous system turn and contextual ambiguities are resolved by the downstream components. In this paper, we explore novel approaches for modeling dialogue context in a recurrent neural network (RNN) based language understanding system. We propose the Hierarchical Dialogue Encoder Network, that allows encoding context from the dialogue history in chronological order. We compare the performance of our proposed architecture with two context models, one that uses just the previous turn context and another that encodes dialogue context in a memory network, but loses the order of utterances in the dialogue history. Experiments with a multi-domain dialogue dataset demonstrate that the proposed architecture results in reduced semantic frame error rates.	artificial neural network;clu;dialog system;downstream (software development);encoder;frame language;natural language understanding;parsing;random neural network;recurrent neural network	Ankur Bapna;Gökhan Tür;Dilek Z. Hakkani-Tür;Larry P. Heck	2017	CoRR		natural language processing;speech recognition;computer science;artificial intelligence;machine learning;linguistics;programming language	NLP	-17.449781345959202	-74.41146858692682	126213
94391c63c86248f679d792f30c2d2496c5a98dcc	source models for natural language text	modelizacion;lenguaje natural;linguistique;analisis estadistico;langage naturel;tratamiento lenguaje;modelisation;modelo;linguistica;statistical analysis;language processing;natural language;analyse statistique;traitement langage;loi zipf;modele;theorie information;modeling;models;information theory;teoria informacion;linguistics	A model of a natural language text is a collection of information that approximates the statistics and structure of the text being modeled. The purpose of the model may be to give insight into rules which govern how language is generated, or to predict properties of future samples of it. This paper studies models of natural language from three different, but related, viewpoints. First, we examine the statistical regularities that are found empirically, based on the natural units of words and letters. Second, we study theoretical models of language, including simple random generative models of letters and words whose output, like genuine natural language, obeys Zipf's law. Innovation in text is also considered by modeling the appearance of previously unseen words as a Poisson process. Finally, we review experiments that estimate the information content inherent in natural text.	natural language	Ian H. Witten;Timothy C. Bell	1990	International Journal of Man-Machine Studies	10.1016/S0020-7373(05)80033-1	n-gram;natural language processing;language identification;cache language model;text simplification;speech recognition;systems modeling;information theory;computer science;linguistics;natural language;language model	DB	-12.328273385731443	-75.21941156052057	126708
a9bdfb74f32b385c33888c2f43572d30604558bc	multilevel heuristics for rationale-based entity relation classification in sentences		Rationale-based models provide a unique way to provide justifiable results for relation classification models by identifying rationales (key words and phrases that a person can use to justify the relation in the sentence) during the process. However, existing generative networks used to extract rationales come with a trade-off between extracting diversified rationales and achieving good classification results. In this paper, we propose a multilevel heuristic approach to regulate rationale extraction to avoid extracting monotonous rationales without compromising classification performance. In our model, rationale selection is regularized by a semi-supervised process and features from different levels: word, syntax, sentence, and corpus. We evaluate our approach on the SemEval 2010 dataset that includes 19 relation classes and the quality of extracted rationales with our manually-labeled rationales. Experiments show a significant improvement in classification performance and a 20% gain in rationale interpretability compared to state-of-theart approaches.	design rationale;experiment;heart rate variability;heuristic (computer science);semeval;semi-supervised learning;semiconductor industry;test set;text corpus	Shiou Tian Hsu;Mandar S. Chaudhary;Nagiza F. Samatova	2018			computer science;natural language processing;artificial intelligence;heuristics	NLP	-19.103370504134286	-68.89664168551373	127031
2633fe61583a79ded19348516467971ce3aeb20a	a bayesian approach to key-finding	bayes estimation;modelizacion;bayesian approach;pitch acoustics;music cognition;acoustique musicale;intelligence artificielle;tonie;tonality;musical acoustics;modelisation;probabilistic model;estimacion bayes;tonalite;acustica musical;altura sonida;cognition;cognicion;artificial intelligence;inteligencia artificial;modeling;estimation bayes	The key-profile model (originally proposed by Krumhansl and Schmuckler, and modified by Temperley) has proven to be a highly successful approach to key-finding. It appears that the key-profile model can be reinterpreted, with a few small modifications, as a Bayesian probabilistic model. This move sheds interesting light on a number of issues, including the psychological motivation for the key-profile model, other aspects of musical cognition such as metrical analysis, and issues such as ambiguity and expectation.	cognition;statistical model	David Temperley	2002		10.1007/3-540-45722-4_18	statistical model;speech recognition;systems modeling;cognition;acoustics;music psychology;bayesian probability;computer science;artificial intelligence;machine learning;musical acoustics;statistics	ML	-12.192983651279341	-75.1980803542378	127309
5df3e730bf7896c23d59a0e8a97f697f2e8f3ae5	expectation-based sentence comprehension in korean: evidence from behavioral and neurological studies	brain localization;fmri;individual differences;working memory capacity;human sentence processing;korean;expectation	The goal of this study was to provide meaningful insights in the algorithms of statistical and computational modeling in natural language processing, by emphasizing the role of expectation in human language comprehension. To obtain the evidence for expectation-based sentence comprehension in Korean, we revisited Lee's study [1, 2] in which the processing of Korean relative-clause sentences was tested. In Study 1, using Lee's materials, we conducted gated cloze tasks by which the conditional probability of a target constituent was computed at each point in a way that a word was incrementally added to a sentence fragment. Then, the patterns of the computed conditional probabilities of target constituents were compared to those of the reading times of target constituents that Lee had observed. In Study 2, we examined whether the patterns of the expectation-based sentence processing that we observed in Study 1 was modulated by readers' working memory capacity. Finally, in Study 3, an fMRI study was conducted to explore the locus of expectation-based sentence processing in brain. We found that the patterns of conditional probabilities were mapped to those of behavioral reading times, but we did not observe individual differences in expectation-based comprehension. We also obtained neurological results suggesting that the Broca area is the locus for the processing of the expected syntactic information. Taken together, our behavioral and neurological findings provided evidence supporting expectation-based sentence comprehension in Korean.	algorithm;central processing unit;gated community;locus;list comprehension;machine code;machine translation;modulation;natural language processing	Hongoak Yun;Yunju Nam;Byeong-Taek Lee	2014		10.1145/2557977.2558027	differential psychology;natural language processing;speech recognition;korean;statistics	NLP	-9.620583495664725	-77.68297993295302	127542
af41a88119bccd08b83aabfff957fe81cb69ca38	deep multimodal features for movie genre and interestingness prediction		In this paper, we propose a multimodal framework for video segment interestingness prediction based on the genre and affective impact of movie content. We hypothesize that the emotional characteristic and impact of a video infer its genre, which can in turn be a factor for identifying the perceived interestingness of a particular video segment (shot) within the entire media. Our proposed approach is based on audio-visual deep features for perceptual content analysis. The multimodal content is quantified in a mid-level representation which consists in describing each audio-visual segment as a distribution over various genres (action, drama, horror, romance, sci-fi for now). Some segment might be more characteristic of a media and therefore be more interesting than a segment containing content with a neutral genre. Having determined the genre of individual video segments, we trained a classifier to produce an interestingness factor which is then used to rank segments. We evaluate our approach on the MediaEval2017 Media Interestingness Prediction Task Dataset (PMIT). We demonstrate that our approach outperforms the existing video interestingness approaches on the PMIT dataset in terms of Mean Average Precision.	flickr;high- and low-level;information retrieval;multimodal interaction;statistical classification	Olfa Ben Ahmed;Benoit Huet	2018	2018 International Conference on Content-Based Multimedia Indexing (CBMI)	10.1109/CBMI.2018.8516504	support vector machine;task analysis;visualization;feature extraction;artificial intelligence;mel-frequency cepstrum;pattern recognition;content analysis;computer science;film genre	Web+IR	-12.175715902010623	-70.17783155160672	127571
81158dce7942cf17bab2160a7cd6a0079c744a3d	left fronto-temporal dynamics during agreement processing: evidence for feature-specific computations	fronto temporal network grammatical agreement language meg reading;reading;grammatical agreement;fronto temporal network;meg;language	Grammatical agreement is a widespread language phenomenon that indicates formal syntactic relations between words; however, it also conveys basic lexical (e.g. grammatical gender) or semantic (e.g. numerosity) information about a discourse referent. In this study, we focus on the reading of Spanish noun phrases, violating either number or gender determiner-noun agreement compared to grammatical controls. Magnetoencephalographic activity time-locked to the onset of the noun in both types of violation revealed a left-lateralized brain network involving anterior temporal regions (~220 ms) and, later in time, ventro-lateral prefrontal regions (>300 ms). These activations coexist with dependency-specific effects: in an initial step (~170 ms), occipito-temporal regions are employed for fine-grained analysis of the number marking (in Spanish, presence or absence of the suffix '-s'), while anterior temporal regions show increased activation for gender mismatches compared to grammatical controls. The semantic relevance of number agreement dependencies was mainly reflected by left superior temporal increased activity around 340 ms. These findings offer a detailed perspective on the multi-level analyses involved in the initial computation of agreement dependencies, and theoretically support a derivational approach to agreement computation.	coexist (image);computation (action);item unique identification;lateral thinking;magnetoencephalography;numerous;onset (audio);phrases;relevance;temporal lobe;emotional dependency	Nicola Molinaro;Horacio A. Barber;Alejandro Pérez Fernández;Lauri Parkkonen;Manuel Carreiras	2013	NeuroImage	10.1016/j.neuroimage.2013.04.025	psychology;natural language processing;computer science;language;communication;reading	NLP	-9.905010959153504	-78.6452146953779	127627
e31472c219515dc3908376ede9d9b31725e801e5	formal distinctiveness of high- and low-imageability nouns: analyses and theoretical implications	nouns;representation cognitive;representation;vocabulaire;schemata cognition;noun;morphology languages;vocabulary;semantics;cognitive representation;concreteness;sound symbolism;speech perception;word order;language acquisition;phonology;vocabulary development;perception de la parole;acquisition du langage;reconnaissance de la parole;imageability;distinctive features language;etymology;pattern recognition;speech recognition;phonetic symbolism;psycholinguistique;psycholinguistics;word processing;symbolisme phonique	Words associated with perceptually salient, highly imageable concepts are learned earlier in life, more accurately recalled, and more rapidly named than abstract words (R. W. Brown, 1976; Walker & Hulme, 1999). Theories accounting for this concreteness effect have focused exclusively on semantic properties of word referents. A novel possibility is that word structure may also contribute to the effect. We report a corpus-based analysis of the phonological and morphological structures of a large set of nouns with imageability ratings (N = 2,023). High- and low-imageability nouns differed by length, etymology, prosody, affixation, phonological neighborhood density, and rates of consonant clustering. On average, nouns denoting abstract concepts were longer, more derivationally complex, and emerged in English from a different distribution of languages than did concrete nouns. We address implications for interactivity of word form and meaning as pertain to theories of word concreteness, lexical acquisition, and word processing.	amiga walker;body of uterus;cluster analysis;corpus linguistics;interactivity;knowledge acquisition;languages;microsoft word for mac;name;semantic prosody;text corpus;theory;walkers;statistical cluster	Jamie Reilly;Jacob Kean	2007	Cognitive science	10.1080/03640210709336988	psychology;natural language processing;noun;etymology;semantics;linguistics;psycholinguistics;communication;phonology	NLP	-11.852389830614712	-79.64081739674398	127662
53879ef15f897ccc91b0b7dc8ca5f837552a2178	pre-processing in sentence comprehension: sensitivity to likely upcoming meaning and structure		"""For more than a decade, views of sentence comprehension have been shifting toward wider acceptance of a role for linguistic pre-processing-that is, anticipation, expectancy, (neural) pre-activation, or prediction-of upcoming semantic content and syntactic structure. In this survey, we begin by examining the implications of each of these """"brands"""" of predictive comprehension, including the issue of potential costs and consequences to not encountering highly constrained sentence input. We then describe a number of studies (many using online methodologies) that provide results consistent with prospective sensitivity to various grains and levels of semantic and syntactic information, acknowledging that such pre-processing is likely to occur in other linguistic and extralinguistic domains, as well. This review of anticipatory findings also includes some discussion on the relationship of priming to prediction. We conclude with a brief examination of some possible limits to prediction, and with a suggestion for future work to probe whether and how various strands of prediction may integrate during real-time comprehension."""	linguistics;list comprehension;preprocessor;priming exercise;prospective search;real-time transcription;sentence extraction	Katherine A. DeLong;Melissa Troyer;Marta Kutas	2014	Language and linguistics compass	10.1111/lnc3.12093	natural language processing;computer science;linguistics;communication;social psychology	NLP	-11.729799481506749	-77.27041594449861	128104
de9fae3dc5133c1b926f7c50588d084f43271802	learning from speaker word choice by assuming adjectives are informative	social and behavioral sciences	Pragmatic abilities are not only a component of efficient communication; they can also be an important learning mechanism for young children. We discuss four experiments and a corpus analysis to investigate whether children and adults can infer information about a speaker’s knowledge based on the choice of an adjective. In Experiments 1 – 3, we found that adults are sensitive to adjective use as an indicator of intended contrast dimension (e.g. that people say “red” if an object could have been blue, but “tall” if it could have been short). In Experiment 4, we found developmental differences between older and younger 4-year-olds: older children were above chance at selecting the referential dimension of interest, while younger children exhibited some contrast inference but a strong color bias. This suggests that by preschool, children are beginning to make inferences from a speaker’s word choices, but that there are differences between adjective types. We conducted an exploratory corpus analysis to investigate possible causes for this developmental difference.	experiment;information	Alexandra Horowitz;Michael C. Frank	2012			psychology;cognitive psychology;speech recognition;linguistics;communication;social psychology;cognitive science	HCI	-8.17499948770977	-76.90074109370974	128165
0a73a15bf53da196363058196961cd21bc262e8f	context2vec: learning generic context embedding with bidirectional lstm		Context representations are central to various NLP tasks, such as word sense disambiguation, named entity recognition, coreference resolution, and many more. In this work we present a neural model for efficiently learning a generic context embedding function from large corpora, using bidirectional LSTM. With a very simple application of our context representations, we manage to surpass or nearly reach state-of-the-art results on sentence completion, lexical substitution and word sense disambiguation tasks, while substantially outperforming the popular context representation of averaged word embeddings. We release our code and pretrained models, suggesting they could be useful in a wide variety of NLP tasks.	display resolution;lexical substitution;long short-term memory;named-entity recognition;natural language processing;semi-supervised learning;text corpus;word sense;word-sense disambiguation	Oren Melamud;Jacob Goldberger;Ido Dagan	2016			artificial intelligence;computer science;machine learning;natural language processing;embedding	NLP	-19.073396232135106	-74.0429462798739	128219
f11b0aec9dba441d80af3884b2d79e6d7a35e9a3	actor and observer: joint modeling of first and third-person videos		Several theories in cognitive neuroscience suggest that when people interact with the world, or simulate interactions, they do so from a first-person egocentric perspective, and seamlessly transfer knowledge between third-person (observer) and first-person (actor). Despite this, learning such models for human action recognition has not been well studied. We address this challenge by introducing Charades-Ego, a large-scale dataset of paired first-person and third-person videos, and presenting a formulation to learn a joint representation of actions from these two perspectives. This talk will present this dataset and our actor-observer model.		Gunnar A. Sigurdsson;Abhinav Gupta;Cordelia Schmid;Ali Farhadi;Karteek Alahari	2018	2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition	10.1145/3265987.3265995	task analysis;computer vision;observer (quantum physics);artificial intelligence;human–computer interaction;computer science;data modeling;cognitive neuroscience	Vision	-10.953948136753064	-69.89267818052652	128388
1f2fa48db761ec4273f67bec96f47516b2b03496	just.ask, a qa system that learns to answer new questions from previous interactions		We present JUST.ASK, a publicly available Question Answering system. Its architecture is composed of the usual Question Processing, Passage Retrieval and Answer Extraction components. Several details on the information generated and manipulated by each of these components are also provided to the user when interacting with the demonstration. Since JUST.ASK also learns to answer new questions based on users’ feedback, (s)he is invited to identify the correct answers. These will then be used to retrieve answers to future questions.	interaction;question answering	Sérgio Curto;Ana Cristina Mendes;Pedro Curto;Luísa Coheur;Ângela Costa	2014			ask price;natural language processing;architecture;computer science;artificial intelligence;question answering	NLP	-14.51207674969417	-67.38641481646677	129363
95797bc972450f92619fbda7bfb0398662f9973f	entity disambiguation by knowledge and text jointly embedding		For most entity disambiguation systems, the secret recipes are feature representations for mentions and entities, most of which are based on Bag-of-Words (BoW) representations. Commonly, BoW has several drawbacks: (1) It ignores the intrinsic meaning of words/entities; (2) It often results in high-dimension vector spaces and expensive computation; (3) For different applications, methods of designing handcrafted representations may be quite different, lacking of a general guideline. In this paper, we propose a different approach named EDKate. We first learn low-dimensional continuous vector representations for entities and words by jointly embedding knowledge base and text in the same vector space. Then we utilize these embeddings to design simple but effective features and build a two-layer disambiguation model. Extensive experiments on real-world data sets show that (1) The embedding-based features are very effective. Even a single one embedding-based feature can beat the combination of several BoW-based features. (2) The superiority is even more promising in a difficult set where the mention-entity prior cannot work well. (3) The proposed embedding method is much better than trivial implementations of some off-the-shelf embedding algorithms. (4) We compared our EDKate with existing methods/systems and the results are also positive.	algorithm;bag-of-words model in computer vision;computation;entity;experiment;knowledge base;word-sense disambiguation	Wei Fang;Jianwen Zhang;Dilin Wang;Zheng Chen;Ming Li	2016			artificial intelligence;computer science;natural language processing;machine learning;entity linking;embedding	NLP	-17.259834278171397	-66.97473985322625	129415
c98fda533cffd6d5be80e590aca3677057397673	matching resumes to jobs via deep siamese network		In this paper we investigate the important and challenging task of recommending appropriate jobs for job seeking candidates by matching semi structured resumes of candidates to job descriptions. To perform this task, we propose to use a siamese adaptation of convolutional neural network. The proposed approach effectively captures the underlying semantics thus enabling to project similar resumes and job descriptions closer to each other, and make dissimilar resumes and job descriptions distant from each other in the semantic space. Our experimental results on a set of 1314 resumes and a set of 3809 job descriptions (5,005,026 resume-job description pairs) demonstrate that our approach is better than the current state-of-the-art approaches.		Saket Maheshwary;Hemant Misra	2018		10.1145/3184558.3186942	convolutional neural network;semantics;machine learning;deep learning;computer science;artificial intelligence	Vision	-16.938782932240283	-66.50964900933276	129417
aff3785d00a49c39c06ebb34557de3d5fcbaa531	sequence-to-sequence models for cache transition systems		In this paper, we present a sequenceto-sequence based approach for mapping natural language sentences to AMR semantic graphs. We transform the sequence to graph mapping problem to a word sequence to transition action sequence problem using a special transition system called a cache transition system. To address the sparsity issue of neural AMR parsing, we feed feature embeddings from the transition state to provide relevant local information for each decoder state. We present a monotonic hard attention model for the transition framework to handle the strictly left-to-right alignment between each transition state and the current buffer input focus. We evaluate our neural transition model on the AMR parsing task, and our parser outperforms other sequence-to-sequence approaches and achieves competitive results in comparison with the best-performing models.1	adaptive multi-rate audio codec;buffer amplifier;focus (computing);natural language;parsing;sparse matrix;transition system	Giorgio Satta;Daniel Gildea;Linfeng Song;Xiaochang Peng	2018			computer science;artificial intelligence;machine learning;theoretical computer science;cache	NLP	-17.74842631679529	-74.56102753905205	130193
3819e8962bbef157d2c3ec6c30aba6a7b856a3c0	the effect of pre-exposure on family resemblance categorization for stimuli of varying levels of perceptual difficulty	conference contribution	This study investigated the effect that pre-exposure to a set of stimuli has on the prevalence of family resemblance categorization. 64 participants were tested to examine the effect that pre-exposure type (same-stimuli vs unrelated-stimuli) and the perceptual difficulty of the stimuli (perceptually similar vs perceptually different) has on categorization strategy. There was a significant effect of perceptual difficulty, indicating that perceptually different stimuli evoked a higher level of family resemblance sorting than perceptually similar stimuli. There was no significant main effect of pre-exposure type; however, there was a significant interaction between pre-exposure type and level of perceptual difficulty. Post-hoc tests revealed that this interaction was the result of an increase in family resemblance sorting for the perceptually different stimuli under relevant preexposure but no such effect for perceptually similar stimuli. The theoretical implications of these findings are discussed.	categorization;hoc (programming language);sorting	Fraser Milton;Edward Copestake;David Satherley;Tobias Stevens;Andy J. Wills	2014			psychology;cognitive psychology;communication;social psychology	HCI	-6.57667155564547	-78.07917188226253	130444
8134db1fbc8b5bc6f9e7ea49c1e1564c9da2a82b	unified neural architecture for drug, disease and clinical entity recognition		Most existing methods for biomedical entity recognition task rely on explicit feature engineering where many features either are specific to a particular task or depends on output of other existing NLP tools. Neural architectures have been shown across various domains that efforts for explicit feature design can be reduced. In this work we propose an unified framework using bi-directional long short term memory network (BLSTM) for named entity recognition (NER) tasks in biomedical and clinical domains. Three important characteristics of the framework are as follows (1) model learns contextual as well as morphological features using two different BLSTM in hierarchy, (2) model uses first order linear conditional random field (CRF) in its output layer in cascade of BLSTM to infer label or tag sequence, (3) model does not use any domain specific features or dictionary, i.e., in another words, same set of features are used in the three NER tasks, namely, disease name recognition (Disease NER), drug name recognition (Drug NER) and clinical entity recognition (Clinical NER). We compare performance of the proposed model with existing state-of-the-art models on the standard benchmark datasets of the three tasks. We show empirically that the proposed framework outperforms all existing models. Further our analysis of CRF layer and word-embedding obtained using character based embedding show their importance.	benchmark (computing);conditional random field;dictionary;feature engineering;long short-term memory;named-entity recognition;natural language processing;tag cloud;unified framework;unified model;word lens;word embedding	Sunil Kumar Sahu;Ashish Anand	2017	CoRR		natural language processing;artificial intelligence;machine learning;computer science;long short term memory;hierarchy;architecture;drug-disease;conditional random field;feature engineering;embedding;named-entity recognition	NLP	-18.589069191642302	-72.77408623485883	131049
2d004e28721f32f3a7c1e35c9da443311af0757b	learning non-linear features for machine translation using gradient boosting machines		In this paper we show how to automatically induce non-linear features for machine translation. The new features are selected to approximately maximize a BLEU-related objective and decompose on the level of local phrases, which guarantees that the asymptotic complexity of machine translation decoding does not increase. We achieve this by applying gradient boosting machines (Friedman, 2000) to learn new weak learners (features) in the form of regression trees, using a differentiable loss function related to BLEU. Our results indicate that small gains in performance can be achieved using this method but we do not see the dramatic gains observed using feature induction for other important machine learning tasks.	bleu;computational complexity theory;decision tree;gradient boosting;loss function;machine learning;machine translation;nonlinear system	Kristina Toutanova;Byung-Gyu Ahn	2013			speech recognition;computer science;machine learning;pattern recognition;gradient boosting	ML	-17.83912158818246	-77.04315597567135	131170
b12225ed094978034e31c0fddef846dcb1c58325	a novel analysis of temporal frame-adverbials	paper interpretation principle;multiple scale;temporal frame-adverbials;novel analysis;temporal hierarchy;swedish temporal expression;complex frame-adverbial expression	In this paper interpretation principles for simple and complex frame-adverbial expressions are presented. Central to these principles is a distinction between p h a s e s and p e r i o d s together with the t e m p o r a l h i e rarchy , where multiple scales of time and relations can be expressed. A system, CLOCKWISE, has been implemented which interprets Swedish temporal expressions according to the principles outlined in the paper. I n t r o d u c t i o n Temporal information is expressed and conveyed in a number of ways in natural language including tense, aspect and lexical items that carry temporal information, eg. temporal adverbs. Most researchers in this field approach temporal entities in language from the perspective of tense and aspect. But there is very little in the literature on other expressions that hold temporal information, such as temporal adverbs, certain prepositional phrases and noun phrases. In most papers the meaning of a temporal adverbial such as 'next year' is merely explained as the predicate 'next year' which specifies a point or interval of time from a reference time. In objective time-modelling systems such as /Kahn & Gorry 1977/and/Bruce 1973/ temporal expressions were never analyzed in their linguistic form; instead they had to be typed in as stereotyped lists. The internal structure of temporal expressions must be investigated in order to construct grammars that can capture general features and be of use in computational applications. In the paper I will focus on temporal frame-adverbial phrases, that is, expressions that refer to a temporal period in which events are located (Cf /Bennet& Partee 1978/,/Hinrichs 1986/). I will not discuss the complex question of how tense, aspect and temporal adverbials interact (for an outline of the problems see/Ejerhed 1987D. TemPoral frame.adverbial phrases A large group of temporal expressions can be classified as frame-adverbial phrases. /Smith 1981/ categorizes temporal frame-adverbial phrases in the following way1: Deictic Clock-Calendar 2 Dependent last week, yesterday at midnight = now, this moment + next week, tomorrow + at midnight previously, before = the same time + later, afterwards 1 My use of + and is the same as Smith's forward and backward arrows. 2 In an earlier paper (Smith 1980) Smith calls this class flexible anchoring adverbials. This classification is based on the concept of anchoring, ie. a deictic is generally anchored to the time of speech (ST), a dependent is anchored to another given time in the context, and a clock calendar adverbial can anchor to either ST or to some other context-dependent time. Smith attributes a relational value to these expressions, -, = and +. These symbols stand in turn for the relational value a n t e r i o r i t y (past), s i m u l t a n e i t y (present) and p o s t e r i o r i t y (future). Frame-adverbials can syntactically occur as adverbs, noun phrases and prepositional phrases. They can be complex expressions such as (1) On Monday next week at 6 pro. where temporal information is specified on several levels and we have a combination of deictic and clock calendar expreso sions, Complex expressions have a relatively loose syntax in that the time denoted in (1) can be expressed as (2) and (3) (2) Next week on Monday at 6 pm. (3) At 6 pm next week on Monday. The issues that need considering are the following: How is the semantic well-formedness of frame-adverbial phrases determined and, if possible, what is needed to establish their temporal reference in terms of locations on the time axis.	apache axis;computation;context-sensitive language;entity;frame language;natural language;temporal expressions	Magnus Merkel	1988			computer science	Vision	-8.6263226327071	-75.1423701424912	131572
c68ec24e2f97c6875cd006a9fa2f0fbe934e4ae0	bidirectional long short-term memory networks for relation classification		Relation classification is an important semantic processing, which has achieved great attention in recent years. The main challenge is the fact that important information can appear at any position in the sentence. Therefore, we propose bidirectional long short-term memory networks (BLSTM) to model the sentence with complete, sequential information about all words. At the same time, we also use features derived from the lexical resources such as WordNet or NLP systems such as dependency parser and named entity recognizers (NER). The experimental results on SemEval-2010 show that BLSTMbased method only with word embeddings as input features is sufficient to achieve state-of-the-art performance, and importing more features could further improve the performance.	finite-state machine;long short-term memory;named entity;natural language processing;word embedding;wordnet	Shu Zhang;Dequan Zheng;Xinchen Hu;Ming Yang	2015			natural language processing;computer science;pattern recognition;information retrieval	NLP	-18.84492901289631	-72.2102160307575	131844
a7af40bc5fc5e2fcb6cb7c4624989e17f189a74c	acquiring word learning biases		Previous research has shown that infants can acquire a “shape bias” in word learning when presented with labels that are perfectly correlated with object shape. However, little research examines whether children can acquire a non-shape word learning bias. Research on inducing this bias can help inform the origins of the shape bias. In our experiment, 3 year-old children successfully acquired a new bias even with relatively few objects and a short training session, illustrating the relevance of the overhypothesis formation account in explaining the acquisition of early inductive constraints.	inductive bias;relevance	Zi Lin Sim;Sylvia Yuan;Fei Xu	2011			social psychology;cognitive psychology;connectionism;perception;property (programming);noun;first language;psychology;referent;learning environment;local language	ML	-8.279018226551713	-76.6296178432388	132145
04556d5f283d7f90e24d43371d3f51faff8c0423	temporal attention-gated model for robust sequence classification		Typical techniques for sequence classification are designed for well-segmented sequences which have been edited to remove noisy or irrelevant parts. Therefore, such methods cannot be easily applied on noisy sequences expected in real-world applications. In this paper, we present the Temporal Attention-Gated Model (TAGM) which integrates ideas from attention models and gated recurrent networks to better deal with noisy or unsegmented sequences. Specifically, we extend the concept of attention model to measure the relevance of each observation (time step) of a sequence. We then use a novel gated recurrent network to learn the hidden representation for the final prediction. An important advantage of our approach is interpretability since the temporal attention weights provide a meaningful value for the salience of each time step in the sequence. We demonstrate the merits of our TAGM approach, both for prediction accuracy and interpretability, on three different tasks: spoken digit recognition, text-based sentiment analysis and visual event recognition.	document classification;experiment;feedback;image noise;iteration;key frame;natural language processing;noise reduction;recurrent neural network;reinforcement learning;relevance;sentiment analysis;text-based (computing)	Wenjie Pei;Tadas Baltrusaitis;David M. J. Tax;Louis-Philippe Morency	2017	2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	10.1109/CVPR.2017.94	artificial intelligence;machine learning;salience (language);computer vision;sentiment analysis;pattern recognition;hidden markov model;logic gate;noise measurement;interpretability;computer science;data modeling	Vision	-16.391482768173194	-72.48070700116104	132232
855561e4017787696d419d766ba0a78923485468	computational and perceptual determinants of film mood in different types of scenes		Films seek to elicit emotions in viewers by infusing the story they tell with an affective character or tone - in a word, a mood. In content-based multimedia analysis, considerable effort has been made to develop methods to estimate film affect computationally. However, results have been hampered by a tendency to classify film scenes either by genre or not at all, while other potentially helpful classification methods have been neglected. In this study, we investigated the quantitative determinants of film mood across different types of scenes. We first collected style and mood ratings for 50 film scenes, which we classified by their location, time of day, and their use of dialogue and music. We then investigated whether the viewers rated the mood (in terms of hedonic tone, energetic arousal, and tense arousal) of various scene types differently, and how well perceptual stylistic attributes as well as low- and high-level computational features correlated with the mood ratings. We found that the mood ratings and their quantitative determinants differed across the scene types. We also found that the energetic arousal ratings were associated with the stylistic attributes and their corresponding low-level features, while hedonic tone and tense arousal were associated with high-level features related to the emotional expression in faces, dialogue, and music. The study contributes to ongoing efforts to estimate film affect computationally in showing that results can be improved by utilizing both low- and high-level features and by considering different scene types separately.	computation;continuous tone-coded squelch system;energetic neutral atom;high- and low-level;statistical classification;temporal logic	Jussi Tarvainen;Jorma Laaksonen;Tapio Takala	2017	2017 IEEE International Symposium on Multimedia (ISM)	10.1109/ISM.2017.10	visualization;mood;pattern recognition;artificial intelligence;computer science;social psychology;perception;affect (psychology);arousal;hedonic tone;emotional expression	Graphics	-11.780152153232125	-70.76993493030587	132538
2c6472a53916a8b69991bc34a7cdc500a4a267d2	beyond sentiment: the manifold of human emotions	human emotions	Sentiment analysis predicts the presence of positive or neg ativ emotions in a text document. In this paper we consider higher dimensional extensions of the sent im concept, which represent a richer set of human emotions. Our approach goes beyond previous work in that our model contains a continuous manifold rather than a finite set of human emotions. We invest igate the resulting model, compare it to psychological observations, and explore its predictive capabilities. Besides obtaining significant improvements over a baseline without manifold, we are also abl e to visualize different notions of positive sentiment in different domains.	baseline (configuration management);sentiment analysis	Seungyeon Kim;Fuxin Li;Guy Lebanon;Irfan A. Essa	2013			artificial intelligence;machine learning	NLP	-13.15024646257104	-70.38470365135156	133106
1621d7d53b855650ce3c79a9d33d65ad66de3952	image-enhanced multi-level sentence representation net for natural language inference		Natural Language Inference (NLI) task requires an agent to determine the semantic relation between a premise sentence (p) and a hypothesis sentence (h), which demands sufficient understanding about sentences from lexical knowledge to global semantic. Due to the issues such as polysemy, ambiguity, as well as fuzziness of sentences, fully understanding sentences is still challenging. To this end, we propose an Image-Enhanced Multi-Level Sentence Representation Net (IEMLRN), a novel architecture that is able to utilize the image to enhance the sentence semantic understanding at different scales. To be specific, we introduce the corresponding image of sentences as reference information, which can be helpful for sentence semantic understanding and inference relation evaluation. Since image information might be related to the sentence semantics at different scales, we design a multi-level architecture to understand sentences from different granularity and generate the sentence representation more precisely. Experimental results on the large-scale NLI corpus and real-world NLI alike corpus demonstrate that IEMLRN can simultaneously improve the performance. It is noteworthy that IEMLRN significantly outperforms the state-of-the-art sentence-encoding based models on the challenging hard subset and challenging lexical subset of SNLI corpus.		Kun Zhang;Guangyi Lv;Le Wu;Enhong Chen;Qi Liu;Han Wu;Fangzhao Wu	2018	2018 IEEE International Conference on Data Mining (ICDM)	10.1109/ICDM.2018.00090	machine learning;natural language processing;artificial intelligence;premise;task analysis;computer science;ambiguity;semantics;architecture;inference;polysemy;sentence	NLP	-16.551140786613622	-69.35533738517027	133141
98acc54694ba7073653cb5e819727921757c7ae9	label-free distant supervision for relation extraction via knowledge graph embedding			graph embedding;knowledge graph;relationship extraction	Guanying Wang;Wen Zhang;Ruoxu Wang;Yalin Zhou;Xi Chen;Wei Zhang;Hai Zhu;Huajun Chen	2018			graph embedding;machine learning;artificial intelligence;relationship extraction;computer science	NLP	-18.765670583646113	-68.43986243816681	133401
ab40f6ca08093ef332d0bb404bc50e082a77d67d	pln-pucrs at emoint-2017: psycholinguistic features for emotion intensity prediction in tweets		Linguistic Inquiry and Word Count (LIWC) is a rich dictionary that map words into several psychological categories such as Affective, Social, Cognitive, Perceptual and Biological processes. In this work, we have used LIWC psycholinguistic categories to train regression models and predict emotion intensity in tweets for the EmoInt-2017 task. Results show that LIWC features may boost emotion intensity prediction on the basis of a low dimension set.	dictionary;probabilistic logic network	Henrique D. P. dos Santos;Renata Vieira	2017			computer science;natural language processing;artificial intelligence;speech recognition	NLP	-13.164972847119627	-73.80481711018213	133504
59aeaa321c9d832f5b797048280309c1f542ce13	word spotting and recognition via a joint deep embedding of image and text				Mohamed Mhiri;Christian Desrosiers;Mohamed Cheriet	2019	Pattern Recognition	10.1016/j.patcog.2018.11.017		Vision	-9.161917446056153	-70.07578152179423	133601
ad76c236fe641aa52d1d6c28bf362ae9ffac91e7	fine-tuned language models for text classification		Transfer learning has revolutionized computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Fine-tuned Language Models (FitLaM), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a state-of-the-art language model. Our method significantly outperforms the state-of-the-art on five text classification tasks, reducing the error by 1824% on the majority of datasets. We opensource our pretrained models and code to enable adoption by the community.	catastrophic interference;computer vision;document classification;language model;natural language processing;open-source software;random neural network	Jeremy Howard;Sebastian Ruder	2018	CoRR		machine learning;natural language processing;transfer of learning;artificial intelligence;scratch;computer science;language model	NLP	-17.30787279570435	-74.69845631040916	133953
533ee188324b833e059cb59b654e6160776d5812	how to construct deep recurrent neural networks		In this paper, we explore different ways to extend a recurrent neural network (RNN) to a deep RNN. We start by arguing that the concept of depth in an RNN is not as clear as it is in feedforward neural networks. By carefully analyzing and understanding the architecture of an RNN, however, we find three points of an RNN which may be made deeper; (1) input-to-hidden function, (2) hidden-tohidden transition and (3) hidden-to-output function. Based on this observation, we propose two novel architectures of a deep RNN which are orthogonal to an earlier attempt of stacking multiple recurrent layers to build a deep RNN (Schmidhuber, 1992; El Hihi and Bengio, 1996). We provide an alternative interpretation of these deep RNNs using a novel framework based on neural operators. The proposed deep RNNs are empirically evaluated on the tasks of polyphonic music prediction and language modeling. The experimental result supports our claim that the proposed deep RNNs benefit from the depth and outperform the conventional, shallow RNNs.	artificial neural network;deep learning;language model;neural networks;random neural network;recurrent neural network	Razvan Pascanu;Çaglar Gülçehre;Kyunghyun Cho;Yoshua Bengio	2013	CoRR		computer science;artificial intelligence;machine learning;data mining	ML	-16.18031588788308	-73.81597817038612	134089
77f9c62e7cd680bff292264feb612b56ffbd5d4c	effect of syntactic features in bangla sentence comprehension		Sentence comprehension is an integral and important part of whole text comprehension. It involves complex cognitive actions, as a reader has to work through lexical, syntactic and semantic aspects in order to understand a sentence. One of the vital features of a sentence is word order or surface forms. Different languages have evolved different systems of word orders, which reflect the cognitive structure of the native users of that language. Therefore, word order affects the cognitive load exerted by a sentence as experienced by the reader. Computational modeling approach to quantify the effect of word order on difficulty of sentence understanding can provide a great advantage in study of text readability and its applications. Plethora of works have been done in English and other languages to address the issue. However, Bangla, which is the fifth mostly spoken languages in the world and a relatively free word order language, still does not have any computational model to quantify the reading difficulty of a sentence. In this paper, we have developed models to predict the comprehending difficulty of a simple sentence according to its different surface forms in Bangla. In the course of action, we have also established that difficulty measures for English do not hold in Bangla. Our model has been validated against a number of user survey. 1 The work was done during the authors stay at IIT Kharagpur 2 http://en.wikipedia.org/wiki/Bengali_language	computation;computational model;integrated information theory;lexicon;list comprehension	Manjira Sinha;Tirthankar Dasgupta;Anupam Basu	2016			natural language processing;bengali;comprehension;syntax;sentence;computer science;artificial intelligence	NLP	-12.679624389302361	-76.88917993542536	134594
72c840681cd85db2ce2f115f08b9ec5b025bd56a	grounding compositional symbols: no composition without discrimination		The classical computational conception of meaning has been challenged by the idea that symbols must be grounded on sensorimotor processes. A difficult question arises from the fact that grounding representations cannot be symbolic themselves but, in order to support compositionality, should work as primitives. This implies that they should be precisely identifiable and strictly connected with discriminable perceptual features. Ideally, each representation should correspond to a single discriminable feature. The present study was aimed at exploring whether feature discrimination is a fundamental requisite for grounding compositional symbols. We studied this problem by using Integral stimuli, composed of two interacting and not separable features. Such stimuli were selected in Experiment 1 as pictures whose component features are easily or barely discriminable (Separable or Integral) on the basis of psychological distance metrics (City-block or Euclidean) computed from similarity judgments. In Experiment 2, either each feature was associated with one word of a two-word expression, or the whole stimulus with a single word. In Experiment 3, the procedure was reversed and words or expressions were associated with whole pictures or separate features. Results support the hypothesis that single words are best grounded by Integral stimuli and composite expressions by Separable stimuli, where a strict association of single words with discriminated features is possible.	image;interaction;judgment;perceptual computing	Alberto Greco;Elena Carrea	2011	Cognitive Processing	10.1007/s10339-011-0427-7	communication;algorithm	AI	-8.473014900399207	-76.13179008685175	134600
fb4536de9f0493866dabd6a24fa32328b370472c	trends and topics in computer vision		We consider the task of learning visual connections between object categories using the ImageNet dataset, which is a large-scale dataset ontology containing more than 15 thousand object classes. We want to discover visual relationships between the classes that are currently missing (such as similar colors or shapes or textures). In this work we learn 20 visual attributes and use them in a zero-shot transfer learning experiment as well as to make visual connections between semantically unrelated object categories.	academy;algorithm;artificial intelligence;berg connector;category theory;cluster analysis;color;dictionary;emoticon;european conference on computer vision;ibm notes;image retrieval;image scaling;imagenet;inventory;lecture notes in computer science;mined;olga (technology);robustness (computer science);semantic similarity;springer (tank);statistical classification;texture mapping;yao graph	Gerhard Goos;Juris Hartmanis;Jan van Leeuwen;David Hutchison;Kiriakos N. Kutulakos;Rogerio Schmidt	2010		10.1007/978-3-642-35749-7	human–computer interaction;computer science	Vision	-14.220996662710695	-66.45655378078162	134603
da10a36a51fad33806650d737f9c9c55a76b092d	an extendable meta-learning algorithm for ontology mapping	learning algorithm;ontology mapping;semantic integration;learning system;machine learning;similarity measure	In this paper, we describe a machine learning approach to ontology mapping. Although Machine learning techniques have been used earlier in many semantic integration approaches, dependence on precision recall curves to preset the weights and thresholds of the learning systems has been a serious bottleneck. By recasting the mapping problem to a classification problem we try to automate this step and develop a robust and extendable meta learning algorithm. The implication is that we can now extend the same method to map the ontology pairs with different similarity measures which might not be specialized for the specific domain, yet obtain results comparable to the state of the art mapping algorithms that exploit machine learning methods. Interestingly we see that as the similarity measures are diluted, our approach performs significantly better for unbalanced classes. We have tested our approach using several similarity measures and two real world ontologies, and the test results we discuss validate our claim. We also present a discussion on the benefits of the proposed meta learning algorithm.	algorithm;artificial intelligence;bayesian network;code;coherence (physics);data mining;database schema;decision tree;extensibility;generative grammar;information theory;international conference on machine learning;journal of web semantics;lazy evaluation;lazy learning;logistic regression;meta learning (computer science);nips;naive bayes classifier;ontology (information science);precision and recall;programming paradigm;semantic integration;semantic reasoner;semantic similarity;semiconductor industry;simulation;unbalanced circuit;world wide web	Saied Haidarian Shahri;Hasan M. Jamil	2009		10.1007/978-3-642-04957-6_36	semi-supervised learning;natural language processing;unsupervised learning;multi-task learning;instance-based learning;algorithmic learning theory;semantic integration;wake-sleep algorithm;computer science;artificial intelligence;online machine learning;machine learning;data mining;database;linguistics;learning classifier system;ontology-based data integration;stability;computational learning theory;world wide web;active learning;information retrieval;population-based incremental learning;generalization error	AI	-18.353234286410736	-66.37393862354358	134636
8660f5e7223a55489527d32c2c6d67c2b4907046	assessing public speaking ability from thin slices of behavior		An important aspect of public speaking is delivery, which consists of the appropriate use of non-verbal cues to strengthen the message. Recent works have successfully predicted ratings of public speaking delivery aspects using the entire presentations of speakers. However, in other contexts, such as the assessment of personality or the prediction of job interview outcomes, it has been shown that thin slices, brief excerpts of behavior, provide enough information for raters to make accurate predictions. In this paper, we consider the use of thin slices for predicting ratings of public speaking behavior. We use a publicly available corpus of public speaking presentations and obtain ratings of full videos and thin slices. We first study how thin slices ratings are related to full video ratings. Then, we use automatic audio-visual feature extraction methods and machine learning algorithms to create models for predicting public speaking ratings, and evaluate these models for predicting thin slices ratings and full videos ratings.	algorithm;feature extraction;machine learning;multimodal interaction;text corpus;vii;web slice	Mathieu Chollet;Stefan Scherer	2017	2017 12th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2017)	10.1109/FG.2017.45	multimedia;feature extraction;public speaking;personality;job interview;computer science	NLP	-11.60443215749099	-70.9874825484221	134745
b09f47eb337f4d9a659608177b260225369bda2f	lemore: a lifelog engine for moments retrieval at the ntcir-lifelog lsat task	lifelogging;semantic image retrieval;egocentric images;conference lecture	Semantic image retrieval from large amounts of egocentric visual data requires to leverage powerful techniques for filling in the semantic gap. This paper introduces LEMoRe, a Lifelog Engine for Moments Retrieval, developed in the context of the Lifelog Semantic Access Task (LSAT) of the the NTCIR-12 challenge and discusses its performance variation on different trials. LEMoRe integrates classical image descriptors with high-level semantic concepts extracted by Convolutional Neural Networks (CNN), powered by a graphic user interface that uses natural language processing. Although this is just a first attempt towards interactive image retrieval from large egocentric datasets and there is a large room for improvement of the system components and the user interface, the structure of the system itself and the way the single components cooperate are very promising. Team Name LEMoRe Team from the University of Barcelona and Technical University of Catalonia. Subtasks Lifelog Semantic Access Task (LSAT)	convolutional neural network;graphical user interface;high- and low-level;image retrieval;lifelog;natural language processing;visual descriptor	Gabriel de Oliveira Barra;Alejandro Cartas Ayala;Marc Bolaños;Mariella Dimiccoli;Xavier Giró;Petia Radeva	2016			computer vision;visual word;computer science;multimedia;information retrieval	Vision	-7.8675289995670585	-69.13524742585369	135038
382d711123c5842b689be8c31696b1d45e1f4295	block2vec: a deep learning strategy on mining block correlations in storage systems	embedding;embedding deep learning block correlation io;block correlation;correlation probability neural networks machine learning natural language processing training computational modeling;io;deep learning;vectors data mining learning artificial intelligence natural language processing neural nets storage management;block2vec real system traces block prediction algorithm natural language processing word embedding technique deep neural network multidimensional vectors semantic patterns storage systems block correlation mining deep learning strategy	Block correlations represent the semantic patterns in storage systems. These correlations can be exploited for data caching, pre-fetching, layout optimization, I/O scheduling, etc. In this paper, we introduce Block2Vec, a deep learning based strategy to mine the block correlations in storage systems. The core idea of Block2Vec is twofold. First, it proposes a new way to abstract blocks, which are considered as multi-dimensional vectors instead of traditional block Ids. In this way, we are able to capture similarity between blocks through the distances of their vectors. Second, based on vector representation of blocks, it further trains a deep neural network to learn the best vector assignment for each block. We leverage the recently advanced word embedding technique in natural language processing to efficiently train the neural network. To demonstrate the effectiveness of Block2Vec, we design a demonstrative block prediction algorithm based on mined correlations. Empirical comparison based on the simulation of real system traces shows that Block2Vec is capable of mining block-level correlations efficiently and accurately. This research and trial show that the deep learning strategy is a promising direction in optimizing storage system performance.	algorithm;artificial neural network;computer data storage;deep learning;i/o scheduling;input/output;mathematical optimization;mined;natural language processing;object-based language;recursive neural network;scheduling (computing);simulation;tracing (software);word embedding	Dong Dai;Forrest Sheng Bao;Jiang Zhou;Yong P Chen	2016	2016 45th International Conference on Parallel Processing Workshops (ICPPW)	10.1109/ICPPW.2016.43	parallel computing;computer science;artificial intelligence;theoretical computer science;operating system;machine learning;embedding;deep learning;deep belief network	HPC	-11.658105020421853	-68.74103932547608	135229
a73970e2b41bf003f725ff84025aa584b78c52b7	using agreement on direction of change to build rank-based emotion classifiers	time continuous emotional descriptors emotion recognition rank based emotion recognition relative emotional labels;relative emotional labels;emotional traces direction of change rank based emotion classifiers automatic emotion recognition realistic domains human interaction noisy emotional descriptors low interevaluator agreement emotional contrasts absolute scores machine learning algorithm expressive behavior relative labels time consuming subjective evaluation label extraction time continuous evaluation qualitative agreement analysis qa analysis rank based classifiers semaine database qa based label preference learning rankers;emotion recognition;emotion recognition reliability databases psychology speech context ieee transactions;rank based emotion recognition;learning artificial intelligence emotion recognition;time continuous emotional descriptors	Automatic emotion recognition in realistic domains is a challenging task given the subtle expressive behaviors that occur during human interactions. The challenges start with noisy emotional descriptors provided by multiple evaluators, which are characterized by low interevaluator agreement. Studies have suggested that evaluators are more consistent in detecting qualitative relations between episodes i.e., emotional contrasts, rather than absolute scores i.e., the actual emotion. Based on these observations, this study explores the use of relative labels to train machine learning algorithms that can rank expressive behaviors. Instead of deriving relative labels from expensive and time-consuming subjective evaluations, the labels are extracted from existing time-continuous evaluations over expressive attributes annotated with FEELTRACE. We rely on the qualitative agreement QA analysis to estimate relative labels which are used to train rank-based classifiers rankers. The experimental evaluation on the SEMAINE database demonstrates the benefits of the proposed approach. The ranking performance using the QA-based labels compare favorably against preference learning rankers trained with relative labels obtained by simply aggregating the absolute values of the emotional traces across evaluators, which is the common approach used by other studies.	algorithm;emotion recognition;interaction;machine learning;preference learning;sensor;software quality assurance;tracing (software)	Srinivas Parthasarathy;Roddy Cowie;Carlos Busso	2016	IEEE/ACM Transactions on Audio, Speech, and Language Processing	10.1109/TASLP.2016.2593944	speech recognition;machine learning	NLP	-11.62645549050606	-70.93346499715075	135616
bbcd352d939998067647bb0c861d2801310480d7	a simple common contexts explanation for the development of abstract letter identities	hebbian learning;tecnologia electronica telecomunicaciones;visual word recognition;computacion informatica;image processing;caracter manuscrito;etude experimentale;manuscript character;procesamiento imagen;grupo de excelencia;traitement image;ciencias basicas y experimentales;pattern recognition;tratamiento caracter;self organization;reconnaissance forme;reseau neuronal;tecnologias;reconocimiento patron;grupo a;caractere manuscrit;visual system;estudio experimental;red neuronal;traitement caractere;artificial neural network;character processing;neural network	letter identities (ALIs) are an early representation in visual word recognition that are specific to written language. They do not reflect visual or phonological features, but rather encode the identities of letters independent of case, font, sound, and so forth. How could the visual system come to develop such a representation? We propose that because many letters look similar regardless of case, font, and other characteristics, these provide common contexts for visually dissimilar uppercase and lowercase forms of other letters (e.g., e between k and y in key and E in the visually similar context K-Y). Assuming that the distribution of words' relative frequencies is comparable in upper and lowercase (that just as key is more frequent than pew, KEY is more frequent than PEW), these common contexts will also be similarly distributed in the two cases. We show how this statistical regularity could lead Hebbian learning to produce ALIs in a competitive architecture. We present a self-organizing artificial neural network that illustrates this idea and produces ALIs when presented with the most frequent words from a beginning reading corpus, as well as with artificial input.	artificial neural network;body of uterus;encode;hebbian theory;languages;organizing (structure);self-organization;sense of identity (observable entity);visual word	Thad A. Polk;Martha J. Farah	1997	Neural Computation	10.1162/neco.1997.9.6.1277	self-organization;speech recognition;visual system;hebbian theory;computer science;artificial intelligence;machine learning;communication;artificial neural network	ML	-11.477526178119772	-76.21600723947562	135793
38b98a26481cf6c78f7024ed45259f22e9f4da20	better text understanding through image-to-text transfer		Generic text embeddings are successfully used in a variety of tasks. However, they are often learnt by capturing the co-occurrence structure from pure text corpora, resulting in limitations of their ability to generalize. In this paper, we explore models that incorporate visual information into the text representation. Based on comprehensive ablation studies, we propose a conceptually simple, yet well performing architecture. It outperforms previous multimodal approaches on a set of well established benchmarks. We also improve the state-of-the-art results for image-related text datasets, using orders of magnitude less data.	benchmark (computing);encoder;headroom (audio signal processing);multimodal interaction;text corpus;vocabulary	Karol Kurach;Sylvain Gelly;Michal Jastrzebski;Philip Häusser;Olivier Teytaud;Damien Vincent;Olivier Bousquet	2017	CoRR		natural language processing;machine learning;architecture;computer science;deep learning;text corpus;artificial intelligence	NLP	-17.953742982352523	-73.70110419168823	135809
0e8715ba7d1b45beb2d72acbd74ad3b958c01e19	interactions of emoticon valence and text processing		Emoticons in informal text communication are common worldwide. They have the potential to reveal emotion and social functions, analogous to facial expression and body gestures in face-to-face verbal communication. Our findings from a corpus study of online text communication by a group of scientists, some of whom were bilingual and others monolingual, suggested that patterns of emoticon use depend on a variety of factors, including emoticon valence and language of texting (Aragon et al., 2014). In the present study we bring these effects into the laboratory by examining the interrelation of emoticons and words in lexical decision (LD) experiments with sequential (SOA 200 ms) but spatially superimposed emoticon-word pairs. Monolingual speakers showed a reliable interaction of emoticon valence with lexicality but interactions with word valence were unreliable. Results will be compared to those from comparable word-word pairs.	emoticon;experiment;interaction	Laurie Feldman;Kit Cho;Cecilia R. Aragon;Judith F. Kroll	2015			psychology;valence (chemistry);communication;cognitive psychology;emoticon;nonverbal communication;facial expression;lexical decision task;text processing;gesture	HCI	-10.842601575481304	-79.53021975534362	136135
5f3a99a8229f9265696128d234b8f414a7d7f633	deriving syntax-semantics mappings: node linking, type shifting and scope ambiguity		In this paper, we introduce a type-shifting operation which provides a principled means of describing the derivational links required in Synchronous TAG accounts of quantification. No longer do links appear on root nodes of predicates on and hoc basis, rather they are generated as a part of a type-shifting mechanism over arguments of the predicate. By introducing to the system a set of temporal variables, we show how this operation can also be used to account for the scope interactions of clausal embedding. We then move on to consider additional cases of multiple clausal embedding and coordination. 1 The Issue Investigations of the syntax-semantics interface in Tree Adjoining Grammar, particularly those making use of Synchronous TAG, grapple with the limitations imposed by the restrictiveness of treeor set-local MCTAG. To the degree that they successfully treat the mapping between syntax and semantics in this restricted setting, this provides evidence in favor of Joshi’s hypothesis that the mild context-sensitivity of TAG is a fundamental property of grammar. Nonetheless, the analyses that have been put forward are at times ad hoc. One wonders why a certain semantic object is associated with some piece of syntax, and why certain nodes of the syntactic representations are linked to the semantics in one manner as opposed to another. In this paper, we report on our first efforts to formulate principles governing STAG pairings, in an effort to provide a more restrictive framework for characterizing STAGderivable syntax-semantics mappings. 2 Tree Shapes and Type Shifting We adopt a traditional view of syntactic elementary trees as the realization of a single lexical predicate and its grammatical “associates” (cf. the Condition on Elementary Tree Minimality and Theta Criterion of Frank (2002)). The corresponding semantic objects are composed from the meaning assignments for the lexical anchor together with the meanings associated with nonprojected non-terminals. Substitution nodes are interpreted as typed variables (with types determined by a bijection from syntactic categories to semantic types: DP to type, NP to type〈e, t〉, CP, TP and VP to type t, etc. We follow Pogodalla (2004) in assuming that such variables are bound by (linear) lambda operators, and take syntactic substitution ofS into T to correspond to (semantic) function application ofT to S. For a syntactic nodeN targeted for adjoining, we assume that the corresponding node in the semantic representation is embedded beneath an abstracted function variable (with type〈α,α〉 whereα is the type determined by the category bijection for N ). Adjoining of auxiliary treeA to treeT corresponds to application ofT to A. We assume that adjoining always applies at nodes to which it may; when no content is added, a semantic identity function is applied. Some linkages between the syntactic and semantic trees are straightforward: non-projected non-terminals are linked to the lambda operators binding their associated variables, while projected nodes in the syntax are linked to lambda operators binding variables of the appropriate 〈α,α〉 type. This gives rise to a pairing of the sort in Figure 1 for the transitive verblove. What is less clear is how to establish the nonbijective linkages between sites for syntactic at-	ccir system a;embedded system;grapple;hoc (programming language);interaction;lambda lifting;transitive closure;tree-adjoining grammar	Dennis Ryan Storoshenko;Robert Frank	2012			syntax;discrete mathematics;ambiguity;semantics;mathematics	PL	-9.377264049986954	-74.94700340052098	136263
d6a57f3d027862289af6a302fc8fa631f2f2db59	simple and sophisticated inning summary generation based on encoder-decoder model and transfer learning		This paper describes an inning summarization method for a baseball game by using an encoder-decoder model. Each inning in a baseball game contains some events, such as hits, strikeouts, homeruns and scoring. Simplified description of the events leads to the improvement of readability of the inning information. Our method learns a relation between play-by-play data in each inning and inning reports. We also incorporate sophisticated expressions acquired from game summaries with the model. We call them Game-changing Phrase, GP. One problem in our task is the size of training data for the learning. To solve this problem, we apply a transfer learning approach into our method. In the experiment, we evaluate the effectiveness of our method with the transfer learning.	automatic summarization;baseline (configuration management);encoder;global positioning system;javaserver pages;video game developer	Yuuki Tagawa;Kazutaka Shimada	2017	2017 International Conference on Asian Language Processing (IALP)	10.1109/IALP.2017.8300591	readability;automatic summarization;encoder;natural language processing;transfer of learning;artificial intelligence;baseball game;expression (mathematics);phrase;computer science;training set	NLP	-16.556799855213246	-71.00555175084993	136979
7e783811fac5ebc3199c678d9ecb6777f52cd692	sharp nearby, fuzzy far away: how neural language models use context		We know very little about how neural language models (LM) use prior linguistic context. In this paper, we investigate the role of context in an LSTM LM, through ablation studies. Specifically, we analyze the increase in perplexity when prior context words are shuffled, replaced, or dropped. On two standard datasets, Penn Treebank and WikiText-2, we find that the model is capable of using about 200 tokens of context on average, but sharply distinguishes nearby context (recent 50 tokens) from the distant history. The model is highly sensitive to the order of words within the most recent sentence, but ignores word order in the long-range context (beyond 50 tokens), suggesting the distant past is modeled only as a rough semantic field or topic. We further find that the neural caching model (Grave et al., 2017b) especially helps the LSTM to copy words from within this distant context. Overall, our analysis not only provides a better understanding of how neural LMs use their context, but also sheds light on recent success from cache-based models.		Urvashi Khandelwal;He He;Peng Qi;Daniel Jurafsky	2018			machine learning;semantic field;fuzzy logic;artificial intelligence;treebank;perplexity;word order;natural language processing;language model;cache;computer science;sentence	NLP	-17.165248595453487	-73.16925154438992	137410
8790d6a20e6a07bd43c9e9f00258cd3f5896df34	a joint detection-classification model for audio tagging of weakly labelled data		Audio tagging aims to assign one or several tags to an audio clip. Most of the datasets are weakly labelled, which means only the tags of the clip are known, without knowing the occurrence time of the tags. The labeling of an audio clip is often based on the audio events in the clip and no event level label is provided to the user. Previous works have used the bag of frames model assume the tags occur all the time, which is not the case in practice. We propose a joint detection-classification (JDC) model to detect and classify the audio clip simultaneously. The JDC model has the ability to attend to informative and ignore uninformative sounds. Then only informative regions are used for classification. Experimental results on the “CHiME Home” dataset show that the JDC model reduces the equal error rate (EER) from 19.0% to 16.9%. More interestingly, the audio event detector is trained successfully without needing the event level label.	compact disc digital audio;enhanced entity–relationship model;information	Qiuqiang Kong;Yong Xu;Wenwu Wang;Mark D. Plumbley	2017	2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2017.7952234	speech recognition;computer science;data mining;world wide web	Robotics	-14.217853810785323	-70.64078533612395	137523
a0cde380227c086f44c9729eeb8add9d7228e3ab	tackling class imbalance and data scarcity in literature-based gene function annotation	kernel methods;class imbalance;text classification;kernel method;gene function	In recent years, a number of machine learning approaches to literature-based gene function annotation have been proposed. However, due to issues such as lack of labeled data, class imbalance and computational cost, they have usually been unable to surpass simpler approaches based on string-matching. In this paper, we propose a principled machine learning approach based on kernel classifiers.  We show that kernels can address the task's inherent data scarcity by embedding additional knowledge and we propose a simple yet effective solution to deal with class imbalance. From experiments on the TREC Genomics Track data, our approach achieves better F1-score than two state-of-the-art approaches based on string-matching and cross-species information.	algorithmic efficiency;experiment;f1 score;machine learning;string searching algorithm	Mathieu Blondel;Kazuhiro Seki;Kuniaki Uehara	2011		10.1145/2009916.2010080	kernel method;computer science;bioinformatics;machine learning;data mining	AI	-18.548711595235314	-66.33083476366818	137590
7f7e59970b71af023cdfd19f7f9051e8017e16b2	deep learning-based document modeling for personality detection from text	pragmatics;neural networks;neural based document modeling;personality;convolution;semantics;distributional semantics;emotion recognition;computational modeling;feature extraction;intelligent systems;artificial intelligence;neurons;convolutional neural network;natural language processing	This article presents a deep learning based method for determining the author's personality type from text: given a text, the presence or absence of the Big Five traits is detected in the author's psychological profile. For each of the five traits, the authors train a separate binary classifier, with identical architecture, based on a novel document modeling technique. Namely, the classifier is implemented as a specially designed deep convolutional neural network, with injection of the document-level Mairesse features, extracted directly from the text, into an inner layer. The first layers of the network treat each sentence of the text separately; then the sentences are aggregated into the document vector. Filtering out emotionally neutral input sentences improved the performance. This method outperformed the state of the art for all five traits, and the implementation is freely available for research purposes.	artificial neural network;binary classification;convolutional neural network;deep learning	Navonil Majumder;Soujanya Poria;Alexander F. Gelbukh;Erik Cambria	2017	IEEE Intelligent Systems	10.1109/MIS.2017.23	natural language processing;speech recognition;intelligent decision support system;feature extraction;computer science;artificial intelligence;machine learning;semantics;personality;convolution;convolutional neural network;computational model;pragmatics	NLP	-19.10153824315168	-71.18153716715139	137600
828ac57f755db989e2886042a85278ae4823297c	uncovering the temporal context for video question answering	video sequence modeling;video question answering;video prediction;cross-media	In this work, we introduce Video Question Answering in the temporal domain to infer the past, describe the present and predict the future. We present an encoder–decoder approach using Recurrent Neural Networks to learn the temporal structures of videos and introduce a dual-channel ranking loss to answer multiple-choice questions. We explore approaches for finer understanding of video content using the question form of “fill-in-the-blank”, and collect our Video Context QA dataset consisting of 109,895 video clips with a total duration of more than 1000 h from existing TACoS, MPII-MD and MEDTest 14 datasets. In addition, 390,744 corresponding questions are generated from annotations. Extensive experiments demonstrate that our approach significantly outperforms the compared baselines.	baseline (configuration management);digital video;encoder;experiment;graphics processing unit;learning to rank;multi-channel memory architecture;question answering;recurrent neural network;titan (supercomputer);video clip	Linchao Zhu;Zhongwen Xu;Yi Yang;Alexander G. Hauptmann	2017	International Journal of Computer Vision	10.1007/s11263-017-1033-7	temporal context;clips;question answering;computer science;information retrieval;recurrent neural network;ranking	Vision	-13.55601771028017	-70.17934269033555	137699
176696349d75466f030aaee036445bf37c762fb7	compression of character stings by an adaptive dictionary			dictionary	Matti Jakobsson	1985	BIT			Theory	-9.159036761093322	-70.15013094258347	137825
e8ade52e2aa3fad6e5c13dccd337e006087e36b6	the influence of co-occurrence and inheritance information on children's inductive generalization		Prior research suggests young children understand that labels serve as category markers and that they can utilize this information to perform category-based induction with both identical and semantically-similar labels (Gelman & Markman, 1986). Recent research suggests that children’s ability to perform category-based induction is limited to a small subset of semantically-similar labels which co-occur in child-directed speech (Fisher, 2010; Fisher, Matlen, & Godwin, in press). However, most of the co-occurring labels used in prior research are not only semantically-similar but they also refer to baby-parent relationships (e.g., puppydog). Thus, children may be able to perform induction with these particular label-pairs, because they contain kinship information rather than because they co-occur. The present study aims to disentangle whether young children’s induction performance is driven by kinship information or co-occurrence probability. Results indicate that 4-year-olds’ (but not 5-year-olds, 7-year-olds, or adults) induction performance was influenced by co-occurrence probability; kinship information was found to be insufficient to promote young children’s induction performance.	godwin's law;mathematical induction	Karrie E. Godwin;Anna V. Fisher;Bryan J. Matlen	2011			cognitive psychology;social psychology;priming (psychology);semantic similarity;co-occurrence;psychology;small set;synonym;peabody picture vocabulary test;cognitive development;childes	NLP	-8.701825761184125	-76.9904069637238	138022
b47a0cc11d224bf723f938a9c6c81995f3ebe356	review aspect extraction based on character-enhanced embedding models		User reviews, in the form of short unstructured natural texts, often provide rich information to benefit product adoption or service improvement. Aspect can be extracted as the abstract meaning from the reviews. Traditional methods have employed either rule-based templates or bag-of-words features for aspect extraction from text. However, these models cannot effectively handle short texts, especially in Chinese reviews. In this paper, we address the issue by learning the character embeddings as the basic semantic unit and incorporating the compositional sentence-level representation into a neural network approach for review aspect classification. For that, the character embeddings from the reviews are learned in position-based and clustered-based fashions, and then combined into sentence vectors to yield better text representations. Extensive experiments on real world data set suggest that our proposed model highly outperforms the state-of-the-art methods for review aspect extraction task.	artificial neural network;bag-of-words model in computer vision;experiment;logic programming;sentence extraction;user review	Jingxuan Yang;Qinjie Lyu;Sheng Gao;Lin Qiu;Jun Guo	2016	2016 IEEE International Conference on Network Infrastructure and Digital Content (IC-NIDC)	10.1109/ICNIDC.2016.7974568	artificial neural network;machine learning;embedding;sentence;artificial intelligence;computer science	NLP	-18.585199930486315	-70.71137569418583	138306
fa73764d62c016bc405da3393d5edd3be0ddb18e	blinkfill: semi-supervised programming by example for syntactic string transformations		The recent Programming By Example (PBE) techniques such as FlashFill have shown great promise for enabling end-users to perform data transformation tasks using inputoutput examples. Since examples are inherently an underspecification, there are typically a large number of hypotheses conforming to the examples, and the PBE techniques suffer from scalability issues for finding the intended program amongst the large space. We present a semi-supervised learning technique to significantly reduce this ambiguity by using the logical information present in the input data to guide the synthesis algorithm. We develop a data structure InputDataGraph to succinctly represent a large set of logical patterns that are shared across the input data, and use this graph to efficiently learn substring expressions in a new PBE system BlinkFill. We evaluate BlinkFill on 207 real-world benchmarks and show that BlinkFill is significantly faster (on average 41x) and requires fewer input-output examples (1.27 vs 1.53) to learn the desired transformations in comparison to FlashFill.	algorithm;data structure;programming by example;scalability;semi-supervised learning;semiconductor industry;substring;supervised learning	Rishabh Singh	2016	PVLDB	10.14778/2977797.2977807	computer science;theoretical computer science;machine learning;data mining;database;mathematics;programming language;algorithm	DB	-13.437553762963391	-67.32432081247129	138825
810eafc9e854ea9b1d7a9e9f755f8102310d5db6	dynamic multimodal instance segmentation guided by natural language queries		We address the problem of segmenting an object given a natural language expression that describes it. Current techniques tackle this task by either (i) directly or recursively merging linguistic and visual information in the channel dimension and then performing convolutions; or by (ii) mapping the expression to a space in which it can be thought of as a filter, whose response is directly related to the presence of the object at a given spatial coordinate in the image, so that a convolution can be applied to look for the object. We propose a novel method that integrates these two insights in order to fully exploit the recursive nature of language. Additionally, during the upsampling process, we take advantage of the intermediate information generated when downsampling the image, so that detailed segmentations can be obtained. We compare our method against the state-of-the-art approaches in four standard datasets, in which it surpasses all previous methods in six of eight of the splits for this task.	convolution;decimation (signal processing);decision model and notation;map;multimodal interaction;natural language;recursion;upsampling	Edgar Margffoy-Tuay;Juan C. Pérez;Emilio Botero;Pablo Arbeláez	2018		10.1007/978-3-030-01252-6_39	upsampling;machine learning;pattern recognition;artificial intelligence;multimodal interaction;computer science;market segmentation;exploit;convolution;recursion;natural language;communication channel	Vision	-14.185391017430668	-70.22631660633304	138832
3a610058a6dadee8507b997e2099159f70d16323	a flexible, parallel generator of natural language	natural language	My Ph.D. thesis (Ward 1992, 1991)1 addressed the task of generating natural language utterances. It was motivated by two difficulties in scaling up existing generators. Current generators only accept input that are relatively poor in information, such as feature structures or lists of propositions; they are unable to deal with input rich in information, as one might expect from, for example, an expert system with a complete model of its domain or a natural language understander with good inference ability. Current generators also have a very restricted knowledge of language— indeed, they succeed largely because they have few syntactic or lexical options available (McDonald 1987)— and they are unable to cope with more knowledge because they deal with interactions among the various possible choices only as special cases. To address these and other issues, I built a system called FIG (flexible incremental generator). FIG is based on a single associative network that encodes lexical knowledge, syntactic knowledge, and world knowledge. Computation is done by spreading activation across the network, supplemented with a small amount of symbolic processing. Thus, FIG is a spreading activation or structured connectionist system (Feldman et al. 1988). In the initial state, some nodes representing concepts are sources of activation; this pattern of activation represents the information to be expressed. Activation flows from these nodes to nodes representing words through the various knowledge structures of the network. When the network settles, the most highly activated word is selected and emitted. Activation levels are then updated to represent the new current state, both in syntactic and semantic aspects. This process of settle, emit, and update repeats until all the input has the subject-predicate construction because it is a verb. FIG’s syntactic coverage is much broader than that of previous connectionist generators such as Gasser (1988); output include “once upon a time there lived an old man and an old woman,” “one day the old woman went to a stream to wash clothes,” and “John ate a peach with an old woman’s fork.” The success of this model in generating utterances of English and Japanese suggests that the complexity present in most treatments of syntax is unnecessary: FIG dispenses with the assembly of syntactic structures, constructions that affect the utterance only by the activation they transmit, directly or indirectly, to words. FIG does without a mechanism for explicit syntactic choice; any number of constructions are potentially active, competing or cooperating in parallel, and the choice among them is emergent. Phenomena traditionally considered to require instantiation and variable binding are handled in FIG with much simpler mechanisms. Grammatical output results not from constraints on the form of syntactic structures or the behavior of an algorithm but, rather, from the structure and weights of the network as a whole. This paragraph summarizes the ways in which FIG addresses the issues that motivated its construction: It handles arbitrarily rich input because the number of nodes activated in the initial state makes no difference to its operation. It handles interaction among choices easily because it tends to settle into a state representing a compatible set of choices as a result of links among nodes that represent such choices. It handles trade-offs among competing goals without additional mechanism because all computation is in terms of numbers. Thus, FIG is the first generator potentially able to perform well at the complex generation tasks that will arise in the future. Of course, to realize this potential requires more experimentation with the details of activation flow and with ways to A Flexible, Parallel Generator of Natural Language	activation function;algorithm;commonsense knowledge (artificial intelligence);complexity;connectionism;emergence;expert system;interaction;mcdonald–kreitman test;natural language;peach;spreading activation;substitution (logic);symbolic computation	Nigel Ward	1992	AI Magazine			AI	-11.849652907839937	-75.540863529071	139293
c762e198b0239313ee50476021b1939390c4ef9d	knowledge graph embedding: a locally and temporally adaptive translation-based approach		A knowledge graph is a graph with entities of different types as nodes and various relations among them as edges. The construction of knowledge graphs in the past decades facilitates many applications, such as link prediction, web search analysis, question answering, and so on. Knowledge graph embedding aims to represent entities and relations in a large-scale knowledge graph as elements in a continuous vector space. Existing methods, for example, TransE, TransH, and TransR, learn the embedding representation by defining a global margin-based loss function over the data. However, the loss function is determined during experiments whose parameters are examined among a closed set of candidates. Moreover, embeddings over two knowledge graphs with different entities and relations share the same set of candidates, ignoring the locality of both graphs. This leads to the limited performance of embedding related applications. In this article, a locally adaptive translation method for knowledge graph embedding, called TransA, is proposed to find the loss function by adaptively determining its margin over different knowledge graphs. Then the convergence of TransA is verified from the aspect of its uniform stability. To make the embedding methods up-to-date when new vertices and edges are added into the knowledge graph, the incremental algorithm for TransA, called iTransA, is proposed by adaptively adjusting the optimal margin over time. Experiments on four benchmark data sets demonstrate the superiority of the proposed method, as compared to the state-of-the-art ones.	algorithm;article 8 of the european convention on human rights;benchmark (computing);entity;experiment;freebase;graph (discrete mathematics);graph embedding;knowledge graph;locality of reference;loss function;question answering;web search engine;wordnet;world wide web	Yantao Jia;Yuanzhuo Wang;Xiaolong Jin;Hailun Lin;Xueqi Cheng	2017	TWEB	10.1145/3132733	graph embedding;computer science;machine learning;data mining;question answering;locality;vector space;vertex (geometry);closed set;embedding;artificial intelligence;convergence (routing)	AI	-16.157606279433296	-66.39790499891902	139634
bc95b70c8e964bec0909f815ae73539c4e4dac96	a temporal community contexts based funny joke generation		It is still a long way to communicate humans and machines emotionally. There are some tries to provide sentimental conversations among humans and machines. Computational humor is one of research topics in computational linguistics and artificial intelligence. We introduce a new method to generate jokes in a sentence related temporal and spatial contexts for continuous conversations with images. We propose a novel model based on a recurrent neural network with natural language processing (NLP) and understanding (NLU) methods. The method generates jokes in a sentence considering temporal and spatial context. The method can joke to trend sensitive users according to different points of humor that vary from region to region. Through this, the user can feel the interest of the conversational service with humorous responses or contents. We apply the method to some applications such as psychiatric counseling and stress management to enhance the applicability of conversational service.	artificial intelligence;artificial neural network;computation;computational humor;computational linguistics;natural language processing;natural language understanding;recurrent neural network	Dongkeon Lee;Seung-Ho Han;KyoJoong Oh;Ho-Jin Choi	2017	2017 18th IEEE International Conference on Mobile Data Management (MDM)	10.1109/MDM.2017.62	spatial contextual awareness;joke;computer science;computational linguistics;computational humor;natural language processing;recurrent neural network;emotion recognition;artificial intelligence;sentence	Robotics	-14.550341579006528	-72.78791371268812	139673
5057a9e72db79901dfcc786b67faa866fe1f79ed	unsupervised learning of semantic audio representations		Even in the absence of any explicit semantic annotation, vast collections of audio recordings provide valuable information for learning the categorical structure of sounds. We consider several class-agnostic semantic constraints that apply to unlabeled nonspeech audio: (i) noise and translations in time do not change the underlying sound category, (ii) a mixture of two sound events inherits the categories of the constituents, and (iii) the categories of events in close temporal proximity are likely to be the same or related. Without labels to ground them, these constraints are incompatible with classification loss functions. However, they may still be leveraged to identify geometric inequalities needed for triplet loss-based training of convolutional neural networks. The result is low-dimensional embeddings of the input spectrograms that recover 41% and 84% of the performance of their fully-supervised counterparts when applied to downstream query-by-example sound retrieval and sound event classification tasks, respectively. Moreover, in limited-supervision settings, our unsupervised embeddings double the state-of-the-art classification performance.	artificial neural network;convolutional neural network;downstream (software development);loss function;query by example;spectrogram;triplet state;unsupervised learning	Aren Jansen;Manoj Plakal;Ratheet Pandya;Daniel P. W. Ellis;Shawn Hershey;Jiayang Liu;R. Channing Moore;Rif A. Saurous	2018	2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2018.8461684	machine learning;convolutional neural network;semantic computing;artificial intelligence;semantics;unsupervised learning;categorical variable;pattern recognition;spectrogram;computer science;annotation	Vision	-14.533061737289989	-69.84592876846291	139972
ceaec4c55005366ed679382e1463a1c307c2e402	semantic derivation of the lexical item shen in mandarin based on conceptual metaphor		The Mandarin word 'Shen' (body)has determined its semantic derivation through conceptual metaphor and metonymy, further resulting in the phenomenon of polysemy. This research discusses how metaphors have influenced the semantic derivation of Mandarin term 'Shen' used in Taiwan, analyze the term's various semantic derivatives, through ontological metaphor, container metaphor, spatial metaphor, metaphor in Buddhist realm, and metonymies of 'the part for the whole', 'the whole for the part' , 'the physical for the abstract', and finally generate a semantic relationship schema.	super robot monkey team hyperforce go!	Xiangyun Qiu	2013		10.1007/978-3-642-45185-0_23	psychology;natural language processing;linguistics;communication	NLP	-12.859381501947153	-76.98997635318045	140384
af4cf35223e71e8f28715af60563d4f4f50a50c9	tweety at semeval-2018 task 2: predicting emojis using hierarchical attention neural networks and support vector machine		We present the system built for SemEval2018 Task 2 on Emoji Prediction. Although Twitter messages are very short we managed to design a wide variety of features: textual, semantic, sentiment, emotion-, and colorrelated ones. We investigated different methods of text preprocessing including replacing text emojis with respective tokens and splitting hashtags to capture more meaning. To represent text we used word n-grams and word embeddings. We experimented with a wide range of classifiers and our best results were achieved using a SVM-based classifier and a Hierarchical Attention Neural Network.	artificial neural network;automatic vectorization;emoji;emoticon;feature engineering;grams;hashtag;n-gram;neural network software;preprocessor;support vector machine;word embedding;word lists by frequency	Daniel Kopev;Atanas Atanasov;Dimitrina Zlatkova;Momchil Hardalov;Ivan Koychev;Ivelina Nikolova;Galia Angelova	2018			support vector machine;natural language processing;artificial neural network;semeval;machine learning;computer science;artificial intelligence	NLP	-18.89978719019541	-71.28132038035491	140492
d0f4e4dcc0ed3c2b41a55e92938944a6a5bdce23	film narrative exploration through the analysis of aesthetic elements	modelizacion;narrative;multimedia;narration;repere visuel;modelisation;aesthetics;narracion;narrative structure;audition;esthetique;audicion;modeling;hearing;estetica;visual cue;marca visual	In this paper, we propose a novel method for performing high-level narrative structure extraction of films. Our objective is to utilize the knowledge of film production for analyzing and extracting the structure of films. This is achieved by combining visual and aural cues on the basis of cinematic principles. An aesthetic model is developed to integrate visual and aural cues (aesthetic fields) to evaluate the aesthetic intensity curve which is associated with the film’s narrative structure. Finally, we conduct experiments on different genres of films. Experimental results demonstrate the effectiveness of our approach.	concatenation;experiment;high- and low-level	Chia-Wei Wang;Wen-Huang Cheng;Jun-Cheng Chen;Shu-Sian Yang;Ja-Ling Wu	2007		10.1007/978-3-540-69423-6_59	computer vision;multimedia;narrative	AI	-8.719285901332949	-68.31162208849531	140689
3ddc0ec67450d17e7324ce0b68c0850d85b40ebe	individual differences in orthographic priming relate to phonological decoding skill in adults	dyslexia;individual differences;masked priming;reading skill;word recognition	We examined relationships between individual differences in orthographic priming and a battery of measures assessing orthographic processing ability, reading history, current reading ability, and verbal intelligence in university students. Pronounceable and unpronounceable nonword primes preceded word and nonword targets. Individual differences in nonword reading skill and other measures of reading and spelling ability were associated with the degree of orthographic priming. Individuals with less phonological decoding skill benefited more from anagram primes for word targets preceded by unpronounceable primes and nonword targets preceded by pronounceable primes. Analyses of extreme groups revealed that the group with the lowest phonemic decoding efficiency scores showed a general benefit of orthographic relatedness, while the group with the highest phonemic decoding efficiency scores showed a benefit only under certain conditions. Thus, individuals with worse nonword reading skills may have less precise orthographic representations and therefore benefit more from overlapping coarse-grained orthographic information, regardless of the pronounceability of the prime or the lexical status of the target. These findings demonstrate that university students vary in their orthographic processing skill and the degree to which orthographic information is used during word recognition.	orthographic projection;priming exercise;anagrams;spelling	Suzanne E. Welcome;Emma R. Trammel	2017	Cognitive Processing	10.1007/s10339-017-0793-x	psychology;speech recognition;linguistics;communication	HCI	-9.206824573505314	-78.38869674467755	140874
6018328a38a196a325f5b8ba5552701ed8f69f8b	zero-shot sequence labeling: transferring knowledge from sentences to tokens		Can attentionor gradient-based visualization techniques be used to infer token-level labels for binary sequence tagging problems, using networks trained only on sentence-level labels? We construct a neural network architecture based on soft attention, train it as a binary sentence classifier and evaluate against tokenlevel annotation on four different datasets. Inferring token labels from a network provides a method for quantitatively evaluating what the model is learning, along with generating useful feedback in assistance systems. Our results indicate that attention-based methods are able to predict token-level labels more accurately, compared to gradient-based methods, sometimes even rivaling the supervised oracle network.	artificial neural network;bitstream;gradient;network architecture;sequence labeling	Marek Rei;Anders Søgaard	2018			artificial intelligence;machine learning;pseudorandom binary sequence;sequence labeling;artificial neural network;oracle;architecture;binary number;computer science;sentence;annotation	NLP	-17.37049235977011	-73.98922485368598	141094
de155b7c0a95994ad67eb8eb7a5fbc3593022df4	using knowledge to understand		It has been apparent to researchers within the domain of natural language understanding for some time that the eventual limit to our solution of that problem would be our ability to characterize world knowledge. In order to build a real understanding system it will be necessary to organize the knowledge that facilitates understanding. We view the process of understanding as the fitting in of new information into a previously organized view of the world. Thus we would extend our previous view of language analysis (Schank [1973] and Riesbeck [1974]) to the problem of understanding in general. That is, a language processor is bottom up until it gets enough information to enable it to make predictions and become top down. Input sentences (like input words in intra-sentence analysis) set up expectations about what is likely to follow in the text. These expectations arise from the world knowledge that pertains to a given situation, and it is these expectations that we wish to explore here.	commonsense knowledge (artificial intelligence);natural language processing;natural language understanding;top-down and bottom-up design	Roger C. Schank	1975		10.3115/980190.980223	artificial intelligence;natural language processing;computer science	NLP	-9.316805393823008	-76.20014762834971	141317
ebfd3d3bdfe0a61b7434ff79d51a5020b0afff01	an empirical symbolic approach to natural language processing	comparative analysis;empirical method;probabilistic system;probabilistic model;learning system;large scale;knowledge acquisition;natural language processing;knowledge base	Empirical methods in the field of natural language processing (NLP) are usually based on a probabilistic model of language. These methods recently gained popularity because of the claim that they provide a better coverage of language phenomena. Though this claim is not entirely proved, empirical methods certainly outperform in this regard rationalist, or symbolic, methods. However, empirical methods provide a probabilistic, not conceptual, explanation of the analyzed linguistic phenomena. Probabilistic systems do “work” in real applications, and this is meritorious, but in our view they are intrinsically unable to provide insight into the mechanisms of human communication, because the output is represented by plain words, or word clusters, with attached probabilities. Eventually, a human analyst must make sense of these data. In the past few years, we explored the possibility of combining the advantages of empirical and rationalist approaches in NLP. Our objective was to define methods for lexical knowledge acquisition that are both scalable and linguistically “appealing”, that is, amenable to a theoretically founded analysis of language. In this paper we describe and evaluate the results of a large-scale lexical learning system, ARIOSTO_LEX, that uses a combination of probabilistic and knowledge-based methods for the acquisition of selectional restrictions of words in sublanguages. We present many experimental data obtained from different corpora in different domains and languages, and show that the acquired lexical data not only have practical applications in NLP, but they are indeed useful for a comparative analysis of sublanguages. Importantly, ARIOSTO_LEX shed light on recurrent linguistic phenomena that have a problematic impact on the large-scale applicability of commonly used NLP techniques. * Corresponding author. E-mail: basiIi@info.utovrm.it. 1 E-mail: pazienza@info.utovrm.it. * E-mail: velardi@anvaxl.cineca.it. 0004-3702/96/$15.00 Copyright	algorithm;artificial intelligence;brill tagger;central processing unit;class hierarchy;cluster analysis;cognition;computation;conceptual clustering;control table;data model;grand challenges;high- and low-level;high-level programming language;human-readable medium;image scaling;knowledge acquisition;knowledge base;lexicographical order;lexicon;natural language processing;norsk data;p (complexity);pa-risc;performance evaluation;principle of good enough;ps (unix);qualitative comparative analysis;really simple discovery;relational model;scalability;software portability;source lines of code;statistical model;sublanguage;test engineer;text corpus;ultima online;uranium dioxide;victor basili;word-sense disambiguation;wordnet	Roberto Basili;Maria Teresa Pazienza;Paola Velardi	1996	Artif. Intell.	10.1016/0004-3702(95)00116-6	natural language processing;qualitative comparative analysis;statistical model;knowledge base;computer science;artificial intelligence;data mining;mathematics;empirical research	NLP	-16.321329953917722	-73.462566256685	141599
7ee3b42b53c05bef81704a10c7936bc604ec1e83	a model of the time course and content of reading	time course	This paper describes a computer simulation of reading that is strongly driven by eye fixation data from human readers. The simulation, READER, is a natural language understanding system that reads a text word by word and whose processing cycles on each word have some correspondence with the human gaze duration on that word. READER operates within a newly developed information processing architecture, a Collaborative, Activation-based, Production System (CAPS) that permits the modeling of the temporal properties of human comprehension. CAPS allows for concurrent, collaborative execution of processes operating at different levels of analysis. As READER encounters each successive word, the word is operated on by processes at the levels of word encoding, lexical access, syntactic and semantic analysis, and referential and schema-level processes. Like human readers, READER uses a strategy of immediacy of comprehension, attempting to interpret each word as soon as it is encountered, rather than unnecessarily buffering information. A major contribution of this simulation is its use of human performance characteristics in constraining and determining the model's mechanisms.	computer simulation;concurrent computing;human reliability;information processing;lexicon;list comprehension;natural language understanding;production system (computer science)	Robert H. Thibadeau;Marcel Adam Just;Patricia Carpenter	1982	Cognitive Science	10.1207/s15516709cog0602_2	psychology;natural language processing;word recognition;computer science;word lists by frequency;linguistics;communication	NLP	-8.140631451375032	-78.09034040955186	142062
07756c6781b868fa9054e6d3ec48963adb06df0f	improved blstm neural networks for recognition of on-line bangla complex words	bangla text;blstm nn;complex temporal pattern;handwritten text	While bi-directional long short-term (BLSTM) neural network have been demonstrated to perform very well for English or Arabic, the huge number of different output classes (characters) encountered in many Asian fonts, poses a severe challenge. In this work we investigate different encoding schemes of Bangla compound characters and compare the recognition accuracies. We propose to model complex characters not as unique symbols, which are represented by individual nodes in the output layer. Instead, we exploit the property of long-distance-dependent classification in BLSTM neural networks. We classify only basic strokes and use special nodes which react to semantic changes in the writing, i.e., distinguishing inter-character spaces from intra-character spaces. We show that our approach outperforms the common approaches to BLSTM neural network-based handwriting recognition considerably.	handwriting recognition;long short-term memory;neural networks;online and offline;optical character recognition	Volkmar Frinken;Nilanjana Bhattacharya;Seiichi Uchida;Umapada Pal	2014		10.1007/978-3-662-44415-3_41	natural language processing;speech recognition;computer science;pattern recognition	AI	-16.025706811460946	-77.6907614519189	142152
1656dfc45fcdf9b46c668c1e9ca978161bc2da6a	phonological encoding of sentence production	social and behavioral sciences	Previous tests of the phonological competition model (Dell, 1986) have mostly investigated the effects of phonological overlap (e.g. pick-pin) in isolated word production (e.g. primed picture naming). This is problematic since recent findings suggest that the effect of phonological overlap depends on the syntactic category of the phonologically related words, and few previous studies investigate phonological planning in the context of grammatical strings. We introduce a novel paradigm to examine two predictions of the so called parallel-then-sequential competition model (O‟Seaghdha and Marin, 2000) against data from the distribution of disfluencies in sentence production. We also extend previous work by comparing different forms of phonological overlap (identity vs. similarity) in both word onsets and rhymes.	programming paradigm	Caitlin Hilliard;Katrina E Furth;T. Florian Jaeger	2011			psychology;cognitive psychology;natural language processing;linguistics	NLP	-11.275711210667325	-79.98755958698828	142219
5ec8bbad4d594b104f37f1e04dd9a647e447aab6	the prediction of character based on recurrent neural network language model		This paper mainly talks about the Recurrent Neural Network and introduces a more effective neural network model named LSTM. Then, the paper recommends a special language model based on Recurrent Neural Network. With the help of LSTM and RNN language models, program can predict the next character after a certain character. The main purpose of this paper is to compare the LSTM model with the standard RNN model and see their results in character prediction. So we can see the huge potential of Recurrent Neural Network Language Model in the field of character prediction.	artificial neural network;language model;long short-term memory;network model;random neural network;recurrent neural network	Zejian Shi;Minyong Shi;Chunfang Li	2017	2017 IEEE/ACIS 16th International Conference on Computer and Information Science (ICIS)	10.1109/ICIS.2017.7960065	deep learning;artificial neural network;physical neural network;time delay neural network;recurrent neural network;language model;machine learning;artificial intelligence;computer science	NLP	-16.96906305864544	-72.44530031400203	142410
67c8734bd4b53b2d2ecf6e199ca638ef953adac4	measurement of the distance between recognition categories by interference experiment	dual task;psychology;interference;face recognition;interference diseases face recognition delay space technology knowledge engineering forgery image recognition hemorrhaging neoplasms;visual perception;psychology visual perception face recognition interference;cerebral disease cerebral recognition categories inter category distance measurement visual sense figure recognition language recognition face recognition visual tasks selective interference dual task method task modality cognitive distance	In the case of doing two things at the same time, if each task uses the same modality (e.g. visual sense) then they interfere with each other, but if each uses a different one (e.g. visual sense and auditory sense) then they don't interfere. We noticed interference between same-modality tasks in this study, and we examined whether there was any strength or weakness of the interference in each cerebral recognition category (figures, languages, faces) in experiments where selective interference occurred when carrying out two visual trials at the same time (dual-task method). Furthermore, we also measured the cognitive distance between each recognition category. From the results, we found that interference is strong in the face category, the distance of facial cognition is close to that of both figures and languages, and the facial cognitive position exists in the middle of the other two categories.	interference (communication)	Akihiko Sugiura;Keiichi Yonemura	2001		10.1109/ICSMC.2001.969848	facial recognition system;computer vision;speech recognition;visual perception;computer science;interference	Vision	-5.580896937247157	-76.23841469547297	142491
6c128e2a8058819ad031894989ceed8126136fc3	on the necessity of u-shaped learning	self referential programs;cognitive development;u shaped learning;mathematical necessity;computability theoretic learning theory;learning criteria	A U-shaped curve in a cognitive-developmental trajectory refers to a three-step process: good performance followed by bad performance followed by good performance once again. U-shaped curves have been observed in a wide variety of cognitive-developmental and learning contexts. U-shaped learning seems to contradict the idea that learning is a monotonic, cumulative process and thus constitutes a challenge for competing theories of cognitive development and learning. U-shaped behavior in language learning (in particular in learning English past tense) has become a central topic in the Cognitive Science debate about learning models. Antagonist models (e.g., connectionism versus nativism) are often judged on their ability of modeling or accounting for U-shaped behavior. The prior literature is mostly occupied with explaining how U-shaped behavior occurs. Instead, we are interested in the necessity of this kind of apparently inefficient strategy. We present and discuss a body of results in the abstract mathematical setting of (extensions of) Gold-style computational learning theory addressing a mathematically precise version of the following question: Are there learning tasks that require U-shaped behavior? All notions considered are learning in the limit from positive data. We present results about the necessity of U-shaped learning in classical models of learning as well as in models with bounds on the memory of the learner. The pattern emerges that, for parameterized, cognitively relevant learning criteria, beyond very few initial parameter values, U-shapes are necessary for full learning power! We discuss the possible relevance of the above results for the Cognitive Science debate about learning models as well as directions for future research.	cognitive science;computational learning theory;connectionism;language identification in the limit;languages;learning disorders;mathematics;natural language processing;population parameter;rem sleep behavior disorder;relevance;tension;cognitive development	Lorenzo Carlucci;John Case	2013	Topics in cognitive science	10.1111/tops.12002	psychology;cognitive psychology;proactive learning;multi-task learning;cooperative learning;error-driven learning;algorithmic learning theory;developmental psychology;sequence learning;epistemology;computer science;artificial intelligence;machine learning;mathematics;sociology;active learning;cognitive development;action learning;social psychology;cognitive science	ML	-9.929617546313374	-75.42907377333479	142643
63e710db25744d4512ddc8c04898aa95d735114c	a deep learning based multi-task ensemble model for intent detection and slot filling in spoken language understanding		An important component of every dialog system is understanding the language popularly known as Spoken Language Understanding (SLU). Intent detection (ID) and slot filling (SF) are the two very important and inter-related tasks of SLU. In this paper, we propose a deep learning based multi-task ensemble model that can perform both intent detection and slot filling tasks together. We use a deep bi-directional recurrent neural network (RNN) with long short term memory (LSTM) and gated recurrent unit (GRU) as the base-level classifiers. A multi-layer perceptron (MLP) framework is used to combine the outputs together. A combined word embedding representation is used to train the model obtained from both Glove and word2vec. This is further augmented with the syntactic Part-of-Speech (PoS) information. On the benchmark ATIS dataset, our experiments show that the proposed ensemble multi-task model (MTM) achieves better results than the individual models and the existing state-of-the-art systems. Experiments on the another dataset, TRAINS also proves that the proposed multi-task ensemble model is more effective compared to the individual models.		Mauajama Firdaus;Shobhit Bhatnagar;Asif Ekbal;Pushpak Bhattacharyya	2018		10.1007/978-3-030-04212-7_57	perceptron;word2vec;word embedding;speech recognition;machine learning;deep learning;recurrent neural network;computer science;spoken language;ensemble forecasting;dialog system;artificial intelligence	NLP	-18.646545632251176	-72.23334350608938	143017
42278656d8994fb93e36c58497f5cbe7bf216d68	adaptive melodic segmentation and motivic identification		The existence of meaningful patterns within musical contexts is undeniable, but the abstract nature of the language makes reliable detection of these relationships by machine a notoriously difficult task. This paper will briefly discuss the unique difficulties associated with musical data mining and propose an autonomous system that attempts to overcome the present challenges through the application of observations in music cognition research as a basis for adaptive algorithms capable of isolating and describing fundamental schemata (motivic structures) in addition to their likely variations. Through application of this system, it may be possible to delineate the relevant vectors in order to abstractly represent characteristics that grant thematic identity to a specific work, style, or genre; in effect providing a detailed musical fingerprint.		Greg Wilder	2008			melody;artificial intelligence;segmentation;computer science;pattern recognition	ML	-5.918938611342652	-73.95206302070798	143183
30a3eee5e9302108416f6234d739373dde68d373	learning to count objects in natural images for visual question answering		Visual Question Answering (VQA) models have struggled with counting objects in natural images so far. We identify a fundamental problem due to soft attention in these models as a cause. To circumvent this problem, we propose a neural network component that allows robust counting from object proposals. Experiments on a toy task show the effectiveness of this component and we obtain state-of-theart accuracy on the number category of the VQA v2 dataset without negatively affecting other categories, even outperforming ensemble models with our single model. On a difficult balanced pair metric, the component gives a substantial improvement in counting over a strong baseline by 6.6%.	artificial neural network;asch conformity experiments;balanced line;baseline (configuration management);ensemble forecasting;question answering	Yan Zhang;Jonathon S. Hare;Adam Prügel-Bennett	2018	CoRR		artificial intelligence;machine learning;pattern recognition;question answering;computer science;artificial neural network;ensemble forecasting	ML	-12.759114987451685	-69.7478922831804	143292
d97783f36b4424779bde61326bd4699857c57a62	propagation filters in pds networks for sequencing and ambiguity resolution	ambiguity resolution	We present a Parallel Distributed Semantic (PDS) Network architecture that addresses the problems of sequencing and ambiguity resolution in natural language understanding. A PDS Network stores phrases and their meanings using multiple PDP networks, structured in the form of a semantic net. A mechanism called Propagation Filters is employed: (1) to control communication between networks, (2) to properly sequence the components of a phrase, and (3) to resolve ambiguities. Simulation results indicate that PDS Networks and Propagation Filters can successfully represent high-level knowledge, can be trained relatively quickly, and provide for parallel inferencing at the knowledge level.	high- and low-level;knowledge level;natural language understanding;network architecture;particle filter;semantic network;simulation;software propagation	Ronald A. Sumida;Michael G. Dyer	1991			computer vision;computer science;algorithm	ML	-16.396139384513674	-73.06128875676954	143313
b2a01c4e4d4cb0caea328560bf7813f6b1243adb	"""300 w: special issue on facial landmark localisation """"in-the-wild"""""""			language localisation	Stefanos P. Zafeiriou;Georgios Tzimiropoulos;Maja Pantic	2016	Image Vision Comput.	10.1016/j.imavis.2016.03.009		Vision	-6.171664625653209	-68.6852883041464	143511
79687964134b6dab914330e21721ffd996bf0bcf	motor influences on grammar in an emergentist model of phonology		Any account aiming to provide a comprehensive picture of children’s acquisition of speech must consider both the development of the phonological grammar and the maturation of the structures and motor skills used to implement the sounds of a language. Much previous literature has been marked by a tendency to draw sharp demarcations between motor and grammatical inf luences, or to assert that all of child speech can be reduced to one or the other. This paper argues that it is neither necessary nor desirable to segregate speech-motor development from grammatical development when modeling speech acquisition, because they are fundamentally intertwined. The paper focuses on bringing together two literatures that have evolved largely independently. The first explores how speech-motor patterns practiced during babbling come to be disproportionately represented in the lexicon in children’s earliest stages of meaningful speech. The second posits that abstract elements of phonology – segments, features, and constraints – can be understood to emerge from generalizations over storedmemory traces at a more holistic level.We argue that an emergentist model of phonological learning can be enhanced by incorporating the insight that memory traces of strings that have been heard and produced are encoded more robustly than strings that have only been heard.	emergentism;holism;lexicon;speech acquisition;tracing (software)	Tara McAllister Byun;Anne-Michelle Tessier	2016	Language and Linguistics Compass	10.1111/lnc3.12205	natural language processing;generative grammar;linguistics;communication	NLP	-8.542478749434128	-79.33711669965616	143570
acf7dd2137dc79e99733311b1f3cb704f876e15e	syntactic realization with data-driven neural tree grammars		A key component in surface realization in natural language generation is to choose concrete syntactic relationships to express a target meaning. We develop a new method for syntactic choice based on learning a stochastic tree grammar in a neural architecture. This framework can exploit state-of-the-art methods for modeling word sequences and generalizing across vocabulary. We also induce embeddings to generalize over elementary tree structures and exploit a tree recurrence over the input structure to model long-distance influences between NLG choices. We evaluate the models on the task of linearizing unannotated dependency trees, documenting the contribution of our modeling techniques to improvements in both accuracy and run time.	deep learning;encode;interaction;knowledge-based systems;natural language generation;parsing;run time (program lifecycle phase);software documentation;sparse matrix;top-down and bottom-up design;vocabulary	Brian McMahan;Matthew Stone	2016			natural language processing;artificial intelligence;indexed grammar;phrase structure grammar;tree-adjoining grammar;syntax;l-attributed grammar;syntactic predicate;context-sensitive grammar;computer science;definite clause grammar	NLP	-18.422071608715033	-74.37265496554849	143827
fd0e99d103c3e6f1a3e78b3d2f8267ea87917676	order matters: distributional properties of speech to young children bootstraps learning of semantic representations		Some researchers claim that language acquisition is critically dependent on experiencing linguistic input in order of increasing complexity. We set out to test this hypothesis using a simple recurrent neural network (SRN) trained to predict word sequences in CHILDES, a 5-million-word corpus of speech directed to children. First, we demonstrated that age-ordered CHILDES exhibits a gradual increase in linguistic complexity. Next, we compared the performance of two groups of SRNs trained on CHILDES which had either been age-ordered or not. Specifically, we assessed learning of grammatical and semantic structure and showed that training on age-ordered input facilitates learning of semantic, but not of sequential structure. We found that this advantage is eliminated when the models were trained on input with utterance boundary information removed.	artificial neural network;childes;recurrent neural network	Philip A. Huebner;Jon A. Willits	2018	CoRR		cognitive psychology;language acquisition;psychology;utterance;linguistic sequence complexity;recurrent neural network;childes	NLP	-10.958474921865951	-77.2168087047091	144103
2619587e20bfded0ff7db15ff6018d260e9c84cf	neural evidence that utterance-processing entails mentalizing: the case of irony	pragmatics;fmri;theory of mind;language;irony;ppi	"""It is now well established that communicators interpret others' mental states through what has been called """"Theory of Mind"""" (ToM). From a linguistic-pragmatics perspective, this mentalizing ability is considered critical because it is assumed that the linguistic code in all utterances underdetermines the speaker's meaning, leaving a vital role for ToM to fill the gap. From a neuroscience perspective, understanding others' intentions has been shown to activate a neural ToM network that includes the right and left temporal parietal junction (rTPJ, lTPJ), the medial prefrontal cortex (MPFC) and the precuneus (PC). Surprisingly, however, there are no studies - to our knowledge - that aim to uncover a direct, on-line link between language processing and ToM through neuroimaging. This is why we focus on verbal irony, an obviously pragmatic phenomenon that compels a listener to detect the speaker's (dissociated, mocking) attitude (Wilson, 2009). In the present fMRI investigation, we compare participants' comprehension of 18 target sentences as contexts make them either ironic or literal. Consider an opera singer who tells her interlocutor: """"Tonight we gave a superb performance!"""" when the performance in question was clearly awful (making the statement ironic) or very good (making the statement literal). We demonstrate that the ToM network becomes active while a participant is understanding verbal irony. Moreover, we demonstrate - through Psychophysiological Interactions (PPI) analyses - that ToM activity is directly linked with language comprehension processes. The paradigm, its predictions, and the reported results contrast dramatically with those from seven prior fMRI studies on irony."""	assumed;cerebral cortex;departure - action;formal language;intention - mental process;interaction;irony;linguistics;list comprehension;literal (mathematical logic);medial graph;mental state;mock object;neuroimaging;neuroscience discipline;online and offline;pixel density;prefrontal cortex;programming paradigm;structure of precuneus;fmri;sentence	Nicola Spotorno;Eric Koun;Jérôme Prado;Jean-Baptiste Van der Henst;Ira A. Noveck	2012	NeuroImage	10.1016/j.neuroimage.2012.06.046	psychology;cognitive psychology;u.s. producer price index;language;communication;social psychology;pragmatics	NLP	-8.718351332803358	-78.2202787932	144133
42b543b4e8b97931484441096fdd712667f0fd05	lexical information for determining japanese unbounded dependency	japanese unbounded dependency;utilizing modification preference;japanese sentence;practical method;function word;global structure;encapsulation power;japanese long sentence;encapsulating power;japanese function word;lexical information;conjunctive particle	This paper presents a practical method for a global structure analyzing Mgorithm of Japanese long sentences with lexical information, a method which we call Lexical Discourse Grammar (LDG). This method assumes that .Japanese function words, such as conjunctive particles (postpositions) located at the end of each clause, have modality and suggest global structures of Japanese long sentences in cooperation with modality within predicates or auxiliary verbs. LDG classifies the encapsulating powers of function words into six levels, and modality in predicates into four types. LDG presumes tile inter-clausal dependency within Japanese sentences prior to syntactic and semantic analyses, by utilizing the differences of the encapsulating powers each Japanese function word has, and by utilizing modification preference between function words and predicates that reflects consistency of modality in them. In order to confirm the encapsulation power of Japanese function words, we analyzed the speech utterances of a male announcer and found the correlation between a particle's encapsulating power and the pause length inserted after the clause with a conjunctive particle. 1 I n t r o d u c t i o n When analyzing long sentences with two or more predicates (i.e. compound and complex sentences), it is difficult to grasp the proper structure of sentences having a large nmnber of possible dependency (modifiermodifee relation) structures. This difficulty is more marked in Japanese than in English, since there are more syntactically ambiguous structures in Japanese. Tile Japanese language has few syntactic indicators for dividing sentences into phrases or clauses, unlike English with its relative pronouns and subordinate conjunctions. One of the most critical features of Japanese is that the difference between a phra~se and a clause is not cleat'. Even subjects or other obligatory elements of clauses are omitted very often when they aye indicated by contexts. In addition, the Japanese language does not have any parts of speech to clearly indicate either the beginning or end of a phrase or a clause. Another critical feature is that the Japanese language is an almost pure Head-final language, i.e., predicates and function words to signify the sentence structure appear at the end of the clause or sentence. This means that it is syntactically possible for all phrases or clauses that can modit) predicates to modify all other phrases or clauses that appear in the latter part of long sentences. These syntactic characteristics of the Japanese language make it difficult to determine the dependency (modification) structure of hmg sentences. Simple parsing of Japanese long sentences inevitably produces a huge number of possible modification structures. A conventional bottom-up parsing method can reduce ambiguity in modification by local information in tim surface structure. However, this inclines toward an improper output, since the locally highest likelihood is sometimes low on the whole. To overcome this problem, several methods to predict the global structure of long sentences have been proposed. One is a top-down parsing method by matching the input sentence and the domain-specific patterns (Furuse et al., 1992). Improvements made by other researchers enabled this method to parse irregular, incomplete and multiplex patterns, by describing the domain-dependent patterns in the form of grammar (Doi, Muraki, et M., 1993). Another method employs global structure presumption to divide a sentence into clauses by utilizing general lexical information. It predicts the sentence structure prior to syntactic analysis only by utilizing domain-independent lexical information such as conjunctive particles, parallel expressions, theme transition, etc. (Mizuno et al., 1990; Kurohashi et al., 1992). Lexical Discourse Grammar (LDG) is one of the approaches with which a global structure of a long sentence is presumed by focusing on function words (Kamei et al, 1986; Doi et al., 1991). LDG assumes that Japanese function words, such as conjunctive partides (postpositions) located at the end of each clause, convey modMity, or propositional attitude, and suggest global structures of Japanese long sentences in cooperation with modality in predicates, especially within	ambiguous grammar;bottom-up parsing;conjunctive normal form;discourse grammar;encapsulation (networking);modality (human–computer interaction);multiplexing;predicate (mathematical logic);top-down and bottom-up design;top-down parsing;word lists by frequency	Shin-ichiro Kamei;Kazunori Muraki;Shinichi Doi	1996			natural language processing;computer science;linguistics	NLP	-11.64677540163244	-79.27069368409389	144253
4b24c11b748d81f14d901d0017b9309f1f51ed38	improving biomedical document retrieval using domain knowledge	information retrieval;explicit knowledge;domain knowledge;link analysis;document retrieval;latent semantic analysis	Research articles typically introduce new results or findings and relate them to knowledge entities of immediate relevance. However, a large body of context knowledge related to the results is often not explicitly mentioned in the article. To overcome this limitation the state-of-the-art information retrieval approaches rely on the latent semantic analysis in which terms in articles are projected to a lower dimensional latent space and best possible matches in this space are identified. However, this approach may not perform well enough if the number of explicit knowledge entities in the articles is too small compared to the amount of knowledge in the domain. We address the problem by exploiting a domain knowledge layer, a rich network of relations among knowledge entities in the domain extracted from a large corpus of documents. The knowledge layer supplies the context knowledge that lets us relate different knowledge entities and hence improve the information retrieval performance. We develop and study a new framework for i) learning and aggregating the relations in the knowledge layer from the literature corpus; ii) and for exploiting these relations to improve the information-retrieval of relevant documents.	document retrieval;entity;hilbert space;information retrieval;latent semantic analysis;relevance;text corpus	Shuguang Wang;Milos Hauskrecht	2008		10.1145/1390334.1390503	natural language processing;document retrieval;knowledge base;explicit semantic analysis;link analysis;latent semantic analysis;computer science;explicit knowledge;body of knowledge;knowledge-based systems;open knowledge base connectivity;data mining;knowledge extraction;information retrieval;domain knowledge	Web+IR	-18.02295325113943	-67.68527455409694	144277
ecb01de21b716bd3df5b58b5715949010dc29b11	efficient processing the braille music notation	music representation;knowledge processing;music data processing;data understanding	Problem stated here is connected with music information processing, especially with Braille music notation. The main objective of this paper is usage of semantics for optimization of Braille music scores processing. This issue is important in the area of huge Braille music scores. Our approach is based on structuring – both syntactical and semantic – in spaces of music information. Optimization would not be possible without such structuring. The main idea is connected with logical score partitioning into smaller pieces that are weakly dependent between each other. Optimization is based on closing changes to small syntactical and semantic items of the structure. Each change during editing touches on of such small items instead of processing significant parts of the whole structure.	algorithm;closing (morphology);information processing;mathematical optimization;printing;shadow volume	Tomasz Sitarek;Wladyslaw Homenda	2012		10.1007/978-3-642-33260-9_29	natural language processing;speech recognition;computer science;pop music automation	AI	-9.32672725413985	-72.93786489206718	144409
88a873f07a4683b12a92c1f68f42b623da329b65	uniqueness and possession: typological evidence for type shifts in nominal determination	definiteness;alienability;type shift;compositional semantics;typology;possession;definite articles	This paper highlights the analogy of definiteness and possession by utilising the distinction between semantic and pragmatic as outlined in Löbners (2011) Concept Type and Determination approach. Assuming, on the basis of the features [± unique] and [± relational], a classification into the four logical types sortal, relational, individual, and functional concept, nouns will be used either in congruence with or deviating from their underlying type. I present evidence from Germanic and Mayan languages for the following claims: (1) noun uses that deviate from the underlying type tend to be reflected by overt morphology. (2) In article split languages, phonologically ’strong’ forms indicate pragmatic uniqueness, thus, denote a function from [− unique] to [+ unique], whereas ‘weak’ forms tend to be semantically redundant. Regarding possession, ‘alienable’ morphology denotes a function from non-relational to relational (pragmatic possession), whereas ‘inalienable’ morphology is restricted to semantic possession. Overall, split systems imply a strong correlation between conceptual markedness and morphosyntactic markedness.	anaphora (linguistics);congruence of squares;galaxy morphological classification;logical connective;marker interface pattern;mathematical morphology;natural language;operational semantics	Albert Ortmann	2013		10.1007/978-3-662-46906-4_14	arithmetic;typology;mathematics;linguistics;sociology;possession;algorithm;principle of compositionality	NLP	-9.708983672464456	-77.1457928061727	144790
9ca4469c5473412bf0aaa41f23b987a46a720a02	sparse category labels obstruct generalization of category membership	social and behavioral sciences	Studies of human category learning typically focus on situations where explicit category labels accompany each example (supervised learning) or on situations were people must infer category structure entirely from the distribution of unlabeled examples (unsupervised learning). However, real-world category learning likely involves a mixture of both types of learning (semi-supervised learning). Surprisingly, a number of recent ndings suggest that people have difficulty learning in semisupervised tasks. To further explore this issue, we devised a category learning task in which the distribution of labeled and unlabeled items suggested alternative organizations of a category. is design allowed us to determine whether learners combined information from both types of episodes via their patterns of generalization at test. In contrast with the prediction of manymodels, we nd little evidence that unlabeled items inuenced categorization behavior when labeled items were also present.	categorization;category theory;concept learning;semi-supervised learning;semiconductor industry;sparse;supervised learning;unsupervised learning	John V. McDonnell;Carol A. Jew;Todd M. Gureckis	2012			psychology;machine learning;pattern recognition;mathematics;social psychology	ML	-7.4804358101450275	-75.84907480881347	144844
79c6f1f5f1342cf0852c72b37217e448ae538575	large-scale multitask learning for machine translation quality estimation		Multitask learning has been proven a useful technique in a number of Natural Language Processing applications where data is scarce and naturally diverse. Examples include learning from data of different domains and learning from labels provided by multiple annotators. Tasks in these scenarios would be the domains or the annotators. When faced with limited data for each task, a framework for the learning of tasks in parallel while using a shared representation is clearly helpful: what is learned for a given task can be transferred to other tasks while the peculiarities of each task are still modelled. Focusing on machine translation quality estimation as application, in this paper we show that multitask learning is also useful in cases where data is abundant. Based on two large-scale datasets, we explore models with multiple annotators and multiple languages and show that state-of-the-art multitask learning algorithms lead to improved results in all settings.	algorithm;computer multitasking;experiment;machine learning;machine translation;natural language processing;query expansion	Kashif Shah;Lucia Specia	2016			artificial intelligence;computer science;natural language processing;machine learning;machine translation;multi-task learning	NLP	-17.351974754842697	-68.7997469290281	144857
fbc8dd828a62804f0fc5c9e70b568d62b0d1a883	a question routing technique using deep neural network for communities of question answering		Online Communities for Question Answering (CQA) such as Quora and Stack Overflow face the challenge of providing high quality answers to the questions asked by their users. Although CQA frameworks receive new questions in a linear rate, the rate of the unanswered questions increases in an exponential way. This variation eventually compromise effectiveness of the CQA frameworks as knowledge sharing platforms. The main cause for this challenge is the improper routing of questions to the potential answerers, field experts or interested users. The proposed technique QR-DSSM uses deep semantic similarity model (DSSM) to extract semantic similarity features using deep neural networks. The extracted semantic features are used to rank the profiles of the answerers by their relevance the routed question. QR-DSSM maps the asked questions and the profiles of the users into a latent semantic space where the relevance is measured using cosine similarity between the two; questions and users’ profiles. QR-DSSM achieved MRR score of 0.1737. QR-DSSM outperformed the baseline models such as query likelihood language model (QLLM), Latent Dirichlet Allocation (LDA), SVM classification technique and RankingSVM learning to rank technique.	deep learning;question answering;routing	Amr Azzam;Neamat Tazi;Ahmad Hany Hossny	2017		10.1007/978-3-319-55753-3_3	machine learning;data mining;information retrieval	NLP	-18.701981291481374	-66.55312283705932	144873
ae6944dba31baf5a15a2f4903b7c67c061b8c90f	phonological abstraction in processing lexical-tone variation: evidence from a learning paradigm	procesamiento informacion;learning;habla;episodic models;etude experimentale;lexicon;lenguaje;abstraction;hombre;speech;langage;percepcion;chino;abstraccion;speech perception;proceso adquisicion;acquisition process;verbal perception;aprendizaje;mandarin chinese;modelo;apprentissage;percepcion verbal;phonological abstraction;phonology;lexical tone;cognition;information processing;human;cognicion;audition;fonologia;modele;phonologie;audicion;parole;language;perception;lexico;traitement information;chinois;chinese;estudio experimental;models;processus acquisition;hearing;homme;perception verbale;lexique	There is a growing consensus that the mental lexicon contains both abstract and word-specific acoustic information. To investigate their relative importance for word recognition, we tested to what extent perceptual learning is word specific or generalizable to other words. In an exposure phase, participants were divided into two groups; each group was semantically biased to interpret an ambiguous Mandarin tone contour as either tone1 or tone2. In a subsequent test phase, the perception of ambiguous contours was dependent on the exposure phase: Participants who heard ambiguous contours as tone1 during exposure were more likely to perceive ambiguous contours as tone1 than participants who heard ambiguous contours as tone2 during exposure. This learning effect was only slightly larger for previously encountered than for not previously encountered words. The results speak for an architecture with prelexical analysis of phonological categories to achieve both lexical access and episodic storage of exemplars.	acoustic cryptanalysis;categories;large;lexicon;programming paradigm;super robot monkey team hyperforce go!;word recognition	Holger Mitterer;Yiya Chen;Xiaolin Zhou	2011	Cognitive science	10.1111/j.1551-6709.2010.01140.x	psychology;natural language processing;speech perception;cognition;information processing;mandarin chinese;speech;abstraction;linguistics;language;communication;perception;chinese;phonology	Vision	-9.84072057571458	-79.41308908770519	145101
edd339c619969ab68c7ac8143c1c5a616fdc4bfb	the neurocognition of referential ambiguity in language comprehension	language comprehension;functional neuroimaging;functional properties;neural system;semantic processing;ambiguity resolution;context dependent;semantic analysis	Referential ambiguity arises whenever readers or listeners are unable to select a unique referent for a linguistic expression out of multiple candidates. In the current article, we review a series of neurocognitive experiments from our laboratory that examine the neural correlates of referential ambiguity, and that employ the brain signature of referential ambiguity to derive functional properties of the language comprehension system. The results of our experiments converge to show that referential ambiguity resolution involves making an inference to evaluate the referential candidates. These inferences only take place when both referential candidates are, at least initially, equally plausible antecedents. Whether comprehenders make these anaphoric inferences is strongly context dependent and co-determined by characteristics of the reader. In addition, readers appear to disregard referential ambiguity when the competing candidates are each semantically incoherent, suggesting that, under certain circumstances, semantic analysis can proceed even when referential analysis has not yielded a unique antecedent. Finally, results from a functional neuroimaging study suggest that whereas the neural systems that deal with referential ambiguity partially overlap with those that deal with referential failure, they show an inverse coupling with the neural systems associated with semantic processing, possibly reflecting the relative contributions of semantic and episodic processing to re-establish semantic and referential coherence, respectively.	anaphora (linguistics);consciousness;converge;experiment;list comprehension	Mante S. Nieuwland;Jos J. A. Van Berkum	2008	Language and Linguistics Compass	10.1111/j.1749-818X.2008.00070.x	psychology;natural language processing;functional neuroimaging;semantic memory;context-dependent memory;linguistics;communication	NLP	-9.076609371160588	-77.26729000470516	145194
da7f6534c3480064369e650133a1256627a3f4dd	teaching classification boundaries to humans	teaching classification;curriculum learning;classification;human learning	Given a classification task, what is the best way to teach the resulting boundary to a human? While machine learning techniques can provide excellent methods for finding the boundary, including the selection of examples in an online setting, they tell us little about how we would teach a human the same task. We propose to investigate the problem of example selection and presentation in the context of teaching humans, and explore a variety of mechanisms in the interests of finding what may work best. In particular, we begin with the baseline of random presentation and then examine combinations of several mechanisms: the indication of an example’s relative difficulty, the use of the shaping heuristic from the cognitive science literature (moving from easier examples to harder ones), and a novel kernel-based “coverage model” of the subject’s mastery of the task. From our experiments on 54 human subjects learning and performing a pair of synthetic classification tasks via our teaching system, we found that we can achieve the greatest gains with a combination of shaping and the coverage model.	baseline (configuration management);cognitive science;experiment;heuristic;humans;machine learning;noise shaping;statistical classification;synthetic intelligence	Sumit Basu;Janara Christensen	2013			simulation;biological classification;computer science;artificial intelligence;machine learning	AI	-9.95725778810071	-74.47892127662213	145277
6265714e46c25d35b2339b4c2ed682f609a35e70	temporal semantic analysis and visualization of words		Today there are many languages spoken in the world, among which English is the most popular one. However, words in English evolved a lot in history such that it is very difficult for contemporary people to read ancient English articles. There are many changes, such as the mutation of word itself, the migration of word usage from one context to another, etc. It is thus very interesting to understand the temporal evolution of word’s semantic across a long span of time. In this paper we look at two datasets: the New York Times and the National Geographic to study the temporal evolution of words. For this purpose a model that can embed word into vectors is needed. Word2Vec is such an neural network model that learns a vector representation for each word in a way that similar words are also similar in the vector space. By similar, I mean that words tends to co-occur in the same context. So, to obtain a temporal Word2Vec representation, a temporal Word2Vec model needs to be trained sequentially, training one individual Word2Vec model for a given dataset in each time period. The temporal Word2Vec model allows us to explore different visualisation techniques of word semantic evolution. Temporal Word cloud, Heatmap, t-distributed stochastic neighbour embedding are some of the techniques that makes the visualisation possible.	artificial neural network;heat map;network model;t-distributed stochastic neighbor embedding;the new york times;word2vec	Zaikun Xu;Fabio Crestani	2017			visualization;computer vision;computer science;artificial intelligence	NLP	-14.738436761066845	-73.99727976550113	145352
5f6ff6990a1afac7e7b5616283b1d4e67a9d034f	a comparison of frequent pattern techniques and a deep learning method for session-based recommendation		Making session-based recommendations, i.e., recommending items solely based on the users’ last interactions without having access to their long-term preference proles, is a challenging problem in various application elds of recommender systems. Using a coarse classication scheme, the proposed algorithmic approaches to this problem in the research literature can be categorized into frequent paern mining algorithms and approaches that are based on sequence modeling. In the context of methods of the laer class, recent works suggest the application of recurrent neural networks (RNN) for the problem. However, the lack of established algorithmic baselines for session-based recommendation problems makes the assessment of such novel approaches dicult. In this work, we therefore compare a state-of-the-art RNN-based approach with a number of (heuristics-based) frequent paern mining methods both with respect to the accuracy of their recommendations and with respect to their computational complexity. e results obtained for a variety of dierent datasets show that in every single case a comparably simple frequent paern method can be found that outperforms the recent RNN-based method. At the same time, the proposed much more simple methods are also computationally less expensive and can be applied within the narrow time constraints of online recommendation.	algorithm;application domain;artificial neural network;baseline (configuration management);categorization;computational complexity theory;deep learning;heuristic (computer science);interaction;markov chain;markov model;os-tan;pa-risc;random neural network;recommender system;recurrent neural network;refresh rate;scientific literature	Iman Kamehkhosh;Dietmar Jannach;Malte Ludewig	2017			data mining;machine learning;deep learning;computer science;artificial intelligence	ML	-18.630030762039006	-67.03959513784189	145429
9906e41c279fce729f2b3d1f75786550f51f72d0	friendly motion learning towards sustainable human robot interaction		For generating interactive behavior of robot to build a long-term relationship between humans and robots, we focus on the difference in familiarity of the human behaviors during conversation. It is difficult to extract interaction motion features correlated to such familiarity as a model in manual. Therefore, we use a machine learning technique: convolution neural network to learn and generate interaction behavior with different familiarity. In the evaluation experiment, we generated interaction behavior using a convolution neural network, which learned from the behaviors of friendship and unknown relationship, who have high and low familiarity respectively. We evaluated how much such interaction behavior affect the human impression by questionnaire survey.		Shuhei Sato;Hiroko Kamide;Yasushi Mae;Masaru Kojima;Tatsuo Arai	2018	2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2018.8593432	conversation;convolutional neural network;artificial intelligence;computer vision;human–computer interaction;artificial neural network;feature extraction;robot;computer science;human behavior;convolution;human–robot interaction	Robotics	-11.790038608665249	-71.03924674736288	145442
6005898fdfa6ecc8fc5341265473de0779aec948	analysis of engagement behavior in children during dyadic interactions using prosodic cues	local level cues;global level cues;engagement;classifier decision fusion;prosody	Child engagement is defined as the interaction of a child with his/her environment in a contextually appropriate manner. Engagement behavior in children is linked to socio-emotional and cognitive state assessment with enhanced engagement identified with improved skills. A vast majority of studies however rely solely, and often implicitly, on subjective perceptual measures of engagement. Access to automatic quantification could assist researchers/clinicians to objectively interpret engagement with respect to a target behavior or condition, and furthermore inform mechanisms for improving engagement in various settings. In this paper, we present an engagement prediction system based exclusively on vocal cues observed during structured interaction between a child and a psychologist involving several tasks. Specifically, we derive prosodic cues that capture engagement levels across the various tasks. Our experiments suggest that a child's engagement is reflected not only in the vocalizations, but also in the speech of the interacting psychologist. Moreover, we show that prosodic cues are informative of the engagement phenomena not only as characterized over the entire task (i.e., global cues), but also in short term patterns (i.e., local cues). We perform a classification experiment assigning the engagement of a child into three discrete levels achieving an unweighted average recall of 55.8% (chance is 33.3%). While the systems using global cues and local level cues are each statistically significant in predicting engagement, we obtain the best results after fusing these two components. We perform further analysis of the cues at local and global levels to achieve insights linking specific prosodic patterns to the engagement phenomenon. We observe that while the performance of our model varies with task setting and interacting psychologist, there exist universal prosodic patterns reflective of engagement.	audio media;automatic control;capture the flag;child behavior disorders;complement system proteins;cross-sectional data;dyadic transformation;entity–relationship model;existential quantification;experiment;global optimization;heart rate variability;information;interaction;language model;linear classifier;modality (human–computer interaction);observable;preparation;projections and predictions;quantitation;rem sleep behavior disorder;semantic prosody;smoothing (statistical technique);span distance;sparse matrix;time series;vocal cord paralysis	Rahul Gupta;Daniel Bone;Sungbok Lee;Shrikanth (Shri) Narayanan	2016	Computer speech & language	10.1016/j.csl.2015.09.003	linguistics;prosody	HCI	-10.78766183193907	-78.0294111802056	145711
94a029f7d9a8683f8cdae7fcb4d04da7f1e0cc44	towards modeling expressed emotions in oral history interviews: using verbal and nonverbal signals to track personal narratives		The article aims to model the verbal and prosodic features of emotional expression in interviews to investigate the potential for synergy between scholarly fields that have the narrative as object of study. Using a digital collection of oral history interviews that contains narrative aspects addressing war and violence in Croatia, we analyzed emotional expression through the words spoken, and through the pitch, vocal effort, and pause duration in the speech signal. The findings were correlated with the linear structure of interviews as well as question type. Our analysis indicates that the weight of emotion words for the overall expressed emotion is stronger in later interview parts as well as after open questions and meaning questions. Similar patterns were found for pitch and pause duration, but not for vocal effort. Although the verbal expression of emotions was somewhat correlated to pause duration, the hypothesized correlation between the verbal and nonverbal features was not confirmed. The research also shows that the various expressive layers in the interviews as well as the relations between them are a suited basis for computational modeling that may help track emotional personal narratives in interview collections. Additional research is needed to further develop the framework for the automated analysis of verbal and nonverbal cues to automatically generate annotations to be used for exploring spoken word collections. ................................................................................................................................................................................. Correspondence:	synergy	Khiet P. Truong;Gerben J Westerhof;Sanne M. A. Lamers;Franciska de Jong	2014	LLC	10.1093/llc/fqu041	natural language processing;speech recognition;linguistics;social psychology	NLP	-8.737643198002791	-79.7329493870545	147014
301d56f6de408f6328baa4f4f5586f7269bb9a6b	sentence relations for extractive summarization with deep neural networks		Sentence regression is a type of extractive summarization that achieves state-of-the-art performance and is commonly used in practical systems. The most challenging task within the sentence regression framework is to identify discriminative features to represent each sentence. In this article, we study the use of sentence relations, e.g., Contextual Sentence Relations (CSR), Title Sentence Relations (TSR), and Query Sentence Relations (QSR), so as to improve the performance of sentence regression. CSR, TSR, and QSR refer to the relations between a main body sentence and its local context, its document title, and a given query, respectively.  We propose a deep neural network model, Sentence Relation-based Summarization (SRSum), that consists of five sub-models, PriorSum, CSRSum, TSRSum, QSRSum, and SFSum. PriorSum encodes the latent semantic meaning of a sentence using a bi-gram convolutional neural network. SFSum encodes the surface information of a sentence, e.g., sentence length, sentence position, and so on. CSRSum, TSRSum, and QSRSum are three sentence relation sub-models corresponding to CSR, TSR, and QSR, respectively. CSRSum evaluates the ability of each sentence to summarize its local contexts. Specifically, CSRSum applies a CSR-based word-level and sentence-level attention mechanism to simulate the context-aware reading of a human reader, where words and sentences that have anaphoric relations or local summarization abilities are easily remembered and paid attention to. TSRSum evaluates the semantic closeness of each sentence with respect to its title, which usually reflects the main ideas of a document. TSRSum applies a TSR-based attention mechanism to simulate people’s reading ability with the main idea (title) in mind. QSRSum evaluates the relevance of each sentence with given queries for the query-focused summarization. QSRSum applies a QSR-based attention mechanism to simulate the attentive reading of a human reader with some queries in mind. The mechanism can recognize which parts of the given queries are more likely answered by a sentence under consideration. Finally as a whole, SRSum automatically learns useful latent features by jointly learning representations of query sentences, content sentences, and title sentences as well as their relations.  We conduct extensive experiments on six benchmark datasets, including generic multi-document summarization and query-focused multi-document summarization. On both tasks, SRSum achieves comparable or superior performance compared with state-of-the-art approaches in terms of multiple ROUGE metrics.	anaphora (linguistics);artificial neural network;automatic summarization;benchmark (computing);centrality;convolutional neural network;deep learning;experiment;multi-document summarization;network model;neural networks;relevance;simulation;traffic sign recognition	Pengjie Ren;Zhumin Chen;Zhaochun Ren;Furu Wei;Liqiang Nie;Jun Ma;Maarten de Rijke	2018	ACM Trans. Inf. Syst.	10.1145/3200864	information retrieval;automatic summarization;rouge;convolutional neural network;discriminative model;artificial neural network;closeness;computer science;sentence;pattern recognition;artificial intelligence	NLP	-17.393511649588653	-70.84318473241875	147725
6cf413f32f48ce62b7835280ee0bfabad315931f	extracting spooky-activation-at-a-distance from considerations of entanglement	data analysis;quantum physics;spreading activation	Following an early claim by Nelson & McEvoy [19] suggesting that word associations can display ‘spooky action at a distance behaviour’, a serious investigation of the potentially quantum nature of such associations is currently underway. This paper presents a simple quantum model of a word association system. It is shown that a quantum model of word entanglement can recover aspects of both the Spreading Activation model and the Spooky model of word association experiments. 1 Modelling Words and Meaning Human beings are adept and drawing context-sensitive associations and inferences across a broad range of situations ranging from the mundane to the creative inferences that lead to scientific discovery. Such reasoning has a strong pragmatic character and is transacted with comparatively scarce cognitive assets. However, despite our apparent proficiency at drawing inferences, and our ability to express words in such a manner that other people can (usually) understand the meaning that we are trying to convey, our theoretical understanding of how this process occurs has been slow to develop. The field of cognitive science has recently produced an ensemble of semantic models which have an encouraging, and at times impressive track record of replicating human information processing, such as human word associations norms [16, 4, 14, 15, 11, 12, 24, 13, 25]. The term “semantic” derives from the intuition that words seen in the context of a given word contribute to its meaning, or, more colloquially expressed, the meaning of a word is derived from the “company it keeps” [8]. In order to progress in our understanding of how meaning is generated from sets of words in a language we must understand the way in which the mental lexicon of that language is generated during language acquisition, and how it works once created in the mind of a specific individual. 1.1 The Mental Lexicon The mental lexicon of a language refers to the words of a language, but its structure is represented by the associative links that bind this vocabulary together. 2 Peter Bruza, Kirsty Kitto, Douglas Nelson, and Cathy McEvoy Such links are acquired through experience and the vast and semi-random nature of this experience ensures that words within this vocabulary are highly interconnected, both directly and indirectly through other words. For example, during childhood development and the associated acquisition of English, the word planet becomes associated with earth, space, moon, and so on. Even within this set, moon can itself become linked to earth and star etc. Words are so associatively interconnected with each other that they meet the qualifications of a ‘small world’ network wherein it takes only a few associative steps to move from any one word to any other in the lexicon [26]. Because of such connectivity individual words are not represented in long-term memory as isolated entities but as part of a network of related words. However, depending upon the context in which they are used, words can take on a variety of different meanings and this is very difficult to model [7]. Much evidence shows that for any individual, seeing or hearing a word activates words related to it through prior learning. Understanding how such activation affects memory requires a map of links among known words, and free association provides one reliable means for constructing such a map [21]. In free association experiments, words are presented to large samples of participants who produce the first associated word to come to mind. The probability or strength of a pre-existing link between words is computed by dividing the production frequency of a response word by its sample size. For example, the probabilities that planet produces earth and mars are 0.61 and 0.10, respectively, and we say that earth is a more likely or a stronger associate of planet than mars. Just like the nonlocality experiments of quantum theory, human memory experiments require very careful preparation of the state to be tested. For example, in extralist cuing, participants typically study a list of to-be-recalled target words shown on a monitor for 3 seconds each (e.g., planet). The study instructions ask them to read each word aloud when shown and to remember as many as possible, but participants are not told how they will be tested until the last word is shown. The test instructions indicate that new words, the test cues, will be shown and that each test cue is related to one of the target words just studied (e.g., universe). These cues are not present during study (hence, the name extralist cuing). As each cue is shown, participants attempt to recall its associatively related word from the study list. In contrast, during intralist cuing the word serving as the test cue is presented with its target during study (e.g., universe planet). Participants are asked to learn the pairing, but otherwise the two tasks are the same. It appears that more associate-to-associate links benefit recall, and two competing explanations for this phenomenon have been proposed: Spreading Activation, and Spooky Activation At a Distance. This paper will demonstrate an intriguing connection between these two explanations, obtained by making the assumption that words can become entangled in the human mental lexicon. Title Suppressed Due to Excessive Length 3 1.2 Isn’t Entanglement Correlation? Entanglement is a phenomenon unique to quantum behaviour. If a system consisting of two components becomes entangled then it cannot be thought of as separate anymore; a description of one component without reference to the other will, in some cases, fail. Indeed, an entangled quantum system will generally exhibit an intercomponent agreement with reference to any combination of measurement settings. This is of particular importance for a system that becomes spatially extended, as in the case where the two components are taken a long way from each other. Here we find that quantum systems display correlation instantaneously in response to what might even be a delayed choice of measurement setting [1], and yet cannot be used to transmit information between two observers, and thus does not actually violate Special Relativity [17]. This is in contrast with classical scenarios of correlation. In a classical situation a system is in a pre-existing state, and this is discovered through the process of measurement. Not so with a quantum system, where the process of measurement can actively influence the outcome itself. This fundamental difference between the two types of system was first alluded to in the by now famous EPR debate, but was only inescapably highlighted with the more subtle (and recent) results surrounding the contextuality of quantum systems (see [10] or [2] for a good introduction to these ideas). An entangled quantum system is very different from a correlated classical system; no pre-existing elements of reality [6] have been found that can explain the agreement that is obtained between distant measuring devices that are set to determine the state of a quantum system. To make these ideas more concrete, let us consider a specific example of classical correlation. If the same number is written on two pieces of paper, enclosed in two envelopes, and sent to Alice and Bob at two distant ends of the Universe, the information obtained upon opening of one of the envelopes will instantly correlate with the state of the other envelope at the other end of the universe. However, these correlated pieces of paper are not entangled. The number on the two pieces of paper can be regarded as a hidden variable, or element of reality; even before we open the envelope it exists, in both envelopes. Upon opening the envelope at one end of the Universe we find out what that number is, and hence know what number is already inscribed upon the other piece of paper. The quantum analogue of this scenario would be far stranger. The situation most similar to the nonlocal effects exhibited by entangled quantum systems would involve Alice, at one end of the Universe choosing to write a number upon her blank piece of paper when she opens her envelope, and then finding that Bob, upon opening his envelope found exactly the same number upon his piece of paper at the other end of the Universe. Obviously this does not happen. However, we might ask if similar cases of intercomponent dependency, or spooky-activation-at-a-distance, exist for systems beyond the field of physics. We shall now look at the problem of modelling associate-to-associate links in the human mental lexicon, before showing how the assumption that associates 4 Einstein–Podolsky–Rosen 4 Peter Bruza, Kirsty Kitto, Douglas Nelson, and Cathy McEvoy might be entangled in a subject’s cognitive state can lead to a new model of word associations. 2 Modelling Associate-to-associate Links Figure 1 shows a hypothetical target word having two target-to-associate links in a subject’s cognitive state. There is also an associate-to-associate link between	action at a distance;alice and bob;cognitive science;context-sensitive grammar;epr paradox;entity;experiment;hidden variable theory;information processing;lexicon;microsoft word for mac;numerical relativity;protologism;quantum entanglement;quantum mechanics;quantum nonlocality;quantum system;semiconductor industry;spreading activation;test case;vocabulary	Peter Bruza;Kirsty Kitto;Douglas L. Nelson;Cathy McEvoy	2009		10.1007/978-3-642-00834-4_8	artificial intelligence;mathematics;spreading activation;data analysis;algorithm;statistics	NLP	-9.000591506986384	-76.19673570332233	147749
2b9024235bc7a601cd7b7127e2577b372e4a3d7d	neural networks for joint sentence classification in medical paper abstracts		Existing models based on artificial neural networks (ANNs) for sentence classification often do not incorporate the context in which sentences appear, and classify sentences individually. However, traditional sentence classification approaches have been shown to greatly benefit from jointly classifying subsequent sentences, such as with conditional random fields. In this work, we present an ANN architecture that combines the effectiveness of typical ANN models to classify sentences in isolation, with the strength of structured prediction. Our model outperforms the state-ofthe-art results on two different datasets for sequential sentence classification in medical abstracts.	conditional random field;neural networks;structured prediction	Franck Dernoncourt;Ji Young Lee;Peter Szolovits	2017			natural language processing;speech recognition;computer science;artificial intelligence;machine learning;pattern recognition	NLP	-18.465442444405745	-71.22552647850024	147952
f55923dfdd16bc1a6ba6a5b4ff61ecb9b42544ff	uphill and downhill in a flat world: the conceptual topography of the yupno house	female;built environment;male;uphill downhill systems;conceptual mappings;papua new guinea;adult;child;space;humans;language;communication;space perception;moire topography;concept formation	"""Speakers of many languages around the world rely on body-based contrasts (e.g., left/right) for spatial communication and cognition. Speakers of Yupno, a language of Papua New Guinea's mountainous interior, rely instead on an environment-based uphill/downhill contrast. Body-based contrasts are as easy to use indoors as outdoors, but environment-based contrasts may not be. Do Yupno speakers still use uphill/downhill contrasts indoors and, if so, how? We report three studies on spatial communication within the Yupno house. Even in this flat world, uphill/downhill contrasts are pervasive. However, the terms are not used according to the slopes beyond the house's walls, as reported in other groups. Instead, the house is treated as a microworld, with a """"conceptual topography"""" that is strikingly reminiscent of the physical topography of the Yupno valley. The phenomenon illustrates some of the distinctive properties of environment-based reference systems, as well as the universal power and plasticity of spatial contrasts."""		Kensy Cooperrider;James D. Slotta;Rafael Núñez	2017	Cognitive science	10.1111/cogs.12357	psychology;simulation;concept learning;space;linguistics;language;built environment	HCI	-7.985404502212994	-77.397475543343	148207
8fbb62cdb8145724f2eec65dbedf62f958a7b64e	prediction of next contextual changing point of driving behavior using unsupervised bayesian double articulation analyzer	unsupervised learning bayes methods driver information systems hidden markov models recurrent neural nets statistical distributions;hidden markov models time series analysis vehicles probability computational modeling semiotics context;supervised learning scheme unsupervised bayesian double articulation analyzer next contextual changing point driving behavior advanced driver assistance systems semiotic predictor two layered hierarchical structure hierarchical dirichlet process hidden semimarkov model nested pitman yor language model latent words posterior probability distribution linear regression recurrent neural networks	Future advanced driver assistance systems (ADASs) should observe a driving behavior and detect contextual changing points of driving behaviors. In this paper, we propose a novel method for predicting the next contextual changing point of driving behavior on the basis of a Bayesian double articulation analyzer. To develop the method, we extended a previously proposed semiotic predictor using an unsupervised double articulation analyzer that can extract a two-layered hierarchical structure from driving-behavior data. We employ the hierarchical Dirichlet process hidden semi-Markov model [4] to model duration time of a segment of driving behavior explicitly instead of the sticky hierarchical Dirichlet process hidden Markov model (HDP-HMM) employed in the previous model [13]. Then, to recover the hierarchical structure of contextual driving behavior as a sequence of chunks, we use the Nested Pitman-Yor Language model [6], which can extract latent words from sequences of latent letters. On the basis of the extension, we develop a method for calculating posterior probability distribution of the next contextual changing point by marginalizing potentially possible results of the chunking method and potentially successive words theoretically. To evaluate the proposed method, we applied the method to synthetic data and driving behavior data that was recorded in a real environment. The results showed that the proposed method can predict the next contextual changing point more accurately and in a longer-term manner than the compared methods: linear regression and Recurrent Neural Networks, which were trained through a supervised learning scheme.	approximation;artificial neural network;biconnected component;embedded system;global positioning system;hidden markov model;hidden semi-markov model;hierarchical database model;kerrison predictor;language model;markov chain;pedestrian detection;random neural network;recurrent neural network;semiconductor industry;semiotics;sensor;shallow parsing;sticky bit;supervised learning;synthetic data;synthetic intelligence;time series;unsupervised learning	Shogo Nagasaka;Tadahiro Taniguchi;Kentarou Hitomi;Kazuhito Takenaka;Takashi Bando	2014	2014 IEEE Intelligent Vehicles Symposium Proceedings	10.1109/IVS.2014.6856468	speech recognition;computer science;machine learning;pattern recognition	AI	-9.684589792691972	-71.57779656229835	148220
d640946d217bc793507dce14bb72c2a68ecb4a23	neural architecture for tibetan word segmentation		Tibetan word segmentation (TWS) is a primary task for Tibetan language processing. In this paper, a novel hybrid neural architecture is proposed to solve TWS which is considered as a sequence tagging task. Due to the high frequency of the contracted words in Tibetan sentences, we firstly use conditional random field (CRF) to deal with this problem. Then we use the character embedding method to obtain basic character representation as input. Most importantly, we apply bi-directional Long short-term memory and CRF (BiLSTM-CRF) to our system. Experimental result shows that our approach obtained state-of-art performance compared with previous approaches used in TWS.	conditional random field;ibm tivoli workload scheduler;long short-term memory;null character;text segmentation	Mengzhu Chen;Shengjie Zhao;Kai Yang	2017	2017 International Conference on Asian Language Processing (IALP)	10.1109/IALP.2017.8300619	architecture;natural language processing;long short term memory;tibetan language;artificial intelligence;recurrent neural network;embedding;conditional random field;text segmentation;computer science	Robotics	-18.166365859434816	-73.10811846883264	148707
16af9c23f9354ca27d0111990d371e4b24c5edab	neural models of selectional preferences for implicit semantic role labeling		Implicit Semantic Role Labeling is a challenging task: it requires high-level understanding of the text while annotated data is very limited. Due to the lack of training data, most researches either resort to simplistic machine learning methods or focus on automatically acquiring training data. In this paper, we explore the possibilities of using more complex and expressive machine learning models trained on a large amount of explicit roles. In addition, we compare the impact of one-way and multi-way selectional preference with the hypothesis that the added information in multi-way models are beneficial. Although our models surpass a baseline that uses prototypical vectors for SemEval-2010, we otherwise face mostly negative results. Selectional preference models perform lower than the baseline on ON5V, a dataset of five ambiguous and frequent verbs. They are also outperformed by the Naı̈ve Bayes model of Feizabadi and Pado (2015) on both datasets. We conclude that, even though multi-way selectional preference improves results for predicting explicit semantic roles compared to one-way selectional preference, it harms performance for implicit roles. We release our source code, including the reimplementation of two previously unavailable systems to enable further experimentation.	baseline (configuration management);high- and low-level;machine learning;naive bayes classifier;one-way function;semeval;semantic role labeling	Minh Le;Antske Fokkens	2018			natural language processing;artificial intelligence;naive bayes classifier;artificial neural network;semantic role labeling;source code;computer science;training set	NLP	-15.823282285870391	-70.4137763966147	149219
033692a6282ac9b8db701f7569935c98deb66c15	factorizing event sequences	large datasets interleaved event sequence factorization electronic medical records;event sequence factorization;electronic medical records;cancer;diabetes;data mining;process mining;interleaved codes;emrs;medical information systems;discovery analytics;diabetes data mining cancer electronic medical records medical diagnostic imaging diseases interleaved codes;diseases;process mining discovery analytics event sequence factorization electronic medical records emrs data mining;medical diagnostic imaging	Factorizing interleaved event sequences, such as those found in electronic medical records, into simpler processes can yield new insights from large datasets.		Naren Sundaravaradan;Naren Ramakrishnan;David A. Hanauer	2012	Computer	10.1109/MC.2012.409	computer science;data science;data mining;process mining;information retrieval;cancer	ML	-5.191747916058695	-67.12818406705696	150388
964d847bb24f72d35866d9ba82efb56ed70c3832	feature centrality and conceptual coherence	ucl;cognitive psychology;pattern;discovery;representation mentale;theses;conference proceedings;cognitive sciences;digital web resources;ucl discovery;processus cognitif;open access;cognition;ucl library;conceptual imagery;modele;book chapters;open access repository;psycholinguistique;psycholinguistics;ucl research;sciences cognitives	Conceptual features differ in how mentally tranformable they are. A robin that does not eat is harder to imagine than a robin that does not chirp. We argue that features are immutable to the extent that they are central in a network of dependency relations. The immutability of a feature reflects how much the internal structure of a concept depends on that feature; i.e., how much the feature contributes to the concept's coherence. Complementarily, mutability reflects the aspects in which a concept is flexible. We show that features can be reliably ordered according to their mutability using tasks that require people to conceive of objects missing a feature, and that mutability (conceptual centrality) can be distinguished from category centrality and from diagnosticity and salience. We test a model of mutability based on asymmetric, unlabeled, pairwise dependency relations. With no free parameters, the model provides reasonable fits to data. Qualitative tests of the model show that mutability judgments are unaffected by the type of dependency relation and that dependency structure influences judgments of variability.	centrality	Steven A. Sloman;Bradley C. Love;Woo-Kyoung Ahn	1998	Cognitive Science	10.1207/s15516709cog2202_2	psychology;cognitive psychology;cognition;computer science;artificial intelligence;mathematics;linguistics;sociology;pattern;psycholinguistics;social psychology;cognitive science	AI	-7.92531300473946	-76.49729317694467	150729
340a09755d1c4ae1a9b909ac921c83660c64ef38	learning concept taxonomies from multi-modal data		We study the problem of automatically building hypernym taxonomies from textual and visual data. Previous works in taxonomy induction generally ignore the increasingly prominent visual data, which encode important perceptual semantics. Instead, we propose a probabilistic model for taxonomy induction by jointly leveraging text and images. To avoid hand-crafted feature engineering, we design end-to-end features based on distributed representations of images and words. The model is discriminatively trained given a small set of existing ontologies and is capable of building full taxonomies from scratch for a collection of unseen conceptual label items with associated images. We evaluate our model and features on the WordNet hierarchies, where our system outperforms previous approaches by a large gap.	automatic taxonomy construction;bayesian network;big data;discriminative model;encode;end-to-end encryption;feature engineering;feedback;graphics processing unit;ibm notes;imagenet;mathematical induction;modal logic;ontology (information science);statistical model;taxonomy (general);wordnet	Hao Zhang;Zhiting Hu;Yuntian Deng;Mrinmaya Sachan;Zhicheng Yan;Eric P. Xing	2016	CoRR		natural language processing;computer science;artificial intelligence;machine learning;data mining	NLP	-15.796155580802232	-68.68944207941892	150740
aaf1b82ba5e4bf916fbb0deeebcf551ede6d47ee	children's semantic and world knowledge overrides fictional information during anticipatory linguistic processing		Using real-time eye-movement measures, we asked how a fantastical discourse context competes with stored representations of semantic and world knowledge to influence children's and adults' moment-by-moment interpretation of a story. Seven-yearolds were less effective at bypassing stored semantic and world knowledge during real-time interpretation than adults. Nevertheless, an effect of discourse context on comprehension was still apparent.	commonsense knowledge (artificial intelligence);list comprehension;real-time locating system	Ruth Lee;Craig Chambers;Falk Huettig;Patricia Ganea	2017				AI	-8.386322487954045	-77.70813492209012	150795
f31644f93b72b2d1c440e948499986f1525869c9	bidirectional grid long short-term memory (bigridlstm): a method to address context-sensitivity and vanishing gradient				Hongxiao Fei;Fengyun Tan	2018	Algorithms	10.3390/a11110172		HPC	-8.799574808764211	-71.2648227642361	150961
1b71d3f30238cb6621021a95543cce3aab96a21b	fine-grained video classification and captioning		We describe a DNN for fine-grained action classification and video captioning. It gives state-of-the-art performance on the challenging Something-Something dataset, with over 220, 000 videos and 174 fine-grained actions. Classification and captioning on this dataset are challenging because of the subtle differences between actions, the use of thousands of different objects, and the diversity of captions penned by crowd actors. The model architecture shares features for classification and captioning, and is trained end-to-end. It performs much better than the existing classification benchmark for Something-Something, with impressive fine-grained results, and it yields a strong baseline on the new Something-Something captioning task. Our results reveal that there is a strong correlation between the degree of detail in the task and the ability of the learned features to transfer to other tasks.	artificial neural network;baseline (configuration management);benchmark (computing);deep learning;end-to-end encryption;imagenet;internationalization and localization;minimum bounding box;question answering;randomness extractor;unsupervised learning	Farzaneh Mahdisoltani;Guillaume Berger;Waseem Gharbieh;David J. Fleet;Roland Memisevic	2018	CoRR		machine learning;architecture;pattern recognition;computer science;artificial intelligence;closed captioning	NLP	-15.183109364862458	-70.69667489659929	151156
d8a867f4f30b1d98242d3ba8ee1a53f0788027a3	"""deconstructing """"tomorrow"""": how children learn the semantics of time"""		Deictic time words (e.g., “tomorrow,” “yesterday”) refer to time periods relative to the present moment. While children produce these words by age 2-3, they use them incorrectly for several more years. Here, as a case study in abstract word learning, we explored what children know about these words during this delay. Specifically, we probed children’s knowledge of three aspects of meaning: deictic (past/future) status, sequential ordering (e.g., “tomorrow” is after “yesterday”), and remoteness from now. We asked 3to 8year-olds to place these words on a timeline extending from the past (left) to the future (right). Even 4-year-olds could meaningfully represent the words’ deictic status and order, and by 6, the majority displayed adult-like performance. Adult-like knowledge of remoteness, however, emerged independently, after age 7. Thus, even while children use these terms incorrectly, they are gradually constructing a structured semantic domain, including information about the deictic, sequential, and metric relations among terms.	timeline	Katharine Tillman;Tyler Marghetis;David Barner;Mahesh Srinivasan	2016			psychology;cognitive psychology;semantics	Web+IR	-6.759951884696073	-77.04911201307937	151169
8aae4e752ec36dae780049de02e663faa8090523	knowledge graph embedding via relation paths and dynamic mapping matrix		Knowledge graph embedding aims to embed both entities and relations into a low-dimensional space. Most existing methods of representation learning consider direct relations and some of them consider multiple-step relation paths. Although those methods achieve state-of-the-art performance, they are far from complete. In this paper, a noval path-augmented TransD (PTransD) model is proposed to improve the accuracy of knowledge graph embedding. This model uses two vectors to represent entities and relations. One of them represents the meaning of a(n) entity (relation), the other one is used to construct the dynamic mapping matrix. The PTransD model considers relation paths as translation between entities for representation learning. Experimental results on public dataset show that PTransD achieves significant and consistent improvements on knowledge graph completion.	graph embedding;knowledge graph	Shengwu Xiong;Weitao Huang;Pengfei Duan	2018		10.1007/978-3-030-01391-2_18	data mining;graph embedding;computer science;feature learning;matrix (mathematics);machine learning;artificial intelligence;graph	NLP	-16.309479410726993	-66.65810900673694	151181
0210ca147481bb20fff501bd0c1a6cbd0f2746ca	a natural language interface for querying general and individual knowledge		Many real-life scenarios require the joint analysis of general knowledge, which includes facts about the world, with individual knowledge, which relates to the opinions or habits of individuals. Recently developed crowd mining platforms, which were designed for such tasks, are a major step towards the solution. However, these platforms require users to specify their information needs in a formal, declarative language, which may be too complicated for näıve users. To make the joint analysis of general and individual knowledge accessible to the public, it is desirable to provide an interface that translates the user questions, posed in natural language (NL), into the formal query languages that crowd mining platforms support. While the translation of NL questions to queries over conventional databases has been studied in previous work, a setting with mixed individual and general knowledge raises unique challenges. In particular, to support the distinct query constructs associated with these two types of knowledge, the NL question must be partitioned and translated using different means; yet eventually all the translated parts should be seamlessly combined to a well-formed query. To account for these challenges, we design and implement a modular translation framework that employs new solutions along with state-of-the art NL parsing tools. The results of our experimental study, involving real user questions on various topics, demonstrate that our framework provides a high-quality translation for many questions that are not handled by previous translation tools.	database;declarative programming;experiment;information needs;machine learning;nl (complexity);natural language user interface;parsing;query language;real life;refinement (computing);relative intensity noise;well-formed element	Yael Amsterdamer;Anna Kukliansky;Tova Milo	2015	PVLDB	10.14778/2824032.2824042	natural language processing;computer science;data mining;database;mathematics;programming language	DB	-16.268505973036344	-68.58601836108198	151383
0d5855a9fb5809c7f715a1c3dd9358f39b9f3ce4	using syntactic and semantic context to explore psychodemographic differences in self-reference		Psychological analysis of language has repeatedly shown that an individual’s rate of mentioning 1st person singular pronouns predicts a wealth of important demographic and psychological factors. However, these analyses are performed out of context — syntactic and semantic — which may change the magnitude or even direction of such relationships. In this paper, we put “pronouns in their context”, exploring the relationship between self-reference and age, gender, and depression depending on syntactic position and verbal governor. We find that pronouns are overall more predictive when taking dependency relations and verb semantic categories into account, and, the direction of the relationship can change depending on the semantic class of the verbal governor.	human factors and ergonomics;self-reference;singular value decomposition;syntactic predicate;syntax (logic);theory;vocabulary;whole earth 'lectronic link	Masoud Rouhizadeh;Lyle H. Ungar;Anneke Buffone;H. Andrew Schwartz	2016			natural language processing;computer science;machine learning;artificial intelligence;syntax;self-reference	NLP	-11.59275757386496	-79.2020200301622	151615
371ca9ee792ea5e2d603fae6fa5d8cb49c6142d1	deep learning for semantic composition		Learning representations to model the meaning of text has been a core problem in natural language understanding (NLP). The last several years have seen extensive interests on distributional approaches, in which text spans of different granularities are encoded as continuous vectors. If properly learned, such representations have been shown to help achieve the state-of-the-art performances on a variety of NLP problems. In this tutorial, we will cover the fundamentals and selected research topics on neural networkbased modeling for semantic composition, which aims to learn distributed representations for larger spans of text, e.g., phrases (Yin and Schütze, 2014) and sentences (Zhu et al., 2016; Chen et al., 2016; Zhu et al., 2015b,a; Tai et al., 2015; Kalchbrenner et al., 2014; Irsoy and Cardie, 2014; Socher et al., 2012), from the meaning representations of their parts, e.g., word embedding. We begin by briefly introducing traditional approaches to semantic composition, including logic-based formal semantic approaches and simple arithmetic operations over vectors based on corpus word counts (Mitchell and Lapata, 2008; Landauer and Dumais, 1997). Our main focus, however, will be on distributed representation-based modeling, whereby the representations of words and the operations composing them are jointly learned from a training objective. We cover the generic ideas behind neural network-based semantic composition and dive into the details of three typical composition architectures: the convolutional composition models (Kalchbrenner et al., 2014; Zhang et al., 2015), recurrent composition models (Zhu et al., 2016), and recursive composition models (Irsoy and Cardie, 2014; Socher et al., 2012; Zhu et al., 2015b; Tai et al., 2015). After that, we will discuss several unsupervised approaches (Le and Mikolov, 2014; Kiros et al., 2014; Bowman et al., 2016; Miao et al., 2016). We will then advance to discuss several selected topics. We first cover the models that consider compositional with non-compositional (e.g., holistically learned) semantics (Zhu et al., 2016, 2015a). Next, we discuss composition models that integrate multiple architectures of neural networks. We also discuss semantic composition and decomposition (Turney, 2014). In the end we briefly discuss sub-word neural-network-based composition models (Zhang et al., 2015; Sennrich et al., 2016) We will then summarize the tutorial, flesh out limitations of current approaches, and discuss future directions that are interesting to us.	artificial neural network;deep learning;entity–relationship model;holism;landauer's principle;natural language processing;natural language understanding;neural network software;performance;recursion;unsupervised learning;word embedding	Xiao-Dan Zhu;Edward Grefenstette	2017		10.18653/v1/P17-5003	machine learning;natural language processing;computer science;artificial intelligence;deep learning;composition (visual arts)	AI	-17.725215719316456	-72.18235870800429	151719
1491c73713ff0b931e5bc1e990b9e762bfe7b60b	fast and simple mixture of softmaxes with bpe and hybrid-lightrnn for language generation		Mixture of Softmaxes (MoS) has been shown to be effective at addressing the expressiveness limitation of Softmax-based models. Despite the known advantage, MoS is practically sealed by its large consumption of memory and computational time due to the need of computing multiple Softmaxes. In this work, we set out to unleash the power of MoS in practical applications by investigating improved word coding schemes, which could effectively reduce the vocabulary size and hence relieve the memory and computation burden. We show both BPE and our proposed Hybrid-LightRNN lead to improved encoding mechanisms that can halve the time and memory consumption of MoS without performance losses. With MoS, we achieve an improvement of 1.5 BLEU scores on IWSLT 2014 German-to-English corpus and an improvement of 0.76 CIDEr score on image captioning. Moreover, on the larger WMT 2014 machine translation dataset, our MoSboosted Transformer yields 29.5 BLEU score for English-toGerman and 42.1 BLEU score for English-to-French, outperforming the single-Softmax Transformer by 0.8 and 0.4 BLEU scores respectively and achieving the state-of-the-art result on WMT 2014 English-to-German task.	algorithm;bleu;baseline (configuration management);byte pair encoding;computation;machine translation;performance;softmax function;time complexity;transformer;vocabulary	Xiang Kong;Qizhe Xie;Zihang Dai;Eduard H. Hovy	2018	CoRR		bleu;machine translation;machine learning;artificial intelligence;encoding (memory);computation;expressivity;computer science;softmax function;closed captioning;vocabulary	NLP	-18.73236047951313	-75.53776014922484	151768
3213cb2d75c158e5aeeb6b9714872f0115644007	the role of quinian bootstrapping in the acquisition of mental state terms			mental state	Szabolcs Kiss	2013			cognitive psychology;social psychology;psychology;bootstrapping;mental state	NLP	-8.401592117115417	-78.56790233811505	151825
ec6bee6531166d59d07f62d51ac66383de4b26b5	an efficient extension to mixture techniques for prediction and decision trees	decision tree	We present an efficient method for maintaining mixtures of prunings of a prediction or decision tree that extends the previous methods for “node-based” prunings (Buntine, 1990; Willems, Shtarkov, & Tjalkens, 1995; Helmbold & Schapire, 1997; Singer, 1997) to the larger class of edge-based prunings. The method includes an online weight-allocation algorithm that can be used for prediction, compression and classification. Although the set of edge-based prunings of a given tree is much larger than that of node-based prunings, our algorithm has similar space and time complexity to that of previous mixture algorithms for trees. Using the general online framework of Freund and Schapire (1997), we prove that our algorithm maintains correctly the mixture weights for edge-based prunings with any bounded loss function. We also give a similar algorithm for the logarithmic loss function with a corresponding weight-allocation algorithm. Finally, we describe experiments comparing node-based and edge-based mixture models for estimating the probability of the next word in English text, which show the advantages of edge-based models.	decision tree	Fernando Pereira;Yoram Singer	1997		10.1145/267460.267487	mathematical optimization;combinatorics;computer science;machine learning;decision tree;mathematics;algorithm	ML	-17.666722012790505	-77.29658081231842	151936
3d591509296cd0c9e9c7f9f748955f02de575afb	a transfer-learnable natural language interface for databases		Relational database management systems (RDBMSs) are powerful because they are able to optimize and answer queries against any relational database. A natural language interface (NLI) for a database, on the other hand, is tailored to support that specific database. In this work, we introduce a general purpose transfer-learnable NLI with the goal of learning one model that can be used as NLI for any relational database. We adopt the data management principle of separating data and its schema, but with the additional support for the idiosyncrasy and complexity of natural languages. Specifically, we introduce an automatic annotation mechanism that separates the schema and the data, where the schema also covers knowledge about natural language. Furthermore, we propose a customized sequence model that translates annotated natural language queries to SQL statements. We show in experiments that our approach outperforms previous NLI methods on the WikiSQL dataset and the model we learned can be applied to another benchmark dataset OVERNIGHT without retraining.	benchmark (computing);domain-specific language;experiment;native-language identification;natural language user interface;programming paradigm;relational database management system;sql	Wenlu Wang;Yingtao Tian;Hongyu Xiong;Haixun Wang;Wei-Shinn Ku	2018	CoRR		relational database management system;data mining;database;sql;data management;natural language;computer science;relational database;natural language user interface;schema (psychology);annotation	DB	-13.49166471381239	-67.32569443234594	152071
172c8881cf438aa2ecb5a9c81637369a41d40a1f	left-corner parsing and psychological plausibility	bottom up;top down;sentence processing	It is well known that even extremely limited centerembedding causes people to have difficulty ill comprehension, but that leftand right-branching constractions produce no such effect. If the difficulty in comprehension is taken to be a result of processing load, as is widely assumed, then measuring the processing load induced by a parsing strategy on these constructions may help determine its plausibility as a psychological model. On this basis, it has been ~rgued [A J91, JL83] that by identifying processing load with space utilization, we can rule out both top-down and bottom-up parsing as viable candidates for the human sentence processing mechanism, attd that left-corner parsing represents a plausible Mternative. Examining their arguments in detail, we find difficulties with each presentation. In this paper we revise the argument and validate its central claim. In so doing, we discover that the key distinction between the parsing methods is not the form of prediction (top-down vs. bottom-up vs. leftcorner), but rather the ability to iastantiate the operation of composition.	bottom-up parsing;bottom-up proteomics;cognitive model;plausibility structure;top-down and bottom-up design	Philip Resnik	1992		10.3115/992066.992098	natural language processing;speech recognition;computer science;top-down and bottom-up design;linguistics	NLP	-11.080379517832416	-76.88992353772078	152074
6e29b83fb5d61434eba566673497130cdb2d05c8	a proposal of new reading text captcha using random dot patterns		According to the growth of troubles caused by malicious programs called bots, CAPTCHA (Completely Automated Public Turing test to tell Computers and Humans Apart) comes to be an important role in the current information society. CAPTCHA identifies bots from legitimate human users by requiring some questions that are easy for humans to solve but difficult for bots. However, the progress of computing technology such as Optical Character Recognition (OCR) function. bots come to be able to solve present CAPTCHAs. In order to outcome such troublesome bots, more sophisticated CAPTCHA that requires the high cognitive ability of human beings is desired. In this paper, we propose a new CAPTCHA scheme that uses random dot patterns. Human beings can recognize a moving figure filled by a random dot pattern from a background that is filled by another random dot pattern; however, they lose the figure in the background when the figure pauses. Since image recognition by computer programs is usually carried out frame by frame, it is hard for bots to recognize such a moving figure filled by a random dot pattern from another random dot pattern background. The proposed CAPTCHA scheme exploits this characteristic of random dot patterns. This CAPTCHA requires users to answer a text filled by a random dot pattern that is moving on a background also filled by another random dot pattern. Several experiments were carried out to confirm that the proposed CAPTCHA scheme has enough resistance against bot attacks using representative image recognition methods. Results of the experiments showed that the image recognition methods cannot find out the answer text. Other experiments were also carried out to evaluate the usability of the proposed CAPTCHA scheme. The system usability scheme was adopted in the experiments. The obtained score was 89 that means this CAPTCHA scheme has high usability. These results showed that the CAPTCHA scheme is usable enough and has enough resistance against bot attacks.		Hisaaki Yamaba;Shotaro Usuzaki;Kentaro Aburada;Masayuki Mukunoki;Mirang Park;Naonobu Okazaki	2018	2018 Sixth International Symposium on Computing and Networking (CANDAR)	10.1109/CANDAR.2018.00036	turing test;optical character recognition;machine learning;exploit;captcha;usability;artificial intelligence;computer science	Security	-5.837539821464313	-69.5653712286801	152176
9d70cc1ecce04a5b0578d47c236787a789c54953	entity identification as multitasking		Standard approaches in entity identification hard-code boundary detection and type prediction into labels and perform Viterbi. This has two disadvantages: 1. the runtime complexity grows quadratically in the number of types, and 2. there is no natural segment-level representation. In this paper, we propose a neural architecture that addresses these disadvantages. We frame the problem as multitasking, separating boundary detection and type prediction but optimizing them jointly. Despite its simplicity, this architecture performs competitively with fully structured models such as BiLSTM-CRFs while scaling linearly in the number of types. Furthermore, by construction, the model induces type-disambiguating embeddings of predicted mentions.	computer multitasking;context-sensitive grammar;entity;hard coding;image scaling;mathematical optimization;reinforcement learning;scalability	Karl Stratos	2017			artificial intelligence;natural language processing;computer science;human multitasking	ML	-19.077835879059016	-73.92020224718105	152358
0cc9fe7bf61bf0d3081e96db6668b19aa07f0fa9	delay of word order development in japanese? evidence from a preferential looking study with 19 and 30-month-old children				Akira Omaki;Romy Lassotta;Tessei Kobayashi;Luigi Rizzi;Julie Franck	2012			cognitive psychology;psychology;word order;developmental psychology	NLP	-8.956580065028003	-78.22284444466423	153031
ecfcd1c4b4b2f1dff05bcbd472a377dfa1b7f0e8	capturing pragmatic knowledge in article usage prediction using lstms		We examine the potential of recurrent neural networks for handling pragmatic inferences involving complex contextual cues for the task of article usage prediction. We train and compare several variants of Long Short-Term Memory (LSTM) networks with an attention mechanism. Our model outperforms a previous state-of-the-art system, achieving up to 96.63% accuracy on the WSJ/PTB corpus. In addition, we perform a series of analyses to understand the impact of various model choices. We find that the gain in performance can be attributed to the ability of LSTMs to pick up on contextual cues, both local and further away in distance, and that the model is able to solve cases involving reasoning about coreference and synonymy. We also show how the attention mechanism contributes to the interpretability of the model’s effectiveness.	artificial neural network;construction grammar;experiment;file spanning;long short-term memory;named entity;random neural network;recurrent neural network;the wall street journal;word embedding	Jad Kabbara;Yulan Feng;Jackie Chi Kit Cheung	2016			artificial intelligence;natural language processing;data mining;computer science	NLP	-17.068918806324742	-72.90257718457524	153302
54ca5f4c1480d30795a3b9c6845af397e4561a26	simultaneous generation-classification using lstm	training;testing;computer architecture;sentiment analysis;predictive models;load modeling;data models	The idea that a concept is properly learned by an agent when the agent is able to generate examples and non-examples of the concept, has motivated research on generative models. Generative models are trained with the aim of improving performance of tasks such as classification. In this paper, a Long Short Term Memory (LSTM) architecture for simultaneous generation-classification is presented. The architecture is designed with the purpose of serving as a model which can generate sequence samples, while simultaneously classifying a given sequence. The presented generation-classification methodology was implemented on a sentiment analysis task. However, it can be applied to any sequence modelling or classification task. The experimental results suggest that this approach can be particularly useful as a regularization methodology which acts similarly to pre-training through Restricted Boltzmann Machines or auto-encoders.	encoder;experiment;generative model;long short-term memory;loss function;mathematical optimization;matrix regularization;multi-objective optimization;restricted boltzmann machine;sentiment analysis;sequence logo;statistical classification	Daniel L. Marino;Kasun Amarasinghe;Milos Manic	2016	2016 IEEE Symposium Series on Computational Intelligence (SSCI)	10.1109/SSCI.2016.7850115	computer science;artificial intelligence;machine learning;data mining	AI	-15.795777860819001	-71.50422849849096	153321
07e27f3fbeae86df57d12c72029ed90163250637	leveraging effective query modeling techniques for speech recognition and summarization		Statistical language modeling (LM) that purports to quantify the acceptability of a given piece of text has long been an interesting yet challenging research area. In particular, language modeling for information retrieval (IR) has enjoyed remarkable empirical success; one emerging stream of the LM approach for IR is to employ the pseudo-relevance feedback process to enhance the representation of an input query so as to improve retrieval effectiveness. This paper presents a continuation of such a general line of research and the main contribution is three-fold. First, we propose a principled framework which can unify the relationships among several widely-used query modeling formulations. Second, on top of the successfully developed framework, we propose an extended query modeling formulation by incorporating critical query-specific information cues to guide the model estimation. Third, we further adopt and formalize such a framework to the speech recognition and summarization tasks. A series of empirical experiments reveal the feasibility of such an LM framework and the performance merits of the deduced models on these two tasks.	automatic summarization;consistency model;continuation;experiment;information retrieval;language model;microsoft outlook for mac;mixture model;national supercomputer centre in sweden;relevance feedback;speech recognition	Kuan-Yu Chen;Shih-Hung Liu;Berlin Chen;Ea-Ee Jan;Hsin-Min Wang;Wen-Lian Hsu;Hsin-Hsi Chen	2014			natural language processing;query expansion;speech recognition;computer science;machine learning;data mining	NLP	-12.87670471770616	-72.89600003972186	153393
9e95df7a7f667c8ee907d0ba4537889e0e27ec3e	learning distributional token representations from visual features		In this study, we compare token representations constructed from visual featuresrn(i.e., pixels) with standard lookup-basedrnembeddings. Our goal is to gain insightrnabout the challenges of encoding a textrnrepresentation from low-level features,rne.g. from characters or pixels. We focus on Chinese, which—as a logographicrnlanguage—has properties that make a representation via visual features challengingrnand interesting. To train and evaluate different models for the token representation,rnwe chose the task of character-based neural machine translation (NMT) from Chinese to English. We found that a tokenrnrepresentation computed only from visualrnfeatures can achieve competitive results tornlookup embeddings. However, we alsornshow different strengths and weaknessesrnin the models’ performance in a part-of-rnspeech tagging task and also a semanticrnsimilarity task. In summary, we show thatrnit is possible to achieve arntext representationrnonly from pixels. We hope that thisrnis a useful stepping stone for future studies that exclusively rely on visual input, orrnaim at exploiting visual features of written language.	encoder;experiment;futures studies;high- and low-level;lookup table;neural machine translation;part-of-speech tagging;pixel;semantic similarity;stepping level;text-based (computing)	Samuel Broscheit	2018			machine translation;written language;pixel;natural language processing;semantic similarity;computer science;security token;artificial intelligence;encoding (memory);strengths and weaknesses	NLP	-17.66687469590177	-73.72210652717641	153398
ab5338aed96a42ec5d596dcb01272fd92b5f19f0	using hidden markov model to uncover processing states from eye movements in information search tasks	hidden markov model;computer model;reading;information search;search;computational models;eye movements;eye movement;decision process;scanning;information;sprak och litteratur	We study how processing states alternate during information search tasks. Inference is carried out with a discriminative hidden Markov model (dHMM) learned from eye movement data, measured in an experiment consisting of three task types: (i) simple word search, (ii) finding a sentence that answers a question and (iii) choosing a subjectively most interesting title from a list of ten titles. The results show that eye movements contain necessary information for determining the task type. After training, the dHMM predicted the task for test data with 60.2% accuracy (pure chance 33.3%). Word search and subjective interest conditions were easier to predict than the question–answer condition. The dHMM that best fitted our data segmented each task type into three hidden states. The three processing states were identified by comparing the parameters of the dHMM states to literature on eye movement research. A scanning type of eye behavior was observed in the beginning of the tasks. Next, participants tended to shift to states reflecting reading type of eye movements, and finally they ended the tasks in states which we termed as the decision states.	hidden markov model;in the beginning... was the command line;markov chain;measurement in quantum mechanics;test data	Jaana Simola;Jarkko Salojärvi;Ilpo Kojo	2008	Cognitive Systems Research	10.1016/j.cogsys.2008.01.002	computer vision;speech recognition;computer science;artificial intelligence;machine learning;hidden markov model;eye movement	ML	-12.802711231456806	-71.75924769987704	153461
46d472543e8fbbc669c8a54a8a159a99dff4c586	decoding sentiment from distributed representations of sentences		Distributed representations of sentences have been developed recently to represent their meaning as real-valued vectors. However, it is not clear how much information such representations retain about the polarity of sentences. To study this question, we decode sentiment from unsupervised sentence representations learned with different architectures (sensitive to the order of words, the order of sentences, or none) in 9 typologically diverse languages. Sentiment results from the (recursive) composition of lexical items and grammatical strategies such as negation and concession. The results are manifold: we show that there is no ‘one-size-fits-all’ representation architecture outperforming the others across the board. Rather, the top-ranking architectures depend on the language and data at hand. Moreover, we find that in several cases the additive composition model based on skip-gram word vectors may surpass supervised state-of-art architectures such as bidirectional LSTMs. Finally, we provide a possible explanation of the observed variation based on the type of negative constructions in each language.		Edoardo Maria Ponti;Ivan Vulic;Anna Korhonen	2017		10.18653/v1/S17-1003	natural language processing;artificial intelligence;linguistics	NLP	-18.416525305137004	-72.86219495155893	153621
168a8a4b3006a760a9aa4cfe58c805c9086b8a30	generating more interesting responses in neural conversation models with distributional constraints		Neural conversation models tend to generate safe, generic responses for most inputs. This is due to the limitations of likelihoodbased decoding objectives in generation tasks with diverse outputs, such as conversation. To address this challenge, we propose a simple yet effective approach for incorporating side information in the form of distributional constraints over the generated responses. We propose two constraints that help generate more content rich responses that are based on a model of syntax and topics (Griffiths et al., 2005) and semantic similarity (Arora et al., 2016). We evaluate our approach against a variety of competitive baselines, using both automatic metrics and human judgments, showing that our proposed approach generates responses that are much less generic without sacrificing plausibility. A working demo of our code can be found at https://github.com/abaheti95/ DC-NeuralConversation.	baseline (configuration management);beam search;dc-to-dc converter;decoding methods;distributional semantics;plausibility structure;semantic similarity	Ashutosh Baheti;Alan Ritter;Jiwei Li;William B. Dolan	2018			conversation;artificial intelligence;machine learning;semantic similarity;natural language processing;decoding methods;computer science;syntax	NLP	-18.44698493315114	-75.21378792192682	153948
57a3b21df63e8aa5f55b144db23f71395485ac6c	research on chinese viseme based on fuzzy clustering and grey relation analysis	feature extraction speech correlation speech recognition animation transform coding systematics;pattern clustering;ttvs system chinese viseme fuzzy clustering grey relation analysis chinese speech pronunciation fuzzy similarity relation matrix text to visual speech system;similarity relation;grey relational analysis;natural languages;grey relation analysis viseme fuzzy clustering ttvs;matrix algebra;fuzzy set theory;fuzzy clustering;grey relation analysis;viseme;grey systems;pattern clustering fuzzy set theory grey systems matrix algebra natural languages;ttvs	In this paper, based on the characteristics of Chinese speech pronunciation, we firstly extract the lip features of consonant and vowels, use grey relation analysis to construct fuzzy similarity relation matrix for consonant and vowels, and then use fuzzy clustering to classify the consonant and vowels, at last we define 13 basic static visemes for Chinese. We realized a TTVS(Text-To-Visual Speech) system to verify the performance of the visemes.	biconnected component;cluster analysis;fuzzy clustering;simulation	Chuanzhen Rong;Zhenjun Yue;Wang Yuan;Yang Yu	2012	2012 9th International Conference on Fuzzy Systems and Knowledge Discovery	10.1109/FSKD.2012.6233888	natural language processing;speech recognition;fuzzy clustering;computer science;grey relational analysis;machine learning;pattern recognition;viseme;mathematics;fuzzy set;natural language	SE	-15.238358385752507	-79.67078386392188	154654
b9195f86e989d4e8638ffa1dfbd5b8a86abf6b8c	automatic miscue detection using rnn based models with data augmentation		This study proposes a method of using data augmentation to address the problem of data shortages in miscue detection tasks. Three main steps were taken. First, a phoneme classifier was developed to acquire force-aligned data, which would be used for miscue classification and data augmentation. In order to create the phoneme classifier, phonetic features of “Seoul Reading Speech” (SRS) corpus were extracted by using grapheme-to-phoneme (G2P) to train CNN-based models. Second, to obtain miscue labeled corpus, we performed data augmentation using the phoneme classifier output, which is artificially generated miscue corpus of SRS (modified-SRS). This miscue corpus was created by randomly deleting or modifying sound sections according to three miscue categories; extension (EXT), pause (PAU), and pre-correction (PRE). Third, the performance of the miscue classifier was tested after training three types of RNN based models (LSTM, BiLSTM, BiGRU) with the modified-SRS corpus. The results show that the BiGRU model performed best at 0.819 in F1-score on augmented data, while BiLSTM model performed best at 0.512	convolutional neural network;extension (semantics);f1 score;long short-term memory;random neural network;randomness;speech corpus;statistical classification	Yoon Seok Hong;Kyung Seo Ki;Gahgene Gweon	2018		10.21437/Interspeech.2018-1644	speech recognition;miscue analysis;pattern recognition;artificial intelligence;computer science	NLP	-16.426568720589177	-77.17649143461365	154854
ad5ac1382a7762bb263c295e9fab9536e33e64a8	spotting social signals in conversational speech over ip: a deep learning perspective		The automatic detection and classification of social signals is an important task, given the fundamental role nonverbal behavioral cues play in human communication. We present the first cross-lingual study on the detection of laughter and fillers in conversational and spontaneous speech collected u0027in the wildu0027 over IP (internet protocol). Further, this is the first comparison of LSTM and GRU networks to shed light on their performance differences. We report frame-based results in terms of the unweighted-average area-under-the-curve (UAAUC) measure and will shortly discuss its suitability for this task. In the mono-lingual setup our best deep BLSTM system achieves 87.0% and 86.3% UAAUC for English and German, respectively. Interestingly, the cross-lingual results are only slightly lower, yielding 83.7% for a system trained on English, but tested on German, and 85.0% in the opposite case. We show that LSTM and GRU architectures are valid alternatives for e. g., on-line and compute-sensitive applications, since their application incurs a relative UAAUC decrease of only approximately 5% with respect to our best systems. Finally, we apply additional smoothing to correct for erroneous spikes and drops in the posterior trajectories to obtain an additional gain in all setups.	deep learning;frame language;long short-term memory;online and offline;smoothing;spontaneous order;voltage spike	Raymond Brueckner;Maximilian Schmitt;Maja Pantic;Björn W. Schuller	2017			speech recognition;spotting;pattern recognition;nonverbal communication;human communication;internet protocol;deep learning;smoothing;computer science;laughter;artificial intelligence	NLP	-15.425469796351061	-73.15461811979497	155172
1482ff560eb62d88c50f58dae966feabefc24162	rethinking the role of error in attentional learning	social and behavioral sciences	Learning how to allocate attention properly is essential for success at many tasks. Extant theories of categorization assume that learning to allocate attention is an error-driven process, where shifts in attention are made to reduce error. The present work introduces a new measure, error bias, which compares the amount of attentional change in response to incorrect responses versus correct responses during category learning. We first confirm that prominent categorization models predict high amounts of error bias. We then test this prediction against human eye-tracking data from 384 participants. Across 7 of 8 data sets we find that participants show minimal or no error bias. This finding suggests that attentional learning mechanisms, as implemented in influential computational models, cannot be generalized to account for measures of overt attention.	categorization;computational model;concept learning;eye tracking;theory	Mark R. Blair;R. Calen Walshe;Jordan I. Barnes;Lihan Chen	2011			psychology;cognitive psychology;developmental psychology;social psychology	ML	-11.813612679716085	-73.8143425600743	155437
468aca5f65e1ef397f52dd2852e448e8b35ebb53	competition, event comprehension, and dynamic location information in sentence processing		Two experiments in the visual world paradigm investigated competition in sentence processing from dynamic eventrelated information about location. In Experiment 1, listeners viewed visual arrays with container objects like a bowl, jar, pan, and jug, while they heard sentences like “The boy will pour the sweetcorn from the bowl into the jar, and he will pour the gravy from the pan into the jug. But first/And then, he will taste the sweetcorn.” While “But first” contexts referred to the “source” location of the discourse-final noun (e.g., “sweetcorn”), “And then” contexts referred to its “goal” location. In Experiment 2, listeners always heard “And then” contexts. We found that listeners rapidly fixated contextrelevant locations. Crucially, they also fixated locations that were context-irrelevant, but related to the discourse-final noun, suggesting object competition, or consistent with abstract location information implied by “But first” (source) or “And then” (goal), suggesting location competition.	experiment;programming paradigm;relevance	Anuenue Kukona;Gerry T. M. Altmann;Yuki Kamide	2013			noun;psychology;spoken language;communication;speech recognition;comprehension;recall;sentence processing;sentence	HCI	-8.420478655007555	-77.32233697957506	155818
7f0232b9ffbc637cdddaed2520098cddc066e5d6	lstm neural reordering feature for statistical machine translation		Artificial neural networks are powerful models, which have been widely applied into many aspects of machine translation, such as language modeling and translation modeling. Though notable improvements have been made in these areas, the reordering problem still remains a challenge in statistical machine translations. In this paper, we present a novel neural reordering model that directly models word pairs and their alignment. Further by utilizing LSTM recurrent neural networks, much longer context could be learned for reordering prediction. Experimental results on NIST OpenMT12 Arabic-English and Chinese-English 1000-best rescoring task show that our LSTM neural reordering feature is robust, and achieves significant improvements over various baseline systems.	artificial neural network;baseline (configuration management);language model;long short-term memory;neural machine translation;random neural network;recurrent neural network;statistical machine translation	Yiming Cui;Shijin Wang;Jianfeng Li	2016		10.18653/v1/N16-1112	natural language processing;speech recognition;computer science;artificial intelligence;machine learning	NLP	-18.657826043247816	-75.20103512143652	155933
428052b90733e1a1f7c3ef07e3b474b375bee827	learning what to say and how to say it: joint optimisation of spoken dialogue management and natural language generation	dialogue system;reinforcement learning;speech;statistical significance;global optimisation;dialogue;information presentation;natural language generation;dialogue systems;dialogue management;dialogue manager	This paper argues that the problems of dialogue management (DM) and Natural Language Generation (NLG) in dialogue systems are closely related and can be fruitfully treated statistically, in a joint optimisation framework such as that provided by Reinforcement Learning (RL). We first review recent results and methods in automatic learning of dialogue management strategies for spoken and multimodal dialogue systems, and then show how these techniques can also be used for the related problem of Natural Language Generation. This approach promises a number of theoretical and practical benefits such as fine-grained adaptation, generalisation, and automatic (global) optimisation, and we compare it to related work in statistical/trainable NLG. A demonstration of the proposed approach is then developed, showing combined DM and NLG policy learning for adaptive information presentation decisions. A joint DM and NLG policy learned in the framework shows a statistically significant 27% relative increase in reward over a baseline policy, which is learned in the same way only without the joint optimisation. We thereby show that that NLG problems can be approached statistically, in combination with dialogue management decisions, and we show how to jointly optimise NLG and DM using Reinforcement Learning.	approximation;baseline (configuration management);dialog system;expectation propagation;global optimization;mathematical optimization;multimodal interaction;natural language generation;reinforcement learning;simulation;software deployment	Oliver Lemon	2011	Computer Speech & Language	10.1016/j.csl.2010.04.005	natural language processing;speech recognition;computer science;speech;artificial intelligence;machine learning;statistical significance;linguistics;reinforcement learning	NLP	-15.685654818254868	-75.07467945898883	156435
fac1a89ba6e4be01494a812ebd57edfb57fc9bab	identifying discourse boundaries in group discussions using a multimodal embedding space		In group discussion, it is not always easy for the participants to effectively control the discussion to make it fruitful. With the goal of contributing to facilitating group discussions, this study proposes a method of segmenting a discussion. Predicted discussion boundaries may be useful for tracking the discussion topics, analyzing the discussion structure, and determining a timing for intervention. We created a multimodal embedding space using an autoencoder, and represented each multimodal utterance data in the embedding space. Then, a simple unsupervised approach was used to detect the discussion boundary. In a preliminary analysis, we found that the proposed method can generate discussion segments that are comprehensible for analyzing a discourse structure. But, the performance in the discourse segmentation task should be improved as future work. Author	autoencoder;feature vector;multimodal interaction;principle of good enough;unsupervised learning	Ken Tomiyama;Fumio Nihei;Yukiko I. Nakano;Yutaka Takase	2018			natural language processing;artificial intelligence;mathematics;embedding	NLP	-17.671078162736674	-69.9311383928236	156529
adab33fb7fcf4fe71efe0e9520543bfe1e9611bc	statistical learning contributions to semantic knowledge development		The organization of semantic knowledge according to relations between concepts influences many facets of higher cognition. Therefore, understanding the origins of relations knowledge is a key focus of cognitive development research. This study investigated the contributions of environmental statistical regularities to relations knowledge in preschool-age children. Using CHILDES to estimate co-occurrence between familiar items, we constructed triads consisting of a target, related distractor, and unrelated distractor in which targets and related distractors consistently co-occurred (e.g., sock-foot), belonged to the same taxonomic category (e.g., sock-coat), or both (e.g., sock-shoe). Using a Visual World paradigm, we then measured relations knowledge as the degree to which children looked at related versus unrelated distractors when asked to look for targets. The results revealed that co-occurrence, regardless of taxonomic relatedness, influenced whether participants looked significantly more at related versus unrelated distractors. These findings demonstrate that co-occurrence regularities between entities in the environment shape knowledge organization.	childes;cognition;cognitive science;entity;knowledge organization;machine learning;programming paradigm;shoe size	Layla Unger;Anna V. Fisher;Robert Powers	2017			cognitive psychology;psychology;semantic memory	AI	-8.099038768052697	-76.70107297632846	157236
86af27afacf35e090e90c8d6d55c26c78f42b5eb	prior knowledge integrated with self-attention for event detection		Recently, end-to-end models based on recurrent neural networks (RNN) have gained great success in event detection. However these methods cannot deal with long-distance dependency and internal structure information well. They are also hard to be controlled in process of learning since lacking of prior knowledge integration. In this paper, we present an effective framework for event detection which aims to address these problems. Our model based on self-attention can ignore the distance between any two words to obtain their relationship and leverage internal event argument information to improve event detection. In order to control the process of learning, we first collect keywords from corpus and then use a prior knowledge integration network to encode keywords to a prior knowledge representation. Experimental results demonstrate that our model has significant improvement of 3.9 F1 over the previous state-of-the-art on ACE 2005 dataset.		Yan Li;Chenliang Li;Weiran Xu;Junliang Li	2018		10.1007/978-3-030-01012-6_21	work in process;knowledge representation and reasoning;leverage (finance);machine learning;recurrent neural network;knowledge integration;computer science;artificial intelligence	AI	-17.852678158015458	-71.40959978102201	157497
49e037edec0d1f065c10d1477fa2e65ed29cdcf9	impedance effects of visual and spatial content upon language-to-logic translation accuracy	macquarie university institutional repository;researchonline;digital repository;macquarie university	There is a body of work that suggests that those elements of the cognitive architecture responsible for processing, on the one hand, visual information (essentially visual properties of objects), and, on the other hand, spatial information (spatial relationships between objects), may compete with each other for resources. In this paper, we explore whether and to what degree the processing of visual and spatial information interferes with the task of translation from natural language into logic, a skill that students often find difficult to master. Using a large corpus of student data, we determine correlations between difficulty and the particular properties used in the sentences, with implications for pedagogical design.	cognitive architecture;natural language;nominal impedance;text corpus	Dave Barker-Plummer;Robert Dale;Richard Cox	2011			psychology;digital library;computer science;artificial intelligence;multimedia;communication	HCI	-8.266628066883019	-76.84071176065264	157592
3c3bcd889a37da4db3efe91c2c87605eb9c6cad2	speed-constrained tuning for statistical machine translation using bayesian optimization		We address the problem of automatically finding the parameters of a statistical machine translation system that maximize BLEU scores while ensuring that decoding speed exceeds a minimum value. We propose the use of Bayesian Optimization to efficiently tune the speed-related decoding parameters by easily incorporating speed as a noisy constraint function. The obtained parameter values are guaranteed to satisfy the speed constraint with an associated confidence margin. Across three language pairs and two speed constraint values, we report overall optimization time reduction compared to grid and random search. We also show that Bayesian Optimization can decouple speed and BLEU measurements, resulting in a further reduction of overall optimization time as speed is measured over a small subset of sentences.	bleu;bayesian optimization;computation;computer multitasking;constraint (mathematics);coupling (computer programming);experiment;loss function;mathematical optimization;optimization problem;parallel computing;random search;randomized algorithm;statistical machine translation;test set	Daniel Edward Robert Beck;Adrià de Gispert;Gonzalo Iglesias;Aurelien Waite;Bill Byrne	2016			computer science;artificial intelligence;machine learning;pattern recognition;data mining;statistics	NLP	-18.075709604773138	-76.85954837168632	158012
9677d2f6a994f598c1d631038d49401c5f707ee0	see, hear, and read: deep aligned representations		We capitalize on large amounts of readily-available, synchronous data to learn a deep discriminative representations shared across three major natural modalities: vision, sound and language. By leveraging over a year of sound from video and millions of sentences paired with images, we jointly train a deep convolutional network for aligned representation learning. Our experiments suggest that this representation is useful for several tasks, such as cross-modal retrieval or transferring classifiers between modalities. Moreover, although our network is only trained with image+text and image+sound pairs, it can transfer between text and sound as well, a transfer the network never observed during training. Visualizations of our representation reveal many hidden units which automatically emerge to detect concepts, independent of the modality.	computer vision;emergence;experiment;feature learning;high- and low-level;machine learning;machine perception;modal logic;modality (human–computer interaction)	Yusuf Aytar;Carl Vondrick;Antonio Torralba	2017	CoRR		modalities;pattern recognition;discriminative model;artificial intelligence;machine learning;computer science;feature learning	ML	-14.295501720100091	-71.03566522022658	158039
2ccba54f2535e2a38c9b3775e92627b68fd5bd0a	an information measure for comparing top k lists	radiation detectors loss measurement encoding displacement measurement position measurement joints;information compression information measure top k lists top k elements mathematical property compressibility information theoretic measure nonoverlapping element;information theory	Comparing the top k elements between two or more ranked results is a common task in many contexts and settings. A few measures have been proposed to compare top k lists with attractive mathematical properties, but they face a number of pitfalls and shortcomings in practice. This work introduces a new measure to compare any two top k lists based on measuring the information these lists convey. Our method investigates the compressibility of the lists, and the length of the message to encode losslessly the lists gives a natural and robust measure of their variability. This information-theoretic measure objectively reconciles all the main considerations that arise when measuring (dis-)similarity between lists: the extent of their non-overlapping elements, the amount of disarray among overlapping elements, the measurement of displacement of actual ranks (positions) of their overlapping elements. We demonstrate that our measure is intuitively simple and superior to other commonly used measures. To the best of our knowledge, this is the first attempt to address the problem using information compression as its basis.	displacement mapping;encode;heart rate variability;information theory;limbo;lossless compression	Arun Siddharth Konagurthu;James H. Collier	2014	2014 IEEE 10th International Conference on e-Science	10.1109/eScience.2014.39	information theory;theoretical computer science;data mining;mathematics;statistics	Visualization	-4.803808210329958	-73.91607351853631	158403
a82b39f5069c4c4c245709523b25b328a44ec2bc	on the emergence of contrast		This paper discusses the emergence of contrast between alveolar stops and alveopalatal affricates in Brazilian Portuguese. Usage-Based Phonology [3] and Exemplar Models [11, 15] are the theoretical perspectives adopted. Alveopalatal affricates were formerly introduced in Brazilian Portuguese as a consequence of the process of palatalization according to which an alveolar stop would be manifested as an alveolapalatal affricate when followed by a high front vowel: tia []>[] ‘aunt’ and dia []>[] ‘day’. Complementary distribution related to the process of palatalization predicts that affricates should only be followed by [i] and alveolar stops should be followed by vowels different from [i] and also appear in consonantal clusters. Nevertheless, unexpected patterns such as affricates followed by vowels different from [i] and alveolar stops followed by [i] started appearing in Brazilian Portuguese, leading to the emergence of contrast between alveolar stops and alveopalatal affricates. This paper suggests that lexical innovation related to neologisms and phonological phenomena involving sound changes is responsible to the emergence of contrast between alveolar stops and alveopalatal affricates in Brazilian Portuguese.	dia;emergence;neologism	Thaïs Cristófaro Silva;Maria Cantoni	2011			psychology	ML	-9.991949065380405	-79.93429590090577	158545
c5114895ed287c09134184e94df1b8475ed74386	benchmarking touchscreen biometrics for mobile authentication		We study user interaction with touchscreens based on swipe gestures for personal authentication. This approach has been analyzed only recently in the last few years in a series of disconnected and limited works. We summarize those recent efforts and then compare them to three new systems (based on support vector machine and Gaussian mixture model using selected features from the literature) exploiting independent processing of the swipes according to their orientation. For the analysis, four public databases consisting of touch data obtained from gestures sliding one finger on the screen are used. We first analyze the contents of the databases, observing various behavioral patterns, e.g., horizontal swipes are faster than vertical independently of the device orientation. We then explore an intra-session scenario, where users are enrolled and authenticated within the same day, and an inter-session one, where enrollment and test are performed on different days. The resulting benchmarks and processed data are made public, allowing the reproducibility of the key results obtained based on the provided score files and scripts. In addition to the remarkable performance, thanks to the proposed orientation-based conditional processing, the results show various new insights into the distinctiveness of swipe interaction, e.g., some gestures hold more user-discriminant information, data from landscape orientation is more stable, and horizontal gestures are more discriminative in general than vertical ones.	authentication;behavioral pattern;benchmark (computing);biometrics;database;discriminant;experiment;google map maker;mixture model;support vector machine;touchpad;touchscreen	Julian Fiérrez;Ada Pozo;Marcos Martinez-Diaz;Javier Galbally;Aythami Morales	2018	IEEE Transactions on Information Forensics and Security	10.1109/TIFS.2018.2833042	support vector machine;artificial intelligence;task analysis;swipe;machine learning;benchmarking;biometrics;pattern recognition;computer science;behavioral pattern;touchscreen;gesture	Mobile	-6.106384846462872	-72.64680128809644	158933
a627c0ef215880857e65f116b9670c3242e90e09	text classification based on word subspace with term-frequency		Text classification has become indispensable due to the rapid increase of text in digital form. Over the past three decades, efforts have been made to approach this task using various learning algorithms and statistical models based on bag-of-words (BOW) features. Despite its simple implementation, BOW features lack of semantic meaning representation. To solve this problem, neural networks started to be employed to learn word vectors, such as the word2vec. Word2vec embeds word semantic structure into vectors, where the angle between vectors indicates the meaningful similarity between words. To measure the similarity between texts, we propose the novel concept of word subspace, which can represent the intrinsic variability of features in a set of word vectors. Through this concept, it is possible to model text from word vectors while holding semantic information. To incorporate the word frequency directly in the subspace model, we further extend the word subspace to the term-frequency (TF) weighted word subspace. Based on these new concepts, text classification can be performed under the mutual subspace method (MSM) framework. The validity of our modeling is shown through experiments on the Reuters text database, comparing the results to various state-of-art algorithms.		Erica K. Shimomoto;Lincon Sales de Souza;Bernardo B. Gatto;Kazuhiro Fukui	2018	2018 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2018.8489458	word2vec;support vector machine;task analysis;pattern recognition;artificial neural network;semantics;machine learning;artificial intelligence;subspace topology;computer science;word lists by frequency;vocabulary	NLP	-17.741770455303325	-70.84937796893803	158936
0e210d27475fca453c168dd7946e5bcd52d45426	internal wiring of cartesian verbs and prepositions		Categorical compositional distributional semantics (CCDS) allows one to compute the meaning of phrases and sentences from the meaning of their constituent words. A type-structure carried over from the traditional categorial model of grammar a la Lambek becomes a u0027wire-structureu0027 that mediates the interaction of word meanings. However, CCDS has a much richer logical structure than plain categorical semantics in that certain words can also be given an u0027internal wiringu0027 that either provides their entire meaning or reduces the size their meaning space. Previous examples of internal wiring include relative pronouns and intersective adjectives. Here we establish the same for a large class of well-behaved transitive verbs to which we refer as Cartesian verbs, and reduce the meaning space from a ternary tensor to a unary one. Some experimental evidence is also provided.	cartesian closed category;categorical logic;charge-coupled device;distributional semantics;linear algebra;unary operation;wiring	Bob Coecke;Martha Lewis;Dan Marsden	2018	CoRR	10.4204/EPTCS.283.6	natural language processing;discrete mathematics;tensor;artificial intelligence;structure (mathematical logic);semantics;categorical variable;distributional semantics;ternary operation;transitive relation;computer science;unary operation	NLP	-9.626558088033985	-77.11463544506174	159900
dea8d1f91737014a582c323121346173f3ae51f8	attention-based linguistically constraints network for aspect-level sentiment		Aspect-level sentiment analysis is an essential subtask of sentiment classification. It aims at classifying the sentiment polarity of given aspect in its context. Recently, a variety of deep learning models have been proposed to solve this task, such as Long Short-Term Memory Networks (LSTM), Convolutional Neural Networks (CNN). In particular, great improvement has been achieved by using attention mechanism. At the same time, the adoption of linguistic resources to improve sentiment classification has also drawn researchers’ attention, and achieved state-of-the-art performance on traditional sentiment classification. Hence in this paper, we explore to combine linguistically constraints with attention mechanism to achieve comparable performance on aspect-level sentiment analysis. Experimental results on SemEval 2014 Datasets showed that the proposed model achieves good performance and verifies the effectiveness of linguistic resources on this task. To our knowledge, there are no work combining the attention mechanism and linguistic resources on this task before. This work gives inspirations to further research.		Jinyu Lu;Yuexian Hou	2018		10.1007/978-3-319-97310-4_32	computer science;artificial intelligence;convolutional neural network;machine learning;sentiment analysis;deep learning;semeval	NLP	-18.336762622589603	-71.66749928148063	159954
9b7745f293ab8c91c97c8110963b03ec80263f8c	contentful mental states for robot baby	logistics support;senses physiology;model redundancy;prototypes;indicators;words language;time series;time series analysis;problem formulation;artificial intelligence;algorithms;planning;csp;health;survey methods;algorithm design;surveys	In this paper we claim that meaningful representations can be learned by programs, although today they are almost always designed by skilled engineers. We discuss several kinds of meaning that representations might have, and focus on a functional notion of meaning as appropriate for programs to learn. Specifically, a representation is meaningful if it incorporates an indicator of external conditions and if the indicator relation informs action. We survey methods for inducing kinds of representations we call structural abstractions. Prototypes of sensory time series are one kind of structural abstraction, and though they are not denoting or compositional, they do support planning. Deictic representations of objects and prototype representations of words enable a program to learn the denotational meanings of words. Finally, we discuss two algorithms designed to find the macroscopic structure of episodes in a domain-independent way.	algorithm;institute for operations research and the management sciences;markov chain;mental state;ordinal data;prototype;robot;time series	Paul R. Cohen;Tim Oates;Carole R. Beal;Niall M. Adams	2002			computer science;artificial intelligence;machine learning;time series;algorithm;statistics	AI	-4.727318355182953	-76.82401627907635	159979
1517487539057c6568d40731ebd9c88ca810de59	the voice of personality: mapping nonverbal vocal behavior into trait attributions	social signal processing;personality trait;big five personality mode;personality assessment;signal processing;nonverbal vocal behavior	This paper reports preliminary experiments on automatic attribution of personality traits based on nonverbal vocal behavioral cues. In particular, the work shows how prosodic features can be used to predict, with an accuracy up to 75% depending on the trait, the personality assessments performed by human judges on a collection of 640 speech samples. The assessments are based on a short version of the Big Five Inventory, one of the most widely used questionnaires for personality assessment. The judges did not understand the language spoken in the speech samples so that the influence of the verbal content is limited. To tho best of our knowledge, this is the first work aimed at inferring automatically traits attributed by judges rather than traits self-reported by subjects.	experiment;speech synthesis	Gelareh Mohammadi;Alessandro Vinciarelli;Marcello Mortillaro	2010		10.1145/1878116.1878123	computer vision;alternative five model of personality;personality assessment inventory;computer science;signal processing	NLP	-13.566693187364757	-78.65699629157963	160294
cef293344cd42145d3a81dbd813e6453c9120d8a	pivot based language modeling for improved neural domain adaptation		Representation learning with pivot-based methods and with Neural Networks (NNs) have lead to significant progress in domain adaptation for Natural Language Processing. However, most previous work that follows these approaches does not explicitly exploit the structure of the input text, and its output is most often a single representation vector for the entire text. In this paper we present the Pivot Based Language Model (PBLM), a representation learning model that marries together pivot-based and NN modeling in a structure aware manner. Particularly, our model processes the information in the text with a sequential NN (LSTM) and its output consists of a context-dependent representation vector for every input word. Unlike most previous representation learning models in domain adaptation, PBLM can naturally feed structure aware text classifiers such as LSTM and CNN. We experiment with the task of cross-domain sentiment classification on 20 domain pairs and show substantial improvements over strong baselines.1	artificial neural network;context-sensitive language;domain adaptation;feature learning;language model;long short-term memory;machine learning;natural language processing;neural network software	Yftah Ziser;Roi Reichart	2018			natural language processing;machine learning;domain adaptation;computer science;artificial intelligence;language model	NLP	-18.34978478023371	-73.52334566064488	160439
9548cd216d9dd9f531f67f7c4549dbfae9086f15	a byte-sized approach to named entity recognition		In biomedical literature, it is common for entity boundaries to not align with word boundaries. Therefore, effective identification of entity spans requires approaches capable of considering tokens that are smaller than words. We introduce a novel, subword approach for named entity recognition (NER) that uses byte-pair encodings (BPE) in combination with convolutional and recurrent neural networks to produce byte-level tags of entities. We present experimental results on several standard biomedical datasets, namely the BioCreative VI Bio-ID, JNLPBA, and GENETAG datasets. We demonstrate competitive performance while bypassing the specialized domain expertise needed to create biomedical text tokenization rules.1	align (company);artificial neural network;biocreative;byte;end-to-end principle;experiment;named entity;named-entity recognition;recurrent neural network;substring;tokenization (data security)	Emily Sheng;Premkumar Natarajan	2018	CoRR		machine learning;tokenization (data security);subject-matter expert;byte;artificial intelligence;computer science;named-entity recognition;recurrent neural network	NLP	-18.92910438607569	-72.62275409364743	160596
41a84f10cbfcf917a0e42b11f903e5a15c114b39	sketch algorithms for estimating point queries in nlp	accurate statistic;sketch method;recent work;important nlp problem;frequency distribution;complete statistic;sketch algorithm;point query;nlp task;large corpus;novel variant	Many NLP tasks rely on accurate statistics from large corpora. Tracking complete statistics is memory intensive, so recent work has proposed using compact approximate “sketches” of frequency distributions. We describe 10 sketch methods, including existing and novel variants. We compare and study the errors (over-estimation and underestimation) made by the sketches. We evaluate several sketches on three important NLP problems. Our experiments show that one sketch performs best for all the three tasks.	approximation algorithm;capability maturity model;experiment;lookahead carry unit;maxima and minima;natural language processing;sketch;text corpus;tip (unix utility)	Amit Goyal;Hal Daumé;Graham Cormode	2012			computer science;theoretical computer science;machine learning;data mining;algorithm	NLP	-18.895411412002655	-78.13921672039264	160626
28162a8320a6c59d57b039f6a6de5f12e3553c2a	recurrent temporal deep field for semantic video labeling		Method Bldg Tree Sky Car Sign Road Pedestrian Fence Col. Pole Sidewalk Bicycle Class Avg. Global Avg. Depth Map [37] 85.3 57.3 95.4 69.2 46.5 98.5 23.8 44.3 22.0 38.1 28.7 55.4 82.1 Super Parsing [38] 87.0 67.1 96.9 62.7 30.1 95.9 14.7 17.9 1.7 70.0 19.4 51.2 83.3 High-order CRF [39] 84.5 72.6 97.5 72.7 34.1 95.3 34.2 45.7 8.1 77.6 28.5 59.2 83.8 CRF+Detector [40] 81.5 76.6 96.2 78.7 40.2 93.9 43.0 47.6 14.3 81.5 33.9 62.5 83.8 Neural Decision Tree[41] N/A 56.1 82.1 Deeplab [14] 82.7 91.7 89.5 76.7 33.7 90.8 41.6 35.9 17.9 82.3 45.9 62.6 84.6 CRFasRNN [20] 84.6 91.3 92.4 79.6 43.9 91.6 37.1 36.3 27.4 82.9 33.7 63.7 86.1 SegNet [2] 73.9 90.6 90.1 86.4 69.8 94.5 86.8 67.9 74.0 94.7 52.9 80.1 86.7 RTDF† 81.8 87.9 91.5 79.2 59.8 90.4 77.1 61.5 66.6 91.2 54.6 76.5 86.5 RTDF* 83.6 89.8 92.9 78.5 61.3 92.2 79.6 61.9 67.7 92.8 56.9 77.9 88.1 RTDF 87.1 85.2 93.7 88.3 64.3 94.6 84.2 64.9 68.8 95.3 58.9 80.5 89.9 Input	conditional random field;depth map;parsing	Peng Lei;Sinisa Todorovic	2016		10.1007/978-3-319-46454-1_19	artificial intelligence;artificial neural network;computer science;machine learning;unary operation;deconvolution;architecture;inference;conditional random field;latent variable;restricted boltzmann machine	Vision	-16.02924278091659	-73.01524257312805	161325
91803143354497b2462a1813e32ad3816c0aad90	a multi-model fusion framework based on deep learning for sentiment classification		With the development of the Internet, more and more data can be found on texts information. People produce texts information via writing blogs, product reviews, microblogs, film reviews and so on, which contain sentiments or opinions of the writer. User comments usually can reflect their intuitive feelings for a product. We can dig out relatively large value through sentiment analysis for these comments. Sentiment classification, as one of the most important tasks in sentiment analysis for many real world applications, is our main focus in this article. To improve the accuracy of sentiment classification, we propose a deep neural network fusion framework, which is composed of a multi-window CNN-LSTM model and a multi-window CNN-CNN model with the fusion of the probability of two models to generate final output. Experimental results instruct that our framework is quite feasible.	algorithm;artificial neural network;attribute grammar;blog;convolution;convolutional neural network;data mining;deep learning;internet;long short-term memory;network model;picture-in-picture;recurrent neural network;sentiment analysis;word embedding	Fen Yang;Jia Zhu;Xuming Wang;Xingcheng Wu;Yong Tang;Long Luo	2018	2018 IEEE 22nd International Conference on Computer Supported Cooperative Work in Design ((CSCWD))	10.1109/CSCWD.2018.8465209	task analysis;data mining;the internet;convolutional neural network;knowledge management;artificial neural network;deep learning;feature extraction;sentiment analysis;computer science;recurrent neural network;artificial intelligence	NLP	-17.571813323287905	-69.8998671310951	161340
1eeaa7e4835dae0613e3a0b35955dc40b224a572	entropy of a zipfian distributed lexicon		This article presents the calculation of the entropy of a system with Zipfian distribution and shows that a communication system tends to present an exponent value close to one, but still greater than one, so that it might maximize entropy and hold a feasible lexicon with an increasing size. This result is in agreement with what is observed in natural languages and with the balance between the speaker and listener communication efforts. On the other hand, the entropy of the communicating source is very sensitive to the exponent value as well as the length of the observable data, making it a poor parameter to characterize the communication process.	lexicon;zipf's law	L. C. Araujo;Thaïs Cristófaro Silva;Hani Yehia	2013	Glottometrics		speech recognition;computer science;artificial intelligence	NLP	-12.7049713334451	-78.77899264391984	161889
0e2cf7f75e076deb897300dfccbafb1a191d341f	style transfer as unsupervised machine translation		Language style transferring rephrases text with specific stylistic attributes while preserving the original attributeindependent content. One main challenge in learning a style transfer system is a lack of parallel data where the source sentence is in one style and the target sentence in another style. With this constraint, in this paper, we adapt unsupervised machine translation methods for the task of automatic style transfer. We first take advantage of style-preference information and word embedding similarity to produce pseudoparallel data with a statistical machine translation (SMT) framework. Then the iterative back-translation approach is employed to jointly train two neural machine translation (NMT) based transfer systems. To control the noise generated during joint training, a style classifier is introduced to guarantee the accuracy of style transfer and penalize bad candidates in the generated pseudo data. Experiments on benchmark datasets show that our proposed method outperforms previous state-of-the-art models in terms of both accuracy of style transfer and quality of input-output correspondence.	algorithm;benchmark (computing);experiment;iterative method;neural machine translation;parallel text;statistical classification;statistical machine translation;teaching method;word embedding	Zhirui Zhang;Shuo Ren;Shujie Liu;Jianyong Wang;Peng Chen;Mu Li;Ming Zhou;Enhong Chen	2018	CoRR		word embedding;machine translation;machine learning;artificial intelligence;computer science;classifier (linguistics);sentence	NLP	-18.492064529331067	-75.25637259321543	161935
aa90a466a2ff7781c36e7da7df0013aa5b117510	image to text conversion: state of the art and extended work		"""The aim of this article is to study the conversion of information between the different modalities (text, image) due to the evolution of human-machine communication that introduced the use of natural communication modalities to humans such as gestures, speech, sound and vision. In fact, one of the main challenges of this """"multimodal"""" learning is the learning of a shared representation between the distinct modalities and the prediction of the missing data (for example, by retrieval or synthesis) from a conditioned modality to another. Some researches work on the different types of conversions; Text to Speech, Speech to Picture or Text to Picture synthesis and vice-versa but in this paper we will focus on: Text to Picture (TTP) and Picture to Text (PTT) synthesis."""	accessibility;artificial intelligence;computer vision;missing data;modality (human–computer interaction);multimodal interaction;speech recognition;trusted third party	Nada Farhani;Naim Terbeh;Mounir Zrigui	2017	2017 IEEE/ACS 14th International Conference on Computer Systems and Applications (AICCSA)	10.1109/AICCSA.2017.159	real-time computing;computer science;natural language processing;modalities;metadata;decoding methods;visualization;missing data;speech synthesis;gesture;artificial intelligence	Vision	-8.537400499643848	-70.20493712522779	162030
51c2d1ec9b1fd20be3a6c332b12043e9df84be8d	application of artificial intelligence in tumors sizing classification for breast cancer		The staging in breast cancer is one of the most important prognostic factors. However, the complex coding TNM criteria, which includes clinical and pathological components, the existence of different versions of TNM classification guides over time, and the variability of the source used to obtain data, makes the manual collection of TNM staging in free text be variable and imprecise. The aim of this project is to develop a tool based on artificial intelligence that allows the collection of tumor size (T) staging data for breast cancer automatically, reducing the variability. Our approach, based on two steps, starts with the detection and extraction of tumor's size characteristics in free text, using a simple natural language processor. Secondly, based on the data extracted, we applied different data mining algorithms for the T classification such as the J48 classifier tree, LADtree and NaiveBayes. Then, structured TNM reports for patients are created.	algorithm;applications of artificial intelligence;data mining;disk staging;heart rate variability;natural language processing;spatial variability;the nameless mod	Ricardo Gonzalez-Otal;Jose Luis Lopez-Guerra;Carlos Luis Parra Calderón;Alicia Martinez-García;Alberto Moreno-Conde;Maria Jose Ortiz-Gordillo	2013			coding (social sciences);breast cancer;t classification;natural language;sizing;classifier (linguistics);c4.5 algorithm;artificial intelligence;computer science;stage (cooking)	AI	-5.1840896751577015	-70.6317399718193	162119
6a26e58e5b5702999369a3ea6ff4d96cb7bf0286	grammar-based and lexicon-based techniques to extract personality traits from text		Language provides an important source of information to predict human personality. However, most studies that have predicted personality traits using computational linguistic methods have focused on lexicon-based information. We investigate to what extent the performance of lexicon-based and grammarbased methods compare when predicting personality traits. We analyzed a corpus of student essays and their personality traits using two lexicon-based approaches, one top-down (Linguistic Inquiry and Word Count (LIWC)), one bottom-up (topic models) and one grammar-driven approach (Biber model), as well as combinations of these models. Results showed that the performance of the models and their combinations demonstrated similar performance, showing that lexicon-based topdown models and bottom-up models do not differ, and neither do lexicon-based models and grammar-based models. Moreover, combination of models did not improve performance. These findings suggest that predicting personality traits from text remains difficult, but that the performance from lexiconbased and grammar-based models are on par.	bottom-up parsing;information source;lexicon;text corpus;top-down and bottom-up design	Maira B. Carvalho;Max M. Louwerse	2017			language and thought;cognitive psychology;lexicon;computational linguistics;psychology;big five personality traits;personality;grammar	NLP	-13.0480409599261	-73.90597060528246	162398
5a1a856008925c5232c6caff81256c7a91919c94	end-to-end non-factoid question answering with an interactive visualization of neural attention weights		1 data -module: data.insuranceqa.v2 2 model -module: model.ap_lstm 3 training -module: training.dynamic 4 evaluation -module: evaluation.default 5 6 data: 7 embeddings: data/glove.6B.100d.txt 8 insuranceqa: data/insuranceQA 9 lowercased: true 10 .. 11 12 model: 13 lstm_cell_size: 141 14 margin: 0.2 15 trainable_embeddings: true 16 .. 17 18 training: 19 batchsize: 20 20 epochs: 100 21 save_folder: checkpoints/ap_lstm 22 dropout: 0.3 23 optimizer: adam 24 initial_learning_rate: 0.001 25 scorer: accuracy 26 .. 27 28 evaluation: 29 skip: true	dropout (neural networks);epoch (reference date);interactive visualization;mathematical optimization;question answering;wired glove	Andreas Rücklé;Iryna Gurevych	2017		10.18653/v1/P17-4004	machine learning;computer science;artificial intelligence;natural language processing;information retrieval;modular design;question answering;artificial neural network;factoid;strengths and weaknesses;interactive visualization;service-oriented architecture;user interface	ML	-17.54333168467351	-73.27960812531218	162681
20a410321809a8eafb9c08bcb18de8b7a43d937f	sparse neural networks with large learning diversity	diversity;error correcting code;memoire associative;systeme nerveux central;erasure;associative memory sparse neural networks learning phase coded recurrent neural networks coding rule binary neurons neural activity binary connections;parity check codes;codigo corrector error;neurons encoding artificial neural networks maximum likelihood decoding parity check codes associative memory;sistema n niveles;intelligence artificielle;classification;borradura;sistema nervioso central;artificial neural networks;error correction code;recurrent neural nets content addressable storage encoding learning artificial intelligence;systeme n niveaux;maximum likelihood decoding;neurofisiologia;multilevel system;effacement;neurophysiologie;associative memory;representacion parsimoniosa;memoria asociativa;artificial intelligence;reseau neuronal recurrent;inteligencia artificial;recurrent neural nets;neurons;recurrent neural network;neurophysiology;learning artificial intelligence;reseau neuronal;capacity;code correcteur erreur;content addressable storage;sparse representation;encoding;sparse coding;clique;clasificacion;red neuronal;central nervous system;learning machine;artificial neural network;sparse coding associative memory capacity classification clique diversity error correcting code learning machine recurrent neural network;computer simulation humans learning mental recall models neurological neural networks computer neurons;neural network;representation parcimonieuse	Coded recurrent neural networks with three levels of sparsity are introduced. The first level is related to the size of messages that are much smaller than the number of available neurons. The second one is provided by a particular coding rule, acting as a local constraint in the neural activity. The third one is a characteristic of the low final connection density of the network after the learning phase. Though the proposed network is very simple since it is based on binary neurons and binary connections, it is able to learn a large number of messages and recall them, even in presence of strong erasures. The performance of the network is assessed as a classifier and as an associative memory.	anatomic node;artificial neuron;biological neural networks;bitwise operation;cable;clique (graph theory);code;column (database);concordance (publishing);content-addressable memory;crossbreeding;directed graph;forward error correction;greater than;increment;information;jean;leigh syndrome , french canadian type;memory disorders;neural network simulation;neural networks;neural coding;neuroglia;neurons;new type;opening (morphology);plausibility structure;recurrent neural network;small;sparse matrix;speaking (activity);speculative execution;statistical classification;weight;contents - htmllinktype;message	Vincent Gripon;Claude Berrou	2011	IEEE Transactions on Neural Networks	10.1109/TNN.2011.2146789	winner-take-all;error detection and correction;computer science;artificial intelligence;theoretical computer science;machine learning;artificial neural network	ML	-11.776197836801643	-74.85536290156234	162803
51644181d6c69182664611501c2d849d4cb50339	retrieval term prediction using deep learning methods		This paper presents methods to predict retrieval terms from relevant/surrounding words or descriptive texts in Japanese by using deep learning methods, which are implemented with stacked denoising autoencoders (SdA), as well as deep belief networks (DBN). To determine the effectiveness of using DBN and SdA for this task, we compare them with conventional machine learning methods, i.e., multi-layer perceptron (MLP) and support vector machines (SVM). We also compare their performance in case of using three regularization methods, the weight decay (L2 regularization), sparsity (L1 regularization), and dropout regularization. The experimental results show that (1) adding automatically gathered unlabeled data to the labeled data for unsupervised learning is an effective measure for improving the prediction precision, and (2) using DBN or SdA results in higher prediction precision than using SVM or MLP, whether or not regularization methods are used.	bayesian network;bernoulli scheme;deep belief network;deep learning;domain-specific language;dropout (neural networks);euler–bernoulli beam theory;experiment;machine learning;matrix regularization;memory-level parallelism;multilayer perceptron;naive bayes classifier;noise reduction;sparse matrix;support vector machine;unsupervised learning	Qing Ma;Ibuki Tanigawa;Masaki Murata	2016			information retrieval;deep learning;artificial intelligence;computer science	ML	-17.297960974386744	-75.60286203160446	162900
436ff669f1d165a45cb2bf12eeb5ec394bea93b4	comparing computational cognitive models of generalization in a language acquisition task		Natural language acquisition relies on appropriate generalization: the ability to produce novel sentences, while learning to restrict productions to acceptable forms in the language. Psycholinguists have proposed various properties that might play a role in guiding appropriate generalizations, looking at learning of verb alternations as a testbed. Several computational cognitive models have explored aspects of this phenomenon, but their results are hard to compare given the high variability in the linguistic properties represented in their input. In this paper, we directly compare two recent approaches, a Bayesian model and a connectionist model, in their ability to replicate human judgments of appropriate generalizations. We find that the Bayesian model more accurately mimics the judgments due to its richer learning mechanism that can exploit distributional properties of the input in a manner consistent with human behaviour.	bayesian network;cognitive model;computation;connectionism;heart rate variability;natural language;self-replicating machine;testbed	Libby Barak;Adele E. Goldberg;Suzanne Stevenson	2016			computer science;elementary cognitive task;machine learning;artificial intelligence;language acquisition;natural language processing;cognition	NLP	-10.821709325839569	-75.84311766499968	163008
f9fb7979af4233c2dd14813da94ec7c38ce9232a	detecting gaze towards eyes in natural social interactions and its use in child assessment		Eye contact is a crucial element of non-verbal communication that signifies interest, attention, and participation in social interactions. As a result, measures of eye contact arise in a variety of applications such as the assessment of the social communication skills of children at risk for developmental disorders such as autism, or the analysis of turn-taking and social roles during group meetings. However, the automated measurement of visual attention during naturalistic social interactions is challenging due to the difficulty of estimating a subject’s looking direction from video. This paper proposes a novel approach to eye contact detection during adult-child social interactions in which the adult wears a point-of-view camera which captures an egocentric view of the child’s behavior. By analyzing the child’s face regions and inferring their head pose we can accurately identify the onset and duration of the child’s looks to their social partner’s eyes. We introduce the Pose-Implicit CNN, a novel deep learning architecture that predicts eye contact while implicitly estimating the head pose. We present a fully automated system for eye contact detection that solves the sub-problems of end-to-end feature learning and pose estimation using deep neural networks. To train our models, we use a dataset comprising 22 hours of 156 play session videos from over 100 children, half of whom are diagnosed with Autism Spectrum Disorder. We report an overall precision of 0.76, recall of 0.80, and an area under the precision-recall curve of 0.79, all of which are significant improvements over existing methods.	artificial neural network;deep learning;end-to-end principle;feature learning;humans;interaction;onset (audio);robot;sensor	Eunji Chong;Katha Chanda;Zhefan Ye;Audrey Southerland;Nataniel Ruiz;Rebecca M. Jones;Agata Rozga;James M. Rehg	2017	IMWUT	10.1145/3131902	computer science;gaze;human–computer interaction;autism;pose;deep learning;autism spectrum disorder;recall;artificial intelligence;feature learning;eye contact	HCI	-11.452948253590428	-71.02376375317196	163171
08f495b841ff3c39bc9fe5d36efa6e4beef6ecd8	recurrent neural network language model with structured word embeddings for speech recognition	standards;training;context modeling context recurrent neural networks standards computational modeling training;会议论文;n best rescoring recurrent neural network language model rnnlm structured word embeddings speech recognition effective word context encoding long term context preserving input word embeddings target word embeddings subword embeddings chinese subword units relative ppl improvement;computational modeling;speech recognition recurrent neural network word embeddings language model;recurrent neural networks;context modeling;speech recognition natural language processing recurrent neural nets;context	Due to effective word context encoding and long-term context preserving, recurrent neural network language model (RNNLM) has attracted great interest by showing better performance over back-off n-gram models and feed-forward neural network language models (FNNLM). However, it still has the difficulty of modelling words of very low frequency in training data. To address this issue, a new framework of structured word embedding is introduced to RNNLM, where both input and target word embeddings are factorized into weighted sum of the corresponding sub-word embeddings. The framework is instantiated for Chinese, where characters can be naturally used as the sub-word units. Experiments on a Chinese twitter LVCSR task showed that the proposed approach effectively outperformed the standard RNNLM, yielding a relative PPL improvement of 8:8% and an absolute 0:59% CER improvement in N-Best re-scoring.	artificial neural network;experiment;feedforward neural network;language model;n-gram;recurrent neural network;speech analytics;speech recognition;weight function;word embedding	Tianxing He;Xu Xiang;Yanmin Qian;Kai Yu	2015	2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2015.7179002	natural language processing;speech recognition;computer science;recurrent neural network;machine learning;time delay neural network;context model;computational model	NLP	-18.782070302515837	-74.62066392784888	163340
6e5c730c356c4d74cab8687a79ec95ada19783ba	the strange geometry of skip-gram with negative sampling		Despite their ubiquity, word embeddings trained with skip-gram negative sampling (SGNS) remain poorly understood. We find that vector positions are not simply determined by semantic similarity, but rather occupy a narrow cone, diametrically opposed to the context vectors. We show that this geometric concentration depends on the ratio of positive to negative examples, and that it is neither theoretically nor empirically inherent in related embedding algorithms.	algorithm;apache axis;encode;ibm notes;n-gram;sampling (signal processing);semantic similarity;text corpus;word embedding	David M. Mimno;Laure Thompson	2017			machine learning;computer science;artificial intelligence;gram;sampling (statistics)	NLP	-13.29266382965908	-68.60493454262783	164226
fa4041c4e1e1701b4fb073bdbce09da8b5c5af34	a bidirectional lstm approach with word embeddings for sentence boundary detection	sentence boundary detection;word embedding;recurrent neural network;long short-term memory	Recovering sentence boundaries from speech and its transcripts is essential for readability and downstream speech and language processing tasks. In this paper, we propose to use deep recurrent neural network to detect sentence boundaries in broadcast news by modeling rich prosodic and lexical features extracted at each inter-word position. We introduce an unsupervised word embedding to represent word identity, learned from the Continuous Bag-of-Words (CBOW) model, into sentence boundary detection task as an effective feature. The word embedding contains syntactic information that is essential for this detection task. In addition, we propose another two low-dimensional word embeddings derived from a neural network that includes class and context information to represent words by supervised learning: one is extracted from the projection layer, the other one comes from the last hidden layer. Furthermore, we propose a deep bidirectional Long Short Term Memory (LSTM) based architecture with Viterbi decoding for sentence boundary detection. Under this framework, the longrange dependencies of prosodic and lexical information in temporal sequences are modeled effectively. Compared with Chenglin Xu xuchenglin@ntu.edu.sg Lei Xie lxie@nwpu-aslp.org Xiong Xiao xiaoxiong@ntu.edu.sg 1 School of Computer Science, Northwestern Polytechnical University, Xi’an, China 2 Temasek Laboratories@NTU, Nanyang Technological University, Singapore, Singapore previous state-of-the-art DNN-CRF method, the proposed LSTM approach reduces 24.8% and 9.8% relative NIST SU error in reference and recognition transcripts, respectively.	artificial neural network;automated system recovery;bag-of-words model;computer science;conditional random field;data recovery;downstream (software development);elegant degradation;feature engineering;feature learning;long short-term memory;model-driven engineering;network architecture;one-hot;recurrent neural network;supervised learning;text corpus;unsupervised learning;word embedding;x image extension	Chenglin Xu;Lei Xie;Xiong Xiao	2018	Signal Processing Systems	10.1007/s11265-017-1289-8	artificial intelligence;artificial neural network;word embedding;viterbi decoder;syntax;machine learning;supervised learning;architecture;computer science;recurrent neural network;sentence;pattern recognition	NLP	-18.716431156345767	-74.19914927235153	164970
ae7d5992c208f4af9e62f38368b382a7c21e2c5f	a study on idiosyncratic handwriting with impact on writer identification		In this paper, we study handwriting idiosyncrasy in terms of its structural eccentricity. In this study, our approach is to find idiosyncratic handwritten text components and model the idiosyncrasy analysis task as a machine learning problem supervised by human cognition. We employ the Inception network for this purpose. The experiments are performed on two publicly available databases and an in-house database of Bengali offline handwritten samples. On these samples, subjective opinion scores of handwriting idiosyncrasy are collected from handwriting experts. We have analyzed the handwriting idiosyncrasy on this corpus which comprises the perceptive ground-truth opinion. We also investigate the effect of idiosyncratic text on writer identification by using the SqueezeNet. The performance of our system is promising.		Chandranath Adak;Bidyut Baran Chaudhuri;Michael Blumenstein	2018	2018 16th International Conference on Frontiers in Handwriting Recognition (ICFHR)	10.1109/ICFHR-2018.2018.00042	artificial intelligence;eccentricity (behavior);pattern recognition;bengali;idiosyncrasy;computer science;handwriting;cognition	Robotics	-18.634941622491827	-69.22822497534605	165303
c75b165166e9041a52a6ec3acddbb42ecfdbb9a6	lstm with sentence representations for document-level sentiment classification		Abstract Recently, due to their ability to deal with sequences of different lengths, neural networks have achieved a great success on sentiment classification. It is widely used on sentiment classification. Especially long short-term memory networks. However, one of the remaining challenges is to model long texts to exploit the semantic relations between sentences in document-level sentiment classification. Existing Neural network models are not powerful enough to capture enough sentiment messages from relatively long time-steps. To address this problem, we propose a new neural network model (SR-LSTM) with two hidden layers. The first layer learns sentence vectors to represent semantics of sentences with long short term memory network, and in the second layer, the relations of sentences are encoded in document representation. Further, we also propose an approach to improve it which first clean datasets and remove sentences with less emotional polarity in datasets to have a better input for our model. The proposed models outperform the state-of-the-art models on three publicly available document-level review datasets.	long short-term memory	Guozheng Rao;Weihang Huang;Zhiyong Feng;Qiong Cong	2018	Neurocomputing	10.1016/j.neucom.2018.04.045	artificial intelligence;machine learning;long short term memory;semantics;artificial neural network;pattern recognition;exploit;mathematics;sentence	NLP	-18.011879056019303	-71.97802091975642	165407
4d74c154b239afb86409298bf4279318beb5024d	singular interpretations linger during the processing of plural noun phrases		Plural nouns do not strictly refer to more than one object, which suggests that they are not semantically marked to mean “more than one” and that plurality inferences are made via a scalar implicature. Consistent with that hypothesis, recent evidence using a picture-matching paradigm supports founds that participants were equally fast to respond to a picture of a single object as a picture of multiple objects after reading a sentence containing a plural. This suggests that comprehenders activate both a semantic (i.e., singular) and a pragmatic interpretation (i.e., plural). The current study found that even after a 1500 ms delay, comprehenders still maintain activation of both meanings after reading a sentence containing a plural. This suggests that the activation of the singular meaning may not be due to the processing of a scalar implicature, but rather may be due to the nature of plural conceptual representations.	programming paradigm	Nikole D. Patson	2016			noun phrase;plural;psychology;cognitive psychology	NLP	-8.802999459612053	-77.09356084226019	165662
19ac38cde06ca199044e456c83a0f7d09d9ac056	computerized spatial language generation for object location	objects location and perceptual salience;computer systems;spatial language;virtual environment;spatial reference frames	Spatial language is the syntax used for object or place locations. Because an object location is inherently relative, it implies a frame of reference, which in turn may be aided by a reference object, other than the one to be located. This reference object is commonly selected based on its perceptual salience, that is, its more prominent features. Computer systems linked to various research areas have been developed to facilitate the communication and/or interpretation of spatial language for localization tasks. In this paper is presented a literature review of computer systems that adopt spatial language and perceptual salience for object location.	hardware description language;internationalization and localization;natural language generation	Graciela Lara López;Angélica de Antonio Jiménez;Adriana Peña Pérez Negrón	2016	Virtual Reality	10.1007/s10055-016-0289-5	natural language processing;computer vision;object-based spatial database;computer science;virtual machine;object;operating system	HCI	-7.390616505829527	-74.8428438809468	165938
ccad1255c9a606b3bb23999469c43f15a4aea76b	learning an executable neural semantic parser		This paper describes a neural semantic parser that maps natural language utterances onto logical forms which can be executed against a task-specific environment, such as a knowledge base or a database, to produce a response. The parser generates tree-structured logical forms with a transition-based approach which combines a generic tree-generation algorithm with domain-general grammar defined by the logical language. The generation process is modeled by structured recurrent neural networks, which provide a rich encoding of the sentential context and generation history for making predictions. To tackle mismatches between natural language and logical form tokens, various attention mechanisms are explored. Finally, we consider different training settings for the neural semantic parser, including fully supervised training where annotated logical forms are given, weakly-supervised training where denotations are provided, and distant supervision where only unlabeled sentences and a knowledge base are available. Experiments across a wide range of datasets demonstrate the effectiveness of our parser.		Jianpeng Cheng;Siva Reddy;Vijay Saraswat;Mirella Lapata	2017	Computational Linguistics	10.1162/coli_a_00342	natural language processing;recursive descent parser;programming language;artificial intelligence;knowledge base;parsing;natural language;computer science;glr parser;executable	NLP	-18.025093334066995	-73.79653057718514	166104
4303839bfd87af38bd35a1a57b5585aed1bd436c	hierarchical modeling to facilitate personalized word prediction for dialogue	text prediction;intelligent user interfaces;personalization;hierarchical model	The advent and ubiquity of mass-market portable computational devices has opened up new opportunities for the development of assistive technologies for disabilities, especially within the domain of augmentative and alternative communications (AAC) devices. Word prediction can facilitate everyday communication on mobile devices by reducing the physical interactions required to produce dialogue with them. To support personalized word prediction, a text prediction system should learn from the user’s own data to update the initial learned likelihoods that provide high quality “out of the box” performance. Within this lies an inherent trade-off: a larger corpus of initial training data can yield better default performance, but may also increase the amount of user data required for personalization of the system to be effective. We investigate a learning approach employing hierarchical modeling of phrases expected to offer sufficient “out of the box” performance relative to other learning approaches, while reducing the amount of initial training data required to facilitate on-line personalization of the text prediction system. The key insight of the proposed approach is the separation of stopwords, which primarily play syntactical roles in phrases, from keywords, which provide context and meaning in the phrase. This allows the abstraction of a phrase from an ordered list of all words to an ordered list of keywords. Thus the proposed hierarchical modeling of phrases employs two layers: keywords and stopwords. A third level abstracting the keywords to a single topic is also considered, combining the power of both topic modeling and trigrams to make predictions within and between layers. Empirically relaxed versions of the developed models are evaluated on training data composed of a mixture of slightly modified dialogues from the Santa Barbara Corpus of Spoken American English. Performance is measured in terms of the number of user interactions (keystroke or touch screen event) required to complete a phrase. We compare their performance against a system employing no prediction.	advanced audio coding;assistive technology;browser user interface;consciousness;display resolution;event (computing);fundamental interaction;hierarchical hidden markov model;input method;latent variable;lexical analysis;microsoft word for mac;mobile device;numerical weather prediction;online and offline;out of the box (feature);personalization;principle of abstraction;text corpus;thinking outside the box;topic model;touchscreen;trigram	Richard Gabriel Freedman;Jingyi Guo;William H. Turkett;Victor Paúl Pauca	2013			natural language processing;speech recognition;computer science;artificial intelligence;machine learning;data mining;personalization;hierarchical database model	NLP	-13.967990742388842	-75.92351616160937	166417
6209fb989c6d20145ae79335778456eab2cf71cf	language learning in large parameter spaces	parameter space;language learning	Various theories of linguistics have proposed that the differences among natural languages can be parameterized. Certainly syntactic theories such as Principles and Parameters (Chomsky, 1981) assume the existence of such parameters. Along with the problem of defining parameters, we need to address the problem of a child’s acquisition of the settings of these parameters. Several algorithms for parameter setting have been proposed and examined on small spaces. Unless we have a realistic space to study, we cannot fully understand the predictions of these algorithms. Having an implemented computational model of these algorithms is important for studying them at greater depths. This study examines one such parameter-setting algorithm in realistic spaces.	algorithm;computation;computational model;natural language;principles and parameters;spaces;theory	Karen T. Kohl	2000			natural language processing;algorithmic learning theory;speech recognition;computer science;machine learning;parameter space	AI	-10.791156744057826	-75.963329343403	166547
87f1bd51ddbbe553ad754519b79cb95ee787aba3	new recurrent neural network variants for sequence labeling		In this paper we study different architectures of Recurrent Neural Networks (RNN) for sequence labeling tasks. We propose two new variants of RNN and we compare them to the more traditional RNN architectures of Elman and Jordan. We explain in details the advantages of these new variants of RNNs with respect to Elman’s and Jordan’s RNN. We evaluate all models, either new or traditional, on three different tasks: POS-tagging of the French Treebank, and two tasks of Spoken Language Understanding (SLU), namely ATIS and MEDIA. The results we obtain clearly show that the new variants of RNN are more effective than the traditional ones.	recurrent neural network;sequence labeling	Marco Dinarelli;Isabelle Tellier	2016		10.1007/978-3-319-75477-2_10	computer science;sequence labeling;natural language processing;machine learning;treebank;spoken language;recurrent neural network;artificial intelligence	NLP	-18.712054466772194	-74.56581680884113	166761
6a473e9e0a2183928b2d78bddf4b3d01ff46c454	chunking with support vector machines	support vector machines;support vector machine;input data;kernel principle;: chunking;svms-based system;distinct chunk representation;english base phrase;high dimensional feature space;ma- jority voting;machine learning;base phrases chunking;high generalization performance;majority voting;higher accuracy;feature space	We apply Support Vector Machines (SVMs) to identify English base phrases (chunks). SVMs are known to achieve high generalization performance even with input data of high dimensional feature spaces. Furthermore, by the Kernel principle, SVMs can carry out training with smaller computational overhead independent of their dimensionality. We apply weighted voting of 8 SVMsbased systems trained with distinct chunk representations. Experimental results show that our approach achieves higher accuracy than previous approaches.	machine learning;overhead (computing);principle of maximum entropy;shallow parsing;support vector machine;the wall street journal	Taku Kudo;Yuji Matsumoto	2001			support vector machine;majority rule;feature vector;computer science;machine learning;pattern recognition;data mining;relevance vector machine	ML	-15.10558706152741	-66.84029757682936	166773
ab64a398892afec054c54af11cea281df5370fe9	effects of the mode of tempo change on perception of tempo change		Tempo is one of the basic factors in musical expression. Although there are studies on perception of tempo change, little is known about how the mode of tempo change affects sensitivity to the change. In this paper, we analyze the effects of modes of tempo change on perception of tempo change. Our analysis focuses on sensitivity to tempo change. Forty-six subject participants were divided into three groups according to their musical experience and the type of playing they are used to. ((A) 15 inexperienced, (B) 21 pianists mostly playing solo, (C) 10 players of musical instruments other than piano mostly playing in groups). We used synthetic piano single tone sequences that change tempo gradually from the common initial value to various target values as stimuli. We also manipulated the mode of tempo change: linear, exponential, and their average. Subject participants were asked to indicate the time point of perception by pressing a key as soon as they perceived the tempo change. Contrary to our presumptio...		Masuzo Yanagida;Seiichi Yamamoto;Ichiro Umata	2016	Proc. Meetings on Acoustics	10.1121/2.0000487	piano;mode (statistics);perception;musical expression;social psychology;time point;psychology	HCI	-4.737328303380019	-79.69111316766445	166815
6462e79a978d5aaee026d16e18b792c458afaf2e	textual inference and meaning representation in human robot interaction		This paper provides a first investigation over existing textual inference paradigms in order to propose a generic framework able to capture major semantic aspects in Human Robot Interaction (HRI). We investigate the use of general semantic paradigms used in Natural Language Understanding (NLU) tasks, such as Semantic Role Labeling, over typical robot commands. The semantic information obtained is then represented under the Abstract Meaning Representation. AMR is a general representation language useful to express different level of semantic information without a strong dependence to the syntactic structure of an underlying sentence. The final aim of this work is to find an effective synergy between HRI and NLU.	adaptive multi-rate audio codec;automated planning and scheduling;human–robot interaction;nl (complexity);natural language understanding;robot;semantic role labeling;synergy;theory;unified framework	Emanuele Bastianelli;Giuseppe Castellucci;Danilo Croce;Roberto Basili	2013			natural language processing;semantic role labeling;natural language understanding;syntax;inference;computer science;human–robot interaction;sentence;artificial intelligence	AI	-14.421252524813005	-68.84508680363736	166910
19ceaa9a914fc192916b0631d69f9aa0963264c7	blcu_nlp at semeval-2018 task 12: an ensemble model for argument reasoning based on hierarchical attention		The argument comprehension reasoning task aims to reconstruct and analyze the argument reasoning. To comprehend an argument and fill the gap between claims and reasons, it is vital to find the implicit supporting warrants behind. In this paper, we propose a hierarchical attention model to identify the right warrant which explains why the reason stands for the claim. Our model focuses not only on the similar part between warrants and other information but also on the contradictory part between two opposing warrants. In addition, we use the ensemble method for different models. Our model achieves an accuracy of 61%, ranking second in this task. Experimental results demonstrate that our model is effective to make correct choices.	argument map;list comprehension	Meiqian Zhao;Chunhua Liu;Lu Liu;Yan Zhao;Dong Yu	2018			natural language processing;machine learning;semeval;artificial intelligence;computer science;ensemble forecasting	NLP	-16.409000588591827	-69.62724539264596	166980
9ac0de608cf939d141959ae24727fa018d0942f5	negative congruence effects in letter and pseudo-letter recognition: the role of similarity and response conflict		Letters and pseudo-letters were presented in three experiments using a sequential same-different task. While first items were always presented in isolation, the second item was either presented in isolation or surrounded by geometrical non-target shapes that could be congruent or incongruent to the target. In two experiments, a physical sameness criterion was used. In Experiment 1, in one condition, different pairs were always distinct in shape, in another they were similar in shape. Negative congruence effects were obtained for different pairs that are similar. In Experiment 2, this effect is replicated within participants. In this experiment, similar and dissimilar stimuli were mixed. The results were explained in terms of the difficulty of responding different to stimuli that are similar in shape: when the second item is surrounded by a congruent shape, the similarity is emphasized, making this response even more difficult. In Experiment 3, the same stimuli were presented using a categorical sameness criterion. This reduces the role of physical similarity and thus eliminates the response conflict. As a result, negative congruence effects were no longer observed. Taken together, the three experiments identify another source of negative congruence effects besides the ones recently reported in the literature.	congruence of squares;experiment;zeller's congruence	Thomas Lachmann;Cees van Leeuwen	2004	Cognitive Processing	10.1007/s10339-004-0032-0	artificial intelligence;communication;social psychology	HCI	-7.0493598038103435	-76.84503681643248	167596
3a296f810d430a48f17952c415bc876111e0fffa	(self-attentive) autoencoder-based universal language representation for machine translation		Universal language representation is the holy grail in machine translation (MT). Thanks to the new neural MT approach, it seems that there are good perspectives towards this goal. In this paper, we propose a new architecture based on combining variational autoencoders with encoder-decoders, and introducing an interlingual loss as an additional training objective. By adding and forcing this interlingual loss, we are able to train multiple encoders and decoders for each language, sharing a common universal representation. Since the final objective of this universal representation is producing close results for similar input sentences (in any language), we propose to evaluate it by encoding the same sentence in two different languages, decoding both latent representations into the same language and comparing both outputs. Preliminary results on the WMT 2017 Turkish/English task shows that the proposed architecture is capable of learning a universal language representation and simultaneously training both translation directions with state-of-the-art results.	artificial neural network;autoencoder;automatic equipment identification;baseline (configuration management);binary decoder;encoder;intermediate representation;machine translation;parallel text;variational principle	Carlos Escolano;Marta R. Costa-Jussà;José A. R. Fonollosa	2018	CoRR		natural language processing;machine translation;machine learning;autoencoder;artificial intelligence;encoding (memory);universal language;decoding methods;architecture;holy grail;computer science;sentence	NLP	-17.69749242203452	-74.75615978178536	167613
004c30db08506c6ecbbbb595b73d943e96b8654b	matetee: a semantic similarity metric based on translation embeddings for knowledge graphs		Large Knowledge Graphs (KGs), e.g., DBpedia or Wikidata, are created with the goal of providing structure to unstructured or semi-structured data. Having these special datasets constantly evolving, the challenge is to utilize them in a meaningful, accurate, and efficient way. Further, exploiting semantics encoded in KGs, e.g., class and property hierarchies, provides the basis for addressing this challenge and producing a more accurate analysis of KG data. Thus, we focus on the problem of determining relatedness among entities in KGs, which corresponds to a fundamental building block for any semantic data integration task. We devise MateTee, a semantic similarity measure that combines the gradient descent optimization method with semantics encoded in ontologies, to precisely compute values of similarity between entities in KGs. We empirically study the accuracy of MateTee with respect to state-of-the-art methods. The observed results show that MateTee is competitive in terms of accuracy with respect to existing methods, with the advantage that background domain knowledge is not required.	knowledge graph;semantic similarity	Camilo Morales;Diego Collarana;Maria-Esther Vidal;Sören Auer	2017		10.1007/978-3-319-60131-1_14	machine learning;semantic data model;semantic similarity;domain knowledge;data mining;similarity measure;computer science;ontology (information science);stochastic gradient descent;semantics;gradient descent;artificial intelligence	NLP	-16.476628473987734	-66.61569810608641	167860
4d06b6d3bf332316446d35817cb4b481a716bf90	adaptive multi-compositionality for recursive neural models with applications to sentiment analysis	recursive neural network;sentiment classification;deep learning;semantic composition	Recursive neural models have achieved promising results in many natural language processing tasks. The main difference among these models lies in the composition function, i.e., how to obtain the vector representation for a phrase or sentence using the representations of words it contains. This paper introduces a novel Adaptive Multi-Compositionality (AdaMC) layer to recursive neural models. The basic idea is to use more than one composition functions and adaptively select them depending on the input vectors. We present a general framework to model each semantic composition as a distribution over these composition functions. The composition functions and parameters used for adaptive selection are learned jointly from data. We integrate AdaMC into existing recursive neural models and conduct extensive experiments on the Stanford Sentiment Treebank. The results illustrate that AdaMC significantly outperforms state-of-the-art sentiment classification methods. It helps push the best accuracy of sentence-level negative/positive classification from 85.4% up to 88.5%. Introduction Recursive Neural Models (RNMs), which utilize the recursive structure of the input (e.g., a sentence), are one family of popular deep learning models. They are particularly effective for many Natural Language Processing (NLP) tasks due to the compositional nature of natural language. Recently, many promising results have been reported on semantic relationship classification (Socher et al. 2012), syntactic parsing (Socher et al. 2013a), sentiment analysis (Socher et al. 2013b), and so on. The main difference among RNMs lies in the semantic composition method, i.e., how to obtain the vector representation for a phrase or sentence using the representations of words and phrases it contains. For instance, we can compute the word vector for the phrase “not good” with the vectors of the words “not” and “good”. For many tasks, we even need to obtain the vector representations for sentences. The composition algorithm becomes the key to make the vector representations go beyond words to phrases and sentences. ⇤Contribution during internship at Microsoft Research. Copyright c 2014, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. There have been several attempts in literature to address the semantic composition for RNMs. Specifically, RNN (Socher et al. 2011) uses a global matrix to linearly combine the elements of vectors, while RNTN (Socher et al. 2013b) employs a global tensor to model the products of dimensions. Sometimes it is challenging to find a single powerful function to model the semantic composition. Intuitively, we can employ multiple composition functions, instead of only using a single global one. Instead of finding more complex composition functions, MV-RNN (Socher et al. 2012) assigns matrices for every words to make the compositions specific. However, the number of composition matrices is the same as vocabulary size, which makes the number of parameters quite large. It is easy to overfit the training data and difficult to be optimized. Moreover, MVRNN needs another global matrix to linearly combine the composition matrices for phrases, which still makes these compositions not specific. In order to overcome these shortcomings and make the compositions specific, it is better to use a certain number of composition functions, and embed the role-sensitive (linguistic and semantic) information into word vectors to adaptively select these compositions rather than concrete words. The example “not (so good)” in sentiment analysis illustrates this point. To obtain the polarity of this phrase, we firstly combine the words “so” and “good”, then combine the “not” and “so good”. Specifically, the first combination is a strengthen composition which makes the sentiment polarity stronger, and the second step is a negation composition which negates the positive polarity to negative. In this paper, we introduce a novel Adaptive MultiCompositionality (AdaMC) method for RNMs. AdaMC consists of more than one composition functions, and adaptively selects them depending on the input vectors. The model learns to embed the semantic categories of words into their corresponding word vectors, and uses them to choose these composition functions adaptively. Specifically, we propose a parametrization method to compute the probability distribution for every function given the child vectors. We also introduce a hyper-parameter to model the adaptive preferences over the different composition functions and show three special cases of AdaMC. By adjusting this hyperparameter, there is a continuous transition between these three special cases. Moreover, all these composition functions and how to select them are automatically learned from Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence	adaptive grammar;algorithm;artificial intelligence;deep learning;experiment;mv-algebra;microsoft research;natural language processing;overfitting;parsing;part-of-speech tagging;random neural network;recursion (computer science);sentiment analysis;treebank;vocabulary;word embedding	Li Dong;Furu Wei;Ming Zhou;Ke Xu	2014			natural language processing;computer science;artificial intelligence;recurrent neural network;machine learning;pattern recognition;deep learning;statistics	AI	-18.58012435832479	-73.7709921295228	168009
42f4aeff8219942153104c3ed5d9d661663d0cd3	saliency revisited: analysis of mouse movements versus fixations		This paper revisits visual saliency prediction by evaluating the recent advancements in this field such as crowd-sourced mouse tracking-based databases and contextual annotations. We pursue a critical and quantitative approach towards some of the new challenges including the quality of mouse tracking versus eye tracking for model training and evaluation. We extend quantitative evaluation of models in order to incorporate contextual information by proposing an evaluation methodology that allows accounting for contextual factors such as text, faces, and object attributes. The proposed contextual evaluation scheme facilitates detailed analysis of models and helps identify their pros and cons. Through several experiments, we find that (1) mouse tracking data has lower inter-participant visual congruency and higher dispersion, compared to the eye tracking data, (2) mouse tracking data does not totally agree with eye tracking in general and in terms of different contextual regions in specific, and (3) mouse tracking data leads to acceptable results in training current existing models, and (4) mouse tracking data is less reliable for model selection and evaluation. The contextual evaluation also reveals that, among the studied models, there is no single model that performs best on all the tested annotations.	crowdsourcing;database;experiment;eye tracking;lazy evaluation;model selection;mouse tracking	Hamed R. Tavakoli;Fawad Ahmed;Ali Borji;Jorma Laaksonen	2017	2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	10.1109/CVPR.2017.673	artificial intelligence;machine learning;computer vision;mouse tracking;salience (neuroscience);fixation (psychology);pattern recognition;computer science;model selection;visualization;context model;eye tracking	Vision	-11.796525117618788	-73.53465982736994	168019
52298e174d5c41c48adddee9865840b7e4bd5729	logical metonymy in a distributional model of sentence comprehension		In theoretical linguistics, logical metonymy is defined as the combination of an event-subcategorizing verb with an entity-denoting direct object (e.g., The author began the book), so that the interpretation of the VP requires the retrieval of a covert event (e.g., writing). Psycholinguistic studies have revealed extra processing costs for logical metonymy, a phenomenon generally explained with the introduction of new semantic structure. In this paper, we present a general distributional model for sentence comprehension inspired by the Memory, Unification and Control model by Hagoort (2013, 2016). We show that our distributional framework can account for the extra processing costs of logical metonymy and can identify the covert event in a classification task. 1 Logical Metonymy: Psycholinguistic Evidence and Computational Modeling The interpretation of so-called logical metonymy (e.g, The student begins the book) has received an extensive attention in both psycholinguistic and linguistic research. The phenomenon is extremely problematic for traditional theories of compositionality (Asher, 2015) and is generally explained as a type clash between an eventselecting metonymic verb (e.g., begin) and an entity-denoting nominal object (e.g., the book), which triggers the recovery of a hidden event (e.g., reading). Past research work brought extensive evidence that such metonymic constructions also determine extra processing costs during online sentence comprehension (McElree et al., 2001; Traxler et al., 2002), although such evidence is not uncontroversial (Falkum, 2011). According to Frisson and McElree (2008), event recovery is triggered by the type clash, and the extra processing load is due to ”the deployment of operations to construct a semantic representation of the event”. Thus, logical metonymy raises two major questions: i.) How is the hidden event recovered? ii.) What is the relationship between such mechanism and the increase in processing difficulty? One of the first accounts of the phenomenon dates back to the works of Pustejovsky (1995) and Jackendoff (1997), which assume that the covert event is retrieved from complex lexical entries consisting of rich knowledge structures (Pustejovsky’s qualia roles). For example, the representation of a noun like book includes telic properties (the purpose of the entity, e.g. read) and agentive properties (the mode of creation of the entity, e.g. write). The predicate-argument type mismatch triggers the retrieval of a covert event from the object noun qualia roles, thereby producing a semantic representation equivalent to begin to write the paper (see also the discussion in Traxler et al. (2002)). On the one hand, the lexicalist explanation is very appealing, since it accounts for the existence of default interpretations of logical metonymies (e.g. begin the book is typically interpreted as begin reading/writing the book). On the other hand, Lascarides and Copestake (1998) and more recently Zarcone et al. (2014) show that qualia roles are simply not flexible enough to account for the wide variety of interpretations that can be retrieved. These are in fact affected by the subject choice, the general syntactic and discourse context, and by our world knowledge. 1 Consider the classical example from Lascarides and Copestake (1998): My goat eats anything. He really enjoys	bridging (networking);commonsense knowledge (artificial intelligence);computation;distributional semantics;han unification;james pustejovsky;list comprehension;our world;software deployment;theory;turned a;word lists by frequency	Emmanuele Chersoni;Alessandro Lenci;Philippe Blache	2017		10.18653/v1/S17-1021	metonymy;distributional semantics;linguistics;comprehension;psycholinguistics;mathematics;sentence	NLP	-10.005997165693458	-73.8602165775239	168305
5259b484e6d64ecbf3474d2f1c65fd578409631a	modeling semantic expectation: using script knowledge for referent prediction		Recent research in psycholinguistics has provided increasing evidence that humans predict upcoming content. Prediction also affects perception and might be a key to robustness in human language processing. In this paper, we investigate the factors that affect human prediction by building a computational model that can predict upcoming discourse referents based on linguistic knowledge alone vs. linguistic knowledge jointly with common-sense knowledge in the form of scripts. We find that script knowledge significantly improves model estimates of human predictions. In a second study, we test the highly controversial hypothesis that predictability influences referring expression type but do not find evidence for such an effect.	computational model;robustness (computer science)	Ashutosh Modi;Ivan Titov;Vera Demberg;Asad B. Sayeed;Manfred Pinkal	2017	Transactions of the Association for Computational Linguistics	10.1162/tacl_a_00044	machine learning;robustness (computer science);computer science;natural language processing;artificial intelligence;predictability;psycholinguistics;perception;referent;scripting language;referring expression	NLP	-12.121823305119735	-73.78147643735255	168386
8ce4b07b42bafe48d87c56f4520e10d4d85df239	auxiliary objectives for neural error detection models		We investigate the utility of different auxiliary objectives and training strategies within a neural sequence labeling approach to error detection in learner writing. Auxiliary costs provide the model with additional linguistic information, allowing it to learn general-purpose compositional features that can then be exploited for other objectives. Our experiments show that a joint learning approach trained with parallel labels on in-domain data improves performance over the previous best error detection system. While the resulting model has the same number of parameters, the additional objectives allow it to be optimised more efficiently and achieve better performance.	error detection and correction;experiment;general-purpose modeling;sequence labeling	Marek Rei;Helen Yannakoudakis	2017			error detection and correction;sequence labeling;artificial intelligence;computer science;machine learning;rule-based machine translation	NLP	-18.165656953046927	-75.35313342254302	169013
ff7782600ae5677f6159fc89d8a8e31644eca38b	computational simulations of second language construction learning		There are few computational models of second language acquisition (SLA). At the same time, many questions in the field of SLA remain unanswered. In particular, SLA patterns are difficult to study due to the large amount of variation between human learners. We present a computational model of second language construction learning that allows manipulating specific parameters such as age of onset and amount of exposure. We use the model to study general developmental patterns of SLA and two specific effects sometimes found in empirical studies: construction priming and a facilitatory effect of skewed frequencies in the input. Our simulations replicate the expected SLA patterns as well as the two effects. Our model can be used in further studies of various	computation;computational model;computer simulation;onset (audio);self-replicating machine;service-level agreement	Yevgen Matusevych;Afra Alishahi;Ad Backus	2013			natural language processing;simulation;computer science;communication	HCI	-10.450205163998616	-76.80821695924597	169043
a0fdacee0f215295e62f172f4cd2cf114c129c2e	from synsets to videos: enriching italwordnet multimodally		The paper describes the multimodal enrichment of ItalWordNet action verbs’ entries by means of an automatic mapping with a conceptual ontology of action types instantiated by video scenes (ImagAct). The two resources present significative differences as well as interesting complementary features, such that a mapping of these two resources can lead to a an enrichment of IWN, through the connection between synsets and videos apt to illustrate the meaning described by glosses. Here, we describe an approach inspired by ontology matching methods for the automatic mapping of ImagAct video scenes onto ItalWordNet. The experiments described in the paper are conducted on Italian, but the same methodology can be extended to other languages for which WordNets have been created, since ImagAct is available also for English, Chinese and Spanish. This source of multimodal information can be exploited to design second language learning tools, as well as for language grounding in action recognition in video sources and potentially for robotics.	experiment;gene ontology term enrichment;lexical definition;multimodal interaction;ontology alignment;robotics;synonym ring;wordnet	Roberto Bartolini;Valeria Quochi;Irene De Felice;Irene Russo;Monica Monachini	2014			natural language processing;artificial intelligence;language acquisition;ontology alignment;ontology;computer science;robotics	AI	-15.079550205014128	-69.24110010082575	169063
a90deeb41b811461f8e0a62a82e8b0776e5b90dd	learning social affordance grammar from videos: transferring human interactions to human-robot interactions		In this paper, we present a general framework for learning social affordance grammar as a spatiotemporal AND-OR graph (ST-AOG) from RGB-D videos of human interactions, and transfer the grammar to humanoids to enable a real-time motion inference for human-robot interaction (HRI). Based on Gibbs sampling, our weakly supervised grammar learning can automatically construct a hierarchical representation of an interaction with long-term joint sub-tasks of both agents and short term atomic actions of individual agents. Based on a new RGB-D video dataset with rich instances of human interactions, our experiments of Baxter simulation, human evaluation, and real Baxter test demonstrate that the model learned from limited training data successfully generates human-like behaviors in unseen scenarios and outperforms both baselines.	baseline (configuration management);baxter (robot);experiment;gibbs sampling;humans;human–robot interaction;language model;linearizability;real-time locating system;real-time web;robot;sampling (signal processing);simulation;social affordance	Tianmin Shu;Xiaofeng Gao;Michael S. Ryoo;Song-Chun Zhu	2017	2017 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2017.7989197	computer science;artificial intelligence;machine learning	Robotics	-11.099654212195501	-69.95039521780554	169545
391e4089f931fd3b8252456f7394239ef4d57349	cognitive similarity grounded by tree distance from the analysis of k.265/300e		Lerdahl and Jackendoff’s theory employed a tree in a representation of internal structure of music. In order for us to claim that such a tree is a consistent and stable representation, we argue that the difference of trees should correctly reflect our coginitive similarity of music. We report our experimental result concerning the comparison of similarity among variations on Ah vous dirai-je, maman, K. 265/300e by Mozart. First we measure the theoretical distance between two variations by the sum of the lengths of time-spans, and then we compare the result with the human psychological resemblance. We show the statistical analysis, and discuss the adequacy of the distance as a metric of similarity, which moreover becomes a metrics of theory.	cognitive tutor;tree (data structure)	Keiji Hirata;Satoshi Tojo;Masatoshi Hamanaka	2013		10.1007/978-3-319-12976-1_36	combinatorics;discrete mathematics;artificial intelligence;machine learning;mathematics	NLP	-6.253355834019658	-79.76701412378813	169816
64c30b2fa8bf625ed45d0ca2da48143e8ff0ef4d	using exponential kernel for word sense disambiguation	exponential kernel;support vector machine svm;会议论文;word sense disambiguation wsd;kernel method;natural language processing	"""The success of machine learning approaches to word sense disambiguation (WSD) is largely dependent on the representation of the context in which an ambiguous word occurs. Typically, the contexts are represented as the vector space using """"Bag of Words (BoW)"""" technique. Despite its ease of use, BoW representation suffers from well-known limitations, mostly due to its inability to exploit semantic similarity between terms. In this paper, we apply the exponential kernel, which models semantic similarity by means of a diffusion process on a graph defined by lexicon and co-occurrence information, to smooth the BoW representation for WSD. Exponential kernel virtually exploits higher order co-occurrences to infer semantic similarities in an elegant way. The superiority of the proposed method is demonstrated experimentally with several SensEval disambiguation tasks."""	kernel (operating system);word sense;word-sense disambiguation	Tinghua Wang;Junyang Rao;Dongyan Zhao	2013		10.1007/978-3-642-40728-4_68	natural language processing;kernel method;speech recognition;semeval;computer science;machine learning;pattern recognition;mathematics	NLP	-17.51853668354716	-67.91303233490034	170074
e94697b98b707f557436e025bdc8498fa261d3bc	multi-perspective context matching for machine comprehension		Previous machine comprehension (MC) datasets are either too small to train endto-end deep learning models, or not difficult enough to evaluate the ability of current MC techniques. The newly released SQuAD dataset alleviates these limitations, and gives us a chance to develop more realistic MC models. Based on this dataset, we propose a Multi-Perspective Context Matching (MPCM) model, which is an end-to-end system that directly predicts the answer beginning and ending points in a passage. Our model first adjusts each word-embedding vector in the passage by multiplying a relevancy weight computed against the question. Then, we encode the question and weighted passage by using bi-directional LSTMs. For each point in the passage, our model matches the context of this point against the encoded question from multiple perspectives and produces a matching vector. Given those matched vectors, we employ another bi-directional LSTM to aggregate all the information and predict the beginning and ending points. Experimental result on the test set of SQuAD shows that our model achieves a competitive result on the leaderboard.	aggregate data;deep learning;encode;end system;end-to-end principle;feature vector;list comprehension;long short-term memory;relevance;test set	Zhiguo Wang;Haitao Mi;Wael Hamza;Radu Florian	2016	CoRR		computer science;artificial intelligence;machine learning;algorithm	NLP	-16.817220711450656	-72.00786373815326	170234
16f125ce5d03b56779cf8d144e8ea1c49e7fd8a6	the fabric of thought: priming tactile properties during reading influences direct tactile perception	embodied cognition;tactile imagery;language	The present studies examined whether implied tactile properties during language comprehension influence subsequent direct tactile perception, and the specificity of any such effects. Participants read sentences that implicitly conveyed information regarding tactile properties (e.g., Grace tried on a pair of thick corduroy pants while shopping) that were either related or unrelated to fabrics and varied in implied texture (smooth, medium, rough). After reading each sentence, participants then performed an unrelated rating task during which they felt and rated the texture of a presented fabric. Results demonstrated that the texture properties implied in sentences influence direct tactile perception. Specifically, after reading about a smooth or rough texture, subsequent fabric ratings became notably smoother or rougher, respectively. However, we also show that there was some specificity to these effects: Fabric-related sentences elicited more specific and interactive effects on subsequent ratings. Together, we demonstrate that under certain circumstances, language comprehension can prime tactile representations and affect direct tactile perception. Results are discussed with regard to the nature and scope of multimodal mental simulation during reading.	list comprehension;multimodal interaction;priming exercise;rating (action);sensitivity and specificity;simulation;textiles;touch perception;sentence;visual perception, sensory transduction of light stimulus	Tad T. Brunyé;Eliza K. Walters;Tali Ditman;Stephanie A. Gagnon;Caroline R. Mahoney;Holly A. Taylor	2012	Cognitive science	10.1111/j.1551-6709.2012.01268.x	psychology;cognitive psychology;embodied cognition;linguistics;language;communication;social psychology	HCI	-7.299184939041299	-76.8096696216261	170675
0e873f084cbb2445f87543236b84cdc53dcc3551	learning kernels for semantic clustering: a deep approach		In this thesis proposal we present a novel semantic embedding method, which aims at consistently performing semantic clustering at sentence level. Taking into account special aspects of Vector Space Models (VSMs), we propose to learn reproducing kernels in classification tasks. By this way, capturing spectral features from data is possible. These features make it theoretically plausible to model semantic similarity criteria in Hilbert spaces, i.e. the embedding spaces. We could improve the semantic assessment over embeddings, which are criterion-derived representations from traditional semantic vectors. The learned kernel could be easily transferred to clustering methods, where the Multi-Class Imbalance Problem is considered (e.g. semantic clustering of definitions of terms).	cluster analysis;entity;harris affine region detector;hilbert space;kernel (operating system);knowledge organization;linear separability;mathematical morphology;natural language processing;ontology learning;semantic similarity;word lists by frequency;yang	Ignacio Arroyo-Fernández	2015			natural language processing;semantic computing;machine learning;cluster analysis;conceptual clustering	NLP	-17.650812816027	-67.10135234483438	170973
a7b3315c020681c3a142c8471500eb629cb57fdb	applying textual entailment to the interpretation of metaphor	text analysis;term similarity metaphor interpretation human language abstract concepts natural language understanding question answering lexical substitution word sense disambiguation semantic content figurative language metaphoric language understanding entailment detection paraphrase detection textual entailment system lexical entailment metaphoric context metaphorical text interpretation machine learning system verbal metaphors;textual entailment metaphoric interpretation;text analysis learning artificial intelligence natural language processing;training data context analytical models semantics data models training computational modeling;learning artificial intelligence;textual entailment;metaphoric interpretation;natural language processing	Metaphor is a pervasive feature of human language that enables us to conceptualize and communicate abstract concepts using more concrete terminology. Unfortunately, computational models of natural language understanding - including systems for question answering, textual entailment, lexical substitution, and word-sense disambiguation - are unable to appropriately grasp the semantic content of metaphor and other forms of figurative language. In particular, we address the problem of understanding metaphoric language in the context of entailment (or paraphrase) detection. We build upon our existing state-of-the-art textual entailment system to specifically address issues of lexical entailment within a metaphoric context and have performed an in-depth experimental analysis to determine which techniques are most effective at interpreting metaphorical text. Our results suggest that a machine learning system trained on metaphor-rich data can achieve an accuracy above 90% for verbal metaphors using a combination of lexical, semantic, and contextual measures of term similarity.	algorithm;computational model;display resolution;gene ontology term enrichment;general-purpose modeling;lexical substitution;machine learning;natural language understanding;norm (social);pervasive informatics;question answering;textual entailment;word sense;word-sense disambiguation;wordnet	Michael Mohler;Marc T. Tomlinson;David B. Bracewell	2013	2013 IEEE Seventh International Conference on Semantic Computing	10.1109/ICSC.2013.30	natural language processing;text graph;text mining;textual entailment;computer science;linguistics	NLP	-16.46363580519047	-68.72837826132776	171044
2c6f7e50175bdccd375a6f41aabdba44610ff3b1	multi grain sentiment analysis using collective classification	data and knowledge engineering;sentiment analysis	Multi grain sentiment analysis is the task of simultaneously classifying sentiment expressed at different levels of granularity, as opposed to single level at a time. Models built for multi grain sentiment analysis assume fully labeled corpus at fine grained level or coarse grained level or both. Huge amount of online reviews are not fully labeled at any of the levels, but are partially labeled at both the levels. We propose a multi grain collective classification framework to not only exploit the information available at all the levels but also use intra dependencies at each level and inter dependencies between the levels. We demonstrate empirically that the proposed framework enables better performance at both the levels compared to baseline approaches.	baseline (configuration management);emoticon;image scaling;iterative method;knowledge base;lexicon;n-gram;sentiment analysis;sparse matrix	S. Shivashankar;Balaraman Ravindran	2010		10.3233/978-1-60750-606-5-823	computer science;data science;data mining;world wide web	NLP	-18.89681254241539	-71.01437738982708	171125
e48dec932b44b16cd586a7d3c698b7270b5dc62d	the clustering of natural terms: an adaptive resonance theory model	natural languages;linguistics natural languages art neural nets pattern classification;pattern classification;word meaning clustering adaptive resonance theory model lexicographic analysis natural language art neural nets pattern classification;native speaker;art neural nets;resonance pattern classification dairy products psychology glass databases marine animals computational modeling stability backpropagation;adaptive resonance theory;linguistics	Adaptive Resonance Theory i s shown to model polysemous lexical relations. The model derives the relations from indirect subjective property rating judgements provided by naive native speakers. The relations derived correspond closely to relations given in an independent corpus-based lexicographic analysis.	adaptive resonance theory;cluster analysis;lexicographical order;text corpus	George Dunbar	1999		10.1109/IJCNN.1999.830870	natural language processing;speech recognition;computer science;artificial intelligence;adaptive resonance theory;machine learning;first language;natural language	NLP	-15.172576759950946	-78.79253072413417	171249
8231a3dafbbfc20b54391f29001498848777277c	end-to-end concept word detection for video captioning, retrieval, and question answering		We propose a high-level concept word detector that can be integrated with any video-to-language models. It takes a video as input and generates a list of concept words as useful semantic priors for language generation models. The proposed word detector has two important properties. First, it does not require any external knowledge sources for training. Second, the proposed word detector is trainable in an end-to-end manner jointly with any video-to-language models. To effectively exploit the detected words, we also develop a semantic attention mechanism that selectively focuses on the detected concept words and fuse them with the word encoding and decoding in the language model. In order to demonstrate that the proposed approach indeed improves the performance of multiple video-to-language tasks, we participate in all the four tasks of LSMDC 2016 [18]. Our approach has won three of them, including fill-in-the-blank, multiple-choice test, and movie retrieval.	end-to-end principle;high- and low-level;language model;natural language generation;question answering	Youngjae Yu;Hyungjin Ko;Jongwook Choi;Gunhee Kim	2017	2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	10.1109/CVPR.2017.347	machine learning;artificial intelligence;knowledge extraction;encoding (memory);computer science;pattern recognition;language model;decoding methods;semantics;exploit;question answering;closed captioning	Vision	-16.228665148030636	-71.0589558867838	171341
616c2b2c8bb35b0da1feb9d869131edd5b53642a	hierarchical lstm with adjusted temporal attention for video captioning		Recent progress has been made in using attention based encoder-decoder framework for video captioning. However, most existing decoders apply the attention mechanism to every generated word including both visual words (e.g., ”gun” and ”shooting”) and non-visual words (e.g. ”the”, ”a”). However, these non-visual words can be easily predicted using natural language model without considering visual signals or attention. Imposing attention mechanism on non-visual words could mislead and decrease the overall performance of video captioning. To address this issue, we propose a hierarchical LSTM with adjusted temporal attention (hLSTMat) approach for video captioning. Specifically, the proposed framework utilizes the temporal attention for selecting specific frames to predict the related words, while the adjusted temporal attention is for deciding whether to depend on the visual information or the language context information. Also, a hierarchical LSTMs is designed to simultaneously consider both low-level visual information and high-level language context information to support the video caption generation. To demonstrate the effectiveness of our proposed framework, we test our method on two prevalent datasets: MSVD and MSR-VTT, and experimental results show that our approach outperforms the state-of-the-art methods on both two datasets.	encoder;high- and low-level;high-level programming language;language model;long short-term memory;microsoft research;natural language;performance	Jingkuan Song;Zhao Guo;Lianli Gao;Wu Liu;Dongxiang Zhang;Heng Tao Shen	2017		10.24963/ijcai.2017/381	artificial intelligence;machine learning;visual word;natural language;speech recognition;computer science;closed captioning	AI	-16.836697045414656	-71.20580080539132	171483
76673de6d81bedd6b6be68953858c5f1aa467e61	discovering a lexicon of parts and attributes	encode attribute;comparative text;novel annotation task;caltech-ucsd bird;twin goal;visual discrimination;discriminative ability;pascal voc person;encode noun;visual attribute	We propose a framework to discover a lexicon of visual attributes that supports fine-grained visual discrimination. It consists of a novel annotation task where annotators are asked to describe differences between pairs of images. This captures the intuition that for a lexicon to be useful, it should achieve twin goals of discrimination and communication. Next, we show that such comparative text collected for many pairs of images can be analyzed to discover topics that encode nouns and modifiers, as well as relations that encode attributes of parts. The model also provides an ordering of attributes based on their discriminative ability, which can be used to create a shortlist of attributes to collect for a dataset. Experiments on Caltech-UCSD birds, PASCAL VOC person, and a dataset of airplanes, show that the discovered lexicon of parts and their attributes is comparable to those created by experts.	discriminative model;encode;generative model;lexicon;recursion;region of interest;ucsd pascal/p-system	Subhransu Maji	2012		10.1007/978-3-642-33885-4_3	natural language processing;computer science;machine learning;data mining	Vision	-16.89152384479178	-69.9858443623751	171602
ba0949fc0a0b2b5e3977faa9e2b2ceb817b0cab1	yzu-nlp at emoint-2017: determining emotion intensity using a bi-directional lstm-cnn model		The EmoInt-2017 task aims to determine a continuous numerical value representing the intensity to which an emotion is expressed in a tweet. Compared to classification tasks that identify 1 among n emotions for a tweet, the present task can provide more fine-grained (real-valued) sentiment analysis. This paper presents a system that uses a bi-directional LSTM-CNN model to complete the competition task. Combining bi-directional LSTM and CNN, the prediction process considers both global information in a tweet and local important information. The proposed method ranked sixth among twenty-one teams in terms of Pearson Correlation Coefficient.	archive;artificial neural network;coefficient;convolutional neural network;deep learning;encode;long short-term memory;natural language processing;numerical analysis;sentiment analysis	Yuanye He;Liang-Chih Yu;K. Robert Lai;Weiyi Liu	2017			artificial intelligence;machine learning;natural language processing;computer science	NLP	-19.067985491562002	-70.99808872895058	171905
0dd42c0d049b05b5d3c37cb2e64d8a307862b196	"""reproducibility report for """"learning to count objects in natural images for visual question answering"""""""		The paper proposes to overcome these challenges by using the attention maps (and not the aggregated feature vectors) as the input to a separate count module. The basic idea is quite intuitive: when we perform weighted averaging based on different attention maps, we end up averaging the features corresponding to the different instances of an object. This makes the feature vectors indistinguishable from the scenario where we had just one instance of the object in the image. Even multiple glimpses (multiple steps of attention) can not resolve this problem as the weights given to one feature vector would not depend on the other feature vectors (that are attended to). Hard attention could be more useful than soft-attention but there is not much empirical evidence in support of this hypothesis.	baseline (configuration management);computation;computational resource;feature engineering;feature vector;graph theory;map;question answering	Shagun Sodhani;Vardaan Pahuja	2018	CoRR		machine learning;information retrieval;artificial intelligence;reproducibility;computer science;question answering	ML	-13.40647817185438	-66.51561675008276	172346
99fb1bf96ae216e5bda6ea5940ccea4fda96d274	dcu-uva multimodal mt system report		We present a doubly-attentive multimodal machine translation model. Our model learns to attend to source language and spatial-preserving CONV5,4 visual features as separate attention mechanisms in a neural translation model. In image description translation experiments (Task 1), we find an improvement of 2.3 Meteor points compared to initialising the hidden state of the decoder with only the FC7 features and 2.9 Meteor points compared to a text-only neural machine translation baseline, confirming the useful nature of attending to the CONV5,4 features.	baseline (configuration management);experiment;meteor;multimodal interaction;neural machine translation;text-based user interface	Iacer Calixto;Desmond Elliott;Stella Frank	2016			machine translation;speech recognition;computer science	NLP	-16.28853237930024	-75.29433593777003	172535
148c1751d148f504a0bd028010ae99d2243e1901	icfhr 2014 competition on recognition of on-line handwritten mathematical expressions (crohme 2014)	performance evaluation;spatial relations;online handwriting;mathematical expression recognition	We present the outcome of the latest edition of the CROHME competition, dedicated to on-line handwritten mathematical expression recognition. In addition to the standard full expression recognition task from previous competitions, CROHME 2014 features two new tasks. The first is dedicated to isolated symbol recognition including a reject option for invalid symbol hypotheses, and the second concerns recognizing expressions that contain matrices. System performance is improving relative to previous competitions. Data and evaluation tools used for the competition are publicly available.	online and offline;statistical classification;unix system iii	Harold Mouchère;Christian Viard-Gaudin;Richard Zanibbi;Utpal Garain	2014	2014 14th International Conference on Frontiers in Handwriting Recognition	10.1109/ICFHR.2014.138	spatial relation;computer vision;speech recognition;intelligent character recognition;computer science;artificial intelligence;machine learning	Vision	-8.262192191798041	-72.4645313776651	172550
ea6bccbfe0406a600e2378f14cc56b93aa0b87ae	corpus-based syntax-prosody tree matching	speech synthesis;empirical study	"""Empirical study of the syntax-prosody relation is hampered by the fact that current prosodic models are essentially linear, while syntactic structure is hierarchical. The present contribution describes a syntax-prosody comparison heuristic based on two new algorithms: Time Tree Induction, TTI, for building a prosodic treebank from time-annotated speech data, and Tree Similarity Indexing, TSI) for comparing syntactic trees with the prosodic trees. Two parametrisations of the TTI algorithm, for different tree branching conditions, are applied to sentences taken from a read-aloud narrative, and compared with parses of the same sentences, using the TSI. In addition, null-hypotheses in the form of flat bracketing of the sentences are compared. A preference for iambic (heavy rightmost branch) grouping is found. The resulting quantitative evidence for syntax-prosody relations has applications in speech genre characterisation and in duration models for speech synthesis. 1. Hierarchical syntax, linear prosody? The objective of this contribution is to provide a well-defined algorithmic approach to extracting complex prosodic information from speech corpora. Current empirical models of speech timing are based on a variety of algorithms, from single indices for timing patterns [1, 2] in psycholinguistics and phonetics to, in the speech synthesis domain, sum-of-products, CART and Bayesian classification approaches [3, 4], including models which use grammatical information. Campbell [5] has a model based on a strictly layered hierarchy, but in general duration models are linear, and hold for flat strings of words or syntactic categories. When syntagmatic grammatical information is used as a predictor for hierarchical structuring, in general the information used is also linear, based on strings of paradigmatic part-of-speech (POS) classes (grammatical categories) which provide weight factors for duration models. Wagner [6] uses a linear model for German speech synthesis based on five weighted POS sets. Grammatical categories imply at least local “hidden hierarchies”, of course. Rarely, explicit hierarchical approaches have been used [7], and detailed approaches to the partially hierarchical description of timing are once more becoming available [8], [9, 10, 11]; But there is currently no technique available for data-driven investigation of more complex hierarchical duration models for syntagmatic prosodic relations, and the issue is not addressed in recent authoritative literature [12]. Classification methods need 1Thanks to Grazyna Demenko, Katarzyna Dziubalska-Kołaczyk, Ekaterina Iassinskaia, Peter Ladkin, Zofia Malisz and lecture audiences in Dublin, Bielefeld, Poznań and Tübingen for discussion and to Ulrike Gut, Katrin Johanning, Sara Johannsen, Josef Raab, Alexandra Thies, Thorsten Trippel for contributing data. The software developed for this work is in the public domain (GPL). to include complex hierarchical timing information in addition to other to other phonetic and lexical properties of speech units. Further, it is a well-known phonostylistic effect that speech timing relations vary in highly complex ways depending on speech genre, including so-called fast speech phenomena [13]. Finally, other discourse factors such as focus and emotion are thought to affecting prosody, and thereby reducing the determining role of phrasal syntax, though these effects are currently not well understood (but see [14]). 2. Linear timing measures One set of approaches to investigating syntagmatic properties of timing is found in phonetic analyses of isochrony in syllable and foot timing. In [15], tone unit duration is divided by the number of feet in the tone unit, yielding average or “ideal” isochronous foot duration, and normalised deviation from mean foot length is measured. Neither hierarchy nor linear alternation of timing units figure in the approach, which may be said to use a Global Evenness (GE) criterion as a measure of the isochrony property, rather than the alternation property. Any arbitrary re-sorting of the relevant segments in an utterance (random, shortest-tolongest, etc.) would yield the same index. Timing fulfils the GE criterion, in some sense, but it has other properties too, so while the GE criterion for timing is a necessary criterion for isochrony it is (going beyond Roach’s stated goals, of course) not a sufficient criterion for an adequate timing model. Ramus, Nespor & Mehler [2] locate different languages in a timing space with the following parameters: , percentage of vocalic intervals relative to overall utterance length; , variance of consonantal intervals; , variance of vocalic intervals. The model also uses a variety of GE criterion: V stretches and C stretches would still yield the same results if randomly sorted (by length, longer consonant sequences first, etc.). Similar considerations apply to the measure, which reflects evenness of vowel sequence lengths, lower values tending to isochrony, and to the measure. The model does not have hierarchical and alternating timing components and is thus is incomplete as a model of rhythm timing, though it is claimed to be a model of rhythm. Cummins has pointed out [9] that the model makes a statement about the evenness of the phonotactics of the language, rather than timing. The model possibly reflects necessary conditions on timing, but falls short of providing a sufficient condition. Low, Grabe & Nolan [1] addressed the GE issue and developed the Pairwise Variability Index (PVI) in order to take iterative alternation into account. The PVI measures normalised differences between the durations of adjacent units (vowels, syllables, etc.): PVI = ! """" $#&%!' $(*),+.0/ The model yields a minimal value of 0 (perfect isochrony), asymptotically approaching 200 for larger length differences. the variant used in [16] reverses the scale, and has a maximum of 100 for perfect isochrony. The model has an empirical problem: PVI assumes strictly binary alternation. Hence, alternations as in “Little John met Robin Hood and so the merrie men were born.” are adequately modelled, but not unary rhythm (syllable timing) as in “This one big fat bear swam fast near Jane’s boat.” or ternary dactylic and anapaestic rhythms (or those with even higher cardinality) as in “Jonathan Appleby wandered around with a tune on his lips and saw Jenni fer Middleton playing a xylophone down on the market-place.” The model has worse a formal problem: the PVI is ambiguous and yields the same value for sets of alternating patterns, for monotonic geometrical series, and for mixtures of these, as shown by the following alternating and exponential series: ) / ) / . A series of length yields patterns with identical PVI, obviously not the required result. So the model presupposes alternating input, and since this will not generally be the case it is not at all clear what the PVI is actually an index of."""	algorithm;alternation (formal language theory);ambiguous grammar;bayesian network;gunnar johannsen;hood method;heart rate variability;heuristic;iteration;jane (software);kateryna yushchenko (scientist);kerrison predictor;linear model;neural oscillation;part-of-speech tagging;randomness;sara (computer);semantic prosody;sorting;speech synthesis;syllable;text corpus;time complexity;time-slot interchange;timing closure;treebank;unary operation	Dafydd Gibbon	2003			speech recognition;syntax;prosody;natural language processing;pattern recognition;artificial intelligence;computer science;speech synthesis	NLP	-12.938670109921969	-79.40999757391262	172824
5e10db4e983497154c7fece681154f5aa210be87	eye-tracking situated language comprehension: immediate actor gaze versus recent action events		Previous visual world eye-tracking studies have shown that when a sentential verb can refer (via tense information on the verb and on a following time adverb) to either a recent and a future action event performed by an actor, people inspected the target of the recent event more often than the (different) target of the future event. This ’recent event preference’ replicated even when the frequency of future events within the experiment greatly exceeded the frequency of recent events (e.g., 75% vs 25%). The recent event preference may arise because the past action is situation-immediate and thus more relevant at the particular point in time when the sentence is processed (at that point participants have seen the past action performed and will not see the future action until after the sentence). If the situation-immediate relevance of a cue is responsible for the recent event preference, then we should be able to “overwrite” the effect of the recent action with another situation-immediate cue. Accordingly, two current eye-tracking experiments pitted the recent event preference against a situation-immediate cue, the shift in the actor’s gaze to the target object. Given that interlocutors’ gaze has been shown to be a powerful cue in guiding listeners’ attention to objects in the visual context, we hypothesized that the actor’s gaze to the future target should rapidly guide a listener’s attention to it. Analyses revealed indeed that listeners’ visual attention was rapidly guided to the target by the actor’s gaze; crucially the gaze cue was particularly helpful in guiding looks to the future target. Importantly, however, we still replicated the overall preference to look at the recent target regardless of tense and gaze; and even for future gaze conditions, the preference was not immediately reversed, suggesting it is surprisingly robust in competition with a situation-specific future-biasing cue.	biasing;experiment;eye tracking;relevance;situated	Dato Abashidze;Pia Knoeferle;Maria Nella Carminati	2015			psychology;natural language processing;communication;social psychology	HCI	-6.9312082456235125	-77.2179408079619	172868
6f0a965db9a9b2b654efa394ba2c50d632f4463f	deep learning hunts for signals among the noise		Neural networks can deliver surprising, and sometimes unwanted, results.	deep learning;neural networks	Chris Edwards	2018	Commun. ACM	10.1145/3204445	theoretical computer science;natural language processing;deep learning;computer science;artificial intelligence	Theory	-5.22244633786993	-71.59201694932875	173186
6b8399743ec258224737839e6196c118020fd922	degrees of grounding based on evidence of understanding	corpus analysis;dialogue management;grounding model	We introduce the Degrees of Grounding model, which defines the extent to which material being discussed in a dialogue has been grounded. This model has been developed and evaluated by a corpus analysis, and includes a set of types of evidence of understanding, a set of degrees of groundedness, a set of grounding criteria, and methods for identifying each of these. We describe how this model can be used for dialogue management.	dialog system	Antonio Roque;David R. Traum	2008			psychology;knowledge management;artificial intelligence;communication	NLP	-10.859187901680617	-78.5650421393158	173286
7d6d1f874f6cf161e67b931eec668321121795a1	a genetic algorithm for the automatic generation of playable guitar tablature		This paper describes a method for mapping a sequence of notes to a set of guitar fretboard positions (tablature). The method uses a Genetic Algorithm (GA) to find playable tablature through the use of a fitness function that assesses the playability of a given set of fretboard positions. Tests of the algorithm on a variety of compositions demonstrate an excellent ability of the GA to discover easily playable tablature that maintains a high degree of consistency with published tablatures transcribed by humans. The algorithm was also found to generally outperform commercial software designed for the same purpose. We conclude that the GA can reliably produce good tablature for any piece of guitar music.	commercial software;genetic algorithm;software release life cycle	Daniel R. Tuohy;Walter D. Potter	2005			speech recognition;acoustics	Graphics	-16.370750310107134	-79.75272909948367	173295
4653b04e72be50f032750256a6d5c725b553965e	a rational model of eye movement control in reading	eye movement	A number of results in the study of realtime sentence comprehension have been explained by computational models as resulting from the rational use of probabilistic linguistic information. Many times, these hypotheses have been tested in reading by linking predictions about relative word difficulty to word-aggregated eye tracking measures such as go-past time. In this paper, we extend these results by asking to what extent reading is well-modeled as rational behavior at a finer level of analysis, predicting not aggregate measures, but the duration and location of each fixation. We present a new rational model of eye movement control in reading, the central assumption of which is that eye movement decisions are made to obtain noisy visual information as the reader performs Bayesian inference on the identities of the words in the sentence. As a case study, we present two simulations demonstrating that the model gives a rational explanation for between-word regressions.	aggregate data;computational model;eye tracking;simulation	Klinton Bicknell;Roger Levy	2010			computer science;artificial intelligence;eye movement	ML	-11.667805781089088	-73.93578141450008	173636
9e821b309ed983f90362965a90ba80b02b302caf	markov logic networks for natural language question answering.		Our goal is to answer elementary-level science questions using knowledge extracted automatically from science textbooks, expressed in a subset of first-order logic. Given the incomplete and noisy nature of these automatically extracted rules, Markov Logic Networks (MLNs) seem a natural model to use, but the exact way of leveraging MLNs is by no means obvious. We investigate three ways of applying MLNs to our task. In the first, we simply use the extracted science rules directly as MLN clauses. Unlike typical MLN applications, our domain has long and complex rules, leading to an unmanageable number of groundings. We exploit the structure present in hard constraints to improve tractability, but the formulation remains ineffective. In the second approach, we instead interpret science rules as describing prototypical entities, thus mapping rules directly to grounded MLN assertions, whose constants are then clustered using existing entity resolution methods. This drastically simplifies the network, but still suffers from brittleness. Finally, our third approach, called Praline, uses MLNs to align the lexical elements as well as define and control how inference should be performed in this task. Our experiments, demonstrating a 15% accuracy boost and a 10x reduction in runtime, suggest that the flexibility and different inference semantics of Praline are a better fit for the natural language question answering task.	align (company);entity;experiment;first-order logic;first-order predicate;markov chain;markov logic network;natural language;question answering	Tushar Khot;Niranjan Balasubramanian;Eric Gribkoff;Ashish Sabharwal;Peter Clark;Oren Etzioni	2015	CoRR		machine learning;name resolution;computer science;artificial intelligence;data mining;semantics;natural language;inference;exploit;question answering;markov chain	NLP	-16.0393409333293	-67.5737574055473	173840
a91e1a6031f685a0794c56e12e85ad0a6f132d2d	prosodic features from large corpora of child-directed speech as predictors of the age of acquisition of words.		The impressive ability of children to acquire language is a widely studied phenomenon, and the factors influencing the pace and patterns of word learning remains a subject of active research. Although many models predicting the age of acquisition of words have been proposed, little emphasis has been directed to the raw input children achieve. In this work we present a comparatively large-scale multimodal corpus of prosody-text aligned child directed speech. Our corpus contains automatically extracted word-level prosodic features, and we investigate the utility of this information as predictors of age of acquisition. We show that prosody features boost predictive power in a regularized regression, and demonstrate their utility in the context of a multimodal factorized language models trained and tested on child-directed speech.		Lea Frermann;Michael C. Frank	2017	CoRR		natural language processing;age of acquisition;artificial intelligence;computer science;prosody;speech recognition;language model;phenomenon	NLP	-15.082528473057609	-77.78117905148531	174266
a8cbb1700761a787ed546ef0caaa765806871249	tone and phonation in southeast asian languages		Southeast Asia is often considered a quintessential Sprachbund where languages from five different language phyla have been converging typologically for millennia. One of the common features shared by many languages of the area is tone: several major national languages of the region have large tone inventories and complex tone contours. In this paper, we suggest a more fine-grained view. We show that in addition to a large number of atonal languages, the tone languages of the region are actually far more diverse than usually assumed, and employ phonation type contrasts at least as often as pitch. Along the same lines, we argue that concepts such as tone and register, while descriptively useful, can obscure important underlying similarities and impede our understanding of the behavior of phonetic properties, typological regularities, and diachrony. We finally draw the readeru0027s attention to some issues of current interest in the study of tone and phonation in Southeast Asia and describe some technical developments that are likely to allow researchers to address new lines of research in years to come.		Marc Brunelle;James P. Kirby	2016	Language and Linguistics Compass	10.1111/lnc3.12182	linguistics;computer science;communication;phonation;sprachbund	NLP	-8.944995530524404	-79.43456660101553	174506
9399f7035e8faa386c8a9f2e2b95e00b5a8ca9c1	utilizing visual attention for cross-modal coreference interpretation	sensibilidad contexto;modelizacion;animacion por computador;interfase usuario;linguistique;embodiment;context aware;realite virtuelle;realidad virtual;user interface;virtual reality;hombre;robotics;atencion visual;modelisation;linguistica;agent intelligent;human;intelligent agent;robotica;interface utilisateur;encarnacion;robotique;agente inteligente;attention visuelle;embodied conversational agent;sensibilite contexte;incarnation;computer animation;speaker;locutor;visual attention;exploratory study;modeling;locuteur;homme;virtual worlds;animation par ordinateur;linguistics	Understanding all of the ways context modulates linguistic forms is a challenging endeavor. An important goal in computational linguistics is defining the relationship between context and referring behavior. One contextual effect on referring behavior that is observed across multiple experimental disciplines and linguistic genres is the relationship between entity salience and ambiguous referring expressions. Speakers use underspecified noun phrases, especially pronouns such as “this” and “he” but also common nouns such as “the button”, freely in discourse, relying on the addressee’s ability to understand which button or person is being referred to. This preference for certain entities, given a prior context, will be called salience in this paper. Salience corresponds to a prediction or expectation that a certain entity will be the topic of the upcoming discourse. Estimating the relative salience of each entity in the universe of discourse is an important task in computational models of referring behavior both in production of felicitous noun phrases and also in interpretting connected discourse. The long-term objective of our research program is to create robust, accurate algorithms for reference interpretation in automated agents. This task is impossible without a firm understanding of contextual effects on referring behavior. It has been well-established in the computational linguistics literature that the discourse history can be interrogated to determine the salience of entities in a sentence one is trying to interpret. However, recent technology improvements create opportunities for human-computer conversations in which contextual factors in addition to the discourse history are in play at the same time, each impacting entity salience in different ways. The goal of our project is to create conversational software agents that can carry on a situated conversation with a human partner. For the purposes of this paper, situated language will be defined as language having these properties: Immersion The conversation takes place within a 3D setting that is perceptually available to the conversational partners. The partners can speak to each other face to face within the setting. Mobility Both conversational partners are at liberty to move about in the world, independently of each other, to gather information or change their perceptual perspective on the world. These characteristics distinguish situated language from the bulk of interaction paradigms that have informed the development of reference processing algorithms, many of which are developed for text or in experimental settings where speakers are not face-to-face. This experimental format was used explicitly to limit the degree to which conversational partners could exploit extra-linguistic contextual clues, such as gesture and gaze. Using new data we have generated in our lab, in this paper we examine situated language between 2 human partners. This allows us to investigate the interplay between the discourse context and the conversational setting on the interpretation of referring expressions in a visually-rich domain. The primary focus of the present work is to develop a model of visual attention that can be used to interpret exophors, reference to items in the discourse setting. Similar to the way that an anaphor constitutes a repeated mention of an item introduced into the context by the linguistic history, an exophor is a repeated mention of an item already introduced into the context by the physical world, in other words, a cross-modal coreference. Our hypothesis is that the world that is visually perceptible to the conversational partners will be likely to shape the content of their discussion, especially when they are performing a task on objects in that world. Moreover, a likely source of denotations for exophors are items that the speaker’s attention is directed toward simultaneously with the utterance she is producing. Given these two factors influencing the dialog, our aim is to test a method of tracking one speaker’s view of the world over the course of a dialog, and use that information as input in a reference resolution algorithm to interpret the referring expressions she produces. Our eventual goal is to construct a model that fuses attentional information provided in the visual channel with that provided by the discourse history. In the present work, we perform pencil-andpaper analysis and offline simulation of our model, as a first step in developing the algorithms that will eventually be implemented. In our current design of system, we used three parameters Recency, Uniqueness and Persistence which are obtained from the visual information of sampled frames to calculate the salience value of each object, and chose the one with the highest salience value to be the actual referrent. Experiment showed that with only the visual information, our system correctly predicts 31.3% of the referents produced by speakers while they were collaborating on a task in the virtual world. With the aid of little semantic information, which is gained by a simple string match process (e.g., “the red chair” can only refer to a chair), the accuracy becomes 52.2%, The performance is comparable with discourse-based salience calculated on the same data.	algorithm;anaphora (linguistics);computation;computational linguistics;computational model;domain of discourse;entity;immersion (virtual reality);modal logic;online and offline;persistence (computer science);regular expression;simulation;situated;software agent;virtual world;dialog	Donna K. Byron;Thomas Mampilly;Vinay Sharma;Tianfang Xu	2005		10.1007/11508373_7	loudspeaker;simulation;systems modeling;computer science;artificial intelligence;virtual reality;computer animation;robotics;user interface;intelligent agent;exploratory research	NLP	-9.43377313413401	-79.15209801784505	174516
c6e3c927978d546519d79c1db81618d783fdd63c	automatic recognition of non-acted affective postures	automatic emotion recognition;ucl;computer model;human emotion recognition;discovery;emotion recognition;theses;conference proceedings;joints;observers;video game;affective state;computational modeling;digital web resources;pose estimation computer games emotion recognition;ucl discovery;affective posture;non acted posture;games;open access;observers games humans emotion recognition labeling computational modeling joints;random repeated subsampling validation automatic nonacted affective postures recognition body movement based video game observers ground truth;ucl library;ground truth;humans;book chapters;open access repository;computer games;non acted posture affective posture automatic emotion recognition human emotion recognition;labeling;pose estimation;ucl research	The conveyance and recognition of affect and emotion partially determine how people interact with others and how they carry out and perform in their day-to-day activities. Hence, it is becoming necessary to endow technology with the ability to recognize users' affective states to increase the technologies' effectiveness. This paper makes three contributions to this research area. First, we demonstrate recognition models that automatically recognize affective states and affective dimensions from non-acted body postures instead of acted postures. The scenario selected for the training and testing of the automatic recognition models is a body-movement-based video game. Second, when attributing affective labels and dimension levels to the postures represented as faceless avatars, the level of agreement for observers was above chance level. Finally, with the use of the labels and affective dimension levels assigned by the observers as ground truth and the observers' level of agreement as base rate, automatic recognition models grounded on low-level posture descriptions were built and tested for their ability to generalize to new observers and postures using random repeated subsampling validation. The automatic recognition models achieve recognition percentages comparable to the human base rates as hypothesized.	avatar (computing);base rate;body position;chroma subsampling;description;dimensions;ground truth;high- and low-level;microscopy, video;personnameuse - assigned;poor posture;observers	Andrea Kleinsmith;Nadia Bianchi-Berthouze;Anthony Steed	2011	IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)	10.1109/TSMCB.2010.2103557	computer simulation;games;labeling theory;pose;ground truth;computer science;artificial intelligence;machine learning;multimedia;computational model	Vision	-11.194626784737412	-70.861842789496	174532
143b69e41688c27da12ec510c8bc2085b8f8796f	neural networks pipeline for offline machine printed arabic ocr	ocr;arabic word segmentation;convolutional neural networks;character recognition	In the context of Arabic optical characters recognition, Arabic poses more challenges because of its cursive nature. We purpose a system for recognizing a document containing Arabic text, using a pipeline of three neural networks. The first network model predicts the font size of an Arabic word, then the word is normalized to an 18pt font size that will be used to train the next two models. The second model is used to segment a word into characters. The problem of words segmentation in the Arabic language, as in many similar cursive languages, presents a challenge to the OCR systems. This paper presents a multichannel neural network to solve the offline segmentation of machine-printed Arabic documents. The segmented characters are then fed as an input to a convolutional neural network for Arabic characters recognition. The font size prediction model produced a test accuracy of 99.1%. The accuracy of the segmentation model using one font is 98.9%, while four-font model showed 95.5% accuracy. The whole pipeline showed an accuracy of 94.38% on Arabic Transparent font of size 18pt from APTI data set.	artificial neural network;autonomous robot;convolutional neural network;microsoft windows;network model;online and offline;optical character recognition;pipeline (computing);printing;text segmentation;vocabulary;window function	Mohamed A. Radwan;Mahmoud I. Khalil;Hazem M. Abbas	2017	Neural Processing Letters	10.1007/s11063-017-9727-y	font;artificial intelligence;machine learning;arabic;convolutional neural network;network model;artificial neural network;cursive;pattern recognition;speech recognition;mathematics	NLP	-16.95272395298182	-77.36849709656975	174567
c6c8d614f582d9855b763c948aa921369a6556f1	cognition and the evolution of music: pitfalls and prospects	relative pitch;music cognition;universiteitsbibliotheek;adaptation;musicality;evolutionary psychology;beat induction;innateness	What was the role of music in the evolutionary history of human beings? We address this question from the point of view that musicality can be defined as a cognitive trait. Although it has been argued that we will never know how cognitive traits evolved (Lewontin, 1998), we argue that we may know the evolution of music by investigating the fundamental cognitive mechanisms of musicality, for example, relative pitch, tonal encoding of pitch, and beat induction. In addition, we show that a nomological network of evidence (Schmitt & Pilcher, 2004) can be built around the hypothesis that musicality is a cognitive adaptation. Within this network, different modes of evidence are gathered to support a specific evolutionary hypothesis. We show that the combination of psychological, medical, physiological, genetic, phylogenetic, hunter-gatherer, and cross-cultural evidence indicates that musicality is a cognitive adaptation.	acclimatization;biological evolution;bottom-up parsing;cognition disorders;inductive reasoning;large;phylogenetics;pitch (music);schmitt trigger;sensitivity and specificity;theory;top-down and bottom-up design;trait	Henkjan Honing;Annemie Ploeger	2012	Topics in cognitive science	10.1111/j.1756-8765.2012.01210.x	psychology;cognitive psychology;relative pitch;neuroscience;developmental psychology;music psychology;artificial intelligence;evolutionary psychology;communication;social psychology;musicality;cognitive science;adaptation	NLP	-7.478056585274966	-78.67610019132856	174628
4b9730e229ff3f59e72bf2a42c96b33444960213	transfer learning method for very deep cnn for text classification and methods for its evaluation		In recent years, it has become possible to perform text classification with high accuracy by using convolutional neural networks (CNNs). Zhang et al. decomposed words into characters and classified texts using a CNN with relatively deep layers to obtain excellent classification results. However, it is often difficult to prepare a sufficient number of labeled samples for solving real-world text-classification problems. One method for handling this problem is transfer learning, which uses a network tuned for an arbitrary task as the initial network for a target task. While transfer learning is known to be effective for image recognition, for tasks in natural language processing, such as document classification, it has not yet been shown for what types of data and to what extent transfer learning is effective. In this paper, we first introduce a character-level CNN adopting the structure of a residual network to construct a network with deeper layers for Japanese text classification. We then demonstrate that we can improve classification accuracy by performing transfer learning between two particular datasets. Additionally, we propose an approach to evaluate the effectiveness of transfer learning and use it to evaluate our model.	artificial neural network;computer vision;convolutional neural network;document classification;effective method;flow network;natural language processing;usability	Shun Moriya;Chihiro Shibata	2018	2018 IEEE 42nd Annual Computer Software and Applications Conference (COMPSAC)	10.1109/COMPSAC.2018.10220	transfer of learning;convolutional neural network;real-time computing;residual;data type;task analysis;machine learning;document classification;data modeling;computer science;training set;artificial intelligence	AI	-17.61309247822168	-71.26999910068358	174996
7cff9331f6601aecf648259c689a9cab5fc2a232	learning and interpreting multi-multi-instance learning networks		We introduce an extension of the multi-instance learning problem where examples are organized as nested bags of instances (e.g., a document could be represented as a bag of sentences, which in turn are bags of words). This framework can be useful in various scenarios, such as text and image classification, but also supervised learning over graphs. As a further advantage, multi-multi instance learning enables a particular way of interpreting predictions and the decision function. Our approach is based on a special neural network layer, called bag-layer, whose units aggregate bags of inputs of arbitrary size. We prove theoretically that the associated class of functions contains all Boolean functions over sets of sets of instances and we provide empirical evidence that functions of this kind can be actually learned on semi-synthetic datasets. We finally present experiments on text classification, on citation graphs, and social graph data, which show that our model obtains competitive results with respect to accuracy when compared to other approaches such as convolutional networks on graphs, while at the same time it supports a general approach to interpret the learnt model, as well as explain individual predictions.		Alessandro Tibo;Manfred Jaeger;Paolo Frasconi	2018	CoRR		machine learning;boolean function;supervised learning;citation;artificial neural network;mathematics;empirical evidence;artificial intelligence;contextual image classification;social graph;graph	ML	-11.163625876068563	-67.20068859271151	175777
cec2d1e66b066e9d2a3ebbfb4ad1f6cbe902311b	research on attention memory networks as a model for learning natural language inference		Natural Language Inference (NLI) is a fundamentally important task in natural language processing that has many applications. It is concerned with classifying the logical relation between two sentences. In this paper, we propose attention memory networks (AMNs) to recognize entailment and contradiction between two sentences. In our model, an attention memory neural network (AMNN) has a variable sized encoding memory and supports semantic compositionality. AMNN captures sentence level semantics and reasons relation between the sentence pairs; then we use a Sparsemax layer over the output of the generated matching vectors (sentences) for classification. Our experiments on the Stanford Natural Language Inference (SNLI) Corpus show that our model outperforms the state of the art, achieving an accuracy of 87.4% on the test data.	activation function;aggregate data;artificial neural network;automatic summarization;experiment;heuristic (computer science);native-language identification;natural language processing;softmax function;sparse matrix;test data	Zhuang Liu;Degen Huang;Jing Zhang;Kaiyu Huang	2016		10.18653/v1/W16-5902	cognitive psychology;natural language processing;algorithmic learning theory;machine learning	NLP	-17.706871278152867	-72.31798151700698	176244
0593fb71a4b0eddff3625f06412b578a520524e6	early-talker and late-talker toddlers and networks show different word learning biases	social and behavioral sciences	In typical development, word learning goes from slow and laborious to fast and seemingly effortless. Typically developing 2-year-olds are so skilled at learning noun categories that they seem to intuit the whole range of things in the category from hearing a single instance named – they are biased learners. This is not the case for children below the 20th percentile on productive vocabulary (late talkers). This paper looks at the individual vocabularies and word-learning biases of lateand early-talking toddlers. Experiment 1 shows that neural networks trained on the vocabularies of individual late talkers learn qualitatively different biases than those trained on early talker vocabularies. Experiment 2 confirms the novel predictions made by the simulations about word learning biases in latevs. early-talking children. The implications for diagnosis and intervention are discussed.	artificial neural network;simulation;single-instance storage;vocabulary	Eliana Colunga;Clare E. Sims	2012			psychology;cognitive psychology;developmental psychology;social psychology	ML	-10.092963425766762	-76.44995669306923	176341
64cfe349f87e985a51e30d5fcd5c9aac1de2ac54	using word familiarities and word associations to measure corpus representativeness		The definition of corpus representativeness used here assumes that a representative corpus should reflect as well as possible the average language use a native speaker encounters in everyday life over a longer period of time. As it is not practical to observe people's language input over years, we suggest to utilize two types of experimental data capturing two forms of human intuitions: Word familiarity norms and word association norms. If it is true that human language acquisition is corpus-based, such data should reflect people's perceived language input. Assuming so, we compute a representativeness score for a corpus by extracting word frequency and word association statistics from it and by comparing these statistics to the human data. The higher the similarity, the more representative the corpus should be for the language environments of the test persons. We present results for five different corpora and for truncated versions thereof. The results confirm the expectation that corpus size and corpus balance are crucial aspects for corpus representativeness.	automatic identification and data capture;microsoft word for mac;text corpus;word lists by frequency	Reinhard Rapp	2014			linguistics	NLP	-13.175610460675735	-78.78037272517943	176388
c2b232aa0e84529e37af5e211ef400f05ad33843	an erp study of syntactic anomaly processing in mandarin sentences		The present study addresses (1) whether Chinese classifier-noun integration is syntactic or semantic in nature, and (2) whether the Anterior Negativity in brainwaves is a separable component indexing automatic morphosyntactic processing (Hagoort, 2003) or instead results from overlapping N400 and P600 components (Tanner, 2014). In Chinese, classifiers (e.g., a sheet of) must be used whenever any noun is quantified or specified and must be congruent with noun meaning. Thirty-three Mandarin speakers read 120 sets of sentences that manipulated classifier-noun congruency (There is a machine-like-classifier/sheet-likeclassifier computer on the table) and classifier presence (a machine-like-classifier computer vs. *a computer). A larger N400 component in the incongruent condition suggests that classifier-noun integration is primarily semantic. In the classifier-absent condition, a P600 was observed during the first half of the experiment but that diminished during the second half and an apparent Anterior Negativity emerged, suggesting that readers changed their processing strategy over time.	anomaly detection;chinese room;erp;negativity (quantum mechanics);neural oscillation;super robot monkey team hyperforce go!;tanner graph	Zhiying Qian;Susan M. Garnsey	2015			psychology;mandarin chinese;syntax;linguistics;natural language processing;artificial intelligence	NLP	-9.824233188537352	-79.86159645344766	176408
fd45156f3921d78bb1215591781c6d0f38d571c6	mixing context granularities for improved entity linking on question answering data across entity categories		The first stage of every knowledge base question answering approach is to link entities in the input question. We investigate entity linking in the context of a question answering task and present a jointly optimized neural architecture for entity mention detection and entity disambiguation that models the surrounding context on different levels of granularity. We use the Wikidata knowledge base and available question answering datasets to create benchmarks for entity linking on question answering data. Our approach outperforms the previous state-of-the-art system on this data, resulting in an average 8% improvement of the final score. We further demonstrate that our model delivers a strong performance across different entity categories.	entity linking;f1 score;knowledge base;precondition;question answering;software quality assurance;wikidata;word-sense disambiguation	Daniil Sorokin;Iryna Gurevych	2018			natural language processing;knowledge base;question answering;granularity;entity linking;artificial intelligence;architecture;computer science	NLP	-18.958814127905452	-71.48781226851568	176428
c211fa1df2275d47f75bc50d2532ab25bcf096f3	lol: an investigation into cybernetic humor, or: can machines laugh?	software;004;deep learning recurrent neural networks dimensionality reduction algorithms;deep learning;dimensionality reduction algorithms;recurrent neural networks	We investigate literary theories of humour from a computational point of view. A corpus of approximately 11,000 jokes is used to train a neural network generating jokes; the state space of such network is then analyzed via appropriate discovery algorithms, and abstractions synthesized by the neural network are compared to those predicted by existing theories. 1998 ACM Subject Classification F.2.2 Nonnumerical Algorithms and Problems, I.2.6 Learning, I.5.4 Applications	algorithm;artificial neural network;cybernetics;lol;state space;text corpus;theory	Davide Bacciu;Vincenzo Gervasi;Giuseppe Prencipe	2016		10.4230/LIPIcs.FUN.2016.3	computer science;artificial intelligence;recurrent neural network;mathematics;deep learning;algorithm	ML	-14.598169816864717	-73.60341888491406	176910
d2c63f222f3d7c37f9e598b23c7ddc696f3cbabe	explaining representational shifts by selective attention, selective memorization, and random chance		Recent studies in category learning have shown that there are shifts in category representation. In the present study, we develop three models categorization that consisted of different learning objectives to examine cognitive mechanism underlying the representational shifts. The results of simulation indicated that the representational shift observed in Johansen & Palmeri (2002) can be explained by selective attention, selective exemplar memorization, or mere random chance. Although these models could not be differentiated based on classification generalization patterns, a detail examination of acquired model coefficients were conducted in order to design future studies.	bourne shell;categorization;category utility;coefficient;concept learning;futures studies;randomness;simulation	Toshihiko Matsuka;Hidehito Honda;Sou Matsuura	2011			stochastic optimization;social psychology;cognitive psychology;computational model;inverse;alcove;categorization;memorization;artificial intelligence;cognition;mathematics;concept learning	AI	-7.294907244549863	-76.17208621407434	177026
d693b540ca26dcce64a7d50b91dd573e94876d1c	automated large program repair based on big code		The task of automatic program repair is to automatically localize and generate the correct patches for the bugs. A prominent approach is to produce a space of candidate patches, then find and validate candidates on test case sets. However, searching for the correct candidates is really challenging, since the search space is dominated by incorrect patches and its size is huge.  This paper presents several methods to improve the automated program repair system Prophet, called Prophet+. Our approach contributes three improvements over Prophet: 1) extract twelve relations of statements and blocks for Bi-gram model using Big code, 2) prune the search space, 3) develop an algorithm to re-rank candidate patches in the search space. The experimental results show that our proposed system enhances the performance of Prophet, recognized as the state-of-the-art system, significantly. Specifically, for the top 1, our system generates the correct patches for 17 over 69 bugs while the number achieved by Prophet is 15.		Hoang Van Thuy;Phan Viet Anh;Nguyen Xuan Hoai	2018		10.1145/3287921.3287958	n-gram;machine learning;artificial intelligence;computer science	SE	-13.515343112940982	-72.37976519399992	177140
4716e6607d0041563a499b472e98a7174a7e4b98	aspectual meaning meets discourse coherence: a look at the russian imperfective		This article investigates aspectual meaning and its interaction with independently motivated temporal constraints imposed by coherence relations. I argue that aspectual markers denote functions from a set of events denoted by a verb-phrase (VP) to a set of VP-event parts that are located relative to (i) an input encoding explicitly temporal information and (ii) an input encoding information about discourse connectivity. By virtue of encoding information about discourse connectivity, aspectual makers play a nontrivial role in determining which coherence relation holds between successive utterances and thereby constrain the ordering of eventualities described by these utterances. The core data that support these claims come from discourses containing the Russian imperfective. This aspect is remarkable because it can constrain the temporal location of different event parts. Depending on the event part that is constrained, the imperfective often leads to an inference that the described event precedes or overlaps a salient event previously mentioned in the discourse. I argue that the imperfective is rarely found in narrative contexts because its semantics rules the so-called OCCASION relation, which establishes a particular kind of contingency relationship between events. The proposed analysis accounts for the discourse properties of the Russian imperfective and is shown to be compatible with the modal properties of this aspect. I also show how the analysis could be extended to account for the meaning of the English progressive and temporal adverbials.	affinity analysis;anaphora (linguistics);apply;carlson's theorem;color gradient;commonsense knowledge (artificial intelligence);computation;contingency (philosophy);core data;event-driven programming;fred (chatterbot);generic programming;hobbs meter;modal logic;olga (technology);processor affinity;requirement;sap hana;temporal logic;whole earth 'lectronic link	Daniel Altshuler	2012	J. Semantics	10.1093/jos/ffr008	philosophy;linguistics;literature	NLP	-8.908489713845722	-75.12642241619346	177249
459793bf47df48dcfc4bdf5cd8394128a6ce1d15	a synchronous corpus-based study of verb-noun fluidity in chinese	noun;conference paper;natural language;part of speech tagging;natural language processing	The problem of verb-noun categorial ambiguity is critical and relatively unique for non-inflectional languages, especially Chinese. We consider the verb-noun categorial fluidity a continuum and any categorial shift a transitional process. A synchronous corpus-based study was conducted to compare the phenomenon with respect to news texts collected from Hong Kong, Beijing, and Taiwan. It was found that about 15% of the verbs in the Hong Kong and Taiwan texts were undergoing the verb-noun categorial shift; whereas Beijing texts had more than 18% of the verbs undergoing this shift. The results also have important implications on various natural language applications, including lexicography, part-of-speech tagging of Chinese, as well as other natural language processing tasks.	categorial grammar;lexicography;natural language processing;part-of-speech tagging;text corpus;triune continuum paradigm	Oi Yee Kwong;Benjamin Ka-Yin T'sou	2003			natural language processing;noun;language identification;speech recognition;linguistics;natural language;language technology	NLP	-12.362603076709451	-80.05698454826025	177440
f30bd28d6917665f97b0be86e8f5d7c672c966f2	identifying clickbait: a multi-strategy approach using neural networks		Online media outlets, in a bid to expand their reach and subsequently increase revenue through ad monetisation, have begun adopting clickbait techniques to lure readers to click on articles. The article fails to fulfill the promise made by the headline. Traditional methods for clickbait detection have relied heavily on feature engineering which, in turn, is dependent on the dataset it is built for. The application of neural networks for this task has only been explored partially. We propose a novel approach considering all information found in a social media post. We train a bidirectional LSTM with an attention mechanism to learn the extent to which a word contributes to the post's clickbait score in a differential manner. We also employ a Siamese net to capture the similarity between source and target information. Information gleaned from images has not been considered in previous approaches. We learn image embeddings from large amounts of data using Convolutional Neural Networks to add another layer of complexity to our model. Finally, we concatenate the outputs from the three separate components, serving it as input to a fully connected layer. We conduct experiments over a test corpus of 19538 social media posts, attaining an F1 score of 65.37% on the dataset bettering the previous state-of-the-art, as well as other proposed approaches, feature engineering or otherwise.	clickbait;concatenation;convolutional neural network;experiment;f1 score;feature engineering;internet;long short-term memory;monetization;neural networks;social media	Vaibhav Kumar;Dhruv Khattar;Siddhartha Gairola;Yash Kumar Lal;Vasudeva Varma	2018		10.1145/3209978.3210144	convolutional neural network;data mining;computer science;digital media;f1 score;machine learning;artificial neural network;concatenation;feature engineering;revenue;social media;artificial intelligence	AI	-18.301865978384495	-70.5888572528817	178354
4b864e06eec92ac580ff3187292e52a8c5983720	mining implicit intention using attention-based rnn encoder-decoder model		Nowadays, people are increasingly inclined to use social tools to express their intentions explicitly and implicitly. Most of the work is dedicated to solving the explicit intention detection, ignoring the implicit intention detection, as the former is relatively easy to solve with the classification method. In this work, we use the Attention-Based Encoder-Decoder model which is specified for the sequence-to-sequence task for user implicit intention detection. Our key idea is to leverage the model to “translate” the implicit intention into the corresponding explicit intent by using the parallel corpora built on the social data. Specifically, our model has domain adaptability since the way people express implicit intentions for different domain is variable, while the way to express explicit intentions is mostly in the same form, such as “I want to do sth”. In order to demonstrate the effectiveness of our method, we conduct experiments in four domains. The results show that our method offers a powerful “translation” for the implicit intentions and consequently identifies them.	encoder;random neural network	Chenxing Li;YaJun Du;Sida Wang	2017		10.1007/978-3-319-63315-2_36	adaptability;leverage (finance);computer science;artificial intelligence;pattern recognition;encoder;machine learning;recurrent neural network	NLP	-17.985122744428104	-70.85130285885685	178639
4f8e26bbb5dd31acfb30b397319bc9c65501f6c6	abstract concepts and pictures of real-world situations activate one another	abstract concepts;event knowledge;grounded cognition;picture-word processing;situation knowledge	concepts typically are defined in terms of lacking physical or perceptual referents. We argue instead that they are not devoid of perceptual information because knowledge of real-world situations is an important component of learning and using many abstract concepts. Although the relationship between perceptual information and abstract concepts is less straightforward than for concrete concepts, situation-based perceptual knowledge is part of many abstract concepts. In Experiment 1, participants made lexical decisions to abstract words that were preceded by related and unrelated pictures of situations. For example, share was preceded by a picture of two girls sharing a cob of corn. When pictures were presented for 500 ms, latencies did not differ. However, when pictures were presented for 1,000 ms, decision latencies were significantly shorter for abstract words preceded by related versus unrelated pictures. Because the abstract concepts corresponded to the pictured situation as a whole, rather than a single concrete object or entity, the necessary relational processing takes time. In Experiment 2, on each trial, an abstract word was presented for 250 ms, immediately followed by a picture. Participants indicated whether or not the picture showed a normal situation. Decision latencies were significantly shorter for pictures preceded by related versus unrelated abstract words. Our experiments provide evidence that knowledge of events and situations is important for learning and using at least some types of abstract concepts. That is, abstract concepts are grounded in situations, but in a more complex manner than for concrete concepts. Although people's understanding of abstract concepts certainly includes knowledge gained from language describing situations and events for which those concepts are relevant, sensory and motor information experienced during real-life events is important as well.		Ken McRae;Daniel Nedjadrasul;Raymond Pau;Bethany Pui-Hei Lo;Lisa King	2018	Topics in cognitive science	10.1111/tops.12328	psychology;cognitive science;cognitive psychology	AI	-7.501392796318495	-76.94066818728116	178735
bec3b18d0b74b7154882505545265b471bd7e68f	speakers optimize information density through syntactic reduction	higher order;stochastic model;logistic regression model	If language users are rational, they might choose to structu e their utterances so as to optimize communicative properties. In particular, in formation-theoretic and psycholinguistic considerations suggest that this may inc lude maximizing the uniformity of information density in an utterance. We investig a e this possibility in the context ofsyntactic reduction , where the speaker has the option of either marking a higher-order unit (a phrase) with an extra word, or leaving it unmarked. We demonstrate that speakers are more likely to reduce less i nformation-dense phrases. In a second step, we combine a stochastic model of st ructured utterance production with a logistic-regression model of syntactic r eduction to study which types of cues speakers employ when estimating the predictab il ty of upcoming elements. We demonstrate that the trend toward predictabil ity-sensitive syntactic reduction (Jaeger, 2006) is robust in the face of a wide varie ty of control variables, and present evidence that speakers use both surface a nd structural cues for predictability estimation.	circuit complexity;information design;item unique identification;logistic regression;theory	Roger Levy;T. Florian Jaeger	2006			natural language processing;speech recognition;higher-order logic;computer science;stochastic modelling;machine learning;logistic regression	NLP	-12.954417982608335	-79.50237427518569	179100
83a7a416147d6619b30390ea365bf23e94c9a2d9	likely to stop? predicting stopout in massive open online courses		Understanding why students stopout will help in understanding how students learn in MOOCs. In this report, part of a 3 unit compendium, we describe how we build accurate predictive models of MOOC student stopout. We document a scalable, stopout prediction methodology, end to end, from raw source data to model analysis. We attempted to predict stopout for the Fall 2012 offering of 6.002x. This involved the meticulous and crowd-sourced engineering of over 25 predictive features extracted for thousands of students, the creation of temporal and nontemporal data representations for use in predictive modeling, the derivation of over 10 thousand models with a variety of state-ofthe-art machine learning techniques and the analysis of feature importance by examining over 70000 models. We found that stop out prediction is a tractable problem. Our models achieved an AUC (receiver operating characteristic area-under-the-curve) as high as 0.95 (and generally 0.88) when predicting one week in advance. Even with more difficult prediction problems, such as predicting stop out at the end of the course with only one weeks’ data, the models attained AUCs of 0.7.	cobham's thesis;compendium;crowdsourcing;machine learning;massive open online course;predictive modelling;receiver operating characteristic;scalability;source data	Colin Taylor;Kalyan Veeramachaneni;Una-May O'Reilly	2014	CoRR		simulation;computer science;artificial intelligence;data science;machine learning;world wide web	ML	-9.571550469473959	-66.48472992831339	179431
425ddc9533b66ee25c6a4636f88739f36a67e4bb	a framework for automated schenkerian analysis	state space	In Schenkerian analysis, one seeks to find structural dependences among the notes of a composition and organize these dependences into a coherent hierarchy that illustrates the function of every note. This type of analysis reveals multiple levels of structure in a composition by constructing a series of simplifications of a piece showing various elaborations and prolongations. We present a framework for solving this problem, called IVI, that uses a state-space search formalism. IVI includes multiple interacting components, including modules for various preliminary analyses (harmonic, melodic, rhythmic, and cadential), identifying and performing reductions, and locating pieces of the Ursatz. We describe a number of the algorithms by which IVI forms, stores, and updates its hierarchy of notes, along with details of the Ursatz-finding algorithm. We illustrate IVI’s functionality on an excerpt from a Schubert piano composition, and also discuss the issues of subproblem interactions and the multiple parsings problem. 1 SCHENKERIAN ANALYSIS A number of types of music analysis are concerned with “labeling” individual objects in a musical score. In harmonic analysis, labels are assigned to chords and notes corresponding to harmonic function; in contrapuntal voice segregation, labels are assigned to notes indicating voice assignment. A rhythmic analysis may assign different levels of metrical importance to notes. These styles of analysis are similar in that they often describe musical components in isolation, or only in relation to their immediate neighbors on the musical surface. Structural analysis, on the other hand, emphasizes discovering relationships among notes and chords in a composition, rather than studying individual tones in a vacuum. The word “structure” here refers to “the complete fabric of the composition as established by melody, counterpoint, and harmony in combination” [1]. Schenkerian analysis is the most well-developed type of structural analysis. This type of analysis examines the “interrelationships among melody, counterpoint, and harmony” [1] in a hierarchical manner. Schenker’s theory of music allows one to determine which notes in a passage of music are more structurally significant than others. It is important not to confuse “structural significance” with “musical importance;” a musically important note (e.g., crucial for articulating correctly in a performance) can be a very insignificant tone from a structural standpoint. Judgments regarding structural importance result from finding dependences between notes or sets of notes: if a note X derives its musical function or meaning from the presence of another note Y , then X is dependent on Y and Y is deemed more structural than X . The process of completing a Schenkerian analysis proceeds in a recursive manner. Starting from the musical score of a composition, one may locate any number of structural dependences. After no more can be found, an abstracted score is produced by rearranging or removing the less structural notes. The new abstracted score will reveal new dependences: when their subservient neighbors are moved or eliminated, various structurally important notes in the original score will be deemed less significant to their new neighbors. This iterative process illustrates Schenker’s conception that tonal compositions consist of a “continuum of interrelated structural levels,” [1] where each structural level of the music represents that composition at a different level of abstraction. Each successively abstract level expands or prolongs various aspects of the previous one. The most abstract level of the piece is the background level. At the other end of the spectrum is the foreground level: an analysis at this level usually still contains most of the notes of the score and most closely represents the musical surface. Between these levels is the middleground level. While Schenker’s own analyses usually only contain these three levels, there can be many levels in between the surface level music and the ultimate background level; rarely are the levels clearly delineated. Schenker theorized that at the background level, all tonal works could be represented by one of three basic outlines, consisting of a three chord harmonic progression (the Bassbrechung or bass arpeggiation) supporting a three-, five-, or eight-note descending melodic line (the Urlinie or fundamental line). Together, these form the Ursatz or fundamen-	algorithm;beneath a steel sky;coherence (physics);color gradient;computer performance;instruction scheduling;interaction;iteration;iterative method;recursion;semantics (computer science);state space search;structural analysis;structural type system;theory;triune continuum paradigm	Phillip B. Kirlin;Paul E. Utgoff	2008			combinatorics;computer science;state space;machine learning;mathematics;world wide web;algorithm;statistics	PL	-10.389641635568918	-79.50112399400268	179842
14557d951608f0d03ec09d036cefc4420e1b8328	a comparative sociopragmatic study of ostensible invitations in english and farsi	pragmatics;analisis datos;selected works;estudio comparativo;etude comparative;data analysis;face threatening acts;anglais;undergraduate student;comparative study;bepress;analyse donnee;english;ingles;politeness;speech act theory;ostensible invitations	In their study in 1990, Clark and Isaacs identified five properties and seven defining features that distinguished between English ostensible and genuine invitations. To see if Persian ostensible and genuine invitations could be distinguished by the same features and properties, the present study was carried out. Forty five field workers observed and reported 566 ostensible and 607 genuine invitations. In addition, 34 undergraduate students were interviewed and 68 ostensible and 68 genuine invitations were gathered. Forty one pairs of friends were also interviewed and afforded 41 ostensible invitations. The results of the data analysis revealed that Persian ostensible invitations can also be distinguished from Persian genuine invitations by the features and properties identified by Clark and Isaacs. 2005 Elsevier B.V. All rights reserved.		Mohammad Ali Salmani-Nodoushan	2006	Speech Communication	10.1016/j.specom.2005.12.001	speech recognition;english;politeness;linguistics;data analysis;pragmatics	HCI	-13.595717283335876	-79.87994439780118	179859
bc6ad001c395e92920839e45dfd7e05ce69405d2	machine comprehension by text-to-text neural question generation		We propose a recurrent neural model that generates natural-language questions from documents, conditioned on answers. We show how to train the model using a combination of supervised and reinforcement learning. After teacher forcing for standard maximum likelihood training, we fine-tune the model using policy gradient techniques to maximize several rewards that measure question quality. Most notably, one of these rewards is the performance of a question-answering system. Our model is trained and evaluated on the recent question-answering dataset SQuAD.	gradient;list comprehension;mathematical optimization;natural language;question answering;recurrent neural network;reinforcement learning;supervised learning	Xingdi Yuan;Tong Wang;Çaglar Gülçehre;Alessandro Sordoni;Philip Bachman;Sandeep Subramanian;Saizheng Zhang;Adam Trischler	2017			natural language processing;computer science;artificial intelligence;machine learning;data mining	ML	-16.097208994026975	-74.76262589913934	179993
55d30f35d0da3a76c4fef697c464a36783316097	collaborative metric learning recommendation system: application to theatrical movie releases		Product recommendation systems are important for major movie studios during the movie greenlight process and as part of machine learning personalization pipelines. Collaborative Filtering (CF) models have proved to be effective at powering recommender systems for online streaming services with explicit customer feedback data. CF models do not perform well in scenarios in which feedback data is not available, in ‘cold start’ situations like new product launches, and situations with markedly different customer tiers (e.g., high frequency customers vs. casual customers). Generative natural language models that create useful theme-based representations of an underlying corpus of documents can be used to represent new product descriptions, like new movie plots. When combined with CF, they have shown to increase the performance in ‘cold start’ situations. Outside of those cases though in which explicit customer feedback is available, recommender engines must rely on binary purchase data, which materially degrades performance. Fortunately, purchase data can be combined with product descriptions to generate meaningful representations of products and customer trajectories in a convenient product space in which proximity represents similarity (in the case of product-toproduct comparisons) and affinity (in the case of customer-toproduct comparisons). Learning to measure the distance between points in this space can be accomplished with a deep neural network that trains on customer histories and on dense vectorizations of product descriptions. We developed a system based on Collaborative (Deep) Metric Learning (CML) to predict the purchase probabilities of new theatrical releases. We trained and evaluated the model using a large dataset of customer histories spanning multiple years, and tested the model for a set of movies that were released outside of the training window. Initial experiments show gains relative to models that don’t train on collaborative preferences.	artificial neural network;cold start;collaborative filtering;deep learning;end-to-end encryption;experiment;file spanning;language model;library (computing);machine learning;natural language;network architecture;open-source software;personalization;pipeline (computing);processor affinity;recommender system;streaming media;tensorflow	Miguel Campo;J. J. Espinoza;Julie Rieger;Abhinav Taliyan	2018	CoRR		new product development;personalization;computer science;recommender system;artificial neural network;collaborative filtering;data mining;natural language;product topology;studio	ML	-13.065807539234532	-72.15214958970515	180021
daf489ba1a9012ec2e5236fddfcc46f38cf848a9	question generation with doubly adversarial nets		We study the problem of question generation on a specific domain, where there are no labeled data. To address this problem, we propose a novel neural question generation approach called DoubAN, or doubly adversarial nets, which fully utilizes labeled data from other domains source domains and unlabeled data from the target domain. Learning a DoubAN involves two adversarial procedures between a question generator and two adversaries. One adversary is a domain-classification discriminator DC-Dis, which is designed to help the generator learn domain-general representations of the input text. The other is a question-answering discriminator QA-Dis, which provides more training data with estimated reward scores for generated text-question pairs. We conduct experiments on the SQuAD dataset as target-domain unlabeled data and the NewsQA dataset as source-domain labeled data. Experiment results show that our DoubAN achieves better results than baselines. Compared to model variants, which adopt only DC-Dis or QA-Dis, we find that the DC-Dis and QA-Dis indirectly interact with each other and jointly improve the quality of generated questions on the target domain. Moreover, extensive analysis and discussion prove the reasonableness and effectiveness of our proposed approach.	adversary (cryptography);discriminator;experiment;limbo;qa & ux manager;question answering;software quality assurance	Junwei Bao;Yeyun Gong;Nan Duan;Mengni Zhou;Tiejun Zhao	2018	IEEE/ACM Transactions on Audio, Speech, and Language Processing	10.1109/TASLP.2018.2859777	labeled data;adversarial system;data modeling;artificial intelligence;computer science;knowledge extraction;pattern recognition;task analysis;adversary;discriminator;training set	NLP	-15.668116898821374	-74.09884704408171	180169
d785135cbce67f217df1384c5363efd2cad1401a	duplicate detection in adverse drug reaction surveillance	drug safety;tecnologia electronica telecomunicaciones;case report;duplicate detection;random matching;mixture model;hit miss model;data cleaning;drug monitoring;data quality;tecnologias;grupo a;adverse drug reaction;record linkage;knowledge discovery	The WHO Collaborating Centre for International Drug Monitoring in Uppsala, Sweden, maintains and analyses the world’s largest database of reports on suspected adverse drug reaction (ADR) incidents that occur after drugs are on the market. The presence of duplicate case reports is an important data quality problem and their detection remains a formidable challenge, especially in the WHO drug safety database where reports are anonymised before submission. In this paper, we propose a duplicate detection method based on the hit-miss model for statistical record linkage described by Copas and Hilton, which handles the limited amount of training data well and is well suited for the available data (categorical and numerical rather than free text). We propose two extensions of the standard hit-miss model: a hit-miss mixture model for errors in numerical record fields and a new method to handle correlated record fields, and we demonstrate the effectiveness both at identifying the most likely duplicate for a given case report (94.7% accuracy) and at discriminating true duplicates from random matches (63% recall with 71% precision). The proposed method allows for more efficient data cleaning in post-marketing drug safety data sets, and perhaps other knowledge discovery applications as well.	data quality;find-a-drug;linkage (software);mixture model;numerical analysis;plasma cleaning	G. Niklas Norén;Roland Orre;Andrew Bate;Ivor Ralph Edwards	2006	Data Mining and Knowledge Discovery	10.1007/s10618-006-0052-8	record linkage;data quality;computer science;mixture model;data mining;database;pharmacovigilance;knowledge extraction;computer security;statistics	ML	-4.581269634739056	-67.51189481392394	180308
2431833891893cc2a4866e04a3223ae4bd8d40d7	an interpretable latent variable model for attribute applicability in the amazon catalogue		Learning attribute applicability of products in the Amazon catalog (e.g., predicting that a shoe should have a value for size, but not for battery-type) at scale is a challenge. The need for an interpretable model is contingent on (1) the lack of ground truth training data, (2) the need to utilise prior information about the underlying latent space and (3) the ability to understand the quality of predictions on new, unseen data. To this end, we develop the MaxMachine, a probabilistic latent variable model that learns distributed binary representations, associated to sets of features that are likely to co-occur in the data. Layers of MaxMachines can be stacked such that higher layers encode more abstract information. Any set of variables can be clamped to encode prior information. We develop fast sampling based posterior inference. Preliminary results show that the model improves over the baseline in 17 out of 19 product groups qualitatively reasonable predictions. 1 Attribute Applicability Many real-world datasets can be viewed as object-by-attribute matrices. A prominent example is the Amazon catalogue which contains over 100 million products (objects) and hundreds of attributes, of which only a small subset is assigned to each product. Thus, product-attribute-assignment can be viewed as a sparse binary matrix, shown for a small subsample of the German Amazon marketplace in Fig. 1. Being able to distinguish between attributes that are truly non-applicable (e.g., battery-type for a shoe), attributes that could reasonably be applied (e.g., weight for a book), and attributes that are clearly applicable (e.g., size for a T-shirt) is crucial for applications such as attribute imputation models, data quality management, template generation, product comparison and virtually all customer-facing downstream applications. We can cast the task of predicting attribute applicability as a multi-label classification problem, where each attribute constitutes a label and an arbitrary number of labels is assigned to each product. While there is recent progress in such extreme multi-label classification problems [1, 2], we face a particular challenge: The absence of reliable training labels makes it difficult to define a training metric. Therefore, we approach attribute applicability as an unsupervised problem and develop a probabilistic latent variable model that describes the generative process by which the binary product/applicability matrix is generated from a set of latent features. We aim to retain a simple, interpretable model, resembling the process of a marketplace seller who is filling in attributes for their product. The rationale behind the model is that each latent feature corresponds to a set of attributes that are likely to appear together such as (title, pages, language, release date) or (width, height, length). Each of these sets is represented by a latent dimension and the generative process for any product-attribute-pair is a noisy disjunction of these feature sets. The model design is further motivated by keeping sampling-based posterior inference scalable. We also assume that additional ∗Work was done at Amazon Berlin 31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA. ar X iv :1 71 2. 00 12 6v 1 [ st at .M L ] 3 0 N ov 2 01 7	baseline (configuration management);clamping (graphics);contingency (philosophy);data quality;design rationale;downstream (software development);encode;geo-imputation;ground truth;information processing;latent variable model;multi-label classification;nips;sampling (signal processing);scalability;software release life cycle;sparse matrix	Tammo Rukat;Dustin Lange;Cédric Archambeau	2017	CoRR		artificial intelligence;machine learning;mathematics;latent variable model;sampling (statistics);ground truth;training set;inference;probabilistic logic;binary number	ML	-12.943250385332881	-66.5315273085284	180325
66d1b7157a44c557be312c3a1a6f164c8ee06a5a	textual sentiment analysis via three different attention convolutional neural networks and cross-modality consistent regression		Abstract Word embeddings and CNN (convolutional neural networks) architecture are crucial ingredients of sentiment analysis. However, sentiment and lexicon embeddings are rarely used and CNN is incompetent to capture global features of sentence. To this end, semantic embeddings, sentiment embeddings and lexicon embeddings are applied for texts encoding, and three different attentions including attention vector, LSTM (long short term memory) attention and attentive pooling are integrated with CNN model in this paper. Additionally, a word and its context are explored to disambiguate the meaning of the word for rich input representation. To improve the performance of three different attention CNN models, CCR (cross-modality consistent regression) and transfer learning are presented. It is worth noticing that CCR and transfer learning are used in textual sentiment analysis for the first time. Finally, some experiments on two different datasets demonstrate that the proposed attention CNN models achieve the best or the next-best results against the existing state-of-the-art models.	artificial neural network;convolutional neural network;modality (human–computer interaction);sentiment analysis	Zu-Fan Zhang;Yang Zou;Chenquan Gan	2018	Neurocomputing	10.1016/j.neucom.2017.09.080	pattern recognition;convolutional neural network;word embedding;machine learning;artificial intelligence;architecture;sentiment analysis;transfer of learning;lexicon;encoding (memory);sentence;computer science	NLP	-17.524388736367396	-71.51448285405021	180704
cad37d64122d93c2c56d6a2b34c89a08c8616c0d	psychological state in text: a limitation of sentiment analysis		Starting with the idea that sentiment analysis models should be able to predict not only positive or negative but also other psychological states of a person, we implement a sentiment analysis model to investigate the relationship between the model and emotional state. We first examine psychological measurements of 64 participants and ask them to write a book report about a story. After that, we train our sentiment analysis model using crawled movie review data. We finally evaluate participants’ writings, using the pretrained model as a concept of transfer learning. The result shows that sentiment analysis model performs good at predicting a score, but the score does not have any correlation with human’s self-checked sentiment.	sentiment analysis	Hwiyeol Jo;Jeong Am Ryu	2018	CoRR		natural language processing;transfer of learning;machine learning;artificial intelligence;ask price;sentiment analysis;computer science	NLP	-13.06474642401167	-71.1082637777057	180827
22c2c10f47dfa6c42bec9d140538c68284027b30	image annotation and refinement with markov chain model of visual keywords and the semantics		This paper presents a discriminative stochastic method for image an- notation and refinement. We first segmented the images into regions and then cluster them into visual blobs with a small number than the whole training im- age regions. Each visual blob is regarded as a key visual word. Given the train- ing image set with annotations, we find that annotation process is conditioned by the selection sequence of both the semantic word and the key visual word. The process could be described in a Markov Chain with the transition process both between the candidate annotations and the visual words set. Experiments show the performance of this annotation method outperforms the state of art methods.		Zhonghua Sun;Kebin Jia	2014		10.1007/978-3-319-07773-4_37	natural language processing;computer science;pattern recognition;information retrieval	Logic	-9.293369742302247	-69.43735617520966	180934
a67b13dc820f79c0291476190b9f27f3d7e25ea8	tracking multiple statistics: simultaneous learning of object names and categories in english and mandarin speakers	individual differences;statistical learning;word learning;category learning;simultaneous processing	Two experiments were conducted to examine adult learners' ability to extract multiple statistics in simultaneously presented visual and auditory input. Experiment 1 used a cross-situational learning paradigm to test whether English speakers were able to use co-occurrences to learn word-to-object mappings and concurrently form object categories based on the commonalities across training stimuli. Experiment 2 replicated the first experiment and further examined whether speakers of Mandarin, a language in which final syllables of object names are more predictive of category membership than English, were able to learn words and form object categories when trained with the same type of structures. The results indicate that both groups of learners successfully extracted multiple levels of co-occurrence and used them to learn words and object categories simultaneously. However, marked individual differences in performance were also found, suggesting possible interference and competition in processing the two concurrent streams of regularities.	categories;experiment;extraction;interference (communication);name;programming paradigm;super robot monkey team hyperforce go!;syllable	Chi-hsin Chen;Lisa Gershkoff-Stowe;Chih-Yi Wu;Hintat Cheung;Chen Yu	2017	Cognitive science	10.1111/cogs.12417	streams;mandarin chinese;statistics;natural language processing;communication;adult learning;visual perception;concept learning;artificial intelligence;computer science	ML	-10.138263322432415	-77.81511509956286	180979
9e1e13ba091f99a0a81a64e85c58e0070e071916	dependencies of discourse structure on the modality of communication: oregon state university	noun phrase;speech acts;production system;discourse structure;oregon;computational linguistic;speech understanding;language production;face to face	"""With the genesis of speech understanding systems, computational linguistics research is becoming less wedded to teletype-based interaction. It would therefore be wise to look for systematic ways in which the discourse structure of voice interaction differs from teletype interaction. Such discoveries could lead to substantially different discourse components for speech understanding systems.Rubin (1980) points out that language experiences should not simply be characterized as oral or written. Rather, there is a set of dimensions along which language experiences such as having a conversation and writing/reading a letter might differ, including: the ability to interact, the sharing of space and time between speaker and hearer, the concreteness of referents, and the use of voice or print.Following Rubin's taxonomy, and influenced by Chapanis et al.'s [1977] communication mode study and Grosz' [1977] task-oriented dialogue work, we conducted a study to explore how the structure of an instruction-giving discourse depends on the communication situation in which it takes place. Twenty-five subjects were videotaped as they instructed twenty-five others in assembling a toy water pump. Five """"dialogues"""" each took place face-to-face, via telephone, teletype, audiotape, and written text. We chose to analyze telephone and teletype dialogues first since results would have direct implications for the design of speech understanding and production systems.Preliminary results indicate that the structure of telephone dialogues is markedly different from that of teletype dialogues. In telephone mode, speakers frequently, explicitly, and often indirectly, request hearers to identify the referents of noun phrases. For example, utterances used indirectly to perform such requests include """"there is a NP"""" and """"the NP?"""". In contrast, teletype """"speakers"""" rarely accomplish the goal of referring in a separate step. Instead, the goals of referring and requesting an assembly action are achieved with one utterance, usually an imperative such as """"Insert the green plunger into the large tube with threads on one end"""".As for computational implications, we are led to conclude that, within the framework of a plan-based theory of speech acts (Perrault and Allen [1980]), referent identification should be treated as a planned action by language production and comprehension systems. That is, by planning to facilitate the healer's plan, producers should design their noun phrases so that hearers can identify the referents. Conversely, comprehenders should reason about what the producer intended to be done with the uttered NP -- find its referent, supply a co-referring NP. etc. Our goal, then is to develop production and comprehension systems capable of reasoning about reference."""	computational linguistics;experience;genesis;imperative programming;modality (human–computer interaction);np (complexity);production system (computer science);speech recognition	Philip R. Cohen	1982	SIGART Newsletter	10.1145/1056663.1056716	natural language processing;noun phrase;computer science;artificial intelligence;linguistics;production system;programming language	NLP	-11.341234776170076	-78.8757394765805	181028
b44415a13f29ddc1af497b3876a2396673c3cfc0	twin networks: using the future as a regularizer		Being able to model long-term dependencies in sequential data, such as text, has been among the long-standing challenges of recurrent neural networks (RNNs). This issue is strictly related to the absence of explicit planning in current RNN architectures, more explicitly, the network is trained to predict only the next token given previous ones. In this paper, we introduce a simple way of biasing the RNNs towards planning behavior. Particularly, we introduce an additional neural network which is trained to generate the sequence in reverse order, and we require closeness between the states of the forward RNN and backward RNN that predict the same token. At each step, the states of the forward RNN are required to match the future information contained in the backward states. We hypothesize that the approach eases modeling of long-term dependencies thus helping in generating more globally consistent samples. The model trained with conditional generation achieved 4% relative improvement (CER of 7.3 compared to a baseline of 7.6).	artificial neural network;automated planning and scheduling;baseline (configuration management);biasing;centrality;random neural network;recurrent neural network	Dmitriy Serdyuk;Nan Rosemary Ke;Alessandro Sordoni;Christopher Joseph Pal;Yoshua Bengio	2017	CoRR		artificial neural network;artificial intelligence;recurrent neural network;machine learning;closeness;computer science	ML	-15.684845082050556	-73.76768165665437	181070
7bf5e5f6da7f04cdf17534fe8b8446c974ec3671	verb bias and structural priming in non-linguistic grammar acquisition task		Domain-general statistical learning (SL) is thought to support language phenomena like verb bias and structural priming. We explored this idea by inducing these phenomena within a non-linguistic serial reaction time (SRT) task where participants learned an English-like artificial language using SL. In a series of two experiments we found error rates to be sensitive to verbs’ structural preferences and abstract structural priming. The similarities between the behaviour in this task and previous linguistic research suggests that this method may be useful for studying the nature of SL in language learning and processing.	division algorithm;experiment;machine learning;natural language processing;sl (complexity)	Marius Janciauskas;Franklin Chang	2013			cognitive psychology;language acquisition;structural priming;priming (psychology);syntax;psychology;artificial grammar learning;linguistics;verb;modal verb;sentence	NLP	-9.692798725151334	-77.6904653784723	181256
a3e3b40ca6f0b3aaf1d725cfb1c276e662f13f6b	a phoc decoder for lexicon-free handwritten word recognition		In this paper, we propose a novel probabilistic model for lexicon-free handwriting recognition. Model inputs are word images encoded as Pyramidal Histogram Of Character (PHOC) vectors. PHOC vectors have been used as efficient attribute-based, multi-resolution representations of either text strings or word image contents. The proposed model formulates PHOC decoding as the problem of finding the most probable sequence of characters corresponding to the given PHOC. We model PHOC layers as Beta-distributed observations, linked to hidden states that correspond to character estimates. Characters are in turn linked to one another along a Markov chain, encoding language model information. The sequence of characters is estimated using the max-sum algorithm in a process that is akin to Viterbi decoding. Numerical experiments on the well-known George Washington database show competitive recognition results.	algorithm;belief propagation;experiment;handwriting recognition;language model;lexicon;markov chain;statistical model;viterbi decoder;whole earth 'lectronic link	Giorgos Sfikas;George Retsinas;Basilios Gatos	2017	2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR)	10.1109/ICDAR.2017.90	computer science;pattern recognition;artificial intelligence;viterbi decoder;word recognition;decoding methods;hidden markov model;language model;handwriting recognition;markov chain;graphical model	Vision	-17.25068018746712	-76.47717327406417	181503
7b9846c86220808a33b560bea06868f7d8251263	learning to sing like a bird: the self-supervised acquisition of birdsong	motor control	This paper presents a new framework for self-supervised sensorimotor learning. We demonstrate this framework with a system that learns to mimic a zebra finch, directly modeled on the dynamics of how male fledglings acquire birdsong from their fathers. Our system first listens to the song of an adult finch. By listening to its own initially nascent attempts at mimicry through an articulatory synthesizer, the system organizes motor maps generating its vocalizations. Our approach is founded on the notion of cross-modal clustering, introduced in (Coen 2005, 2006a), and is unusual for its recursive reuse of perceptual mechanisms in developing motor control. In this paper, we outline this framework, present its results on the unsupervised acquisition of birdsong, and discuss other potential applications.	cluster analysis;finch;map;modal logic;recursion	Michael H. Coen	2007				AI	-5.612811559190533	-78.98413784408473	181656
10a36dea0167511b66deca65fdca978aa9afdb11	simple baseline for visual question answering		We describe a very simple bag-of-words baseline for visual question answering. This baseline concatenates the word features from the question and CNN features from the image to predict the answer. When evaluated on the challenging VQA dataset [2], it shows comparable performance to many recent approaches using recurrent neural networks. To explore the strength and weakness of the trained model, we also provide an interactive web demo1, and open-source code2.	artificial neural network;bag-of-words model;baseline (configuration management);concatenation;open-source software;question answering;recurrent neural network	Bolei Zhou;Yuandong Tian;Sainbayar Sukhbaatar;Arthur Szlam;Rob Fergus	2015	CoRR		computer science;machine learning;data mining;information retrieval	NLP	-16.491034453090595	-70.88071353714086	181735
79b78399eeb05f505b4487926131a5b30527dd78	effects of the restriction of hand gestures on disfluency		This paper describes an experimental pilot study of disfluency and gesture rates in spontaneous speech where speakers perform a communication task in three conditions: hands free, one arm immobilized, both arms immobilized. Previous work suggests that the restriction of the ability to gesture can have an impact on the fluency of speech. In particular, it has been found that the inability to produce iconic gestures, which depict actions and objects, results in a higher rate of disfluency. Models of speech production account for this by suggesting that gesture and speech production are part of the same integrated system. Such models differ in their interpretation of the location of the gesture planning mechanism in relation to the speech model: some authors suggest that iconic gestures relate closely to lexical access, while others suggest that the link is located around the conceptualization stage. The findings of this study tentatively confirm that there is a relationship between gesture and fluency – overall, disfluency increases as gesture is restricted. But it remains unclear whether the disfluency is more related to lexical access than to conceptualization. Proposals for a larger study are suggested. The work is of interest to psycholinguists focusing on the integration of gesture into models of speech production and to Speech and Language Therapists who need to know about the impact that an impaired ability to produce gestures may have on communication.	coat of arms;conceptualization (information science);gesture recognition;lexicon;need to know;spontaneous order	Sheena Finlayson;Victoria Forrest;Robin J. Lickley;Janet MacKenzie Beck	2003			conceptualization;gesture recognition;communication;speech disorder;fluency;need to know;psycholinguistics;psychology;speech production;gesture	HCI	-8.14876925154865	-79.40193155356101	181956
7c6e5af5119ffa8b644b702a9a6063e8709fec3e	gated convolutional recurrent neural networks for multilingual handwriting recognition		In this paper, we propose a new neural network architecture for state-of-the-art handwriting recognition, alternative to multi-dimensional long short-term memory (MD-LSTM) recurrent neural networks. The model is based on a convolutional encoder of the input images, and a bidirectional LSTM decoder predicting character sequences. In this paradigm, we aim at producing generic, multilingual and reusable features with the convolutional encoder, leveraging more data for transfer learning. The architecture is also motivated by the need for a fast training on GPUs, and the requirement of a fast decoding on CPUs. The main contribution of this paper lies in the convolutional gates in the encoder, enabling hierarchical context-sensitive feature extraction. The experiments on a large benchmark including seven languages show a consistent and significant improvement of the proposed approach over our previous production systems. We also report state-of-the-art results on line and paragraph level recognition on the IAM and Rimes databases.	artificial neural network;benchmark (computing);central processing unit;context-sensitive grammar;convolutional code;convolutional neural network;database;document layout analysis;encoder;experiment;feature extraction;graphics processing unit;handwriting recognition;identity management;language identification;long short-term memory;network architecture;programming paradigm;recurrent neural network	Théodore Bluche;Ronaldo O. Messina	2017	2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR)	10.1109/ICDAR.2017.111	artificial intelligence;pattern recognition;encoder;architecture;task analysis;computer science;feature extraction;artificial neural network;recurrent neural network;decoding methods;handwriting recognition	Vision	-17.15118067253534	-74.67994162185956	182015
a62495e63a1e447817f4d7c9c8a3889aad8f369d	using multi-task and transfer learning to solve working memory tasks		We propose a new architecture called Memory-Augmented Encoder-Solver (MAES) that enables transfer learning to solve complex working memory tasks adapted from cognitive psychology. It uses dual recurrent neural network controllers, inside the encoder and solver, respectively, that interface with a shared memory module and is completely differentiable. We study different types of encoders in a systematic manner and demonstrate a unique advantage of multi-task learning in obtaining the best possible encoder. We show by extensive experimentation that the trained MAES models achieve task-size generalization, i.e., they are capable of handling sequential inputs 50 times longer than seen during training, with appropriately large memory modules. We demonstrate that the performance achieved by MAES far outperforms existing and well-known models such as the LSTM, NTM and DNC on the entire suite of tasks.		T. S. Jayram;Tomasz Kornuta;Ryan L. McAvoy;Ahmet S. Ozcan	2018	2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)		memory management;encoder;memory architecture;transfer of learning;machine learning;encoding (memory);working memory;computer science;recurrent neural network;artificial intelligence;shared memory	ML	-14.36394901123794	-74.63542965724903	182027
afc3b39d8aa0100d7aeb6123668a9bec9bd6c63e	adapting neural single-document summarization model for abstractive multi-document summarization: a pilot study		Till now, neural abstractive summarization methods have achieved great success for single document summarization (SDS). However, due to the lack of large scale multi-document summaries, such methods can be hardly applied to multi-document summarization (MDS). In this paper, we investigate neural abstractive methods for MDS by adapting a state-of-the-art neural abstractive summarization model for SDS. We propose an approach to extend the neural abstractive model trained on large scale SDS data to the MDS task. Our approach only makes use of a small number of multi-document summaries for fine tuning. Experimental results on two benchmark DUC datasets demonstrate that our approach can outperform a variety of base-	automatic summarization;benchmark (computing);encoder;multi-document summarization;upsampling	Jianmin Zhang;Jiwei Tan;Xiaojun Wan	2018				AI	-17.168849684898674	-74.48166677960363	182594
81e71eab6f3a373f817c871364af869be2f21511	bilingual analysis of song lyrics and audio words	audioword;mllda;lda;sparse coding;topic model	Thanks to the development of music audio analysis, state-of-the-art techniques can now detect musical attributes such as timbre, rhythm, and pitch with certain level of reliability and effectiveness. An emerging body of research has begun to model the high-level perceptual properties of music listening, including the mood and the preferable listening context of a music piece. Towards this goal, we propose a novel text-like feature representation that encodes the rich and time-varying information of music using a composite of features extracted from the song lyrics and audio signals. In particular, we investigate dictionary learning algorithms to optimize the generation of local feature descriptors and also probabilistic topic models to group semantically relevant text and audio words. This text-like representation leads to significant improvement in automatic mood classification over conventional audio features.	algorithm;dictionary;high- and low-level;machine learning;pitch (music)	Jen-Yu Liu;Chin-Chia Michael Yeh;Yi-Hsuan Yang;Yuan-Ching Teng	2012		10.1145/2393347.2396323	natural language processing;speech recognition;computer science;machine learning;topic model;neural coding	Web+IR	-16.90721466297711	-70.74424755890485	182707
0a00df600e766775593ebad226a10bd778f33ee3	classifying relations via long short term memory networks along shortest dependency paths	会议论文	Relation classification is an important research arena in the field of natural language processing (NLP). In this paper, we present SDP-LSTM, a novel neural network to classify the relation of two entities in a sentence. Our neural architecture leverages the shortest dependency path (SDP) between two entities; multichannel recurrent neural networks, with long short term memory (LSTM) units, pick up heterogeneous information along the SDP. Our proposed model has several distinct features: (1) The shortest dependency paths retain most relevant information (to relation classification), while eliminating irrelevant words in the sentence. (2) The multichannel LSTM networks allow effective information integration from heterogeneous sources over the dependency paths. (3) A customized dropout strategy regularizes the neural network to alleviate overfitting. We test our model on the SemEval 2010 relation classification task, and achieve an F1-score of 83.7%, higher than competing methods in the literature.	artificial neural network;brown corpus;dropout (neural networks);entity;f1 score;long short-term memory;natural language processing;network model;overfitting;plasma cleaning;recurrent neural network;relation (database);relevance;semeval;software propagation;wordnet	Yan Xu;Lili Mou;Ge Li;Yunchuan Chen;Hao Peng;Zhi Jin	2015		10.18653/v1/D15-1206	computer science;artificial intelligence;machine learning;data mining	NLP	-18.228374549070015	-71.69406361826286	182719
24ec4f193f084535394127ae8ddfe48f9749c201	using context and sensory data to learn first and second person pronouns	humanoid robot;deixis;real time;autism;pronoun reversal;natural language;concept learning;word learning;chi square test;pronouns	"""We present a method of grounded word learning that can learn the meanings of first and second person pronouns. The model selectively associates new words with agents in the environment by using already understood words to establish context. The method uses chi-square tests to find significant associations between the new words and attributes of the relevant agents. We show that this model can learn from a transcript of a parent-child interaction that """"I"""" refers to the person who is speaking. With the additional information that questions about wants refer to the person being asked about them, the system learns that """"you"""" refers to the person being addressed. We show that an incorrect assumption about the subject of """"want"""" questions can lead to pronoun reversal, a linguistic error most commonly found in autistic and congenitally blind children. Finally, we present results from a physical implementation on a robot that runs in real time."""	protologism;robot	Kevin Gold;Brian Scassellati	2006		10.1145/1121241.1121262	pronoun reversal;natural language processing;personal pronoun;concept learning;object pronoun;deixis;autism;computer science;humanoid robot;artificial intelligence;subject pronoun;natural language	AI	-9.16236172511299	-76.62440650776067	182850
736203ae164c572491654dac0bcf142e4ecf0daf	automated game design via conceptual expansion		Automated game design has remained a key challenge within the field of Game AI. In this paper, we introduce a method for recombining existing games to create new games through a process called conceptual expansion. Prior automated game design approaches have relied on hand-authored or crowdsourced knowledge, which limits the scope and applications of such systems. Our approach instead relies on machine learning to learn approximate representations of games. Our approach recombines knowledge from these learned representations to create new games via conceptual expansion. We evaluate this approach by demonstrating the ability for the system to recreate existing games. To the best of our knowledge, this represents the first machine learning-based automated game design system.	approximation algorithm;baseline (configuration management);crowdsourcing;encode;knowledge base;machine learning;video game design	Matthew J. Guzdial;Mark O. Riedl	2018			machine learning;simulation;artificial intelligence;computer science;game design	AI	-15.921463110869917	-68.99978072250573	183588
f370949d16135d87330f55c7f6747aa6eb5072e3	shape retrieval with qualitative relations: the influence of part-order and approximation precision on retrieval performance and computational effort	remarkable retrieval result;qualitative relation;shape part-order;retrieval performance;computational effort;appropriate approximation precision;similarity-based shape retrieval;shape descriptors;precision value;approximation precision;thorough investigation;intended investigation	remarkable retrieval result;qualitative relation;shape part-order;retrieval performance;computational effort;appropriate approximation precision;similarity-based shape retrieval;shape descriptors;precision value;approximation precision;thorough investigation;intended investigation	approximation;computation	Arne Schuldt	2011		10.1007/978-3-642-24455-1_30	computer vision;machine learning;mathematics;information retrieval	Web+IR	-11.546946679737415	-67.9843438903567	183781
597bdf2b508722f13c74451832a36465b4ec6ad8	representations of context in recognizing the figurative and literal usages of idioms		Many idiomatic expressions can be interpreted literally or figuratively, depending on the context in which they occur. Developing an appropriate computational model of the context is crucial for automatic idiom usage recognition. While many existing methods incorporate some elements of context, they have not sufficiently captured the interactions between the linguistic properties of idiomatic expressions and the representations of the context. In this paper we perform an in-depth exploration of the role of representations of the context for idiom usage recognition; we highlight the advantages and limitations of different representation choices in existing methods in terms of known linguistic properties of idioms; we then propose a supervised ensemble method that selects representations adaptively for different idioms. Experimental result suggests that the proposed method performs better for a wider range of idioms than previous methods.	computational model;interaction;literal (mathematical logic);programming idiom	Changsheng Liu;Rebecca Hwa	2017			machine learning;artificial intelligence;natural language processing;computer science;literal and figurative language;expression (mathematics)	AI	-16.51756379593271	-68.967907124401	183988
f6dc77a306f50feabe10538e3d546d5d98bb1826	polarity and intensity: the two aspects of sentiment analysis		Current multimodal sentiment analysis frames sentiment score prediction as a general Machine Learning task. However, what the sentiment score actually represents has often been overlooked. As a measurement of opinions and affective states, a sentiment score generally consists of two aspects: polarity and intensity. We decompose sentiment scores into these two aspects and study how they are conveyed through individual modalities and combined multimodal models in a naturalistic monologue setting. In particular, we build unimodal and multimodal multitask learning models with sentiment score prediction as the main task and polarity and/or intensity classification as the auxiliary tasks. Our experiments show that sentiment analysis benefits from multi-task learning, and individual modalities differ when conveying the polarity and intensity aspects of sentiment.	computer multitasking;database;emotion recognition;experiment;mosi protocol;machine learning;modality (human–computer interaction);multi-task learning;multimodal interaction;sentiment analysis	Leimin Tian;Catherine Lai;Johanna D. Moore	2018	CoRR		artificial intelligence;sentiment analysis;computer science;modalities;machine learning;affect (psychology)	NLP	-12.084789566767007	-70.86162915694796	184084
385b720ffc30b5a8267f830e7e24e5d27b395179	neural relation classification with text descriptions		Relation classification is an important task in natural language processing fields. State-of-the-art methods usually concentrate on building deep neural networks based classification models on the training data in which the relations of the labeled entity pairs are given. However, these methods usually suffer from the data sparsity issue greatly. On the other hand, we notice that it is very easy to obtain some concise text descriptions for almost all of the entities in a relation classification task. The text descriptions can provide helpful supplementary information for relation classification. But they are ignored by most of existing methods. In this paper, we propose DesRC, a new neural relation classification method which integrates entities text descriptions into deep neural networks models. We design a two-level attention mechanism to select the most useful information from the ”intra-sentence” aspect and the ”cross-sentence” aspect. Besides, the adversarial training method is also used to further improve the classification performance. Finally, we evaluate the proposed method on the SemEval 2010 dataset. Extensive experiments show that our method achieves much better experimental results than other state-of-the-art relation classification methods.	artificial neural network;baseline (configuration management);deep learning;entity;experiment;natural language processing;personalization;semeval;sparse matrix;teaching method	Feiliang Ren;Di Zhou;Zhihui Liu;Yongcheng Li;Rongsheng Zhao;Yongkang Liu;Xiaobo Liang	2018			artificial intelligence;natural language processing;computer science	AI	-17.88970558877467	-71.15091225955544	184235
05f4d88a5d7315ffea26b82d366fe1fa775f8eca	pervasive attention: 2d convolutional neural networks for sequence-to-sequence prediction		Current state-of-the-art machine translation systems are based on encoder-decoder architectures, that first encode the input sequence, and then generate an output sequence based on the input encoding. Both are interfaced with an attention mechanism that recombines a fixed encoding of the source tokens based on the decoder state. We propose an alternative approach which instead relies on a single 2D convolutional neural network across both sequences. Each layer of our network re-codes source tokens on the basis of the output sequence produced so far. Attention-like properties are therefore pervasive throughout the network. Our model yields results that are competitive with state-of-the-art encoder-decoder systems, while being conceptually simpler and having fewer parameters.	artificial neural network;autoregressive model;bleu;code;convolution;convolutional neural network;encode;embedded system;encoder;list of minor characters in the matrix series;machine translation;neural machine translation;pervasive informatics;programming paradigm	Maha Elbayad;Laurent Besacier;Jakob Verbeek	2018			machine learning;machine translation;convolutional neural network;encoding (memory);artificial intelligence;computer science	NLP	-17.050446188781475	-75.00622194307797	185287
f5350ef1d45574e33f5b0f1c013a5bb00e1b1c55	decoding strategies for neural referring expression generation		RNN-based sequence generation is now widely used in NLP and NLG (natural language generation). Most work focusses on how to train RNNs, even though also decoding is not necessarily straightforward: previous work on neural MT found seq2seq models to radically prefer short candidates, and has proposed a number of beam search heuristics to deal with this. In this work, we assess decoding strategies for referring expression generation with neural models. Here, expression length is crucial: output should neither contain too much or too little information, in order to be pragmatically adequate. We find that most beam search heuristics developed for MT do not generalize well to referring expression generation (REG), and do not generally outperform greedy decoding. We observe that beam search heuristics for termination seem to override the model’s knowledge of what a good stopping point is. Therefore, we also explore a recent approach called trainable decoding, which uses a small network to modify the RNN’s hidden state for better decoding results. We find this approach to consistently outperform greedy decoding for REG.	bleu;beam search;greedy algorithm;heuristic (computer science);information;mathematical optimization;natural language generation;natural language processing;random neural network;referring expression generation	Sina Zarrieß;David Schlangen	2018				NLP	-18.645783185351767	-75.9878891574005	185308
9c0baa5ff5e882625cb6dd1a9cef3bfa85c92e50	bits_pilani@inli-fire-2017: indian native language identification using deep learning		The task of Native Language Identification involves identifying the prior or first learnt language of a user based on his writing technique and/or analysis of speech and phonetics in second language. There is a surplus of such data present on social media sites and organised dataset from bodies like Educational Testing Service(ETS), which can be exploited to develop language learning systems and forensic linguistics. In this paper we propose a deep neural network for this task using hierarchical paragraph encoder with attention mechanism to identify relevant features over tendencies and errors a user makes with second language for the INLI task in FIRE 2017. The task involves six Indian languages as prior/native set and english as the second language which has been collected from user's social media account.	artificial neural network;deep learning;encoder;hybrid system;language identification;n-gram;native-language identification;social media	Rupal Bhargava;Jaspreet Singh;Shivangi Arora;Yashvardhan Sharma	2017			native-language identification;natural language processing;deep learning;computer science;artificial intelligence	NLP	-17.246251932215305	-75.94305444946548	185564
9f595b6c3608736c891748b4fbabe7f3e1ce7b0f	plan optimization for creating bilingual dictionaries of low-resource languages		The constraint-based approach has been proven useful for inducing bilingual lexicons for closely-related low-resource languages. When we want to create multiple bilingual dictionaries linking several languages, we need to consider manual creation by bilingual language experts if there are no available machine-readable dictionaries are available as input. To overcome the difficulty in planning the creation of bilingual dictionaries, the consideration of various methods and costs, plan optimization is essential. We adopt the Markov Decision Process (MDP) in formalizing plan optimization for creating bilingual dictionaries; the goal is to better predict the most feasible optimal plan with the least total cost before fully implementing the constraint-based bilingual dictionary induction framework. We define heuristics based on input language characteristics to devise a baseline plan for evaluating our MDP-based approach with total cost as an evaluation metric. The MDP-based proposal outperformed heuristic planning on total cost for all datasets examined.	algorithm;automated planning and scheduling;baseline (configuration management);bilingual dictionary;data dictionary;graph theory;heuristic (computer science);human-readable medium;lexicon;markov chain;markov decision process;mathematical optimization;time complexity	Arbi Haza Nasution;Yohei Murakami;Toru Ishida	2017	2017 International Conference on Culture and Computing (Culture and Computing)	10.1109/Culture.and.Computing.2017.21	machine learning;total cost;heuristics;markov decision process;markov process;heuristic;computer science;bilingual dictionary;artificial intelligence	AI	-18.93657370336416	-76.82496079412543	185690
0fe9e8da7954c1749d956949f668509b6ac22056	a computational model of risk-context-dependent inductive reasoning based on a support vector machine	support vector machines;computer model;kernel function;conceptual clustering;corpus based conceptual clustering;context model;inductive reasoning;risk;kernel method;context dependent;support vector machine;natural language processing;context;context effect	A computational model of cognitive inductive reasoning that accounts for risk context effects is proposed. The model is based on a Support Vector Machine (SVM) that utilizes the kernel method. Kernel functions within the model are assumed to represent the functions of similarity computations based on distances between premise entities and conclusion entities in inductive reasoning arguments. Multipliers related to the kernel functions have the role of adjusting similarities and can explain rating shifts between two different risk contexts. Model fitting data supports the SVM-based model with kernel functions as a model of inductive reasoning in risk contexts. Finally, the paper discusses how the multipliers for kernel functions provide a satisfactory cognitive theoretical account of similarity adjustment.	computation;computational model;entity;inductive reasoning;kernel method;support vector machine	Kayo Sakamoto;Masanori Nakagawa	2008		10.1007/978-3-540-78159-2_26	kernel method;kernel embedding of distributions;radial basis function kernel;machine learning;pattern recognition;data mining;mathematics;tree kernel;polynomial kernel	AI	-8.533261165355992	-66.62260784305343	185916
0d310cf7f829b8704c591be6f55e98f78b288a34	modeling inter-aspect dependencies for aspect-based sentiment analysis		Aspect-based Sentiment Analysis is a finegrained task of sentiment classification for multiple aspects in a sentence. Present neuralbased models exploit aspect and its contextual information in the sentence but largely ignore the inter-aspect dependencies. In this paper, we incorporate this pattern by simultaneous classification of all aspects in a sentence along with temporal dependency processing of their corresponding sentence representations using recurrent networks. Results on the benchmark SemEval 2014 dataset suggest the effectiveness of our proposed approach.	benchmark (computing);feedback;recurrent neural network;semeval;sentiment analysis	Devamanyu Hazarika;Soujanya Poria;Prateek Vij;Gangeshwar Krishnamurthy;Erik Cambria;Roger Zimmermann	2018			natural language processing;sentiment analysis;machine learning;computer science;artificial intelligence	NLP	-18.361120435010516	-71.94809711342225	186281
8e04c4254e105bf3b9b043f2ca19f2fb29949c3c	a neural network based model for loanword identification in uyghur		Lexical borrowing happens in almost all languages. To obtain more bilingual knowledge from monolingual corpora, we propose a neural network based loanword identification model for Uyghur. We build our model on a bidirectional LSTM CNN framework, which can capture past and future information effectively and learn both word level and character level features from training data automatically. To overcome data sparsity that exists in model training, we also suggest three additional features , such as hybrid language model feature, pronunciation similarity feature and part-of-speech tagging feature to further improve the performance of our proposed approach. We conduct experiments on Chinese, Arabic and Russian loanword detection in Uyghur. Experimental results show that our proposed method outperforms several baseline models.	academy;artificial neural network;baseline (configuration management);concatenation;experiment;feature vector;language model;long short-term memory;part-of-speech tagging;sparse matrix;test set;text corpus;word embedding	Chenggang Mi;Yating Yang;Lei Wang;Xi Zhou;Tonghai Jiang	2018			artificial intelligence;natural language processing;speech recognition;artificial neural network;computer science;loanword	NLP	-18.935520344042104	-73.93699422441175	186320
01a2b2ac4d64f663cef6efeeb0a925b05fa09db5	bootstrapping social emotion classification with semantically rich hybrid neural networks		Social emotion classification aims to predict the aggregation of emotional responses embedded in online comments contributed by various users. Such a task is inherently challenging because extracting relevant semantics from free texts is a classical research problem. Moreover, online comments are typically characterized by a sparse feature space, which makes the corresponding emotion classification task very difficult. On the other hand, though deep neural networks have been shown to be effective for speech recognition and image analysis tasks because of their capabilities of transforming sparse low-level features to dense high-level features, their effectiveness on emotion classification requires further investigation. The main contribution of our work reported in this paper is the development of a novel model of semantically rich hybrid neural network (HNN) which leverages unsupervised teaching models to incorporate semantic domain knowledge into the neural network to bootstrap its inference power and interpretability. To our best knowledge, this is the first successful work of incorporating semantics into neural networks to enhance social emotion classification and network interpretability. Through empirical studies based on three real-world social media datasets, our experimental results confirm that the proposed hybrid neural networks outperform other state-of-the-art emotion classification methods.	artificial neural network;deep learning;embedded system;feature vector;high- and low-level;hybrid neural network;image analysis;social media;sparse matrix;speech recognition	Xiangsheng Li;Yanghui Rao;Haoran Xie;Raymond Y. K. Lau;Jian Yin;Fu Lee Wang	2017	IEEE Transactions on Affective Computing	10.1109/TAFFC.2017.2716930	hybrid neural network;machine learning;unsupervised learning;time delay neural network;feature vector;emotion classification;artificial neural network;deep learning;feature extraction;artificial intelligence;pattern recognition;computer science	AI	-17.57994654739883	-68.75812564312986	186361
98e6461b4d9eab81d17478cd732368c380d1edac	integrating tree structures and graph structures with neural networks to classify discussion discourse acts		We proposed a model that integrates discussion structures with neural networks to classify discourse acts. Several attempts have been made in earlier works to analyze texts that are used in various discussions. The importance of discussion structures has been explored in those works but their methods required a sophisticated design to combine structural features with a classifier. Our model introduces tree learning approaches and a graph learning approach to directly capture discussion structures without structural features. In an evaluation to classify discussion discourse acts in Reddit, the model achieved improvements of 1.5% in accuracy and 2.2 in F1 score compared to the previous best model. We further analyzed the model using an attention mechanism to inspect interactions among different learning approaches.	f1 score;graphics core next;interaction;long short-term memory;neural networks;statistical classification	Yasuhide Miura;Ryuji Kano;Motoki Taniguchi;Tomoki Taniguchi;Shotaro Misawa;Tomoko Ohkuma	2018			artificial intelligence;pattern recognition;artificial neural network;computer science;tree structure;graph	NLP	-17.75747085170723	-70.04122638141824	186385
3204192d28e961c358405519061422198782132a	cross device matching for online advertising with neural feature ensembles : first place solution at cikm cup 2016		We describe the 1st place winning approach for the CIKM Cup 2016 Challenge. In this paper, we provide an approach to reasonably identify same users across multiple devices based on browsing logs. Our approach regards a candidate ranking problem as pairwise classification and utilizes an unsupervised neural feature ensemble approach to learn latent features of users. Combined with traditional hand crafted features, each user pair feature is fed into a supervised classifier in order to perform pairwise classification. Lastly, we propose supervised and unsupervised inference techniques. The source code for our solution can be found at http://github.com/vanzytay/cikm cup.	baseline (configuration management);clickstream;deep learning;feature vector;language model;machine learning;online advertising;supervised learning;unsupervised learning	Yi Tay;Cong-Minh Phan;Tuan-Anh Nguyen Pham	2016	CoRR		computer science;machine learning;pattern recognition;data mining	AI	-16.812491974810982	-70.04553725104299	186972
f2abaa1476fe1f00358f3eaa77dde2f348f58982	towards an unequivocal representation of actions		This work introduces verb-only representations for actions and interactions; the problem of describing similar motions (e.g. u0027open dooru0027, u0027open cupboardu0027), and distinguish differing ones (e.g. u0027open dooru0027 vs u0027open bottleu0027) using verb-only labels. Current approaches for action recognition neglect legitimate semantic ambiguities and class overlaps between verbs (Fig. 1), relying on the objects to disambiguate interactions. We deviate from single-verb labels and introduce a mapping between observations and multiple verb labels - in order to create an Unequivocal Representation of Actions. The new representation benefits from increased vocabulary and a soft assignment to an enriched space of verb labels. We learn these representations as multi-output regression, using a two-stream fusion CNN. The proposed approach outperforms conventional single-verb labels (also known as majority voting) on three egocentric datasets for both recognition and retrieval.	interaction;vocabulary;while	Michael Wray;Davide Moltisanti;Dima Damen	2018			machine learning;artificial intelligence;pattern recognition;fusion;majority rule;verb;computer science;vocabulary	AI	-16.202087638319995	-69.32284469571779	187918
a1cec9c22de44cc5df9b49eb429df1bb5092b3e7	offensive sentence classification using character-level cnn and transfer learning with fake sentences		There are two difficulties in classifying offensive sentences: One is the modifiability of offensive terms, and the other is the class imbalance which appears in general offensive corpus. Solving these problems, we propose a method of pre-training fake sentences generated as character-level to convolution layers preventing under-fitting from data shortage, and dealing with the data imbalance. We insert the offensive words to half of the randomly generated sentences, and train the convolution neural networks (CNN) with theses sentences and the labels of whether offensive word is included. We use the trained filter of CNN for training new CNN given original data, resulting in the increase of the amount of training data. We get higher F1-score with the proposed method than that without pre-training in three dataset of insult from kaggle, Bullying trace, and formspring.		Suin Seo;Sung-Bea Cho	2017		10.1007/978-3-319-70096-0_55	transfer of learning;machine learning;offensive;pattern recognition;economic shortage;artificial intelligence;insult;artificial neural network;computer science;training set;convolution;sentence	NLP	-16.347295742860407	-76.58340322419744	188307
5f87b205a9e2a69012aced5d8d036312a32948a9	efficiency tools in the speeches of martin luther king, jr	complex grammatical structure;computer program;clear linkage;embedded clause;computer-aided analysis;dr. king;diverse audience;efficiency tool;efficiency function;reverend martin luther king;syntactic function	This thesis represents the results of a computer-aided analysis of aspects of speeches of the Reverend Martin Luther King, Jr. Specifically, the analysis has investigated the occurrence of indicators of the efficiency function--tools facilitating the comprehension of a discourse by a hearer or reader--in four speeches of Dr. King.Contrary to the expectations of many who anticipate complex grammatical structures in the discourse of those who are speechmakers before many and diverse audiences, this study has demonstrated that the speeches of Dr. King are replete with simple structural devices--sequential clauses as opposed to embedded clauses, sentences in which there are clear linkages between clauses, and clear linkages between sentences, to name a few.The analysis of the texts of Dr. King was accomplished in part by a computer program which used as input a surface semantic description of a sentence as a basis for predicting the syntactic function of elements of the sentence.		M. Cassandra Foster Smith	1980			syntax;natural language processing;artificial intelligence;computer science;computer program;linguistics;sentence;comprehension	EDA	-12.584339260456003	-77.89239735385854	188387
adf5051667350c2a216d782377fd6a1e7bd7be6b	verbal fluency, or how to stay on top of the wave?	verbal fluency	Speaking a language and achieving proficiency in another one is a highly complex process which requires the acquisition of various kinds of knowledge and skills, like the learning of words, rules and patterns and their connection to communicative goals (intentions), the usual starting point. To help the learner to acquire these skills we propose an enhanced, electronic version of an age old method: pattern drills (henceforth PDs). While being highly regarded in the fifties, PDs have become unpopular since then, partially because of their lack of grounding (natural context) and rigidity. Despite these shortcomings we do believe in the virtues of this approach, at least with regard to the acquisition of basic linguistic reflexes or skills (automatisms), necessary to survive in the new language. Of course, the method needs improvement, and we will show here how this can be achieved. Unlike tapes or books, computers are open media, allowing for dynamic changes, taking users’ performances and preferences into account. Building an electronic version of PDs amounts to building an open resource, accomodatable to the users’ ever changing needs.	book;computer;performance	Michael Zock;Stergos D. Afantenos	2008			cognitive psychology;developmental psychology;communication	NLP	-9.995114908610919	-76.06650512602742	188699
ff2515e5696f4fa0a6dbe86791e9141e817487f3	interval distinction on melody perception for music information retrieval	query processing;pitch hierarchy;melody comparison;music information retrieval;music perception	The problem of musical query processing can be env isioned as a substring-matching problem when the melody is repre sented as a sequence of notes associated with a set of attributes. In compa rison of two musical sequences, one of the important problems is to dete rmin the weights of each operation. This paper presents an alternate weighti n -scheme which is based on diatonic distinctions on melody perception. To achi eve this, we run a cognitive experimentation applying Probe-Tone method. The res ults showed that perceptional hierarchy of pitches changes according to the interval distinction on melody, whether it has more disjunt interval tha n conjunct intervals, vice versa. Consequently, if the new weighting-scheme cre ated in this study are used in sequenced-based melody comparison, melodies retr iev d to user would have a more credible ranking. The details of experimenta tions and the results we reach are also presented in detail.	chi;database;env;eve;factor analysis;foreach loop;information retrieval;matthews correlation coefficient;pro tools;substring;theory	Cihan Isikhan;Adil Alpkocak;Yetkin Ozer	2008		10.1007/978-3-642-02518-1_13	natural language processing;melody;speech recognition;computer science	Web+IR	-6.417447058912418	-79.83636448741642	189070
7aae5f408e83cd26fdb57897e9d4d77536c58559	category learning in the context of co-presented items	categorisation;learning;etude experimentale;concepts;supervised classification;hombre;prior knowledge;learning environment;proceso adquisicion;comparison;acquisition process;aprendizaje;multi dimensional;apprentissage;categorizacion;contexto;human;contexte;category learning;context effects;estudio experimental;context;processus acquisition;categorization;homme	A series of four studies explore how the presentation of multiple items on each trial of a categorization task affects the course of category learning. In a three-category supervised classification task involving multi-dimensionally varying artificial organism-like stimuli, learners are shown a target plus two context items on every trial, with the context items’ category membership explicitly identified. These triads vary in whether one, two, or all three categories are represented. This presentation context can support within-category comparison and/or between-category contrast. The most successful learning occurs when all categories are represented in each trial. This pattern occurs across two different underlying category structures and across variations in learners’ prior knowledge of the relationship between the target and context items. These results appear to contrast with some other recent findings and make clear the potential importance of context-based inter-item evaluation in human category learning, which has implications for psychological theory and for real-world learning environments.	artificial life;categorization;category utility;classification;concept learning;learning disorders;machine learning;numerous;supervised learning;triad acrylic resin;all categories	Janet K. Andrews;Kenneth R. Livingston;Kenneth J. Kurtz	2010	Cognitive Processing	10.1007/s10339-010-0377-5	psychology;cognitive psychology;concepts;concept learning;context effect;artificial intelligence;machine learning;pattern recognition;linguistics;categorization	ML	-7.651413514206456	-76.15314648674756	189086
9f40c84755c4d46f8d065a73c8260a0b71de9bc7	speaker-dependent variation in content selection for referring expression generation		In this paper we describe machine learning experiments that aim to characterise the content selection process for distinguishing descriptions. Our experiments are based on two large corpora of humanproduced descriptions of objects in relatively small visual scenes; the referring expressions are annotated with their semantic content. The visual context of reference is widely considered to be a primary determinant of content in referring expression generation, so we explore whether a model can be trained to predict the collection of descriptive attributes that should be used in a given situation. Our experiments demonstrate that speaker-specific preferences play a much more important role than existing approaches to referring expression generation acknowledge.	experiment;machine learning;referring expression generation;regular expression;text corpus	Jette Viethen;Robert Dale	2010			referring expression generation;artificial intelligence;expression (mathematics);computer science;pattern recognition	NLP	-12.5205129507673	-69.95051350482132	189891
19ad2bd4334e788d1e4ac51bc1a6197e9293a2f9	integration processes compared: cortical differences for consistency evaluation and passive comprehension in local and global coherence		This research studies the neural systems underlying two integration processes that take place during natural discourse comprehension: consistency evaluation and passive comprehension. Evaluation was operationalized with a consistency judgment task and passive comprehension with a passive listening task. Using fMRI, the experiment examined the integration of incoming sentences with more recent, local context and with more distal, global context in these two tasks. The stimuli were stories in which we manipulated the consistency of the endings with the local context and the relevance of the global context for the integration of the endings. A whole-brain analysis revealed several differences between the two tasks. Two networks previously associated with semantic processing and attention orienting showed more activation during the judgment than the passive listening task. A network previously associated with episodic memory retrieval and construction of mental scenes showed greater activity when global context was relevant, but only during the judgment task. This suggests that evaluation, more than passive listening, triggers the reinstantiation of global context and the construction of a rich mental model for the story. Finally, a network previously linked to fluent updating of a knowledge base showed greater activity for locally consistent endings than inconsistent ones, but only during passive listening, suggesting a mode of comprehension that relies on a local scope approach to language processing. Taken together, these results show that consistency evaluation and passive comprehension weigh differently on distal and local information and are implemented, in part, by different brain networks.	auditory perception;dna integration;knowledge base;lazy evaluation;list comprehension;local variable;memory disorders;mental model;neurobiology;occur (action);pdf/a;precipitating factors;relevance;fmri;sentence	Giovanna Egidi;Alfonso Caramazza	2016	Journal of Cognitive Neuroscience	10.1162/jocn_a_00982	psychology;cognitive psychology;communication;social psychology	NLP	-8.689805900688844	-77.39181478784754	190066
1238c66a0bf7601bcf0233a2a44a7d07b65c65c3	comprehension of chinese classifiers in preschool children		The present research aimed to investigate children’s comprehension of Chinese classifiers. Sixty-five Chinesespeaking children between the ages of 4 and 6 recruited in Taiwan participated in the experiment. The results indicate that children can make generalization based on their understanding of classifiers instead of solely relying on classifier-noun associations. The results also show that the participants performed equally on both shape-based and feature-shared classifiers, which suggests that children not only use shape salience to learn Chinese classifiers, but are also sensitive to other relations between objects classified by the same Chinese classifier. Besides, the complex patterns in the results imply that in spite of the exposure to classifiers, the semantic transparency between classifiers and objects varies considerably in both semantic types of classifier, which might be the primary reason that some classifiers are more difficult for children to acquire.	chinese room;list comprehension	Yu-Han Luo;Jon-Fan Hu	2017			cognitive psychology;psychology;comprehension	HCI	-7.085483184917888	-76.1385177185363	190551
4ddfa0b53accf20455666dcb6fc667017504cbfb	aligning implicit learning and statistical learning: two approaches, one phenomenon		"""The past 15-20 years have witnessed a particularly strong interest in our ability to rapidly extract structured information from the environment. This fundamental process of human cognition is widely believed to underpin many complex behaviors – from language development and social interaction to intuitive decision making and music cognition – so this interest spans practically all branches of cognitive science. Research on this topic can be found in two related, yet traditionally distinct research strands, namely """"implicit learning"""" (Reber, 1967) and """"statistical learning"""" (Saffran, Aslin, & Newport, 1996). Both lines of research focus on how we acquire information from complex stimulus domains and both rely heavily on the use of artificial systems (e.g., finite-state grammars, pseudoword lexicons). In typical experiments, participants are initially exposed to stimuli generated by an artificial system and then tested to determine what they have learned. Given these and other significant similarities, Perruchet and Pacton (2006) argue that these distinct lines of research actually represent two approaches to a single phenomenon, and Conway and Christiansen (2006) propose combining the two in name: """"implicit-statistical learning"""". Yet, despite frequent acknowledgements that researchers in implicit learning and statistical learning might essentially be looking at the same phenomenon, there is surprisingly little alignment between the two strands. This symposium seeks to remedy this situation by bringing together leading researchers from both areas in order to promote a shared understanding of research questions and methodologies, to discuss similarities and differences between the two approaches, and to work towards a joint research agenda. The symposium comprises four presentations, followed by a thematic discussion, which provide coverage of these phenomena in terms of development (children and adults), different language learning tasks (sublexical phonotactics, word acquisition, grammar learning), and their role in both production and comprehension, each integrating multidisciplinary perspectives. Gomez focuses on implicit-statistical learning in early development, identifying words and grammatical sequences and the memory systems that underlie this learning. Monaghan and Rebuschat measure word learning and grammar learning in adults, while varying the knowledge that participants have of the structure they are acquiring. Dell and Anderson demonstrate how their work on acquisition of phonotactic constraints is exhibited in speakers’ productions, and discuss the inter-relation in speech between implicit and statistical learning. Finally, Conway provides an overview of the two fields, and proposes a novel framework that unifies implicit learning and statistical learning."""	cognition;cognitive science;context-free grammar;conway's game of life;experiment;lexicon;machine learning;reinforcement learning	Patrick Rebuschat;Padraic Monaghan;Rebecca Gomez;Gary S. Dell;Nathaniel Anderson;Christopher Conway	2016			cognitive psychology;psychology;implicit learning;phenomenon	NLP	-10.350163283411316	-75.60164001159139	191257
66e28b48dedb39310f1c5997b989fb1dc356d737	learning modality-invariant representations for speech and images		In this paper, we explore the unsupervised learning of a semantic embedding space for co-occurring sensory inputs. Specifically, we focus on the task of learning a semantic vector space for both spoken and handwritten digits using the TIDIGITs and MNIST datasets. Current techniques encode image and audio/textual inputs directly to semantic embeddings. In contrast, our technique maps an input to the mean and log variance vectors of a diagonal Gaussian from which sample semantic embeddings are drawn. In addition to encouraging semantic similarity between co-occurring inputs, our loss function includes a regularization term borrowed from variational autoencoders (VAEs) which drives the posterior distributions over embeddings to be unit Gaussian. We can use this regularization term to filter out modality information while preserving semantic information. We speculate this technique may be more broadly applicable to other areas of cross-modality/domain information retrieval and transfer learning.	encode;image;information retrieval;loss function;mnist database;map;modality (human–computer interaction);semantic similarity;speech recognition;unsupervised learning;variational principle	Kenneth Leidal;David Harwath;James R. Glass	2017	2017 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)	10.1109/ASRU.2017.8268967	transfer of learning;machine learning;mathematics;vector space;semantic similarity;mnist database;artificial intelligence;unsupervised learning;embedding;regularization (mathematics);invariant (mathematics)	ML	-14.156459431101041	-69.7516669971856	191476
6db4edae5b6a9d8ab95eb5d1319621ff0f135b44	a progressive learning method for symbols recognition	allocation rule;user feedback;discriminant analysis;learning methods;conditional discriminant analysis;symbol recognition	This paper deals with a progressive learning method for symbols recognition which improves its own recognition rate when new symbols are recognized in graphics documents. We propose a discriminant analysis method which provides allocation rules from learning samples with known classes. However a discriminant analysis method is efficient only if learning samples and data are defined in the same conditions but it is rare in real life. In order to overcome this problem, a conditional vector is added to each observation to take into account the parasitic effects between the data and the learning samples. We propose also an adaptation to consider the user feedback.	graphics;linear discriminant analysis;real life	Sabine Barrat;Salvatore Tabbone	2007		10.1145/1244002.1244145	semi-supervised learning;speech recognition;computer science;machine learning;pattern recognition;optimal discriminant analysis;linear discriminant analysis	AI	-6.451768309344492	-70.39968006819558	191768
f7f3548124d2e4a5f44ad39631d225fe0c8b7351	space, agency and word order: evidence from greek		We examined the role of spatial representations and word order on thematic role assignment in Greek. Previous studies suggest that spatial representations influence thematic role assignment; agent is typically depicted on the left, and patient on the right. Here, we address this issue using a language with flexible word order which allows us to manipulate sentence structure (SVO–OVS) orthogonally to thematic role. Greek speakers heard SVO/OVS sentences while viewing depictions of actions involving two characters and they judged whether sentence and picture matched in meaning. The agent’s position in the picture was directly manipulated. The results support the effect of left bias on language processing. However, this bias may be better understood when its interaction with other sources of information and languagespecific constraints are taken into account. Theories of prediction may help us illuminate how spatial biases and linguistic factors interactively affect the way we process our world.	interactivity;our world;sparse voxel octree;theory	Spyridoula Cheimariou;Sonia Loui	2013			social psychology;agrammatism;word order;psychology;noun;cognitive psychology;linguistics;writing system;comprehension;population;verb;sentence	AI	-8.299412405770909	-77.48241988122554	192113
aaee29c0e903709c92257bf08844c5253584a5b9	a comparison of supervised learning classifiers for link discovery	linked data;instance matching;machine learning;benchmarks;semantic web;link discovery	The detection of links between resources is intrinsic to the vision of the Linked Data Web. Due to the mere size of current knowledge bases, this task is commonly addressed by using tools. In particular, manifold link discovery frameworks have been developed. These frameworks implement several different machine-learning approaches to discovering links. In this paper, we investigate which of the commonly used supervised machine-learning classifiers performs best on the link discovery task. To this end, we first present our evaluation pipeline. Then, we compare ten different approaches on three artificial and three real-world benchmark data sets. The classification outcomes are subsequently compared with several state-of-the-art frameworks. Our results suggest that while several algorithms perform well, multilayer perceptrons perform best on average. Moreover, logistic regression seems best suited for noisy data.	algorithm;benchmark (computing);data web;knowledge base;linked data;logistic regression;machine learning;multilayer perceptron;signal-to-noise ratio;supervised learning	Tommaso Soru;Axel-Cyrille Ngonga Ngomo	2014		10.1145/2660517.2660532	computer science;machine learning;pattern recognition;data mining	AI	-17.85179342796159	-66.40967670204653	192753
5a2a8d736942a3e5fb88547b41ae05369a3d1329	temporal characteristics of lexical error and appropriateness repairs in spontaneous dutch speech		This paper presents a phonetic analysis of lexical repairs taken from a corpus of spontaneous Dutch speech. The analysis focuses on the temporal relationship between the reparandum and repair components. Two predictors are tested, alongside several control variables: the pragmatic type of repair (error or appropriateness) and the structural type (interrupted or completed). Results suggest that pragmatic type has no consistent effect on the temporal organization of repairs, while structural type has some effect. Moreover, a significant effect is found for a measure of the relative phonological complexity of the reparandum and repair.	control variable (programming);interrupt;norm (social);spontaneous order;structural type system;text corpus	Leendert Plug;Paul Carter	2011			natural language processing;speech recognition;computer science;communication	NLP	-11.42562428940531	-80.0841028338749	192778
26c996073d845168b863d2e4f2f29d81b9273cf4	investigation of rule interestingness in medical data mining	user interface;interestingness measure;data mining	This research experimentally investigates the performance of conventional rule interestingness measures and discusses their usefulness for supporting KDD through human-system interaction in medical domain. We compared the evaluation results by a medical expert and those by selected sixteen kinds of interestingness measures for the rules discovered in a dataset on hepatitis. χ2 measure, recall, and accuracy demonstrated the highest performance, and specificity and prevalence did the lowest. The interestingness measures showed a complementary relationship for each other. These results indicated that some interestingness measures have the possibility to predict really interesting rules at a certain level and that the combinational use of interestingness measures will be useful. We then discussed how to combinationally utilize interestingness measures and proposed a post-processing user interface utilizing them, which supports KDD through human-system interaction.	data mining	Miho Ohsaki;Shinya Kitaguchi;Hideto Yokoi;Takahira Yamaguchi	2003		10.1007/11423270_10	engineering;data science;data mining;information retrieval	ML	-7.4977977554871575	-66.17849375265521	192807
234dc7984668f72ee4917755915040386be4eb1f	learning to match using local and distributed representations of text for web search	neural networks;information retrieval;document ranking	Models such as latent semantic analysis and those based on neural embeddings learn distributed representations of text, and match the query against the document in the latent semantic space. In traditional information retrieval models, on the other hand, terms have discrete or local representations, and the relevance of a document is determined by the exact matches of query terms in the body text. We hypothesize that matching with distributed representations complements matching with traditional local representations, and that a combination of the two is favourable. We propose a novel document ranking model composed of two separate deep neural networks, one that matches the query and the document using a local representation, and another that matches the query and the document using learned distributed representations. The two networks are jointly trained as part of a single neural network. We show that this combination or ‘duet’ performs significantly better than either neural network individually on a Web page ranking task, and significantly outperforms traditional baselines and other recently proposed models based on neural networks.	artificial neural network;baseline (configuration management);deep learning;information retrieval;latent semantic analysis;pagerank;ranking (information retrieval);relevance;structure of observed learning outcome;web page;web search engine	Bhaskar Mitra;Fernando Diaz;Nick Craswell	2017		10.1145/3038912.3052579	ranking;computer science;machine learning;data mining;database;world wide web;information retrieval;artificial neural network	Web+IR	-17.991420464556274	-67.08452211833423	192843
1f142dc4b5e7c860d026870c1f12cf33447254cb	active prediction of syntactic information during sentence processing		We describe an eye-tracking experiment that tested the effe ct o syntactic predictability on skipping rates during reading. We found that plural noun phrases were skipped more often than singular noun phrases, in syntactic contexts which induced a high expecta tion for a plural. We interpret this effect as evidence that the plural noun phrase has been predicted ah ea of time. The results indicate that the examination of skipping rates might be a useful tool for t he investigation of syntactic prediction effects.	experiment;eye tracking	Zeynep Ilkin;Patrick Sturt	2011	D&D		natural language processing;noun phrase;speech recognition;computer science;linguistics	NLP	-10.125679693884473	-78.34516157691732	193347
ce84ec02c0e1f1d3cf29aa880eac57eac8a19596	representation of structured events and efficient procedures for their recognition	prototype;parallel recognition;template matching;relational representation;structured event	Abstract Structured events are configurations of objects in logical, spatial, temporal or activity relations. A parameterized structural representation system for this class of events is discussed. Parameters in such representations are arbitrarily chosen symbols used to insure consistent references to the same object in diverse relations. All-or-none matching of two representations is the basis for pattern recognition. In this framework, descriptions of pattern or concept prototypes act as structural templates for stimuli. As a result, recognition can be performed in a natural and structural way and is unaffected by manipulations of irrelevant variables. Typical recognition procedures are reviewed and a variety of alternative approaches are considered in light of the potential combinatorial explosions which might arise in applications of these procedures. One alternative is proposed which can exploit both redundancy among partially matching templates and computational parallelism in exhaustive search (recognition) problems. Another possibility considered is to find special recognition procedures for particular recognition problems. For example, to accomplish word recognition in speech understanding systems, highly practical techniques exist to match many templates in parallel (simultaneously) using only simple bit string operations. In addition, both the possibility of additional heuristic approaches to general recognition procedures and the use of less general relational representations are also considered in this paper.		Frederick Hayes-Roth	1976	Pattern Recognition	10.1016/0031-3203(76)90015-7	feature;computer science;theoretical computer science;machine learning;pattern recognition;mathematics;3d single-object recognition;algorithm	Vision	-8.203675005357528	-72.6924732741128	193360
0034aa614ddd46ddc0d4a70762fedb54353d370c	toward a rich phonology	high dimensionality;real time;speaker independent;discrete system	A radically new conception of linguistic representations is proposed. The claim is that language is stored in memory in the form of large distributions of specific utterances in a rich high-dimensional space, sometimes called exemplar memory. This is the form the brain uses for understanding and creating utterances in real time. In contrast, the abstract, speaker-independent description of language (as modelled by alphabetical orthographies and by linguistic descriptions using phonemes, etc.) exhibits many structures and patterns that comprise a social institution, maintained by speakers over time, and approximating a discrete system made from components. However, these phenomena, shaped by social as well as articulatory and auditory factors, play no clear role in real-time language processing. The traditional view For about a century, linguists have trusted their intuitions that speech presents itself to our consciousness in the form of segments, that is, consonant or vowel units (Saussure, 1916; Jones, 1918, p. 1; Ladefoged, 1972; IPA, 1999) but these powerful intuitions may be partially (or wholly) a result of the lifelong literacy training to which all readers of this paragraph have been subjected. The vast majority of experimental evidence supports a very rich memory for language (resembling our detailed and contextsensitive memory for everyday events and activities, Nosofsky, 1986; Shiffrin and Steyvers, 1997), not a memory that uses abstract, speakerindependent tokens in serial order. However, the abstract, phoneme-based view has prevailed in the field despite many kinds of evidence against it.	consciousness;discrete system;jones calculus;phoneme;real-time computing;real-time transcription	Robert F. Port	2006			natural language processing;speech recognition;computer science;communication	NLP	-11.158152082353967	-78.12096974159242	193518
a1fd8740c609e848286a22661a65d9f792ab7346	translating from original to simplified sentences using moses: when does it actually work?	004 informatik	In recent years, several studies have approached the Text Simplification (TS) task as a machine translation (MT) problem. They report promising results in learning how to translate from ‘original’ to ‘simplified’ language using the standard phrasebased translation model. However, our results indicate that this approach works well only when the training dataset consists mostly of those sentence pairs in which the simplified sentence is already very similar to its original. Our findings suggest that the standard phrase-based approach might not be appropriate to learn strong simplifications which are needed for certain target populations.	experiment;hannah dee;language model;moses;population;programming paradigm;statistical machine translation;text corpus;text simplification	Sanja Stajner;Horacio Saggion	2015			epistemology;computer science;linguistics;cognitive science	NLP	-17.19323352927605	-73.17283058159589	193737
d1fde872aa0d072282e25e6bb598f8fd82b52ba5	the role of the hierarchy of activation in the process of natural language understanding		The elements of the stock of knowledge shared .by the speaker and the hearer change their salience, in the sense of being immediately accessible in the bearer's memory. The hierarchy of salience is argued to be a basic component of a mechanism serving for the identification of reference. Some of the regularities of this mechanism are discussed, the description of which is a necessary prerequisite of an automatic understanding of connected texts.	natural language understanding	Eva Hajicová;Jarka Vrbová	1982				AI	-9.018184856580206	-76.98480188350015	194248
0d58923f4f5c0104202b47e7af1fdef8cfab6632	entity matching across heterogeneous sources	heterogeneous sources;cross lingual matching;topic model	Given an entity in a source domain, finding its matched entities from another (target) domain is an important task in many applications. Traditionally, the problem was usually addressed by first extracting major keywords corresponding to the source entity and then query relevant entities from the target domain using those keywords. However, the method would inevitably fails if the two domains have less or no overlapping in the content. An extreme case is that the source domain is in English and the target domain is in Chinese.  In this paper, we formalize the problem as entity matching across heterogeneous sources and propose a probabilistic topic model to solve the problem. The model integrates the topic extraction and entity matching, two core subtasks for dealing with the problem, into a unified model. Specifically, for handling the text disjointing problem, we use a cross-sampling process in our model to extract topics with terms coming from all the sources, and leverage existing matching relations through latent topic layers instead of at text layers. Benefit from the proposed model, we can not only find the matched documents for a query entity, but also explain why these documents are related by showing the common topics they share. Our experiments in two real-world applications show that the proposed model can extensively improve the matching performance (+19.8% and +7.1% in two applications respectively) compared with several alternative methods.	algorithm;ambiguous name resolution;baseline (configuration management);entity;experiment;factor graph;ibm notes;information;sampling (signal processing);semi-supervised learning;semiconductor industry;topic model;unified model	Yang Yang;Yizhou Sun;Jie Tang;Bo Ma;Juan-Zi Li	2015		10.1145/2783258.2783353	computer science;machine learning;data mining;topic model;world wide web;information retrieval	ML	-17.727411393366328	-66.25438570800753	194530
dd216b5070a1bf97473a40c8ef4b90158d728e15	tvqa: localized, compositional video question answering		Recent years have witnessed an increasing interest in image-based question-answering (QA) tasks. However, due to data limitations, there has been much less work on video-based QA. In this paper, we present TVQA, a largescale video QA dataset based on 6 popular TV shows. TVQA consists of 152,545 QA pairs from 21,793 clips, spanning over 460 hours of video. Questions are designed to be compositional in nature, requiring systems to jointly localize relevant moments within a clip, comprehend subtitle-based dialogue, and recognize relevant visual concepts. We provide analyses of this new dataset as well as several baselines and a multi-stream end-to-end trainable neural network framework for the TVQA task. The dataset is publicly available at http://tvqa.cs.unc.edu.	artificial neural network;baseline (configuration management);benchmark (computing);end-to-end principle;experiment;file spanning;human reliability;multimodal interaction;question answering;software quality assurance;trusted timestamping	Jie Lei;Licheng Yu;Mohit Bansal;Tamara L. Berg	2018			natural language processing;clips;subtitle;artificial intelligence;artificial neural network;computer science;question answering	NLP	-14.773014963957667	-70.7460851845729	194692
cf88c64f83d559bd9db5122ca7cf640b41296e9a	longitudinal l2 development of the english article in individual learners		We investigate the accuracy development of the English article by learners of English as a second language. The study focuses on individual learners, tracking their learning trajectories through their writings in the EF-Cambridge Open Language Database (EFCAMDAT), an open access learner corpus. We draw from 17,859 writings by 1,280 learners and ask whether article accuracy in individual learners fluctuates randomly or whether learners can be clustered according to their developmental trajectories. In particular, we apply kmeans clustering to automatically cluster in a bottom up fashion learners with similar learning curves. We follow learners for a period covering one CEFR level. Given the relatively short learning window, the majority of learners follow a horizontal line. Nevertheless, we also identify groups of learners showing a power-function and U-shaped curve. Crucially, these groups are ‘hidden’ when the aggregate of learners is considered, a finding highlighting the importance of individual level analysis.	aggregate data;cluster analysis;entity framework;k-means clustering;randomness;top-down and bottom-up design	Akira Murakami;Theodora Alexopoulou	2016			psychology;natural language processing;speech recognition;linguistics	ML	-14.274736873953145	-78.44789900388453	194993
9303913740e0800ca9551bb64c4c69a6a5cb030c	towards machine translation in semantic vector space	recursive neural network;statistical machine translation;max margin training;vector embedding space;semantic meaning distance	Measuring the quality of the translation rules and their composition is an essential issue in the conventional statistical machine translation (SMT) framework. To express the translation quality, the previous lexical and phrasal probabilities are calculated only according to the co-occurrence statistics in the bilingual corpus and may be not reliable due to the data sparseness problem. To address this issue, we propose measuring the quality of the translation rules and their composition in the semantic vector embedding space (VES). We present a recursive neural network (RNN)-based translation framework, which includes two submodels. One is the bilingually-constrained recursive auto-encoder, which is proposed to convert the lexical translation rules into compact real-valued vectors in the semantic VES. The other is a type-dependent recursive neural network, which is proposed to perform the decoding process by minimizing the semantic gap (meaning distance) between the source language string and its translation candidates at each state in a bottom-up structure. The RNN-based translation model is trained using a max-margin objective function that maximizes the margin between the reference translation and the n-best translations in forced decoding. In the experiments, we first show that the proposed vector representations for the translation rules are very reliable for application in translation modeling. We further show that the proposed type-dependent, RNN-based model can significantly improve the translation quality in the large-scale, end-to-end Chinese-to-English translation evaluation.	artificial neural network;autoencoder;bottom-up parsing;encoder;end-to-end principle;experiment;loss function;neural coding;optimization problem;random neural network;recursion;recursive neural network;statistical machine translation;virtual execution system	Jiajun Zhang;Shujie Liu;Mu Li;Ming Zhou;Chengqing Zong	2015	ACM Trans. Asian & Low-Resource Lang. Inf. Process.	10.1145/2699927	natural language processing;synchronous context-free grammar;speech recognition;transfer-based machine translation;example-based machine translation;computer science;machine learning;rule-based machine translation	NLP	-18.169589159593055	-74.70159883422163	195158
6ebf0f125fca67d08379672e0806e75e5a362474	aspect-based sentiment analysis using a two-step neural network architecture		The World Wide Web holds a wealth of information in the form of unstructured texts such as customer reviews for products, events and more. By extracting and analyzing the expressed opinions in customer reviews in a fine-grained way, valuable opportunities and insights for customers and businesses can be gained. We propose a neural network based system to address the task of AspectBased Sentiment Analysis to compete in Task 2 of the ESWC-2016 Challenge on Semantic Sentiment Analysis. Our proposed architecture divides the task in two subtasks: aspect term extraction and aspect-specific sentiment extraction. This approach is flexible in that it allows to address each subtask independently. As a first step, a recurrent neural network is used to extract aspects from a text by framing the problem as a sequence labeling task. In a second step, a recurrent network processes each extracted aspect with respect to its context and predicts a sentiment label. The system uses pretrained semantic word embedding features which we experimentally enhance with semantic knowledge extracted from WordNet. Further features extracted from SenticNet prove to be beneficial for the extraction of sentiment labels. As the best performing system in its category, our proposed system proves to be an effective approach for the Aspect-Based Sentiment Analysis.	artificial neural network;cognitive science;customer relationship management;experiment;framing (world wide web);information extraction;lexicon;network architecture;recurrent neural network;sentiment analysis;sequence labeling;terminology extraction;word embedding;wordnet;world wide web	Soufian Jebbara;Philipp Cimiano	2016		10.1007/978-3-319-46565-4_12	time delay neural network	NLP	-18.457462494658476	-70.76835943904362	195209
0c97113fb4e84710e357cd621cd3c5d438891d21	using sentence type information for syntactic category acquisition	standard bhmm;sentence type information;bayesian hidden markov model;syntactic category acquisition;new model;intonation pattern;sentence type;new source;syntactic acquisition cross-linguistically;different syntactic pattern	In this paper we investigate a new source of information for syntactic category acquisition: sentence type (question, declarative, imperative). Sentence type correlates strongly with intonation patterns in most languages; we hypothesize that these intonation patterns are a valuable signal to a language learner, indicating different syntactic patterns. To test this hypothesis, we train a Bayesian Hidden Markov Model (and variants) on child-directed speech. We first show that simply training a separate model for each sentence type decreases performance due to sparse data. As an alternative, we propose two new models based on the BHMM in which sentence type is an observed variable which influences either emission or transition probabilities. Both models outperform a standard BHMM on data from English, Cantonese, and Dutch. This suggests that sentence type information available from intonational cues may be helpful for syntactic acquisition crosslinguistically.	concept learning;experiment;hidden markov model;imperative programming;information source;markov chain;sparse matrix	Stella Frank;Sharon Goldwater;Frank Keller	2010			natural language processing;speech recognition;inverted sentence;computer science;linguistics	NLP	-11.411562289047275	-77.60255152254423	195340
36a14a3d4657b16bc0bd1f1dbadf451aa2ee12d3	learning semantic representation with neural networks for community question answering retrieval	text mining;question retrieval;期刊论文;community question answering;yahoo answers	"""Learning the semantic representation using neural network architecture.The neural network is trained via pre-training and fine-tuning phase.The learned semantic level feature is incorporated into a LTR framework. In community question answering (cQA), users pose queries (or questions) on portals like Yahoo! Answers which can then be answered by other users who are often knowledgeable on the subject. cQA is increasingly popular on the Web, due to its convenience and effectiveness in connecting users with queries and those with answers. In this article, we study the problem of finding previous queries (e.g., posed by other users) which may be similar to new queries, and adapting their answers as the answers to the new queries. A key challenge here is to the bridge the lexical gap between new queries and old answers. For example, """"company"""" in the queries may correspond to """"firm"""" in the answers. To address this challenge, past research has proposed techniques similar to machine translation that """"translate"""" old answers to ones using the words in the new queries. However, a key limitation of these works is that they assume queries and answers are parallel texts, which is hardly true in reality. As a result, the translated or rephrased answers may not look intuitive.In this article, we propose a novel approach to learn the semantic representation of queries and answers by using a neural network architecture. The learned semantic level features are finally incorporated into a learning to rank framework. We have evaluated our approach using a large-scale data set. Results show that the approach can significantly outperform existing approaches."""	artificial neural network;question answering	Guangyou Zhou;Yin Zhou;Tingting He;Wensheng Wu	2016	Knowl.-Based Syst.	10.1016/j.knosys.2015.11.002	text mining;computer science;data mining;world wide web;information retrieval	NLP	-18.15946989644524	-66.92174108718737	195451
8324818aabdc25d98f4f9945dbf35446e970d85c	the german vorfeld and local coherence	vorfeld;natural language generation;constituent order;german;local coherence	We present a method for improving local coherence in German with a positive effect on automatically as well as human-generated texts. We demonstrate that local coherence crucially depends on which constituent occupies the initial position in a sentence. To support our hypothesis, we provide statistical evidence based on a corpus investigation and on results of an experiment with human judges. Additionally, we implement our findings in a generation module for determining the Vorfeld constituent automatically.		Katja Filippova;Michael Strube	2007	Journal of Logic, Language and Information	10.1007/s10849-007-9044-3	natural language processing;philosophy;german;mathematics;linguistics	Logic	-12.46303105599204	-79.78983890847056	195566
9da40f8b672a74ee64cf2cef9f3e2804fe810eb4	an automatically compilable recognition network for structured patterns	bottom up;pattern matching;speech understanding;parallel processing	A new method for efficient recognition of general relational structures is described and compared with existing methods. Patterns to be recognized are defined by templates consisting of a set of predicate calculus relations. Productions are representable by associating actions with templates. A network for recognizing occurrences of any of the template patterns in data may be automatically compiled. The compiled network is economical in the sense that conjunctive products (subsets) of relations common to several templates are represented in and computed by the network only once. The recognition network operates in a bottom-up fashion, in which all possibilities for pattern matches are evaluated simultaneously. The distribution of the recognition process throughout the network means that it can readily be decomposed into parallel processes for use on a multiprocessor machine. The method is expected to be especially useful in errorful domains (e.g., vision, speech) where parallel treatment of alternative hypotheses is desired. The network is illustrated with an example from the current syntax and semantics module in the Hearsay II speech understanding system.	bottom-up parsing;compiler;first-order logic;general frame;multiprocessing;pattern matching;top-down and bottom-up design	Frederick Hayes-Roth;D. Moslow	1975			natural language processing;parallel processing;computer science;artificial intelligence;machine learning;pattern matching;top-down and bottom-up design;programming language;algorithm	AI	-8.248830023789665	-72.67278541055413	195630
a663b175e09664435bae3c88a4dbf1ea50fa521c	assessing the time course of the influence of featural, distributional and spatial representations during reading	social and behavioral sciences	What does semantic similarity between two concepts mean? How could we measure it? The way in which semantic similarity is calculated might differ depending on the theoretical notion of semantic representation. In an eyetracking reading experiment, we investigated whether two widely used semantic similarity measures (based on featural or distributional representations) have distinctive effects on sentence reading times. In other words, we explored whether these measures of semantic similarity differ qualitatively. In addition, we examined whether visually perceived spatial distance interacts with either or both of these measures. Our results showed that the effect of featural and distributional representations on reading times can differ both in direction and in its time course. Moreover, both featural and distributional information interacted with spatial distance, yet in different sentence regions and reading measures. We conclude that featural and distributional representations are distinct components of semantic representation.	eye tracking;interaction;semantic interpretation;semantic similarity	Ernesto Guerra;Falk Huettig;Pia Knoeferle	2014			psychology;developmental psychology;communication;social psychology	NLP	-8.280939094396851	-76.96733637392146	195797
4e8e560328f8d7358535913d56b35f0ac89606be	attentive pooling networks		In this work, we propose Attentive Pooling (AP), a two-way attention mechanism for discriminative model training. In the context of pair-wise ranking or classification with neural networks, AP enables the pooling layer to be aware of the current input pair, in a way that information from the two input items can directly influence the computation of each other’s representations. Along with such representations of the paired inputs, AP jointly learns a similarity measure over projected segments (e.g. trigrams) of the pair, and subsequently, derives the corresponding attention vector for each input to guide the pooling. Our two-way attention mechanism is a general framework independent of the underlying representation learning, and it has been applied to both convolutional neural networks (CNNs) and recurrent neural networks (RNNs) in our studies. The empirical results, from three very different benchmark tasks of question answering/answer selection, demonstrate that our proposed models outperform a variety of strong baselines and achieve state-of-the-art performance in all the benchmarks.	artificial neural network;attentive user interface;benchmark (computing);computation;convolutional neural network;discriminative model;emoticon;feature engineering;feature learning;heat map;interaction;question answering;recurrent neural network;similarity measure;trigram;word embedding	Cícero Nogueira dos Santos;Ming Tan;Bing Xiang;Bowen Zhou	2016	CoRR		computer science;artificial intelligence;machine learning;data mining	ML	-17.007362197461564	-70.94159792579691	195926
b457b113ce2e2cc1cf74cb6785e80b46cd20c7e1	modeling hidden dynamics of multimodal cues for spontaneous agreement and disagreement recognition	eyebrows;analytical models;hidden dynamics modeling;hidden conditional random field;facial expressions;support vector machines;hidden markov model;head gestures;training;hcrf model;speech;spontaneous agreement recognition;psychology;nonverbal multimodal cues;visualization;auditory cues;hidden markov models analytical models psychology visualization training eyebrows speech;face recognition;hidden markov models;random processes;conditional random field;spontaneous disagreement recognition;concept learning;auditory cues hidden dynamics modeling nonverbal multimodal cues spontaneous agreement recognition spontaneous disagreement recognition sequential discriminative model hidden conditional random field social attitudes hcrf model social psychology hidden markov models support vector machines head gestures hand gestures facial expressions;social psychology;support vector machines face recognition gesture recognition hidden markov models psychology random processes;support vector machine;hand gestures;social attitudes;gesture recognition;sequential discriminative model;discriminative model;analytical model	This paper attempts to recognize spontaneous agreement and disagreement based only on nonverbal multi-modal cues. Related work has mainly used verbal and prosodic cues. We demonstrate that it is possible to correctly recognize agreement and disagreement without the use of verbal context (i.e. words, syntax). We propose to explicitly model the complex hidden dynamics of the multimodal cues using a sequential discriminative model, the Hidden Conditional Random Field (HCRF). In this paper, we show that the HCRF model is able to capture what makes each of these social attitudes unique. We present an efficient technique to analyze the concepts learned by the HCRF model and show that these coincide with the findings from social psychology regarding which cues are most prevalent in agreement and disagreement. Our experiments are performed on a spontaneous dataset of real televised debates. The HCRF model outperforms conventional approaches such as Hidden Markov Models and Support Vector Machines.	algorithm;conditional random field;discriminative model;experiment;hidden markov model;markov chain;modal logic;multimodal interaction;spontaneous order;support vector machine;television	Konstantinos Bousmalis;Louis-Philippe Morency;Maja Pantic	2011	Face and Gesture 2011	10.1109/FG.2011.5771341	psychology;speech recognition;pattern recognition;communication	NLP	-11.202830316074593	-70.92287532253955	195998
306995307e51d59cb3f9a103188437f6a0562155	a neural-linguistic approach for the recognition of a wide arabic word lexicon	vocabulaire;networks;neural networks;learning;nerve;0705m;0130c;lexicon;vocabulary;4230s;consonants;accuracy;apprentissage;recherche documentaire;precision;arabic;busqueda documental;pattern recognition;knowledge integration;arabe;document retrieval;reconnaissance forme;lexico;reseau neuronal;consonne;neural network;lexique	Recently, we have investigated the use of Arabic linguistic knowledge to improve the recognition of wide Arabic word lexicon. A neural-linguistic approach was proposed to mainly deal with canonical vocabulary of decomposable words derived from tri-consonant healthy roots. The basic idea is to factorize words by their roots and schemes. In this direction, we conceived two neural networks TNN_R and TNN_S to respectively recognize roots and schemes from structural primitives of words. The proposal approach achieved promising results. In this paper, we will focus on how to reach better results in terms of accuracy and recognition rate. Current improvements concern especially the training stage. It is about 1) to benefit from word letters order 2) to consider “sisters letters” (having same features), 3) to supervise networks behaviours, 4) to split up neurons to save letter occurrences and 5) to solve observed ambiguities. Considering theses improvements, experiments carried on 1500 sized vocabulary show a significant enhancement: TNN_R (resp. TNN_S) top4 has gone up from 77% to 85.8% (resp. from 65% to 97.9%). Enlarging the vocabulary from 1000 to 1700 by 100 words, again confirmed the results without altering the networks stability.	artificial neural network;experiment;lexicon;rsa problem;semantic network;triangular function;vocabulary	Imen Ben Cheikh;Afef Kacem;Abdel Belaïd	2010		10.1117/12.839975	natural language processing;speech recognition;computer science;machine learning;accuracy and precision;artificial neural network;statistics	NLP	-19.05436845021648	-73.16909723369112	196019
e7e6d20b30ab04b679ba47a4bf9701f4aa5ff421	an adversarial joint learning model for low-resource language semantic textual similarity		Semantic Textual Similarity (STS) of low-resource language is a challenging research problem with practical applications. Traditional solutions employ machine translation techniques to translate the low-resource languages to some resource-rich languages such as English. Hence, the final performance is highly dependent on the quality of machine translation. To decouple the machine translation dependency while still take advantage of the data in resource-rich languages, this work proposes to jointly learn the low-resource language STS task and that of a resource-rich one, which only relies on multilingual word embeddings. In particular, we project the low-resource language word embeddings into the semantic space of the resource-rich language via a translation matrix. To make the projected word embeddings resemble that of the resource-rich language, a language discriminator is introduced as an adversarial teacher. Thus the parameters of sentence similarity neural networks of two tasks can be effectively shared. The plausibility of our model is demonstrated by extensive experimental results.		Junfeng Tian;Man Lan;Yuanbin Wu;Jingang Wang;Long Xin Qiu;Sheng Li;Jun Lang;Luo Si	2018		10.1007/978-3-319-76941-7_7	natural language processing;data mining;adversarial system;machine translation;discriminator;artificial neural network;computer science;sentence;artificial intelligence	NLP	-18.811828889413956	-73.70593422338641	196039
d56c87bb26fc76a47397cb6777ef84147281999e	a method for analyzing spatial relationships between words in sign language recognition	sign language recognition;sign language;spatial relationships	There are expressions using spatial relationships in sign language that are called directional verbs. To understand a sign-language sentence that includes a directional verb, it is necessary to analyze the spatial relationship between the recognized sign-language words and to find the proper combination of a directional verb and the sign-language words related to it. In this paper, we propose an analysis method for evaluatingthe spatial relationship between a directional verb and other sign-language words according to the distribution of the parameters representing the spatial relationship.	language identification	Hirohiko Sagawa;Masaru Takeuchi	1999		10.1007/3-540-46616-9_18	natural language processing;computer science;linguistics;communication	Vision	-14.965161191944265	-79.02484122924702	196406
8a82d7a8a397646a4074834331ac80378c8154ad	binary paragraph vectors		Recently Le & Mikolov described two log-linear models, called Paragraph Vector, that can be used to learn state-ofthe-art distributed representations of documents. Inspired by this work, we present Binary Paragraph Vector models: simple neural networks that learn short binary codes for fast information retrieval. We show that binary paragraph vectors outperform autoencoder-based binary codes, despite using fewer bits. We also evaluate their precision in transfer learning settings, where binary codes are inferred for documents unrelated to the training corpus. Results from these experiments indicate that binary paragraph vectors can capture semantics relevant for various domainspecific documents. Finally, we present a model that simultaneously learns short binary codes and longer, real-valued representations. This model can be used to rapidly retrieve a short list of highly relevant documents from a large document collection.	algorithm;archive;artificial neural network;autoencoder;benchmark (computing);binary code;distributed memory;experiment;information retrieval;linear model;log-linear model;nonlinear system;sigmoid function;softmax function;text corpus	Karol Grzegorczyk;Marcin Kurdziel	2017			binary independence model;computer science;theoretical computer science;data mining;information retrieval	ML	-17.61772579357554	-74.28995040451495	196772
45cccc9a1a9dd03330626190f27edf5ab6be96a7	how to robustly combine judgements from crowd assessors with aware		We propose the Assessor-driven Weighted Averages for Retrieval Evaluation (AWARE) probabilistic framework, a novel methodology for dealing with multiple crowd assessors, who may be contradictory and/or noisy. By modeling relevance judgements and crowd assessors as sources of uncertainty, AWARE directly combines the performance measures computed on the ground-truth generated by the crowd assessors instead of adopting some classification technique to merge the labels produced by them. We propose several unsupervised estimators that instantiate the AWARE framework and we compare them with Majority Vote (MV) and Expectation Maximization (EM) showing that AWARE approaches improve both in correctly ranking systems and predicting their actual performance scores.	crowdsourcing;expectation–maximization algorithm;experiment;relevance	Marco Ferrante;Nicola Ferro;Maria Maistro	2018				AI	-12.352598953678514	-66.82820717991004	196807
f4136bd7f3948be30c4c11876a1bf933e3cc8549	zara the supergirl: an empathetic personality recognition system		Zara the Supergirl is an interactive system that, while having a conversation with a user, uses its built in sentiment analysis, emotion recognition, facial and speech recognition modules, to exhibit the human-like response of sharing emotions. In addition, at the end of a 5-10 minute conversation with the user, it can give a comprehensive personality analysis based on the user’s interaction with Zara. This is a first prototype that has incorporated a full empathy module, the recognition and response of human emotions, into a spoken language interactive system that enhances human-robot understanding. Zara was shown at the World Economic Forum in Dalian in September 2015.	emotion recognition;interaction;interactivity;prototype;robot;sentiment analysis;speech recognition	Pascale Fung;Anik Dey;Farhad Bin Siddique;Ruixi Lin;Yang Yang;Yan Wan;Ricky Ho Yin Chan	2016			natural language processing;artificial intelligence;computer science;personality	AI	-12.28779896157386	-71.57678816315384	196953
d4873898d230609ad83298e22deabf0f202c1005	empty category detection with joint context-label embeddings		This paper presents a novel technique for empty category (EC) detection using distributed word representations. A joint model is learned from the labeled data to map both the distributed representations of the contexts of ECs and EC types to a low dimensional space. In the testing phase, the context of possible EC positions will be projected into the same space for empty category detection. Experiments on Chinese Treebank prove the effectiveness of the proposed method. We improve the precision by about 6 points on a subset of Chinese Treebank, which is a new state-ofthe-art performance on CTB.	amiga enhanced chip set;artificial neural network;coding tree unit;feature engineering;treebank;word embedding	Xun Wang;Katsuhito Sudoh;Masaaki Nagata	2015			speech recognition;algorithm	NLP	-19.038283391963486	-72.38222774144226	197250
44323d625b6c53f04e2f4e8326d6e071116d0939	grounding semantics in olfactory perception		Multi-modal semantics has relied on feature norms or raw image data for perceptual input. In this paper we examine grounding semantic representations in olfactory (smell) data, through the construction of a novel bag of chemical compounds model. We use standard evaluations for multi-modal semantics, including measuring conceptual similarity and cross-modal zero-shot learning. To our knowledge, this is the first work to evaluate semantic similarity on representations grounded in olfactory data.	cheminformatics;cognitive model;expectation propagation;information retrieval;lattice boltzmann methods;modal logic;modality (human–computer interaction);natural language generation;raw image format;semantic similarity;speculative execution	Douwe Kiela;Luana Bulat;Stephen Clark	2015			natural language processing	NLP	-14.26966337230588	-68.47278196728888	197498
b7a0da59f4177ef866958694595dee2739b8bd00	learning to extract action descriptions from narrative text	intelligent narrative;qa76 76 e95 expert systems intelligent knowledge based systems;constrained learning;constrained learning intelligent narrative natural language processing structured prediction;structured prediction;semantics knowledge representation context games bayes methods cognition data models;natural language processing	This paper focuses on the mapping of natural language sentences in written stories to a structured knowledge representation. This process yields an exponential explosion of instance combinations since each sentence may contain a set of ambiguous terms, each one giving place to a set of instance candidates. The selection of the best combination of instances is a structured classification problem that yields a high-demanding combinatorial optimization problem which, in this paper, is approached by a novel and efficient formulation of a genetic algorithm, which is able to exploit the conditional independence among variables, while improving the parallel scalability. The automatic rating of the resulting set of instance combinations, i.e., possible text interpretations, demands an exhaustive exploitation of the state-of-the-art resources in natural language processing to feed the system with pieces of evidence to be fused by the proposed framework. In this sense, a mapping framework able to reason with uncertainty, to integrate supervision and evidence from external sources, was adopted. To improve the generalization capacity while learning from a limited amount of annotated data, a new constrained learning algorithm for Bayesian networks is introduced. This algorithm bounds the search space through a set of constraints which encode information on mutually exclusive values. The mapping of natural language utterances to a structured knowledge representation is important in the context of game construction, e.g., in an RPG setting, as it alleviates the manual knowledge acquisition bottleneck. The effectiveness of the proposed algorithm is evaluated on a set of three stories, yielding nine experiments. Our mapping framework yields performance gains in predicting the most likely structured representations of sentences when compared with a baseline algorithm.	baseline (configuration management);bayesian network;combinatorial optimization;description;encode (action);entity name part qualifier - adopted;experiment;generalization (psychology);genetic algorithm;interpretation process;knowledge acquisition;knowledge representation and reasoning;mathematical optimization;natural language processing;optimization problem;rpg;scalability;statistical classification;exponential;sentence	Oswaldo Ludwig;Quynh Ngoc Thi Do;Cameron G. Smith;Marc Cavazza;Marie-Francine Moens	2017	IEEE Transactions on Games	10.1109/TCIAIG.2017.2657690	genetic algorithm;knowledge representation and reasoning;knowledge acquisition;natural language;combinatorial optimization;natural language processing;scalability;bayesian network;sentence;artificial intelligence;computer science	NLP	-15.869304024023242	-71.47891608667845	197769
d6b8821d0b844073f4c715a121587f639a0b689a	feature induction of linear-chain conditional random fields - a study based on a simulation		Conditional Random Fields (CRFs) is a probabilistic framework for labeling sequential data. Several approaches were developed to automatically induce features for CRFs. They have been successfully applied in real-world applications, e.g. in natural language processing. The work described in this paper was originally motivated by processing the sequence data of table soccer games. As labeling such data is very time consuming, we developed a sequence generator (simulation), which creates an extra phase to explore several basic issues of the feature induction of linear-chain CRFs. First, we generated data sets with different configurations of overlapped and conjunct atomic features, and discussed how these factors affect the induction. Then, a reduction step was integrated into the induction which maintained the prediction accuracy and saved the computational power. Finally, we developed an approach which consists of a queue of CRFs. The experiments show that the CRF queue achieves better results on the data sets in all the configurations.	benchmark (computing);booting;bootstrapping (statistics);computation;conditional random field;decision tree;experiment;mathematical induction;natural language processing;open-source software;simulation;test set	Dapeng Zhang;Bernhard Nebel	2011			machine learning;computer science;artificial intelligence;conditional random field;pattern recognition	AI	-16.63980920173069	-72.36993933044671	197876
ac564fb7e53cc3627743c2178e59d6cbd05b28e9	representing spatial structure through maps and language: lord of the rings encodes the spatial structure of middle earth	maps;english literature;spatial cognition;embodied cognition;geographic location;municipalities;cognitive maps;mental representations;language processing;spatial ability;cognitive mapping;twentieth century literature;computational linguistics;fiction;latent semantic analysis;geographical structures;symbol interdependency;mathematical linguistics	Spatial mental representations can be derived from linguistic and non-linguistic sources of information. This study tested whether these representations could be formed from statistical linguistic frequencies of city names, and to what extent participants differed in their performance when they estimated spatial locations from language or maps. In a computational linguistic study, we demonstrated that co-occurrences of cities in Tolkien's Lord of the Rings trilogy and The Hobbit predicted the authentic longitude and latitude of those cities in Middle Earth. In a human study, we showed that human spatial estimates of the location of cities were very similar regardless of whether participants read Tolkien's texts or memorized a map of Middle Earth. However, text-based location estimates obtained from statistical linguistic frequencies better predicted the human text-based estimates than the human map-based estimates. These findings suggest that language encodes spatial structure of cities, and that human cognitive map representations can come from implicit statistical linguistic patterns, from explicit non-linguistic perceptual information, or from both.	cognitive map;estimated;geographic coordinate system;linguistics;name;text-based (computing)	Max M. Louwerse;Nick Benesh	2012	Cognitive science	10.1111/cogs.12000	psychology;cognitive map;computer science;artificial intelligence;computational linguistics;mathematics;linguistics;communication;cognitive science	NLP	-8.079783959526068	-77.22108639408496	198105
115c896f53bde675fbd8e43b79a1960f52d5e881	an information-theory-based feature type analysis for the modeling of statistical parsing		The paper proposes an information-theorybased method for feature types analysis in probabilistic evaluation modelling for statistical parsing. The basic idea is that we use entropy and conditional entropy to measure whether a feature type grasps some of the information for syntactic structure prediction. Our experiment quantitatively analyzes several feature types’ power for syntactic structure prediction and draws a series of interesting conclusions.	conditional entropy;dual total correlation;entropy (information theory);heuristic;information theory;language model;neural coding;prefetch input queue;statistical model;statistical parsing;stochastic context-free grammar;windows update	Zhifang Sui;Jian Zhao;Dekai Wu	2000				NLP	-12.675595439175174	-74.83178098612196	198245
8dca55b4c74ac6b085b49962d7b63aca707f4c48	transition-based deep input linearization		Traditional methods for deep NLG adopt pipeline approaches comprising stages such as constructing syntactic input, predicting function words, linearizing the syntactic input and generating the surface forms. Though easier to visualize, pipeline approaches suffer from error propagation. In addition, information available across modules cannot be leveraged by all modules. We construct a transition-based model to jointly perform linearization, function word prediction and morphological generation, which considerably improves upon the accuracy compared to a pipelined baseline system. On a standard deep input linearization shared task, our system achieves the best results reported so far.	baseline (configuration management);natural language generation;pipeline (computing);propagation of uncertainty;software propagation	Yue Zhang;Manish Shrivastava;Ratish Puduppully	2017			computer science;artificial intelligence;machine learning;feedback linearization;control theory;linearization	NLP	-17.9523375045822	-74.45657509194689	198403
0c825bec9b72b728a7b5cdbed306bfbf6384d0e5	verb argument structure alternations in word and sentence embeddings		Verbs occur in different syntactic environments, or frames. We investigate whether artificial neural networks encode grammatical distinctions necessary for inferring the idiosyncratic frame-selectional properties of verbs. We introduce five datasets, collectively called FAVA, containing in aggregate nearly 10k sentences labeled for grammatical acceptability, illustrating different verbal argument structure alternations. We then test whether models can distinguish acceptable English verb–frame combinations from unacceptable ones using a sentence embedding alone. For converging evidence, we further construct LaVA, a corresponding word-level dataset, and investigate whether the same syntactic features can be extracted from word embeddings. Our models perform reliable classifications for some verbal alternations but not others, suggesting that while these representations do encode finegrained lexical information, it is incomplete or can be hard to extract. Further, differences between the wordand sentence-level models show that some information present in word embeddings is not passed on to the downstream sentence embeddings.	aggregate data;artificial neural network;downstream (software development);encode;encoder;experiment;grammar induction;linear classifier;sentence boundary disambiguation;word embedding	Katharina Kann;Alex Warstadt;Adina Williams;Samuel R. Bowman	2018	CoRR		artificial intelligence;natural language processing;artificial neural network;syntax;embedding;computer science;verb;sentence	NLP	-18.394393717051244	-73.53314779292849	198628
b5cbd030929bf9e910465704f851642b0826bff1	on-line processing of pop-out words in spoken french dialogues	potentiel evoque cognitif;information structure;procesamiento informacion;event evoked potential;discurso;habla;time course;french;lenguaje;conversacion;hombre;speech;langage;electrophysiology;frances;francais;discours;cognition;information processing;human;palabra;potencial evocado cognitivo;conversation;cognicion;word;electrofisiologia;parole;language;event related potential erp;traitement information;discourse;electrophysiologie;mot;homme	Highlighting relevant information in a discourse context is a major aim of spoken language communication. Prosodic cues such as focal prominences are used to fulfill this aim through the pragmatic function of prosody. To determine whether listeners make on-line use of focal prominences to build coherent representations of the informational structure of the utterances, we used the brain event-related potential (ERP) method. Short dialogues composed of a question and an answer were presented auditorily. The design of the experiment allowed us to examine precisely the time course of the processing of prosodic patterns of sentence-medial or -final words in the answer. These patterns were either congruous or incongruous with regard to the pragmatic context introduced by the question. Furthermore, the ERP effects were compared for words with or without focal prominences. Results showed that pragmatically congruous and incongruous prosodic patterns elicit clear differences in the ERPs, which were largely modulated in latency and polarity by their position within the answer. By showing that prosodic patterns are processed on-line by listeners in order to understand the informational structure of the message, the present results demonstrate the psychobiological validity of the pragmatic concept of focus, expressed via prosodic cues. Moreover, the functional significance of the positive-going effects found sentence medially and negative-going effects found sentence finally is discussed. Whereas the former may reflect the processing of surprising and task-relevant prosodic patterns, the latter may reflect the integration problems encountered in extracting the overall informational structure of the sentence.	coherence (physics);erp;focal (programming language);medial graph;mental event;modulation;online and offline;semantic prosody;informational;polarity	Cyrille Magne;Corine Astésano;Anne Lacheret;Michel Morel;Kai Alter;Mireille Besson	2005	Journal of Cognitive Neuroscience	10.1162/0898929053747667	psychology;french;information processing;linguistics;communication	NLP	-9.540447688610863	-79.46352286950852	198655
fac5f0492b92b0072fe88c976c4315e820773192	refinement of a q-matrix with an ensemble technique based on multi-label classification algorithms		There are numerous algorithms and tools to help an expert map exercises and tasks to underlying skills. The last decade has witnessed a wealth of data driven approaches aiming to refine expert-defined mappings of tasks to skill. This refinement can be seen as a classification problem: for each possible mapping of task to skill, the classifier has to decide whether the expert’s advice is correct, or incorrect. Whereas most algorithms are working at the level of individual mappings, we introduce an approach based on a multi-label classification algorithm that is trained on the mapping of a task to all skills simultaneously. The approach is shown to outperform the existing task to skill mapping refinement techniques.		Sein Minn;Michel C. Desmarais;Shunkai Fu	2016		10.1007/978-3-319-45153-4_13	ensemble learning	EDA	-9.101961538404646	-66.39689303514838	198801
470a9b2c6fc42f9ccd13bc6fa38316f1f2ca6980	neural network models for the study of post-tonal music	learning algorithm;sensorial perception;pitch acoustics;acoustique musicale;intelligence artificielle;tonie;algorithme apprentissage;musical acoustics;acustica musical;altura sonida;backpropagation algorithm;algorithme retropropagation;artificial intelligence;musicologie;inteligencia artificial;reseau neuronal;percepcion sensorial;algoritmo aprendizaje;red neuronal;perception sensorielle;neural network;algoritmo retropropagacion	Neural networks are used to study two issues pertaining to atonal music. In the first part of the paper, feed-forward neural networks, using a variant of the backpropagation learning algorithm, try to learn a variety of abstract theoretical constructs from pitch-class set theory. First, learning the properties of individual sets is studied. Then a network's ability to learn various relationships between sets is examined. Based on the behavior of the network during learning, conclusions are drawn with regard to perceptual issues relating to pcset theory. In the second part of the paper, an interactive activation and competition (IAC) network is used to parse a musical passage into analytical objects. The paper concludes with suggestions for further research. 1 I n t r o d u c t i o n The atonal music of the Second Viennese School continues to challenge both listeners and scholars. While this can be attributed to a number of factors, the principal reason is that, without the hierarchy inherent in the diatonic scales and the major /minor tonal system, relations between pitches in Schoenberg's post-tonal music are not defined systemically. In the scholarly community there has been considerable theoretical work on the organization of this music, particularly regarding pitch structure. Beginning with Babbitt 's studies in the 1950s (which actually concerned the properties of hexachords in twelve-tone music), music theorists developed an ambitious appropriation and adaptation of mathematical set theory to study relations among unordered collections of pitch-classes (or pcsets) in the music. Although a number of theorists have contributed to this development, the formalizations of Forte are most widely discussed (Forte, 1973). Forte's catalog of pitch-class set classes and related theoretical apparatus have been used extensively in the more than 30 years since they were first introduced. Forte's proposals have been hotly debated (Forte, 1985; Haimo, 1996; Perle, 1990; Taruskin, 1979). A consistent criticism of pcset theory is that its constructions lack perceptual validity. Unfortunately, there has been relatively little experimental research which tests predictions inferred from pitchclass set theory (Bruner, 1984; Gibson, 1986; Krumhansl, Sandell, & Sargeant, 1987; Stammers, 1994; Imberty, 1993). The conclusions that can be drawn from these studies which have been done are limited, however. Claims about the perceptual relevance of pcset theory are hard to verify experimentally	algorithm;backpropagation;experiment;feedforward neural network;forte 4gl;interactive activation and competition networks;neural networks;parsing;pitch (music);relevance;set theory	Eric J. Isaacson	1996		10.1007/BFb0034118	speech recognition;computer science;artificial intelligence;backpropagation;machine learning;musical acoustics;artificial neural network	ML	-11.892336651895514	-75.12889910203286	198975
16e0fb71f8fd976805f91cac7eecdcf3b6a6fef6	predictive modeling of expressed emotions in music using pairwise comparisons	pairwise comparison;expressed emotion;active learning;gaussian process	We introduce a two-alternative forced-choice (2AFC) experimental paradigm to quantify expressed emotions in music using the arousal and valence (AV) dimensions. A wide range of well-known audio features are investigated for predicting the expressed emotions in music using learning curves and essential baselines. We furthermore investigate the scalability issues of using 2AFC in quantifying emotions expressed in music on large-scale music databases. The possibility of dividing the annotation task between multiple individuals, while pooling individuals’ comparisons is investigated by looking at the subjective differences of ranking emotion in the AV space. We find this to be problematic due to the large variation in subjects’ rankings of excerpts. Finally, solving scalability issues by reducing the number of pairwise comparisons is analyzed. We compare two active learning schemes to selecting comparisons at random by using learning curves. We show that a suitable predictive model of expressed valence in music can be achieved from only 15% of the total number of comparisons when using the Expected Value of Information (EVOI) active learning scheme. For the arousal dimension we require 9% of the total number of comparisons.	active learning (machine learning);baseline (configuration management);database;gaussian process;list of online music databases;predictive modelling;programming paradigm;scalability;whole earth 'lectronic link	Jens Madsen;Bjørn Sand Jensen;Jan Larsen	2012		10.1007/978-3-642-41248-6_14	pairwise comparison;artificial intelligence;machine learning;gaussian process;active learning;statistics	ML	-12.089054267212838	-69.2234949441137	199019
76fc0468267e4351b800a9766712c4e039715839	continuous semantic topic embedding model using variational autoencoder		This paper proposes the continuous semantic topic embedding model (CSTEM) which finds latent topic variables in documents using continuous semantic distance function between the topics and the words by means of the variational autoencoder(VAE). The semantic distance could be represented by any symmetric bell-shaped geometric distance function on the Euclidean space, for which the Mahalanobis distance is used in this paper. In order for the semantic distance to perform more properly, we newly introduce an additional model parameter for each word to take out the global factor from this distance indicating how likely it occurs regardless of its topic. It certainly improves the problem that the Gaussian distribution which is used in previous topic model with continuous word embedding could not explain the semantic relation correctly and helps to obtain the higher topic coherence. Through the experiments with the dataset of 20 Newsgroup, NIPS papers and CNN/Dailymail corpus, the performance of the recent state-of-the-art models is accomplished by our model as well as generating topic embedding vectors which makes possible to observe where the topic vectors are embedded with the word vectors in the real Euclidean space and how the topics are related each other semantically.	autoencoder;calculus of variations;embedded system;euclidean distance;experiment;nips;ontology components;topic model;variational principle;word embedding	Namkyu Jung;Hyeong In Choi	2017	CoRR		euclidean space;topic model;metric (mathematics);mahalanobis distance;mathematics;word embedding;artificial intelligence;machine learning;autoencoder;semantic similarity;natural language processing;embedding	ML	-17.165965377665547	-67.21947690913527	199371
118409c099fa94bcdead50f4dca87a7f081aa1f9	mindfulness and the quality of organizational attention	conceptualizing;mindful organizing;attention;mindfulness;encoding	Mindfulness as depicted by Levinthal and Rerup (2006) involves encoding ambiguous outcomes in ways that influence learning, and encoding stimuli in ways that match context with a repertoire of routines. We add to Levinthal and Rerup's conjectures by examining Western and Eastern versions of mindfulness and how they function as a process of knowing an object. In our expanded view, encoding becomes less central. What becomes more central are activities such as altering the codes, differentiating the codes, introspecting the coding process itself, and, most of all, reducing the overall dependence on coding and codes. Consequently, we shift from Levinthal and Rerup's contrast between mindful and less mindful to a contrast between conceptual and less conceptual. When people move away from conceptuality and encoding, outcomes are affected more by the quality than by the quantity of attention.		Karl E. Weick;Kathleen M. Sutcliffe	2006	Organization Science	10.1287/orsc.1060.0196	psychology;developmental psychology;attention;psychotherapist;social psychology;encoding	NLP	-7.142763368811083	-77.54521071195308	199530
9756bb08dc33216b12d7acf2f9f6df42f4840ca5	designing semantic kernels as implicit superconcept expansions	text mining;stable models;a priori knowledge;background knowledge;experimental evaluation;support vector machine;bag of words	Recently, there has been an increased interest in the exploitation of background knowledge in the context of text mining tasks, especially text classification. At the same time, kernel-based learning algorithms like Support Vector Machines have become a dominant paradigm in the text mining community. Amongst other reasons, this is also due to their capability to achieve more accurate learning results by replacing standard linear kernel (bag-of-words) with customized kernel functions which incorporate additional apriori knowledge. In this paper we propose a new approach to the design of ‘semantic smoothing kernels’ by means of an implicit superconcept expansion using well-known measures of term similarity. The experimental evaluation on two different datasets indicates that our approach consistently improves performance in situations where (i) training data is scarce or (ii) the bag-ofwords representation is too sparse to build stable models when using the linear kernel.	apriori algorithm;bag-of-words model;document classification;experiment;kernel (operating system);linear algebra;local interconnect network;machine learning;programming paradigm;scheme;semantic similarity;smoothing;sparse matrix;support vector machine;text corpus;text mining;web services for devices;word sense;word-sense disambiguation	Stephan Bloehdorn;Roberto Basili;Marco Cammisa;Alessandro Moschitti	2006			kernel method;radial basis function kernel;computer science;machine learning;pattern recognition;data mining;tree kernel;polynomial kernel	ML	-18.92976811953946	-66.36830981598843	199629
8b115250c9811308738bf36c344fa9b5c041a71b	deceptive text detection using continuous semantic space models				Ángel Hernández-Castañeda;Hiram Calvo	2017	Intell. Data Anal.	10.3233/IDA-170882	artificial intelligence;machine learning;pattern recognition;computer science	AI	-9.169627877310987	-70.01996848038304	199851
92ceb19575312a202b6c40e4304f4740cc4fed90	timbre interfaces using adjectives and adverbs	timbre;neural networks;qa 76 software;computer programming;natural language;neural network	How can we provide interfaces to synthesis algorithms that will allow us to manipulate timbre directly, using the same timbre-words that are used by human musicians to communicate about timbre? This paper describes ongoing work that uses machine learning methods (principally genetic algorithms and neural networks) to learn (1) to recognise timbral characteristics of sound and (2) to adjust timbral characteristics of existing synthesized sounds.	artificial neural network;genetic algorithm;machine learning	Colin G. Johnson;Alex Gounaropoulos	2006			natural language processing;speech recognition;computer science;machine learning;computer programming;natural language;artificial neural network	AI	-15.703925046551541	-80.14859549200368	199888
fb0d6b2c5b97add34ef093a0764cdf9a9407e84f	sex differences in verbal fluency: the role of strategies and instructions	clustering;effect of instruction;phonemic fluency;semantic fluency;sex differences;switching;verbal fluency	Sex differences in verbal fluency performance and strategies are highly controversial, nevertheless suggesting a slight female advantage at least for phonemic fluency. A tendency of increased clustering of words into phonemic and semantic subcategories in men and increased switching between those categories in women has been suggested. In spatial tasks, it has been demonstrated that changes in instructions favoring a certain cognitive strategy can alter sex differences in performance. Such an approach has, however, not been attempted previously with verbal tasks. In the present investigation, 19 women in their luteal cycle phase and 23 men performed a phonemic and a semantic fluency task with three different instructions, one neutral, one emphasizing the clustering, and one emphasizing the switching of words. While under neutral instructions no sex differences were observed in verbal fluency performance and strategies, sex differences in switching and overall performance were observed in semantic fluency with an instruction requiring a switching strategy. Furthermore, correlation analyses suggested that the importance of strategies for overall performance differed between women and men. While only switching, but not clustering was related to overall verbal fluency performance in all tasks under all instructions, this relationship was driven by women in the phonemic task, but by men in the semantic task. These results highlight the importance of a consistent methodology in sex difference research. Slight variations in instructions may in part explain inconsistencies regarding sex differences in verbal fluency between previous studies.	attempt;categories;cluster analysis;sex characteristics;statistical cluster	Andrea Scheuringer;Ramona Wittig;Belinda Pletzer	2017		10.1007/s10339-017-0801-1	psychology;cognitive psychology;communication;social psychology;verbal fluency test	AI	-9.899465730105447	-79.11309110052623	199935
