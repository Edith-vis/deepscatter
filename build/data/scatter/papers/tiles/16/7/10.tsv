id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
2e7f752720ad429c5a92e8c2a7ddb863906c3fcd	xcalablemp implementation and performance of nas parallel benchmarks	distributed memory;high performance computing;distributed memory system;programming model;conjugate gradient;parallel programming language;high performance computer;fortran;parallel programs;nas parallel benchmarks;parallel applications	XcalableMP is a parallel extension of existing languages, such as C and Fortran, that was proposed as a new programming model to facilitate program parallel applications for distributed memory systems. In order to investigate the performance of parallel programs written in XcalableMP, we have implemented NAS Parallel Benchmarks, specifically, the Embarrassingly Parallel (EP) benchmark, the Integer Sort (IS) benchmark, and the Conjugate Gradient (CG) benchmark, using XcalableMP. The results show that the performance of XcalableMP is comparable to that of MPI. In particular, the performances of IS with a histogram and CG with two-dimensional parallelization achieve almost the same performance. The results also demonstrate that XcalableMP allows a programmer to write efficient parallel applications at a lower programming cost.	benchmark (computing);conjugate gradient method;convex conjugate;distributed memory;embarrassingly parallel;expectation propagation;fortran;image histogram;integer sorting;nas parallel benchmarks;parallel computing;performance;programmer;programming model	Masahiro Nakao;Jinpil Lee;Taisuke Boku;Mitsuhisa Sato	2010		10.1145/2020373.2020384	computer architecture;parallel computing;embarrassingly parallel;computer science;programming language	HPC	-6.102933840585167	42.34270230952401	42257
5c0fe1c34111b170a92006d83e75bdc9c695ea61	pdrs: a performance data representation system	base relacional dato;decision support;design and development;programacion paralela;parallel programming;relational database;data representation;program optimization;performance programme;parallel computer;base donnee relationnelle;eficacia programa;optimisation programme;program performance;systeme gestion base donnee;sistema gestion base datos;database management system;programmation parallele;optimizacion programa	We present the design and development of a Performance Data Representation System (PDRS) for scalable parallel computing. PDRS provides decision support that helps users find the right data to understand their programs’ performance and to select appropriate ways to display and analyze it. PDRS is an attempt to provide appropriate assistant to help programmers identifying performance bottlenecks and optimizing their programs.	bottleneck (software);decision support system;parallel computing;programmer;scalability	Xian-He Sun;Xingfu Wu	2000		10.1007/3-540-45591-4_37	parallel computing;simulation;decision support system;relational database;computer science;theoretical computer science;program optimization;database;external data representation;programming language	HPC	-17.985147841166288	41.09883896440064	42432
3f6790b25b3ce2104216e311a66db6689b1519fe	acceleration of turbulent flow simulations with intel xeon phi(tm) manycore processors		Enhancing the performance of turbulent flow simulations is important as the size of simulations grows with higher Reynolds number. We discuss the performance of our in-house turbulent flow simulation solver, named as DNS-TBL (Direct Numerical Simulation: Turbulent Boundary Layer), on the Intel Xeon Phi™ manycore processors. With bootable Knights Landing processors, the DNS-TBL solver shows excellent parallel scalability and, in particular, shows a 1.6 times better performance in solver time than the original CPU-based version. Current intermediate results serve as a practical case-study which directly shows how much turbulent flow simulations can be accelerated on manycore processors, providing a good reference for the parallelization and optimization schemes in the filed of computational fluid dynamics.	booting;central processing unit;computational fluid dynamics;computer simulation;direct numerical simulation;knights;manycore processor;mathematical optimization;parallel computing;reynolds-averaged navier–stokes equations;scalability;solver;turbulence;xeon phi	Ji-Hoon Kang;Hoon Ryu	2017	2017 IEEE International Conference on Cluster Computing (CLUSTER)	10.1109/CLUSTER.2017.36	parallel computing;xeon;computer science;real-time computing;xeon phi;boundary layer;multi-core processor;turbulence;direct numerical simulation;computational fluid dynamics;solver	HPC	-5.160678603490313	38.95885786671245	42594
a3ea36822dd4f5f90a89e5c7d56d7b4793ee47ab	a new multi-processor architecture for parallel lazy cyclic reference counting	processor architecture;reference counting;java memory management virtual machining data structures computer languages parallel programming programming profession heuristic algorithms algorithm design and analysis parallel architectures;memory management;storage management;parallel architectures multiprocessing systems storage management;parallel architectures;multiprocessing systems;mutator collector synchronization multiprocessor architecture parallel lazy cyclic reference counting memory management technique mutator collector communication	Reference counting is the memory management technique of most widespread use today. This paper presents a new multi-processor architecture for parallel cyclic reference counting. In this architecture, there is no direct mutator-collector communication and synchronization is kept minimal.	lazy evaluation;memory management;microarchitecture;multiprocessing;mutator method;reference counting	Rafael Dueire Lins	2005	17th International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD'05)	10.1109/CAHPC.2005.6	reference architecture;computer architecture;reference counting;parallel computing;real-time computing;microarchitecture;computer science;operating system;programming language;memory management	Arch	-14.307015938373299	40.820293966306195	42615
9443d3f3050381b44ca65c57417e59831242e5d5	object-oriented support for adaptive methods on paranel machines	object oriented	"""This article reports on experiments from our ongoing project whose goal is to develop a C++ library which supports adaptive and irregular data structures on distributed memory supercomputers. We demonstrate the use of our abstractions in implementing """"tree codes"""" for large-scale N-body simulations. These algorithms require dynamically evolving treelike data structures, as well as load-balancing, both of which are widely believed to make the application difficult and cumbersome to program for distributed-memory machines. The ease of writing the application code on top of our C++ library abstractions (which themselves are application independent), and the low overhead of the resulting C++ code (over hand-crafted C code) supports our belief that object-oriented approaches are eminently suited to programming distributed-memory machines in a manner that (to the applications programmer) is architecture-independent. Our contribution in parallel programming methodology is to identify and encapsulate general classes of communication and load-balancing strategies useful across applications and MIMD architectures. This article reports experimental results from simulations of half a million particles using multiple methods."""		Sandeep N. Bhatt;Marina C. Chen;James R. Cowie;Cheng-Yee Lin;Pangfeng Liu	1993	Scientific Programming		parallel computing;computer science;theoretical computer science;operating system;distributed computing;programming language;object-oriented programming	HPC	-13.18544319808365	39.84061753926178	42625
527803ad14d80391891983c626a65cb1f304c6d1	glosim: global system image for cluster computing	file attente;distributed system;single system image;cluster computing;systeme unix;sistema imagen unico;haute performance;architecture systeme;systeme reparti;shared memory;network server;memoria compartida;unix system;distributed computing;queue;parallel computation;serveur reseau;noyau systeme exploitation;grappe calculateur;network servers;calculo paralelo;sistema repartido;semaphore;cluster system;systeme image unique;alto rendimiento;calculo repartido;middleware;arquitectura sistema;sistema unix;single system image ssi;semaforo;operating system kernels;system architecture;high performance;calcul parallele;fila espera;calcul reparti;memoire partagee	This paper presents a novel architecture of a single system image built on cluster system, named Glosim. This system orientates to cluster system middleware, which provides global system image support. It not only supports global IPC objects including message queue, semaphore and shared memory, but also presents a new concept of global working process and provides it SSI support smoothly and transparently. Combined with Linux Virtual Server, single IO space, it completely constructs a high performance SSI cluster network server.	computer cluster;linux virtual server;message queue;middleware;semaphore (programming);server (computing);shared memory;single system image;smoothing	Hai Jin;Guo Li;Zongfen Han	2003		10.1007/978-3-540-45145-7_25	shared memory;embedded system;parallel computing;semaphore;computer cluster;computer science;operating system;middleware;queue;server;systems architecture	HPC	-17.883545062071597	42.85155488344985	42690
04706cfdae1e666fa0e7a8c2c23d179712a3d792	high performance datacenter networks: architectures, algorithms, and opportunities	network architecture and design;topology;fiber optics;parallel computer architecture;system design;interconnection networks;network architecture;high performance	"""Datacenter networks provide the communication substrate for large parallel computer systems that form the ecosystem for high performance computing (HPC) systems and modern Internet applications. The design of new datacenter networks is motivated by an array of applications ranging from communication intensive climatology, complex material simulations and molecular dynamics to such Internet applications as Web search, language translation, collaborative Internet applications, streaming video and voice-over-IP. For both Supercomputing and Cloud Computing the network enables distributed applications to communicate and interoperate in an orchestrated and efficient way. This book describes the design and engineering tradeoffs of datacenter networks. It describes interconnection networks from topology and network architecture to routing algorithms, and presents opportunities for taking advantage of the emerging technology trends that are influencing router microarchitecture. With the emergence of """"many-core"""" processor chips, it is evident that we will also need """"many-port"""" routing chips to provide a bandwidth-rich network to avoid the performance limiting effects of Amdahl's Law. We provide an overview of conventional topologies and their routing algorithms and show how technology, signaling rates and cost-effective optics are motivating new network topologies that scale up to millions of hosts. The book also provides detailed case studies of two high performance parallel computer systems and their networks. Table of Contents: Introduction / Background / Topology Basics / High-Radix Topologies / Routing / Scalable Switch Microarchitecture / System Packaging / Case Studies / Closing Remarks"""	algorithm;data center	Dennis Abts;John Kim	2011		10.2200/S00341ED1V01Y201103CAC014	computer architecture;parallel computing;real-time computing;network architecture;computer science;optical fiber;operating system;distributed computing;systems design	HPC	-8.39995057525736	42.72628131976363	42921
c20e653737cf2fe7932fa213c8fec1631ea3035e	using pvm to implement ppardb/pvm, a portable parallel database management system	management system;parallel databases;parallel systems;heterogeneous network	Although parallel databases have been an active research topic for several years, portable parallel databases represent a relatively new concept. They are required in order to make parallel systems available and appealing to an application-demanding user community. PPARDB / PVM, a portable parallel database management system that employs a shared nothing architecture and uses operator parallelism has been built on a heterogeneous workstation network. PPARDB / PVM uses PVM for portable communication primitives. Each workstation in the network is treated as a separate database node.		N. Papakostas;George K. Papakonstantinou;Panayiotis Tsanakas	1996		10.1007/3540617795_14	computer architecture;parallel computing;distributed computing	DB	-12.203524294987998	43.988232075877185	43176
997d0725d83babc0699c0c22bf92a60771dcda61	analyzing asynchronous pipeline schedules	performance measure;directed acyclic graph;distributed memory;graph theory;distributed system;grafo aciclico;optimisation;teoria grafo;systeme reparti;algoritmo busqueda;algorithm performance;systeme multiprocesseur memoire repartie;optimizacion;time complexity;algorithme recherche;search algorithm;graphe acyclique;ejecucion programa;schedulability analysis;theorie graphe;acyclic graph;program execution;parallel computation;complexite temps;calculo paralelo;sistema repartido;data dependence;resultado algoritmo;scheduling;execution programme;directed graph;sistema multiprocesador memoria distribuida;graphe oriente;performance algorithme;deadlock;interbloqueo;ordonamiento;grafo orientado;optimization;oleoducto;distributed memory multiprocessor system;pipelining;interblocage;task scheduling;complejidad tiempo;loop optimization;shared memory system;calcul parallele;distributed memory parallelism;ordonnancement;pipeline	Asynchronous pipelining is a form of parallelism that is useful in both distributed and shared memory systems. We show that asynchronous pipeline schedules are a generalization of both noniterative DAG (directed acyclic graph) schedules as well as simpler pipeline schedules, unifying these two types of scheduling. We generalize previous work on determining if a pipeline schedule will deadlock, and generalize Reiter's well-known formula for determining the iteration interval of a deadlock-free schedule, which is the primary measure of the execution time of a schedule. Our generalizations account for nonzero communication times (easy) and the assignment of multiple tasks to processors (nontrivial). A key component of our generalized approach to pipeline schedule analysis is the use of pipeline scheduling edges with potentially negative data dependence distances. We also discuss implementation of an asynchronous pipeline schedule at runtime; show how to efficiently simulate pipeline execution on a sequential processor; define and derive bounds on the startup time of a schedule, which is a secondary schedule performance measure; and describe a new algorithm for evaluating the iteration interval formula.	asynchronous circuit;central processing unit;data dependency;deadlock;directed acyclic graph;distributed memory;duckduckgo;interval arithmetic;iteration;loop splitting;parallel computing;pipeline (computing);retiming;run time (program lifecycle phase);schedule (computer science);scheduling (computing);search algorithm;shared memory;simulation	Val Donaldson;Jeanne Ferrante	1998	International Journal of Parallel Programming	10.1023/A:1018786922750	pipeline;parallel computing;real-time computing;computer science;graph theory;operating system;distributed computing;pipeline;directed acyclic graph;algorithm	Arch	-14.597220179490884	42.77020707046641	43373
31d4076e1ad7e5621c83c4bf324b5430db452d53	revisiting the issue of performance enhancement of discrete event simulation software	virtual memory;algorithm analysis;simpy language;software performance evaluation;cache memory;cache memory discrete event simulation software simpy language compiler efficiency interpreter efficiency hybrid interpreted compiled code virtual memory;compiler efficiency;software performance evaluation discrete event simulation;discrete event simulation software performance algorithm design and analysis computer science cache memory delay read write memory context modeling software libraries analytical models;hybrid interpreted compiled code;discrete event simulation software;interpreter efficiency;discrete event simulation	New approaches are considered for performance enhancement of discrete-event simulation software. Instead of taking a purely algorithmic analysis view, we supplement algorithmic considerations with focus on system factors such as compiler/interpreter efficiency, hybrid interpreted/compiled code, virtual and cache memory issues, and so on. The work here consists of a case study of the SimPy language, in which we achieve significant speedups by addressing these factors	algorithm;cpu cache;compiler;interpreter (computing);simpy;simulation software	Alex Bahouth;Steven Crites;Norman Matloff;Todd Williamson	2007	40th Annual Simulation Symposium (ANSS'07)	10.1109/ANSS.2007.36	computer architecture;parallel computing;cache coloring;computer science;programming language	Embedded	-14.32673749692648	41.60379079330923	43523
bf7e5300f3c172f12e249bb8c29901bea591900a	the tersoff many-body potential: sustainable performance through vectorization		We extend the LAMMPS molecular dynamics program with a new, vectorized implementation of the Tersoff potential [7]. Given the well-established and well-studied mechanisms for parallelism in molecular dynamics programs [1], our efforts focus on vectorization as a further step to fully utilize available hardware. This contribution describes how our implementation achieves sustainable performance across a number of architectures, most notably the Xeon Phi coprocessor, using vectorization. On current architectures, vectorization contributes greatly to the system’s peak performance; this is true for CPUs with the SSE or AVX instruction set extensions, and especially for machines with wide vectors, such as the Xeon Phi. Many successful open-source molecular dynamics packages—e.g. Gromacs, NAMD, LAMMPS and ls1 mardyn [6, 9, 8]—take advantage of vectorization. Implementation methods vary between hand-written assembly, intrinsics (compiler-provided functions that closely map to machine instructions), and annotations that guide the compiler’s optimization [10]. Typically, only the parts of the calculation that consume a large fraction of the total runtime are optimized; among them, the neighbor list construction and the force calculation. For most simulations, the forces are derived from pair potentials, such as the Coulomb or Lennard-Jones potentials. Indeed, vectorized implementations of the force calculation due to pair potentials are found in many molecular dynamics programs. However, some applications, especially in materials science, require many-body potential formulations. With these, the force between two atoms does not depend solely on the distance between them, but also on the relative position of the surrounding atoms. For many-body potentials, the force calculation is not vectorized in the available molecular dynamics programs. There has been previous work on implementing many-body potentials on the GPU [3, 4, 5], but not on more conventional architectures with vectorization support.	advanced vector extensions;assembly language;automatic vectorization;bond order potential;central processing unit;compiler;coprocessor;gromacs;graphics processing unit;intrinsic function;jones calculus;large-scale atomic/molecular massively parallel simulator;lennard-jones potential;many-body problem;mathematical optimization;nanoscale molecular dynamics;open-source software;parallel computing;simulation;streaming simd extensions;verlet list;whole earth 'lectronic link;xeon phi	Markus Höhnerbach;Ahmed E. Ismail;Paolo Bientinesi	2015	CoRR		software;mathematics;compiler;molecular dynamics;instruction set;mathematical optimization;architecture;parallel computing;xeon phi;central processing unit;vectorization (mathematics)	HPC	-5.1764979941004805	39.067505465371354	43528
a8d727e8d9269f3fbc59d1a4a30287a82e13efed	experiences evaluating functionality and performance of ibm power8+ systems		In preparation for Summit, Oak Ridge National Laboratory’s next generation supercomputer, two IBM Power-based systems were deployed in late 2016 at the Oak Ridge Leadership Computing Facility (OLCF). This paper presents a detailed description of the acceptance of the first IBM Power-based early access systems installed at the OLCF. The two systems, Summitdev and Tundra, contain IBM POWER8+ processors with NVIDIA Pascal GPUs and were acquired to provide researchers with a platform to optimize codes for the Power architecture. In addition, this paper presents early functional and performance results obtained on Summitdev with the latest software stack available.		Verónica G. Vergara Larrea;Wayne Joubert;Mark A. Berrill;Swen Boehm;Arnold N. Tharrington;Wael R. Elwasif;Don Maxwell	2017		10.1007/978-3-319-67630-2_20	power8;computer architecture;ibm;power architecture;software;oak ridge national laboratory;computer science;operating system;supercomputer;java	HPC	-8.564415902133419	39.573441044723495	43569
793b3f69b14dd578e3ba7dc9d49dec3bb119ffd8	splicing grammar systems	lenguaje programacion;gramatica chomsky;chomsky grammar;tranchage;programming language;grammaire chomsky;gramatica cf;regular grammar;grammaire cf;slicing;context free grammar;chapeado;langage programmation;systeme parallele;parallel system;communication;comunicacion;sistema paralelo	The aim of this paper is to bring together two new and powerful tools: on the one hand, the splicing operation as a basic operation on DNA sequences and, on the  other hand, the parallelism and communication features in grammar systems. As expected, the result of the above combination is a very powerful mechanism, leading to a new characterization of recursively enumerable languages.	grammar systems theory	Jürgen Dassow;Victor Mitrana	1996	Computers and Artificial Intelligence		regular grammar;computer science;chomsky hierarchy;linguistics;context-free grammar;programming language;algorithm	AI	-15.535176300824785	34.49225782364491	43662
755c0e55843181efe40b3b7818ee4fb96911d17e	retire fortran?: a debate rekindled	lenguaje programacion;compilateur;programming language;programacion paralela;sistema informatico;parallel programming;computer system;supercomputer;compiler;functional programming;supercomputador;langage programmation;sisal;systeme informatique;programmation fonctionnelle;fortran;programacion funcional;compilador;superordinateur;programmation parallele	A Debate Rekindled-of 1984, te between ~cGraw ~awrence ivermore tional Laboratory (LLNL) and David Kuck and Michael Wolfe of Kuck and Associates, appeared in Physics Today [19]. The subject was whether to retire Fortran. Eight years have passed, and we wish to reopen the debate and provide further evidence that Fortran is not the sine qua non of high-speed computing. Many believe that the existing investments in Fortran and the quality of existing Fortran compilers are preventing a change in programming methodology. Many also feel that support for Fortran must continue because the language is familiar and widely available. Unfortunately , the complexity of writing correct parallel programs in Fortran is perpetuating today's software crisis. We believe, as did McGraw in 1984, that increased productivity, generality, utility, portability, and performance are only possible if programmers avoid the constraints of imperative languages and adopt a higher level of abstraction. We must escape the morass of imperative semantics and attain a level of abstraction that separates the programmer from the machine, stresses problem definition over the mechanics of solution, and provides complete information to the compiler. While Kuck and Wolfe would probably have agreed with the above statements, they wisely argued that programmers would not use languages that did not allow them to get the performance they required. To this McGraw had no counterargument, for in 1984, only Fortran provided the performance needed for large-scale scientific computing. The intent of this article is to reopen the debate and present overwhelming evidence that functional supercomputing is possible. To this end, we compare the execution performance of Sisal, a functional language for large-scale scientific computing, and For-tran on a Cray Y-MP/864. The Crays remain the most heavily used machines in our nation's supercom-puter centers, and are the preferred machines of most scientific programmers. Thus, it is here that languages must outperform For-tran if they are to replace it. For completeness and for the benefit of those readers not familiar with the principles of functional computing, the next two sections examine the functional programming paradigm, discuss its attributes and advantages, and highlight the salient features of Sisal. In the remaining sections we illustrate the potential inefficiencies of functional computing, present our most recent performance data, and give some closing remarks regarding Fortran and the future of high-speed computing. In 1984, McGraw noted that, by all indications, future supercomputers would be multiprocessors. Today, most supercomputer users …	closing (morphology);compiler;computational science;cray y-mp;david kuck;fortran;functional programming;imperative programming;programmer;programming paradigm;sisal;software crisis;software development process;software portability;supercomputer;utility	David C. Cann	1992	Commun. ACM	10.1145/135226.135231	computer architecture;compiler;supercomputer;parallel computing;computer science;programming language;functional programming	HPC	-15.80735033404152	39.98546542184568	43848
82eae43b9a09290efbfb3728076f0a081a185b54	practical structured parallelism using bmf	parallel computing;thesis or dissertation;bird meertens formalism	This thesis concerns the use of the Bird-Meertens Formalism as a mechanism to control parallelism in an imperative programming language. One of the main reasons for the failure of parallelism to enter mainstream computing is the di culty of developing software and the lack of the portability and performance predictability enjoyed by sequential systems. A key objective should be to minimize costs by abstracting much of the complexity away from the programmer. Criteria for a suitable parallel programming paradigm to meet this goal are de ned. The Bird-Meertens Formalism, which has in the past been shown to be a suitable vehicle for expressing parallel algorithms, is used as the basis for a proposed imperative parallel programming paradigm which meets these criteria. A programming language is proposed which is an example of this paradigm, based on the BMF Theory of Lists and the sequential language C. A concurrent operational semantics is outlined, with the emphasis on its use as a practical tool for increasing con dence in program correctness, rather than on full and rigorous formality. A prototype implementation of a subset of this language for a distributed memory, massively parallel computer is produced in the form of a C subroutine library. Although not o ering realistic absolute performance, it permits measurements of scalability and relative performance to be undertaken. A case study is undertaken which implements a simple but realistic algorithm in the language, and considers how well the criteria outlined at the start of the project are met. The prototype library implementation is used for performance measurements. A range of further possibilities is examined, in particular ways in which the paradigm language might be extended, and the possibility of using alternative BMF-like type theories. Pragmatic considerations for achieving performance in a production implementation are discussed.	apl;amdahl's law;american federation of information processing societies;bird–meertens formalism;boolean algebra;bridging (networking);bridging model;c++;calculus of communicating systems;coat of arms;cobham's thesis;computation;computational fluid dynamics;computer scientist;concurrency (computer science);consortium;correctness (computer science);data dependency;data structure;david gries;deadlock;distributed computing;distributed memory;endeavour (supercomputer);goodyear mpp;graphics;gustafson's law;hoare logic;imperative programming;information science;iteration;john d. gannon;john gustafson (scientist);jones calculus;kelly criterion;lecture notes in computer science;library (computing);list ranking;message passing interface;michael j. fischer;my life as a teenage robot;naruto shippuden: clash of ninja revolution 3;nash equilibrium;octal;operational semantics;parallel algorithm;parallel computing;parallel language;parallel processing (dsp implementation);parallel programming model;programmer;programming research group;programming language;programming paradigm;prototype;random access;recurrence relation;roberto busa;rosemary candlin;sanjeev khanna;scalability;semantics (computer science);simulation;software portability;springer (tank);subroutine;susan owicki;symposium on theory of computing;synthetic intelligence;task parallelism;theoretical computer science;yang	David Crooke	1998			computer science;theoretical computer science;algorithm	PL	-16.662374601158685	33.27816138391221	44300
e3d57f42aa6f9e824e71998ed39a697cbbfbcf68	a note on associative processors for data management	data management;database machines;garbage collection;associative processors;point of view	Associative “logic-per-track” processors for data management are examined from a technological and engineering point of view. Architectural and design decisions are discussed. Some alternatives to the design of comparators, garbage collection, and domain extraction for architectures like the Relational Associative Processor (RAP) are offered.	central processing unit;comparator;garbage collection (computer science)	Glen G. Langdon	1978	ACM Trans. Database Syst.	10.1145/320251.320254	parallel computing;data management;computer science;theoretical computer science;content-addressable memory;database;garbage collection;programming language	DB	-11.543059631644548	44.148972602545975	44578
6e53baf38d183238bc82519f926742b58589929e	towards a high-level implementation of flexible parallelism primitives for symbolic languages	informatica;symbolic computation;parallel logic programming;parallelism;logic programming	The advent of multicore processors is bringing renewed interest in parallelism and, accordingly, in the development of languages and tools to simplify the task of writing parallel programs. This is especially important for the complex, non-regular algorithms often found in software which performs non-trivial symbolic tasks. Such software can benefit from being written in a high-level language whose nature is symbolic as well, since this narrows the gap between the conceptual definition of the task to be performed and the code which executes it. In our case we will use for concreteness a logic-based multiparadigm language, Ciao [1], which is based on a logic-programming kernel and a flexible mechanism whereby multiple extensions are built supporting Prolog, functional programming, constraint programming, and other systemand user-level languages. The base language and system features dynamic typing, higher-order capabilities, polymorphism, and static type inference and checking (also of non-trivial properties, such as computational complexity). Such language capabilities are largely orthogonal to parallelism; however, the way parallelism is expressed combines seamlessly with the the rest of the language. An advantage of logic-based languages (and, in general, of declarative languages) is that their clean semantics and highlevel nature makes it possible to perform automatic parallelization more easily [4, 2]. At the same time, the runtime	algorithm;automatic parallelization;central processing unit;ciao;computational complexity theory;constraint programming;functional programming;high- and low-level;high-level programming language;logic programming;multi-core processor;parallel computing;programming paradigm;prolog;theoretical definition;type inference;type system;user space	Amadeo Casas;Manuel Carro;Manuel V. Hermenegildo	2007		10.1145/1278177.1278193	computer architecture;parallel computing;symbolic computation;declarative programming;horn clause;computer science;functional logic programming;computational logic;mathematics;data parallelism;programming paradigm;symbolic programming;inductive programming;fifth-generation programming language;programming language;logic programming;instruction-level parallelism;comparison of multi-paradigm programming languages;implicit parallelism;task parallelism;algebra	PL	-14.223715872171587	37.78223116562131	44652
bb7d4a01af4d7e33e463f9f70def2fd4889859e8	a unified mapreduce domain-specific language for distributed and shared memory architectures		MapReduce is a suitable and efficient parallel programming pattern for processing big data analysis. In recent years, many frameworks/languages have implemented this pattern to achieve high performance in data mining applications, particularly for distributed memory architectures (e.g., clusters). Nevertheless, the industry of processors is now able to offer powerful processing on single machines (e.g., multi-core). Thus, these applications may address the parallelism in another architectural level. The target problems of this paper are code reuse and programming effort reduction since current solutions do not provide a single interface to deal with these two architectural levels. Therefore, we propose a unified domain-specific language in conjunction with transformation rules for code generation for Hadoop and Phoenix++. We selected these frameworks as state-of-the-art MapReduce implementations for distributed and shared memory architectures, respectively. Our solution achieves a programming effort reduction from 41.84% and up to 95.43% without significant performance losses (below the threshold of 3%) compared to Hadoop and Phoenix++.	domain-specific language;mapreduce;shared memory	Daniel Couto Adornes;Dalvan Griebler;Cleverson Ledur;Luiz Gustavo Fernandes	2015		10.18293/SEKE2015-204	uniform memory access;distributed shared memory;shared memory;computer architecture;parallel computing;distributed memory;distributed computing;data diffusion machine	HPC	-5.938197025244531	44.030149444347735	44993
9d731325ac82b440ba519db143fc1c13135f84f1	dpac: an object-oriented distributed and parallel computing framework for manufacturing applications	interprocess communication;object oriented methods;fault tolerant;parallel processing manufacturing distributed computing internet computer architecture pervasive computing fault tolerance job shop scheduling processor scheduling concurrent computing;computer model;combinatorial optimization problem;distributed computing;application program interface;manufacturing industries;indexing terms;parallel and distributed computing;branch and bound computational models dpac object oriented distributed and parallel computing framework manufacturing applications application programming interface large scale computing manufacturing automation real time scheduling internet ultra large coarse grained parallel applications diverse heterogeneous geographically distributed computing environments scalable fault tolerant architecture running performance interoperable platform java piecework;industrial control fault tolerant computing java internet object oriented methods application program interfaces distributed control manufacturing industries;large scale;fault tolerant computing;internet;design and implementation;object oriented;real time scheduling;application program interfaces;industrial control;parallel computer;coarse grained;branch and bound;manufacturing system;distributed control;parallel applications;geographic distribution;java	Parallel and distributed computing infrastructure are increasingly being embraced in the context of manufacturing applications, including real-time scheduling. In this paper, we present the design and implementation of one such framework that can work on the Internet, with applications in manufacturing. The architecture, aliased as DPAC (Distributed and Parallel Computing framework), has the goal of harnessing the Internet’s vast, growing computational capacity for ultra-large, coarse-grained parallel applications. The idea is to bring together diverse, heterogeneous, geographically distributed computing environments in order to attack large-scale computing problems. We present a scalable and fault-tolerant architecture in DPAC and the results of running performance experiments. DPAC is implemented on the interoperable, increasingly secure, and ubiquitous platform, viz, Java. The unique feature of DPAC is that it frees application developers from concerns about complex interprocess communication and fault tolerance among Internet-worked hosts and supports piecework and branch-and-bound computational models. We describe an implementation and present case studies showing the effectiveness in solving complex combinatorial optimization problems in the context of manufacturing systems.	branch and bound;combinatorial optimization;computation;computational model;distributed computing;experiment;fault tolerance;inter-process communication;internet;interoperability;java;mathematical optimization;parallel computing;real-time clock;scalability;scheduling (computing);viz: the computer game	N. R. Srinivasa Raghavan;Tanmay Waghmare	2002	IEEE Trans. Robotics and Automation	10.1109/TRA.2002.802236	computer simulation;fault tolerance;parallel computing;real-time computing;the internet;index term;application programming interface;computer science;distributed computing;manufacturing;object-oriented programming;java;branch and bound;inter-process communication	HPC	-12.573158691489187	43.56793345599689	45074
c0096ff3c900e457ad01627b30d440818514f489	mapping of large task network on manycore architecture. (placement de graphes de tâches de grande taille sur architectures massivement multicoeurs)			manycore processor;multi-core processor	Karl-Eduard Berger	2015				EDA	-9.444762440492667	43.30890543469318	45318
66d72c3e76a020eff39c2736c869871592c85249	evaluation of a floating-point intensive kernel on fpga - a case study of geodesic distance kernel		Heterogeneous platforms provide a promising solution for high-performance and energy-efficient computing applications. This paper presents our research on usage of heterogeneous platform for a floating-point intensive kernel. We first introduce the floating-point intensive kernel from the geographical information system. Then we analyze the FPGA designs generated by the Intel FPGA SDK for OpenCL, and evaluate the kernel performance and the floating-point error rate of the FPGA designs. Finally, we compare the performance and energy efficiency of the kernel implementations on the Arria 10 FPGA, Intel’s Xeon Phi Knights Landing CPU, and NVIDIA’s Kepler GPU. Our evaluation shows the energy efficiency of the single-precision kernel on the FPGA is 1.35X better than on the CPU and the GPU, while the energy efficiency of the double-precision kernel on the FPGA is 1.36X and 1.72X less than the CPU and GPU, respectively.	distance (graph theory);field-programmable gate array;kernel (operating system)	Zheming Jin;Hal Finkel;Kazutomo Yoshii;Franck Cappello	2017		10.1007/978-3-319-75178-8_53	field-programmable gate array;kernel (linear algebra);parallel computing;xeon phi;floating point;word error rate;central processing unit;computer science	NLP	-4.747154006355597	43.94426754964623	45325
a5ccdf7e8501fa32cb00869a2952366a4d8a2a4e	performance prediction and procurement in practice: assessing the suitability of commodity cluster components for wavefront codes	workload;estensibilidad;mainframes;modelizacion;evaluation performance;commodity cluster components;commodity based infiniband cluster;performance evaluation;compra;perforation;evaluacion prestacion;supercomputer;qa76 electronic computers computer science computer software;supercomputador;modelisation;qa75 electronic computers computer science;supercomputing resources;codes;performance evaluation codes mainframes parallel machines;wavefront codes;performance procurement;retard;charge travail;achat;atomic weapons establishment;parallel machines;performance prediction;extensibilite;scalability;commodity based infiniband cluster performance prediction performance procurement commodity cluster components wavefront codes supercomputing resources scalability chimaera benchmarking code atomic weapons establishment code performance;carga trabajo;chimaera benchmarking code;retraso;modeling;predictive coding;purchases;superordinateur;code performance	The cost of state-of-the-art supercomputing resources makes eac h individual purchase an expensive and, in many cases, lengthy process. Often eac h candidate architecture will need to be benchmarked using a variety of tools to assess po tential performance. However, benchmarking alone often provides only limite d insight into the potential scalability and suitability of each architecture for procureme nt. In this paper we present a case study applying two recently developed pe rformance models to the Chimaera benchmarking code written by the United Kingd om Atomic Weapons Establishment (AWE) with a view to analysing how the code will perform and scale on a medium sized, commodity based InfiniBand cluste r. Our models are validated with average accuracies of 90% against an existing I nfi iBand machine and then used as the basis for predicting code performan ce on a variety of hardware configurations including changes in the underlying n etwork, faster processors and high core density per processor. The results of our experimentation with machine performance parameter s demonstrate the compute-bound nature of Chimaera and its sensitivity to network la tency at increased processor counts. By using these insights we are able to dis cuss potential strategies which may be employed during the procurement of future m id-range clusters for a wavefront-code rich workload.	bandwidth (signal processing);benchmark (computing);beowulf cluster;central processing unit;code;cross-correlation;elegant degradation;gigabit;infiniband;limbo;linear algebra;multi-core processor;performance prediction;period-doubling bifurcation;predictive modelling;procurement;run time (program lifecycle phase);scalability;simulation;speedup;supercomputer	Simon D. Hammond;Gihan R. Mudalige;J. A. Smith;J. A. Davis;A. B. Mills;Stephen A. Jarvis;J. Holt;I. Miller;J. A. Herdman;A. Vadgama	2009	IET Software	10.1049/iet-sen.2009.0007	supercomputer;parallel computing;scalability;simulation;systems modeling;computer hardware;computer science;engineering;software engineering;code	HPC	-16.41588881166602	43.13329600026751	45352
6cccc9f44b901a6f64d396a95818d2730f479394	scalable parallel amg on ccnuma machines with openmp	distributed data;ccnuma;linear system of equations;hypre;multigrid method;data locality;differential equation;programming model;large scale;standard model;openmp;load balance;petsc;parallel programming model;lama;memory bandwidth;sparse linear system;amg;first touch;numerical simulation	In many numerical simulation codes the backbone of the application covers the solution of linear systems of equations. Often, being created via a discretization of differential equations, the corresponding matrices are very sparse. One popular way to solve these sparse linear systems are multigrid methods—in particular AMG—because of their numerical scalability. But looking at modern multi-core architectures, also the parallel scalability has to be taken into account. With the memory bandwidth usually being the bottleneck of sparse matrix operations these linear solvers can’t always benefit from increasing numbers of cores. To exploit the available aggregated memory bandwidth on larger scale NUMA machines evenly distributed data is often more an issue than load balancing. Additionally, using a threading model like OpenMP, one has to ensure the data locality manually by explicit placement of memory pages. On non uniform data it is always a trade-off between these three principles, while the ideal strategy is strongly machine- and application dependent. In this paper we want to present some benchmarks of an AMG implementation based on a new performance library. Main focus is on the comparability to state-of-the-art solver packages regarding sequential performance as well as parallel scalability on common NUMA machines. To maximize throughput on standard model problems, several thread and memory configurations have been evaluated. We will show that even on large scale multi-core architectures easy parallel programming models, like OpenMP, can achieve a competitive performance compared to more complex programming models.	computer simulation;discretization;internet backbone;linear system;load balancing (computing);locality of reference;memory bandwidth;multi-core processor;multigrid method;non-uniform memory access;numerical analysis;openmp;parallel computing;scalability;solver;sparse matrix;thread (computing);threaded code;throughput	Malte Förster;Jiri Kraus	2011	Computer Science - Research and Development	10.1007/s00450-011-0159-z	computer simulation;standard model;mathematical optimization;parallel computing;computer science;theoretical computer science;operating system;distributed computing;programming language;differential equation;memory bandwidth;multigrid method;parallel programming model	HPC	-4.959354356400532	39.65496359997667	45627
bad408f97c9ed86d94d501b22f68c0ce03386615	job scheduling in a high performance computing environment	information systems;program processors random access memory workstations processor scheduling educational institutions;scheduling;computational chemistry high performance computing hpc job scheduling parallel computing clusters;workstation clusters;drug discovery job scheduling high performance computing environment high performance cluster environment particular hardware environment computer hardware software semiautomatic batch cluster hpc environment computational chemists;workstation clusters parallel processing scheduling;parallel processing	Preparing jobs to run within a high performance cluster environment usually involves at least the understanding of a series of compromises that will affect the time taken to process the work and produce useful results. Software generally is architected by domain specialists who design for a particular hardware environment. Good, well-written software usually incorporates `tweaks' or switches that can be externally invoked to take advantage of the different hardware environments likely to be encountered by the software. With the ever changing landscape of computer hardware, it is not uncommon to have to address the way we work with software in order to maximize the capabilities of the software within a new environment. This paper discusses some of the technical challenges encountered when attempting to use software intended for workstation use within a semi-automatic batch cluster (HPC) environment. The paper chronicles the efforts and solutions deployed working with a team of computational chemists actively engaged on ground-breaking work applied to new drug discovery.	computation;computer hardware;job scheduler;job shop scheduling;job stream;network switch;scheduling (computing);semiconductor industry;supercomputer;workstation	R. L. Warrender;J. Tindle;D. Nelson	2013	2013 International Conference on High Performance Computing & Simulation (HPCS)	10.1109/HPCSim.2013.6641474	parallel processing;parallel computing;real-time computing;computer science;operating system;distributed computing;scheduling;information system	HPC	-8.221037373517644	40.505863152665306	45731
6c9414a385cea3cd607cf9f03309bb7e6bb7c4c8	a distributed object model for solving irregularly structured problems on cluster	dynamic load balancing;data structures application software computer applications object oriented modeling processor scheduling hybrid integrated circuits load management fluid dynamics runtime high performance computing;application software;heterogeneous cluster;high performance computing;processor scheduling;moide;runtime;hybrid integrated circuits;computer applications;support system;conjugate gradient;distributed objects;object oriented;data structures;ray tracing;load management;data access;fluid dynamics;distributed object;irregularly structured problems;object oriented modeling	This paper presents a distributed object model MOIDE for solving irregularly structured problems on cluster. The primary appeal of MOIDE is its flexible system structure that is adaptive to heterogeneous architecture of a cluster. MOIDE integrates the object-oriented and multithreaded methodologies to set up a unified computing environment. Both the shared-data access and remote messaging are incorporated in a two-layer communication mechanism for efficient inter-object communication with the common communication interface. MOIDE supports dynamic load balancing by its autonomous load scheduling technique. A runtime support system implements the MOIDE model as a platform-independent infrastructure for developing and executing irregularly structured applications. N-body, ray tracing, and conjugate gradient applications are implemented to illustrate the advantages of MOIDE model.	autonomous robot;computation;conjugate gradient method;data access;data dependency;data structure;distributed computing;distributed object;fabric computing;load balancing (computing);multithreading (computer architecture);overhead (computing);parallel computing;ray tracing (graphics);scalability;scheduling (computing);thread (computing);tree structure	Yudong Sun;Cho-Li Wang	2001	Proceedings 42nd IEEE Symposium on Foundations of Computer Science	10.1109/CLUSTR.2001.959976	data access;ray tracing;application software;parallel computing;real-time computing;computer science;operating system;distributed computing;conjugate gradient method;distributed object;computer applications;object-oriented programming	HPC	-9.76658849493249	38.64205975548719	45837
b6714ec10e5881f461864d631089af515d74b1e1	influence of cross-interferences on blocked loops: a case study with matric-vector multiply	gestion memoire;blocage;data locality;storage management;localization;bloqueo;cache memory;localizacion;blocking;antememoria;gestion memoria;antememoire;localisation;cache performance;numerical code;numerical codes;algoritmo optimo;algorithme optimal;optimal algorithm;cache conflicts interferences;cache conflict;data locality optimization	State-of-the art data locality optimizing algorithms are targeted for local memories rather than for cache memories. Recent work on cache interferences seems to indicate that these phenomena can severely affect blocked algorithms cache performance. Because of cache conflicts, it is not possible to know the precise gain brought by blocking. It is even difficult to determine for which problem sizes blocking is useful. Computing the actual optimal block size is difficult because cache conflicts are highly irregular. In this article, we illustrate the issue of precisely evaluating cross-interferences in blocked loops with blocked matrix-vector multiply. Most significant interference phenomena are captured because unusual parameters such as array base addresses are being considered. The techniques used allow us to compute the precise improvement due to blocking and the threshold value of problem parameters for which the blocked loop should be preferred. It is also possible to derive an expression of the optimal block size as a function of problem parameters. Finally, it is shown that a precise rather than an approximate evaluation of cache conflicts is sometimes necessary to obtain near-optimal performance.	approximation algorithm;block size (cryptography);blocking (computing);cpu cache;cobham's thesis;control flow;input/output base address;interference (communication);locality of reference;mathematical optimization;optimization problem	Christine Fricker;Olivier Temam;William Jalby	1995	ACM Trans. Program. Lang. Syst.	10.1145/210184.210185	parallel computing;internationalization and localization;cpu cache;computer science;theoretical computer science;distributed computing;blocking	PL	-15.090363708680602	44.741618184414115	45857
3ecf7b660ebde316e1b7e4943b965d51e2e81974	lighthouse: a taxonomy-based solver selection tool	linear algebra;machine learning;taxonomy;mathematical software	Linear algebra provides the building blocks for a wide variety of scientific and engineering simulation codes. Users face a world of continuously developing new algorithms and high-performance implementations of these fundamental calculations. In this paper, we describe new capabilities of our Lighthouse framework, whose goal is to match specific problems in the area of high-performance numerical computing with the best available solutions developed by experts. Lighthouse provides a searchable taxonomy of popular but difficult to use numerical software for dense and sparse linear algebra. Because multiple algorithms and implementations of the same mathematical operations are available, Lighthouse also classifies algorithms based on their performance. We introduce the design of Lighthouse and show some examples of the taxonomy interfaces and algorithm classification results for the preconditioned iterative linear solvers in the Parallel Extensible Toolkit for Scientific Computation (PETSc).	algorithm;code;computation;computational science;download;hoc (programming language);iterative method;linear algebra;linear system;list of numerical analysis software;numerical linear algebra;petsc;simulation;solver;sparse matrix;taxonomy (general)	Kanika Sood;Boyana Norris;Elizabeth R. Jessup	2015		10.1145/2837476.2837485	simulation;computer science;theoretical computer science	HPC	-9.27598161897739	36.01413254543283	46134
c31daa3da01f00cfd291dc3c95bc13110730b8a6	complex fans: a representation for vectors in polar form with interval attributes	programming language;interval computation;abstract data type;complex numbers;interval computations;complex fans;common lisp object system;qualitative reasoning	If we allow the magnitude and angle of a complex number (expressed in polar form) to range over an interval, it describes a semicircular region, similar to a fan; these regions are what we call complex fans. Complex numbers are a special case of complex fans, where the magnitude and angle are point intervals. Operations (especially addition) with complex numbers in polar form are complicated. What most applications do is to convert them to rectangular form, perform operations, and return the result to polar form. However, if the complex number is a Complex Fan, that transformation increases ambiguity in the result. That is, the resulting Fan is not the smallest Fan that contains all possible results. The need for minimal results took us to develop algorithms to perform the basic arithmetic operations with complex fans, ensuring the result will always be the smallest possible complex fan. We have developed the arithmetic operations of addition, negation, subtraction, product, and division of complex fans. The algorithms presented in this article are written in pseudocode, and the programs in Common Lisp, making use of CLOS (Common Lisp Object System). Translation to any other high-level programming language should be straightforward.	algorithm;allegro common lisp;circular convolution;clos network;common lisp;direct method in the calculus of variations;electrical engineering;high- and low-level;high-level programming language;linux;microsoft windows;network analysis (electrical circuits);pseudocode;sparc;windows 95;workstation	Juan J. Flores	1999	ACM Trans. Math. Softw.	10.1145/317275.317277	arithmetic;mathematical optimization;mathematical analysis;qualitative reasoning;computer science;theoretical computer science;mathematics;complex number;programming language;abstract data type;algorithm;algebra	Theory	-11.80596804474519	33.132311934231666	46137
7cca30e46d7c8673c3add42b76c93204226c4f4e	a steering and visualization toolkit for distributed applications.	distributed application;distributed computing;high performance computer;parallel applications	Parallel and high performance computing has enabled great strides to be made in advancing science and solving large problems. However, this progress is limited by the lack of needed tools and the difficulty of programming and running parallel applications. Specifically, there is a lack of needed steering and visualization tools, which can be easily integrated in existing applications. This paper presents the design of a steering and visualization toolkit to address this deficit.	parallel computing;supercomputer;vtk	Cara Stein;Daniel Bennett;Paul A. Farrell;Arden Ruttan	2006			computational science;distributed algorithm;computer science;theoretical computer science;distributed computing;distributed design patterns	HPC	-10.053435859844726	38.205907498051594	46393
cd9a401306963740f76565df91a838e9039d6f4e	replicated state space approach for parallel simulation	common random numbers;shared memory;bonferroni inequality;feasibility analysis;selection;object oriented programming;interconnection network;state space;message passing;local computation;technical report;data consistency;variance reduction;parallel processing;parallel simulation	Parallel processing offers the possibility of greatly increased performance for simulations which are computationally bound on existing machines. On shared memory machines, such as the BBN Butterfly, a natural approach is to allocate entities to be processed on different processors with locks used to prevent synchronization problems for a state space in global memory. Parallel processors having local memory only, such as the hypercube architectures, cannot use this approach. Such machines are potentially less expensive than shared memory architectures with similar local computational power, since the interconnection network is simpler. The most natural simulation paradigm for such machines, object oriented programming with interactions limited to messages, may become communications bound if the entities represented are tightly coupled. This paper presents an alternative approach based on use of replicated state spaces on each processor, and consolidation of these changes on a processor basis rather than an interaction basis to minimize message passing. The effect is to trade a parallel processing synchronization problem for a data consistency problem. The approach then relies only on a message broadcasting or passing architecture. For small degrees of parallelism, this requirement can be met by a variety of architectures. The method described is being applied to parallelize the CORBAN combat simulation for operation on a hypercube architecture as part of preliminary feasibility analysis concerning simulation support of Airland Battle Management (ALBM).	bbn butterfly;central processing unit;entity;interaction;interconnection;lock (computer science);message passing;parallel computing;parallel processing (dsp implementation);programming paradigm;semiconductor consolidation;shared memory;simulation;state space	John B. Gilmer;Jung-Pyo Hong	1986		10.1145/318242.318470	uniform memory access;shared memory;parallel processing;selection;parallel computing;message passing;simulation;distributed memory;computer science;state space;technical report;theoretical computer science;distributed computing;programming language;data consistency;object-oriented programming;variance reduction	Arch	-11.755295347863607	41.83786997839277	46434
132047df437f0bd822816d65559783da3d889405	the fuzzy barrier: a mechanism for high speed synchronization of processors	multiprocessor systems;perforation;parallelizing compilers;program transformation;hot spot;parallel programs;high speed;parallel processing;software implementation	Parallel programs are commonly written using barriers to synchronize parallel processes. Upon reaching a barrier, a processor must stall until all participating processors reach the barrier. A software implementation of the barrier mechanism using shared variables has two major drawbacks. Firstly, the execution of the barrier may be slow as it may not only require execution of several instructions and but also result in hot-spot accesses. Secondly, processors that are stalled waiting for other processors to reach the barrier are essentially idling and cannot do any useful work. In this paper, the notion of the fuzzy barrier is presented, that avoids the above drawbacks. The first problem is avoided by implementing the mechanism in hardware. The second problem is solved by extending the barrier concept to include a region of statements that can be executed by a processor while it awaits synchronization. The barrier regions are constructed by a compiler and consist of several instructions such that a processor is ready to synchronize upon reaching the first instruction in this region and must synchronize before exiting the region. When synchronization does occur, the processors could be executing at any point in their respective barrier regions. The larger the barrier region, the more likely it is that none of the processors will have to stall. Preliminary investigations show that barrier regions can be large and the use of program transformations can significantly increase their size. Examples of situations where such a mechanism can result in improved performance are presented. Results based on a software implementation of the fuzzy barrier on the Encore multiprocessor indicate that the synchronization overhead can be greatly reduced using the mechanism.	central processing unit;compiler;hot spare;multiprocessing;overhead (computing);parallax barrier;program transformation;shared variables	Rajiv Gupta	1989		10.1145/70082.68187	parallel processing;computer architecture;parallel computing;real-time computing;memory barrier;computer science;operating system;distributed computing;programming language;hot spot	Arch	-15.561298603384467	45.70437742945098	46512
46fdcf924c1f1eee02ee1c0b53e8f329faefbbfc	demonstration of automatic data partitioning techniques for parallelizing compilers on multicomputers	perfectbenchmarks;linpack;multicomputers;fortran programs;parallelizing compilers;index termsautomatic data partitioning;parallel programming;indexing terms;data distribution;data partitioning;data structures;datadistribution;scientific application programs automatic data partitioning parallelizing compilers multicomputers constraints data distribution data structures fortran programs linpack eispack libraries perfect benchmarks;eispack libraries;program compilers data structures parallel programming;program processors programming profession data structures libraries costs scalability nasa parallel languages context;program compilers;scientific application programs;constraints	An important problem facing numerous research projects on parallelizing compilers for distributed memory machines is that of automatically determining a suitable data partitioning scheme for a program. Most of the current projects leave this tedious problem almost entirely to the user. In this paper, we present a novel approach to the problem of automatic data partitioning. We introduce the notion of constraints on data distribution, and show how, based on performance considerations, a compiler identiies constraints to be imposed on the distribution of various data structures. These constraints are then combined by the compiler to obtain a complete and consistent picture of the data distribution scheme, one that ooers good performance in terms of the overall execution time. We present results of a study we performed on Fortran programs taken from the Linpack and Eispack libraries and the Perfect Benchmarks to determine the applicability of our approach to real programs. The results are very encouraging, and demonstrate the feasibility of automatic data partitioning for programs with regular computations that may be statically analyzed, which covers an extremely signiicant class of scientiic application programs.	automatic parallelization;compiler;computation;data structure;distributed memory;eispack;fortran;library (computing);lunpack;partition (database);run time (program lifecycle phase)	Manish Gupta;Prithviraj Banerjee	1992	IEEE Trans. Parallel Distrib. Syst.	10.1109/71.127259	computer architecture;parallel computing;index term;data structure;computer science;database;programming language	HPC	-12.936805684367073	37.80522842357172	46539
4a0c4755b156e29eb679b47cec753f978d1119ea	apply cluster and grid computing on parallel 3d rendering	processor scheduling;linux pc clusters;grid computing environment;linux red hat 9;subnet cluster setting;supercomputer;grid computing;distributed memory systems;data resources;large-scale resource aggregation;computing job monitoring;internet computing;globus toolkit;resource allocation;rendering (computer graphics);computational resources;disk-less slave node processors;sun grid engine;system architecture;linux;computing job schedule;system benchmark performances;cluster machines;parallel 3d rendering;resource sharing;workstation clusters;middleware;institutional boundaries;pc cluster;cluster computing;grid middleware;heterogeneous pc clusters;master node;cpu utilization;resource management;physics;internet;parallel rendering;high performance computing;high energy physics;computer architecture;master slave	A cluster is a collection of independent and cheap machines, used together as a supercomputer to provide a solution. In this paper, a PC cluster consisting of one master node and nine disk-less slave nodes (10 processors), is proposed and built for parallel rendering purposes. The system architecture and benchmark performances of this cluster are also presented. Internet computing and grid technologies promise to change the way we tackle complex problems. They will enable large-scale aggregation and sharing of computational, data and other resources across institutional boundaries. Harnessing these new technologies effectively will transform scientific disciplines ranging from high-energy physics to the life sciences. Also, in this paper, we construct two heterogeneous PC clusters for parallel rendering purpose and install Linux Red Hat 9 on each PC cluster. Then, these clusters are set to the different subnet. Therefore, we use the grid middleware lambdaobus ToolKit, to connect these two clusters to form a grid computing environment on multiple Linux PC clusters. We also install the SUN Grid Engine, to manage and monitor incoming or outgoing computing jobs and schedule the job to achieve high performance computing and high CPU utilization. The system architecture and benchmark performances of this cluster are also presented	3d rendering;apply;benchmark (computing);central processing unit;computation;computer cluster;diskless node;grid computing;job stream;linux;message passing;middleware;oracle grid engine;parallel rendering;performance;ray tracing (graphics);speedup;subnetwork;supercomputer;systems architecture	Chao-Tung Yang;Chuan-Lin Lai	2004	2004 IEEE International Conference on Multimedia and Expo (ICME) (IEEE Cat. No.04TH8763)		shared resource;shared memory;embedded system;master/slave;supercomputer;parallel computing;the internet;computer cluster;resource allocation;computer science;operating system;cpu time;parallel rendering;middleware;parallel algorithm;grid;linux kernel;grid computing	HPC	-12.501446228141598	43.34329097689619	46973
7d5ecd59ea5abefe0fa05a73246d97d4b97702d0	an introduction to the portable parallel programming language seymour	global operations portable parallel programming language seymour high level data parallel algorithms standardized global operations prefix broadcast sort compression associative read divide and conquer reduce and create cross product reduce and compress;data parallel;high level languages;parallel algorithm;programming language;parallel programming;crossed product;parallel programming language;parallel programming parallel algorithms algorithm design and analysis parallel processing concurrent computing computer architecture computer science parallel machines programming profession lan interconnection;efficient implementation;numerical algorithm;divide and conquer;parallel algorithms;parallel programming high level languages parallel algorithms	Seymour, a high-level data parallel programming language that can be used to design, express, and implement efficient portable parallel algorithms, is introduced. Seymour is based on the approach of designing parallel algorithms based on standardized global operations such as prefix, broadcast, sort, compression, and associative read. Seymour also incorporates fundamental paradigms, such as divide-and-conquer, reduce-and-create-cross-product, and reduce-and-compress, which are derived from theoretical parallel algorithms. Seymour redirects the difficulties of portability and efficiency into similar difficulties for the global operations and paradigms. However, the cost of developing efficient implementations of standardized operations on the various target architectures can be amortized over numerous algorithms. >	parallel computing;parallel programming model;programming language	Russ Miller;Quentin F. Stout	1989		10.1109/CMPSAC.1989.65063	parallel computing;embarrassingly parallel;computer science;theoretical computer science;analysis of parallel algorithms;distributed computing;parallel algorithm;programming paradigm;programming language;bulk synchronous parallel;cost efficiency;parallel programming model	HPC	-12.168447261765733	37.78160345975144	47119
5bfd9b532183bb85043e7025be7d4a5e5eff84e4	concurrency, synchronization, and speculation - the dataflow way		This chapter provides a brief overview of dataflow, including concepts, languages, historical architectures, and recent architectures. It is to serve as an introduction to and summary of the development of the dataflow paradigm during the past 45 years. Dataflow has inherent advantages in concurrency, synchronization, and speculation over control flow or imperative implementations. However, dataflow has its own set of challenges to efficient implementations. This chapter addresses the advantages and challenges of dataflow to set a context for the remainder of this issue.	concurrency (computer science);control flow;dataflow;imperative programming;programming paradigm;speculative execution;synchronization (computer science)	Krishna M. Kavi;Charles Shelor;Domenico Pace	2015	Advances in Computers	10.1016/bs.adcom.2014.10.004	dataflow architecture;computer architecture;parallel computing;computer science;theoretical computer science;dataflow	Arch	-14.535805910277436	39.58744837610935	47188
560162c55b97accf3389776f327b92acda257bd6	performance benchmarking of smart contracts to assess miner incentives in ethereum		A defining feature of the Ethereum blockchain is its ability to execute smart contracts, providing a Turing complete programming model for distributed applications in non-trusted environments. The successful operation of the Ethereum blockchain depends on whether the minersu0027 incentives (in the form of fees) to execute contracts is proportional to the minersu0027 cost (in terms of energy usage, and thus CPU usage). In general, if the received fee is not proportional to the computational cost, miners would prefer some tasks over others, thus potentially adversely affecting the continuing dependable operation of the blockchain. In this paper we design a benchmark to compare smart contract execution time with the award a miner would receive, to determine if incentives align. We present the design of the benchmarking approach and provide initial results for the Python Ethereum client running on a Mac. The results indicate that for functions in Ethereumu0027s most popular contracts the difference of reward per CPU second can be up to a factor of almost 50. In addition, contract creation, which is done once for each new contract, can be up to 6 times more lucrative than the regular execution of contract functions. Potentially, these discrepancies result in misaligned incentives that impact the dependable operation of the blockchain.	algorithmic efficiency;align (company);benchmark (computing);bitcoin;central processing unit;computation;distributed computing;ethereum;programming model;python;run time (program lifecycle phase);smart contract;turing completeness	Amjad Aldweesh;Maher Alharby;Ellis Solaiman;Aad van Moorsel	2018	2018 14th European Dependable Computing Conference (EDCC)	10.1109/EDCC.2018.00034	real-time computing;turing completeness;cpu time;programming paradigm;smart contract;benchmarking;incentive;python (programming language);benchmark (computing);distributed computing;computer science	PL	-6.848190657873221	42.98546431244554	47207
296716b48f8623c8b25008ad3a87beeedf6fa669	trace register allocation	just in time compilation;register allocation;virtual machines;trace compilation;linear scan	This paper proposes the idea of Trace Register Allocation, a register allocation approach that is tailored for just-in-time (JIT) compilation in the context of virtual machines with run-time feedback. The basic idea is to offload costly operations such as spilling and splitting to less frequently executed branches and to focus on efficient registers allocation for the hot parts of a program. This is done by performing register allocation on traces instead of on the program as a whole. We believe that the basic approach is compatible to Linear Scan, the predominant register allocation algorithm for just-in-time compilation, in both code quality and allocation time, while our design leads to a simpler and more extensible solution. This extensibility allows us to add further enhancements in order to optimize the allocation based on the run-time profile of the application and thus to outperform current Linear Scan implementations.	algorithm;compiler;extensibility;just-in-time compilation;processor register;register allocation;software quality;tracing (software);virtual machine	Josef Eisl	2015		10.1145/2814189.2814199	parallel computing;real-time computing;computer hardware;computer science;virtual machine;operating system;just-in-time compilation;static memory allocation;programming language;register allocation	PL	-18.573335348120562	36.412074345169714	47239
322d95fee258ce8977d6a208c93c40a4bc9cb5f5	burroughs b1700 memory utilization	familiar problem;intuitive notion;program working-sets;virtual memory;information content;unlimited amount;program compaction;burroughs b1700 memory utilization;segment swap	"""Squeezing more information into memory is a familiar problem to everyone who has written a program which was too large to fit into memory. Program compaction is also important to those who work on machines with virtual memory (such as the B5500); despite the almost unlimited amount of storage, one wants to keep program working-sets (collections of segments needed in core at the same time) as small as possible to reduce both the number and duration of segment swaps. In general, one seeks to raise the information content (or reduce the redundancy) of the blocks of information which one is using. In this discussion, """"information content"""" will suffice as an intuitive notion."""	a mathematical theory of communication;burroughs b1700;burroughs large systems;byte;code;data compaction;documentation;fortran;huffman coding;institute of radio engineers;locality of reference;redundancy (engineering);relevance;requirement;self-information;working set	W. T. Wilner	1972		10.1145/1479992.1480074	computer science;artificial intelligence;algorithm;memory management	PL	-8.666513943532514	32.93927937333818	47448
16c11b1cb7270ac4668a9328f4553021b79103ed	a study of real world i/o performance in parallel scientific computing	distributed memory;computation fluid dynamics;software architecture;object oriented;high per formance computing;parallel computer;parallel scientific computing	Parallel computing is indisputably present in the future of high performance computing. For distributed memory systems, MPI is widely accepted as a de facto standard. However, I/O is often neglected when considering parallel performance. In this article, a number of I/O strategies for distributed memory systems will be examined. These will be evaluated in the context of COOLFluiD, a framework for object oriented computational fluid dynamics. The influence of the system and software architecture on performance will be studied. Benchmark results will be provided, enabling a comparison between some commonly used parallel file systems. 1 Motivation and Problem Description 1.1 Parallel Programming Numerical simulation and other computationally intensive problems are often successfully tackled using parallel computing. Frequently these problems are too large to solve on a single system or the time needed to complete them makes single-CPU calculation unpractical. Successful parallelisation is usually measured by the problem “speedup”. This quantity indicates how much faster a given problem is solved on multiple processors, compared to the solution time on one processor. More often than not, this speedup is only based on the computationally intensive part of the code, and phases as program startup or data loading and saving elude the test. Also, when the ratio of computation to the input data is high enough, I/O time is negligible in the total execution time. However, when scaling to larger problem sizes (and consequently more processors), one often sees that I/O is becoming an increasingly large bottleneck. The main reason for this is that without parallel I/O, the I/O and calculation potential of a cluster quickly becomes unbalanced. This is visible both in hardware and in software; often there is but a single file server managing data for the B. K̊agström et al. (Eds.): PARA 2006, LNCS 4699, pp. 871–881, 2007. c © Springer-Verlag Berlin Heidelberg 2007 872 D. Kimpe et al. whole cluster. Moreover, traditional I/O semantics do not offer enough expressional power to coordinate requests, leading to file server congestion, reducing the already limited I/O bandwidth even further. 1.2 Computational Fluid Dynamics and COOLFluiD Computational fluid dynamics (CFD) deals with the solution of a system of partial differential equations describing the motion of a fluid. This is commonly done by discretizing these equations on a mesh. Depending on the numerical algorithm, a set of unknowns is associated with either nodes or cells of the mesh. The amount of computational work is proportional to the number of cells. For realistic problems this quickly leads to simulations larger than a single system can handle. COOLFluiD[4] is an object oriented framework for computational fluid dynamics, written in C++. It supports distributed memory parallelisation through MPI, but still allows optimized compilation without MPI for single-processor systems. COOLFluiD utilises parallel I/O for two reasons. One is to guarantee scalability of the code. The other is to hide parallelisation from the end user. During development, a goal was set to mask the differences between serial and parallel builds of COOLFluiD as much as possible. This, among other things, requires that the data files used and generated by the parallel version do not differ from those in the serial version. This depends on parallel I/O, as opening a remote file for writing on multiple processors using posix semantics is ill defined and often leads to corrupted files. 1.3 I/O in a Parallel Simulation There has been much research on the optimal parallel solution of a system of PDEs. However, relatively little study has been devoted to creating scalable I/O algorithms for this class of problems. Generally speaking, there are three reasons for performing I/O during a simulation. At the start of the program, the mesh (its geometric description and an initial value for each of the associated unknowns) needs to be loaded into memory. During the computation, snapshots of the current solution state are stored. Before ending the program, the final solution is saved. In a distributed memory machine, the mesh is divided between the nodes. Consequently each CPU requires a different portion of the mesh to operate. This offers opportunities for parallel I/O, since every processor only accesses distinct parts of the mesh. Figure 1 shows an example of a typical decomposition, and the resulting I/O access pattern. On the left, the partitioned mesh is shown. On the right, the file layout (row-major ordering) can be seen. Color indicates which states are accessed by a given CPU. A Study of Real World I/O Performance in Parallel Scientific Computing 873 Fig. 1. Decomposition and file access pattern of a 3D sphere 2 I/O Strategies Within COOLFluiD, I/O is fully abstracted. This simplifies supporting multiple file formats and access APIs, and allows run-time selection of the desired format. Mesh input and output is provided by file plugins. A file plugin offers a well defined, format independent interface to the stored mesh, and can implement any of the following access strategies: Parallel Random Access: This strategy has the potential to offer the highest performance. It allows every processor to read and write arbitrary regions of the file. If the system architecture has multiple pathways to the file this can be exploited. File plugins implementing this interface enable all CPUs to concurrently access those portions of the mesh required for their calculations. Non-Parallel Random Access: In this model, the underlying file format (or access API) does not support parallel access to the file. Only a single CPU is allowed to open the file, which will be random accessible. This strategy can be used with data present on non-shared resources, for example local disks. Non-Parallel Sequential Access: Sometimes the way data is stored prohibits meaningful true parallel access. For example, within an ASCII based file format, it is not possible to read a specific mesh element without first reading all the previous elements. This is due to the varying stride between the elements. As such, even when the OS and API allow parallel writing to the file, for mesh based applications, this cannot be done without corrupting the file structure. Note that applications that do not care about the relative ordering of the entries in the file can still use parallel I/O to read and write from this file (using shared file pointer techniques). However, as this article studies I/O patterns for mesh based applications this is not taken into consideration. 3 Performance Testing Currently, obtaining good parallel I/O performance is still somewhat of a black art. By making use of the flexibility COOLFluiD offers concerning mesh I/O, an attempt is made to explore and analyse the many different combinations of file system, API and interconnect that can be found in modern clusters. 874 D. Kimpe et al. 3.1 Test Description We will concentrate on the parallel random access pattern, since the other two access strategies are inherently non-scalable (when considering I/O bandwidth). Although COOLFluiD supports them, they are offered as a convenience. For large simulations, converting the mesh to one of the formats supporting true parallel random access is recommended. Figure 2 shows the software invoked during mesh transfers. COOLFluiD has file plugins that utilise a storage library (HDF5[3] or PnetCDF[7]) or that directly employ MPI-IO to access the mesh. Internally, these storage libraries rely on the I/O functions of MPI to access raw files. ROMIO[6] is an implementation of these I/O functions, and is used in almost all research or open source MPI implementations. ROMIO has a number of ADIO (abstract-device interface for I/O) drivers providing optimized access to a certain file system. While PVFS2[2] and NFS have specific ADIO implementations, Lustre[1], aiming for full POSIX compliance, is accessed through the generic “UFS” driver. Operating System UFS PVFS2 NFS MPI ROM−IO (MPI−IO) PHDF5 PNetCDF lustre PVFS2 COOLFluiD Fig. 2. Software stack for parallel mesh I/O For testing, the time needed to access a set of unknowns (of a given dimension) will be measured. These unknowns are stored as a linear sequence of “states” (figure 3), each state consisting of a number of doubles. The storage library (HDF5, PnetCDF) is responsible for the mapping between the virtual layout (n×d doubles) and the file layout (a linear byte sequence). In general, each state is only accessed by one CPU. However, states on the border of a partition will be accessed by multiple CPUs. States are loaded or stored in groups, where the group size is determined by the buffer size. Since MPI-IO requires file datatypes to have positive type displacements, states need to be addressed in increasing order (for a given CPU). This means that in each access round, a CPU will access buffer size sizeof(double)×d states. Because the state partitions are balanced to evenly distribute the computational cost between the CPUs, this also causes the I/O load to be balanced. 3.2 Test Hardware All tests were conducted on VIC, a 862 CPU cluster located at K.U.Leuven. The cluster has a number of different interconnect fabrics. All nodes possess a gigabit A Study of Real World I/O Performance in Parallel Scientific Computing 875 ... } d x double 0 1 2 3 ...	algorithm;algorithmic efficiency;application programming interface;benchmark (computing);bottleneck (engineering);byte;c++;coolfluid;central processing unit;compiler;computation;computational fluid dynamics;computational science;distributed memory;double-precision floating-point format;file server;file system api;gigabit;hierarchical data format;image scaling;input/output;lecture notes in computer science;library (computing);lustre (programming language);mos technology vic-ii;message passing interface;netcdf;network congestion;numerical analysis;open-source software;operating system;posix;parallel i/o;parallel computing;plug-in (computing);pointer (computer programming);random access;random-access memory;run time (program lifecycle phase);scalability;sequential access;serial ata;server (computing);simulation;software architecture;software performance testing;speedup;springer (tank);supercomputer;systems architecture;unbalanced circuit;universal flash storage;xfig	Dries Kimpe;Andrea Lani;Tiago Quintino;Stefan Vandewalle;Stefaan Poedts;Herman Deconinck	2006		10.1007/978-3-540-75755-9_104	software architecture;parallel computing;distributed memory;embarrassingly parallel;computer science;theoretical computer science;massively parallel;data-intensive computing;distributed computing;object-oriented programming;computing with memory;unconventional computing	HPC	-10.501973657077912	35.16060272372967	47583
bfd1c83cd052a5ff42f11ab1c9753b2a3bb5a73b	gumsmp : a scalable parallel haskell implementation			haskell;scalability	Malak Saleh Aljabri	2015				PL	-9.88097419911001	34.10692198138302	47617
74d22c83040e2fd891a8e59c6b3e2a654de068d5	broadway: a software architecture for scientific computing	meta-interfaces;optimization;software libraries;software architecture;scientific computing;software quality;linear algebra	Scientific programs rely heavily on software libraries. This paper describes the limitations of this reliance and shows how it degrades software quality. We offer a solution that uses a compiler to automatically optimize library implementations and the application programs that use them. Using examples from the PLAPACK parallel linear algebra library, we present our solution, which includes a simple declarative annotation language that describes certain aspects of a library’s implementation. We also show how our approach can yield simpler scientific programs that are easier to understand, modify and maintain.	broadway (microprocessor);comparison of linear algebra libraries;compiler;computational science;lapack;library (computing);software architecture;software quality	Samuel Z. Guyer;Calvin Lin	2000			computer science;theoretical computer science;software engineering	PL	-12.897962069250843	38.64206734669397	48040
ab88646e5e6640adf984e55e59ee61f2c5a3e688	parallel and distributed simulation	parallel and distributed simulation	This tutorial gives an introduction to parallel and distributed simulation systems. Issues concerning the execution of discrete-event simulations on parallel and distributed computers either to reduce model execution time or to create geographically distributed virtual environments are covered. The emphasis of this tutorial is on the algorithms and techniques that are used in the underlying simulation executive to execute simulations on parallel and distributed computing platforms.	simulation	Simon J. E. Taylor	1998	Journal of Systems Architecture	10.1016/S1383-7621(97)00054-4	computer science	HPC	-11.105445766431382	39.998521997370084	48135
3bcb430edac39041808b5de9d34b9d57421ae9a0	dsm-pm2: a portable implementation platform for multithreaded dsm consistency protocols	parallelisme;distributed system;protocols;systeme reparti;electronic mail;release consistency;sequential consistency;shared memory;protocole transmission;memoria compartida;langage java;portability;protocols electronic mail java;consistency model;protocolo transmision;parallelism;sistema repartido;col;paralelismo;portabilite;multithread;coherence;multitâche;coherencia;portabilidad;memoire partagee;java language;java;transmission protocol	DSM-PM2 is a platform for designing, implementing and experimenting multithreaded DSM consistency protocols. It provides a generic toolbox which facilitates protocol design and allows for easy experimentation with alternative protocols for a given consistency model. DSM-PM2 is portable across a wide range of clusters. We illustrate its power with figures obtained for different protocols implementing sequential consistency, release consistency and Java consistency, on top of Myrinet, Fast-Ethernet and SCI	communications protocol;consistency model;experiment;java;pm2;release consistency;sequential consistency;thread (computing)	Gabriel Antoniu;Luc Bougé	2001	Proceedings 15th International Parallel and Distributed Processing Symposium. IPDPS 2001	10.1109/IPDPS.2001.925070	shared memory;communications protocol;parallel computing;real-time computing;coherence;computer science;consistency model;operating system;release consistency;distributed computing;programming language;java;sequential consistency	Arch	-18.154118059950804	42.69180001383947	48180
b389096a8149d484e0ee115c2abf8f7c2f84766f	une bibliothèque certifiée de programmes fonctionnels bsp	certification;preuve;functional;coq;proof;fonctionnel;bsp.;bs p. keywords:library;mots-clés :bibliothèque;model of computation;bulk synchronous parallel;data structure;higher order logic	The Bulk-Synchronous Parallel ML (BSML) is a functional lan guage for BSP programming, a model of computing which allows parallel progra ms to be ported to a wide range of architectures. It is based on an extension of the ML langua ge by parallel operations on a parallel data structure called parallel vector, which is gi ven by intention. We present the certification of a library of BSML programs with the Coq proof ass istant. This library could be used for the development of certified BSP algorithms. This de velopment is an example of the usefulness of higher-order logic in the process of software ce tification of parallel applications. MOTS-CLÉS :bibliothèque, certification, preuve, fonctionnel, Coq, BS P.	algorithm;binary space partitioning;bulk synchronous parallel;concurrent data structure;coq (software);library;parallel computing;ven (currency)	Frédéric Gava	2006	Technique et Science Informatiques	10.3166/tsi.25.1621-1280	model of computation;binary space partitioning;higher-order logic;data structure;library;computer science;artificial intelligence;parallel algorithm;programming language;certification;functional programming;algorithm;bulk synchronous parallel	PL	-15.248788209790062	38.655025309609414	48251
01f21f3aacb36a425aa9213a10ccc543a11659ab	the scalable commutativity rule: designing scalable software for multicore processors	article	What fundamental opportunities for scalability are latent in interfaces, such as system call APIs? Can scalability opportunities be identified even before any implementation exists, simply by considering interface specifications? To answer these questions this paper introduces the following rule: Whenever interface operations commute, they can be implemented in a way that scales. This rule aids developers in building more scalable software starting from interface design and carrying on through implementation, testing, and evaluation.  To help developers apply the rule, a new tool named Commuter accepts high-level interface models and generates tests of operations that commute and hence could scale. Using these tests, Commuter can evaluate the scalability of an implementation. We apply Commuter to 18 POSIX calls and use the results to guide the implementation of a new research operating system kernel called sv6. Linux scales for 68% of the 13,664 tests generated by Commuter for these calls, and Commuter finds many problems that have been observed to limit application scalability. sv6 scales for 99% of the tests.	central processing unit;high- and low-level;kernel (operating system);linux;multi-core processor;operating system;posix;scalability;system call	Austin T. Clements;M. Frans Kaashoek;Nickolai Zeldovich;Robert Tappan Morris;Eddie Kohler	2013		10.1145/2517349.2522712	computer architecture;parallel computing;computer science;theoretical computer science	OS	-13.20380187327862	38.976803544822275	48276
554b8b80361179bc3c9627fc6ccccd20c7257da2	a comprehensive study on the energy efficiency of java’s thread-safe collections	software;energy consumption;data structures;licenses;programming;benchmark testing;java	Java programmers are served with numerous choices of collections, varying from simple sequential ordered lists to sophisticated hashtable implementations. These choices are well-known to have different characteristics in terms of performance, scalability, and thread-safety, and most of them are well studied. This paper analyzes an additional dimension, energy efficiency. We conducted an empirical investigation of 16 collection implementations (13 thread-safe, 3 non-thread-safe) grouped under 3 commonly used forms of collections (lists, sets, and mappings). Using micro-and real world-benchmarks (Tomcat and Xalan), we show that our results are meaningful and impactful. In general, we observed that simple design decisions can greatly impact energy consumption. In particular, we found that using a newer hashtable version can yield a 2.19x energy savings in the micro-benchmarks and up to 17% in the real world-benchmarks, when compared to the old associative implementation. Also, we observed that different implementations of the same thread-safe collection can have widely different energy consumption behaviors. This variation also applies to the different operations that each collection implements, e.g, a collection implementation that performs traversals very efficiently can be more than an order of magnitude less efficient than another implementation of the same collection when it comes to insertions.	apache tomcat;apache xalan;computer performance;hash table;java;programmer;scalability;thread safety;tree traversal	Gustavo Pinto;Kenan Liu;Fernando Castor Filho;Yu David Liu	2016	2016 IEEE International Conference on Software Maintenance and Evolution (ICSME)	10.1109/ICSME.2016.86	benchmark;programming;real-time computing;data structure;computer science;operating system;software engineering;database;programming language;java	SE	-18.38366004491007	35.54005020371228	48438
03b8f2d86ff39221ece4dc6c760efbe6317fe1f4	the distributed open network emulator: using relativistic time for distributed scalable simulation	protocols;kernel;network emulation;emulation controllability protocols large scale systems prototypes tcpip linux kernel sockets virtual prototyping;hybrid network;prototypes;controllability;tcpip;emulation;sockets;virtual prototyping;large scale simulation;design and implementation;linux;simulation model;simulation environment;large scale systems	In this paper, we present the design and implementation of The Distributed Open Network Emulator (dONE), a scalable hybrid network emulation/simulation environment. It has several novel contributions. First, a new model of time called relativistic time that combines the controllability of virtual time with the naturally flowing characteristics of wall-clock time. This enables a hybrid environment in which direct code execution can be mixed with simulation models. Second, dONE uses a new transparent object based framework called Weaves, which enables the composition of unmodified network applications and protocol stacks to create large-scale simulations. Finally, it implements a novel parallelization strategy that minimizes the number of independent timelines and offers an efficient mechanism to progress the event timeline. Our prototype implementation incorporates the complete TCP/IP stack from the Linux 2.4 kernel family and executes any application code written for the BSD sockets interface. The prototype runs on 16 processors and produces super-linear speedup in a simulation of hundred infinite-source to infinite-sink pairs.	bsd;central processing unit;emulator;linux;network emulation;object-based language;parallel computing;prototype;scalability;simulation;speedup;timeline	Craig Bergstrom;Srinidhi Varadarajan;Godmar Back	2006	20th Workshop on Principles of Advanced and Distributed Simulation (PADS'06)	10.1109/PADS.2006.34	communications protocol;emulation;parallel computing;kernel;real-time computing;simulation;controllability;computer science;operating system;simulation modeling;distributed computing;prototype;internet protocol suite;linux kernel	Networks	-12.339991317996944	43.1989844764291	48565
96d2e5456b8d7b8ad763781a16b61beabf2d7fcf	automatic command queue scheduling for task-parallel workloads in opencl	kernel;paper;performance evaluation;tesla c2050;heterogeneous systems;seismology;processor scheduling;performance;runtime;kernel runtime performance evaluation processor scheduling context schedules dynamic scheduling;scheduling opencl runtime systems;runtime systems;pattern clustering computer interfaces multiprocessing systems;scheduling;schedules;nvidia;computer science;task scheduling;opencl;context;high performance computing clusters automatic command queue scheduling task parallel workloads heterogeneous compute devices portable interface cluster nodes workflow abstraction queue device mapping command queue creation time device architectures intelligent runtime scheduler multicl snu npb opencl benchmark suite real world seismology simulation source lines runtime optimizations optimal device set runtime overhead open computing language;dynamic scheduling	"""OpenCL is a portable interface that can be used to program cluster nodes with heterogeneous compute devices. The OpenCL specification tightly binds its workflow abstraction, or """"command queue,"""" to a specific device for the entire program. For best performance, the user has to find the ideal queue -- device mapping at command queue creation time, an effort that requires a thorough understanding of the match between the characteristics of all the underlying device architectures and the kernels in the program. In this paper, we propose to add scheduling attributes to the OpenCL context and command queue objects that can be leveraged by an intelligent runtime scheduler to automatically perform ideal queue - device mapping. Our proposed extensions enable the average OpenCL programmer to focus on the algorithm design rather than scheduling and automatically gain performance without sacrificing programmability. As an example, we design and implement an OpenCL runtime for task-parallel workloads, called MultiCL, which efficiently schedules command queues across devices. Within MultiCL, we implement several key optimizations to reduce runtime overhead. Our case studies include the SNU-NPB OpenCL benchmark suite and a real-world seismology simulation. We show that, on average, users have to apply our proposed scheduler extensions to only four source lines of code in existing OpenCL applications in order to automatically benefit from our runtime optimizations. We also show that MultiCL always maps command queues to the optimal device set with negligible runtime overhead."""	algorithm design;benchmark (computing);command queue;dynamic device mapping;experiment;finite difference method;opencl api;overhead (computing);programmer;runtime system;scheduling (computing);simulation;source lines of code	Ashwin M. Aji;Antonio J. Peña;Pavan Balaji;Wu-chun Feng	2015	2015 IEEE International Conference on Cluster Computing	10.1109/CLUSTER.2015.15	parallel computing;kernel;real-time computing;performance;dynamic priority scheduling;schedule;computer science;operating system;programming language;scheduling	Arch	-6.588634301825969	44.21571098047386	48736
2454743d13ceedd359a6bbb3d170d0b8752eb490	unity to uc: a case study in the derivation of parallel programs	porous media;parallel programs;computer simulation	This paper describes the use of the UNITY [6] notation and the UC compiler [2] in the design of parallel programs for execution on the Connection Machine CM2 (CM). We illustrate our ideas in the context of a computer simulation of particle diffusion and aggregation in a porous media.	uc browser;unity	Indranil Chakravarty;Michael F. Kleyn;Thomas Y. C. Woo;Rajive L. Bagrodia;Vernon Austel	1991		10.1007/3-540-55160-3_30	computational science;parallel computing;computer science;distributed computing	NLP	-9.370059995967218	37.22699211981677	48762
fa1e1aa8af836e7e4b7bbdb204fb41b0e622c4fe	advanced mpi including new mpi-3 features	real application;example code;advanced mpi;newest version;hybrid programming;multithreaded communication;dynamic process;one-sided communication;new feature;code example;mpi-3 feature;advanced topic	This tutorial will cover several advanced topics in MPI. We will cover one-sided communication, dynamic processes, multithreaded communication and hybrid programming, and parallel I/O. We will also discuss new features in the newest version of MPI, MPI-3, which is expected to be officially released a few days before this tutorial. The tutorial will be heavily example driven; we will introduce concepts by using code examples based on scenarios found in real applications. The example codes will be available for attendees to run on their laptops.	message passing interface	William Gropp;Ewing L. Lusk;Rajeev Thakur	2012		10.1007/978-3-642-33518-1_5	computational science;computer science;theoretical computer science	HPC	-8.528165884534339	40.18035947966119	48976
52be81d4d5adf230d1cb106d16464648689eba8a	a flexible and inexpensive method of monitoring program execution in a digital computer	electronic circuits;computer program;convergence;computer aided instruction;iterative methods;computerized monitoring;registers;computerized monitoring computer errors algorithms registers computer aided instruction convergence iterative methods electronic circuits humans;algorithms;humans;computer errors	A method of monitoring the program execution in a digital computer on the basis of the flow diagram of the computing program has been devised. A comparatively low-cost equipment for monitoring a maximum of 64 boxes in a flow diagram has been constructed. The monitoring method is flexible and convenient in its application. It can be used in connection with relative or symbolic addresses, compilers, etc. The user must provide only a flow diagram drawn on translucent paper in a certain form and the information to correlate this diagram with the computing program. A subroutine modifies the computing program as needed for the monitoring purpose and restores it to its original form when the user so desires. The monitoring introduces only a very small increase in computing time, requiring for each call-up of a box in the flow diagram only a time amounting to that needed for two simple unconditional jumps. The monitor can be used to present during the computation a visual dynamic picture of the progress of the program and to register, on occurrence, the whereabouts of an interruption, thus facilitating the tracing of the error. The principle of the monitoring method and the subroutine program, and the essentials of the constructed monitor equipment, are described in detail.	computer	Frank F. Tsui	1961	IRE Trans. Electronic Computers	10.1109/TEC.1961.5219196	electronic circuit;convergence;computer hardware;computer science;electrical engineering;theoretical computer science;operating system;iterative method;processor register	Graphics	-13.763146551630106	32.961464120701784	49166
0dfb42d070bcad927455271edd9f5aa81a7e8fe9	implementing scalable parallel search algorithms for data-intensive applications	estensibilidad;arbre recherche;algoritmo paralelo;data intensive application;parallel algorithm;algoritmo busqueda;shared memory;algorithme recherche;memoria compartida;search algorithm;distributed computing;application intensive;algorithme parallele;large scale;search trees;intensive application;arbol investigacion;calculo repartido;distributed computing environment;extensibilite;scalability;escala grande;search tree;calcul reparti;memoire partagee;echelle grande	Scalability is a critical issue in the design of parallel software for large-scale search problems. Previous research has not addressed this issue for data-intensive applications. We describe the design of a library for parallel search that focuses on efficient data and search tree management for such applications in distributed computing environments.	algorithm;data-intensive computing;distributed computing;scalability;search tree	Laszlo Ladányi;Ted K. Ralphs;Matthew J. Saltzman	2002		10.1007/3-540-46043-8_60	shared memory;parallel computing;scalability;computer science;operating system;distributed computing;parallel algorithm;search tree;distributed computing environment;search algorithm	HPC	-17.069867728997647	43.1815934016292	49428
79c709130f185d6a173f76c07f02e92d0bdc09ae	design and performance issues of cholesky and lu solvers using upcblas	libraries;upcblas;pgas memory model;shared memory;software libraries;pgas unified parallel c language;parallel numerical application cholesky solver lu solver upcblas partitioned global address space pgas language shared memory productivity locality exploitation large scale distributed memory system parallel numerical library dense matrix computation pgas unified parallel c language upc language library interface pgas memory model systems of equation cholesky factorization lu factorization mpi version scalapack parallel solver;lu pgas upc upcblas scalapack matrix computations cholesky;cholesky;parallel numerical application;parallel programming;parallel solver;locality exploitation;partitioned global address space;upc;lu;cholesky factorization;arrays;parallel numerical library;c language;dense matrix computation;libraries message systems instruction sets electronics packaging equations vectors arrays;vectors;library interface;matrix decomposition;cholesky solver;message systems;pgas language;distributed shared memory systems;upc language;lu solver;message passing;systems of equation;matrix computations;pgas;mpi version;productivity;software libraries c language distributed shared memory systems matrix decomposition message passing parallel languages parallel programming;electronics packaging;parallel languages;lu factorization;large scale distributed memory system;instruction sets;scalapack	Partitioned Global Address Space (PGAS) languages offer programmers a shared memory view that increases their productivity and allow locality exploitation to obtain good performance on current large-scale distributed memory systems. UPCBLAS is a parallel numerical library for dense matrix computations using the PGAS Unified Parallel C (UPC) language. The interface of this library exploits the characteristics of the PGAS memory model and thus it is easier to use than MPI-based libraries. This paper addresses the implementation of solvers of systems of equations through Cholesky and LU factorizations in UPC using UPCBLAS. The developed codes are experimentally evaluated and compared to the MPI versions using ScaLAPACK. Parallel solvers of equations are present in many parallel numerical applications and they have been traditionally developed in MPI. This work shows that UPCBLAS can be considered as a good alternative to the MPI-based libraries for increasing the productivity of numerical application developers.	cholesky decomposition;code;computation;distributed memory;experiment;lu decomposition;library (computing);locality of reference;message passing interface;numerical analysis;partitioned global address space;programmer;scalapack;shared memory;sparse matrix;unified parallel c (upc)	Jorge Gonz&#x00E1;lez-Dom&#x00ED;nguez;Osni Marques;María J. Martín;Guillermo L. Taboada;Juan Touriño	2012	2012 IEEE 10th International Symposium on Parallel and Distributed Processing with Applications	10.1109/ISPA.2012.14	parallel computing;computer science;theoretical computer science;partitioned global address space;operating system;distributed computing;cholesky decomposition	HPC	-11.166865966235662	37.61328012290291	49592
a2305a57b0025c7e6169e97a6c057ba5021df98d	parallelism and array processing	parallel computing;computers;digital computers;array processing;processing;general and miscellaneous mathematics computing and information science;concurrent computing;programming language;cray1 star100 bibliography computation concurrency data history;multiple processor systems;data processing;arrays;computer architecture;concurrency;parallel computer architecture;parallel processing computers concurrent computing pipeline processing arrays computer architecture hardware;array processors;programming 990200 mathematics computers;document types;functional unit;reviews;parallel computing array processing computer architecture computer history concurrency multiple processor systems parallel algorithms;architecture;parallel processing;computer history;pipeline processing;programming languages;hardware;parallel algorithms	Modern computing, as well as the historical development of computing, has been dominated by sequential monoprocessing. Yet there is the alternative of parallelism, where several processes may be in concurrent execution. This alternative is discussed, in which the main developments involving parallelism are considered both from the standpoint of computing systems and that of applications than can exploit such systems. The account seeks to treat parallelism in a historical context, and to identify all the main aspects of concurrency in computation right up to the present time. The review includes a discussion both of parallel computer architectures and functional units as components in these architectures. The important question of limitations in concurrency is considered, and there is an account of typical numerical problems which contain parallelism, as well as languages appropriate to code these problems. Included will be a brief consideration of what use parallelism might be In the field of data processing.	array processing;parallel computing	Vasilii Zhakarov	1984	IEEE Trans. Computers	10.1109/TC.1984.5009314	parallel processing;computer architecture;parallel computing;concurrent computing;concurrency;data processing;computer science;processing;theoretical computer science;architecture;data parallelism;programming language;instruction-level parallelism;implicit parallelism;task parallelism	Arch	-14.18846531248049	40.40812815261709	49610
30aa9ce87ede4418d2a772f1a435bf2eab144e0e	efficient execution of skepu skeleton programs on the low-power multicore processor myriad2	energy efficiency;embedded chip;heterogeneous computing;loading;myriad2;skeleton;skeleton programming;skepu;multicore processing;multicore computing;programming;parallel processing;containers	SkePU is a state-of-the-art skeleton programming library for high-level portable programming and efficient execution on heterogeneous parallel computer systems, with a publically available implementation for general-purpose multicore CPU and multi-GPU systems. This paper presents the design, implementation and evaluation of a new back-end of the SkePU skeleton programming library for the new low-power multicore processor Myriad2 by Movidius Ltd. This enables seamless code portability of SkePU applications across both HPC and embedded (Myriad2) parallel computing systems, with decent performance, on these architecturally very diverse types of execution platforms.	automatic vectorization;c++;central processing unit;compiler;computation;embedded system;general-purpose markup language;graphics processing unit;high- and low-level;library (computing);low-power broadcasting;multi-core processor;parallel computing;seamless3d;skeleton (computer programming);software portability	Sebastian Thorarensen;Rosandra Cuello;Christoph W. Kessler;Lu Li;Brendan Barry	2016	2016 24th Euromicro International Conference on Parallel, Distributed, and Network-Based Processing (PDP)	10.1109/PDP.2016.123	parallel processing;computer architecture;parallel computing;real-time computing;computer science;skeleton	HPC	-5.955670961558803	44.409604043023464	49790
b6df77c1c4bab3dcdc5598a9c9ff47c5cc8568f9	practical floating-point divergence detection		Reducing floating-point precision allocation in HPC programs is of considerable interest from the point of view of obtaining higher performance. However, this can lead to unexpected behavioral deviations from the programmer’s intent. In this paper, we focus on the problem of divergence detection: when a given floating-point program exhibits different control flow (or differs in terms of other discrete outputs) with respect to the same program interpreted under reals. This problem has remained open even for everyday programs such as those that compute convex-hulls. We propose a classification of the divergent behaviors exhibited by programs, and propose efficient heuristics to generate inputs causing divergence. Our experimental results demonstrate that our input generation heuristics are far more efficient than random input generation for divergence detection, and can exhibit divergence even for programs with thousands of inputs.	control flow;heuristic (computer science);programmer;vergence	Wei-Fan Chiang;Ganesh Gopalakrishnan;Zvonimir Rakamaric	2015		10.1007/978-3-319-29778-1_17	simulation;computer science;theoretical computer science;algorithm	PL	-18.652632132784756	38.36795979016508	49872
cdb1874e279320c5ca23bf920304fdd7859b7764	an optimal skew-insensitive join and multi-join algorithm for distributed architectures	modelizacion;distributed system;base relacional dato;algoritmo paralelo;base donnee;systeme reparti;parallel algorithm;computational techniques;equilibrio de carga;efficient algorithm;equilibrage charge;database;base dato;intelligence artificielle;parallel database system;relational database;approche deterministe;algorithme parallele;deterministic approach;synchronisation;modelisation;parallel databases;sistema repartido;synchronization;algorithme reparti;enfoque determinista;load balancing;base donnee relationnelle;base donnee parallele;artificial intelligence;algoritmo repartido;load balance;sincronizacion;inteligencia artificial;distributed algorithm;modeling;cost model;distributed architecture	The development of scalable parallel database systems requires the design of efficient algorithms for the join operation which is the most frequent and expensive operation in relational database systems. The join is also the most vulnerable operation to data skew and to the high cost of communication in distributed architectures. In this paper, we present a new parallel algorithm for join and multijoin operations on distributed architectures based on an efficient semijoin computation technique. This algorithm is proved to have optimal complexity and deterministic perfect load balancing. Its tradeoff between balancing overhead and speedup is analyzed using the BSP cost model which predicts a negligible join product skew and a linear speed-up. This algorithm improves our fa join and sfa join algorithms by reducing their communication and synchronization cost to a minimum while offering the same load balancing properties even for highly skewed data.	analysis of algorithms;computation;computational complexity theory;join (sql);linear logic;load balancing (computing);overhead (computing);parallel algorithm;parallel database;relational algebra;relational database;scalability;semiconductor industry;speedup	Mostafa Bamha	2005		10.1007/11546924_60	synchronization;distributed algorithm;parallel computing;computer science;load balancing;theoretical computer science;database;distributed computing	DB	-18.220409942139742	44.58865419470625	49915
4f74d666dd2abfcd0e4398a4a9d69d8930b65b13	the peppher composition tool: performance-aware dynamic composition of applications for gpu-based systems	task based peppher runtime system peppher composition tool performance aware dynamic composition gpu based system graphics processing unit c c based component multicore system manycore system multigpu based system computational functionality sequential implementation variant parallel implementation variant execution unit meta data run time context high level programming front end;paper;object oriented methods;tesla c2050;heterogeneous systems;peppher project;performance;gpu based systems;tesla c1060;cuda;graphics processing units;performance portability;datavetenskap datalogi;parallel processing graphics processing units multiprocessing systems object oriented methods;nvidia;component model;multiprocessing systems;computer science;parallel processing	The PEPPHER component model defines an environment for annotation of native C/C++ based components for homogeneous and heterogeneous multicore and manycore systems, including GPU and multi-GPU based systems. For the same computational functionality, captured as a component, different sequential and explicitly parallel implementation variants using various types of execution units might be provided, together with metadata such as explicitly exposed tunable parameters. The goal is to compose an application from its components and variants such that, depending on the run-time context, the most suitable implementation variant will be chosen automatically for each invocation. We describe and evaluate the PEPPHER composition tool, which explores the application's components and their implementation variants, generates the necessary low-level code that interacts with the runtime system, and coordinates the native compilation and linking of the various code units to compose the overall application code. With several applications, we demonstrate how the composition tool provides a high-level programming front-end while effectively utilizing the task-based PEPPHER runtime system (StarPU) underneath.	c++;compiler;component-based software engineering;computation;execution unit;graphics processing unit;high- and low-level;high-level programming language;manycore processor;multi-core processor;run time (program lifecycle phase);runtime system	Usman Dastgeer;Lu Li;Christoph W. Kessler	2012	2012 SC Companion: High Performance Computing, Networking Storage and Analysis	10.1109/SC.Companion.2012.97	parallel processing;computer architecture;parallel computing;real-time computing;performance;computer science;operating system;component object model;distributed computing;programming language	HPC	-6.789670116660692	43.94734285585235	50119
109e885380f46c0cb573cc75d270eb7673a99a8b	a logic simulation engine based on a modified data flow architecture	logic simulation engine;modified data flow architecture;distributed algorithm;dynamic data;discrete event simulation;data flow;distributed algorithms	Logic simulation contains a high degree of dynamic parallelism which can be exploited by a data flow architecture. This paper fast develops an optimum application-specific data flow architecture for accelerating the standard event driven logic simulation. In the second part, a new conservative distributed simulation algorithm is developed which minimizes the use of NULL messages. A pseudo-dynamic data flow architecture is then developed to implement this distributed algorithm efficiently. Finally, a comparison of the standard event driven algorithm based data flow accelerator is made to the distributed simulation algorithm based accelerator on several benchmark circuits. It is shown that the distributed simulation algorithm on the specialized dam flow accelerator outperforms the standard event driven algorithm based data flow accelerator by a factor of three in most cases.	benchmark (computing);dataflow architecture;distributed algorithm;dynamic data;dynamic programming;event-driven programming;logic simulation;null (sql);parallel computing	Ausif Mahmood;William I. Baker;Jayantha A. Herath;Anura P. Jayasumana	1992		10.1145/304032.304137	data flow diagram;distributed algorithm;parallel computing;real-time computing;dynamic data;simulation software;computer science;theoretical computer science;discrete event simulation;logic simulation	EDA	-8.219577247711923	42.11996277859837	50137
34acbf261d477f75a15a0883a02af53e45380154	parallel simulation techniques for telecommunication network modelling	computer software programming computer software communication	In this thesis, we consider the application of parallel simulation to the performance modelling of telecommunication networks. A largely automated approach was f i rs t explored using a parallelizing compiler to speedup the simulation of simple models of circuit-switched networks. This yielded reasonable results for relatively l i t t l e effor t compared w i t h other approaches. However, more complex simulation models of packetand cell-based telecommunication networks, requiring the use of discrete event techniques, need an alternative approach. A cri t ical review of parallel discrete event simulation indicated that a distr ibuted model components approach using conservative or opt imist ic synchronization would be wor th exploring. Experiments were therefore conducted using simulation models of queueing networks and Asynchronous Transfer Mode ( A T M ) networks to explore the potent ia l speed-up possible using this approach. Specifically, i t is shown tha t these techniques can be used successfully to speed-up the execution of useful telecommunication network simulations. A detailed investigation has demonstrated that conservative synchronization performs very well for applications w i t h good lookahead properties and sufficient message traff ic density and, given such properties, w i l l significantly ou tper fo rm opt imist ic synchronization. Opt imis t ic synchronization, however, gives reasonable speed-up for models w i t h a wider range of such properties and can be optimized for speed-up and memory usage at r un t ime. Thus, i t is confirmed as being more generally applicable par t icular ly as model development is somewhat easier than for conservative synchronization. This has to be balanced against the more di f f icul t task of developing and debugging an opt imis t ic synchronization kernel and the application models.	circuit switching;compiler;debugging;parallel computing;parsing;simulation;speedup;synchronization (computer science);telecommunications network;ical	Alan Hind	1994			real-time computing;computer science;theoretical computer science;distributed computing	AI	-12.82225949285272	42.05886542945744	50227
0d9c39200e541ce7c5a2f3cfa54302c2c9bc631a	efficient detection of determinacy races in cilk programs	directed acyclic graph;asymptotic efficiency;shared memory;programming language;least common ancestor;linear time;series parallel	A parallel multithreaded program that is ostensibly deterministic may nevertheless behave nondeterministically due to bugs in the code. These bugs are called determinacy races, and they result when one thread updates a location in shared memory while another thread is concurrently accessing the location. We have implemented a provably efficient determinacy-race detector for Cilk, an algorithmic multithreaded programming language. If a Cilk program is run on a given input data set, our debugging tool, which we call the ``Nondeterminator,'' either determines at least one location in the program that is subject to a determinacy race, or else it certifies that the program is race free when run on the data set. The core of the Nondeterminator is an asymptotically efficient serial algorithm (inspired by Tarjan's nearly linear-time least-common-ancestors algorithm) for detecting determinacy races in series-parallel directed acyclic graphs. For a Cilk program that runs in T time on one processor and uses v shared-memory locations, the Nondeterminator runs in O(T α(v,v)) time, where α is Tarjan's functional inverse of Ackermann's function, a very slowly growing function which, for all practical purposes, is bounded above by 4 . The Nondeterminator uses at most a constant factor more space than does the original program. On a variety of Cilk program benchmarks, the Nondeterminator exhibits a slowdown of less than 12 compared with the serial execution time of the original optimized code, which we contend is an acceptable slowdown for debugging purposes.	ackermann function;cilk plus;debugger;debugging;directed acyclic graph;emoticon;indeterminacy in concurrent computation;programming language;run time (program lifecycle phase);sensor;sequential algorithm;series and parallel circuits;series-parallel graph;shared memory;software bug;thread (computing);time complexity	Mingdong Feng;Charles E. Leiserson	1997	Theory of Computing Systems	10.1007/s002240000120	time complexity;shared memory;series and parallel circuits;discrete mathematics;computer science;theoretical computer science;mathematics;programming language;directed acyclic graph;algorithm;lowest common ancestor	PL	-13.072704185830457	32.744203531420816	50306
9e0536767e252dcbc4c02c782ca3722c45f759c0	colthpf, a run-time support for the high-level co-ordination of hpf tasks		This paper describesCOLTHPF, a run-time support specifically designed for the co-ordination of concurrent and communicating HPF tasks.COLTHPF is implemented on top of MPI and requires only small changes to the run-time support of the HPF compiler used. Although the COLTHPF API can be used directly by programmers to write applications as a flat collection of interacting data-parallel tasks, we believe that it can be used more productively through a compiler of a simple high-level co-ordination languagewhich facilitates programmers in structuring a set of data-parallel HPF tasks according to common forms oftask-parallelism. The paper outlines design and implementation issues, and discusses the main differences from other approaches to exploiting task parallelism in the HPF framework. We show how COLTHPF can be used to implement common forms of parallelism, e.g. pipeline and processor farms, and we present experimental results regarding both synthetic micro-benchmarks and sample applications. The experiments were conducted on an SGI/Cray T3E using Adaptor, a public domain HPF compiler. Copyright  1999 John Wiley & Sons, Ltd.	application programming interface;compiler;cray t3e;data parallelism;experiment;high performance fortran;high- and low-level;interaction;john d. wiley;parallel computing;pipeline (computing);programmer;synthetic intelligence;task parallelism	Salvatore Orlando;Raffaele Perego	1999	Concurrency - Practice and Experience	10.1002/(SICI)1096-9128(199907)11:8%3C407::AID-CPE435%3E3.0.CO;2-0	computer architecture;parallel computing;public domain;computer hardware;computer science	PL	-6.738264387730177	43.60863154383562	50525
2fd5b337a401edda60d0b4d9d790a0921644de22	concurrent simulation at the switch, gate, and register levels			simulation;switch	Ernst G. Ulrich	1985			computer science;real-time computing;computer architecture	EDA	-10.00777506141208	43.843370420552475	50583
87bbcef65b7bfcfa9be36107777ea72e11296b3e	hybrid particle-field molecular dynamics simulations: parallelization and benchmarks	molecular dynamics;parallelization;coarse graining	The parallel implementation of a recently developed hybrid scheme for molecular dynamics (MD) simulations (Milano and Kawakatsu, J Chem Phys 2009, 130, 214106) where self-consistent field theory (SCF) and particle models are combined is described. Because of the peculiar formulation of the hybrid method, considering single particles interacting with density fields, the most computationally expensive part of the hybrid particle-field MD simulation can be efficiently parallelized using a straightforward particle decomposition algorithm. Benchmarks of simulations, including comparisons of serial MD and MD-SCF program profiles, serial MD-SCF and parallel MD-SCF program profiles, and parallel benchmarks compared with efficient MD program GROMACS 4.5.4 are tested and reported. The results of benchmarks indicate that the proposed parallelization scheme is very efficient and opens the way to molecular simulations of large scale systems with reasonable computational costs.	algorithm;analysis of algorithms;benchmark (computing);gromacs;hartree–fock method;interaction;molecular dynamics;molecular modelling;parallel computing;particle filter;quantum field theory;simulation	Ying Zhao;Antonio De Nicola;Toshihiro Kawakatsu;Giuseppe Maria Milano	2012	Journal of computational chemistry	10.1002/jcc.22883	computational science;molecular dynamics;chemistry;granularity;theoretical computer science;computational chemistry;physics	HPC	-5.144991219885102	37.69624858771	50600
702d32c41a631beaab53aad66dc89d700af08e38	the parallel sysplex as smp: viewing performance, capacity, and scalability through a familiar lens			ibm parallel sysplex;scalability	Irwin F. Kraus	1996			parallel computing;scalability;computer science	HPC	-9.5860929022409	42.42410755775682	50606
2d513761505383f90c5914a2a85c9190a1d6dcc2	early evaluation of directive-based gpu programming models for productive exascale computing	hand-written gpu codes;early evaluation;abstraction levels;cuda gpus;program functionality;reasonable performance;parallel programming;parallel architectures;graphics processing units;directive-based model;productive exascale computing;different level;software performance evaluation;directive-based gpu programming model early evaluation;programming effort levels;exascale computing;gpu architecture programming;gpu code;programming gpu architecture;programming effort;high performance computing;directive-based gpu programming model;programming complexity;program tunability;program debuggability;graphics processing unit-based parallel computer architectures;program scalability;performance potential;fault tolerance;markov model	Graphics Processing Unit (GPU)-based parallel computer architectures have shown increased popularity as a building block for high performance computing, and possibly for future Exascale computing. However, their programming complexity remains as a major hurdle for their widespread adoption. To provide better abstractions for programming GPU architectures, researchers and vendors have proposed several directive-based GPU programming models. These directive-based models provide different levels of abstraction, and required different levels of programming effort to port and optimize applications. Understanding these differences among these new models provides valuable insights on their applicability and performance potential. In this paper, we evaluate existing directive-based models by porting thirteen application kernels from various scientific domains to use CUDA GPUs, which, in turn, allows us to identify important issues in the functionality, scalability, tunability, and debuggability of the existing models. Our evaluation shows that directive-based models can achieve reasonable performance, compared to hand-written GPU codes.	cuda;code;computer architecture;directive (programming);graphics processing unit;parallel computing;principle of abstraction;programming complexity;scalability;supercomputer	Seyong Lee;Jeffrey S. Vetter	2012	2012 International Conference for High Performance Computing, Networking, Storage and Analysis		data modeling;programming;fault tolerance;computer architecture;parallel computing;kernel;computer science;theoretical computer science;operating system;distributed computing;markov model;programming language;computational model	HPC	-6.577147670281371	44.55041422469058	50626
bfedb67be6a01f25b441845dc9217a4f2f78d282	qcmpi: a parallel environment for quantum computing	parallel computing;schrodinger equation;03 67 lx;quantum algorithms;03 67 ac;quantum fourier transform;quantum computer;quantum algorithm;message passing inter face;density matrix;parallel computer;fortran;parallel processing;quantum simulation	Article history: Received 19 August 2008 Received in revised form 17 November 2008 Accepted 26 November 2008 Available online 30 November 2008 PACS: 03.67.Ac 03.67.Lx	central processing unit;controlled not gate;density matrix;error detection and correction;fortran;hamiltonian (quantum mechanics);integer factorization;matrix mechanics;message passing interface;model of computation;numerical analysis;one-way function;parallel computing;quantum algorithm;quantum computing;quantum decoherence;qubit;qutrit;schrödinger;shor's algorithm;simulation;time complexity;wolfram mathematica	Frank Tabakin;Bruno Juliá-Díaz	2009	Computer Physics Communications	10.1016/j.cpc.2008.11.021	quantum operation;parallel processing;quantum fourier transform;shor's algorithm;discrete mathematics;quantum information;computer science;theoretical computer science;quantum network;quantum capacity;analysis of parallel algorithms;mathematics;quantum computer;quantum process;quantum algorithm;physics;algorithm;one-way quantum computer;quantum mechanics;quantum phase estimation algorithm;quantum error correction	HPC	-4.639283673735595	34.7034700053259	50679
ccda83190e3c0af05c43b669f27a7f32575e3e71	quasi monte carlo integration in grid environments: further leaping effects	distributed system;configuracion salto rana;haute performance;systeme reparti;metodo monte carlo;integracion numerica;leap frog configuration;sous sequence;quasi monte carlo integration;distributed computing;configuration saut grenouille;methode monte carlo;grid;leap frog technique;sistema repartido;subsequences;numerical integration;rejilla;monte carlo method;quasi monte carlo;alto rendimiento;grille;calculo repartido;integration numerique;grid computing;high performance;calcul reparti	The splitting of Quasi-Monte Carlo (QMC) point sequences into interleaved substreams has been suggested to raise the speed of distributed numerical integration and to lower the traffic on the network. The usefulness of this approach in GRID environments is discussed. After specifying requirements for using QMC techniques in GRID environments in general we review and evaluate the proposals made in literature so far. In numerical integration experiments we investigate the quality of single leaped QMC point sequence substreams, comparing the respective properties of Sobol’, Halton, Faure, Niederreiter-Xing, and Zinterhof sequences in detail. Numerical integration results obtained on a distributed system show that leaping sensitivity varies tremendously among the different sequences and we provide examples of deteriorated results caused by leaping effects, especially in heterogeneous settings which would be expected in GRID environments.	computation;distributed computing;elegant degradation;experiment;failure;monte carlo integration;monte carlo method;numerical analysis;numerical integration;quantum monte carlo;quasi-monte carlo method;requirement	Heinz Hofbauer;Andreas Uhl;Peter Zinterhof	2006	Parallel Processing Letters	10.1142/S0129626406002654	quasi-monte carlo method;simulation;numerical integration;computer science;distributed computing;grid;algorithm;grid computing;monte carlo method	HPC	-17.886497158900315	43.972467922242636	50754
c851b593709e870627e761000bfe0270ff6fb338	"""a distributed rendering system """"on demand rendering system"""""""	distributed system;parallel rendering;haute performance;systeme reparti;visualizacion;parallel computation;large scale;visualization;rendering system;calculo paralelo;sistema repartido;distributed rendering;visualisation;network traffic;high performance computer;parallel computer;alto rendimiento;parallel architecture;rendu infographie;rendering computer graphics;high performance;calcul parallele	In parallel computing, providing the way for visualizing a large scale dataset becomes demanding. To provide a necessary levels of performance, there have been several software-based rendering system developed for general purpose parallel architectures. We have been developing the distributed rendering system focused on reducing network traffic to visualize a large scale dataset especially 3D geometric data. This paper describes the design of our distributed parallel rendering server (called On Demand Rendering System), and the possibility for applying this system to the visualization of high performance computing.	parallel rendering	Hideo Miyachi;Toshihiko Kobayashi;Yasuhiro Takeda;Hiroshi Hoshino;Xiuyi Jin	2000		10.1007/3-540-39999-2_56	embedded system;tiled rendering;parallel computing;simulation;image-based modeling and rendering;visualization;rendering;computer science;operating system;parallel rendering;texture memory;alternate frame rendering;software rendering;computer graphics (images)	Graphics	-17.545479529012162	42.615889522965034	50837
a6459a48b4a9852e5192995b68d07516b8aec82e	dynamic memory abp work-stealing	file attente;distributed system;work stealing;systeme reparti;overflow computer arithmetics;observable;multiprocessor;equilibrio de carga;multiprogrammation;equilibrage charge;distributed computing;queue;multiprogramming;effet dimensionnel;synchronisation;sistema repartido;marcador;pointer;multiprogramacion;synchronization;size effect;robustesse;indexation;load balancing;rebasamiento capacidad;calculo repartido;pointeur;robustness;depassement capacite;load balance;sincronizacion;efecto dimensional;multiprocesador;fila espera;calcul reparti;robustez;multiprocesseur	The non-blocking work-stealing algorithm of Arora, Blumofe, and Plaxton (hencheforth ABP work-stealing) is on its way to becoming the multiprocessor load balancing technology of choice in both Industry and Academia. This highly efficient scheme is based on a collection of array-based deques with low cost synchronization among local and stealing processes. Unfortunately, the algorithm’s synchronization protocol is strongly based on the use of fixed size arrays, which are prone to overflows, especially in the multiprogrammed environments which they are designed for. This is a significant drawback since, apart from memory inefficiency, it means users must tailor the deque size to accommodate the effects of the hard-to-predict level of multiprogramming, and add expensive blocking overflow-management mechanisms. This paper presents the first dynamic memory work-stealing algorithm. It is based on a novel way of building non-blocking dynamic memory ABP deques by detecting synchronization conflicts based on “pointercrossing” rather than “gaps between indexes” as in the original ABP algorithm. As we show, the new algorithm dramatically increases robustness and memory efficiency, while causing applications no observable performance penalty. We therefore believe it can replace array-based ABP work-queues, eliminating the need to add application specific overflow mechanisms.	alternating bit protocol;blocking (computing);computer multitasking;double-ended queue;load balancing (computing);locality of reference;memory management;multiprocessing;non-blocking algorithm;observable;robustness (computer science);sensor;work stealing	Danny Hendler;Yossi Lev;Nir Shavit	2004		10.1007/978-3-540-30186-8_14	synchronization;parallel computing;real-time computing;computer science;load balancing;operating system;distributed computing;programming language;algorithm	HPC	-16.178489431685122	44.87447262718899	50985
671002c5ff17664b55b0b1af5037114bd0526cab	a taxonomy of task-based technologies for high-performance computing		Task-based programming models for shared memory, for example OpenMP and Cilk, have existed for decades, and are well documented. However, with the increase in heterogeneous, many-core and parallel systems, a number of research-driven projects have developed more diversified task-based support, employing various programming and runtime features. Unfortunately, despite the fact that dozens of different task-based systems exist today and are actively used for parallel and high-performance computing, no comprehensive overview or classification of task-based technologies for HPC exists. In this paper, we provide an initial task-focused taxonomy for HPC technologies, which covers both programming interfaces and runtime mechanisms. We demonstrate the usefulness of our taxonomy by classifying state-of-the-art task-based environments in use today.	application programming interface;categorization;cilk plus;documentation;ecosystem;manycore processor;multi-core processor;online and offline;openmp;parallel computing;programmer;programming paradigm;scheduling (computing);shared memory;supercomputer;taxonomy (general)	Peter Thoman;Khalid Hasanov;Kiril Dichev;Roman Iakymchuk;Xavier Aguilar;Philipp Gschwandtner;Pierre Lemarinier;Stefano Markidis;Herbert Jordan;Erwin Laure;Kostas Katrinis;Dimitrios S. Nikolopoulos;Thomas Fahringer	2017		10.1007/978-3-319-78054-2_25	runtime system;parallel computing;distributed computing;programming paradigm;cilk;fault tolerance;computer science;supercomputer;shared memory	HPC	-7.778785729402736	44.67873061665076	51006
a32f16bd806513898c223c201f245415e3c651d8	flexpar: reconfigurable middleware for parallel environments	flexpar;communicating sequential process;heterogeneous environment;parallel programming;flexible component based middleware;qa75 electronic computers computer science;next generation;middleware java system recovery parallel processing portable computers current supplies parallel programming supercomputers prototypes libraries;middleware;reconfigurable middleware;flexible component based middleware flexpar reconfigurable middleware parallel processing dual core processors parallel programming;dual core processors;parallel programs;parallel applications;parallel processing;parallel programming middleware	Although a growing number of devices have the support for parallel processing, parallelism is not widely exploited, as it should be. This can be illustrated by the fact that all Apple desktops and laptops are currently supplied with one or more dual- core processors. Despite this, parallel programming in popular languages such as Java is not widely encouraged and often only recommended as a last resort. In addition, it is likely that the next generation parallel applications will have to operate within a diverse range of heterogeneous devices ranging from supercomputers to sensors. This paper proposes a flexible component-based middleware that aims at facilitating the construction of deadlock-free parallel and concurrent applications for heterogeneous environments. The middleware is particularly targeted to tailor applications to the target need and environment. For our prototyping, we implemented plu- gins that are capable of deploying JCSP (CSP library for Java programmers) and OCCam-pi processes. Both JCSP and OCCam-pi make use of the CSP disciplines. The CSP (Communicating Sequential Processes) paradigm helps us to avoid concurrency problems such as deadlocks. It should be stressed that there is no bias towards these languages as the proposed middleware is highly extensible.	central processing unit;communicating sequential processes;component-based software engineering;concurrency (computer science);deadlock;desktop computer;jcsp;java;laptop;middleware;next-generation network;parallel computing;programmer;programming paradigm;sensor;supercomputer;occam	Jo Ueyama;Edmundo Roberto Mauro Madeira;Paul Grace	2008	2008 11th IEEE International Symposium on Object and Component-Oriented Real-Time Distributed Computing (ISORC)	10.1109/ISORC.2008.76	embedded system;parallel processing;parallel computing;real-time computing;computer science;operating system;middleware;distributed computing;programming language	HPC	-12.66901920536808	40.79498417747355	51186
60c188f4a3c7b1c2105f680ab3c8d26f5680eb35	algorithm-system scalability of heterogeneous computing	parallel computing;estensibilidad;tratamiento paralelo;modelizacion;distributed system;algoritmo paralelo;evaluation performance;systeme reparti;parallel algorithm;performance evaluation;traitement parallele;heterogeneous computing;evaluacion prestacion;distributed computing;metric;algorithme parallele;modelisation;sistema repartido;algorithme reparti;parallel computer;calculo repartido;metrico;algoritmo repartido;extensibilite;scalability;distributed algorithm;modeling;calcul reparti;parallel processing;metrique	Scalability is a key factor of the design of distributed systems and parallel algorithms and machines. However, conventional scalabilities are designed for homogeneous parallel processing. There is no suitable and commonly accepted definition of scalability metric for heterogeneous systems. Isospeed scalability is a well-defined metric for homogeneous computing. This study extends the isospeed scalability metric to general heterogeneous computing systems. The proposed isospeed-efficiencymodel is suitable for both homogeneous and heterogeneous computing. Through theoretical analyses, we derive methodologies of scalability measurement and prediction for heterogeneous systems. Experimental results have verified the analytical results and confirmed that the proposed isospeed-efficiency scalability works well in both homogeneous and heterogeneous environments. © 2008 Elsevier Inc. All rights reserved.	clustered file system;distributed computing;experiment;grid computing;heterogeneous computing;image scaling;parallel algorithm;parallel computing;scalability;scalability testing;semiconductor industry	Yong P Chen;Xian-He Sun;Ming Wu	2008	J. Parallel Distrib. Comput.	10.1016/j.jpdc.2008.06.007	parallel processing;distributed algorithm;parallel computing;scalability;systems modeling;metric;computer science;theoretical computer science;distributed computing;parallel algorithm;symmetric multiprocessor system	HPC	-17.758872918298973	43.70118270498474	51346
43a339663a9ce28e0cbc2d4c00b120010ba9315e	parallel from the beginning: the case for multicore programming in thecomputer science undergraduate curriculum	course design;introductory programming;multicore computing development education;computer science education	"""The computing landscape has shifted towards multicore architectures. To learn about software development, it is increasingly important for students to gain hands-on parallel programming experience in multicore environments. This experience will be significantly different from programming for uniprocessors, because it involves a profound understanding of how to write software that is (1) free of concurrency bugs and (2) able to effectively utilize the underlying parallel hardware architecture. We present our work at Yonsei University and The University of Sydney to teach parallel programming to first and second-year undergraduate students. Our objective is to introduce parallelism early on in the curriculum, to instill it as a first principle of computation. We introduce a series of five parallel programming course modules suitable for a one semester introductory programming course. Each module teaches one fundamental concept of parallel programming: parallelism and execution indeterminism, thread-and-lock based programming, performance of parallel programs, hardware acceleration using OpenCL, and stream-parallel programming with StreamIt. We report our experience from four course offerings (2008-2011) at Yonsei University, and two course offerings at The University of Sydney. Over 73% of students surveyed enjoyed this multicore programming experience and preferred exposure to parallelism at this early stage of their CS education. Our course has been awarded an Intel microgrant for """"Parallelism in the Classroom"""", and it is available online at Intel's Multicore Curriculum Initiative Website."""	computation;concurrency (computer science);hands-on computing;hardware acceleration;multi-core processor;multiprocessing;opencl api;parallel computing;software bug;software development;uniprocessor system	Yousun Ko;Bernd Burgstaller;Bernhard Scholz	2013		10.1145/2445196.2445320	computational science;computer science;theoretical computer science;operating system;software engineering;programming paradigm;programming language;parallel programming model	PL	-14.287511719864213	39.711076480352595	51416
b7207f4c1ce11c22b833608db775604ade2752a8	adaptive opencl computation offloading framework on mobile device.				Olivier Valery;Wei-Shu Hung;Ju-Cheng Chou;Pangfeng Liu;Jan-Jan Wu	2014		10.3233/978-1-61499-484-8-1335	embedded system;parallel computing;computer science;operating system	Robotics	-8.232102443743273	43.14217821045079	51442
b48a17502a9c7dc51a4729aeb682dec7adc8acb9	hardware synthesis from term rewriting systems	term rewriting systems;hardware synthesis;high level synthesis	Term Rewriting System (TRS) is a good formalism for describing concurrent systems that embody asynchronous and nondeterministic behavior in their specifications. Elsewhere, we have used TRS’s to describe speculative micro-architectures and complex cache-coherence protocols, and proven the correctness of these systems. In this paper, we describe the compilation of TRS’s into a subset of Verilog that can be simulated and synthesized using commercial tools. TRAC, Term Rewriting Architecture Compiler, enables a new hardware development framework that can match the ease of today’s software programming environment. TRAC reduces the time and effort in developing and debugging hardware. For several examples, we compare TRAC-generated RTL’s with hand-coded RTL’s after they are both compiled for Field Programmable Gate Arrays by Xilinx tools. The circuits generated from TRS are competitive with those described using Verilog RTL, especially for larger designs.	asynchronous i/o;cache coherence;central processing unit;compiler;computer programming;concurrency (computer science);correctness (computer science);debugging;field-programmable gate array;formal system;integrated development environment;nondeterministic algorithm;rewriting;speculative execution;trac;triune continuum paradigm;verilog	James C. Hoe;Arvind	1999			parallel computing;computer science;theoretical computer science;programming language;mesif protocol	EDA	-17.269805811954356	32.674070672779926	51560
d848e62d07d31dbbd5fa334f51ef35494929f3b5	implementing a dsp-based petri-net simulation tool	software structure;computational modeling hardware computer simulation digital signal processors signal processing algorithms petri nets computer architecture system recovery process control inhibitors;hardware architecture;simulator implementation dsp based petri net simulation tool parallel systems high execution speed optimized software structure digital signal processors tms320 family simulation algorithm;virtual machines;virtual machines digital simulation parallel processing petri nets;parallel systems;digital signal processor;petri nets;petri net;simulation tool;parallel processing;digital simulation	An efficient simulator of Petri nets, suitable for both loosely and tightly coupled parallel systems and featuring high-execution speed, is proposed. This speed is obtained through an optimized software structure on an original hardware architecture that is based on digital signal processors of the TMS320 family. The Petri net class outlined compactly represents a wide range of processes by restricting the model size and the relevant simulation times. The simulation algorithm and simulator implementation are described.<<ETX>>	algorithm;central processing unit;digital signal processor;petri net;simulation;texas instruments tms320	Antonella Di Stefano;Orazio Mirabella;Fabio Presente	1991	IEEE Micro	10.1109/40.76619	parallel processing;computer architecture;parallel computing;real-time computing;computer science;operating system;hardware architecture;process architecture;petri net	EDA	-10.463602944869642	40.23749355371496	51650
2af028ccd5753406b3f7a8f190da377bc483fe4c	automatic type-driven library generation for telescoping languages	automatic type-driven library generation;telescoping system;matlab type;telescoping languages;highly-optimized domain-specific library;type-inference system;linear algebra library;library procedure;c library;prototype matlab code;general telescoping system;matlab development code;scientific visualization;wave propagation;volume rendering;prototypes;parallel rendering;linear algebra;power generation;type inference;computer science;production	Telescoping languages is a strategy to automatically generate highly-optimized domain-specific libraries. The key idea is to create specialized variants of library procedures through extensive offline processing. This paper describes a telescoping system, called ARGen, which generates high-performance Fortran or C libraries from prototype Matlab code for the linear algebra library, ARPACK. ARGen uses variable types to guide procedure specializations on possible calling contexts. ARGen needs to infer Matlab types in order to speculate on the possible variants of library procedures, as well as to generate code. This paper shows that our type-inference system is powerful enough to generate all the variants needed for ARPACK automatically from the Matlab development code. The ideas demonstrated here provide a basis for building a more general telescoping system for Matlab.		Arun Chauhan;Cheryl McCosh;Ken Kennedy;Richard Hanson	2003		10.1109/SC.2003.10038	electricity generation;computational science;parallel computing;scientific visualization;wave propagation;computer science;theoretical computer science;linear algebra;operating system;type inference;parallel rendering;prototype;programming language;volume rendering	NLP	-13.177119105883436	35.86928617839241	52332
ae2355e7217c20254ab895f0da8ab7467cb83988	intel i860 versus digital signal processors (dsp)	digital signal processor	The overall d~aracteristies of Digital Signal Processors and RISC p~:c~sor~ are described in this paper. The instructions of the i860 processor from Intel which are of special interest to digital signal processing algorithms is a major subject of this paper. The cast saving aspects of using the i860 processor in digital signal environments are described. The advantages of using the programming language Ada are described with the safety, maintenance and other requirements of digital signal processing in mind. The practical aspects and the main features of the Ada development tools are described. The main conclusion is that the i860 processor can replace some Digital Signal Processors, thus saving development costs.	ada;algorithm;central processing unit;digital signal processing;digital signal processor;intel i860;programming language;programming tool;requirement	Steen Silberg	1992	Microprocessing and Microprogramming	10.1016/0165-6074(92)90375-H	digital signal processor;computer architecture;parallel computing;media processor;computer hardware;computer science;operating system;fujitsu fr	EDA	-16.308203470139645	39.04318426007189	52407
a76304a35b5a101e9f2a7d48e6f6e16e4aacf281	an axiomatic semantics for data parallel computation		Proof rules for both directly and indirectly indexed data-parallel array assignment are presented. Consequently, the correctness of two programs, (i) a representation of Cannon’s algorithm and (ii) sparse matrix-vector multiplication, are established by application of the rules.	apl;algorithm;axiomatic semantics;compiler;computation;correctness (computer science);data parallelism;matrix multiplication;parallel array;parallel computing;programming language;sparse matrix	Alan Stewart	1997				PL	-12.371589219574727	36.9081063280634	52489
49e840c4f0b7f133a8dfa8ff04a248bc39173416	coz: finding code that counts with causal profiling	software reliability;fault tolerance;state machine replication	"""Improving performance is a central concern for software developers. To locate optimization opportunities, developers rely on software profilers. However, these profilers only report where programs spent their time: optimizing that code may have no impact on performance. Past profilers thus both waste developer time and make it difficult for them to uncover significant optimization opportunities.   This paper introduces  causal profiling.  Unlike past profiling approaches, causal profiling indicates exactly where programmers should focus their optimization efforts, and quantifies their potential impact. Causal profiling works by running  performance experiments  during program execution. Each experiment calculates the impact of any potential optimization by  virtually speeding  up code: inserting pauses that slow down all other code running concurrently. The key insight is that this slowdown has the same  relative  effect as running that line faster, thus """"virtually"""" speeding it up.   We present C oz , a causal profiler, which we evaluate on a range of highly-tuned applications: Memcached, SQLite, and the PARSEC benchmark suite. C oz  identifies previously unknown optimization opportunities that are both significant and targeted. Guided by C oz , we improve the performance of Memcached by 9%, SQLite by 25%, and accelerate six PARSEC applications by as much as 68%; in most cases, these optimizations involve modifying under 10 lines of code."""	causal filter	Charlie Curtsinger;Emery D. Berger	2015		10.1145/2815400.2815409	fault tolerance;parallel computing;real-time computing;computer science;operating system;state machine replication;programming language;software quality	OS	-18.342885006577834	37.38223824596995	52528
137ae62161120ad2b749bb8cee38f46c59ea9887	opendf: a dataflow toolset for reconfigurable hardware and multicore systems	programming model;parallel computer;interchange format;reconfigurable hardware	This paper presents the OpenDF framework and recalls that dataflow programming was once invented to address the problem of parallel computing. We discuss the problems with an imperative style, von Neumann programs, and present what we believe are the advantages of using a dataflow programming model. The CAL actor language is briefly presented and its role in the ISO/MPEG standard is discussed. The Dataflow Interchange Format (DIF) and related tools can be used for analysis of actors and networks, demonstrating the advantages of a dataflow approach. Finally, an overview of a case study implementing an MPEG- 4 decoder is given.	cal actor language;data interchange format;dataflow programming;field-programmable gate array;imperative programming;moving picture experts group;multi-core processor;parallel computing;programming model;reconfigurable computing;von neumann architecture;von neumann programming languages	Shuvra S. Bhattacharyya;Gordon J. Brebner;Jörn W. Janneck;Johan Eker;Carl von Platen;Marco Mattavelli;Mickaël Raulet	2008	SIGARCH Computer Architecture News	10.1145/1556444.1556449	dataflow architecture;computer architecture;parallel computing;real-time computing;stream processing;reconfigurable computing;computer science;operating system;dataflow;signal programming;programming paradigm;programming language	Arch	-8.504571266620523	43.46359095705897	52591
909eb0981242f5ee1d87b4ffb6f34132fd8576c6	construction of performance model of tile caqr and performance result of the implementation		Highly parallel computational resources can be exploited by asynchronously executing many fine-grained tasks. The tile algorithm for matrix decomposition can generate many fine-grained tasks, so is suitable for modern multicore/manycore architectures. However, the performance of this algorithm significantly depends on the tile size. We implement the tile algorithm in OpenMP/MPI hybrid fashion on a cluster system and construct a performance model that tunes the tile size by measuring the performance of simple computational kernels in our implementation. In this report, we test our communication-avoiding tile QR implementation for tall and skinny matrices on the K computer, and demonstrate the applicability of the performance model.	algorithm;clustered file system;computation;computational resource;k computer;manycore processor;multi-core processor;openmp;qr code;scalapack;speedup	Masatoshi Takayanagi;Tomohiro Suzuki	2017	2017 IEEE 11th International Symposium on Embedded Multicore/Many-core Systems-on-Chip (MCSoC)	10.1109/MCSoC.2017.18	kernel (linear algebra);parallel computing;tile;task analysis;dynamic priority scheduling;cluster analysis;matrix (mathematics);matrix decomposition;computer science;multi-core processor	HPC	-4.610596897631136	41.76658460105233	52603
4bc66004bd2c98ad819950e2a6f5f62748d520d6	evaluation of the computational efficacy in gpu-accelerated simulations of spiking neurons	gpgpu;cuda;acceleration;spiking neural network;neuron model;simulation and numerical modeling;numerical chaos	To understand the mechanism of information processing by a biological neural network, computer simulation of a large-scale spiking neural network is an important method. However, because of a high computation cost of the simulation of a large-scale spiking neural network, the simulation requires high performance computing implemented by a supercomputer or a computer cluster. Recently, hardware for parallel computing such as a multi-core CPU and a graphics card with a graphics processing unit (GPU) is built in a gaming computer and a workstation. Thus, parallel computing using this hardware is becoming widespread, allowing us to obtain powerful computing power for simulation of a large-scale spiking neural network. However, it is not clear how much increased performance the parallel computing method using a new GPU yields in the simulation of a large-scale spiking neural network. In this study, we compared computation time between the computing methods with CPUs and GPUs in a simulation of neuronal models. We developed computer programs of neuronal simulations for the computing systems that consist of a gaming graphics card with new architecture (the NVIDIA GTX 1080) and an accelerator board using a GPU (the NVIDIA Tesla K20C). Our results show that the computing systems can perform a simulation of a large number of neurons faster than CPU-based systems. Furthermore, we investigated the accuracy of a simulation using single precision floating point. We show that the simulation results of single precision were accurate enough compared with those of double precision, but chaotic neuronal response calculated by a GPU using single precision is prominently different from that calculated by a CPU using double precision. Furthermore, the difference in chaotic dynamics appeared even if we used double precision of a GPU. In conclusion, the GPU-based computing system exhibits a higher computing performance than the CPU-based system, even if the GPU system includes data transfer from a graphics card to host memory.	artificial neural network;central processing unit;chaos theory;computation;computer cluster;computer graphics;computer program;computer simulation;double-precision floating-point format;gaming computer;geforce 10 series;graphics processing unit;hardware acceleration;higher computing;information processing;multi-core processor;nvidia tesla;parallel computing;quadruple-precision floating-point format;single-precision floating-point format;spiking neural network;supercomputer;time complexity;video card;workstation	Kazuhisa Fujita;Shun Okuno;Yoshiki Kashimori	2018	Computing	10.1007/s00607-018-0590-0	mathematics;mathematical optimization;spiking neural network;architecture;parallel computing;graphics processing unit;central processing unit;computer cluster;general-purpose computing on graphics processing units;cuda;supercomputer	HPC	-5.241087524849112	35.74683673837087	52745
da10643553d82940302f95e6234f428b13679f7b	space-efficient scheduling of nested parallelism	scheduling algorithm;parallel language implementation;parallel computer;nested parallelism;load balance;runtime system;parallel programs;parallel languages;space efficiency;dynamic scheduling;multithreading	Many of today's high-level parallel languages support dynamic, fine-grained parallelism. These languages allow the user to expose all the parallelism in the program, which is typically of a much higher degree than the number of processors. Hence an efficient scheduling algorithm is required to assign computations to processors at runtime. Besides having low overheads and good load balancing, it is important for the scheduling algorithm to minimize the space usage of the parallel program. This article presents an on-line scheduling algorithm that is provably space efficient and time efficient for nested-parallel languages. For a computation with depth <italic>D</italic> and serial space requirement <italic>S</italic><subscrpt>1</subscrpt>, the algorithm generates a schedule that  requires at most <italic>S</italic><subscrpt>1</subscrpt> + <italic>O</italic><italic>(K•D•p</italic>) space (including scheduler space) on <italic>p</italic> processors. Here, <italic>K</italic> is a user-adjustable runtime parameter specifying the net amount of memory that a thread may allocate before it is preempted by the scheduler.  Adjusting the value of <italic>K</italic> provides a trade-off between the running time and the memory requirement of a parallel computation. To allow the scheduler to scale with the number of processors we also parallelize the scheduler and analyze the space and time bounds of the computation to include scheduling costs. In addition to showing that the scheduling algorithm is space and time efficient in theory, we demonstrate that it is effective in practice.  We  have implemented a runtime system that uses our algorithm to schedule lightweight parallel threads. The results of executing parallel programs on this system show that our scheduling algorithm significantly reduces memory usage compared to previous techniques, without compromising performance.	algorithm;central processing unit;computation;high- and low-level;load balancing (computing);online and offline;parallel computing;parallel programming model;preemption (computing);run time (program lifecycle phase);runtime system;schedule (computer science);scheduling (computing);space–time tradeoff;time complexity	Girija J. Narlikar;Guy E. Blelloch	1999	ACM Trans. Program. Lang. Syst.	10.1145/314602.314607	fair-share scheduling;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;multithreading;gang scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;load balancing;two-level scheduling;distributed computing;data parallelism;least slack time scheduling;programming language;scheduling;task parallelism	PL	-13.730758591744914	46.081371781811065	52761
0fd6dc702859c932e2cc53cbe1321440615f2dd1	supporting efficient execution of continuous space agent-based simulation on gpu	agent based simulation;performance evaluation;gpu memory management;gpu memory hierarchy;parallel execution	Using agent-based simulation (ABS) to analyze complex adaptive systems gains growing popularity over the past decades. One of the fundamental issues in ABS is to increase the execution speed. In this paper, we identify two common modules that widely exist in ABS applications, namely, the agent management module and the agent interaction module. Improving the efficiency of these two common modules can significantly speed up the ABS execution in general. GPU architecture, programming model, and memory hierarchy are studied. Effective strategies on GPU are proposed when we design the two modules. The first contribution of this work is to propose an AgentPool data structure to handle agent creation and deletion on GPU. The second contribution is an efficient agent interaction module, which is designed by carefully utilizing the GPU memory hierarchy. To demonstrate effectiveness and generality, the proposed strategies are applied to a range of ABS applications, including game-of-life, flocking boids, prey-and-predator, and the social force-based crowd simulation. The simulation results demonstrate that the proposed strategies achieve better performance than the commonly used CPU and GPU ABS framework, namely, Mason and FLAME, for ABS applications using continuous space. Copyright © 2016 John Wiley & Sons, Ltd.	agent-based model;boids;complex adaptive system;crowd simulation;data structure;flame (malware);graphics processing unit;john d. wiley;mason;memory hierarchy;prey;programming model;social force model;speedup	Xiaosong Li;Wentong Cai;Stephen John Turner	2016	Concurrency and Computation: Practice and Experience	10.1002/cpe.3808	parallel computing;real-time computing;simulation;computer science;operating system;database;distributed computing	AI	-10.849525154250191	39.11086232781941	52845
86de8fc70436e3418bf59dc067ceda22117410e2	compiler optimization techniques for openmp programs	cross-loop data dependence analysis;openmp api;memory consistency;coherency optimization show;dataflow analysis technique;memory synchronization analysis;openmp program;definitions analysis;aggressive compiler optimizations;general openmp implementation;compiler optimization technique;compiler optimization	In this paper, we present some compiler optimization techniques for explicit parallel programs using OpenMP API. To enable optimizations across threads, we designed data ow analysis techniques in which interaction between threads is e ectively modeled. Structured description of parallelism and relaxed memory consistency in OpenMP make the analyses e ective and eÆcient. We show algorithms for reaching de nitions analysis, memory synchronization analysis, and cross-loop data dependence analysis for parallel loops. Our primary target is a compiler-directed software DSM system where aggressive compiler optimizations for software-implemented coherence scheme are crucial to obtain good performance. We also show optimizations applicable to general OpenMP implementations, namely redundant barrier removal and privatization of dynamically allocated objects. We consider compiler optimizations are bene cial for performance portability across various platforms and non-expert programmers. Experimental results for the coherency optimization in a compilerdirected software DSM system shows that aggressive compiler optimizations are quite e ective for a shared-write intensive program because coherenceinduced communication volume in such a program is much larger than the those for shared-read intensive programs.	air traffic control radar beacon system;algorithm;application programming interface;consistency model;data dependency;dependence analysis;mathematical optimization;openmp;optimizing compiler;parallel computing;programmer;software portability	Shigehisa Satoh;Kazuhiro Kusano;Mitsuhisa Sato	2001	Scientific Programming		manifest expression;computer architecture;parallel computing;profile-guided optimization;compiler correctness;interprocedural optimization;computer science;loop optimization;operating system;optimizing compiler;programming language;functional compiler	HPC	-16.09335693429091	36.3481577719473	52867
dfba7f4c859280470de2f44dff657d6931e3bee4	injecting parallel computing into cs2	shared memory;cs2;parallel;openmp;patterns;multithreading	In today's multicore world, every CS student should learn about and gain experience with (at least) shared-memory parallelism. CS Curriculum 2013 acknowledges this by shifting parallel computing from elective status into the core. This paper argues that students should be introduced to parallelism early, that the CS2 (Data Structures) course is a natural place to do so, and reports our experience in doing this. The paper also argues that students should be taught to solve problems using parallel patterns, which are industry-standard best-practice strategies for parallel problem solving. To support such teaching, the paper presents patternlets -- minimalist, scalable, executable programs, each illustrating the behavior of a parallel pattern -- as a useful pedagogical tool for teaching parallel concepts. Several patternlets and their executions are given. The paper presents evidence that this injection of parallelism into CS2 has been successful.	cs games;executable;multi-core processor;parallel computing;problem solving;scalability;shared memory	Joel C. Adams	2014		10.1145/2538862.2538883	shared memory;parallel computing;multithreading;embarrassingly parallel;computer science;theoretical computer science;operating system;parallel;data parallelism;pattern;programming language;implicit parallelism;task parallelism	HPC	-14.027531476417845	39.66382822652651	52911
43d0de73d84ad3a44145540df2741c07000e2ac2	mc2: map concurrency characterization for mapreduce on the cloud	map concurrency characterization;mc 2 standalone utility program map concurrency characterization pervasive analytics engine open source implementation high dimensional space configuration parameters cost effective execution configurable parameters map slots map tasks mapreduce application predicted information map phase configuration hadoop performance static analysis unmodified job code private cloud hadoop 0 20 2 amazon ec2;concurrent computing mathematical model runtime equations time factors engines benchmark testing;public domain software;data analysis;map concurrency;concurrency control;public domain software cloud computing concurrency control data analysis;mapreduce;hadoop;map concurrency characterization mapreduce hadoop map concurrency;cloud computing	MapReduce is now a pervasive analytics engine on the cloud. Hadoop is an open source implementation of MapReduce and is currently enjoying wide popularity. Hadoop offers a high-dimensional space of configuration parameters, which makes it difficult for practitioners to set for efficient and cost-effective execution. In this work we observe that MapReduce application performance is highly influenced by map concurrency. Map concurrency is defined in terms of two configurable parameters, the number of available map slots and the number of map tasks running over the slots. We show that some inherent MapReduce characteristics enable well-informed prediction of map concurrency. We propose Map Concurrency Characterization (MC2), a standalone utility program that can predict the best map concurrency for any given MapReduce application. By leveraging the generated predicted information, MC2 can judiciously guide Map phase configuration and, consequently, improve Hadoop performance. Unlike many of relevant schemes, MC2 does not employ simulation, dynamic instrumentation, and/or static analysis of unmodified job code to predict map concurrency. In contrast, MC2 utilizes a simple, yet effective mathematical model, which exploits the MapReduce characteristics that impact map concurrency. We implemented MC2 and conducted comprehensive experiments on a private cloud and on Amazon MC2 using Hadoop 0.20.2. Our results show that MC2 can correctly predict the best map concurrencies for the tested benchmarks and provide up to 2.2X speedup in runtime.	apache hadoop;cloud computing;concurrency (computer science);experiment;mapreduce;mathematical model;open-source software;simulation;speedup;static program analysis	Mohammad Hammoud;Majd F. Sakr	2013	2013 IEEE Sixth International Conference on Cloud Computing	10.1109/CLOUD.2013.93	real-time computing;cloud computing;computer science;operating system;concurrency control;database;distributed computing;data analysis;public domain software;distributed concurrency control	DB	-4.917446882555288	45.373634559615724	53146
d53103dad436687cd57be744d9411c0e07fbce82	a simple algorithm for clock synchronization in transputer networks	distributed system;evaluation performance;systeme reparti;performance evaluation;implementation;evaluacion prestacion;sistema informatico;computer system;transputer;experimental result;synchronisation;ejecucion;sistema repartido;synchronization;resultado experimental;clock synchronization;systeme informatique;sincronizacion;distributed systems;resultat experimental	Abstract#R##N##R##N#In a distributed system based on Transputer components there is one clock for each processing element, and the definition of the global system time requires the choice of a hardware or software synchronization method. This paper describes the RING_SYNC algorithm, based on a ring-structured synchronization scheme. RING_SYNC has no provision for fault tolerance, but it introduces little overhead, thanks to the optimization of both the number of messages exchanged at sync time and the resynchronization frequency. The implementation of the algorithm together with the tests performed for measuring the synchronization error and their results are discussed extensively, and some typical applications are pointed out.	algorithm;clock synchronization;transputer	Ugo de Carlini;Umberto Villano	1988	Softw., Pract. Exper.	10.1002/spe.4380180404	clock synchronization;embedded system;synchronization;real-time computing;computer science;operating system;distributed computing;data synchronization	Theory	-18.62588646577726	43.24452211427735	53345
6e957bfdae51a055736c032b80ea13996e17453c	efficient detection of determinacy races in cilk programs	directed acyclic graph;whi;asymptotic efficiency;shared memory;programming language;least common ancestor;linear time;series parallel	A parallel multithreaded program that is ostensibly deterministic may nevertheless behave nondeterministically due to bugs in the code. These bugs are called determinacy races, and they result when one thread updates a location in shared memory while another thread is concurrently accessing the location. We have implemented a provably efficient determinacy-race detector for Cilk, an algorithmic multithreaded programming language. If a Cilk program is run on a given input data set, our debugging tool, which we call the ``Nondeterminator,'' either determines at least one location in the program that is subject to a determinacy race, or else it certifies that the program is race free when run on the data set.	cilk plus	Mingdong Feng;Charles E. Leiserson	1997		10.1145/258492.258493	time complexity;shared memory;series and parallel circuits;parallel computing;real-time computing;computer science;operating system;distributed computing;programming language;directed acyclic graph;algorithm;lowest common ancestor	Logic	-13.105704515338532	32.75786876830367	53400
1289544c5bb6f403dc8a512d61ef384dab2d49b1	parallel i/o optimizations for scalable deep learning		As deep learning systems continue to grow in importance, researchers have been analyzing approaches to make such systems efficient and scalable on high-performance computing platforms. As computational parallelism increases, however, data I/O becomes the major bottleneck limiting the overall system scalability. In this paper, we continue our efforts to improve LMDB, the I/O subsystem of the Caffe deep learning framework. In a previous paper we presented LMDBIO---an optimized I/O plugin for Caffe that takes into account the data access pattern of Caffe in order to vastly improve I/O performance. Nevertheless, LMDBIO's optimizations, which we henceforth call LMM (localized mmap), are limited to intranode performance, and these optimizations do little to minimize the I/O inefficiencies in distributed-memory environments. In this paper, we propose LMDBIO-DM, an enhanced version of LMDBIO-LMM that optimizes the I/O access of Caffe in distributed-memory environments. We present several sophisticated data I/O techniques that allow for significant improvement in such environments. Our experimental results show that LMDBIO-DM can improve the overall execution time of Caffe by more than 30-fold compared with LMDB and by 2-fold compared with LMDBIO-LMM.	data access;deep learning;distributed memory;input/output;mmap;openldap lightning memory-mapped database;parallel i/o;parallel computing;run time (program lifecycle phase);scalability;supercomputer	Sarunya Pumma;Min Si;Wu-chun Feng;Pavan Balaji	2017	2017 IEEE 23rd International Conference on Parallel and Distributed Systems (ICPADS)	10.1109/ICPADS.2017.00097	mmap;deep learning;plug-in;scalability;parallel i/o;distributed database;computer science;distributed computing;data access;bottleneck;artificial intelligence	HPC	-5.131003262138052	42.2607581732357	53621
f3ae7effd36f082825c5c150d8f4cddae6b77fae	parallel graph reduction on a supercomputer: a status report	computers;computer program;general and miscellaneous mathematics computing and information science;computer graphics;functional programming;computer graphic;run time system;data analysis;execution environment;programming 990210 supercomputers 1987 1989;functional language;parallel processing;cray computers	We describe an ongoing effort to develop a parallel graph reduction run-time system hosted on a multiprocessor supercomputer. This run-time system is presently augmented by the functional language compiler of the ALFALFA system. Admittedly, parallel graph reduction is hardly a novel idea. The interesting notion is the provision of a parallel execution environment sufficiently powerful to support development of large prototypical scientific and symbolic codes in a functional language. This will allow the investigation of the functional programming paradigm within these application domains in an empirical fashion. In this paper, we discuss the motivation for the effort, describe the basic elements of the implementation, and provide some preliminary insight distilled from our experience with an initial version of the run-time system.	graph reduction;supercomputer	Randy Michelson;Lauren Smith;Elizabeth Williams;Bonnie Yantis	1986		10.1007/3-540-18420-1_52	computational science;parallel computing;computer science;theoretical computer science	HPC	-13.121242579645761	39.222351015533334	53796
722a442a27b2774800ca639e96d3259e931c961c	coordination of distributed/parallel multi-grid domain decomposition	domain decomposition;coordination language;optimization problem	A workable approach for the solution of many (numerical and non-numerical) problems is domain decomposition. If a problem can be divided into a number of sub-problems that can be solved in a distributed/parallel fashion, the overall performance can signiicantly improve. In this paper, we discuss one of our experiments using the new coordination language MANIFOLD to solve an instance of the classical optimization problem by domain decomposition. We demonstrate the applicability of MANIFOLD in expressing the solutions to domain decomposition problems in a generic way and its utility in producing executable code that can carry out such solutions in both distributed and parallel environments. The multiple-grid domain decomposition method used in this paper is based on adaptive partitioning of the domain and results in highly irregular grids as shown in the examples. The implementation of the distributed/parallel approach presented in this paper looks very promising and its coordinator modules are generally applicable.	compiler;computation;distributed computing;domain decomposition methods;executable;experiment;library (computing);mathematical optimization;mod database;modular programming;numerical analysis;optimization problem;programmer;programming paradigm;requirement	C. T. H. Everaars;Farhad Arbab	1996		10.1007/BFb0030103	mathematical optimization;domain;computer science;theoretical computer science;distributed computing;domain decomposition methods	AI	-8.7353136126074	35.93877500082218	53922
2dc0dafd488859dd903679b2f8f3d2cd96883215	mapping parallel application communication topology to rhombic overlapping-cluster multiprocessors	cluster computing;cluster;modeling technique;shared memory;parallel programming;interconnection network;computer architecture;low latency;overlapped cluster;parallel programs;parallel applications;analytical model;shared memory multiprocessor	This paper extends research into rhombic overlapping-connectivity interconnection networks into the area of parallel applications. As a foundation for a shared-memory non-uniform access bus-based multiprocessor, these interconnection networks create overlapping groups of processors, buses, and memories, forming a clustered computer architecture where the clusters overlap. This overlapping-membership characteristic is shown to be useful for matching parallel application communication topology to the architecture's bandwidth characteristics. Many parallel applications can be mapped to the architecture topology so that most or all communication is localized within an overlapping cluster, at the low latency of processor direct to cache (or memory) over a bus. The latency of communication between parallel threads does not degrade parallel performance or limit the graininess of applications. Parallel applications can execute with good speedup and scaling on a proposed architecture which is designed to obtain maximum advantage from the overlapping-cluster characteristic, and also allows dynamic workload migration without moving the instructions or data. Scalability limitations of bus-based shared-memory multiprocessors are overcome by judicious workload allocation schemes, that take advantage of the overlapping-cluster memberships. Bus-based rhombic shared-memory multiprocessors are examined in terms of parallel speedup models to explain their advantages and justify their use as a foundation for the proposed computer architecture. Interconnection bandwidth is maximized with bi-directional circular and segmented overlapping buses. Strategies for mapping parallel application communication topologies to rhombic architectures are developed. Analytical models of enhanced rhombic multiprocessor performance are developed with a unique bandwidth modeling technique, and are compared with the results of simulation.	ab initio quantum chemistry methods;bandwidth (signal processing);central processing unit;cluster analysis;computer architecture;image scaling;interconnection;multiprocessing;overhead (computing);scalability;shared memory;simulation;speedup	Kenneth E. Hoganson	2000	The Journal of Supercomputing	10.1023/A:1008171822063	shared memory;computer architecture;parallel computing;embarrassingly parallel;computer cluster;computer science;operating system;distributed computing;cluster;low latency	Arch	-9.642499631841513	45.190264912962036	54190
cdfb769bb867000ca46931914580eda7b390c93f	parallel bidirectional search on message passing environment	message passing		bidirectional search;message passing	Kwangho Cha;Jeongwoo Hong;Okhwan Byeon	2003			message passing;bidirectional search;computer science;distributed computing;message broker	SE	-10.482217254308543	42.433593393816416	54191
7f2b4d7506d531e8502cc505ccc853de608a9c62	experiences with unix ipc for low latency messaging solutions			unix	Manoj K. Nambiar;Sricharan Samudrala;Sundar Narayanan	2009			latency (engineering);operating system;embedded system;unix;computer science	OS	-10.371402131880885	43.992344382862925	54204
2a4990618f13f036953f746849b030adc0d92b90	an overview of the a architecture for optimisation problems in a logic programming environment	artificial intelligent;state space;parallel computer;content addressable memory;logic programs	Search of a state space is a common function in artificial intelligence applications consuming a large proportion of the total processing time. In this paper we propose a hierarchical architecture using content addressable memory to accelerate the A* algorithm in a Prolog system and remove the associated high memory overheads.	algorithm;applications of artificial intelligence;content-addressable memory;high memory;integrated development environment;logic programming;mathematical optimization;prolog;state space	D. P. Rodohan;Ray J. Glover	1991	SIGARCH Computer Architecture News	10.1145/122576.122589	computer architecture;parallel computing;computer science;state space;theoretical computer science;content-addressable memory;programming language;algorithm;memory map;state space search	Arch	-10.334104809745273	34.17468334888593	54380
0f6ac70ae5b3858acdf79acbcaac21a2b0819497	efficient update of ghost regions using active messages	benchmarking;particle mesh ewald methods;active messages;keywords active message;global collective synchronization ghost region updates active messages distributed grid applications remotely held boundary data local read only data copies parallel programming language data transfer data computation one sided communications array data distribution read and write operations high level operations x10 distributed arrays update algorithms split phase ghost updates intel x86 64 cluster qdr infiniband blue gene p system computational chemistry application code dynamically threaded architecture pairwise synchronization;structured grid;ghost regions;partitioned global address space;x10 language;conference paper;lattice boltz mann method;parallel programming models;smooth particle mesh ewald method;algorithms;synchronisation grid computing multi threading parallel algorithms parallel programming;structured grids;parallel programming model;parall active messages;distributed arrays;matlab;partitioned global address space pgas;data transfer;smooth particle mesh ewald method parallel programming models partitioned global address space pgas x10 language active messages structured grids distributed arrays ghost regions lattice boltz mann method	The use of ghost regions is a common feature of many distributed grid applications. A ghost region holds local read-only copies of remotely-held boundary data which are exchanged and cached many times over the course of a computation. X10 is a modern parallel programming language intended to support productive development of distributed applications. X10 supports the “active message” paradigm, which combines data transfer and computation in one-sided communications. A central feature of X10 is the distributed array, which distributes array data across multiple places, providing standard read and write operations as well as powerful high-level operations. We used active messages to implement ghost region updates for X10 distributed arrays using two different update algorithms. Our implementation exploits multiple levels of parallelism and avoids global synchronization; it also supports split-phase ghost updates, which allows for overlapping computation and communication. We compare the performance of these algorithms on two platforms: an Intel x86-64 cluster over QDR InfiniBand, and a Blue Gene/P system, using both stand-alone benchmarks and an example computational chemistry application code. Our results suggest that on a dynamically threaded architecture, a ghost region update using only pairwise synchronization exhibits superior scaling to an update that uses global collective synchronization.	active message;algorithm;blue gene;code;computation;computational chemistry;distributed computing;eclipse;ghost;high- and low-level;image scaling;infiniband;national computational infrastructure national facility (australia);p system;parallel computing;parallel programming model;programming language;programming paradigm;quad data rate sram;read-only memory;synchronization (computer science);tcp global synchronization;the australian;thomas j. watson research center;watson (computer);x10;x86;x86-64	Josh Milthorpe;Alistair P. Rendell	2012	2012 19th International Conference on High Performance Computing	10.1109/HiPC.2012.6507484	parallel computing;computer science;theoretical computer science;partitioned global address space;operating system;distributed computing;programming language;benchmarking;parallel programming model	HPC	-11.070043559623567	45.51408296448373	54568
60ad818f6b7337380de811bfe71015203330a7f3	debugopt: debugging fully optimized natively compiled programs using multistage instrumentation		Abstract The accuracy of debugging information is crucial for source level debugging. However the debugging information may be inaccurate after sophisticated optimizations if the target program is compiled into native code. Hence, the efficiency of diagnosing software is affected due to inaccurate debugging information. To address the issue, we propose Debugopt, a framework for debugging fully optimized natively compiled programs using multistage instrumentation. At compile time, Debugopt generates unoptimized programs with accurate debugging information and optimized programs. At debugging time, Debugopt dynamically replaces the execution of optimized programs with unoptimized programs. Debugopt is implemented on multiple architectures, including x86-32, x86-64, armv7 and mips3. Debugoptu0027s overhead is small during normal execution on a large range of benchmarks.	compiler;debugging;multistage amplifier	Jie Yin;Gang Tan;Hao Li;Xiaolong Bai;Yu-Ping Wang;Shi-Min Hu	2019	Sci. Comput. Program.	10.1016/j.scico.2018.09.005	programming language;machine code;computer architecture;debugging;software;arm architecture;instrumentation;computer science;compile time	PL	-17.329338306178	36.299382980341576	54596
84e6f313f4942facc71241cd380e6a06a213b110	the relationship between benchmark tests and microcomputer price	eficacia sistema;system configuration;performance systeme;cote nivellement;prix;system performance;bench mark;price;cota nivelacion;precio	A highly accurate model predicts microcomputer price based on benchmark performance by analyzing the impact on predicted price of fluctuations in system configuration and benchmark results.	benchmark (computing);microcomputer;system configuration	Sumit Sircar;Dinesh Dave	1986	Commun. ACM	10.1145/5666.5672	simulation;benchmark;computer science;computer performance;operations research	Metrics	-17.73357188253604	46.26873523152636	55124
5f02b228c1d39fe7d3db081afa702ad275a4c22c	locality-aware memory association for multi-target worksharing in openmp	gpu;layout;runtime;coprocessors;heterogeneous;adaptive systems;graphics processing units;openmp;optimization;programming	Heterogeneity is an ever-growing challenge in computing. The clearest example is the increasing popularity of GPUs, and purpose-designed coprocessors such as Intel Xeon Phi. Even disregarding coprocessors, heterogeneity continues to increase with the rise in CPU core counts, adaptive per-core frequencies, and increasingly hierarchical and complex memory systems. Take a system with four memory nodes, associated with four cores each, and four GPUs, each with a distinct address space and tens to hundreds of cores pro­grammed like a bulk-synchronous parallel cluster. In this case, we are effectively programming clusters of miniature constellations in every node.	address space;bulk synchronous parallel;central processing unit;coprocessor;graphics processing unit;locality of reference;openmp;xeon phi	Thomas Scogland;Wu-Chun Feng	2014	2014 23rd International Conference on Parallel Architecture and Compilation (PACT)	10.1145/2628071.2671428	layout;programming;computer architecture;parallel computing;computer hardware;computer science;adaptive system;operating system;coprocessor	HPC	-6.524932836507001	45.435087912717	55143
bf7263e396b9c4b95e622271a0e46cd9896844a3	dma performance analysis and multi-core memory optimization for swim benchmark on the cell processor	experimental tests;swim benchmark program dma performance analysis multicore memory optimization swim benchmark cell processor architecture heterogeneous multicore processor data communication memory bandwidth mathematical analysis;cell processor architecture;microprocessors;multicore memory optimization;optimisation;multi core processor;swim benchmark;cell processor;optimisation benchmark testing computer architecture data communication mathematical analysis microprocessor chips;test bed;memory optimization multi core processor dma performance spec parallelization;heterogeneous multicore processor;performance analysis bandwidth delay benchmark testing multicore processing data communication context performance evaluation mathematical analysis fitting;swim benchmark program;mathematical analysis;data communication;computer architecture;dma performance;spec parallelization;memory optimization;performance analysis;bandwidth;optimization;dma performance analysis;copper;magnetic cores;memory bandwidth;parallel applications;benchmark testing;microprocessor chips	The Cell processor is a typical heterogeneous multi-core processor, which owns powerful computing capability. But we are facing the challenges of 'memory wall' in developing parallel applications, such as, limited capacity of local memory, limited memory bandwidth for multi-cores and the long latency for data communication. The DMA transfer mechanism is often used to hide the long latency and improve the effective usage of memory bandwidth. In the paper, we start with a series of DMA experimental tests in the context of the Cell processor architecture, and perform mathematical analysis to setup a unified formula on the average bandwidth of DMA by means of exponential fitting, which describes that SPE amount and DMA block size take main effects on DMA bandwidth in quantity. With the supports of the DMA performance formula, we perform 4 types of memory optimization in the process of parallelizing the SWIM benchmark program into a multi-core version. We take Sony PlayStation 3 (PS3) as our test-bed. For SWIM benchmark, with 6 SPE cores, we obtain over 13 times of speedup compared to single PPE, and 3.3 to 6.18 times to AMD and Intel CPU.	automatic parallelization;benchmark (computing);block size (cryptography);cell (microprocessor);central processing unit;computation;direct memory access;disk controller;mathematical optimization;memory bandwidth;microarchitecture;microprocessor;multi-core processor;performance tuning;playstation 3;power processing element;profiling (computer programming);program optimization;random-access memory;requirement;speedup;testbed;time complexity	Yong Dou;Lin Deng;Jinhui Xu;Yi Zheng	2008	2008 IEEE International Symposium on Parallel and Distributed Processing with Applications	10.1109/ISPA.2008.54	multi-core processor;benchmark;computer architecture;i/o acceleration technology;parallel computing;real-time computing;computer science;operating system;copper;memory bandwidth;bandwidth;testbed	Arch	-4.767902755914829	40.010069507815174	55182
16ad107ee8a3acd8cf68b9dc46620b46306109f1	velociraptor: an embedded compiler toolkit for numerical programs targeting cpus and gpus	compiler framework for array based language;gpu hybrid systems;runtime;arrays;python;graphics processing units;matlab;buildings;data transfer	Developing just-in-time (JIT) compilers that that allow scientific programmers to efficiently target both CPUs and GPUs is of increasing interest. However building such compilers requires considerable effort. We present a reusable and embeddable compiler toolkit called Velociraptor that can be used to easily build compilers for numerical programs targeting multicores and GPUs.  Velociraptor provides a new high-level IR called VRIR which has been specifically designed for numeric computations, with rich support for arrays, plus support for high-level parallel and GPU constructs. A compiler developer uses Velociraptor by generating VRIR for key parts of an input program. Velociraptor provides an optimizing compiler toolkit for generating CPU and GPU code and also provides a smart runtime system to manage the GPU.  To demonstrate Velociraptor in action, we present two proof-of-concept case studies: a GPU extension for a JIT implementation of MATLAB language, and a JIT compiler for Python targeting CPUs and GPUs.	add-ons for firefox;array data structure;benchmark (computing);care-of address;central processing unit;code generation (compiler);computation;dynamic dispatch;embedded system;graphics processing unit;high- and low-level;hybrid system;just-in-time compilation;list of toolkits;matlab;mathematical optimization;numerical analysis;optimizing compiler;programmer;prototype;python;rewriting;runtime library;runtime system;software portability	Rahul Garg;Laurie J. Hendren	2014	2014 23rd International Conference on Parallel Architecture and Compilation (PACT)	10.1145/2628071.2628097	computer architecture;parallel computing;python;computer science;operating system;programming language	PL	-13.07879606478507	35.97940247298755	55238
a04daff774c4dc58a663e387cda9934fbe0b52f0	"""fast """"short"""" messages on a linux cluster"""	sistema operativo;protocole transmission;protocole tcp ip;linux cluster;parallel computation;interconnection network;protocolo transmision;codificacion;calculo paralelo;operating system;coding;pc cluster;systeme exploitation;communication;calcul parallele;comunicacion;red interconexion;codage;reseau interconnexion;transmission protocol	We discuss an experiment aimed at lowering the operating system related overheads when performing small size message communications on a Beowulf class Linux PC cluster. The experiment consists in adding a small number of new system calls to the Linux kernel allowing user code to send/receive messages to/from remote processes. The system calls have been implemented using the standard kernel module mechanism provided by Linux. Those new system calls allow small size messages to be exchanged between cluster nodes with times that are 10 to 15% smaller than those achieved using standard TCP/IP communications.	computer cluster;linux	Marco Danelutto;Arianna Rampini	2001		10.1007/3-540-48228-8_40	embedded system;real-time computing;htree;computer cluster;computer science;operating system;epoll;coding;linux kernel	OS	-17.825750824770328	43.46063562589877	55271
b5eedd215faa9dba6e4e50e7e42ec79bf0682fb2	a tool for programming embarrassingly task parallel applications on cow and now.		Embarrassingly parallel problems can be split in parts that are characterized by a really low (or sometime absent) exchange of information during their computation in parallel. As a consequence they can be effectively computed in parallel exploiting commodity hardware, hence without particularly sophisticated interconnection networks. Basically, this means Clusters, Networks of Workstations and Desktops as well as Computational Clouds. Despite the simplicity of this computational model, it can be exploited to compute a quite large range of problems. This paper describes JJPF, a tool for developing task parallel applications based on Java and Jini that showed to be an effective and efficient solution in environment like Clusters and Networks of Workstations and Desktops.	central processing unit;client-side;commodity computing;computation;computational model;computational resource;embarrassingly parallel;fault tolerance;futures and promises;interconnection;java;load balancing (computing);multi-core processor;pal;workstation;jini	Patrizio Dazzi	2013	CoRR		parallel computing;distributed computing;embarrassingly parallel;computation;workstation;computer science;java	HPC	-11.707875001969171	40.84659916837548	55284
725eb2e08b54cd0598e2db71c6256635e3bc8212	cluster communication protocols for parallel-programming systems	clusters;data transmission;evaluation performance;interfase usuario;estacion trabajo;computacion informatica;performance evaluation;protocole transmission;user interface;programacion paralela;implementation;station travail;evaluacion prestacion;reseau ordinateur;multidestinatario;grupo de excelencia;parallel programming;cluster of workstations;interconnection network;interface reseau;computer network;system area network;protocolo transmision;network interfaces;workstation;ciencias basicas y experimentales;transmission donnee;high performance computer;red informatica;communication protocol;interface utilisateur;parallel programming systems;implementacion;network interface;parallel programs;programmable networks;multidestinataire;parallel applications;red interconexion;transmision datos;data transfer;multicast;programmation parallele;system area networks;reseau interconnexion;transmission protocol	Clusters of workstations are a popular platform for high-performance computing. For many parallel applications, efficient use of a fast interconnection network is essential for good performance. Several modern System Area Networks include programmable network interfaces that can be tailored to perform protocol tasks that otherwise would need to be done by the host processors. Finding the right trade-off between protocol processing at the host and the network interface is difficult in general. In this work, we systematically evaluate the performance of different implementations of a single, user-level communication interface. The implementations make different architectural assumptions about the reliability of the network and the capabilities of the network interface. The implementations differ accordingly in their division of protocol tasks between host software, network-interface firmware, and network hardware. Also, we investigate the effects of alternative data-transfer methods and multicast implementations, and we evaluate the influence of packet size. Using microbenchmarks, parallel-programming systems, and parallel applications, we assess the performance of the different implementations at multiple levels. We use two hardware platforms with different performance characteristics to validate our conclusions. We show how moving protocol tasks to a relatively slow network interface can yield both performance advantages and disadvantages, depending on specific characteristics of the application and the underlying parallel-programming system.	admissible numbering;central processing unit;communications protocol;computer cluster;firmware;interconnection;multicast;network interface;network packet;networking hardware;parallel computing;supercomputer;user space;workstation	Kees Verstoep;Raoul Bhoedjang;Tim Rühl;Henri E. Bal;Rutger F. H. Hofman	2004	ACM Trans. Comput. Syst.	10.1145/1012268.1012269	embedded system;real-time computing;computer science;network interface;operating system;network simulation;distributed computing;computer network;data transmission	HPC	-17.13786705099698	43.152763765020225	55378
1d6b64580842e8bf715e6219f90b9c6962301cb5	development and implementation of block-structured adaptive mesh refinement for parallel computations in fluid mechanics			adaptive mesh refinement;computation;refinement (computing)	Rafael Sene de Lima	2012				HPC	-6.993925701443386	38.024386594052835	55591
412f902781bba0b70e3f07c4d42eebacfaa2218e	computing on multi-core platform: performance issues	multi core processor;cache;high performance computing;data locality;tiling;high performance computer;parallel programs;multi core processors	The ubiquity of multi-core processors in commodity computing systems has raised a significant programming challenge for their effective use. As multi-core processors with tens or hundreds of cores begin to proliferate, system optimization issues once faced by the high-performance computing (HPC) community will become important to all programmers. The focus of the multi-core programmer will be on productivity, portability as well as performance. We discuss in this paper mainly the performance issues involved in developing the software on the multi-core platform. This will help the developer in fine tuning his application on multi-core architecture. The paper studies a way to incorporate data locality problem into the parallel programming system using tiling approach coupled with OpenMP. The paper also shows that, there is a considerable performance enhancement with this approach when used in the algorithm.	admissible numbering;algorithm;central processing unit;commodity computing;intel core (microarchitecture);locality of reference;mathematical optimization;multi-core processor;openmp;parallel computing;program optimization;programmer;supercomputer;tiling window manager	M. R. Pimple;S. R. Sathe	2011		10.1145/1947940.1947997	computer architecture;parallel computing;real-time computing;computer science	HPC	-7.31123773801654	44.702597822190825	55694
1cb154c7cd0ed610161b7d4713b4a07dbbbc15ee	io-lite: a unified i/o buffering and caching system	workload;memoria tampon;sistema operativo;evaluation performance;optimisation;systeme unix;interprocess communication;entrada salida;performance evaluation;red www;optimizacion;concepcion sistema;caching;implementation;unix system;evaluacion prestacion;reseau ordinateur;serveur informatique;menu;cache memory;subestructura;buffer system;partage ressource;experimental result;computer network;sistema amortiguador;subsystem;antememoria;input output;prototipo;ejecucion;antememoire;zero copy;performance improvement;internet;operating system;programa aplicacion;sous systeme;application program;file system;system design;programme application;resource sharing;networking;sous structure;particion recursos;substructure;charge travail;red ordenador;resultado experimental;i o buffering;servidor informatico;world wide web;systeme exploitation;optimization;reseau www;serveur fichier;access control;sistema unix;computer hardware;carga trabajo;resultat experimental;systeme tampon;data protection;memoire tampon;subsistema;prototype;materiel informatique;material informatica;conception systeme;file server;entree sortie;computer server;buffer memory	This article presents the design, implementation, and evaluation of IO -Lite, a unified I/O buffering and caching system for general-purpose operating systems. IO-Lite unifies all buffering and caching in the system, to the extent permitted by the hardware. In particular, it allows applications, the interprocess communication system, the file system, the file cache, and the network subsystem to safely and concurrently share a single physical copy of the data. Protection and security are maintained through a combination of access control and read-only sharing. IO-Lite eliminates all copying and multiple buffering of I/O data, and enables various cross-subsystem optimizations. Experiments with a Web server show performance improvements between 40 and 80% on real workloads as a result of IO-Lite.	access control;adobe flash lite;bandwidth-delay product;cache (computing);common gateway interface;fault detection and isolation;freebsd;general-purpose markup language;input/output;inter-process communication;multiple buffering;operating system;prototype;read-only memory;serial ata;server (computing);socket.io;synthetic intelligence;throughput;web server	Vivek S. Pai;Peter Druschel;Willy Zwaenepoel	2000	ACM Trans. Comput. Syst.	10.1145/332799.332895	shared resource;input/output;embedded system;file server;real-time computing;the internet;cpu cache;substructure;computer science;bicarbonate buffering system;access control;operating system;system;prototype;data protection act 1998;implementation;server;systems design;inter-process communication	OS	-17.382077026118154	45.766842479338706	55794
7c332fe1daaaaff647c7f3a6108317be72eac313	scaling and analyzing the stencil performance on multi-core and many-core architectures	optimizations stencil multi core architecture many core architecture;program compilers graphics processing units multiprocessing systems;optimizations;compiler stencil performance multicore architecture many core architecture seven point jacobi stencil numerical simulation intel sandy bridge processor intel xeon phi coprocessor nvidia fermi c2070 gpu kepler k20x gpu graphics processing unit multithreading vectorization optimization wnad stencil;many core architecture;multi core architecture;stencil;kernel computer architecture optimization graphics processing units microwave integrated circuits registers instruction sets	Stencils are among the most important and time-consuming kernels in many applications. While stencil optimization has been a well-studied topic on CPU platforms, achieving higher performance and efficiency for the evolving numerical stencils on the more recent multi-core and many-core architectures is still an important issue. In this paper, we explore a number of different stencils, ranging from a basic 7-point Jacobi stencil to more complex high-order stencils used in finer numerical simulations. By optimizing and analyzing those stencils on the latest multi-core and many-core architectures (the Intel Sandy Bridge processor, the Intel Xeon Phi coprocessor, and the NVIDIA Fermi C2070 and Kepler K20x GPUs), we investigate the algorithmic and architectural factors that determine the performance and efficiency of the resulting designs. While multi-threading, vectorization, and optimization on cache and other fast buffers are still the most important techniques that provide performance, we observe that the different memory hierarchy and the different mechanism for issuing and executing parallel instructions lead to the different performance behaviors on CPU, MIC and GPU. With vector-like processing units becoming the major provider of computing power on almost all architectures, the compiler's inability to align all the computing and memory operations would become the major bottleneck from getting a high efficiency on current and future platforms. Our specific optimization of the complex WNAD stencil on GPU provides a good example of what the compiler could do to help.	align (company);automatic vectorization;central processing unit;compiler;coprocessor;graphics processing unit;jacobi method;kepler (microarchitecture);manycore processor;mathematical optimization;memory hierarchy;multi-core processor;multithreading (computer architecture);numerical analysis;sandy bridge;scalability;simulation;stencil buffer;thread (computing);xeon phi	Lin Gan;Haohuan Fu;Wei Xue;Yangtong Xu;Chao Yang;Xinliang Wang;Zihong Lv;Yang You;Guangwen Yang;Kaijian Ou	2014	2014 20th IEEE International Conference on Parallel and Distributed Systems (ICPADS)	10.1109/PADSW.2014.7097797	computer architecture;parallel computing;computer hardware;computer science;operating system;stencil	HPC	-4.649383427561345	39.89730999477941	55834
5afbbef5409b6bf9f94c38d97a7aea93d89e4697	compile-time thread distinguishment algorithm on vim-based architecture	modelizacion;latencia;evaluation performance;largeur bande;arithmetic operation;microarchitecture;architecture systeme;storage access;performance evaluation;localite;latence;operation arithmetique;evaluacion prestacion;locality;cache memory;operacion aritmetica;system performance;bolted joint;antememoria;programming model;memory access;modelisation;miniaturisation;computer architecture;antememoire;microstructure;low latency;architecture ordinateur;assemblage boulonne;anchura banda;retard;acces memoire;ensamblaje empernado;microarquitectura;hierarchie memoire;acceso memoria;bandwidth;arquitectura sistema;procesador;arquitectura ordenador;miniaturization;latency;memory hierarchy;miniaturizacion;processeur;system architecture;jerarquia memoria;retraso;modeling;processor;analytical model;microestructura	VIM integrates vector units into memory, which exploits the low-latency and high-bandwidth memory access. On VIM-based architecture, the low temporal locality thread running on VIM processor is called Light-Weight Thread, while the low cache miss rate thread running on host processor is called Heavy-Weight Thread. The thread distinguishment can impact the system performance directly. Compared with the distinguishment at programming model level, compile-time thread distinguishment can release programmer from changing existing program. After overviewing the VIM micro-architecture and the system architecture, this paper presents an analytical model of thread distinguishment. Based on this model, we present a compile-time algorithm and evaluate it with two thread instances on the evaluation environment we develop. We find that parameters affecting the thread distinguishment are the cache miss rate, the vectorizable operation rate and the arithmetic-to-memory ratio. We believe that this algorithm is constructive to improve the performance of the VIM-based node computer.	algorithm	Xiaobo Yan;Xuejun Yang;Pu Wen	2006		10.1007/11859802_58	embedded system;latency;parallel computing;win32 thread information block;systems modeling;cpu cache;computer hardware;microarchitecture;microstructure;computer science;operating system;miniaturization;computer performance;bolted joint;programming paradigm;bandwidth;systems architecture;low latency	Arch	-15.907329671683172	43.99867820603676	55875
46a1204c2779405c217cf108447b09963dc20369	supporting dynamic data and processor repartitioning for irregular applications	dynamic reconfiguration;resource allocation;cholesky factorization;dynamic data;parallel programming environment;distributed resource management;parallel applications	Recent research has shown that dynamic reconfiguration of resources allocated to parallel applications can improve both system utilization and application throughput. Distributed Resource Management System (DRMS) is a parallel programming environment that supports development and execution of reconfigurable applications on a dynamically varying set of resources. This paper describes DRMS support for developing reconfigurable irregular applications, using a sparse Cholesky factorization as a model application. We present performance levels achieved by DRMS redistribution primitives, which show that the cost of dynamic data redistribution between different processor configurations for irregular data are comparable to those for regular data.	dynamic data	José E. Moreira;Kalluri Eswar;Ravi B. Konuru;Vijay K. Naik	1996		10.1007/BFb0030114	parallel computing;real-time computing;computer science;distributed computing	Arch	-12.825222686464647	44.06082202870808	55950
e7264016181480b2b7998c0144ba6a3fa6e9c5c8	a concurrent computer architecture and a ring based implementation	data stream computation;computer architecture;information flow;concurrent programs;data flow	A multi-instruction-multi-data stream computer architecture is presented which is aimed at supporting highly concurrent general-purpose computation. The proposed machine is organised as a set of autonomous resources, each having direct access to a common intercommunication medium which is implemented as a rotating ring. The machine language is based on a generalised concept of control which provides an alternative to the data flow organisation for highly concurrent programming.  The progress of a concurrent computation is characterised by the flow of packets of work through resources via the ring. This information flow is organised in such a way as to optimise concurrent operation of the resources and to simplify allocation and intercommunication. Initial simulation results are presented to show the feasibility of the architecture.	autonomous robot;computation;computer architecture;concurrency (computer science);concurrent computing;dataflow;general-purpose modeling;machine code;random access;simulation	Edward P. Farrell;Noordin Ghani;Philip C. Treieaven	1979		10.1145/800090.802887	data flow diagram;computer architecture;parallel computing;information flow;computer science;theoretical computer science;operating system;distributed computing;programming language	Arch	-13.62384863334881	40.6459432495805	55953
8174aac0f597e4910cf31dc10ca0de4430a71c4a	how well do graph-processing platforms perform? an empirical performance evaluation and analysis	benchmark graph processing performance evaluation;graph processing;performance evaluation;measurement benchmark testing yarn scalability algorithm design and analysis terrestrial atmosphere programming;benchmark;data analysis benchmark testing;resource utilization graph processing platforms empirical performance evaluation comprehensive process representative metrics datasets algorithmic classes benchmarking suite user lever performance	Graph-processing platforms are increasingly used in a variety of domains. Although both industry and academia are developing and tuning graph-processing algorithms and platforms, the performance of graph-processing platforms has never been explored or compared in-depth. Thus, users face the daunting challenge of selecting an appropriate platform for their specific application. To alleviate this challenge, we propose an empirical method for benchmarking graph-processing platforms. We define a comprehensive process, and a selection of representative metrics, datasets, and algorithmic classes. We implement a benchmarking suite of five classes of algorithms and seven diverse graphs. Our suite reports on basic (user-lever) performance, resource utilization, scalability, and various overhead. We use our benchmarking suite to analyze and compare six platforms. We gain valuable insights for each platform and present the first comprehensive comparison of graph-processing platforms.	algorithm;graph (abstract data type);overhead (computing);performance evaluation;scalability	Yong Guo;Marcin Biczak;Ana Lucia Varbanescu;Alexandru Iosup;Claudio Martella;Theodore L. Willke	2014	2014 IEEE 28th International Parallel and Distributed Processing Symposium	10.1109/IPDPS.2014.49	simulation;benchmark;computer science;data science;data mining	Metrics	-4.548732227638759	45.23082436149722	56019
67d4f6b4b13ed47de28565446cb0c8c6cd3d764c	the role of parallel cellular programming in computational science	parallelisme;simulation systeme;modeling and simulation;programacion paralela;parallel programming;dynamic system;parallel computation;programming model;parallelism;calculo paralelo;paralelismo;efficient implementation;design and implementation;automate cellulaire;parallel computer;parallel programming tool;parallel implementation;cellular automata;system simulation;parallel languages;calcul parallele;simulacion sistema;cellular automaton;programmation parallele;automata celular	Cellular automata provide an abstract model of parallel computation that can be effectively used for modeling and simulation of complex phenomena and systems. The design and implementation of parallel languages based on cellular automata provide useful tools for the development of scalable algorithms and applications in computational science. We discuss here the use of cellular automata programming models and tools for parallel implementation of real-life problems in computational science. Cellular parallel programming tools allow for the exploitation on the inherent parallelism of cellular automata in the efficient implementation of natural solvers that simulate dynamical systems by a very large number of simple agents (cells) that interact locally. As a practical example, the paper shows the design of parallel cellular programs by a language called CARPET and discusses other languages for parallel cellular programming.	computation;computational science	Domenico Talia	2000		10.1007/3-540-44942-6_17	cellular automaton;computational science;parallel computing;computer science;cellular architecture;theoretical computer science;dynamical system;distributed computing;programming paradigm;algorithm;parallel programming model	HPC	-11.03413709360341	38.51399084447617	56118
918ee08c5577694b74706806697969d6a504bc1e	analysis and design of parallel algorithms and implementations for some image processing operations.	parallel algorithm;image processing;analysis and design			Mehrad Yasrebi;James C. Browne;Dharma P. Agrawal	1987			computer architecture;parallel computing;image processing;computer science;theoretical computer science;digital image processing;parallel algorithm;cost efficiency	EDA	-9.01167328694475	41.52445683124422	56257
bb8129f2c87de2d11523965fe3b4088599a10372	algorithms for distributed simulation - comparative study	asynchronous simulation discrete event simulation distributed simulation synchronization protocols;protocols;memory management;clocks;distributed computing;parallel programming;physics computing;asynchronous simulation;computational modeling discrete event simulation synchronization protocols clocks distributed computing physics computing parallel processing memory management system recovery;computational modeling;system recovery;synchronization;distributed programming discrete event simulation parallel programming;distributed programming;comparative study;distributed simulation;parallel processing;synchronization protocols;parallel and distributed simulation;discrete event simulation	Distributed discrete-event simulation is proposed as ail alternative to traditional sequential simulation. The paper discusses some important issues associated with the implementation of parallel and distributed simulation. The topics that are covered are classical and new synchronization protocols. The effectiveness of different algorithms for asynchronous simulation is discussed based on the numerical tests results.	algorithm;simulation	Ewa Niewiadomska-Szynkiewicz;Andrzej Sikora	2002		10.1109/PCEE.2002.1115262	communications protocol;parallel processing;synchronization;parallel computing;real-time computing;computer science;theoretical computer science;discrete event simulation;operating system;comparative research;distributed computing;computational model;memory management	EDA	-13.119604534838267	42.57942328217226	56663
36c3d1134a1dcfd428464ca78c1a45dd26d8bbce	the x-kernel: an architecture for implementing network protocols	distributed system;sistema operativo;protocols;kernel;systeme reparti;heart;network protocol;performance evaluation;protocole transmission;x kernel;application software;implementation;network operating systems;sistema informatico;nucleo sistema operativo;transmission message;computer system;sockets;operating systems kernel access protocols hardware application software sockets computer architecture performance evaluation heart encoding;interface x kernel architecture network protocols operating system kernel;message transmission;noyau systeme exploitation;ejecucion;computer architecture;protocolo transmision;network protocols;sistema repartido;operating system;interface;access protocols;protocols network operating systems;systeme exploitation;systeme informatique;operating system kernel;encoding;architecture;operating systems;transmision mensaje;hardware;transmission protocol	This paper describes a new operating system kernel, called the x-kernel, that provides an explicit architecture for constructing and composing network protocols. Our experience implementing and evaluating several protocols in the x-kernel shows that this architecture is both general enough to accommodate a wide range of protocols, yet efficient enough to perform competitively with less structured operating systems.	communications protocol;kernel (operating system);operating system	Norman C. Hutchinson;Larry L. Peterson	1991	IEEE Trans. Software Eng.	10.1109/32.67579	embedded system;communications protocol;real-time computing;computer science;operating system	OS	-18.41528291114865	42.9634913155393	56706
370947137e46482c7a30d8913307178bc094851f	an efficient solution to the mutual exclusion problem using unfair and weak semaphore	mutual exclusion	"""f r o m s e a u e n t i a l c, r o c e s s i n g i n t h a t t h e o r d e r i n w h i c h t h e e l e m e n t a r y s t e m s o # tlqe v a r i o u s p r o c e s s e s a r e e x e c u t e d i s n o t p r e d e t e r m i n e d b u t m a y d e m e ~ d o n v a r i a b l e s s u c h a s t h e r e l a t i v e s p e e d s o f t h e p r o c e s s e s. a e """" c r i t i c a l s e c t i o n s """" a n d a t m o s t o n e m r o c e s s c a n b e i n t h e c r i t i c a l s e c t i o n a t a g i v e n i n s t a n t o f t i m e. S u c h m u t u a l e x c l u s i o n o f a c c e s s t o c r i t i c a l s e c t i o n i s e n s u r e d b y meaz%s o f entr-ar~ce p r o t o c o l a~qd e x i t p r o t o c o l. It i s t h e j o b o f t h e p r o t o c o l t o e n s u r e t h a t o n l y o n e p r o c e s s a t a t i m e i s i n i t a c r …"""	emoticon;mutual exclusion	Sibsankar Haldar;D. K. Subramanian	1988	Operating Systems Review	10.1145/43914.43920	parallel computing;mutual exclusion;computer science;distributed computing	AI	-10.676818501643364	42.18707339240121	56710
b30f5a53e68581d09c9a3501cb4e67618b59d5a8	a concept visualization study of a parallel computing program	conceptual visualization;proposed visualization;high performance program code;language model;various visualization;concept visualization study;distinct visualization model;visualization technique;proposed visualization model;parallel program;parallel computing program;high level abstraction;concurrent computing;high performance computing;parallel computer;data mining;parallel processing;computer architecture;distributed computing;computer science;relational model;data visualization	Conceptual visualization is proposed in this paper to facilitate reading and understanding parallel programs. This addresses the need to better understand high performance program codes, especially, in an environment where the codes reflect the diversity in architecture as well as in programming and language models. A relational model is developed to represent abstractions about the program. High level abstractions are termed concepts in this work. A visualization technique based on the relation hierarchy and composed of two distinct visualization models is further proposed in this paper. A study of a simple MPI parallel program is made. Various visualizations from both of the proposed visualization models are included and discussed. Combined, the visualizations provide for qualitative and quantitative aspects relating to the concepts in the given program. This study suggests that the proposed visualizations do facilitate the understanding of parallel programs.	code;language model;message passing interface;parallel computing;relational model	Brian J. d'Auriol	2004	Workshops on Mobile and Wireless Networking/High Performance Scientific, Engineering Computing/Network Design and Architecture/Optical Networks Control and Management/Ad Hoc and Sensor Networks/Compil	10.1109/ICPPW.2004.1328023	parallel processing;computer architecture;parallel computing;relational model;concurrent computing;computer science;theoretical computer science;operating system;distributed computing;programming language;data visualization;language model	HPC	-13.81149696215728	39.39032749973513	56725
4778b83206e4ea4c1794958cf7ea516057a91ce1	using metaprogramming to parallelize functional specifications	functional programming;parallelization;metaprogramming;skeletons	Metaprogramming is a paradigm for enhancing a general-purpose programming language with features catering for a special-purpose application domain, without a need for a reimplementation of the language. In a staged compilation, the special-purpose features are translated and optimised by a domain-specific preprocessor, which hands over to the general-purpose compiler for translation of the domain-independent part of the program. The domain we work in is high-performance parallel computing. We use metaprogramming to enhance the functional language Haskell with features for the efficient, parallel implementation of certain computational patterns, called skeletons.	metaprogramming	Christoph Armin Herrmann;Christian Lengauer	2002	Parallel Processing Letters	10.1142/S0129626402000926	metaprogramming;computer architecture;parallel computing;dynamic compilation;template metaprogramming;computer science;metacompiler;programming language;functional programming	HPC	-14.564195718588447	36.96566407085919	56732
5e45ea8d472ed354d3c63c80c527af3adbf1fc3d	fault-aware grid scheduling using performance prediction by workload modeling	workload;parallel computing;grid scheduling;algorithme rapide;file attente;modelizacion;distributed system;outil logiciel;algoritmo paralelo;evaluation performance;optimisation;software tool;haute performance;ciclo desarrollo;systeme reparti;computational grid;parallel algorithm;optimum;performance evaluation;neural networks;optimizacion;life cycle;gestion labor;neural model;resource allocation;real time;evaluacion prestacion;online scheduling;resource management;machine parallele;distributed computing;queue;supercomputer;satisfiability;deadline;algorithme parallele;grid;supercomputador;modelisation;gestion recursos;large scale;scheduling algorithm;sistema repartido;gestion tâche;distributed environment;rejilla;scheduling;fast algorithm;temps reel;optimo;algorithme reparti;charge travail;performance model;parallel computer;cycle developpement;alto rendimiento;grille;gestion ressources;calculo repartido;tiempo real;distributed resource management;parallel machines;performance prediction;algoritmo repartido;optimization;asignacion recurso;task scheduling;reseau neuronal;allocation ressource;date limite;carga trabajo;herramienta software;fechas ultimas;distributed algorithm;modeling;grid computing;high performance;job scheduling;real time application;fila espera;calcul reparti;algoritmo rapido;red neuronal;ordonnancement;reglamento;superordinateur;neural network;time constraint	Computational grids hold great promise in utilizing geographically separated heterogeneous resources to solve large-scale complex problems. However, they suffer from a number of major technical hurdles, including distributed resource management and effective job scheduling. The main focus of this work is devoted on online scheduling of real time applications in distributed environments such as grids. Specifically, we are interested in applications with several independent tasks, each task with a prespecified lifecycle called deadline. Here, our goal is to schedule applications within an optimum overall time considering the specified deadlines. To achieve this, the resource performance prediction based on workload modeling and with the help of queuing techniques is employed. Afterward, a mathematical neural model is used to schedule the subtasks of the application. The main contributions of this work is to incorporate the impatiency factor as well as resource fault in performance modeling of nondedicated distributed systems, and also presenting an efficient and fast parallel scheduling algorithm under time constraint and heterogeneous resources. The proposed model is appropriate for implementation on parallel machines and in O(1) time. The new model was implemented on GridSim toolkit and under various conditions and with different parameters to evaluate the performance of scheduling algorithm. Simulation outcomes have shown that approximately in 87.8% of cases, our model schedules the tasks in such a way that all constraints are satisfied.	algorithm;artificial neural network;bandwidth (signal processing);c date and time functions;computation;dvd region code;distributed computing;emoticon;experiment;hysteresis;job scheduler;linux test project (ltp);mathematical optimization;performance prediction;probabilistic analysis of algorithms;queueing theory;response time (technology);responsiveness;run time (program lifecycle phase);scheduling (computing);simulation;statistical model;time series;twisted pair	Mohammad Kalantari;Mohammad Kazem Akbari	2008	The Journal of Supercomputing	10.1007/s11227-008-0183-3	fair-share scheduling;parallel computing;real-time computing;simulation;dynamic priority scheduling;computer science;operating system;distributed computing;scheduling;artificial neural network	HPC	-17.973834820734172	43.82670441608051	56759
7fa51f83eddf824c46d36206c7d7778503edb521	a coordination language for programming embedded multi-core systems	multi core processor;probability density function;niobium;process network;parallel programming;coordination language;data mining;argon;embedded system;embedded systems;parallel programming embedded system concurrent computing multicore processing application software programming profession computational modeling distributed computing embedded computing yarn;side effect;legacy code reusing coordination language embedded multicore system programming implicitly parallel language sequential process coordination translation scheme dataflow process network;software reusability;software reusability data flow computing embedded systems multiprocessing systems parallel languages parallel programming;data flow computing;multiprocessing systems;parallel languages;program processors	We propose an implicitly parallel language for the coordination of sequential processes and present a translation scheme to dataflow process networks. Our language is well-suited for programming embedded systems and allows to benefit from the computational power offered by modern multi-core processors. Moreover, it facilitates the reuse of legacy code and can deal with side effects that may arise between functions written in the guest language by taking into account dependencies due to shared resources.	best, worst and average case;c++;central processing unit;code refactoring;computation;data parallelism;dataflow;debugging;embedded system;java;kahn process networks;legacy code;mapreduce;model of computation;multi-core processor;parallel computing;parallel language;programmer;real-time clock;real-time computing;run time (program lifecycle phase);syntax-directed translation;worst-case execution time	Tobias Schüle	2009	2009 International Conference on Parallel and Distributed Computing, Applications and Technologies	10.1109/PDCAT.2009.38	multi-core processor;niobium;computer architecture;probability density function;parallel computing;language primitive;specification language;programming domain;computer science;programming language implementation;operating system;database;distributed computing;low-level programming language;programming language;argon;programming language specification;high-level programming language;side effect	EDA	-15.281359510042638	38.790344794184314	56814
4b6e260a8cf9de595ace0f58734987c036f33c19	a two step hardware design method using cλash	haskell two step hardware design method cλash hdl fpga higher level abstraction mechanism functional hardware description language adequate abstraction mechanisms polymorphism higher order function dsp application mathematical definition particle filtering;logic design;hardware description languages;mathematical analysis;program compilers field programmable gate arrays functional languages hardware description languages logic design mathematical analysis particle filtering numerical methods;hardware atmospheric measurements particle measurements design methodology equations mathematical model systematics;functional languages;field programmable gate arrays;program compilers;particle filtering numerical methods	In order to effectively utilize the growing number of resources available on FPGAs, higher level abstraction mechanisms are needed to deal with increasing complexity resulting from large designs. Functional hardware description languages, like the CλaSH HDL, offer adequate abstraction mechanisms such as polymorphism and higher-order functions. This paper describes a two step design method to implement a DSP application on an FPGA, starting from a mathematical specification, followed by an implementation in CλaSH. A non trivial application, a particle filter, is used to evaluate both the method and CλaSH. First, a straightforward translation is performed from the mathematical definition of a particle filtering to Haskell, a functional programming language with syntax and semantics similar to CλaSH. Secondly, minor changes are applied to the Haskell implementation so that it is accepted by the CλaSH compiler. The resulting hardware produced by our method is evaluated and shows that this method eases reasoning about structure and parallelism in both the mathematical definition and the resulting hardware.	compiler;digital signal processor;field-programmable gate array;functional programming;hardware description language;haskell;higher-order function;parallel computing;particle filter;programming language	Rinse Wester;Christiaan Baaij;Jan Kuper	2012	22nd International Conference on Field Programmable Logic and Applications (FPL)	10.1109/FPL.2012.6339258	embedded system;logic synthesis;computer science;theoretical computer science;hardware description language;programming language;functional programming;algorithm;field-programmable gate array	PL	-15.308130844470913	33.712964441051156	56822
1e3ee8a373c21d5c2b43bac455371675513fe53e	call path refinement profiles	optimising compilers;design decisions;program diagnostics;optimisation;cost function;recursive fashion;performance tuning call path refinement profiles complex programs recursive fashion reused general components performance information design decisions optimization opportunities function call sequences performance bottlenecks cpprof profiler;profiling;gollete estrangulamiento;optimising compilers software tools optimisation software performance evaluation program diagnostics;software performance evaluation;refinement;call path;inspection;design optimization;information presentation;optimization opportunities;program optimization;function call sequences;cost function design optimization programming profession optimizing compilers finite difference methods inspection data structures;reused general components;afinamiento;performance programme;goulot etranglement;performance bottlenecks;data structures;programming profession;affinement;call path refinement profiles;eficacia programa;performance information;software tools;optimisation programme;program performance;optimizing compilers;cpprof profiler;bottleneck;performance tuning;finite difference methods;complex programs;optimizacion programa	In order to effectively optimize complex programs built in a layered or recursive fashion (possibly from reused general components), the programmer has a critical need for performance information connected directly to the design decisions and other optimization opportunities present in the code. Call path refinement profiles are novel tools for guiding the optimization of such programs, that: (1) provide detailed performance information about arbitrarily nested (direct or indirect) function call sequences, and (2) focus the user's attention on performance bottlenecks by limiting and aggregating the information presented. This paper discusses the motivation for such profiles, describes in detail their implementation in the CPPROF profiler, and relates them to previous profilers, showing how most widely available profilers can be expressed simply and efficiently in terms of call path refinements. >		Robert J. Hall	1995	IEEE Trans. Software Eng.	10.1109/32.391375	real-time computing;multidisciplinary design optimization;simulation;inspection;data structure;computer science;finite difference method;operating system;software engineering;program optimization;refinement;profiling;programming language;engineering drawing	SE	-17.792450220228584	35.253655447297014	56865
ee62b6e7db7b08626a64aca9390fa158acaa4d6f	implementation and evaluation of an amr framework for fdm applications		Abstract   In order to e xecute various finite-difference method applications on large-scale parallel computers with a reasonable cost of computer resources, a framework using an adaptive mesh refinement (AMR) technique has been developed. AMR can realize high -resolution simulations while saving computer resources by generating and removing hierarchica l grids dynamically. In the AMR frame work, a dynamic domain decomposition (DDD) technique, as a dynamic load balancing method, is also implemented to correct the computational load imbalance between each process associated with parallelization. By performing a 3D AM R test simulation, it is confirmed that dynamic load balancing can be achieved and execution time can be reduced by introducing the DDD technique.		Masaharu Matsumoto;Futoshi Mori;Satoshi Ohshima;Hideyuki Jitsumoto;Takahiro Katagiri;Kengo Nakajima	2014		10.1016/j.procs.2014.05.084	embedded system;parallel computing;real-time computing;computer science	Vision	-4.979137582553937	40.49934857860969	57120
12c6db658575fdc16d52f9f6c3568a0deeb2676e	pat : an interactive fortran parallelizing assistant tool			automatic parallelization;fortran	Kevin Smith;William F. Appelbe	1988				HCI	-8.668762936799528	37.474579380045576	57187
0bfcb778feb03978e57c0c87959c1ff4b3a466b5	the mgap's programming environment and the *c++ language	mgap s programming environment;programming environments;programming environments assembly high level languages computer architecture computer science workstations application specific integrated circuits performance loss coprocessors high performance computing;programming environment;custom asics;data type;compiler;parallel data types like bit;workstation co processor board;c language;application specific integrated circuits;class concept;fine grain processors;high level language mgap s programming environment c language workstation co processor board fine grain processors custom asics class concept parallel data types like bit data types compiler;c language programming environments application specific integrated circuits parallel processing;high level language;parallel processing;data types	The MGAP is a special-purpose, workstation co-processor board in which the computing elements are fine grain processors implemented as custom ASICs. In this paper we present the language *CC++, used for programming on the MGAP. Using the class concept of C++ we create special parallel data-types like bit, digit, word and array and overload operators to manipulate the parallel data required by the MGAP. The hierarchical relationships among the data-types are used by the compiler to generate parallel code for the MGAP. We demonstrate that by using the same high-level language and the same program we can operate on data at all levels of granularity, from bits to arrays, without any loss in performance.	c++;integrated development environment	Raminder Singh Bajwa;Robert Michael Owens;Mary Jane Irwin	1995		10.1109/ASAP.1995.522912	embedded system;parallel processing;computer architecture;parallel computing;data type;computer science;operating system;programming language	PL	-13.3364887422331	38.139436500204084	57234
f7bf32308e0a4403c13d602d8ee7c26677e2d216	a cloud computing based framework for general 2d and 3d cellular automata simulation	simulation;web services;cellular automata;sparse matrices;game of life;cloud computing	Cellular automata can be applied to solve several problems in a variety of areas, such as biology, chemistry, medicine, physics, astronomy, economics, and urban planning. The automata are defined by simple rules that give rise to behavior of great complexity running on very large matrices. 2D applications may require more than 106 x 106 matrix cells, which are usually beyond the computational capacity of local clusters of computers. This paper presents a solution for traditional cellular automata simulations. We propose a scalable software framework, based on cloud computing technology, which is capable of dealing with very large matrices. The use of the framework facilitates the instrumentation of simulation experiments by non-computer experts, as it removes the burden related to the configuration of MapReduce jobs, so that researchers need only be concerned with their simulation algorithms.	algorithm;automata theory;cellular automaton;cloud computing;computation;computer;experiment;graphics processing unit;intranet;job stream;mapreduce;parallel computing;scalability;scheduling (computing);scripting language;server (computing);simulation;software development kit;software framework;solver;sparse matrix;subdivision surface	Rodrigo Marques;Bruno Feijó;Karin K. Breitman;Thieberson Gomes;Laercio Ferracioli;Hélio Lopes	2013	Advances in Engineering Software	10.1016/j.advengsoft.2013.05.014	cellular automaton;web service;simulation;sparse matrix;cloud computing;computer science;artificial intelligence;theoretical computer science;operating system;machine learning;mathematics;distributed computing;algorithm	HPC	-8.544782373454765	37.62609164316741	57241
a34dc27abcc2c46ab9dba0bf5b6c639771656b33	improving dynamic binary optimization through early-exit guided code region formation	virtual machine;trace based jit compilation;performance;hardware based performance monitoring;hot region formation;design;dynamic binary translation;article	Most dynamic binary translators (DBT) and optimizers (DBO) target binary traces, i.e. frequently executed paths, as code regions to be translated and optimized. Code region formation is the most important first step in all DBTs and DBOs. The quality of the dynamically formed code regions determines the extent and the types of optimization opportunities that can be exposed to DBTs and DBOs, and thus, determines the ultimate quality of the final optimized code. The Next-Executing-Tail (NET) trace formation method used in HP Dynamo is an early example of such techniques. Many existing trace formation schemes are variants of NET. They work very well for most binary traces, but they also suffer a major problem: the formed traces may contain a large number of early exits that could be branched out during the execution. If this happens frequently, the program execution will spend more time in the slow binary interpreter or in the unoptimized code regions than in the optimized traces in code cache. The benefit of the trace optimization is thus lost. Traces/regions with frequently taken early-exits are called delinquent traces/regions. Our empirical study shows that at least 8 of the 12 SPEC CPU2006 integer benchmarks have delinquent traces.  In this paper, we propose a light-weight region formation technique called Early-Exit Guided Region Formation (EEG) to improve the quality of the formed traces/regions. It iteratively identifies and merges delinquent regions into larger code regions. We have implemented our EEG algorithm in two LLVM-based multi-threaded DBTs targeting ARM and IA32 instruction set architecture (ISA), respectively. Using SPEC CPU2006 benchmark suite with reference inputs, our results show that compared to an NET-variant currently used in QEMU, a state-of-the-art retargetable DBT, EEG can achieve a significant performance improvement of up to 72% (27% on average), and to 49% (23% on average) for IA32 and ARM, respectively.	arm architecture;algorithm;benchmark (computing);cpu cache;digital footprint;dragon ball online;electroencephalography;ia-32;llvm;mathematical optimization;thread (computing);tracing (software)	Chun-Chen Hsu;Pangfeng Liu;Jan-Jan Wu;Pen-Chung Yew;Ding-Yong Hong;Wei-Chung Hsu;Chien-Min Wang	2013		10.1145/2451512.2451519	design;parallel computing;real-time computing;simulation;performance;computer science;virtual machine;operating system;programming language	Arch	-18.434308062734164	36.72874639474939	57246
65884088e5015b211547eae44e01c7244795fc4b	efficiency of parallel java using smp and client-server	message passing inter- face;rmi.;sockets;threads;java;distributed and parallel programming;client server;ease of use;message passing interface	Networked UNIX workstations as well as workstations running Windows 98 and Windows NT are fast becoming the standard computing environments at many universities and research sites. Additionally, many of these workstations, because of recent cost improvements, are commonly Symmetric Multiprocessor (SMP) workstations with two or four (or sometimes more) CPUs. Educators and researchers search for efficient methods of taking advantage of these advances in hardware technology. Java, with its wide usage, is fast becoming the choice of professionals because of its wealth of options as well as its ease of use. This paper investigates the use of Java sockets, Java RMI, and Java threads for parallel programming. We compare Java results with a standard message passing environment widely used in distributed programming, message passing interface (MPI).	central processing unit;distributed computing;java remote method invocation;message passing interface;microsoft windows 98;parallel computing;symmetric multiprocessing;unix;usability;windows nt;workstation	Maurice Eggen;Roger Eggen	2000			message passing;computer science;client–server model;distributed computing;parallel computing;usability;operating system;message passing interface;java	HPC	-11.36996064871744	41.01646089420411	57264
a65bdc139c6c706a8583bccab398601b762c2b05	instruction-level parallelism in prolog: analysis and architectural support	vliw architectures.;global code optimizations;symbol project;static kstruction- level parallelism;code analysis result;berkeley abstract machine;architectural support;instruction-level parallelism;global compaction techniques;past microcoded implementation;basic dedicated feature;global compaction technique;risc-based processor;high performance prolog processor;prolog shared-menwy model;implementation detail;compaction;hardware;concurrent computing;code optimization;abstract machine;shared memory;data analysis;prototypes;very large scale integration;parallel processing	The demand of increasing computation power for symbolic processing has given a strong impulse to the development of ASICs dedicated to the execution of prolog. Unlike past microcoded implementation based on the Warren machine model, novel trends in high performance Prolog processors suggest the implementation of RISC-based processors committed to prolog only through the adoption of a few basic dedicated features, like the Berkeley Abstract Machine (BAM) processor.Following the idea of using a smart compiler for a simple instruction set, the SYMBOL project represents an experiment in applying global compaction techniques and VLIW design philosophy to the static exploitation of instruction-level parallelism in Prolog.This paper presents code analysis results and  shows how we can approach the theoretical speed-up limit (about 3) imposed by Amdahl's law on shared memory models, by means of global code optimizations and a suitable architectural support. In addition, we show implementation details and some preliminary data of a VLSI prototype architecture.	instruction-level parallelism;parallel computing;prolog	Alessandro De Gloria;Paolo Faraboschi	1992		10.1109/ISCA.1992.753319	shared memory;compaction;parallel processing;computer architecture;parallel computing;concurrent computing;computer science;theoretical computer science;operating system;program optimization;prototype;abstract machine;very-large-scale integration;data analysis;programming language	Arch	-14.1169716184164	39.09426571267506	57367
acb59ee7f53539939c5c8c30d4c290745f822656	world-wide distributed multiple replications in parallel for quantitative sequential simulation	planetlab;sequential quantitative stochastic simulation;experimental networking facilities;open queuing network;akaroa2;multiple replications in parallel	With the recent deployment of global experimental networking facilities, dozens of computer networks with large numbers of computers have become available for scientific studies. Multiple Replications in Parallel (MRIP) is a distributed scenario of sequential quantitative stochastic simulation which offers significant speedup of simulation if it is executed on multiple computers of a local area network. We report results of running MRIP simulations on PlanetLab, a global overlay network which can currently access more than a thousand computers in forty different countries round the globe. Our simulations were run using Akaroa2, a universal controller of quantitative discrete event simulation designed for automatic launching of MRIP-based experiments. Our experimental results provide strong evidence that global experimental networks, such as PlanetLab, can efficiently be used for quantitative simulation, without compromising speed and efficiency.	computer;distributed computing;experiment;full scale;online and offline;overlay network;planetlab;run time (program lifecycle phase);simulation;software deployment;speedup	Mofassir Haque;Krzysztof Pawlikowski;Donald C. McNickle;Gregory Ewing	2011		10.1007/978-3-642-24669-2_4	parallel computing;simulation;computer science;theoretical computer science;operating system;distributed computing	Comp.	-11.25996651660458	40.96986352179341	57498
1c15b44c2d40fe7d44c1f7d6f99086c7c9144af4	exploiting memory affinity in openmp through schedule reuse	shared memory;non uniform memory access;data;page placement;programming model;computation affinity;loop scheduling;shared memory programming models;data access;openmp;article	In this paper we explore the idea of reusing loop schedules to improve the scalability of numerical codes in shared-memory architectures with non-uniform memory access. The main objective is to implicitly construct affinity links between threads and data accesses and reuse them as much as possible along the execution of the program. These links are created through the definition and reuse of iteration schedules which are either defined statically by the user or created dynamically at run time. The paper does not include a formal proposal of OpenMP extensions but includes some experiments showing the usefulness of constructing affinity links in both regular and irregular codes.	code;experiment;iteration;non-uniform memory access;numerical analysis;openmp;processor affinity;run time (program lifecycle phase);scalability;shared memory;uniform memory access	Dimitrios S. Nikolopoulos;Ernest Artiaga;Eduard Ayguadé;Jesús Labarta	2001	SIGARCH Computer Architecture News	10.1145/563647.563657	uniform memory access;data access;shared memory;computer architecture;parallel computing;computer science;operating system;distributed computing;programming paradigm;programming language;data;non-uniform memory access	HPC	-7.394257141079903	43.752095715014036	57525
38add6d6fb840594d7d0ff87633bca2b4c0013f6	pacxxv2 + rv: an llvm-based portable high-performance programming model		To achieve high performance on todayu0027s high-performance computing (HPC) systems multiple programming models have to be used. An example for this burden to the developer is OpenCL: the OpenCLu0027s SPMD programming model must be used together with a host programming model, commonly C or C++. Different programming models require different compilers for code generation, which introduce challenges for the software developer, e. g., different compilers must be convinced to agree on basic properties like type layouts to avoid subtle bugs. Moreover, the resulting performance highly depends on the features of the used compilers and may vary unpredictably. We present PACXXv2 -- an LLVM based, single-source, single-compiler programming model which integrates explicitly parallel SPMD programming into C++. Our novel CPU back-end provides portable and predictable performance on various state-of-the-art CPU architectures comprising Intel x86 architectures, IBM Power8 and ARM Cortex CPUs. We efficiently integrate the Region Vectorizer (RV) into our back-end and exploit its whole function vectorization capabilities for our kernels. PACXXv2 utilizes C++ generalized attributes to transparently propagate information about memory allocations to the PACXX back-ends to enable additional optimizations. We demonstrate the high-performance capabilities of PACXXv2 together with RV on benchmarks from well-known benchmark suites and compare the performance of the generated code to Intelu0027s OpenCL driver and POCL -- the portable OpenCL project based on LLVM.	arm architecture;automatic vectorization;benchmark (computing);c++;central processing unit;code generation (compiler);comparison of raster-to-vector conversion software;compiler;llvm;opencl api;programming model;region-based memory management;spmd;software bug;software developer;supercomputer;x86	Michael Haidl;Simon Moll;Lars Klein;Huihui Sun;Sebastian Hack;Sergei Gorlatch	2017		10.1145/3148173.3148185	compiler;parallel computing;power8;computer architecture;spmd;software;x86;programming paradigm;code generation;arm architecture;computer science	HPC	-6.120590706846011	44.61708211922645	57734
d5070dd26507034afb057a7d7f952be5637cf073	a framework for exploiting object parallelism in distributed systems	distributed system;eficacia sistema;architecture systeme;systeme reparti;interoperabilite;sistema informatico;performance systeme;computer system;system performance;computer network;distributed objects;sistema repartido;parallel architectures;architecture parallele;reseau informatique;parallel computer;arquitectura sistema;systeme informatique;interoperability;system architecture	To support parallel computing in a distributed object-based computing platform, a uniform high performance distributed object architecture layer is necessary. In this paper, we propose a distributed object-based framework called DoHPC to support parallel computing on distributed object architectures. We present the use of dependence analysis technique to exploit intra-object parallelism and an interoperability model for supporting distributed parallel objects. Experimental results on a Fujitsu AP3000 UltraSPARC workstation cluster computer show that with intra-object parallel computation speedup eeciency is greater than 90% and with overhead of less than 10% for large problems. In addition, the interoperability model improves speedup by 20%.	alloy analyzer;central processing unit;compiler;computation;computer cluster;data parallelism;dependence analysis;distributed computing;distributed object;interoperability;load balancing (computing);object-based language;overhead (computing);parallel computing;scalability;scheduling (computing);speedup;ultrasparc;workstation	Wang Chen;Yong Meng Teo	2000		10.1007/3-540-45492-6_82	embedded system;interoperability;distributed algorithm;parallel computing;computer science;operating system;distributed computing;computer performance;data parallelism;distributed object;distributed design patterns;systems architecture	HPC	-17.51949922142764	42.71231253604287	57950
fccdb51887233b82f7f55287ab337c30a5a18895	computer benchmark evaluation and design of experiments, a case study	user load;modelizacion;eficacia sistema;configuracion;computer aided software engineering capacity planning performance analysis computer performance predictive models operating systems economic forecasting environmental economics analysis of variance delay;computer installation;charge systeme;main storage configuration;performance evaluation computer installation configuration management;metodologia;performance evaluation;analisis sistema;gollete estrangulamiento;carga sistema;benchmark;sistema informatico;performance systeme;response time;computer system;area of concern;system performance;statistical model;methodologie;computer performance analysis computer benchmark evaluation design of experiments installation tuning computer configurations paging configuration models statistical model response time user load main storage configuration;modelisation;goulot etranglement;paging configuration;design of experiments;computer configurations;computer benchmark evaluation;analyse performance;performance analysis;system analysis;computer performance analysis;installation tuning;systeme informatique;analyse systeme;methodology;configuration;modeling;bottleneck;configuration management;models;analytical model;system load;analisis eficacia;design of experiment	The author defines installation tuning and promotes it as an important area of concern for computer configurations. Examples include deciding on the paging configuration for a particular workload and partitioning available memory into system and user areas. Available tuning options are often difficult to select due to poor understanding of their effects, so analytic models rarely exist for these areas. The author illustrates the use of various models to assess the significance of installation tuning factors. A case study is presented in which a statistical model for response time is developed incorporating the key factors of user load, paging, and main storage configuration. A case study is presented in which a statistical design of experiments to computer performance analysis is presented. General statistical issues pertaining to the design and analysis of computer performance experiments are identified and illustrated. >	benchmark (computing);design of experiments	Robert F. Berry	1992	IEEE Trans. Computers	10.1109/12.166605	embedded system;simulation;operating system;computer performance;design of experiments;statistics	Mobile	-17.764131531674042	46.23614527794286	57986
4b6e2d78b08968a672d1febbb7b99f678d7bb4c9	co-scheduling of mpi and adaptive thread applications under solaris			message passing interface;scheduling (computing)	Angela C. Sodan;M. Riyadh	2002			parallel computing;distributed computing;scheduling (computing);thread (computing);computer science	HPC	-9.717631269682078	43.19884866555531	58019
5335a9bcd9d415138f305f96055dd9b360a68f7b	multicasting in optical bus connected processors using coincident pulse techniques			multicast	Chunming Qiao;Rami G. Melhem;Donald M. Chiarulli;Steven P. Levitan	1991			multicast;parallel computing;distributed computing;coincident;computer science;pulse (signal processing)	EDA	-10.846764168691402	43.13986325847057	58100
817017c84d580e644fe954c81a3323e15bc6e624	memory semantics in large grained persistent objects			memory semantics (computing)	Partha Dasgupta;Raymond C. Chen	1990			memory semantics;theoretical computer science;computer science	DB	-11.193199865751396	43.9320630535071	58237
2ca1640c722b3a73806641dfe8a5dc708ce5a632	distributed data structures and the power of topological self-stabilization			data structure;self-stabilization	Sebastian Kniesburges	2015				Theory	-9.22217336172888	33.69754473255813	58248
8ff666e560bd0df3ad4e5b8f7b7dedf86244239c	executing communication-intensive irregular programs efficiently	algoritmo paralelo;parallel algorithm;algorithm performance;processor scheduling;algorithme parallele;computer architecture;calculateur mimd;architecture ordinateur;resultado algoritmo;performance algorithme;arquitectura ordenador;ordonnancement processeur;parallel programs;mimd computer	We consider the problem of eÆciently executing completely irregular, communication-intensive parallel programs. Completely irregular programs are those whose number of parallel threads as well as the amount of computation performed in each thread vary during execution. Our programs run on MIMD computers with some form of space-slicing (partitioning) and time-slicing (scheduling) support. A hardware barrier synchronization mechanism is required to eÆciently implement the frequent communications of our programs, and this constrains the computer to a xed size partitioning policy. We compare the possible scheduling policies for irregular programs on xed size partitions: local scheduling and multi-gang scheduling, and prove that local scheduling does better. Then we introduce competitive analysis and formally analyze the online rebalancing algorithms required for eÆcient local scheduling under two scenarios: with full information and with partial information.	algorithm;amortized analysis;barrier (computer science);best, worst and average case;central processing unit;communications of the acm;competitive analysis (online algorithm);computation;computer;distributed computing;experiment;gang scheduling;icdcs;job scheduler;job shop scheduling;lecture notes in computer science;mimd;online algorithm;overhead (computing);paging;responsiveness;spaa;scheduling (computing);simulation;springer (tank);time slicing (digital broadcasting)	Vara Ramakrishnan;Isaac D. Scherson	2000		10.1007/3-540-45591-4_61	parallel computing;real-time computing;computer science;operating system;distributed computing;parallel algorithm;programming language;algorithm	Arch	-14.227108492726305	45.92860149543449	58497
880b780ec1b4d61bd89c73b1aaa40c7fd8406095	fault-tolerant parallel computing for dem data blocks with layered dependent relationships based on redundancy mechanism	parallel computing;dem data blocks;layered dependent relationships;dta;digital elevation model;data dependency models;data partitioning;parallelism;fault tolerant computing;redundancy;digital terrain analysis;fault tolerance;parallel scheduling	The objective of this paper is to build a quantitative method of data partition in parallelisation of digital terrain analysis DTA so as to guide the design of algorithms in parallel computing. According to the data-intensive characteristics of the digital elevation model DEM, a data dependency model is proposed to describe the hierarchical relationships of data blocks. The parallel schedule policies and algorithms for the DEM are built according to the model. With the increase of computing scale in data or tasks, the reliability of the calculation must also be considered in parallel computing. A fault-tolerant parallel computing method is proposed based on the data dependence graph. Respectively, this paper puts forward parallel computing algorithms of two times redundant, three times redundant and partially redundant, with a discussion of their respective advantages. Finally, a visibility algorithm in DTA as an example is used to verify the validity of the strategies and methods.	parallel computing	Wanfeng Dou;Shoushuai Miao;Yan Li	2015	IJHPCN	10.1504/IJHPCN.2015.072784	fault tolerance;parallel computing;digital elevation model;computer science;theoretical computer science;operating system;database;distributed computing;data parallelism;redundancy	HPC	-8.337256712257687	45.015381187978996	59131
6a6f321a38c21c6a6b4164fa6c5e206b44b4f2c0	an analysis of some multi-microprocessor scheduling strategies for parallel programs			microprocessor;scheduling (computing)	M. B. Crespo	1980				Arch	-9.62208748738421	43.21236323956754	59138
076c7a425231d61d2843d37db395275140c9509d	automatic parallelization	automatic parallelization	When people talk about parallel computers, they often make assertions about the ability (or inability) of compilers to automatically parallelize programs, especially existing applications or dusty decks. Some people are quite optimistic; others are very pessimistic. The collected claims of the two groups have given rise to the myth of automatic parallelization. There are two common versions of the myth:	agi-plan;algorithm;automatic parallelization;column (database);compiler;computer;computer chess;flow-matic;matrix multiplication;optimistic concurrency control;parallel programming model;program comprehension;register allocation;scalar processor	Preston Briggs	1996	SIGPLAN Notices	10.1145/249118.249121	automatic parallelization	PL	-13.088345734071494	39.72365105183435	59167
7155aea050dc20483c6a70d6feb15d9afb867a31	agent-based simulation of kernel p systems with division rules using flame		Kernel P systems (or kP systems) bring together relevant features from several P systems flavours into a unified kernel model which allows solving complex problems using a straightforward code programming approach. kPWorkbench is a software suite enabling specification, parsing and simulation of kP systems models defined in the kernel P– Lingua (or kP-Lingua) programming language. It has been shown that any computation of a kP system involving only rewriting and communication rules can be simulated by a family of Communicating Stream X-Machines (or CSXM ), which are the core of FLAME agent based simulation environment. Following this, kPWorkbench enables translating kPLingua specifications into FLAME models, which can be simulated in a sequential or parallel (MPI based) way by using the FLAME framework. Moreover, FLAME GPU framework enables efficient simulation of CSXM on CUDA enabled GPGPU devices. In this paper we present an extension of kPWorkbench framework to generate FLAME models from kP–Lingua specifications including structural rules; and consider translation of FLAME specifications into FLAME GPU models. Also, we conduct a performance evaluation regarding simulation of equivalent kP systems and CSXM models in kPWorkbench and FLAME respectively.	agent-based model;cuda;computation;flame (malware);general-purpose computing on graphics processing units;graphics processing unit;kernel (operating system);p system;parsing;performance evaluation;pixel;programming language;rewriting;simulation;software suite;x-machine	Raluca Lefticaru;Luis F. Macías-Ramos;Ionut-Mihai Niculescu;Laurentiu Mierla	2016		10.1007/978-3-319-54072-6_18	combinatorics;discrete mathematics;theoretical computer science;mathematics	Embedded	-11.338805229520911	34.12787836696165	59172
b343fe24d239132190a155700c6493ccc5accd30	faster simulation of timed petri nets via distributed simulation	null message based scheme;petri nets computational modeling concurrent computing discrete event simulation parallel processing fires distributed computing cities and towns educational institutions computer simulation;distributed algorithms;concurrent computing;distributed computing;distributed simulation schemes;place nodes;discrete event system;time petri net;computational modeling;concurrency;algorithmic details timed petri net simulation distributed simulation null message based scheme distributed simulation schemes discrete event systems place nodes concurrency overhead messages;distributed algorithms discrete event simulation petri nets;discrete event systems;overhead messages;cities and towns;algorithmic details;petri nets;distributed simulation;fires;computer simulation;parallel processing;discrete event simulation;timed petri net simulation	In an earlier work (D. Kumar and S. Harous, 1990; 1994), we presented an approach towards the distributed simulation of timed Petri nets. This approach is based on some major changes to K.M. Chandy and J. Misra's (1979) null message based scheme. These changes were required because the well known distributed simulation schemes for discrete event systems do not directly apply to timed Petri nets due to the nonautonomous nature of place nodes in these systems. Moreover, our scheme incorporated several ideas to increase the degree of concurrency and to reduce the number of overhead messages in distributed simulation. We provide several algorithmic details to implement the above approach. The specific model of timed Petri nets that we assume here was also presented by us in the same earlier work.	petri net;simulation	Devendra Kumar;Amit Kohli;Venkatasubramaniam Narayanswamy	1997		10.1109/CMPSAC.1997.624778	computer simulation;parallel processing;real-time computing;stochastic petri net;concurrent computing;concurrency;computer science;theoretical computer science;discrete event simulation;distributed computing;process architecture;programming language;computational model;petri net	EDA	-13.339304112486124	42.54425327853959	59296
d7aa22f4db5ca61d029b93db3770a2a05cb169a8	cachetor: detecting cacheable data to remove bloat	runtime bloat;cacheable data;dynamic dependence analysis;performance optimization	Modern object-oriented software commonly suffers from runtime bloat that significantly affects its performance and scalability. Studies have shown that one important pattern of bloat is the work repeatedly done to compute the same data values. Very often the cost of computation is very high and it is thus beneficial to memoize the invariant data values for later use. While this is a common practice in real-world development, manually finding invariant data values is a daunting task during development and tuning. To help the developers quickly find such optimization opportunities for performance improvement, we propose a novel run-time profiling tool, called Cachetor, which uses a combination of dynamic dependence profiling and value profiling to identify and report operations that keep generating identical data values. The major challenge in the design of Cachetor is that both dependence and value profiling are extremely expensive techniques that cannot scale to large, real-world applications for which optimizations are important. To overcome this challenge, we propose a series of novel abstractions that are applied to run-time instruction instances during profiling, yielding significantly improved analysis time and scalability. We have implemented Cachetor in Jikes Research Virtual Machine and evaluated it on a set of 14 large Java applications. Our experimental results suggest that Cachetor is effective in exposing caching opportunities and substantial performance gains can be achieved by modifying a program to cache the reported data.	cache (computing);call site;computation;data structure;dependence analysis;java;jikes;mathematical optimization;memoization;online and offline;overhead (computing);profiling (computer programming);scalability;sensor;software bloat;virtual machine	Khanh Nguyen;Guoqing Xu	2013		10.1145/2491411.2491416	real-time computing;simulation;computer science;theoretical computer science	SE	-18.129249674756437	37.280061941878	59340
d8edd8193e3eb0e97a12d13bc1250c79e8de83b2	what is a lightweight kernel?	high performance computing;lightweight kernels;hybrid kernels;multi kernels	Lightweight kernels (LWK) have been in use on the compute nodes of supercomputers for decades. Although many high-end systems now run Linux, interest in options and alternatives has increased in the last couple of years. Future extreme-scale systems require rethinking of the operating system, and modern LWKs may well play a role in the final solution.  In the course of our research, it has become clear that no single definition for a lightweight kernel exists. This paper describes what we mean by the term and what makes LWKs different from other operating system kernels.	ibm websphere extreme scale;kernel (operating system);lightweight kernel operating system;linux;supercomputer	Rolf Riesen;Arthur B. Maccabe;Balazs Gerofi;David N. Lombard;Jack Lange;Kevin T. Pedretti;Kurt B. Ferreira;Mike Lang;Pardo Keppel;Robert W. Wisniewski;Ron Brightwell;Todd Inglett;Yoonho Park;Yutaka Ishikawa	2015		10.1145/2768405.2768414	real-time computing;simulation;computer science;theoretical computer science	OS	-9.179088276386594	45.39754389060829	59437
95aaff897259b843149fc2bca85c6a5210bc7fec	monitoring shared virtual memory performance on a myrinet-based pc cluster	object oriented framework;parallel scientific computation;shared virtual memory;distributed data structures;network connectivity;pc cluster;parallel computer	Network-connected clusters of PCs or workstations are beco ming a widespread parallel computing platform. Performance meth odologies that use either simulation or high-level software inst rumentation cannot adequately measure the detailed behavior of suc h systems. The availability of new network technologies based on programmable network interfaces opens a new avenue of research in analyzing and improving the performance of software shared m mory protocols. We have developed monitoring firmware embedd ed in the programmable network interfaces of a Myrinet-based P C cluster. Timestamps on network packets facilitate the coll e tion of low-level statistics on, e.g., network latencies, inter rupt handler times and inter-node synchronization. This paper describes our use of the low-level software perfo rmance monitor to measure and understand the performance of a Shared Virtual Memory (SVM) system implemented on a Myrinet based cluster, running the SPLASH-2 benchmarks. We measure d time spent in various communication stages during the main p rotocol operations: remote page fetch, remote lock synchroni zation, and barriers. These data show that remote request contentio n i the network interface and hosts can serialize their handlin g and artificially increase the page miss time. This increase then di lates the critical section within which it occurs, increasing loc k ontention and causing lock serialization. Furthermore, lock serialization is reflected in the waiting time at barriers. These resul ts of our study sharpen and deepen similar but higher-level speculat ions in previous simulation-based SVM performance research. More over, the insights about different layers, including communicat ion architecture, SVM protocol, and applications, on real systems pr ovide guidelines for better designs in those layers.	computer cluster;critical section;firmware;high- and low-level;network interface;parallel computing;serialization;simulation;software architecture;workstation	Cheng Liao;Dongming Jiang;Liviu Iftode;Margaret Martonosi;Douglas W. Clark	1998		10.1145/277830.277886	distributed shared memory;shared memory;parallel computing;distributed memory;computer science;operating system;distributed computing;data diffusion machine	Arch	-11.45456172656404	45.72785197155953	59438
0c3b25522ce157f6a813660fd3f2209d4105d814	drama: a library for parallel dynamic load balancing of finite element applications	direct mesh migration;drama library;application code;finite element applications;jostle package;dynamic load balancing;application data;parallel dynamic load;necessary information;software library;finite element code;communication requirement	We describe a software library for dynamic load balancing of finite element codes. The application code has to provide the current distributed mesh and information on the calculation and communication requirements, and receives from the library all necessary information to re-allocate the application data. The library computes a new partitioning, either via direct mesh migration or via parallel graph re-partitioning, by interfacing to the ParMetis or Jostle package. We describe the functionality of the DRAMA library and we present some results.	load balancing (computing)	Bart Maerten;Dirk Roose;Achim Basermann;Jochen Fingberg;Guy Lonsdale	1999			simulation;numerical analysis;computer science;load balancing;finite element method;computer security;algorithm	HPC	-8.770778169432697	37.20415866213941	59521
f03b018347cc5a02c6b8683a8567c01ce8243d89	bfxm: a parallel file system model based on the mechanism of distributed shared memory	sistema operativo;gestion memoire;entrada salida;architecture systeme;systeme multiprocesseur memoire repartie;storage management;reseau ordinateur;gestion fichier;file management;computer network;input output;algorithme;memory access;algorithm;gestion memoria;operating system;cache only memory access;sistema multiprocesador memoria distribuida;parallel file system;manejo archivos;network of workstation;data access;red ordenador;arquitectura sistema;systeme exploitation;systeme parallele;distributed memory multiprocessor system;parallel system;system architecture;distributed shared memory;sistema paralelo;reading and writing;entree sortie;algoritmo	This paper proposes a parallel file system model under NOWs (network of workstations) environment. According to the features of NOWs, the system incorporates the mechanism of distributed shared memory, particularly the mechanism of COMA (cache only memory access). It links the memory of all nodes into a large cache; each node aggressively uses not only the local memory but also the remote memory of other nodes, which expedites the data accesses dramatically. It also accesses disks in parallel to improve I/O performance. Furthermore, in our model, data are shared naturally and conveniently among nodes as opposed to the traditional parallel file systems. The architecture of the parallel file system and its detailed implementation, such as file read and write, data replacement, file data dissipation, parallel file read and write are presented in this paper.	algorithm;cpu cache;cache (computing);cache-only memory architecture;clustered file system;computer cluster;computer data storage;connection machine;cubix;disk storage;distributed computing;distributed shared memory;ibm gpfs;ieee micro;input/output;operating system;parallel i/o;parallel computing;performance;rsa conference;refinement (computing);relevance;workstation	Qun Li;Jie Jing;Li Xie	1997	Operating Systems Review	10.1145/271019.271025	flash file system;fork;uniform memory access;distributed shared memory;self-certifying file system;data access;shared memory;input/output;embedded system;parallel computing;torrent file;distributed memory;memory-mapped file;device file;computer file;computer science;stub file;versioning file system;operating system;unix file types;journaling file system;open;file system fragmentation;systems architecture;file control block;supercomputer architecture	HPC	-16.735257878654753	44.23720949879418	59642
4eb00977d7a38b5cc70a1d778dd2e944767ff94f	crowd simulation on a graphics processing unit based on a least effort model		Large crowd simulation is becoming a very important field of study for many researchers. In this paper we endeavour to study large crowds and their interactions with each other and the environment. The interaction is based on a very simple Least Effort Model inspired from a real world pedestrian modelling scenario. The simulation of the crowd is computationally very expensive and GPU modelling and simulation is a viable alternative computational means to accelerate the simulation process. Compute Unified Device Architecture or CUDA is used for GPU implementation.	cuda;crowd simulation;endeavour (supercomputer);graphics processing unit;interaction	Sankha Baran Dutta;Robert D. McLeod	2013		10.5220/0004488903690376	simulation;computer hardware;computer science;computer graphics (images)	AI	-6.624455683089382	34.680596912952865	59677
58207c04384746e34aebea787c2ad182295e7fc9	an efficient algorithm for the creation of single assignment forms	efficient algorithm;parallel programming;software quality fortran parallelising compilers parallel programming parallel algorithms;parallel processing debugging computer science programming environments centralized control throughput parallel programming registers data analysis packaging;parallelising compilers;static single assignment;fortran;name reclamation single assignment forms fine grain parallelism static single assignment code fortran unstructured fortran code near optimal quality assignment statements program length;software quality;parallel algorithms	Transformation to single ass&mnent form is presented as a technique. enabling the exploitation of fkgrain parallelism in program. An efficient algorithm is pnznted far the creation of Single Ass&nment and Static Single Assignment co&? from unstkuctunzd FORlRAN cook The algo&hm creates code of near optimal quality wit3 msmt to both the number of names and assignment statements added to the code. Experiunenntal nzul& show the &gnze of enhugement of storage and program length when creating single ass&mnent code, and the containment of enlargement using name reclamation. Other results show tie extent of improved pamlleliz3tion using single assignment code.	algorithm;assignment (computer science);parallel computing;static single assignment form	Patricia Prather Pineo	1996		10.1109/HICSS.1996.495465	augmented assignment;parallel computing;computer science;theoretical computer science;operating system;database;parallel algorithm;programming language;static single assignment form;software quality	PL	-15.410181623800455	35.52952469449149	59714
4ff8b75d2055855b05f6485cd41fdf337d788975	efficient parallel simulation of direct methanol fuel cell models	computation;simulation;measurement;modeling	Fuel cells, as highly efficient and environment-friendly power sources, have attracted ever-increasing research and development in the past few decades. Mathematical modeling and simulation are applied to examine the influence of the different physical and electrochemical phenomena occurring in the structure of the fuel cell during operation. Such simulation programs take a very long time (of the order of days or even weeks) to run, especially when accurate results are called for. To achieve accurate results and more insight, we need even more complex models (twoand threedimensional models). In this paper, we present techniques for the parallel simulation of a mathematical model of direct methanol fuel cells (DMFC). In particular, we employ a paradigm called LessTalk. LessTalk is a general technique that can be employed to reduce communications in parallel computations. Using LessTalk, we have achieved almost linear speedup in simulating the DMFC model. The results were validated against measurements available from the Connecticut Global Fuel Cell Center (CGFCC). [DOI: 10.1115/1.1840866]	computation;mathematical model;programming paradigm;simulation;speedup	Sanguthevar Rajasekaran;Reda A. Ammar;K. Reifsnider;Luke E. K. Achenie;Ahmed M. Mohamed;Guiqing Zhang;M. Ahmed	2004			systems modeling;computation;measurement	HPC	-6.230147146633446	36.69030398714757	59943
3afba9fe2423a90a7907ecfbeba304de2b7521b4	spatial computing as intensional data parallelism	data fields;data parallel;spatial programming framework spatial computing intentional data parallelism;intentional data parallelism;clocks;data parallelism;parallel programming;spatial programming framework;data parallelism spatial computing collection data fields data flow declarative definition intensionnal programming stream;arrays;collection;intensionnal programming;computational modeling;declarative definition;fabrics;field data;data flow;spatial computing;programming;parallel processing;fabrics arrays clocks parallel processing programming computational modeling;stream	In this paper, we show that various concepts and tools developed in the 90’s in the field of data-parallelism provide a relevant spatial programming framework. It allows high level spatial computation specifications to be translated into efficient low-level operations on processing units. We provide some short examples to illustrate this statement.	amorphous computing;asynchrony (computer programming);automata theory;cellular automaton;compiler;computation;computer;concurrent data structure;data parallelism;fault tolerance;high- and low-level;high-level programming language;intensional logic;modelling of general systems;ocaml;parallel computing;scheduling (computing)	Antoine Spicher;Olivier Michel;Jean-Louis Giavitto	2010	2010 Fourth IEEE International Conference on Self-Adaptive and Self-Organizing Systems Workshop	10.1109/SASOW.2010.73	data flow diagram;parallel processing;programming;parallel computing;collection;computer science;data field;theoretical computer science;data parallelism;programming language;computational model;stream	Robotics	-15.037498547654964	37.740842388975885	60524
2895c6dfe26fd2a13547480a470db29284b50116	communication modeling of heterogeneous networks of workstations for performance characterization of collective operations	electrical capacitance tomography;personal communication networks;performance evaluation;information science;communication layers;collective communication;high performance computing;availability;point to point;communication complexity;scattering;testing;collective communication algorithms;communication model;collective communication algorithms heterogeneous workstation networks communication modeling performance characterization collective operations high performance computing interconnects communication layers point to point communication collective communication operations broadcast operations scatter operations gather operations;performance characterization;synchronisation;collective communication operations;collective operations;communication modeling;communication complexity workstation clusters performance evaluation synchronisation;interconnects;workstations;network of workstation;point to point communication;high performance computer;broadcast operations;gather operations;heterogeneous workstation networks;broadcasting;workstation clusters;workstations personal communication networks broadcasting scattering electrical capacitance tomography high performance computing local area networks information science testing availability;local area networks;heterogeneous network;scatter operations	Networks of Workstations (NOW) have become an attractive alternative platform for high performance computing. Due to the commodity nature of workstations and interconnects and due to the multiplicity of vendors and platforms, the NOW environments are being gradually redefined asHeterogeneous Networks of Workstations (HNOW). Having an accurate model for the communication in HNOW systems is crucial for design and evaluation of efficient communication layers for such systems. In this paper we present a model for point-to-point communication in HNOW systems and show how it can be used for characterizing the performance of different collective communication operations. In particular, we show how the performance of broadcast, scatter, and gather operations can be modeled and analyzed. We also verify the accuracy of our proposed model by using an experimental HNOW testbed. Furthermore, it is shown how this model can be used for comparing the performance of different collective communication algorithms. We also show how the effect of heterogeneity on the performance of collective communication operations can be predicted.	atm turbo;algorithm;definition;electrical connection;fm broadcasting;load balancing (computing);point-to-point protocol;point-to-point (telecommunications);run time (program lifecycle phase);supercomputer;testbed;workstation	Mohammad Banikazemi;Jayanthi Sampathkumar;Sandeep Prabhu;Dhabaleswar K. Panda;P. Sadayappan	1999		10.1109/HCW.1999.765117	simulation;computer science;theoretical computer science;distributed computing	HPC	-10.916609517346307	45.84819228778058	60579
6e6e2416221fe5f2da29b743f55915d1723acc7b	exploiting event-level parallelism for parallel network simulation on multicore systems	network simulation;protocols;computer model;simulation;network simulator;computational modeling;design and implementation;multicore system;ns 2 network simulator event level parallelism parallel network simulation methodology multicore systems sequential simulations;multicore processing;computational modeling protocols multicore processing parallel processing load modeling simulation;multiprocessing systems;load modeling;multicore system network simulation parallel simulation;article;parallel processing;parallel processing discrete event simulation multiprocessing systems;parallel simulation;model simulation;discrete event simulation	This paper proposes a parallel simulation methodology to speed up network simulations on modern multicore systems. In this paper, we present the design and implementation of this approach and the performance speedups achieved under various network conditions. This methodology provides two unique and important advantages: 1) one can readily enjoy performance speedups without using an unfamiliar simulation language/library to rewrite his protocol module code for parallel simulations, and 2) one can conduct parallel simulations in the same way as when he conducts sequential simulations. We implemented this methodology and evaluated its performance speedups on the popular ns-2 network simulator. Our results show that this methodology is feasible and can provide satisfactory performance speedups under high event load conditions on wired networks.	multi-core processor;parallel computing;rewrite (programming);simulation language	Shie-Yuan Wang;Chih-Che Lin;Yan-Shiun Tzeng;Wen-Gao Huang;Tin-Wei Ho	2012	IEEE Transactions on Parallel and Distributed Systems	10.1109/TPDS.2011.215	parallel processing;computer architecture;parallel computing;real-time computing;computer science;network simulation;computer network	HPC	-12.656185995483398	42.18196718037662	61003
19c1bc2a9e8caafb30da70475c76f855a0c8307c	synchronization error detection of mpi programs by symbolic execution	libraries;symbolic execution mpi synchronization error;synchronization data communication libraries optimization buffer storage prototypes schedules;symbol manipulation application program interfaces message passing programming;prototypes;buffer storage;data communication;symbolic execution;synchronization;schedules;mpi;optimization;message passing interface symbolic execution asynchrony based overlapping computation communication asynchronous mpi programming input related synchronization error detection prototype tool cloud9;synchronization error	Asynchrony based overlapping of computation and communication is commonly used in MPI applications. However, this overlapping introduces synchronization errors frequently in asynchronous MPI programming. In this paper, we propose a symbolic execution based method for detecting input-related synchronization errors. The path space of an MPI program is systematically explored, and the related operations of the synchronization errors in the program are checked specifically. In addition, two optimizations are proposed to improve the efficiency. We have implemented our method as a prototype tool based on the symbolic executor Cloud9. The results of the extensive experiments indicate the effectiveness of our method.	asynchrony (computer programming);cloud9 ide;computation;error detection and correction;experiment;message passing interface;prototype;sensor;symbolic execution	Xianjin Fu;Zhenbang Chen;Chun Chang Huang;Wei Dong;Ji Wang	2014	2014 21st Asia-Pacific Software Engineering Conference	10.1109/APSEC.2014.28	synchronization;parallel computing;real-time computing;schedule;computer science;message passing interface;distributed computing;prototype;data synchronization;synchronization	SE	-15.82319358376887	37.428071769895205	61013
77f160f144c272e9a848d3c9131c6c65f94a17d9	the nx message passing interface	parallelisme;multiordinateur;nx interface;performance;intel;transmission message;communication model;message transmission;interfase;modelo;parallelism;paralelismo;message passing interface;interface;message passing;evaluation;modele;evaluacion;rendimiento;intel multicomputers;communication;comunicacion;interface nx;models;transmision mensaje	Abstract   The challenge in designing a message passing interface for massively parallel distributed memory supercomputers is to balance high performance with usability. The NX interface and its implementations represent successful achievement of that balance in a highly evolved, full featured, high performance interface for parallel applications. It is the vendor-supplied programming interface on Intel multicomputers, implementing the typed send/receive model of multicomputer message passing. Central to this paper is a section on the philosophy behind the NX design, which explains design tradeoffs and why we think they result in a successful interface.	message passing interface	Paul Pierce	1994	Parallel Computing	10.1016/0167-8191(94)90023-X	parallel computing;message passing;real-time computing;models of communication;performance;computer science;message passing interface;evaluation;operating system;interface;distributed computing;programming language	HPC	-16.395954342695838	41.70750289895852	61227
c15a5e153f691e76c7420bab3944885462e0ec0c	software for interval arithmetic: a reasonably portable package	variables;data type;computer program documentation;compilers;computer programs;computer architecture;large scale;formats;arithmetic;fortran;interval arithmetic;subroutines	The design and capabflltms of a package of Fortran subroutines for performing mterval arithmetic calculations are discussed Apart from a relatively small number of primitives and constants, the package Is directly transferrable to most large scale computers, and has been successfully implemented on IBM, CDC, DEC, and Honeywell eqmpment m additmn to the UNIVAC 1110 This package has been designed to be compatible with the AUGMENT precompiler, it includes interval analogs of appropriate standard Fortran operatmns and functions, as well as operatmns and functions peculiar to interval arithmetic. The result is that the user who has access to AUGMENT may write programs usmg interval arithmetic just as though Fortran recogmzed INTERVAL as a standard data type.	algol 60;arithmetic logic unit;computer;ext js javascript framework;fortran;high- and low-level;interval arithmetic;linear algebra;math-matic;preprocessor;rounding;springer (tank);subroutine;univac i	J. Michael Yohe	1979	ACM Trans. Math. Softw.	10.1145/355815.355819	variables;compiler;arbitrary-precision arithmetic;data type;computer science;theoretical computer science;subroutine;saturation arithmetic;affine arithmetic;interval arithmetic;programming language;algorithm;algebra	Graphics	-11.897771553974577	34.964535358716766	61300
3db7ca2976dc2ba2d53982f24f853f9286644c3b	fast timing-based algorithms	algorithme rapide;consensus;shared memory;shared memory algorithms;time complexity;memoria compartida;contention free complexity;timing based model;tiempo acceso;exclusion mutual;mutual exclusion;upper bound;memory access;synchronisation;complexite temps;concurrent systems;synchronization;fast algorithm;temps acces;temps retard;sincronizacion;exclusion mutuelle;delay time;complejidad tiempo;critical section;tiempo retardo;algoritmo rapido;memoire partagee;access time;timing	 Concurrent systems in which there is a known upper bound Δ on memory access time are considered. Two prototypical synchronization problems, mutual exclusion and consensus, are studied, and solutions that have constant (i.e. independent of Δ and the total number of processes) time complexity in the absence of contention are presented. For mutual exclusion, in the absence of contention, a process needs only five accesses to the shared memory to enter its critical section, and in the presence of contention, the winning process may need to delay itself for 4 ⋅ Δ time units. For consensus, in absence of contention, a process decides after four accesses to the shared memory, and in the presence of contention, it may need to delay itself for Δ time units.	access time;algorithm;cas latency;concurrency (computer science);consensus (computer science);critical section;mutual exclusion;shared memory;time complexity	Rajeev Alur;Gadi Taubenfeld	1996	Distributed Computing	10.1007/s004460050020	synchronization;parallel computing;real-time computing;computer science;operating system;distributed computing	Theory	-15.902110171477679	45.501620691964206	61361
11606b1a0777362b34ed8872b70286ace9dc8a3f	multiprocessor image rotation	teledetection;communication process;eficacia sistema;satellite data;observation par satellite;multiprocessor;multiprocessor systems;computer graphics;observacion por satelite;data management;performance systeme;image;system performance;data communication;proceso comunicacion;processus communication;satellite observation;imagen;remote sensing;teledeteccion;gestion transmission;communications managing;rotacion;multiprocesador;rotation;gestion transmision;grafico computadora;infographie;multiprocesseur	A technique for reducing the time taken to perform image rotation on general purpose computing hardware is presented. A powerful attribute of the technique is that it is easily mapped onto multiprocessor systems, returning a performance proportional to the number of processors employed. In this article, particular attention has been given to the issues of data management and data communication associated wtih a multiple-processor approach to pure rotation of images. The speed enhancement obtained using concurrently operating processors has been quantified and the limitations have been examined. With the performance achieved, low-cost PC-based multiprocessor systems can satisfactorily process the satellite data now readily available from National Remote Sensing Centres.	multiprocessing	James E. L. Hollis;T. E. Cronk	1995	J. Parallel Distrib. Comput.	10.1006/jpdc.1995.1130	embedded system;parallel computing;real-time computing;multiprocessing;simulation;telecommunications;rotation;data management;computer science;operating system;image;computer graphics;symmetric multiprocessor system	HPC	-15.357902273457332	43.618938359040975	61370
45ecd5688e1be4a32e81809449a78177a7ec95f7	a programming model for reconfigurable computing based in functional concurrency	reconfigurable computing concurrent functional language rewire concurrency functional hardware description language first class concurrency concurrent applications concurrent algorithms fpga programmability programming model functional concurrency;concurrent computing;clocks;reconfigurable architectures concurrency control field programmable gate arrays functional languages functional programming hardware description languages parallel algorithms;software engineering;computational modeling;hardware concurrent computing clocks parallel processing programming software engineering computational modeling;programming;parallel processing;hardware	FPGA programmability remains a concern with respect to the broad adoption of the technology. One reason for this is simple: FPGA applications are frequently implementations of concurrent algorithms that could be most directly rendered in concurrent languages, but there is little or no first-class support for concurrent applications in conventional hardware description languages. It stands to reason that FPGA programmability would be enhanced in a hardware description language with first-class concurrency. The starting point for this paper is a functional hardware description language with built-in support for concurrency called ReWire. Because it is a concurrent functional language, ReWire supports the elegant expression of common concurrency paradigms; we illustrate this with several case studies.	algorithm;canonical account;concurrency (computer science);field-programmable gate array;functional programming;hardware description language;programming model;reconfigurable computing	William L. Harrison;Ian Graves;Adam M. Procter;Michela Becchi;Gerard Allwein	2016	2016 11th International Symposium on Reconfigurable Communication-centric Systems-on-Chip (ReCoSoC)	10.1109/ReCoSoC.2016.7533911	parallel processing;programming;computer architecture;parallel computing;concurrent computing;concurrency;computer science;concurrency control;multiversion concurrency control;non-lock concurrency control;programming language;computational model;concurrent object-oriented programming;distributed concurrency control	Arch	-14.581952180180354	39.79884602366084	61468
a65480a6ca90ad70d28a4d0e920a3335e436524c	implicit parallelism: the united functions and objects approach	object oriented;parallel machines;parallel languages	UFO is a general-purpose, implicitly parallel language designed to allow a wide range of applications to be implemented efficiently on a wide range of parallel machines while minimising the conceptual difficulties for the programmer. To achieve this, it draws on the experience gained in the functional and object-oriented “worlds” and attempts to bring these worlds together in a harmonious fashion.	implicit parallelism	John Sargeant	1993		10.1007/3-540-56891-3_10	computer science;theoretical computer science;distributed computing;data parallelism;programming language;implicit parallelism;task parallelism	DB	-14.209865755035045	39.001330839394186	61483
e2c33bf6ede5230b05b672cece84f404af864f50	parallel kirchhoff pre-stack depth migration on large high performance clusters		Kirchhoff Pre-Stack Depth Migration (KPSDM) is a widely used algorithm for seismic imaging in petroleum industry. To provide higher FLOPS, modern high performance clusters are equipped with more computing nodes and more cores for each node. The evolution style of clusters leads to two problems for upper layer applications such as KPSDM: (1) the increasing disparity of the I/O capacity and computing performance is becoming a bottleneck for higher scalability; (2) the decreasing Mean Time Between Failures (MTBF) limits the availability of the applications. In this paper, we present an optimized parallel implementation of KPSDM to adapt to modern clusters. First, we convert the KPSDM into a clear and simple task-based parallel application by decomposing the computation along two dimensions: the imaging space and seismic data. Then, those tasks are mapped to computing nodes that are organized using a two-level master/worker architecture to reduce the I/O workloads. And each task is further parallelized using multi-cores to fully utilize the computing resources. Finally, fault tolerance and checkpoint are implemented to meet the availability requirement in production environments. Experimental results with practical seismic data show that our parallel implementation of KPSDM can scale smoothly from 51 nodes (816 cores) to 211 nodes (3376 cores) with low I/O workloads on the I/O sub-system and multiple process failures can be tolerated efficiently.	kirchhoff's theorem;supercomputer	Chao Li;Yida Wang;Changhai Zhao;Haihua Yan;Jianlei Zhang	2015		10.1007/978-3-319-27137-8_20	mathematical optimization;theoretical computer science	HPC	-5.427789378516032	40.875896826555945	61540
4b5b03d414be81bbe50b958bcae05543035709b3	an improved automatic mpi code generation algorithm for distributed memory machine	parallel computing;automatic code generation;distributed memory systems;data analysis programming profession writing supercomputers parallel processing concurrent computing parallel machines hardware parallel programming information analysis;parallelizing compilers;distributed memory machine;code generation;automatic mpi code generation;parallelising compilers application program interfaces distributed memory systems message passing;message passing parallelizing compiler;data dependence;parallelising compilers;application program interfaces;message passing;data flow analysis;parallel computing automatic mpi code generation distributed memory machine message passing parallelizing compiler;reading and writing	This paper presents an overview of our ongoing project KAP, which aims to build a message-passing parallelizing compiler for distributed-memory machines. In this paper, an improved automatic code generation algorithm is discussed. Our algorithm uses the data and computation decomposition, and the reading and writing access functions to create the communication code. We can not only solve the problems which the conventional algorithm can do but also can solve another kind of problem. In such cases: there is no data dependence and the read access is not aligned in the loop nest, or the exact data-flow analysis is not given because of the limitation of the algorithm of LWT, the conventional algorithm can not create communication code correctly while our improved algorithm can resolve this problem. Experiments prove that the novel algorithm can achieve satisfactory effect	algorithm;automatic parallelization;automatic programming;code generation (compiler);compiler;computation;data dependency;data-flow analysis;dataflow;distributed memory;experiment;message passing	Xue-rong Gong;Yong-hong Sheng;Lin-sheng Lu;Ping Zhang	2006	2006 Seventh International Conference on Parallel and Distributed Computing, Applications and Technologies (PDCAT'06)	10.1109/PDCAT.2006.32	algorithm design;computer architecture;parallel computing;message passing;computer science;data-flow analysis;distributed computing;programming language;algorithmics;code generation	HPC	-14.280881870292516	37.333668328295914	61613
44b77c55b61c2fca94cb0f9ba022f34712e5d41a	large scale parallel solution of incompressible flow problems using uintah and hypre	hypre;navier stokes equations;mathematical model equations combustion scalability software computational modeling educational institutions;titan machine large scale parallel solution incompressible flow problems uintah software framework fluid structure interaction problems structured adaptive grids large scale problem long running problem data intensive problem fluid flow solvers particle based methods asynchronous task based approach fully automated load balancing combustion applications scalable linear solver code scalability hypre software uintah weak scalability hypre weak scalability software engineering nsf kraken architecture cpu cores;computational fluid dynamics;parallelism;linear equations uintah hypre parallelism scalability;chemically reactive flow;software packages chemically reactive flow combustion computational fluid dynamics navier stokes equations;scalability;linear equations;combustion;software packages;uintah	The Uintah Software framework was developed to provide an environment for solving fluid-structure interaction problems on structured adaptive grids on large-scale, long-running, data-intensive problems. Uintah uses a combination of fluid-flow solvers and particle-based methods for solids together with a novel asynchronous task-based approach with fully automated load balancing. As Uintah is often used to solve incompressible flow problems in combustion applications it is important to have a scalable linear solver. While there are many such solvers available, the scalability of those codes varies greatly. The hypre software offers a range of solvers and pre-conditioners for different types of grids. The weak scalability of Uintah and hypre is addressed for particular examples of both packages when applied to a number of incompressible flow problems. After careful software engineering to reduce startup costs, much better than expected weak scalability is seen for up to 100K cores on NSFs Kraken architecture and up to260K cpu cores, on DOEs new Titan machine. The scalability is found to depend in a crtitical way on the choice of algorithm used by hypre for a realistic application problem.	algorithm;central processing unit;code;complex adaptive system;data-intensive computing;hypre;helium;image scaling;load balancing (computing);numerical linear algebra;plume (fluid dynamics);scalability;scott continuity;software development;software engineering;software framework;solver;titan (supercomputer);vii	John A. Schmidt;Martin Berzins;Jeremy Thornock;Tony Saad;James C. Sutherland	2013	2013 13th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing	10.1109/CCGrid.2013.10	computational science;parallel computing;scalability;computational fluid dynamics;computer science;theoretical computer science;distributed computing;linear equation;combustion	HPC	-5.371689366732686	38.1126005265473	61651
7c3f2523802f64ae15a5d3e7fa3609742fb02683	applied scientific computing			alice and bob;approximation algorithm;computation;computational science;computer science;emoticon;eval;hardware acceleration;nonlinear system;polynomial;round-off error;series expansion;springer (tank);status message (instant messaging);visual intercept	Peter R. Turner;Thomas Arildsen;Kathleen Kavanagh	2018		10.1007/978-3-319-89575-8	python (programming language);computer science;computational science	HPC	-7.383649282443681	37.70549152657291	61831
04c0299143eccdfd399bbe0c7aba586457200a8f	"""a solution to a problem with morel and renvoise's """"global optimization by suppression of partial redundancies"""""""	lenguaje programacion;optimisation;compilateur;optimizacion;programming language;redundancia;optimization technique;tratamiento lenguaje;compiler;redundancy;language processing;traitement langage;data flow analysis;langage programmation;global optimization;optimization;code motion;compilador;redondance	Morel and Renvoise have previously described a method for global optimization and code motion by suppression of partial redundancies [l]. Morel and Renvoise use data flow analysis to determine expression computations that should be inserted at the end of certain basic blocks and to determine redundant computations that can be eliminated. The execution of these techniques results in the movement of loop invariant expressions out of the loop. In addition to [l] Morel and Renvoise's techniques can also be applied to subexpressions of larger expressions. Then, however, in certain special cases these optimization techniques move expressions to places where some of its subexpressions are neither available nor moved together with the expression. In this paper we present a modification of Morel and Renvoise's algorithm that avoids the above described situations.	algorithm;basic block;computation;data-flow analysis;dataflow;global optimization;loop invariant;loop-invariant code motion;mathematical optimization;zero suppression	Karl-Heinz Drechsler;Manfred P. Stadel	1988	ACM Trans. Program. Lang. Syst.	10.1145/48022.214509	compiler;computer science;artificial intelligence;theoretical computer science;data-flow analysis;redundancy;programming language;algorithm;global optimization	PL	-18.97159711882404	33.29733764762904	61858
792e8085aee79f1f9b5d6384c013670be55e0cfd	alchemi+: an agent-based approach to grid programming	developpement logiciel;modelizacion;parallelisme;distributed system;algoritmo paralelo;multiagent system;haute performance;systeme reparti;computational grid;parallel algorithm;agent mobile;capsula convexa;agent based;agente movil;soporte matricial;distributed computing;intelligence artificielle;matrix system;support matriciel;algorithme parallele;enveloppe convexe;grid;modelisation;parallelism;sistema repartido;paralelismo;rejilla;desarrollo logicial;agent intelligent;software development;intelligent agent;alto rendimiento;grille;calculo repartido;artificial intelligence;matrix multiplication;agente inteligente;inteligencia artificial;mobile agent;sistema multiagente;convex hull;parallel programs;modeling;grid computing;high performance;calcul reparti;grid system;systeme multiagent	Computational grids have provided the usage of computational distributed resources for computation intensive applications. The development of programs that use these capabilities is one of the challenging issues for grid computing. In this article, an effort has been made to solve this problem by presenting mobile-agent-based parallel programming on the grid. The presentation of this model which has been realized by extending Alchemi grid system with adding agent properties and navigational commands that let user to develop his program by using mobile agents. To evaluate the system, algorithms of matrix multiplication and convex hull have been implemented in the mentioned system.	agent-based model;algorithm;computation;convex hull;grid computing;matrix multiplication;mobile agent;parallel computing	Roohollah Mafi;Hossein Deldari;Mojtaba Mazoochi	2005		10.1007/11752578_24	simulation;systems modeling;matrix multiplication;computer science;artificial intelligence;software development;convex hull;mobile agent;distributed computing;parallel algorithm;grid;intelligent agent;algorithm;grid computing	HPC	-17.965472674085344	41.69332315351807	61934
ebff03b9b7fd5e4b095f1ed1b635ca1b3a455faf	improving the execution of dependent and-parallel prolog ddas	parallel logic programming;abstract machine	In this paper, a scheme that improves the execution of the Dynamic Dependent And-parallel Scheme, a dependent and-parallel execution model for Prolog, is presented. The main idea is to make further use of dependence information that is already used in the extraction in parallelism to improve the precision of both the forward and backward execution schemes. As the information is already available, no overhead is incurred in obtaining it, and reusing it imposes very small implementation overheads. An abstract machine instruction set which implements these improvements is then presented. This instruction set can also be used to implement other and-parallel logic programming languages, and offers some advantages over previously proposed schemes.	prolog	Kish Shen	1994		10.1007/3-540-58184-7_121	computer architecture;parallel computing;computer science;programming language;prolog	Arch	-17.096191100980995	40.107479554252826	61999
ab1b15688b32557a9d550f1102527a56a259af82	superpascal - a publication language for parallel scientific computing	parallel scientific computing	Parallel computers will not become widely used until scientists and engineers adopt a common programming language for publication of parallel scientific algorithms. This paper describes the publication language SuperPascal by examples. SuperPascal extends Pascal with deterministic statements for parallel processes and synchronous message communication. The language permits unrestricted combinations of recursive procedures and parallel statements. SuperPascal omits ambiguous and insecure features of Pascal. Restrictions on the use of variables enable a single-pass compiler to check that parallel processes are disjoint, even if the processes use procedures with global variables. A portable implementation of SuperPascal has been developed on a Sun workstation under Unix.	algorithm;compiler;computational science;computer;global variable;pascal;programming language;recursion;sun workstation;unix	Per Brinch Hansen	1994	Concurrency - Practice and Experience	10.1002/cpe.4330060504	parallel computing;computer science;theoretical computer science;operating system;database;distributed computing;programming language	PL	-12.295098225662967	36.451582556956566	62084
adb71f4c0bc2e71cf2b1fc3efa72a8c4594aebc2	parallelization of simulation tasks: methodology-implementation-application	structural model;model comparison;simulation software	After a short discussion on the parallelization of simulation software the socalled MME-structure (model — method — experiment) for simulation tasks is introduced. This study extends the well known structure of model frame and experimental frame by a third frame of methods. The structure of the methods is a hierarchical one, being the base for the parallelization of simulation tasks. Starting at a medium hierarchical level a parallelization can be realized in a model-independent manner. Examples are parameter variation, linearization at different points, model comparison, where also analytical procedures can be used. The concept was implemented within the Simulation System PARALLEL_HYBSYS on a PC based transputer system (T800).	automatic parallelization;parallel computing;simulation	Felix Breitenecker;G. Schuster;Irmgard Husinsky;Josef Fritscher	1991		10.1007/3-540-55437-8_97	computational science;dynamic simulation;computer architecture;theoretical computer science	HPC	-10.491287678718129	39.958412758390324	62200
9ea55b620dac5ea434ac9eb667cbcd27718e8407	shared memory implementation of constraint satisfaction problem resolution	shared memory;constraint satisfaction problems;irregular applications;openmp;constraint satisfaction problem;parallel processing	Many problems in C o m p u t e r Science, especially in Artificial Intelligence, can be formulated as Const ra in t Satisfaction Problems ( C S P ) . Th i s p a p e r presents a parallel implementa t ion of the Forward-Checking a lgor i thm for solving a binary C S P over finite domains . I ts ma in contr ibut ion is to use a simple decomposit ion s t ra tegy in order to d is t r ibute dynamical ly the search t ree a m o n g machines. T h e feasibility and benefit of this approach are s tudied for a Shared Memory model . A n implementa t ion is draf ted using the new emergent s t anda rd O p e n M P library for shared memory, thus controlling load balancing. We mainly highlight satisfactory efficiencies wi thout using any tricky load balancing policy. All t h e exper iments were carried out runn ing on the Sillicon Graphics Origin 2000 parallel machine.	artificial intelligence;const (computer programming);constraint satisfaction problem;dynamical system;emergence;graphics;load balancing (computing);look-ahead (backtracking);parallel computing;shared memory	Zineb Habbas;Michaël Krajecki;Daniel Singer	2001	Parallel Processing Letters	10.1142/S0129626401000749	distributed shared memory;parallel processing;parallel computing;computer science;constraint graph;theoretical computer science;operating system;constraint satisfaction dual problem;distributed computing;programming language;constraint satisfaction problem;algorithm;hybrid algorithm;backtracking	AI	-9.938812238433856	39.48160494692201	62245
ab4c823103a171d92cbc3e9784c6ece36b15d957	parallelism, pipelines, and partitions: variations on communicating modules	concurrent computing;design engineering;resource management;resource management concurrent computing system recovery parallel processing software design design engineering physics computing;physics computing;system recovery;software design;parallel processing	A software design model is examined witlh regard to three design objectives: splitfing execution threads of a given process; deriving pipelines from hierirchical designs; and partifoning data and actions to Increase cohcurrency. T he intent of this article, and of its companion study, ' is to provide the software engineer with a unified design model, a conceptual framework that can assist in making reasoned choices in the design of complex systems. Such systems are characterized by the need for concurrent execution of several processes, and by the distribution of data and subprograms in different memories. Following a summary of the design model, we will explore the application of the model to parallel designs (in which a single execution thread is divided into several concurrent threads); pipeline designs (in which we dispense with procedure-call hierarchies); and multiprocess modules (in which the concurrent execution of several processes within a single module is enabled by data and action partitioning).	complex systems;pipeline (computing);pipeline (software);software design;software engineer;subroutine;thread (computing)	Bernard I. Witt	1985	Computer	10.1109/MC.1985.1662804	parallel processing;computer architecture;parallel computing;concurrent computing;computer science;software design;resource management;data-intensive computing;distributed computing;data parallelism;utility computing;distributed design patterns;programming language	Arch	-13.569181312875275	40.5511472419928	62289
8dbadffa116d366327d31de25ccfa49857801178	mostly automated formal verification of loop dependencies with applications to distributed stencil algorithms		The class of stencil programs involves repeatedly updating elements of arrays according to fixed patterns, referred to as stencils. Stencil problems are ubiquitous in scientific computing and are used as an ingredient to solve more involved problems. Their high regularity allows massive parallelization. Two important challenges in designing such algorithms are cache efficiency and minimizing the number of communication steps between nodes. In this paper, we introduce a mathematical framework for a crucial aspect of formal verification of both sequential and distributed stencil algorithms, and we describe its Coq implementation. We present a domain-specific embedded programming language with support for automating the most tedious steps of proofs that nested loops respect dependencies, applicable to sequential and distributed examples. Finally, we evaluate the robustness of our library by proving the dependency-correctness of some real-world stencil algorithms, including a state-of-the-art cache-oblivious sequential algorithm, as well as two optimized distributed kernels.	algorithm;formal verification	Thomas Grégoire;Adam Chlipala	2016		10.1007/978-3-319-43144-4_11	parallel computing;computer science;theoretical computer science;programming language	EDA	-10.971165579402491	39.454977206172146	62339
c36c4c6c6205d0315ebff7b8ff61498beb9b4b3f	chapter two - exploring future many-core architectures: the teraflux evaluation framework	dataflow			Roberto Giorgi	2017	Advances in Computers	10.1016/bs.adcom.2016.09.002	computer architecture;parallel computing;real-time computing;computer science;dataflow	NLP	-9.14696478374847	43.58378200415535	62346
d9f0fa41670a4da2f4c6030cd32e66387ffc546d	hybrid mpi/openmp parallelization of the effective fragment potential method in the libefp software library	libefp;message passing interface;effective fragment potential;parallel;openmp	A new hybrid MPI/OpenMP parallelization scheme is introduced for the Effective Fragment Potential (EFP) method implemented in the libefp software library. The new implementation employs dynamic load balancing algorithm that uses a master/slave model. The software shows excellent parallel scaling up to several hundreds of CPU-cores across multiple nodes. The code uses functions only from the well-established MPI-1 standard that simplifies portability of the library. This new parallel EFP implementation greatly expands the applicability of the EFP and QM/EFP methods by extending attainable time- and length-scales.		Ilya Kaliman;Lyudmila V. Slipchenko	2015	Journal of computational chemistry	10.1002/jcc.23772	computational science;message passing interface;parallel	HPC	-5.671678459539099	39.69174234816721	62404
208fcc4a703ed5a1fb4ad1fb3edbe9879f84432e	the ultracomputer as a vehicle for polymer simulations	molecular dynamics;polymer simulations;parallel computer;mimd computer;nyu ultracomputer	The application of a parallel computer (the NYU Ultracomputer) for molecular dynamics calculations of polymer systems is discussed. It is shown that the special architecture of this machine will greatly enhance our capabilities for investigating important phenomena which are beyond the power of current computers.	polymer;simulation;ultracomputer	Marvin Bishop	1984	Parallel Computing	10.1016/S0167-8191(84)90060-7	computational science;molecular dynamics;parallel computing;computer science;theoretical computer science	HPC	-6.349473837378169	37.22450319025963	62553
8559ff1f6868b69efbf0d373f207cce7ddf0ec83	dcache, storage system for the future	parallelisme;distributed system;sistema operativo;streaming;systeme reparti;storage system;failure;gestion archivos;localization;resource manager;logicial personalizado;distributed computing;multiplicite;gestion fichier;punto caliente;cache memory;physique haute energie;grid middleware;localizacion;file management;hot spot;antememoria;intergiciel;grid;antememoire;transmission en continu;parallelism;sistema repartido;fracaso;localisation;paralelismo;obra;operating system;fisica alta energia;high energy physics;rejilla;file system;smoothing;building site;systeme memoire;multiplicidad;alisamiento;point chaud;grille;calculo repartido;middleware;systeme exploitation;transmision fluyente;sistema memoria;calcul reparti;multiplicity;lissage;open standard;data grid;echec;chantier construction	In 2007, the most challenging high energy physics experiment ever, the Large Hardon Collider(LHC), at CERN, will produce a sustained stream of data in the order of 300MB/sec, equivalent to a stack of CDs as high as the Eiffel Tower once per week. This data is, while produced, distributed and persistently stored at several dozens of sites around the world, building the LHC data grid. The destination sites are expected to provide the necessary middle-ware, so called Storage Elements, offering standard protocols to receive the data and to store it at the site specific Storage Systems. A major player in the set of Storage Elements is the dCache/SRM system. dCache/SRM has proven to be capable of managing the storage and exchange of several hundreds of terabytes of data, transparently distributed among dozens of disk storage nodes. One of the key design features of the dCache is that although the location and multiplicity of the data is autonomously determined by the system, based on configuration, cpu load and disk space, the name space is uniquely represented within a single file system tree. The system has shown to significantly improve the efficiency of connected tape storage systems, by caching, ’gather & flush’ and scheduled staging techniques. Furthermore, it optimizes the throughput to and from data clients as well as smoothing the load of the connected disk storage nodes by dynamically replicating datasets on the detection of load hot spots. The system is tolerant against failures of its data servers which enables administrators to go for commodity disk storage components. Access to the data is provided by various standard protocols. Furthermore the software is coming with an implementation of the Storage Resource Manager protocol (SRM), which is evolving to an open standard for grid middleware to communicate with site specific storage fabrics.	cache (computing);central processing unit;dcache;disk space;disk staging;disk storage;eiffel;experiment;large hadron collider;magnetic tape data storage;middleware;smoothing;storage resource manager;technical standard;terabyte;throughput;warez	Patrick Fuhrmann;Volker Gülzow	2006		10.1007/11823285_116	embedded system;real-time computing;storage area network;converged storage;open standard;internationalization and localization;cpu cache;computer science;resource management;operating system;middleware;data grid;database;distributed computing;multiplicity;information repository;grid;computer security;hot spot;smoothing	HPC	-19.10562634918876	44.58077281398377	62832
d76a80d0d0f7d36accac608a4b79e0a57f2a6741	optimization and profiling of the cache performance of parallel lattice boltzmann codes	distributed system;algoritmo paralelo;optimisation;code treillis;gestion memoire;systeme reparti;parallel algorithm;cache;modelo 3 dimensiones;optimizacion;code optimization;profiling;calculator cluster;modele 3 dimensions;storage management;performance;three dimensional model;codigo treillis;cache memory;trellis code;algorithme parallele;program optimization;antememoria;computational fluid dynamics;gestion memoria;antememoire;grappe calculateur;sistema repartido;cache performance;lattice boltzmann method;lattice boltzmann;optimization;optimisation programme;mecanique fluide numerique;mecanica fluido numerica;optimizacion programa	When designing and implementing highly efficient scientific applications for parallel computers such as clusters of workstations, it is inevitable to consider and to optimize the single-CPU performance of the codes. For this purpose, it is particularly important that the codes respect the hierarchical memory designs that computer architects employ in order to hide the effects of the growing gap between CPU performance and main memory speed. In this article, we present techniques to enhance the single-CPU efficiency of lattice Boltzmann methods which are commonly used in computational fluid dynamics. We show various performance results for both 2D and 3D codes in order to emphasize the effectiveness of our optimization techniques.	cpu cache;central processing unit;code;computational fluid dynamics;computer cluster;computer data storage;lattice boltzmann methods;mathematical optimization;megabyte;parallel computing;speedup;workstation	Thomas Pohl;Markus Kowarschik;Jens Wilke;Klaus Iglberger;Ulrich Rüde	2003	Parallel Processing Letters	10.1142/S0129626403001501	parallel computing;computer science;theoretical computer science;program optimization;lattice boltzmann methods;algorithm	HPC	-16.002461073032418	43.714289349531036	62833
7c800faa1dd797aeaea7451f20af50d8358dcfd2	the use of hardware transactional memory for the trace-based parallelization of recursive java programs	java programming;hardware transactional memory;parallelism;coarse grained;transactional memory;traces;java	We describe a framework for trace-based parallelization of recursive Java programs. We also explore and evaluate the feasibility of using a hardware transactional memory (HTM) system to handle dependences. We design, implement, and evaluate a system that takes as input a sequential program, identifies traces on it, and groups these traces into coarse-grain units of computation, or tasks. We then insert code that allows tasks to execute in parallel transactions using a fork/join paradigm. We also present a software algorithm that ensures sequential program order is maintained by transactional memory. We identify the associated issues and describe criteria that are necessary for Java programs to execute successfully on HTM systems. Our evaluation using JOlden benchmarks indicates that the computational phases of the benchmarks can be executed effectively on HTM systems. The average speedup is 2.7 for four processors. We conclude that HTM is a viable solution to dealing with dependences when performing trace-based parallelization.	algorithm;central processing unit;computation;fork (software development);html;java;parallel computing;programming paradigm;recursion;speedup;tracing (software);transactional memory	Borys J. Bradel;Tarek S. Abdelrahman	2009		10.1145/1596655.1596671	transactional memory;parallel computing;real-time computing;computer science;real time java;programming language	PL	-18.396670322359917	37.34671238490545	62879
61bf80b87e96176f29315faa68b161f522427bbb	dddp: a distributed data driven processor	distributed data;computers;processing element;processing;general and miscellaneous mathematics computing and information science;problem structure;resource allocation;data processing;broadcast;interconnection network;banyan;macropipeline;programming 990200 mathematics computers;mapping;ring;data flow;distributed data processing;architecture;parallel processing;pipeline;fault diagnosis;structured data	This paper describes an architecture of a data flow computer named the Distributed Data Driven Processor (DDDP), and presents an experimental system and the results of experiments using several benchmarks. The experimental system has four processing elements connected by a ring bus, and a structured data memory. The main features of our system are that each processing element is provided with a hardware hashing mechanism to implement token coloring, and a ring bus is used to pass tokens concurrently among processing elements. A hardware monitor was used to measure the performance of the experimental system.  The experimental system adopts a low key technology and yet is capable of executing about 0.7 million instructions per second through the benchmarks. This implies that data flow computers can be alternative to the conventional von-Neumann computers if state-of-the-art technologies are adequately introduced.	benchmark (computing);computer;dataflow architecture;experiment;experimental system;graph coloring;von neumann architecture	Masasuke Kishi;Hiroshi Yasuhara;Yasusuke Kawamura	1983		10.1145/800046.801661	parallel processing;computer architecture;parallel computing;data processing;resource allocation;computer science;processing;theoretical computer science;architecture;operating system;distributed computing;programming language;pipeline;ring	Arch	-11.848157016764153	44.28158802119439	63025
b19edd79e66d76f0351331b5cc7ebbdb448fc410	adding parallelism to visual data flow programs	shared memory;tool support;visual programming language;visual language;parallel;data flow;parallel programs;article	Programming in parallel is an error-prone and complex task compounded by the lack of tool support for both programming and debugging. Recent advances in compiler-directed shared memory APIs, such as OpenMP, have made shared-memory parallelism more widely accessible for users of traditional procedural languages: however, the mechanisms provided are difficult to use and error-prone. This paper examines the use of visual notations for data flow programming to enable the creation of shared memory parallel programs. We present a model, arising from research on the ReactoGraph visual programming language, that allows code in a general class of visual data flow languages to be parallelized using visual annotations, and discuss the advantages this has over current textual methods.	cognitive dimensions of notations;compiler;dataflow;debugging;openmp;parallel computing;shared memory;visual programming language	Philip T. Cox;Simon Gauvin;Andrew Rau-Chaplin	2005		10.1145/1056018.1056037	fourth-generation programming language;shared memory;data flow diagram;first-generation programming language;parallel computing;declarative programming;programming domain;reactive programming;computer science;theoretical computer science;operating system;third-generation programming language;parallel;computer programming;programming paradigm;inductive programming;fifth-generation programming language;visual programming language;programming language;second-generation programming language;high-level programming language;control flow analysis;parallel programming model	HPC	-13.90835170446543	38.081786530565324	63086
8771a03b327c5f6074092118bb704e271b099af0	reverse code generation for parallel discrete event simulation		Reverse computation has become a central notion in discrete event simulation over the last decade. It is not just a theoretical line of research, but an immensely practical one that is necessary to achieve high performance for large parallel discrete event simulations (PDES). The models that are implemented for PDES are of increasing complexity and size and require various language features to support abstraction, encapsulation, and composition when building a simulation model. In this paper we focus on parallel simulation models that are written in C++ and present an approach for automatically generating reverse code for C++. The strategy we have adopted for our approach is to first assure that we can correctly handle event methods that use the entire C++ language. Although a significant runtime overhead is introduced with our technique, the assurance that the reverse code is always generated fully automatically is an enormous win that can open the door to routine optimistic simulation with models that can be implemented using the entire C++ language.		Markus Schordan;David R. Jefferson;Peter D. Barnes;Tomas Oppelstrup;Daniel J. Quinlan	2015		10.1007/978-3-319-20860-2_6	parallel computing;real-time computing;programming language	Logic	-11.602122691618561	36.2774757809132	63094
81b334de2e15eecaee59b28373af8c42b190a9da	a multiprocessor architecture combining fine-grained and coarse-grained parallelism strategies	parallelisme;instruction level parallel;multiprocessor;superscalar;multiprocessor systems;estudio comparativo;boucle programme;performance;performance comparison;instruction;estrategia;instruccion;loop level parallelism;system performance;bucle programa;superscolaire;strategy;etude comparative;computer architecture;parallelism;paralelismo;multiprocessor architecture;comparative study;arquitectura;program loop;oleoducto;pipelining;rendimiento;coarse grained;multiprocesador;instruction level parallelism;register transfer level;strategie;high performance;architecture;fine grained;performance comparisons;pipeline;instructions per cycle;parallelisme niveau instruction;shared memory multiprocessor;multiprocesseur	A wide variety of computer architectures have been proposed that attempt to exploit parallelism at different granularities. For example, pipelined processors and multiple instruction issue processors exploit the fine-grained parallelism available at the machine instruction level, while shared memory multiprocessors exploit the coarse-grained parallelism available at the loop level. Using a registertransfer level simulation methodology, this paper examines the performance of a multiprocessor architecture that combines both coarse-grained and fine-grained parallelism strategies to minimize the execution time of a single application program. These simulations indicate that the best system performance is obtained by using a mix of fine-grained and coarse-grained parallelism in which any number of processors can be used, but each processor should be pipelined to a degree of 2 to 4, or each should be capable of issuing from 2 to 4 instructions per cycle. These results suggest that current high-performance microprocessors, which typically can have 2 to 4 instructions simultaneously executing, may provide excellent components with which to construct a multiprocessor system.	central processing unit;computer architecture;instructions per cycle;machine code;microprocessor;multiprocessing;parallel computing;pipeline (computing);run time (program lifecycle phase);shared memory;simulation	David. J. Lilja	1994	Parallel Computing	10.1016/0167-8191(94)90003-5	computer architecture;parallel computing;real-time computing;computer science;memory-level parallelism;operating system;computer performance;data parallelism;pipeline;instruction-level parallelism;scalable parallelism;implicit parallelism;task parallelism	Arch	-15.329568153626749	43.572005173716796	63098
ca117bc3cc64cc7849943a04bbb982a1389d5157	the development and integration of a distributed 3d fft for a cluster of workstations	cluster of workstations	In this paper, the authors discuss the steps taken in the formulation of a parallel 3D FFT with good scalability on a cluster of fast workstations connected via commodity 100 Mb/s ethernet. The motivation for this work is to improve the performance and scalability of the Distributed Particle Mesh Ewald (DPME) N-body solver. Scalability issues in the FFT and DPME as an application are presented separately. Also discussed are scalability issues related to the networking hardware used in the cluster. Results indicate that the existence of a parallel FFT significantly improves performance in DPME from a maximum of 5 processors to at least 24 processors on a cluster of workstations. This has an associated increase in speedup from 4 to 12 times faster than the serial version.	computer cluster;fast fourier transform;workstation	Christopher E. Cramer;John A. Board	2000			parallel computing;real-time computing;computer science;distributed computing	HPC	-7.816623227540771	41.784530436386014	63202
a1c249f9a6004ea11b53b854a35d9e5549a5fd0d	a hybrid parallel delaunay image-to-mesh conversion algorithm scalable on distributed-memory clusters		In this paper, we present a scalable three dimensional hybrid MPI+Threads parallel Delaunay image-to-mesh conversion algorithm. A nested master-worker communication model for parallel mesh generation is implemented which simultaneously explores process-level parallelization and thread-level parallelization: inter-node communication using MPI and inter-core communication inside one node using threads. In order to overlap the communication (task request and data movement) and computation (parallel mesh refinement), the inter-node MPI communication and intra-node local mesh refinement is separated. The master thread that initializes the MPI environment is in charge of the inter-node MPI communication while the worker threads of each process are only responsible for the local mesh refinement within the node. We conducted a set of experiments to test the performance of the algorithm on Turing, a distributed memory cluster at Old Dominion University High Performance Computing Center and observed that the granularity of coarse level data decomposition, which affects the coarse level concurrency, has a significant influence on the performance of the algorithm. With the proper value of granularity, the algorithm expresses impressive performance potential and is scalable to 30 distributed memory compute nodes with 20 cores each (the maximum number of nodes available for us in the experiments). c © 2016 The Authors. Published by Elsevier Ltd. Peer-review under responsibility of organizing committee of the 25th International Meshing Roundtable (IMR25).	adaptive mesh refinement;algorithm;computation;concurrency (computer science);delaunay triangulation;distributed memory;experiment;inter-process communication;message passing interface;organizing (structure);parallel computing;parallel mesh generation;refinement (computing);scalability;thread (computing);turing	Daming Feng;Andrey N. Chernikov;Nikos Chrisochoides	2018	Computer-Aided Design	10.1016/j.cad.2017.11.006	granularity;concurrency;mathematics;scalability;computation;thread (computing);algorithm;delaunay triangulation;distributed memory;mesh generation	HPC	-6.282085328432556	40.970268347385094	63242
048732d041485cb9fd0778be1544966051a6077f	vectorizing c compilers: how good are they?	convex cc compiler;cray ymp sec compiler c compiler vectorization programming language c c loop kernels convex cc compiler convex application compiler cray 2 sec compiler;c compiler vectorization;programming language;loosely coupled computers;cray 2 sec compiler;programming language c;data mining;generate and test;c language;distributed computing system;process mapping;sequential selection;c loop kernels;convex application compiler;fortran;heuristics;program compilers;kernel computer languages computer architecture optimizing compilers testing;time constraints;program compilers c language;cray ymp sec compiler	The programming language C is becoming more and more popular among users of high performance vector com­ puter architectures. With this popularity of C, it becomes more critical to have a good optimizinglvecto rizing C com­ piler. This paper describes a study of four such vectorizing C compilers, with emphasis on the automatic vectorization ability of each compiler. This study is similar to the Fortran study that was described in [CDL88} and in fact, one facet of this study is a C version of the same kernels. Three suites of C loop kernels have been developed to determine the strengths and weaknesses of vectorizing compilers. The Convex ec compiler, the Convex Application Compiler, the Cray 2 sec compiler, and the Cray YMP sec compiler have been tested against these suites. The paper gives the results for each suite, with identification of problem areas for each compiler.	compiler;vector graphics	Lauren L. Smith	1991	Proceedings of the 1991 ACM/IEEE Conference on Supercomputing (Supercomputing '91)	10.1145/125826.126105	computer architecture;compiler;parallel computing;compiler correctness;interprocedural optimization;computer science;operating system;heuristics;compiler construction;program optimization;data mining;programming language;intrinsic function;functional compiler	HPC	-13.02268733526592	36.67529715770685	63259
b499f27aa3d1a5991b0f4b2111f72841c755c595	a data and task parallel image processing environment for distributed memory systems	distributed memory;distributed memory systems;image processing;parallel programming;stereo vision distributed memory systems low level image processing task decomposition image application task graph;parallel image processing;parallel programming image processing distributed memory systems;algorithmic skeletons;stereo vision;image processing skeleton parallel processing stereo vision weather forecasting physics pattern recognition biomedical imaging parallel architectures computer architecture;task graphs	The paper presents a data and task parallel low-level image processing environment for distributed memory systems. Image processing operators are parallelized by data decomposition using algorithmic skeletons. At the application level we use task decomposition, based on the Image Application Task Graph. In this way, an image processing application can be parallelized both by data and task decomposition, and thus better speed-ups can be obtained. We validate our method on the multi-baseline stereo vision application.	distributed memory;image processing	Cristina Nicolescu;Pieter P. Jonker	2001		10.1109/ICPPW.2001.951848	computer vision;feature detection;parallel computing;analog image processing;distributed memory;image processing;computer science;stereopsis;theoretical computer science;digital image processing	HPC	-6.019051174655281	42.00712401961024	63333
80af9532ad1a8da77bea76b5deaca931963e9d54	parallel execution of prolog programs: a survey	informatica;shared memory;memory management;prolog;parallelizing compilers;abstract machine;run time system;parallelism;logic programming;dynamic data structure;constraint programming;timing analysis;logic programs;automatic parallelization	Since the early days of logic programming, researchers in the field realized the potential for exploitation of parallelism present in the execution of logic programs. Their high-level nature, the presence of nondeterminism, and their referential transparency, among other characteristics, make logic programs interesting candidates for obtaining speedups through parallel execution. At the same time, the fact that the typical applications of logic programming frequently involve irregular computations, make heavy use of dynamic data structures with logical variables, and involve search and speculation, makes the techniques used in the corresponding parallelizing compilers and run-time systems potentially interesting even outside the field. The objective of this article is to provide a comprehensive survey of the issues arising in parallel execution of logic programming languages along with the most relevant approaches explored to date in the field. Focus is mostly given to the challenges emerging from the parallel execution of Prolog programs. The article describes the major techniques used for shared memory implementation of Or-parallelism, And-parallelism, and combinations of the two. We also explore some related issues, such as memory management, compile-time analysis, and execution visualization.	automatic parallelization;compile time;compiler;computation;data structure;dynamic data;dynamization;high- and low-level;logic programming;memory management;nondeterministic algorithm;parallel computing;programming language;prolog;referential transparency;shared memory	Gopal Gupta;Enrico Pontelli;Khayri A. M. Ali;Mats Carlsson;Manuel V. Hermenegildo	2001	ACM Trans. Program. Lang. Syst.	10.1145/504083.504085	shared memory;constraint programming;parallel computing;declarative programming;computer science;theoretical computer science;functional logic programming;abstract machine;programming paradigm;inductive programming;programming language;prolog;logic programming;static timing analysis;automatic parallelization;memory management	PL	-17.408777703074897	33.718487267429914	63422
90074258718c37f7a50f0f265e69f6a857f4ae85	an evaluation model and benchmark for parallel computing frameworks		MARS and Spark are two popular parallel computing frameworks and widely used for large-scale data analysis. In this paper, we first propose a performance evaluation model based on support vector machine (SVM), which is used to analyze the performance of parallel computing frameworks. Furthermore, we give representative results of a set of analysis with the proposed analytical performance model and then perform a comparative evaluation of MARS and Spark by using representative workloads and considering factors, such as performance and scalability. The experiments show that our evaluation model has higher accuracy than multifactor line regression (MLR) in predicting execution time, and it also provides a resource consumption requirement. Finally, we study benchmark experiments between MARS and Spark. MARS has better performance than Spark in both throughput and speedup in the executions of logistic regression and Bayesian classification because MARS has a large number of GPU threads that can handle higher parallelism. It also shows that Spark has lower latency than MARS in the execution of the four benchmarks.	benchmark (computing);parallel computing	Weibei Fan;Zhi-jie Han;Ruchuan Wang	2018	Mobile Information Systems	10.1155/2018/3890341	parallel computing;throughput;naive bayes classifier;support vector machine;spark (mathematics);scalability;speedup;computer science;thread (computing);mars exploration program	HPC	-4.566148749034155	45.04389706381235	63616
5c8b7ae1272401561d80f115185adcb6ca1c4423	the worst case analysis of algorithm on multiple stacks manipulation	storage allocation;gestion memoire;algorithm analysis;multiple stacks;storage management;sistema informatico;stack;pila;computer system;worst case analysis;analysis of algorithms;gestion memoria;dynamic allocation;data structures;estructura datos;analyse algorithme;structure donnee;systeme informatique;asignacion dinamica;allocation memoire;allocation dynamique;asignacion memoria;data structure;article;pile memoire;analisis algoritmo		algorithm;best, worst and average case	Been-Chian Chien;Wei-Pang Yang	1992	Inf. Process. Lett.	10.1016/0020-0190(92)90194-Z	data structure;stack;computer science;artificial intelligence;analysis of algorithms;programming language;algorithm	Robotics	-18.613281753454203	41.465025679572385	63685
c758aff0dfb2574d490d12c0675980cba3532834	algorithmic performance of dataflow multiprocessors	application software;computer aided instruction;computer applications;computer networks;computer architecture;computer simulation computational modeling computer aided instruction data structures algorithm design and analysis application software computer applications computer architecture computer networks;computational modeling;data structures;computer simulation;algorithm design and analysis	"""A dataflow computer simulation with algorithmic benchmark studies verifies that distributed accessing of structured data is indeed superior to centralized data accessing. D ata-driven computers can offer a high degree ofconcurrent exeD cution among many instructions. 1,2 Numerous architectures3-8 have been put forward for developing an effective dataflow computer system. This article presents an algorithmic simulation methodology to compare critical architectural issues in the design and application of dataflow computers. One critical issue in both static and dynamic dataflow systems is the mechanism for accessing structured data. To illustrate our comparative method, we present a study of two approaches to this issue. A centralized approach was once suggested for the MIT static dataflow machine.9 A distributed method was practiced in the simulated Irvine machine,'0 which is a typical dynamic dataflow machine using tagged tokens. In this study, we offer simulation tools for comparing the performance of the major dataflow computers. For a general review of dataflow computers, the readers are referred to the articles by Treleaven I and Dennis. 7 A special issue on dataflow systems has appeared in the February 1982 issue of Computer."""" In Chapter 10 of Hwang and Briggs,2 dataflow computers and languages are introduced and assessed."""	benchmark (computing);ce-ata;centralized computing;computer simulation;dataflow	William W. Carlson;Kai Hwang	1985	Computer	10.1109/MC.1985.1662773	computer simulation;computational science;algorithm design;computer architecture;computing;application software;computer science;theoretical computer science;operating system;computational criminology;computer performance;abstract machine;computer applications;computer network programming;computational model;computer network operations;software system;computer engineering	HPC	-13.259333897837106	42.172524210533666	63873
f938cd611808c6e72fb5880b2839db3067ab62cf	mpus: a scalable parallel simulator for redneurons parallel computer	parallel computer;complicated architecture;cmp technology;scalable parallel simulator;high performance parallel computer;redneurons parallel computer;next generation	In this paper, we present a scalable parallel simulator --- MPUS --- for verifying the design of our next generation high performance parallel computer --- RedNeurons(RN) parallel computer. The RedNeurons parallel computer is based on CMP technology, and it adopts an advanced but maybe some complicated architecture and topology. This paper mainly describes the design and implementation of the MPUS.	microprocessor;parallel computing;scalability	Li Hui;Junming Wu;Guoliang Chen;Xiufeng Sui	2007		10.1145/1366804.1366846	computational science;computer architecture;parallel computing;computer science	HPC	-6.256850719645341	37.612171098986735	63931
e186a89a3b749f00f6ed912c8c7fcda08f1f94ea	architecture of parallel management kernel for pie64	distribution;tratamiento paralelo;parallelisme;sistema operativo;cargamento;traitement parallele;parallel operating system;loading;chargement;parallelism;paralelismo;particion;operating system;scheduling;partition;arquitectura;load distribution;systeme exploitation;ordonamiento;load partitioning;parallel inference machine;distribucion;architecture;parallel processing;ordonnancement	We describe the architecture of the parallel management kernel for the parallel inference engine PIE64, focusing on how to treat load distribution and scheduling in highly parallel symbolic processing. Since the kernel manages automatic load distribution and scheduling, the task remaining for the programmer is to employ parallel algorithms with sufficient concurrency. A programmer need no longer be concerned with load distribution, load partitioning, load assignment, parallelism explosion, exhaustion of resources, or execution efficiency. We also describe an evaluation of the load distribution method	kernel (operating system)	Yasuo Hidaka;Hanpei Koike;Hidehiko Tanaka	1994	Future Generation Comp. Syst.	10.1016/0167-739X(94)90049-3	partition;distribution;parallel processing;parallel computing;real-time computing;computer science;architecture;operating system;distributed computing;scheduling	Arch	-15.73332288256407	42.927654889639776	64036
fa2da5ecd8da1df8883ca5d66413e8eb3c22a44f	large-scale scientific irregular computing on clusters and grids	irregularity;clusters;scientific application;distributed system;integrated approach;data intensive application;virtual memory;gestion memoire;systeme reparti;computational grid;storage management;distributed computing;paralelisacion;runtime library;irregularite;grid;large scale;software architecture;gestion memoria;sistema repartido;irregular problems;parallelisation;irregularidad;memoire virtuelle;parallelization;calculo repartido;out of core computing;external memory;escala grande;calcul reparti;memoria virtual;echelle grande	Data sets involved in many scientific applications are often too massive to fit into main memory of even the most powerful computers and therefore they must reside on disk, and thus communication between internal and external memory, and not actual computation time, becomes the bottleneck in the computation. The most challenging are scientific and engineering applications that involve irregular (unstructured) computing phases. This paper discusses an integrated approach, namely ideas, techniques, concepts and software architecture for implementing such data intensive applications on computational clusters and the computational Grid, an emerging computing infrastructure. The experimental performance results achieved on a cluster of PCs are included.		Peter Brezany;Marian Bubak;Maciej Malawski;Katarzyna Zajac	2002		10.1007/3-540-46043-8_49	software architecture;parallel computing;computer science;virtual memory;theoretical computer science;operating system;database;distributed computing;grid	HPC	-17.292743955021255	43.129378873004306	64153
6793756d29dbedd5cfa4d61325cba89358dd20b4	arquitetura multi-core reconfigurável para detecção de pedestres baseada em visão			multi-core processor	José Arnaldo Mascagni de Holanda	2017			field-programmable gate array;parallel computing;multi-core processor;computer science	Crypto	-9.423440673465866	42.870029576866585	64239
084f6b5aa673f2e31dd922fc430e4cea73009997	eine homogene programmierumgebung für einen heterogenen multiprozessor zur echtzeit-bildverarbeitung		Nowadays common Computer Systems do not offer the Computing power to process video data in real time. Dedicated Systems as heterogeneous multiprocessors which are fit to the particular properties of image processing functions have to be used. But their programming and handling are much more complicated and require a deep knowledge of the underlying hardand Software. Besides specialists, users will not accept such heterogeneous multiprocessor Systems without extended development tools already containing the system specific knowledge. Two aspects have reached a certain importance: the implementation of applications without knowledge of the underlying hardware and the scheduling of the different program parts to the heterogeneous mul¬ tiprocessor. The analysis of these two problems led to the subject of this work, to the homogeneous programming environment for a hetero¬ geneous multiprocessor for real-time image processing. It allows also non expert users the development of complex applications on a real system (in our case a combination of a systolic array and a transputer network) in a short time. At the well-known Visual programming language Cantata a hard¬ ware independent way of programming is shown. Then the steps are explained which are necessary to build up an executable program. They include the extraction of a dataflow graph out of the application, its analysis, the finding of a static configuration for the system and at last the generation of source code for the different types of processors. All transformations and algorithms are parts of the development environ¬ ment and are automatically executed. The required knowledge about hardware and the run-time behaviour of the functions is provided by a central data base. Besides the easiness of programming, the best utilization of a system	algorithm;central processing unit;co-ment;data-flow analysis;database;dataflow;eine and zwei;executable;gesellschaft für informatik;image processing;integrated development environment;multiprocessing;programming tool;real-time clock;regular expression;run time (program lifecycle phase);scheduling (computing);systolic array;transputer;visual programming language;warez;whole earth 'lectronic link	Markus Zeltner	1994			computer graphics (images);computer architecture;digital image processing;computer science	HPC	-16.989456116256573	39.67404443757244	64377
5798e18a22ec9ce07e91f59b6e67ed45816f775d	fortran legacy code performance optimization: sequential and parallel processing with openmp	libraries;linear algebra;level 3 bias;yarn;shared memory;basic linear algebra subroutines;scientific program;software maintenance;product code;climate model;software performance evaluation;parallel programming;compiler;data mining;scientific program fortran legacy code performance optimization sequential processing parallel processing openmp quantitative characterization performance gain sequential optimization level 3 bias basic linear algebra subroutine fortran 90 95 array notation fortran 77 compiler source code shared memory parallel computing model weather climate model climate research;software performance evaluation application program interfaces digital arithmetic fortran linear algebra meteorology parallel programming shared memory systems software maintenance;arrays;fortran 77;sequential processing;shared memory systems;optimization parallel processing concurrent computing performance gain production software engineering mathematical model high performance computing computer languages computer science;quantitative characterization;application program interfaces;weather climate model;parallel computer;performance gain;openmp;digital arithmetic;fortran legacy code performance optimization;level 3 blas;optimization;source code;fortran;fortran 90 95 array notation;climate research;shared memory parallel computing model;magnetic cores;performance optimization;sequential optimization;meteorology;program processors;basic linear algebra subroutine;parallel processing	Several optimization alternatives are presented for legacy FORTRAN 77 scientific programs, each one with a quantitative characterization in terms of performance gain. Initially, sequential optimization is focused on the analisys of Level 3 BLAS (Basic Linear Algebra Subroutines) utilization, since BLAS have several performance optimized implementations. Also, the Fortran 90/95 array notation is used as a code upgrade from Fortran 77 to Fortran 90/95and, also, to provide the compiler a better source code for performance optimization. Since the shared memory parallel computing model is widely available (multiple cores and/or processors), the analysis of possible parallel processing via OpenMP is presented, along with the performance gain in a specific case. Sequential optimization as well parallelization work is done on a real (production code) program: a weather climate model implemented about two decades ago and used for climate research.	blas;central processing unit;climate model;code refactoring;compiler;computer;distributed memory;fortran;legacy code;linear algebra;mathematical optimization;multi-core processor;open research;openmp;parallel computing;parallel processing (dsp implementation);performance tuning;program optimization;sse2;shared memory;subroutine;time complexity	Fernando Tinetti;Mónica A. López;Pedro G. Cajaraville;Diego L. Rodrigues	2009	2009 WRI World Congress on Computer Science and Information Engineering	10.1109/CSIE.2009.90	shared memory;parallel processing;computer architecture;compiler;parallel computing;computer science;linear algebra;operating system;universal product code;programming language;software maintenance;climate model;source code	HPC	-8.371015696522653	40.4003906347705	64449
ecf034dafdbcf50d3e853b34b2f3ae7075e11e78	mapping communication layouts to network hardware characteristics on massive-scale blue gene systems	torus networks;process mapping;blue gene	For parallel applications running on high-end computing systems, which processes of an application get launched on which processing cores is typically determined at application launch time without any information about the application characteristics. As high-end computing systems continue to grow in scale, however, this approach is becoming increasingly infeasible for achieving the best performance. For example, for systems such as IBM Blue Gene and Cray XT that rely on flat 3D torus networks, process communication often involves network sharing, even for highly scalable applications. This causes the overall application performance to depend heavily on how processes are mapped on the network. In this paper, we first analyze the impact of different process mappings on application performance on a massive Blue Gene/P system. Then, we match this analysis with application communication patterns that we allow applications to describe prior to being launched. The underlying process management system can use this combined information in conjunction with the hardware characteristics of the system to determine the best mapping for the application. Our experiments study the performance of different communication patterns, including 2D and 3D nearest-neighbor communication and structured Cartesian grid communication. Our studies, that scale up to 131,072 cores of the largest BG/P system in the United States (using 80% of the total system size), demonstrate that different process mappings can show significant difference in overall performance, especially on scale. For example, we show that this difference can be as much as 30% for P3DFFT and up to twofold for HALO. Through our proposed model, however, such differences in performance can be avoided so that the best possible performance is always achieved.	blue gene;experiment;ibm personal computer xt;job control (unix);launch time;networking hardware;p system;regular grid;scalability;semantic network	Pavan Balaji;Rinku Gupta;Abhinav Vishnu;Peter H. Beckman	2011	Computer Science - Research and Development	10.1007/s00450-011-0168-y	mathematical optimization;parallel computing;real-time computing;simulation;computer science;operating system;database;distributed computing	HPC	-8.31657012605814	44.72077293115711	64508
caa0831e7645630496f65e6a6443083ff6030d05	a parallel reed-solomon decoder on the imagine stream processor	calcul scientifique;desciframiento;circuit decodeur;algoritmo paralelo;largeur bande;haute performance;parallel algorithm;decodage;decoding;gollete estrangulamiento;complex programming;correction erreur;real time;programacion compleja;distributed computing;codigo bloque;circuito desciframiento;arithmetique;application intensive;algorithme parallele;organizacion memoria;computer architecture;decoding circuit;goulot etranglement;computacion cientifica;aritmetica;architecture ordinateur;media processing;intensive application;arithmetics;code reed solomon;error correction;temps reel;anchura banda;organisation memoire;reed solomon;scientific computing;alto rendimiento;hierarchie memoire;calculo repartido;tiempo real;bandwidth;programmation complexe;code bloc;arquitectura ordenador;codigo reed solomon;memory organization;memory hierarchy;correccion error;stream processing;scientific computation;aplicacion intensiva;jerarquia memoria;galois field;high performance;bottleneck;memory bandwidth;block code;calcul reparti;block codes;reed solomon code;software implementation	The increasing gap between processor and memory speeds is a wellknown problem in modern computer architecture. Imagine stream architecture can solve bandwidth bottleneck by its particular memory hierarchy and stream processing for computationally intensive applications. Good performance has been demonstrated on media processing and partial scientific computing domains. Reed-Solomon (RS) codes are powerful block codes widely used as an error correction method. RS decoding demands a high memory bandwidth and intensive ALUs because of complex and special processing (galois field arithmetic), and real time requirement. People usually use specialized processor or DSP to solve it that gains high performance but lacks flexibility. This paper presents a software implementation of a parallel Reed-Solomon decoder on the Imagine platform. The implementation requires complex stream programming since the memory hierarchy and cluster organization of the underlying architecture are exposed to the Imagine programmer. Results demonstrate that Imagine has comparable performance to TI C64x. This work is an ongoing effort to validate the stream architecture is efficient and makes contribution to extend the application domain.	application domain;block code;computational science;computer architecture;computer cluster;digital signal processor;error detection and correction;folded reed–solomon code;high memory;memory bandwidth;memory hierarchy;programmer;reed–solomon error correction;stream processing;ti-basic;texas instruments tms320	Mei Wen;Chunyuan Zhang;Nan Wu;Haiyan Li;Li Li	2004		10.1007/978-3-540-30566-8_6	block code;parallel computing;real-time computing;computer science;artificial intelligence;operating system;reed–solomon error correction;algorithm;statistics	Arch	-15.89168684275669	41.29890189724785	64704
a2093b911622b12f3aa23e5aaea2a2f34a030c87	improving java performance using dynamic method migration on fpgas	simulation;fpga;coprocessor;dynamic migration;java coprocessors;dynamic method migration;embedded systems;multimedia mobile devices;java performance;reconfiguarable architectures	With the diffusion of Java in advanced multimedia mobile devices, there is a growing need for speeding up the execution of Java bytecode beyond the limits of traditional interpreters and just-in-time compilers. In this area, Java coprocessors are viewed as a promising technology, which marries the flexibility of a general-purpose microprocessor to run legacy code and lightweight Java methods, with the high performance of a specialised execution engine on speed-critical bytecode. This work proposes and analyses a microprocessor with FPGA coprocessor architecture with efficient shared-memory communication support. Furthermore, we describe a complete run-time environment that supports dynamic migration of Java methods to the coprocessor, and we quantitatively analyse speedups achievable under a number of system configurations using an accurate complete-system simulator.	field-programmable gate array;java performance	Emanuele Lattanzi;Aman Gayasen;Mahmut T. Kandemir;Narayanan Vijaykrishnan;Luca Benini;Alessandro Bogliolo	2005	IJES	10.1504/IJES.2005.009952	embedded system;computer architecture;parallel computing;real-time computing;java concurrency;computer science;operating system;strictfp;embedded java;real time java;programming language;java;coprocessor;field-programmable gate array	EDA	-5.97886653958169	44.92192964589622	64977
51bcb9098031a6901948ff28b7e0ecfdc8ce4546	on the efficiency of symbolic computations combined with code generation for finite element methods	variational forms;symbolic computation;automated code generation;code generation;finite element method;compiler;finite element;metaprogramming;high level language;automation	Efficient and easy implementation of variational forms for finite element discretization can be accomplished with metaprogramming. Using a high-level language like Python and symbolic mathematics makes an abstract problem definition possible, but the use of a low-level compiled language is vital for run-time efficiency. By generating low-level C++ code based on symbolic expressions for the discrete weak form, it is possible to accomplish a high degree of abstraction in the problem definition while surpassing the run-time efficiency of traditional hand written C++ codes. We provide several examples where we demonstrate orders of magnitude in speedup.	c++;calculus of variations;code generation (compiler);compiled language;compiler;discretization;finite element method;high- and low-level;high-level programming language;metaprogramming;python;s-expression;speedup;symbolic computation;weak formulation	Martin Sandve Alnæs;Kent-André Mardal	2010	ACM Trans. Math. Softw.	10.1145/1644001.1644007	symbolic computation;computer science;theoretical computer science;finite element method;programming language;algorithm;code generation	PL	-11.646846194061995	35.55786220755761	65010
2b361d56671eab2adbb6d799bfbe7d302e71b9d0	memory referencing behavior in compiler-parallelized applications	true sharing;eficacia sistema;haute performance;compilateur;parallelizing compilers;performance systeme;informing science;cache memory;paralelisacion;memory performance;compiler;system performance;antememoria;antememoire;sharing;particion;false sharing;parallelisation;false and true sharing;array processors;cache performance;parallelization;alto rendimiento;memory systems;partage;translators;high performance;memory devices;parallel applications;parallel processing;compilador;mathematics computers information science management law miscellaneous	Compiler-parallelized applications are increasing in importance as moderate-scale multiprocessors become common. This paper evaluates how features of advanced memory systems (e.g., longer cache lines) impact memory system behavior for applications amenable to compiler parallelization. Using full-sized input data sets and applications taken from the SPEC, NAS, PERFECT, and RICEPS benchmark suites, we measure statistics such as speedups, memory costs, causes of cache misses, cache line utilization, and data traffic. This exploration allows us to draw several conclusions. First, we find that larger granularity parallelism often correlates with good memory system behavior, good overall performance, and high speedup in these applications. Second, we show that when long (512 byte) cache lines are used, many of these applications suffer from false sharing and low cache line utilization. Third, we identify some of the common artifacts in compiler-parallelized codes that can lead to false sharing or other types of poor memory system performance, and we suggest methods for improving them. Overall, this study offers both an important snapshot of the behavior of applications compiled by state-of-the-art compilers, as well as an increased understanding of the interplay between cache line size, program granularity, and memory performance in moderate-scale multiprocessors.	benchmark (computing);byte;cpu cache;cache (computing);code;compiler;false sharing;network-attached storage;parallel computing;perfect;snapshot (computer storage);speedup	Evan Torrie;Margaret Martonosi;Mary W. Hall;Chau-Wen Tseng	1996	International Journal of Parallel Programming	10.1007/BF03356754	bus sniffing;uniform memory access;shared memory;parallel processing;interleaved memory;compiler;cache-oblivious algorithm;parallel computing;real-time computing;cache coloring;false sharing;cpu cache;cache;computer science;theoretical computer science;cache invalidation;operating system;programming language;cache algorithms;cache pollution;algorithm;cache-only memory architecture;non-uniform memory access	Arch	-15.838712857725271	44.56070004974366	65229
471a9554af951d8b12e07ed70da0bf6fee6ce2ed	parameterisation to tailor commodity clusters to applications	scientific application;cluster computing;first principle;commodity computing;parallel machines;scientific applications;parallel applications;data transfer	Parallel applications can be parameterised by the quotient γa of flop/s and data transfers between the processors, and by the machine-dependent, maximum local processor performance ra. Clusters can be parameterised by the quotient γm of ra and the per processor network communication bandwidth bm. All those parameters are predictable. In parallel machines, the communication time is smaller than the computing time if γm < γa. A first principles chemistry application is described and parameterised. Benchmarks on the Swiss-T1 cluster machine show that the predicted inter-processor communication and computing times correspond well to the measured times. These parameterisations can now be used to tailor clusters from commodity components to the applications. © 2002 Elsevier Science B.V. All rights reserved.	algorithm;bandwidth (signal processing);central processing unit;commodity computing;flops;fast fourier transform;machine-dependent software;mathematical optimization;memory bandwidth;parallel computing;real life;switzerland;ultrasparc t1	Ralf Gruber;Pieter Volgers;Alessandro De Vita;Massimiliano Stengel;Trach-Minh Tran	2003	Future Generation Comp. Syst.	10.1016/S0167-739X(02)00105-X	first principle;computer cluster;computer science;theoretical computer science;operating system;database;distributed computing	HPC	-6.812922283313588	39.30658996787858	65380
8ebdf319fb0736c7a88d61d973dc3a4ac677c79c	efficient interpreter optimizations for the jvm	threaded code;dynamic languages;rhino;java virtual machine;interpreters;jython;just in time compilers	The Java virtual machine is a popular target for many language implementers. Due to the unusually poor performance of hosted interpreters, many programming language implementers resort to implementing a custom compiler that emits Java bytecode instead. We studied performance of these hosted interpreters targeting the JVM and identified common bottlenecks preventing their efficient execution. First, similar to interpreters written in C/C++, instruction dispatch is expensive on the JVM. Second, Java's array semantics dictate expensive runtime exception checks, which negatively affect array performance essential to interpreters.  We present two optimizations targeting these bottlenecks and show that the performance of the optimized interpreters increases dramatically: we report speedups by a factor of up to 2.45 over the Jython interpreter, and 3.57 over the Rhino interpreter respectively. Furthermore, the performance attained through our optimizations is comparable with custom compiler performance. We provide an easily accessible annotation-based interface to enable our optimizations. Thus, interpreter implementers can expect substantial performance boosts in a matter of hours of implementation effort.	c++;compiler;dynamic dispatch;exception handling;interpreter (computing);java bytecode;java virtual machine;jython;programming language	Gülfem Savrun-Yeniçeri;Wei Zhang;Huahan Zhang;Chen Li;Stefan Brunthaler;Per Larsen;Michael Franz	2013		10.1145/2500828.2500839	parallel computing;interpreter;computer science;operating system;compiled language;programming language;threaded code	PL	-17.868036085610047	36.43107151452792	65438
7cbb58a3eb324c4b6841c7a40260f06e44e608cb	solving the partitioning problem in distributed virtual environment systems using evolutive algorithms			algorithm;partition problem;virtual reality	Pedro Morillo;Marcos Fernández;Juan M. Orduña	2005		10.1201/9781420035063.ch30	virtual machine;distributed computing;computer science	HPC	-10.651203923063983	42.582354756334084	65569
b1c8ae7570714454c3495dc8c492c40979e4ccbb	gemma in april: a matrix-like parallel programming architecture on opencl	gemma;opencl kernels;kernel;computer model;computer graphic equipment;parallel programming;data transferring;coprocessors;parallel computing architecture;programming languages computer graphic equipment coprocessors parallel programming;graphics processing unit computer architecture sparse matrices computational modeling kernel parallel programming;computer architecture;computational modeling;open computing language matrix like parallel programming architecture graphics processing unit parallel computing architecture gemma april parallel algorithms opencl kernels data storing data transferring;graphic processing unit;matrix like parallel programming architecture;data storing;graphics processing unit;parallel programs;sparse matrices;april;programming languages;parallel algorithms;open computing language	Nowadays, Graphics Processing Unit (GPU), as a kind of massive parallel processor, has been widely used in general purposed computing tasks. Although there have been mature development tools, it is not a trivial task for programmers to write GPU programs. Based on this consideration, we propose a novel parallel computing architecture. The architecture includes a parallel programming model, named Gemma, and a programming framework, named April. Gemma is based on generalized matrix operations, and helps to alleviate the difficulty of describing parallel algorithms. April is a high-level framework that can compile and execute tasks described in Gemma with OpenCL. In particular, April can automatically 1) choose the best parallel algorithm and mapping scheme, and generate OpenCL kernels, 2) schedule Gemma tasks based on execution costs such as data storing and transferring. Our experimental results show that with competitive performance, April considerably reduces the programs' code length compared with OpenCL.	central processing unit;compiler;computation;computer architecture;computer cluster;general-purpose computing on graphics processing units;graphics processing unit;high- and low-level;matrix multiplication;multi-core processor;opencl api;parallel algorithm;parallel computing;parallel programming model;programmer;programming tool;random-access memory;scheduling (computing);speedup;video ram (dual-ported dram)	Tianji Wu;Di Wu;Yu Wang;Xiaorui Zhang;Hong Luo;Ningyi Xu;Huazhong Yang	2011	2011 Design, Automation & Test in Europe	10.1109/DATE.2011.5763119	computer simulation;embedded system;computer architecture;parallel computing;kernel;sparse matrix;computer science;theoretical computer science;gemma;operating system;parallel algorithm;programming language;computational model;coprocessor	HPC	-5.751543257712863	42.931374959571265	65658
0167b6819a5f7a3611dce88102464f4d65a39957	an effective two-dimensional mesh partitioning strategy	evaluation performance;performance evaluation;mesh partitioning;processor allocation;evaluacion prestacion;resource management;estrategia;allocation;red mallada cerrada;strategy;gestion recursos;reseau maille;particion;2d mesh;partition;gestion ressources;afectacion;meshed network;affectation;procesador;processeur;strategie;processor	Mesh-connected parallel architectures have become increasingly popular in the design of multiprocessor systems in recent years. Many partitionable two-dimensional (2D) mesh systems have been built or are currently being developed. To allow the best usage of these systems, an effective mesh partitioning/submesh allocation strategy is desirable. In this paper, we report on a new best-fit processor allocation strategy for 2D mesh systems. An efficient implementation of this strategy is presented that keeps the searching overhead low. Extensive simulations have been performed to compare the performance of this strategy with existing ones. The results show that it outperforms existing strategies in terms of mean response time under all load conditions and different job characteristics.		Yung-Kang Chu;Diane T. Rover	1995	Parallel Processing Letters	10.1142/S0129626495000552	partition;combinatorics;simulation;strategy;resource management;distributed computing	HPC	-16.80483904773564	44.10897269994491	66086
ab47db45cab7c02cb54de3160b057ff2bb5c419b	on the interaction of tiling and automatic parallelization	spec cpu95;automatic parallelization;performance benefit;tiling technique;tiling algorithm;sequential tiling technique;iteration space tiling;compiler technique;advanced parallelizing compiler;spec cpu2000 fortran;tiling pass	Iteration space tiling is a well-explored programming and compiler technique to enhance program locality. Its performance benefit appears obvious, as the ratio of processor versus memory speed increases continuously. In an effort to include a tiling pass into an advanced parallelizing compiler, we have found that the interaction of tiling and parallelization raises unexplored issues. Applying existing, sequential tiling techniques, followed by parallelization, leads to performance degradation in many programs. Applying tiling after parallelization without considering parallel execution semantics may lead to incorrect programs. Doing so conservatively, also introduces overhead in some of the measured programs. In this paper, we present an algorithm that applies tiling in concert with parallelization. The algorithm avoids the above negative effects. Our paper also presents the first comprehensive evaluation of tiling techniques on compiler-parallelized programs. Our tiling algorithm improves the SPEC CPU95 floating-point programs by up to 21% over non-tiled versions (4.9% on average) and the SPEC CPU2000 Fortran 77 programs up to 49% (11% on average). Notably, in about half of the benchmarks, tiling does not have a significant effect.	algorithm;automatic parallelization;compiler;elegant degradation;fortran;iteration;locality of reference;overhead (computing);parallel computing;programming language;tessellation (computer graphics);tiling window manager	Zhelong Pan;Brian Armstrong;Hansang Bae;Rudolf Eigenmann	2005		10.1007/978-3-540-68555-5_3	loop tiling;computer architecture;parallel computing;computer science;theoretical computer science;automatic parallelization	HPC	-17.82976107678975	37.30895139831192	66171
f167856b33b81729363d9e9d5bddb088729aa615	"""educational multiprocessor simulator """"e14"""" and its usage for expanding the formula of amdahl's law"""	mullticore;parallel calculations;simulator;computer architecture;amdahl s law;speedup	"""This paper describes demonstrative software simulator """"E14"""", helpful in studying on an ordinary PC essentials of parallel calculations. It contains five virtual processors with identical instruction set, one of which controls the other four. Simulator has several mechanisms of data exchange between processors, so it can be used for studying both architectures with shared and distributed memory. Parallel architecture of """"E14"""" naturally extends classical single-processor one, hence proposed approach makes students' knowledge more systematic. """"E14"""" may also be employed as a platform for the estimation of parallel algorithms' performance. The example, considered in the paper, clearly demonstrates how data exchange between processors may essentially degrade speedup, predicted by Amdahl's law."""	amdahl's law;central processing unit;computer science;distributed memory;full-range speaker;linear algebra;multi-core processor;multiprocessing;operating system;overhead (computing);parallel algorithm;physics processing unit;shared memory;speedup	Evgeny A. Eremin	2017	2017 25th Euromicro International Conference on Parallel, Distributed and Network-based Processing (PDP)	10.1109/PDP.2017.28	amdahl's law;computer architecture;parallel computing;speedup;computer science;theoretical computer science;operating system;analysis of parallel algorithms;distributed computing;programming language;karp–flatt metric	HPC	-6.369761141381321	39.610274064452284	66343
3716f58b22c646df91d7ff70816b042be113e7ee	kernel tuner: a search-optimizing gpu code auto-tuner		Abstract A very common problem in GPU programming is that some combination of thread block dimensions and other code optimization parameters, like tiling or unrolling factors, results in dramatically better performance than other kernel configurations. To obtain highly-efficient kernels it is often required to search vast and discontinuous search spaces that consist of all possible combinations of values for all tunable parameters. This paper presents Kernel Tuner, an easy-to-use tool for testing and auto-tuning OpenCL, CUDA, and C kernels with support for many search optimization algorithms that accelerate the tuning process. This paper introduces the application of many new solvers and global optimization algorithms for auto-tuning GPU applications. We demonstrate that Kernel Tuner can be used in a wide range of application scenarios and drastically decreases the time spent tuning, e.g. tuning a GEMM kernel on AMD Vega Frontier Edition 71.2x faster than brute force search.	graphics processing unit;kernel (operating system);pitch correction;tv tuner card	Ben van Werkhoven	2019	Future Generation Comp. Syst.	10.1016/j.future.2018.08.004	real-time computing;kernel (linear algebra);parallel computing;global optimization;brute-force search;program optimization;cuda;general-purpose computing on graphics processing units;thread (computing);computer science;tuner	Arch	-5.038117594722176	43.188419116762596	66406
d7e0045c2eb6ab10e2aa97b3c95cafc0e8b27c02	wait-free hyperobjects for task-parallel programming systems	data sharing;reference counting;computer languages;task parallel programming systems;associative reducer hyperobject;programming language;wait free hyperobjects;resource allocation;task parallelism hyperobjects wait free reduce reference counting finish;reduce;cilk programming language;parallel programming;synchronization computational modeling object oriented modeling instruction sets programming computer languages runtime;hyperobjects;runtime;reference counted resource management;synchronisation;c language;computational modeling;synchronization primitives;task analysis c language data structures parallel languages parallel programming resource allocation synchronisation;synchronization;data structures;task analysis;finish;wait free manner;finisher hyperobject;task parallelism;parallel languages;programming;data structure;object oriented modeling;wait free;cilk programming language wait free hyperobjects task parallel programming systems data structure data sharing programming language wait free manner finisher hyperobject synchronization primitives reference counted resource management associative reducer hyperobject;instruction sets	Hyperobjects are efficient mechanisms to coordinate accesses to shared variables and data-structures in task-parallel programming models, where each thread can operate on its own coordinated local view of the shared data. Synchronization between local views is restricted to occur at well-defined points in the execution, and can be left to the hyperobject implementation. This paper provides a general model for hyperobjects that does not require programming language or runtime support and may therefore be used with any task-parallel programming system. We show that hyperobjects can be efficiently implemented in a wait-free manner, meaning that all concurrent accesses to a hyperobject are guaranteed to complete in a bounded number of steps. The novel finisher hyperobject presented in this paper provides transitive termination detection for task-parallel programs. It can be used to efficiently implement task synchronization primitives like finish. However, finishers can also be used to manage reference-counted resources, e.g. shared pointers and copy-on-write pointers. Finally, we provide a wait-free variant of the associative reducer hyperobject known from the Cilk++ programming language.	admissible numbering;boost;cilk plus;compiler;computation;copy-on-write;non-blocking algorithm;open-source software;parallel computing;programming language;reference counting;scalability;shared variables	Martin Wimmer	2013	2013 IEEE 27th International Symposium on Parallel and Distributed Processing	10.1109/IPDPS.2013.10	synchronization;parallel computing;real-time computing;data structure;computer science;operating system;distributed computing;programming language;algorithm	Arch	-13.937367866718459	45.460862684735396	66411
6e6eaeef0db388eaad34eb9324673218a90c7f13	sunos multi-thread architecture	application program interface;separation logic;programming model	We describe a model for multiple threads of control within a single UNIX process. The main goals are to provide extremely lightweight threads and to rationalize and extend the UNIX Application Programming Interface for a multi-threaded environment. The threads are intended to be sufficiently lightweight so that there can be thousands present and that synchronization and context switching can be accomplished rapidly without entering the kernel. These goals are achieved by providing lightweight user-level threads that are multiplexed on top of kernel-supported threads of control. This architecture allows the programmer to separate logical (program) concurrency from the required real concurrency, which is relatively costly, and to control both within a single programming model.	application programming interface;concurrency (computer science);context switch;kernel (operating system);multiplexing;programmer;programming model;sunos;thread (computing);unix;user space	M. L. Powell;Steve R. Kleiman;Steve Barton;Devang Shah;Dan Stein;Mary Weeks	1991			computer architecture;parallel computing;computer science;programming language	OS	-13.534107794364797	41.038271709843634	66422
73f6514e316cc1158b8bfdf83cf3be2ee2023fae	ctdnet iii-an eager reduction model with laziness features	langage fonctionnel;parallelisme;school of no longer in use;electronics and computer science;reduction machines;multiprocessing;reduction;multiprogrammation;lazy evaluation;lenguaje funcional;estrategia;supercombinator reduction;multiprogramming;functional programming;supercombinator;strategy;parallelism;paralelismo;multiprogramacion;message passing;reduccion;programmation fonctionnelle;functional architectures;supercombinators;functional language;programacion funcional;strategie	A message passing multiprocessor model for computation based on functional languages has been s model follows the applicative (eager) order of reduction, giving it an edge in exploiting parallelis following normal order. However, the applicative strategy is prone to being unsafe and is incapabl recursion. A concept of Partial task has been introduced whose sluggishness in reduction is controlled version of recursion. The model has certain other features which make it selectively la reduction tends to be more need-based and hence more safe.	applicative programming language;computation;functional programming;linear algebra;message passing;multiprocessing;recursion	Padam Kumar;Jai Prakash Gupta;Stephen C. Winter	1995	Future Generation Comp. Syst.	10.1016/0167-739X(95)00004-C	parallel computing;message passing;multiprocessing;reduction;computer multitasking;strategy;computer science;theoretical computer science;operating system;lazy evaluation;distributed computing;programming language;functional programming;algorithm	Logic	-17.229448875826478	40.69404627304894	66495
e066e674be44fd78024794d9491bf70718838801	design verification of large scientific computers	scientific computing;design verification	Large scientific computers containing 2 million gates can be simulated using a combination of block simulation and gate simulation of 450, 00O gates.	and gate;co-ment;computer;logic simulation	Howard E. Krohn	1977			computational science;computer science;theoretical computer science;computer engineering	HPC	-7.616255203301884	37.34579759476107	66499
661cb659e36d5f9022f7788a069e173709723173	lessons from ftm: an experiment in design and implementation of a low-cost fault-tolerant system	tolerancia falta;fiabilidad;reliability;fault tolerant;multiprocessor;etude experimentale;transaction processing microcomputers fault tolerant computing reliability operating system kernels workstations;continuous system;fault tolerant system;fault tolerant computing;fault tolerant systems hardware fault tolerance operating systems costs local area networks computer crashes application software continuous time systems computer architecture;operating system;design and implementation;reliability fault tolerant microprocessor general purpose fault tolerant system standard workstations operating system source code compiling stable transactional memory mach micro kernel servers;fiabilite;workstations;fault tolerance;memoire stable;sistema tolerando faltas;systeme tolerant les pannes;source code;computer hardware;operating system kernels;multiprocesador;transaction processing;estudio experimental;materiel informatique;material informatica;tolerance faute;microcomputers;multiprocesseur	This report describes an experiment in the design of a general purpose fault tolerant system, FTM. The main objective of the FTM design was to implement a “low-cost” fault tolerant system that could be used on standard workstations. At the operating system level, our goal was to provide a methodology for the design of modular reliable operating systems, while of fering fault tolerance transparency to user applications. In other words, porting an application to FTM had only to require compiling the source code without having to modify it. These objectives were achieved using the Mach micro-kernel and a modular set of reliable servers which implement application checkpoints and provide continuous system functions despite machine crashes. At the architectural level, our approach relies on a high performance stable storage implementation, called Stable T ransactional Memory (STM), which can be implemented either by hardware or software. W e first motivate our design choices, then we detail the FTM implementation at both architectural and operating system level. W e comment on the reasons for the evolution of our stable memory technology from hardware to software. Finally , we present a performance evaluation of the FTM prototype. W e conclude with lessons learned and give some assessments. Key-words: Fault Tolerance, Blocking Consistent Checkpointing, Stable Memory , Modular Operating System, Micro-kernel. Leçons du projet FTM : une expérimentation dans la conception d’un système tolérant les fautes de faible coût Résumé :Ce document présente une expérimentation dans la conception d’un système tolérant les fautes à vocation générale, le FTM. Notre motivation principale était la conception d’un système de faible coût pouvant être utilisé sur des stations de travail standard. En ce qui concerne le système d’exploitation, notre objectif était de développer une méthodologie de conception de systèmes d’exploitation fiables offrant la transparence de la tolérance aux fautes aux applications utilisateurs. Autrement dit, le portage d’une application sur FTM ne doit nécessiter que la compilation du logiciel source sans avoir à modifier ce dernier . Nos objectifs ont été atteints en utilisant le micro-noyau Mach et un ensemble modulaire de serveurs fiables qui implément les points de reprises des applications et of fr nt un service système continu, malgré la défaillance d’une machine. Au niveau de l’architecture, notre approche a reposé sur la conception d’une mémoire stable rapide pouvant être mise en œuvre soit par matériel, soit par logiciel. Nous décrivons tout d’abord nos choix de conception, puis nous présentons la mise en œuvre du FTM en ce qui concerne l’architecture et le système d’exploitation. En particulier , nous décrivons l’évolution de la technologie mémoire stable depuis sa mise en œuvre par matériel jusqu’à son implémentation par logiciel. Enfin, nous présentons une évaluation des performances du prototype qui a été réalisé au cours de cette étude. Nous concluons en tirant les leçons de ce projet. Mots-clé : tolérance aux fautes, points de reprise cohérents, mémoire stable, système d’exploitation modulaire, micro-noyau. Lessons from FTM: an Experiment in the Design and Implementation of a Low Cost Fault	application checkpointing;bibliothèque des ecoles françaises d'athènes et de rome;compiler;fault tolerance;linear algebra;micro isv;modifier key;operating system;performance evaluation;prototype;reactions to the november 2015 paris attacks;sans institute;software transactional memory;stable storage;workstation	Gilles Muller;Michel Banâtre;Nadine Peyrouze;Bruno Rochat	1996	IEEE Trans. Reliability	10.1109/24.510822	reliability engineering;embedded system;fault tolerance;parallel computing;real-time computing;computer science	OS	-18.44777483485752	42.830412287362414	66679
06b5973d2fde715a6c5970ebac373a4009dd4963	execution of recursive queries in apache spark		MapReduce environments offer great scalability by restricting the programming model to only map and reduce operators. This abstraction simplifies many difficult problems occuring in generic dis-ion simplifies many difficult problems occuring in generic distributed computations like fault tolerance and synchronization, hiding them from the programmer. There are, however, algorithms that cannot be easily or efficiently expressed in MapReduce, such as recursive functions. In this paper we extend the Apache Spark runtime so that it can support recursive queries. We also introduce a new parallel and more lightweight scheduling mechanism, ideal for scheduling a very large set of tiny tasks. We implemented the aformentioned scheduler and found that it simplifies the code for recursive computation and can perform up to 2.1× faster than the default Spark scheduler.	algorithm;apache spark;asynchronous array of simple processors;computation;fault tolerance;hierarchical and recursive queries in sql;job scheduler;limbo;mapreduce;n-body problem;overhead (computing);programmer;programming model;recursion;rubber duck debugging;scalability;scheduling (computing);simulation	Pavlos Katsogridakis;Sofia Papagiannaki;Polyvios Pratikakis	2017		10.1007/978-3-319-64203-1_21	operator (computer programming);scalability;parallel computing;fault tolerance;scheduling (computing);spark (mathematics);programming paradigm;distributed computing;recursion;programmer;computer science	OS	-14.812980937446808	38.610114958665584	66790
4a0289dcf4a3d32cd33b27085f12239ffeb751d2	parallel implementations of cellular automata for traffic models		The Biham-Middleton-Levine (BML) traffic model is a simple two-dimensional discrete Cellular Automaton (CA) that has been used to study self-organization and phase transitions in traffic flows. From the computational point of view, the BML model exhibits the usual features of discrete CA, where the new state of each cell is computed according to simple rules involving its current state and that of the immediate neighbors. In this paper we evaluate the impact of various optimizations for speeding up CA computations on shared-memory parallel architectures using the BML model as a case study. In particular, we analyze parallel implementations of the BML automaton for multicore CPUs and GPUs. Experimental evaluation provides quantitative measures of the payoff of different optimization techniques. Contrary to popular claims of “double-digit speedups” of GPU versus CPU implementations, our findings show that the performance gap between CPU and GPU implementations of the BML traffic model can be greatly reduced by clever exploitation of all available CPU features.	battle management language;biham–middleton–levine traffic model;cellular automaton;central processing unit;computation;directive (programming);graphics processing unit;mathematical optimization;multi-core processor;openmp;overhead (computing);simd;self-organization;simulation;speedup;video card	Moreno Marzolla	2018		10.1007/978-3-319-99813-8_46	implementation;traffic model;theoretical computer science;cellular automaton;computation;stochastic game;computer science;performance gap;multi-core processor	Metrics	-8.530204584145071	45.391318549199866	66817
1e2bfc4119468e9a950c281caa1d46bdfd3b78e0	reuse and refactoring of gpu kernels to design complex applications	kernel composition;tesla s1050;graphics processing units gpu kernel reusability gpu kernel refactoring complex applications design software engineering community component based design flexible components generic components performance optimization performance improvement application performance design issue gpu resource usage performance signature data sharing kernel scheduling design optimization nonoptimal parameters molecular dynamics application fermi gpu;paper;refactoring;software maintenance;software reusability object oriented programming physics computing scheduling software maintenance software performance evaluation;molecular dynamics;software performance evaluation;gpu;fft;refactoring gpu component reuse kernel composition;object oriented programming;software engineering;physics computing;nvidia geforce gtx 480;cuda;scheduling;component reuse;software reusability;nvidia;optimization;computer science;kernel graphics processing unit instruction sets merging hardware registers design methodology	"""Developers of GPU kernels, such as FFT, linear solvers, etc, tune their code extensively in order to obtain optimal performance, making efficient use of different resources available on the GPU. Complex applications are composed of several such kernel components. The software engineering community has performed extensive research on component based design to build generic and flexible components, such that a component can be reused across diverse applications, rather than optimizing its performance. Since a GPU is used primarily to improve performance, application performance becomes a key design issue. The contribution of our work lies in extending component based design research in a new direction, dealing with the performance impact of refactoring an application consisting of the composition of highly tuned kernels. Such refactoring can make the composition more effective with respect to GPU resource usage especially when combined with suitable scheduling. Here we propose a methodology where developers of highly tuned kernels can enable application designers to optimize performance of the composition. Kernel developers characterize the performance of a kernel through its """"performance signature"""". The application designer combines these kernels such that the performance of the refactored kernel is better than the sum of the performances of the individual kernels. This is partly based on the observation that different kernels may make unbalanced use of different GPU resources like different types of memory. Kernels may also have the potential to share data. Refactoring the kernels, combining them, and scheduling them suitably can improve performance. We study different types of potential design optimizations and evaluate their effectiveness on different types of kernels. This may even involve choosing non-optimal parameters for an individual kernel. We analyze how the performance signature of the composition changes from that of the individual kernels through our techniques. We demonstrate that our techniques lead to over 50% improvement with some kernels. Furthermore, the performance of a basic molecular dynamics application can be improved by around 25.7%, on a Fermi GPU, compared with an un-refactored implementation."""	antivirus software;cas latency;code refactoring;context (computing);data dependency;design tool;fast fourier transform;fermi (microarchitecture);graphics processing unit;kernel (operating system);mathematical optimization;molecular dynamics;performance tuning;scheduling (computing);shared memory;software engineering;unbalanced circuit	Santonu Sarkar;Sayantan Mitra;Ashok Srinivasan	2012	2012 IEEE 10th International Symposium on Parallel and Distributed Processing with Applications	10.1109/ISPA.2012.26	fast fourier transform;molecular dynamics;parallel computing;real-time computing;computer science;theoretical computer science;operating system;programming language;object-oriented programming;software maintenance;scheduling;code refactoring	HPC	-6.452867666391703	45.53477492102991	66983
5ed3e62ff6060c72e2b12ef6bd41cb188c2b0edc	a general, fine-grained, machine independent, object-oriented language	object oriented language;adaptive programming;code reuse;object oriented programming languages;timing analysis;parallel programs;parallel languages	This paper introduces the general-purpose object-oriented programming language Ellie which supports machine independent fine-grained objects and parallelism. As something particular, classes, types, blocks, and methods are abstracted by first class objects/citizens called Ellie objects. Ellie demonstrates new approaches for abstraction and code reuse in parallel programming.The goals of Ellie have been to obtain an extremely flexible, machine independent, parallel language. Ellie tries to meet these goals by extensive usage of selected language concepts combined with compile-time analysis to adapt programs for efficient execution on the available hardware. Ellie runs on a parallel mesh transputer network.	code reuse;compile time;compiler;first-class function;general-purpose modeling;parallel computing;parallel language;programming language;transputer	Birger Andersen	1994	SIGPLAN Notices	10.1145/181734.181739	parallel computing;computer science;theoretical computer science;programming language;object-oriented programming	PL	-14.36123384903506	38.473191531966904	67132
903de4f045328201fc978ba888dc7b24db0bc4d3	self-adaptive parallel programming through tunable concurrency	parallel programming;concurrency;actors	Recent advances in hardware architectures, particularly multicore and manycore systems, implicitly require programmers to write concurrent programs. However, writing correct and efficient concurrent programs is challenging. We envision a system where the concurrent programs can be self-adaptive when executing on different hardware. We have developed two different tuning policies, which enable users' programs to adjust their level of concurrency at compile-time and run-time respectively.	compile time;compiler;concurrency (computer science);manycore processor;multi-core processor;parallel computing;programmer	Tai Nguyen;Xinghui Zhao	2014		10.1145/2660252.2660394	computer architecture;parallel computing;real-time computing;isolation;concurrent computing;concurrency;computer science;concurrency control;multiversion concurrency control;non-lock concurrency control;programming language;concurrent object-oriented programming	HPC	-14.692995109788656	39.89019460467138	67145
ec9e1811ba1df006b0d4c7b2755675eaa457d944	a semantic framework to address data locality in data parallel languages	parallel programs design;data parallel;data locality;program design;equational languages semantics;data parallel programming;parallel programs	We developed a theory in order to address crucial questions of program design methodology. This theory deals with data locality which is a main issue in parallel programming. In this article, we regard this theory and its model as a minimum semantic domain for data parallel languages. The introduction of a semantic domain is justified because the classical data parallel languages (HPF and C) have different intuitive semantics: Indeed, they use different concepts in order to express data locality. These concepts are alignment in HPF and shape in C. Consequently these two languages define their own balance between compiler and programmer investments in order to reach program efficiency. We present our theory as a foundation for defining a better balance. 2003 Elsevier B.V. All rights reserved.	compiler;data parallelism;high performance fortran;locality of reference;parallel computing;parallel programming model;programmer	Eric Violard	2004	Parallel Computing	10.1016/S0167-8191(03)00089-9	parallel computing;computer science;theoretical computer science;operating system;program design language;programming language;algorithm	PL	-14.192327328843735	39.13446396438008	67148
ab17f0a8e092b20f5afeaad19089913a8cb9fd72	editorial: high performance computing and networking: simulation practice	network simulator	High Performance Computing and Networking (HPCN) has now reached a state that it can be applied relatively easy. Many institutes have access to a large scale Massively Parallel Processor. Even more institutes use a cluster of interconnected workstations for their large scale simulation problems. As a result there is a great expansion of application areas where HPCN is applied. This special issue of Simulation Practice and Theory is completely devoted to HPCN applications. Here, both contributions devoted to the parallelization of the underlying numerical algorithms for High Performance Computing as contributions on High Performance Networking have been included. The first contribution of Professor Eugene Shapiro gives a detailed overview of this special issue. The papers of this issue have all been presented at the successful EUROSIM Conference on HPCN Challenges in Telecomp and Telecom: Parallel Simulation of Complex Systems and Large-Scale Applications. This conference was held from June 10 until June 12, 1996 at Delft University of Technology.’ A number of authors of papers that had been presented at the conference were invited to submit an extended version of the conference paper to this special issue of Simulation Practice and Theory. The selected papers for this issue were all subject to the standard review process of the journal to retain the high quality of the journal papers.	algorithm;complex systems;display resolution;goodyear mpp;numerical analysis;parallel computing;simulation;supercomputer;workstation	Arnold W. Heemink;Jan C. Zuidervaart	1998	Simul. Pr. Theory	10.1016/S0928-4869(97)00042-6	computational science;active networking;computer architecture simulator;simulation;computer science;network simulation;software-defined networking;computer engineering	HPC	-8.089057348526813	38.79933421123455	67247
010e81d9c71da3b0dd203ddc7bbe50e7b4b7aa62	simulation of scientific programs on parallel architectures with mimesis environment	distributed memory;scientific application;distributed memory systems;electronic mail;concurrent computing;fortran analyzer;modeling and simulation;prototypes;mimesis environment;distributed computing;spmd programming model;edf codes scientific program simulation parallel architectures mimesis environment scientific application spmd programming model message passing fortran analyzer simulation tool mimesis project edf distributed memory computer models;parallel programming;mimesis project;automatic generation;parallel programming virtual machines parallel architectures message passing distributed memory systems;edf codes;programming model;computer architecture;computational modeling;parallel architectures;virtual machines;parallel architectures computational modeling computer simulation hardware distributed computing concurrent computing prototypes computer architecture density estimation robust algorithm electronic mail;density estimation robust algorithm;message passing;scientific program simulation;distributed memory computer models;edf;fortran;parallel architecture;simulation tool;computer simulation;hardware	T h i s paper presents h o w a scientific application writt e n us ing a n SPMD programming model wi th messagepassing can be modeled and simulated. T h i s descript i o n is based o n the counting of basic operations and the recognition of k n o w n kernels. A Fortran analyzer was built t o generate automatically a model o f such a n application for t h e s imula t ion tool of the M I M E SIS project, developed a t EDF (Electricate' de France). Models of distributed-memory computers , taking advantage of this description, were implemented w i t h the prototype of t h e project. T h e approach was validated wi th t w o EDF codes, for which the s imula t ions gave good results.	code;computer;distributed memory;earliest deadline first scheduling;fortran;programming model;prototype;spmd;simulation	Gilles Kempf;Christian Caremoli;G. Damm;Wei-Ying Thang;Aad J. van der Steen	1996		10.1109/SIMSYM.1996.492150	computer simulation;computer architecture;parallel computing;message passing;distributed memory;concurrent computing;computer science;virtual machine;operating system;modeling and simulation;distributed computing;prototype;programming paradigm;programming language;computational model	Robotics	-10.539369229258764	40.077582532390124	67279
f24c72b82b9b9e5f9b0642721206424e62ad40d6	transparent gpu execution of numpy applications	jit;code generation;gpu;computational science;computational science python numpy gpu code generation jit;n body applications transparent gpu execution python library numpy applications dynamic code generation kernel generation bohrium runtime system array operation data parallelization gpu computation back end low level gpu executable kernels black scholes applications successive overrelaxation applications shallow water applications;python numpy;graphics processing units kernel vectors arrays engines bridges libraries;software libraries graphics processing units program compilers	In this work, we present a back-end for the Python library NumPy that utilizes the GPU seamlessly. We use dynamic code generation to generate kernels, and data is moved transparently to and from the GPU. For the integration into NumPy, we use the Bohrium runtime system. Bohrium hooks into NumPy through the implicit data parallelization of array operations, this approach requires no annotations or other code modifications. The key motivation for our GPU computation back-end is to transform high-level Python/NumPy applications to the lowlevel GPU executable kernels, with the goal of obtaining highperformance, high-productivity and high-portability, HP3. We provide a performance study of the GPU back-end that includes four well-known benchmark applications, Black-Scholes, Successive Over-relaxation, Shallow Water, and N-body, implemented in pure Python/NumPy. We demonstrate an impressive 834 times speed up for the Black-Scholes application, and an average speedup of 124 times across the four benchmarks.	abstraction layer;benchmark (computing);black–scholes model;code generation (compiler);computation;computer simulation;executable;expect;graphics processing unit;high- and low-level;just-in-time compilation;linear programming relaxation;numpy;parallel computing;programming language;python;runtime system;self-modifying code;software portability;speedup;successive over-relaxation;supercomputer	Troels Blum;Mads Ruben Burgdorff Kristensen;Brian Vinter	2014	2014 IEEE International Parallel & Distributed Processing Symposium Workshops	10.1109/IPDPSW.2014.114	computational science;parallel computing;computer science;operating system;just-in-time compilation;programming language;code generation	Arch	-6.561997387342092	43.05950809643191	67314
d531f989251e82074f49df5c9ea60019aacb9517	unsafe operations in b-trees	evaluation performance;base donnee;mise a jour;performance evaluation;modele mathematique;evaluacion prestacion;database;base dato;modelo matematico;multi user;algorithme;algorithm;dynamic data structure;estructura datos;concurrency control;mathematical model;structure donnee;puesta al dia;controle concurrence;control concurrencia;information system;data structure;systeme information;updating;analytical model;algoritmo;sistema informacion	A simple mathematical model for analyzing the dynamics of a B-tree node is presented. From the solution of the model, it is shown that the simple technique of allowing a B-tree node to be slightly less than half full can significantly reduce the rate of split, merge and borrow operations. We call split, merge, borrow and balance operations unsafe operations in this paper. In a multi-user environment, a lower unsafe operation rate implies less blocking and higher throughput, even when tailored concurrency control algorithms (e.g., that proposed by Lehman and Yao [10]) are used. A lower unsafe operation rate also means a longer life time of an optimally initialized B-tree (e.g., compact B-tree). It is in general useful to have an analytical model which can predict the rate of unsafe operations in a dynamic data structure, not only for comparing the behavior of variations of B-trees, but also for characterizing workload for performance evaluation of different concurrency control algorithms for such data structures. The model presented in this paper represents a starting point in this direction.	algorithm;b-tree;blocking (computing);concurrency (computer science);concurrency control;data structure;dynamic data;mathematical model;multi-user;performance evaluation;throughput;user interface;yao graph	Bin Zhang;Meichun Hsu	1989	Acta Informatica	10.1007/BF00289145	simulation;data structure;computer science;artificial intelligence;concurrency control;mathematical model;programming language;information system;algorithm	Metrics	-17.55187461008453	45.38727111121047	67369
138e4f0ff207aad23d0ef2519cf80c5f5b072e4f	an optimal distributed load balancing algorithm for homogeneous work units	high performance computing;adaptive mesh refinement;complexity analysis;scaling;distributed load balancing	Many parallel applications, for example, Adaptive Mesh Refinement simulations, need dynamic load balancing during the course of their execution because of dynamic variation in the computational load. We propose a novel tree-based fully distributed algorithm for load balancing homogeneous work units. The proposed algorithm achieves perfect load balance while doing minimum number of migrations of work units.	adaptive mesh refinement;distributed algorithm;load balancing (computing);refinement (computing);simulation	Akhil Langer	2014		10.1145/2597652.2600108	supercomputer;parallel computing;real-time computing;adaptive mesh refinement;scaling;computer science;load balancing;distributed computing;algebra	HPC	-6.0194555493443245	40.81354108691279	67372
23c334643aad81efbad051463d0413b5c6bc2a47	nested parallelism for multi-core systems using java			java;multi-core processor;parallel computing	Aamir Shafi	2006				EDA	-9.310918173593679	42.90616738105311	67433
2c7bc007a0dcea57776963f39f887609c8ba6de5	a language for distributed applications	libraries;intermediate queues;durra language;high level languages;application software;software development durra language distributed applications large grained tasks heterogeneous network application level program heterogeneous machine network intermediate queues dynamic reconfigurations;distributed processing;resource management;software engineering;distributed applications;computer networks;dynamic reconfigurations;large grained tasks;heterogeneous machine network;application software resource management libraries programming software quality software engineering computer science computer network management computer networks us government;computer network management;software development;application level program;computer science;programming;software engineering distributed processing high level languages;software quality;us government;heterogeneous network	Durra is a language designed to support the development of distributed applications consisting of multiple, concurrent, large-grained tasks executing in a heterogeneous network. An application-level program is written in Durra as a set of task descriptions that prescribes a way to manage the resources of a heterogeneous machine network. The application describes the tasks to be instantiated and executed as concurrent processes, the intermediate queues required to store the messages as they move from producer to consumer processes, and the possible dynamic reconfigurations of the application. The application-level programming paradigm fits very naturally a top-down, incremental method of software development. Although we don’t claim to have solved all problems or identified all the necessary tools, we would like to suggest that a language like Durra would be of great value in the development of large, distributed systems . 1. Programming Heterogeneous Machines A computing environment consisting of looselyconnected networks of multiple specialand generalpurpose processors constitutes a heterogeneous machine. Users of heterogeneous machines are concerned with allocating specialized resources to tasks of medium to large size. They need to create processes, which are instances of tasks, allocate these processes to processors, and specify the communication patterns between processes. These activities constitute application-level programming, to distinguish them from the activities leading to the development of the individual component tasks. This work is sponsored by the U.S. Department of Defense. The views and conclusions contained in this document are solely those of the author@) and should not be interpreted as representing official policies, either expressed or implied, of Carnegie Mellon University, the US. Air Force, the Department of Defense, or the US. Government. CH2854-8/90/oooo/oo59$01.00	central processing unit;distributed computing;fits;heterogeneous computing;process (computing);programming paradigm;software development;top-down and bottom-up design	Mario Barbacci;Jeannette M. Wing	1990		10.1109/ICCL.1990.63761	programming;application software;real-time computing;heterogeneous network;computer science;resource management;software development;distributed computing;programming language;high-level programming language;software quality	HPC	-13.732595891623575	41.12916272613044	67560
95625091eddee071a64bb30963ab0698d5796bca	an adaptive system for forest fire behavior prediction	parallel computing;prediction method;forest fire behavior prediction;real time systems adaptive systems data assimilation disasters environmental science computing fires forestry hazards parallel processing;forestry;high performance computing;real time;environmental conditions;hazards;dynamic data driven application system parallel computing forest fire prediction parallel simulation high performance computing evolutionary computing;real time data;environmental science computing;dynamic data driven application system;forest fire prediction;adaptive systems;forest fire;high performance computer;adaptive system;parallel computer;environmental condition;parallel computing adaptive system forest fire behavior prediction dynamic data driven application system wildfire propagation prediction environmental condition hazard parallel wildfire prediction real time data assimilation;parallel wildfire prediction;data assimilation;wildfire propagation prediction;dynamic adaptation;fires;wildfire;real time data assimilation;hazard;parallel processing;parallel simulation;disasters;evolutionary computing;real time systems	In this paper, we propose a combination of two dynamic data driven application system (DDDAS) methodologies to predict wildfirespsila propagation. Our goal is to build a system that dynamically adapts to constant changes in environmental conditions when a hazard occurs and under strict real-time deadlines. For this purpose, we are on the way of building a parallel wildfire prediction method, which is able to assimilate real-time data to be injected in the prediction process at execution time.	adaptive system;aggregate data;dynamic data driven applications systems;experiment;hazard (computer architecture);real-time clock;real-time data;run time (program lifecycle phase);simulation;software propagation;unit propagation	Roque Rodríguez;Ana Carolina Castro Côrtes;Tomàs Margalef;Emilio Luque	2008	2008 11th IEEE International Conference on Computational Science and Engineering	10.1109/CSE.2008.15	simulation;hazard;computer science;adaptive system	Robotics	-6.061778534155304	33.53406630613073	67564
0c3988763a1c9ca32df2edd73164d01086de568e	performance analysis of openshmem applications with tau commander		The TAU Performance System® (TAU) is a powerful and highly versatile profiling and tracing tool ecosystem for performance engineering of parallel programs. Developed over the last twenty years, TAU has evolved with each new generation of HPC systems and scales efficiently to hundreds of thousands of cores. TAU’s organic growth has resulted in a loosely coupled software toolbox such that novice users first encountering TAU’s complexity and vast array of features are often intimidated and easily frustrated. To lower the barrier to entry for novice TAU users, ParaTools and the US Department of Energy have developed “TAU Commander,” a performance engineering workflow manager that facilitates a systematic approach to performance engineering, guides users through common profiling and tracing workflows, and offers constructive feedback in case of error. This work compares TAU and TAU Commander workflows for common performance engineering tasks in OpenSHMEM applications and demonstrates workflows targeting two different SHMEM implementations, Intel Xeon “Haswell” and “Knights Landing” processors, direct and indirect measurement methods, callsite, profiles, and traces.	midnight commander;profiling (computer programming)	John C. Linford;Samuel Khuvis;Sameer Shende;Allen D. Malony;Neena Imam;Manjunath Gorentla Venkata	2017		10.1007/978-3-319-73814-7_11	implementation;xeon;computer architecture;profiling (computer programming);shmem;workflow;software;tracing;performance engineering;computer science	Crypto	-7.705826682512644	45.80848418073042	67639
ce8467ba0ae59f54ac660f4ee18bdc589d8fe197	averages, distributions and scalability of mpi communication times for ethernet and myrinet networks	long tail;network performance;community networks;parallel computer;mpi benchmarks	Most modern parallel computers are clusters using Myrinet or Ethernet communication networks. Several studies have been published comparing the performance of these two networks for parallel computing, however these focus on average performance, and do not address the distributions of communication times, which can have long tails due to contention effects. In the case of Ethernet with TCP, retransmit timeouts (RTOs) can also occur. Slow communication events may have significant impact, particularly for applications requiring frequent synchronization, where the performance is determined by the slowest process. We have analysed the distributions of communication times for standard MPI routines on Ethernet with TCP and Myrinet with GM communications networks on the same cluster, and studied the scalability of the distributions as the number of communicating processes is increased, and the effect of RTOs for Ethernet with TCP.	best, worst and average case;central processing unit;computer cluster;linux;mpich;message passing interface;parallel computing;recovery time objective;scalability;synchronization (computer science);tails;telecommunications network;timeout (computing)	Nor Asilah Wati Abdul Hamid;Paul D. Coddington	2007			parallel computing;real-time computing;computer science;network interface controller;computer network	HPC	-10.335839917232402	46.04641002109217	67652
aed6902b57f54c53eced62b33d7a4cad352479be	reducing manipulation overhead of remote data-structure by controlling remote memory access order		The Advanced Communication Primitives (ACP) is a communication library which provides the PGAS programming model to existing programming languages. The communication primitives of ACP include remote-to-remote data transfer and atomic operations. The reference implementation of communication primitives of ACP uses connectionless sockets over UDP and agent threads. The remote-to-remote data transfer is implemented as a protocol. The ACP data library (ACPdl) is a utility library using the communication primitives that include interfaces to create and manipulate several types of remote and distributed data structures. In the current implementation of ACP, there is a performance issue in the erase and insert functions of vector-type data structures due to the in-place data movement algorithm. This paper proposes a new technique called ‘remote ordering’ for the remote-to-remote data transfer protocol. The remote ordering technique overlaps the progresses of the protocol for the data movement simultaneously. The evaluation results show that the average execution times of the functions were reduced to about one seventh.	data structure;in-place algorithm;partitioned global address space	Yuichiro Ajima;Takafumi Nose;Kazushige Saga;Naoyuki Shida;Shinji Sumimoto	2016		10.1007/978-3-319-46079-6_7	distributed computing;computer security	EDA	-14.511308119537311	46.357371061500224	67736
995f6aa02131176e94cfc53667ba1ee2dd40071d	spar: a dsl for high-level and productive stream parallelism	software;hardware and architecture;stream parallelism;c 11 attributes;theoretical computer science;parallel design patterns;algorithmic skeletons;high level parallel programming;domain specific languages	This paper introduces SPar, an internal C++ Domain-Specific Language (DSL) that supports the development of classic stream parallel applications. The DSL uses standard C++ attributes to introduce annotations tagging the notable components of stream parallel applications: stream sources and stream processing stages. A set of tools process SPar code (C++ annotated code using the SPar attributes) to generate FastFlow C++ code that exploits the stream parallelism denoted by SPar annotations while targeting shared memory multi-core architectures. We outline the main SPar features along with the main implementation techniques and tools. Also, we show the results of experiments assessing the feasibility of the entire approach as well as SPar’s performance and expressiveness.	c++;digital subscriber line;distributed memory;domain-specific language;experiment;high- and low-level;java annotation;message passing interface;multi-core processor;parallel computing;scalability;shared memory;software portability;stream processing;toolchain;workstation	Dalvan Griebler;Marco Danelutto;Massimo Torquati;Luiz Gustavo Fernandes	2017	Parallel Processing Letters	10.1142/S0129626417400059	computer architecture;parallel computing;computer science;domain-specific language;data parallelism;programming language;instruction-level parallelism;implicit parallelism;task parallelism	HPC	-15.28230293673462	37.315358787388455	67854
80aefb2b730ce4545dad540d90b40effb03a5b66	array privatization for parallel execution of loops	algorithms;compiler algorithm;real program;array privatization;parallel programming;parallel execution;critical role;compilers;successful parallelization;super computers;recent experiment;program analysis;parallel processing	In recent experiments, array privatization played a critical role in successful parallelization of several real programs. This paper presents compiler algorithms for the program analysis for this transformation. The paper also addresses issues in the implementation.	algorithm;compiler;experiment;parallel computing;program analysis	Zhiyuan Li	1992		10.1145/143369.143426	program analysis;parallel processing;computer architecture;parallel computing;computer science;theoretical computer science;operating system;programming language	HPC	-14.169350500594865	39.12303335380455	68270
324a1a300472713fec45bc32687da699b58cabbd	parallel implementation of bags	efficient implementation;parallel implementation;functional programming language	Multisets (also called bags) are an interesting data structure for parallelly implemented functional programming languages, since they do not force an unneeded restriction of the data flow and allow to exploit as. much parallelism as possible. Most operations on multisets can be understood as special cases of the so-called Gamma scheme [BL90]. In the present paper, we investigate efficient implementations of several instances of this Gamma scheme on MIMDmachines,	data structure;dataflow;functional programming;gamma correction;parallel computing;programming language	Herbert Kuchen;Katia Gladitz	1993		10.1145/165180.165226	computer architecture;parallel computing;computer science;programming language implementation;programming language;functional programming;parallel programming model	PL	-14.521661544397796	37.92331203045462	68318
4677632ce0dfb6e5102383966dbb4ff1c9bb57ba	multiple context multithreaded superscalar processor architecture	parallelisme;instruction level parallel;microprocessor;haute performance;roscado;simulation;multiple context multithreaded superscalar mcms;simulacion;feasibility;parallelism;paralelismo;data dependence;alto rendimiento;threading;superscalar processor;microprocesseur;computer hardware;multiple context;processeur superscalaire;instruction level parallelism;high performance;microprocesador;materiel informatique;trace driven simulation;material informatica;hardware implementation;practicabilidad;faisabilite;filetage;multithreading	Superscalar architecture is becoming the norm in today's high performance microprocessor design. However, achievable instruction level parallelism in programs limits the scalability of such architectures. In this paper, we introduce the Multiple Context Multithreaded Superscalar Processor (MCMS), which is an extension of conventional superscalar processor architecture to support multithreading. This is motivated by the enormous potential instruction level parallelism present in multithreaded programs. A hardware implementation of multithreaded constructs is also proposed. Results from trace-driven simulation show that with the MCMS, instruction level parallelism is indeed increased signi®cantly. A MCMS processor with four hardware contexts can produce a speedup of up to 2.5 times over superscalar processor with similar hardware resources. We found that the primary limitation shifts from data dependencies in the superscalar processor to resource contentions in MCMS. Ó 2000 Elsevier Science B.V. All rights	context switch;data dependency;dependence analysis;emoticon;execution unit;instruction-level parallelism;locality of reference;microarchitecture;microprocessor;multithreading (computer architecture);naruto shippuden: clash of ninja revolution 3;parallel computing;processor design;requirement;resource contention;scalability;simulation;speedup;superscalar processor;thrashing (computer science);thread (computing);throughput	K. S. Loh;W. F. Wong	2000	Journal of Systems Architecture	10.1016/S1383-7621(99)00004-1	embedded system;pipeline burst cache;feasibility study;computer architecture;parallel computing;real-time computing;multithreading;threading;computer science;operating system;instruction-level parallelism	Arch	-15.545028708046239	43.98792461623768	68335
372c476ddbcc843867f8a124da738ed3227b06dc	atomic snapshots in o(n log n) operations (preliminary version)	distributed system;shared memory;efficient implementation;data structure	The atomic snapshot object is an important primitive used for the design and verification of wait-free algorithms in shared-memory distributed systems. A snapshot object is a shared data structure partitioned into segments. Processors can either update an individual segment or instantaneously scan all segments of the object. This paper presents an implementation of an atomic snapshot object in which each high-level operation (scan or update) requires O(n logn) low-level operations on atomic read/write registers.	concurrent data structure;distributed computing;high- and low-level;non-blocking algorithm;shared memory;snapshot (computer storage)	Hagit Attiya;Ophir Rachman	1993		10.1145/164051.164055	shared memory;parallel computing;real-time computing;data structure;computer science;distributed computing;programming language	Theory	-15.147387261232028	46.20175434347542	68363
839c8f3c1df359a0c32a5db9b4f205c233a4c1b7	communication-free alignment for array references with linear subscripts in three loop index variables or quadratic subscripts	parallel computing;nested loops;parallelizing compilers;data dependence analysis;data dependence;indexation;load balancing;parallel computer;load balance;communication free alignment;loop optimization	Bau et al. proposed an efficient and precise data alignment method to ascertain whether there is communication-free alignment of array reference function with linear subscripts in one loop index variable. Chu et al. presented an efficient and precise data alignment method to determine whether there is communication-free alignment of array reference function with linear subscripts in two loop index variables or quadratic subscripts (ai2+bi+d). However, for array reference function with linear subscripts in three loop index variables or quadratic subscripts (ai2+bi+cj+d), their methods cannot be applied. In this paper, we propose two new alignment functions for loop iteration space and array elements. The new alignment functions can be applied towards checking whether there is communication-free alignment of array reference function with linear subscripts in three loop index variables or quadratic subscripts. Experiments with benchmarks taken from Parallel loop and Vector loop showed that among the 7 nested loops tested, three of them had their data alignment improved by the method proposed.	application domain;array data structure;computation;control flow;data parallelism;data structure alignment;for loop;iteration;kernel (linear algebra);linear algebra;locality of reference	Weng-Long Chang;Chih-Ping Chu;Jia-Hwa Wu	2001	The Journal of Supercomputing	10.1023/A:1011144404437	parallel computing;real-time computing;computer science;load balancing;theoretical computer science;distributed computing;computer security	HPC	-13.312684237259598	35.57055939392555	68456
4dfefcf19afee311d6114efa5bccbce63d477274	accelerating gpgpu architecture simulation	performance;micro architecture simulation;general purpose graphics processing unit gpgpu	Recently, graphics processing units (GPUs) have opened up new opportunities for speeding up general-purpose parallel applications due to their massive computational power and up to hundreds of thousands of threads enabled by programming models such as CUDA. However, due to the serial nature of existing micro-architecture simulators, these massively parallel architectures and workloads need to be simulated sequentially. As a result, simulating GPGPU architectures with typical benchmarks and input data sets is extremely time-consuming. This paper addresses the GPGPU architecture simulation challenge by generating miniature, yet representative GPGPU kernels. We first summarize the static characteristics of an existing GPGPU kernel in a profile, and analyze its dynamic behavior using the novel concept of the divergence flow statistics graph (DFSG). We subsequently use a GPGPU kernel synthesizing framework to generate a miniature proxy of the original kernel, which can reduce simulation time significantly. The key idea is to reduce the number of simulated instructions by decreasing per-thread iteration counts of loops. Our experimental results show that our approach can accelerate GPGPU architecture simulation by a factor of 88X on average and up to 589X with an average IPC relative error of 5.6%.	approximation error;benchmark (computing);cuda;computation;computer graphics;general-purpose computing on graphics processing units;general-purpose markup language;graphics processing unit;iteration;kernel (operating system);microarchitecture;proxy server;simulation	Zhibin Yu;Lieven Eeckhout;Nilanjan Goswami;Tao Li;Lizy Kurian John;Hai Jin;Cheng-Zhong Xu	2013		10.1145/2465529.2465540	parallel computing;real-time computing;performance;computer science;theoretical computer science;operating system	Arch	-4.780948733756251	45.214553670610314	68510
5c8a192eb9cdbe8d831d68ac20161b353fd55858	and-parallel execution of logic programs on a shared memory multiprocessor: a summary of results			logic programming;multiprocessing;shared memory	Yow-Jian Lin;Vipin Kumar	1988				Arch	-10.841139303867143	41.55188590729432	68680
07f584e8750fd1299ed495506f0e0ebf4c7e8221	optimizing the performance of streaming numerical kernels on the ibm blue gene/p powerpc 450 processor	simd;blue gene p;high performance computing;code generation;thesis;performance optimization	Several emerging petascale architectures use energy-efficient processors with vectorized computational units and in-order thread processing. On these architectures the sustained performance of streaming numerical kernels, ubiquitous in the solution of partial differential equations, represents a challenge despite the regularity of memory access. Sophisticated optimization techniques are required to fully utilize the Central Processing Unit (CPU). We propose a new method for constructing streaming numerical kernels using a highlevel assembly synthesis and optimization framework. We describe an implementation of this method in Python targeting the IBM Blue Gene/P supercomputer’s PowerPC 450 core. This paper details the high-level design, construction, simulation, verification, and analysis of these kernels utilizing a subset of the CPU’s instruction set. We demonstrate the effectiveness of our approach by implementing several three-dimensional stencil kernels over a variety of cached memory scenarios and analyzing the mechanically scheduled variants, including a 27-point stencil achieving a 1.7x speedup over the best previously published results. keywords: High Performance Computing, Performance Optimization, Code Generation, SIMD, Blue Gene/P	blue gene;central processing unit;high- and low-level;level design;mathematical optimization;numerical analysis;optimizing compiler;petascale computing;powerpc 400;python;simd;simulation;speedup;supercomputer	Tareq M. Malas;Aron J. Ahmadia;Jed Brown;John A. Gunnels;David E. Keyes	2013	IJHPCA	10.1177/1094342012444795	computer architecture;supercomputer;parallel computing;simd;computer science;operating system;programming language;code generation	HPC	-4.708185343209905	40.199989213749525	68769
2fbe342bcd17afb916fd35128e80b8f28903a25b	highlights from nhc - a space-efficient haskell compiler	polymorphic typing;run time system;unification;type checking;code size;source code;boxing	Self-compiling implementations of Haskell, i.e., those written in Haskell, have been and, except one, are still space consuming monsters. Object code size for the compilers themselves are 3-8 MByte, and they need 12-20 MByte to recompile themselves. One reason for the huge demands for memory is that the main goal for these compilers is to produce fast code. However, the compiler described in this paper, called nhc for Nearly a Haskell Compiler, is the above mentioned exception. This compiler concentrates on keeping memory usage down, even at a cost in time. The code produced is not fast but nhc is usable, and the resulting programs can be run, on computers with small memory. This paper describes some of the implementation choices done, in the Haskell part of the source code, to reduce memory consumption in nhc. It is possible to use these also in other Haskell compilers with no, or very small, changes to their run-time systems. Time is neither the main focus of nhc nor of this paper, but there is nevertheless a small section about the speed of nhc. The most notable observation concerning speed is that nhc spends approximately half the time processing interface files, which is much more than needed in the type checker. Processing interface files is also the most space consuming part of nhc in most cases. It is only when compiling source files with large sets of mutually recursive functions that more memory is needed to type check than to process interface files.	compiler;computer;haskell;megabyte;mutual recursion;object code;type system	Niklas Röjemo	1995		10.1145/224164.224217	parallel computing;computer science;unification;programming language;algorithm;code generation;source code	PL	-18.746333785679344	33.858219428090585	68854
1b8cf905e92595ce0225b430155f2edc59b16e2e	topic 15: gpu and accelerator computing - (introduction).	null	Computational accelerators such as GPUs, FPGAs and many-core accelerators can dramatically improve the performance of computing systems and catalyze highly demanding applications. Many scientific and commercial applications are beginning to integrate computational accelerators in their code. However, programming accelerators for high performance remains a challenge, resulting from the restricted architectural features of accelerators compared to general purpose CPUs. Moreover, software must conjointly use conventional CPUs with accelerators to support legacy code and benefit from general purpose operating system services. The objective of this topic is to provide a forum for exchanging new ideas and findings in the domain of accelerator-based computing. © 2013 Springer-Verlag.		Naoya Maruyama;Leif Kobbelt;Pavan Balaji;Nikola Puzovic;Samuel Thibault;Kun Zhou	2013		10.1007/978-3-642-40047-6_79	computational science;parallel computing;theoretical computer science	EDA	-7.614435143389386	40.43690677569641	68882
ad272ffa1b921c0a3fb0b9ca51bb02727c1f66a2	preface: high-level parallel programming and applications.	parallel programs		parallel computing	Gaétan Hains;Quentin Miller	2001	Parallel Processing Letters		computer science;parallel programming model	HPC	-10.16018569656502	40.818449361296715	68919
d24cce80d327006ad7654fd99755e2de315e0718	accept() scalability in linux		"""This report explores the possible effects of a """"thundering herd"""" problem associated with the Linux implementation of the POSIX accept() system call. We discuss the nature of the problem and how it may affect the scalability of the Linux kernel. In addition, we identify candidate solutions and considerations to keep in mind. Finally, we present a solution and benchmark it, giving a description of the benchmark methodology and the results of the benchmark."""	benchmark (computing);linux;mind;posix;scalability;system call;thundering herd problem	Stephen Molloy;Chuck Lever	2000				OS	-7.442848804676292	44.80805385561054	69029
edabca81813082463177d80ecccd9d7d7edb02ee	implementation of a ranlux based pseudo-random number generator in fpga using vhdl and impulse c	fpga;hpc;prng;vhdl	Monte Carlo simulations are widely used e.g. in the field of physics and molecular modelling. The main role played in these is by the high performance random number generators, such as RANLUX or MERSSENE TWISTER. In this paper the authors introduce the world’s first implementation of the RANLUX algorithm on an FPGA platform for high performance computing purposes. A significant speed-up of one generator instance over 60 times, compared with a graphic card based solution, can be noticed. Comparisons with concurrent solutions were made and are also presented. The proposed solution has an extremely low power demand, consuming less than 2.5 Watts per RANLUX core, which makes it perfect for use in environment friendly and energy-efficient supercomputing solutions and embedded systems.	algorithm;embedded system;field-programmable gate array;mersenne twister;molecular modelling;monte carlo method;random number generation;simulation;supercomputer;vhdl;video card;watts humphrey	Agnieszka Dabrowska-Boruch;Grzegorz Gancarczyk;Kazimierz Wiatr	2013	Computing and Informatics		embedded system;supercomputer;parallel computing;computer hardware;vhdl;computer science;operating system;pseudorandom number generator;algorithm;field-programmable gate array	HPC	-5.666140040164573	35.474827569573584	69045
bae1f940475f4be4862425582aa84a24e57e0d46	processing mpi datatypes outside mpi	experimental evaluation;parallel applications;open source	The MPI datatype functionality provides a powerful tool for describing structured memory and file regions in parallel applications, enabling noncontiguous data to be operated on by MPI communication and I/O routines. However, no facilities are provided by the MPI standard to allow users to efficiently manipulate MPI datatypes in their own codes. We present MPITypes, an open source, portable library that enables the construction of efficient MPI datatype processing routines outside the MPI implementation. MPITypes enables programmers who are not MPI implementors to create efficient datatype processing routines. We show the use of MPITypes in three examples: copying data between user buffers and a “pack” buffer, encoding of data in a portable format, and transpacking. Our experimental evaluation shows that the implementation achieves rates comparable to existing MPI implementations.	code;input/output;library (computing);mpich;message passing interface;netcdf;open mpi;open-source license;open-source software;programmer;programming model;serialization;two-phase locking	Robert B. Ross;Robert Latham;William Gropp;Ewing L. Lusk;Rajeev Thakur	2009		10.1007/978-3-642-03770-2_11	computer architecture;parallel computing;computer science;message passing interface;distributed computing	HPC	-12.72536402559276	41.56460667091125	69150
fcb63ff05388d85bec50a95823128b968b4f5885	self scheduling and execution threads	storage allocation;time sharing programs multiprocessing programs parallel programming programming environments scheduling storage allocation;programming environments;multiprocessing programs;thread management;time sharing programs;resource allocation;execution threads;parallel programming;multi user;program parallelism;shared memory multiprocessors;scheduling;parallel programming environment;parallel iterations;parallel computer;self scheduling;loop iterations;multi user multiprocessors;yarn processor scheduling parallel processing resource management operating systems australia concurrent computing programming environments dynamic scheduling process control;parallel execution;parallel iterations operating systems execution threads parallel execution shared memory multiprocessors loop iterations multi user multiprocessors program parallelism parallel programming environment self scheduling thread management;operating systems;shared memory multiprocessor	Two major strategies exist for the exploitation of parallel execution on shared memory multiprocessors. Multiple threads of execution can be created within a shared program context and loop iterations can be scheduled between processors. While the two techniques are well established in isolation, the design of large, general purpose multi-user multiprocessors requires a seamless blend. This paper examines a set of system structures which combine the two parallel computing models to exploit inherent program parallelism. The objective is a general purpose parallel programming environment in which programs can create as many threads as desired, which are scheduled on the share of processor resource allocated to the program. From within any of these threads, the self scheduling of iterations interacts with the thread management so that free processor resource is dynamically allocated to parallel iterations.	central processing unit;integrated development environment;iteration;multi-user;parallel computing;scheduling (computing);seamless3d;shared memory;thread (computing)	Rhys S. Francis;Arnold Pears	1990		10.1109/SPDP.1990.143608	thread;parallel computing;real-time computing;gang scheduling;resource allocation;computer science;operating system;distributed computing;scheduling;process	Arch	-13.611621533756008	44.669617480401286	69194
83287550c054e83dcf4e2b08e59f248803c84184	speculative hardware/software co-designed floating-point multiply-add fusion	instruction fusion;combined multiply add;fma;hw sw co designed processors;binary translator	A Fused Multiply-Add (FMA) instruction is currently available in many general-purpose processors. It increases performance by reducing latency of dependent operations and increases precision by computing the result as an indivisible operation with no intermediate rounding. However, since the arithmetic behavior of a single-rounding FMA operation is different than independent FP multiply followed by FP add instructions, some algorithms require significant revalidation and rewriting efforts to work as expected when they are compiled to operate with FMA--a cost that developers may not be willing to pay. Because of that, abundant legacy applications are not able to utilize FMA instructions. In this paper we propose a novel HW/SW collaborative technique that is able to efficiently execute workloads with increased utilization of FMA, by adding the option to get the same numerical result as separate FP multiply and FP add pairs. In particular, we extended the host ISA of a HW/SW co-designed processor with a new Combined Multiply-Add (CMA) instruction that performs an FMA operation with an intermediate rounding. This new instruction is used by a transparent dynamic translation software layer that uses a speculative instruction-fusion optimization to transform FP multiply and FP add sequences into CMA instructions. The FMA unit has been slightly modified to support both single-rounding and double-rounding fused instructions without increasing their latency and to provide a conservative fall-back path in case of mispeculation. Evaluation on a cycle-accurate timing simulator showed that CMA improved SPECfp performance by 6.3% and reduced executed instructions by 4.7%.	algorithm;cma-es;central processing unit;compiler;fma instruction set;general-purpose markup language;indivisible;just-in-time compilation;linearizability;mathematical optimization;multiply–accumulate operation;numerical analysis;rewriting;rounding;specfp;shattered world;speculative execution;transform, clipping, and lighting	Marc Lupon;Enric Gibert;Grigorios Magklis;Sridhar Samudrala;Raúl Martínez;Kyriakos Stavrou;David R. Ditzel	2014		10.1145/2541940.2541978	computer architecture;parallel computing;real-time computing;computer hardware;computer science;operating system;programming language;first-mover advantage	Arch	-4.717049944270979	46.0989183183827	69343
cf79a7b363f3f82b6dd443d75fc1910dda2e0576	efficient data-driven evaluation: theory and implementation	parallelisme;compilacion;general and miscellaneous mathematics computing and information science;data;sistema informatico;performance;flot donnee;tratamiento lenguaje;ejecucion programa;computer system;flujo datos;mathematical logic;program execution;computer architecture;modelo;parallelism;paralelismo;architecture ordinateur;language processing;execution programme;data flow processing;analyse performance;traitement langage;performance analysis;compilation;programming 990200 mathematics computers;algorithms;systeme informatique;modele;arquitectura ordenador;logic programs;data flow;models;data compilation;parallel processing;information;analisis eficacia	The data-driven execution scheme achieves parallelism by simultaneously activating all operations whose data are available. However, in a dataflow machine with limited resources, the datadriven scheme can lose efficiency when a significant amount of time is spent on the execution of useless computations. Determining and terminating useless computations dynamically has always been considered a formidable task. In this paper, we present an E@ient Data-Driven Evaluation Scheme which improves the performance of conventional data-driven execution by terminating useless computations at run time. This is accomplished by the construction at compile time of an extended dataflow graph in which useless computations can be identified and by the addition of a Termination Unit to the conventional dataflow ring architecture as a mechanism to support dynamic termination of useless computations. When useless computations are terminated, program execution times should improve since more resources are available for the processing of computations which contribute to the final results. o 1990 Academic PREP, I I I C .	compile time;compiler;computation;data-flow analysis;dataflow;divergence (computer science);parallel computing;powerpc reference platform;run time (program lifecycle phase)	Harrick M. Vin;Francine Berman;James S. Mattson	1990	J. Parallel Distrib. Comput.	10.1016/0743-7315(90)90036-O	data flow diagram;parallel processing;mathematical logic;parallel computing;information;performance;telecommunications;computer science;theoretical computer science;operating system;distributed computing;programming language;algorithm;statistics;data	PL	-16.558555736061237	42.14229038939295	69417
1c0ae1316d9e34d4d5dcafc082ee6b01349d8da1	a parallel process definition and control system	control system;parallel processing	The purpose of this work is to supply a simple method for definition and efficient control of a network for asynchronous parallel processing.	control system;parallel computing	Dan Cohen	1968		10.1145/1476706.1476723	parallel computing;real-time computing;computer science;distributed computing	ML	-10.160458987639041	43.26320917763927	69927
4c4b43995daa0f07e71b2f83ed3270f75db535dc	simulating neural networks in a distributed computing environment using neurograph	neural networks;computing environment	 NeuroGraph is a simulator for design, construction and execution of neural networks in a distributed computing environment. The simulator either runs on single computers or as a distributed application on UNIX/X-based networks consisting of personal computers, workstations or multi-processors. The parallelization component oilers the possibility to divide neural nets into concurrently executable modules, according to restrictions due to the neural net topology and computer net capabilities, i.e. NeuroGraph selects the best configuration out of the available distributed hardware environment to fit performance requirements.	artificial neural network;distributed computing environment	Peter Wilke	1993		10.1007/3-540-56798-4_179	distributed algorithm;cellular neural network;distributed computing;distributed design patterns;autonomic computing	HPC	-11.546386227840948	42.52721703375126	70015
2ea41dc1ced087aea64bcae2339bcacb4ff1d32e	scalable atomistic simulation algorithms for materials research	parallel computing;analytical models;parallel algorithm;performance test;data compression;interactive visualization;molecular dynamics;testing;space time;visibility culling;adaptive load balancing;density functional theory;computational modeling;atomistic simulation;quantum mechanics;density function theory;load management;load balancing;parallel computer;molecular dynamic;load balance;error bound;product quality;algorithm design;data compression parallel computing molecular dynamics variable charge molecular dynamics quantum mechanics density functional theory load balancing;variable charge molecular dynamics;algorithm design and analysis;computer errors;computational modeling algorithm design and analysis parallel algorithms analytical models quantum mechanics density functional theory testing load management data compression computer errors;md simulation;parallel algorithms	A suite of scalable atomistic simulation programs has been developed for materials research based on space-time multiresolution algorithms. Design and analysis of parallel algorithms are presented for molecular dynamics (MD) simulations and quantum-mechanical (QM) calculations based on the density functional theory. Performance tests have been carried out on 1,088-processor Cray T3E and 1,280-processor IBM SP3 computers. The linear-scaling algorithms have enabled 6.44-billion-atom MD and 111,000-atom QM calculations on 1,024 SP3 processors with parallel efficiency well over 90%. The production-quality programs also feature wavelet-based computational-space decomposition for adaptive load balancing, spacefilling-curve-based adaptive data compression with user-defined error bound for scalable I/O, and octree-based fast visibility culling for immersive and interactive visualization of massive simulation data.	analysis of parallel algorithms;atom;central processing unit;computer;cray t3e;data compression;density functional theory;functional theories of grammar;input/output;interactive visualization;load balancing (computing);molecular dynamics;molecular modelling;octree;parallel algorithm;quantum mechanics;scalability;simulation;space-filling curve;speedup;wavelet	Aiichiro Nakano;Rajiv K. Kalia;Priya Vashishta;Timothy Campbell;Shuji Ogata;Fuyuki Shimojo;Subhash Saini	2001	ACM/IEEE SC 2001 Conference (SC'01)	10.1145/582034.582035	computational science;algorithm design;molecular dynamics;parallel computing;computer science;load balancing;theoretical computer science;parallel algorithm;density functional theory	HPC	-6.652151228856912	37.31549064574639	70075
6b3fd50e83471a97143e07f4fff7b769900544cf	ada tasking: from semantics to efficient implementation	control systems;kernel;efficient algorithm;resource management;runtime environment;efficient implementation;data structures;programming profession;process control;operating systems data structures runtime environment programming profession timing kernel resource management process control control systems;operating systems;timing	Tasking is one of the strengths of Ada, and, contrary to some opinion, can be implemented for a single shared processor by simple, straightforward, and efficient algorithms.	ada;algorithm	Theodore P. Baker;Gregory A. Riccardi	1985	IEEE Software	10.1109/MS.1985.230349	computer architecture;kernel;real-time computing;computer science;engineering;resource management;process control;distributed computing;programming language	Embedded	-15.44190361167825	38.593926861816676	70221
28c71187d8cacd3ffed3975b5a0ac9c5d2963118	libwater: heterogeneous distributed computing made easy	paper;heterogeneous systems;heterogeneous computing;opencl mpi;distributed computing;ati;nvidia geforce gtx 480;programming model;cuda;nvidia;mpi;runtime system;computer science;nvidia geforce gtx 460;opencl;ati radeon hd 5870	Clusters of heterogeneous nodes composed of multi-core CPUs and GPUs are increasingly being used for High Performance Computing (HPC) due to the benefits in peak performance and energy efficiency. In order to fully harvest the computational capabilities of such architectures, application developers often employ a combination of different parallel programming paradigms (e.g. OpenCL, CUDA, MPI and OpenMP), also known in literature as hybrid programming, which makes application development very challenging. Furthermore, these languages offer limited support to orchestrate data and computations for heterogeneous systems.  In this paper, we present libWater, a uniform approach for programming distributed heterogeneous computing systems. It consists of a simple interface, compliant with the OpenCL programming model, and a runtime system which extends the capabilities of OpenCL beyond single platforms and single compute nodes. libWater enhances the OpenCL event system by enabling inter-context and inter-node device synchronization. Furthermore, libWater's runtime system uses dependency information enforced by event synchronization to dynamically build a DAG of enqueued commands which enables a class of advanced runtime optimizations. The detection and optimization of collective communication patterns is an example which, as shown by experimental results, improves the efficiency of the libWater runtime system for several application codes.	cuda;central processing unit;code;computation;directed acyclic graph;distributed computing;graphics processing unit;heterogeneous computing;mathematical optimization;message passing interface;multi-core processor;opencl api;openmp;orchestration (computing);parallel computing;programming model;programming paradigm;runtime system	Ivan Grasso;Simone Pellegrini;Biagio Cosenza;Thomas Fahringer	2013		10.1145/2464996.2465008	computer architecture;parallel computing;computer science;message passing interface;operating system;programming paradigm;symmetric multiprocessor system	HPC	-6.587778182561415	43.93554656916326	70403
54f5754d5cad3f1df01b695dce70ea137356b7ae	estimating the performance advantages of relaxing consistency in a shared memory multiprocessor			multiprocessing;shared memory	Josep Torrellas;John L. Hennessy	1990			pram consistency;distributed computing;parallel computing;consistency model;cache coherence;distributed memory;multiprocessing;distributed shared memory;computer science;shared memory	Arch	-10.81572556069748	43.580240809082994	70549
9ffd6e83bad27380becea4c9924bd3c7250be5bb	optimization of dynamic languages using hierarchical layering of virtual machines	juste a temps;dynamic programming;lenguaje programacion;dynamic languages;virtual machine;actionscript;compilacion;optimisation;language use;programacion dinamica;compilateur;optimizacion;programming language;performance;dynamic program;machine virtuelle;compiler;just in time compiler;interpreteur;trace compilation;programmation dynamique;hierarchical virtual machines;langage programmation;compilation;design;lua;just in time;optimization;justo en tiempo;interpreter;maquina virtual;interprete;performance optimization;languages;compilador	Creating an interpreter is a simple and fast way to implement a dynamic programming language. With this ease also come major drawbacks. Interpreters are significantly slower than compiled machine code because they have a high dispatch overhead and cannot perform optimizations. To overcome these limitations, interpreters are commonly combined with just-in-time compilers to improve the overall performance. However, this means that a just-in-time compiler has to be implemented for each language.  We explore the approach of taking an interpreter of a dynamic language and running it on top of an optimizing trace-based virtual machine, i.e., we run a guest VM on top of a host VM. The host VM uses trace recording to observe the guest VM executing the application program. Each recorded trace represents a sequence of guest VM bytecodes corresponding to a given execution path through the application program. The host VM optimizes and compiles these traces to machine code, thus eliminating the need for a custom just-in-time compiler for the guest VM. The guest VM only needs to provide basic information about its interpreter loop to the host VM.	compiler;dynamic dispatch;dynamic programming;interpreter (computing);just-in-time compilation;machine code;overhead (computing);programming language;tracing (software);virtual machine	Alexander Yermolovich;Christian Wimmer;Michael Franz	2009		10.1145/1640134.1640147	design;compiler;parallel computing;real-time computing;interpreter;actionscript;performance;computer science;virtual machine;dynamic programming;programming language	PL	-18.99517649669361	36.251164589959664	70587
54853f5d867261c62a44acbfbb96faf9c5d6e60f	compiler parallelization of an elliptic grid generator for 1990 gordon bell prize	network simulation;grid generation;awards;data parallel model;data mining;hardware and software cache coherence;scalable multiprocessors	The paper presents a case study involving the applz­ cation of an automatically parallelizing compiler to a numerically intensive Fortran program, and mchtdes a detai led analysIs of the result. The paper IS based all work performed as part of an entry that won the 1990 Gordon Bell Pnze for Compzler Parallelization. The compiler involved IS the CM Fortran 1.0 com­ piler, which targets the 2048 nodes/FPUs avazlable 111 a full size CM-2 parallel computer. The applicatIOn code implements grid generatIOn for numencal simu­ lation. The paper presents a parallel speedup of 4770 over a serial run on a Sun workstatIOn (which only has 1 FPUj, and includes a cycle counting analysIs of how such a speedup is possible with 2048 FPUs. A full 2048 node/FPU CM-2 is also compared to a 1 node/FPU CM-2, and the measured speedup of 1900 is discussed.	compiler;connection machine;data point;extrapolation;gordon bell prize;parallel computing;scalar processor;speedup;time complexity	Gary Sabot;Lisa Tennies;Alex Vasilevsky;Richard Shapiro	1991	Proceedings of the 1991 ACM/IEEE Conference on Supercomputing (Supercomputing '91)	10.1145/125826.126020	parallel computing;computer science;theoretical computer science;operating system;data mining;network simulation;distributed computing;programming language;computer network	HPC	-7.046712332611242	39.70284980496637	70673
577cdc238ac951cb49cf80ae02b3dc1f3c03bdae	autobench/auto-opt: towards an integrated construction environment for virtual prototyping in the automotive industry	algoritmo paralelo;concepcion asistida;computer aided design;new technology;industrie automobile;parallel algorithm;realite virtuelle;realidad virtual;automovil;integracion numerica;automotive industry;numerical method;reutilizacion;distributed computing;virtual reality;work environment;reuse;algorithme parallele;prototipo;simulation software;virtual prototyping;metodo numerico;automobile;numerical integration;industria automovil;motor car;numerical algorithm;interactive simulation;parallel computer;conception assistee;calculo repartido;car body;carroceria;integration numerique;prototype;calcul reparti;automobile industry;methode numerique;reutilisation;carrosserie	The present paper describes two cooperative projects (AUTO-BENCH and AUTO-OPT) carried out with partners in the automotive industries (AUDI, BMW, DaimlerChrysler, Karmann and Porsche), software vendors of simulation software (ESI, INTES, INPRO, SFE) and technology providers (Uni Stuttgart, FhG-SCAI and DLR-SISTEC). Both projects aim at the development of integrated working environments for virtual automotive prototypes. Special focus is on simulation of functional behaviour of the car body, production of its parts and their improvement. New technologies have been developed for the handling of numerical grids, integration of CAE tools, numerical algorithms and visualisation. Parallel computing is supported throughout the projects on a simulation level as well as for optimisation purposes. Ongoing work concentrates on the interactive simulation and optimisation as well as the reuse of the vast amount of resulting data.		Annette Kuhlmann;Clemens-August Thole;Ulrich Trottenberg	2003		10.1007/978-3-540-39924-7_95	simulation;computer science;automotive industry;virtual reality	DB	-8.0184651463906	35.630140109535986	70693
f967b9162682025af9da1b9acc168a90d8e3a003	performance analysis and optimisation of the met unified model on a cray xc30		The Unified Model (UM) code supports simulation of weather, climate and earth system processes. It is primarily developed by the UK Met Office, but in recent years a wider community of users and developers have grown around the code. Here we present results from the optimisation work carried out by the UK National Centre for Atmospheric Science (NCAS) for a high resolution configuration (N512 ≈ 25km) on the UK ARCHER supercomputer, a Cray XC-30. On ARCHER, we use Cray Performance Analysis Tools (CrayPAT) to analyse the performance of UM and then Cray Reveal to identify and parallelise serial loops using OpenMP directives. We compare performance of the optimised version at a range of scales, and with a range of optimisations, including altered MPI rank placement, and addition of OpenMP directives. It is seen that improvements in MPI configuration yield performance improvements of between 5 and 12%, and the added OpenMP directives yield an additional 5-16% speedup. We also identify further code optimisations which could yield yet greater improvement in performance. We note that speedup gained using addition of OpenMP directives does not result in improved performance on the IBM Power platform where much of the code has been developed. This suggests that performance gains on future heterogeneous architectures will be hard to port. Nonetheless, it is clear that the investment of months in analysis and optimisation has yielded performance gains that correspond to the saving of tens of millions of core-hours on current climate projects.	cray xc30;earth system science;emoticon;heterogeneous system architecture;ibm power microprocessors;image resolution;image scaling;ivy bridge (microarchitecture);mathematical optimization;message passing interface;openmp;profiling (computer programming);race condition;simulation;speedup;supercomputer;thread (computing);thread safety;unified model	Karthee Sivalingam;Grenville Lister;Bryan Lawrence	2015	CoRR		parallel computing;simulation;computer hardware;computer science	HPC	-6.840099491862786	40.17181421755447	70733
8c7fc1cbf2ff8bd6ae9e3d0c403eaf74baccedf6	computer organization and architecture - designing for performance (4. ed.)			microarchitecture	William Stallings	1996				Arch	-9.017247596371126	43.661466496349455	70844
70f06282e1fdb55b1118d89fcbe35d4eda3dfb71	multitasking algorithms for optimization of space structures	aerospace computing;multiprogramming;parallel algorithms;structural engineering computing;autotasking;macrotasking;microtasking;multitasking approaches;space structures;space truss structures	Various multitasking approaches are inveirtigatczi for optimization of large space structures. Judicious combination of microtczrking, macrotarking, and autotasking is explored with the goal of achieving a vectorized and multitaskxd algorithm for optimization of large structure with marimum speedup p~ormance. Speedup results are presented and compared for three space truss structures with 526, 1046, and 3126 members.	algorithm;computer multitasking;mathematical optimization;speedup	A. Saleh;Hojjat Adeli	1992			parallel computing;computer multitasking;computer science;theoretical computer science;operating system;distributed computing;parallel algorithm	PL	-4.787098228511195	41.57742520443264	70987
51bc72619496df84c2a946101cadd6932114be7b	representing and exploiting data parallelism using multidimensional dataflow diagrams	silage multidimensional dataflow diagrams graphical programming environment signal processing data parallelism syntax semantics synchronous dataflow model reduced dependence graphs systolic array design stream oriented functional languages lucid sisal;data parallel;stream oriented functional languages lucid;syntax;programming environments;multidimensional dataflow diagrams;application software;synchronous dataflow model;data parallelism;dependence graph;systolic array;semantics;reduced dependence graphs;runtime;functional programming;graphical programming;visual programming;graphical programming environment;signal processing;visual programming functional programming programming environments programming languages;multidimensional signal processing;sisal;multidimensional systems parallel processing signal processing algorithms multidimensional signal processing equations real time systems application software algorithm design and analysis runtime hardware;synchronous dataflow;systolic array design;signal processing algorithms;silage;functional language;algorithm design and analysis;parallel processing;multidimensional systems;programming languages;hardware;real time systems	The author shows how a graphical programming environment like those commonly used for signal processing can expose data parallelism. In particular, he sets objectives for the syntax and semantics of graphical programs. It is shown that the synchronous dataflow model can be extended to multidimensional streams to represent and exploit data parallelism in signal processing applications. The resulting semantics are related to reduced dependence graphs used in systolic array design and to the stream-oriented functional languages Lucid, Sisal, and Silage. Formal properties are developed. >		Edward A. Lee	1993		10.1109/ICASSP.1993.319153	parallel computing;computer science;theoretical computer science;data parallelism;visual programming language;programming language;functional programming;instruction-level parallelism;implicit parallelism;task parallelism	Embedded	-15.09672515370043	37.59467842794454	71091
24599f2a004801182f0461a384571e9c3c5914f7	language support for concurrent symbolic and numeric systems			comparison of numerical analysis software	Yannis Cotronis;Apostolos Nikolaos Refenes;Eugene Eberbach	1994	Software - Concepts and Tools		computer science;theoretical computer science;symbolic-numeric computation;symbolic communication	SE	-10.48778626127207	33.36477216986675	71274
5090ed315d3ab9f0135c83f287c5021d61929760	denali: a goal-directed superoptimizer	eficacia sistema;machine language;evaluation performance;lenguaje maquina;compilateur;performance evaluation;optimizing compiler;optimal code;generacion automatica;code optimal;generation code;evaluacion prestacion;sistema informatico;generacion codigo;performance systeme;code generation;computer system;optimizacion compiladora;compiler;system performance;automatic generation;theorem proving;demonstration theoreme;theorem prover;generation automatique;superoptimizer;compiler optimization;subroutine;sous programme;systeme informatique;demostracion teorema;codigo optimal;langage machine;optimisation compilateur;compilador;subprograma	This paper provides a preliminary report on a new research project that aims to construct a code generator that uses an automatic theorem prover to produce very high-quality (in fact, nearly mathematically optimal) machine code for modern architectures. The code generator is not intended for use in an ordinary compiler, but is intended to be used for inner loops and critical subroutines in those cases where peak performance is required, no available compiler generates adequately efficient code, and where current engineering practice is to use hand-coded machine language. The paper describes the design of the superoptimizer, and presents some encouraging preliminary results.	automated theorem proving;code generation (compiler);compiler;machine code;subroutine;superoptimization	Rajeev Joshi;Greg Nelson;Keith H. Randall	2002		10.1145/512529.512566	dead code;code bloat;object code;computer science;theoretical computer science;dead code elimination;redundant code;optimizing compiler;computer performance;automated theorem proving;programming language;algorithm;code generation;threaded code;unreachable code;source code	PL	-18.55720220694521	35.871347550019344	71378
9a9a78fc3a4736e1ef726b296d92cecec9608111	enhancing large-scale docking simulation on heterogeneous systems: an mpi vs rcuda study		Abstract Virtual Screening (VS) methods can considerably aid clinical research by predicting how ligands interact with pharmacological targets, thus accelerating the slow and critical process of finding new drugs. VS methods screen large databases of chemical compounds to find a candidate that interacts with a given target. The computational requirements of VS models, along with the size of the databases, containing up to millions of biological macromolecular structures, means computer clusters are a must. However, programming current clusters of computers is no easy task, as they have become heterogeneous and distributed systems where various programming models need to be used together to fully leverage their resources. This paper evaluates several strategies to provide peak performance to a GPU-based molecular docking application called M E T A D O C K in heterogeneous clusters of computers based on CPU and NVIDIA Graphics Processing Units (GPUs). Our developments start with an OpenMP, MPI and CUDA M E T A D O C K version as a baseline case of cluster utilization. Next, we explore the virtualized GPUs provided by the r C U D A framework in order to facilitate the programming process. rCUDA allows us to use remote GPUs, i.e. installed in other nodes of the cluster, as if they were installed in the local node, so enabling access to them using only OpenMP and CUDA. Finally, several load balancing strategies are analyzed in a search to enhance performance. Our results reveal that the use of middleware like rCUDA is a convincing alternative to leveraging heterogeneous clusters, as it offers even better performance than traditional approaches and also makes it easier to program these emerging clusters.	docking (molecular);simulation;rcuda	Baldomero Imbernon;Javier Prades;Domingo Giménez;José M. Cecilia;Federico Silla	2018	Future Generation Comp. Syst.	10.1016/j.future.2017.08.050	symmetric multiprocessor system;parallel computing;real-time computing;virtual screening;clinical research;distributed computing;cuda;programming paradigm;computer cluster;computer science;middleware;load balancing (computing)	Arch	-4.580101188641937	43.20178297707628	71407
3e030e385eb5cadb38eea3f08056851301b69756	performance improvement for applications on parallel computers	concurrent computing;application software;heterogeneous cluster;optimization technique;reduced instruction set computing;distributed computing;application software computer applications concurrent computing performance analysis timing reduced instruction set computing parallel processing distributed computing intelligent systems bioinformatics;generation time;fixed point iteration;computer applications;performance improvement;parallel systems;performance analysis;intelligent systems;data access;parallel computer;parallel applications;parallel processing;bioinformatics;timing	(Grant 69933020) and National high –tech program. Abstract The performance of applications on parallel computer systems is analyzed, and a general timing formula is proposed in the paper. The analyses are based on the “double-stream” (computation and data access) idea. According to these analyses, some techniques for improving the performance of applications on parallel systems are given. The cache thrashing phenomena on symmetric multiprocessors (SMP) are analyzed, and the “fix point” iteration method is used to deal with some cache thrashing phenomena. The timing balance problem of heterogeneous clusters is discussed, and the non-uniform partition strategy is studied. Some optimization techniques (horizontal-vertical decomposition, non-uniform partition, and overlapping of communication with computation) are used to improve the performance of a class of parallel applications on clusters of multiprocessors. Compared with previous results, our experiences show distinct performance improvements.	computation;computer performance;data access;generalized timing formula;iteration;mathematical optimization;parallel computing;symmetric multiprocessing;thrashing (computer science)	Xiangzhen Qiao	2001	Proceedings 15th International Parallel and Distributed Processing Symposium. IPDPS 2001	10.1109/IPDPS.2001.925124	data access;fixed-point iteration;parallel processing;reduced instruction set computing;application software;parallel computing;concurrent computing;computer science;theoretical computer science;operating system;distributed computing;computer applications;generation time	HPC	-7.969942859910291	41.04737789600961	71572
88fc4e30e729924082242ff83a12d1f6e42a9efe	understanding the mvs/xa i/o subsystem through dasd event traces			digital footprint;input/output	William R. Fairchild	1989			parallel computing;input/output;computer science;distributed computing	ML	-10.223922445649091	43.824999966605056	71610
403dccaaa0eab37f2214e6243b4b442be4a6d9fd	anydsl: a partial evaluation framework for programming high-performance libraries		This paper advocates programming high-performance code using partial evaluation. We present a clean-slate programming system with a simple, annotation-based, online partial evaluator that operates on a CPS-style intermediate representation. Our system exposes code generation for accelerators (vectorization/parallelization for CPUs and GPUs) via compiler-known higher-order functions that can be subjected to partial evaluation. This way, generic implementations can be instantiated with target-specific code at compile time.   In our experimental evaluation we present three extensive case studies from image processing, ray tracing, and genome sequence alignment. We demonstrate that using partial evaluation, we obtain high-performance implementations for CPUs and GPUs from one language and one code base in a generic way. The performance of our codes is mostly within 10%, often closer to the performance of multi man-year, industry-grade, manually-optimized expert codes that are considered to be among the top contenders in their fields.	admissible numbering;automatic vectorization;central processing unit;code generation (compiler);compile time;compiler;graphics processing unit;higher-order function;image processing;intermediate representation;interpreter (computing);library (computing);parallel computing;partial evaluation;ray tracing (graphics);sequence alignment	Roland Leißa;Klaas Boesche;Sebastian Hack;Arsène Pérard-Gayot;Richard Membarth;Philipp Slusallek;André Müller;Bertil Schmidt	2018	PACMPL	10.1145/3276489	image processing;theoretical computer science;implementation;code generation;computer science;vectorization (mathematics);general-purpose computing on graphics processing units;ray tracing (graphics);compile time;partial evaluation	PL	-14.429847047790895	36.53479172429785	71947
941812a9da118682bdb5ba765c26cf8ff82fafce	a new parallel python tool for the standardization of earth system model data	earth;computational modeling;production;atmospheric modeling;meteorology;standardization;data models	We have developed a new parallel Python tool for the standardization of Earth System Model (ESM) data for publication as part of Model Intercomparison Projects (MIPs). It was specifically designed to aid Community Earth System Model (CESM) scientists at the National Center for Atmospheric Research (NCAR) in preparation for the Coupled Model Intercomparison Project, Phase 6 (CMIP6), expected to start in early 2017. However, the tool is general to any and all MIPs and ESMs. The tool is implemented with MPI parallelism using mpi4py, and it performs the data standardization computation with a directed acyclic graph (DAG) data structure capable of streaming data from ESM input data to standardized output files. In this paper, we describe the tool, its design and testing.	community earth system model;computation;coupled model intercomparison project;data center;data structure;directed acyclic graph;earth system science;message passing interface;parallel computing;python;speedup;stream (computing)	Kevin Paul;Sheri A. Mickelson;John M. Dennis	2016	2016 IEEE International Conference on Big Data (Big Data)	10.1109/BigData.2016.7840946	simulation;computer science;theoretical computer science	Robotics	-7.204913169139162	35.09963413434788	71962
1f3ed85877a056cef2ce9c6c1f84e9f2c619ae0b	a computational model for message-passing	message passing algorithms message passing architectures machine model communicating random access machine programming paradigm cram;programming paradigm;computer model;message passing architectures;message passing algorithms;parallel programming;computational modeling read write memory computer architecture random access memory parallel architectures phase change random access memory memory architecture algorithm design and analysis message passing multiprocessor interconnection networks;random access machine;communicating random access machine;parallel architectures;parallel programming message passing parallel algorithms parallel architectures;message passing;machine model;cram;parallel algorithms	An important motivation for developing a computational model and a programming paradigm for message-passing stems from the architecture point of view. Parallel architectures may be broadly classied into two categories: shared memory, and messagepassing based on the inherent communication and synchronization model underlying the basic architecture. The justi cation for de ning two algorithmclasses corresponding to the two architecture classes is that certain problems may map more naturally into one class than the other.	computation;computational model;message passing;programming paradigm;shared memory;synchronization model	Anand Sivasubramaniam;Umakishore Ramachandran;H. Venkateswaran	1992		10.1109/IPPS.1992.223020	parallel computing;message passing;pointer machine;computer science;theoretical computer science;distributed computing	Arch	-12.694278216156551	40.19228817716525	71990
12ee1b07768812ba6416432e7f5c60e93c29f5d9	a high performance multi-modal traffic simulation platform and its case study with the dublin city		This paper describes a highly scalable multi-modal traffic simulation platform and its case study in Dublin city. By leveraging various sources of open and administrative data for the Greater Dublin Region, we have built a city operating system like platform that simulates not only private cars but also public buses and trains. Our performance study demonstrates that our simulator is highly scalable by achieving 15.5 times faster than real-world time with 12 parallel threads. This is the first effort that has provided a high-performance and high-scalability traffic simulation on a distributed-memory environment and demonstrated the validity of the approach using real data sets.	dvd region code;distributed computing;distributed memory;modal logic;operating system;scalability;shortest path problem;simulation;software architecture	Toyotaro Suzumura;Gavin McArdle;Hiroki Kanezashi	2015	2015 Winter Simulation Conference (WSC)		data modeling;simulation;computer science;engineering;civil engineering;transport engineering	Metrics	-6.927277602429212	33.9535369954855	72054
904b12b2aaad48161e3f6997acd74ecbfc652c37	distributed finite element analysis implementation in .net	parallel computing;personal computers distributed finite element analysis net framework object oriented implementation desktop computers distributed computing;mathematics computing;personal computer;object oriented programming distributed processing finite element analysis mathematics computing;distributed processing;net framework;distributed computing;object oriented programming;net object oriented programming finite element analysis distributed analysis parallel computing;net;finite element methods distributed computing distributed processing matrix decomposition equations computer networks computer science paper technology space technology symmetric matrices;object oriented;parallel computer;finite element analysis;distributed analysis	The paper describe a detailed study into the object-oriented implementation of distributed finite element analysis on desktop computers using the .NET framework. Numerical tests where carried out and reasonable speed-up was achieved, particularly for direct solution methods. It is concluded that .NET provides a viable framework for implementing distributed computing on networks of personal computers.	.net framework;desktop computer;distributed computing;finite element method;numerical linear algebra;personal computer	Wenjun Liu;Rongqiao Wang	2008	2008 International Conference on Computer Science and Software Engineering	10.1109/CSSE.2008.1138	computational science;computer science;theoretical computer science;distributed computing;programming language;object-oriented programming	HPC	-9.580948382272505	37.094184743933205	72092
f4fbe43f653311f03c9da3a7576b591f738815f8	mamber: a cpu/mic collaborated parallel framework for amber on tianhe-2 supercomputer	microwave integrated circuits;coprocessors;acceleration;computational modeling;optimization;scalability;central processing unit	Molecular dynamics (MD) is a computer simulation method of studying physical movements of atoms and molecules that provide detailed microscopic sampling on molecular scale. With the continuous efforts and improvements, MD simulation gained popularity in materials science, biochemistry and biophysics with various application areas and expanding data scale. Assisted Model Building with Energy Refinement (AMBER) is one of the most widely used software packages for conducting MD simulations. However, the speed of AMBER MD simulations for system with millions of atoms in microsecond scale still need to be improved. In this paper, we propose a parallel acceleration strategy for AMBER on Tianhe-2 supercomputer. The parallel optimization of AMBER is carried out on three different levels: fine grained OpenMP parallel on a single MIC, single-node CPU/MIC collaborated parallel optimization and multi-node multi-MIC collaborated parallel acceleration. By the three levels of parallel acceleration strategy above, we achieved the highest speedup of 25–33 times compared with the original program. Source Code: https://github.com/tianhe2/mAMBER	assisted model building with energy refinement (amber);central processing unit;computer simulation;hardware acceleration;mathematical optimization;molecular dynamics;openmp;paradiseo;sampling (signal processing);speedup;supercomputer	Shaoliang Peng;Xiaoyu Zhang;Yutong Lu;Xiangke Liao;Kai Lu;Canqun Yang;Jie Liu;Weiliang Zhu;Dongqing Wei	2016	2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2016.7822595	acceleration;computational science;parallel computing;scalability;computer hardware;computer science;central processing unit;computational model;coprocessor	HPC	-5.570385773644795	37.505992870088285	72176
c0c7e824ce635455fa622481d4b3251c151df761	parallel loops - a test suite for parallelizing compilers: description and example results	parallelisme;compilateur;multiprocessor;multiprocessor systems;parallel test suite;sistema informatico;parallelizing compilers;computer system;paralelisacion;compiler;traitement programme;parallelism;paralelismo;parallelisation;convex;parallelization;systeme informatique;results;multiprocesador;compilador;cray;multiprocesseur	Several multiprocessor systems are now commercially available, and advances in compiler technology provide automatic conversion of programs to run on such systems. However, no accepted measure of this parallel compiler ability exists. This paper presents a test suite of subroutines and loops, called Parallel Loops, designed to (1) measure the ability of parallelizing compilers to convert code to run in parallel and (2) determine how effectively parallel hardware and software work together to achieve high performance across a range of problem sizes. In addition, we present the results of compiling this suite using two commercially available parallelizing Fortran compilers, Cray and Convex.	automatic parallelization;compiler;convex computer;fortran;multiprocessing;subroutine;test suite	Jack J. Dongarra;Mark Furtney;Steven P. Reinhardt;J. Russell	1991	Parallel Computing	10.1016/S0167-8191(05)80036-5	computer architecture;compiler;parallel computing;multiprocessing;computer science;operating system;programming language	HPC	-15.92407048685288	41.579796795889756	72188
b728efeb28faeb9e1a481a8175eaf8358cb42095	parallel vhdl simulation	discrete event simulation;hardware description languages;high level synthesis;parallel algorithms;ibm parallel computer;pdes model;vhdl model;conservative parallel discrete event simulation algorithm;critical distance;external distance;interconnection	VHDL simulation is a common tool for verifying a circuit design. The complexity of modern computer components is growing at a substantial rate. Consider modern processors and GPUs which contain 100 to 300 million transistors. In a variety of consumer markets ranging from scientific computing to business servers to PC gaming, substantial effort is being made to maximize performance while also trying to decrease the time to market to stay competitive. This presents a problem for sequential VHDL simulators. In this poster, we plan to present the preliminary results of a parallel VHDL simulator based on the POSE discrete event simulation framework. By using POSE, the simulator is able to utilize various features of the portable and adaptive Charm++ runtime system. Parallel simulation will reduce the time to verify new designs. Additionally, it will allow larger, more complex designs to be simulated than would be possible with current sequential simulators.	central processing unit;circuit design;computational science;computer hardware;graphics processing unit;pc game;runtime system;sequential logic;simulation;transistor;vhdl;verification and validation	David M. Kunzman;Terry Wilmarth;Laxmikant V. Kalé	2005			embedded system;real-time computing;simulation;computer science	EDA	-6.2240853954699755	44.45788758013104	72533
9b7710865206f5436950f6bee418e477f6e14b96	a transformation system for interactive reformulation of design optimization strategies	interactive reformulation;software testing;optimisation;numerical design optimization algorithms;programming environments;constraint optimization;design engineering;application software;interactive formulation;search space;data flow graphs;interactive testing;cad;software environment;design optimization application software design engineering constraint optimization boats software testing system testing computer science pathology;design optimization;racing yacht design;objective function;optimization problem;transformation system;application domain;program testing;racing yacht design interactive reformulation design optimization strategies numerical design optimization algorithms transformation system search space objective function constraints application domain software environment interactive formulation interactive testing second order dataflow graphs;system testing;cad optimisation programming environments program testing data flow graphs interactive programming;computer science;design optimization strategies;pathology;constraints;interactive programming;boats;second order dataflow graphs	"""ion and Decomposition: Will the overall optimization problem be split into subproblems that can be solved sequentially (or in parallel)? If so, what will be the subproblems? What will be the strategy for solving each subproblem? Setting up the Search Space: Over what search space will each subproblem optimization be carried out? How will each space be parameterized, i.e., what coordinate system will be used? Handling of Constraints: Which equality constraints will be handled by the numeric optimization algorithm? Which will be solved externally to the optimizer, resulting in a reduction of the dimension of the search space? Which inequality constraints will be forced to be active, i.e., made into equality constraints? Which will be allowed to become inactive? Selecting Approximations: What approximations will be used in computing the objective function, and evaluating the constraints? How will any tting coe cients in those approximations be t to the problem at hand? Will approximations be re-calibrated during the optimization process? If so, how often, and when? The Optimization Algorithm: What optimization algorithm will be used for each subproblem? How will each tolerance parameter be set? How will gradients be computed? How will line searches be carried out? How many seed points will be used? How will seed points be selected? Figure 3: Choices in Setting up an Optimization Process constraints. After preparing the initial strategy, the user selects a transformation from a menu and applies it to the initial strategy, to create a new, derived strategy. In many cases, a given transformation can be applied in more than one way. In such cases, the system asks the user which instantiation of the transformation he wants to apply. The system then applies the selected transformation and displays the revised strategy to the user. As the user interacts with the strategy transformation system, he generates a tree in the space of design optimization strategies. The system keeps track of this search tree during the strategy development process. (See Figure 6.) Each node in the tree holds a description of an optimization strategy. Each arc in the tree is labeled with the transformation used in converting the parent strategy into the child strategy. The tree thus implicitly describes all the di erences between ancestors and descendants in the tree. The user can move up and down the tree at will to backtrack to previous strategies to try new alternatives. He can run the strategy in any node on a set of test problems and store the results in a database associated with that node. He can also generate plots of various kinds of data that describe the behavior of strategies on test problems, e.g., a plot of the path through a search space, or a plot of the evolution of a measure of merit, or other quantities appearing in the constraints and the objective function. The user can also annotate the current strategy node with his own observations and conclusions about the behavior of the strategy. The annotated tree of strategies and databases thus serves as a record of the whole design strategy development process. 5 First Order Operations: { Arithmetic, Trigonometry, Interpolation, Conditionals, Relational, Boolean, Set and List Operations. Second Order Operations: { Solving systems of algebraic equations. { Integrating systems di erential equations. { Optimizing functions subject to constraints. { Iterating functions to converge on xed points. Figure 4: Primitives in the Strategy Language 5 Transformations between Strategies Transformations that reformulate the search space are described in Figure 7. The transformation called \Drop Parameter"""" is useful whenever the user believes that a design parameter may not have a great impact on the objective function or constraints appearing in the problem. By removing the parameter from the space, the user may improve the e ciency of the strategy without loss of design quality. For example, in the yacht domain, the user might believe that the Beam parameter is not important and should be dropped from the search space. The transformation called \Parameterize Intermediate Quantity"""" allows the user to introduce a new parameter in to the search space. The user may select any intermediate quantity appearing in a constraint or objective function and allow that quantity to be directly manipulated by the design optimization algorithm. For example, in the yacht domain, the user might decide that the displacement of the yacht (i.e., the amount of water displaced by the hull) should be made into an explicit design parameter. The transformation called \Constrain Intermediate Quantity"""" allows the user to impose a new equality or inequality constraint on the problem. This transformation can be used in several ways. One use is simply to convert an inequality constraint into an equality constraint. For example, in the yacht domain the user might reason that the optimal design will have a sail that is as large as possible while satisfying the NetRating inequality constraint. This inequality constraint will therefore be exactly satis ed in any optimal solution. By making this into an equality constraint, the user can restrict the search to smaller subspace with a potential improvement in e ciency. The transformation called \Constrain Intermediate Quantity"""" can also be used for another purpose. For example, in the yacht domain, the NetRating function contains conditional expressions that apply rating penalties to yachts whose geometries fall outside certain critical dimensions. These penalties result in non-smoothness in the value of NetRating. Optimal designs very often lie in subspaces of the search space where the penalties come into e ect, i.e. were the NetRating is non-smooth. The user can apply the transformation called \Constrain Intermediate Quantity"""" to introduce a new equality constraint that will force the solution to lie in a such a non-smooth subspace, with a potential improvement in e ciency. The transformation called \Solve Equality Constraint"""" allows the user to reduce the dimension 6"""	algebraic equation;algorithm;approximation;backtrack;boolean algebra;converge;database;displacement mapping;fractal dimension;gradient;interpolation;line search;multidisciplinary design optimization;optimal design;optimization problem;optimizing compiler;program optimization;search tree;social inequality;substitution (logic)	Thomas Ellman;John Eric Keane;Takahiro Murata;Mark Schwabacher	1995		10.1109/KBSE.1995.490118	probabilistic-based design optimization;optimization problem;constrained optimization;topology optimization;application software;application domain;engineering optimization;multidisciplinary design optimization;simulation;test functions for optimization;computer science;theoretical computer science;cad;software testing;vector optimization;system testing;engineering drawing	AI	-15.909820085356824	32.382806158638935	72601
1378b35dc3ca7a65922defc80b8960440bd4b325	backwards-compatible bounds checking for arrays and pointers in c programs		This paper presents a new approach to enforcing array bounds and pointer checking in the C language Check ing is rigorous in the sense that the result of pointer arithmetic must refer to the same object as the orig inal pointer this object is sometimes called the in tended referent The novel aspect of this work is that checked code can inter operate without restriction with unchecked code without interface problems with some e ective checking and without false alarms This backwards compatibility property allows the overheads of checking to be con ned to suspect modules and also facilitates the use of libraries for which source code is not available The paper describes the scheme its pro totype implementation as an extension to the GNU C compiler presents experimental results to evaluate its e ectiveness and discusses performance issues and the e ectiveness of some simple optimisations Introduction and related work C is unusual among programming languages in provid ing the programmer with the full power of pointers Languages in the Pascal Algol family have arrays and pointers with the restriction that arithmetic on point ers is disallowed Languages like BCPL allow arbitrary operations on pointers but lack types and so require clumsy scaling by object sizes An advantage of the Pascal Algol approach is that array references can be checked at run time fairly e ciently in fact so e ciently that there is a good case for bounds checking in production code Bounds check ing is easy for arrays because the array subscript syn tax speci es both the address calculation and the array within which the resulting pointer should point A pointer in C can be used in a context divorced from the name of the storage region for which it is valid it s intended referent and this has prevented a fully satisfactory bounds checking mechanism from being de veloped There is overwhelming evidence that bounds checking is desirable and a number of schemes have been presented The main di erence between our work and Kendall s bcc and Ste en s rtcc is that in our scheme the representation of pointers is unchanged This is crucial since it means that inter operation with non checked modules and libraries still works and much checking is still possible Compared with interpretative schemes like Sabre C we o er the potential for much higher performance Patil and Fischer present a sophisticated technique with very low overheads using a second CPU to perform checking in parallel Unfor tunately their scheme requires function interfaces to be changed to carry information about pointers so also has the inter operation problem Another approach is exempli ed by the commercially available checking package Purify Purify processes the binary representation of the software so can handle binary only code Each memory access instruction is modi ed to maintain a bit map of valid storage regions and whether each byte has been initialised Accesses to unallocated or uninitialised locations are reported as errors Purify catches many important bugs and is fairly e cient However Purify does not catch abuse of pointer arithmetic which yields a pointer to a valid region which is not the intended referent Fischer and Patil provide evidence for the importance of this re nement Our goals in this paper are to describe a method of bounds checking C programs that ful lls the following criteria Backwards compatibility the ability to mix checked code and unchecked libraries for which the source may be proprietary or otherwise unavailable Works with all common C programming styles	bcpl;backward compatibility;binary number;bounds checking;byte;central processing unit;gnu compiler collection;image scaling;library (computing);michael j. fischer;nx bit;naruto shippuden: clash of ninja revolution 3;pointer (computer programming);programmer;programming language;purify;run time (program lifecycle phase);sabre (computer system);software bug	Richard W. M. Jones;Paul H. J. Kelly	1997			pointer (computer programming);bcpl;smart pointer;memory safety;compiler;bounds checking;byte;programming language;source code;computer science	PL	-17.56318973480281	35.54141947440668	72618
c10680767dff78d106d835ef93010c328f061aa6	improving stream buffer management of stream-based computing platform on gpu	graphics processing units buffer storage computer architecture;buffer management;buffer storage;gpu;cuda;graphics processing unit computer architecture clocks kernel runtime instruction sets;computer architecture;design and implementation;graphics processing units;stream computing;high performance computer;handling streams stream buffer management stream based computing platform gpu based computing high performance computing fields gpgpu application gpu architectures caravela platform stream buffers handling;stream computing gpu cuda	GPU-based computing has become one of the popular high performance computing fields. The field is called GPGPU. This paper presents design and implementation of a uniform GPGPU application that is optimized for both the legacy and the recent GPU architectures. As a typical example of such the GPGPU application, this paper will discuss the uniform implementation of the Caravela platform, with focusing on the method of handling stream buffers. Two methods for handling streams have been proposed and implemented. To verify the effectiveness of the proposed methods, evaluation has been done using applications.	general-purpose computing on graphics processing units;graphics processing unit;input/output (c++);opencl api;opengl;parallel computing;shared memory;supercomputer	Masahiro Arai;Koichi Wada;Shinichi Yamagiwa	2011	2011 Second International Conference on Networking and Computing	10.1109/ICNC.2011.60	computer architecture;parallel computing;computer science;operating system;stream;general-purpose computing on graphics processing units	HPC	-5.404555706950627	46.07866715937578	72657
8bdb13209eb1bd99b5b604f30215a30d214fb70f	towards automatic restrictification of cuda kernel arguments		<i>Many</i> <i>procedural</i> <i>languages</i>, <i>such</i> <i>as</i> <i>C</i> <i>and</i> <i>C</i>++, <i>have</i> <i>pointers</i>. <i>Pointers</i> <i>are</i> <i>powerful</i> <i>and</i> <i>convenient</i>, <i>but</i> <i>pointer</i> <i>aliasing</i> <i>still</i> <i>hinders</i> <i>compiler</i> <i>optimizations</i>, <i>despite</i> <i>several</i> <i>years</i> <i>of</i> <i>research</i> <i>on</i> <i>pointer</i> <i>aliasing</i> <i>analysis</i>. <i>Because</i> <i>alias</i> <i>analysis</i> <i>is</i> <i>a</i> <i>difficult</i> <i>task</i> <i>and</i> <i>results</i> <i>are</i> <i>not</i> <i>always</i> <i>accurate</i>, <i>the</i> <i>ISO</i> <i>C</i> <i>standard</i> 99 <i>has</i> <i>added</i> <i>a</i> <i>keyword</i>, <i>named</i> <i>restrict</i> <i>to</i> <i>allow</i> <i>the</i> <i>programmer</i> <i>to</i> <i>specify</i> <i>non</i>−<i>aliasing</i> <i>as</i> <i>an</i> <i>aid</i> <i>to</i> <i>the</i> <i>compiler</i>′<i>s</i> <i>optimizer</i> <i>and</i> <i>to</i> <i>thereby</i> <i>possibly</i> <i>improve</i> <i>performance</i>. <i>The</i> <i>task</i> <i>of</i> <i>annotating</i> <i>pointers</i> <i>with</i> <i>the</i> <i>restrict</i> <i>keyword</i> <i>is</i> <i>still</i> <i>left</i> <i>to</i> <i>the</i> <i>programmer</i>. <i>This</i> <i>task</i> <i>is</i>, <i>in</i> <i>general</i>, <i>tedious</i> <i>and</i> <i>prone</i> <i>to</i> <i>errors</i> <i>especially</i> <i>since</i> <i>the</i> <i>C</i> <i>does</i> <i>not</i> <i>perform</i> <i>any</i> <i>verification</i> <i>to</i> <i>ensure</i> <i>that</i> <i>restrict</i> <i>keyword</i> <i>is</i> <i>not</i> <i>misplaced</i>. <i>In</i> <i>this</i> <i>paper</i> <i>we</i> <i>present</i> <i>a</i> <i>static</i> <i>analysis</i> <i>tool</i> <i>that</i> (<i>i</i>) <i>finds</i> <i>CUDA</i> <i>kernels</i> <i>call</i> <i>sites</i> <i>in</i> <i>which</i> <i>actual</i> <i>parameters</i> <i>do</i> <i>not</i> <i>alias</i>; (<i>ii</i>) <i>clones</i> <i>the</i> <i>kernels</i> <i>called</i> <i>at</i> <i>such</i> <i>sites</i>; (<i>iii</i>) <i>after</i> <i>performing</i> <i>an</i> <i>alias</i> <i>analysis</i> <i>in</i> <i>these</i> <i>kernels</i>, <i>adds</i> <i>the</i> <i>restrict</i> <i>keyword</i> <i>to</i> <i>their</i> <i>arguments</i>; <i>and</i> (<i>iv</i>) <i>replaces</i> <i>the</i> <i>original</i> <i>kernel</i> <i>call</i> <i>by</i> <i>a</i> <i>call</i> <i>to</i> <i>the</i> <i>optimized</i> <i>clone</i> <i>whenever</i> <i>possible</i>.	cuda;kernel (operating system)	Rokiatou Diarra	2018		10.1145/3238147.3241533	computer science;pointer (computer programming);theoretical computer science;programming language;compiler;alias analysis;alias;program optimization;pointer aliasing;restrict;optimizing compiler	NLP	-17.64334424195412	34.15116357329711	72669
0acf5847a55365689fd5f61eef1c2ba4c7c09d48	disk-directed i/o for mimd multiprocessors	available bandwidth;scientific application;sistema operativo;evaluation performance;disk directed i o;performance evaluation;multiprocessor;evaluacion prestacion;simulation;menu;weather forecasting;gestion fichier;simulacion;file management;data distribution;input output interface;calculateur mimd;collective i o;operating system;interface entree sortie;mimd;file system;parallel file system;manejo archivos;interfase entrada salida;systeme exploitation;parallel i o;serveur fichier;systeme parallele;parallel system;seismic analysis;multiprocesador;high performance;file server;sistema paralelo;mimd computer;file caching;reading and writing;multiprocesseur	Many scientific applications that run on today's multiprocessors, such as weather forecasting and seismic analysis, are bottlenecked by their file-I/O needs. Even if the multiprocessor is configured with sufficient I/O hardware, the file system software often fails to provide the available bandwidth to the application. Although libraries and enhanced file system interfaces can make a significant improvement, we believe that fundamental changes are needed in the file server software. We propose a new technique, disk-directed I/O, to allow the disk servers to determine the flow of data for maximum performance. Our simulations show that tremendous performance gains are possible both for simple reads and writes and for an out-of-core application. Indeed, our disk-directed I/O technique provided consistent high performance that was largely independent of data distribution and obtained up to 93% of peak disk bandwidth. It was as much as 18 times faster than either a typical parallel file system or a two-phase-I/O library.	clustered file system;dataflow;file server;input/output;library (computing);mimd;multiprocessing;out-of-core algorithm;seismic analysis;simulation;two-phase locking	David Kotz	1994	ACM Trans. Comput. Syst.	10.1145/244764.244766	file server;parallel computing;real-time computing;multiprocessing;weather forecasting;mimd;seismic analysis;computer science;operating system;distributed computing	OS	-17.035111864115578	44.3200301501794	72766
a44da331c75cd356437ad887f96d49e21b7bae19	finding, expressing and managing parallelism in programs executed on clusters of workstations	parallel programming languages;parallel programming tools;parallelizing compilers;cluster of workstations;group communication;distributed operating system;parallel programming language;execution environment;dsm;parallel programming tool;parallel programs;distributed operating systems supporting parallelism management;parallelism management;distributed shared memory;high performance;process migration;parallel processing	The goal of this paper to identify and discuss the basic issues of and solutions to parallel processing on clusters of workstations (COWs). Firstly, identification and expressing parallelism in application programs are discussed. The following approaches to finding and expressing parallelism are characterized: parallel programming languages, parallel programming tools, sequential programming supported by distributed shared memory (DSM), and parallelising compilers. Secondly, efficient management of available parallelism is discussed. As parallel execution requires an efficient management of processes and computational resources, a parallel execution environment proposed here is to be built based on a distributed operating system. This system, in order to allow parallel programs to achieve high performance and transparency, should provide services such as global scheduling, process migration, local and remote process creation, computation coordination, group communication and distributed shared memory. q 1999 Elsevier Science B.V. All rights reserved.	compiler;computation;computational resource;concurrent computing;distributed operating system;distributed shared memory;parallel computing;process migration;programming language;programming tool;scheduling (computing);workstation	Andrzej M. Goscinski	1999	Computer Communications	10.1016/S0140-3664(99)00072-9	distributed shared memory;parallel processing;computer architecture;parallel computing;process migration;communication in small groups;computer science;operating system;distributed computing;data parallelism;instruction-level parallelism;implicit parallelism;task parallelism;parallel programming model	HPC	-12.94230473067066	42.94751351895446	72902
ffb8c78e3dd2aeb16b6a94965d88f98d87053765	the ibm 701 speedcoding system	speedcoding system	The IBM 701 Speedcoding System is a set of instructions which causes the 701 to behave like a three-address floating point calculator. Let us call this the Speedcoding calculator. In addition to operating in floating point, this Speedcoding calculator has extremely convenient means for getting information into the machine and for printing results; it has an extensive set of operations to make the job of programming as easy as possible. Speedeoding also provides automatic address modification, flexible tracing, convenient use of auxiliary storage, and built-in checking. The system was developed by IBMPs New York Scientific Computing Service. Since this floating point Speedcoding calculator is slower than the 701, despite the conveniences that it offers, you might ask: Why go to a lot of trouble to make an extremely fast calculator like the 701 behave like a slower one? There are two principal reasons. The first is that some computing greups are working against time, and the elapsed time for solving a problem may often be reduced by minimizing the time for programming and checking out the problem even though the running time is thereby increased. The second and most important reason for having a Speedcoding calculator, in addition to the 701, is a matter of economy. Often, the expense of operating a computing installation is almost equally divided between machine costs and personnel cost. Furthermore, machine time spent checking out problems is frequently a very appreciable percentage of the total machine time. It is clear, therefore, that programming and testing cost often comprise between 50 and 75% of the total cost of operating a computing installation. Since Speedcoding reduces coding and testing time considerably , and is fairly fast in operation, it will often be the more economical way of solving a problem. Speedcoding is an interpretive system. I have implied that Speedcoding is a three-address system. Actually this is not quite the case. In a floating point system data and instructions have completely different forms and are treated differently. Therefore, it was thought desirable to have separate methods of dealing with each of these two types of information. Thus, each Speed-coding instruction has two operation codes in it called OP 1 and OP 2. OP 1 has three addresses A, B, and C, associated with it and is always an arithmetic or an input-output operation. OP 2 has one address, D, associated with it and is always a logical …	as-easy-as;auxiliary memory;code;goto;ibm 701;printing;speedcoding;time complexity	John W. Backus	1954	J. ACM	10.1145/320764.320766	ibm high availability cluster multiprocessing;queued telecommunications access method;rs/6000;industry standard architecture;cics;ibm floating point architecture;tivoli management framework;ibm san volume controller;time-sharing	PL	-14.27671089299089	33.40766314164064	72915
34ec1b2f74142c652902df3ddfcf1d3ba918c92d	cluster computing for industrial strength cfd applications.	cluster computing			J. C. T. Wang;J. T. Thomas;E. J. Hollmeier;Craig A. Lee	2001			computational science;parallel computing;operating system	HPC	-7.19608311783364	37.708614353603565	72923
5376be1afe4e810f4517135afff0e270d51d80ee	an effective automated approach to specialization of code	code size	Application performance is heavily dependent on the compiler optimizations. Modern compilers rely largely on the information made available to them at the time of compilation. In this regard, specializing the code according to input values is an effective way to communicate necessary information to the compiler. However, the static specialization suffers from possible code explosion and dynamic specialization requires runtime compilation activities that may degrade the overall performance of the application. This article proposes an automated approach for specializing code that is able to address both the problems of code size increase and the overhead of runtime activities. We first obtain optimized code through specialization performed at static compile time and then generate a template that can work for a large set of values through runtime specialization. Our experiments show significant improvement for different SPEC benchmarks on Itanium-II(IA-64) and Pentium-IV processors using icc and gcc compilers.	benchmark (computing);central processing unit;compile time;embedded system;experiment;itanium;object code;optimizing compiler;overhead (computing);partial template specialization;run time (program lifecycle phase);speedup	Minhaj Ahmad Khan;Henri-Pierre Charles;Denis Barthou	2007		10.1007/978-3-540-85261-2_21	dead code;compile time;code bloat;parallel computing;real-time computing;dynamic compilation;computer science;dead code elimination;redundant code;compilation error;programming language;tracing just-in-time compilation;code generation;unreachable code;source code	SE	-17.941064408822097	36.62250036277481	73058
8ce375120e21da4ffbf249fd60704a6862d6ad54	parallel particle advection and ftle computation for time-varying flow fields	lyapunov methods;computational fluid dynamics;flow visualisation;ftle computation;finite-time lyapunov exponent field;flow visualization technique;parallel ftle framework;parallel particle advection;particle tracing algorithms scale;scientific simulation;time-varying flow field	Flow fields are an important product of scientific simulations. One popular flow visualization technique is particle advection, in which seeds are traced through the flow field. One use of these traces is to compute a powerful analysis tool called the Finite-Time Lyapunov Exponent (FTLE) field, but no existing particle tracing algorithms scale to the particle injection frequency required for high-resolution FTLE analysis. In this paper, a framework to trace the massive number of particles necessary for FTLE computation is presented. A new approach is explored, in which processes are divided into groups, and are responsible for mutually exclusive spans of time. This pipelining over time intervals reduces overall idle time of processes and decreases I/O overhead. Our parallel FTLE framework is capable of advecting hundreds of millions of particles at once, with performance scaling up to tens of thousands of processes.	algorithm;computation;image resolution;image scaling;lyapunov fractal;overhead (computing);pipeline (computing);simulation;tracing (software)	Boonthanome Nouanesengsy;Teng-Yok Lee;Kewei Lu;Han-Wei Shen;Tom Peterka	2012	2012 International Conference for High Performance Computing, Networking, Storage and Analysis		acceleration;heuristic;mathematical optimization;parallel computing;simulation;computational fluid dynamics;computer science;theoretical computer science;mathematical model;distributed computing;quantum chemistry	HPC	-5.876393240579726	36.89980919275302	73417
17ade5bca7ede66709e6837bb8d4ec96a77dd966	a comparative study of the use of the data-parallel approach for compressible flow calculations	parallelisme;data parallel;compressible flow;equation euler;performance results;programmation parallele donnee;portability;computational fluid dynamics;parallelism;paralelismo;performance result;portabilite;ecuacion euler;euler equations;data parallel programming;resultat performance;portabilidad;euler equation;dynamique calcul fluide	The results are presented of an investigation into the use of the data-parallel programming approach on four different massively-parallel computers: the MasPar MP-1 and MP-2 and the Thinking Machines CM-200 and CM-5. A code to calculate inviscid compressible flow, originally written in FORTRAN 77 for a traditional vector computer, has been re-written entirely in Fortran 90 to take advantage of the compilers available on the massively-parallel computers. It is shown that the discretization of the governing equations on a regular mesh is well adapted to data parallelism. For a typical test problem of supersonic flow through a ramped duct, computational speeds have been achieved using these massively-parallel computers that are superior to those obtained using a single processor of a Cray Y-MP. In addition, this study has enabled the question of code portability between the different computers to be assessed.		Mark L. Sawley;C. M. Bergman	1994	Parallel Computing	10.1016/S0167-8191(06)80019-0	parallel computing;computer science;theoretical computer science;euler equations;algorithm	HPC	-4.788326664044454	36.51911230525169	73432
fb923971cfd49912790366f22da0977415892385	a comparison of storage optimizations in automatically-generated attribute evaluators	arbre graphe;storage allocation;optimisation;optimizacion;tree graph;traductor;context free language;stack;traducteur;gramatica cf;attribute grammar;automatic generation;grammaire cf;context free grammar;almacenamiento;gramatica por atributo;grammaire par attribut;stockage;system development;memoire pile;evaluation;optimization;translator;computer science;evaluacion;allocation memoire;arbol grafo;asignacion memoria;storage	Attribute grammars are a value-oriented, non-procedural extension to context-free grammars that facilitate the specification of translations whose domain is described by the underlying context-free grammar. Just as parsers for context-free languages can be automatically constructed from a context-free grammar, so can translators, called attribute evaluators, be automatically generated from an attribute grammar. A major obstacle to generating efficient attribute evaluators is that they typically use large amounts of memory to represent the attributed parse tree. In this report we investigate the problem of efficient representation of the attributed parse tree by analyzing and comparing the strategies of two systems that have been used to automatically generate a translator from an attribute grammar: the GAG system developed at the Universitat de Karlsruhe and the LINGUIST-86 system written at Intel Corporation. Our analysis will characterize the two strategies and highlight their respective strengths and weaknesses. Drawing on the insights given by this analysis, we propose a strategy for storage optimization in automatically generated attribute evaluators that not only incorporates the best features of both GAG and LINGUIST-86, but also contains novel features that address aspects of the problem that are handled poorly by both systems.	attribute grammar;context-free grammar;context-free language;mathematical optimization;parse tree;parsing	Rodney Farrow;Daniel M. Yellin	1986	Acta Informatica	10.1007/BF00267865	natural language processing;l-attributed grammar;stack;computer science;evaluation;context-free language;context-free grammar;programming language;attribute grammar;tree;algorithm	PL	-16.6931097300788	33.9671853188337	73587
737c7298166e2a8a258cafd1ceafabdd28af9fd9	concept of a multi-processor parallel processing unit	parallel processing	The logical concept of a processing system withm, 1<m≤n, identical or different processors is given where the processors operate onp, p≤n subprograms which are parts of a program for the system. As many of the processors as possible work in parallel, and as soon as a processor has terminated its process this processor is automatically turned over to another program to compute. Dargestellt wird das logische Konzept eines Rechenwerks mitm, 1<m≤n, identischen oder verschiedenen Prozessoren, wobei die Prozessoren aufp, p≤n Unterprogrammen arbeiten, die Teile eines Programmes für das Rechenwerk sind. So viele der Prozessoren als möglich arbeiten parallel, und sobald ein Prozessor seinen Prozeß beendet hat, wird er automatisch einem anderen zu berechnenden Programm übergeben.	central processing unit;multiprocessing;parallel computing;subroutine	Rudolf F. Albrecht	1980	Computing	10.1007/BF02243878	computer architecture;parallel computing;computer science;theoretical computer science;mathematics	HPC	-10.511112303355322	42.21354377464646	73755
b49ebadf5c991cafda7cc1703bf89dc681b28c56	detecting value-based scalar dependence	static single assignment;ssa;compiler optimization;control flow;graph;graph representation;scalars;data;scalar	Precise value-based data dependence analysis for scalars is useful for advanced compiler optimizations. The new method presented here for ow and output dependence uses Factored Use and Def chains (FUD chains), our interpretation and extension of Static Single Assignment. It is precise with respect to conditional control ow and dependence vectors. Our method detects dependences which are independent with respect to arbitrary loop nesting, as well as loop-carried dependences. A loop-carried dependence is further classiied as being carried from the previous iteration, with distance 1, or from any previous iteration, with direction <. This precision cannot be achieved by traditional analysis, such as dominator information or reaching deenitions. To compute anti-and input dependence , we use Factored Redef-Use chains, which are related to FUD chains. We are not aware of any prior work which explicitly deals with scalar data dependence utilizing a sparse graph representation.	data dependency;dependence analysis;dominator (graph theory);graph (abstract data type);iteration;optimizing compiler;scalar processor;sensor;sparse graph code;sparse matrix;static single assignment form	Eric Stoltz;Michael Wolfe	1994		10.1007/BFb0025879	parallel processing;parallel computing;scalar;computer science;theoretical computer science;graph;programming language;control flow;static single assignment form;algorithm;data;memory management	SE	-16.522772636288312	35.00079637293832	73820
0bbf408d8298476b102a67f0d2d1f3877ab151f7	a general scheduling framework for parallel execution environments	software portability parallel programming scheduling resource allocation multiprocessing systems software performance evaluation;software portability;resource allocation;software performance evaluation;distributed programs;parallel programming;scheduling;execution environment;multiprocessor architecture;parallel programming kernel programming profession runtime load management parallel processing sockets multiprocessing systems proposals scholarships;resource availability;load balance;multiprocessing systems;parallel programs;load balancing schemes general scheduling framework parallel execution environments parallel programming distributed programming multiprocessor architecture concurrent activities program portability architecture resources concurrent activity graph scheduling kernel program level	A major problem in the context of parallel and distributed programming is how to explore the resources of a multiprocessor architecture eficiently in order to obtain a gain in pedormance in the execution of a program. In the classical approach, to write a parallel program, the programmer needs, first, to detect the concurrent activities in the application and their respective synchronisations, and second, to distribute the activities and their data among the resources available on the architecture. In this approach we can find a Low degree of program portability because the code will be dependent on the architecture resources. In this paper we present an alternative to this classical approach where the programmer is responsible only for describing its application by a graph of concurrent activities. We propose a scheduling kemel that is independent from the program level to support the execution. This scheduling kernel was developed in order to support different load balancing schemes, improving program portability.	distributed computing;graph (discrete mathematics);load balancing (computing);multiprocessing;programme level;programmer;scheduling (computing);software portability	Gerson G. H. Cavalheiro	2001		10.1109/CCGRID.2001.923260	software portability;computer architecture;parallel computing;real-time computing;resource allocation;computer science;load balancing;operating system;distributed computing;programming language;scheduling;parallel programming model	HPC	-13.410885326449533	41.362470602710715	73944
3f869b11d4b275870117b854378f9b6517a6c5d8	efficient communication algorithms for pipeline multicomputers	matrix multiplication;communication functions;point to point routing;pipeline multicomputers;message size;distributed memory systems;parallel architectures;right message size;communication algorithms;distributed memory;important communication function;pipeline multicomputer;propagation delay;parallel algorithms;data broadcast;efficient communication algorithm;various communication algorithm;data distribution;data collection;pipeline processing;broadcasting;hardware;point to point;cost function;bandwidth	In this paper, we study the various communication algorithms on the pipeline multicomputer. We show how the three important communication functions (data distribution, data collection, and data broadcast) can be improved by reducing the propagation delay and using the right message size.	algorithm;broadcasting (networking);parallel computing;pipeline (computing);propagation delay;software propagation	Kok Kin Kee;Salim Hariri	1994			propagation delay;parallel processing;vector processor;parallel computing;distributed memory;matrix multiplication;point-to-point;computer science;theoretical computer science;distributed computing;parallel algorithm;broadcasting;bandwidth;data transmission;memory management;data collection	Arch	-10.444408600480818	44.86270469334401	73958
7d119c066a4e88af26518edfdd97639f6793b4cf	an efficient framework for multi-dimensional tuning of high performance computing applications	libraries;software;graph theory;poisson solver code;software tool;refactoring;measurement;high performance computing;software tools computer architecture graph theory parallel machines poisson distribution;compiler feedback;runtime;upc;probes;runtime observation;memory access;computer architecture;measurement tuning runtime probes software libraries;memory access multidimensional tuning high performance computing machine architecture expert knowledge static analysis runtime observation refactoring compiler feedback software tool lbmhd code poisson solver code graph analysis code upc;tuning;graph analysis code;machine architecture;lbmhd code;parallel machines;software tools;expert knowledge;static analysis;poisson distribution;multidimensional tuning	Deploying an application onto a target platform for high performance oftentimes demands manual tuning by experts. As machine architecture gets increasingly complex, tuning becomes even more challenging and calls for systematic approaches. In our earlier work we presented a prototype that combines efficiently expert knowledge, static analysis, and runtime observation for bottleneck detection, and employs refactoring and compiler feedback for mitigation. In this study, we develop a software tool that facilitates \emph{fast} searching of bottlenecks and effective mitigation of problems from major dimensions of computing (e.g., computation, communication, and I/O). The impact of our approach is demonstrated by the tuning of the LBMHD code and a Poisson solver code, representing traditional scientific codes, and a graph analysis code in UPC, representing emerging programming paradigms. In the experiments, our framework detects with a single run of the application intricate bottlenecks of memory access, I/O, and communication. Moreover, the automated solution implementation yields significant overall performance improvement on the target platforms. The improvement for LBMHD is up to 45\%, and the speedup for the UPC code is up to 5. These results suggest that our approach is a concrete step towards systematic tuning of high performance computing applications.	code refactoring;compiler;computation;database;experiment;input/output;performance tuning;programming paradigm;programming tool;prototype;solver;speedup;static program analysis;supercomputer;universal product code	Guojing Cong;Hui-Fang Wen;I-Hsin Chung;David J. Klepacki;Hiroki Murata;Yasushi Negishi	2012	2012 IEEE 26th International Parallel and Distributed Processing Symposium	10.1109/IPDPS.2012.124	parallel computing;real-time computing;computer science;graph theory;theoretical computer science;operating system;distributed computing;universal product code;poisson distribution;programming language;static analysis;code refactoring;measurement;statistics	HPC	-7.76774707005996	45.98522038215926	74022
17dd48f2c8f021ada21032fa5d540f9828eec599	statistical models for automatic performance tuning	reponse temporelle;evaluation performance;ajustamiento modelo;sistema experto;performance evaluation;automatic tuning;automatic system;evaluacion prestacion;data collection;heuristic method;base connaissance;metodo heuristico;statistical model;ajustement modele;accord frequence;sistema automatico;tuning;time response;accord automatique;model matching;automatic performance tuning;modele statistique;systeme automatique;subroutine;base conocimiento;modelo estadistico;sous programme;sintonizacion frecuencia;methode heuristique;statistical techniques;computer hardware;systeme expert;respuesta temporal;materiel informatique;material informatica;decision rule;subprograma;sintonizacion automatica;knowledge base;expert system	Achieving peak performance from library subroutines usually requires extensive, machine-dependent tuning by hand. Automatic tuning systems have emerged in response, and they typically operate by (1) generating a large number of possible implementations of a subroutine, and (2) selecting the fastest implementation by an exhaustive, empirical search. This paper presents quantitative data that motivates the development of such a search-based system, and discusses two problems which arise in the context of search. First, we develop a heuristic for stopping an exhaustive compile-time search early if a near-optimal implementation is found. Second, we show how to construct run-time decision rules, based on run-time inputs, for selecting from among a subset of the best implementations. We address both problems by using statistical techniques to exploit the large amount of performance data collected during the search. We apply our methods to actual performance data collected by the PHiPAC tuning system for matrix multiply on a variety of hardware platforms.	automatic control;compile time;compiler;fastest;heuristic;library (computing);machine-dependent software;matrix multiplication;performance tuning;regular expression;statistical model;subroutine	Richard W. Vuduc;James Demmel;Jeff A. Bilmes	2001		10.1007/3-540-45545-0_21	statistical model;knowledge base;simulation;computer science;artificial intelligence;subroutine;decision rule;expert system;algorithm;statistics;data collection	HPC	-18.01564352775212	38.73296243138814	74035
29c1afe5ff4e56e732f6d3c8dd12768e50c4f601	just-in-time length specialization of dynamic vector code	just in time compilation;data parallelism;tracing;r	Dynamically typed vector languages are popular in data analytics and statistical computing. In these languages, vectors have both dynamic type and dynamic length, making static generation of efficient machine code difficult. In this paper, we describe a trace-based just-in-time compilation strategy that performs partial length specialization of dynamically typed vector code. This selective specialization is designed to avoid excessive compilation overhead while still enabling the generation of efficient machine code through length-based optimizations such as vector fusion, vector copy elimination, and the use of hardware SIMD units. We have implemented our approach in a virtual machine for a subset of R, a vector-based statistical computing language. In a variety of workloads, containing both scalar and vector code, we show near autovectorized C performance over a large range of vector sizes.	compiler;computational statistics;just-in-time compilation;machine code;overhead (computing);partial template specialization;simd;type system;virtual machine	Justin Talbot;Zach DeVito;Pat Hanrahan	2014		10.1145/2627373.2627377	parallel computing;real-time computing;computer science;theoretical computer science;just-in-time compilation;code generation	PL	-18.07397576053223	35.8625728082991	74045
7b62b5c3d8abf50b7b24451464db88f628198e6c	dynamo - a portable tool for dynamic load balancing on distributed memory multicomputers	dynamic load balancing;load distribution;distributed memory multicomputer;load balance	Dynamic load balancing is an important technique when developing applications with unpredictable load distribution on distributed memory multicomputers. A tool, Dynamo, that can be used to utilize dynamic load balancing is presented. This tool separates the application from the load balancer and thus makes it possible to easily exchange the load balancer of a given application and experiment with different load balancing strategies.		Erik Tärnvik	1992		10.1007/3-540-55895-0_446	parallel computing;real-time computing;distributed computing	HPC	-13.406416299818243	43.73193765117716	74204
0d86666f832caaad86fd584c88f19377aee25ad0	on parallelization of the openfoam-based solver for the heat transfer in electrical power cables	domain decomposition;multicore;mpi;openfoam;parallel algorithms	In this work, we study the parallel performance of OpenFOAM-based solver for heat conduction in electrical power cables. The 2D benchmark problem is used for our tests. The parallelization approach used in OpenFOAM-based solver is described and a basic scalability analysis is done. Results of computational experiments on a cluster of multicore computers are presented and the parallel efficiency and scalability of the solver are analyzed.	openfoam;parallel computing;solver	Raimondas Ciegis;Vadimas Starikovicius;Andrej Bugajev	2014		10.1007/978-3-319-14325-5_1	multi-core processor;computational science;parallel computing;computer science;message passing interface;theoretical computer science;domain decomposition methods;parallel algorithm	HPC	-5.821983491174885	37.53226519227277	74225
465ac6ce909e6641ccebbf8e26f691da3962d4ce	fault-tolerant hardware configuration management on the multiprocessor system dirmu 25	fault tolerant;multiprocessor systems;programming environment;hardware architecture;operating system;graph model;parallel programs;configuration management;parallel applications;fault diagnosis	This paper describes fault tolerance techniques which have been developed and implemented for the multiprocessor system DIRMU 25 a 25-processor system which is operational at the University of Erlangen-Nuremberg. First a short overview of the DIRMU hardware architecture, programming envirorment and parallel application pregram~ is giver~ Fault-diagnosis and reconfiguration are implemented in a layer of the DIRMOS operating system: the hardware configuration management. The concept of this configuration management is described in general (based on a graph model) and its application for the fault-tolerant execution of parallel programs is discussed.		Erik Maehle;Klaus Moritzen;Klaus Wirl	1986		10.1007/3-540-16811-7_170	fault tolerance;computer architecture;parallel computing;real-time computing;computer science;operating system;hardware architecture;configuration management	HPC	-11.778991270015059	43.46645751282916	74234
db143a3d0288dbe2cc687bc9a9f739311af5fb45	a comparative study of redundancy in trace caches (research note)	trace cache performance;evaluation performance;performance evaluation;redundancia;evaluacion prestacion;redundancy;technology and engineering;duplication;duplicacion;redondance	Trace cache performance is limited by two types of redundancy: duplication and liveness. In this paper, we show that duplication is not strongly correlated to trace cache performance. Generally, the best-performing trace caches also introduce the most duplication. The amount of dead traces is extremely high, ranging from 76% in the smallest trace cache to 35% in the largest trace cache studied. Furthermore, most of these dead traces are never used between storing them and replacing them from the trace cache.	cpu cache	Hans Vandierendonck;Alex Ramírez;Koen De Bosschere;Mateo Valero	2002		10.1007/3-540-45706-2_69	parallel computing;real-time computing;computer hardware;computer science;cache invalidation;redundancy;gene duplication	Metrics	-16.829241358253544	45.38439055530188	74381
e9b0243616501fb9ed770867b3e847e98cf1f0cb	a comparison of task distribution patterns for matrix factorization on mimd multiprocessor architectures	mimd multiprocessor architecture;matrix factorization;task distribution pattern		mimd;multiprocessing	Suchendra M. Bhandarkar;Peiqing Jiang	1994	Neural Parallel & Scientific Comp.		computer architecture;parallel computing;mimd;theoretical computer science	HPC	-9.325466202047505	42.335204836486014	74581
835c0aa9082e7fd7937c802f64e0393e267e6496	a practical multi-word compare-and-swap operation	gestion memoire;algorithmique;shared memory;memoria compartida;architecture memoire;storage management;gestion memoria;algorithmics;algoritmica;memory architecture;estructura datos;compare and swap;structure donnee;data structure;memoire partagee	Work on non-blocking data structures has proposed extending processor designs with a compare-and-swap primitive, CAS2, which acts on two arbitrary memory locations. Experience suggested that current operations, typically single-word compare-and-swap (CAS1), are not expressive enough to be used alone in an eÆcient manner. In this paper we build CAS2 from CAS1 and, in fact, build an arbitrary multi-word compare-and-swap (CASN). Our design requires only the primitives available on contemporary systems, reserves a small and constant amount of space in each word updated (either 0 or 2 bits) and permits nonoverlapping updates to occur concurrently. This provides compelling evidence that current primitives are not only universal in the theoretical sense introduced by Herlihy, but are also universal in their use as foundations for practical algorithms. This provides a straightforward mechanism for deploying many of the interesting non-blocking data structures presented in the literature that have previously required CAS2.	blocking (computing);compare-and-swap;data structure;language primitive;maurice herlihy;non-blocking algorithm;paging;quantum gate	Timothy L. Harris;Keir Fraser;Ian Pratt	2002		10.1007/3-540-36108-1_18	shared memory;data structure;computer science;artificial intelligence;theoretical computer science;operating system;database;programming language;algorithmics;computer security;compare-and-swap;algorithm	Theory	-15.46724237730812	46.351126594878394	74606
493b5da4b6b76bebcfb58b481ff07ec67f087076	an adaptive system for dynamic storage allocation	run time systems;algol 68 implementation;adaptive system;dynamic storage allocation	Abstract#R##N##R##N#We describe a technique (the adaptive creation of free lists) for dynamic storage allocation that is particularly suited to situations in which the distribution of sizes of blocks requested has one or more sharp peaks. We describe a particular dynamic storage allocation system and the environment in which it runs, and give the results of some experiments to determine the usefulness of the technique in this system. Our experiments also tested the efficacy of a technique suggested by Knuth for improving the performance of similar systems.		Bruce W. Leverett;Peter G. Hibbard	1982	Softw., Pract. Exper.	10.1002/spe.4380120606	real-time computing;simulation;computer hardware;computer science;adaptive system;operating system	DB	-18.239812754963637	38.441283265271686	74730
e8fc6e3a632ed671c8edc1528fcca0b33ebdf843	large scale finite element fluid analysis by massively parallel processors	element by element;mpp;finite element;large scale;large scale computing;massively parallel computer;finite elements;massively parallel processor	A finite element fluid analysis code, which is based on the matrix-storage free formulation and the element-by-element computation strategy, is developed. The code has reduced memory requirements due to the matrix-storage free formulation. Simulations involving one million elements can be carried out with less than 208 Mbytes of memory. The code is implemented on the massively parallel computers, KSRI and CRAY T3D. In the case of KSRI, high parallel efficiency is achieved, i.e. 95.9% with 16 CPUs. In the case of T3D, excellent scalability is achieved. Each time step of a 3D cavity flow problem with one million elements required 36.3, 18.7 and 9.8 s of CPU time by using 32, 64 and 128 processors, respectively.	central processing unit;computation;computer simulation;cray t3d;finite element method;flow network;parallel computing;requirement;scalability;speedup;the matrix	Yasushi Nakabayashi	1996	Parallel Computing	10.1016/S0167-8191(97)89284-8	computational science;parallel computing;computer science;massively parallel;finite element method;distributed computing	HPC	-5.592090950694587	37.41825171235774	74798
98a419e0389384c4d168b28f7e2c06ff7a1ce862	a universal parallel sat checking kernel	mobile agents.;multithreading;parallel symbolic computation;parallel sat checking;symbolic computation;mobile agent;programming model;boolean satisfiability	We present a novel approach to parallel Boolean satisfiability (SAT) checking. A distinctive feature of our parallel SAT checker is that it incorporates all essential heuristics employed by the state-of-the-art sequential SAT checking algorithm. This property makes our parallel SAT checker applicable in a wide range of different application domains. For its distributed execution a combination of the strict multithreading and the mobile agent programming model is employed. We give results of run-time measurements for problem instances taken from different application domains, indicating the usefulness of the presented method.	algorithm;application domain;boolean satisfiability problem;combinatorial search;dynamic problem (algorithms);heuristic (computer science);kernel (operating system);mobile agent;multithreading (computer architecture);parallel computing;programming model;thread (computing)	Wolfgang Blochinger;Carsten Sinz;Wolfgang Küchlin	2003			kernel (linear algebra);parallel computing;multithreading;theoretical computer science;mobile agent;computer science;heuristics;programming paradigm;symbolic computation;#sat;boolean satisfiability problem	AI	-11.686998815300754	32.63258130291327	74919
09c483991e911a8db3b28d818f1adcf130e3e0de	experiences in dynamic placement of actors on multicomputer systems	highly dynamic computations;acwn;adaptive contracting within neighbourhood;distributed memory systems;dynamic load balancing;multicomputer architectures;programming tools;resource allocation;dynamic actor placement;balancer behavior;parallel programming;object oriented programming;low cost;random allocation algorithm;availability dynamic programming microprocessors communications technology computer architecture costs programming profession high performance computing amplitude shift keying runtime;dynamic load balancer;multicomputer systems;parallel machines;communication technology;operating system kernels;balancer behavior dynamic actor placement multicomputer systems multicomputer architectures low cost programming tools highly dynamic computations dynamic load balancer ask run time kernel parallel actor programming transputer network random allocation algorithm adaptive contracting within neighbourhood acwn;object oriented programming parallel machines distributed memory systems resource allocation parallel programming operating system kernels;high performance;ask run time kernel;programming tool;parallel actor programming;transputer network	The availability of low-cost microprocessors and the advances in communication technologies have promoted a great interest in multicomputer architectures. These systems are characterized by high performance, availability and extensibility at low cost but nowadays lack of good programming tools which could help the programmer to really exploit the resources of the computing system. One of the most significant problems, especially for highly dynamic computations, is how to allocate work to the nodes of the system. We examine the main topics concerning a dynamic load balancer integrated in the ASK run-time kernel which supports parallel actor programming on a transputer network. The balancer implements both a random allocation algorithm and a more complex one called Adaptive Contracting Within Neighbourhood (ACWN). Experimental results concerning the balancer behavior on some sample algorithms are presented and analyzed. >		Michele Di Santo;Franco Frattolillo;Giulio Iannello	1995		10.1109/EMPDP.1995.389146	parallel computing;real-time computing;computer science;distributed computing	EDA	-12.894848561276904	43.34930962710084	74929
6d001a0aaff32ed782e068d437a214e46ab84d95	manycore performance-portability: kokkos multidimensional array library	optimal data access pattern;multidimensional array;kokkos array programming model;data parallel kernel;diverse programming model;computational kernel;manycore performance-portability;programming model;kokkos multidimensional array library;device-specific data access mapping;application programming interfaces apis;data access pattern;gpgpu;multicore	Large, complex scientific and engineering application code have a significant investment in computational kernels to implement their mathematical models. Porting these computational kernels to the collection of modern manycore accelerator devices is a major challenge in that these devices have diverse programming models, application programming interfaces APIs, and performance requirements. The Kokkos Array programming model provides library-based approach to implement computational kernels that are performance-portable to CPU-multicore and GPGPU accelerator devices. This programming model is based upon three fundamental concepts: 1 manycore compute devices each with its own memory space, 2 data parallel kernels and 3 multidimensional arrays. Kernel execution performance is, especially for NVIDIA® devices, extremely dependent on data access patterns. Optimal data access pattern can be different for different manycore devices --potentially leading to different implementations of computational kernels specialized for different devices. The Kokkos Array programming model supports performance-portable kernels by 1 separating data access patterns from computational kernels through a multidimensional array API and 2 introduce device-specific data access mappings when a kernel is compiled. An implementation of Kokkos Array is available through Trilinos [Trilinos website, http://trilinos.sandia.gov/, August 2011].	manycore processor;multi-core processor	H. Carter Edwards;Daniel Sunderland;Vicki Porter;Chris Amsler;Sam Mish	2012	Scientific Programming	10.3233/SPR-2012-0343	multi-core processor;computer architecture;parallel computing;computer science;theoretical computer science;operating system;general-purpose computing on graphics processing units	HPC	-5.3341571155480745	43.65496392195118	74938
26ea56def507029c1835922d06fdedd54fda2aa2	probabilistic communication optimizations and parallelization for distributed-memory systems	distributed memory;distributed memory systems;performance evaluation;optimization technique;performance evaluation fortran parallel languages distributed memory systems parallelising compilers;data analysis runtime concurrent computing optimizing compilers program processors computer languages data flow computing information analysis;parallelizing compilers;program optimization;parallelising compilers;fortran;communication optimization;data flow;parallel languages;high performance;hpf f90 probabilistic communication optimizations parallelization distributed memory systems high performance systems execution time optimization static program analysis runtime information probabilistic data flow frameworks representative profile runs high performance fortran probabilistic data flow information attributes vfc source to source parallelizing compiler	In high-performance systems execution time is of crucial importance justifying advanced optimization techniques. Traditionally, optimization is based on static program analysis. The quality of program optimizations, however, can be substantially improved by utilizing runtime information. Probabilistic data-flow frameworks compute the probability with what data-flow facts may hold at some program point based on representative profile runs. Advanced optimizations can use this information in order to produce highly efficient code. In this paper we introduce a novel optimization technique in the context of High Performance Fortran (HPF) that is based on probabilistic data-flow information. We consider statically undefined attributes which play an important role for parallelization and compute for those attributes the probabilities to hold some specific value during runtime. For the most probable attribute values highly-optimized, specialized code is generated. In this way significantly better performance results can be achieved. The implementation of our optimization is done in the context of VFC, a source-to-source parallelizing compiler for HPF/F90.	automatic parallelization;compiler;data-flow analysis;dataflow;distributed memory;feature connector;high performance fortran;mathematical optimization;parallel computing;program optimization;run time (program lifecycle phase);static program analysis;undefined behavior	Eduard Mehofer;Bernhard Scholz	2001		10.1109/EMPDP.2001.905042	computer architecture;parallel computing;profile-guided optimization;computer science;programming language	PL	-15.20768760555601	36.940495740785785	74957
3c7a9ecfb712587d0741ef65997fb1d93ababf8a	online adaptive code generation and tuning	libraries;optimising compilers;parallel programming optimising compilers;paper;just in time compilation;online adaptive code generation;code generation;parallel programming;runtime;servers;parallelism;just in time compiler;tuning;active harmony;adaptive coding;auto tuner;hpc platform;tuning framework;face;optimization;computer science;parallel programs;code variant;tuning optimization runtime servers libraries educational institutions face;parallel program;tunable parameter;parallel applications;code variant online adaptive code generation runtime compilation tuning framework parallel program auto tuner active harmony tunable parameter optimization just in time compilation parallelism hpc platform;runtime compilation	In this paper, we present a runtime compilation and tuning framework for parallel programs. We extend our prior work on our auto-tuner, Active Harmony, for tunable parameters that require code generation (for example, different unroll factors). For such parameters, our auto-tuner generates and compiles new code on-the-fly. Effectively, we merge traditional feedback directed optimization and just-in-time compilation. We show that our system can leverage available parallelism in today's HPC platforms by evaluating different code-variants on different nodes simultaneously. We evaluate our system on two parallel applications and show that our system can improve runtime execution by up to 46% compared to the original version of the program.	code generation (compiler);compiler;just-in-time compilation;mathematical optimization;parallel computing;pitch correction;profile-guided optimization;tv tuner card	Ananta Tiwari;Jeffrey K. Hollingsworth	2011	2011 IEEE International Parallel & Distributed Processing Symposium	10.1109/IPDPS.2011.86	computer architecture;parallel computing;real-time computing;computer science;operating system;just-in-time compilation;distributed computing;programming language	HPC	-6.643117465782548	45.820657993140706	74967
914619e9cfaeb243a2da4c8661b749b1dab3d8ba	the implementation of ab initio quantum chemistry calculations on transputers	parallel computer;high efficiency;quantum chemistry	The RHF and geometry optimization sections of the ab initio quantum chemistry code, GAMESS, have been optimized for a network of parallel microprocessors, Inmos T800-20 transputers, using both indirect and direct SCF techniques. The results indicate great scope for implementation of such codes on small parallel computer systems, very high efficiencies having been achieved, particularly in the cases of direct SCF and geometry optimization with large basis sets. The work, although performed upon one particular parallel system, the Meiko Computing Surface, is applicable to a wide range of parallel systems with both shared and distributed memory.	basis set (chemistry);code;computer systems;distributed memory;efficiency;energy minimization;gamess (us);mathematical optimization;microprocessor;organic chemistry phenomena;parallel computing;transputer	Matthew D. Cooper;Ian H. Hillier	1991	Journal of computer-aided molecular design	10.1007/BF00124337	computational science;chemistry;computer science;theoretical computer science;computational chemistry;quantum chemistry	HPC	-4.832470520914932	37.30934917493189	75084
2716fb81fed410d8e4c5504ed55fca135187c807	optimal implementation of wait-free binary relations	shared memory;generic algorithm;binary relation;parallel languages	"""In this article we derive an algorithm for computing the \optimal"""" wait-free program on two processors that implements a given relation from the semantics of a small atomic read/write shared-memory parallel language. This algorithm is compared with the more general algorithm given in 8, 12] based on the participated set algorithm of 1]. An extension to this is given, where we add a test&set primitive to the previous language. This work is a natural follow up of 6]."""	central processing unit;non-blocking algorithm;parallel language;shared memory;test-and-set	Eric Goubault	1997		10.1007/BFb0030599	distributed shared memory;parallel computing;computer science;theoretical computer science;self-balancing binary search tree;distributed computing	Theory	-15.120519908909857	46.132801914562	75171
abac566b8adca82962b81ca7b8439812489640f1	mesh partitioning for computational grids	minimisation;finite element methods;minimization;computational grid;concurrent computing;mesh partitioning;cost function;application software;heterogeneous computing;computer applications;application execution time;computer networks;computational modeling;graph partitioning;partition quality mesh partitioning computational grids heterogeneous networks pagrid multilevel graph partitioning minimization application execution time;load management;communication cost;multilevel graph partitioning;pagrid;load balance;partition quality;computational grids;computer science;grid computing application software load management computational modeling cost function concurrent computing computer applications computer science computer networks finite element methods;mesh generation;grid computing;heterogeneous networks;heterogeneous network;grid computing minimisation mesh generation	Computational grids, with a collection of heterogeneous resources connected by heterogeneous networks, are being developed globally. Efficient partitioning of applications to exploit such grids is becoming an emerging area of research. Recent work in our group led to the creation of the PaGrid, an application that partitions meshes onto grids. The first version of PaGrid used a multilevel graph partitioning approach, with refinement based on minimization of total communication cost, augmented by execution time load balancing in the final uncoarsening phase. PaGrid was found to produce significantly better partitions for two models of heterogeneous computational grids, compared to two other partitioners, JOSTLE and METIS. In the present work we have redesigned PaGrid to minimize the estimated application execution time in all refinement levels of the multilevel scheme. This has led to significant improvements in partition quality.	computation;graph partition;load balancing (computing);metis;refinement (computing);run time (program lifecycle phase);semantic network	Renaud Wanschoor;Eric E. Aubanel	2004	Proceedings. Second Annual Conference on Communication Networks and Services Research, 2004.	10.1109/DNSR.2004.1344745	parallel computing;heterogeneous network;concurrent computing;computer science;theoretical computer science;operating system;distributed computing;computer network	HPC	-6.342399676852923	40.630045709961216	75191
3b35e216176cf511f1f006802fcc52e624a730c6	parallel multigrid summation for the n-body problem	distributed system;algoritmo paralelo;electrostatique;electrostatics;systeme reparti;parallel algorithm;shared memory;protocole transmission;electroestatica;problema n cuerpos;memoria compartida;communicating process;n body problem;distributed computing;multigrille;molecular dynamics;fast electrostatic solvers;probleme n corps;particle mesh ewald;periodic boundary condition;algorithme parallele;dynamique moleculaire;proceso comunicante;protocolo transmision;sistema repartido;parallel n body solvers;multigrid summation;envoi message;processus communicant;multigrid;multigrilla;message passing;calculo repartido;molecular dynamic;parallel implementation;dinamica molecular;calcul reparti;memoire partagee;open source;transmission protocol	An Θ(n) parallel multigrid summation method for the N -body problem is presented. The method works with vacuum or periodic boundary conditions. It is based on a hierarchical decomposition of computational kernels on multiple grids. For low accuracy calculations, appropriate for molecular dynamics, a sequential implementation is faster than both Fast Multipole and Particle Mesh Ewald (PME). Its parallel implementation is more scalable than PME and comparable to the fast multipole. The method can be combined with multiple time stepping integrators to produce a powerful simulation protocol for simulation of biological molecules and other materials. The parallel implementation is based on MPI, and is tested in a variety of clusters and shared memory computers. It is available as open-source in http://protomol.sourceforge.net. An auxiliary tool allows the automatic selection of optimal parameters for given molecular systems and accuracies required, and is available in http://mdsimaid.cse.nd.edu.	computer;ewald summation;message passing interface;molecular dynamics;multigrid method;n-body problem;numerical methods for ordinary differential equations;open-source software;particle mesh;periodic boundary conditions;scalability;shared memory;simulation;sourceforge;stepping level	Jesús A. Izaguirre;Scott S. Hampton;Thierry Matthey	2005	J. Parallel Distrib. Comput.	10.1016/j.jpdc.2005.03.006	shared memory;molecular dynamics;parallel computing;message passing;computer science;theoretical computer science;n-body problem;distributed computing;parallel algorithm;periodic boundary conditions;algorithm;multigrid method	HPC	-4.716550330497029	36.33180013969018	75294
2d0471a2ce9c5943f898c10d6c3039f01c50f0a4	functional pearl: a sql to c compiler in 500 lines of code	staging;sql;query compilation;futamura projections;generative programming	We present the design and implementation of a SQL query processor that outperforms existing database systems and is written in just about 500 lines of Scala code -- a convincing case study that high-level functional programming can handily beat C for systems-level programming where the last drop of performance matters. The key enabler is a shift in perspective towards generative programming. The core of the query engine is an interpreter for relational algebra operations, written in Scala. Using the open-source LMS Framework (Lightweight Modular Staging), we turn this interpreter into a query compiler with very low effort. To do so, we capitalize on an old and widely known result from partial evaluation known as Futamura projections, which state that a program that can specialize an interpreter to any given input program is equivalent to a compiler. In this pearl, we discuss LMS programming patterns such as mixed-stage data structures (e.g. data records with static schema and dynamic field components) and techniques to generate low-level C code, including specialized data structures and data loading primitives.	automatic programming;compiler;computer programming;data structure;database;disk staging;functional programming;high- and low-level;open-source software;partial evaluation;relational algebra;sql;scala;select (sql);source lines of code	Tiark Rompf;Nada Amin	2015		10.1145/2784731.2784760	sql;computer science;query by example;theoretical computer science;database;programming language	PL	-18.58959246365851	34.70246861812382	75443
8b782fc933d6c918ad8efe246405fb1b829bda15	process migration as an aid to tuning embedded systems	process migration;embedded system		embedded system;process migration	P. Burgess;Mike Livesey;Colin Allison	1993			theoretical computer science;process migration;computer science	EDA	-10.232823128593413	43.934624062986984	75451
4cc92a001a98c92406de77ba3d3f74002480acb5	big data processing: is there a framework suitable for economists and statisticians?		The emerging wave of Big Data applications is flooding all branches of scientific knowledge. Economic and statistical applied research carried out in central banks and policy advising institutions is no exception. In this paper we present one of the most promising platform providing a unifying framework for different researchers willing to harness their knowledge of popular and simple computing environment such as R and Python. Along with their Integrated Development Environment (IDE), these are two of the most used numerical computing framework which are open source, provide built-in capabilities for statistical analysis and include a wide array of user contributed packages for an ample set of analytical tools suitable for different scientific applications. In the Big Data framework, we show how to provide researchers with a suitable programming environment allowing them to tame the intrinsic complexity of a High Performance Computing Cluster. Here we provide few empirical applications based on classical econometric and machine learning modeling.	big data;canonical account;computer cluster;integrated development environment;machine learning;numerical analysis;open-source software;python;r language;tame	Giuseppe Bruno;Demetrio Condello;Alberto Falzone;Andrea Luciani	2017	2017 IEEE International Conference on Big Data (Big Data)	10.1109/BigData.2017.8258446	data mining;software;computer science;python (programming language);big data;applied research;sociology of scientific knowledge;development environment;supercomputer	HPC	-8.53597731121918	39.71641705311167	75665
1877a4b8be5237d7385637e8c6ecb591f835f253	a code motion technique for accelerating general-purpose computation on the gpu	computer languages;paper;perforation;computer graphics;distributed programming assembly language computer graphic equipment coprocessors;computer graphic equipment;gpu;acceleration graphics pipelines hardware high performance computing engines assembly central processing unit application software clustering algorithms;coprocessors;general purpose computation acceleration;fragment processors;nvidia geforce 6800;programming techniques;fragment processors code motion general purpose computation acceleration gpu graphics processing units vertex processors;assembly language;distributed programming;graphics processing units;nvidia;graphic processing unit;vertex processors;opengl;code motion;computer science	Graphics processing units (GPUs) are providing increasingly higher performance with programmable internal processors, namely vertex processors (VPs) and fragment processors (FPs). Such newly added capabilities motivate us to perform general-purpose computation on GPUs (GPGPU) beyond graphics applications. Although VPs and FPs are connected in a pipeline, many GPGPU implementations utilize only FPs as a computational engine in the GPU. Therefore, such implementations may result in lower performance due to highly loaded FPs (as compared to VPs) being a performance bottleneck in the pipeline execution. The objective of our work is to improve the performance of GPGPU programs by eliminating this bottleneck. To achieve this, we present a code motion technique that is capable of reducing the FP workload by moving assembly instructions appropriately from the FP program to the VP program. We also present the definition of such movable instructions that do not change the I/O specification between the CPU and the GPU. The experimental results show that (1) our technique improves the performance of a Gaussian filter program with reducing execution time by approximately 40% and (2) it successfully reduces the FP workload in 10 out of 18 GPGPU programs	central processing unit;compiler;computation;filter (software);gaussian blur;general-purpose computing on graphics processing units;general-purpose markup language;graphics processing unit;high- and low-level;input/output;loop-invariant code motion;mathematical optimization;norm (social);run time (program lifecycle phase)	T. Ikeda;Fumihiko Ino;Kenichi Hagihara	2006	Proceedings 20th IEEE International Parallel & Distributed Processing Symposium	10.1109/IPDPS.2006.1639323	computer architecture;parallel computing;computer hardware;computer science;operating system;distributed computing;programming language;computer graphics;coprocessor;assembly language	Arch	-6.064029204479626	43.975123415110325	75694
f9b78c93bcdf54a8466fa15cc9d194748cd9acfa	an effective load balancing scheme for 3d texture-based sort-last parallel volume rendering on gpu clusters	workload;bsp tree;parallelisme;agregacion;cluster algorithm;data parallel;evaluation performance;carga dinamica;texture;parallel rendering;tecnologia electronica telecomunicaciones;octree;hierarchical data structure;performance evaluation;octarbol;visualizacion;hierarchized structure;volume rendering;equilibrio de carga;evaluacion prestacion;gain;equilibrage charge;octarbre;hierarchical visualization;structure hierarchisee;adaptive dynamics;charge dynamique;dynamic load;aggregation;algorithme;algorithm;visualization;parallelism;paralelismo;visualisation;arbol binario;transfer function;funcion traspaso;estructura datos;arbre binaire;signal classification;textura;performance analysis;charge travail;load balancing;pc cluster;agregation;classification signal;fonction transfert;structure donnee;load balance;image compositing;classification automatique;ganancia;tecnologias;carga trabajo;grupo a;automatic classification;clasificacion automatica;data structure;estructura jerarquizada;adaptive dynamic load balancing;algoritmo;binary tree	We present an adaptive dynamic load balancing scheme for 3D texture based sort-last parallel volume rendering on a PC cluster equipped with GPUs. Our scheme exploits not only task parallelism but also data parallelism during rendering by combining the hierarchical data structures (octree and parallel BSP tree) in order to skip empty regions and distribute proper workloads to rendering nodes. Our scheme can also conduct a valid parallel rendering and image compositing in visibility order by employing a 3D clustering algorithm. To alleviate the imbalance when the transfer function is changed, a load rebalancing is inexpensively supported by exchanging only needed data. A detailed performance analysis is provided and scaling characteristics of our scheme are discussed. These show that our scheme can achieve the significant performance gains by increasing parallelism and decreasing synchronizing costs compared to the traditional static distribution schemes. key words: octree, BSP tree, hierarchical visualization, parallel rendering, volume rendering, adaptive dynamic load balancing	algorithm;binary space partitioning;cluster analysis;compositing;computer cluster;data parallelism;data structure;graphics processing unit;hierarchical database model;image scaling;load balancing (computing);octree;order by;parallel computing;parallel rendering;profiling (computer programming);task parallelism;texture mapping;transfer function;volume rendering	Won-Jong Lee;Vason P. Srini;Woo-Chan Park;Shigeru Muraki;Tack-Don Han	2008	IEICE Transactions	10.1093/ietisy/e91-d.3.846	parallel computing;real-time computing;visualization;data structure;computer science;load balancing;operating system;data parallelism;programming language;computer security;algorithm;computer graphics (images)	HPC	-15.96824604625004	42.654435982496594	75959
4900ee48727d8f221ca186e730a6a7919283a9cf	hardware implementation of dynamic load balancing in the parallel inference machine pim/c			load balancing (computing)	Takayuki Nakagawa;Noriyasu Ido;Toshiaki Tarui;Machiko Asaie;Mamoru Sugie	1992			real-time computing;parallel computing;computer science;inference;dynamic load testing;distributed computing	HPC	-10.028538029150246	42.584780817431046	76025
06787b5a871126df029428e86df52311b0b60b26	parallel implementation of tree skeletons	modelizacion;systeme unix;base donnee repartie;distributed database;automatic proving;algorithmique;systeme multiprocesseur memoire repartie;complexite calcul;programacion paralela;implementation;unix system;base repartida dato;parallel programming;demostracion automatica;data type;homomorphism;algebraically construction;modelisation;demonstration automatique;ejecucion;complejidad computacion;estudio caso;algorithmics;algoritmica;arbol binario;computational complexity;sistema multiprocesador memoria distribuida;arbre binaire;homomorphisme;etude cas;parallel implementation;systeme parallele;distributed memory multiprocessor system;sistema unix;parallel system;homomorfismo;modeling;sistema paralelo;tree skeleton;programmation parallele;binary tree	Trees are a useful data type, but they are not routinely included in parallel programming systems because their irregular structure makes them seem hard to compute with e ciently. We present a method for constructing implementations of skeletons, high-level homomorphic operations on trees, that execute in parallel. In particular, we consider the case where the size of the tree is much larger than the the number of processors available, so that tree data must be partitioned. The approach uses the theory of categorical data types to derive implementation templates based on tree contraction. Many useful tree operations can be computed in time logarithmic in the size of their argument, on a wide range of parallel systems.	archive;categorical variable;central processing unit;code generation (compiler);compiler;data structure;high- and low-level;mathematical optimization;parallel computing;path expression;structured text	David B. Skillicorn	1996	J. Parallel Distrib. Comput.	10.1006/jpdc.1996.0160	homomorphism;parallel computing;systems modeling;data type;binary tree;computer science;theoretical computer science;operating system;distributed computing;weight-balanced tree;programming language;computational complexity theory;implementation;algorithmics;distributed database;algorithm	PL	-16.25749477028356	41.51014792926914	76070
69c6ad3d076aba4654e903d2191056a1312ff484	parallel simulation of 3d incompressible flows and performance comparison for several mpp and cluster platforms	distributed memory;evaluation performance;shared memory;performance evaluation;modelo 3 dimensiones;memoria compartida;modele 3 dimensions;evaluacion prestacion;simulacion numerica;performance comparison;three dimensional model;paralelisacion;viscous fluid;fluide visqueux;computer architecture;architecture ordinateur;incompressible flow;fluido viscoso;parallelisation;simulation numerique;parallelization;arquitectura ordenador;systeme parallele;parallel system;memoire repartie;incompressible viscous flow;sistema paralelo;parallel simulation;memoire partagee;numerical simulation	This paper describes a parallelization method for the numerical simulation of 3D incompressible viscous flow in a cylindrical domain. Implementation details are discussed for efficient parallelization on distributed memory computers with relatively slow communication links. The developed parallel code is used for the performance evaluation of several computers of different architectures, with the number of processors used from 1 to 16. The obtained results are compared to the measured computational and communication characteristics of these computers.		Oleg Bessonov;Dominique Fougère;Bernard Roux	2001		10.1007/3-540-44743-1_41	computer simulation;shared memory;viscous liquid;parallel computing;simulation;distributed memory;computer science;theoretical computer science;incompressible flow	HPC	-4.9841273145952725	36.78023953235436	76207
108d6b389a0b2bcb60b85181d7dbc946f580385a	array language support for parallel sparse computation	parallel computing;sparse array;indexation;performance model;parallel computer;mpi;parallel language;sparse matrix;nas parallel benchmarks;advanced zpl;parallel languages;data structure	This paper describes an array-based language-level approach to parallel sparse computation. Our approach is unique due to its separation of sparse index sets from arrays, both syntactically and in the implementation. This design allows users to express their computation using dense array syntax, making the code easier for readers to understand and for compilers to parallelize and optimize. This work is done within the context of Advanced ZPL, retaining its crisp syntax and source-level performance model. Our implementation uses a novel sparse storage format that supports general operations such as arbitrary iteration and slicing. We describe how our compiler automatically optimizes this data structure in to more compact forms based on the operations required by the program. We demonstrate our approach using the NAS CG and MG benchmarks, comparing our implementations with the original Fortran+MPI versions in terms of clarity and performance. We present performance results on the Cray T3E indicating that our implementation compares favorably to the hand-coded NAS versions in terms of memory requirements and often surpasses them in terms of execution speed.	cg (programming language);compiler;computation;cray t3e;data structure;database index;iteration;mg (editor);requirement;sparse matrix;zpl	Bradford L. Chamberlain;Lawrence Snyder	2001		10.1145/377792.377820	parallel computing;data structure;sparse matrix;computer science;message passing interface;theoretical computer science;operating system;programming language;sparse array	HPC	-12.291391338134082	37.01246682806642	76691
81d84eb072236eddfe7b7b82b7b8da415ba5baec	warped: time warp simulation kernel for analysis and application development	application development;time warp;optimisation;comparative analysis;shared memory;microcomputer applications time warp simulation discrete event simulation development systems optimisation message passing synchronisation application program interfaces shared memory systems parallel algorithms;synchronisation;shared memory systems;message passing interface;dynamic simulation parameter adjustment warped time warp simulation kernel application development configurable environment time warp optimizations c mpi standard message passing interface shared memory sun workstation network sun smp workstation ibm sp1 sp2 multiprocessors intel paragon ibm compatible pcs linux sequential kernel implementation comparative analysis logical process clustering;application program interfaces;message passing;time warp simulation kernel sun workstations standards development design optimization message passing communication standards personal communication networks linux;development systems;time warp simulation;microcomputer applications;logical process;discrete event simulation;parallel algorithms	WARPED is a publically available Time Warp simulation kernel for experimentation and application development. The kernel defines a standard interface to the application developer and is designed to provide a highly configurable environment for the integration of Time Warp optimizations. It is written in C-t+, uses the MPI message passing standard and shared memory for communication, and executes on a variety of platforms including a network of SUN workstations, a SUN SMP workstation, the IBM SPl/SPb multiprocessors, the Intel Paragon, and IBM compatible PCs running Linux. WARPED is distributed with several applications and includes a sequential kernel implementation for comparative analysis. The kernel supports LP clustering, various Time Warp algorithms, and several optimizations that dynamically adjust simulation parameters.	algorithm;cluster analysis;dynamic time warping;ibm pc compatible;intel paragon;kernel (operating system);linux;message passing;qualitative comparative analysis;shared memory;simulation;symmetric multiprocessing;workstation	Dale E. Martin;Timothy J. McBrayer;Philip A. Wilsey	1996		10.1109/HICSS.1996.495485	shared memory;qualitative comparative analysis;synchronization;parallel computing;message passing;real-time computing;computer science;message passing interface;discrete event simulation;operating system;parallel algorithm;rapid application development;configfs	HPC	-11.279772312606777	44.82551797274812	76701
ca3c4c517b879f4c6dd8948cb6a472730b92185d	integrated range comparison for data-parallel compilation systems	program evaluation compilation parallel programming restructuring compilation parallel performance range comparison data parallel programming;data parallel;parallel performance;performance evaluation;software prototyping;software performance evaluation parallel programming parallelising compilers;prototypes;parallelizing compilers;software performance evaluation;software systems;parallel programming;parallel compiler;scalability performance analysis parallel processing parallel programming sun parallel machines memory architecture message passing software prototyping prototypes;indexing terms;program evaluation;scalable computing;scaling up;restructuring compilation;range comparison;memory architecture;parallelising compilers;performance analysis;sun;message passing;compilation;data parallel programming;parallel machines;fortran;scalability;parallel programs;parallel processing	A major diiculty in restructuring compilation and in parallel programming in general is how to compare parallel performance over a range of system and problem sizes. Execution time varies with system and problem size, and an initially fast implementation may become slow when system and problem size scale up. This paper introduces the concept of range comparison. Unlike conventional execution time comparison in which performance is compared for a particular system and problem size, range comparison compares the performance of programs over a range of ensemble and problem sizes via scalability and performance crossing point analysis. A novel algorithm is developed to predict the crossing point automatically. The correctness of the algorithm is proved and a methodology is developed to integrate range comparison into restructuring compilations for data-parallel programming. A preliminary prototype of the methodology is implemented and tested under Vienna Fortran Compilation System. Experimental results demonstrate that range comparison is feasible and eeective. It is an important asset for program evaluation, restructuring compilation, and parallel programming.	algorithm;analysis of algorithms;compiler;correctness (computer science);fortran;parallel computing;prototype;run time (program lifecycle phase);scalability	Xian-He Sun;Mario Pantano;Thomas Fahringer	1999	IEEE Trans. Parallel Distrib. Syst.	10.1109/71.770134	parallel processing;computer architecture;parallel computing;message passing;scalability;index term;program evaluation;computer science;operating system;distributed computing;prototype;programming language;software system	HPC	-11.78896197552995	38.2376036878629	77051
d16371c1106aa242384840d566101412208a5ac4	automatic source-to-source error compensation of floating-point programs	libraries;silicon;electronic mail;program transformation;system recovery error compensation floating point arithmetic program compilers;algorithm design and analysis libraries optimization parallel processing error compensation electronic mail silicon;error compensation;error compensation program transformation;optimization;algorithm design and analysis;parallel processing;source code transformation automatic source to source error compensation floating point programs numerical programs ieee 754 floating point computation finite precision arithmetic numerical quality	Numerical programs with IEEE 754 floating-point computations may suffer from inaccuracies since finite precision arithmetic is an approximation of real arithmetic. Solutions that reduce the loss of accuracy are available as, for instance, compensated algorithms, more precise computation with double-double or similar libraries. Our objective is to automatically improve the numerical quality of a numerical program with the smallest impact on its performance. We define and implement source code transformation to derive automatically compensated programs. We present several experimental results to compare the transformed programs and existing solutions. The transformed programs are as accurate and efficient as the implementations of compensated algorithms when the latter exist.	algorithm;approximation;arithmetic logic unit;computation;elementary function;gnu compiler collection;genetic algorithm;library (computing);mathematical optimization;numerical analysis;numerical linear algebra;overhead (computing);program optimization;program transformation;run time (program lifecycle phase)	Laurent Thévenoux;Philippe Langlois;Matthieu Martel	2015	2015 IEEE 18th International Conference on Computational Science and Engineering	10.1109/CSE.2015.11	parallel processing;algorithm design;parallel computing;real-time computing;computer science;theoretical computer science;silicon	Embedded	-14.465983289590477	36.30223579289225	77152
da04d88e4775c5bb3012f56a91cac5b4261390e3	"""corrections to """"time dependent processing in a parallel pipeline architecture'"""	communication system traffic control;time dependent;software libraries;computer graphics;information filtering;pipelines;data visualization;information filters		pipeline (computing)	John Biddiscombe;Berk Geveci;Ken Martin;Kenneth Moreland;David S. Thompson	2008	IEEE Trans. Vis. Comput. Graph.	10.1109/TVCG.2008.3	real-time computing;computer science;theoretical computer science;distributed computing;pipeline transport;computer graphics;data visualization;statistics	Arch	-4.671620964770287	32.359280644600084	77319
20ca53144ee880e7d26d16265b7e2d8ed9382e50	terminal response times in data communications systems	front end;response time analysis;data communication;system design;synchronous communication;data link control	A response time analysis for a general class of terminals-to-computer subsystem is presented in this paper. The model used is based on the most advanced data communications system in which terminals are connected to Terminal Control Units (TCU) that are in turn connected to local Front-End Processors (FEP). The line control procedures used to interface a TCU and an FEP may be half-duplex Binary Synchronous Communications (BSC) , half-duplex Synchronous Data Link Control (SDLC), or full-duplex SDLC. The models presented here can be used to determine bottlenecks in the entire system and to facilitate the initial phase of system design and configuration. Introduction A generic configuration of data communications systems consists of many components such as terminals, Terminal Controller Units (TCU) , communications lines, remote as well as local Front-End Processors (FEP) , host processors, and auxiliary storage devices (see Fig. 1 ) . Each one of these components has its own specifications and operating characteristics in terms of data rate, transmission media, and functional capabilities. One of the key factors in design and evaluation of such systems is the calculation of terminal response time, which can be defined as the time interval from the operator’s pressing the last key (send key) of the input to the terminal’s typing or displaying the first character of the response. Systems differ widely in their response time requirements, and the response time needed can, in turn, have a major effect on the design of the data transmission network and the data processing facilities. This paper presents the development of an analytical framework for analyzing response time requirements of data communications systems. The terminal response time as defined above is the totality of several time elements. At the time when the send key is depressed, the complete transaction has already been stored at a prespecified buffer area in the TCU, one for each terminal. Transactions stored at their terminal buffers cannot be transmitted to the host site until the particular TCU at which these transactions reside is polled by the local FEP in accordance with a given polling list. The time spent by a transaction waiting for polling is the first time element to be calculated in obtaining the total terminal response time. This element depends on the system configuration and line pro272 cedures. The time r quired for t ansaction transmission I . H. CHANG along communications lines is relatively easy to calculate once we know the length of a transaction and the line speed. When a transaction arrives at an FEP, certain delays may occur because this is where most communications functions are performed. In case the FEP is a simple control unit whose only function is character assembly and disassembly, such delay would be negligible. After the whole transaction has entered the host processor, its processing time depends on the application programs, CPU processing speed, operating system, access methods, and the characteristics of the auxiliary storage devices such as disk files. A completely processed transaction will then wait at the FEP until the addressed line and TCU are ready to receive their responses. The length of this waiting time can generally be analyzed by an approximate queuing model. Readers familiar with teleprocessing systems are aware of the fact that there are many different variations in system configurations and operations. The connection between the TCU and FEPs may be in the form of loops, stars, or multi-drops. The mode of transmission may be half-duplex or full-duplex with different line control procedures such as Binary Synchronous Communications (BSC) and Synchronous Data Link Controls (SDLC). After an inquiry has been sent to the host site for processing, the whole communication path may be held throughout the entire question-answering period, or the sending terminal may release the communication path, in whole or in part, so that other terminals and TCUs can send and receive their transactions. It is assumed in this paper that a terminal will release its line after its transaction is keyed in, and that several TCUs share the same high speed line in a multi-drop fashion to I B M J . RES. DEVELOP. communicate with the local FEPs. However, both the half-duplex and full-duplex modes can be accommodated by the analysis. In a recent survey paper, Green and Tang I ] discussed in depth the state of the art in using analytical models to design terminal-oriented systems. They divided the whole design and configuration process into two parts: the network models and the host models. Various problem areas and the progress to date were summarized. It was indicated that there has been no overall treatment of complete computer communications systems that would allow one to carry out the configuration process, taking into account details of the various transactions within the system. To the best knowledge of the author, the present paper represents the first attempt to bridge the gap between, on the one hand, buffered terminals with terminal cluster controllers and line control in the network models, and, on the other hand, CPU models, file accessing, and front-end processor analysis in the host models. The models presented here can be used to determine bottlenecks in the entire system and to facilitate the initial phase of system design and configuration. Polling cycle analysis Polling and operations in u polling cycle Under normal operating conditions several terminals as well as several TCUs may be prepared to transmit transactions at the same time from remote locations to the host site. Only one can do so, and the others must wait their turns. To organize this, the line will normally be polled. For cases where terminals are controlled by the TCUs, as assumed in our model, transactions are sent to the controller at will and accumulated there so that only the TCUs need to be polled. In other cases, terminals are polled individually. Normally the local FEP (if any) or the host processor organizes the polling. In the main memory there is a polling list telling the programs the sequence in which to poll the TCUs or terminals. The polling list and its use therefore determine the priorities with which the remote devices are scanned. There are several major time elements that constitute a polling cycle, and these include transaction transmission time, the time for either an unsuccessful (negative) or a successful (positive) poll and the associated acknowledgment. Except for the first item, all other elements depend to a great extent on the line control procedures employed by the system. Two such procedures are considered in our model: the Binary Synchronous Communications (BSC) and the Synchronous Data Link Controls (SDLC) . Without going into details (see, for example, [ 21 and [ 3 ] ) , some of the differences between these are that BSC can be used only for half-du-	acknowledgment index;approximation algorithm;auxiliary memory;binary symmetric channel;bottleneck (software);central processing unit;computer data storage;control flow;data rate units;develop;disassembler;duplex (telecommunications);front-end processor;image processing;line level;modulation;multidrop bus;operating system;polling (computer science);question answering;queueing theory;requirement;response time (technology);synchronous data link control;system configuration;systems design;telecommunication control unit;terminal emulator;web hosting service	John H. Chang	1975	IBM Journal of Research and Development	10.1147/rd.193.0272	data link control;embedded system;real-time computing;telecommunications;computer science;engineering;electrical engineering;front and back ends;asynchronous communication;systems design	Embedded	-14.085347532525969	33.14629858263679	77456
7070b9b121499070249e6cb0a51a4380dfe5add4	blue gene/l programming and operating environment		programming and operating environment J. E. Moreira G. Almási C. Archer R. Bellofatto P. Bergner J. R. Brunheroto M. Brutman J. G. Castaños P. G. Crumley M. Gupta T. Inglett D. Lieber D. Limpert P. McCarthy M. Megerian M. Mendell M. Mundy D. Reed R. K. Sahoo A. Sanomiya R. Shok B. Smith G. G. Stewart With up to 65,536 compute nodes and a peak performance of more than 360 teraflops, the Blue Genet/L (BG/L) supercomputer represents a new level of massively parallel systems. The system software stack for BG/L creates a programming and operating environment that harnesses the raw power of this architecture with great effectiveness. The design and implementation of this environment followed three major principles: simplicity, performance, and familiarity. By specializing the services provided by each component of the system architecture, we were able to keep each one simple and leverage the BG/L hardware features to deliver high performance to applications. We also implemented standard programming interfaces and programming languages that greatly simplified the job of porting applications to BG/L. The effectiveness of our approach has been demonstrated by the operational success of several prototype and production machines, which have already been scaled to 16,384 nodes.	audio control surface;benchmark (computing);blue gene;flops;fortran;input/output;integrated development environment;job control (unix);library (computing);operating environment;programmer;programming language;prototype;scalability;software architecture;supercomputer;systems architecture;taito l system	José E. Moreira;George Almási;Charles Archer;Ralph Bellofatto;Peter Bergner;José R. Brunheroto;Michael Brutman;José G. Castaños;Paul Crumley;Manish Gupta;Todd Inglett;Derek Lieber;David Limpert;Patrick McCarthy;Mark Megerian;Mark P. Mendell;Michael Mundy;Don Reed;Ramendra K. Sahoo;Alda Sanomiya	2005	IBM Journal of Research and Development	10.1147/rd.492.0367	real-time computing;computer hardware;computer science;operating system	HPC	-8.71771933481583	45.24507068790164	77490
200adc5e9ca486f6919bc194415cec28e986df2d	lightweigt causal and atomic group multicast	distribution;tolerancia falta;lightweight;message processing;environments;total order;multicast communication;fiabilidad;reliability;fault tolerant;sistema informatico;distributed processing;performance;fault tolerant process groups;distributed computing;distributed programs;communication and radio systems;transmission message;computer system;causal ordering;transport layer;group communication;message transmission;algorithme;computer programming;algorithm;protocol computers;transport;synchronism;applications programs computers;telecomunicacion;fiabilite;fault tolerance;telecommunication;systeme informatique;broadcasting;rendimiento;message ordering;tolerance faute;transmision mensaje;algoritmo;layers	The Isis toolkit is a distributed programming environment based on support for virtually synchronous process groups and group communication. We present a new suite of protocols in support of this model. Our approach revolves around a muiticast primitive, called CBCAST, which implements a fault-tolerant, causally ordered message delivery. This primitive can be used directly, or extended into a totally ordered multicast primitive, called ABCAST. It normally delivers messages immediately upon reception, and imposes a space overhead proportional to the size of the groups to which the sender belongs, usually a small number. We conclude that process groups and group communication can achieve performance and scaling comparable to that of a raw message transport layer a finding contradicting the widespread concern that this style of distributed computing may be unacceptably costly.	blocking (computing);causal filter;device driver;distributed computing;fifo (computing and electronics);fault tolerance;isis;image scaling;integrated development environment;multicast;overhead (computing);streaming media;virtual synchrony	Kenneth P. Birman;André Schiper;Pat Stephenson	1991	ACM Trans. Comput. Syst.	10.1145/128738.128742	embedded system;fault tolerance;real-time computing;computer science;operating system;distributed computing;computer network	Networks	-18.407357655404486	43.57402627697139	77561
edee200c5f80e2a02bc7387f84101c43d6420b64	exploiting data exchange patterns in creating objects for numa shared virtual memory systems	data exchange			Jayashree Ramanathan;Lionel M. Ni	1992			data diffusion machine;parallel computing;distributed computing;distributed shared memory;memory map;distributed memory;cache-only memory architecture;computer science;overlay;shared memory;uniform memory access	Arch	-10.515268041416554	43.93108881938929	77824
c7d3b2ed7dfc0ea8a9ac28f9ed66fcb18bd4bfbd	a type-based locality analysis for a functional distributed language	thesis or dissertation;distributed shared memory	 In this thesis we give a type-based analysis for an ML-like distributed languagethat detects references certain not to escape from one processor to another.We assume a model of distribution based on distributed shared memory. Fromthe programmer's viewpoint, the same reference on dierent machines refers tothe same data object in a single logical store, but data is in fact distributed amongthe machines. A coherency protocol is then responsible for determining for eachoperation with... 	distributed computing;locality of reference	Álvaro F. Moreira	2000			natural language processing;distributed shared memory;computer science;theoretical computer science;distributed computing	PL	-14.567336086087726	46.00975863732793	77894
be02e16f0eb5532d1eaad487e5cb92981aca9291	fast reductions on a network of workstations	network of workstations;global virtual time;high speed reductions;barrier synchronization;concurrent computing;termination detection;distributed computing;distributed snapshots;parallel programming;contracts;popular high performance computing platform;parallel and distributed computing;global virtual time computation;lan interconnection;parallel discrete event simulations;test facilities;innovative algorithms;springs;operating system;parallel discrete event simulation;workstations discrete event simulation distributed computing concurrent computing parallel programming hardware computer science test facilities springs contracts;workstations;network of workstation;high performance computer;performance requirements fast reductions network of workstations reduction operations distributed computing barrier synchronization distributed snapshots termination detection global virtual time computation parallel discrete event simulations adaptive synchronization algorithms popular high performance computing platform pentium pro pc linux operating system myrinet synchronization algorithms high speed reductions innovative algorithms;synchronization algorithms;multiprocessing systems;pentium pro pc;computer science;lan interconnection parallel programming parallel algorithms discrete event simulation workstations multiprocessing systems;adaptive synchronization algorithms;linux operating system;reduction operations;myrinet;performance requirements;high speed;fast reductions;hardware;discrete event simulation;parallel algorithms	Reduction operations are very useful in parallel and distributed computing, with applications in barr ier synchronization, distributed snapshots, termination detection, global virtual time computation, etc. In the context of parallel discrete-event simulations, we have previously introduced a class of adaptive synchronization algorithms based on fast reductions. Here, we explore the implementation of fast reductions on a popular high performance computing platform a network of workstations. The specifi c platform is a set of Pentium Pro PC's running the Linux operating system, interconnected by Myrinet a Gbps network. The general reduction model on which our synchronization algorithms are based is introduced first, followed by a description of how this model can be implemented. We discuss several design trade-offs that must be made in order to achieve the driving goal of high speed reductions and provide innovative algorithms to meet the correctness and performance requirements of the	algorithm;computation;computer cluster;correctness (computer science);data rate units;distributed computing;linux;operating system;parallel computing;requirement;simulation;supercomputer;workstation	Sudhir Srinivasan;Margaret J. Lyell;Jeff Wehrwein;Paul F. Reynolds	1997		10.1109/HIPC.1997.634531	parallel computing;real-time computing;workstation;concurrent computing;computer science;discrete event simulation;operating system;distributed computing;parallel algorithm	HPC	-9.640981927277977	41.52861805786054	78179
743cfa50f56b810a0219d12414331a011ba2928a	visualization of multi-layer i/o performance in vampir		Nowadays, high performance computing systems provide a wide range of storage technologies like HDDs, SSDs or network devices. With the introduction of NVRAM, these systems become more heterogenous and finally provide a complex I/O stack that is challenging to use for applications. However, parallel programs have to efficiently utilize available I/O resources to overcome the scalability problem. Typically, performance analysis tools focus on investigating computation efficiency, executed program paths, and communication patterns. However, these tools only visualize I/O performance information of single layers of the I/O stack. To fully understand the I/O behavior of an application, it is necessary to investigate the interaction between the layers. This work introduces new visualizations of I/O performance events and metrics throughout the complete I/O stack of parallel applications. We implement our approach on the basis of the performance analysis tool Vampir. We extend its timeline visualizations with performance details of I/O operations. Further, we introduce a new timeline view which depicts I/O activities on each layer of the used I/O stack as well as the interaction between layers. This view enables application developers to identify I/O bottlenecks across layers of a complicated I/O stack. We demonstrate our I/O performance visualization approach with a case study of a cloud model simulation code. Thereby, we analyze the I/O behavior in detail, including information of all involved multi-layered I/O libraries.	computation;input/output;library (computing);lustre;non-volatile random-access memory;profiling (computer programming);scalability;simulation;software developer;solid-state drive;supercomputer;timeline	Hartmut Mix;Christian Herold;Matthias Weber	2018	2018 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)	10.1109/IPDPSW.2018.00073	computer science;networking hardware;data visualization;parallel computing;distributed computing;visualization;scalability;cloud computing;software;input/output;supercomputer	HPC	-8.99082270550864	46.28667560987164	78191
432dde6efaf05fe3601fd1caac7b5c00e7575965	performance analysis of multilevel parallel applications on shared memory architectures	shared memory;performance evaluation;programming paradigm;graphical user interface;inspection;performance tests;computer programs;computer architecture;shared memory systems application program interfaces message passing performance evaluation graphical user interfaces;graphical user interfaces;shared memory systems;programming paradigms;application program interfaces;performance analysis;message passing;parallel processing computers;openmp;graphic user interface;reliability analysis;dynamic instrumentation;performance analysis memory architecture parallel processing hardware parallel programming computer architecture instruments application software message passing nasa;multilevel parallelism;architecture computers;computer systems performance;shared memory computer architectures performance analysis multilevel parallel applications shared memory architectures paraver ompitrace performance analysis system paraver graphical user interface benchmark code programming paradigms;memory computers;parallel applications	In this paper we describe how to apply powerful performance analysis techniques to understand the behavior of multilevel parallel applications. We use the Paraver/OMPltrace performance analysis system for our study. This system consists of two major components: The OMPItrace dynamic instrumentation mechanism, which allows the tracing of processes and threads and the Paraver graphical user interface for inspection and analyses of the generated traces. We describe how to use the system to conduct a detailed comparative study of a benchmark code implemented in five different programming paradigms applicable for shared memory	barrier (computer science);batch processing;benchmark (computing);code;graphical user interface;library (computing);message passing in computer clusters;openmp;operating system;overhead (computing);parallel computing;profiling (computer programming);programming paradigm;run time (program lifecycle phase);scalability;shared memory;synchronization (computer science);tracing (software)	Gabriele Jost;Haoqiang Jin;Jesús Labarta;Judit Giménez;Jordi Caubet	2003		10.1109/IPDPS.2003.1213183	computer architecture;parallel computing;computer science;theoretical computer science;operating system;graphical user interface;distributed computing;programming language	HPC	-11.809887894063746	43.622662142266556	78194
029b487fd54e958a4f5a26a198ac3e3e1c960bc5	mpi for big data	out of core;big data;distributed;high performance	The processing of massive amounts of data on clusters with finite amount of memory has become an important problem facing the parallel/distributed computing community. While MapReduce-style technologies provide an effective means for addressing various problems that fit within the MapReduce paradigm, there are many classes of problems for which this paradigm is ill-suited. In this paper we present a runtime system for traditional MPI programs that enables the efficient and transparent out-of-core execution of distributed-memory parallel programs. This system, called BDMPI, leverages the semantics of MPI’s API to orchestrate the execution of a large number of MPI processes on much fewer compute nodes, so that the running processes maximize the amount of computation that they perform with the data fetched from the disk. BDMPI enables the development of efficient out-of-core parallel distributed memory codes without the high engineering and algorithmic complexities associated with multiple levels of blocking. BDMPI achieves significantly better performance than existing technologies on a single node as well as on a small cluster, and performs within 30% of optimized out-of-core implementations. 2014 Published by Elsevier B.V.	apache hadoop;application programming interface;big data;blocking (computing);code;computation;computational complexity theory;distributed computing;distributed memory;experiment;mapreduce;message passing interface;out-of-core algorithm;programming paradigm;runtime system;workstation	Dominique LaSalle;George Karypis	2014	Parallel Computing	10.1016/j.parco.2014.07.003	programming with big data in r;parallel computing;real-time computing;out-of-core algorithm;big data;computer science;operating system;distributed computing	HPC	-4.906274585957156	42.932111570725326	78268
83a5e3371117e4557a691eebe5e46c68fd5c372e	scheduling and evaluation of sequential and parallel processes' interaction in a nondedicated cluster			computer cluster;scheduling (computing)	Adel Ben Mnaouer;Badriya Al-Riyami	2004			parallel computing;scheduling (computing);computer science;distributed computing	NLP	-9.72887704239293	42.99444064752008	78304
18b7f80d8f00c297558d59cf0c80a7de9b1aeaeb	dynamic multi-partitioning for parallel finite element applications	dynamic load balancing;crash simulation;multi phase multi constraint parititioning;finite element;parallel computer;message passing;load balance;cost model;multi phase multi constraint partitioning;parallel simulation;qa76 computer software	The DRAMA project 1 has been initiated to support the take-up of large scale parallel simulation in industry by dealing with the main problem which restricts the use of message passing simulation codes | the inability to perform dynamic load balancing. The central product of the project is a library comprising a variety of tools for dynamic repartitioning of unstructured Finite Element (FE) applications. The starting point for the DRAMA library is a discretisation mesh distribution into sub-domains that results in imbalanced costs of the application code. The core library functions then perform a parallel computation of a mesh re-allocation that will re-balance the costs based on the DRAMA cost model. We discuss the basic features of this cost model which allows a general approach to load identi cation, modelling and imbalance minimisation. First results are presented which show the necessity for multi-phase/multi-constraint partitioning components.	analysis of algorithms;code;computation;discretization;finite element method;library (computing);load balancing (computing);message passing;parallel computing;simulation	Achim Basermann;Jochen Fingberg;Guy Lonsdale;Bart Maerten;Chris Walshaw	1999	Parallel Computing	10.1016/S0167-8191(01)00072-2	parallel computing;message passing;simulation;computer science;load balancing;theoretical computer science;finite element method;distributed computing;programming language	HPC	-7.69363202658078	36.33216360661793	78359
0d89addbd0d0e723f3c1d9df9c1506f7a7cd0da8	linear performance-breakdown model: a framework for gpu kernel programs performance analysis	gpgpu;apu	In this paper we describe our performance-breakdown model for GPU programs. GPUs are a popular choice as accelerator hardware due to their high performance, high availability and relatively low price. However, writing programs that are highly efficient represents a difficult and time consuming task for programmers because of the complexities of GPU architecture and the inherent difficulty of parallel programming. That is the reason why we propose the Linear Performance-Breakdown Model Framework as a tool to assist in the optimization process. We show that the model closely matches the behavior of the GPU by comparing the execution time obtained from experiments in two different types of GPU, an Accelerated Processing Unit (APU) and a GTX660, a discrete board. We also show performance-breakdown results obtained from applying the modeling strategy and how they indicate the time spent during the computation in each of the three Mayor Performance Factors that we define as processing time, global memory transfer time and shared memory transfer time.Â	graphics processing unit;kernel (operating system);profiling (computer programming)	Mario Alberto Chapa Martell;Hiroyuki Sato	2015	IJNC		parallel computing;real-time computing;computer science;computer graphics (images)	HPC	-5.216603546061437	44.99252215315098	78490
e7973a5d612b3dbcce76fdfcdcdf6890e5e24751	topology aware task mapping techniques: an api and case study	sensibilidad contexto;distributed system;switching networks;topology;systeme reparti;context aware;uniform topology;product code;performance;interface programme application;network performance;effet dimensionnel;three dimensional;reseau commutation;network topology;sistema repartido;toro;torus;size effect;tore;application program interfaces;algorithme reparti;retard;wormhole routing;algorithms;algoritmo repartido;mapping;sensibilite contexte;efecto dimensional;topologie uniforme;retraso;communication;distributed algorithm;topologie circuit;topologia uniforme	Optimal network performance is critical to efficient parallel scaling for communication-bound applications on large machines. With wormhole routing, no-load latencies do not increase significantly with number of hops traveled. Yet, we, and others have recently shown that in presence of contention, message latencies can grow substantially large. Hence task mapping strategies should take the topology of the machine into account on large machines. This poster presents a uniform API which provides topology information on 3D tori like IBM Blue Gene and Cray XT machines. We present techniques to use this API to improve performance. The API can be used by user-level codes to obtain information about allocated partitions at runtime which is essential for mapping.  We motivate why it is important to consider network topology, using a simple 3D Stencil kernel. We then present mapping strategies for a production code, OpenAtom, running on three-dimensional torus and mesh topologies. OpenAtom presents complex communication scenarios of interaction between multiple groups of objects. Results are presented in the context of 3D Stencil and OpenAtom on up to 16,384 processors of Blue Gene/L, 8,192 processors of Blue Gene/P and 2,048 processors of Cray XT3.	application programming interface;blue gene;central processing unit;code;cray xt3;image scaling;network performance;network topology;openatom;parallel computing;routing;run time (program lifecycle phase);user space;wormhole switching	Abhinav Bhatele;Eric J. Bohm;Laxmikant V. Kalé	2009		10.1145/1504176.1504225	three-dimensional space;distributed algorithm;parallel computing;real-time computing;performance;computer science;torus;distributed computing;universal product code;network performance;network topology	HPC	-9.058412451219622	44.31703681609625	78700
22b76a615658dd1475b54e51984688a0f8ab53c1	mpi datatype processing using runtime compilation	hybrid parallel programming;endpoints;mpi;interoperability	Data packing before and after communication can make up as much as 90% of the communication time on modern computers. Despite MPI's well-defined datatype interface for non-contiguous data access, many codes use manual pack loops for performance reasons. Programmers write access-pattern specific pack loops (e.g., do manual unrolling) for which compilers emit optimized code. In contrast, MPI implementations in use today interpret datatypes at pack time, resulting in high overheads. In this work we explore the effectiveness of using runtime compilation techniques to generate efficient and optimized pack code for MPI datatypes at commit time. Thus, none of the overhead of datatype interpretation is incurred at pack time and pack setup is as fast as calling a function pointer. We have implemented a library called libpack that can be used to compile and (un)pack MPI datatypes. The library optimizes the datatype representation and uses the LLVM framework to produce vectorized machine code for each datatype at commit time. We show several examples of how MPI datatype pack functions benefit from runtime compilation and analyze the performance of compiled pack functions for the data access patterns in many applications. We show that the pack/unpack functions generated by our packing library are seven times faster than those of prevalent MPI implementations for 73% of the datatypes used in a scientific application and in many cases outperform manual pack loops.	compiler;computer;data access;file system permissions;function pointer;just-in-time compilation;llvm;machine code;message passing interface;overhead (computing);pointer (computer programming);programmer;set packing	Timo Schneider;Fredrik Kjolstad;Torsten Hoefler	2013		10.1145/2488551.2488552	parallel computing;real-time computing;computer science;theoretical computer science	HPC	-17.57914905227199	36.2069423493518	78840
e35bbea8809428cd1e0439e65559df369c011f5e	parallel linear multigrid by agglomeration for the acceleration of 3d compressible flow calculations on unstructured meshes	compressible flow;2 dimensional;software development;unstructured mesh;3 dimensional;parallel architecture;tetrahedral mesh;navier stokes equation;euler equation	In this paper, we report on our recent efforts concerning the design of parallel linear multigrid algorithms for the acceleration of 3-dimensional compressible flow calculations. The multigrid strategy adopted in this study relies on a volume agglomeration principle for the construction of the coarse grids starting from a fine discretization of the computational domain. In the past, this strategy has mainly been studied in the 2-dimensional case for the solution of the Euler equations (see Lallemand et al. [6]), the laminar Navier–Stokes equations (see Mavriplis and Venkatakrishnan [12]) and the turbulent Navier–Stokes equations (see Carré [1], Mavriplis [10] and Francescatto and Dervieux [4]). A first extension to the 3-dimensional case is presented by Mavriplis and Venkatakrishnan in [13] and more recently in Mavriplis and Pirzadeh [11]. The main contribution of the present work is twofold: on the one hand, we demonstrate the successful extension and application of the multigrid by a volume agglomeration principle to the acceleration of complex 3-dimensional flow calculations on unstructured tetrahedral meshes and, on the other hand, we enhance further the efficiency of the methodology through its adaptation to parallel architectures. Moreover, a nontrivial aspect of this work is that the corresponding software developments are taking place in an existing industrial flow solver.	algorithm;automatic parallelization;computation;computer simulation;data structure;discretization;earliest deadline first scheduling;elegant degradation;euler;finite element method;finite volume method;linear algebra;linear system;locality of reference;multigrid method;navier–stokes equations;numerical analysis;numerical methods for ordinary differential equations;parallel computing;relevance;run time (program lifecycle phase);spmd;semiconductor industry;solver;sparse matrix;speedup;turbulence;unstructured grid	G. Carré;Stéphane Lanteri	2000	Numerical Algorithms	10.1023/A:1019161730732	three-dimensional space;mathematical optimization;combinatorics;two-dimensional space;compressible flow;software development;mathematics;geometry;euler equations	HPC	-5.798147848782998	38.383938803453496	78887
a42b8035c7ef04b8983c607064bad374408b7e0a	amesos: a set of general interfaces to sparse direct solver libraries	software libraries;object oriented design;distributed memory architecture;linear system;linear equations	We present the Amesos project, which aims to define a set of general, flexible, consistent, reusable and efficient interfaces to direct solution software libraries for systems of linear equations on both serial and distributed memory architectures. Amesos is composed of a collection of pure virtual classes, as well as several concrete implementations in the C++ language. These classes allow access to the linear system matrix and vector elements and their distribution, and control the solution of the linear system. We report numerical results that show that the overhead induced by the object-oriented design is negligible under typical conditions of usage. We include examples of applications, and we comment on the advantages and limitations of the approach.	c++;comment (computer programming);distributed memory;library (computing);linear equation;linear system;numerical analysis;overhead (computing);solver;sparse;system of linear equations	Marzio Sala;Kendall S. Stanley;Michael A. Heroux	2006		10.1007/978-3-540-75755-9_115	parallel computing;computer science;theoretical computer science;operating system;object-oriented design;distributed computing;linear equation;linear system;programming language;algorithm	PL	-9.678860243174814	36.09935652381835	78924
d22cded29287c727fd473ff71a830c4e358c3f6b	a methodology for modeling m204 on-line existing workloads using best/1 and mics mvs model generator				Win-Yeu Winnie Chen	1985			parallel computing;computer architecture;computer science	Robotics	-9.31354015855197	42.779103691759246	79027
6a6d506a1397f59f67deac72c928f1ebe621df2d	a lightweight task graph scheduler for distributed high-performance scientific computing	high degree;increased simulation complexity;task graph scheduler;simulation task;message passing interface;modern programming technique;lightweight task graph scheduler;high-performance scientific computing;scientific software framework;concise user-level code	The continually growing demand for increased simulation complexity introduces the need for scientific software frameworks to parallelize simulation tasks. We present our approach for a task graph scheduler based on modern programming techniques. The scheduler utilizes the Message Passing Interface to distribute the tasks among distributed computing nodes. We show that our approach does not only offer a concise user-level code but also provides a high degree of scalability.	computational science;distributed computing;message passing interface;scalability;scheduling (computing);simulation;software framework;user space	Josef Weinbub;Karl Rupp;Siegfried Selberherr	2012		10.1007/978-3-642-36803-5_47	parallel computing;real-time computing;computer science;theoretical computer science;operating system;distributed computing	HPC	-10.022302233634568	38.421819970795646	79166
5bb7188a9039ecc8afc9812de912eeba313797b3	molecular dynamics simulations on commodity gpus with cuda	nvidia geforce 8800 gtx;paper;parallel algorithm;molecular dynamics;compute unified device architecture;molecular dynamic simulation;computer graphic;cuda;molecular biology;chemistry;high performance computer;nvidia;graphic processing unit;performance ratio;system simulation;high performance;off the shelf	Molecular dynamics simulations are a common and often repeated task in molecular biology. The need for speeding up this treatment comes from the requirement for large system simulations with many atoms and numerous time steps. In this paper we present a new approach to high performance molecular dynamics simulations on graphics processing units. Using modern graphics processing units for high performance computing is facilitated by their enhanced programmability and motivated by their attractive price/performance ratio and incredible growth in speed. To derive an efficient mapping onto this type of architecture, we have used the Compute Unified Device Architecture (CUDA) to design and implement a new parallel algorithm. This results in an implementation with significant runtime savings on an off-the-shelf computer graphics card.	autodock;cuda;computer graphics;computer simulation;gromacs;graphics hardware;graphics processing unit;molecular dynamics;p5 (microarchitecture);parallel algorithm;speedup;supercomputer;video card	Weiguo Liu;Bertil Schmidt;Gerrit Voss;Wolfgang Müller-Wittig	2007		10.1007/978-3-540-77220-0_20	cuda pinned memory;computational science;molecular dynamics;parallel computing;computer science;operating system;parallel algorithm;general-purpose computing on graphics processing units;computer graphics (images)	HPC	-5.114154245053498	37.116773104334214	79283
40f6d8711d91ea86e9ee84b3bd9624c2be5063bc	automatic tuning technique exploring within the hardware-specific constrained parameters	calcul matriciel;autoregulacion;ajustamiento modelo;haute performance;mise a jour;performance indicator;machine unique;operating conditions;echantillonnage;distributed computing;autoregulation;sampling;actualizacion;grid;ajustement modele;single machine;maquina unica;condition operatoire;self regulation;rejilla;model matching;alto rendimiento;grille;calculo repartido;matrix calculus;muestreo;condicion operatoria;high performance;calcul reparti;calculo de matrices;updating	This paper covers an efficient strategy for exploring the sampling parameters on auto-tuning processes. Byte/flop is considered as a performance indicator, and finding the best parameter is interpreted as an optimisation problem with some hardware-specific constrained conditions. In this work, we also evaluate the performance of various unrolled loops both in a rank-update operation and a matrix-vector multiplication which appear in a significant operation of an eigensolver. The tuned routines running on a single processor of a Hitachi SR8000 and a Fujitsu VPP5000 record 1080 MFLOPS and 8342 MFLOPS respectively.		Toshiyuki Imamura;Ken Naono	2005		10.1007/11666806_47	simulation;engineering;artificial intelligence;algorithm	HCI	-18.550906312521818	44.45785029842002	79312
68988fb403b7967b82aa557cc8f6542ced74c459	improving cache performance by runtime data movement		The performance of a recursive data structure (RDS) increasingly depends on good data cache behaviour, which may be improved by software/hardware prefetching or by ensuring that the RDS has a good data layout. The latter is harder but more effective, and requires solving two separate problems: firstly ensuring that new RDS nodes are allocated in a good location in memory, and secondly preventing a degradation in layout when the RDS changes shape due to pointer updates. The first problem has been studied in detail, but only two major classes of solutions to the second exist. Layout degradation may be side-stepped by using a ‘cache-aware’ RDS, one designed to have inherently good cache behaviour (e.g. using a B-Tree in place of a binary search tree), but such structures are difficult to devise and implement. A more automatic solution in some languages is to use a ‘layout-improving’ garbage collector, which attempt to improve heap data layout during collection using online profiling of data access patterns. This may carry large performance, memory and latency overheads. In this thesis we investigate the insertion of code into a program which attempts to move RDS nodes at runtime to prevent or reduce layout degradation. Such code affects only the performance of a program not its semantics. The body of this thesis is a thorough and systematic evaluation of three different forms of data movement. The first method adapts existing work on static RDS data layout, performing ad-hoc single node movements at a program’s pointer-update sites, which is simple to apply and effective in practice, but the performance gain may be hard to predict. The second method performs infrequent movement of larger groups of nodes, borrowing techniques from garbage collection but also embedding data movement in existing traversals of the RDS; the benefit of performing additional data movement to compact the heap is also demonstrated. The third method restores a pre-chosen layout after each RDS pointer update, which is a complex but effective technique, and may be viewed both as an optimisation and as a way of synthesising new cache-aware RDSs. Concentrating on both maximising performance while minimising latency and extra memory usage, two fundamental RDSs are used for the investigation, representative of two common data access patterns (linear and branching). The methods of this thesis compare favourably to upper bounds on performance and to the canonical cache-aware solutions. This thesis shows the value of runtime data movement, and as well as producing optimisation useful in their own right may be used to guide the design of future cacheaware RDSs and layout-improving garbage collectors.	b-tree;cpu cache;data access;data structure;elegant degradation;global variable;hoc (programming language);mathematical optimization;pointer (computer programming);recursion;run time (program lifecycle phase);search tree	C. M. S. Adcock	2009			computer architecture;parallel computing;real-time computing;cache coloring;cache;cache invalidation;smart cache;cache algorithms;cache pollution	PL	-18.52037670727569	36.1414349923783	79328
5820ad98509f8ffe21f2a51fcc0c7b2a7ece7b56	parallelization of full search motion estimation algorithm for parallel and distributed platforms	gpu;motion estimation;cuda;openmp;block matching;mpi	This work presents an efficient method to map the Full Search algorithm for Motion Estimation (ME) onto General Purpose Graphic Processing Unit (GPGPU) architectures using Compute Unified Device Architecture (CUDA) programming model. Our method jointly exploits the massive parallelism available in current GPGPU devices and the parallelism potential of Full Search algorithm. Our main goal is to evaluate the feasibility of video codecs implementation using GPGPUs and its advantages and drawbacks compared to other platforms. Therefore, for comparison reasons, three solutions were developed using distinct programming paradigms for distinct underlying hardware architectures: (i) a sequential solution for general-purpose processor (GPP); (ii) a parallel solution for multi-core GPP using OpenMP library; (iii) a distributed solution for cluster/grid machines using Message Passing Interface (MPI) library. The CUDA-based solution for GPGPUs achieves speed-up compatible to the indicated by the theoretical model for different search areas. Our GPGPU Full Search Motion Estimation provides 2×, 20× and 1664× speed-up when compared to MPI, OpenMP and sequential implementations, respectively. Compared to state-of-the-art, our solution reaches up to 17× speed-up.	automatic parallelization;cuda;central processing unit;codec;data compression;distributed computing;general-purpose computing on graphics processing units;general-purpose markup language;genetic algorithm;graph partition;graphics processing unit;message passing interface;motion estimation;multi-core processor;openmp;overhead (computing);parallel computing;pipeline (computing);programming model;programming paradigm;run time (program lifecycle phase);search algorithm;server message block;theory	Eduarda Monteiro;Bruno Boessio Vizzotto;Cláudio Machado Diniz;Marilena Maule;Bruno Zatt;Sergio Bampi	2012	International Journal of Parallel Programming	10.1007/s10766-012-0216-7	computer architecture;parallel computing;computer science;message passing interface;theoretical computer science;operating system;motion estimation	HPC	-4.988880037754131	43.34669815810959	79372
181478c7af9d36d06745693e781ad07aedc5f185	cooperative rendezvous protocols for improved performance and overlap		With the emergence of larger multi-/many-core clusters and new areas of HPC applications, performance of large message communication is becoming more important. MPI libraries use different rendezvous protocols to perform large message communication. However, existing rendezvous protocols do not take the overall communication pattern into account or make optimal use of the Sender and the Receiver CPUs. In this work, we propose a cooperative rendezvous protocol that can provide up to 2x improvement in intra-node bandwidth and latency for large messages. We also propose designs to dynamically choose the best rendezvous protocol for each message based on the overall communication pattern. Finally, we show how these improvements can increase the overlap of intra-node communication and computation with inter-node communication and lead to application level benefits at scale. We evaluate the proposed designs on three different architectures Intel Xeon, Knights Landing, and OpenPOWER against state-of-the-art MPI libraries including MVAPICH2 and Open MPI. Compared to existing designs, the proposed designs show benefits of up to 19% with Graph500, 16% with CoMD, and 10% with MiniGhost.	algorithm;benchmark (computing);central processing unit;computation;control variable (programming);download;emergence;executable;graph500;ibm openpower;infiniband;knights;library (computing);load balancing (computing);mathematical optimization;message passing interface;open mpi;open-source software;point-to-point protocol;rendezvous protocol;system under test;test-and-set;xeon phi	S. Chakraborty;Mohammadreza Bayatpour;Jahanzeb Maqbool Hashmi;Hari Subramoni;Dhabaleswar K. Panda	2018			xeon;latency (engineering);computer network;computer science;computation;graph500;rendezvous;communication source;distributed computing;bandwidth (signal processing)	HPC	-7.660086614477254	44.00913751874143	79379
182b6887300e0a843988ae8d19966d2d05093f64	faster topology-aware collective algorithms through non-minimal communication	collective communication;collective communication algorithms;clos network	Known algorithms for two important collective communication operations, allgather and reduce-scatter, are minimal-communication algorithms; no process sends or receives more than the minimum amount of data. This, combined with the data-ordering semantics of the operations, limits the flexibility and performance of these algorithms. Our novel non-minimal, topology-aware algorithms deliver far better performance with the addition of a very small amount of redundant communication. We develop novel algorithms for Clos networks and single or multi-ported torus networks. Tests on a 32k-node BlueGene/P result in allgather speedups of up to 6x and reduce-scatter speedups of over 11x compared to the native IBM algorithm. Broadcast, reduce, and allreduce can be composed of allgather or reduce-scatter and other collective operations; our techniques also improve the performance of these algorithms.	algorithm;blue gene;clos network	Paul Sack;William Gropp	2012		10.1145/2145816.2145823	parallel computing;computer science;clos network;theoretical computer science;distributed computing	HPC	-10.249480529071551	46.22900462232924	79387
2b569bd43821487e446d40d6c6bb6228861af967	decentralized simulation of resource managers	management system;resource allocation;resource manager;message passing;distributed control	There are two primary means of resource allocaUon in computer systems. One ~s the powerful mechanism of using a centrahzed resource manager to allocate the resources. An apparently weaker mechanism is for the asynchronous processes of the system to allocate resources with some type of message passing. A unifying treatment of these two methods is provided. It is shown that a managed system may be simulated by the processes using test and set instructions. As a corollary, a wide variety of synchronization algorithms may be accomplished without a manager. The simulation works correctly even m an environment where processes die in an undetectable manner. All memory cells are of s~ze at most four. Thus this general simulation provides the first known algorithm for fairly synchronizing dying processes with bounded sized memory cells. In particular, the simulation solves the/-crmcal section problem w~th test-and-set instructions operating on bounded size memory.	algorithm;die (integrated circuit);message passing;simulation;test-and-set	Jeffrey M. Jaffe	1983	J. ACM	10.1145/322374.322379	message passing;resource allocation;knowledge management;resource management;management system;distributed computing;human resource management system	Theory	-13.834773001039158	44.72242376838157	79542
2773fb9f60d8ced8336782a56cb05249efa1b6a8	another c threads library	interprocess communication;shared memory;operating system	In this paper we present the main results achieved with the implementation of an efficient multithread library, hereinafter called DIA_Thread library, built on the top of a shared memory symmetric multiprocessor environment. The idea which led us to this project was the lack of a minimal common layer which, as far the multitasking concerns, should help us to make our applications portable among different architectures and/or operating systems. In fact, there are more and more multiprocessor machines available but it is still difficult to exploit the inherent parallelism of the underlying hardware inside a single user application because the available tools are often different in performance and semantics.This package is intendend to be portable. It consists of less than two thousands lines of C code and only a few lines of assembly code. Moreover bif effort was spent to design the main structures in order to have a package absolutely architecture independent, that is, the dependencies on the host operating system were minimized and no assumption was made on the processor configuration, both on their total number and their basic interprocess communication support.The DIA_Thread library basically provides few functions to activate and manage multiple flows of control with a little extra overhead. The useer application may be split in a virtually unlimited number of threads which will carry on their own task communicating each other by means of common memory areas protected by semaphores.	assembly language;c standard library;computer multitasking;inter-process communication;operating system;overhead (computing);parallel computing;semaphore (programming);shared memory;symmetric multiprocessing;thread (computing)	Giuseppe Cattaneo;G. Di Giore;M. Ruotolo	1992	SIGPLAN Notices	10.1145/142181.142208	shared memory;parallel computing;real-time computing;computer hardware;computer science;programming language;inter-process communication	Arch	-12.319162565529844	45.93385561620146	79559
05234358746e1c5e21ea77af0f5b98a5c6cef588	pes: a system for parallelized fitness evaluation of evolutionary methods	developpement logiciel;robot movil;distributed system;sistema operativo;virtual machine;systeme reparti;physics based modeling;probleme livraison;software platform;mobile robot;machine parallele;paralelisacion;machine virtuelle;biblioteca electronica;sistema repartido;parallel evolution;robot mobile;operating system;desarrollo logicial;parallelisation;software development;dispatching problem;parallelization;algorithme evolutionniste;systeme exploitation;parallel machines;algoritmo evolucionista;electronic library;evolutionary algorithm;parallel virtual machine;maquina virtual;moving robot;bibliotheque electronique;problema reparto	The paper reports the development of a software platform, named PES (Parallelized Evolution System), that parallelizes the fitness evaluations of evolutionary methods over multiple computers connected via a network. The platform creates an infrastructure that allows the dispatching of fitness evaluations onto a group of computers, running both Windows or Linux operating systems, parallelizing the evolutionary process. PES is based on the PVM (Parallel Virtual Machine) library and consists of two components; (1) a server component, named PES-Server, that executes the basic evolutionary method, the management of the communication with the client computers, and (2) a client component, named PES-Client, that executes programs to evaluate a single individual and return the fitness back to the server. Performance of PES is tested for the problem of evolving behaviors for a swarm of mobile robots simulated as physics-based models, and the speed-up characteristics are analyzed.	computer;evolutionary algorithm;linux;microsoft windows;mobile robot;operating system;packetized elementary stream;parallel virtual machine;parallel computing;potential energy surface;server (computing);swarm	Onur Soysal;Erkin Bahçeci;Erol Sahin	2003		10.1007/978-3-540-39737-3_112	mobile robot;embedded system;simulation;computer science;virtual machine;artificial intelligence;software development;operating system;parallel evolution;evolutionary algorithm;distributed computing	Metrics	-17.490128012001335	41.68485269761984	79702
3439a0e5742b723f49f401b05a3404e6a1f4f0cd	scientific computing on multicore architectures	berakningsmatematik;berakningsvetenskap;software engineering;computational mathematics;scientific computing;programvaruteknik	Tillenius, M. 2014. Scientific Computing on Multicore Architectures. Digital Comprehensive Summaries of Uppsala Dissertations from the Faculty of Science and Technology 1139. 47 pp. Uppsala: Acta Universitatis Upsaliensis. ISBN 978-91-554-8928-1. Computer simulations are an indispensable tool for scientists to gain new insights about nature. Simulations of natural phenomena are usually large, and limited by the available computer resources. By using the computer resources more efficiently, larger and more detailed simulations can be performed, and more information can be extracted to help advance human knowledge. The topic of this thesis is how to make best use of modern computers for scientific computations. The challenge here is the high level of parallelism that is required to fully utilize the multicore processors in these systems. Starting from the basics, the primitives for synchronizing between threads are investigated. Hardware transactional memory is a new construct for this, which is evaluated for a new use of importance for scientific software: atomic updates of floating point values. The evaluation includes experiments on real hardware and comparisons against standard methods. Higher level programming models for shared memory parallelism are then considered. The state of the art for efficient use of multicore systems is dynamically scheduled task-based systems, where tasks can depend on data. In such systems, the software is divided up into many small tasks that are scheduled asynchronously according to their data dependencies. This enables a high level of parallelism, and avoids global barriers. A new system for managing task dependencies is developed in this thesis, based on data versioning. The system is implemented as a reusable software library, and shown to be as efficient or more efficient than other shared-memory task-based systems in experimental comparisons. The developed runtime system is then extended to distributed memory machines, and used for implementing a parallel version of a software for global climate simulations. By running the optimized and parallelized version on eight servers, an equally sized problem can be solved over 100 times faster than in the original sequential version. The parallel version also allowed significantly larger problems to be solved, previously unreachable due to memory constraints.	acta informatica;central processing unit;computation;computational science;computer simulation;data dependency;distributed memory;experiment;global serializability;high-level programming language;international standard book number;library (computing);multi-core processor;parallel computing;registered jack;runtime system;shared memory;thread (computing);transactional memory;unreachable memory	Martin Tillenius	2014			computational science;computing;computer science;theoretical computer science;computer engineering	HPC	-9.776527321250242	38.967137811071986	79893
8244b9018cecfb2098a4f20819801356f8e8f14a	a study of irreducibility in c programs	irreducibility;control flow;c;structural analysis;open source	Compilers use a variety of techniques to optimize and transform loops. However, many of these optimizations do not work when the loop is irreducible. Node splitting techniques transform irreducible loops into reducible loops, but many real-world compilers choose to leave them unoptimized. This article describes an empirical study of irreducibility in current versions of open-source software, and then compares them with older versions. We also study machine-generated C code from a number of software tools. We find that irreducibility is extremely rare, and is becoming less common with time. We conclude that leaving irreducible loops unoptimized is a perfectly feasible future-proof option due to the rarity of its occurrence in non-trivial software.	irreducibility	James Stanier;Des Watson	2012	Softw., Pract. Exper.	10.1002/spe.1059	computer science;structural analysis;programming language;control flow;algorithm	SE	-11.973295859248465	33.94550262991702	79968
d13fbc6f5b69fcfba0f7d64308994dfc516d0044	an evaluation of cjava system architecture	clusters cjava system architecture dsm distributed shared memory jvm java virtual machine cjava dsm primitives remote signaling thread subsystem distributed object manager multithread java applications memory space;multi threading;virtual machines java workstation clusters open systems multi threading distributed shared memory systems distributed object management;memory management;java virtual machine;run time system;distributed objects;virtual machines;distributed shared memory systems;distributed object management;workstation clusters;system architecture;java yarn virtual machining application software computer architecture programming profession multiprocessing systems instruction sets systems engineering and theory runtime;open systems;distributed shared memory;java	In this work, we propose a new distributed run-time environment, which we called cJava, that enables multithread Java applications to execute in clusters transparently. Our implementation of cJava supports the distributed shared memory (DSM) which required significant extensions to the original Java virtual machine (JVM). First, a distributed object manager was incorporated to the JVM’s memory management subsystem for creating a global object space. Second, synchronized accesses to the global object space were extended so that they could use the lock() and unlock() primitives that cJava’s DSM supports. Third, cJava adapted the thread subsystem to enable remote creation and global monitors. Last, a subsystem for remote signaling was added to the original JVM. The main advantage of cJava is that it can execute existing multithread Java applications straightaway. Most importantly, our results of cJava’s performance across several benchmarks show that cJava offers an efficient run-time system for executing transparently multithread Java applications in clusters.	computer;distributed memory;distributed object;distributed shared memory;java virtual machine;lazy evaluation;lock (computer science);memory management;multiprocessing;object manager;radio-controlled model;release consistency;runtime system;sim lock;supercomputer;surround sound;thread (computing);tuple space	Anderson Faustino da Silva;Marcelo Lobosco;Claudio Luis de Amorim	2003		10.1109/CAHPC.2003.1250325	distributed shared memory;parallel computing;real-time computing;multithreading;computer science;virtual machine;operating system;distributed object;open system;programming language;java;systems architecture;memory management	PL	-14.509432844311524	45.861997015201474	80050
05bed0357e41b745b2965e0ec077640b792eb33e	optimizing the for loop: comparison of for loop and micro for loop		Looping is one of the fundamental logical instructions used for repeating a block of code. It is used in programs across all programming languages. Traditionally, in languages like C, the ‘for’ loop is used extensively for repeated execution of a block of code, due to its ease for use and simplified representation. This paper proposes a new way of representing the ‘for’ loop to improve its runtime efficiency and compares the experimental statistics with the traditional ‘for’ loop representation. It is found that for small number of iterations, the difference in computational time may not be considerable. But given any large number of iterations, the difference is noticeable. Keywords— Loop, Micro For Loop, Programming standards, Time efficiency, C programming.	computation;for loop;iteration;optimizing compiler;programming language;time complexity;universal quantification	Rishabh Jain;Sakshi Gupta	2014	CoRR		loop tiling;loop fusion;loop inversion;while loop;loop fission;conditional loop;loop interchange;loop dependence analysis;computer science;loop nest optimization;theoretical computer science;loop unrolling;do while loop;loop invariant;loop counter;programming language;algorithm;inner loop;loop splitting	PL	-16.850305412935235	35.76292532146245	80054
37016c74e206c827c44ae265a3ae1ecbeb5bbe7a	autobahn: using genetic algorithms to infer strictness annotations	laziness;strictness annotations;genetic algorithms;haskell	Although laziness enables beautiful code, it comes with non-trivial performance costs. The ghc compiler for Haskell has optimizations to reduce those costs, but the optimizations are not sufficient. As a result, Haskell also provides a variety of strictness annotations so that users can indicate program points where an expression should be evaluated eagerly. Skillful use of those annotations is a black art, known only to expert Haskell programmers. In this paper, we introduce AUTOBAHN, a tool that uses genetic algorithms to automatically infer strictness annotations that improve program performance on representative inputs. Users examine the suggested annotations for soundness and can instruct AUTOBAHN to automatically produce modified sources. Experiments on 60 programs from the NoFib benchmark suite show that AUTOBAHN can infer annotation sets that improve runtime performance by a geometric mean of 8.5%. Case studies show AUTOBAHN can reduce the live size of a GC simulator by 99% and infer application-specific annotations for Aeson library code. A 10-fold cross-validation study shows the AUTOBAHN -optimized GC simulator generally outperforms a version optimized by an expert.	benchmark (computing);cross-validation (statistics);experiment;functional programming;genetic algorithm;lazy evaluation;optimizing compiler;programmer;run time (program lifecycle phase);schedule (computer science);the glorious glasgow haskell compilation system	Yisu Remy Wang;Diogenes Nunez;Kathleen Fisher	2016		10.1145/2976002.2976009	genetic algorithm;computer science;database;programming language;algorithm	PL	-17.098600903102326	36.57045322607539	80279
4f0cdfe9a893223cf3bb4931b28e16426d080b11	a cellular general purpose computer	computer architecture;2 dimensional;functional unit	"""A 2-dimensional cellular general-purpose computer is specified. This particular cellular computer is distinguished from previously proposed, locally-controlled cellular computers in that the cellular structure is """"hidden"""" from the user. At the ISP level, the machine is similar to a small-scale computer of the von Neumann type. However, the architecture of the computer does not feature physically isolated functional units to implement memory, processor, or control. As a result, we present a machine which may be programmed in the conventional manner, but which has the hardware advantages associated with the cellular structure. Additionally, the machine is controlled by a software microprogram, which lends itself to dynamic micro-programming and to such related applications as machine simulation."""	computer;general-purpose markup language;microcode;simulation	R. G. Cornell	1974		10.1145/642089.642124	embedded system;computer architecture;two-dimensional space;parallel computing;computer science;cellular architecture;theoretical computer science;operating system;abstract machine	Arch	-13.336704897506053	40.831775008488705	80313
336bbc903c7a42c6e89c157fef8115ff0ab2719e	compiler optimization for extreme-scale scripting	openmp compiler optimization extreme scale scripting data driven task parallelism execution model parallel programming model large scale distributed memory system parallel computing swift t high level scripting language flexible data flow composition mpi;reference counting parallel programming data flow parallelism compiler optimization garbage collection;optimization runtime parallel processing memory management analytical models process control benchmark testing;parallel programming authoring languages data flow computing distributed memory systems optimising compilers	The data-driven task parallelism execution model can support parallel programming models that are well suited for large-scale distributed-memory parallel computing, for example, simulations and analysis pipelines running on clusters and clouds. We describe a novel compiler intermediate representation and optimizations for this execution model, including adaptions of standard techniques alongside novel techniques. These techniques are applied to Swift/T, a high-level scripting language for flexible data flow composition of functions, which may be serial or use lower-level parallel programming models such as MPI and OpenMP. This paper presents preliminary results, indicating that our compiler optimizations reduce communication overhead by 70% to 93% on distributed-memory systems.	dataflow;distributed memory;high- and low-level;ibm websphere extreme scale;intermediate representation;keystroke-level model;message passing interface;openmp;optimizing compiler;overhead (computing);parallel computing;pipeline (computing);scripting language;simulation;swift (programming language);task parallelism	Timothy G. Armstrong;Justin M. Wozniak;Michael Wilde;Ian T. Foster	2014	2014 14th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing	10.1109/CCGrid.2014.115	computer architecture;compiler;parallel computing;profile-guided optimization;compiler correctness;computer science;loop optimization;compiler construction;program optimization;data parallelism;programming language;functional compiler;implicit parallelism;task parallelism	HPC	-6.961677607720765	43.90835142883246	80427
1668461574c14e59249e9b4746ce92f836af35d1	raid, caid and virtual disk architecture and concepts			computer-aided industrial design;raid;virtual disk	Philip B. Berman	1995			architecture;parallel computing;raid;computer science	DB	-10.29786122146554	43.26922193626081	80517
90a6b6b1e04a953b786744f81f87d4ddbd779983	shenfun: high performance spectral galerkin computing platform				Mikael Mortensen	2018	J. Open Source Software	10.21105/joss.01071		HPC	-6.943818825621417	38.22248845283208	80558
1af0dfbdc5832adf3866c8bd1eb0b33ed16d1b5d	rosa: r optimizations with static analysis		R is a popular language and programming environment for data scientists. It is increasingly co-packaged with both relational and Hadoop-based data platforms and can often be the most dominant computational component in data analytics pipelines. Recent work has highlighted inefficiencies in executing R programs, both in terms of execution time and memory requirements, which in practice limit the size of data that can be analyzed by R. This paper presents ROSA, a static analysis framework to improve the performance and space efficiency of R programs. ROSA analyzes input programs to determine program properties such as reaching definitions, live variables, aliased variables, and types of variables. These inferred properties enable program transformations such as C++ code translation, strength reduction, vectorization, code motion, in addition to interpretive optimizations such as avoiding redundant object copies and performing in-place evaluations. An empirical evaluation shows substantial reductions by ROSA in execution time and memory consumption over both CRAN R and Microsoft R Open.	apache hadoop;automatic vectorization;c++;computation;data science;in-place algorithm;integrated development environment;loop-invariant code motion;pipeline (computing);program transformation;reaching definition;relational model;requirement;run time (program lifecycle phase);static program analysis;strength reduction	Rathijit Sen;Jianqiao Zhu;Jignesh M. Patel;Somesh Jha	2017	CoRR		parallel computing;real-time computing;computer science;theoretical computer science;programming language	PL	-17.952358931401157	33.70060110285323	80684
98f97a2c2b96c2cadad45b9f7e5d5acaa964e3a8	stochastic evaluation of a static storage allocation	static storage allocation;stochastic evaluation	By static storage allocation we mean the pre-run assignment of a l ibrary of programs and data to operating and storage locations in the computer memory. Once such an assignment has been made it remains fixed during the operation of the program system. A problem in allocating the programs and data arises when the memory space available for allocation is exceeded by the total length of programs and data to be allocated. This is generally the case when an operating system is associated with an executive program which calls programs and data out of the l ibrary as required. The need for an efficient allocation becomes acute when the executive program must handle a large number of requests and deals with a large l ibrary of programs and data. In particular, one would like to be able to specify an allocation tha t minimizes the number of expected overlays required in a given period of operation. I f we assume tha t the executive program is capable of remembering which programs are in the memory at the t ime of a new call on the system, unnecessary overlays can be avoided. In this ease the expected number of overlays can be made to depend on the storage allocation as a function of the frequency of calls on each of the programs and data groups in the library. I t is the purpose of this paper to develop an objective rule of evaluation of the efficiency of a specific allocation of a given library. We assume specifically tha t all programs are called directly out of the libratT, so tha t we are concerned only with minimizing the number of reads. This means tha t the executive program does not preserve any resultant program or data for later use in the running of the system. Finally, we assume tha t called programs which require overlays at their own direction restore the overlayed areas to their original condition. In many eases this is a severe restriction and later work will consider systems in which this restriction has been removed. A more expansive discussion of the problem and characteristics of the allocation technique is to be found in [1]. In the next section a brief review of this technique is presented.	computer memory;dspace;memory management;operating system;resultant;static random-access memory	Leo J. Cohen	1961	Commun. ACM	10.1145/366786.366808	theoretical computer science;computer science	PL	-15.539832692414356	33.34168099239772	80698
4984f46e59de1ddcef92e63278b47fbf8179d7ee	experiments with program parallelization using archetypes and stepwise refinement	proceso secuencial comunicante;logica formal;programacion paralela;communicating sequential process;parallel programming;concurrent program;processus sequentiel communicant;calcul raffinement;programa competidor;refinement calculus;formal logic;tools and techniques;parallel programs;logique formelle;programme concurrent;programmation parallele	Parallel programming continues to be difficult and error-prone, whether starting from specifications or from an existing sequential program. This paper presents (1) a methodology for parallelizing sequential applications and (2) experiments in applying the methodology. The methodology is based on the use of stepwise refinement together with what we call p rallel programming archetypes (briefly, abstractions that capture common features of classes of programs), in which most of the work of parallelization is done using familiar sequential tools and techniques, and those parts of the process that cannot be addressed with sequential tools and techniques are addressed with formally-justified transformations. The experiments consist of applying the methodology to sequential application programs, and they provide evidence that the methodology produces correct and reasonably efficient programs at reasonable human-effort cost. Of particular interest is the fact that the aspect of the methodology that is most completely formally justified is the aspect that in practice was the most trouble-free.	automatic parallelization;cognitive dimensions of notations;experiment;parallel computing;refinement (computing);stepwise regression;top-down and bottom-up design	Berna L. Massingill	1998		10.1007/3-540-64359-1_747	refinement calculus;computer science;artificial intelligence;theoretical computer science;database;programming language;logic;algorithm	PL	-16.819060453536963	33.5639100309302	80790
5f8325ffe18612c2143d3c2e7767cd190e8f754b	novel views of performance data to analyze large-scale adaptive applications	computer debugging;data analysis;data visualisation;mesh generation;multiprocessing systems;parallel processing;performance evaluation;ibm blue gene/p system;adaptive mesh refinement;application communication topology;large-scale adaptive applications;load-balanced amr library;mitigation strategy;parallel scientific codes;per-core data;per-level measurements;per-phase measurements;performance analysis;performance data projection;performance data visualization;performance debugging process;performance improvement;performance tuning process;structured amr library	Performance analysis of parallel scientific codes is becoming increasingly difficult due to the rapidly growing complexity of applications and architectures. Existing tools fall short in providing intuitive views that facilitate the process of performance debugging and tuning. In this paper, we extend recent ideas of projecting and visualizing performance data for faster, more intuitive analysis of applications. We collect detailed per-level and per-phase measurements for a dynamically load-balanced, structured AMR library and project per-core data collected in the hardware domain on to the application's communication topology. We show how our projections and visualizations lead to a rapid diagnosis of and mitigation strategy for a previously elusive scaling bottleneck in the library that is hard to detect using conventional tools. Our new insights have resulted in a 22% performance improvement for a 65,536-core run of the AMR library on an IBM Blue Gene/P system.	adaptive multi-rate audio codec;blue gene;code;core data;debugging;image scaling;load balancing (computing);p system;performance tuning	Abhinav Bhatele;Todd Gamblin;Katherine E. Isaacs;Brian T. N. Gunney;Martin Schulz;Peer-Timo Bremer;Bernd Hamann	2012	2012 International Conference for High Performance Computing, Networking, Storage and Analysis		parallel processing;mesh generation;computer architecture;parallel computing;real-time computing;computer science;operating system;distributed computing;data analysis;programming language;general-purpose computing on graphics processing units	HPC	-8.452225932768867	46.02757369479517	80873
2793701b86038fc9dadbb5a39e428205efc88132	searching for concurrent design patterns in video games	soft real time system;paper;performance;video game;parallel programming environment;games;design pattern;performance analysis;tools and techniques;algorithms;computer science;open source	The transition to multicore architectures has dramatically underscored the necessity for parallelism in software. In particular, while new gaming consoles are by and large multicore, most existing video game engines are essentially sequential and thus cannot easily take advantage of this hardware. In this paper we describe techniques derived from our experience parallelizing an open-source video game Cube 2. We analyze the structure and unique requirements of this complex application domain, drawing conclusions about parallelization tools and techniques applicable therein. Our experience and analysis convinced us that, while existing tools and techniques can be used to solve parts of this problem, none of them constitutes a comprehensive solution. As a result we were inspired to design a new parallel programming environment (PPE) targeted specifically at video game engines and other complex soft real-time systems. The initial implementation of this PPE, Cascade, and its performance analysis are also presented.	application domain;automatic parallelization;cascade amplifier;computation;correctness (computer science);cube 2: sauerbraten;filemaker;game engine;integrated development environment;multi-core processor;open-source video game;parallel computing;power processing element;profiling (computer programming);programmer;real-time clock;real-time computing;requirement;speedup	Micah J. Best;Alexandra Fedorova;Ryan Dickie;Andrea Tagliasacchi;Alex Couture-Beil;Craig Mustard;Shane Mottishaw;Aron Brown;Zhi Feng Huang;Xiaoyuan Xu;Nasser Ghazali;Andrew Brownsword	2009		10.1007/978-3-642-03869-3_84	game development tool;games;parallel computing;real-time computing;simulation;performance;computer science;theoretical computer science;operating system;database;distributed computing;design pattern;programming language;game programming	EDA	-11.713948313741152	40.40444559600689	81064
14c12c11b67ca6a8b660c247362a3416e7ebf09b	simulating the dynix operating system parallel programming interface on a unix system		This paper presents the implementation of multitasking functions of DYNIX Sequent computers on the UNIX operating system. The Sequent computers are shared memory multiprocessor computers running the DYNIX operating system. These functions support data and function partitioning. They let the user implement subprograms by the processors of a Sequent computer in parallel. The functions can synchronize, lock, and unlock data and program segments. As a result, the simulator allows the users to develop their multitasking programs on a uniprocessor computer such as a SUN workstation, and later port them to a Sequent computer. Further, the simulator adds a level of abstraction on top of UNIX for concurrent programming. The functions of the simulator allow the user to handle the communication and synchronization of the processes in a program at a higher level of abstraction, while concentrating on the design of multitasking algorithms. The simulator is applied to a parallel selection algorithm.  1998 John Wiley & Sons, Ltd.	central processing unit;computer multitasking;concurrent computing;dynix;john d. wiley;multiprocessing;operating system;sim lock;sun workstation;selection algorithm;shared memory;simulation;subroutine;uniprocessor system;unix	Mehdi Badii	1998	Softw., Pract. Exper.	10.1002/(SICI)1097-024X(19980425)28:5%3C463::AID-SPE162%3E3.0.CO;2-O		Arch	-13.836515469529044	43.857321306714184	81148
c7602ce2aba8223293ff3de385cda3f0a231b0a8	static program analysis for identifying energy bugs in graphics-intensive mobile apps	androids;humanoid robots;monitoring;graphics processing units;games;optimization;computer bugs	A major drawback of mobile devices is limited battery life. Apps that use graphics are especially energy greedy and developers must invest significant effort to make such apps energy efficient. We propose a novel static optimization technique for eliminating drawing commands to produce energy-efficient apps. The key insight we exploit is that the static analysis is able to predict future behavior of the app, and we give three exemplars that demonstrate the value of this approach. Firstly, loop invariant texture analysis identifies repetitive texture transfers in the render loop so that they can be moved out of the loop and performed just once. Secondly, packing identifies images that are drawn together and therefore can be combined into a larger image to eliminate overhead associated with multiple smaller images. Finally, identical frames detection uses a combination of static and dynamic analysis to identify frames that are identical to the previous frame and therefore do not have to be drawn. We implemented the technique against LibGDX, an Android game engine, and evaluated it using open source projects. Our experiments indicate savings up to 44% of the total energy consumption of the device.	android;callback (computer programming);control flow;experiment;game engine;graphics;graphics processing unit;greedy algorithm;library (computing);loop invariant;mathematical optimization;mobile device;open-source software;overhead (computing);programmer;set packing;software bug;static program analysis;libgdx	Chang Hwan Peter Kim;Daniel Kroening;Marta Z. Kwiatkowska	2016	2016 IEEE 24th International Symposium on Modeling, Analysis and Simulation of Computer and Telecommunication Systems (MASCOTS)	10.1109/MASCOTS.2016.28	games;embedded system;real-time computing;simulation;software bug;computer science;humanoid robot;operating system	Arch	-19.005606788258767	36.64154565699299	81162
b2c6d7c927d2dbfc66f3863bc9d7ee3b4480af24	toward more efficient computer organizations	programming language;continuous improvement	Two significant trends have evolved which will substantially effect the nature of computer organizations over the next ten years:  1. The almost universal use of higher level programming languages and corresponding decrease in the use of machine level programming.  2. The continued improvement in cost and performance of both logic and memory technologies.	programming language	Michael J. Flynn	1971		10.1145/1478873.1479034	computer science;algorithm;computer engineering	Arch	-14.176985751606749	40.97347622268059	81300
f3d7fbb231f91885198aff30349186993e6c4765	semi-automatic tool to ease the creation and optimization of gpu programs	kernel;arrays;graphics processing units;optimization;programming;instruction sets;hardware	We present a tool that reduces the development time of GPU-executable code. We implement a catalogue of common optimizations specific to the GPU architecture. Through the tool, the programmer can semi-automatically transform a computationally-intensive code section into GPU-executable form and apply optimizations thereto. Based on experiments, the code generated by the tool can be 3-256X faster than code generated by an OpenACC compiler, 4-37X faster than optimized CPU code, and attain up to 25% of peak performance of the GPU. We found that by using pattern-matching rules, many of the transformations can be performed automatically, which makes the tool usable for both novices and experts in GPU programming.	compile time;compiler;computer data storage;control flow;data dependency;emoticon;executable;experiment;graphics processing unit;openacc;parsing;pattern matching;programmer;semiconductor industry;time complexity;universal product code;usability	Jacob Jepsen	2014	2014 43rd International Conference on Parallel Processing Workshops	10.1109/ICPPW.2014.36	dead code;programming;computer architecture;parallel computing;kernel;computer science;theoretical computer science;operating system;instruction set;programming language	SE	-14.678523756141832	36.60186029903395	81370
79c2dda134031672160bfcf9333bfcc92128f8aa	phantom: predicting performance of parallel applications on large-scale parallel machines using a single node	distributed system;debugging;algoritmo paralelo;communication process;puesta a punto programa;evaluation performance;systeme reparti;parallel algorithm;performance evaluation;measurement;execution time;machine unique;sequential computation;convolution;real time;evaluacion prestacion;performance;machine parallele;calcul sequentiel;ejecucion programa;convolucion;network simulator;program execution;simulator;debogage;algorithme parallele;proceso comunicacion;processus communication;large scale;single machine;maquina unica;sistema repartido;simulador;execution programme;temps reel;prediction accuracy;deterministic replay;parallel computer;simulateur;tiempo real;temps execution;parallel machines;performance prediction;calculo secuencial;tiempo ejecucion;trace driven simulation;parallel applications;parallel processing;parallel application	For designers of large-scale parallel computers, it is greatly desired that performance of parallel applications can be predicted at the design phase. However, this is difficult because the execution time of parallel applications is determined by several factors, including sequential computation time in each process, communication time and their convolution. Despite previous efforts, it remains an open problem to estimate sequential computation time in each process accurately and efficiently for large-scale parallel applications on non-existing target machines.  This paper proposes a novel approach to predict the sequential computation time accurately and efficiently. We assume that there is at least one node of the target platform but the whole target system need not be available. We make two main technical contributions. First, we employ deterministic replay techniques to execute any process of a parallel application on a single node at real speed. As a result, we can simply measure the real sequential computation time on a target node for each process one by one. Second, we observe that computation behavior of processes in parallel applications can be clustered into a few groups while processes in each group have similar computation behavior. This observation helps us reduce measurement time significantly because we only need to execute representative parallel processes instead of all of them.  We have implemented a performance prediction framework, called PHANTOM, which integrates the above computation-time acquisition approach with a trace-driven network simulator. We validate our approach on several platforms. For ASCI Sweep3D, the error of our approach is less than 5% on 1024 processor cores. Compared to a recent regression-based prediction approach, PHANTOM presents better prediction accuracy across different platforms.	computation;computer;convolution;parallel computing;performance prediction;run time (program lifecycle phase);time complexity	Jidong Zhai;Wenguang Chen;Weimin Zheng	2010		10.1145/1693453.1693493	embedded system;parallel processing;parallel computing;real-time computing;performance;computer science;network simulation;parallel algorithm;convolution;debugging;measurement;cost efficiency	Metrics	-16.743145417214276	43.538874247527424	81371
61700870502dcccdd7823390b76f87ee4b8706aa	pempis: a new methodology for modeling and prediction of mpi programs performance	new computer design;computer architect;simulation time;detailed simulation;mpi programs performance;new methodology;important tool;time consuming;prediction model;message passing;parallel programming	The evaluation and prediction of parallel programs performance are becoming more and more important, so that they require appropriate techniques to identify the factors which influence the application execution time and also the way they interact. In this paper, we present some contributions of our research in this area by describing PEMPIs, a new methodology applied to the performance analysis and prediction of MPI programs. A new task graph helps us both to understand details of the application and to increase the accuracy of the prediction models. The proposed techniques are detailed and tested through the modeling of a complete application. PEMPIs efficiency has been proved by the results of this application modeling—most tests executed in a cluster of computers showed errors up to 10.		Edson T. Midorikawa;Hélio Marci de Oliveira;Jean Marcos Laine	2004		10.1109/CAHPC.2004.31	computer architecture;parallel computing;message passing;computer science;operating system;distributed computing;predictive modelling;programming language	HPC	-7.049212617908656	45.738460436652005	81458
7d63b17763203afe09672f6aed4e66a281f267ea	an analysis of message passing systems for distributed memory computers	distributed memory;data parallel;distributed memory systems;message passing system;application oriented high level notation message passing systems distributed memory computers occam tds transputer based systems vertex vortex ncube express architecture independent system program portability efficiency flexibility parallel architectures parallel software investment parallel programming paradigms pipelined processing data parallel processing;parallel programming;investment;parallel architectures;general purpose computers;parallel systems;message passing distributed computing concurrent computing application software parallel programming computer networks operating systems computer architecture programming environments parallel architectures;message passing;parallel architecture;parallel programs;general purpose computers message passing distributed memory systems parallel architectures parallel programming investment	Analyses three of the most widely used message passing environments for parallel systems, namely Occam/TDS for Transputer based systems, Vertex-Vortex for nCUBE, and Express, which is an architecture-independent message passing system. The aim of our analysis is to contrast the features provided by the different systems, and from among them to select the most suitable one with respect to some criteria, i.e. program portability, efficiency and flexibility of the message passing system. Program portability should ensure that we will be able to use tomorrow, on new parallel architectures, today's parallel software, thus preserving our investment. Efficiency of the application is a must for parallel software. With flexibility, we intend that the message passing system is able to accommodate different parallel programming paradigms (such as pipelined, data parallel) in a natural way. The use of a general-purpose message passing system, like those considered, is also contrasted with the use of an application-oriented high-level notation. >	computer;distributed memory;message passing	Andrea Clematis;Ornella Tavani	1993		10.1109/EMPDP.1993.336388	computer architecture;parallel computing;message passing;embarrassingly parallel;computer science;message passing interface;data-intensive computing;distributed computing;parallel algorithm;parallel programming model	HPC	-12.518896727976905	40.98780116959186	81482
3f03f918b10abb0f39fb6a22abdfe721e55965bc	reevaluating amdahl's law in the multicore era	workload;estensibilidad;modelizacion;acces contenu;arquitectura circuito;storage access;memory wall;processeur multicoeur;fixed time;circuit architecture;paralelisacion;procesador multinucleo;scalable computing;chip;upper bound;modelisation;content access;parallelisation;acces memoire;architecture circuit;charge travail;performance model;data access;parallelization;acceso contenido;acceso memoria;multicore processor;extensibilite;scalability;multicore architecture;carga trabajo;borne superieure;modeling;cost model;cota superior	Microprocessor architecture has entered the multicore era. Recently, Hill and Marty presented a pessimistic view of multicore scalability. Their analysis was based on Amdahl’s law (i.e. fixed-workload condition) and challenged readers to develop bettermodels. In this study,we analyzemulticore scalability under fixed-time andmemory-bound conditions and from the data access (memorywall) perspective.We use the same hardware cost model of multicore chips used by Hill and Marty, but achieve very different and more optimistic performance models. These models show that there is no inherent, immovable upper bound on the scalability of multicore architectures. These results complement existing studies and demonstrate that multicore architectures are capable of extensive scalability. © 2009 Elsevier Inc. All rights reserved.	amdahl's law;analysis of algorithms;data access;fm towns marty;microprocessor;multi-core processor;scalability	Xian-He Sun;Yong P Chen	2010	J. Parallel Distrib. Comput.	10.1016/j.jpdc.2009.05.002	chip;multi-core processor;data access;embedded system;parallel computing;real-time computing;scalability;systems modeling;computer science;operating system;distributed computing;upper and lower bounds	DB	-15.710585654757136	44.56003607599145	81528
ca6bcc46620b714c39c0790f9e909acecd1d0156	a multiplatform comparison of a dynamic compilation using roslyn and mathematical parser libraries in .net for expression evaluation		This work aims to provide a multiplatform comparison of a dynamic compilation using Roslyn and mathematical parser libraries in .NET for expression evaluation. In the first part, our own implementation of a mathematical parser, based on a new .NET compiler platform called Roslyn to implement on-fly compiling for mathematical expressions, is introduced. We then define the benchmark and perform performance measurements of our solution against selected mathematical parsers. At the end of the work, we discuss the results of the benchmark on different platforms.	.net compiler platform;dynamic compilation;parser	Petr Capek;Erik Kral;Roman Senkerik	2015		10.1007/978-3-319-18473-9_34	computer science;database;programming language;information retrieval	Vision	-14.14585874043603	36.0627832203438	81733
b004d1cac69fa6b6e841162ca54334ae45094bb8	an experiment to improve operand addressing	programming environment;stack machine;data type;computer architecture;machine design;addressing modes;high level language	MCODE is a high-level language, stack machine designed to support strongly-typed, Pascal-based languages with a variety of data types in a modular programming environment. The instruction set, constructed for efficiency and extensibility, is based on an analysis of 120,000 lines of Pascal programs. The design was compared for efficiency with the instruction sets of the Digital Equipment PDP-11 and VAX by examining the generated code from the same compiler for all three machines. In addition, the original design choices were tested by analyzing the generated code from 19,000 lines of StarMod programs. As a result of this iterative experiment, we have summarized our observations in an efficient reorganization of the VAX's addressing modes.	addressing mode;compiler;extensibility;high- and low-level;high-level programming language;integrated development environment;iteration;iterative method;modular programming;operand;pdp-11;pascal;stack machine;strong and weak typing;vax	Robert P. Cook;Nitin Donde	1982		10.1145/800050.801830	computer architecture;parallel computing;addressing mode;call stack;data type;computer science;instruction set;programming language;high-level programming language;orthogonal instruction set	PL	-13.990810714212774	37.156154240681055	81840
8930b32a46e5e39fcb69807a52c80e8d4bdf982f	a parallel unstructured mesh infrastructure	mathematics computing;parma parallel unstructured mesh infrastructure doe office department of energy office of science scientific discovery advanced computing scidac framework fastmath software package frameworks algorithms and scalable technologies for mathematics pumi partitioning using mesh adjacency;architecture awareness;parallel processing mathematics computing mesh generation;partition improvement;two level mesh partitioning;unstructured mesh;threading;partition improvement unstructured mesh architecture awareness two level mesh partitioning threading;mesh generation;parallel processing	Two Department of Energy (DOE) office of Science's Scientific Discovery through Advanced Computing (SciDAC) Frameworks, Algorithms, and Scalable Technologies for Mathematics (FASTMath) software packages, Parallel Unstructured Mesh Infrastructure (PUMI) and Partitioning using Mesh Adjacencies (ParMA), are presented.	energy citations database;unstructured grid	E. Seegyoung Seol;Cameron W. Smith;Daniel Ibanez;Mark S. Shephard	2012	2012 SC Companion: High Performance Computing, Networking Storage and Analysis	10.1109/SC.Companion.2012.135	computational science;parallel processing;mesh generation;parallel computing;threading;computer science;theoretical computer science	HPC	-7.743424309292041	38.82057897352008	81893
2b1570aa9e44a767652f27d5f7555eeded296732	parallel algorithms for image enhancement and segmentation by region growing with an experimental study	machine specific implementations;software portability;thinking machines cm 5;parallel performance;connected components;image segmentation;meiko scientific cs 2;image processing;data parallelism;landsat thematic mapper satellite data;filters;machine specific implementations parallel algorithms image enhancement image segmentation region growing portable implementations symmetric neighborhood filter spl delta connected components data distribution data coalescence task parallelism data parallelism parallel merging split c landsat thematic mapper satellite data thinking machines cm 5 ibm sp 1 ibm sp 2 cray research t3d meiko scientific cs 2 intel paragon workstation clusters execution times;testing;parallel algorithms image enhancement image segmentation clustering algorithms satellites filters merging workstations testing remote sensing;data distribution;symmetric neighborhood filter;image enhancement;parallel merging;remote sensing;satellites;workstations;portable implementations;split c;merging;cray research t3d;ibm sp 1;clustering algorithms;δ connected components;data coalescence;technical report;task parallelism;workstation clusters;region growing;remote sensing image enhancement image segmentation parallel algorithms software portability filters merging;ibm sp 2;intel paragon;execution times;parallel algorithms	This paper presents eficient and portable implementations of a useful image enhancement process, the Symmetric Neighborhood Filter (SNF), and an image segmentation technique which makes use of the SNF and a variant of the conventional connected components algorithm which we call S-Connected Components. We use efjicient techniques for distributing and coalescing data as well as efficient combinations of task and data parallelism. The image segmentation algorithm makes use of an eficient connected components algorithm based on a novel approach for parallel merging. The algorithms have been coded in SPLIT-C and run on a variety of plagorms, including the Thinking Machines CM-5, IBM SP-I and SP-2, Cray Research T30, Meiko Scienti$c CS-2, Intel Paragon, and workstation clusters. Our experimental results are consistent with the theoretical analysis (and provide the best known execution timesfor segmentation, even when compared with machinespeci$c implementations.) Our test data include dificult images from the Landsat Thematic Mapper (TM) satellite data.	connected component (graph theory);connection machine;data parallelism;image editing;image segmentation;intel paragon;mapper;parallel algorithm;parallel computing;region growing;skolem normal form;split-c;test data;workstation	David A. Bader;Joseph JáJá;David Harwood;Larry S. Davis	1996		10.1109/IPPS.1996.508089	software portability;parallel computing;connected component;workstation;computer hardware;image processing;computer science;technical report;theoretical computer science;operating system;parallel algorithm;data parallelism;region growing;software testing;image segmentation;cluster analysis;satellite;task parallelism	HPC	-6.103194031575844	41.922607385708105	81932
69fd7302dc1b5b5611b817de180295b125e2f0bf	a list-processing-oriented data flow machine architecture and its evaluation	it evaluation;data flow	This paper analyzes some issues concerning list processing under a data flow control environment from the viewpoint of parallelism and also presents a new type of list-processing-oriented data flow machine, based on an association memory and logic-in-memory.  The mechanism of partial execution in each function is shown by example to be effective in exploiting the parallelism in list processing. The lenient cons mechanism is shown to exploit maximally parallelism among activated functions.	dataflow;in-memory database;lisp;parallel computing	Ryuzo Hasegawa;Hirohide Mikami;Makoto Amamiya	1982	Systems and Computers in Japan	10.1002/scj.4690160206	data flow diagram;parallel computing;real-time computing;computer science;theoretical computer science;operating system;programming language;algorithm	Arch	-14.449387859629084	44.39400247086168	82000
92fc4dea7dcf01307231ccba1c10ce72bccd5a6f	optimizing legacy molecular dynamics software with directive-based offload	potentials;performance;mathematics and computing molecular dynamics;molecular dynamics;mathematics and computing;gpu;accelerator;coprocessor;morphology;xeon phi;many core	"""The directive-based programming models are one solution for exploiting many-core coprocessors to increase simulation rates in molecular dynamics. They offer the potential to reduce code complexity with offload models that can selectively target computations to run on the CPU, the coprocessor, or both. In our paper, we describe modifications to the LAMMPS molecular dynamics code to enable concurrent calculations on a CPU and coprocessor. We also demonstrate that standard molecular dynamics algorithms can run efficiently on both the CPU and an x86-based coprocessor using the same subroutines. As a consequence, we demonstrate that code optimizations for the coprocessor also result in speedups on the CPU; in extreme cases up to 4.7X. We provide results for LAMMAS benchmarks and for production molecular dynamics simulations using the Stampede hybrid supercomputer with both Intel (R) Xeon Phi (TM) coprocessors and NVIDIA GPUs: The optimizations presented have increased simulation rates by over 2X for organic molecules and over 7X for liquid crystals on Stampede. The optimizations are available as part of the """"Intel package"""" supplied with LAMMPS. (C) 2015 Elsevier B.V. All rights reserved."""	directive (programming);molecular dynamics;optimizing compiler	W. Michael Brown;Jan-Michael Y. Carrillo;Nitin Gavhane;Foram M. Thakkar;Steven J. Plimpton	2015	Computer Physics Communications	10.1016/j.cpc.2015.05.004	molecular dynamics;computer architecture;parallel computing;morphology;performance;computer science;operating system;xeon phi;coprocessor	HPC	-5.239647659341829	39.06176661865226	82104
6e54af5a7af5e4112dc961fe98d904d503a9b4ee	gpgpu calculations of gas thermodynamic quantities	paper;mechanical engineering computing;aga8;tesla c2050;nvidia tesla;computer graphic equipment;nvidia geforce gtx 570;coprocessors;thermodynamics computer graphic equipment coprocessors differential equations fluid dynamics mechanical engineering computing;gas thermodynamic quantities;cuda;gas state equation;gpgpu;mathematical model approximation methods graphics processing unit thermodynamics equations instruction sets;fermi;mathematical model;nvidia;thermodynamics;fluid dynamics;approximation methods;cfd;differential equations;graphics processing unit;differential equation gpgpu calculation general purpose graphics processing unit nvidia tesla gpu gas thermodynamic quantity fermi generation cuda architecture compute unified device architecture fluid dynamics modeling;nvidia tesla gas state equation aga8 gas thermodynamic quantities cfd gpgpu cuda fermi;instruction sets	Computational processors NVIDIA Tesla GPU based on the new Fermi generation of CUDA architecture are intended to perform massively parallel calculations applicable to various parts of the scientific and technical research, including the area of fluid dynamics modeling, in particular the simulation of real gas flow. In this paper we show that a significant acceleration of simulation calculations can be achieved even without the parallelization of the solution of involved differential equations by parallel pre-calculation of thermodynamic quantities using GPGPU.	approximation;bilinear filtering;cuda;central processing unit;computation;fermi (microarchitecture);general-purpose computing on graphics processing units;graphics processing unit;interpolation;mathematical optimization;maxwell (microarchitecture);nvidia tesla;parallel computing;performance tuning;simulation;tesla (microarchitecture);the matrix	Igor Mracka;Peter Somora;Tibor Zácik	2011	2011 Federated Conference on Computer Science and Information Systems (FedCSIS)		computational science;parallel computing;computational fluid dynamics;computer science;theoretical computer science;fermi gamma-ray space telescope;instruction set;mathematical model;differential equation;general-purpose computing on graphics processing units;coprocessor;fluid dynamics	HPC	-5.919660983136708	37.48969786713146	82151
3203c50f570fd4936f795e218ac8cadb14fb8d43	architecture and early performance of the new ibm hps fabric and adapter	remote access;architectural design;sistema multiple;largeur bande;haute performance;acceso remoto;storage access;communicating process;acces a distance;acceso directo;multiple system;proceso comunicante;transport protocols;remote direct memory access;low latency;acces direct;envoi message;processus communicant;anchura banda;acces memoire;message passing;alto rendimiento;direct access;acceso memoria;transport protocol;bandwidth;high performance;protocole transport;systeme multiple	In this paper we describe the architecture, design, and performance of the new cluster switch fabric and adapter called HPS (High Performance Switch) HPS delivers very low latency and very high bandwidth We demonstrate latency of less than 4.3us MPI library; 1.8GB/s of delivered unidirectional bandwidth and 2.9GB/s of bidirectional bandwidth between 2 MPI tasks running on 1.9GHz Power 4+ IH based nodes HPS also supports RDMA (remote direct memory access capability) A unique capability of RDMA over HPS is that reliable RDMA is supported over an underlying unreliable transport (unlike Infiniband and other RDMA transport protocols which depend on the underlying transport being reliable) We profile the performance of RDMA and its impact on striping for systems in which multiple network adapters are available to tasks of parallel jobs.		Rama K. Govindaraju;Peter H. Hochschild;Don G. Grice;Kevin J. Gildea;Robert Blackmore;Carl A. Bender;Chulho Kim;Piyush Chaudhary;Jason Goscinski;Jay Herring;Steven Martin;John Houston	2004		10.1007/978-3-540-30474-6_21	embedded system;parallel computing;telecommunications;computer science;operating system;programming language;transport layer	DB	-18.29413602489192	44.1496660588222	82225
d7ec94f31460c93612316fd05c04fa487530d780	parallelism in lassap, a large scale sequence comparisons package	sequence comparison;shared memory;homology search;large scale;message passing;parallel machines;work in progress	We present the parallel module of a program called LASSAP which is intended to raise numerous limitations of current sequence  comparison programs and which is able to handle homologies searches at a large scale level. This module is MIMD oriented,  taking advantages of the intrinsic parallelism of most problems. It can run on various architectures (shared memory and message  passing) and achieves near perfect speed-up on highly parallel machines (more than 100 processors). Work in progress focus  on the way to deal with a network of parallel super-computers, taking advantage of the specificities of each of them.  		Jean-Jacques Codani;Eric Glémet	1995		10.1007/BFb0046715	shared memory;parallel computing;message passing;computer science;theoretical computer science;operating system;work in process;distributed computing;programming language	Vision	-12.40549617514633	40.10774994689458	82280
d0b4dec1435677c90343823bf6b8b14bcb52588f	experiments with speculative parallelism in parlog	concurrent language;interprocess communication;concurrent logic programming;search algorithm;parallel computer;language extension;branch and bound;divide and conquer	One way to execute a program faster on a parallel computer is to allocate some processors to speculative computation: work which may prove to be unnecessary. However, this technique, speculative parallelism, requires the programmer to have some control over the physical processors in the machine, and is therefore not usually possible in high-level concurrent languages. This paper investigates the exploitation of speculative parallelism in concurrent logic programming languages. We propose a simple language extension that makes the technique possible, and illustrate its use in two applications: (1) the familiar branch-and-bound search algorithm, and (2) a new dynamic buffer protocol for interprocess communication. The new language feature has been implemented by extending the JAM Parallel Parlog system. The results of our experiments confirm that speculative parallelism can result in greater parallel speedups than is possible with other (divide and conquer) forms of parallelism alone.	ada;branch and bound;central processing unit;computation;concurrent logic programming;constraint logic programming;experiment;high- and low-level;inter-process communication;look-ahead (backtracking);multiprocessing;parallel computing;parlog;parsing;programmer;programming language;search algorithm;sequent calculus;speculative execution;task parallelism;travelling salesman problem;warren abstract machine;yang	Steve Gregory	1993			parallel computing;divide and conquer algorithms;computer science;theoretical computer science;programming language;branch and bound;algorithm;search algorithm;inter-process communication	PL	-16.334124919667246	34.28254468006161	82512
25da43dacededf907d5f9d1945c09c6688a021dd	building blocks for graph based network analysis	network theory graphs graph theory;algorithm design and analysis software algorithms data structures libraries software runtime heuristic algorithms;essens library graph based network analysis graph abstraction graph operation network analysis algorithm graph algorithm component based interface	Network analysis using graph abstractions is a powerful tool for studying complex systems. While there are multiple libraries for both graph operations in general and network analysis algorithms in particular, there is no components based standardization of both of these key set of operations. We propose a framework that abstracts the data stuctures, architecture, programming models for the graph algorithms underneath a very simple component based interface. We also build on these graph abstractions to provide a layer of abstraction that are key for network analysis. A reference implementation of the abstractions and its performance is also demonstrated using a new library - ESSENS.	abstraction layer;algorithm;complex systems;data structure;graph operations;graph theory;high- and low-level;high-level programming language;library (computing);list of algorithms;network science;network theory;programming model;reference implementation;simulation;social network analysis	Vladimir Ufimtsev;Sanjukta Bhowmick;Sivasankaran Rajamanickam	2014	2014 IEEE High Performance Extreme Computing Conference (HPEC)	10.1109/HPEC.2014.7040982	graph bandwidth;null graph;computer science;clique-width;theoretical computer science;machine learning;voltage graph;distributed computing;graph;moral graph;graph database;graph rewriting	HPC	-10.494143972146965	36.0113196056656	82745
2aa4caa740564d3ff887cdb6543293341fafefaa	compiling array statements for efficient execution on distributed-memory machines: two-level mappings	data parallel;distributed memory machine;high performance fortran;indexation	In languages such as High Performance Fortran (HPF), array statements are used for expressing data parallelism. In compiling array statements for distributed-memory machines, eecient enumeration of local index sets and communication sets is important. The virtual processor approach, among several other methods, has been proposed for eecient enumeration of these index sets. In this paper, using simple mathematical properties of regular sections, we extend the virtual processor approach to address the memory allocation and index set enu-meration problems for array statements involving arrays mapped using the two-level mapping supported by HPF. Performance results on the Cray T3D are presented to demonstrate the eecacy of the extensions and identify various tradeoos associated with the proposed method.	central processing unit;compile time;compiler;computation;cray t3d;data parallelism;distributed memory;high performance fortran;locality of reference;parallel computing;principle of locality;regular expression	S. D. Kaushik;Chua-Huang Huang;P. Sadayappan	1995		10.1007/BFb0014201	computer architecture;parallel computing;computer science;programming language	HPC	-12.623217056714264	37.427725363685155	82859
b0a7d9f87e23bdc991ff4f67a4956be52a4f6186	a c programming model for os/2 device drivers	microordenador;software;lenguaje programacion;sistema operativo;programming language;logiciel;microordinateur;microcomputer;programming model;codificacion;operating system;coding;langage programmation;logicial;systeme exploitation;code;codigo;device driver;codage	The recent growth in the number of new and different types of devices for use with personal computers has challenged software engineers to plan new and better ways of developing software to run the devices. For Operating System/2® (OS/2®) device drivers, an improvement would be to code in a high-level language rather than to use assembly language. A practical and proven method of writing OS/2 device drivers in the C programming language is presented here. The C language was chosen because of its documented suitability as a systems programming language and because of its universal availability for use on small systems.	os/2;programming model	Dan T. Feriozi	1991	IBM Systems Journal	10.1147/sj.303.0322	embedded system;parallel computing;computer science;operating system;microcomputer;programming paradigm;coding;programming language;code	OS	-15.66508462786927	34.575226049126826	83171
e0244abb7d8480ecfb430df1cecbe637037a5281	sac/c formulations of the all-pairs n-body problem and their performance on smps and gpgpus	vectorisation;data parallelism;universiteitsbibliotheek;functional programming;graphics cards;auto parallelisation;high productivity;high performance;single assignment c	This paper describes our experience in implementing the classical N-body algorithm in SAC and analysing the runtime performance achieved on three different machines: a dual-processor 8-core Dell PowerEdge 2950 (a Beowulf cluster node, the reference machine), a quad-core hyper-threaded Intel Core-i7 based system equipped with an NVidia GTX-480 graphics accelerator and an Oracle Sparc T4-4 server with a total of 256 hardware threads. We contrast our findings with those resulting from the reference C code and a few variants of it that employ OpenMP pragmas as well as explicit vectorisation. Our experiments demonstrate that the SAC implementation successfully combines a high-level of abstraction, very close to the mathematical specification, with very competitive runtimes. In fact, SAC matches or outperforms the hand-vectorised and hand-parallelised C codes on all three systems under investigation without the need for any source code modification. Furthermore, only SAC is able to effectively harness the advanced compute power of the graphics accelerator, again by mere recompilation of the same source code. Our results illustrate the benefits that SAC provides to application programmers in terms of coding productivity, source code and performance portability among different machine architectures, as well as long-term maintainability in evolving hardware environments. Copyright c © 2012 John Wiley & Sons, Ltd.	algorithm;beowulf cluster;code;dell poweredge;experiment;general-purpose computing on graphics processing units;graphics processing unit;high- and low-level;hyper-threading;john d. wiley;multi-core processor;n-body problem;openmp;programmer;run time (program lifecycle phase);runtime system;sac;sparc;server (computing)	Artjoms Sinkarovs;Sven-Bodo Scholz;Robert Bernecky;Roeland Douma;Clemens Grelck	2014	Concurrency and Computation: Practice and Experience	10.1002/cpe.3078	parallel computing;computer hardware;computer science;operating system;database;distributed computing;data parallelism;programming language;functional programming	HPC	-6.856934982449478	43.464865342491294	83239
e44d2eaf66973b9efbbd3fe948279b8f1069412a	a high performance simulator system for a multiprocessor system based on a multi-way cluster	processor model;multiprocessor system;multi-way cluster;inter-processor communication performance;insufficient performance;communication performance;developed simulator system;inter-processor communication process;high performance;changeable system architecture;high performance simulator system;distributed application;system architecture;high level language	In the ubiquitous era, it is necessary to research the architectures of multiprocessor system with high performance and low power consumption. A simulator developed in high level language is useful because of its easily changeable system architecture including application specific instruction sets and functions. However, there is a problem in processing speed that both PCs and workstations provide insufficient performance for the simulation of a multiprocessor system. In this research, a simulator for a multiprocessor system based on the multi-way cluster was developed, because it was expected to provide the high parallelism and high performance with multiple CPUs on each node. In the developed simulator system, one processor model consists of an instruction set simulator (ISS) process and several inter-processor communication processes. For the maximization of the simulation performance, each processor model is assigned to the specific CPU on the multi-way cluster. Also, each inter-processor communication process is implemented with MPI, which can minimize the CPU resource usage in a communication waiting state. The evaluation results of the processing and communication performance using a distributed application program such as JPEG encoding show that each ISS process in the developed simulator system consumes approximately 100% CPU resources keeping enough inter-processor communication performance. This result means the performance increases in proportion to the number of integrated CPUs on the cluster. This paper concludes the simulator system is useful for the simulation of a multiprocessor system suitable for the ubiquitous era.	central processing unit;distributed computing;expectation–maximization algorithm;high-level programming language;instruction set simulator;jpeg;message passing interface;multiprocessing;parallel computing;simulation;systems architecture;workstation	Arata Shinozaki;Masatoshi Shima;Minyi Guo;Mitsunori Kubo	2006		10.1007/11859802_19	computer science;simulation;real-time computing;parallel computing;computer architecture simulator;instruction set;distributed algorithm;multiprocessing;distributed memory;computer cluster;instruction set simulator;central processing unit	HPC	-14.566633222327729	42.8549429210777	83279
be55b674f2dc83b3afd43da9441faf0c12c657f4	computing trends using graphic processor in high energy physics	computational physics;cluster computing;paper;overview;graphics processor unit;physics;data analysis;high energy physics;graphics processors;high energy physics experiment;monte carlo	One of the main challenges in Heavy Energy Physics is to make fast analysis of high amount of experimental and simulated data. At LHC-CERN one p-p event is approximate 1 Mb in size. The time taken to analyze the data and obtain fast results depends on high computational power. The main advantage of using GPU(Graphic Processor Unit) programming over traditional CPU one is that graphical cards bring a lot of computing power at a very low price. Today a huge number of application(scientific, financial etc) began to be ported or developed for GPU, including Monte Carlo tools or data analysis tools for High Energy Physics. In this paper, we'll present current status and trends in HEP using GPU. Keywordsgpu; high energy physics; trend; overview	approximation algorithm;central processing unit;computation;graphical user interface;graphics processing unit;heterogeneous element processor;large hadron collider;megabyte;monte carlo method	Mihai Niculescu;Sorin-Ion Zgura	2011	CoRR		computational science;parallel computing;computer cluster;computer science;theoretical computer science;data analysis;statistics;monte carlo method;computer graphics (images)	HPC	-6.585816606276964	35.6724348927617	83312
7cf38dec9f490ac20a22f578cce7df0244c06637	time aware genetic algorithm for forest fire propagation prediction: exploiting multi-core platforms	forest fire spread;simulation;genetic algorithm;time aware;calibration;master worker;multi core		genetic algorithm;multi-core processor;software propagation	Tomàs Artés;Andrés Cencerrado;Ana Carolina Castro Côrtes;Tomàs Margalef	2017	Concurrency and Computation: Practice and Experience	10.1002/cpe.3837	multi-core processor;real-time computing;calibration;simulation;genetic algorithm;computer science	PL	-5.906067593321947	33.43166243735135	83391
0898a0b3918cc41e01f84396459ff43c72f9fe72	a multi-paradigm object oriented parallel environment	linear algebra;data parallel;massively parallel systems;object oriented language;performance evaluation;parallel programming;object oriented programming;data encapsulation;parallel processing object oriented modeling parallel programming concurrent computing support vector machines object oriented programming linear algebra jacobian matrices switches message passing;programming model;shared memory systems;object oriented;performance evaluation linear algebra parallel programming object oriented programming object oriented languages data encapsulation shared memory systems;performance results multiparadigm object oriented parallel environment data parallelism control parallelism massively parallel system programming encapsulation sequential object oriented language spmd programming model language extensions shared virtual memory epee eiffel parallel execution environment linear algebra;object oriented languages	Control and data parallelism are two complementary but often mutually exclusive paradigms used to program massively parallel systems. We propose to encapsulate both control and data parallelism in regular classes of a sequential Object Oriented language: a SPMD programming model is used and thus no language extensions are needed, provided a Shared Virtual Memory is available. We show how these ideas are implemented in EPEE, our Eiiel Parallel Execution Environment. As an example, we present the implementation of both paradigms on a toy linear algebra example and show how they can interoperate. We conclude with some performance results and prospectives remarks.	data parallelism;interoperability;linear algebra;parallel computing;programming model;spmd	F. Hamelin;Jean-Marc Jézéquel;Thierry Priol	1994		10.1109/IPPS.1994.288303	first-generation programming language;method;parallel computing;object model;programming domain;reactive programming;computer science;object;object-relational mapping;distributed computing;programming paradigm;programming language;parallel programming model	PL	-14.78313505232168	39.31458220453191	83583
6a56374c0040047be80d617b33cd414c9a3bd627	spec hpg - spec hpg benchmarks	memory bandwidth	SPEC HPG has been creating benchmarks for comparing HPC systems. Currently they have a benchmark suite based on OpenMP (SPEC OMP) and another based on real applications supporting multiple parallel paradigms (SPEC HPC2002). SPEC is now in the process of developing a benhcmark based on MPI applications. This new suite is expected to measure MPI, CPU, compiler, memory bandwidth and interconnect performance. The BOF will focus on SPEC HPG benchmarks and will introduce the new SPEC MPI2006 benchmark.	benchmark (computing);central processing unit;compiler;memory bandwidth;message passing interface;openmp;spec#	Kumaran Kalyanasundaram	2006		10.1145/1188455.1188473	computer architecture;parallel computing;computer science;operating system;memory bandwidth	HPC	-5.535246747563202	44.365572659103144	83690
3192066dd51374cef854b131063e00613b52e3db	on the abstraction of message-passing communications using algorithmic skeletons	modelizacion;distributed system;interprocess communication;systeme reparti;programme tri;algorithmique;guidage;esqueleto;reutilizacion;communicating process;programa ordenacion;abstraction;guiado;abstraccion;reuse;skeleton;proceso comunicante;modelisation;sort routine;sistema repartido;message passing interface;algorithmics;algoritmica;envoi message;processus communicant;algorithmic skeletons;message passing;squelette;guidance;mpi;electronic computers computer science;modeling;reutilisation	This is an initial case on exploring the application of algorithmic skeletons to abstract low-level interprocess communication in MPI. The main purpose is intended to illustrate the competitive performance demonstrated by the skeletal approach when compared to utilization of the pure MPI, whilst providing an abstraction with reusability advantages. This initial work involves the implementation of the Wagar’s hyperquicksort algorithm in conjunction with the MPI-basedeSkelskeleton library. The reported results compare three MPI-based implementations of hyperquicksort. Firstly a canonic MPI one; secondly, two implementations using the MPI-based skeletal library eSkel. Lastly, theS3L sort routine, part of its optimized numerical libraries from Sun, is employed as baseline. This overall comparison demonstrates that the use of algorithmic skeletons caused a slight performance degradation, while providing some promising guidance on the use of abstraction for low-level communication operations using the eSkelmodel.	algorithm;algorithmic skeleton;baseline (configuration management);elegant degradation;high- and low-level;inter-process communication;library (computing);message passing interface;numerical analysis;while	Horacio González-Vélez	2005		10.1007/11533962_5	parallel computing;computer science;message passing interface;theoretical computer science;operating system;database;distributed computing;programming language;algorithmics;algorithm	HPC	-16.525552842086913	42.09675205648972	83696
f57bb715872b5cd05abf1d45f4da3906147fe1ff	parallelizing more loops with compiler guided refactoring	semiautomatic parallelization compiler guided refactoring parallel application performance instruction level parallelism loop level parallelism automatic loop parallelization interactive compilation feedback system application source code modification loop parallel code generation sequential benchmarks image processing edge detection scalable parallelized code eight core intel xeon 5570 system quad core ibm power6 system benchmark performance;kernel;software performance evaluation benchmark testing edge detection parallel programming parallelising compilers program control structures software maintenance;refactoring;software maintenance;edge detection;compiler feedback;refactoring automatic loop parallelization compiler feedback;radiation detectors;program control structures;software performance evaluation;parallel programming;arrays;image edge detection;parallelising compilers;production;optimization;benchmark testing arrays kernel optimization image edge detection production radiation detectors;automatic loop parallelization;benchmark testing	The performance of many parallel applications relies not on instruction-level parallelism but on loop-level parallelism. Unfortunately, automatic parallelization of loops is a fragile process, many different obstacles affect or prevent it in practice. To address this predicament we developed an interactive compilation feedback system that guides programmers in iteratively modifying their application source code. This helps leverage the compiler's ability to generate loop-parallel code. We employ our system to modify two sequential benchmarks dealing with image processing and edge detection, resulting in scalable parallelized code that runs up to 8.3 times faster on an eight-core Intel Xeon 5570 system and up to 12.5 times faster on a quad-core IBM POWER6 system. Benchmark performance varies significantly between the systems. This suggests that semi-automatic parallelization should be combined with target-specific optimizations. Furthermore, comparing the first benchmark to manually-parallelized, hand-optimized pthreads and OpenMP versions, we find that code generated using our approach typically outperforms the pthreads code (within 93-339%). It also performs competitively against the OpenMP code (within 75-111%). The second benchmark outperforms manually-parallelized and optimized OpenMP code (within 109-242%).	automatic parallelization;benchmark (computing);code refactoring;comment (computer programming);demosaicing;edge detection;image processing;instruction-level parallelism;loop-level parallelism;mathematical optimization;multi-core processor;openmp;optimizing compiler;posix threads;platform-specific model;programmer;scalability;semiconductor industry;task parallelism	Per Larsen;Razya Ladelsky;Jacob Lidman;Sally A. McKee;Sven Karlsson;Ayal Zaks	2012	2012 41st International Conference on Parallel Processing	10.1109/ICPP.2012.48	dead code;benchmark;computer architecture;parallel computing;kernel;edge detection;computer science;operating system;programming language;particle detector;software maintenance;code refactoring;code generation	HPC	-6.556786775662807	45.79854831083051	83715
323d85a8a56b4d91c1957a4dc5d89a7a0d5465b9	modeling the input history of programs for improved instruction-memory performance	relative position;bayesian network;instruction memory;memory performance;probabilistic model;operating system;code layout optimization;memory hierarchy;bayesian networks	When a program is loaded into memory for execution the relative position of its basic blocks is crucial, since loading basic blocks that are unlikely to be executed first places them high in the instruction-memory hierarchy only to be dislodged as the execution goes on. In this paper, we study the use of Bayesian networks as models of the input history of a program. The main point is the creation of a probabilistic model that persists as the program is run on different inputs and at each new input refines its own parameters in order to reflect the program’s input historymore accurately. As the model is thus tuned, it causes basic blocks to be reordered so that, upon arrival of the next input for execution, loading the basic blocks into memory automatically takes into account the input history of the program. We report on extensive experiments, whose results demonstrate the efficacy of the overall approach in progressively lowering the execution times of a program on identical inputs placed randomly in a sequence of varied inputs. We provide results on selected SPEC CINT2000 programs and also evaluate our approach as compared with the gcc level-3 optimization and with Pettis–Hansen reordering.	basic block;bayesian network;command (computing);experiment;mathematical optimization;memory hierarchy;randomness;specint;statistical model	Carlos A. G. Assis;Edil S. Tavares Fernandes;Valmir Carneiro Barbosa	2006	Comput. J.	10.1093/comjnl/bxl044	parallel computing;real-time computing;simulation;computer science;operating system;bayesian network;database;programming language;algorithm	SE	-18.236237309750546	37.410719714859965	83807
2107e838692a51814aba372fd52b99fc08be66fb	evaluating the performance of cache-affinity scheduling in shared-memory multiprocessors	calcul matriciel;scientific application;sistema operativo;affinity;shared memory;execution time;multiprocessor;reutilizacion;memoria compartida;affinite;afinidad;priorite;cache memory;reuse;antememoria;aplicacion cientifica;antememoire;operating system;scheduling;temps execution;systeme exploitation;application scientifique;ordonamiento;matrix calculus;multiprocesador;tiempo ejecucion;priority;prioridad;calculo de matrices;ordonnancement;memoire partagee;reutilisation;shared memory multiprocessor;multiprocesseur	As a process executes on a CPU, it builds up state in that CPU's cache. In multipro-grammed workloads, the opportunity to reuse this state may be lost when a process gets rescheduled, either because intervening processes destroy its cache state or because the process may migrate to another processor. In this paper, we explore aanity scheduling, a technique that helps reduce cache misses by preferentially scheduling a process on a CPU where it has run recently. Our study focuses on a bus-based multiprocessor executing a variety of workloads, including mixes of scientiic, software development, and database applications. In addition to quantifying the performance beneets of exploiting aanity, our study is distinctive in that it provides low-level data from a hardware performance monitor that details why the workloads perform as they do. Overall, for the workloads studied, we show that aanity scheduling reduces the number of cache misses by 7{36%, resulting in execution time improvements of up to 10%. Although the overall improvements are small, modifying the OS scheduler to exploit aanity appears worthwhile|aanity has no negative impact on the workloads and we show that it is extremely simple to add to existing schedulers.	cpu cache;central processing unit;database;high- and low-level;multiprocessing;operating system;processor affinity;run time (program lifecycle phase);scheduling (computing);shared memory;software development	Josep Torrellas;Andrew Tucker;Anoop Gupta	1995	J. Parallel Distrib. Comput.	10.1006/jpdc.1995.1014	shared memory;parallel computing;real-time computing;multiprocessing;cpu cache;matrix calculus;computer science;operating system;reuse;distributed computing;scheduling	Arch	-16.053977471767933	44.42012738458682	83833
ebe362f91cad2f1206788a48fc95f9717913134a	experiences with slalom on the distributed pleiades/esp system		The paper describes experiences gained during the process of Implementing a standard serial benchmark (SLALOM) on a distributed computing system (Pleiades running ESP/C++). Based on a real problem In computer graphics, SLALOM Is a timed benchmark that Includes problem set-up and I/O costs. The purpose of our experiments has been to maximize the speedup of a distributed implementation of SLALOM when compared to Its serial implementation. As a result of these experiments, we have developed several guidelines for adapting algorithms for distributed systems.	pleiades (supercomputer)	Unda F. Wilson;Mario J. Gonzalez;Michael W. Cruess	1993	Concurrency - Practice and Experience	10.1002/cpe.4330050408	parallel computing;computer science;distributed computing;speedup;computer graphics	OS	-10.982518018400743	40.792391436652544	84064
3d3bdae2618c54bdc150bd824fe3733dfc3f27bc	accurate static branch prediction by value range propagation	register allocation;branch prediction;static single assignment;source code;instruction scheduling;constant propagation	The ability to predict at compile time the likelihood of a particular branch being taken provides valuable information for several optimizations, including global instruction scheduling, code layout, function inlining, interprocedural register allocation and many high level optimizations. Previous attempts at static branch prediction have either used simple heuristics, which can be quite inaccurate, or put the burden onto the programmer by using execution profiling data or source code hints. This paper presents a new approach to static branch prediction called value range propagation. This method tracks the weighted value ranges of variables through a program, much like constant propagation. These value ranges may be either numeric of symbolic in nature. Branch prediction is then performed by simply consulting the value range of the appropriate variable. Heuristics are used as a fallback for cases where the value range of the variable cannot be determined statically. In the process, value range propagationsubsumes both constant propagation and copy propagation. Experimental results indicate that this approach produces significantly more accurate predictions than the best existing heuristic techniques. The value range propagation method can be implemented over any “factored” dataflow representation with a static single assignment property (such as SSA form or a dependence flow graph where the variables have been renamed to achieve single assignment). Experimental results indicate that the technique maintains the linear runtime behavior of constant propagation experienced in practice.	assignment (computer science);branch predictor;compile time;compiler;constant folding;copy propagation;dataflow;heuristic (computer science);high-level programming language;inline expansion;instruction scheduling;programmer;register allocation;scheduling (computing);software propagation;static single assignment form	Jason R. C. Patterson	1995		10.1145/207110.207117	parallel computing;real-time computing;computer science;theoretical computer science;instruction scheduling;programming language;sparse conditional constant propagation;static single assignment form;register allocation;constant folding;branch predictor;source code	PL	-17.87139152050242	36.80653005962884	84156
418b19fa28022837924785b112a718263fe8dc13	use of parallel computing and visualisation techniques in the simulation of large scale geoenvironmental engineering problems	parallel computing;iterative solver;3d visualisation;parallel algorithm;data analysis;large scale;geoscience;parallel computer;geoenvironmental;nuclear waste disposal	This paper discusses some of the computational and visualisation challenges encountered in the field of geoenvironmental engineering. The use of iterative solvers and parallel computation methods are identified as being of particular relevance to addressing the computation challenges. 3D stereoscopic visualisation is discussed in relation to data analysis and communication. An example analysis is presented related to the issue of nuclear waste disposal where the use of iterative solvers and parallel algorithms was found to yield significant results.	computation;discretization;iterative method;optimization problem;parallel algorithm;parallel computing;prototype;relevance;simulation;stereoscopy;visualization (graphics);while	Peter J. Cleall;Hywel R. Thomas;Troy A. Melhuish;David-Huw Owen	2006	Future Generation Comp. Syst.	10.1016/j.future.2005.04.006	computational science;parallel computing;computer science;theoretical computer science;parallel algorithm;data analysis;radioactive waste	HPC	-7.0406596208675944	36.79310206819339	84274
16a8fb4a91e1b40c89355eb78a6cff33a8ea0973	the search for performance in scientific processors (turing award lecture)	scientific processor;turing award lecture	I am honored and grateful to have been selected to join the ranks of ACM Turing Award winners. I probably have spent too much of my life thinking about computers, but I do not regret it a bit. I was fortunate to enter the field of computing in its infancy and participate in its explosive growth. The rapid evolution of the underlying technologies in the past 30 years has not only provided an exciting environment, but has also presented a constant stream of intellectual challenges to those of us trying to harness this power and squeeze it to the last ounce. I hasten to say, especially to the younger members of the audience, there is no end in sight. As a matter of fact, I believe the next thirty years will be even more exciting and rich with challenges. The three principal contributors to performance in scientific processors are the algorithm, the compiler, and the machine organization. When possible, the simultaneous optimization of these three factors holds the key to the highest possible performance. Of the three contributors, algorithm improvements are the most important. An idea that changes an algorithm from N**2 to N* log N operations, where N is proportionate to the number of input elements, is considerably more spectacular than an improvement in machine organization, where only a constant factor of run-time is achieved. Unfortunately, really exploiting the characteristics of a particular algorithm in the underlying machine organization often results in a specialized computer that will not perform well on most other algorithms. Signal processors are an example of this. They handle information transforms very fast, even i.n one clock cycle, but can be extremely inefficient :in computing anything else. My interests have been in achieving high performance for a broad range of scientific calculations. There-	acm turing award;algorithm;central processing unit;clock signal;compiler;computer;mathematical optimization;regret (decision theory)	John Cocke	1988	Commun. ACM	10.1145/42392.42394	computational science;computer science;artificial intelligence	HPC	-8.42282488505033	33.29313837936147	84330
869087f5481cdfee3a9a6ee29425382f88747032	an empirical study of the performance and productivity of two parallel programming models	empirical study;computer languages;shared memory;parallel programming languages;time measurement;productivity parallel programming testing message passing programming profession time measurement performance analysis computer languages parallel processing parallel languages;high performance computing;unified parallel c parallel programming models parallel programming languages program performance programmer productivity hpc high performance computing message passing mpi shared memory programming paradigms upc;parallel programming;statistical significance;unified parallel c;testing;upc;hpc;parallel programming models;observational study;programming profession;performance analysis;message passing;parallel programming message passing parallel languages;mpi;shared memory programming paradigms;program performance;productivity;parallel programming model;programmer productivity;parallel languages;empirical evaluation;parallel processing;hypothesis test	The choice of parallel programming models and languages is a major factor in program performance and programmer productivity in HPC. However, evaluation of their relative merits is usually done based on conventional wisdom and subjective beliefs. We present a quantitative approach to evaluate such hypotheses statistically and validate them with empirical data. We apply this approach to compare two languages representing the message passing (MPI) and shared memory programming (UPC) paradigms. We formulate hypothesis tests for comparing the performance and productivity of these two models and evaluate them with data from observational studies of HPC programmers. We present and analyze several results, some of which are statistically significant, that demonstrate the promise of empirical evaluation in HPC development.	correctness (computer science);high productivity computing systems;image scaling;message passing;parallel computing;partitioned global address space;profiling (computer programming);programmer;programming productivity;shared memory;speedup;threat (computer);universal product code	Imran Patel;John R. Gilbert	2008	2008 IEEE International Symposium on Parallel and Distributed Processing	10.1109/IPDPS.2008.4536192	shared memory;parallel processing;statistical hypothesis testing;computer architecture;productivity;supercomputer;parallel computing;message passing;computer science;message passing interface;distributed computing;statistical significance;universal product code;software testing;programming language;empirical research;observational study;time;parallel programming model	HPC	-7.030415787290857	44.77883327567751	84340
18660e6ad0d154fde71f3822a2d70ed9bae04761	estimating execution time of distributed applications	distributed application;distributed system;programa paralelo;evaluation performance;estacion trabajo;systeme reparti;performance evaluation;execution time;ordinateur parallele;station travail;evaluacion prestacion;simultaneidad informatica;cluster of workstations;workstation;concurrency;sistema repartido;scheduling;clusters of workstations;ordenador paralelo;parallel computer;communication delay;temps execution;ordonamiento;tiempo ejecucion;simultaneite informatique;parallel program;ordonnancement;communication delays;programme parallele	In this work we consider the problem of estimating execution time of distributed applications. The main difficulty stems from the communication delays and shared nature of the computing and communication media. A simple method taking into account communications and concurrency of computations is proposed to estimate the execution time of a distributed application. The proposed technique is evaluated in a sequence of experiments. It is demonstrated that this method is feasible. Other interesting consequences are also outlined.	computation;concurrency (computer science);distributed computing;experiment;profiling (computer programming);run time (program lifecycle phase);usability	Maciej Drozdowski	2001		10.1007/3-540-48086-2_15	parallel computing;real-time computing;workstation;concurrency;computer science;operating system;distributed computing;scheduling;distributed concurrency control	HPC	-17.010755592785614	43.84891463131462	84434
97ee49e2cba694228ff6f63c44f9ea7c504476d6	efficient trigger-broadcasting in heterogeneous clusters	distributed system;algoritmo paralelo;cluster computing;systeme reparti;parallel algorithm;personal computer;collective communication;heterogeneous cluster;racimo calculadura;distributed computing;radiodifusion;heterogeneous clusters;nows;parallel computation;algorithme parallele;grappe calculateur;calculo paralelo;sistema repartido;parallel computer;calculo repartido;broadcasting;algoritmo optimo;algorithme optimal;optimal algorithm;calcul parallele;calcul reparti;algorithme declenchement;radiodiffusion	Broadcasts in parallel computing environments are often used to trigger ''personal'' computations at the processors (or, nodes) that comprise the system. (The qualifier ''personal'' means that the triggered computations may differ in type and complexity at each node.) We present an algorithm for trigger-broadcasting in a node-heterogeneous cluster of workstations, which comes predictably close to minimizing the time for completing both the broadcast and the computations it triggers. The algorithm orchestrates its broadcast taking account of: the speeds of the cluster's constituent workstations, the speed of the cluster's network, and the complexities of the computations that the broadcast triggers. The algorithm is within a constant factor of optimal when the speeds of the cluster's workstations and of its network are independent of the number of workstations. The algorithm is exactly optimal when the cluster is homogeneous-no matter how diverse the ''personal'' computations are.		Pierre Fraigniaud;Bernard Mans;Arnold L. Rosenberg	2005	J. Parallel Distrib. Comput.	10.1016/j.jpdc.2004.12.003	parallel computing;computer cluster;computer science;theoretical computer science;operating system;distributed computing;parallel algorithm;broadcasting	HPC	-16.61498676751598	44.05808882438238	84662
a7eebe3c088b430bfe26cc6b0d1524cfedff6945	parallel performance results for the openmoc neutron transport code on multicore platforms	neutron transport;method of characteristics;openmp;multicore processors	The shift towards multi-core architectures has ushered in a new era of shared memory parallelism for scientific applications. This transition has introduced challenges for the nuclear engineering community as it seeks to design high-fidelity full-core reactor physics simulation tools. This paper describes the parallel transport sweep algorithm in the OpenMOC method of characteristics (MOC) neutron transport code for multi-core platforms using OpenMP. Strong and weak scaling studies are performed for both Intel Xeon and IBM Blue Gene/Q multi-core processors. The results demonstrate 100% parallel efficiency for 12 threads on 12 cores on Intel Xeon platforms, and over 90% parallel efficiency with 64 threads on 16 cores on the IBM Blue Gene/Q. These results illustrate the potential for hardware acceleration for MOC neutron transport on modern multi-core and future many-core architectures. In addition, this work highlights the pitfalls of programming for multi-core architectures, with a focal point on false sharing.	algorithm;blue gene;central processing unit;dynamical simulation;focal (programming language);false sharing;hardware acceleration;image scaling;manycore processor;multi-core processor;openmp;parallel computing;reactor (software);scalability;shared memory;speedup	William Boyd;Andrew R. Siegel;Shuo He;Benoit Forget;Kord Smith	2016	IJHPCA	10.1177/1094342016630388	neutron transport;multi-core processor;computer architecture;parallel computing;computer science;method of characteristics;operating system	HPC	-6.09662062523073	39.21222786668782	84771
efa95b4d911e4e043189f995347d9355342d8678	compiling away soft trajectory constraints in planning		Soft goals in planning are optional objectives that should be achieved in the terminal state. However, failing to achieve them does not result in the plan becoming invalid. State trajectory constraints are hard requirements towards the state trajectory of the plan. Soft trajectory constraints are a combination of both: soft preferences on how the hard goals are reached, i. e., optional requirements towards the state trajectory of the plan. Such a soft trajectory constraint may require that some fact should be always true, or should be true at some point during the plan. The quality of a plan is then measured by a metric which adds the sum of all action costs and a penalty for each failed soft trajectory constraint. Keyder and Geffner showed that soft goals can be compiled away. We generalize this approach and illustrate a method of compiling soft trajectory constraints into conditional effects and state dependent action costs using LTLf and deterministic finite automata. We provide two compilation schemes, with and without reward shaping, by rewarding and penalizing different states in the plan. With this we are able to handle such soft trajectory constraints without the need of altering the search algorithm or heuristics, using classical planners.	automata theory;benchmark (computing);compiler;deterministic finite automaton;experiment;failure;finite-state machine;heuristic (computer science);noise shaping;partial-order planning;requirement;search algorithm;soft goal;solid-state drive	Benedict Wright;Robert Mattmüller;Bernhard Nebel	2018				AI	-15.80082134676675	32.34532900687334	84801
8664fd144303f18471fcd4cb0fb2c9382a13e924	compilation of a functional language for the multithreaded architecture: davrid	parallel programming language;multithreaded architecture;functional language;parallel processing;massively parallel processing	Multithreading has been much focused on as one of the strongest parallel instruction execution paradigms for massively parallel processing. In this paper, we describe the compilation processes of parallel programming language Id~ for a multithreaded architecture DAVRIDfDAtaflow Von Neumann RISC hybrlD). Two fundamental issues in parallel processing, tolerance to communication latency and inexpensive synchronization, are solved by a compiler-controlled multithreading. Our compiler features a simple mechanism for handling closures, and a loop unfolding technique for handling parallel and sequential loops in separate, which can greatly contribute to parallel execution of loops.	compiler;functional programming;multithreading (computer architecture);parallel computing;parallel programming model;programming language;thread (computing);unfolding (dsp implementation);von neumann architecture	Eunha Rho;Sangho Ha;Sang-Yong Han;H. H. Kim;Daejoon Hwang	1994		10.1109/ICPP.1994.70	parallel processing;computer architecture;parallel computing;embarrassingly parallel;computer science;massively parallel;programming language;parallel programming model	HPC	-13.920582194967405	40.06847131906621	84869
1af0fbae28a0eaa5aeff8877897ab55765fdf844	an integrated computation system for the era-1103	integrated computation system	"""The development of faster, more capacious, and more expensive computers has brought with it larger programnfing staffs, more handling of programming material outside the computer, and the urgent need to make the most of the scheduled production time of the computer. In order to make efficient use of machine and personnel time, the programming staff at The Ramo-Wooldridge Corporation has developed a computation scheme for the ERA-1103 in which almost all data for program assembly and check out is stored in its most convenient and readily accessible form on magnetic drum and magnetic tape. Since part of the information stored is the means for handling the information itself, the system is automatic; appropriate data transfers are made, check sums computed, translation and input-output functions performed, and suitable indications given in the case of untoward circumstances. The computation system has been in operation since April, 1955. The accomplishment of this system represents the belief that """"automatic programming"""" means a great deal more than an assembly or compiler program. The input language should properly be only a part of an over-all system to optimize the use of the computer in reducing programmer, computer, and clerical time in bringing problems to the production stage. The ERA-1103 computer is especially adapted to an integrated computation system involving the internal storage of a comprehensive system of service and subroutines. Besides the 1024 words of electrostatic storage serving as the quick-access internal storage of the computer, the 1103 has 16,384 words of drum storage also regarded as internal storage since all drum addresses may be used in the instructions. The computer employs a two-address logic having many useful and powerful instructions. The speed of operation for electrostatic storage operands ranges from approximately 40 microseconds for a transfer operation from one cell to another, to approximately 250 microseconds for multiplication of 36-bit numbers. The input-output organization of the computer is such that almost all the time of the input-output equipment cycle may be used for computation and two or more equipments may be used simultaneously. The system makes use of two input-output registers which serve as buffer storage to the equipments. The units connected to The Ramo-Wooldridge 1103 allow handling of paper tape or punched card information as follows: a card reproducer for card input-output, a line printer, a Ferranti paper tape reader, a 60 Character per second paper tape punch, and an electric typewriter. The main feature of the computation system consists of the storage of the entire utility routine library on the magnetic drum locations with allocations as"""	36-bit;assembly language;automatic programming;compiler;computation;computer;drum memory;mathematical optimization;operand;printer (computing);programmer;punched card;subroutine;univac 1103	Walter F. Bauer	1956	J. ACM	10.1145/320831.320836	model of computation	Arch	-14.252397076803332	33.256653651936745	85126
3754127df3993be7182a56a30ca6460aadfa6658	performance, scalability and object-orientation in discrete graph-based simulation models	object oriented;data structure;simulation model;three dimensions;regular graph;euclidean space;phase space	Many interesting simulation problems in computational physics and engineering are posed on a regular data structure, such as a lattice, in two or three dimensions. There is increasing interest however in studying systems on less regular graphs that are embedded in Euclidean spaces of dimensions higher than three. We report on our experiences in attempting to formulate a highly general object-oriented framework in Java for simulating complex model systems on a generalised mesh in arbitrary dimensions and connectivity geometry. We discuss the performance and scalability issues that arose for managing large-scale complex model simulations and exploring their phase-spaces.	code;compiler;complex systems;computational physics;data structure;embedded system;experience;iteration;java;lattice model (physics);library (computing);matlab;run time (program lifecycle phase);scalability;simulation;specification language;supercomputer;wolfram mathematica	Kenneth A. Hawick;Heath A. James	2005			discrete mathematics;lattice graph;euclidean space;beta skeleton;simulation modeling;scalability;theoretical computer science;regular graph;euclidean geometry;data structure;mathematics	HPC	-10.141129791412414	36.70194213545431	85133
dcec92d434ffa19d183668b7ac9de88ca8721aac	debugging of heterogeneous parallel systems	distributed system;parallel systems	The Agora system supports the development of heterogeneous parallel programs, e.g. programs written in multiple languages and running on heterogeneous machines. Agora has been used since September 1986 in a large distributed system [1]: Two versions of the application have been demonstrated in one year, contrary to the expectation of two years per one version. The simplicity in debugging is one of the reasons of the productivity speedup gained. This simplicity is due both to the deeper understanding that the debugger has of parallel systems, and to a novel feature: the ability to replay the execution of parallel systems built with Agora. A user is able to exactly repeat for any number of times and at a slower pace an execution that failed. This makes it easy to identify time-dependent errors, which are peculiar to parallel and distributed systems. The debugger can also be customized to support user defined synchronization primitives, which are built on top of the system provided ones. The Agora debugger tackles three set of problems that no parallel debugger in the past has simultaneously addressed: dealing with programming-in-the-large, multiple processes in different languages, and multiple machine architectures.	agora;debugger;debugging;distributed computing;heterogeneous computing;programming in the large and programming in the small;speedup;synchronization (computer science)	Alessandro Forin	1988		10.1145/68210.69228	parallel computing;real-time computing;computer science;distributed computing;programming language	HPC	-13.055718287517044	39.848305749318655	85223
729c911b6ea94e81cb7b993d7ce24222a49e2e60	performance evaluation of priority queues for fine-grained parallel tasks on gpus		Graphics processing units (GPUs) are increasingly applied to accelerate tasks such as graph problems and discreteevent simulation that are characterized by irregularity, i.e., a strong dependence of the control flow and memory accesses on the input. The core data structure in many of these irregular tasks are priority queues that guide the progress of the computations and which can easily become the bottleneck of an application. To our knowledge, currently no systematic comparison of priority queue implementations on GPUs exists in the literature. We close this gap by a performance evaluation of GPU-based priority queue implementations for two applications: discrete-event simulation and parallel A* path searches on grids. We focus on scenarios requiring large numbers of priority queues holding up to a few thousand items each. We present performance measurements covering linear queue designs, implicit binary heaps, splay trees, and a GPU-specific proposal from the literature. The measurement results show that up to about 500 items per queue, circular buffers frequently outperform tree-based queues for the considered applications, particularly under a simple parallelization of individual item enqueue operations. We analyze profiling metrics to explore classical queue designs in light of the importance of high hardware utilization as well as homogeneous computations and memory accesses across GPU threads.	a* search algorithm;agent-based model;circular buffer;computation;control flow;core data;data structure;futures studies;graphics processing unit;heap (data structure);parallel computing;performance evaluation;priority queue;run time (program lifecycle phase);sequential access;simulation;splay tree;thread (computing);vergence	Nikolai Baudis;Florian Jacob;Philipp Andelfinger	2017	2017 IEEE 25th International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems (MASCOTS)	10.1109/MASCOTS.2017.15	real-time computing;priority queue;distributed computing;profiling (computer programming);splay tree;thread (computing);data structure;computer science;bottleneck;heap (data structure);queue	Arch	-8.701774594337603	45.592057012398506	85340
b3bd374752659aa65c8b5a59b7cd25a94153f593	"""early evaluation of the """"infinite memory engine"""" burst buffer solution"""				Wolfram Schenck;Salem El Sayed;Maciej Foszczynski;Wilhelm Homberg;Dirk Pleiter	2016		10.1007/978-3-319-46079-6_41	embedded system;real-time computing;computer hardware	Logic	-9.934238242520866	44.52413704919567	85368
e223c126c738f1f838b3c0d5a5b021bb86d19411	distributed dynamic hardware operating system for multiport reconfigurable memory	operating system		operating system	Steven I. Kartashev;Svetlana P. Kartashev	1982			parallel computing;embedded system;computer science;embedded operating system	Arch	-9.897812821688944	43.519467701004224	85374
0b24a92bd075be0a13c86440087fbbd01f273720	quantum dynamics simulation of electrons in materials on high-performance computers	computational materials science;high performance computing;materials engineering;ions;electronic structure level quantum dynamics simulation high performance computers complex material property calculation modern leadership class supercomputers ehrenfest nonadiabatic electron ion dynamics floating point processing units leadership class computing architecture energy transfer high energy particle crystalline gold hydrogen atom;materials;quantum computing electronic structure floating point arithmetic gold hydrogen materials science computing parallel architectures parallel machines;hpc;gold;scientific computing;mathematical model;scientific computing quantum electron dynamics high performance computing hpc computational materials science;high performance computing mathematical model equations projectiles quantum computing materials engineering scientific computing;quantum computing;projectiles;quantum electron dynamics	Advancement in high-performance computing allows us to calculate properties of increasingly complex materials with unprecedented accuracy. At the same time, to take full advantage of modern leadership-class supercomputers, the calculations need to scale well on hundreds of thousands of processing cores. We demonstrate such high scalability of our recently developed implementation of Ehrenfest non-adiabatic electron-ion dynamics up to 1 million floating-point processing units on two different leadership-class computing architectures. As a representative example of material properties that derive from quantum dynamics of electrons, we demonstrate the accurate calculation of electronic stopping power, which characterizes the rate of energy transfer from a high-energy particle to electrons in materials. We discuss the specific case of crystalline gold with a hydrogen atom as the high-energy particle, and we illustrate detailed scientific insights that can be obtained from the quantum dynamics simulation at the electronic structure level. Please note that two animation videos of the time evolution for Figure 3 are available as Web extras at http://youtu.be/WxiMZ2DVBbM and http://youtu.be/bAcaxF9ARzM.	ehrenfest model;electron;electronic structure;hydrogen;quantum dynamics;scalability;simulation;supercomputer	André Schleife;Erik W. Draeger;Victor M. Anisimov;Alfredo A. Correa;Yosuke Kanai	2014	Computing in Science & Engineering	10.1109/MCSE.2014.55	gold;computational science;supercomputer;parallel computing;simulation;computer science;theoretical computer science;operating system;projectile;mathematical model;mathematics;quantum computer;physics;algorithm;quantum mechanics;statistics;ion	HPC	-5.627009120779964	37.08387526057663	85434
c7f26f03e943fab569cd85eff4c83b689280c9ba	tomographic image reconstruction using abstractions	high level parallel constructions;abstractions;image reconstruction;concurrence;object orientation;threads	New trends in High Performance Computing Architectures are arising an old concept, concurrence. But concurrence is not parallelism. To afford parallelism in the new computing arena, parallel applications need to consider this or just being completely rewritten in such a way that parallelism can be expressed by means of concurrence. Abstractions may help to keep performance on the new, and also on the legacy, platforms. This paper shows how abstractions may play an important role when used to model the problem.	iterative reconstruction;tomography	José Antonio Álvarez-Bermejo;Javier Roca Piera	2009		10.1007/978-3-642-04772-5_44	iterative reconstruction;thread;computer science;theoretical computer science;distributed computing;abstraction;data parallelism;object-orientation;algorithm;task parallelism	Vision	-14.061221436605232	39.84365792344512	85534
92f4a5901726147700c0736614c5a2331efeb313	automated detection of structured coarse-grained parallelism in sequential legacy applications	thesis or dissertation;compilers;multicore;programming;automatic parallelization;skeletons	The e cient execution of sequential legacy applications on modern, parallel computer architectures is one of today’s most pressing problems. Automatic parallelization has been investigated as a potential solution for several decades but its success generally remains restricted to small niches of regular, array-based applications. This thesis investigates two techniques that have the potential to overcome these limitations. Beginning at the lowest level of abstraction, the binary executable, it presents a study of the limits of Dynamic Binary Parallelization (Dbp), a recently proposed technique that takes advantage of an underlying multicore host to transparently parallelize a sequential binary executable. While still in its infancy, Dbp has received broad interest within the research community. This thesis seeks to gain an understanding of the factors contributing to the limits of Dbp and the costs and overheads of its implementation. An extensive evaluation using a parameterizable Dbp system targeting a Cmp with light-weight architectural Tls support is presented. The results show that there is room for a significant reduction of up to 54% in the number of instructions on the critical paths of legacy Spec Cpu2006 benchmarks, but that it is much harder to translate these savings into actual performance improvements, with a realistic hardware-supported implementation achieving a speedup of 1.09 on average. While automatically parallelizing compilers have traditionally focused on data parallelism, additional parallelism exists in a plethora of other shapes such as task farms, divide & conquer, map/reduce and many more. These algorithmic skeletons, i.e. high-level abstractions for commonly used patterns of parallel computation, differ substantially from data parallel loops. Unfortunately, algorithmic skeletons are largely informal programming abstractions and are lacking a formal characterization in terms of established compiler concepts. This thesis develops compilerfriendly characterizations of popular algorithmic skeletons using a novel notion of commutativity based on liveness. A hybrid static/dynamic analysis framework for the context-sensitive detection of skeletons in legacy code that overcomes limitations of static analysis by complementing it with profiling information is described. A proof-of-concept implementation of this framework in the Llvm compiler infrastructure is evaluated against Spec Cpu2006 benchmarks for the detection of a	acm/ieee supercomputing conference;algorithmic skeleton;amdahl's law;analysis of algorithms;antivirus software;approximation;artificial intelligence;automatic parallelization;benchmark (computing);binary code;binary file;binary translation;born–haber cycle;branch (computer science);c++;cobol;cp/m;central processing unit;certificate authority;cloud computing;code coverage;code generation (compiler);combinational logic;computation;concurrency (computer science);concurrent computing;context-sensitive grammar;control flow;data dependency;data parallelism;data-flow analysis;dataflow architecture;de morgan's laws;dependence analysis;design automation conference;digital signal processor;diwan-khane;dynamic data;dynamic programming;embedded system;entity–relationship model;executable;fm towns marty;finite-state machine;for loop;franz lisp;gesellschaft für informatik;gillespie algorithm;gprof;graphics processing unit;grid computing;https;harris affine region detector;heart rate variability;herbert w. franke;hierarchical editing language for macromolecules;high- and low-level;holism;holographic principle;icpads;icse;ieee transactions on computers;ims associates, inc.;information processing letters;instruction-level parallelism;integer programming;international conference on architectural support for programming languages and operating systems;international federation for information processing;international parallel and distributed processing symposium;international symposium on computer architecture;international symposium on microarchitecture;iteration;iterative method;java;job control (unix);john d. wiley;jones calculus;just-in-time compilation;koch snowflake;kota the triceratops;lam/mpi;llvm;lecture notes in computer science;legacy code;linked data structure;list comprehension;list of astronomical catalogues;liveness;logic gate;low-power broadcasting;mpsoc;mapreduce;mathematical optimization;message passing;michael scaife;moore's law;multi-core processor;multiprocessing	Tobias Joseph Kastulus Edler Von Koch	2014			computer architecture;parallel computing;computer science;programming language;automatic parallelization	PL	-16.066960982999692	38.15671831667452	85890
51c146e2a37ddcc4ee165966c2121a49c650c066	research on optimal path of data migration among multisupercomputer centers		Data collaboration between supercomputer centers requires a lot of data migration. In order to increase the efficiency of data migration, it is necessary to design optimal path of data transmission among multisupercomputer centers. Based on the situation that the target center which finished receiving data can be regarded as the new source center to migrate data to others, we present a parallel scheme for the data migration among multisupercomputer centers with different interconnection topologies using graph theory analysis and calculations. Finally, we verify that this method is effective via numeric simulation.		Gang Li;Qingpu Zhang;Zhengqian Feng	2016	Scientific Programming	10.1155/2016/5018213	parallel computing;computer science;database;distributed computing	HPC	-6.72578564277433	40.35673244005425	85956
f8281d0e94f1d81db783f53289eba49f51fe80bb	choosing the best resource by method of mamdani	cluster computing	В современном мире одной из важных задач является задача передачи и хранения информации. Данная статья посвящается поиску оптимального ресурса для хранения информации. Роль и важность системы хранения определяются постоянно возрастающей ценностью информации в современном обществе. Возможность доступа к данным и управления ими является необходимым условием для выполнения любых задач. Безвозвратная потеря данных может привести к фатальным последствиям. Утраченные вычислительные ресурсы можно восстановить, а утраченные данные, при отсутствии грамотно спроектированной и внедренной системы резервирования, уже не подлежат восстановлению. Разработка разного рода «распределенных файловых систем» в настоящее время является одной из активно развиваемых областей информатики. Большинство таких систем работает на основе изготовления множества полных копий данных, хранимых в разных местах, и обеспечения различных механизмов синхронизации этих данных. Авторы статьи предлагают использовать аппарат нечеткой логики при выборе ресурса для хранения информации. Предложенный способ позволяет быстро и эффективно выбирать такой ресурс. Практический опыт разработки систем нечеткого логического вывода свидетельствует, что сроки и стоимость их проектирования значительно меньше, чем при использовании традиционного математического аппарата. При этом обеспечивается требуемый уровень робастности и прозрачности моделей. Каждый ресурс обладает следующими характеристиками: скорость доступа (будем измерять в Mb/s), надежность (процент времени непрерывной работы), концентрация (процент информации уже находящейся на ресурсе). Использование одного ресурса или сервиса для хранения всей информации авторы считают не целесообразным. Методом Мамдани для каждого ресурса вычислим вероятность того, что на данный ресурс будет загружена очередная порция информации.	mebibyte	Elena Legchekova;Oleg Titov	2011	CoRR		computer cluster;computer science;artificial intelligence;operating system;machine learning;data mining	NLP	-8.620613941298096	42.26745761523158	86000
91bb93301056525ae378defeff8dbc53d6e98846	compilation optimisante pour processeurs extensibles. (optimizing compilation for extensible processors)			optimizing compiler	Antoine Floch	2012				DB	-17.42900466983362	39.55019913183187	86196
a9836593ea0a4f6ce957e318aded844caad8cd5d	revisiting thread execution methods for gpu-oriented opencl programs on multicore processors		OpenCL is one of the most popular frameworks for parallel computing. OpenCL is platform independent in principle, and OpenCL programs can be executed on various hardware platforms such as GPUs, multicore processors and FPGAs. However, OpenCL programs written for GPUs are often poorly executed on multicore processors in terms of performance due to the granularity of threads. This paper addresses efficient execution of GPU-oriented OpenCL programs on multicore processors. This paper solves a couple of draw-backs in an existing OpenCL framework and shows the effectiveness of this work through experiments.		Takafumi Miyazaki;Hayato Hidari;Naohisa Hojo;Ittetsu Taniguchi;Hiroyuki Tomiyama	2018	2018 Sixth International Symposium on Computing and Networking Workshops (CANDARW)	10.1109/CANDARW.2018.00101	field-programmable gate array;parallel computing;granularity;multi-core processor;thread (computing);computer science	Arch	-6.249145992785644	45.3331270804661	86387
8d22399396d21bb985a96c022cf6968ce170d0da	service without servers	libraries;policies;computer architecture;operating system;high performance;operating systems computers;systems approach	We propose a new style of operating system architecture appropriate for microkernel-based operating systems: services are implemented as a combination of shared libraries and dedicated server processes. Shared libraries implement performance critical portions of each system service, while dedicated servers implement the parts of each service that do not require high performance or that are diicult to implement in an application. Our initial experiments show that this approach to operating system structure can yield performance that is comparable to monolithic kernel systems while retaining all the modularity advantages of microkernel technology. Since services reside in libraries, an application is free to use the library that is most appropriate. This approach can even yield better performance than monolithic kernel systems by allowing the shared libraries to be closely coupled with the applications, thereby exploiting application-speciic knowledge in policy decisions.	dedicated hosting service;experiment;library (computing);microkernel;monolithic kernel;operating system;server (computing);systems architecture	Chris Maeda;Brian N. Bershad	1993			embedded system;embedded operating system;real-time computing;computer science;operating system;systems thinking	OS	-12.740329265258115	45.18535976159115	86490
42d118488f0365c5352e0b7c31ac6f3a08940411	ameeda: a general-purpose mapping tool for parallel applications on dedicated clusters	distributed application;interfase usuario;appel procedure;user interface;extraccion parametro;parameter extraction;multigraph;llamada procedimiento;automatic mapping for efficient execution of distributed application;extraction parametre;multigrafo;interface utilisateur;multigraphe;application repartie;procedure call;article;application parallele	The mapping of parallel applications constitutes a difficult problem for which very few practical tools are available. AMEEDA has been developed in order to overcome the lack of a general-purpose mapping tool. The automatic services provided in AMEEDA include instrumentation facilities, parameter extraction modules and mapping strategies. With all these services, and a novel graph formalism called TTIG, users can apply different mapping strategies to the corresponding application through an easy-to-use GUI, and run the application on a PVM cluster using the desired mapping.		Xiao Yuan;Concepció Roig;Ana Ripoll;Miquel A. Senar;Fernando Guirado;Emilio Luque	2002		10.1007/3-540-45706-2_32	computer science;theoretical computer science;operating system;multigraph;database;distributed computing;user interface	HPC	-18.15656641433409	41.546899729394035	86566
b9430420c77b897920711d5a999b4326fa16a479	predicting cpu utilization by fuzzy stochastic prediction	theorie stochastique;prediccion;eficacia sistema;evaluation performance;base donnee;performance evaluation;stochastic method;evaluacion prestacion;logique floue;performance systeme;database;base dato;logica difusa;system performance;teoria estocastica;fuzzy logic;methode stochastique;stochastic theory;prediction;metodo estocastico	In this paper, we use the fuzzy stochastic technique to predict the mainframe's CPU utilization from the given database of IBM's OS/390 system log at a specific time. Consequently, system programmers can tune the system to improve its performance by moving out the unimportant jobs during the peak time. To address this issue, we proposed an effective method, a fuzzy stochastic prediction (FSP), to predict the CPU utilization in a specific time. The fuzzy stochastic variable is a parameter in FSP, which is generated by the recent system behavior.	central processing unit	Yi-Fan Wang;Mei-Hua Hsu;Yu-Liang Chuang	2001	Computers and Artificial Intelligence		fuzzy logic;simulation;prediction;computer science;artificial intelligence;database;computer performance;algorithm;statistics	AI	-17.033792195806786	45.082400496189535	86635
6680ab896eb5d810872cef7364d2f25a3e79b9d3	high-level language for embedded microprocessors	high level language	Abstract   The importance of high-level languages used in programming embedded microprocessors cannot be overestimated. It has become increasingly undesirable to use assembler language for complex applications, particularly in those areas of process automation which require sophisticated control algorithms. As a result, high-level languages are gradually replacing assembler language. This paper presents the implementation of a number of modifications to an existing high-level language cross-compiler, MPL, to allow efficient cross-software development for the Motorola MC6800/MC6809 family of embedded microprocessors. Also included is an example of an interrupt-driven microprocessor application using floating-point calculations, which was developed on a Vax/VMS system with the help of this cross-compiler.	embedded system;microprocessor	Jacob Davidson	1989	Microprocessors and Microsystems - Embedded Hardware Design	10.1016/0141-9331(89)90016-1	inline assembler;embedded system;computer architecture;parallel computing;real-time computing;language primitive;computer science;low-level programming language;programming language;high-level programming language;algorithm	EDA	-15.279748229052528	33.83449954180392	86648
35e59c53a8fab779cab1e86296f90700a90e3bd5	a comparative study of the nas mg benchmark across parallel languages and architectures	good portability;parallel language support;comparative study;portable performance;co-array fortran;parallel programming language;nas mg benchmark;hierarchical algorithm;hierarchical application;multigrid application;cray t3e;high performance fortran;matrix multiply;scientific computing;computer architecture;clustering algorithms;neural network;parallel programming;linux;sun;linux cluster;adaptive mesh refinement	Hierarchical algorithms such as multigrid applications form an important cornerstone for scientific computing. In this study, we take a first step toward evaluating parallel language support for hierarchical applications by comparing implementations of the NAS MG benchmark in several parallel programming languages: Co-Array Fortran, High Performance Fortran, Single Assignment C, and ZPL. We evaluate each language in terms of its portability, its performance, and its ability to express the algorithm clearly and concisely. Experimental platforms include the Cray T3E, IBM SP, SGI Origin, Sun Enterprise 5500 and a high-performance Linux cluster. Our findings indicate that while it is possible to achieve good portability, performance, and expressiveness, most languages currently fall short in at least one of these areas. We find a strong correlation betweenexpressiveness and a language's support for a global view of computation, and we identify key factors for achieving portable performance in multigrid applications.	algorithm;benchmark (computing);computation;computational science;computer cluster;cray t3e;high performance fortran;linux;mg (editor);multigrid method;nas parallel benchmarks;parallel computing;parallel language;parallel programming model;programming language;sa-c (programming language);software portability;zpl	Bradford L. Chamberlain;Steven J. Deitz;Lawrence Snyder	2000	ACM/IEEE SC 2000 Conference (SC'00)		computer architecture;parallel computing;adaptive mesh refinement;matrix multiplication;computer cluster;computer science;theoretical computer science;operating system;cluster analysis;programming language;linux kernel;artificial neural network;parallel programming model	HPC	-7.201617203176044	42.404851137431606	86753
03984f51f2db2f59210350dcc3b66bfb80b0c473	a one-billion-determinant full-ci benchmark on the cray t3d	one-billion-determinant full-ci benchmark;cray t3d	The implementation of an out-of-core version of a full CI algorithm on the Cray T3D is described. The introduction of heavy I/O activity, necessary to handle larger problems, required particular attention in order to maintain good performance. As an application, the FCI energy of the Be 2 molecule with a [9s2p1d] basis set (all electrons), whose FCI space has a dimension of more than one billion (10 9 ) of symmetry-adapted determinants in D 2h symmetry was computed. A single iteration on the Cray T3D at CINECA (64 processors) required about four hours, 30 minutes of which were spent in I/O operations. 27 iterations were performed and a precision of at least one μhartree in the energy was achieved. Due to the scalability of the code, substantially larger calculations could be performed provided that more processors and a larger amount of disk space were available.	benchmark (computing);cray t3d;full configuration interaction	Roberto Ansaloni;Stefano Evangelisti;Elda Rossi	1996		10.1007/3-540-61142-8_679	supercomputer;jaguar	NLP	-4.740746892509749	37.683785633510006	87008
012405a9cc8b3096e0699651ae99ae832b3a8056	parallel pic plasma simulation through particle decomposition techniques	plasma simulation;data parallel;domain decomposition;performance test;particle in cell simulation;high performance fortran extrinsic procedure;parallel systems;high performance fortran;load balance;parallel architecture;particle in cell;particle decomposition	Parallelization of a particle-in-cell (PIC) code has been accomplished through a “particle decomposition” technique instead of the more usual “domain decomposition” one. The adopted technique requires a moderate effort in porting the code in parallel form and results in intrinsic load balancing and modest inter-processor communication. The resulting data parallel implementation has been carried out within the High Performance Fortran (HPF) framework, and tested on the IBM SP parallel system. The performance tests obtained confirm the hypothesis of high effectiveness of the strategy, if targeted towards moderately parallel architectures. Optimal use of resources is also discussed with reference to a specific physics problem.	plasma active;simulation	Beniamino Di Martino;Sergio Briguglio;Gregorio Vlad;Piero Sguazzero	2001	Parallel Computing	10.1016/S0167-8191(00)00098-3	computational science;particle-in-cell;parallel computing;computer science;load balancing;theoretical computer science;domain decomposition methods	HPC	-5.10655209232635	37.440017695221876	87041
ab3894cb2feeed3b922c71d0b45d6a10ecd1b906	the openmp memory model	computers;general and miscellaneous mathematics computing and information science;specifications;memory consistency;fortran;distributed shared memory;memory model	The memory model of OpenMP has been widely misunderstood since the first OpenMP specification was published in 1997 (Fortran 1.0). The proposed OpenMP specification (version 2.5) includes a memory model section to address this issue. This section unifies and clarifies the text about the use of memory in all previous specifications, and relates the model to well-known memory consistency semantics. In this paper, we discuss the memory model and show its implications for future distributed shared memory implementations of OpenMP.	allocate-on-flush;application programming interface;cpu cache;compiler;consistency model;directive (programming);distributed shared memory;fortran;memory model (programming);openmp;spec#	Jay P. Hoeflinger;Bronis R. de Supinski	2005		10.1007/978-3-540-68555-5_14	memory address;uniform memory access;distributed shared memory;shared memory;memory model;parallel computing;distributed memory;computer science;physical address;theoretical computer science;operating system;overlay;flat memory model;programming language;cache-only memory architecture;memory map	HPC	-15.010008336335	39.450327075324736	87148
a0be0e9a431baf0d60178358ebe3a48ab8728a50	parallel laplacian edge detection performance analysis on green cluster architecture		The current trend of computer hardware declining and the speed of personal computer increasing had lead to opportunity of parallel programming. This paper presents the implementation of parallel Laplacian edge detection on cluster of four used personal computers. The algorithm was developed using C# language and had utilized the Message Passing Interface (MPI) library for parallel implementation. Comparison between sequential versus parallel implementation had been made based on sequential time taken for varies of images sizes. Results show significant time improvement as well as performance efficiency earned using parallel computing platform focusing on image processing Laplacian edge detection algorithm.	edge detection;profiling (computer programming)	Noor Elaiza Abdul Khalid;Noorhayati Mohamed Noor;Siti Arpah Ahmad;Mohd Helmi Rosli;Mohd Nasir Taib	2011		10.1007/978-3-642-22603-8_28	parallel computing;distributed computing;computer graphics (images)	Vision	-6.084911139149818	42.30382781571585	87270
ee23de2f0bdd77575fda474675383487fc3b9c4f	a new cell space devs specification: reviewing the parallel devs formalism seeking fast cell space simulations	modular form;non modular devs;devs formalism;simulation methods;message passing;cell space modeling;devs;high performance;cellular devs	This paper introduces a new specification for cellular DEVS models that assures high performance. It starts with the parallel DEVS specification and derives a high performance cellular DEVS layer using the property of closure under coupling. This is done through converting the parallel DEVS into its equivalent non-modular form which involves computational and communication overhead tradeoffs. The new specification layer, in contrast to multicomponent DEVS, is identical to the modular parallel DEVS in the sense of state trajectories which are updated according to the modular message passing methodology. The equivalency of the two forms is verified using simulation methods. Once the equivalency has been ensured, analysis of the models becomes a decisive factor in employing modularity in cellular DEVS models. Non-modular models guarantee the efficiency of the models in contrast to the current cellular DEVS implementation approaches. This was achieved by converting the cell space partially or fully into atomic model in order to eliminate inter-cell messages. However, the new specification needs an automated way to implement and verify models since they might become complicated ones.	computation;devs;layer (electronics);message passing;overhead (computing);scale space;semantics (computer science);simulation;speedup;time complexity	Fahad A. Shiginah;Bernard P. Zeigler	2011	Simulation Modelling Practice and Theory	10.1016/j.simpat.2011.01.006	embedded system;parallel computing;message passing;real-time computing;modular form;computer science;devs;sp-devs	HPC	-10.836230670900623	34.342102390114384	87344
49da82b1fdebe56b4dd99fe3d1e4bd42e79192c4	a capabilities-aware framework for using computational accelerators in data-intensive computing	distributed system;accelerateur;haute performance;systeme reparti;asymmetric multicores;informatique dans les nuages;carte graphique;asymmetry;heterogeneous cluster;resource allocation;base donnee tres grande;processeur multicoeur;resource manager;resource management;programacion basada sobre modelo;distributed computing;programming accelerators;cell processor;indice aptitud;accelerator;base de datos a gran escala;procesador multinucleo;asymetrie;heterogeneous clusters;paralelismo masivo;programming model;indice aptitude;gestion recursos;sistema repartido;capability index;high performance computer;programmation basee sur modele;alto rendimiento;graphic processing unit;gestion ressources;calculo repartido;asimetria;unidad de proceso grafico;multicore processor;model based programming;asignacion recurso;mapreduce;data intensive computing;very large databases;large scale distributed systems;allocation ressource;acelerador;computational efficiency;high performance;parallelisme massif;calcul reparti;massive parallelism;computacion en nube;cloud computing	Multicore computational accelerators such as GPUs are now commodity components for high-performance computing at scale. While such accelerators have been studied in some detail as stand-alone computational engines, their integration in large-scale distributed systems raises new challenges and trade-offs. In this paper, we present an exploration of resource management alternatives for building asymmetric accelerator-based distributed systems. We present these alternatives in the context of a capabilities-aware framework for data-intensive computing, which uses an enhanced implementation of the MapReduce programming model for accelerator-based clusters, compared to the state of the art. The framework can transparently utilize heterogeneous accelerators for deriving high performance with low programming effort. Our work is the first to compare heterogeneous types of accelerators, GPUs and a Cell processors, in the same environment and the first to explore the trade-offs between compute-efficient and control-efficient accelerators on data-intensive systems. Our investigation shows that our framework scales well with the number of different compute nodes. Furthermore, it runs simultaneously on two different types of accelerators, successfully adapts to the resource capabilities, and performs 26.9% better on average than a static execution approach.	data-intensive computing	M. Mustafa Rafique;Ali Raza Butt;Dimitrios S. Nikolopoulos	2011	J. Parallel Distrib. Comput.	10.1016/j.jpdc.2010.09.004	multi-core processor;parallel computing;real-time computing;cloud computing;resource allocation;process capability index;computer science;resource management;operating system;data-intensive computing;distributed computing;programming paradigm;asymmetry	HPC	-17.036944421637685	43.149885275540065	87354
b1421a89fb5f2b5e7e82d06b8185e0095d459eac	microservers: a new memory semantics for massively parallel computing	microserver;massively parallel computer;high performance computer;concurrent programs;massively parallel;processing in memory	The semantics of memory—a large state which can only be read or changed a small piece at a time—has remained virtually untouched since von Neumann, and its effects—latency and bandwidth—have proved to be the major stumbling block for high performance computing. This paper suggests a new model termed “microservers” that exploits “Processing-In-Memory” VLSI technology, and that can reduce memory traffic, increase inherent opportunities for concurrency, and support a variety of highly concurrent programming paradigms. Application of this model is then discussed in the framework of several on-going programs, particularly the HTMT petaflops project.	concurrency (computer science);concurrent computing;flops;memory semantics (computing);parallel computing;programming paradigm;stumbleupon;supercomputer;very-large-scale integration	Jay B. Brockman;Peter M. Kogge;Thomas L. Sterling;Vincent W. Freeh;Shannon K. Kuntz	1999		10.1145/305138.305234	computer architecture;parallel computing;computer science;operating system;massively parallel;distributed computing;programming language	HPC	-13.986954371028308	40.2009360497353	87543
d53b213a1546549697a455147eef3af6c65cb814	performance and power-aware modeling of mpi applications for cluster computing		The paper presents modeling of performance and power consumption when running parallel applications on modern cluster-based systems. The model includes basic so-called blocks representing either computations or communication. The latter includes both point-to-point and collective communication. Real measurements were performed using MPI applications and routines run on three different clusters with both Infiniband and Gigabit Ethernet interconnects. Regression allowed to obtain specific coefficients for particular systems, all modeled with the same formulas. The model has been incorporated into the MERPSYS environment for modeling parallel applications and simulation of execution on large-scale cluster and volunteer based systems. Using specific application and system models, MERPSYS allows to predict application execution time, reliability and power consumption of resources used during computations. Consequently, the proposed models for computational and communication blocks are of utmost importance for the environment.	computer cluster	Jerzy Proficz;Pawel Czarnul	2015		10.1007/978-3-319-32152-3_19	parallel computing;infiniband;computation;gigabit ethernet;computer cluster;energy consumption;computer science	HPC	-7.921784035491845	46.06594135352997	87549
e87fd714dc58dbb2d0b25079a215c43e5bde40bc	advanced high-level cache management by processor access information	level 2;gestion informacion;storage access;execution time;multiprocessor;multiprocessor systems;cache memory;information access;antememoria;antememoire;l1 cache;cache replacement;information management;cache replacement policy;acces memoire;hierarchical memory system;acces information;memory systems;hierarchie memoire;acceso memoria;temps execution;victim cache;acceso informacion;memory hierarchy;information system;gestion information;information acces processeur;multiprocesador;processor access information;tiempo ejecucion;jerarquia memoria;cache management;systeme information;sistema informacion;multiprocesseur	In this paper, we propose an advanced high-level cache management policy based on the processor access information, named as L1VPAI (L1 plus Victim cache with Processor Access Information). The L1VPAI is a cache replacement policy that uses the frequency of the specific cache line. In this policy, conflicted lines in the L1 cache are placed selectively in the victim cache or the level 2 (L2) cache based on previous memory access patterns. In this manner, the L1VPAI policy can make the frequently used address of cache locations reside longer in the high-level caches. We simulate our policy with RSIM, the event-driven simulator, and analyze the simulation results. The simulation results show that the average execution time of the L1VPAI outperforms the simple victim cache (L1V) by up to 6.44%. Moreover, performance gain is expected to increase, in the case of multiprocessor systems.	cpu cache;central processing unit;event-driven programming;high- and low-level;logic simulation;multiprocessing;run time (program lifecycle phase)	Jong Wook Kwak;Cheol Hong Kim;Sung-Hoon Shim;Chu Shik Jhon	2006	J. Inf. Sci. Eng.		bus sniffing;least frequently used;pipeline burst cache;cache-oblivious algorithm;snoopy cache;parallel computing;real-time computing;cache coloring;page cache;cpu cache;cache;computer science;write-once;cache invalidation;operating system;database;adaptive replacement cache;smart cache;information management;mesi protocol;cache algorithms;cache pollution;mesif protocol;non-uniform memory access;global assembly cache	HPC	-15.605707162145775	44.99707523222247	87663
fb44d4c4b6daf676cecf0664b82c4f71fa9f4971	on the implementation of spmd applications using haskell	programming environments;parallel programming;software engineering;lower level mpi implementations commodities built clusters distributed parallel processing high performance computing haskell sub parallel programming language messaging passing libraries software engineering requirements spmd benchmark programs;parallel programming parallel processing concurrent computing costs programming profession computer architecture distributed computing software libraries software engineering application software;parallel programming language;application program interfaces;functional languages;high performance computer;message passing;benchmark testing functional languages parallel programming parallel languages message passing application program interfaces workstation clusters programming environments;workstation clusters;parallel programs;parallel languages;parallel processing;benchmark testing	Commodities-built clusters, a low cost alternative for distributed parallel processing, brought high-performance computing to a wide range of users. Most of them are interested in parallelising scientific applications. Message passing parallel programming using lower level mechanisms, such as MPI and PVM libraries, has become popular, because these tools are free, easy to obtain, and efficient. However, for large-scale applications, parallel software engineering using low level tools is a very hard task, due to its poor abstraction and modularity. This makes difficult the widespread use of cluster computing, by mathematicians, biologists, engineers, physicists, et al. Haskell# is an attempt to bring together higher-level parallel programming and cluster-based architectures, without sacrificing speedup and scalability. This paper compares speedup, scalability, and modularity of Haskell # and MPI implementations of some representative NAS benchmarks (EP, IS and CG). Keywords—Parallel programming, clusters, benchmarking.	benchmark (computing);cg (programming language);computer cluster;expectation propagation;haskell;library (computing);message passing interface;nas parallel benchmarks;parallel virtual machine;parallel computing;spmd;scalability;software engineering;speedup;supercomputer	Francisco Heron de Carvalho Junior;Rafael Dueire Lins;Nívia Cruz Quental	2003		10.1109/CAHPC.2003.1250321	parallel processing;benchmark;computer architecture;parallel computing;message passing;computer science;operating system;programming language;parallel programming model	HPC	-12.88832752733664	39.29448146792783	87731
a9374b039d09b93138ec764957fe746aac99ce74	analytical estimation of scalability of iterative numerical algorithms on distributed memory multiprocessors		This article presents a new high-level parallel computational model named BSF – Bulk Synchronous Farm. The BSF model extends the BSP model to deal with the compute-intensive iterative numerical methods executed on distributed-memory multiprocessor systems. The BSF model is based on the master-worker paradigm and the SPMD programming model. The BSF model makes it possible to predict the upper scalability bound of a BSF-program with great accuracy. The BSF model also provides equations for estimating the speedup and parallel efficiency of a BSF-program.	algorithm;bean scripting framework;computational model;distributed memory;high- and low-level;iterative method;multiprocessing;numerical method;programming model;spmd;scalability;speedup	Leonid B. Sokolinsky	2017	CoRR	10.1134/S1995080218040121	parallel computing;distributed memory;spmd;programming paradigm;theoretical computer science;speedup;scalability;multiprocessing;computer science	HPC	-4.7805747606216915	38.6181599836958	87732
1a4519b61301bc9e8898d3e424b2cf9e95bd71a6	a knowledge discovery methodology for behavior analysis of large-scale applications on parallel architectures	data mining;large scale;recommender system;scientific computing;knowledge discovery in database;memory hierarchy;parallel architecture;behavior analysis;discrete event simulation;knowledge discovery	The focus of this paper is the application and extension of the knowledge discovery in databases process [5] developed in PYTHIA recommender system, to analyze the behavior of a DOE ASCI application/hardware pairs in the context of POEMS project[4]. The POEMS project has built a library of models for modeling scalable architectures like those in the ASCI program. Moreover, it supports detail simulation of a variety of state-of-the-art processors and memory hierarchies and incorporates parallel evaluation of discrete-event simulation. The driver application used is SWEEP3D.		Elias N. Houstis;Vassilios S. Verykios;Ann Christine Catlin;John R. Rice	2003		10.1007/3-540-44864-0_76	computer science;data science;discrete event simulation;operating system;machine learning;data mining;database;programming language;recommender system	HPC	-10.040539004514834	40.0478680335728	87804
22a233de128b61e2f5caaba174e70b70391bb3af	a study of the speed and the accuracy of the boundary element method as applied to the computational simulation of biological organs	computational physics;paper;medical physics;cuda;package;nvidia;nvidia quadro 4000;mathematical software;mpi;fortran;computer science	In this work, first a Fortran code is developed for three dimensional linear elastostatics using constant boundary elements; the code is based on a MATLAB code developed by the author earlier.  Next, the code is parallelized using BLACS, MPI, and ScaLAPACK. Later, the parallelized code is used to demonstrate the usefulness of the Boundary Element Method (BEM) as applied to the realtime computational simulation of biological organs, while focusing on the speed and accuracy offered by BEM. A computer cluster is used in this part of the work. The commercial software package ANSYS is used to obtain the `exact' solution against which the solution from BEM is compared; analytical solutions, wherever available, are also used to establish the accuracy of BEM. A pig liver is the biological organ considered. Next, instead of the computer cluster, a Graphics Processing Unit (GPU) is used as the parallel hardware. Results indicate that BEM is an interesting choice for the simulation of biological organs. Although the use of BEM for the simulation of biological organs is not new, the results presented in the present study are not found elsewhere in the literature.  Also, a serial MATLAB code, and both serial and parallel versions of a Fortran code, which can solve three dimensional (3D) linear elastostatic problems using constant boundary elements, are provided as supplementary files that can be freely downloaded.		P KiranaKumara	2013	CoRR		computational science;parallel computing;computer science;theoretical computer science	Robotics	-5.525302103396444	37.03071638475481	87817
76bfa93eb47ec820eddcaac2e193451b860aef13	parallel forward chaining technique with dynamic scheduling, for rule-based expert systems	evaluation performance;base donnee;sistema experto;shared memory;performance evaluation;implementation;memoria compartida;evaluacion prestacion;sistema informatico;rule based;database;base dato;computer system;raisonnement;dynamical system;systeme dynamique;ejecucion;scheduling;razonamiento;ordonamiento;forward chaining;systeme informatique;systeme parallele;parallel system;systeme expert;reasoning;sistema dinamico;ordonnancement;sistema paralelo;memoire partagee;dynamic scheduling;expert system	Tout, K.R. and D.J. Evans, Parallel forward chaining technique with dynamic scheduling, for rule-based expert systems, Parallel Computing 18 (1992) 913-930. In this paper we discuss two parallel forward chaining models together with their implementations on muitiprocessor systems. The forward chaining models use a dynamic scheduling strategy, and are for a rule-based expert system. All the models are domain-independent. To support the use of these models, a 'rulebase compiler' has been built to translate a rule base in text format into the data structure needed by the system.	compiler;data structure;david c. evans;expert system;forward chaining;logic programming;parallel computing;rule-based system;scheduling (computing)	Kifah R. Tout;David J. Evans	1992	Parallel Computing	10.1016/0167-8191(92)90037-8	shared memory;embedded system;real-time computing;forward chaining;dynamic priority scheduling;computer science;dynamical system;implementation;scheduling;expert system;reason;inference engine;algorithm	AI	-18.454120598904883	41.55666073770698	87824
df797bc863783db352bc35454774c48b31e64047	datarol: a massively parallel architecture for functional languages	high level languages;etc;datarol;continuation based execution model massively parallel architecture functional languages parallel machine architecture ultra multiprocessing facility parallel execution multi thread control flow datarol explicitly specified continuation linkage concurrent execution instructions;multi thread control flow;program counter;massively parallel architecture;instructions;functional programming;concurrent execution;limu;parallel architectures;functional languages;control flow;parallel machine architecture;parallel architectures computer architecture couplings parallel machines counting circuits process design writing concurrent computing switches communication system control;parallel machines;parallel architecture;parallel architectures functional programming high level languages;functional language;parallel execution;explicitly specified continuation linkage;ultra multiprocessing facility;continuation based execution model	Proposes a parallel machine architecture which incorporates an ultra-multiprocessing facility for parallel execution of functional programs. The machine performs parallel executions along a multi-thread control flow called datarol. A datarol program, instead of using a program counter, the instructions to be executed next are explicitly specified in the preceding instructions. The explicitly specified continuation linkage enables the concurrent execution of the instructions of different function instances, as well as the parallel execution of multi-thread control flow within a function instance. Based on a continuation-based execution model, the datarol processor is designed to implement an efficient parallel execution mechanism needed for ultra-multi-processing. First, the datarol concept is discussed in comparison with a dataflow model. Next, the datarol machine architecture and datarol processor design are described. Finally, the evaluation of the datarol architecture is shown. >	functional programming;parallel computing	Makoto Amamiya;Rin-ichiro Taniguchi	1990		10.1109/SPDP.1990.143635	program counter;computer architecture;parallel computing;computer science;distributed computing;programming language;functional programming;control flow;high-level programming language	HPC	-13.546003723951461	38.45585245345585	87832
df3dd8b16130ee7cd1f6b066622fd3638a649202	on using an hybrid mpi-thread programming for the implementation of a parallel sparse direct solver on a network of smp nodes	symmetric configuration;distributed system;algoritmo paralelo;haute performance;systeme reparti;parallel algorithm;shared memory;multiprocessor;gollete estrangulamiento;memoria compartida;configuration symetrique;communicating process;storage structure;distributed computing;sparse;supercomputer;algorithme parallele;proceso comunicante;supercomputador;computer architecture;goulot etranglement;configuracion simetrica;sistema repartido;architecture ordinateur;envoi message;processus communicant;message passing;alto rendimiento;calculo repartido;estructura memoria;arquitectura ordenador;structure memoire;multiprocesador;high performance;bottleneck;calcul reparti;superordinateur;memoire partagee;multiprocesseur	Since the last decade, most of the supercomputer architectures are based on clusters of SMP nodes. In those architectures the exchanges between processors are made through shared memory when the processors are located on a same SMP node and through the network otherwise. Generally, the MPI implementations provided by the constructor on those machines are adapted to this situation and take advantage of the shared memory to treat messages between processors in a same SMP node. Nevertheless, this transparent approach to exploit shared memory does not avoid the storage of the extra-structures needed to manage efficiently the communications between processors. For high performance parallel direct solvers, the storage of these extra-structures can become a bottleneck. In this paper, we propose an hybrid MPI-thread implementation of a parallel direct solver and analyse the benefits of this approach in terms of memory and run-time performances.	central processing unit;performance;shared memory;solver;sparse;supercomputer;symmetric multiprocessing	Pascal Hénon;Pierre Ramet;Jean Roman	2005		10.1007/11752578_127	distributed shared memory;shared memory;supercomputer;parallel computing;message passing;multiprocessing;distributed memory;computer science;operating system;distributed computing;parallel algorithm	HPC	-16.60776970685293	42.87073514377039	87926
8dff9b665e4a01e60185fe0f53712154ef998044	raftlib: a c++ template library for high performance stream parallel processing	irregular program;simulation;parallel programming;habanero java;java;discrete event simulation	Stream processing or data-flow programming is a compute paradigm that has been around for decades in many forms yet has failed garner the same attention as other mainstream languages and libraries (e.g., C++ or OpenMP [15]). Stream processing has great promise: the ability to safely exploit extreme levels of parallelism. There have been many implementations, both libraries and full languages. The full languages implicitly assume that the streaming paradigm cannot be fully exploited in legacy languages, while library approaches are often preferred for being integrable with the vast expanse of legacy code that exists in the wild. Libraries, however are often criticized for yielding to the shape of their respective languages. RaftLib aims to fully exploit the stream processing paradigm, enabling a full spectrum of streaming graph optimizations while providing a platform for the exploration of integrability with legacy C/C++ code. RaftLib is built as a C++ template library, enabling end users to utilize the robust C++ standard library along with RaftLib's pipeline parallel framework. RaftLib supports dynamic queue optimization, automatic parallelization, and real-time low overhead performance monitoring.	automatic parallelization;c++ standard library;compatibility of c and c++;dataflow;legacy code;library (computing);mathematical optimization;openmp;overhead (computing);parallel computing;programming paradigm;real-time clock;stream processing;template metaprogramming	Jonathan C. Beard;Peng Li;Roger D. Chamberlain	2015		10.1145/2712386.2712400	parallel computing;computer science;message passing interface;theoretical computer science;programming language	PL	-14.551473120766452	38.3419796099604	88103
47488c34088ccd8adf78fa24b5c82dcbcf200021	hierarchical collectives in mpich2	hierarchical structure;shared memory;collective communication;col;parallel systems;performance model;message passing;mpi;multicore processors	Most parallel systems on which MPI is used are now hierarchical: some processors are much closer to others in terms of interconnect performance. One of the most common such examples are systems whose nodes are symmetric multiprocessors (including “multicore” processors). A number of papers have developed algorithms and implementations that exploit shared memory on such nodes to provide optimized collective operations, and these show significant performance benefits compared to implementations that do not exploit the hierarchical structure of the nodes. However, shared memory between processes is often a scarce resource. How necessary is it to use shared memory for collectives in MPI? How much of the performance benefit comes from tailoring the algorithm to the hierarchical topology of the system? In this paper, we describe an implementation based entirely on message-passing primitives but that exploits knowledge of the two-level hierarchy. We discuss both rootless collectives (such as Allreduce) and rooted collectives (such as Reduce), and develop a performance model. Our results show that for most collectives, exploiting shared memory directly will bring small additional benefit, and the places where shared memory is beneficial suggest design approaches that make best use of a pool of shared memory.	algorithm;central processing unit;mpich;message passing interface;multi-core processor;multistage interconnection networks;network topology;reduce;shared memory;symmetric multiprocessing;tree network	Hao Zhu;David Goodell;William Gropp;Rajeev Thakur	2009		10.1007/978-3-642-03770-2_41	computer architecture;parallel computing;computer science;distributed computing	HPC	-9.568764848478152	44.97248422815964	88163
6420dbb4daa4e73801cfabb53f06552e22aaa848	choosing method of the most effective nested loop shearing for parallelism	matrix algebra;parallel architectures;parallel programming;parallelising compilers;program control structures;simd architecture;inner loop index;loop parallelizing method;loop transformations;matrix operations;nested loop shearing;outer loop index;parallelising compiler;shearing conversions	Our loop parallelizing method of compiler for SIMD architecture enables SIMD instructions to be generated from loops which include complicated data dependency. The characteristic of our method is in choosing the more optimising method for parallelization from two shearing conversions by inner and outer loop carried data dependences. One of them is novel and involves shearing horizontally along the inner loop index and the other is well-established shearing vertically along the outer loop index. These loop transformations are formalized by matrix operations. They enable the original loop indexes to be expressed using new loop indexes so that compiler does not need to make any change in loop body. At this point, simple templates suffice to generate optimal code. To conclude we summarize the conditions for choosing suitable shearing method and the requirements for conversion.	array data structure;bubble sort;coins;compiler;control flow;data definition language;data dependency;inner loop;loop invariant;object code;overhead (computing);parallel computing;polyhedron;program transformation;requirement;simd	Kyoko Iwasawa;Alan Mycroft	2007	Eighth International Conference on Parallel and Distributed Computing, Applications and Technologies (PDCAT 2007)	10.1109/PDCAT.2007.44	loop tiling;loop fusion;manifest expression;loop inversion;parallel computing;real-time computing;loop fission;conditional loop;nested loop join;loop interchange;matrix multiplication;loop dependence analysis;computer science;loop nest optimization;loop unrolling;do while loop;distributed computing;loop counter;inner loop;loop splitting	HPC	-15.639352273418186	35.34226205217719	88191
6a53301b2fd3bcd5a15df32043ae8dfed4353b37	scalable loop self-scheduling schemes for heterogeneous clusters	parallel computing;heterogeneous cluster;concurrent programming;loops;heterogeneous clusters;parallel loops;scalable;distributed scheduling;scalable self scheduling;scheduling schemes;load balancing;distributed;lans	Heterogeneous cluster systems (e.g., a LAN of computers) can be used for concurrent processing for some applications. However, a serious difficulty in concurrent programming of a heterogeneous system is how to deal with scheduling and load balancing of such a system that may consist of heterogeneous computers. Distributed scheduling schemes suitable for parallel loops with independent iterations on heterogeneous computer clusters have been proposed and analysed in the past. Here, we implement the previous schemes in MPI. We present an extension of these schemes implemented in a hierarchical Master Slave architecture and include experimental results and comparisons.	scheduling (computing)	Anthony T. Chronopoulos;Satish Penmatsa;Ning Yu;Yu Du	2005	IJCSE	10.1504/IJCSE.2005.009696	fair-share scheduling;parallel computing;real-time computing;scalability;concurrent computing;computer science;load balancing;distributed computing;computer security	HPC	-12.899448781980453	43.55952938657342	88234
8e13337429c92f70257f72387daa16cd1fc15e19	a perspective of hpcn requirements in the european aerospace industry	tratamiento paralelo;modelizacion;numerical algorithmics;design tool;computational modelling;grid generation;ciclo desarrollo;algorithm complexity;traitement parallele;life cycle;complejidad algoritmo;complejidad programa;ingenieria logiciel;computer modelling;software engineering;modelisation;complexite algorithme;algorithmique numerique;numerical algorithm;numerical algorithms;cycle developpement;genie logiciel;program complexity;computational electromagnetics;modeling;product complexity;design cycles;algoritmico numerico;parallel processing;complexite programme	Product complexity is increasing rapidly to address the demanding requirements driven by customers, regulations and safety. More complex designs and an increasing number of design options must be evaluated whilst controlling the cost and length of the design cycle. The engineering requirements come from different disciplines, such as aerodynamics, structures and electromagnetics. The division of engineering into separate disciplines is not recognised by nature, with the result that addressing requirements within one discipline can compromise requirements in other disciplines. Product complexity is now such that requirements from multiple engineering disciplines need to be simultaneously addressed at an early stage of the design cycle to avoid costly re-design. These problems have placed strong demands on computational design, driving key trends in numerically intensive modelling, as well as the requirement for more computational resource. The requirement for more computational resource arises in many disciplines and is compounded by the need for multi-disciplinary design. This results from the increased product complexity which has to be matched by increasing the mathematical complexity of the mode1 providing the underlying framework for the computational design tools. The availability of increased computational resource via parallel platforms at affordable prices enables these problems to be addressed facilitating . computational analyses of more complex problems * simultaneous computational analyses of multiple design and planning options . multi-disciplinary analyses, i.e. simultaneously address requirements in different disciplines. The continua1 growth in computational design and computational resource provides the potential for the end-user engineer to carry out far more design more rapidly and accurately. However this potential can only be exploited if the end-user can efficiently define more complex problems, multiple problems, multi-disciplinary problems and also analyse the large volume of results. Consequently considerable effort needs to be placed on the user environment, encompassing problem set-up and results analysis. This paper expands on these requirements within the aerospace and related sectors with examples of applications from specific disciplines. Some emphasis is attached to the growing supercomputer disciplines, computational electromagnetics in particular. Some key features of parallel processing are discussed including . the high degree of parallelism required to get a modest percentage of peak performance . exploitation of parallel platforms without Teraflop performance * the potential benefits of hybrid or heterogeneous platforms compared to homogeneous platforms.	automated planning and scheduling;computation;computational electromagnetics;computational resource;degree of parallelism;flops;numerical analysis;parallel computing;requirement;software design;supercomputer;user interface;while	J. A. Murphy	1995	Future Generation Comp. Syst.	10.1016/0167-739X(95)00019-O	biological life cycle;parallel processing;parallel computing;simulation;systems modeling;computer science;artificial intelligence;distributed computing;computational electromagnetics;operations research	HPC	-7.971086815530406	34.80652064646353	88257
2301b5a94252b42cd36f311ccbf5a656d637c87f	optimizing gaussian filtering of volumetric data using sse	simd;memory layout;volume filtering;gaussian filter;optimization	Gaussian filtering is a basic operation commonly used in numerous image and volume processing algorithms. It is, therefore, desirable to perform it as efficiently as possible. Over the last decade CPUs have been successfully extended with several SIMD (Single Instruction Multiple Data) extensions, such as MMX, 3DNow!, and SSE series. In this paper we introduce a new technique for Gaussian filtering of volume data sets—the extended volume—together with its SIMD implementation using the SSE technology. We further introduce a SIMD optimized recursive IIR implementation of the Gaussian filter, and finally, we parallelize the SSE versions with the help of OpenMP (Open Multi-Processing). Experimental evaluation indicates that the SIMD implementation can significantly speed up both versions of the Gaussian filtering and that the non-recursive extended volume version is faster than the recursive IIR one for small widths of the Gaussian filter. Copyright 2010 John Wiley & Sons, Ltd.	3dnow!;algorithm;central processing unit;computation;double-precision floating-point format;gaussian blur;infinite impulse response;john d. wiley;kernel (operating system);larrabee (microarchitecture);loop unrolling;mmx (instruction set);multiprocessing;openmp;optimizing compiler;parallel computing;parallel programming model;performance evaluation;recursion;speedup;streaming simd extensions;x86-64	Anton Vasko;Milos Srámek	2011	Concurrency and Computation: Practice and Experience	10.1002/cpe.1620	parallel computing;simd;computer hardware;computer science;theoretical computer science;operating system;gaussian filter	HPC	-4.753685484968115	42.224954224548995	88402
2101405b8bb078c442ac5dfc9dec1654f8ac3efe	flashstoragesim: performance modeling for ssd architectures		We present FlashStorageSim, an SSD architecture performance model for data center servers, validated with an enterprise SSD. In addition to the SSD controller, SSD organization, and flash devices, FlashStorageSim models the host interface (e.g., SATA, PCIe, DDR). This allows users to explore non-traditional SSD use cases. We also implement mechanisms to improve simulation speed, which is shown to reduce simulation time by more than 7X. We show how FlashStorageSim can help researchers understand SSD design decisions.	data center;flash memory controller;pci express;serial ata;simulation;solid-state drive	Krishna T. Malladi;Mu-Tien Chang;Dimin Niu;Hongzhong Zheng	2017	2017 International Conference on Networking, Architecture, and Storage (NAS)	10.1109/NAS.2017.8026860	real-time computing;architecture;parallel computing;pci express;control theory;computer science;data center;server;use case	HPC	-9.073590389315653	46.327525728701545	88428
36d2234e6ea1df8137e6eb3dfd034e47ce861a09	omnirpc: a grid rpc facility for cluster and global computing in openmp	parallelisme;distributed system;appel procedure;systeme reparti;shared memory;programming environment;memoria compartida;reseau ordinateur;global computing;remote procedure call;computer network;parallelism;sistema repartido;llamada procedimiento;paralelismo;red ordenador;openmp;multithread;multitâche;procedure call;memoire partagee	Omni remote procedure call facility, OmniRPC, is a threadsafe grid RPC facility for cluster and global computing environments. The remote libraries are implemented as executable programs in each remote computer, and OmniRPC automatically allocates remote library calls dynamically on appropriate remote computers to facilitate location transparency. We propose to use OpenMP as an easy-to-use and simple programming environment for the multi-threaded client of OmniRPC. We use the POSIX thread implementation of the Omni OpenMP compiler which allows multi-threaded execution of OpenMP programs by POSIX threads even in a single processor. Multiple outstanding requests of OmniRPC calls in OpenMP work-sharing construct are dispatched to di erent remote computers to exploit network-wide parallelism.	compiler;executable;integrated development environment;library (computing);openmp;posix threads;parallel computing;remote computer;remote procedure call;subroutine;thread (computing);threadsafe	Mitsuhisa Sato;Motonori Hirano;Yoshio Tanaka;Satoshi Sekiguchi	2001		10.1007/3-540-44587-0_12	shared memory;parallel computing;computer science;operating system;database;distributed computing;programming language;remote procedure call	HPC	-17.532384303985065	42.56477290951274	88459
a72a14ad45aeace4cf68da32d82933c6d8d76782	the feelfem system - a repository system for the finite element method	code generation;parallel programming;object oriented programming;software repository tool feelfem system finite element method code generator program models parallel programming parallel solvers software reuse expandability flexibility object oriented technique implementation oriented pseudo code representation numerical algorithms gid partial differential equations pde parallel fem applications personal pre post processor;finite element method;programming model;numerical scheme;partial differential equations;object oriented;parallelising compilers;software reusability;numerical algorithm;software tools finite element analysis parallelising compilers parallel programming software reusability object oriented programming partial differential equations;software tools;finite element analysis;parallel programs;finite element methods software tools parallel algorithms national electric code internet laboratories object oriented modeling parallel programming software prototyping prototypes;software reuse	We have developed a finite element method (FEM) software repository tool named feelfem that serves as a code generator. One important feature of feelfem is that it is designed to generate various program models of FEM analysis, including users' own newly developed numerical schemes. Another feature is that interfaces to newly developed parallel programming paradigms and parallel solvers can easily be added to it. Software reuse is an important target of the feelfem system. To achieve flexibility and expandability for the system, we adopt an object-oriented technique and implementation-oriented pseudo-code representation of numerical algorithms. In its latest released version, feelfem has strong interaction with the personal pre/post processor GiD. By using a combination of feelfem and GiD, users can generate prototype parallel FEM applications with newly developed solvers very easily and quickly.	finite element method	Hidehiro Fujio	2003		10.1109/IPDPS.2003.1213461	parallel computing;computer science;theoretical computer science;operating system;finite element method;distributed computing;programming language;object-oriented programming	HPC	-9.725000239554467	36.81121165884634	89154
a85751085f822c2fe3de33a6207f6d557cb0b699	the cray t3d as a production machine at konrad-zuse-zentrum berlin	parallel computer	In November 1994 a 192 processor Cray T3D was installed at ZIB. Experience with a parallel computer in a computer center with heterogeneous user community is reported on.	cray t3d	Hinnerk Stueben	1995		10.1007/BFb0046651	computational science;supercomputer;red storm;parallel computing;computer science;cray xk7;jaguar	NLP	-8.05448786721349	38.890265738713374	89253
07cbd49e505629453703d9037a5c8f65ad89914f	a parallel solution for high resolution histological image analysis	microscopy;high resolution histological image processing;whole slide imaging;mpi;low and high level parallel image processing	This paper describes a general methodology for developing parallel image processing algorithms based on message passing for high resolution images (on the order of several Gigabytes). These algorithms have been applied to histological images and must be executed on massively parallel processing architectures. Advances in new technologies for complete slide digitalization in pathology have been combined with developments in biomedical informatics. However, the efficient use of these digital slide systems is still a challenge. The image processing that these slides are subject to is still limited both in terms of data processed and processing methods. The work presented here focuses on the need to design and develop parallel image processing tools capable of obtaining and analyzing the entire gamut of information included in digital slides. Tools have been developed to assist pathologists in image analysis and diagnosis, and they cover low and high-level image processing methods applied to histological images. Code portability, reusability and scalability have been tested by using the following parallel computing architectures: distributed memory with massive parallel processors and two networks, INFINIBAND and Myrinet, composed of 17 and 1024 nodes respectively. The parallel framework proposed is flexible, high performance solution and it shows that the efficient processing of digital microscopic images is possible and may offer important benefits to pathology laboratories.	algorithm;architecture as topic;central processing unit;computation (action);distributed memory;execution;gigabyte;high- and low-level;image analysis;image processing;image resolution;infiniband;informatics (discipline);laboratory;message passing;parallel computing;scalability;slide (glass microscope);software portability;benefit	Gloria Bueno García;R. González;Oscar Déniz-Suárez;Marcial García-Rojo;J. González-García;M. del Milagro Fernández-Carrobles;Noelia Vállez;Jesús Salido	2012	Computer methods and programs in biomedicine	10.1016/j.cmpb.2012.03.007	computer vision;parallel computing;computer science;microscopy;message passing interface;theoretical computer science;digital image processing;computer graphics (images)	HPC	-8.323399615627974	38.39603832994121	89294
5ec97700585fcf9399ec916deab560cfcb33e7ce	poster: improved opencl programmability with clutil	parallel for;heterogeneous computing clutil opencl parallel for;software libraries;heterogeneous computing;resource allocation;software libraries c language resource allocation;multiple opencl devices improved opencl programmability clutil c 11 features load balancing automatic work distribution;c language;opencl;clutil	This poster presents clUtil, a library that simplifies OpenCL's C frontend. It provides significant productivity improvements using C++11 features, such as variadic templated functions for launching kernels, while giving users a simple construct for exploiting multiple heterogeneous devices. The parallel-for construct allows developers to seamlessly use multiple OpenCL devices with automatic work distribution and load-balancing.	c++11;load balancing (computing);opencl api;variadic function;variadic template	Rick Weber;Gregory D. Peterson	2012	2012 SC Companion: High Performance Computing, Networking Storage and Analysis	10.1109/SC.Companion.2012.252	computer architecture;parallel computing;resource allocation;computer science;operating system;symmetric multiprocessor system	HPC	-6.397551353363564	44.11447192094184	89333
51fce49faba556558b7215cd25b64839b5a79ed8	high-performance fortran	high performance fortran	The advantages of using parallel processing technology in industrial applications lie in the field of cost reduction and turnaround time improvement. For example in seismic production, the improvement in turnaround time can lead to lower costs and quicker results for clients. Also in product development where computer simulations play a significant role, for instance drug design, aircraft design and flow meter design, the use of parallel processing technology leads to a decrease in the time-to-market.	computer simulation;high performance fortran;new product development;parallel computing	G. Matthijs van Waveren	1994		10.1007/3-540-57981-8_155	computer science	HPC	-6.7556180220031985	36.129238516842435	89612
89a68693887f75513ed8a3ac2788bb4b4d2fcefb	apr: a novel parallel repacking algorithm for efficient gpgpu parallel code transformation	parallel repacking;parallel programming;gpgpu;code transformation	General-purpose graphics processing units (GPGPU) brings an opportunity to improve the performance for many applications. However, exploiting parallelism is low productive in current programming frameworks such as CUDA and OpenCL. Programmers have to consider and deal with many GPGPU architecture details; therefore it is a challenge to trade off the programmability and the efficiency of performance tuning.  Parallel Repacking (PR) is a popular performance tuning approach for GPGPU applications, which improves the performance by changing the parallel granularity. Existing code transformation algorithms using PR increase the productivity, but they do not cover adequate code patterns and do not give an effective code error detection. In this paper, we propose a novel parallel repacking algorithm (APR) to cover a wide range of code patterns and improve efficiency. We develop an efficient code model that expresses a GPGPU program as a recursive statement sequence, and introduces a concept of singular statement. APR building upon this model uses appropriate transformation rules for singular and non-singular statements to generate the repacked codes. A recursive transformation is performed when it encounters a branching/loop singular statement. Additionally, singular statements unify the transformation for barriers and data sharing, and enable APR to detect the barrier errors. The experiment results based on a prototype show that out proposed APR covers more code patterns than existing solutions such as the automatic thread coarsening in Crest, and the repacked codes using the APR achieve effective performance gain up to 3.28X speedup, in some cases even higher than manually tuned repacked codes.		Yulong Yu;Xubin He;He Guo;Sihui Zhong;Yuxin Wang;Xin Chen;Weijun Xiao	2014		10.1145/2576779.2576789	parallel computing;real-time computing;computer science;theoretical computer science	HPC	-15.226599039568493	36.467281045650175	89715
2f60adda37f857b75a9dd444c638fc3c22dbd549	dynamically transforming data structures	transformation arraylist data structure;possibly changing context;computer and information science;context abstracts arrays algorithm design and analysis switches complexity theory;dacapo benchmark suite;natural sciences;internal representation variant;data structures;hash bag variant;datavetenskap datalogi;datavetenskap;computer science;possibly changing context transformation arraylist data structure hash bag variant dacapo benchmark suite internal representation variant	Fine-tuning which data structure implementation to use for a given problem is sometimes tedious work since the optimum solution depends on the context, i.e., on the operation sequences, actual parameters as well as on the hardware available at run time. Sometimes a data structure with higher asymptotic time complexity performs better in certain contexts because of lower constants. The optimal solution may not even be possible to determine at compile time. We introduce transformation data structures that dynamically change their internal representation variant based on a possibly changing context. The most suitable variant is selected at run time rather than at compile time. We demonstrate the effect on performance with a transformation ArrayList data structure using an array variant and a linked hash bag variant as alternative internal representations. Using our transformation ArrayList, the standard DaCapo benchmark suite shows a performance gain of 5.19% in average.	asymptotic computational complexity;benchmark (computing);compile time;compiler;dacapo;data structure;dynamic array;run time (program lifecycle phase);time complexity	Erik Österlund;Welf Löwe	2013	2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)	10.1109/ASE.2013.6693099	natural science;data structure;computer science;theoretical computer science;data mining;database;programming language	SE	-17.288560613717724	37.414005188048066	89784
91aa6249fb77e5f9944b7ee95452b6fbb5bb27bc	a new hierarchy cache scheme using ram and pagefile	sistema operativo;evaluation performance;diseno circuito;random access memory;entrada salida;memoria acceso directo;performance evaluation;evaluacion prestacion;circuit design;cache memory;extreme programming;antememoria;programacion extrema;input output;computer architecture;antememoire;architecture ordinateur;operating system;filter;memoire acces direct;filtre;programmation extreme;systeme exploitation;conception circuit;arquitectura ordenador;access method;filtro;entree sortie	One newly designed hierarchical cache scheme is presented in this article. It is a two-level cache architecture using a RAM of a few megabytes and a large pagefile. Majority of cached data is in the pagefile that is nonvolatile and has better IO performance than that of normal data disks because of different data sizes and different access methods used. The RAM cache collects small writes first and then transfers them to the pagefile sequentially in large sizes. When the system is idle, data will be destaged from the pagefile to data disks. We have implemented the hierarchical cache as a filter driver that can be loaded onto the current Windows 2000/Windows XP operating system transparently. Benchmark test results show that the cache system can improve IO performance dramatically for small writes.	paging;random-access memory	Rui-fang Liu;Changsheng Xie;Zhi-hu Tan;Qing Yang	2004		10.1007/978-3-540-30102-8_43	input/output;embedded system;cache-oblivious algorithm;snoopy cache;parallel computing;real-time computing;cache coloring;page cache;extreme programming;cpu cache;tag ram;filter;cache;computer science;write-once;cache invalidation;operating system;circuit design;database;distributed computing;smart cache;cache algorithms;cache pollution;access method	Theory	-17.185376068421878	45.64791520893858	89943
00b8e660089919da0f4c64e86d4e1573024c1db8	wavelet-based adaptive multi-resolution solver on heterogeneous parallel architecture for computational fluid dynamics	task based parallelisms;adaptive multi resolution;computation fluid dynamics;fluid flow;multi gpu;error analysis;data based parallelisms;weighted essentially non oscillatory;parallel architecture;multi resolution;data structure;multi core	For the efficient simulation of fluid flows governed by a wide range of scales a wavelet-based adaptive multi-resolution solver on heterogeneous parallel architectures is proposed for computational fluid dynamics. Both data- and task-based parallelisms are used for multi-core and multi-GPU architectures to optimize the efficiency of a high-order wavelet-based multi-resolution adaptative scheme with a 6th-order adaptive central-upwind weighted essentially non-oscillatory scheme for discretization of the governing equations. A modified grid-block data structure and a new boundary reconstruction method are introduced. A new approach for detecting small scales without using buffer levels is introduced to obtain additional speed-up by minimizing the number of required blocks. Validation simulations are performed for a double-Mach reflection with different refinement criteria. The simulations demonstrate accuracy and computational performance of the solver.	computational fluid dynamics;data structure;discretization;graphics processing unit;multi-core processor;multiphase particle-in-cell method;parallel computing;refinement (computing);sensor;simulation;solver;wavelet	L. H. Han;T. Indinger;Xiangyu Hu;Nikolaus A. Adams	2011	Computer Science - Research and Development	10.1007/s00450-011-0167-z	multi-core processor;mathematical optimization;parallel computing;data structure;computer science;theoretical computer science;programming language	HPC	-5.987303778298613	39.36697913303366	90087
43d61cb32467ee1e8fd881abe1349c14aec5a6ef	tensors come of age: why the ai revolution will help hpc		Thirty years ago, parallel computing was coming of age. A bitter battle began between stalwart vector computing supporters and advocates of various approaches to parallel computing. IBM skeptic Alan Karp, reacting to announcements of nCUBE’s 1024-microprocessor system and Thinking Machines’ 65,536-element array, made a public $100 wager that no one could get a parallel speedup of over 200 on real HPC workloads. Gordon Bell softened that to an annual award for the best speedup, what we now know as the Gordon Bell Prize.	gordon bell prize;parallel computing;speedup;vector processor	John L. Gustafson;Lenore M. Restifo Mullin	2017	CoRR		tensor;automation;theoretical computer science;unum;scalability;computer science;software	HPC	-8.192879837690592	40.15793035782456	90414
b1eb45ead3e2bab504f7ff3b88e4f3108f180e5d	paradeis: an object library for parallel sparse array computation	simulation ordinateur;distributed memory;algoritmo paralelo;parallel algorithm;object oriented language;algorithm performance;simulacion numerica;algorithme parallele;resultado algoritmo;estructura datos;simulation numerique;performance algorithme;structure donnee;sparse data;simulacion computadora;parallel programs;development time;data structure;computer simulation;massively parallel processor;numerical simulation	Parallel programming of sparse data structure has been recognized to be hard to debug and to require an excessive amount of development time. The paradeis library (PARAllel Data Environment for Irregular Structure) is an object library that aims at providing a data-parallel approach with object oriented languages to ease the treatment of the sparse data structure for SPMD-like programs on Massively Parallel Processors (MPPs) with distributed memory. This paper focuses on the core of communication layout: the conversion of global addresses to communications, and its relationship with partitioning strategies.	computation;library (computing);sparse	Franck Delaplace;Didier Rémy	1999		10.1007/3-540-49164-3_15	computer simulation;parallel computing;distributed memory;sparse matrix;computer science;theoretical computer science;distributed computing;parallel algorithm;programming language;object-oriented programming	HPC	-11.428376668372033	38.42032306319847	90454
5895be3a05b0d4432ff94820125db49acffc026f	machine-adaptable dynamic binary translation	dynamic compilation;emulation;hardware architecture;interpretation	Dynamic binary translation is the process of translating and optimizing executable code for one machine to another at runtime, while the program is “executing” on the target machine. Dynamic translation techniques have normally been limited to two particular machines; a competitor's machine and the hardware manufacturer's machine. This research provides for a more general framework for dynamic translations, by providing a framework based on specifications of machines that can be reused or adapted to new hardware architectures. In this way, developers of such techniques can isolate design issues from machine descriptions and reuse many components and analyses. We describe our dynamic translation framework and provide some initial results obtained by using this system.	binary translation;dynamical system;executable;just-in-time compilation;run time (program lifecycle phase)	David Ung;Cristina Cifuentes	2000		10.1145/351397.351414	emulation;binary code;computer architecture;parallel computing;real-time computing;dynamic compilation;transfer-based machine translation;interpretation;computer science;dynamic programming;hardware architecture;optimizing compiler;programming language;code generation;reverse engineering	Arch	-16.769986499248944	36.06564965661972	90496
27fd294405cbc613fca3fe416646a045c2345134	from a calculus to an execution environment for stream processing	streamit;audio video;data processing;cql;intermediate language;execution environment;language development;sawzall;domain specific language;stream processing;high frequency;volume data	At one level, this paper is about River, a virtual execution environment for stream processing. Stream processing is a paradigm well-suited for many modern data processing systems that ingest high-volume data streams from the real world, such as audio/video streaming, high-frequency trading, and security monitoring. One attractive property of stream processing is that it lends itself to parallelization on multicores, and even to distribution on clusters when extreme scale is required. Stream processing has been co-evolved by several communities, leading to diverse languages with similar core concepts. Providing a common execution environment reduces language development effort and increases portability. We designed River as a practical realization of Brooklet, a calculus for stream processing. So at another level, this paper is about a journey from theory (the calculus) to practice (the execution environment). The challenge is that, by definition, a calculus abstracts away all but the most central concepts. Hence, there are several research questions in concretizing the missing parts, not to mention a significant engineering effort in implementing them. But the effort is well worth it, because using a calculus as a foundation yields clear semantics and proven correctness results.	correctness (computer science);high-frequency trading;ibm websphere extreme scale;parallel computing;programming paradigm;stream processing;streaming media	Robert Soulé;Martin Hirzel;Bugra Gedik;Robert Grimm	2012		10.1145/2335484.2335487	real-time computing;stream processing;data processing;computer science;domain-specific language;operating system;high frequency;database;distributed computing;programming language;intermediate language	DB	-14.684430040312018	38.27749845878266	90577
c109e0d064916a3d99afb7ca673d7868ea0b6848	lu factorisation on xeon and xeon phi processors			lu decomposition;xeon phi	Adrian Jackson;Mateusz Iwo Dubaniowski	2015		10.3233/978-1-61499-621-7-591	parallel computing	HPC	-6.434601044863946	39.8448714684317	90607
106daf1a447522d7216f70cefbae527367147460	a systolizing compilation scheme: abstract		We describe a methodology for mapping linear recurrence equations to a spectrum of systolic architectures. First, we design a systolic program in a very general architecture referred to as Basic Systolic Architecture and establish the correctness of the implementation. Next, we show how ef-cient transformations/implementations of programs for diierent systolic architectures can be obtained through transformations such as projections and translations.	correctness (computer science);recurrence relation	Michael Barnett;Christian Lengauer	1991			distributed computing;computer science	Arch	-13.331151509321382	34.331366651357996	90676
08421d951f7666eae565ed467705c14af9567797	siblingrivalry: online autotuning through local competitions	autotuning;genetic algorithm;evolutionary algorithm	Modern high performance libraries, such as ATLAS and FFTW, and programming languages, such as PetaBricks, have shown that autotuning computer programs can lead to significant speedups. However, autotuning can be burdensome to the deployment of a program, since the tuning process can take a long time and should be re-run whenever the program, microarchitecture, execution environment, or tool chain changes. Failure to re-autotune programs often leads to widespread use of sub-optimal algorithms. With the growth of cloud computing, where computations can run in environments with unknown load and migrate between different (possibly unknown) microarchitectures, the need for online autotuning has become increasingly important.  We present SiblingRivalry, a new model for always-on online autotuning that allows parallel programs to continuously adapt and optimize themselves to their environment. In our system, requests are processed by dividing the available cores in half, and processing two identical requests in parallel on each half. Half of the cores are devoted to a known safe program configuration, while the other half are used for an experimental program configuration chosen by our self-adapting evolutionary algorithm. When the faster configuration completes, its results are returned, and the slower configuration is terminated. Over time, this constant experimentation allows programs to adapt to changing dynamic environments and often outperform the original algorithm that uses the entire system.	atlas;auto-tune;cloud computing;computation;computer program;evolutionary algorithm;fftw;high availability;library (computing);microarchitecture;programming language;software deployment;toolchain	Jason Ansel;Maciej Pacula;Yee Lok Wong;Cy P. Chan;Marek Olszewski;Una-May O'Reilly;Saman P. Amarasinghe	2012		10.1145/2380403.2380425	embedded system;parallel computing;real-time computing;simulation;genetic algorithm;computer science;operating system;evolutionary algorithm;distributed computing	HPC	-16.774176766088026	38.22546656237834	90871
d6ae59089aa1b75201da4b05b349e6afe81c5a12	workflow editor for definition and execution of parallelized earth data processing algorithms		The aim of this paper is to present a workflow editor application meant to facilitate the description of parallelizable Earth Data processing algorithms. The application was developed as part of the BigEarth project, whose overall aim was to improve the execution time of large Earth Observation data sets by spreading the processing effort over a distributed, high-performance computing network. To achieve a simple and flexible manner of partitioning the parallel parts of the algorithms between different processing nodes, we chose to represent them using a simple, workflow-based model. Since one of the main purposes of the project was to provide a simple and intuitive way of creating algorithms descriptions, we chose to implement a Domain Specific Language coupled with a visual workflow representation used for providing feedback. Throughout this paper, we will be demonstrating the use of the workflow editor together with the description language in order to define and execute distributed data processing algorithms. We will be highlighting the effectiveness of the application as a means of providing processing algorithms by analyzing its behavior under various stress tests.	algorithm;distributed computing;domain-specific language;parallel computing;run time (program lifecycle phase);stress testing (software);supercomputer	Constantin I. Nandra;Dorian Gorgan	2018			theoretical computer science;workflow;data processing;computer science	HPC	-10.326485941990256	38.17734226857783	91289
0d543df529f8df62b6084df02005504ce294706d	constructing large suffix trees on a computational grid	dna;sufijo;parallelisme;distributed system;algoritmo paralelo;carga dinamica;haute performance;dynamic load balancing;systeme reparti;computational grid;parallel algorithm;localite;hierarchized structure;equilibrio de carga;suffix;communicating process;equilibrage charge;distributed computing;chaine caractere;bioinformatique;locality;structure hierarchisee;charge dynamique;dynamic load;lead time;algorithme parallele;proceso comunicante;suffix tree;grid;parallelism;sistema repartido;paralelismo;rejilla;envoi message;estructura datos;cadena caracter;processus communicant;analyse sequence;load balancing;biological sequence analysis;message passing;alto rendimiento;grille;calculo repartido;mpi;structure donnee;tiempo puesta en marcha;sequence analysis;bioinformatica;information system;suffixe;dna sequence;grid computing;high performance;data structure;temps mise en oeuvre;calcul reparti;systeme information;estructura jerarquizada;grid system;character string;bioinformatics;sistema informacion;parallel algorithms	The suffix tree is a key data structure for biological sequence analysis, since it permits efficient solutions to many string-based problems. Constructing large suffix trees is challenging because of high memory overheads and poor memory locality. Even though efficient suffix tree construction algorithms exist, their run-time is still very high for long DNA sequences such as whole human chromosomes. In this paper, we are using a hierarchical grid system as a computational platform in order to reduce this run-time significantly. To achieve an efficient mapping onto this type of architecture we introduce a parallel suffix tree construction algorithm that makes use of a new data structure called the common prefix suffix tree. Using this algorithm together with a dynamic load balancing strategy we show that our distributed grid implementation leads to significant run-time savings.	grid computing;suffix tree	Chunxi Chen;Bertil Schmidt	2006	J. Parallel Distrib. Comput.	10.1016/j.jpdc.2006.08.004	generalized suffix tree;parallel computing;data structure;computer science;theoretical computer science;operating system;distributed computing;parallel algorithm;compressed suffix array;programming language;fm-index;algorithm	HPC	-17.061045702982675	42.79586326510374	91323
43aca55ebc6a0567becc3556f55ac09ebedf9cfe	hotspot symbolic execution of floating-point programs	symbolic execution;hotspot;floating point	This paper presents hotspot symbolic execution (HSE) to scale the symbolic execution of floating-point programs. The essential idea of HSE is to (1) explore the paths of some functions (called hotspot functions) in priority, and (2) divide the paths of a hotspot function into different equivalence classes, and explore as fewer path as possible inside the function while ensuring the coverage of all the classes. We have implemented HSE on KLEE and carried out extensive experiments on all 5528 functions in GNU Scientific Library (GSL). The experimental results demonstrate the effectiveness and efficiency of HSE. Compared with the baseline, HSE detects >12 times of exceptions in 30 minutes.	baseline (configuration management);experiment;gnu scientific library;java hotspot virtual machine;symbolic execution;turing completeness	Minghui Quan	2016		10.1145/2950290.2983966	parallel computing;real-time computing;hotspot;computer science;floating point;operating system	SE	-13.473342800218427	36.18127663413917	91331
b6e4cc922a398a1b7ddf88a10af0f3395b61637a	a distributed hardware barrier in an optical bus-based distributed shared memory multiprocessor.	distributed shared memory			Martin H. Davis;Umakishore Ramachandran	1992			shared disk architecture;uniform memory access;distributed shared memory;shared memory;interleaved memory;parallel computing;distributed memory;computer science;operating system;data diffusion machine;replication;supercomputer architecture	Arch	-10.359224356891147	43.443205462467	91369
1b399353d92c4267d6d38cef6a19d12f7414f257	performance and scalability analysis of teraflop-scale parallel architectures using multidimensional wavefront applications	discrete ordinate method;data transmission;performance;66 physics;informing science;neutron transport;physics;computer architecture;discrete ordinates method;mathematical models;array processors;message passing;mathematical model;algorithms;99 mathematics computers information science management law miscellaneous;parallel architecture;supercomputers;parallel processing;mathematics computers information science management law miscellaneous	We develop a model for the parallel performance of algorithms that consist of concurrent, twodimensional wavefronts implemented in a message passing environment. The model, based on a LogGP machine parametrization, combines the separate contributions of computation and communication wavefronts. We validate the model on three important supercomputer systems, on up to 500 processors. We use data from a deterministic particle transport application taken from the ASCI workload, although the model is general to any wavefront algorithm implemented on a 2-D processor domain. We also use the validated model to make estimates of performance and scalability of wavefront algorithms on 100-TFLOPS computer systems expected to be in existence within the next decade as part of the ASCI program and elsewhere. In this context, we analyze two problem sizes. Our model shows that on the largest such problem ( 1 billion cells), inter-processor communication performance is not the bottleneck. Single-node efficiency is the dominant factor.	algorithm;central processing unit;computation;flops;inter-process communication;message passing;scalability;supercomputer	Adolfy Hoisie;Olaf M. Lubeck;Harvey J. Wasserman	2000	IJHPCA	10.1177/109434200001400405	computational science;parallel processing;parallel computing;computer science;theoretical computer science;operating system;mathematical model;mathematics;programming language;algorithm;statistics	HPC	-6.310606911312931	38.51488078362387	91378
ca364fe858ee8dbb89632103ce5004ace5bec3d4	composing functional unit blocks for efficient interpretation of mimd code sequences on simd processors	processing element;data parallel;software architecture;functional unit	The branching regions of data-parallel programs can lead to serial execution on a SIMD processor. However, recent investigations show that these branching regions can be compiled into instruction sequences that are placed in the Processing Element (PE) memories for interpretation. Thus, when the branching region is reached, the control unit of the SIMD processor executes an instruction interpreter that causes the concurrent execution (through interpretation) of the branching code at each PE. Interpretation incurs some overhead and therefore, it is necessary to carefully design the instruction set to be interpreted. In this paper, we present a software architecture called Compose with 9 functional units and show that these functional units can be composed together to realize (at least) 42 distinct useful instructions. Thus, each iteration of the interpreter loop pays only the overhead of broadcasting execution orders for a few operations and yet manages to interpret (in parallel) a much larger set of operations.	execution unit;mimd;simd	Ross A. Bagley;Philip A. Wilsey;Nael B. Abu-Ghazaleh	1994		10.1007/3-540-58430-7_54	computer architecture;parallel computing;mimd;computer science;programming language	Arch	-13.60955787103643	41.04043808757742	91399
ea2a727b2720f7357693bcc695d290531685986c	mgf: a grid-enabled mpi library with a delegation mechanism to improve collective operations	parallelisme;distributed system;virtual machine;haute performance;systeme reparti;mpich g2;point to point;distributed computing;machine virtuelle;grid;network topology;parallelism;sistema repartido;paralelismo;collective operations;message passing interface;rejilla;envoi message;message passing;alto rendimiento;grille;calculo repartido;mpi;source code;parallel programs;maquina virtual;grid computing;high performance;topologie circuit;calcul reparti;grid system	The success of Grid technologies depends on the ability of libraries and tools to hide the heterogeneous complexity of Grid systems. MPI-based programming libraries can make this environment more accessible to developers with parallel programming skills. In this paper we present MGF, an MPI library which extends the existing MPICH-G2. MGF aims are: to allow parallel MPI applications to be executed on Grids without source code modifications; to give programmers a detailed view of the execution system network topology; to use the most efficient channel available for point-to-point communications and finally, to improve collective operations efficiency introducing a delegation mechanism.	collective operation;daemon (computing);fibre channel point-to-point;library (computing);mpich;message passing interface;network topology;pacx;parallel computing;performance;point-to-point protocol;private network;programmer	Francesco Gregoretti;Giuliano Laccetti;Almerico Murli;Gennaro Oliva;U. Scafuri	2005		10.1007/11557265_38	parallel computing;computer science;message passing interface;theoretical computer science;operating system;database;distributed computing	HPC	-17.427574399061914	42.496689285291794	91473
bc62bc0a43a268de07a9ec8d42e02afedacd018c	toward auto-scheduling compilers	parallel computer;parallel programs	In this paper we propose a general framework for compiling, scheduling, and executing parallel programs on parallel computers. We discuss important aspects of program partitioning, scheduling, and execution, and consider possible realistic alternatives for each issue. Subsequently we propose a possible implementation of an auto-scheduling compiler and give simple examples to illustrate the principles. Our approach to the entire problem is to utilize program information available to the compiler while, at the same time, allowing for run-time “corrections” and flexibility.	compiler;computer;parallel computing;scheduling (computing)	Constantine D. Polychronopoulos	1988	The Journal of Supercomputing	10.1007/BF00129782	computer architecture;parallel computing;computer science;operating system;distributed computing;programming language	HPC	-11.216542956257829	40.30406796978234	91498
d52b2fbdeef9da31af656874d0a8412b9d73196d	look-ahead dynamic reconfiguration of link connections in multi-processor architectures			multiprocessing	Marek Tudruj	1995			computer science;control reconfiguration;parallel computing;look-ahead	Arch	-9.978750139408582	43.402602153962206	91562
63502daab29661d8bebce8008df8e63baacda7e3	resource contention in shared-memory multiprocessors: a parameterized performance degradation model	modelizacion;parallelisme;distributed system;evaluation performance;systeme reparti;shared memory;performance evaluation;multiprocessor;memoria compartida;evaluacion prestacion;sistema informatico;computer system;modelisation;parallelism;sistema repartido;paralelismo;systeme informatique;multiprocesador;modeling;memoire partagee;shared memory multiprocessor;multiprocesseur	A standard metric conventionally employed to compare the performance of different multiprocessor systems is speedup. Although providing a measure of the improvement in execution speed achievable on a system, this metric does not yield any insight into the factors responsible for limiting the potential improvement in speed. This paper studies the performance degradation in shared-memory multiprocessors as a result of contention for shared-memory resources. A replicate workload framework with a flexible mechanism for workload specification is proposed for measuring performance. Two normalized performance metrics-eJiciency and overhead factor-are introduced to quantify the factors limiting performance and facilitate comparison across architectures. Finally, the proposed model is employed to measure and compare the performance of three contemporary shared-memory systems, with special emphasis on the newly released BBN Butterfly-II (TC2000), currently undergoing Beta test. o 1991 Academic PKSS, IX.	bbn butterfly;elegant degradation;multiprocessing;overhead (computing);resource contention;self-replicating machine;shared memory;software performance testing;software release life cycle;speedup	Arun K. Nanda;Honda Shing;Ten H. Tzen;Lionel M. Ni	1991	J. Parallel Distrib. Comput.	10.1016/0743-7315(91)90003-R	shared memory;embedded system;parallel computing;real-time computing;multiprocessing;systems modeling;computer science;operating system	HPC	-16.58084177402676	43.35034314770738	91723
c80698daaad26182c35160a9a0b349a456a69c21	sensitivity analysis and mapping programs to parallel architectures.	sensitivity analysis;parallel architecture			Michael A. Driscoll;Jingsong Fu;Satish Maruti Pai;Chintamani Patwardhan;Liono Sedowijoso;De-Zheng Tang;Kiswanto Thayib	1991			computer science;sensitivity analysis	HPC	-9.478943394116948	41.86022948339156	91734
991102a5afab7359ab7b50b80453118a811e1a41	fast and low overhead architectural transaction level modelling for large-scale network-on-chip simulation	developpement logiciel;systeme temps reel;modelizacion;microscheduler;switching;arquitectura red;hardware verification;coroutine concepts;integrated circuit;registro rtl;fil;transaction processing electronic engineering computing integrated circuit modelling network on chip operating systems computers software engineering system on chip;large scale noc;function object concepts;sistema informatico;circuito integrado;computer system;sistema complejo;many core soc;architecture reseau;system on a chip;interconnection network;architectural analysis;modelisation;large scale;hilo;host computer;systeme complexe;operating system;sistema sobre pastilla;complex system;desarrollo logicial;scheduling;host computer low overhead architectural transaction level modelling large scale network on chip simulation software development architectural analysis hardware verification many core system on chips many core soc register transfer level rtl systemc based architectural modelling techniques microscheduler coroutine concepts function object concepts large scale noc operating system;software development;conmutacion;systemc based architectural modelling techniques;niveau transfert registre;low overhead architectural transaction level modelling;real time system;systeme informatique;network architecture;sistema tiempo real;systeme sur puce;thread;escala grande;large scale network on chip simulation;modeling;register transfer level;rtl;commutation;red interconexion;ordonnancement;circuit integre;reglamento;many core system on chips;echelle grande;reseau interconnexion	Early system modelling is an essential tool to accelerate software development, architectural analysis and hardware verification in complex many-core system-on-chips (SoCs). Transaction level modelling (TLM) offers a higher level of abstraction than register transfer level (RTL) and can be used for early system modelling. Maintaining simulation speed with the right accuracy is a major challenge and this paper proposes SystemC-based architectural modelling techniques that extend TLM to deliver faster simulation models for many-core system. The proposed approach considers a micro-scheduler for large modules (in the sense of SystemC modules) to locally manage all events in the module. Exploiting this micro-scheduler along with function object and coroutine concepts, the authors propose a lightweight thread process that significantly reduces the context switching overhead among the different processes. Additionally the micro-scheduler allows some processes to be run ahead of simulation time. The proposed techniques are applied to the model of a very large networks-on-chip (NoC) formed by thousands of cores stressing the simulation capabilities of the host computer and operating system. The experimental results demonstrate that the model can run successfully and exhibits up to 93% improvement in simulation speed compared to traditional SystemC-based modelling.		Mohammad Hosseinabady;José Luis Núñez-Yáñez	2012	IET Computers & Digital Techniques	10.1049/iet-cdt.2012.0001	system on a chip;embedded system;thread;complex systems;parallel computing;real-time computing;real-time operating system;systems modeling;network architecture;computer science;engineering;software development;operating system;integrated circuit;scheduling;register-transfer level;host	Web+IR	-18.805754622605487	42.86014682523241	91798
115848c4e273c88c1675278736905d6260e03776	practical experience in the numerical dangers of heterogeneous computing	distributed memory;heterogeneous processor networks;reliability;distributed memory systems;numerical software;heterogeneous systems;heterogeneous computing;g 1 0 numerical analysis general computer arithmetic;network of workstation;parallel computer;message passing;algorithms;floating point arithmetic;d 1 3 programming techniques concurrent programming distributed programming;heterogeneous network;parallel algorithms	Special challenges exist in writing reliable numerical library software for heterogeneous computing environments. Although a lot of software for distributed-memory parallel computers has been written, porting this software to a network of workstations requires careful consideration. The symptoms of heterogeneous computing failures can range from erroneous results without warning to deadlock. Some of the problems are straightforward to solve, but for others the solutions are not so obvious, or incur an unacceptable overhead. Making software robust on heterogeneous systems often requires additional communication. We describe and illustrate the problems encountered during the development of ScaLAPACK and the NAG Numerical PVM Library. Where possible, we suggest ways to avoid potential pitfalls, or if that is not possible, we recommend that the software not be used on heterogeneous networks.	computer cluster;deadlock;distributed memory;heterogeneous computing;numerical analysis;numerical linear algebra;overhead (computing);parallel virtual machine;parallel computing;scalapack;semantic network;workstation	L. Susan Blackford;Andrew J. Cleary;Antoine Petitet;R. Clinton Whaley;James Demmel;Inderjit S. Dhillon;Haohaohb Ren;Ken Stanley;Jack J. Dongarra;Sven Hammarling	1997	ACM Trans. Math. Softw.	10.1145/264029.264030	parallel computing;message passing;heterogeneous network;distributed memory;computer science;floating point;theoretical computer science;reliability;distributed computing;parallel algorithm;programming language;algorithm;symmetric multiprocessor system	HPC	-12.961871695459596	41.9625900280176	91858
7fccb480973e8303219692b88e254e777e770703	ssa-based matlab-to-c compilation and optimization	optimizing compiler;matlab;source to source compiler;ssa	Many fields of engineering, science and finance use models that are developed and validated in high-level languages such as MATLAB. However, when moving to environments with resource constraints or portability challenges, these models often have to be rewritten in lower-level languages such as C. Doing so manually is costly and error-prone, but automated approaches tend to generate code that can be substantially less efficient than the handwritten equivalents. Additionally, it is usually difficult to read and improve code generated by these tools. In this paper, we describe how we improved our MATLAB-to-C compiler, based on the MATISSE framework, to be able to compete with handwritten C code. We describe our new IR and the most important optimizations that we use in order to obtain acceptable performance. We also analyze multiple C code versions to identify where the generated code is slower than the handwritten code and identify a few key improvements to generate code capable of outperforming handwritten C. We evaluate the new version of our compiler using a set of benchmarks, including the Disparity benchmark, from the San Diego Vision Benchmark Suite, on a desktop computer and on an embedded device. The achieved results clearly show the efficiency of the current version of the compiler.	algorithm;benchmark (computing);binocular disparity;code generation (compiler);cognitive dimensions of notations;desktop computer;embedded system;high- and low-level;iterative method;matlab;mathematical optimization;opencl api;openmp;optimizing compiler;resultant;type inference	Luís Reis;João Bispo;João M. P. Cardoso	2016		10.1145/2935323.2935330	dead code;compile time;compiler;code bloat;parallel computing;loop-invariant code motion;compiler correctness;interprocedural optimization;computer science;operating system;dead code elimination;redundant code;compilation error;programming language;inline expansion;functional compiler;code generation;unreachable code;source code	PL	-17.176707944647717	36.10309644083013	91871
0c597f6c2c5a288381a06198b2f4e8ff650f4d0b	efficient discovery of regular stride patterns in irregular programs	lenguaje programacion;evaluation performance;compilateur;performance evaluation;programming language;profiling;data prefetch;generation code;evaluacion prestacion;prechargement donnee;generacion codigo;code generation;profiles methods;compiler;integrated stride and frequency profiling;performance programme;performance improvement;strongly single strided loads;data prefetching;analizador sintaxico;langage programmation;eficacia programa;itanium processor family;phased multi strided loads;parser;program performance;analyseur syntaxique;compilador	Irregular data references are difficult to prefetch, as the future memory address of a load instruction is hard to anticipate by a compiler. However, recent studies as well as our experience indicate that some important load instructions in irregular programs contain stride access patterns. Although the load instructions with stride patterns are difficult to identify with static compiler techniques, we developed an efficient profiling method to discover these load instructions. The new profiling method integrates the profiling for stride information and the traditional profiling for edge frequency into a single profiling pass. The integrated profiling pass runs only 17% slower than the frequency profiling alone. The collected stride information helps the compiler to identify load instructions with stride patterns that can be prefetched efficiently and beneficially. We implemented the new profiling and prefetching techniques in a research compiler for Itanium Processor Family (IPF), and obtained significant performance improvement for the SPECINT2000 programs running on Itanium machines. For example, we achieved a 1.59x speedup for 181.mcf, 1.14x for 254.gap, and 1.08x for 197.parser. We also showed that the performance gain is stable across input data sets. These benefits make the new profiling and prefetching techniques suitable for production compilers.	cpu cache;compiler;itanium;memory address;speedup	Youfeng Wu	2002		10.1145/512529.512555	compiler;parallel computing;real-time computing;computer science;operating system;profiling;programming language;code generation	Arch	-18.193535096996857	37.88595517007633	92223
5b9c731111ee4e32a46c040ef8235d936a0fe499	automatic tuning of bag-of-tasks applications	resource management;task analysis application program interfaces c language resource allocation;tuning;automatic tuning resource utilisation optimisation c api task execution time variability bag of tasks applications cpu user specific constraint aplug;lead;parallel processing tuning bioinformatics resource management supercomputers time frequency analysis lead;time frequency analysis;supercomputers;parallel processing;bioinformatics	This paper presents APlug, a framework for automatic tuning of large scale applications of many independent tasks. APlug suggests the best decomposition of the original computation into smaller tasks and the best number of CPUs to use, in order to meet user-specific constraints. We show that the problem is not trivial because there is large variability in the execution time of tasks, and it is possible for a task to occupy a CPU by performing useless computations. APlug collects a sample of task execution times and builds a model, which is then used by a discrete event simulator to calculate the optimal parameters. We provide a C++ API and a stand-alone implementation of APlug, and we integrate it with three typical applications from computational chemistry, bioinformatics, and data mining. A scenario for optimizing resources utilization is used to demonstrate our framework. We run experiments on 16,384 CPUs on a supercomputer, 480 cores on a Linux cluster and 80 cores on Amazon EC2, and show that APlug is very accurate with minimal overhead.	amazon elastic compute cloud (ec2);application programming interface;bioinformatics;c++;central processing unit;cloud computing;computation;computational chemistry;computer cluster;coupled cluster;data mining;degree of parallelism;docking (molecular);experiment;interdependence;linux;machine learning;overhead (computing);parallel computing;profiling (computer programming);run time (program lifecycle phase);sequence alignment;simulation;spatial variability;supercomputer	Majed Sahli;Essam Mansour;Tariq Alturkestani;Panos Kalnis	2015	2015 IEEE 31st International Conference on Data Engineering	10.1109/ICDE.2015.7113338	parallel processing;lead;parallel computing;real-time computing;time–frequency analysis;computer science;resource management;theoretical computer science;database;programming language	DB	-7.763758340427203	43.788507956405084	92426
b239b267f91b038263b1816aa98a3c316cf20a30	a versatile external control method for self-routable permutations in benes network			clos network;routing	Nabanita Das;Krishnendu Mukhopadhyaya;Jayasree Dattagupta	1992			permutation;distributed computing;parallel computing;computer science	Robotics	-10.376061670500352	42.94248105269404	92491
02ff011cfd76e317c9146bbffbdcfc2ad237148b	a path selection-based algorithm for real-time data staging in grid applications	distributed system;path selection;systeme reparti;blocage;grid applications;search space;base donnee tres grande;real time;concurrency in scheduling;distributed computing;simultaneidad informatica;bloqueo;satisfiability;real time data;blocking;data staging;large scale;dense data;concurrency;sistema repartido;scheduling;algorithme reparti;blocking analysis;data scheduling;calculo repartido;timing analysis;application temps reel;donnee intense;algoritmo repartido;data intensive and real time applications;is success;very large databases;distributed algorithm;simultaneite informatique;real time application;calcul reparti;ordonnancement;geographic distribution;reglamento;blocking analysis concurrency in scheduling	Efficient data scheduling is becoming an important issue in distributed real-time applications that produce huge data sets. The Grid environment on which these applications may run seeks to harness the geographically distributed resources for the applications. Scheduling components should account for real-time measures of the applications and reduce communication overhead due to enormous data size experienced, especially in dissemination applications. In this study, we consider the data staging scheme to provide the dissemination of large-scale data sets for the distributed real-time applications. We propose a new path selection-based algorithm for optimizing a criterion that reflects the general satisfiability of the system. The algorithm adopts a blocking-time analysis method combined with a simple heuristic to explore the most likely regions of a search space. Two heuristics are provided for the algorithm to explore these regions of the search space. Simulation results show that the proposed algorithm together with either of the heuristic has higher performance compared to other algorithms in the literature. We also show by simulation that a new optimization criterion we proposed in this study is successful in improving the performance of the individual applications. © 2005 Elsevier Inc. All rights reserved.		Mohammed E. Eltayeb;Atakan Dogan;Füsun Özgüner	2005	J. Parallel Distrib. Comput.	10.1016/j.jpdc.2005.05.027	distributed algorithm;mathematical optimization;real-time data;parallel computing;real-time computing;concurrency;computer science;theoretical computer science;operating system;distributed computing;scheduling;static timing analysis;blocking;algorithm;satisfiability	HPC	-17.394286237696807	44.16724054919015	92599
f4f336dedaac8a3e121809ba94165d6ab602dc54	hardware implementation of mpi_barrier on an fpga cluster	distributed memory;distributed memory parallel computer;fpga cluster;collective communication;point to point;tree based algorithm mpi_barrier operation fpga cluster message passing interface distributed memory parallel computer collective communication operation on chip off chip network kernel module;on chip off chip network;system on a chip;chip;programming model;fpga implementation;message passing interface;tree based algorithm;kernel module;application program interfaces;parallel computer;message passing;hardware design;hardware field programmable gate arrays parallel programming computer interfaces concurrent computing distributed computing delay algorithm design and analysis network on a chip kernel;collective communication operation;mpi_barrier operation;field programmable gate arrays;switches;ethernet networks;microprocessor chips application program interfaces field programmable gate arrays message passing;high speed;program processors;hardware implementation;software implementation;microprocessor chips;hardware	Message-Passing is the dominant programming model for distributed memory parallel computers and Message- Passing Interface (MPI) is the standard. Along with pointto- point send and receive message primitives, MPI includes a set of collective communication operations that are used to synchronize and coordinate groups of tasks. The MPI_Barrier, one of the most important collective procedures, has been extensively studied on a variety of architectures over last twenty years. However, a cluster of Platform FPGAs is a new architecture and offers interesting, resourceefficient options for implementing the barrier operation. This paper describes an FPGA implementation of MPI Barrier. The premise is that barrier (and other collective communication operations) are very sensitive to latency as the number of nodes scales to the tens-of-thousands. The relatively slow processors found on FPGAs will significantly cap performance. The FPGA hardware design implements a tree-based algorithm and is tightly integrated with the custom high-speed on-chip/off-chip network. MPI access is available through a specially-designed kernel module. This effectively offloads the work from the CPU and OS into hardware. The evaluation of this design shows signficant performance gains compared with a conventional software implementation on both an FPGA cluster and a commodity cluster. Further, it suggests that moving other MPI collective operations into hardware would be beneficial.	algorithm;barrier function;beowulf cluster;central processing unit;computer;distributed memory;field-programmable gate array;loadable kernel module;message passing interface;operating system;parallel computing;programming model;tree (data structure)	Shanyuan Gao;Andrew G. Schmidt;Ron Sass	2009	2009 International Conference on Field Programmable Logic and Applications	10.1109/FPL.2009.5272560	chip;system on a chip;embedded system;computer architecture;parallel computing;message passing;distributed memory;network switch;point-to-point;computer science;message passing interface;operating system;distributed computing;programming paradigm;field-programmable gate array	HPC	-10.93361085232377	46.369999246220665	92630
b62fff57b794a5a4af69d2fc3cc06efaa3fc2d25	using fpgas as control support in mimd executions	parallel architecture	In the wide eld of parallel architectures, machines involving fpgas on each node have appeared during the last years. Connecting these reconngurable components opens new research horizons. Expensive control tasks required by distributed applications may then be accelerated using application speciic hard-wired elements. A derivation from a standard algorithm for distributed simulation and its partial hardware implementation are presented in this paper, providing three magnitude orders speed-ups.	algorithm;distributed computing;field-programmable gate array;internet-speed development;mimd;simulation	Christophe Beaumont	1995		10.1007/3-540-60294-1_102	computer architecture;parallel computing;real-time computing;mimd;computer science	HPC	-8.67236499083502	41.04725774043393	92690
f8c7721f93a142c81c7cf534f651d56563b6b961	implementation approach to parallel systems	parallel systems	Abstract Parallel system (problem), computation history, concurrency matrix, scheduling discipline		Ludwik Czaja	1978	Inf. Process. Lett.	10.1016/0020-0190(78)90008-X	parallel computing;embarrassingly parallel;computer science;theoretical computer science;mathematics;distributed computing;parallel extensions;cost efficiency	DB	-9.980027312268245	41.19440278661057	92717
6200a2baf508fd15f96f6bc8ccdd749d505e20c2	high-level microprogramming: an optimizing c compiler for a processing element of a cad accelerator	high level languages;code generation;message passing;parallel processing;high level language;hardware accelerator;programming language;mars;compiler optimization;very large scale integration;design automation;space time;microprogramming;acceleration	The development of a high-level language compiler for a micro-programmable processing element (PE) in the MARS multicomputer is described. MARS, an MIMD message passing machine, was designed to speed up VLSI CAD and similar other non-numerical applications. The need for support of a high-level language at the PE level of a multicomputer is considered, and the choice of C as an appropriate programming language is justified. Special features found in VLSI processors are examined along with compiler support for them. Conventional retargetable compiler techniques are shown to be inadequate for the highly concurrent micro-programmable PE. These techniques must be extended for microcode generation. The design of the MARS compiler is outlined. Performance data is provided to evaluate the benefit of various compiler optimizations, and to compare compiler generated microcode to hand generated microcode in terms of space and time performance	central processing unit;computer-aided design;high- and low-level;high-level programming language;mimd;message passing;microcode;numerical analysis;optimizing compiler;parallel computing;retargeting	Paul Kenyon;Prathima Agrawal;Sharad C. Seth	1990		10.1145/255237.255255	manifest expression;parallel processing;computer architecture;compiler;parallel computing;compiler correctness;interprocedural optimization;computer science;loop optimization;operating system;compiler construction;optimizing compiler;programming language;inline expansion;intrinsic function;high-level programming language;functional compiler	Arch	-13.998092106725561	38.23237647719935	92729
c03b36542659028b8eb24969e2a89b43c6fcb53a	liger: a hybrid dataflow architeture exploiting data/control locality			dataflow;locality of reference	Tzi-cker Chiueh	1991			distributed computing;parallel computing;dataflow;locality;computer science	Arch	-9.976323812455863	43.462337631413554	92756
0bb358c341ed27f222429f1e8ac1402893a3a944	achieving transparency mapping parallel applications: a memory hierarchy affair		Computer systems are becoming increasingly complex: they provide the expected compute capability at the cost of deeper memory hierarchies (high-bandwidth and high-capacity memories), heterogeneous compute elements (latency-optimized and throughput-optimized cores), and heterogeneous memories (volatile and non-volatile). To run a parallel application, users need to determine the mapping of MPI tasks and OpenMP/POSIX threads to the hardware resources. Not only this can be challenging but when executing the same application on a different system, the mapping will likely change to attain reasonable performance.  This work empirically evaluates a memory-driven algorithm, namely mpibind, to map parallel hybrid applications to the underlying architecture transparently from the point of view of applications. We use mpibind to bridge the gap between performance and ease-of-use in the context of Intel's Knights Landing architecture. This architecture presents a challenging environment to program including a two-level memory system, three memory modes, and four clustering modes of cache operation. We show that mpibind leverages the performance of advanced memory and clustering modes and, at the same time, enables application developers to map their applications without knowledge of the hardware topology as if using a simpler configuration. The key to achieving this goal relies on following the memory hierarchy, which is mpibind's design focus.		Edgar A. León;Matthieu Hautreux	2018		10.1145/3240302.3240316	challenging environment;architecture;cache;cluster analysis;hierarchy;transparency (graphic);posix threads;memory hierarchy;distributed computing;computer science	HPC	-7.530186305323293	44.586619600603605	93109
c14cd836deb61943f485fd4558ff83e205bda336	parallel domain connectivity algorithm for unsteady flow computations using overlapping and adaptive grids	overset grid;time dependent;interpolation;dynamique;adaptive mesh refinement;performance;adaptive grid;calculation;methode calcul;algorithme parallele;multi solver paradigm;computational fluid dynamics;technique calcul;dynamics;rotors;unsteady flow;calculation methods;algorithms;dynamic simulation;reprints;parallel execution;adaptive grids;domain connectivity;data transfer;ecoulement instationnaire;parallel algorithms	This paper describes the algorithms and functionality of a new module developed to support overset grid assembly associated with performing time-dependent and adaptive moving body calculations of external aerodynamic flows using a multi-solver paradigm (i.e. different CFD solvers in different parts of the computational domain). We use the term ‘‘domain connectivity” in this paper to denote all the procedures that are involved in an overset grid assembly, and the module developed is referred henceforth as the domainconnectivity module. The domain-connectivity module coordinates the data transfer between different solvers applied in different parts of the computational domain – body fitted structured or unstructured to capture viscous near-wall effects, and Cartesian adaptive mesh refinement to capture effects away from the wall. The execution of the CFD solvers and the domain-connectivity module are orchestrated by a Python-based computational infrastructure. The domain-connectivity module is fully parallel and performs all its operations (identification of grid overlaps and determination of data interpolation strategy) on the partitioned grid data. In addition, the domain connectivity procedures are completely automated such that no user intervention or manual input is necessary. The capabilities and performance of the package are presented for several test problems, including flow over a NACA 0015 wing and an AGARD A2 slotted airfoil, hover simulation of a scaled V-22 rotor, and dynamic simulation of a UH-60A rotor in forward flight. A modification to the algorithm for improved domain connectivity solutions in problems with tight tolerances as well as heterogeneous grid clustering is also presented. Published by Elsevier Inc.	adaptive grammar;adaptive mesh refinement;algorithm;angular defect;automation;categorization;central processing unit;cluster analysis;computation;cutting stock problem;data validation;distributed computing;dynamic simulation;internationalized domain name;interpolation;on the fly;parallel computing;programming paradigm;python;r.o.t.o.r.;refinement (computing);scalability;second level address translation;solver;test case;the wall street journal;unbalanced circuit;velocity (software development);vortex	Jayanarayanan Sitaraman;Matthew Floros;Andrew M. Wissink;Mark Potsdam	2010	J. Comput. Physics	10.1016/j.jcp.2010.03.008	dynamic simulation;mathematical optimization;dynamics;parallel computing;calculation;adaptive mesh refinement;performance;computational fluid dynamics;interpolation;computer science;theoretical computer science;parallel algorithm;algorithm	HPC	-8.41987296704692	35.67573372798706	93128
066f071b571a8d94ba0faba6b07bd14b1db0e5f6	the # model: separation of concerns for reconciling modularity, abstraction and efficiency in distributed parallel programming	separation of concern;parallel programming;software engineering;large scale;levels of abstraction;science communication;high performance computer;parallel programming model;separation of concerns;parallel programs;parallel languages;high performance computing software	The computer science community has been looking for parallel languages and models with a higher level of abstraction and modularity, without performance penalties, that could be used in conjunction with advanced software engineering techniques, and that are suitable to work with large-scale programs. This paper discusses how the # parallel programming model addresses the issues of modularity and abstraction of parallel programs using the techniques of separation of concerns.	computer science;parallel computing;parallel programming model;separation of concerns;software engineering	Francisco Heron de Carvalho Junior;Rafael Dueire Lins	2005		10.1145/1066677.1066984	separation of concerns;computer science;theoretical computer science;database;distributed computing;programming language;parallel programming model	SE	-14.050022361115577	39.80832947806463	93162
28761b7398b4b9f6c7158687be2b634b06a5d28e	run-time and compile-time support for adaptive irregular problems	data handling;data structures;distributed memory systems;parallelising compilers;physics computing;software libraries;chaos;chaos primitives;charmm;fortran d;syracuse fortran 90d/hpf prototype compiler;adaptive irregular applications;adaptive irregular problems;compile-time support;compilers;data access patterns;data arrays;distributed memory machines;dynamic data partitioning;fast data migration;gas flow simulation;indirection arrays;kernels;molecular dynamics code;run-time support;runtime library;runtime primitives	In adaptive irregular problems, data arrays are accessed via indirection arrays, and data access patterns change during computation. Parallelizing such problems on distributed memory machines requires support for dynamic data partitioning, efficient preprocessing and fast data migration. This paper describes CHAOS, a library of efficient runtime primitives that provides such support. To demonstrate the effectiveness of the runtime support, two adaptive irregular applications have been parallelized using CHAOS primitives: a molecular dynamics code (CHARMM) and a code for simulating gas flows (DSMC). We have also proposed minor extensions to Fortran D which would enable compilers to parallelize irregular forall loops in such adaptive applications by embedding calls to primitives provided by a runtime library. We have implemented our proposed extensions in the Syracuse Fortran 90D/HPF prototype compiler, and have used the compiler to parallelize kernels from two adaptive applications.	chaos;charmm;compile time;compiler;complex adaptive system;computation;data access;direct simulation monte carlo;distributed memory;dynamic data;high performance fortran;indirection;molecular dynamics;parallel computing;preprocessor;prototype;runtime library	Shamik D. Sharma;Ravi Ponnusamy;Bongki Moon;Yuan-Shin Hwang;Raja Das;Joel H. Saltz	1994			data access;parallel processing;compiler;parallel computing;data migration;dynamic data;computer science;technical report;theoretical computer science;operating system;group method of data handling;programming language;data transmission;memory management	HPC	-9.884951919742562	37.7788231583501	93176
b2cf86185e5ea827edde8b11ce342d3c4e18fd71	an instruction issuing approach to enhancing performance in multiple functional unit processors	computers;digital computers;eficacia sistema;multiple functional unit processors;optimisation;processing;unite fonctionnelle;general and miscellaneous mathematics computing and information science;mathematics;processor performance enhancement dispatch stack dynamic instruction scheduling instruction issuing instruction unit multiple functional unit processors multiple instruction dispatching;productivite;optimizacion;multiple instruction dispatching;performance;performance systeme;data processing;instruction;instruccion;supercomputer;mathematical logic;productividad;system performance;supercomputador;simulation 990200 mathematics computers;instruction issuing;statistical computing;instruction unit;array processors;computerized simulation;scientific computing;statistics;computer codes;algorithms;optimization;procesador;processor performance enhancement;productivity;functional unit;dynamic instruction scheduling;task scheduling;processeur;process simulation;multiple;high performance;supercomputers;dispatch stack;processor;cray computers;superordinateur	Processors with multiple functional units, such as CRAY-1, Cyber 205, and FPS 164, have been used for high-end scientific computation tasks. Much effort has been put into increasing the throughput of such systems. One critical consideration in their design is the identification and implementation of a suitable instruction issuing scheme. Existing approaches do not issue enough instructions per machine cycle to fully utilize the functional units and realize the high-performance level achievable with these powerful execution resources.	cdc cyber;central processing unit;computation;computational science;cray-1;execution unit;floating point systems;instruction cycle;throughput	Ramón D. Acosta;Jacob Kjelstrup;Hwa C. Torng	1986	IEEE Transactions on Computers	10.1109/TC.1986.1676841	embedded system;computer architecture;mathematical logic;productivity;supercomputer;parallel computing;process simulation;data processing;performance;computer science;electrical engineering;processing;theoretical computer science;operating system;programming language;algorithm;multiple;statistics	Arch	-15.262387221206776	43.372537494592166	93651
b31b9a8aa0e3512c0daa0935caa8b04e433651ab	scalable multi-agent simulation based on mapreduce		Jason is perhaps the most advanced multi-agent programming language based on AgentSpeak . Unfortunately, its current Java-based implementation does not scale up and is seriously limited for simulating systems of hundreds of thousands of agents. We are presenting a scalable simulation platform for running huge numbers of agents in a Jason style simulation framework. Our idea is (1) to identify independent parts of the simulation in order to parallelize as much as possible, and (2) to use and apply existing technology for parallel processing of large datasets (e.g.MapReduce). We evaluate our approach on an early benchmark and show that it scales up linearly (in the number of agents).	agentspeak;benchmark (computing);jason;java;mapreduce;multi-agent system;parallel computing;programming language;scalability;simulation	Tobias Ahlbrecht;Jürgen Dix;Niklas Fiekas	2016		10.1007/978-3-319-59294-7_31	scalability;distributed computing;computer science;java	AI	-11.572895307405613	40.239864356431255	93811
eb179734cfb5f1fcaadf2742f91d3d71b46eeeff	input space splitting for opencl	llvm;paper;polyhedral representation;divergence;intel;spmd;vectorization;compilers;computer science;opencl	The performance of OpenCL programs suffers from memory and control flow divergence. Therefore, OpenCL compilers employ static analyses to identify non-divergent control flow and memory accesses in order to produce faster code. However, divergence is often input-dependent, hence can be observed for some, but not all inputs. In these cases, vectorizing compilers have to generate slow code because divergence can occur at run time. In this paper, we use a polyhedral abstraction to partition the input space of an OpenCL kernel. For each partition, divergence analysis produces more precise results i.e., it can classify more code parts as non-divergent. Consequently, specializing the kernel for the input space partitions allows for generating better SIMD code because of less divergence. We implemented our technique in an OpenCL driver for the AVX instruction set and evaluate it on a range of OpenCL benchmarks. We observe speed ups of up to 9x for irregular kernels over a state-of-the-art vectorizing OpenCL driver.	advanced vector extensions;compiler;control flow;kernel (operating system);opencl api;polyhedron;run time (program lifecycle phase);simd;static program analysis;vergence	Simon Moll;Johannes Doerfert;Sebastian Hack	2016		10.1145/2892208.2892217	computer architecture;compiler;parallel computing;computer science;vectorization;programming language;divergence;spmd	PL	-6.008275850110358	45.86497965432618	93816
53d2d90d79b47a76000b8cfcfd71565a26db2862	algorithm 656: an extended set of basic linear algebra subprograms: model implementation and test programs	basic linear algebra subprogram;model implementation;test software;test program;additional key words and phrases: extended blas;utilities;basic linear algebra subprograms;extended set;specialized implementation;matrix-vector operation;high-performance computer;portable set	This paper describes a model implementation and test software for the Level 2 Basic Linear Algebra Subprograms (Level 2 BLAS). Level 2 BLAS are targeted at matrix-vector operations with the aim of providing more efficient, but portable, implementations of algorithms on high-performance computers. The model implementation provides a portable set of FORTRAN 77 Level 2 BLAS for machines where specialized implementations do not exist or are not required. The test software aims to verify that specialized implementations meet the specification of Level 2 BLAS and that implementations are correctly installed.	algorithm;blas;cpu cache;computer;fortran;linear algebra;reference implementation;subroutine;supercomputer	Jack J. Dongarra;Jeremy Du Croz;Sven Hammarling;Richard J. Hanson	1988	ACM Trans. Math. Softw.	10.1145/42288.42292	computational science;computer architecture;parallel computing;computer science;basic linear algebra subprograms	PL	-12.747666057307743	36.29196437435787	93825
bc9b9dddde9097b4527998ad949a4bfb82331e20	comparison of parallel programming models for multicore architectures	multiprocessing programs;multicore architectures;software engineering multiprocessing programs multiprocessing systems parallel programming;energy efficient;parallel programming;software engineering;hot spot;programming model;automatic speech recognition;gcd;parallel programming models;synchronization;automatic speech recognition parallel programming models multicore architectures multicore computing platforms software development tools openmp gcd pthreads parallelize face detection;multicore processing;openmp;speech recognition;multicore computing platforms;software development tools;pthreads;face;multiprocessing systems;parallel programming model;parallelize face detection;face detection;high performance;programming;high power;multicore processing programming face parallel processing instruction sets synchronization;parallel processing;instruction sets	Multicore computing platforms have emerged as the most common computing platform to overcome challenges stemming from high power densities and thermal hot spots in conventional microprocessors. However, providing multiple cores does not directly translate into increased performance or better energy efficiency for most applications. The burden is placed on developers and tools to find and exploit parallelism and eventually utilize all of the available computing resources. Since multicore applications are more complex than single core applications, the software development tools play a crucial role to help programmers create high performance and correct software. In this paper we compare the most popular programming models OpenMP, GCD and Pthreads by applying these models to parallelize face detection and automatic speech recognition applications.	face detection;microprocessor;multi-core processor;openmp;posix threads;parallel computing;programmer;programming language;programming model;programming tool;software development;speech recognition;stemming	T. C. Deepak Shekhar;Kiran Varaganti;Rahul Suresh;Rahul Garg;Ramalingam Ramamoorthy	2011	2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum	10.1109/IPDPS.2011.324	face;multi-core processor;parallel processing;synchronization;programming;face detection;computer architecture;parallel computing;computer science;posix threads;operating system;instruction set;distributed computing;efficient energy use;programming paradigm;programming language;hot spot;greatest common divisor;parallel programming model	Arch	-6.454165147649155	44.553003166153815	93986
5715ca95df211850d73d5feab9993573070d4300	a communication model for optimizing hierarchical multiprocessor systems	communication model;parallel processing;hierarchical system	Experimental hierarchial multiprocessor systems have been built, notably the Cm* and the EGPA machine and the construction of the Cedar is in progress. As an examination of these three systems shows, hierarchical systems encompass a range of processor configurations and interprocessor communication links. The development of cost and performance models together with a knowledge of the eventual workload enables us to choose an appropriate processor configuration. This in turn permits us to examine the suitability of particular systems for solving problems with different patterns of interprocessor communication and to emulate other multiprocessor interconnection schemes. Since our primary objective is to compare various processor configurations in large systems, the models we have developed ignore factors which tend to have a similar effect on a wide range of configurations.	multiprocessing;optimizing compiler	Santosh G. Abraham;Edward S. Davidson	1986			distributed computing;workload;interconnection;architecture;parallel computing;computer program;multiprocessing;models of communication;computer science;parallel processing;hierarchical control system	HPC	-14.313771254753764	43.13246341360719	94152
8927440b9cd0d1822509be4201117122893d9d55	rank reordering strategy for mpi topology creation functions	distributed system;algoritmo paralelo;program graph;eficacia sistema;systeme reparti;parallel algorithm;systeme multiprocesseur memoire repartie;ordinateur parallele;multiprocessor systems;etude experimentale;implementation;performance systeme;system performance;algorithme parallele;hardware architecture;ejecucion;sistema repartido;graphe programme;mappage;sistema multiprocesador memoria distribuida;ordenador paralelo;parallel computer;mapping;distributed memory multiprocessor system;grafo programa;modular architecture;estudio experimental;parallel applications	A large fraction of all parallel applications use process topologies. Mapping of those topologies onto hardware architecture  has been studied for long time. Meanwhile, many current multiprocessor systems are implemented in modular architecture. This  paper presents a new mapping strategy that takes advantage of this modularity. The idea was implemented in MPI's topology  creation functions and found to be very effective.  		Takao Hatazaki	1998		10.1007/BFb0056575	embedded system;parallel computing;computer science;hardware architecture;parallel algorithm;implementation;algorithm	HPC	-16.73930234838778	42.619553839816184	94262
d9120ae5aa7fb4c7097ce286392df33531691a6f	portable parallel programming: cross machine comparisons for simple	parallel programs		parallel computing;simple	Calvin Lin;Lawrence Snyder	1991			computational science;computer science;theoretical computer science;distributed computing;parallel programming model	HPC	-9.844593496995502	41.01623800066181	94374
03d551cddcec9cb61a9dcec7b0e436dc1f583696	from distributed sequential computing to distributed parallel computing	sequential machines;multi threading;parallel cholesky factorization distributed sequential computing parallel computing parallel programming sequential thread performance data program transformation parallel jacobi iteration;program transformation;concurrent computing distributed computing parallel processing yarn parallel programming jacobian matrices navigation computer science software agents computer networks;cholesky factorization;iterative methods;parallel computer;distributed parallel computing;parallel programs;jacobian matrices;multi threading jacobian matrices iterative methods sequential machines	One approach to distributed parallel programming is to utilize self-migrating threads. Computations can be distributed first, and parallelized second. The first step produces a distributed sequential thread, which can be incrementally parallelized by the second step. This paper prescribes three transformations that turn distributed sequential programs into distributed parallel programs. Real-life examples and performance data are presented, and the advantages of our approach are discussed.	computation;parallel computing	Lei Pan;Lubomir F. Bic;Michael B. Dillencourt;Ming Kin Lai	2003		10.1109/ICPPW.2003.1240378	distributed algorithm;parallel computing;multithreading;embarrassingly parallel;computer science;theoretical computer science;massively parallel;distributed computing;iterative method;cholesky decomposition;cost efficiency;parallel programming model	HPC	-10.359212229546305	39.22254238704776	94377
6f2c5c84bc2c7a6b768db5a4712acc1060ac73dc	experiences with asynchronous parallel molecular dynamics simulations	molecular dynamic simulation;performance analysis;message passing;modes of operation;network congestion;parallel processing	This article provides some insight in the runtime behavior of asynchronous methods for parallel molecular dynamics simulations that we recently introduced. From this, the advantages of the asynchronous mode of operation becomes very obvious, i.e. the abilities to hide message passing latencies, to reduce network congestion and to level out processing power and/or load fluctuations. The conclusions are validated by simulation runs on a network of up to 12 workstations, comparing the results to a synchronous mode of execution.	algorithm;block cipher mode of operation;code;computation;computer cluster;desktop computer;message passing;microsoft outlook for mac;molecular dynamics;network congestion;parallel computing;simulation;synchronization (computer science);workstation	Marcus Dormanns;Walter Sprangers	1996		10.1007/3-540-61142-8_550	parallel processing;parallel computing;message passing;real-time computing;computer science;distributed computing;programming language;network congestion;computer network	HPC	-10.483519802142137	45.52369286401434	94447
1b9479fbf2f2b8d59b4e461a678b4cd5de8f124f	a recursive hypergraph bipartitioning framework for reducing bandwidth and latency costs simultaneously	standards;measurement;bandwidth measurement program processors solid modeling standards computational modeling sparse matrices;partitioning;computational modeling;solid modeling;load balancing;communication cost;combinatorial scientific computing;bandwidth;latency;hypergraph;program processors;sparse matrices;recursive bipartitioning;combinatorial scientific computing communication cost bandwidth latency partitioning hypergraph recursive bipartitioning load balancing sparse matrix vector multiplication;sparse matrix vector multiplication	"""Intelligent partitioning models are commonly used for efficient parallelization of irregular applications on distributed systems. These models usually aim to minimize a single communication cost metric, which is either related to communication volume or message count. However, both volume- and message-related metrics should be taken into account during partitioning for a more efficient parallelization. There are only a few works that consider both of them and they usually address each in separate phases of a two-phase approach. In this work, we propose a recursive hypergraph bipartitioning framework that reduces the total volume and total message count in a single phase. In this framework, the standard hypergraph models, nets of which already capture the bandwidth cost, are augmented with <italic>message nets</italic>. The message nets encode the message count so that minimizing conventional cutsize captures the minimization of bandwidth and latency costs together. Our model provides a more accurate representation of the overall communication cost by incorporating both the bandwidth and the latency components into the partitioning objective. The use of the widely-adopted successful recursive bipartitioning framework provides the flexibility of using any existing hypergraph partitioner. The experiments on instances from different domains show that our model on the average achieves up to <inline-formula><tex-math notation=""""LaTeX"""">$52$</tex-math><alternatives> <inline-graphic xlink:href=""""aykanat-ieq1-2577024.gif""""/></alternatives></inline-formula> percent reduction in total message count and hence results in <inline-formula><tex-math notation=""""LaTeX"""">$29$</tex-math><alternatives> <inline-graphic xlink:href=""""aykanat-ieq2-2577024.gif""""/></alternatives></inline-formula> percent reduction in parallel running time compared to the model that considers only the total volume."""	distributed computing;encode;experiment;graph partition;heuristic (computer science);parallel computing;programming paradigm;recursion (computer science);requirement;time complexity;two-phase commit protocol;xlink	R. Oguz Selvitopi;Seher Acer;Cevdet Aykanat	2017	IEEE Transactions on Parallel and Distributed Systems	10.1109/TPDS.2016.2577024	latency;parallel computing;sparse matrix;computer science;load balancing;theoretical computer science;distributed computing;solid modeling;computational model;computer security;bandwidth;measurement;statistics	Visualization	-6.264844897501875	40.871861114719934	94581
e9af79926782d09467472489335339052653397c	scalability analysis of parallel particle-in-cell codes on computational grids	globus toolkit;computational grid;52 65 rr;mpich g2;collective communication;point to point;particle in cell code;three dimensional;07 05 bx;grid computing;particle in cell;communication pattern	We have performed benchmarks of two three-dimensional parallel Particle-In-Cell (PIC) codes that are similar but have quite different communication patterns on different computational Grids. An electrostatic code with only electrons based on the three-dimensional skeleton PIC code employs the FFT Poisson solver that uses collective communication patterns. Another is the TRISTAN (TRI-dimensional STATNford) code parallelized with MPI, an electromagnetic full particle code, which uses a field solver that only requires point-to-point neighbor communication patterns. We present the mpptest benchmarks on cluster-based computational Grids, where both the basic point-to-point communication patterns and the basic collective communication patterns used in these PIC codes are tested. The results of these benchmarks clearly allow us to quantify and understand the scalability of both communication patterns on the Grids. The present results show that the parallelized TRISTAN code (without all-to-all collective communication) is more scalable than the parallelized skeleton PIC code (with all-to-all collective communication), in cluster-based computational Grid systems where communication performances is poor.	code;particle-in-cell;scalability	WeiFeng Tao;DongSheng Cai;Xiaoyang Yan;Ken-ichi Nishikawa;Bertrand Lembege	2008	Computer Physics Communications	10.1016/j.cpc.2008.07.004	three-dimensional space;particle-in-cell;parallel computing;point-to-point;computer science;theoretical computer science;distributed computing;physics;grid computing	HPC	-5.592159434828648	37.53614570998083	94658
b488f9ff585ae6803a8affca8907e66a542da2cb	kaira: development environment for mpi applications		This tool paper presents Kaira (http://verif.cs.vsb.cz/ kaira/) – a tool for simplifying development of parallel applications in the area of scientific and engineering computations for distributed memory systems. Our goal is to provide an environment in which a user can implement and experiment with his or her ideas in a short time; create a real running program; and verify its performance, scalability, and correctness. A unifying element in our approach is a visual programming language inspired by Colored Petri Nets that is used to define the parallel behavior, to show an inner state of a developed application back to the user, and for configurations of analyzes.		Stanislav Böhm;Marek Behalek;Ondrej Meca;Martin Surkovský	2014		10.1007/978-3-319-07734-5_22	real-time computing;simulation;computer science;artificial intelligence;distributed computing;programming language;algorithm	HPC	-10.70324144726526	37.8844587681839	94863
47aa99cbdb08786d3475efb35fb11a1cd1b205eb	parallel performance analysis of a regional numerical weather prediction model in a petascale machine		This paper presents the parallel performance achieved by a regional model of numerical weather prediction (NWP), running on thousands of computing cores in a petascale supercomputing system. It was obtained good scalability, running with up to 13440 cores, distributed in 670 nodes. These results enables this application to solve large computational challenges, such as perform weather forecast at very high spatial resolution.	numerical weather prediction;petascale computing;profiling (computer programming)	Roberto Pinto Souto;Pedro Leite da Silva Dias;Franck Vigilant	2015		10.1007/978-3-319-26928-3_11	computational science;simulation;computer science;data science	HPC	-7.165857563080054	36.40243064933013	94937
4f0a7a76fdd4a97cd69a1034e020cf7cc3f14fe2	rmr-efficient implementations of comparison primitives using read and write operations	comparison primitives;consensus;shared memory;remote memory references;mutual exclusion;load linked store conditional	We consider asynchronous multiprocessors where processes communicate only by reading or writing shared memory. We show how to implement consensus, compare-and-swap and other comparison primitives, as well as load-linked/store-conditional (LL/SC) using only a constant number of remote memory references (RMRs), in both the cache-coherent and the distributed-shared-memory models of such multiprocessors. Our implementations are blocking, rather than wait-free: they ensure progress provided all processes that invoke the implemented primitive are live. Our results imply that any algorithm using read and write operations, and either comparison primitives or LL/SC, can be simulated by an algorithm that uses read and write operations only, with at most a constant-factor increase in RMR complexity.	blocking (computing);cache coherence;coherence (physics);compare-and-swap;comparison sort;distributed shared memory;ll grammar;ll parser;load-link/store-conditional;non-blocking algorithm;paging	Wojciech M. Golab;Vassos Hadzilacos;Danny Hendler;Philipp Woelfel	2011	Distributed Computing	10.1007/s00446-011-0150-8	shared memory;embedded system;parallel computing;consensus;mutual exclusion;computer science;theoretical computer science;operating system;distributed computing;programming language	Theory	-15.214225053479527	46.369685579840045	94948
0eef022e861420a2e4fc78ba3939a3f576cbd0b8	the serial performance standards for the bbs test program	performance standards;serial performance standard;because benchmark set;bbs test program;parallel computer architecture	ESPRIT Project 5417 BECAUSE is concerned with the benchmarking of parallel computer architectures for computer intensive scientific and engineering applications. Fluid flow, semi-conductor modelling and electromagnetic field simulation software was profiled on a range of example applications and sizes. The profiling results were used to select the algorithms and functions that ought to be included in the Because Benchmark Set (BBS). This paper reviews the BBS results obtained on the 'control' sequential architecture computer. The results show consistent performance with some interesting variations in achieved Mflops.	algorithm;benchmark (computing);computer architecture;flops;parallel computing;semiconductor industry;simulation software	C. P. Riley;J. Simkin	1994	Future Generation Comp. Syst.	10.1016/0167-739X(94)90006-X	parallel computing;simulation;computer science;operating system;database;distributed computing	HPC	-8.382457097033683	39.930959119206015	95041
a705f4cf42bf7ec2a779a7673fd836a975de363a	flexible skeletal programming with eskel	modelizacion;parallelisme;distributed system;haute performance;systeme reparti;esqueleto;distributed computing;skeleton;modelisation;parallelism;sistema repartido;paralelismo;alto rendimiento;squelette;calculo repartido;parallel programs;modeling;high performance;calcul reparti	We present an overview of eSkel, a library for skeletal parallel programming. eSkel aims to maximise the conceptual flexibility afforded by its component skeletons and to facilitate dynamic selection of skeleton compositions. We present simple examples which illustrate these properties, and discuss the implementation challenges which the model poses.	parallel computing	Anne Benoit;Murray Cole;Stephen Gilmore;Jane Hillston	2005		10.1007/11549468_83	simulation;systems modeling;computer science;artificial intelligence;distributed computing;skeleton;algorithm	HCI	-17.66237619444846	41.94720687159927	95140
92530ca9a573d436043b5a66abd3141389849df5	automating performance bottleneck detection using search-based application profiling	application profiling;performance bottlenecks	Application profiling is an important performance analysis technique, when an application under test is analyzed dynamically to determine its space and time complexities and the usage of its instructions. A big and important challenge is to profile nontrivial web applications with large numbers of combinations of their input parameter values. Identifying and understanding particular subsets of inputs leading to performance bottlenecks is mostly manual, intellectually intensive and laborious procedure. We propose a novel approach for automating performance bottleneck detection using search-based input-sensitive application profiling. Our key idea is to use a genetic algorithm as a search heuristic for obtaining combinations of input parameter values that maximizes a fitness function that represents the elapsed execution time of the application. We implemented our approach, coined as Genetic Algorithm-driven Profiler (GA-Prof) that combines a search-based heuristic with contrast data mining of execution traces to accurately determine performance bottlenecks. We evaluated GA-Prof to determine how effectively and efficiently it can detect injected performance bottlenecks into three popular open source web applications. Our results demonstrate that GA-Prof efficiently explores a large space of input value combinations while automatically and accurately detecting performance bottlenecks, thus suggesting that it is effective for automatic profiling.	bottleneck (software);data mining;fitness function;genetic algorithm;heuristic;intellect;open-source software;parameter (computer programming);run time (program lifecycle phase);search-based application;sensor;software release life cycle;system under test;tracing (software);web application	Du Shen;Qi Luo;Denys Poshyvanyk;Mark Grechanik	2015		10.1145/2771783.2771816	real-time computing;computer science;theoretical computer science;data mining	SE	-17.465765943398864	37.72246723732864	95261
87f7350257e0a3758b0561e1c5c58d9014375040	the effectiveness of multiple hardware contexts	parallelisme;optimisation;optimizacion;execution time;multiprocessor;multiprocessing;branch prediction;data locality;simulation;simulacion;ejecucion programa;profile based optimization;program execution;branch target buffers;parallelism;paralelismo;trace scheduling;execution programme;long memory;multitraitement;temps execution;context dependent;optimization;procesador;processeur;multiprocesador;tiempo ejecucion;processor;multiprocesseur;multitratamiento	Multithreaded processors are used to tolerate long memory latencies. By executing threads loaded in multiple hardware contexts, an otherwise idle processor can keep busy, thus increasing its utilization. However, the larger size of a multi-thread working set can have a negative effect on cache conflict misses. In this paper we evaluate the two phenomena together, examining their combined effect on execution time. The usefulness of multiple hardware contexts depends on: program data locality, cache organization and degree of multiprocessing. Multiple hardware contexts are most effective on programs that have been optimized for data locality. For these programs, execution time dropped with increasing contexts, over widely varying architectures. With unoptimized applications, multiple contexts had limited value. The best performance was seen with only two contexts, and only on uniprocessors and small multiprocessors. The behavior of the unoptimized applications changed more noticeably with variations in cache associativity and cache hierarchy, unlike the optimized programs. As a mechanism for exploiting program parallelism, an additional processor is clearly better than another context. However, there were many configurations for which the addition of a few hardware contexts brought as much or greater performance than a larger multiprocessor with fewer than the optimal number of contexts.	cpu cache;cache (computing);central processing unit;locality of reference;multiprocessing;parallel computing;run time (program lifecycle phase);thread (computing);uniprocessor system;working set	Radhika Thekkath;Susan J. Eggers	1994		10.1145/195473.195583	computer architecture;parallel computing;real-time computing;multiprocessing;computer science;operating system;programming language	Arch	-15.779524903149644	44.5065830930747	95474
281e6f8c23a8d1cc733acbc9fe20a6523a604224	development of openmp parallelization in tim code		This article describes development of OpenMP parallelization in True Irregular Method (TIM) code designed for solving multidimensional non-stationary problems of continuum mechanics using non-structured Lagrangian meshes of random form.	augmented lagrangian method;automatic parallelization;openmp;parallel computing;stationary process;triune continuum paradigm	F. O. Golomidov;A. A. Voropinov;I. G. Novikov	2017	2017 International Conference on High Performance Computing & Simulation (HPCS)	10.1109/HPCS.2017.141	parallel computing;theoretical computer science;multi-core processor;polygon mesh;instruction set;automatic parallelization;continuum mechanics;computational science;computer science;lagrangian	HPC	-6.55784311506101	38.14371873340274	95530
9e048036559c9ac573361d25b2ef115a557cbc27	dynamic task scheduling for the uintah framework	task graph approach;directed acyclic graph;automatic message generation;queuing architecture dynamic task scheduling fluid structure interaction fluid flow algorithm adaptive mesh refinement mpm particle methods uintah domain decomposition task graph approach asynchronous communication automatic message generation distributed directed acyclic graph task memory data warehouse;fluid structure interaction;domain decomposition;adaptive mesh refinement;processor scheduling;task memory;data flow graphs;queueing theory;fluid flow;runtime;out of order;particle method;large scale;computational modeling;mpm particle methods;distributed directed acyclic graph;fluid flow algorithm;asynchronous communication;task analysis;queuing architecture;mathematical model;runtime system;task graphs;task scheduling;program processors computational modeling data warehouses processor scheduling load modeling mathematical model runtime;data warehouses;data warehouse;load modeling;task analysis data flow graphs data warehouses queueing theory;program processors;uintah;dynamic task scheduling	Uintah is a computational framework for fluid-structure interaction problems using a combination of the ICE fluid flow algorithm, adaptive mesh refinement (AMR) and MPM particle methods. Uintah uses domain decomposition with a task-graph approach for asynchronous communication and automatic message generation. The Uintah software has been used for a decade with its original task scheduler that ran computational tasks in a predefined static order. In order to improve the performance of Uintah for petascale architecture, a new dynamic task scheduler allowing better overlapping of the communication and computation is designed and evaluated in this study. The new scheduler supports asynchronous, out-of-order scheduling of computational tasks by putting them in a distributed directed acyclic graph (DAG) and by isolating task memory and keeping multiple copies of task variables in a data warehouse when necessary. A new runtime system has been implemented with a two-stage priority queuing architecture to improve the scheduling efficiency. The effectiveness of this new approach is shown through an analysis of the performance of the software on large scale fluid-structure examples.	adaptive multi-rate audio codec;adaptive mesh refinement;algorithm;central processing unit;code;computation;computational fluid dynamics;directed acyclic graph;domain decomposition methods;gadget (computer science);graphics processing unit;load balancing (computing);material point method;maximum flow problem;message passing interface;multi-core processor;overhead (computing);parallel computing;petascale computing;priority queue;refinement (computing);run time (program lifecycle phase);runtime system;scheduling (computing);thread (computing);windows task scheduler	Qingyu Meng;Justin Luitjens;Martin Berzins	2010	2010 3rd Workshop on Many-Task Computing on Grids and Supercomputers	10.1109/MTAGS.2010.5699431	parallel computing;real-time computing;adaptive mesh refinement;computer science;out-of-order execution;operating system;data warehouse;asynchronous communication;mathematical model;task analysis;database;distributed computing;domain decomposition methods;queueing theory;computational model;directed acyclic graph	HPC	-6.200882665834553	41.68079554984615	95699
546ab483b07ae8d68a8c6295042d01397c6637de	a multiprocessing system for the direct execution of lisp	text;computer architecture;real time garbage collection;data flow;engineering electronics and electrical	Current implementations were found to be impractical for airborne use due to LISP's incompatability with conventional computer architectures. Direct execution of LISP with tasks distributed between three processors, seemed to be a workable solution. The language was analyzed, and a special token was devised, using a descriptor with a single pointer. Through careful distribution of responsibilities, control and data flow between the processors was minimized. Significant memory savings resulted from ASCII storage and real time garbage collection. A simulation was used to help estimate execution times and showed a factor of 50 to 100 increase in speed. Thus, through the direct execution of LISP by a multiprocessing system, Computer-Aided Decision-Making could be implimented to enhance the safety of flight operations.	airborne ranger;central processing unit;computer architecture;dataflow;garbage collection (computer science);multiprocessing;pointer (computer programming);simulation	Rhon Williams	1978		10.1145/800128.804165	manual memory management;data flow diagram;computer architecture;parallel computing;real-time computing;computer science;operating system;garbage collection;programming language	Arch	-16.511694958778126	39.09673880311458	95826
8b97bf1ca9b9d49c4e4fc89e26a1eb68c2af03ec	declarative language design for interactive visualization	object oriented language;declarative language design;event handling;programming language;user interface;parallelized execution;interactive visualization;unobtrusive optimization;data visualization rendering computer graphics optimization visualization java animation indexes;user interface toolkit;information visualization;hardware accelerator;object oriented programming;indexing terms;specification language;data model;mobile phone;data visualisation;indexes;visualization;visualization specification;object oriented;specification languages;declarative languages;animation;data visualization;hardware accelerated rendering;domain specific language;optimization;rendering computer graphics;specification languages data visualisation interactive programming java object oriented programming rendering computer graphics;statically typed programming language;user interfaces;animated transition;interactive programming;optimization information visualization user interfaces toolkits domain specific languages declarative languages;declarative domain specific language;protovis specification language;hardware accelerated rendering declarative language design interactive visualization declarative domain specific language unobtrusive optimization protovis specification language statically typed programming language object oriented language java animated transition event handling runtime compilation visualization specification parallelized execution;domain specific languages;runtime compilation;java;toolkits	We investigate the design of declarative, domain-specific languages for constructing interactive visualizations. By separating specification from execution, declarative languages can simplify development, enable unobtrusive optimization, and support retargeting across platforms. We describe the design of the Protovis specification language and its implementation within an object-oriented, statically-typed programming language (Java). We demonstrate how to support rich visualizations without requiring a toolkit-specific data model and extend Protovis to enable declarative specification of animated transitions. To support cross-platform deployment, we introduce rendering and event-handling infrastructures decoupled from the runtime platform, letting designers retarget visualization specifications (e.g., from desktop to mobile phone) with reduced effort. We also explore optimizations such as runtime compilation of visualization specifications, parallelized execution, and hardware-accelerated rendering. We present benchmark studies measuring the performance gains provided by these optimizations and compare performance to existing Java-based visualization tools, demonstrating scalability improvements exceeding an order of magnitude.	animation;benchmark (computing);compiler;data model;declarative programming;deploy;desktop computer;discretization;domain-specific language;dynamic compilation;event (computing);execution;graphics processing unit;hl7publishingsubsection <operations>;handling (psychology);hardware acceleration;imagery;interactive visualization;interpolation;java programming language;language model;large;mathematical optimization;mobile phone;overhead (computing);parallel computing;phase ii/iii trial;prefuse;protovis;retargeting;scalability;shading;specification language;thread (computing);type system;benefit	Jeffrey Heer;Michael Bostock	2010	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2010.144	computer science;theoretical computer science;database;programming language;object-oriented programming;user interface;data visualization	Visualization	-12.898422544730918	35.801414087058596	95834
97cb09d597cfaa469351df4ff79928d7ab1d460d	mesh-tensorflow: deep learning for supercomputers		"""Batch-splitting (data-parallelism) is the dominant distributed Deep Neural Network (DNN) training strategy, due to its universal applicability and its amenability to Single-Program-Multiple-Data (SPMD) programming. However, batch-splitting suffers from problems including the inability to train very large models (due to memory constraints), high latency, and inefficiency at small batch sizes. All of these can be solved by more general distribution strategies (model-parallelism). Unfortunately, efficient model-parallel algorithms tend to be complicated to discover, describe, and to implement, particularly on large clusters. We introduce Mesh-TensorFlow, a language for specifying a general class of distributed tensor computations. Where data-parallelism can be viewed as splitting tensors and operations along the """"batch"""" dimension, in Mesh-TensorFlow, the user can specify any tensor-dimensions to be split across any dimensions of a multi-dimensional mesh of processors. A Mesh-TensorFlow graph compiles into a SPMD program consisting of parallel operations coupled with collective communication primitives such as Allreduce. We use Mesh-TensorFlow to implement an efficient data-parallel, modelparallel version of the Transformer [Vas+17] sequence-to-sequence model. Using TPU meshes of up to 512 cores, we train Transformer models with up to 5 billion parameters, surpassing SOTA results on WMT’14 English-to-French translation task and the one-billion-word Language modeling benchmark. Mesh-Tensorflow is available at https://github.com/tensorflow/mesh ."""	benchmark (computing);central processing unit;computation;dec text processing utility;data parallelism;deep learning;language model;parallel algorithm;parallel computing;spmd;supercomputer;tensorflow;transformer	Noam Shazeer;Yonglong Cheng;Niki Parmar;Dustin Tran;Ashish Vaswani;Penporn Koanantakool;Peter Hawkins;HyoukJoong Lee;Mingsheng Hong;Cliff Young;Ryan Sepassi;Blake A. Hechtman	2018			tensor;machine learning;computer science;artificial intelligence;language model;latency (engineering);artificial neural network;computation;spmd;deep learning;polygon mesh;distributed computing	HPC	-4.6538843808814025	42.10014476882991	95917
bcc64b43b9e713ee94d459f527937d923d80c11a	recent advances on gpu computing in operations research	parallel computing;paper;gpu computing;parallel processing graphics processing units integer programming linear programming operations research;linear programming gpu computing operations research graphics processing units high performance computing applications highly threaded parallel computing processors integer programming;operations research;parallel computing gpu computing operations research integer programming linear programming;integer programming;graphics processing units;linear programming;graphics processing units linear programming instruction sets computer architecture programming dynamic programming;computer science;review;parallel processing	In the last decade, Graphics Processing Units(GPUs) have gained an increasing popularity as accelerators for High Performance Computing (HPC) applications. Recent GPUs are not only powerful graphics engines but also highly threaded parallel computing processors that can achieve sustainable speedup as compared with CPUs. In this context, researchers try to exploit the capability of this architecture to solve difficult problems in many domains in science and engineering. In this article, we present recent advances on GPU Computing in Operations Research. We focus in particular on Integer Programming and Linear Programming.	algorithm;c++;cuda;central processing unit;code;compiler;double-precision floating-point format;flops;fortran;general-purpose computing on graphics processing units;graphics processing unit;heuristic;high memory;high- and low-level;integer programming;kepler (microarchitecture);linear programming;memory bandwidth;openacc;opencl api;openmp;operations research;parallel computing;programmer;programming tool;single-precision floating-point format;speedup	Vincent Boyer;Didier El Baz	2013	2013 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum	10.1109/IPDPSW.2013.45	computer architecture;parallel computing;stream processing;reactive programming;functional reactive programming;computer science;theoretical computer science;extensible programming;end-user computing;data-intensive computing;procedural programming;algorithmic skeleton;inductive programming;general-purpose computing on graphics processing units;unconventional computing	HPC	-7.616449966376649	42.80648769063539	96033
00ec3d2274b2e558a63964a1fc4f10d8369cfca2	a taxonomy of computer-based simulations and its mapping to parallel and distributed systems simulation tools	parallel and distributed system;distributed system;design principle;design and development;simulation tools;complex system;parallel systems;taxonomy;parallel system;simulation tool	In recent years, extensive research has been conducted in the area of simulation to model large complex systems and understand their behavior, especially in parallel and distributed systems. At the same time, a variety of design principles and approaches for computer-based simulation have evolved. As a result, an increasing number of simulation tools have been designed and developed. Therefore, the aim of this paper is to develop a comprehensive taxonomy for design of computer-based simulations, and apply this taxonomy to categorize and analyze various simulation tools for parallel and distributed systems. Copyright c © 2004 John Wiley & Sons, Ltd.	categorization;complex systems;distributed computing;john d. wiley;systems simulation;taxonomy (general)	Anthony Sulistio;Chee Shin Yeo;Rajkumar Buyya	2004	Softw., Pract. Exper.	10.1002/spe.585	computational science;computer science;theoretical computer science;distributed computing;distributed design patterns;taxonomy	HPC	-13.309208202081818	41.94216913790899	96077
e763b7c4ecb5a9197855b7d824061a77dbb4d0c8	tuning mpi runtime parameter setting for high performance computing	statistical analysis application program interfaces message passing optimisation parallel architectures parallel machines;optimisation;anova mpi runtime parameter tuning;anova;parallel architectures;statistical analysis;tuning runtime computer architecture kernel libraries performance gain computers;application program interfaces;message passing;spec mpi 2007 benchmark suite mpi runtime parameter setting tuning high performance computing parallel computers input programs optimized programs analysis of variance anova optimization space computational kernels hpc open mpi library parallel architectures;parallel machines;mpi;runtime parameter tuning	The performance of MPI applications on parallel computers can be considerably improved by tuning the runtime parameters provided by modern MPI libraries. However, due to the large and increasing number of tunable parameters, finding a parameter setting which optimizes the execution of several user programs on a chosen target machine is challenging. Existing tools execute input programs multiple times with varying parameter settings until a satisfying performance is reached. Several hundred runs of the input programs are nevertheless needed making this approach appealing only when the cost of the tuning phase can be amortized over many runs of the optimized programs. In this paper, we introduce a novel technique for tuning MPI runtime parameter values to better suit the underlying system architecture. The MPI parameter values are determined by performing the analysis of variance (ANOVA) on experimental data collected by randomly exploring the optimization space of a set of computational kernels commonly employed in High Performance Computing (HPC). We use our new technique to derive optimized values for 27 runtime parameters of the Open MPI library for two different parallel architectures. Results show an average performance improvement up to 20% for codes from the SPEC MPI 2007 benchmark suite with respect to Open MPI's default parameter setting.	amortized analysis;benchmark (computing);best, worst and average case;code;computer;experiment;iterative method;library (computing);mathematical optimization;message passing interface;nas parallel benchmarks;open mpi;parallel computing;randomness;runtime system;specfp;spec#;supercomputer;systems architecture	Simone Pellegrini;Radu Prodan;Thomas Fahringer	2012	2012 IEEE International Conference on Cluster Computing Workshops	10.1109/ClusterW.2012.15	parallel computing;message passing;analysis of variance;computer science;message passing interface;theoretical computer science;operating system;distributed computing;statistics	HPC	-5.512736838745809	45.29359151385949	96212
a81a3bcba41a9ec7ddc7d2ded0ddf255e60c9f98	parallel implementations of block-based motion vector estimation for video compression on four parallel processing systems	parallelisme;distributed memory;simd;algoritmo paralelo;software tool;estimation mouvement;parallel algorithm;ordinateur parallele;memoria compartida;estimacion movimiento;mode mixte;video compression;distributed memory machine;technique video;video processing;motion estimation;calculateur simd;vecteur;tecnica video;data partitioning;algorithme parallele;parallelism;calculateur mimd;paralelismo;mimd;simd computer;motion vector;ordenador paralelo;parallel computer;mixed mode;video technique;parallel machines;vector;parallel implementation;mixed mode parallelism;memoire repartie;motion vector estimation;large classes;parallel processing;mimd computer;exhaustive search;timing	Parallel algorithms, based on a distributed memory machine model, for an exhaustive search technique for motion vector estimation in video compression are being designed and evaluated. Results from the execution on a 16,384 processor MasPar MP-1 (an SIMD machine), a 140 node Intel Paragon XP/S and a 16 node IBM SP2 (two M IMD machines), and the 16 processor PASM prototype (a partitionable SIMD/MIMD mixed-mode machine) are presented. The trade-offs of using different modes of parallelism (SIMD, SPMD, and mixed-mode) and different data partitioning schemes (the rectangular and stripe subimage methods) are examined. The analytical and experimental results shown in this application study will help practitioners to predict and contrast the performance of different approaches to parallel implementation of this important video compression technique. The results presented are also applicable to a large class of image and video processing tasks. Case studies, such as the one presented here, are a necessary step in developing software tools for mapping an application task onto a single parallel machine and for mapping a set of independent application tasks, or the subtasks of a single application task, onto a heterogeneous suite of parallel machines.	brute-force search;data compression;data striping;distributed memory;experiment;image;intel paragon;mimd;maspar;mixed-signal integrated circuit;parallel algorithm;parallel computing;parallel processing (dsp implementation);prototype;simd;spmd;usc interactive media & games division;video processing	Min Tan;Janet M. Siegel;Howard Jay Siegel	1999	International Journal of Parallel Programming	10.1023/A:1018785512609	data compression;parallel processing;computer architecture;parallel computing;real-time computing;distributed memory;simd;mimd;vector;computer science;operating system;motion estimation;brute-force search;parallel algorithm;video processing	HPC	-8.860870326628323	41.520029673646484	96273
40274cb56956af6738ca1b6e62adba5151c9227a	the solution of radiation engineering problems on a transputer-based system	computer science and informatics	Monte Carlo and finite element methods are numerical techniques used for solving complex problems in reactor physics and radiation shielding. In this paper we are concerned with the implementation of existing research-level codes based on these two methods, written originally for serial computers, on an MIMD transputer-based system. Results and performanse of the parallelized codes are presented.	code;finite element method;mimd;monte carlo method;numerical analysis;parallel computing;reactor (software);serial computer;transputer	S. A. Khaddaj;H. Al-Bahadili;Anthony J. H. Goddard;C. R. E. de Oliveira;J. Wood	1991	Concurrency - Practice and Experience	10.1002/cpe.4330030418	computational science;engineering informatics;computer science;informatics engineering;information and computer science	HPC	-7.183858558092533	37.36424754918655	96446
3f4b55f9ff461a1eb863537e6911368c223215f9	comparing shared and distributed memory computers	distributed memory	There are two distinct types of MIMD (Multiple Instruction, Multiple Data) computers: the shared memory machine, e.g. Butterfly, and the distributed memory machine, e.g. Hypercubes, Transputer arrays. Typically these utilize different programming models: the shared memory machine has monitors, semaphores and fetch-and-add; whereas the distributed memory machine uses message passing. Moreover there are two popular types of operating systems: a multi-tasking, asynchronous operating system and a crystalline, loosely synchronous operating system.#R##N##R##N#In this paper I firstly describe the Butterfly, Hypercube and Transputer array MIMD computers, and review monitors, semaphores, fetch-and-add and message passing; then I explain the two types of operating systems and give examples of how they are implemented on these MIMD computers. Next I discuss the advantages and disadvantages of shared memory machines with monitors, semaphores and fetch-and-add, compared to distributed memory machines using message passing, answering questions such as “is one model ‘easier’ to program than the other?” and “which is ‘more efficient‘?”. One may think that a shared memory machine with monitors, semaphores and fetch-and-add is simpler to program and runs faster than a distributed memory machine using message passing but we shall see that this is not necessarily the case. Finally I briefly discuss which type of operating system to use and on which type of computer. This of course depends on the algorithm one wishes to compute.	computer;distributed memory	Clive F. Baillie	1988	Parallel Computing	10.1016/0167-8191(88)90113-5	uniform memory access;distributed shared memory;shared memory;parallel computing;real-time computing;distributed memory;mimd;computer science;operating system;distributed computing;overlay;conventional memory;extended memory;flat memory model;programming language;data diffusion machine;memory map;memory management	HPC	-12.492772756802536	44.72068490325822	96518
fb3617bae380e97f7d565cf372bedc24c62d0e72	process groups: a mechanism for the coordination of and communication among processes in the venus collective communication library	debugging;distributed memory systems;concurrent computing;multiprocessing programs;application software;collective communication;run time libraries;venus;n body problem;distributed computing;venus run time communication library;abstraction;parallel programming;venus collective communication library;runtime library;programming massively parallel computers;process groups;monitoring;massively parallel computer;data structures;object oriented approach;message passing;n body problems;data structures message passing process groups venus collective communication library programming massively parallel computers run time libraries venus run time communication library abstraction object oriented approach debugging monitoring n body problems;parallel programming data structures distributed memory systems message passing multiprocessing programs;venus concurrent computing runtime library parallel programming distributed computing monitoring application software debugging data structures buildings;data structure;buildings	In programming massively parallel computers, it is often necessary to have sets of processes cooperate in performing certain computations and communications. Most run-time libraries require that such sets of processes be explicitly specified in the program. In the Venus run-time communication library however, a Process Group abstraction is used to enable implicit coordination of and communication over dynamically determined sets of processes. The Process Groups mechanism in Venus offers an object-oriented approach for handling sets of processes and enhances the debugging and monitoring of programs. The authors describe the Process Groups mechanism in Venus, illustrate its use on the class of N-body problems, and outline some of the data structures and algorithms used to implement this mechanism in Venus. >		Vasanth Bala;Shlomo Kipnis	1993		10.1109/IPPS.1993.262809	parallel computing;computer science;theoretical computer science;distributed computing	HPC	-12.636388455077846	38.64461926244278	96759
17f6da4acb74aa4fe1ce3cde800a5c3f9bf9de1d	self-adapting linear algebra algorithms and software	production performance;linear algebra;linear systems;iterative method;metodo adaptativo;optimisation;mathematics computing;optimizacion;software libraries;programacion automatica;matrix vector product;program design;dense kernels;conception programme;methode adaptative;automatic programming;linear system;linear solver algorithms;preconditioners;matrix matrix product;high performance kernels;proof of concept;sparse kernels adaptive methods basic linear algebra subprograms blas dense kernels iterative methods linear systems matrix matrix product matrix vector product performance optimization preconditioners;metodo iterativo;iterative methods;self adapting linear algebra algorithms;sparse kernels;methode iterative;algebre lineaire;adaptive method;adaptive methods;basic linear algebra subprograms;algebra lineal;optimization;software libraries mathematics computing linear algebra operating system kernels software packages;operating system kernels;bibliotheque logiciel;iteration method;software libraries self adapting linear algebra algorithms self adapting linear algebra software high performance kernels blas basic linear algebra subprograms linear solver algorithms software packages;high performance;performance optimization;blas;concepcion programa;software packages;basic linear algebra subprograms blas;programmation automatique;linear algebra software algorithms kernel computer architecture hardware computer science software libraries laboratories iterative algorithms sparse matrices;self adapting linear algebra software	One of the main obstacles to the efficient solution of scientific problems is the problem of tuning software, both to the available architecture and to the user problem at hand. We describe approaches for obtaining tuned high-performance kernels and for automatically choosing suitable algorithms. Specifically, we describe the generation of dense and sparse Basic Linear Algebra Subprograms (BLAS) kernels, and the selection of linear solver algorithms. However, the ideas presented here extend beyond these areas, which can be considered proof of concept.	atlas;algorithm;automatic programming;blas;code generation (compiler);compiler;computer scientist;data modeling;library (computing);mathematical optimization;numerical linear algebra;programming language;reference implementation;salsa;solver;sparse matrix;subroutine	Richard Carl Demmel;Jack J. Dongarra;Victor Eijkhout;Erika Fuentes;Antoine Petitet;Richard W. Vuduc;R. Clint Whaley;Katherine A. Yelick	2005	Proceedings of the IEEE	10.1109/JPROC.2004.840848	computational science;parallel computing;computer science;theoretical computer science;linear algebra;basic linear algebra subprograms;iterative method	HPC	-9.516277578707614	35.7812297157281	96865
3a5a1d6ad2da9c174b6eba958fd811c71e8bf18d	massively parallel simulations of relativistic fluid dynamics on graphics processing units with cuda	parallel computing;computational physics;viscosity;nuclear theory;numerical calculations;paper;relativistic fluid dynamics;performance;gpu;quark gluon plasma;nvidia geforce gtx titan z;nvidia geforce gtx 560 m;high energy physics phenomenology;cuda;physics;flow gubser;numerical methods;multiprocessor graphics;fluid relativistic;nvidia;algorithms;fluid dynamics;boundary condition fluctuation;intel xeon phi;programming;nvidia geforce gtx 980 ti;hydrodynamics	Relativistic fluid dynamics is a major component in dynamical simulations of the quark–gluon plasma created in relativistic heavy-ion collisions. Simulations of the full three-dimensional dissipative dynamics of the quark–gluon plasma with fluctuating initial conditions are computationally expensive and typically require some degree of parallelization. In this paper, we present a GPU implementation of the Kurganov–Tadmor algorithm which solves the 3 + 1d relativistic viscous hydrodynamics equations including the effects of both bulk and shear viscosities. We demonstrate that the resulting CUDA-based GPU code is approximately two orders of magnitude faster than the corresponding serial implementation of the Kurganov–Tadmor algorithm. We validate the code using (semi-)analytic tests such as the relativistic shock-tube and Gubser flow.#R##N#Program summary#R##N#Manuscript Title: Massively parallel simulations of relativistic fluid dynamics on graphics processing units with CUDA#R##N##R##N#Authors: Dennis Bazow, Ulrich Heinz, Michael Strickland#R##N##R##N#Program Title: GPU-VH#R##N##R##N#Journal Reference:#R##N##R##N#Catalogue identifier:#R##N##R##N#Licensing provisions: none#R##N##R##N#Programming language: CUDA C#R##N##R##N#Computer: Any machine with an Nvidia graphics processing unit#R##N##R##N#Operating system: GNU/Linux distributions#R##N##R##N#Global memory usage: 0.5 GB (for a 1283 grid)#R##N##R##N#Keywords: Relativistic fluid dynamics, Quark-gluon plasma, GPU, CUDA, Parallel computing#R##N##R##N#Classification: 12 Gases and Fluids, 17 Nuclear Physics#R##N##R##N#External routines/libraries: Google Test, GNU Scientific Library (GSL)#R##N##R##N#Nature of problem: Dynamical evolution of the fluid dynamic stage of the quark–gluon plasma produced in nuclear collisions.#R##N##R##N#Solution method: Kurganov–Tadmor algorithm#R##N##R##N#Running time: Typical running time on an Nvidia GeForce GTX 980 Ti graphics card for fluid dynamic simulations that includes a nonconformal equation of state with bulk and shear viscosities on a 1283 grid is 38.4 sec/time step.	cuda;computer graphics;graphics processing unit;simulation	Dennis Bazow;Ulrich Heinz;Michael Strickland	2018	Computer Physics Communications	10.1016/j.cpc.2017.01.015	computational science;programming;parallel computing;viscosity;performance;numerical analysis;computer science;theoretical computer science;atomic theory;quark–gluon plasma;xeon phi;general-purpose computing on graphics processing units;physics;quantum mechanics;fluid dynamics	Graphics	-5.313497576467761	36.09963461208401	96914
0a33feb3215d239d81fe7129bd02089626a00399	parse: simulation of message passing communication networks	multiprocessor interconnection networks;distributed memory;cost effective communication hardware;message passing distributed memory systems;message passing communication networks object oriented modeling hardware computer architecture parallel architectures costs performance analysis computational modeling condition monitoring;distributed memory systems;communication architectures;communication networks;simulation framework;message passing communication network simulation;object oriented programming;object oriented implementation message passing communication network simulation parse communication network hardware message passing distributed memory systems performance requirements parallel system hardware implementation costs cost effective communication hardware parallel architecture simulation communication architectures analytic communication models;communication model;multiprocessor interconnection networks message passing distributed memory systems object oriented programming parallel architectures virtual machines;computer architecture;computational modeling;parallel architectures;condition monitoring;virtual machines;community networks;parallel systems;object oriented;communication network hardware;performance analysis;parse;message passing;parallel architecture simulation;cost effectiveness;parallel system;parallel architecture;hardware implementation costs;object oriented implementation;performance requirements;hardware implementation;analytic communication models;object oriented modeling;hardware	The number of design decisions for communication network hardware in message passing distributedmemory systems is quite large, as illustrated by many different implemented and proposed designs. Many of the decisions are driven by, on one side, performance requirements of targeted applications for the parallel system, and on the other side, hardware implementation costs. To obtain cost effective communication hardware matching a certain application domain, use of a parallel architecture simulation framework is inevitable. The simulator presented here, named PARSE, offers a base for such a framework. It can accurately simulate a wide range of communication architectures and, unlike analytic communication models, does properly model all performance aspects. Changing parameters of simulated architectures is very flexible and the object oriented implementation of the simulator facilitates future extensions and enhancements.	application domain;computer architecture;henk g. sol;hotspot (wi-fi);message passing;networking hardware;parallel computing;parsing;requirement;simulation;telecommunications network	J. G. E. Olk	1994		10.1109/SIMSYM.1994.283106	computer architecture;parallel computing;computer science;distributed computing	Arch	-10.856636685726954	40.55595738475674	97009
4d94ec108a6d2f74a8f195fb44f3a4a4384f699f	cellular automaton belousov-zhabotinsky model for binary full adder		The continuous increment in the performance of classical computers has been driven to its limit. New ways are studied to avoid this oncoming bottleneck and many answers can be found. An example is the Belousov–Zhabotinsky (BZ) reaction which includes some fundamental and essential characteristics that attract chemists, biologists, and computer scientists. Interaction of excitation wave-fronts in BZ system, can be interpreted in terms of logical gates and applied in the design of unconventional hardware components. Logic gates and other more complicated components have been already proposed using different topologies and particular characteristics. In this study, the inherent parallelism and simplicity of Cellular Automata (CAs) modeling is combined with an Oregonator model of light-sensitive version of BZ reaction. The resulting parallel and computationally-inexpensive model has the ability to simulate a topology that can be considered as a one-bit full adder digital component towards the design of an Arithmetic Logic Unit (ALU).	and gate;adder (electronics);andrew adamatzky;arithmetic logic unit;belousov–zhabotinsky reaction;bottleneck (software);cellular automaton;computer scientist;digital electronics;discretization;excitable medium;exclusive or;experiment;field-programmable gate array;graphics processing unit;logic gate;parallel computing;simulation	Nikolaos I. Dourvas;Georgios Ch. Sirakoulis;Andrew Adamatzky	2017	I. J. Bifurcation and Chaos	10.1142/S0218127417500894	theoretical computer science;network topology;arithmetic logic unit;logic gate;unconventional computing;cellular automaton;binary number;adder;belousov–zhabotinsky reaction;computer science	EDA	-5.486577045177091	34.87049114211408	97580
29247a0966edae7b022733d9194608bd09076d62	parallel applications of a schwarz preconditioned krylov solver for nuclear power plant simulation.	nuclear power plant;parallel applications			John Steill;Thomas J. Downar;Jen-Ying Wu	1997			computational science;mathematical optimization;parallel computing	EDA	-7.029459392948155	37.94229655091771	97628
22939aa1f799a472ff186569f8b9bd60473cbcc1	looking back at dense linear algebra software	dense linear algebra;decompositional approach;parallel algorithms	Over the years, computational physics and chemistry served as an ongoing source of problems that demanded the ever increasing performance from hardware as well as the software that ran on top of it. Most of these problems could be translated into solutions for systems of linear equations: the very topic of numerical linear algebra. Seemingly then, a set of efficient linear solvers could be solving important scientific problems for years to come. We argue that dramatic changes in hardware designs precipitated by the shifting nature of the marketplace of computer hardware had a continuous effect on the software for numerical linear algebra. The extraction of high percentages of peak performance continues to require adaptation of software. If the past history of this adaptive nature of linear algebra software is any guide then the future theme will feature changes as well – changes aimed at harnessing the incredible advances of the evolving hardware infrastructure.	computational physics;computer hardware;linear equation;numerical analysis;numerical linear algebra;system of linear equations	Piotr Luszczek;Jakub Kurzak;Jack J. Dongarra	2014	J. Parallel Distrib. Comput.	10.1016/j.jpdc.2013.10.005	mathematical optimization;combinatorics;parallel computing;computer science;theoretical computer science;operating system;mathematics;distributed computing;parallel algorithm;numerical linear algebra;programming language;algorithm;statistics	HPC	-7.551571058102701	40.15348433544232	97634
7b32b8470f74ff5eb9fc1d6bbc572e010a8a91cf	parallel algorithm design for remote sensing image processing in the pc cluster environment	remote sensing image;geophysical image processing;pc cluster environment;multi threading;parallel algorithm;image processing;image radiation;parallel algorithm design;charge coupled devices;remote sensing application program interfaces geophysical image processing multiprocessing systems multi threading parallel algorithms;multithread processing algorithm;remote sensing image processing algorithm design and analysis data models parallel algorithms message passing;remote sensing image processing;remote sensing;application program interfaces;design pattern;openmp library;pc cluster;message passing;openmp;multicore cpu;mpi;pc cluster environment parallel algorithm remote sensing image processing mpi openmp;charge coupled devices parallel algorithm design remote sensing image processing pc cluster environment mpi interface multithread processing algorithm openmp library multicore cpu image radiation four band hj 1a ccd;multiprocessing systems;mpi interface;algorithm design and analysis;four band hj 1a ccd;data models;parallel algorithms	In the PC cluster environment, parallel algorithms can significantly improve the efficiency of remote sensing image processing. The remote sensing dataset is the raster data stored by order of band, therefore, it is feasible to assign executable tasks to some computing nodes by band and complete the processing tasks together through communicating each other amount the computing nodes by MPI interface. In addition, the multi-thread processing algorithm is scheduled based on OpenMP library toward the single computing node with multi-core CPU. The experiment evaluates image radiation performance about the four-band HJ-1A CCD remote sensing image in the PC cluster environment which consists of 4 sets of dual-core computers. Its performance is increased by 6 times to 6.5 times comparing with a single PC. Through validating, the dual level design pattern is available based on integrating MPI and OpenMP to improve the efficiency of remote sensing image processing.	algorithm design;central processing unit;charge-coupled device;computer cluster;executable;image processing;level design;message passing interface;multi-core processor;openmp;parallel algorithm;personal computer;raster data;software design pattern	Hongping Wang;Juan Zhang;Xiuguo Liu;Xiaodong Huang	2010	2010 18th International Conference on Geoinformatics	10.1109/GEOINFORMATICS.2010.5567904	parallel computing;computer science;operating system;distributed computing	HPC	-6.603587595021386	41.62382271915116	97728
68e1f5770453d477547b7ef16cb6e7b9bd96943f	evaluating the performance of mpi-2 dynamic communicators and one-sided communication	parallelisme;communicating process;proceso comunicante;parallelism;paralelismo;envoi message;processus communicant;message passing	This paper evaluates the performance of several MPI implementations regarding two chapters of the MPI-2 specification. First, we analyze, whether the performance using dynamically created communicators is comparable to the approach presented in MPI-1 using a static communicator for different MPI libraries. We than evaluate, whether the communication performance of one-sided communication on current machines, represents a benefit or a drawback to the end-user compared to the more conventional two-sided communication.	fastest;library (computing);mathematical optimization;message passing interface	Edgar Gabriel;Graham E. Fagg;Jack J. Dongarra	2003		10.1007/978-3-540-39924-7_16	parallel computing;message passing;real-time computing;computer science;distributed computing;programming language	HPC	-16.537719099430515	42.45690464772483	97783
412afad768850305bf81dcfb7e6ccbac6bf3cb83	a dendritic cell-mediated framework for optimal resources scheduling and planning	pg_thesis		cell (microprocessor);scheduling (computing)	Man-ying Nicole Lee	2015			parallel computing;real-time computing;computer science;operations management	Robotics	-9.393740356849014	43.408054180748685	97888
e26f362e4d2bb72004c153527629faa76302790e	goldilocks and the three bears confront the future of supercomputing	bears confront;automatic parallelization;grain size		supercomputer	Robert Borchers;Tom Anderson;Burton J. Smith;Steven J. Wallach	1995		10.1109/SUPERC.1995.99	computer architecture;parallel computing;real-time computing;computer science;grain size;automatic parallelization	HPC	-8.34030592072522	40.056755408986625	97988
a5c5a43ce36064bd01ca864f21e87c3108b78450	poster: evaluation topology mapping via graph partitioning	topology;fft;graph partitioning;load balancing;communication	Intelligently mapping applications to machine network topologies has been shown to improve performance, but considerable developer effort is required to find good mappings. Techniques from graph partitioning have the potential to automate topology mapping and relieve the developer burden. Graph partitioning is already used for load balancing parallel applications, but can be applied to topology mapping as well. We show performance gains by using a topology-targeting graph partitioner to map sparse matrix-vector and volumetric 3-D FFT kernels onto a 3-D torus network.	fast fourier transform;graph partition;load balancing (computing);network topology;sparse matrix	Anshu Arya;Todd Gamblin;Bronis R. de Supinski;Laxmikant V. Kalé	2012	2012 SC Companion: High Performance Computing, Networking Storage and Analysis	10.1109/SC.Companion.2012.197	fast fourier transform;parallel computing;graph bandwidth;computer science;graph partition;load balancing;theoretical computer science;distributed computing	HPC	-5.5198117681650505	40.958369743346644	98082
5eb9bb0450cf8ad4b8ee7bf8ceba5553f4fdf137	lost in abstraction: pitfalls of analyzing gpus at the intermediate language level		Modern GPU frameworks use a two-phase compilation approach. Kernels written in a high-level language are initially compiled to an implementation agnostic intermediate language (IL), then finalized to the machine ISA only when the target GPU hardware is known. Most GPU microarchitecture simulators available to academics execute IL instructions because there is substantially less functional state associated with the instructions, and in some situations, the machine ISA’s intellectual property may not be publicly disclosed. In this paper, we demonstrate the pitfalls of evaluating GPUs using this higher-level abstraction, and make the case that several important microarchitecture interactions are only visible when executing lower-level instructions. Our analysis shows that given identical application source code and GPU microarchitecture models, execution behavior will differ significantly depending on the instruction set abstraction. For example, our analysis shows the dynamic instruction count of the machine ISA is nearly 2× that of the IL on average, but contention for vector registers is reduced by 3× due to the optimized resource utilization. In addition, our analysis highlights the deficiencies of using IL to model instruction fetching, control divergence, and value similarity. Finally, we show that simulating IL instructions adds 33% error as compared to the machine ISA when comparing absolute runtimes to real hardware.	application binary interface;compiler;encode;first-order logic;first-order predicate;graphics processing unit;high- and low-level;high-level programming language;instruction cycle;interaction;microarchitecture;runtime system;simulation;two-phase locking;vector processor	Anthony Gutierrez;Bradford M. Beckmann;Alexandru Dutu;Joseph Gross;Michael LeBeane;John Kalamatianos;Onur Kayiran;Matthew Poremba;Brandon Potter;Sooraj Puthoor;Matthew D. Sinclair;Mark Wyse;Jieming Yin;Xianwei Zhang;Akshay Jain;Timothy G. Rogers	2018	2018 IEEE International Symposium on High Performance Computer Architecture (HPCA)	10.1109/HPCA.2018.00058	kernel (linear algebra);parallel computing;instruction set;computer science;intermediate language;source code;microarchitecture;abstraction	Arch	-17.197598383392364	35.942130551757714	98084
a50bc7a8029fdf1f40f2ce9fbd7d8029bb628bfe	design and analysis of scheduling strategies for multi-cpu and multi-gpu architectures	work stealing;accelerators;parallel programming;data flow dependencies;task parallelism	In this paper, we present a comparison of scheduling strategies for heterogeneous multi-CPU and multi-GPU architectures. We designed and evaluated four scheduling strategies on top of XKaapi runtime: work stealing, data-aware work stealing, locality-aware work stealing, and Heterogeneous Earliest-Finish-Time (HEFT). On a heterogeneous architecture with 12 CPUs and 8 GPUs, we analysed our scheduling strategies with four benchmarks: a BLAS-1 AXPY vector operation, a Jacobi 2D iterative computation, and two linear algebra algorithms Cholesky and LU. We conclude that the use of work stealing may be efficient if task annotations are given along with a data locality strategy. Furthermore, our experimental results suggests that HEFT scheduling performs better on applications with very regular computations and low data locality.	algorithm;blas;central processing unit;cholesky decomposition;computation;graphics processing unit;heterogeneous earliest finish time;iterative method;jacobi method;lu decomposition;linear algebra;locality of reference;open-shop scheduling;scheduling (computing);work stealing	João V. F. Lima;Thierry Gautier;Vincent Danjean;Bruno Raffin;Nicolas Maillard	2015	Parallel Computing	10.1016/j.parco.2015.03.001	parallel computing;real-time computing;computer science;operating system;distributed computing;task parallelism	HPC	-4.79154184777758	42.23040507903439	98145
c99f0d1c09bb66a07b6e8bf5e1e6f410be2a9c4c	parallel optimization strategies for mic heterogeneous parallel systems	parallel architectures coprocessors optimisation;microwave integrated circuits coprocessors optimization instruction sets benchmark testing programming parallel processing;k means application program mic architecture many integrated core heterogeneous parallel system program porting performance optimization;performance optimization many integrated core mic heterogeneous system	In the traditional multithread programming model, there is no dedicated performance optimization strategy for Many Integrated Core (MIC) heterogeneous system. To fully exploit the high computing power of MIC processor, this paper discusses the specific program porting and performance optimization strategies on the MIC heterogeneous parallel system based on the k-means application program. Experimental results show that the proposed porting and performance optimization strategies are effective, and can be able to guide the programmer to port and optimize applications effectively to MIC heterogeneous parallel system.	k-means clustering;mathematical optimization;paradiseo;programmer;programming model;thread (computing);xeon phi	Tao Ju;Xiaoshe Dong;Endong Wang;Liang Li;Zhengdong Zhu	2014	2014 Sixth International Symposium on Parallel Architectures, Algorithms and Programming	10.1109/PAAP.2014.39	computer architecture;parallel computing;real-time computing;computer science	Arch	-5.777003849654793	44.32207691729807	98153
542c5a6cf70816c7704045c49535890878d14755	performance evaluation of offloading software modules to cluster network	performance evaluation;cluster network;offloading	A design of software to offload user-defined software modules to Maestro2 cluster network, named Maestro dynamic offloading mechanism(MDO), and results of its performance evaluation are described. Maestro2 is a high-performance network for clusters. The network interface and the switch of Maestro2 have a general-purpose processor tightly coupled with dedicated communication hard-ware. MDO enables the users to offload software modules to both the network interface and the switch. The effectiveness of MDO are discussed through the evaluation of offloading collective communications and parallel Gauss-Jordan elimination benchmark.	performance evaluation	Keiichi Aoki;Hiroki Maruoka;Koichi Wada;Masaaki Ono	2007			embedded system;real-time computing;computer science;operating system	OS	-10.711006502803132	45.61035737683721	98431
88d75a85fb21b976ca2fcc6ab1c82a85d2bc2fe4	a dynamic load-balancing scheme for xpath queries parallelization in shared memory multi-core systems	query parallelization;shared memory;xpath	Due to the rapid popularity of multi-core processors systems, the parallelization of XPath queries in shared memory multi-core systems has been studied gradually. Existing work developed some parallelization methods based on cost estimation and static mapping, which could be seen as a logical optimization of parallel query plan. However, static mapping may result in load imbalance that hurts the overall performance, especially when nodes in XML are not evenly distributed. In this paper, we solve the problem from another view using parallelizing techniques. We use dynamic mapping to improve XPath query performance, which can achieve better load balance no matter what XML document is queried. Compared with static mapping, dynamic mapping is a more general method. We first design a parallel XPath query algebra called PXQA (ParallelXPath Query Algebra) to explain the parallel query plan. And second, using PXQA we extract the task-dependence graph to define which operations can be executed in parallel and help analyze the overheads of dynamic mapping. At last, we discuss how to do the data partition based on dynamic mapping in accordance with the runtime situations adaptively. Experimental results show that the adaptive runtime XPath queries parallelization achieves a good performance in shared memory multi-core systems.	algorithm;automatic parallelization;central processing unit;computer cluster;computer data storage;emergence;graphics processing unit;library (computing);load balancing (computing);mathematical optimization;message passing;multi-core processor;overhead (computing);parallel computing;query plan;scalability;shared memory;supercomputer;xml;xpath	Xiaocheng Huang;Xujie Si;Xiaojie Yuan;Chao Wang	2014	JCP	10.4304/jcp.9.6.1436-1445	shared memory;parallel computing;computer science;theoretical computer science;database;automatic parallelization	HPC	-7.275961746131342	45.41068869935058	98432
21a1d6f7e550522476fffd45c0a903b15f221806	accelerator programming using directives		In this paper, we document the workflow of our practice to port a PETSc application with OpenACC to a supercomputer, Titan, at Oak Ridge National Laboratory. Our experience shows a few lines of code modifications with OpenACC directives can give us a speedup of 1.34x in a PETSc-based Poisson solver (conjugate gradient method with algebraic multigrid precondi‐ tioner). This demonstrates the feasibility of enabling GPU capability in PETSc with OpenACC. We hope our work can serve as a reference to those who are interested in porting their legacy PETSc applications to modern heterogeneous platforms.	conjugate gradient method;graphics processing unit;multigrid method;openacc;petsc;solver;source lines of code;speedup;supercomputer;titan	Sunita Chandrasekaran;Guido Juckeland	2017		10.1007/978-3-319-74896-2		HPC	-7.151986561950007	38.878131781335206	98487
00f0c5be7dbecf232c88c4a84fa184a0854c75e8	bounds on bus and memory interference in a class of multiple bus multiprocessor systems		BUS AND CACHE MEMORY ORGANIZATIONS FOR MULTIPROCESSORS by Donald Charles Winsor Chairman: Trevor Mudge The single shared bus multiprocessor has been the most commercially successful multiprocessor system design up to this time, largely because it permits the implementation of efficient hardware mechanisms to enforce cache consistency. Electrical loading problems and restricted bandwidth of the shared bus have been the most limiting factors in these systems. This dissertation presents designs for logical buses constructed from a hierarchy of physical buses that will allow snooping cache protocols to be used without the electrical loading problems that result from attaching all processors to a single bus. A new bus bandwidth model is developed that considers the effects of electrical loading of the bus as a function of the number of processors, allowing optimal bus configurations to be determined. Trace driven simulations show that the performance estimates obtained from this bus model agree closely with the performance that can be expected when running a realistic multiprogramming workload in which each processor runs an independent task. The model is also used with a parallel program workload to investigate its accuracy when the processors do not operate independently. This is found to produce large errors in the mean service time estimate, but still gives reasonably accurate estimates for the bus utilization. A new system organization consisting essentially of a crossbar network with a cache memory at each crosspoint is proposed to allow systems with more than one memory bus to be constructed. A two-level cache organization is appropriate for this architecture. A small cache may be placed close to each processor, preferably on the CPU chip, to minimize the effective memory access time. A larger cache built from slower, less expensive memory is then placed at each crosspoint to minimize the bus traffic. By using a combination of the hierarchical bus implementations and the crosspoint cache architecture, it should be feasible to construct shared memory multiprocessor systems with several hundred processors. c Donald Charles Winsor All Rights Reserved 1989 To my family and friends	access time;cas latency;cpu cache;cache coherence;central processing unit;computer multitasking;crossbar switch;data dredging;electrical load;interference (communication);memory bus;multiprocessing;shared memory;simulation;systems design	M. A. Marson	1982			distributed computing;memory bus;symmetric multiprocessor system;distributed memory;parallel computing;multiprocessing;computer science;system bus;local bus;physical address;back-side bus	Arch	-14.704700934097605	44.536894730564676	98606
03a87a79b62621d0ed1cc47c3b620a2559e6daee	egeria: a framework for automatic synthesis of hpc advising tools through multi-layered natural language processing		Achieving high performance on modern systems is challenging. Even with a detailed profile from a performance tool, writing or refactoring a program to remove its performance issues is still a daunting task for application programmers: it demands lots of program optimization expertise that is often system specific.  Vendors often provide some detailed optimization guides to assist programmers in the process. However, these guides are frequently hundreds of pages long, making it difficult for application programmers to master and memorize all the rules and guidelines and properly apply them to a specific problem instance.  In this work, we develop a framework named Egeria to alleviate the difficulty. Through Egeria, one can easily construct an advising tool for a certain high performance computing (HPC) domain (e.g., GPU programming) by providing Egeria with a optimization guide or other related documents for the target domain. An advising tool produced by Egeria provides a concise list of essential rules automatically extracted from the documents. At the same time, the advising tool serves as a question-answer agent that can interactively offers suggestions for specific optimization questions. Egeria is made possible through a distinctive multi-layered design that leverages natural language processing techniques and extends them with knowledge of HPC domains and how to extract information relevant to code optimization Experiments on CUDA, OpenCL, and Xeon Phi programming guides demonstrate, both qualitatively and quantitatively, the usefulness of Egeria for HPC.	cuda;code refactoring;graphics processing unit;interactivity;mathematical optimization;natural language processing;opencl api;program optimization;programmer;supercomputer;xeon phi	Hui Guan;Xipeng Shen;Hamid Krim	2017		10.1145/3126908.3126961	computer science;program optimization;xeon phi;code refactoring;natural language processing;artificial intelligence;general-purpose computing on graphics processing units;cuda;memorization;supercomputer	HPC	-14.93298622492189	36.20961452374257	98636
712c64a0764c911c0ccf0e0a0d34bf53240085b0	a web-based parallel pde solver generation system for distributed memory computing environments	distributed memory systems partial differential equations parallel programming;distributed memory;finite element methods;biology computing;front end;partial differential equation;distributed memory systems;concurrent computing;chaos;refiner;web based;distributed computing;parallel programming;partitioner;finite element method;indexing terms;partial differential equations solver generation system pde solver distributed memory computing web based finite element method parallel processing;automatic generation;load balancer;solver;partial differential equations;distributed memory computing;web sites;pc cluster;parallel computer;partial differential equations solver generation system;world wide web;load balance;self stabilizing;graph g;k5 free;pde solver;parallel processing;concurrent computing distributed computing finite element methods biology computing partial differential equations costs parallel programming chaos parallel processing web sites;workstation cluster	Abs t rac t -The finite element method is widely applied to many domains, such as engineering, atmology, oceanography, biology, etc. The major drawback of the finite element method is that its execution takes a lot of time and memory spaces. Due to the computation-intensiveness and computation-locality properties, we can use the parallel processing method to improve the performance of the finite element method on distributed memory computing environments. However, it is quite difficult to program the finite element method on a distributed memory computing environment. Therefore, the development of a front-end parallel partial differential equations solver generation system is important. In this paper, we want to develop a front-end parallel partial differential equations solver generation system based on the World Wide Web on a distributed-memory computing environment, such as a PC cluster, a workstation cluster, etc. With the system, users who want to use parallel computers to solver partial differential equations can use web browser to input data and parameters. The system will automatically generate the corresponding parallel codes and execute the codes on the distributed memory computing environment. The execution result will be shown on the web browser. The results can also be download by user.	code;computation;computer cluster;distributed memory;download;finite element method;locality of reference;parallel computing;solver;workstation;world wide web	Chao-Jen Lee;Yeh-Ching Chung	2000		10.1109/CMPSAC.2000.884691	parallel processing;parallel computing;concurrent computing;computer science;load balancing;theoretical computer science;operating system;finite element method;database;distributed computing;programming language;partial differential equation;computing with memory	HPC	-9.55701700803513	37.51292576175951	98669
993971dea4aa8d90830132b2224de0b2550c4ace	towards scalable adaptive mesh refinement on future parallel architectures	qa76 electronic computers computer science computer software	In the march towards exascale, supercomputer architectures are undergoing a significant change. Limited by power consumption and heat dissipation, future supercomputers are likely to be built around a lower-power many-core model. This shift in supercomputer design will require sweeping code changes in order to take advantage of the highly-parallel architectures. Evolving or rewriting legacy applications to perform well on these machines is a significant challenge.#R##N##R##N#Mini-applications, small computer programs that represent the performance characteristics of some larger application, can be used to investigate new programming models and improve the performance of the legacy application by proxy. These applications, being both easy to modify and representative, are essential for establishing a path to move legacy applications into the exascale era.#R##N##R##N#The focus of the work presented in this thesis is the design, development and employment of a new mini-application, CleverLeaf, for shock hydro- dynamics with block-structured adaptive mesh refinement (AMR). We report on the development of CleverLeaf, and show how the fresh start provided by a mini-application can be used to develop an application that is flexible, accurate, and easy to employ in the investigation of exascale architectures.#R##N##R##N#We also detail the development of the first reported resident parallel block-structured AMR library for Graphics Processing Units (GPUs). Extending the SAMRAI library using the CUDA programming model, we develop datatypes that store data only in GPU memory, as well the necessary operators for moving and interpolating data on an adaptive mesh. We show that executing AMR simulations on a GPU is up to 4.8⇥ faster than a CPU, and demonstrate scalability on over 4,000 nodes using a combination of CUDA and MPI.#R##N##R##N#Finally, we show how mini-applications can be employed to improve the performance of production applications on existing parallel architectures by selecting the optimal application configuration. Using CleverLeaf, we identify the most appropriate configurations on three contemporary supercomputer architectures. Selecting the best parameters for our application can reduce run-time by up to 82% and reduce memory usage by up to 32%.		D. A. Beckingsale	2015			computer architecture;parallel computing;computer science;theoretical computer science	HPC	-5.822142911414053	39.66548985723905	98701
1d4c0211549a8fe259a273da88c63e8f00fef463	practical partial evaluation for high-performance dynamic language runtimes		Most high-performance dynamic language virtual machines duplicate language semantics in the interpreter, compiler, and runtime system. This violates the principle to not repeat yourself. In contrast, we define languages solely by writing an interpreter. The interpreter performs specializations, e.g., augments the interpreted program with type information and profiling information. Compiled code is derived automatically using partial evaluation while incorporating these specializations. This makes partial evaluation practical in the context of dynamic languages: It reduces the size of the compiled code while still compiling all parts of an operation that are relevant for a particular program. When a speculation fails, execution transfers back to the interpreter, the program re-specializes in the interpreter, and later partial evaluation again transforms the new state of the interpreter to compiled code. We evaluate our approach by comparing our implementations of JavaScript, Ruby, and R with best-in-class specialized production implementations. Our general-purpose compilation system is competitive with production systems even when they have been heavily optimized for the one language they support. For our set of benchmarks, our speedup relative to the V8 JavaScript VM is 0.83x, relative to JRuby is 3.8x, and relative to GNU R is 5x.	benchmark (computing);compiler;gnu;general-purpose markup language;interpreter (computing);jruby;javascript;partial evaluation;profiling (computer programming);r language;ruby;runtime system;speedup;virtual machine	Thomas Würthinger;Christian Wimmer;Christian Humer;Andreas Wöß;Lukas Stadler;Chris Seaton;Gilles Duboscq;Doug Simon;Matthias Grimmer	2017		10.1145/3062341.3062381	compiler;programming language;interpreted language;theoretical computer science;runtime system;computer science;interpreter pattern;javascript;interpreter;partial evaluation;compiled language	PL	-17.59805616163864	36.06675217699089	98728
e761bc40bdbaa94fd41373cb73006c9f83d058fe	adapting a message-driven parallel application to gpu-accelerated clusters	computer graphics;coprocessors;parallel processing;gpu hardware;gpu kernel execution;gpu software development tools;gpu-accelerated clusters;graphics processing units;message-driven parallel application;parallel molecular dynamics simulation package	Graphics processing units (GPUs) have become an attractive option for accelerating scientific computations as a result of advances in the performance and flexibility of GPU hardware, and due to the availability of GPU software development tools targeting general purpose and scientific computation. However, effective use of GPUs in clusters presents a number of application development and system integration challenges. We describe strategies for the decomposition and scheduling of computation among CPU cores and GPUs, and techniques for overlapping communication and CPU computation with GPU kernel execution. We report the adaptation of these techniques to NAMD, a widely-used parallel molecular dynamics simulation package, and present performance results for a 64-core 64-GPU cluster.	central processing unit;computation;computational science;graphics processing unit;nanoscale molecular dynamics;programming tool;scheduling (computing);simulation;software development;system integration	James C. Phillips;John E. Stone;Klaus Schulten	2008	2008 SC - International Conference for High Performance Computing, Networking, Storage and Analysis	10.1145/1413370.1413379	computational science;programming;molecular dynamics;computer architecture;parallel computing;kernel;petascale computing;computer science;software development;molecular model;computer graphics;rapid application development;computational model;coprocessor;system integration	HPC	-6.303374181619254	38.13871167128676	98913
911d10376d80d567e27d398640fb63d6027949ef	finding the right processor for the job: co-processors in a dbms			central processing unit	Hannes Rauhe	2014				Theory	-9.652666937229888	42.90163989883573	98960
7dbb0ea080e7e9c42446bd084904258cfaf960ad	persistence in dynamic code transformation systems	program instrumentation;cache memory profiling;transform coding;multiprocessor simulation;dynamic instrumentation	Dynamic code transformation systems (DCTS) can broadly be grouped into three distinct categories: optimization, translation and instrumentation. All of these face the critical challenge of minimizing the overhead incurred during transformation since their execution is interleaved with the execution of the application itself. The common DCTS tasks incurring overhead are the identification of frequently executed code sequences, costly analysis of program information, and run-time creation (writing) of new code sequences. The cost of such work is amortized by the repeated execution of the transformed code. However, as these steps are applied to all general code regions (regardless of their execution frequency and characteristics), there is substantial overhead that impacts the application's performance. As such, it is challenging to effectively deploy dynamic transformation under fixed performance constraints. This paper explores a technique for eliminating the overhead incurred by exploiting persistent application execution characteristics that are shared across different application invocations. This technique is implemented and evaluated in Pin, a dynamic instrumentation engine. This version of Pin is referred to as Persistent Pin (PPin). Initial PPin experimental results indicate that using information from prior runs can reduce dynamic instrumentation overhead of SPEC applications by as much as 25% and over 90% for everyday applications like web browsers, display rendering systems, and spreadsheet programs.	amortized analysis;benchmark (computing);binary code;cache (computing);instrumentation (computer programming);mathematical optimization;overhead (computing);persistence (computer science);personal identification number;spreadsheet;thread (computing)	Vijay Janapa Reddi;Daniel A. Connors;Robert S. Cohn	2005	SIGARCH Computer Architecture News	10.1145/1127577.1127591	embedded system;computer architecture;parallel computing;real-time computing;transform coding;computer science;operating system;programming language	Arch	-18.920546854275567	36.92132851671849	99017
bf384d0ed240d05f690f13c5b716b8d43aeac960	efficient memory management for smps running parallel and sequential workloads	memory management		memory management;out-of-core algorithm	T. Newhall;P. Boe	2002			parallel computing;computer architecture;memory management;working set;computer science	Arch	-9.300727747839268	43.709721843304116	99149
2af791292d9ebf3f47cbc883544f275b0ea8fad8	comparative aspects between the cluster and grid implementations of bigbatch	image processing;distributed environment;load balance	BigBatch is an image processing environment designed to process batches of thousands of monochromatic documents. One of the flexibilities and pioneer aspects of BigBatch is offering the possibility of working in distributed environments such as clusters and grids. This paper presents an overview of BigBatch image processing features and analyzes the results of a number of experiments devised to compare its cluster and grid configurations. Although preliminary results were published earlier on, the new data shown here that sheds new lights onto this aspect. The results obtained exhibit almost no difference in total execution times for some grid and cluster configurations, but significant differences for others, indicating that the choice between such configurations must take into account a number of details in order to reach peak performance. Besides those, there are other qualitative aspects that may impact this choice. This paper analyzes these aspects and provides a general picture of how to successfully use BigBatch to process document images employing computers in parallel for this task.	algorithm;benchmark (computing);byte;central processing unit;computer cluster;document processing;electrical load;experiment;filter (signal processing);image processing;internet;linux;load balancing (computing);map (parallel pattern);microsoft windows;monochrome;multi-core processor;multiprocessing;ourgrid;parallel computing;programming tool;randomness;run time (program lifecycle phase);scheduling (computing);simulation;the times;unix	Giorgia de Oliveira Mattos;Andrei de Araújo Formiga;Rafael Dueire Lins;Francisco Heron de Carvalho Junior;Fernando Mário Junqueira Martins	2008	J. UCS	10.3217/jucs-014-18-3031	simulation;image processing;computer science;artificial intelligence;load balancing;operating system;software engineering;distributed computing;world wide web;algorithm;distributed computing environment	HPC	-13.88724328912453	43.71855785658537	99172
030298b28cba9cea581abdd357634da44692217a	java object header elimination for reduced memory consumption in 64-bit virtual machines	virtual machine;information structure;typed virtual addressing;java object model;java virtual machine;memory performance;technology and engineering;64 bit implementation;implicit typing;object model	Memory performance is an important design issue for contemporary computer systems given the huge processor/memory speed gap. This paper proposes a space-efficient Java object model for reducing the memory consumption of 64-bit Java virtual machines. We completely eliminate the object header through typed virtual addressing (TVA) or implicit typing. TVA encodes the object type in the object's virtual address by allocating all objects of a given type in a contiguous memory segment. This allows for removing the type information as well as the status field from the object header. Whenever type and status information is needed, masking is applied to the object's virtual address for obtaining an offset into type and status information structures. Unlike previous work on implicit typing, we apply TVA to a selected number of frequently allocated object types, hence, the name selective TVA (STVA); this limits the amount of memory fragmentation. In addition to applying STVA, we also compress the type information block (TIB) pointers for all objects that do not fall under TVA. We implement the space-efficient Java object model in the 64-bit version of the Jikes RVM on an AIX IBM platform and compare its performance against the traditionally used Java object model using a multitude of Java benchmarks. We conclude that the space-efficient Java object model reduces memory consumption by on average 15% (and up to 45% for some benchmarks). About one-half the reduction comes from TIB pointer compression; the other one-half comes from STVA. In terms of performance, the space-efficient object model generally does not affect performance; however, for some benchmarks we observe statistically significant performance speedups, up to 20%.	32-bit;64-bit computing;aix;apply;benchmark (computing);byte;fragmentation (computing);ibm pc compatible;jdom;java virtual machine;jikes;memory segmentation;object type (object-oriented programming);power4;pointer (computer programming);selective repeat arq	Kris Venstermans;Lieven Eeckhout;Koen De Bosschere	2007	TACO	10.1145/1275937.1275941	method;parallel computing;real-time computing;object model;java concurrency;computer science;virtual machine;theoretical computer science;operating system;strictfp;common object request broker architecture;real time java;unreachable memory;programming language;java;scala;java annotation	PL	-19.05749940979114	36.76624564132202	99174
617e0552b17c3f3c4be861421c6337ee9fb0932c	upmlib: a runtime system for tuning the memory performance of openmp programs on scalable shared-mem	sistema operativo;gestion memoire;programacion paralela;storage management;parallel programming;computer architecture;performance programme;gestion memoria;shared memory systems;architecture ordinateur;operating system;systeme exploitation;eficacia programa;arquitectura ordenador;program performance;systeme memoire partagee;programmation parallele	We present the design and implementation of UPM LIB , a runtime system that provides transparent facilities for dynamical ly tuning the memory performance of OpenMP programs on scalable shared-memory m ultiprocessors with hardware cache-coherence. UPM LIB integrates information from the compiler and the operating system, to implement algorithms tha t perform accurate and timely page migrations. The algorithms and the associat ed mechanisms correlate memory reference information with the semantics of p arallel programs and scheduling events that break the association between threa ds and data for which threads have memory affinity at runtime. Our experimental ev idence shows that UPMLIB makes OpenMP programs immune to the page placement strategy of the operating system, thus obviating the need for introduci ng data placement directives in OpenMP. Furthermore, UPMlib provides solid i mprovements of throughput in multiprogrammed execution environments.	algorithm;biasing;cache (computing);cache coherence;code;compiler;experiment;locality of reference;memory access pattern;openmp;operating system;process migration;processor affinity;programming model;run time (program lifecycle phase);runtime system;scalability;scheduling (computing);shared memory;throughput	Dimitrios S. Nikolopoulos;Theodore S. Papatheodorou;Constantine D. Polychronopoulos;Jesús Labarta;Eduard Ayguadé	2000		10.1007/3-540-40889-4_7	computer architecture;parallel computing;computer science;operating system;distributed computing;programming language	HPC	-15.400368047646934	44.34165480955384	99431
23e0180aa291591aea79edf149d3a37cc6b91b32	mpi-interoperable generalized active messages	utilizing ams;mpi-interoperable ams;accumulate operation;mpi accumulate;mpi-interoperable generalized active messages;mpi standard;richer semantics;accumulate-style ams;alternative communication paradigm;mpi implementation;correctness semantics;message passing;open systems	Data-intensive applications have become increasingly important in recent years, yet traditional data movement approaches for scientific computation are not well suited for such applications. The Active Message (AM) model is an alternative communication paradigm that is better suited for such applications by allowing computation to be dynamically moved closer to data. Given the wide usage of MPI in scientific computing, enabling an MPI-interoperable AM paradigm would allow traditional applications to incrementally start utilizing AMs in portions of their applications, thus eliminating the programming effort of rewriting entire applications. In our previous work, we extended the MPI ACCUMULATE and MPI GET ACCUMULATE operations in the MPI standard to support AMs. However, the semantics of accumulate-style AMs are fundamentally restricted by the semantics of MPI ACCUMULATE and MPI GET ACCUMULATE, which were not designed to support the AM model. In this paper, we present a new generalized framework for MPI-interoperable AMs that can alleviate those restrictions, thus providing a richer semantics to accommodate a wide variety of application computational patterns. Together with a new API, we present a detailed description of the correctness semantics of this functionality and a reference implementation that demonstrates how various API choices affect the flexibility provided to the MPI implementation and consequently its performance.	active message;application programming interface;computation;computational science;correctness (computer science);interoperability;message passing interface;programming paradigm;reference implementation;rewriting	Xin Zhao;Pavan Balaji;William Gropp;Rajeev Thakur	2013	2013 International Conference on Parallel and Distributed Systems	10.1109/ICPADS.2013.38	layout;data modeling;parallel computing;message passing;concurrent computing;computer science;theoretical computer science;operating system;database;distributed computing;semantics;open system;programming language;computational model	HPC	-11.175329290825506	37.541442107661894	99535
d5e623dc14707a535a7e5e5fcb64d0b8cf5d2b77	practical considerations in the use of multithreading for parallelising applications			simultaneous multithreading;thread (computing)	Ju-Pin Ang;Chu-Cheow Lim	1997			computer architecture;parallel computing;computer science;multithreading	Arch	-9.642831109907245	43.521924436876155	99587
d9912ea262986794e29e3f15e5f8930d42f2ced4	fast string searching	architecture systeme;compilateur;algoritmo busqueda;algorithme recherche;search algorithm;test;compiler;ensayo;algorithme;algorithm;essai;boyer moore;string searching;pattern matching;arquitectura sistema;concordance forme;system architecture;compilador;algoritmo	Since the Boyer-Moore algorithm was described in 1977, it has been the standard benchmark for the practical string search literature. Yet this yardstick compares badly with current practice. We describe two algorithms that perform 47% fewer comparisons and are about 4.5 times faster across a wide range of architectures and compilers. These new variants are members of a family of algorithms based on the skip loop structure of the preferred, but often neglected, fast form of Boyer-Moore. We present a taxonomy for this family, and describe a toolkit of components that can be used to design an algorithm most appropriate for a given set of requirements.	benchmark (computing);bottleneck (software);boyer–moore string search algorithm;brian;compiler;fast fourier transform;hume (programming language);requirement;stavros fasoulas;string searching algorithm;taxonomy (general);theory	Andrew Hume;Daniel Sunday	1991	Softw., Pract. Exper.	10.1002/spe.4380211105	compiler;computer science;artificial intelligence;theoretical computer science;pattern matching;boyer–moore string search algorithm;software testing;programming language;algorithm;systems architecture;search algorithm	ML	-16.670152033696727	34.008184302141615	99785
70f99d690495d809ae2c13bbb8fbb137ceb3f459	queue-based multi-processing lisp	artificial intelligent;high speed	As the need for high-speed computers increases, the need for multi-processors will be become more apparent. One of the major stumbling blocks to the development of useful multi-processors has been the lack of a good multi-processing language—one which is both powerful and understandable to programmers.  Among the most compute-intensive programs are artificial intelligence (AI) programs, and researchers hope that the potential degree of parallelism in AI programs is higher than in many other applications. In this paper we propose multi-processing extensions to Lisp. Unlike other proposed multi-processing Lisps, this one provides only a few very powerful and intuitive primitives rather than a number of parallel variants of familiar constructs.	artificial intelligence;central processing unit;computer;computer multitasking;degree of parallelism;distributed computing;lisp;multi-core processor;multiprocessing;parallel algorithm;parallel computing;programmer;runtime system;shared memory;stumbleupon	Richard P. Gabriel;John McCarthy	1984		10.1145/800055.802019	computer science;theoretical computer science;programming language;algorithm	AI	-13.101747067576593	39.60278357753816	99798
58e0e3f19a2fae540f6cacfd5b53b6675fa96dca	adaptively increasing performance and scalability of automatically parallelized programs	estensibilidad;lenguaje programacion;programa paralelo;metodo adaptativo;compilacion;evaluation performance;haute performance;compilateur;performance evaluation;preprocesor;systeme multiprocesseur memoire repartie;programming language;preprocesseur;preprocessor;performance estimation;evaluacion prestacion;memoria virtualmente compartida;distributed computing;methode adaptative;compiler;memoire virtuellement partagee;sistema multiprocesador memoria distribuida;adaptive method;alto rendimiento;langage programmation;compilation;calculo repartido;extensibilite;distributed memory multiprocessor system;scalability;parallel programs;distributed shared memory;high performance;parallel program;calcul reparti;compilador;automatic parallelization;programme parallele	This paper presents adaptive execution techniques that determine whether automatically parallelized loops are executed parallelly or sequentially in order to maximize performance and scalability. The adaptation and performance estimation algorithms are implemented in a compiler preprocessor. The preprocessor inserts code that automatically determines at compile-time or at run-time the way the parallelized loops are executed. Using a set of standard numerical applications written in Fortran77 and running them with our techniques on a distributed shared memory multiprocessor machine (SGI Origin2000), we obtain the performance of our techniques, on average, 26%, 20%, 16%, and 10% faster than the original parallel program on 32, 16, 8, and 4 processors, respectively. One of the applications runs even more than twice faster than its original parallel version on 32 processors.	parallel computing;scalability	Jaejin Lee;H. D. K. Moonesinghe	2002		10.1007/11596110_14	distributed shared memory;computer architecture;compiler;parallel computing;real-time computing;scalability;computer science;programming language;preprocessor;automatic parallelization	HPC	-16.4836580338159	42.32852332027805	99822
4dbe8349592cab897829b065b049c23a5920a517	management of multilevel, multiclient cache hierarchies with application hints	workload;tiempo respuesta;evaluation performance;replication;gestion memoire;systeme intelligent;performance evaluation;cache;integrated circuit;hierarchized structure;estudio comparativo;storage management;evaluacion prestacion;sistema inteligente;performance;simulation;response time;structure hierarchisee;simulacion;cache memory;circuito integrado;sistema n niveles;buffer system;replicacion;sistema amortiguador;antememoria;algorithme;temps reponse;etude comparative;algorithm;gestion memoria;antememoire;hints;systeme n niveaux;comparative study;multilevel system;intelligent system;borne inferieure;charge travail;design;temps retard;delay time;carga trabajo;systeme tampon;multilevel;management;tiempo retardo;estructura jerarquizada;lower bound;circuit integre;cota inferior;algoritmo	Multilevel caching, common in many storage configurations, introduces new challenges to traditional cache management: data must be kept in the appropriate cache and replication avoided across the various cache levels. Additional challenges are introduced when the lower levels of the hierarchy are shared by multiple clients. Sharing can have both positive and negative effects. While data fetched by one client can be used by another client without incurring additional delays, clients competing for cache buffers can evict each other’s blocks and interfere with exclusive caching schemes.  We present a global noncentralized, dynamic and informed management policy for multiple levels of cache, accessed by multiple clients. Our algorithm, MC2, combines local, per client management with a global, system-wide scheme, to emphasize the positive effects of sharing and reduce the negative ones. Our local management scheme, Karma, uses readily available information about the client’s future access profile to save the most valuable blocks, and to choose the best replacement policy for them. The global scheme uses the same information to divide the shared cache space between clients, and to manage this space. Exclusive caching is maintained for nonshared data and is disabled when sharing is identified.  Previous studies have partially addressed these challenges through minor changes to the storage interface. We show that all these challenges can in fact be addressed by combining minor interface changes with smart allocation and replacement policies. We show the superiority of our approach through comparison to existing solutions, including LRU, ARC, MultiQ, LRU-SP, and Demote, as well as a lower bound on optimal I/O response times. Our simulation results demonstrate better cache performance than all other solutions and up to 87% better performance than LRU on representative workloads.	algorithm;arc (programming language);cpu cache;cache (computing);input/output;simulation	Gala Yadgar;Michael Factor;Kai Li;Assaf Schuster	2011	ACM Trans. Comput. Syst.	10.1145/1963559.1963561	embedded system;design;replication;real-time computing;cache coloring;simulation;performance;cache;computer science;cache invalidation;operating system;integrated circuit;cache algorithms;cache pollution;response time	OS	-17.383271413541024	45.841290859006136	99869
5e5a194a1998adc6fc4e1e1eb4245dca0a4962b3	an efficient dynamic switching mechanism (dsm) for hybrid processor architecture	file attente;modelizacion;processor architecture;virtual memory;calculateur embarque;shared memory;modele agrege;supervised learning;machine unique;memoria compartida;pervasive computing;localization;modelo agregado;queue;localizacion;compatibilidad;classification;informatica difusa;modelisation;computer architecture;hybrid processor;single machine;maquina unica;localisation;architecture ordinateur;informatique diffuse;dynamic switching mechanism;estructura datos;boarded computer;memoire virtuelle;compatibility;utilisabilite;aggregate model;design;compatibilite;structure donnee;arquitectura ordenador;apprentissage supervise;usabilidad;farm computing algorithm;usability;aprendizaje supervisado;modeling;data structure;fila espera;clasificacion;calculador embarque;memoria virtual;memoire partagee	Increasing the processor resources usability and boosting processor compatibility and capability to support multi-executions models in a single core are highly needed nowadays to benefit from the recent developments in electronics technology. This work introduces the concept of a dynamic switching mechanism (DSM), which supports multi-instruction set execution models in a single and simple processor core. This is achieved dynamically by execution mode–switching scheme and a sources–results locations computing unit for a novel queue execution model and a well-known stack based execution model. The queue execution model is based on queue computation that uses queue-registers, a circular queue data structure, for operands and results manipulations and assigns queue words according to a single assignment rule. We present the DSM mechanism and we describe its hardware complexity and preliminary evaluation results. We also describe the DSM target architecture.	microarchitecture	Md. Musfiquzzaman Akanda;Ben A. Abderazek;Sotaro Kawata;Masahiro Sowa	2005		10.1007/11596356_11	shared memory;embedded system;design;parallel computing;real-time computing;usability;data structure;computer science;virtual memory;artificial intelligence;operating system;database;distributed computing;supervised learning;programming language;compatibility;queue;ubiquitous computing	Arch	-16.182398087748524	43.82384186932564	99957
d3e045356fe951f7158e215d70cfc9fead8e4728	accelerating speculative execution in high-level synthesis with cancel tokens	high level synthesis;speculative execution;high level language	We present an improved method for scheduling speculative data paths which relies on cancel tokens to undo computations in misspeculated paths. Performancewise, this method is considerably faster than lenient execution, and faster than any other known approach applicable for general (including non-pipelined) computation structures. We present experimental evidence obtained by implementing our method as part of the high-level language hardware/software compiler COMRADE.	benchmark (computing);compiler;computation;computer hardware;high- and low-level;high-level programming language;high-level synthesis;scheduling (computing);speculative execution;undo	Hagen Gädke-Lütjens;Andreas Koch	2008		10.1007/978-3-540-78610-8_19	parallel computing;real-time computing;computer science;operating system;high-level synthesis;programming language;high-level programming language;speculative multithreading;speculative execution	EDA	-16.357367637650466	36.1936549752627	100123
449bdc7bd7f3efa46abfc014deb6134155870ea1	soax: a generic c++ structure of arrays for handling particles in hpc codes		Abstract The numerical study of physical problems often require integrating the dynamics of a large number of particles evolving according to a given set of equations. Particles are characterized by the information they are carrying such as an identity, a position other. There are generally speaking two different possibilities for handling particles in high performance computing (HPC) codes. The concept of an Array of Structures (AoS) is in the spirit of the object-oriented programming (OOP) paradigm in that the particle information is implemented as a structure. Here, an object (realization of the structure) represents one particle and a set of many particles is stored in an array. In contrast, using the concept of a Structure of Arrays (SoA), a single structure holds several arrays each representing one property (such as the identity) of the whole set of particles. The AoS approach is often implemented in HPC codes due to its handiness and flexibility. For a class of problems, however, it is known that the performance of SoA is much better than that of AoS. We confirm this observation for our particle problem. Using a benchmark we show that on modern Intel Xeon processors the SoA implementation is typically several times faster than the AoS one. On Intel’s MIC co-processors the performance gap even attains a factor of ten. The same is true for GPU computing, using both computational and multi-purpose GPUs. Combining performance and handiness, we present the library SoAx that has optimal performance (on CPUs, MICs, and GPUs) while providing the same handiness as AoS. For this, SoAx uses modern C++ design techniques such template meta programming that allows to automatically generate code for user defined heterogeneous data structures. Program summary Program Title: SoAx Program Files doi: http://dx.doi.org/10.17632/m463pc4mv8.1 Licensing provisions: GPLv3 Programming language: C++ Nature of problem: Structures of arrays (SoA) are generally faster than arrays of structures (AoS) while AoS are more handy. This library (SoAx) combines the advantages of both. By means of C++(11) meta-template programming SoAx achieves maximal performance (efficient use of vector units and cache of modern CPUs) while providing a very convenient user interface (including object-oriented element handling) and flexibility. It has been designed to handle list-like sets of particles (similar to struct int id; double[3] pos; float[3] vel;;) in the context of high-performance numerical simulations. It can be applied to many other problems. Solution method: Template Metaprogramming, Expression Templates	algorithm;array data structure;automatic vectorization;benchmark (computing);central processing unit;code generation (compiler);compiler;decade (log scale);fold (higher-order function);general-purpose computing on graphics processing units;graphics processing unit;handy board;metaprogramming;modern c++ design;multi-purpose viewer;numerical analysis;programming paradigm;supercomputer	Holger Homann;Francois Laenen	2018	Computer Physics Communications	10.1016/j.cpc.2017.11.015	parallel computing;expression templates;struct;theoretical computer science;generic programming;metaprogramming;cuda;object-oriented programming;template metaprogramming;computer science;data structure	HPC	-6.462146976735937	42.4511001050029	100565
db568a20e7d10e04182cd6223b5191d584ce0371	on the performance portability of structured grid codes on many-core computer architectures	paper;gpu;structured grid;rotorsim;xeon phi;heterogeneous;performance portability;multi grid multi block;cloverleaf;lattice boltzmann;fluid dynamics;opencl;intel xeon phi;many core	With the advent of many-core computer architectures such as GPGPUs from NVIDIA and AMD, and more recently Intel's Xeon Phi, ensuring performance portability of HPC codes is potentially becoming more complex. In this work we have focused on one important application area -- structured grid codes -- and investigated techniques for ensuring performance portability across a diverse range of different, high-end many-core architectures. We chose three codes to investigate: a 3D lattice Boltzmann code D3Q19 BGK, the CloverLeaf hydrodynamics mini application from Sandia's Mantevo benchmark suite, and ROTORSIM, a production-quality structured grid, multiblock, compressible finite-volume CFD code. We have developed OpenCL versions of these codes in order to provide cross-platform functional portability, and compared the performance of the OpenCL versions of these structured grid codes to optimized versions on each platform, including hybrid OpenMP/MPI/AVX versions on CPUs and Xeon Phi, and CUDA versions on NVIDIA GPUs. Our results show that, contrary to conventional wisdom, using OpenCL it is possible to achieve a high degree of performance portability, at least for structured grid applications, using a set of straightforward techniques. The performance portable code in OpenCL is also highly competitive with the best performance using the native parallel programming models on each platform.	computer architecture;regular grid	Simon McIntosh-Smith;Michael Boulton;Dan Curran;James Price	2014		10.1007/978-3-319-07518-1_4	computer architecture;parallel computing;computer science;operating system;xeon phi;fluid dynamics	HPC	-5.548270651408892	40.11084394962213	100733
aed965f5afecea3a36c4d1f10c8e46782a377deb	performance characterization research at oak ridge national laboratory	national organizations;general and miscellaneous mathematics computing and information science;parallel algorithm;us organizations 990200 mathematics computers;national organic program;performance;performance characterization;computer architecture;us aec;array processors;us erda;ornl;us doe;parallel architecture;programming;parallel processing	Research in performance characterization at Oak Ridge National Laboratory is focused on providing tools for analyzing and modeling the behavior of parallel algorithms on parallel architectures. The ultimate goal is to attain a deeper understanding of the complex interaction between parallel algorithms and architectures in order to improve performance on existing architectures and to predict performance as an aid to designing new architectures. In this paper, we describe our approach and the current status of the research. 1 ref., 3 figs.		Patrick H. Worley;Michael T. Heath	1989			simulation;computer science;theoretical computer science	Theory	-8.053265912671678	39.20504188932195	100839
7fb9df449356e2fcc579786854352986cd837fd3	benchmarking data and compute intensive applications on modern cpu and gpu architectures	jpeg 2000;signal processing	The use of graphics hardware for non-graphics applications has become popular among many scientific programmers and researchers as we have observed a higher rate of theoretical performance increase than the CPUs in recent years. However, performance gains may be easily lost in the context of a specific parallel application due to various both hardware and software factors. Consequently, software benchmarks and performance testing are still the best techniques to compare the efficiency of emerging parallel architectures with the built-in support for parallelism at different levels. Unfortunately, many available benchmarks are either relatively simple application kernels, they have been optimized only for a certain parallel architecture or they do not take advantage of recent capabilities provided by modern hardware and low level APIs. Thus, the main aim of this paper is to present a comprehensive real performance analysis of selected applications following the complex standard for data compression and coding JPEG 2000. It consists of a chain of data and compute intensive tasks that can be treated as good examples of software benchmarks for modern parallel hardware architectures. In this paper we compare achieved performance results of our standard based benchmarks executed on selected architectures for different data sets to identify possible bottlenecks. We discuss also best practices and advices for parallel software development to help users to evaluate in advance and then select appropriate solutions to accelerate the execution of their applications.	benchmark (computing);best practice;blocking (computing);bottleneck (software);cpu cache;canonical account;central processing unit;computation;data compression;graphics hardware;graphics processing unit;jpeg 2000;loop nest optimization;mathematical optimization;multi-core processor;multithreading (computer architecture);parallel computing;performance evaluation;profiling (computer programming);program optimization;programmer;software development;software performance testing;software transactional memory;thread (computing);unavailability	Milosz Ciznicki;Michal Kierzynka;Piotr Kopta;Krzysztof Kurowski;Pawel Gepner	2012		10.1016/j.procs.2012.04.208	computer architecture;parallel computing;real-time computing;computer science;operating system	HPC	-5.050207441793923	44.65561639968957	100864
8cbc758c3ec719c8e6698871be0ae3077c728b41	gpu acceleration of the wsm6 cloud microphysics scheme in grapes model	grapes;gpu computing;cuda;wsm6	The microphysical process that leads to cloud and precipitation formation is one of the most important physical processes in numerical weather prediction (NWP) and climate models. The Weather Research Forecast (WRF) Single Moment 6-class (WSM6) microphysics scheme in the Global/Regional Assimilation and Prediction System (GRAPES) includes predictive variables of water vapor, cloud water, cloud ice, rain, snow and graupel. The computation of WSM6 is the most time-consuming portion among that of the entire GRAPES model. In recent years, with the advent of the Compute Unified Device Architecture (CUDA), modern graphics processing units (GPUs) with the advantage of low-power, low-cost, and high-performance computing capacity have been exploited to accomplish the arithmetic operations in scientific and engineering simulations. In this paper, we present an implementation of the WSM6 scheme in GRAPES using GPU to accelerate the computation. After a brief introduction to the WSM6 scheme, the data dependence for the GPU implementation of the WSM6 scheme is discussed. The data parallel method is employed to exploit the massive fine-grained parallelism. The CUDA programming model is used to convert the original WSM6 module into GPU programs. To achieve high computational performance, mapping horizontal domain onto an optimal block size is proposed. The experimental results demonstrate that the GPU version obtains over 140x speedup compared with the CPU serial version, and is an efficient parallel implementation.	graphics processing unit	Huadong Xiao;Jing Sun;Xiaofeng Bian;Zhijun Dai	2013	Computers & Geosciences	10.1016/j.cageo.2013.06.016	parallel computing;simulation;computer science;theoretical computer science;general-purpose computing on graphics processing units	Crypto	-6.192523262846005	35.65031072316011	100957
de690a6a0dd3399787b2a64dc3eb122f773a93ef	auto-cfd: efficiently parallelizing cfd applications on clusters	message passing parallelizing compilers parallel programming;dependence analysis;computation fluid dynamics;parallel programming;computational fluid dynamics;parallel programming computational fluid dynamics message passing workstation clusters parallelising compilers;parallelising compilers;parallel computer;message passing;cost effectiveness;fortran;workstation clusters;image decomposition;parallel programs;computational fluid dynamics auto cfd cfd application parallelization parallel computing mpp boxes pre compiler fortran cfd sequential programs message passing parallel programs user directives parallelization dependency analysis mirror image decomposition self dependent field loops redundant synchronizations nonredundant synchronization	Computational Fluid Dynamics (CFD) applications are highly demanding for parallel computing. Many such applications have been shifted from expensive MPP boxes to cost-effective clusters. Auto-CFD is a pre-compiler which transforms Fortran CFD sequential programs to efficient message-passing parallel programs running on clusters. Our work has the following three unique contributions. First, this pre-compiler is highly automatic, requiring a minimum number of user directives for parallelization. Second, we have applied a dependency analysis technique for the CFD applications, called analysis after partitioning. We propose a mirror-image decomposition technique to parallelize self-dependent field loops that are hard to parallelize by existing methods. Finally, traditional optimizations of communication focus on eliminating redundant synchronizations. We have developed an optimization scheme which combines all the non-redundant synchronizations in CFD programs to further reduce the communication overhead. The Auto-CFD has been implemented on clusters and has been successfully used for automatically parallelizing structured CFD application programs. Our experiments show its effectiveness and scalability for parallelizing large CFD applications.	algorithm;automatic differentiation;automatic parallelization;compiler;computation;computational fluid dynamics;dependence analysis;directive (programming);experiment;fortran;goodyear mpp;mathematical optimization;message passing;overhead (computing);parallel computing;spmd;scalability	Li Xiao;Xiaodong Zhang;Zhengqian Kuang;Baiming Feng;Jichang Kang	2003		10.1109/CLUSTR.2003.1253298	computer architecture;parallel computing;message passing;cost-effectiveness analysis;computational fluid dynamics;computer science;theoretical computer science;operating system;programming language;dependence analysis	HPC	-11.873136693802696	37.87157022918546	101025
86a2bfb06c6cd91483d0603db9db07060824bccf	high-performance computing with graphics processing units for physics of complex systems			complex systems	Armin Seibert	2016				HPC	-7.3545080492449735	37.56449165396374	101068
8141c6e62c890102b3b32c91907fe5e870d847d0	supercomputing's exaflop target	energy consumption	The twin challenges of parallelism and energy consumption are enlivening supercomputersu0027 progress.	flops;parallel computing;supercomputer	Tom Geller	2011	Commun. ACM	10.1145/1978542.1978549	computer science	HPC	-8.76315756243453	42.70830061160163	101079
980065bc00b7bab200b0be57584c049471b3114c	dynamic distribution of workload between cpu and gpu for a parallel conjugate gradient method in an adaptive fem	conjugate gradient method	Abstract   The parallel preconditioned conjugate gradient method (CGM) is often used in adaptive FEMs and has a critical impact on the performance. This article proposes a method for dynamically balancing the computational load of this CGM between CPU and GPU. For the determination of the optimal balance of the computational load on CPU and GPU, an execution time model for the CGM is developed which considers the different execution speeds of the two kinds of processing units. The model relies on data-specific and machine-specific parameters which are both determined at runtime. The accuracy of the model is verified in experiments. This auto-tuning-based approach for CPU/GPU collaboration enables significant performance benefits compared to CPU-only or GPU-only execution.	central processing unit;conjugate gradient method;finite element method;graphics processing unit	Jens Lang;Gudula Rünger	2013		10.1016/j.procs.2013.05.193	parallel computing;real-time computing;computer hardware;computer science;cpu shielding	HPC	-4.852645663500477	40.58284811428013	101225
1a1f7a3ff261565a23c68db9a524e8f660017fce	programming with bsp homomorphisms	bulk synchronous parallelism;constructive algorithms;algorithmic skeletons;all nearest smaller values;sparse linear algebra	Algorithmic skeletons in conjunction with list homomorphisms play an important role in formal development of parallel algorithms. We have designed a notion of homomorphism dedicated to bulk synchronous parallelism. In this paper we derive two application using this theory: sparse matrix vector multiplication and the all nearest smaller values problem. We implement a support for BSP homomorphism in the Orléans Skeleton Library and experiment it with these two applications.	algorithmic skeleton;all nearest smaller values;ambiguous name resolution;bulk synchronous parallel;c++;expression templates;formal methods;library (computing);matrix multiplication;open shading language;parallel algorithm;parallel computing;sparse matrix;x86	Joeffrey Legaux;Zhenjiang Hu;Frédéric Loulergue;Kiminori Matsuzaki;Julien Tesson	2013		10.1007/978-3-642-40047-6_46	parallel computing;computer science;theoretical computer science;distributed computing;algorithmic skeleton	HPC	-10.072101019322437	40.55313076777347	101383
38255b8af4cd6387cb98ddd8d4cf48d690d42807	imperative bsplib-style communications in bsml		Bulk synchronous parallelism (BSP) offers a simple model of parallelism yet allows to take realistically into account the communication costs of parallel algorithms. BSPlib and its variants are programming libraries for the C language that support the BSP style. Bulk Synchronous Parallel ML (BSML) is a library for BSP programming with the functional language OCaml. BSML programs can be seen as sequential programs working on a parallel data structure (seq of par) while a BSPlib program is written in the SPMD style and understood as a parallel composition of communicating sequential programs (par of seq). The communication styles of BSML and BSPlib are also quite different. This paper shows that BSPlib-style communications can be implemented on op of BSML, withou the need to extend BSML parallel pr mitives.	application programming interface;bulk synchronous parallel;concurrent data structure;data (computing);experiment;functional programming;imperative programming;library (computing);message passing;ocaml;parallel algorithm;parallel computing;performance;spmd;usability	Frédéric Loulergue	2017		10.1016/j.procs.2017.05.267	programming language;bulk synchronous parallel;parallel computing;computer science;functional programming;parallel algorithm;spmd;data structure	PL	-13.692339282397203	39.27443314756697	101621
5d38454fd77adff50a45888464470f6cfb8a295c	towards the optimal synchronization granularity for dynamic scheduling of pipelined computations on heterogeneous computing systems	dynamic load balancing;performance evaluation;notere;heterogeneous systems;pipelined computations;communication model;software architecture;synchronization;performance prediction;distributed systems;loops with data dependencies;inter processor communication	ANTHONY THEODORE CHRONOPOULOS CITATIONS FOR H-INDEX Citations for 29 publications, which are used to compute the author h-index=29 (This list also contains some self-citations, only if needed to compute the h-index) Publications accessible at: www.cs.utsa.edu/faculty/atc Please reference our publications, if they are relevant to your research (Sources: Citeseer, google, MathScinet, proQuest, scopus, web-of-science)	citeseerx;computation;heterogeneous computing;scheduling (computing);scopus	Ioannis Riakiotakis;Florina M. Ciorba;Theodore Andronikos;George K. Papakonstantinou;Anthony T. Chronopoulos	2012	Concurrency and Computation: Practice and Experience	10.1002/cpe.2812	synchronization;software architecture;parallel computing;real-time computing;models of communication;computer science;operating system;database;distributed computing;data synchronization;synchronization	Theory	-8.891946986633458	43.45725390806684	101724
ef68139d7334e367384d35e992b7f89ab3017d01	automatic generation of parallel c code for stencil applications written in matlab	openacc;high performance computing;message passing interface;openmp;stencil applications;matlab;source to source compiler	High-level programming languages such as MATLAB are widely used in scientific domains to implement prototypes based on mathematical models. These prototypes are finally often re-implemented in low-level languages to reach execution times required for the operational use. In order to exploit latest hardware architectures additional effort is necessary to add parallelism to the applications. This paper presents performance results of an automatic translation from a MATLAB subset into efficient parallelized C code for different architectures: multicores, compute clusters, and GPGPUs. We present the first compiler that generates native MPI code from MATLAB source and thereby showing significant performance improvements. The evaluation is done for two stencil applications which use different communication patterns, a Game-of-Life application and a Tsunami simulation. For the Game-of-Life application, the generated parallel code shows nearly optimal speedup. The generated parallel code of the Tsunami simulation reaches the performance of the available parallel reference implementations.	application programming interface;code generation (compiler);compiler;computer cluster;conway's game of life;distributed memory;dynamic data exchange;general-purpose computing on graphics processing units;high- and low-level;image scaling;matlab;machine translation;mathematical model;message passing interface;multi-core processor;openacc;openmp;overhead (computing);parallel computing;parallel programming model;programming language;prototype;run time (program lifecycle phase);simulation;speedup;symmetric multiprocessing;unified parallel c (upc);video card	Johannes Spazier;Steffen Christgau;Bettina Schnor	2016		10.1145/2935323.2935329	computer architecture;parallel computing;computer science;programming language	HPC	-6.292531170232842	43.32651437548351	101793
540d3c8fe9935072798cdec369a36b5cfd558770	data type transformation in heterogeneous shared memory multiprocessors	distributed system;evaluation performance;architecture systeme;systeme reparti;shared memory;performance evaluation;multiprocessor;memoria compartida;evaluacion prestacion;data type;sistema repartido;unite traitement;modificacion;arquitectura sistema;multiprocesador;system architecture;memoire partagee;modification;shared memory multiprocessor;multiprocesseur	A heterogeneous shared memory multiprocessor, which contains different types of specialized processors, may execute a complex problem faster than either a homogeneous multiprocessor or a heterogeneous network. However, since dissimilar processors often use different representations for primitive data types, the shared data must be transformed. Analytical performance models and queueing models predict the performance of alternative designs for the transformation of shared data. These models indicate that significant performance advantages are provided by hardware transformation units, caching of unshared data, and local memory. Conversely, caching of shared data and the location of the transformation units have a less significant effect on performance. The primary applications for these type of designs are in special-purpose applications that require maximum performance and tight coupling between heterogeneous processors. The linking that must be done at compile time makes these designs less suited for general-purpose applications and development work.	shared memory	Michael W. Strevell;Harvey G. Cragon	1991	J. Parallel Distrib. Comput.	10.1016/0743-7315(91)90021-Z	distributed shared memory;shared memory;embedded system;parallel computing;real-time computing;multiprocessing;distributed memory;data type;computer science;operating system;distributed computing;symmetric multiprocessor system;systems architecture	HPC	-15.11648757109454	44.07618675781217	101803
656ae33636855005b979eb9045768d530ac01150	towards full prolog on a distributed architecture	tratamiento paralelo;distributed memory;symbolic computation;systeme multiprocesseur memoire repartie;traitement parallele;logical programming;calculo simbolico;search trees;side effect;programmation logique;sistema multiprocesador memoria distribuida;distributed memory multiprocessor system;programacion logica;calcul symbolique;parallel processing;distributed architecture	This paper presents an implementation of some essential side-effects of Prolog: cut and findall, on a distributed memory system. Although the techniques proposed herein are valid for any distributed memory implementation, they are advantageous in those based on recomputation, such as PDP (Prolog Distributed Processor), a model for Independent-AND/OR parallel execution of Prolog. The key idea to implement the cut predicate is to exploit as much parallelism as possible, but in such a way that the computation of a branch of the search tree which cannot be pruned by a cut is never delayed to control computations depending on a cut, (i.e. to analyze the pruning of the branch of these computations and to kill them). The model proposed for the findall predicate reduces the communication as much as possible.	distributed computing;prolog	Lourdes Araujo	1997		10.1007/BFb0002870	parallel processing;parallel computing;symbolic computation;distributed memory;computer science;theoretical computer science;operating system;database;distributed computing;programming language;side effect;algorithm	Arch	-17.53542758476133	40.254652371090344	101853
69faa6a307275f5087708f35fa632f0d0327433d	distributed problem solving: a universal computer architecture	computer architecture		computer architecture;problem solving	Victor Alves;Abílio Ribeiro;José Neves	1993			theoretical computer science;computational science;space-based architecture;computer science	Arch	-10.14939786041115	40.79424882746487	101877
4edffce8874da2ff248be73a71c54b891eb8de7b	advanced optimistic approaches in logic simulation	virtual time paradigm;protocols;logic simulation;high level system simulation;predictive time warp;waiting periods;virtual time paradigma;distributed logic simulation;circuit optimisation;optimistic synchronization mechanism;roll-back frequency;advanced optimistic approach;implementation time warp;ptw synchronization approach;roll-back probability;digital simulation;classical time warp;certain period;forecast events;high level synthesis;synchronisation;probability;optimistic logical process;optimistic logical processes;data structures;information technology;logic;discrete event simulation;predictive models;engines;history	This paper presents the optimistic synchronization mechanism Predictive Time Warp (PTW) based on the implementation Time Warp of the Virtual Time paradigma for use in the simulation of electronic systems and high level system simulation. In comparison to most existing approaches extending and improving classical Time Warp, the aim of this development was to reduce the roll- back frequency of optimistic logical processes without imposing waiting periods. Part of PTW is the introduction of forecast events predicting a certain period in the future and thus reduce the rollback probability. On the example of a distributed logic simulation the benefit of the PTW synchronization approach is shown.	dynamic time warping;high-level programming language;logic simulation	Stefan Schmerler;Yankin Tanurhan;Klaus D. Müller-Glaser	1998			real-time computing;simulation;computer science;theoretical computer science;discrete event simulation;logic simulation;probability;information technology;logic	OS	-13.503627728662204	42.44279136418118	102065
a829a5c1f0930c0f787dc93eb34f48a8fb3a1ad8	algorithm design and analysis using the wpram model	parallel computing;software portability parallel programming;software portability;convergence;costing;performance analysis wpram model parallel computing portable software bsp model shared queue data type;parallel programming;computer industry;shared queue data type;wpram model;parallel systems;programming profession;portable software;performance analysis;parallel computer;software algorithms;bsp model;algorithm design and analysis costs queueing analysis parallel processing costing software algorithms performance analysis programming profession computer industry convergence;algorithm design;algorithm design and analysis;parallel processing;queueing analysis	The takeup of parallel computing has been hampered by the lack of portable software. The BSP model allows the design of portable code for regular computations. This paper describes the use of the WPRAM model to support more irregular problems. A shared queue data type is described, which provides predictable and scalable performance characteristics. The queue can be used to structure the sharing of data in a parallel system, resulting in code which is portable and amenable to performance analysis.	algorithm design;computation;parallel computing;scalability	Jonathan M. Nash	1997		10.1109/HIPS.1997.582965	parallel processing;algorithm design;computer architecture;parallel computing;computer science;operating system;distributed computing;programming language	HPC	-11.719384349083807	41.458996713743524	102709
04c5bfe74a4c68379a623b039d59f244b091f7a7	design and microprogramming of bit-sequential processors for parallel systems	parallel systems		microcode	Václav Dvorák	1987	Elektronische Informationsverarbeitung und Kybernetik		computer science	Arch	-9.820900853999131	42.54615192246101	102724
ddbb4d83baea251e219664b5cb521076f9722e88	large-eddy simulations on distributed shared memory clusters	simulation grande echelle;gas turbine engine;distributed memory;largeur bande;cluster computing;haute performance;motor gas;network bandwidth;benchmark;racimo calculadura;memoria compartida;turbina gas;memoria virtualmente compartida;computation fluid dynamics;distributed computing;turbulent combustion;combustion turbulente;gas engine;large eddy simulation;computational fluid dynamics;memoire virtuellement partagee;computer architecture;gas turbine;grappe calculateur;computational fluid dynamics cfd;distributed memory computing;moteur gaz;large eddy simulation les;anchura banda;symmetric multi processor;cluster system;benchmarks;alto rendimiento;calculo repartido;bandwidth;multiprocesseur parallele;turbine gaz;memoire repartie;mecanique fluide numerique;parallel performance benchmarks;mecanica fluido numerica;distributed shared memory;high performance;memory bandwidth;calcul reparti;combustion turbulenta;simulacion les	The practicality of Large-eddy simulation (LES) of turbulent combustion, as is found in gas turbine engines, on clusters of commodity PC-based symmetric multi-processor (SMP) systems in 2-, 4-, and 8-way configurations has been investigated. Bandwidth demands from both memory and networking in the benchmark LES algorithm are shown to the primary performance inhibitors. Contention in the various SMP architectures tested is shown to compound these two hardware limitations. To investigate the ability of the parallel clustered systems, low-level hardware studies are conducted in conjunction with bench-marking of the LES application. The hardware tests focus on memory and communication contention under loads found in the LES algorithm. For comparison, the benchmarks are also applied to two industry leading high-performance super-computing architectures. It is found that contention in the 4and 8-way SMP architecture studied here limits their applicability while the 2-way systems shows competitive performance and speed-up compared to its industry counterparts. It is concluded that design-level combustion LES on clusters of commodity hardware, when equipped with sufficient memory and communication bandwidth, are a viable substitute for more expensive super-computing platforms. © 2004 Elsevier Inc. All rights reserved.	algorithm;benchmark (computing);central processing unit;commodity computing;computer cluster;distributed shared memory;gigabit;high- and low-level;image scaling;internet protocol suite;item unique identification;large eddy simulation;limiter;memory bandwidth;network switch;supercomputer;symmetric multiprocessing;turbulence;web ontology language	Christopher P. Stone;Suresh Menon	2004	J. Parallel Distrib. Comput.	10.1016/j.jpdc.2004.08.001	distributed shared memory;embedded system;parallel computing;simulation;distributed memory;benchmark;computational fluid dynamics;computer cluster;computer science;memory bandwidth;bandwidth;large eddy simulation	HPC	-16.389871145799198	43.264529510102676	102728
e3537d184dc1a8ca2b4e8d63164721f67dd48685	thread migration and load-balancing in heterogeneous environments	developpement logiciel;scientific application;distributed memory systems;programacion paralela;heterogeneous environment;parallel programming;optimizacion compiladora;thread migration;software distributed shared memory;computer architecture;systeme memoire repartie;shared memory systems;architecture ordinateur;desarrollo logicial;compiler optimization;software development;network of workstation;load balance;arquitectura ordenador;optimisation compilateur;parallel applications;systeme memoire partagee;programmation parallele	"""Networks of workstations are fast becoming the standard environment for parallel applications. However, the use of """"found"""" resources as a platform for tightly-coupled runtime environments has at least three obstacles: contention for resources, differing processor speeds, and processor heterogeneity. All three obstacles result in load imbalance, leading to poor performance for scientific applications. This paper describes the use of thread migration in transparently addressing this load imbalance in the context of the CVM software distributed shared memory system. We describe the implementation and performance of mechanisms and policies that accommodate both resource contention, and heterogeneity in clock speed and processor type. Our results show that these cycles can indeed be effectively exploited, and that the runtime cost of processor heterogeneity can be quite manageable. Along the way, however, we identify a number of problems that need to be addressed before such systems can enjoy widespread use."""	load balancing (computing);process migration;thread pool	Kritchalach Thitikamol;Peter J. Keleher	2000		10.1007/3-540-40889-4_20	parallel computing;real-time computing;computer science;load balancing;software development;operating system;optimizing compiler;database;distributed computing;programming language	HPC	-16.3980441927574	42.85206772759332	102975
31a66d0efbc1ce6460bc6e4093d1b5e850328ace	parallel computation of optical flow	parallel algorithm;distributed computing;gigabit ethernet;parallel computer;optical flow	  This paper describes a new parallel algorithm to compute the optical flow of a video sequence. A previous sequential algorithm  has been distributed over a cluster. It has been implemented in a cluster with 8 nodes connected by means of a Gigabit Ethernet.  On this architecture, the algorithm, that computes the optical flow of every image on the sequence, is able of processing  10 images of 720 × 576 pixels per second.    	computation;optical flow;parallel computing	Antonio García Dopico;Miguel V. Correia;Jorge A. Santos;Luís Miguel Nunes	2004		10.1007/978-3-540-30126-4_49	parallel computing;parallel optical interface;ethernet flow control;computer science;theoretical computer science;massively parallel;optical flow;distributed computing;parallel algorithm;network interface controller	Vision	-10.802545817169586	42.96272038188063	103140
b41e66475bc25142e86e35257a59e8d4a8c0cd33	the possibility of fast large-scale numerical simulation implemented with graphics processing units	parallel computing;finite volume method;nvidia geforce gtx 280;high resolution;paper;powerful graphics processor;travelling shock waves;computer graphic equipment;gpu;shock wave;nvidia gtx280;coprocessors;fast large scale numerical simulation implemention;cuda;numerical analysis computer graphic equipment coprocessors;large scale;numerical analysis;graphics processing unit mathematical model instruction sets equations graphics central processing unit numerical simulation;graphics processing units;double precision floating number;graphics processors;parallel computer;parallel computing gpu cuda euler equation finite volume shock wave;mathematical model;core 2 duo e8500 system fast large scale numerical simulation implemention graphics processing units powerful graphics processor nvidia gtx280 double precision floating number euler equation travelling shock waves;nvidia;graphic processing unit;fluid dynamics;computer science;core 2 duo e8500 system;graphics processing unit;finite volume;graphics;central processing unit;instruction sets;numerical simulation;euler equation	The main purpose of this paper is to demonstrate how we make use of the powerful graphics processor, NVIDIA GTX280, in numerical simulation with the support of double precision floating number. Apply the finite volume method in simulating the Euler equation, two well-known examples for travelling shock waves were examined in high resolution. We had achieved at best 878 times faster than a Core 2 Duo E8500 system as one core used. Beside that, the potential of multi-GPU parallelism in large-scale model is also been exhibited.	central processing unit;computer simulation;double-precision floating-point format;euler;finite volume method;geforce 200 series;geometric modeling;gigabyte;graphics hardware;graphics processing unit;image resolution;job stream;list of intel core 2 microprocessors;numerical integration;parallel computing;solver;springer (tank)	Chi-Jer Yu;Chii-Tung Liu	2010	International Symposium on Parallel and Distributed Processing with Applications	10.1109/ISPA.2010.37	computational science;parallel computing;computer hardware;computer science;operating system;finite volume method;fluid dynamics	Arch	-5.512984272624598	36.70504465947833	103147
407ffbd4d00bc20a74760eeb8865adf6b0cb761d	high-performance parallel computations using python as high-level language	code development;high level languages;high performance computations;python;productivity	High-performance and parallel computations have always represented a challenge in terms of code optimization and memory usage, and have typically been tackled with languages that allow a low-level management of resources, like Fortran, C and C++. Nowadays, most of the implementation effort goes into constructing the bookkeeping logic that binds together functionalities taken from standard libraries. Because of the increasing complexity of this kind of codes, it becomes more and more necessary to keep it well organized through proper software engineering practices. Indeed, in the presence of chaotic implementations, reasoning about correctness is difficult, even when limited to specific aspects like concurrency; moreover, due to the lack in flexibility of the code, making substantial changes for experimentation becomes a grand challenge. Since the bookkeeping logic only accounts for a tiny fraction of the total execution time, we believe that for such a task it can be afforded to introduce an overhead due to a high-level language. We consider Python as a preliminary candidate with the intent of improving code readability, flexibility and, in turn, the level of confidence with respect to correctness. In this study, the bookkeeping logic of SMP-MRRR, a C & Fortran highly optimized multi-core eigensolver, is ported to Python. We report here on the porting process and on the pros and cons of using a high-level language in a high-performance parallel library.	c++;chaos theory;code;computation;computational science;computer programming;concurrency (computer science);correctness (computer science);deadlock;eigenvalue algorithm;fortran;global interpreter lock;grand challenges;high- and low-level;high-level programming language;human-readable medium;library (computing);mathematical optimization;multi-core processor;overhead (computing);parallel algorithm;program optimization;python;run time (program lifecycle phase);software engineering;standard library	Stefano Masini;Paolo Bientinesi	2010		10.1007/978-3-642-21878-1_66	productivity;parallel computing;python;computer science;theoretical computer science;operating system;database;distributed computing;programming language	PL	-12.731341232903482	38.70697193803408	103273
f7e19a7a316e8564bd54f1b5ca021abfd1d2b42f	further improving the scalability of the scalasca toolset	scalasca;juser;websearch;scalability;publications database	Scalasca is an open-source toolset that can be used to analyze the performance behavior of parallel applications and to identify opportunities for optimization. Target applications include simulation codes from science and engineering based on the parallel programming interfaces MPI and/or OpenMP. Scalasca, which has been specifically designed for use on large-scale machines such as IBM Blue Gene and Cray XT, integrates runtime summaries suitable to obtain a performance overview with in-depth studies of concurrent behavior via event tracing. Although Scalasca was already successfully used with codes running with 294,912 cores on a 72-rack Blue Gene/P system, the current software design shows scalability limitations that adversely affect user experience and that will present a serious obstacle on the way to mastering larger scales in the future. In this paper, we outline how to address the two most important ones, namely the unification of local identifiers at measurement finalization as well as collating and displaying analysis reports.	acm/ieee supercomputing conference;algorithm;arnold;assignment zero;benchmark (computing);blue gene;bus mastering;code;computation;concurrent computing;connectionism;data model;donald becker;dynamic loading;graphical user interface;ibm personal computer xt;identifier;international journal of high performance computing applications;international parallel and distributed processing symposium;labeled security protection profile;mathematical optimization;message passing interface;microsoft outlook for mac;multicast;open-source software;openmp;p system;parallel computing;parallel processing (dsp implementation);profiling (computer programming);realms of the haunting;scalability;simulation;software design;software release life cycle;speedup;springer (tank);strategic computing initiative;system of measurement;ti advanced scientific computer;unification (computer science);user experience;xml	Markus Geimer;Pavel Saviankou;Alexandre Strube;Zoltán Szebenyi;Felix Wolf;Brian J. N. Wylie	2010		10.1007/978-3-642-28145-7_45	parallel computing;real-time computing;scalability;computer science;theoretical computer science;operating system;programming language;algorithm	HPC	-9.795773795975126	41.068865901295325	103420
0ba237584104897f2bb45b872d5ecf18657f20ad	abstract interpretation of pic programs through logic programming	microcontrollers;high level languages;toconference;memory management;performance evaluation;software libraries;program transformation;linear constraint;logic programming;programming profession;partial evaluation;performance analysis;performance gain;program analysis;computer science;logic programs;abstract interpretation;convex hull;logic programming performance analysis microcontrollers programming profession computer science high level languages performance evaluation performance gain software libraries memory management	A logic based general approach to abstract interpretation of low-level machine programs is reported. It is based on modelling the behavior of the machine as a logic program. General purpose program analysis and transformation of logic programs, such as partial evaluation and convex hull analysis, are applied to the logic based model of the machine. A small PIC microcontroller is used as a case study. An emulator for this microcontroller is written in Prolog, and standard programming transformations and analysis techniques are used to specialise this emulator with respect to a given PIC program. The specialised emulator can now be further analysed to gain insight into the given program for the PIC microcontroller. The method describes a general framework for applying abstractions, illustrated here by linear constraints and convex hull analysis, to logic programs. Using these techniques on the specialised PIC emulator, it is possible to obtain constraints on and linear relations between data registers, enabling detection of for instance overflows, branch conditions and so on.	abstract interpretation;convex hull;emulator;high- and low-level;logic programming;pic microcontroller;partial evaluation;program analysis;prolog	Kim S. Henriksen;John P. Gallagher	2006	2006 Sixth IEEE International Workshop on Source Code Analysis and Manipulation	10.1109/SCAM.2006.1	program analysis;microcontroller;real-time computing;computer science;theoretical computer science;convex hull;software engineering;programming language;logic programming;partial evaluation;high-level programming language;memory management	PL	-18.268759753826423	34.24459554516085	103479
3828629d23b6a4a36168b1b02f1de1521306b5ee	specification of inefficiency patterns for mpi-2 one-sided communication	parallelisme;distributed system;algoritmo paralelo;data transmission;remote access;programa paralelo;evaluation performance;lien hypertexte;systeme reparti;acceso remoto;parallel algorithm;storage access;performance evaluation;collective communication;point to point;enlace hipertexto;evaluacion prestacion;communicating process;acces a distance;distributed computing;hyperlink;abstraction;ejecucion programa;program verification;abstraccion;analisis automatico;program execution;analisis programa;algorithme parallele;proceso comunicante;synchronisation;performance programme;verificacion programa;parallelism;automatic analysis;sistema repartido;paralelismo;synchronization;execution programme;transmission donnee;envoi message;processus communicant;acces memoire;performance analysis;message passing;analyse automatique;acceso memoria;calculo repartido;eficacia programa;sincronizacion;program analysis;program performance;spatial relationships;remote memory access;analyse programme;parallel programs;verification programme;parallel program;calcul reparti;transmision datos;data transfer;programme parallele	Automatic performance analysis of parallel programs can be accomplished by scanning event traces of program execution for pa tterns representing inefficient behavior. The temporal and spatial relationshi p between individual runtime events recorded in the event trace allow the recogni ti n of wait states as a result of suboptimal parallel interaction. In our earlier work [1], we have shown how patterns related to MPI point-to-point and collective communication can be easily specified using common abstractions that represent e x cution-state information and links between related events. In this article, we present new abstractions targeting remote memory access (also referred to as on eided communication) as defined in theMPI-2 standard. We also describe how the general structure of these abstractions differs from our earlier work to a ccommodate the more complicated sequence of data-transfer and synchronizatio n operations required for this type of communication. To demonstrate the benefits o f our methodology, we specify typical performance properties related to one-s id d communication.	complex systems;computer data storage;distributed memory;epoch (reference date);message passing interface;pa-risc;parallel computing;point-to-point protocol;programmer;prototype;relevance;revolution in military affairs;synchronization (computer science);test suite;titanium nitride;tracing (software);wait state	Andrej Kühnal;Marc-André Hermanns;Bernd Mohr;Felix Wolf	2006		10.1007/11823285_6	synchronization;real-time computing;simulation;telecommunications;computer science;distributed computing;data transmission	HPC	-16.914422172160368	41.93623315818274	103590
a00b149d7679cf78c71b53a3fb7060ee06a2ff13	traffic analysis in a double grain dataflow array processor	trafic;densite;producto matriz;gollete estrangulamiento;flot donnee;trafico;densidad;procesador panel;flujo datos;array processor;analyse;processeur tableau;dataflow architecture;goulot etranglement;communication overhead;traffic;traffic analysis;analysis;density;data flow;produit matrice;bottleneck;matrix product;analisis	One of the main problems of Dataflow architecture is the high communication overhead. This paper is dedicated to estimation of traffic densities in the communication links of a proposed Dataflow machine having a double grain array architecture. Results show a distinct advantage of it over existing Dataflow machines so far as communication bottlenecks are concerned. The machine however, is not infinitely scaleable.	array processing;dataflow;traffic analysis;vector processor	S. Bhattacharya;M. Nasipuri	2000	Journal of Systems Architecture	10.1016/S1383-7621(98)00059-9	dataflow architecture;embedded system;parallel computing;real-time computing;computer science;signal programming;analysis	Arch	-15.29732039869351	43.79628997809719	103665
d1acad7e17343b69d3347cdb323e8fe5813b5438	pynetlogo: linking netlogo with python		Methods for testing and analyzing agent-based models have drawn increasing attention in the literature, in the context of efforts to establish standard frameworks for the development and documentation of models. This process can benefit from the use of established software environments for data analysis and visualization. For instance, the popular NetLogo agent-based modelling software can be interfaced with Mathematica and R, letting modellers use the advanced analysis capabilities available in these programming languages. To extend these capabilities to an additional user base, this paper presents the pyNetLogo connector, which allows NetLogo to be controlled from the Python general-purpose programming language. Given Pythonâ€™s increasing popularity for scientific computing, this provides additional flexibility for modellers and analysts. PyNetLogoâ€™s features are demonstrated by controlling one of NetLogoâ€™s example models from an interactive Python environment, then performing a global sensitivity analysis with parallel processing.	agent-based model;computational science;general-purpose programming language;netlogo;parallel computing;python;r language;suicidegirls;warez;wolfram mathematica	Marc Jaxa-Rozen;Jan H. Kwakkel	2018	J. Artificial Societies and Social Simulation	10.18564/jasss.3668	documentation;management science;visualization;software;computer science;netlogo;parallel processing;python (programming language);computational science	HPC	-10.260262293963219	36.33250677266511	103709
740273773307d62efdef1a63d1bcda6d0ffb30d6	the path to scalable distributed quantum computing	microarchitecture;anyons;quantum dots;scalable architectures;superconductors;quantum networks;distributed memory multicomputers;topological coding;ion tracking;quantum processing;quantum processors;quantum computing;hardware	Researchers are fabricating quantum processors powerful enough to execute small instances of quantum algorithms. Scalability concerns are motivating distributed-memory multicomputer architectures, and experimental efforts have demonstrated some of the building blocks for such a design. Numberous systems are emerging with the goal of enabling local and distributed quantum computing.	central processing unit;distributed memory;parallel computing;quantum algorithm;quantum computing;scalability	Rodney Van Meter;Simon J. Devitt	2016	Computer	10.1109/MC.2016.291	parallel computing;quantum information;quantum information science;microarchitecture;computer science;theoretical computer science;quantum network;distributed computing;quantum dot;topological quantum computer;superconductivity;quantum computer;one-way quantum computer	Arch	-8.391177721095433	41.44792762718849	103797
9b40f0f39628578699baae9a3b39952191029060	paramedir: a tool for programmable performance analysis	application development;scientific application;programming paradigm;hardware architecture;computer programs;performance metric;computer programming;programmers;performance analysis;performance prediction;reliability analysis;architecture computers;time functions	Performance analysis of paallel scientific applications is time consuming and requires great expertise in areas such as programming paradigms, system software, and computer hardware architectures. In this paper we describe a tool that facilitates the programmability of performance metric calculations thereby allowing the automation of the analysis and reducing the application development time. We demonstrate how the system can be used to capture knowledge and intuition acquired by advanced parallel programmers in order to be transferred to novice users.	computer hardware;profiling (computer programming);programmer;programming paradigm	Gabriele Jost;Jesús Labarta;Judit Giménez	2004		10.1007/978-3-540-24685-5_67	computer architecture;computer science;hardware architecture;computer programming;programming paradigm;symbolic programming;programming language;computer network programming	HPC	-8.254188799309569	45.490964779267316	103935
02c54805642c871819d029f7437d525048045e08	on the parallel elliptic single/multigrid solutions about aligned and nonaligned bodies using the virtual machine for multiprocessors	parallel implementation;parallel application;shared memory;virtual machine;parallel program writing;message-passing case;theshared-memory case;target multiprocessors;memory multiprocessor;multigrid solution;memory multiprocessors;nonaligned case;nonaligned body	Parallel elliptic single/multigrid solutions around an aligned andnonaligned body are presented and implemented on two multi-user andsingle-user shared memory multiprocessors (Sequent Symmetry andMOS) and on a distributed memory multiprocessor (a Transputernetwork). Our parallel implementation uses the Virtual Machine forMuli-Processors (VMMP), a software package that provides a coherentset of services for explicitly parallel application programsrunning on diverse multiple instruction multiple data (MIMD)multiprocessors, both shared memory and message passing. VMMP isintended to simplify parallel program writing and to promoteportable and efficient programming. Furthermore, it ensures highportability of application programs by implementing the sameservices on all target multiprocessors. The performance of ouralgorithm is investigated in detail. It is seen to fit well theabove architectures when the number of processors is less than themaximal number of grid points along the axes. In general, theefficiency in the nonaligned case is higher than in the alignedcase. Alignment overhead is observed to be up to 200% in theshared-memory case and up to 65% in the message-passing case. Wehave demonstrated that when using VMMP, the portability of thealgorithms is straightforward and efficient.	multigrid method;virtual machine	Amir Averbuch;Eran Gabber;Samuel Itzikowitz;Barack Shoham	1994	Scientific Programming		computer architecture;parallel computing;computer science;virtual machine;operating system;distributed computing;programming language	HPC	-6.446409614891787	42.818091870742435	104093
685cd26a0b4b39ea7998cd66997e707d8a9eebd2	performance modeling and optimization framework for space-time adaptive processing (stap)	optimisation;performance evaluation;building block;optimization framework;prototypes;optimal method;minimization methods;cots pc cluster;parallel systems;radar processing algorithm;signal processing;adaptive signal detection;performance model;pc cluster;clustering algorithms;clustering algorithms spaceborne radar minimization methods radar signal processing signal processing interference cancellation radar detection adaptive signal detection parallel processing prototypes;parallel machines;radar detection;parallel system;workstation clusters parallel machines performance evaluation optimisation;workstation clusters;heuristic approach;execution time model;cots pc cluster performance modeling optimization framework space time adaptive processing radar processing algorithm heuristic approach optimal method parallel system execution time model;performance modeling;radar signal processing;interference cancellation;parallel processing;spaceborne radar;space time adaptive processing	Summary form only given. Fully-adaptive space-time adaptive processing (STAP) is an optimal but impractical radar processing algorithm due to the overwhelming number of operations required. Hence, many different heuristic approaches are sought to approximate the optimal method with fewer number of operations. We introduce a framework for prototyping various STAP methods on a parallel system: describing STAP methods, building execution time models for basic building blocks, and using these models to automatically optimize performance of the algorithms. We also present the performance results from a COTS PC cluster.	approximation algorithm;computer cluster;heuristic;mathematical optimization;profiling (computer programming);run time (program lifecycle phase);space-time adaptive processing	Kyusoon Lee;Adam W. Bojanczyk	2004	18th International Parallel and Distributed Processing Symposium, 2004. Proceedings.	10.1109/IPDPS.2004.1303308	embedded system;parallel processing;single antenna interference cancellation;parallel computing;real-time computing;space-time adaptive processing;computer science;signal processing;prototype;cluster analysis	HPC	-11.625039156626672	37.87381960868294	104132
29d4569c6074c89a42dfbe6952a2232bb17e765a	individual-oriented model crowd evacuations distributed simulation☆	mpi	Emergency plan preparation is an important problem in building design to evacuate people as fast as possible. Simulation exercises as fire drills are not a realistic situation to understand people behaviour. In the case of crowd evacuations the complexity and uncertainty of the systems increases. Computer simulation allows us to run crowd dynamics models and extract information from emergency situations. Several models solve the emergency evacuation problem. Individual oriented modelling allows to give behaviour rules to the individual and simulate interactions between them. Due to variation on the emergency situations results have to be statistically reliable. This reliability increases the computing demand. Distributed and parallel paradigms solve the performance problem. In the present work we present a crowd evacuations distributed simulator. We implemented two versions of the model. One using Netlogo and another using C with MPI. We chose a real environment to test the simulator: pavilion 2 of Fira de Barcelona building, able to hold thousands of persons. The distributed simulator was tested with 62,820 runs in a distributed environment with 15,000 individuals. In this work we show how the distributed simulator has a linear speedup and scales efficiently.	computer simulation;crowdsourcing;federation of international robot-soccer association;interaction;message passing interface;netlogo;speedup	Albert Gutierrez-Milla;Francisco Borges;Remo Suppi;Emilio Luque	2014		10.1016/j.procs.2014.05.145	simulation;artificial intelligence;operations research	HPC	-6.9386855463650825	33.8593308426428	104205
5b5792bda4d975374401c281ef08da464c0e368e	fleng prolog - the language which turns supercomputers into parallel prolog machines	language use;parallel computer architecture;logic programs	This paper suggests a new way of executing logic programming languages, using small-grain parallelism on vector parallel computer architectures. The main topic is the general purpose language FLENG Prolog. This is a logic programming language for arbitrary architectures, but is especially designed to run efficiently on vector architectures. The most important contribution of the paper is the described combination of the language FLENG Prolog with vector architectures.	prolog;supercomputer	Martin Nilsson;Hidehiko Tanaka	1986		10.1007/3-540-18024-9_32	computer architecture;computer science;theoretical computer science;programming language	Arch	-13.33967348554712	38.4579571865272	104501
d62f7a0da086492eb36c2646c77f957423f63c13	evolving gpu machine code	genetic programming;machine code;graphics processing units	Parallel Graphics Processing Unit (GPU) implementations of GP have appeared in the literature using three main methodologies: (i) compilation, which generates the individuals in GPU code and requires compilation; (ii) pseudo-assembly, which generates the individuals in an intermediary assembly code and also requires compilation; and (iii) interpretation, which interprets the codes. This paper proposes a new methodology that uses the concepts of quantum computing and directly handles the GPU machine code instructions. Our methodology utilizes a probabilistic representation of an individual to improve the global search capability. In addition, the evolution in machine code eliminates both the overhead of compiling the code and the cost of parsing the program during evaluation. We obtained up to 2.74 trillion GP operations per second for the 20-bit Boolean Multiplexer benchmark. We also compared our approach with the other three GPU-based acceleration methodologies implemented for quantum-inspired linear GP. Significant gains in performance were obtained.	assembly language;benchmark (computing);compiler;flops;graphics processing unit;machine code;multiplexer;overhead (computing);parsing;quantum computing	Cleomar Pereira da Silva;Douglas Mota Dias;Cristiana Bentes;Marco Aurélio Cavalcanti Pacheco;Leandro F. Cupertino	2015	Journal of Machine Learning Research		dead code;genetic programming;computer architecture;parallel computing;machine code;computer science;theoretical computer science;machine learning;code generation;unreachable code;source code	HPC	-16.68188854607024	35.940467728357056	104627
924ada84103804d88701ed257e2afd1d7ede75fc	transformations source-à-source pour l'optimisation de codes irréguliers et multithreads. (source-to-source transformations for irregular and multithreaded code optimization)			code;mathematical optimization;program optimization;thread (computing)	Julien Jaeger	2012				PL	-17.135371044989203	39.48681590444529	104715
a5f0e22746054535f0314e8d7c00967f509fab2e	ccl: a portable and tunable collective communication library for scalable parallel computers	software portability;point to point communication model ccl tunable collective communication library scalable parallel computers programming interface software portability ibm 9076 scalable powerparallel system 1 performance semantics;collective communication;point to point;communication model;design and implementation;parallel computer;computer communications software;parallel processing computer communications software software portability;caltech library services;parallel applications;parallel processing;libraries concurrent computing portable computers broadcasting application software parallel programming scattering computer interfaces runtime algorithm design and analysis	A collective communication library for parallel computers includes frequently used operations such as broadcast, reduce, scatter, gather, concatenate, synchronize, and shift. Such a library provides users with a convenient programming interface, efficient communication operations, and the advantage of portability. A library of this nature, the Collective Communication Library (CCL), intended for the line of scalable parallel amputer products by IBM, has been designed. CCL is pact of the parallel application programming interface of the recently announced IBM 9076 Scalable POWERparallel System 1 (SP1). In this paper, we examine several issues related to the functionality, correctness, and performance of a portable collective communication library while focusing on three novel aspects in the design and implementation of CCL: 1) the introduction of process groups, 2) the definition of semantics that ensures correctness, and 3) the design of new and tunable algorithms based on a realistic point-to-point communication model.	algorithm;application programming interface;computer;concatenation;correctness (computer science);ibm scalable powerparallel;parallel computing;point-to-point protocol;point-to-point (telecommunications);scalability	Vasanth Bala;Shlomo Kipnis;Marc Snir;Jehoshua Bruck;Robert Cypher;Pablo Elustondo;Alex Ho;C. T. Howard Ho	1994		10.1109/IPPS.1994.288208	parallel computing;computer science;theoretical computer science;distributed computing	HPC	-11.205889646924973	45.267918032743246	104741
336b1d25d8a170412839a24a22c157a4f9493556	a layout-oriented routing method for low-latency hpc networks			routing	Ryuta Kawano;Hiroshi Nakahara;Ikki Fujiwara;Hiroki Matsutani;Michihiro Koibuchi;Hideharu Amano	2017	IEICE Transactions		artificial intelligence;latency (engineering);computer science;parallel computing;computer vision;network topology;supercomputer	HPC	-9.755888463468205	43.42085171179047	104751
213d335eda76253b2e01e7b663bb848fa9653b33	parallel computation of component trees on distributed memory machines		Component trees are region-based representations that encode the inclusion relationship of the threshold sets of an image. These representations are one of the most promising strategies for the analysis and the interpretation of spatial information of complex scenes as they allow the simple and efficient implementation of connected filters. This work proposes a new efficient hybrid algorithm for the parallel computation of two particular component trees—the max- and min-tree—in shared and distributed memory environments. For the node-local computation a modified version of the flooding-based algorithm of Salembier is employed. A novel tuple-based merging scheme allows to merge the acquired partial images into a globally correct view. Using the proposed approach a speed-up of up to 44.88 using 128 processing cores on eight-bit gray-scale images could be achieved. This is more than a five-fold increase over the state-of-the-art shared-memory algorithm, while also requiring only one-thirty-second of the memory.	8-bit;computation;computer vision;distributed algorithm;distributed memory;encode;grayscale;hybrid algorithm;list of algorithms;maxima and minima;parallel computing;run time (program lifecycle phase);scalability;shared memory	Mª Del Mar de la Fuente;Gabriele Cavallaro;Thierry G&#x00E9;raud;Matthias Book;Morris Riedel	2018	IEEE Transactions on Parallel and Distributed Systems	10.1109/TPDS.2018.2829724	tuple;grayscale;parallel computing;merge (version control);spatial analysis;computation;computer science;hybrid algorithm;distributed computing;distributed memory;image resolution	HPC	-6.752737253066689	41.0023165274208	104833
4e8e8df2fbd446e473b2c23147ced40c3c6fe40f	bottleneck identification methodology for performance-oriented design of shared-bus multiprocessors	shared bus multiprocessors;design alternatives;subsystem access time;bottleneck identification methodology			Chiung-San Lee;Tai-Ming Parng	1995	IEICE Transactions		computer architecture;parallel computing;computer science;distributed computing	EDA	-10.077579960586156	43.635890553851766	104854
4816a8a3718b75f28de9b0c20dbddda34b3f7755	gpu-accelerated evolutionary design of the complete exchange communication on wormhole networks	communication scheduling;evolutionary design;collective communications;gpu based acceleration;multi gpu systems;complete exchange communication	The communication overhead is one of the main challenges in the exascale era, where millions of compute cores are expected to collaborate on solving complex jobs. However, many algorithms will not scale since they require complex global communication and synchronisation. In order to perform the communication as fast as possible, contentions, blocking and deadlock must be avoided. Recently, we have developed an evolutionary tool producing fast and safe communication schedules reaching the lower bound of the theoretical time complexity. Unfortunately, the execution time associated with the evolution process raises up to tens of hours, even when being run on a multi-core processor. In this paper, we propose a revised implementation accelerated by a single Graphic Processing Unit (GPU) delivering speed-up of 5 compared to a quad-core CPU. Subsequently, we introduce an extended version employing up to 8 GPUs in a shared memory environment offering a speed-up of almost 30. This significantly extends the range of interconnection topologies we can cover.	algorithm;blocking (computing);central processing unit;continuous design;deadlock;graphics processing unit;interconnection;multi-core processor;overhead (computing);run time (program lifecycle phase);shared memory;time complexity	Jirí Jaros;Radek Tyrala	2014		10.1145/2576768.2598315	mathematical optimization;parallel computing;real-time computing;computer science;artificial intelligence;machine learning;distributed computing	HPC	-5.434503209933445	41.580890290575105	105215
4d524ea3922111022935a766da861ca8167ff635	retrospective on high-level language computer architecture	high-level language computer;high-level language computer architecture;specialized language;various language;cost-effective computer system;concrete definition;fundamental problem;numerous design;programming community	High-level language computers (HLLC) have attracted interest in the architectural and programming community during the last 15 years; proposals have been made for machines directed towards the execution of various languages such as ALGOL,<supscrpt>1,2</supscrpt> APL,<supscrpt>3,4,5</supscrpt> BASIC,<supscrpt>6,7</supscrpt> COBOL,<supscrpt>8,9</supscrpt> FORTRAN,<supscrpt>10,ll</supscrpt> LISP,<supscrpt>12,13</supscrpt> PASCAL,<supscrpt>14</supscrpt> PL/I,<supscrpt>15,16,17</supscrpt> SNOBOL,<supscrpt>18,19</supscrpt> and a host of specialized languages. Though numerous designs have been proposed, only a handful of high-level language computers have actually been implemented.<supscrpt>4,7,9,20,21</supscrpt> In examining the goals and successes of high-level language computers, the authors have found that most designs suffer from fundamental problems stemming from a misunderstanding of the issues involved in the design, use, and implementation of cost-effective computer systems. It is the intent of this paper to identify and discuss several issues applicable to high-level language computer architecture, to provide a more concrete definition of high-level language computers, and to suggest a direction for high-level language computer architectures of the future.	fortran;high- and low-level;high-level language computer architecture;high-level programming language;stemming	David R. Ditzel;David A. Patterson	1980		10.1145/800053.801914	fourth-generation programming language;computer architecture;parallel computing;cost-effectiveness analysis;language primitive;specification language;data control language;computer science;programming language generations;programming language implementation;domain-specific language;theoretical computer science;operating system;third-generation programming language;low-level programming language;cobol;programming language;second-generation programming language;high-level programming language;assembly language	Arch	-15.093172719493804	34.46088500809297	105295
43cf09d3f505a6901c5d5d1e2b226364547d9e21	an alternative implementation schema for assist parmod	processing element;data parallel;software libraries parallel programming;software libraries;stream parallelism;parallel programming parallel processing programming profession libraries skeleton concurrent computing scattering algorithm design and analysis streaming media image processing;data parallelism;parallel programming;cluster of workstations;irregular computation;algorithmic skeletons;load balance;structured parallel programming;data flow;auomatic load balancing algorithmic skeletons data flow data parallelism stream parallelism irregular computation;auomatic load balancing;parallelism exploitation patterns algorithmic skeleton data flow data parallelism stream parallelism irregular computation automatic load balancing assist parmod structured parallel programming environment parmod parallel construct	ASSIST is a structured parallel programming environment targeting networks/clusters of workstations and grids. It introduced the parmod parallel construct, supporting a variety of parallelism exploitation patterns, including classical ones. The original implementation of parmod relies on static assignment of parallel activities to the processing elements at hand. In this work, we discuss an alternative implementation of the parmod construct that implements completely dynamic assignment of parallel activities to the processing elements. We show that the new implementation introduces very limited overhead in case of regular computations, whereas it performs much better than the original one in case of irregular applications. The whole implementation of parmod is available as a C++/MPI library.	assist (computing);central processing unit;computation;dataflow;experiment;grid computing;integrated development environment;load balancing (computing);overhead (computing);parallel computing;skipper (former orm designer);state (computer science);stateful firewall;stateless protocol;workstation	Marco Danelutto;C. Migliore;C. Pantaleo	2006	14th Euromicro International Conference on Parallel, Distributed, and Network-Based Processing (PDP'06)	10.1109/PDP.2006.20	data flow diagram;computer architecture;parallel computing;computer science;load balancing;theoretical computer science;operating system;distributed computing;data parallelism;programming language	HPC	-12.11790301665851	39.50444897104484	105348
85efe9ce79bcd104bcdac907a77ea61a75a3f99b	interaction between pvm parameters and communication performances on atm networks	tratamiento paralelo;virtual machine;traitement parallele;sistema informatico;computer system;machine virtuelle;atm networks;transmision asincronica;computer network;reseau informatique;asynchronous transmission;transmission asynchrone;systeme informatique;maquina virtual;parallel processing;workstation cluster	This short paper presents preliminary results of an investigation to improve PVM communication on workstation clusters over ATM. The experiments show that a better exploitation of ATM bandwidth could be gained by tuning parameters like PVM packet fragment size and TCP socket buffer size.	atm turbo;parallel virtual machine;performance	Maurizio Giordano;Mario Mango Furnari;Francesco Vitobello	1999		10.1007/3-540-49164-3_62	embedded system;parallel processing;parallel computing;real-time computing;computer science;virtual machine;operating system;asynchronous communication	Theory	-16.502197468719196	43.3831676655753	105421
818b6ef3fc8114d6a198471d2a235b02c51d69f1	hybrid architecture paradigms in a radar esm data processing application	data processing;hybrid architecture	The paper discusses the development of a parallel radar data processing system using OCCAM and the transputer. The initial conversion of a serial implementation of one subsystem into parallel form was supplemented by the addition of new parallel algorithms for other subsystems. The architecture of the system is pipelined. However, the architecture within each stage varies according to the stage. This hybrid approach was felt to be key to the success of this real application, which has shown that a multitransputer implementation of a radar ESM (electronic surveillance measures) data processing system is a practical possibility.	parallel algorithm;pipeline (computing);radar;transputer;occam	Richard Beton;S. P. Turner;Colin Upstill	1989	Microprocessors and Microsystems - Embedded Hardware Design	10.1016/0141-9331(89)90121-X	embedded system;parallel computing;real-time computing;computer science;data architecture	HPC	-9.78840164646296	41.30222024025834	105450
281738876233698b543d81870141f2a9f235afd5	multidimensional static block data decomposition for heterogeneous clusters	distributed system;programa paralelo;systeme reparti;modelo 3 dimensiones;heterogeneous cluster;modele 3 dimensions;three dimensional model;multidimensional data;three dimensional;grid;sistema repartido;modelo 2 dimensiones;rejilla;modele 2 dimensions;grille;parallel programs;parallel program;two dimensional model;programme parallele	We propose general static block and block-cyclic heterogeneous decomposition of multidimensional data over processes of parallel program mapped onto multidimensional process grid. The decomposition is compared with decomposition of two-dimensional data over twodimensional process grid of Beaumont et al and with natural decomposition of three-dimensional data over three-dimensional process grid.		Alexey Kalinov;Sergey Klimov	2003		10.1007/978-3-540-24669-5_117	three-dimensional space;simulation;computer science;theoretical computer science;distributed computing;grid;algorithm	HPC	-6.681264483910523	39.98744244835338	105463
e66b04cf671698ef06b0de538fef6f8a99b92e63	bulk synchronous parallelisation of genetic programming	genetic program;science and technology;bulk synchronous parallel;parallel implementation;evolutionary algorithm	Abstract. A parallel implementation of Genetic Programming (GP) is described, using the Bulk SynchronousParallel Programming (BSP) model, as implemented by the Oxford BSP library. Two approaches to the parallel implementation of GP are examined. The first is based on global parallelisation while the second implements the island model for evolutionary algorithms. It is shown that considerable speedup of the GP execution can be achieved and that the BSP model is very suitable for parallelisation of similar algorithms.	computation;evolutionary algorithm;genetic programming;parallel computing;speedup;synchronous programming language	Dimitris C. Dracopoulos;Simon Kent	1996		10.1007/3-540-62095-8_23	parallel computing;computer science;theoretical computer science;evolutionary algorithm;distributed computing;programming language;bulk synchronous parallel;science, technology and society	HPC	-9.769032219835152	39.32025673479212	105509
c6b96622ab52f525540aff5d120f1854e9b8cd69	an asynchronous api for numerical linear algebra		We present a task-parallel asynchronous API for numerical linear algebra that utilizes multiple CPUs, multiple GPUs, or a combination of both. Furthermore, we present a wrapper of this interface for use in MATLAB. Our API imposes only small overheads, scales perfectly to two processor cores, and shows even better performance when utilizing computational resources on the GPU.	algorithm;application programming interface;central processing unit;computational resource;engineering sample;graphics processing unit;high- and low-level;matlab;numerical analysis;numerical linear algebra;scheduling (computing)	André Rigland Brodtkorb	2008	Scalable Computing: Practice and Experience		parallel computing;real-time computing;computer science;theoretical computer science	HPC	-6.194519975993892	43.38376242458483	105604
fd0da0862a6902128cc8cef4dbfb4bdbaa314eaf	hmpi - hybrid mpi	magnetic resonance imaging operating systems libraries workstations network servers bridges communication system security communication standards tcpip communication channels;hmpi daemons hybrid mpi high performance application cluster machines connection pools;operating system;application program interfaces;message passing;runtime system;workstation clusters message passing application program interfaces operating systems computers;workstation clusters;high performance;operating systems computers	This paper presents the HMPI, a runtime system to integrate several MPI implementations, used to develop high performance applications that must run both in nodes with several operating systems and clusters of clusters infrastructures. HMPI has two different approaches to achieve this integration, using connection pools and HMPI daemons.	daemon (computing);message passing interface;operating system;runtime system	Francisco Isidro Massetto;Augusto Mendes Gomes Junior;Liria Matsumoto Sato	2005	HPDC-14. Proceedings. 14th IEEE International Symposium on High Performance Distributed Computing, 2005.	10.1109/HPDC.2005.1520987	embedded operating system;parallel computing;message passing;computer science;operating system;distributed computing;programming language	HPC	-11.249207572016418	45.53505003200372	105626
8ddb47909a94c582adb48d0d12e1e2ab7ed548c3	nsim: an interconnection network simulator for extreme-scale parallel computers	discrete event simulation;parallel processing	In the near future, interconnection networks of massively parallel computer systems will connect more than a hundred thousands of computing nodes. The performance evaluation of the interconnection networks can provide real insights to help the development of efficient communication library. Hence, to evaluate the performance of such interconnection networks, simulation tools capable of modeling the networks with sufficient details, supporting a user-friendly interface to describe communication patterns, providing the users with enough performance information, completing simulations within a reasonable time, are a real necessity. This paper introduces a novel interconnection network simulator NSIM, for the evaluation of the performance of extreme-scale interconnection networks. The simulator implements a simplified simulation model so as to run faster without any loss of accuracy. Unlike the existing simulators, NSIM is built on the execution-driven simulation approach. The simulator also provides a MPI-compatible programming interface. Thus, the simulator can emulate parallel program execution and correctly simulate point-to-point and collective communications that are dynamically changed by network congestion. The experimental results in this paper showed sufficient accuracy of this simulator by comparing the simulator and the real machine. We also confirmed that the simulator is capable of evaluating ultra large-scale interconnection networks, consumes smaller memory area, and runs faster than the existing simulator. This paper also introduces a simulation service built on a cloud environment. Without installing NSIM, users can simulate interconnection networks with various configurations by using a web browser. key words: discrete event simulation, multiprocessor interconnection, parallel processing	application programming interface;ibm websphere extreme scale;interconnection;message passing interface;multiprocessing;network congestion;parallel computing;performance evaluation;point-to-point (telecommunications);simulation;usability	Hideki Miwa;Ryutaro Susukita;Hidetomo Shibamura;Tomoya Hirao;Jun Maki;Makoto Yoshida;Takayuki Kando;Yuichiro Ajima;Ikuo Miyoshi;Toshiyuki Shimizu;Yuji Oinaga;Hisashige Ando;Yuichi Inadomi;Koji Inoue;Mutsumi Aoyagi;Kazuaki Murakami	2011	IEICE Transactions		embedded system;parallel processing;real-time computing;computer architecture simulator;simulation;computer science;artificial intelligence;discrete event simulation;operating system;computer network	HPC	-12.612611466496766	42.36613856034297	105668
1e5cc3e2927ef2d2ef6c164e7c38f8eecda2a872	efficient lock-free work-stealing iterators for data-parallel collections	work stealing collections;data parallelism;work stealing iterators lock free work stealing iterators high level data structures multicores data parallel collection operations general purpose programming languages high level abstraction scheduling penalties shared memory architectures abstraction penalties data parallel operation;callsite specialization;domain specific work stealing data parallelism work stealing collections callsite specialization;parallel processing data handling data structures general purpose computers multiprocessing systems;kernel java parallel processing reactive power throughput contracts scheduling;domain specific work stealing	High-level data-structures are an important foundation for most applications. With the rise of multicores, there is a trend of supporting data-parallel collection operations in general purpose programming languages. However, these operations often incur high-level abstraction and scheduling penalties. We present a generic data-parallel collections design based on work-stealing for shared-memory architectures that overcomes abstraction penalties through call site specialization of data-parallel operation instances. Moreover, we introduce work-stealing iterators that allow more fine-grained and efficient work-stealing. By eliminating abstraction penalties and making work-stealing data-structure-aware we achieve several dozen times better performance compared to existing JVM-based approaches.	call site;data structure;high- and low-level;iterator;non-blocking algorithm;parallel computing;parallel text;partial template specialization;programming language;scheduling (computing);shared memory;work stealing	Aleksandar Prokopec;Dmitry Petrashko;Martin Odersky	2015	2015 23rd Euromicro International Conference on Parallel, Distributed, and Network-Based Processing	10.1109/PDP.2015.65	parallel computing;real-time computing;computer science;operating system;distributed computing;data parallelism;programming language	PL	-7.20675851564558	45.55923825911327	105714
489615f90ffa505855fc1d6bcfd2d45f63d38d75	experimental comparison of some parsing methods	top down	INTRODUCTION A production compiler, especially one written for a popular machine, may be used thousands of times every day. At an installation where the primary activity is software development, compilers will be one of the biggest users of system resources. In light of this, efficiency is a major concern of the compiler writer. Even very small gains in the run time efficiency of a compiler will pay major dividends over the life of the compiler. In spite of this fact, that efficiency should be an important concern for the design of a compiler, there is surprisingly little literature in which different techniques which can be used for the various phases of a compiler are compared experimentally. This paper hopes to on a ea. make a start on correcting that deficit in 2, ~, ~ parsing methods. This author is aware of three previous papers which make comparisons of different parsing methods. These do not c~mpare the techniques which are in widest use today. A recent paper compares recursive descent with a generated LL(1) parser. This paper will describe a set of experiments performed to compare several techniques. The methods chosen were: recursive descent, SLR and operator precedence. Recursive descent was chosen as representative of top-down methods and because it is not a table driven method. SLR was chosen as the simplest of the LR techniques and as representative of the other LR methods. Operator precedence was chosen because it is still used to parse expressions and it differs from other table driven methods in that it ignores non-terminals. The analysis in the appendix shows that the time relationship for a table driven LL(1) parser is very similar to that for the SLR parser. It is for that reason that we did not test this method. The next section describes the design of the experiments. The following section describes the language for which the parsers were written. This is followed by an analytical comparison of the methods, the experiments and their results and a discussion of the results. In the final section, some additional experiments that need to be performed are discussed. An appendix gives the details of the analytical results.	algol 68;compiler;experiment;expression (computer science);hoare logic;ll parser;order of operations;parsing;recursion (computer science);recursive descent parser;run time (program lifecycle phase);simple lr parser;software development;top-down and bottom-up design	Robert Gerardy	1987	SIGPLAN Notices	10.1145/35596.35604	computer science;top-down and bottom-up design	PL	-17.502322361312196	35.29806092534368	105865
3ef9d054ed13f2acf126cadcffb9beac94a98390	factoring: a method for scheduling parallel loops	programa paralelo;parallel loop scheduling;optimisation;optimizacion;sistema informatico;boucle programme;partitioning;computer system;ingenieria logiciel;software engineering;bucle programa;loop scheduling;scheduling;genie logiciel;program loop;ordonamiento;optimization;systeme informatique;systeme parallele;parallel system;parallel program;ordonnancement;sistema paralelo;chunking;dynamic scheduling;programme parallele	~lw advantage of , capability of rallel machines, application programs must contain sufficient parallelism, and this parallelism must be effectively scheduled on multiple processors. Loops without dependences among their iterations are a rich source of parallelism in scientific code. Restructuring compilers for sequential programs have been particularly successful in determining when loop iterations are independent and can be executed in parallel. Because of the prevalence of parallel loops, optimal parallel-loop scheduling has received considerable attention in both academic and industrial communities. The fundamental trade-off in scheduling parallel-loop iterations is that of maintaining balanced processor workloads vs. minimizing scheduling overhead. Consider, for example, a loop with N iterations that contain an IF statement. Depending on whether the body of the IF statement is executed, an iteration has LONG or SHORT execution time. If we naively schedule the iterations on P processors in chunks of N/P iterations, a strategy called static chunking (SC), a chunk of one processor may consist of iterations that are all LONG, while a chunk of another processor may consist of iterations that are all SHORT. Hence, different processors may finish at widely different times. Since the loop finishing time is equal to the latest finishing time of any of the processors executing the loop, the overall finishing time may be greater than optimal with SC. Alternatively, if we (also naively) schedule the iterations one at a time, a strategy called self-scheduling (SS), then there will be N scheduling operations. With SS, a processor obtains a new iteration whenever it becomes idle, so the processors finish at nearly the same time and the workload is balanced. Because of the scheduling overhead , however, the overall finishing time may be greater than optimal. The characteristics of the iterations determine which scheme performs better. For instance, variable-length, coarse-grained iterations favor SS, while constant-length, fine-grained iterations favor SC. Even when iterations do not contain conditional statements, their running times are likely to be variable because of interference from their environment (other iterations, the operating system, and other programs). The scheduling schemes just discussed are extremes; between the two lie schemes that attempt to minimize the cumulative contribution of uneven processor finishing times and of scheduling overhead. Such schemes schedule iterations in chunks of sizes greater than one but less than N/P, where size is the number of iterations in the chunk. Both fixed-size and variable-size chunk-ing schemes have been proposed. In …	central processing unit;chunking (computing);compiler;conditional (computer programming);data parallelism;integer factorization;interference (communication);iteration;loop scheduling;operating system;overhead (computing);parallel algorithm;parallel computing;run time (program lifecycle phase);scheduling (computing);shallow parsing	Susan Flynn Hummel;Edith Schonberg;Lawrence E. Flynn	1992	Commun. ACM	10.1145/135226.135232	parallel computing;real-time computing;dynamic priority scheduling;computer science;operating system;distributed computing;chunking;scheduling	HPC	-15.556226845820284	44.694757224799076	105891
d75527e5071a3ba6d6dd2c99a766ccc239b994fb	task parallel programming on the cell processor (task-parallele programmierung auf dem cell-prozessor)			cell (microprocessor);parallel computing	Andreas Prell	2011	it - Information Technology	10.1524/itit.2011.0628	stream processing	HPC	-9.707435902982738	42.54622619307552	106206
71583890363de485ceb24e347790886829072731	the performance impact of exploiting branch ilp with tree representation of ilp code	compilacion;evaluation performance;modele empirique;compilateur;performance evaluation;langage c;structure arborescente;evaluacion prestacion;instruction;instruccion;ejecucion programa;program execution;parallel computation;calculo paralelo;estructura arborescente;scheduling;execution programme;tree structure;empirical model;compilation;modelo empirico;c programming language;program compilers;calcul parallele;ordonnancement	Modern single-CPU microprocessors exploit instruction-level parallelism (ILP) by deriving their performance advantage mainly from parallel execution of ALU and memory instructions within a single clock cycle. This performance advantage obtained by exploiting dataILP is severely offset by sequential execution of conditional branches, especially in branch-intensive non-numerical code. Consequently, branch ILP must also be exploited by executing branches and data instructions in parallel. This requires compilation support for scheduling branches as well as architectural support for executing branches and data instructions in the same cycle. This paper performs a comprehensive empirical study aimed at evaluating the performance impact of exploiting branch ILP using a representation of ILP code calledtree representation , which has been proposed by Nicolau [A. Nicolau (1985), Technical Report TR-85-678, Cornell University, Ithaca, NY] and Ebcioğlu to exploit branch ILP in the most generalized form. Our results indicate that exploiting branch ILP can enhance performance substantially (i.e., as much as a geometric mean of speedup 4.5 in the 16-ALU machine, compared to the base speedup 3.0) and that the performance benefit comes not only from the intended parallel execution but from the decrease of useless speculative execution due to earlier scheduling of branches.	addressing mode;cpu cache;central processing unit;clock signal;compiler;instruction-level parallelism;loop-invariant code motion;microprocessor;numerical analysis;parallel computing;scheduling (computing);speculative execution;speedup	Soo-Mook Moon;Kemal Ebcioglu	1998	Comput. J.	10.1093/comjnl/41.1.26	computer architecture;parallel computing;real-time computing;computer science;operating system;tree structure;programming language;scheduling;algorithm;empirical modelling	Arch	-15.59475813218542	43.81239069751379	106321
091cf7a6c8bb023d4e8c6a4195c96ff722518733	weld: a multithreading technique towards latency-tolerant vliw processors	parallelisme;vliw processor;latencia;gestion memoire;compilateur;program counter;latence;storage management;latency tolerance;compiler;computer architecture;gestion memoria;parallelism;paralelismo;architecture ordinateur;multithread;procesador;arquitectura ordenador;latency;multitâche;processeur;multitarea;processor;compilador	This paper presents a new architecture model, named Weld, for VLIW processors. Weld integrates multithreading support into a VLIW processor to hide run-time latency effects that cannot be determined by the compiler. It does this through a novel hardware technique called operation welding that merges operations from different threads to utilize the hardware resources more efficiently. Hardware contexts such as program counters and fetch units are duplicated to support multithreading. The experimental results show that the Weld architecture attains a maximum of 27% speedup as compared to a single-threaded VLIW architecture.	central processing unit;compiler;interrupt latency;multithreading (computer architecture);speedup;thread (computing);very long instruction word	Emre Özer;Thomas M. Conte;Saurabh Sharma	2001		10.1007/3-540-45307-5_17	program counter;computer architecture;compiler;latency;parallel computing;real-time computing;computer science;operating system;temporal multithreading;super-threading	Arch	-14.778432506040701	44.674562181641775	106405
18fd33c5a354610b07f97addfbf9c9dbba86bce4	backup metadata as data: dpc-tolerance to commodity file system	disk pointer snapshot;parallelisme;sistema operativo;seguridad funcionamiento;os aware recovery;fiabilidad;reliability;surete fonctionnement;mise a jour;procedure secours;metadata;gestion archivos;disk pointer types;gestion fichier;estructura archivo;file management;actualizacion;back up procedures;parallelism;ordered recovery;marcador;paralelismo;procedimiento de restauracion;pointer;operating system;file system;fiabilite;out of partition restoration;dependability;structure fichier;disk pointer corruption;file structure;metadonnee;pointeur;systeme exploitation;metadatos;in partition restoration;updating	Backup Metadata As Data (MAD) is a user-level solution that enables commodity file systems to replicate their critical metadata and to recover from disk pointer corruptions. More specifically, it extracts disk pointers from file system and saves them as user data. When some data blocks become inaccessible due to pointer corruptions, Backup MAD restores access paths to them either by copying the blocks to another file system or by directly updating on-disk structures of file system. The latter technique helps Backup MAD restore lost files faster than any other recovery solution because data blocks are not moved during restoration. Also, as the technique relies on disk pointers extracted from a consistent file system state, it can rescue up to 50% more files than a scan-based recovery tool that infers block dependencies from a corrupted partition. We demonstrate the effectiveness of our technique by two real implementations, MAD-NTFS and MADext2. Backup MAD enhances dependability of file system by protecting disk pointers on behalf of file system.	backup;circuit restoration;deferred procedure call;dependability;mad;pointer (computer programming);self-replicating machine;user space	Youngjin Yu;Dongin Shin;Hyeong Seog Kim;Hyeonsang Eom;Heon Young Yeom	2011	J. Inf. Sci. Eng.		fork;self-certifying file system;parallel computing;pointer;torrent file;device file;computer file;incremental backup;computer science;stub file;versioning file system;operating system;unix file types;inode pointer structure;journaling file system;reliability;dependability;database;open;data file;file format;file system fragmentation;metadata;computer security;design rule for camera file system;archive bit;file control block	OS	-18.284929219980512	45.26338136566372	106621
34d9ae15e893f931dd768c3f638776a2d020712d	a functional programming language compiler for massively parallel computers	data parallel;massively parallel systems;optimization technique;inference rule;massively parallel computer;functional programming language;generic programming	Functional programming languages remove programmers from low-level machine details, an important achievement when programming massively parallel systems. We present an overview of an FP compiler that generates programs capable of exploiting data-parallelism, a view of parallelism where distinct data elements reside on distinct processors and all processors execute a single instruction stream. To achieve this form of parallelism, FP's sequences are represented as arrays. This representation makes possible optimization techniques developed for APL compilers that compose routing functions at compile-time. These techniques are described succinctly by a set of axioms and inference rules. We demonstrate the optimizations by compiling several FP functions, obtaining optimal performance.	apl;central processing unit;compile time;compiler;data parallelism;functional programming;high- and low-level;mathematical optimization;parallel computing;programmer;programming language;routing	Clifford Walinsky;Deb Banerjee	1990		10.1145/91556.91610	computer architecture;parallel computing;reactive programming;computer science;massively parallel;functional logic programming;programming paradigm;programming language;functional programming;generic programming;implicit parallelism;rule of inference;parallel programming model	PL	-13.80341015934318	37.59647117613893	106924
0096eac4f1c1d9c89751293cd459e8e7dce6b2f9	metaprogramming applied to numerical problems	programming language;ordinary differential equation;data management;differential equation;data analysis;operating system;computer software;differential equations;data acquisition;runge kutta;programming languages;subroutines	Metaprogramming is a programming technique where a computer program is written that writes or manipulates another program (or itself) that then solves a given task. This approach has several advantages over classical programming. Firstly, it leads to more efficient programming because the process of generating code is automated as you basically write code that writes code. Secondly, it might also lead to higher performance because using automatic code generation one can more easily produce code that can be optimized more efficiently by the compiler. A popular example is the Matrix Template Library (MTL) where Template Metaprogramming is used to create a high performance linear algebra library [1]. In C++ this is mostly realized by the use of templates and is then called Template Metaprogramming [2, 3]. Templates are placholders for data types that are replaced – instantiated – by the compiler at compile time. Although templates where originally introduced to provide the functionality of parametrized types [4], it was quickly realized that they are indeed much more powerful and form a programming language themself [5]. The first examples using C++ templates for Metaprogramming calculated prime numbers and were presented by E. Unruh on the C++ standardization meeting in 1994 in San Diego [6]. As most simple and instructive example serves the calculation of the factorial of a number at compile time [7]. Nowadays, Template Metaprogramming has found many applications, the most sophisticated are collected in the boost libraries, like Boost.MSM, Boost.Units, Boost.Accumulators and many others. In this work, we will use the ideas and techniques of Metaprogramming to implement numerical algorithms. This will heavily rely on existing Metaprogramming libraries, namely Boost.MPL [8] and Boost.Fusion [9] – compile time libraries that simplify the creation of Metaprogramming algorithms. Metaprogramming is especially suitable to numerical algorithms where an approximate result is found by the successive application of a previously known number of stages where the type of computation at each state is similar. Perfect examples for such algorithms are the explicit Runge-Kutta schemes [10] for finding the solution of Ordinary Differential Equations (ODEs). In practice, solving ODEs numerically is usually done by finding the solution to an Initial Value Problem (IVP):	apl;accumulator (computing);approximation algorithm;automatic programming;boost;c++;code generation (compiler);comparison of linear algebra libraries;compile time;compiler;computation;computer program;library (computing);matrix template library;multiphoton lithography;numerical analysis;programming language;remote manipulator;runge–kutta methods;template (c++);template metaprogramming;the matrix	Mario Mulansky;Karsten Ahnert	2011	CoRR	10.1063/1.3637933	metaprogramming;dynamic compilation;data management;computer science;theoretical computer science;programming language;differential equation;physics;algorithm;quantum mechanics	PL	-11.16679918289768	35.160843285489484	106970
87a94bf9a3b78ff690a7618f760c58eb4995ce48	from (sequential) haskell to (parallel) eden: an implementation point of view	langage fonctionnel;lenguaje programacion;distributed system;compilacion;systeme reparti;execution time;programming language;implementation;langage parallele donnee;lenguaje funcional;parallel computation;ejecucion;calculo paralelo;parallel programming language;sistema repartido;scheduling;langage programmation;compilation;temps execution;ordonamiento;runtime system;point of view;data parallel language;tiempo ejecucion;functional language;calcul parallele;ordonnancement	The explicitly parallel programming language Eden adds a coordination level to the lazy functional language Haskell. This paper describes how a compiler and runtime system for Eden can incrementally be built on the basis of a compiler and runtime system for the computation language. The modiications needed in the compiler are restricted to speciic orthogonal extensions. We show that Eden's design for distributed memory systems proves beneecial for the construction of a lean parallel runtime system.	compiler;computation;distributed memory;functional programming;haskell;lazy evaluation;parallel computing;parallel programming model;point of view (computer hardware company);programming language;runtime system	Silvia Breitinger;Ulrike Klusik;Rita Loogen	1998		10.1007/BFb0056623	compiler;parallel computing;compiler correctness;computer science;operating system;distributed computing;programming language;functional programming;implementation;scheduling;functional compiler;algorithm;parallel programming model	PL	-16.883427411608984	41.0779496435392	107533
290e4a1846096716987ad0d40d401597b32de4bf	rome 2018 invited talk		DASH is a realization of the PGAS programming model in the form of a C++ template library that uses on MPI-3 RMA for one-sided communication. This talk gives a brief overview of DASH and discusses our experiences with developing the DASH runtime system (DART) on top of MPI-3 RMA.	c++;message passing interface;partitioned global address space;programming model;revolution in military affairs;runtime system	Karl Fuerlinger	2018	2018 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)	10.1109/IPDPSW.2018.00200	computer science;runtime system;parallel computing;partitioned global address space;dash;programming paradigm;dart	Embedded	-9.835890170678685	40.86411238506716	107621
a530ae4845f11f98a6d53e2749a2186031c48aad	designing programming languages for the analyzability of pointer data structures	structure donnee pointeur;lenguaje programacion;pointer data structures;programming language;langage programmation imperatif;language theory;imperative programming language;teoria lenguaje;analysabilite;programming theory;loop unrolling speculative traversability;estructura datos;analyzability;langage programmation;pointer data structure;theorie programmation;structure donnee;data structure;theorie langage;imperative programming languages	"""-ln this paper we propose a programming language mechanism and associated compiler techniques which significantly enhance the analyzability of pointer-based data structures frequently used in non-scientific programs. Our approach is based on exploiting two important properties of pointer data structures: structural inductivity and speculative traversability. Structural inductivity facilitates the application of a static interference analysis method for such pointer data structures based on path matrices, and speculative traversability is utilized by a novel loop unrolling technique for while loops that exploit fine-grain parallelism by speculatively traversing such data structures. The effectiveness of this approach is demonstrated by applying it to a collection of loops found in typical non-scientific C programs. analyzability imperative programming languages speculative traversability pointer data structures loop unrolling 1. I N T R O D U C T I O N In the past decade, the dramatic improvement of VLSI technology has led to modern high-performance microprocessors that support some level of fine-grain parallelism. Even with today's RISC processors, some degree of instruction-level parallelism is required to fully utilize the architecture. With ULSI (ultra-large scale integration) based multi-million transistor processor chips under way within this decade, we can expect an even higher degree of fine-grain parallelism due to deep instruction pipelining and multiple functional units (particularly multiple pipelined functional units). This rapid advance of VLSI technology and computer architectures has provided important challenges for programming language designers and compiler writers alike. It is becoming increasingly important to provide programming languages and associated compiler support such that user programs can be effectively analyzed in order to effectively utilize the underlying architectures. In particular, it is critical to provide compile-t ime analysis that results in accurate alias analysis and data-dependency information for complex data structures. In this paper we argue that such analyzability is an important principle of program language design and implementation, and that it is particularly critical for the efficient mapping of non-scientific programs to architectures supporting some level of instruction-level parallelism. The importance of the analyzability has been demonstrated by the considerable success of automatic parallelization and optimization of large-scale scientific numerical programs. In such scientific programs, arrays are the most important data structures, and programs using these array structures can often be analyzed effectively. The keys to such analysis are: (1) arrays are frequently defined on rectangular index regions with dimensions, shapes, and bounds known to the compiler; (2) array operations are often encapsulated in """"well structured"""" loops (for loops without gotos) with the iteration space of the loop matching the index regions of the arrays; and (3) in loops arrays are frequently accessed (""""traversed"""") in a regular fashion. For example, the index expression is often an affine function of the loop indices. This mathematical structure of the arrays and the regularity of their accesses in embedded loops has lead to the development of a variety of dependence analysis, loop transformation, and parallelization techniques [1-5]. Although many of these techniques were pioneered in the areas of vectorizing and parallelizing compilers, these techniques are also being applied to architectures supporting tThis work was supported in part by FCAR, NSERC and the McGill Faculty of Graduate Studies and Research."""	apl;alias analysis;automatic parallelization;central processing unit;compiler;computer architecture;control flow;data dependency;data structure;dependence analysis;embedded system;imperative programming;instruction pipelining;instruction-level parallelism;integrated circuit;interference (communication);iteration;loop optimization;loop unrolling;mathematical optimization;mathematical structure;microprocessor;numerical analysis;parallel computing;pipeline (computing);pointer (computer programming);programming language;speculative execution;transistor;very-large-scale integration	Laurie J. Hendren;Guang R. Gao	1993	Comput. Lang.	10.1016/0096-0551(93)90006-M	imperative programming;data structure;computer science;philosophy of language;theoretical computer science;escape analysis;programming language;algorithm	PL	-13.341038700857895	34.725866867761845	107998
017e8cd7ac6ef4d3df4c8f9e57fbbc5a7e716400	an approach for non-intrusively adding malleable fork/join parallelism into ordinary javabean compliant applications	parallel computing;non invasive tuning;distributed computing;ease of use;real world application;fork join parallelism;execution environment;parallel computer;implicit parallelism;parallel programs;programming tool;java	Motivated by the advent of powerful hardware such as SMP machines and execution environments such as Grids, research in parallel programming has gained much attention within the Distributed Computing community. There is a substantial body of efforts in the form of parallel libraries and frameworks that supply developers with programming tools to exploit parallelism in their applications. Still, many of these efforts prioritize performance over other important characteristics such as code invasiveness, ease of use and independence of the underlying executing hardware/environment. In this paper, we present EasyFJP, a new approach for semi-automatically injecting parallelism into sequential Java applications that offers a convenient balance to these four aspects. EasyFJP is based upon the popular fork/join parallel pattern, and combines implicit, application-level parallelism with explicit, non-invasive application tuning. Experiments performed with several classic CPU-intensive benchmarks and a real-world application confirm that EasyFJP effectively addresses these problems while delivers very competitive performance.	central processing unit;distributed computing;java;library (computing);parallel computing;programming tool;semiconductor industry;symmetric multiprocessing;usability	Cristian Mateos;Alejandro Zunino;Marcelo R. Campo	2010	Computer Languages, Systems & Structures	10.1016/j.cl.2009.12.003	parallel computing;real-time computing;usability;computer science;distributed computing;data parallelism;programming language;java;instruction-level parallelism;scalable parallelism;implicit parallelism;task parallelism	HPC	-12.38399028797609	40.53433470466555	108080
bae174f768ef59fefc818b2ae4be88490f6f468a	a computer organization and programming system for automated maintenance	signal generators;automatic programming hardware writing signal analysis voltage signal generators humans computer errors error correction functional programming;design automation;signal analysis;automatic programming;functional programming;error correction;voltage;writing;humans;computer errors;hardware	"""selecting one X and one Y line. The bits of the word are planes. If a word of all """"ones"""" is written, then 72 bits stacked vertically in memory, one bit per plane, at the on the selected X and Y lines will be switched from intersections of the half-selected X and Y lines. In the """"zero"""" to """"one."""" Thus to apply MAP2 it would be necabsence of any other windings the half-selection of an essary to neglect 72 switching cores, or one core out of X and Y line will cause """"ones"""" to be written in all bit 128 in each plane. This might be stretching the linear positions in the selected word. To allow for the writing model upon which MAP is based a little far. However, of """"zeros"""" inhibit lines are introduced. An inhibit line if words with fewer """"ones"""" are written, the conditions passes through cores in one plane only. Half-selection of the linear model are more nearly met. of an inhibit line in a given plane cancels the effect of the Unfortunately, many noise-transfer calculations that half-selected Y line, thus preventing the writing of a can be done for two-dimensional arrays cannot be done """"one"""" in that plane. Besides the inhibit winding, each for three-dimensional arrays. This is a consequence of plane has its own sense winding. the fact that the Y and inhibit lines interact with the In spite of the increased complexity of the threesame sense line at many different points. With some indimensional array, there are still some cases in which the genuity, however, a partial analysis of noise transfer techniques and computer programs described above can from X line to sense line or from inhibit line to Y line be used. For example, propagation of sense signals on can be done. In general, the MAP2 and MAP3 comthe sense lines can still be analyzed with the MAP2 puter programs are more useful for the analysis of twocomputer program by introducing the output of a dimensional arrays than three-dimensional arrays. switching core as a voltage generator on the sense line. Three-dimensional arrays, however, are a characteristic The propagation of drive pulses on the X and Y lines of berrite-core technology. The newer technologies lean is amenable to analysis by MAP2 in most cases. Here, toward two-dimensional word-oriented memories. Thus in general, it is necessary to neglect more than one the MAP2 and MAP3 programs should prove more useswitching core. To take a typical example, a large memful in the newer technologies than in the older ferriteory might have 128 X lines, 128 Y lines and 72 bit core technology."""	admissible numbering;computer program;lean software development;line level;linear model;microarchitecture;software propagation	Klim Maling;E. L. Allen	1963	IEEE Trans. Electronic Computers	10.1109/PGEC.1963.263592	constraint programming;electronic engineering;voltage;error detection and correction;reactive programming;computer science;electrical engineering;theoretical computer science;computer programming;event-driven programming;procedural programming;inductive programming;programming language;computer network programming;functional programming;system programming;writing;algorithm;signal generator	Theory	-14.758166022521308	32.699220298271946	108300
1aa1a63c8d4834cb13421da998fbe088bef80d9d	implementation of committed choice logic languages on shared memory multiprocessors	logic programming languages computer software computer engineering;thesis;shared memory multiprocessor			James Alexander Crammond	1988			distributed shared memory;shared memory;computer architecture;computing;parallel computing;distributed memory;computer science;third-generation programming language;functional logic programming;computational logic;computer programming;ontology language;fifth-generation programming language;programming language theory;programming language;second-generation programming language;comparison of multi-paradigm programming languages;cache-only memory architecture	Logic	-14.89092182126329	39.135076909508165	108335
ec9006c579376f6a07ca37b1fbb28c9eaf5cdead	barrier synchronization techniques for distributed process creation	hypercube networks distributed process creation loosely coupled processors run time characteristics performance synchronization ipsc 2 snap 1 distributed system process creation barrier synchronization loosely coupled system message passing symbolic processing spawn in transit;distributed system;multiprocessing programs;performance evaluation;distributed processing;parallel programming;synchronisation;performance evaluation synchronisation multiprocessing programs parallel programming;runtime costs distributed computing hypercubes degradation bandwidth;message passing	Synchronization techniques are proposed for algorithms which spawn processes remotely on loosely coupled processors based on run-time characteristics. The performance of the proposed synchronization schemes are measured on the iPSC/2 and SNAP-1 multiprocessors and their implementation cost is discussed. Results show that processes created dynamically throughout a distributed system can be synchronized at comparable overhead and cost to that required for fixed-location process creation. >	barrier (computer science)	Ronald F. DeMara;Cheng Lin;S. Kuo;Bahman S. Motlagh	1994		10.1109/IPPS.1994.288243	parallel computing;real-time computing;computer science;distributed computing	HPC	-13.481021632776544	44.67786482051434	108499
12caeef689859d58020f6a3ee7043c774d53b1db	bitvalue inference: detecting and exploiting narrow bitwidth computations	processor architecture;reduction;langage evolue;narrow band;computations;logic circuits;optimizacion compiladora;bande etroite;detection;synthesis;compilers;banda estrecha;compiler optimization;inferencia;algorithms;lenguaje evolucionado;optimization;c programming language;computer hardware;bitvalue;high level language;materiel informatique;material informatica;optimisation compilateur;inference	We present a compiler algorithm called BitValue, which can discover both unused and constant bits in dusty-deck C programs. BitValue uses forward and backward dataflow analyses, generalizing constantfolding and dead-code detection at the bit-level. This algorithm enables compiler optimizations which target special processor architectures for computing on non-standard bitwidths. Using this algorithm we show that up to 31% of the computed bytes are thrown away (for programs from SpecINT95 and Mediabench). A compiler for reconfigurable hardware uses this algorithm to achieve substantial reductions (up to 20-fold) in the size of the synthesized circuits.	algorithm;bit-level parallelism;byte;central processing unit;computation;dataflow;dead code;dual in-line package;execution unit;field-programmable gate array;mmx (instruction set);optimizing compiler	Mihai Budiu;Majd F. Sakr;Kip Walker;Seth Copen Goldstein	2000		10.1007/3-540-44520-X_137	compiler;parallel computing;reduction;logic gate;microarchitecture;computer science;artificial intelligence;theoretical computer science;operating system;machine learning;computation;optimizing compiler;database;distributed computing;programming language;high-level programming language;algorithm	Arch	-17.00795896048609	34.86135274451878	108894
0ad0c35669e7d520fc9dca7583aa7f8445dc4a36	fragment molecular orbital method adaptations for heterogeneous computing platforms	algorithmic adaptations;gamess;heterogeneous computing platforms;middleware;fragment molecular orbital method	Modern electronic structure calculations are characterized by unprecedented complexity and accuracy. They de-mand the full power of high-performance computing and must be in tune with the given architecture for superior efficiency. Thus, it is desirable to enable their static and dynamic adaptations using some external software (middle-ware), which may monitor both system availability and application needs, rather than mix science with system-related calls inside the application.Building on the successful usage of the NICAN middleware with the computational chemistry package GAMESS, the work described in this paper links NICAN with the fragment molecular orbital (FMO) method to augment FMO with adaptive capabilities. Specifically, its fragment scheduling is performed, both statically and dynamically, based on current conditions within a heterogeneous computing environment. Significant execution time and throughput gains have been obtained with static adaptations, while the dynamic ones prevented FMO to abort calculations due to the insuffcient memory available at the runtime.	fragment molecular orbital;heterogeneous computing	Sai Kiran Talamudupula;Masha Sosonkina;Alexander Gaenko;Michael W. Schmidt	2012		10.1016/j.procs.2012.04.052	parallel computing;real-time computing;computer science;operating system;middleware;distributed computing	HPC	-9.299143573327408	45.74485381658884	109330
5de6c427378f2c1d7686062f2d86c3040773ce8c	benchmarking opencl, openacc, openmp, and cuda: programming productivity, performance, and energy consumption		Many modern parallel computing systems are heterogeneous at their node level. Such nodes may comprise general purpose CPUs and accelerators (such as, GPU, or Intel Xeon Phi) that provide high performance with suitable energy-consumption characteristics. However, exploiting the available performance of heterogeneous architectures may be challenging. There are various parallel programming frameworks (such as, OpenMP, OpenCL, OpenACC, CUDA) and selecting the one that is suitable for a target context is not straightforward. In this paper, we study empirically the characteristics of OpenMP, OpenACC, OpenCL, and CUDA with respect to programming productivity, performance, and energy. To evaluate the programming productivity we use our homegrown tool CodeStat, which enables us to determine the percentage of code lines that was required to parallelize the code using a specific framework. We use our tool x-MeterPU to evaluate the energy consumption and the performance. Experiments are conducted using the industry-standard SPEC benchmark suite and the Rodinia benchmark suite for accelerated computing on heterogeneous systems that combine Intel Xeon E5 Processors with a GPU accelerator or an Intel Xeon Phi co-processor.	benchmark (computing);cuda;central processing unit;coprocessor;geforce 200 series;geforce 700 series;geforce 900 series;graphics processing unit;heterogeneous system architecture;heterogeneous computing;human factors and ergonomics;openacc;opencl api;openmp;parallel computing;programming productivity;titan;xeon phi	Suejb Memeti;Lu Li;Sabri Pllana;Joanna Kolodziej;Christoph W. Kessler	2017		10.1145/3110355.3110356	xeon;benchmarking;parallel computing;computer architecture;spec#;programming productivity;energy consumption;xeon phi;cuda;computer science	HPC	-5.56168752276431	44.215216199993115	109337
703a5bc2064ba4e781b07f74d97a2a581ce68c6f	evaluating performance of openmp and mpi on the sgi origin 2000 with benchmarks of realistic problem sizes	benchmarking;message processing;parallel computing performance;computer communications;performance engineering;openmp;computer benchmarking;mpi;distributed data processing;parallel processing;computer program verification	Six application benchmarks, including four numerical aerodynamic simulation (NAS) codes, provided by H. Jin and J. Wu, were previously parallelized using OpenMP and message-passing interface (MPI) and run on a 128-processor Silicon Graphics Inc. (SGI) Origin 2000. Detailed profile data were collected to understand the factors causing imperfect scalability. The results show that load imbalance and cost of remote accesses are the main factors in limited speedup of the OpenMP versions, whereas communication costs are the single major factor in the performance of the MPI versions.	code;graphics;message passing interface;numerical analysis;openmp;parallel computing;scalability;simulation;speedup	Csaba K. Zoltani;Punyam Satya-narayana;Dixie Hisley	2000	Scalable Computing: Practice and Experience	10.1007/978-1-4615-4489-0_6	computer architecture;parallel computing;computer science;operating system	HPC	-6.99758219919486	39.76402921393893	109368
3f5b569595f6011ff7a59cb74140f3c2ce9c6e1c	design and implementation of message-passing services for the blue gene/l supercomputer	performance measure;design and implementation;message passing;modes of operation	of message-passing services for the Blue Gene/L supercomputer G. Almási C. Archer J. G. Castaños J. A. Gunnels C. C. Erway P. Heidelberger X. Martorell J. E. Moreira K. Pinnow J. Ratterman B. D. Steinmacher-Burow W. Gropp B. Toonen The Blue Genet/L (BG/L) supercomputer, with 65,536 dualprocessor compute nodes, was designed from the ground up to support efficient execution of massively parallel message-passing programs. Part of this support is an optimized implementation of theMessage Passing Interface (MPI), which leverages the hardware features of BG/L. MPI for BG/L is implemented on top of a more basic message-passing infrastructure called the message layer. This message layer can be used both to implement other higher-level libraries and directly by applications. MPI and the message layer are used in the two BG/L modes of operation: the coprocessor mode and the virtual node mode. Performance measurements show that our message-passing services deliver performance close to the hardware limits of the machine. They also show that dedicating one of the processors of a node to communication functions (coprocessor mode) greatly improves the message-passing bandwidth, whereas running two processes per compute node (virtual node mode) can have a positive impact on application performance.	block cipher mode of operation;blue gene;central processing unit;code;computation;computer;coprocessor;job control (unix);library (computing);mpich;message passing interface;nas parallel benchmarks;parallel computing;programmer;prototype;scalability;supercomputer	George Almási;Charles Archer;José G. Castaños;John A. Gunnels;C. Christopher Erway;Philip Heidelberger;Xavier Martorell;José E. Moreira;Kurt W. Pinnow;Joe Ratterman;Burkhard D. Steinmacher-Burow;William Gropp;Brian R. Toonen	2005	IBM Journal of Research and Development	10.1147/rd.492.0393	parallel computing;message passing;real-time computing;computer science;operating system;programming language	HPC	-11.270617853545215	45.93052837180928	109414
49652d409ba97e582073d4dc47e26906a42389f4	measuring determinism in real-time embedded systems using cached processors			embedded system;real-time clock	Richard G. Scottow;Klaus D. McDonald-Maier	2005			determinism;computer science;cache;embedded operating system;distributed computing	Embedded	-9.88305645643658	44.231648350718324	109435
6e5c9286657818ba0beac6a9cad4cbbaa814ce2b	a machine learning approach for efficient parallel simulation of beam dynamics on gpus		Parallel computing architectures like GPUs have traditionally been used to accelerate applications with dense and highly-structured workloads; however, many important applications in science and engineering are irregular and dynamic in nature, making their effective parallel implementation a daunting task. Numerical simulation of charged particle beam dynamics is one such application where the distribution of work and data in the accurate computation of collective effects at each time step is irregular and exhibits control-flow and memory access patterns that are not readily amenable to GPU's architecture. Algorithms with these properties tend to present both significant branch and memory divergence on GPUs which leads to severe performance bottlenecks.We present a novel cache-aware algorithm that uses machine learning to address this problem. The algorithm presented here uses supervised learning to adaptively model and track irregular access patterns in the computation of collective effects at each time step of the simulation to anticipate the future control-flow and data access patterns. Access pattern forecast are then used to formulate runtime decisions that minimize branch and memory divergence on GPUs, thereby improving the performance of collective effects computation at a future time step based on the observations from earlier time steps. Experimental results on NVIDIA Tesla K40 GPU shows that our approach is effective in maximizing data reuse, ensuring workload balance among parallel threads, and in minimizing both branch and memory divergence. Further, the parallel implementation delivers up to 485 Gflops of double precision performance, which translates to a speedup of up to 2.5X compared to the fastest known GPU implementation.	algorithm;automatic parallelization;cobham's thesis;computation;computer simulation;control flow;data access;double-precision floating-point format;electron;flops;fastest;graphics processing unit;heuristic;machine learning;nvidia tesla;parallel algorithm;parallel computing;particle system;rp (complexity);simulation;speedup;supervised learning;two-phase commit protocol	Kamesh Arumugam;Desh Ranjan;Mohammad Zubair;Balsa Terzic;Alexander Godunov;Tunazzina Islam	2017	2017 46th International Conference on Parallel Processing (ICPP)	10.1109/ICPP.2017.55	computer simulation;distributed computing;parallel computing;supervised learning;computation;theoretical computer science;architecture;computer science;instruction set;cuda pinned memory;machine learning;thread (computing);speedup;artificial intelligence	HPC	-5.413087080979188	38.89363314302042	109486
d05e940a15362aa50d376f69049c34d26289069a	horizons in scientific and distributed computing	distributed computing java scientific computing computer networks intelligent networks arithmetic internet web sites parallel processing technological innovation;scientific application;software reviews;distributed memory systems;distributed networks;engineering computing;distributed computing;parallel programming;object oriented programming;computer networks;c language;distributed object management;scientific computing;message passing;computer communications software;natural sciences computing;atm aggressive marketing scientific applications globally distributed networks computing technologies commercial computing world distributed scientific computing language support java mpi openmp distributed computation management distributed components mobile agents advanced networking technologies ipv6;asynchronous transfer mode;telecommunication networks;asynchronous transfer mode natural sciences computing computer networks java message passing parallel programming distributed object management;java	23 Over the past decade, a remarkable assortment of new communications and computing technologies has surfaced. Scientists and engineers have traditionally been at the forefront of developing and adopting such new technologies. For example, Unix, the Internet, the World Wide Web, and parallel computing incubated in scientific research environments before being mature enough for the general marketplace. However, the rapid commercial growth in personal computing and commodity networking has created a much larger consumer market equally hungry for new ideas. Consequently, many innovations in networking and computing are going directly from the laboratory to the marketplace, bypassing the scrutiny of scientific users before making a big commercial splash. For instance, spreadsheets, PCs, and even Visual Basic were quickly adopted by the businesscomputing community and only afterwards seen to be useful in scientific-computing circles. This article reviews some networking and computing technologies that are having a significant impact, real or perceived, in the commercial computing world and might be valuable for future distributed scientific computing. In many cases, an unfortunate combination of technical inbreeding and aggressive marketing has created jargon and hyperbole barriers to understanding. So, presentations of these technologies too often use terminology potentially foreign to scientific-computing people. That has been our experience at least. This article’s goal is to remove some of these barriers. Developing scientific applications on globally distributed networks requires language support (Java, MPI, OpenMP), mechanisms for managing distributed computations and services (components and agents), and advanced networking technologies (IPv6, ATM). We are devoting scarcely a page to each topic, and a little knowledge can be a dangerous thing. Nonetheless, the basic ideas are relatively easy to communicate and grasp.	atm turbo;computation;computational science;distributed computing;internet;jargon;java;message passing interface;microsoft forefront;openmp;parallel computing;personal computer;spreadsheet;unix;visual basic;world wide web	Carl J. Beckmann;Donald P McManus;George Cybenko	1999	Computing in Science and Engineering	10.1109/5992.743619	computational science;parallel computing;message passing;computer science;theoretical computer science;operating system;asynchronous transfer mode;distributed computing;programming language;object-oriented programming;java	HPC	-12.77818228041338	40.64302530618702	109558
b4a1809877083327d69705b484b2c6a290688cb3	communication-passing style for coordination languages	langage fonctionnel;lenguaje programacion;distributed system;semantica operacional;systeme reparti;programming language;lenguaje funcional;operational semantics;coordination language;data migration;semantique operationnelle;sistema repartido;message passing;langage programmation;systeme parallele;parallel system;functional language;sistema paralelo	Coordination languages for parallel and distributed systems specify mechanisms for creating tasks and communicating data among them. These languages typically assume that (a) once a task begins execution on some processor, it will remain resident on that processor throughout its lifetime, and (b) communicating shared data among tasks is through some form of message-passing and data migration. In this paper, we investigate an alternative approach to understanding coordination. Communication-passing style (CmPS) refers to a coordination semantics in which data communication is always undertaken by migrating the continuation of the task requiring the data to the processor where the data resides. Communication-passing style is closely related to continuation-passing style (CPS), a useful transformation for compiling functional languages. Just as CPS eliminates implicit call-return sequences, CmPS eliminates implicit inter-processor data communication and synchronization requests. In a CmPS-transformed program, only continuations (i.e., control contexts) are transmitted across machines; all synchronization and data communication occurs locally. Besides providing signiicant optimization opportunities, CmPS is a natural representation for implementations on networks of workstations. This paper presents an operational semantics for a coordination language that supports rst-class distributed data repositories. The computation sublanguage considered is an untyped call-by-value functional language similar to pure Scheme. Optimizations and implementation issues that arise from using a CmPS-driven coordination language are also described.	compiler;computation;continuation;continuation-passing style;distributed computing;emoticon;functional programming;mathematical optimization;message passing;operational semantics;scheme;sublanguage;workstation	Suresh Jagannathan	1997		10.1007/3-540-63383-9_77	parallel computing;message passing;data migration;computer science;artificial intelligence;operating system;database;distributed computing;programming language;functional programming;operational semantics;computer security;algorithm	PL	-16.69793670672331	41.49344852800046	109695
d43935e592858a71c304c1711ea559e3cd743c96	design considerations for a flexible multigrid preconditioning library	design consideration;trilinos software project;large sparse linear system;muelu package;trilinos capability;parallel multigrid;linear algebra operation;flexible multigrid;modern software construct;modern multigrid method;internal design	MueLu is a library within the Trilinos software project [An overview of Trilinos, Technical Report SAND2003-2927, Sandia National Laboratories, 2003] and provides a framework for parallel multigrid preconditioning methods for large sparse linear systems. While providing efficient implementations of modern multigrid methods based on smoothed aggregation and energy minimization concepts, MueLu is designed to be customized and extended. This article gives an overview of design considerations for the MueLu package: user interfaces, internal design, data management, usage of modern software constructs, leveraging Trilinos capabilities, linear algebra operations and advanced application.	multigrid method;preconditioner	Jérémie Gaidamour;Jonathan J. Hu;Christopher M. Siefert;Ray S. Tuminaro	2012	Scientific Programming	10.3233/SPR-2012-0344	computational science;parallel computing;computer science;theoretical computer science;multigrid method	HPC	-8.480895982683831	36.87395758118082	110103
48b8bbbcf6e0e3c21741f5335d8abf6698e5e7e8	ieee 1394: another low cost viable alternative interconnect for high performance computing			ieee 1394	Joseph Gill;Charles Torsoo;Legand L. Burge;Jiang Li	2005			computer science;parallel computing;distributed computing;ieee 1394;interconnection;supercomputer	HPC	-8.727839229545296	42.83236837158726	110133
dd0c9e99827cd178002e0b99c25fd17c70fe9231	implementation of a general-purpose dataflow multiprocessor	electrical engineering and computer science;thesis	Dataflow is one of the major models of parallel computation. Implementation of a General Purpose Dataflow Multiprocessor extends work in this area by introducing an unusually simple model of dynamic dataflow execution, called the Explicit Token Store (ETS) architecture, and its realization in Monsoon, a large-scale dataflow multiprocessor. Monsoon is currently under construction at the Motorola Microcomputer Division. Papadopoulos argues that the underlying sequential architecture of contemporary multiprocessors has not been able to support the synchronization demands of parallel execution and that these systems have largely failed to meet expectations for programmability and performance. He points out that processors must be fundamentally changed to execute a parallel machine language that coordinates parallel activities efficiently as instructions are scheduled. Although dataflow architectures have met this challenge by radically reformulating the basic specification of a machine program, they have suffered from substantial implementation shortcomings, notable the need for large associative memories. The ETS architecture Papadopoulos introduces here achieves the power of previous tagged-token dataflow architectures, but with a much leaner cycle and much less complexity. Gregory Papadopoulos is an Assistant Professor of Electrical Engineering and Computer Science in the Laboratory for Computer Science at MIT. Contents: General Purpose Multiprocessing. The TaggedToken Dataflow Architecture. The Explicit Token Store. Compiling for an ETS Dataflow Processor. Compiling Imperative Languages for an ETS. Monsoon: An ETS Multiprocessor. A Monsoon Instruction Decoding.	dataflow;general-purpose markup language;multiprocessing	Gregory M. Papadopoulus	1991			computer architecture;computer science;software engineering;computer engineering	Arch	-8.884076410129309	45.188959513327454	110324
77005c1514ee1016df6ca220de05d9c889fd9fe3	rückgekoppelte baumrechner und programmierung	parallelisme;multiprocessor;programming environment;programacion paralela;metodo dividir para vencer;parallel programming;ingenieria logiciel;transputer;software engineering;medio ambiente programacion;methode diviser pour gagner;parallelism;paralelismo;arbol binario;divide and conquer method;arbre binaire;genie logiciel;multiprocesador;environnement programmation;programmation parallele;multiprocesseur;binary tree	This paper describes a combination of a parallel computer architecture and a software engineering method. The underlying network structure is a complete binary tree of independend processors. In addition, a backlooping network exists		Jürgen Günter Kienhöfer	1989	Angewandte Informatik		parallel computing;multiprocessing;binary tree;computer science;theoretical computer science;algorithm	HCI	-16.302764054646325	40.786265880933314	110561
1e206370501442adb6a36826eb678e26dcef2f58	a compiler framework to detect parallelism in irregular codes	parallelisme;lenguaje programacion;strongly connected component;classification algorithm;analyse statique;programming language;parallelizing compilers;dependence graph;distributed computing;dependence;systematique;dependance;classification;analisis estatica;compilateur parallelisation;parallelism;paralelismo;sistematica;taxonomy;langage programmation;calculo repartido;static analysis;calcul reparti;clasificacion;dependencia	This paper describes a compiler framework that enhances the detection of parallelism in loops with complex irregular computations. The framework is based on the static analysis of the Gated Single Assignment (GSA) program representation. A taxonomy of the strongly connected components (SCCs) that appear in GSA dependence graphs is presented as the basis of our framework. Furthermore, an algorithm for classifying the set of SCCs associated with loops is described. We have implemented a prototype of the SCC classification algorithm using the infrastructure provided by the Polaris parallelizing compiler. Experimental results for a suite of real irregular programs are shown.	approximation;benchmark (computing);code;compiler;computation;computer graphics;data parallelism;finite element method;global storage architecture;international conference on services computing;loop-level parallelism;parallel computing;pattern matching;prototype;recurrence relation;scan conversion;sparse matrix;static program analysis;static single assignment form;strongly connected component;taxonomy (general)	Manuel Arenaz;Juan Touriño;Ramón Doallo	2001		10.1007/3-540-35767-X_20	parallel computing;biological classification;computer science;theoretical computer science;operating system;distributed computing;programming language;strongly connected component;static analysis;algorithm;taxonomy	HPC	-16.285945987312004	40.42937756727544	110617
6e8500534bbb30608a881e7c78d6155f5298c8ca	a holistic architecture for super real-time multiagent simulation platforms	message passing;multi agent systems	This paper describes a holistic architecture for super real-time multi-agent simulation platforms by implementing a complete and integrated simulation stack including a simulation runtime and an application layer that can be used for such situations as traffic simulations. With our prototype system, the first experiment tested the performance scalability when simulating millions of agents on 1,536 CPU cores over 256 nodes. By compiling the X10-based agent simulation system into C++ using MPI, we could run 600 simulation steps in only 78 seconds, which is nearly 10 times faster than real time. We then tested a national network spanning Japan, which was able to simulate a 100 million agents and at near-real time while using 128 nodes. This was the first attempt to deal with such a large number of agents and shows that this infrastructure could be used for large-scale agent simulations in various fields.	agent-based model;c++;central processing unit;compiler;file spanning;holism;message passing interface;prototype;real-time clock;scalability;simulation	Toyotaro Suzumura;Hiroki Kanezashi	2013	2013 Winter Simulations Conference (WSC)		parallel computing;message passing;real-time computing;simulation;computer science;multi-agent system;distributed computing;programming language	AI	-6.865490606302229	34.12351269534229	110645
710e13e8d05add939db39d8fb14059786f76a744	an adaptive data objects placement algorithm for non-uniform capacities	distributed memory;dynamic change;distributed system;distribution donnee;systeme reparti;systeme grande taille;algoritmo adaptativo;memoria compartida;distributed storage;stockage donnee;distributed storage system;large scale system;interval maps;data distribution;capacite stockage;adaptive algorithm;data storage;dynamic data;sistema repartido;stockage reparti;algorithme adaptatif;object oriented;capacidad almacenaje;storage capacity;noeud stockage objet donnee;almacenamiento datos;oriente objet;memoire repartie;orientado objeto;distribucion dato;sistema gran escala	The capacities of storage nodes usually are non-uniform and storage nodes are dynamically changed in large-scale distributed storage systems. In this paper, a novel dynamic data objects placement algorithm is proposed; data objects are always distributed among the storage nodes according to their capabilities. When storage nodes are changed, it affords to immediately rebalance data objects distribution according to weight of storage nodes. Simulation results indicates that data objects are always distributed among the storage nodes according to their capabilities and data objects are migrated throughout all storage nodes in parallel, resulting in minimum amount of replacement of objects.	algorithm	Zhong Liu;Xing-Ming Zhou	2004		10.1007/978-3-540-30208-7_59	parallel computing;dynamic data;distributed memory;distributed data store;computer science;operating system;computer data storage;database;distributed computing;object-oriented programming;algorithm	DB	-18.940335595609568	45.64623328614292	110718
3f38f1b86c0d9a5440383238427f1c68e7c5b271	load balancing in nest: a network of workstations	network of workstation;load balance		computer cluster;load balancing (computing);nest (neural simulation tool);workstation	Ahmed K. Ezzat	1986			computer architecture;parallel computing;computer science;load balancing;distributed computing	HPC	-10.608995920947336	42.79224029873705	111034
783cc4f510e1d32f4569210b1dfc1ea7c4df8ff8	a graphical environment for development of mpi applications	hyperedge replacement grammar;graph grammar;java mpi;workflow;parallel applications	This paper presents GD-MPI: a Graphical environment for Development of parallel MPI applications. GD-MPI offers users a web browser-based GUI to graphically specify both: workflows that represent a set of Java-MPI processes and communication between these processes including group creation, point-to-point and collective communications. GD-MPI also runs such processes remotely.	graphical user interface;java;message passing interface;point-to-point (telecommunications);web application	José Luis Quiroz-Fabián;Graciela Román-Alonso;Miguel A. Castro-García;Jorge Buenabad-Chávez;Manuel Aguilar Cornejo	2014		10.1145/2642769.2642793	computer science;theoretical computer science;distributed computing;programming language	HPC	-10.338888027938072	37.41299173123125	111208
be06d2db03e7ff7529d5b56efe48657de297e9a5	parallel genetic programming and its application to trading model induction	genetic program;premature convergence;distributed memory machine;financial trading models;parallel genetic programming;trading strategy;performance analysis;load balance;parallel implementation;dynamic scheduling	This paper presents a scalable parallel implementation of genetic programming on distributed memory machines. The system runs multiple master-slave instances each mapped on all the allocated nodes and multithreading is used to overlap message latencies with useful computation. Load balancing is achieved using a dynamic scheduling aigorithm and comparison with a static algorithm is reported. To alleviate premature convergence, asynchronous migration of individuals is performed among processes. We show that nearly linear speedups can be obtained for problems of large enough size. The system has been applied to infer robust trading strategies which is a compute-intensive financial application.	algorithm;asynchronous circuit;computation;distributed memory;genetic programming;load balancing (computing);multithreading (computer architecture);premature convergence;scalability;scheduling (computing);thread (computing)	Mouloud Oussaidène;Bastien Chopard;Olivier V. Pictet	1997	Parallel Computing	10.1016/S0167-8191(97)00045-8	parallel computing;dynamic priority scheduling;computer science;load balancing;theoretical computer science;trading strategy;distributed computing;premature convergence	HPC	-7.85669162640319	42.56761228388609	111247
29d485fc57f246bbbb3ef2e9adacd199ef494d6c	42 tflops hierarchical n-body simulations on gpus with applications in both astrophysics and turbulence	turbulence computational complexity graphics processing units n body simulations astronomical parallel architectures trees mathematics;work stealing;dynamic load balancing;paper;fast multipole method;task pools;performance;n body simulations;n body simulation;global arrays;cuda;armci;nvidia geforce 8800 gts;nvidia;graphic processing unit;pgas;astrophysics;hierarchical n body simulations cpu algorithm cost performance periodic fmm homogeneous isotropic turbulence vortex particle simulation gravitational simulation vortex particles turbulence simulation gravitational n body simulation unprecedented efficiency fast multipole method treecode graphics processing units astrophysics gpu	As an entry for the 2009 Gordon Bell price/performance prize, we present the results of two different hierarchical N-body simulations on a cluster of 256 graphics processing units (GPUs). Unlike many previous N-body simulations on GPUs that scale as O(N2), the present method calculates the O(N log N) treecode and O(N) fast multipole method (FMM) on the GPUs with unprecedented efficiency. We demonstrate the performance of our method by choosing one standard application --a gravitational N-body simulation-- and one non-standard application --simulation of turbulence using vortex particles. The gravitational simulation using the treecode with 1,608,044,129 particles showed a sustained performance of 42.15 TFlops. The vortex particle simulation of homogeneous isotropic turbulence using the periodic FMM with 16,777,216 particles showed a sustained performance of 20.2 TFlops. The overall cost of the hardware was 228,912 dollars. The maximum corrected performance is 28.1TFlops for the gravitational simulation, which results in a cost performance of 124 MFlops/$. This correction is performed by counting the Flops based on the most efficient CPU algorithm. Any extra Flops that arise from the GPU implementation and parameter differences are not included in the 124 MFlops/$.	algorithm;central processing unit;computer graphics;flops;fast multipole method;gordon bell;graphics processing unit;simulation;software prototyping;turbulence;vortex	Tsuyoshi Hamada;Tetsu Narumi;Rio Yokota;Kenji Yasuoka;Keigo Nitadori;Makoto Taiji	2009	Proceedings of the Conference on High Performance Computing Networking, Storage and Analysis	10.1145/1654059.1654123	parallel computing;simulation;performance;fast multipole method;computer science;theoretical computer science;partitioned global address space;n-body simulation	HPC	-4.567117286687777	38.38897196602009	111316
fdc822946fb1ae90c6ac2a01fb1300cd7b1fe362	paging strategy for prolog based dynamic virtual memory	virtual memory		paging;prolog	M. L. Ross;Kotagiri Ramamohanarao	1986			data diffusion machine;flat memory model;parallel computing;demand paging;page replacement algorithm;computer architecture;memory management;conventional memory;memory segmentation;virtual memory;computer science	Arch	-10.753037923964376	43.955708460371476	111381
887a5ba2ecc0b21f0e8ecf8c5b0041153310ea34	parallel monte-carlo simulations on gpu and xeon phi for stratospheric balloon envelope drift descent analysis	microwave integrated circuits;performance evaluation;coprocessors;computer architecture;graphics processing units;monte carlo methods;instruction sets	A performance evaluation of parallel Monte-Carlo simulations on GPU, MIC is presented, the application to stratospheric balloon envelope drift descent is considered. The experiments show that GPU, MIC permit one to decrease computing time by a factor of 4, 2, respectively, as compared to a parallel code implemented on a two sockets CPU (E5-2680-v2) which allows us to use these devices in operational conditions.	automatic vectorization;central processing unit;code;descent;experiment;graphics processing unit;initial condition;library (computing);locality of reference;midi;monte carlo method;numerical analysis;parallel algorithm;parallel computing;performance evaluation;ray tracing (graphics);simulation;tesla (microarchitecture);xeon phi	Bastien Plazolles;Didier El Baz;Martin Spel;Vincent Rivola;Pascal Gegout	2016	2016 Intl IEEE Conferences on Ubiquitous Intelligence & Computing, Advanced and Trusted Computing, Scalable Computing and Communications, Cloud and Big Data Computing, Internet of People, and Smart World Congress (UIC/ATC/ScalCom/CBDCom/IoP/SmartWorld)	10.1109/UIC-ATC-ScalCom-CBDCom-IoP-SmartWorld.2016.0103	embedded system;parallel computing;computer hardware;computer science;operating system;instruction set;coprocessor;monte carlo method;computer graphics (images)	HPC	-5.597929471868262	39.38749077441882	111531
641c050c743834f232eba73fdc0d9b3f183e88a1	automatic data distribution for composite grid applications	composite grid application;automatic data distribution	Problem topology is the key to efficient parallelization support for partially regular applications. Specifically, problem topology provides the information necessary for automatic data distribution and regular application optimization of a large class of partially regular applications. Problem topology is the connectivity of the problem. This research focuses on composite grid applications and strives to take advantage of their partial regularity in the parallelization and compilation process. Composite grid problems arise in important application areas, e.g., reactor and aerodynamic simulation. Related physical phenomena are inherently parallel and their simulations are computationally intensive. We present algorithms that automatically determine data distributions for composite grid problems. Our algorithmu0027s alignment and distribution specifications may be used as input to a High Performance Fortran program to apply the mapping for execution of the simulation code. These algorithms eliminate the need for user-specified data distribution for this large class of complex topology problems. We test the algorithms using a number of topological descriptions from aerodynamic and water-cooled nuclear reactor simulations. Speedup-bound predictions with and without communication, based on the automatically generated distributions, indicate that significant speedups are possible using these algorithms.		Lorie M. Liebrock;Ken Kennedy	1997	Scientific Programming		mathematical optimization;computer science;theoretical computer science;distributed computing	HPC	-8.370761455863176	35.62030029411036	111537
b62166d29dfbe71b90e667bbb5ce353249fb0fac	a pipeline technique for dynamic data transfer on a multiprocessor grid	parallel and distributed system;pipeline tasks;processor classes;dynamic data;high performance fortran;block cyclic redistribution;data transfer	This paper describes a pipeline technique which is used to redistribute data on a multiprocessor grid during runtime. The main purposes of the algorithm are to minimize the data transfer time, prevent congestion on the ports of the receiving processors, and minimize the number of idle processors. One of the key ideas for this algorithm is the creation of processor classes, firstly introduced by Desprez et al. [IEEE Transactions on Parallel and Distributed Systems 9(2):102 (1998).] Based on the idea of classes, we create the pipeline tasks used to organize the redistribution of data. Our experimental results show that this pipeline technique can significantly reduce the amount of time required to complete a dynamic data transfer task.	central processing unit;circulant matrix;distributed computing;dynamic data;formal grammar;multiprocessing;network congestion;parallel algorithm;pipeline (computing);processor register	Stavros Souravlas;Manos Roumeliotis	2004	International Journal of Parallel Programming	10.1023/B:IJPP.0000038068.80639.52	parallel computing;real-time computing;dynamic data;computer science;operating system;distributed computing	EDA	-11.471484199249105	43.19716499160949	111634
ef4d0858835ce735dc24b7263446c29993631d44	evaluating architecture and compiler design through static loop analysis	optimising compilers;program diagnostics;storage management;program control structures;compiler design evaluation prefetcher loop buffer size vectorization evaluation register allocation evaluation assembly patterns large representative code corpus low level assembly feature extraction benchmark suits binary loops maqao loop static analyzer static loop analysis architecture design evaluation;storage management feature extraction optimising compilers program control structures program diagnostics software architecture;registers benchmark testing vectors assembly measurement computer architecture ports computers;simulation and evaluation techniques benchmarking and assessment software monitoring and measurement hpc monitoring and instrumentation modeling;software architecture;feature extraction	Using the MAQAO loop static analyzer, we characterize a corpus of binary loops extracted from common benchmark suits such as SPEC, NAS, etc. and several industrial applications. For each loop, MAQAO extracts low-level assembly features such as: integer and floating-point vectorization ratio, number of registers used and spill-fill, number of concurrent memory streams accessed, etc. The distributions of these features on a large representative code corpus can be used to evaluate compilers and architectures and tune them for the most frequently used assembly patterns. In this paper, we present the MAQAO loop analyzer and a characterization of the 4857 binary loops. We evaluate register allocation and vectorization on two compilers and propose a method to tune loop buffer size and stream prefetcher based on static analysis of benchmarks.	automatic vectorization;benchmark (computing);compiler;gnu compiler collection;heuristic (computer science);high- and low-level;mesh analysis;nehalem (microarchitecture);period-doubling bifurcation;prefetcher;register allocation;sandy bridge;static program analysis;text corpus	Yuriy Kashnikov;Pablo de Oliveira Castro;Emmanuel Oseret;William Jalby	2013	2013 International Conference on High Performance Computing & Simulation (HPCS)	10.1109/HPCSim.2013.6641465	loop tiling;software architecture;computer architecture;parallel computing;real-time computing;loop interchange;feature extraction;computer science;operating system;programming language	HPC	-17.11138735634509	38.60480442734556	111695
529600daea7a0374c80bb282b7bf1c9ae2b23d40	self-optimization of mpi applications within an autonomic framework	distributed application;distributed system;occupation time;optimisation;haute performance;systeme reparti;n body system;optimizacion;dynamic reconfiguration;reconfigurable architectures;atelier genie logiciel;distributed computing;systeme n corps;dynamical system;systeme dynamique;sistema repartido;temps occupation;message passing interface;envoi message;algorithme reparti;tiempo ocupacion;message passing;alto rendimiento;calculo repartido;algoritmo repartido;sistema n cuerpos;mpi;optimization;sistema dinamico;distributed algorithm;high performance;calcul reparti;architecture reconfigurable;software engineering workshop	An existing autonomic framework (MAWeS) can be used to provide run-time self-optimization for distributed applications. This paper introduces a new MAWeS Component that provides an interface for MPI applications. As case study, we will present the implementation of a dynamically-reconfigurable n-body solver, evaluating its obtained performance with and without the MAWeS framework under several different working load conditions.	autonomic computing;distributed computing;load (computing);mathematical optimization;message passing interface;solver	M. Iannotta;Emilio Pasquale Mancini;Massimiliano Rak;Umberto Villano	2006		10.1007/11847366_22	distributed algorithm;parallel computing;real-time computing;computer science;message passing interface;distributed computing	HPC	-18.150828689062834	42.409485476293845	111791
4c72540455511f6eb0e881a3ae87d96b0ccb1f41	automatically partitioning threads based on remote paths	remote paths;optimising compilers;graph theory;procedural programs;thread scheduling optimized threads remote paths multithreaded architectures nonredundant data dependence graph automatic program partitioning low level threads procedural programs earth c compiler intermediate representation thread partitioning constraints;thread scheduling;multi threading;yarn;processor scheduling;ddg;yarn partitioning algorithms delay program processors parallel processing buildings communication switching algorithm design and analysis communication system control bandwidth;automatic program partitioning;parallel architectures;data dependence;computational complexity;multithreaded architecture;thread partitioning constraints;multithreaded architectures;bandwidth;communication switching;parallel architectures multi threading optimising compilers graph theory processor scheduling computational complexity;communication system control;program processors;algorithm design and analysis;parallel processing;buildings;earth c compiler;partitioning algorithms;optimized threads;low level threads;intermediate representation;nonredundant data dependence graph	"""In order to program multithreaded architectures e ectively compiler support to automatically partition programs into threads is essential. This paper proposes a remote-path based thread partitioning framework, which can generate low-level threads from procedural programs automatically. The framework has been implemented in the EARTH-C compiler, which uses Data Dependence Graph (DDG) as an intermediate representation for thread partitioning. To make the compiler work fast, a practical O(n2) algorithm is designed to build non-redundant DDG. To generate correct and e cient threaded code, the remote-path heuristic is employed to satisfy thread partitioning constraints and schedule threads to run fast. The experimental results show that the DDG building algorithm is fast and the remote path based heuristic is very e ective in partitioning programs into \optimized"""" threads."""	algorithm;compiler;data dependency;duckduckgo;heuristic;high- and low-level;intermediate representation;thread (computing);threaded code	Xinan Tang;Guang R. Gao	1998		10.1109/ICPADS.1998.741146	parallel processing;algorithm design;computer architecture;parallel computing;real-time computing;multithreading;computer science;graph theory;operating system;distributed computing;green threads;programming language;intermediate language;computational complexity theory;bandwidth;algorithm	PL	-14.684044684025496	41.70923844281126	111853
9c084a56c1c625da116eca474208d9780539ceff	db2 parallel edition	tratamiento paralelo;detection erreur;optimisation;deteccion error;base donnee;mise a jour;shared memory;edition electronique;protocole transmission;traitement parallele;optimizacion;reseau interconnecte;memoria compartida;correction erreur;database;base dato;protocolo transmision;edicion electronica;error correction;optimization;puesta al dia;electronic publishing;systeme parallele;parallel system;correccion error;error detection;red interconectada;interconnected power system;parallel processing;sistema paralelo;updating;memoire partagee;transmission protocol	The rate of increase in database size and response time requirements has outpaced advancements in processor and mass storage technology. One way to satisfy the increasing demand for processing power and I/O bandwidth in database applications is to have a number of processors, loosely or tightly coupled, serving database requests concurrently. Technologies developed during the last decade have made commercial parallel database systems a reality and these systems have made an inroad into the stronghold of traditionally mainframe based large database applications. This paper describes the parallel database project initiated at IBM Research at Hawthorne and the DB2/AIX-PE product based on it.	central processing unit;ibm research;input/output;mainframe computer;mass storage;parallel database;requirement;response time (technology);stronghold	Chaitanya K. Baru;Gilles Fecteau;Ambuj Goyal;Hui-I Hsiao;Anant Jhingran;Sriram Padmanabhan;George P. Copeland;Walter G. Wilson	1995	IBM Systems Journal	10.1147/sj.342.0292	parallel processing;error detection and correction;telecommunications;computer science;artificial intelligence;operating system;database;electronic publishing	DB	-18.80570200285083	44.287441420084185	111983
b98d2a853949cf4eb24043c26a0dfe6ea99b954f	modeling the weather with a data flow supercomputer	parallel calculus;atmospheric models;computers;equation differentielle;concurrent computing;weather;pipelined computation computer architecture data flow global weather model parallel computation partial differential equations performance analysis;flot donnee;pipelined computation;differential equation;global weather model;arrays computers computational modeling meteorology computer architecture supercomputers concurrent computing;parallel computation;modelisation;arrays;computer architecture;pipelining computers;computational modeling;architecture ordinateur;partial differential equations;analyse performance;computerized simulation;performance analysis;iteration;parallel processing computers;machine oriented languages;data flow;architecture computers;super ordinateur;modeling;calcul parallele;meteorology;supercomputers;programming languages	Data flow computers promise efficient parallel computation limited in speed only by data dependencies in the calculation being performed. At the Massachusetts Institute of Technology Laboratory for Computer Science, the Computation Structures Group is working to design practical data flow computers that can outperform conventional supercomputers. Since data flow computers differ radically in structure from conventional (sequential) computers, the projection of their performance must be done through analysis of specific computations. The performance improvement that data flow computers offer is shown for a NASA benchmark program that implements a global weather model. We present the structure of the weather code as expressed in VAL, a functional programming language designed by the Computation Structures Group, and develop the corresponding machine-level program structures for efficient execution on a data flow supercomputer. On the basis of this analysis, we specify the capacities of hardware units and the number of each type of unit required to achieve a twenty-fold improvement in performance for the weather simulation application.	benchmark (computing);computation;data dependency;dataflow architecture;functional programming;mit computer science and artificial intelligence laboratory;numerical weather prediction;parallel computing;programming language;simulation;supercomputer;variable assembly language	Jack B. Dennis;Guang R. Gao;Kenneth W. Todd	1984	IEEE Transactions on Computers	10.1109/TC.1984.5009332	embedded system;computational science;parallel computing;iteration;concurrent computing;computer science;theoretical computer science;operating system;programming language;atmospheric models;differential equation;algorithm	HPC	-11.277299020179717	38.38066749225037	112024
668c8da354dcf31304fb9a3be11c8c93fba23a0a	importance of runtime considerations in performance engineering of large-scale distributed graph algorithms		Due to the ever increasing complexity of the modern supercomputers, performance analysis of irregular applications became an experimental endeavor. We show that runtime considerations are inseparable from algorithmic concerns in performance engineering of large-scale distributed graph algorithms, and we argue that the whole system stack, starting with the algorithm at the top down to low-level communication libraries must be considered.	algorithm;list of algorithms;performance engineering	Jesun Sahariar Firoz;Thejaka Amila Kanewala;Marcin Zalewski;Martina Barnas;Andrew Lumsdaine	2015		10.1007/978-3-319-27308-2_45	computer science;theoretical computer science;distributed computing	DB	-13.943342056247623	39.65014977493714	112104
2dbee14cdb2f4af629997451eaaf6aef828ba8fa	reducing resource consumption of expandable collections: the pharo case		Abstract Expandable collections are collections whose size may vary as elements are added and removed. Hash maps and ordered collections are popular expandable collections. Expandable collection classes offer an easy-to-use API, however this apparent simplicity is accompanied by a significant amount of wasted resources. We describe some improvements of the collection library to reduce the amount of waste associated with collection expansions. We have designed two new collection libraries for the Pharo programming language that exhibit better resource management than the standard library. We improved the Pharo collection library using two complementary perspectives. First, across a basket of 5 applications, our optimized collection library significantly reduces the memory footprint of the collections: (i) the amount of intermediary internal array storage by 73%, (ii) the number of allocated bytes by 67% and (iii) the number of unused bytes by 72%. This reduction of memory is accompanied by a speedup of about 3% for most of our benchmarks. Second, we looked for an alternative to the classical expandable collection. The Lua programming language offers a unique abstract data type called table . We designed, implemented, and introduced this data type in the Pharo programming language and we ran a number of micro and macro-benchmarks. Overall, replacing the standard Pharo collection library by one inspired on Luau0027s table data type results in an execution speedup of up to 15% and a reduction of the memory consumption by up to 19%. We analyzed the collection implementations of Java, C#, Scala, and Ruby: these implementations largely behave like Pharou0027s, therefore with the same limitations. Our results are thus likely to benefit designers of future programming languages and collection libraries.	pharo	Alexandre Bergel;Alejandro Infante;Sergio Maass;Juan Pablo Sandoval Alcocer	2018	Sci. Comput. Program.	10.1016/j.scico.2017.12.009	programming language;hash table;memory footprint;data type;abstract data type;scala;pharo;speedup;computer science;java	Logic	-18.594078962697143	35.25487809361014	112179
15abf3baf2b10631002a715fc66d334ad2716e5b	scalability of an unstructured grid continuous galerkin based hurricane storm surge model	parallel computing;forecasting;galerkin method;high resolution;domain decomposition;real time;finite element method;finite element;shallow water equations;scaling;unstructured grid;message passing interface;storm surge;generalized wave continuity equation;time use;parallel computer;hurricane storm surge model;shallow water equation	This paper evaluates the parallel performance and scalability of an unstructured grid Shallow Water Equation (SWE) hurricane storm surge model. We use the ADCIRC model, which is based on the generalized wave continuity equation continuous Galerkin method, within a parallel computational framework based on domain decomposition and the MPI (Message Passing Interface) library. We measure the performance of the model run implicitly and explicitly on various grids. We analyze the performance as well as accuracy with various spatial and temporal discretizations. We improve the output writing performance by introducing sets of dedicated writer cores. Performance is measured on the Texas Advanced Computing Center Ranger machine. A high resolution 9,314,706 finite element node grid with 1 s time steps can complete a day of real time hurricane storm surge simulation in less than 20 min of computer wall clock time, using 16,384 cores with sets of dedicated writer cores.	algorithm;analysis of algorithms;central processing unit;computation;discretization;domain decomposition methods;finite element method;galerkin method;image resolution;image scaling;message passing interface;multistage interconnection networks;requirement;scalability;scott continuity;simulation;teragrid;unstructured grid;ranger	S. Tanaka;Shintaro Bunya;Joannes J. Westerink;Clint Dawson;Rick A. Luettich	2011	J. Sci. Comput.	10.1007/s10915-010-9402-1	meteorology;real-time computing;simulation;computer science;finite element method;mathematics;shallow water equations;thermodynamics	HPC	-6.6024730041682975	38.50785170200654	112193
11fb91cf78700428342aa3ed6636f655bb97ca33	rcdc: a relaxed consistency deterministic computer	estensibilidad;modelizacion;memoria tampon;comptage;gestion memoire;fiabilidad;reliability;haute performance;data race;shared memory;systeme multiprocesseur memoire repartie;multiprocessor;hardware complexity;complexite materiel;memoria compartida;acces concurrent;relacion orden;storage management;performance;ordering;parallel programming;langage java;contaje;approche deterministe;deterministic approach;modelisation;relation ordre;gestion memoria;acceso simultaneo;multicore;innovation;speculation;consistencia soltada;multiprocessor architecture;fiabilite;data races;complejidad hardware;sistema multiprocesador memoria distribuida;enfoque determinista;consistance relachee;counting;alto rendimiento;multithread;design;lenguaje java;runtime system;extensibilite;distributed memory multiprocessor system;scalability;multitâche;relaxed consistency;multiprocesador;determinism;innovacion;parallel programs;memoire tampon;modeling;high performance;multitarea;especulacion;memoire partagee;java language;shared memory multiprocessor;multiprocesseur;buffer memory;memory model	Providing deterministic execution significantly simplifies the debugging, testing, replication, and deployment of multithreaded programs. Recent work has developed deterministic multiprocessor architectures as well as compiler and runtime systems that enforce determinism in current hardware. Such work has incidentally imposed strong memory-ordering properties. Historically, memory ordering has been relaxed in favor of higher performance in shared memory multiprocessors and, interestingly, determinism exacerbates the cost of strong memory ordering. Consequently, we argue that relaxed memory ordering is vital to achieving faster deterministic execution.  This paper introduces RCDC, a deterministic multiprocessor architecture that takes advantage of relaxed memory orderings to provide high-performance deterministic execution with low hardware complexity. RCDC has two key innovations: a hybrid HW/SW approach to enforcing determinism; and a new deterministic execution strategy that leverages data-race-free-based memory models (e.g., the models for Java and C++) to improve performance and scalability without sacrificing determinism, even in the presence of races. In our hybrid HW/SW approach, the only hardware mechanisms required are software-controlled store buffering and support for precise instruction counting; we do not require speculation. A runtime system uses these mechanisms to enforce determinism for arbitrary programs.  We evaluate RCDC using PARSEC benchmarks and show that relaxing memory ordering leads to performance and scalability close to nondeterministic execution without requiring any form of speculation. We also compare our new execution strategy to one based on TSO (total-store-ordering) and show that some applications benefit significantly from the extra relaxation. We also evaluate a software-only implementation of our new deterministic execution strategy.	algorithm;benchmark (computing);c++;compiler;debugging;java;linear programming relaxation;memory ordering;multiprocessing;multithreading (computer architecture);parsec;race condition;runtime system;scalability;serializability;shared memory;shattered world;software deployment;software design;speculative execution;thread (computing)	Joseph Devietti;Jacob S Nelson;Tom Bergan;Luis Ceze;Dan Grossman	2011		10.1145/1950365.1950376	innovation;shared memory;memory model;design;speculation;parallel computing;real-time computing;scalability;performance;computer science;operating system;reliability;distributed computing;programming language;counting;determinism	Arch	-19.03268634324027	40.7348084874592	112209
8572ca46c8b0b2bc262b168035859a43124e1d1d	debugging and testing features of the dataflow parallel computing system components and devices	computers;communication networks;computer model;data processing;computer architecture;software architecture;computational modeling;program testing;community networks;data visualization;parallel computer;data flow computing;data visualization computational modeling communication networks parallel processing computer architecture data processing computers;software architecture data flow computing program debugging program testing;program debugging;nontraditional architecture debugging features testing features dataflow parallel computing system dynamic display computational process;parallel processing	The paper describes the new tools for dynamic display of the computational process for modeling a dataflow parallel computing system that implements non-traditional architecture. These tools allow evaluating the effectiveness of program and localization functions during the task.	c localization functions;computation;dataflow;debugging;internationalization and localization;parallel computing	N. N. Levchenko;A. S. Okunev;D. E. Yakhontov;D. N. Zmejev	2011	2011 9th East-West Design & Test Symposium (EWDTS)	10.1109/EWDTS.2011.6116603	dataflow architecture;computer architecture;parallel computing;computer science;programming language	SE	-11.85511341715877	43.318856639117946	112227
fbae43324ac9500ad8c976e1ffe3b382c6f29b0f	parallel calculations on the cm-2: bbs test programs and spectral methods	spectral method	Abstract   The implementation of the Because Benchmark Set programs on the Connection Machine CM-2 is presented and discussed. The characteristics of this machine have been taken into account during the BBS implementations, leading to somewhat different formulations, for some of the BBS programs. These situations are detailed to outline the way algorithms work.  In a second section, the generation of a Computational Fluid Dynamics software is described; the numerical method used (spectral method) is explained, in order to understand the algorithmic solutions that are proposed. The resulting code has then been run on an example showing mixing layer instability, and then compared with similar codes running on Convex and CRAY II vector supercomputers.	connection machine;spectral method	Jean-Michel Malé	1994	Future Generation Comp. Syst.	10.1016/0167-739X(94)90002-7	parallel computing;computer science;theoretical computer science;distributed computing;algorithm;spectral method	Arch	-4.605260564087902	36.75607134008141	112333
59ea950568acd366a521efdb9749ad4d8f54afbb	a survey of algorithmic skeleton frameworks: high-level structured parallel programming enablers	high-level structured parallel programming;parallel computation;parallel program;parallel software development environment;structured parallel program;algorithmic skeleton;algorithmic skeleton framework;algorithmic structure;parameterizable algorithmic skeleton;abstract description	Structured parallel programs ought to be conceived as two se parate and complementary entities: computation, which expresses the calculations in a procedu ral manner, and coordination, which abstracts the interaction and communication. By abstracting commonl y-used patterns of parallel computation, communication, and interaction, algorithmic skeletons en able programmers to code algorithms without specifying platform-dependent primitives. This article p r sents a literature review on algorithmic skeleton frameworks (ASKF), parallel software development environments furnishin g a collection of parameterisable algorithmic skeletons, where the control flow, nesting, res ource monitoring, and portability of the resulting parallel program is dictated by the AS KF as opposed to the programmer. Consequently, the AS KF can be positioned as high-level structured parallel programming e ablers, as their systematic utilisation permits the abstract description of programs and fosters portability b y focusing on the description of the algorithmic structure rather than on its detailed implementation. Copy right c © 0000 John Wiley & Sons, Ltd.	algorithm;algorithmic skeleton;computation;control flow;entity;high- and low-level;john d. wiley;kalman filter;parallel computing;programmer;software development;software portability;year 10,000 problem	Horacio González-Vélez;Mario Leyton	2010	Softw., Pract. Exper.	10.1002/spe.1026	parallel computing;computer science;theoretical computer science;operating system;distributed computing;algorithmic skeleton;programming language	PL	-13.879955732337375	39.12228687380623	112427
69bde1f9095b287aaced3bc339c451adc1580976	the partitioning problem for a class of data parallel algorithms	tratamiento datos;lenguaje programacion;outil logiciel;algoritmo paralelo;data parallel;software tool;partition method;parallel algorithm;shared memory;programming language;memoria compartida;sistema informatico;data processing;traitement donnee;computer system;spmd;algorithme parallele;calculateur mimd;methode partition;herramienta controlada por logicial;datavetenskap datalogi;langage programmation;systeme informatique;metodo particion;systeme parallele;parallel system;computer science;sistema paralelo;mimd computer;memoire partagee	Abstract   A solution to the partitioning problem is presented for a class of data parallel algorithms (including for example explicit difference methods for time-dependent PDE, and image processing algorithms based on local filters). Conditions are formulated, that characterize the optimal partitioning. From them, an explicit formula for the optimal partitioning is derived, which is valid in special cases. For the general case, the conditions provide a basis for the formulation of iterative partitioning algorithms. One such algorithm is proposed. The partitioning algorithm is intended as a tool to be used in utility routines or, ultimately, compilers, to enhance SPMD programming of MIMD-type computers with distributed memory. Results from an application in image analysis show that the algorithm is suitable for this purpose.	data parallelism;parallel algorithm;partition problem	M. Thune	1992	Parallel Computing	10.1016/0167-8191(92)90033-4	shared memory;parallel computing;data processing;computer science;theoretical computer science;parallel algorithm;spmd;set partitioning in hierarchical trees;algorithm	HPC	-12.245886476323621	37.63003317970634	112457
f5a5a775ad414deec549aac371f2294d62fbd137	fast distributed computing for complete large scale backtranslation of oligopeptides: application to probe design	distributed algorithms;biology computing;oligonucleotide probes parallelization meta programming model driven engineering complete backtranslation;resource allocation;software engineering;c language;statistics;lab on a chip;workstation clusters;load balancing distributed computing complete large scale backtranslation oligopeptides microarray probes design distributed algorithm functional microarrays oligonucleotides model driven engineering metaprogramming approach pc multiprocessor server computing cluster computing grid c programming language statistics simulated biological datasets real biological datasets;workstation clusters biology computing c language distributed algorithms grid computing lab on a chip resource allocation software engineering statistics;grid computing;probes dna amino acids proteins program processors algorithm design and analysis	We present a new efficient distributed algorithm to compute a full backtranslation of short oligopeptides for functional microarrays, and to filter generated oligonucleotides according to usual selection criteria for the design of microarray probes. We used a model driven engineering and metaprogramming approach to simultaneously process several hundreds of oligopeptides whether using a PC, a multiprocessor server, a computing cluster or a computing grid. We implemented our algorithm with the C++ programming language and we present its performance and statistics on both simulated and real biological datasets. Our algorithm includes load balancing and the obtained results show a significant computing speedup on different architectures (SMP, cluster and Grid) and an important gain of about 40% of disk space when filtering oligonucleotides.	computer cluster;disk space;distributed algorithm;distributed computing;grid computing;load balancing (computing);metaprogramming;microarray;model-driven engineering;multiprocessing;server (computing);speedup;the c++ programming language	Faouzi Jaziri;Eric Peyretaillade;Pierre Peyret;David R. C. Hill	2013	2013 International Conference on High Performance Computing & Simulation (HPCS)	10.1109/HPCSim.2013.6641423	distributed algorithm;parallel computing;lab-on-a-chip;resource allocation;computer science;theoretical computer science;operating system;distributed computing;programming language;grid computing	HPC	-9.32874489219917	37.981087856341986	112515
ab140134932b95958f19d39ebbfed4a9296eadaa	synthesizing mpi implementations from functional data-parallel programs	data parallelism;code generation;data distribution;mpi;type inference	Distributed memory architectures such as Linux clusters have become increasingly common but remain difficult to program. We target this problem and present a novel technique to automatically generate data distribution plans, and subsequently MPI implementations in C++, from programs written in a functional core language. The main novelty of our approach is that we support distributed arrays, maps, and lists in the same framework, rather than just arrays. We formalize distributed data layouts as types, which are then used both to search (via type inference) for optimal data distribution plans and to generate the MPI implementations. We introduce the core language and explain our formalization of distributed data layouts. We describe how we search for data distribution plans using an adaptation of the Damas–Milner type inference algorithm, and how we generate MPI implementations in C++ from such plans.	algorithm;c++;computer cluster;distributed memory;linux;map;type inference	Tristan Aubrey-Jones;Bernd Fischer	2015	International Journal of Parallel Programming	10.1007/s10766-015-0359-4	parallel computing;computer science;message passing interface;theoretical computer science;operating system;type inference;data parallelism;programming language;code generation	PL	-13.868084353083674	37.44559856789892	112556
c6c0f08e9271a601fdc02a9836a6cef1f6c0e2f9	a page-swapping prototype for vm/hpo	tiempo respuesta;virtual machine;eficacia sistema;evaluation performance;productivite;memory management;performance evaluation;evaluacion prestacion;performance systeme;response time;ingenieria logiciel;machine virtuelle;software engineering;productividad;system performance;temps reponse;prototipo;paging;acces par pages;genie logiciel;productivity;maquina virtual;high performance;prototype	This paper discusses a series of changes that were made to a system running the Virtual Machinelsystem Product with the High Performance Option to enhance paging. The motivation and the background for these enhancements are discussed, and the design of a se-ries of experimental paging subsystems is described and contrasted with the old design: specifically, the new algorithms for main memory management, block paging, working set identification, trimming, prepag ing, page replacement, page-out device selection, and page-out slot selection. The performance impact of these changes is illustrated by results of benchmark measurements, which are then contrasted to measure-ments without the enhancements. Some things learned in running the prototype are discussed and conclu-sions drawn. 	hpo formalism;hot swapping;paging;prototype	William H. Tetzlaff;Thomas Beretvas;William M. Buco;Jerry Greenberg;David R. Patterson;Gerald A. Spivak	1987	IBM Systems Journal	10.1147/sj.262.0215	embedded system;productivity;simulation;computer science;engineering;virtual machine;operating system;prototype;computer performance;response time;paging;memory management	OS	-17.530941265134636	45.624320837557974	112583
58f82f46735463f3bf424e6a1a4ec1f7946fcf6c	optimizing loops in database programming languages	database programming languages;timing optimization	Database programming languages like O 2 , E, and O++ include the ability to iterate through a set. Nested iterators can be used to express joins. We describe compile-time optimizations of such programming constructs that are similar to relational transformations like join reordering. Ensuring that the program’s semantics are preserved during transformation requires paying careful attention to the flow of values through the program. This paper presents conditions under which such transformations can be applied and analyzes the I/O performance of several different classes of program fragments before and after applying transformations. The analysis shows that the transformations can significantly reduce the number of I/Os performed, even when both the initial and transformed programs use the same join method.	acm computing surveys;algorithm;automatic parallelization;codasyl;compile time;computation;data manipulation language;database;dataflow;david kuck;david maier;decompiler;design rationale;fortran;heuristic (computer science);in-memory database;input/output;iteration;iterator;join (sql);linear algebra;loop interchange;mathematical optimization;nested sql;optimizing compiler;paging;parallel computing;parallel processing (dsp implementation);parallels desktop for mac;performance evaluation;persistence (computer science);program analysis;programming language;quantifier (logic);query optimization;query plan;richardson number;sorting;source-to-source compiler;speedup;stanley (vehicle);supercomputer;tree (data structure)	Daniel F. Lieuwen;David J. DeWitt	1991			computer science;third-generation programming language;database;programming paradigm;fifth-generation programming language;programming language;algorithm	DB	-17.724558054471068	34.2468743934563	112591
e3904ce275e6691e3f9fff64bd253f4f14fa9780	developing transputer-based systems using hood and parallel c	communication;concurrency;transputer;design	Parallel C is one of a number of high level languages now being used to program the transputer as well as Occam. These languages have been used successfully to program the transputer in a variety of application areas. Large-scale software systems should be specified at higher levels of abstraction during the early stages of system development. Design methods promote a systematic and methodical approach to the development of software. This paper describes the use of a particular method, HOOD, for the design of transputer-based systems. It has been used with Ada and C to program other architectures. Both HOOD and Parallel C support concurrency and are based on the synchronous approach to inter-process communication. Therefore, a consistent approach to concurrency and communication is adopted at the design and implementation phases. The paper outlines the transformation from HOOD to Parallel C and the implementation of HOOD's design features. The overall approach is best used with coarse-grain client-server applications, though some optimization during implementation is still necessary.	ada;client–server model;concurrency (computer science);hood method;high-level programming language;inter-process communication;mathematical optimization;principle of abstraction;server (computing);software system;transputer;unified parallel c (upc);occam	Paul Moore;Peter G. O'Donoghue	1994	Information & Software Technology	10.1016/0950-5849(94)90035-3	computer architecture;parallel computing;operating system	SE	-15.221308342429323	39.82567663588324	112901
d2a669dc11418ecec27673c3210380a793b50950	a transputer based generic message passing library	message passing;high performance	The message passing library provides an efficient set of simple message passing operations sufficient to implement the more  complex operations of standard message passing libraries. The library is portable to any system where a transputer process  can run in parallel with a compute process, which may run on a connected high-performance microprocessor.  	message passing;transputer	Adrian Cox	1995		10.1007/BFb0046741	computer architecture;parallel computing;message passing;computer science;distributed computing;message broker;programming language	HPC	-11.185796670053863	43.53781266976354	112965
f27e72bd719338f2eef9387023c7d0dc93928c40	exploiting data coherence to improve parallel volume rendering	rendering computer graphics concurrent computing pixel image generation distributed computing societies physics computing data visualization supercomputers power generation;virtual memory;fujitsu ap1000;concurrent computing;neighboring pixels;processing nodes;geometrically defined structures;volume rendering;distributed computing;physics computing;data distribution;image generation;world map;parallel processing rendering computer graphics coherence;pixel;image space work distribution;data visualization;parallel volume rendering;volume data sets;high quality image generation;power generation;coherence;distributed virtual memory;societies;data coherence;rendering computer graphics;coordinate axes;supercomputers;2d image partitioning;parallel processing;3d data assignment;ray casting;3d data assignment data coherence parallel volume rendering image space work distribution distributed virtual memory data distribution neighboring pixels ray casting fujitsu ap1000 high quality image generation volume data sets geometrically defined structures coordinate axes world map 2d image partitioning processing nodes;volume data	We have implemented a parallel volume renderer that successfully manages work and data distribution by exploiting data coherence-the tendency of neighboring pixels to use the same data during rendering, particularly when rendering volume data. This flexible, powerful renderer uses ray-casting on a Fujitsu AP1000 to generate high-quality images of volume data sets with other geometrically defined structures, such as a set of coordinate axes or a world map. This article focuses on our schemes for work and data distribution. Using image-space work distribution to partition a 2D image among processing nodes, and distributed virtual memory to assign 3D volume data, this renderer effectively and efficiently parallelizes volume rendering.<<ETX>>	parallel computing;pixel;ray casting;volume rendering	Paul Mackerras;Brian D Corrie	1994	IEEE Parallel & Distributed Technology: Systems & Applications	10.1109/88.311568	electricity generation;parallel processing;parallel computing;coherence;concurrent computing;computer science;virtual memory;theoretical computer science;operating system;ray casting;programming language;volume rendering;data visualization;pixel;computer graphics (images)	Visualization	-6.875057391054716	41.099524636658536	113201
f9d04e9769c5b2ce7899995e2aafdfc594ba3234	toward a dataflow/von neumann hybrid architecture	parallel architectures;dataflow/von neumann hybrid architecture;machine level latency;parallel machine language;program-level parallelism;scheduling;simulation studies;synchronization;uniform synchronization paradigm	Dataflow architectures offer the ability to trade program level parallelism in order to overcome machine level latency. Dataflow further offers a uniform synchronization paradigm, representing one end of a spectrum wherein the unit of scheduling is a single instruction. At the opposite extreme are the von Neumann architectures which schedule on a task, or process, basis. This paper examines the spectrum by proposing a new architecture which is a hybrid of dataflow and von Neumann organizations. The analysis attempts to discover those features of the dataflow architecture, lacking in a von Neumann machine, which are essential for tolerating latency and synchronization costs. These features are captured in the concept of a parallel machine language which can be grafted on top of an otherwise traditional von Neumann base. In such an architecture, the units of scheduling, called scheduling quanta, are bound at compile time rather than at instruction set design time. The parallel machine language supports this notion via a large synchronization name space. A prototypical architecture is described, and results of simulation studies are presented. A comparison is made between the MIT Tagged-Token Dataflow machine and the subject machine which presents a model for understanding the cost of synchronization in a parallel environment.	compile time;compiler;dataflow architecture;machine code;parallel computing;programme level;programming paradigm;quanta computer;scheduling (computing);simulation;von neumann architecture	Robert A. Iannucci	1988			dataflow architecture;spectrum;computer architecture;parallel computing;real-time computing;computer science;theoretical computer science;operating system;dataflow;programming language	Arch	-13.58380331131214	40.535992265150604	113251
96d67c6fe2ae98208482338b37750fe809080230	the design of a packet capturing system for measuring ieee802.5 token-ring performances (abstract only)	simd;parallel sorting;multiprocessor;linearly connected parallel computer;mesh connected parallel computer		packet analyzer;performance;token ring	Dennis S. Mok	1987		10.1145/322917.322981	computer architecture;parallel computing;multiprocessing;simd;computer science;distributed computing	Metrics	-10.695930014725935	43.07060105492426	113270
45af5120f7a2c0ab5a7c1a346dd88ee64bcca381	a cellular automata calculation model based on ternary optical computers	optical computing;large scale;cellular automata;dislocations	This paper proposes a novel CACM (Cellular Automata Calculation Model), which has two advantages: the high controllability and the parallelism of computing. The former advantage means that: the transformation rules of every cell and a cell at different time can be different. And the latter guarantees that it is possible to construct a large-scale CA efficiently, for the reason that the CA is computed in parallel. The computing platform is TOC (Ternary Optical Computer) and the algorithm is superposition in dislocation, which are both the bases of the CACM. Using the CACM, it is valid to construct more complicated and powerful CA.		Liang Teng;Junjie Peng;Yi Jin;Mei Li	2009		10.1007/978-3-642-11842-5_52	cellular automaton;parallel computing;computer science;theoretical computer science;dislocation;distributed computing;optical computing;algorithm	Theory	-7.616389818564493	36.765481311566695	113433
62e1de0075f26f5df14ea4c2bfe8712446ae79d3	a second-order distributed trotter-suzuki solver with a hybrid kernel		The Trotter-Suzuki approximation leads to an efficient algorithm for solving the timedependent Schrödinger equation. Using existing highly optimized CPU and GPU kernels, we developed a distributed version of the algorithm that runs efficiently on a cluster. Our implementation also improves single node performance, and is able to use multiple GPUs within a node. The scaling is close to linear using the CPU kernels, whereas the efficiency of GPU kernels improve with larger matrices. We also introduce a hybrid kernel that simultaneously uses multicore CPUs and GPUs in a distributed system. This kernel is shown to be efficient when the matrix size would not fit in the GPU memory. Larger quantum systems scale especially well with a high number nodes. The code is available under an open source license.	algorithm;approximation;cpu socket;central processing unit;distributed computing;graphics processing unit;hybrid kernel;image scaling;kernel (operating system);multi-core processor;open-source license;open-source software;quantum system;schrödinger;solver;the matrix	Peter Wittek;Fernando M. Cucchietti	2012	CoRR		computational science;hybrid kernel;parallel computing;hamiltonian;numerical analysis;computer science;message passing interface;theoretical computer science;package;general-purpose computing on graphics processing units;physics;quantum mechanics	HPC	-4.817449499389229	39.29938001965646	113466
b21a5afafc1b70906fe8b73571878cf7c10e6cbf	accomplishments and challenges in code development for parallel and multimechanics simulations	engineering;technology development;performance;transient analysis;chip;simulation software;heat transfer;mechanics;computer codes;large deformation;parallel processing	The Methods Development Group at Lawrence Livermore National Laboratory has historically developed and supported software for engineering simulations, with a focus on nonlinear structural mechanics and heat transfer. The quality, quantity and complexity of engineering analyses have continued to increase over time as advances in chip speed and multiprocessing computers have empowered this simulation software. As such, the evolution of simulation software has seen a greater focus on multimechanics and the incorporation of more sophisticated algorithms to improve accuracy, robustness and usability. This paper will give an overview of the latest code technologies developed by the Methods Development group in the areas of large deformation transient analysis and implicit coupled codes. Applications were run on the state of the art hardware available at the national laboratories.	algorithm;code;computer simulation;multiprocessing;nonlinear system;simulation software;transient state;usability	Tony Degroot;Robert Ferencz;Mark Havstad;Neil Hodge;Jerry Lin;Dennis Parsons;Michael Puso;Jerome Solberg;Edward Zywicz	2008		10.1007/978-3-540-92859-1_20	chip;parallel processing;parallel computing;simulation;simulation software;performance;computer science;distributed computing;heat transfer	SE	-6.5743756094495	37.746189578794635	113658
726dbeb9921e5e7ec5caa5f35a31bdf28cf96631	the processing of a class of transitive-closure queries on uniprocessor and shared-nothing multiprocessor systems	distributed system;base relacional dato;algoritmo paralelo;evaluation performance;systeme reparti;parallel algorithm;algoritmo busqueda;performance evaluation;multiprocessor;multiprocessor systems;algorithme recherche;evaluacion prestacion;sistema informatico;algoritmo recursivo;search algorithm;interrogation base donnee;multiprocessors;interrogacion base datos;transmission message;computer system;relational database;message transmission;recursive rules;algorithme parallele;sistema repartido;algorithme recursif;fermeture transitive;transitive closure queries;base donnee relationnelle;transitive closure;systeme informatique;recursive algorithm;relational databases;information system;multiprocesador;non numeric algorithms;database query;systeme information;cierre transitivo;transmision mensaje;sistema informacion;deductive databases;multiprocesseur	Abstract   This paper examines, using probabilistic average-valued analytical models, the performance of the δ- wavefront , a sequential algorithm suitable for processing an important class of recursive queries, the partially-instantiated closure ( TC ) ones. Moreover, it develops and evaluates several parallel variants to the δ- wavefront  algorithm. These variants assume the shared-nothing (message-passing) multi-processor organization. The studies presented in this paper reveal, among other findings, that the performance of the δ- wavefront  algorithm and its variants is strongly dependent on the characteristics of the system's hardware, the processed base-relation and, to a less degree, the processed query. Although the speed of the different parallel variants has been found to exhibit anomalous behavior (i.e. an increase in the number of processing nodes in the distributed system beyond a certain value brings a decrease in the speed of these algorithms rather than an increase), nevertheless, this study reveals that the processing of a  TC  query can be greatly speeded up provided that the proper parallel variant and the proper number of processing nodes are chosen. Two parallel variants to the δ- wavefront  algorithm are identified to possess the best performance, one for systems with a slow interconnect and the other for systems with a fast one.	multiprocessing;shared nothing architecture;transitive closure;uniprocessor system	Ghassan Z. Qadah;Jung J. Kim	1992	Data Knowl. Eng.	10.1016/0169-023X(92)90005-V	relational database;computer science;artificial intelligence;theoretical computer science;database;distributed computing;programming language;algorithm	DB	-16.61156513466973	44.731387564987706	113661
2c498abf6a91f4d7fa2a6c933bb759913756afcc	language and compiler support for adaptive applications	data intensive application;parallel performance;application software;real time;performance;gyrokinetic;runtime;data analysis;permission;distributed environment;streaming media;programming profession;adaptive applications;runtime data visualization application software computer science programming profession permission batteries streaming media data analysis algorithm design and analysis;theory;batteries;data visualization;eulerian;language extension;program analysis;computer science;coarse grained;algorithm design and analysis;gyro;turbulence	There exist many application classes for which the users have significant flexibility in the quality of output they desire. At the same time, there are other constraints, such as the need for real-time response or limit on the consumption of certain resources, which are more crucial. This paper provides a combined language/compiler and runtime solution for supporting adaptive execution of these applications, i.e., to allow them to achieve the best precision while still meeting the specified constraint at runtime. The key idea in our language extensions is to have the programmers specify adaptation parameters, i.e, the parameters whose values can be varied within a certain range. A program analysis algorithm states the execution time of an application component as a function of the values of the adaptation parameters and other runtime constants. These constants are determined by initial runs of the application in the target environment. We integrate this work with our previous work on supporting coarse-grained pipelined parallelism, and thus support adaptive execution for data-intensive applications in a distributed environment. Our experimental results on three applications have shown that our combined compile-time/runtime model can predict the execution times quite well, and therefore, support adaptation to meet a variety of constraints.	algorithm;compile time;compiler;data-intensive computing;parallel computing;pipeline (computing);program analysis;programmer;real-time clock;real-time computing;run time (program lifecycle phase)	Wei Du;Gagan Agrawal	2004	Proceedings of the ACM/IEEE SC2004 Conference	10.1109/SC.2004.33	program analysis;turbulence;algorithm design;application software;parallel computing;real-time computing;simulation;performance;computer science;theoretical computer science;operating system;runtime verification;data analysis;programming language;theory;data visualization;algorithm;distributed computing environment;eulerian path	HPC	-13.769458407656012	45.386703282128664	113665
b20f046edf42078090448ebc9b04464bab107653	lightweight computational steering of very large scale molecular dynamics simulations	parallel computing;computational steering;66 physics;scripting languages;molecular dynamics;large scale systems computational modeling analytical models visualization workstations code standards internet production data analysis packaging;molecular dynamic simulation;physics;molecular dynamics method;data analysis;large scale;visualization;spasm;large scale simulation;array processors;swig;computerized simulation;parallel computer;swig molecular dynamics data analysis large scale simulation steering scripting languages visualization parallel computing spasm;molecular dynamic;99 mathematics computers information science management law miscellaneous;steering;parallel processing;scripting language;md simulation;mathematics computers information science management law miscellaneous	We present a computational steering approach for controlling, analyzing, and visualizing very large scale molecular dynamics simulations involving tens to hundreds of millions of atoms. Our approach relies on extensible scripting languages and an easy to use tool for building extensions and modules. The system is extremely easy to modify, works with existing C code, is memory efficient, and can be used from inexpensive workstations and networks. We demonstrate how we have used this system to manipulate data from production MD simulations involving as many as 104 million atoms running on the CM-5 and Cray T3D. We also show how this approach can be used to build systems that integrate common scripting languages (including Tcl/Tk, Perl, and Python), simulation code, user extensions, and commercial data analysis packages.	computation;computational steering;computer simulation;connection machine;cray t3d;molecular dynamics;perl;python;scripting language;tcl;workstation	David M. Beazley;Peter S. Lomdahl	1996	Proceedings of the 1996 ACM/IEEE Conference on Supercomputing	10.1145/369028.369136	computational science;molecular dynamics;parallel computing;computer science;theoretical computer science;operating system;scripting language;programming language	HPC	-9.836682795474657	37.53281355998522	113992
ab6f4c3e93369cffe33a4bdb3f18490437b8525b	"""introduction to the special section on """"optimization of parallel scientific applications with accelerated high-performance computers"""""""			computer;optimizing compiler;supercomputer	Jesús Carretero;Francisco Javier García Blas;Maya G. Neytcheva	2015	Computers & Electrical Engineering	10.1016/j.compeleceng.2015.09.017		HPC	-8.141510280537206	39.54819383302326	114132
5c8936e35657651a3177ee7cfd59cc75620c717f	time propagation of partial differential equations using the short iterative lanczos method and finite-element discrete variable representation: an experiment using the intel phi coprocessors: extended abstract	taudem;parallel pitremove algorithm;hpc	The Short Iterative Lanczos (SIL) method has been combined with the Finite-Element Discrete Variable Representation (SIL-FEDVR) to yield a powerful approach to solving the time-dependent Schrödinger equation. It has been applied to the interaction of short, intense laser radiation (attosecond pulses) to describe the single and double ionization of atoms and molecules, but the approach is not limited to this particular application. The paper begins with a brief description of the method and algorithms and then discusses how they have been successfully ported to the Intel Phi coprocessors.1 While further experimentation is needed, the results provide reasonable evidence that by suitably modifying the code to combine MPI, OpenMP, and compiler assisted offload (CAO) directives, one can achieve a significant improvement in performance from these coprocessors for problems such as the above. Future work will examine porting the code to GPU's and a comparison in performance of the two coprocessors.	compiler;coprocessor;double ionization;graphics processing unit;iterative method;lanczos algorithm;openmp;schrödinger;software propagation	Barry I. Schneider;Klaus Bartschat;Xiaoxu Guan	2016		10.1145/2949550.2949565	parallel computing;computer science;theoretical computer science;algorithm	HPC	-5.110866720454618	37.98742967207014	114136
ffb140bb25b531fc679842d3b2c947d39c64a213	on the relationship of sector references, sector placement and paging performance		The performance of a program in a paged virtual memory environment is significantly influenced by the placement of its relocatable sectors. Considerable effort is currently being invested in optimising the paging performance of frequently used programs. This paper examines the relationship of a program’s sector reference behaviour to its page reference behaviour. Lower bounds for a program’s paging performance with optimum placement of its relocatable sectors are obtained for the independent reference model and for the least recently used and the working set page replacement policies. These bounds are based upon the theoretically optimum sector fetch and replacement policies. The reasons for rejecting alternative sector replacement policies are discussed. It is shown how the shape of a lower bound can be used to estimate the page allocation or working set size necessary to obtain a required paging performance. Results of applying the technique to a fairly well structured compiler are given to illustrate the tightness of the lower bounds in a realistic situation. The algorithms can be applied to a program’s reference trace before pagination to obtain an estimate of the gain which might be realised by improving the placement of its relocatable sectors in virtual memory.	paging	Donald R. Innes	1976		10.1007/978-3-642-95289-0_26	embedded system;real-time computing;computer science;computer network	EDA	-17.33585761352044	37.01391794184734	114298
ffc4781406666cc5910cdb19d7e09654ab5ab4ca	a flow-executing scheme for doacross loops on dynamic dataflow machines	cyclic packet;parallelisme;color management;plane;coloration;boucle doacross;boucle programme;performance;flot donnee;plan;doacross loop;semantics;flujo datos;semantica;semantique;paquet donnee;bucle programa;dynamic dataflow machine;parallelism;paralelismo;boucle doserial;flot donnee dynamique;coloracion;plano;program loop;rendimiento;data flow	Abstract#R##N##R##N#This paper modifies a flow-executing scheme of the color-reuse type, using multiple initial loop control packets, and then proves that the flow-executing scheme is best suited for executing DOACROSS loops on dynamic dataflow machines. Flow-executing schemes can be divided into four categories: (1) those using a single initial loop control packet; (2) those using multiple initial loop packets; (a) the color overflow type; and (b) the color reuse type. Then the flow-executing scheme can be classified into Classes (1-a), (1b), (2-a), and (2-b) through the combination of Categories (1), (2), (a), and (b). This paper suggests that Class (2-b) is best suited for executing DOACROSS loops, as it extracts full parallelism from DOACROSS loops, no sychronization overhead exists, and no memory access overhead exists after the synchronization.		Yoshihiko Ishii;Hayato Yamana;Toshiaki Yasue;Yoichi Muraoka	1993	Systems and Computers in Japan	10.1002/scj.4690240401	data flow diagram;parallel computing;real-time computing;performance;computer science;operating system;plane;distributed computing;semantics;plan;programming language;algorithm	HPC	-16.41793039399153	40.836727817768704	114727
d5da75849d7f4ae62eba85c7d7bf2cd907e4ccf9	adaptive quadrature on a message-passing multiprocessor	parallelisme;distributed system;algoritmo paralelo;systeme reparti;parallel algorithm;multiprocessor;distribucion carga;algorithme parallele;parallelism;sistema repartido;paralelismo;message passing;distribution charge;load distribution;multiprocesador;multiprocesseur	We study the problem of numerically integrating a continuous functionf(x) over a closed interval [a, b]. This is one of the oldest problems in applied mathematics, and one which is still the subject of active research, e.g., [3, 61. The adaptive quadrature strategy attempts to tailor a general integration method (such as a Newton-Cotes rule) to each specific integrand. This has long been recognized as a reasonable approach to the problem of achieving accuracy and reliability while attempting to minimize the computational workload. Adaptive quadrature routines are found in most major scientific subroutine libraries. We present an algorithm based on an adaptive Simpson’s Rule, modified to efficiently use a message-passing multiprocessor network. Such a network consists of a set of independent, asynchronous processors called nodes. Each node is capable of executing code to manipulate variables in its own local memory. Data and results are sent from node to node by explicitly passing messages. All nodes are connected to a central host processor which directs the startup, loading of code, problem distribution, and shutdown. Many such computers are now commercially available, and various interconnection networks for the host and nodes have been proposed. The algorithms in this paper were developed using a 6-D Intel iPSC/2 Hypercube (and simulators for it) at Oak Ridge National Laboratory. This machine is made up of 64 node processors connected to an Intel 301 host, which runs the System V UNIX operating system. The host and nodes are 80386/80387 processors running at 16 MHz, with 4 Mbytes of main memory.	adaptive quadrature;algorithm;central processing unit;computation;computer data storage;interconnection;library (computing);message passing;multiprocessing;newton;newton–cotes formulas;numerical analysis;numerical integration;operating system;shutdown (computing);simpson's rule;simulation;subroutine	Valerie A. Miller;George J. Davis	1992	J. Parallel Distrib. Comput.	10.1016/0743-7315(92)90079-3	parallel computing;message passing;real-time computing;multiprocessing;computer science;weight distribution;operating system;distributed computing;parallel algorithm	HPC	-14.567351352604053	43.21004298515173	114797
a172b2ae689f044a6f9818574b1f0c7783a44d7f	performance improvement of data mining in weka through gpu acceleration	parallel computing;paper;data mining tools;gpu;tesla m2050;data mining;comuter science;cuda;nvidia quadro k 2000;package;nvidia;tesla k20;matrix multiplication;java	Data mining tools may be computationally demanding, so there is an increasing interest on parallel computing strategies to improve their performance. The popularization of Graphics Processing Units (GPUs) increased the computing power of current desktop computers, but desktop-based data mining tools do not usually take full advantage of these architectures. This paper exploits an approach to improve the performance of Weka, a popular data mining tool, through parallelization on GPU-accelerated machines. From the profiling of Weka object-oriented code, we chose to parallelize a matrix multiplication method using state-of-the-art tools. The implementation was merged into Weka so that we could analyze the impact of parallel execution on its performance. The results show a significant speedup on the target parallel architectures, compared to the original, sequential Weka code. c © 2014 The Authors. Published by Elsevier B.V. Selection and peer-review under responsibility of Elhadi M. Shakshuki.	algorithm;central processing unit;cloud computing;data mining;data security;desktop computer;graphics processing unit;java;matrix multiplication;multi-core processor;parallel computing;profiling (computer programming);speedup;the matrix;weka	Tiago Augusto Engel;Andrea Schwertner Charão;Manuele Kirsch-Pinheiro;Luiz Angelo Steffenel	2014		10.1016/j.procs.2014.05.402	parallel computing;computer hardware;matrix multiplication;computer science;operating system;data mining;programming language;package;java	HPC	-4.76878461013742	43.99622798298822	114825
6cbd8b1decf115ae3024d1281708bb0ca622e0ee	cassandra: a decentralized structured storage system	estensibilidad;modelo dinamico;distributed memory;distributed system;base relacional dato;sistema operativo;relational data model;record format;fiabilidad;reliability;systeme reparti;storage system;rich internet application;centre donnee;memoria compartida;format enregistrement;dynamic model;database;software systems;base dato;hyperlink;distributed storage;distributed storage system;relational database;centro datos;dynamic control;data model;decentralized system;data center;sistema repartido;centre calcul;operating system;design and implementation;fiabilite;systeme memoire;modele dynamique;estructura datos;base de donnees;sistema descentralizado;base de donnees relationnelle;systeme exploitation;structure donnee;modele donnee;extensibilite;scalability;systeme decentralise;data layout;computer center;formato grabacion;memoire repartie;peer to peer;sistema memoria;edge computing;data structure;centro calculo;cloud computing;data models;structured data	Cassandra is a distributed storage system for managing very large amounts of structured data spread out across many commodity servers, while providing highly available service with no single point of failure. Cassandra aims to run on top of an infrastructure of hundreds of nodes (possibly spread across different data centers). At this scale, small and large components fail continuously. The way Cassandra manages the persistent state in the face of these failures drives the reliability and scalability of the software systems relying on this service. While in many ways Cassandra resembles a database and shares many design and implementation strategies therewith, Cassandra does not support a full relational data model; instead, it provides clients with a simple data model that supports dynamic control over data layout and format. Cassandra system was designed to run on cheap commodity hardware and handle high write throughput while not sacrificing read efficiency.	clustered file system;commodity computing;computer data storage;data center;data model;nosql;relational model;reliability engineering;scalability;single point of failure;software system;throughput	Avinash Lakshman;Prashant Malik	2010	Operating Systems Review	10.1145/1773912.1773922	log-structured merge-tree;simulation;data structure;data model;computer science;operating system;database;world wide web	OS	-19.110825840667996	44.83370979506211	114920
5c3b19c58e63b17ba0d161636e53f67d6f2c5aa7	a review of lightweight thread approaches for high performance computing	libraries;concurrent computing;semantics;lightweight threads;synchronization;message systems;conference report;openmp;programming models;instruction sets;hardware	High-level, directive-based solutions are becoming the programming models (PMs) of the multi/many-core architectures. Several solutions relying on operating system (OS) threads perfectly work with a moderate number of cores. However, exascale systems will spawn hundreds of thousands of threads in order to exploit their massive parallel architectures and thus conventional OS threads are too heavy for that purpose. Several lightweight thread (LWT) libraries have recently appeared offering lighter mechanisms to tackle massive concurrency. In order to examine the suitability of LWTs in high-level runtimes, we develop a set of microbenchmarks consisting of commonly-found patterns in current parallel codes. Moreover, we study the semantics offered by some LWT libraries in order to expose the similarities between different LWT application programming interfaces. This study reveals that a reduced set of LWT functions can be sufficient to cover the common parallel code patterns andthat those LWT libraries perform better than OS threads-based solutions in cases where task and nested parallelism are becoming more popular with new architectures.	application programming interface;code;concurrency (computer science);directive (programming);high- and low-level;library (computing);light-weight process;manycore processor;operating system;parallel computing;programming model;runtime system;spawn (computing)	Adrián Castelló;Antonio J. Peña;Sangmin Seo;Rafael Mayo;Pavan Balaji;Enrique S. Quintana-Ortí	2016	2016 IEEE International Conference on Cluster Computing (CLUSTER)	10.1109/CLUSTER.2016.12	synchronization;parallel computing;real-time computing;concurrent computing;computer science;operating system;instruction set;distributed computing;semantics;programming paradigm;programming language	HPC	-6.906499058475794	45.36203740922149	115005
87f548428c5c79ecb2cd550a488d67c675a97210	star: a local network system for real-time management of imagery data	topology;processing;general and miscellaneous mathematics computing and information science;mathematics;distributed database;image processing;fault tolerant;real time;simd machines;mimd machines;interconnection network;computer networks;distributed scheduling;image database management;parallel image processing;communication subnet;topology management;local computation;programming 990200 mathematics computers;cost effectiveness;network architecture;local computer network;failures;networked systems;management;architecture;distributed control;data base management;parallel processing;computational topology;simd machines communication subnet image database management interconnection network local computer network mimd machines parallel image processing;real time systems	Overall architecture of a local computer network, Star, is described. The objective is to accomplish a cost-effective system which provides multiple users a real-time service of manipulating very large volume imagery information and data. Star consists of a reconfigurable communication subnet (Starnet), heterogeneous resource units, and distributed-control software entities. Architectural aspects of a fault-tolerant communication subnet, distributed database management, and a distributed scheduling strategy for configuring desirable computation topology are exploited. A model for comparing cost-effectiveness among Starnet, crossbar, and multiple buses is included. It is concluded that Starnet outperforms the other two when the number of units to be connected is larger than 64. This project serves as a research tool for using current and projected technology to innovate better schemes for parallel image processing.		Chuan-lin Wu;Tse-Yun Feng;Min-Chang Lin	1982	IEEE Trans. Computers	10.1109/TC.1982.1675901	embedded system;parallel processing;parallel computing;computational topology;network architecture;image processing;computer science;processing;theoretical computer science;architecture;operating system;distributed computing;distributed database;computer network	Visualization	-12.314741880429693	44.05216746076139	115283
e714a105c283b348e0383ca5a05a94bd8b5583d5	astrophysics - the cosmic simulator	ucsd;adaptive mesh refinement;sdsc;structure formation;tree algorithm;data analysis;storage resource broker;many body simulation;llnl;cosmological simulation;reconfigurable processor;data grid;data archive;numerical simulation	In the coming decade, the visible universe will be surveyed to unprecedented breadth, depth, and spectral coverage to explore its structures, past history, and future fate. Data volumes of many petabytes are expected. Numerical simulations of cosmic structure formation and evolution must keep pace in scale and complexity if they are to assist in the interpretation of such data, as well as to make predictions. We describe the Cosmic Simulator, a software facility under development at UCSD for performing, analyzing, and archiving cosmological simulations of unprecedented scale and physical realism. Its major components are the adaptive mesh refinement hydrodynamic cosmology simulation code ENZO, a data analysis pipeline, and a Storage Resource Broker (SRB)-managed data archive housed at SDSC. We show scientific results from the Cosmic Simulator implemented on a data grid connecting LLNL and SDSC computational resources, and discuss future plans.	adaptive mesh refinement;archive;cosmic;computational resource;numerical linear algebra;petabyte;refinement (computing);research data archiving;san diego supercomputer center;simulation;storage resource broker	Michael L. Norman	2006		10.1145/1188455.1188509	computer simulation;parallel computing;simulation;adaptive mesh refinement;structure formation;computer science;data science;theoretical computer science;operating system;storage resource broker;data grid;data analysis;computer network	HPC	-7.222275345188752	36.43460916971236	115309
49ff6de0f7aca0b8eafef6c04cb21a54b847a3b4	parallel implementations of ensemble data assimilation for atmospheric prediction	mutually exclusive scheduling;dynamic load balancing;grid partitioning	Numerical models are used to find approximate solutions to the coupled nonlinear partial differential equations associated with the prediction of the atmosphere. The model state can be represented by a grid of discrete values; subsets of grid points are assigned to tasks for parallel solution. Data assimilation algorithms are used to combine information from a model forecast with atmospheric observations to produce an improved state estimate. Observations are irregular in space and time, for instance following the track of a polar orbiting satellite. Ensemble assimilation algorithms use statistics from a set (ensemble) of forecasts to update the model state. All the challenges of heterogeneous grid computing and partitioning for atmospheric models are in play. In addition, the heterogeneous distribution of observations in space and time is a further source of irregular computing load while ensembles lead to increased storage and an additional communication pattern. Adjacent observations cannot be assimilated simultaneously leading to a mutual exclusion scheduling problem that interacts with the grid partitioning communication patterns and load balancing. Simulations of efficient approaches to the scheduling and grid partitioning problem for ensemble assimilation are presented. Prospects for implementation on accelerator architectures are also discussed.	approximation algorithm;data assimilation;grid computing;load balancing (computing);mutual exclusion;nonlinear system;partition problem;scheduling (computing)	Jeffrey Anderson;Helen Kershaw;Nancy Collins	2013		10.1145/2535753.2535760	computer science;theoretical computer science;machine learning;distributed computing	HPC	-5.913910924093338	36.282163616013264	115311
4bc97c343734bd112080eaf67062d7442f8ffdca	meta-programming for cross-domain tensor optimizations		Many modern application domains crucially rely on tensor operations. The optimization of programs that operate on tensors poses difficulties that are not adequately addressed by existing languages and tools. Frameworks such as TensorFlow offer good abstractions for tensor operations, but target a specific domain, i.e. machine learning, and their optimization strategies cannot easily be adjusted to other domains. General-purpose optimization tools such as Pluto and existing meta-languages offer more flexibility in applying optimizations but lack abstractions for tensors. This work closes the gap between domain-specific tensor languages and general-purpose optimization tools by proposing the Tensor optimizations Meta-Language (TeML). TeML offers high-level abstractions for both tensor operations and loop transformations, and enables flexible composition of transformations into effective optimization paths. This compositionality is built into TeML's design, as our formal language specification will reveal. We also show that TeML can express tensor computations as comfortably as TensorFlow and that it can reproduce Pluto's optimization paths. Thus, optimized programs generated by TeML execute at least as fast as the corresponding Pluto programs. In addition, TeML enables optimization paths that often allow outperforming Pluto.	compiler;computation;convolution;data structure alignment;distributed memory;first-class function;formal language;general-purpose markup language;graphics processing unit;high- and low-level;high-level programming language;machine learning;mathematical optimization;memory virtualization;metaprogramming;microsoft outlook for mac;polyhedron;principle of abstraction;programming language specification;semantics (computer science);source lines of code;sparse matrix;tensorflow;theano (software);usability	Adilla Susungi;Norman A. Rink;Albert Cohen;Jerónimo Castrillón;Claude Tadonki	2018		10.1145/3278122.3278131	programming language;principle of compositionality;tensor;tensor algebra;denotational semantics;computation;metaprogramming;formal language;abstraction;computer science	PL	-12.164805346570114	35.64771996978828	115386
2a2b7ddcb1d0d3eeef5cf5b74a12fadfe5428a87	linear algebra operators for gpu implementation of numerical algorithms	graphics hardware;numerical simulation	In this work, the emphasis is on the development of strategies to realize techniques of numerical computing on the graphics chip. In particular, the focus is on the acceleration of techniques for solving sets of algebraic equations as they occur in numerical simulation. We introduce a framework for the implementation of linear algebra operators on programmable graphics processors (GPUs), thus providing the building blocks for the design of more complex numerical algorithms. In particular, we propose a stream model for arithmetic operations on vectors and matrices that exploits the intrinsic parallelism and efficient communication on modern GPUs. Besides performance gains due to improved numerical computations, graphics algorithms benefit from this model in that the transfer of computation results to the graphics processor for display is avoided. We demonstrate the effectiveness of our approach by implementing direct solvers for sparse matrices, and by applying these solvers to multi-dimensional finite difference equations, i.e. the 2D wave equation and the incompressible Navier-Stokes equations.	algorithm;graphics processing unit;linear algebra;numerical analysis	Jens H. Krüger;Rüdiger Westermann	2003	ACM Trans. Graph.	10.1145/882262.882363	chip;fluid simulation;computational science;ray tracing;mathematical optimization;finite difference;wave equation;sparse matrix;rendering;computer science;theoretical computer science;linear algebra;mathematics;geometry;numerical linear algebra;graphics hardware;national science education standards;algorithm;computer graphics (images)	Graphics	-6.360285378774987	37.855447956727595	115464
088a82ad7ec22823b84394603c4f3cebf7e0e3ef	optimizing parallel reduction on opencl fpga platform – a case study of frequent pattern compression		Field-programmable gate arrays (FPGAs) are becoming a promising heterogeneous computing component in high-performance computing. To facilitate the usage of FPGAs for developers and researchers, high-level synthesis tools are pushing the FPGA-based design abstraction from the registertransfer level to high-level language design flow using OpenCL/C/C++. Currently, there are few studies on parallel reduction using atomic functions in the OpenCL-based design flow on an FPGA. Inspired by the reduction operation in frequent pattern compression, we transform the function into an OpenCL kernel, and describe the optimizations of the kernel on an Arria10-based FPGA platform as a case study. We found that automatic kernel vectorization does not improve the kernel performance. Users can manually vectorize the kernel to achieve performance speedup. Overall, our optimizations improve the kernel performance by a factor of 11.9 over the baseline kernel. The performance per watt of the kernel on an Intel Arria 10 GX1150 FPGA is 5.3X higher than an Intel Xeon 16-core CPU while 0.625X lower than an Nvidia K80 GPU.	automatic vectorization;baseline (configuration management);c++;central processing unit;design flow (eda);field-programmable gate array;graphics processing unit;heterogeneous computing;high- and low-level;high-level programming language;high-level synthesis;kernel (operating system);opencl api;optimizing compiler;performance per watt;speedup;supercomputer	Zheming Jin;Hal Finkel	2018	2018 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)	10.1109/IPDPSW.2018.00015	symmetric multiprocessor system;xeon;field-programmable gate array;parallel computing;kernel (linear algebra);computer science;speedup;image tracing;performance per watt;design flow	HPC	-5.057643113267937	44.81916431485434	115485
b3b76905123f300f05ecbbb0dd8f3da33e56d83f	interprocedural register allocation for risc machines	gnu c compiler;register allocation;webs;graph coloring;interprocedural register allocation;risc computer	Efficient register allocation can significantly impact the performance of a program. Most register allocation investigations deal with intraprocedural register allocation. This paper presents two interprocedural register allocation approaches along with empirical data to judge the value of each approach on a variety of benchmark programs. The GNU C compiler is used on a Data General Aviion computer as the investigation environment.	benchmark (computing);gnu compiler collection;register allocation	John Wood;Harold C. Grossman	1992		10.1145/503720.503796	computer architecture;parallel computing;register window;interprocedural optimization;computer science;stack register;processor register;programming language;register allocation	PL	-13.197764892350682	36.42937199991985	115515
425482237575b4cd78b225357f1996f34a29d4bb	supporting energy-efficient computing on heterogeneous cpu-gpu architectures		Modern high performance computing and cloud computing infrastructures often leverage Graphic Processing Units (GPUs) to provide accelerated, massively parallel computational power. This performance gain, however, may also introduce higher energy consumption. The energy challenge has become more and more pronounced when the system scales. To address this challenge, we propose Archon, a framework for supporting energy-efficient computing on CPU-GPU heterogeneous architectures. Specifically, Archon takes user's programs as input, automatically distribute the workload between CPU and GPU, and dynamically tunes the distribution ratio at runtime for an energy-efficient execution. Experiments have been carried out to evaluate the effectiveness of Archon, and the results show that it can achieve considerable energy savings at runtime, without significant efforts from the programmers.	ahead-of-time compilation;archon;central processing unit;cloud computing;face detection;graphics processing unit;image processing;matrix multiplication;programmer;run time (program lifecycle phase);supercomputer	Kyle Siehl;Xinghui Zhao	2017	2017 IEEE 5th International Conference on Future Internet of Things and Cloud (FiCloud)	10.1109/FiCloud.2017.46	massively parallel;parallel computing;workload;leverage (finance);efficient energy use;cloud computing;energy consumption;computer science;supercomputer	HPC	-5.124146858144254	45.77312275151059	115525
3b1b641a1065713ef16635b06687bf250cdda3b2	évaluation de performances d'une architecture parallèle pour le traitement d'images. (performance evaluation of parallel architecture for image processing)			image processing;parallel computing;performance evaluation	Pierre Houeix	1988				Arch	-9.06797133543908	41.480340722119934	115609
fd23175bb50f36df27c78e47a8837edcd6099c80	biotc: an open-source cfd code for simulating biomass fast pyrolysis	chemical kinetics;computer program;partial differential equation;programming language;biomass fast pyrolysis;ordinary differential equation;computation fluid dynamics;distributed programs;fluid model;numerical scheme;cfd simulation;operating system;object oriented;multi fluid model;fluid dynamics;chemical reactions;chemical reaction;openfoam;computer simulation;reaction mechanism;fluidized bed reactor;open source	The BIOTC code is a computer program that combines a multi-fluid model for multiphase hydrodynamics and global chemical kinetics for chemical reactions to simulate fast pyrolysis of biomass at reactor scale. The object-oriented characteristic of BIOTC makes it easy for researchers to insert their own sub-models, while the user-friendly interface provides users a friendly environment as in commercial software. A laboratory-scale bubbling fluidized bed reactor for biomass fast pyrolysis was simulated using BIOTC to demonstrate its capability.	commercial software;computer program;kinetics internet protocol;multiphase particle-in-cell method;open-source software;openfoam;reactor (software);simulation;subroutine;usability	Qingang Xiong;Soroush Aramideh;Alberto Passalacqua;Song-Charng Kong	2014	Computer Physics Communications	10.1016/j.cpc.2014.02.012	computer simulation;real-time computing;simulation;chemical reaction;chemical kinetics;computer science;theoretical computer science;physics;fluid dynamics	HPC	-9.423733628025513	36.758575467978005	115618
c0f1b21925e0071a9dc8bc04417ae1dedfd1d8da	online selection of short-lived particles on many-core computer architectures in the cbm experiment at fair			computer architecture;manycore processor	Maksym Zyzak	2015				ML	-9.196281774571267	43.69015336292458	115663
75e08d53b364527bfd899cfc77630af77b5a62a0	a parallel algorithm manager for networked workstations	parallel algorithm;object oriented design;branch and bound algorithm;learning networks;network of workstation;software package;parallel computer;message passing;parallel architecture;parallel programs;network programming;parallel languages	Difficulties in computer solution of large problems often result from the requirements of the algorithm exceeding the space or time capacity of the computer chosen. A natural resolution of this difficulty is to parallelize the algorithm which can promise either reduc-tion in space or time, or both. However, several obstacles confront the scientist in order to successfully parallelize the algorithm. Time must be invested to study parallel architectures and to learn a parallel language. The cost of a special purpose parallel computer can easily exceed the available budget. One alternative is to use an existing network of workstations as a parallel computer. Although the cost has been eliminated, the task of learning network programming has been introduced. There are software packages which bundle network programming effectively, but provide varying degrees of guidance in the development and management of parallel program applications. To ease the effort required, we introduce a parallel algorithm manager which is developed using a message passing paradigm. An object-oriented design approach has been taken to facilitate distributed parallel program-ming. Base manager and worker classes are inherited by a user to form the instantiable classes to drive the parallel program. An example of a branch and bound algorithm and its resulting distributed form are presented. Copyright Kluwer Academic Publishers 1997	parallel algorithm;workstation	Margaret K. Mayer;Louis J. Plebani	1997	Annals OR	10.1023/A:1018919531503	parallel computing;message passing;embarrassingly parallel;computer science;theoretical computer science;object-oriented design;parallel rendering;distributed computing;parallel algorithm;computer network programming;branch and bound;bulk synchronous parallel;cost efficiency;parallel programming model	Robotics	-11.224373634455961	37.28457960924427	115747
bd560c663e7c449109a65c05116b59b7fb28bc8c	accelerating molecular structure determination based on inter-atomic distances using opencl	nmr;hardware architectures molecular structure determination inter atomic distances opencl 3d structure physical properties chemical properties biological properties restrained molecular dynamics simulated annealing commodity multicore cpu commodity multicore gpu parallel scalability x plor n ih professional software package;parallel algorithms molecular structure determination nmr molecular dynamics gpu opencl simulated annealing;nuclear magnetic resonance proteins three dimensional displays computational modeling graphics processing units molecular imaging simulated annealing;software packages biocomputing biology computing graphics processing units molecular dynamics method multiprocessing programs simulated annealing;molecular imaging;molecular dynamics;molecular structure determination;gpu;nuclear magnetic resonance;simulated annealing;computational modeling;proteins;three dimensional displays;graphics processing units;opencl;parallel algorithms	Fast and accurate determination of the 3D structure of molecules is essential for better understanding their physical, chemical, and biological properties. We focus on an existing method for molecular structure determination: restrained molecular dynamics with simulated annealing. In this method a hybrid function, composed by a physical model and experimental restraints, is minimized by simulated annealing. Our goal is to accelerate computation time using commodity multi-core CPUs and GPUs in a heterogeneous computing model. We present a parallel and portable OpenCL implementation of this method. Experimental results are discussed in terms of accuracy, execution time, and parallel scalability. With respect to the XPLOR-NIH professional software package, compared to the single CPU core implementation, we obtain speedups of three to five times (increasing with problem size) on commodity GPUs. We achieve these performances by writing specialized kernels for different problem sizes and hardware architectures.	analysis of algorithms;central processing unit;computation;computational chemistry;computational model;desktop computer;flops;graphics processing unit;hardware acceleration;heterogeneous computing;manycore processor;molecular dynamics;multi-core processor;opencl api;parallel computing;parallel programming model;performance;personal computer;programming paradigm;run time (program lifecycle phase);scalability;simulated annealing;simulation;time complexity;write once, run anywhere	István Lorentz;Razvan Andonie;Levente Fabry-Asztalos	2015	IEEE Transactions on Parallel and Distributed Systems	10.1109/TPDS.2014.2385712	computational science;molecular dynamics;parallel computing;simulated annealing;computer science;theoretical computer science;operating system;parallel algorithm;molecular imaging;computational model	HPC	-5.454661237441309	37.741262759073294	115830
4a3191fdf0a27f0554140cb6bca44d66c952f004	retargeting gcc: do we reinvent the wheel every time?		Porting GCC to new architecture requires writing a Machine Description (MD) file that contains mapping from GCC’s intermediate form to the target assembly code. Constructin g an MD file is a difficult task because it requires the user to understand both (a) the internals of GCC, and (b) the intricacies of the target architecture. Instruction sets of diff erent architectures exhibit significant amount of semantic simil arities across a large class (for example, the instruction set s for RISC architectures) and differ only in syntax. Therefore, i t is expected that MD files of machines with similar architectures should also have similarities. To confirm our hypothesis, we createdmdcompare , a tool to (a) extract RTL patterns (machine independent abstraction of RTL templates) from MD files of well known architectures and (b) compare the similarity of patterns across architectures. The resul ts are encouraging; we found that 28% – 70% RTL expressions are similar across pairs of MD files, the similarity percentage b eing on the higher side for pairs of similar architectures.	assembly language;diff utility;emoticon;gnu compiler collection;intermediate representation;molecular dynamics;reinventing the wheel;retargeting	P SaravanaPerumal;Amey Karkare	2013	CoRR		parallel computing;real-time computing;computer science;operating system;programming language	Arch	-15.10122501384361	36.36265836575685	115959
585baf7d92bba7672672cc9aaba263314049f1e7	a stratified view of programming language parallelism for undergraduate cs education	parallel computing;programming language;parallelism;parallel programming language;parallel computer;parallel programs;programming languages	It is no longer news that undergraduates in computer science need to learn more about parallelism. The range of options for parallel programming is truly staggering, involving hundreds of languages. How can a CS instructor make informed choices among all the options? This panel provides a guided introduction to parallelism in programming languages and their potential for undergraduate CS education, organized into four progressive categories: low-level libraries and; higher-level libraries and features; programming languages that incorporate parallelism; and frameworks for productive parallel programming. The four panelists will present representative examples in their categories, then present viewpoints on how those categories relate to coursework, curriculum, and trends in parallelism.	computer science;high- and low-level;library (computing);parallel computing;programming language	Richard A. Brown;Joel C. Adams;David P. Bunde;Jens Mache;Elizabeth Shoop	2012		10.1145/2157136.2157162	fourth-generation programming language;first-generation programming language;declarative programming;very high-level programming language;programming domain;reactive programming;computer science;theoretical computer science;third-generation programming language;functional logic programming;data parallelism;programming paradigm;procedural programming;inductive programming;fifth-generation programming language;programming language theory;programming language;second-generation programming language;instruction-level parallelism;comparison of multi-paradigm programming languages;implicit parallelism;task parallelism;parallel programming model	PL	-14.390175200965139	39.46081121893591	115976
2e513e7d198376a44f88772d80466d85f90e167d	a framework for incremental extensible compiler construction	compiler construction;extensibility;random graph;code optimization;incremental compilation;internal structure;compilers;design and implementation;design framework;performance analysis;data flow analysis;incremental analysis;optimal algorithm;intermediate representation	Much of the research in compiler design and optimization has traditionally focused on the effectiveness and efficiency of code optimization. However, the subject of efficiency of the entire compilation process itself (as opposed to the complexity of individual analysis or optimization algorithms) remains a highly complex and less investigated topic. In this paper we present a global approach to extensible and efficient compiler design, which aims at also improving the effectiveness and efficiency of analysis and optimization capabilities. Extensibility in complex compiler systems goes well beyond modularity of design and it needs to be considered from the early stages of the design, especially the design of the Intermediate Representation (IR). One of the primary barriers to compiler pass extensibility and modularity is interference between passes caused by transformations that invalidate existing analysis information. In this paper we also present a callback system which is provided to automatically track changes to the compiler's internal representation (IR) allowing full pass reordering and an easy-to-use interface for developing lazy update incremental analysis passes. We present a new algorithm for incremental interprocedural data flow analysis and demonstrate the benefits of our design framework and our prototype compiler system. It is shown that compilation time for multiple data flow analysis algorithms can be cut in half by incrementally updating data flow analysis. Our quantitative performance analysis is based on well-known benchmarks instead of random graphs like previous works. For smaller optimizations, order of magnitude improvements have been demonstrated. Our approach also simplifies design and implementation and hides many of the intricacies of a compiler's internal structures from the developer.	algorithm;callback (computer programming);compiler;data-flow analysis;dataflow;extensibility;interference (communication);intermediate representation;lazy evaluation;mathematical optimization;program optimization;prototype;random graph	Steven Carroll;Constantine D. Polychronopoulos	2003		10.1145/782814.782824	random graph;manifest expression;single compilation unit;compiler;parallel computing;dynamic compilation;extensibility;profile-guided optimization;compiler correctness;interprocedural optimization;computer science;loop optimization;theoretical computer science;operating system;data-flow analysis;compiler construction;dead code elimination;program optimization;optimizing compiler;compilation error;programming language;intermediate language;inline expansion;intrinsic function;functional compiler;algorithm	PL	-17.775705411442853	35.23496005636333	116199
7bb9db294f784bd050f22c464647c356ec55f715	book review: multiprocessor performance by erol gelenbe (j. wiley & sons, chichester, england)		"""Multiprocessor Performance is a relatively short monograph, which starts out with chapters giving an overview of mul-tiprocessor performance, multiprocessor architectures, speedup and Amdahl's Law, and the important topic of interconnection network performance. These were generally quite readable, and occasionally informative. The next chapters turn heavily to mathematical analysis of program structures , acyclic graphs as models of parallel programs, """"'task graph"""" models, and super-computer performance evaluation. I found these hard to follow, partly for notational reasons to be discussed, and partly because, with one exception, the analyses were not validated by benchmarks taken of real programs on real machines, rather by simulations. Like some other books in this area, Multiprocessor Performance contains several claims which are not substantiated: ° """"'A (potentially parallel application) will have to be written in a programming language where the nature of these cooperating sequential processes becomes explicit..."""" (reviewer's emphasis)-I do not believe this to be true. For example , the summation of a list of numbers L can be performed by recursive doubling on a Connection Machine, which certainly requires such cooperation. However, it can be expressed in an abstract manner in APL or J as: \tt +/L. ° """"'Multiprocessor architectures offer the greatest potential for performance"""". This is based on a loaded dice comparison with processor arrays in which the processor array is fixed in size, but in which the number of processors in the multipro-cessor are allowed to increase with the problem size. This is mitigated somewhat by the admittedly larger granularity of cost associated with increasing the size of a processor array. The chapters on Amdahl's Law introduces amendments based on load imbalance which help to explain why real applications often appear to violate the Law. Chapter 4, Performance of Interconnection Networks, introduces and discusses DROP and HOLD, which are two approaches to circuit establishment in such networks. I have not seen previous mention of these in other literature. I gave up on trying to read the chapters on General Acyclic Random Graph Models, and Multiprocessor Performance with Task Graph Models. Although there appears to be useful material in them, they are rather dry mathematical derivations, without much to draw the reader. Appeal to other disciplines would be helpful. (I should explain that I am a language designer and imple-menter, and quite rusty at analysis, so the fault may be mine rather than the author's). For example, in determining the execution time …"""	apl;amdahl's law;analysis of algorithms;benchmark (computing);book;central processing unit;computer performance;connection machine;directed acyclic graph;exception handling;human-readable medium;information;interconnection;john d. wiley;multiprocessing;network performance;performance evaluation;period-doubling bifurcation;pointer jumping;processor array;programming language;random graph;run time (program lifecycle phase);simulation;speedup;supercomputer	Robert Bernecky	1991	SIGARCH Computer Architecture News	10.1145/121956.773552	parallel computing;computer science;multiprocessing	Arch	-13.148229267118474	41.888413696252414	116390
a437784a92063d8424cb5606ec50b495a036c05b	correct, fast, maintainable: choose any three!	fault tolerance;storage;repair	The common-case IPC handler in microkernels, referred to as the fastpath, is performance-critical and thus is often optimised using hand-written assembly. However, compiler technology has advanced significantly in the past decade, which suggests that we should re-evaluate this approach.  We present a case study of optimising the IPC fast-path in the seL4 microkernel. This fastpath is written in C and relies on an optimising C compiler for good performance. We present our techniques in modifying the C sources to assist with compiler optimisation. We compare our results with a hand-optimised assembly implementation, which gains no extra benefit from hand-tuning.	assembly language;fast path;fastpath;formal verification;hot spot (computer programming);l4 microkernel family;mathematical optimization;microarchitecture;optimizing compiler;overhead (computing);the australian;user space	Bernard Blackham;Gernot Heiser	2012		10.1145/2349896.2349909	parallel computing;real-time computing;computer science;operating system	HPC	-17.40406558384042	36.37653771524238	116546
e7ce2f490d0e252989b5d25c63a3e8c1de7e53c1	go-realtime: a lightweight framework for multiprocessor real-time system in user space		We present the design of Go-RealTime, a lightweight framework for real-time parallel programming based on Go language. Go-RealTime is implemented in user space with portability and efficiency as important design goals. It takes the advantage of Go language's ease of programming and natural model of concurrency. Goroutines are adapted to provide scheduling for real-time tasks, with resource reservation enabled by exposing Linux APIs to Go. We demonstrate nearly full utilization on 32 processors scheduling periodic heavy tasks using Least Laxity First (LLF) algorithm. With its abstraction and system support, Go-RealTime greatly simplifies the set up of sequential and parallel real-time programs on multiprocessor systems.	algorithm;central processing unit;concurrency (computer science);linux;multiprocessing;parallel computing;real-time clock;real-time computing;real-time transcription;scheduling (computing);user space	Zhou Fang;Mulong Luo;Fatima M. Anwar;Hao Zhuang;Rajesh K. Gupta	2017	SIGBED Review	10.1145/3177803.3177811	real-time computing;distributed computing;real-time operating system;least slack time scheduling;scheduling (computing);user space;computer science;concurrency;software portability;abstraction;multiprocessing	Embedded	-13.547177978591257	45.64051773582243	116806
c5e385f8ad4be9f5048d31b1072b2be294bbb77e	a new algorithm for node placement optimization in shufflenets			algorithm	Ho-lun T. Wong;Kwan Lawrence Yeung	1999			computer science;parallel computing;distributed computing	EDA	-10.47411556569643	42.62545462769512	116862
18b79f10cc62efad4cc3aaf216a4355fdfcae619	an intermediate language and estimator for automated design space exploration on fpgas		We present the TyTra-IR, a new intermediate language intended as a compilation target for high-level language compilers and a front-end for HDL code generators. We develop the requirements of this new language based on the design-space of FPGAs that it should be able to express and the estimation-space in which each configuration from the design-space should be mappable in an automated design flow. We use a simple kernel to illustrate multiple configurations using the semantics of TyTra-IR. The key novelty of this work is the cost model for resource-costs and throughput for different configurations of interest for a particular kernel. Through the realistic example of a Successive OverRelaxation kernel implemented both in TyTra-IR and HDL, we demonstrate both the expressiveness of the IR and the accuracy of our cost model.	analysis of algorithms;compiler;design space exploration;field-programmable gate array;hardware description language;high- and low-level;high-level programming language;kernel (operating system);requirement;successive over-relaxation;throughput	Syed Waqar Nabi;Wim Vanderbauwhede	2015	CoRR		parallel computing;real-time computing;computer science;theoretical computer science;operating system;programming language	PL	-15.935806393058662	36.367365391391075	116937
d42c4aaab3e16683ded1d7d9affed843ffa132cc	high speed simulation of discrete event systems by mixing process oriented and equational approaches	high performance computing;object oriented simulation;discrete event system;mixing process;evolution equation;simulation technique;high performance computer;distributed simulation;high speed;discrete event simulation	This paper shows how the Prosit system, a new C + +-based framework for both sequential and distributed discrete event simulation, developed at INRIA-Sophia-Antipolis, makes an easy and efficient integration of classical discrete event simulation and of new high speed simulation techniques based on evolution equations possible. This demonstrates in particular the feasibility of distributed simulations involving simulators of different nature. Important applications of these techniques may be found in the simulation of communication switches, as illustrated in an example. Keywor~Ls: Discrete event simulation; Object-oriented simulation; Distributed simulation; High performance computing	complex system;computation;experiment;network switch;requirement;simulation	Bruno Gaujal;Alain Jean-Marie;Philippe Mussi;Günther Siegel	1997	Parallel Computing	10.1016/S0167-8191(96)00106-8	dynamic simulation;supercomputer;parallel computing;real-time computing;simulation;continuous simulation;discrete event dynamic system;computer science;theoretical computer science;discrete event simulation;simulation language;network traffic simulation	HPC	-10.86401077855224	40.01402492373837	116945
6f5827f7bd883751fb2ef034563ec16b2d63c6ef	adaptive just-in-time value class optimization: transparent data structure inlining for fast execution	value classes;jit;meta tracing;data structure optimization	The performance of value classes is highly dependent on how they are represented in the virtual machine. Value class instances are immutable, have no identity, and can only refer to other value classes or primitives and since they should be very lightweight and fast, it is important to optimize them well. In this paper we present a technique to detect and compress commonly occurring patterns of value class usage to improve memory usage and performance. microbenchmarks show two to ten-fold speedup of a small prototypical implementation over the implementation of value classes in other object-oriented language implementations.	data structure;immutable object;inline expansion;just-in-time compilation;mathematical optimization;speedup;time value of money;virtual machine	Tobias Pape;Carl Friedrich Bolz;Robert Hirschfeld	2015		10.1145/2695664.2695837	parallel computing;real-time computing;computer science;operating system;just-in-time compilation;database;programming language	PL	-19.066483874885833	35.674562719446264	117050
e086e0f308023d429e489480004c8be5053e6d3d	the scalability of embedded structured grids and unstructured grids in large scale ice sheet modeling on distributed memory parallel computers		Currently, there are two approaches to implementing large-scale ice sheet simulations. One approach, which is based on the use of an evenly-spaced structured grid, is to simulate the entire ice sheet at the highest resolution required. The other approach is to model the ice sheet at different levels of resolution using unstructured meshes. Structured grids lend themselves quite well to partitioning on multi-core, distributed memory parallel computers, leading to good computational efficiency, load-balancing and reduced communication costs. The disadvantage is the significant computational resources required to model a system of this size at a high enough resolution to correctly model regions of the ice sheet undergoing rapid change. Unstructured meshes can reduce such costs by allocating more computational resources to areas of the ice sheet whose dynamics are evolving quickly and fewer resources to areas evolving more slowly. However, unstructured meshes do not easily lend themselves to effective decomposition on distributed memory parallel computers, and can experience poor cache utilization, significant load imbalance, high communication costs, and increased synchronization times. In this paper, we describe our alternative approach based on embedded simulation, which provides a degree of multi-resolution capabilities to structured grids while maintaining many of the computational efficiencies that come with the structured approach. We provide experimental results focusing on the scalability characteristics and cache efficiency of each approach as a function of increasing problem size and core counts. We show that the embedded approach scales very well across all problem sizes and core counts, and that the unstructured approach scales well at smaller problem sizes and core counts but degrades significantly as the problem size becomes large.	analysis of algorithms;cpu cache;computation;computational resource;computer;distributed memory;embedded software;embedded system;image resolution;load balancing (computing);multi-core processor;parallel computing;regular grid;scalability;simulation;unstructured grid	Phillip M. Dickens;Christopher Dufour;James Fastook	2018	2018 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)	10.1109/IPDPSW.2018.00152	grid;parallel computing;distributed computing;computer science;ice sheet;scalability;distributed memory;cache;synchronization;polygon mesh;atmospheric model	HPC	-5.474510029028619	40.3675961654593	117263
1587af4ae416b6e4812587e18998fb7775f30857	automatic parallelization by pattern-matching	distributed memory;top down;pattern matching;message passing;fortran;automatic parallelization	Abst rac t . We present the top-down design of a new system which performs automatic parallelization of numerical Fortran 77 or C source programs for execution on distributed-memory message passing multiprocessors such as e.g. the INTEL iPSC860 or the TMC CM-5. The key idea is a high-level pattern-matching approach which in some useful way permits partial restructuring of a wide class of numerical programs. With only a few hundred patterns, we will be able to completely match many important numerical algorithms. Together with mathematical background knowledge and parallel compiler engineering experience, this opens access to a new potential for automatic paxallelization that has never been exploited before.	algorithm;automatic parallelization;compiler;connection machine;distributed memory;fortran;high- and low-level;message passing;numerical analysis;oracle rac;pattern matching;top-down and bottom-up design;traffic message channel	Christoph W. Kessler;Wolfgang J. Paul	1993		10.1007/3-540-57314-3_14	computer architecture;parallel computing;computer science;programming language;automatic parallelization	HPC	-13.072865540616787	38.203664035232094	117611
8e1283efa685a16b7814e47c2d6394aebc8a35fe	high-level support for hybrid parallel execution of c++ applications targeting intel® xeon phi™ coprocessors	datavetenskap datalogi;computer science	Abstract   The introduction of Intel ®  Xeon Phi™ coprocessors opened up new possibilities in development of highly parallel applications. Even though the architecture allows developers to use familiar programming paradigms and techniques, high-level development of programs that utilize all available processors (host+coprocessors) in a system at the same time is a challenging task.  In this paper we present a new high-level parallel library construct which makes it easy to apply a function to every member of an array in parallel. In addition, it supports the dynamic distribution of work between the host CPUs and one or more coprocessors. We describe associated runtime support and use a physical simulation example to demonstrate that our library can facilitate the creation of C++ applications that benefit significantly from hybrid execution. Experimental results show that a single optimized source code is sufficient to simultaneously exploit all of the host's CPU cores and coprocessors efficiently.	c++;coprocessor;xeon phi	Jirí Dokulil;Enes Bajrovic;Siegfried Benkner;Sabri Pllana;Martin Sandrieser;Beverly Bachmayer	2013		10.1016/j.procs.2013.05.430	computer architecture;parallel computing;computer hardware;computer science;operating system	HPC	-6.236304947678907	43.89878394913197	117871
877dc1341a4c46e189bbb4c6426a14b21e8c8548	languages and compilers for parallel computing		Although there has been some experimentation with Java as a language for numerically intensive computing, there is a perception by many that the language is not suited for such work. In this paper we show how optimizing array bounds checks and null pointer checks creates loop nests on which aggressive optimizations can be used. Applying these optimizations by hand to a simple matrix-multiply test case leads to Java compliant programs whose performance is in excess of 500 Mflops on an RS/6000 SP 332MHz SMP node. We also report in this paper the effect that each optimization has on performance. Since all of these optimizations can be automated, we conclude that Java will soon be a serious contender for numerically intensive computing.	flops;java;mathematical optimization;numerical analysis;offset binary;parallel computing;pointer (computer programming);rs/6000;test case;verification and validation	Jan van Leeuwen	1999		10.1007/3-540-48319-5	parallel computing;compiler;programming language;computer architecture;data structure;compiler construction;computer science	PL	-17.392409419261803	35.9658239181795	118130
fe881ff3cf1195232a8c1490085276dddebc143b	spec: a specification processing environment with controls			spec#	Timothy K. Shih;Ruth E. Davis	1994	J. Inf. Sci. Eng.		distributed computing;computer science;spec#;computer architecture	DB	-10.3353419805218	43.825949506362456	118154
90bb7a201805b25be0513560d3217f2d88c5ad90	note on a problem with reed and long's fbr results	gestion memoire;critical study;algorithm performance;implementation;storage management;cache memory;etude critique;antememoria;algorithme;estudio critico;algorithm;ejecucion;gestion memoria;antememoire;data cache;operating system;resultado algoritmo;analyse performance;performance analysis;performance algorithme;algoritmo;analisis eficacia	This short note discusses a problem we found in a recent article in Operating Systems Review [1]. The problem is related to apparent inconsistencies in results presented for a data cache algorithm, known as FBR (frequency based replacement), which we first described in [2]. A property of this algorithm is that cache miss ratios obtained using FBR can be related to LRU cache miss ratios for any given trace. Application of this property to the results in [1] reveals apparent inconsistencies. These inconsistencies could be the result of errors either in implementing the algorithm or in recording the results. This note also highlights this property of FBR, which should help contribute to its understanding.	algorithm;cpu cache;reed–solomon error correction	John T. Robinson;Murthy V. Devarakonda	1997	Operating Systems Review	10.1145/254784.254786	parallel computing;cpu cache;computer science;artificial intelligence;operating system;implementation;algorithm	Metrics	-16.68320192229764	45.313983757049144	118270
54a489614b4379c9ecade7099734277a71347234	dash: a benchmark suite for hybrid dataflow and shared memory programming models	shared memory;articulo;programming model;benchmark suite;dataflow;transactional memory	The current trend in development of parallel programming models is to combine different well established models into a single programming model in order to support efficient implementation of a wide range of real world applications. The dataflow model has particularly managed to recapture the interest of the research community due to its ability to express parallelism efficiently. Thus, a number of recently proposed hybrid parallel programming models combine dataflow and traditional shared memory models. Their findings have influenced the introduction of task dependency in the OpenMP 4.0 standard.#R##N##R##N#This article presents DaSH – the first comprehensive benchmark suite for hybrid dataflow and shared memory programming models. DaSH features 11 benchmarks, each representing one of the Berkeley dwarfs that capture patterns of communication and computation common to a wide range of emerging applications. DaSH also includes sequential and shared-memory implementations based on OpenMP and Intel TBB to facilitate easy comparison between hybrid dataflow implementations and traditional shared memory implementations based on work-sharing and/or tasks. Finally, we use DaSH to evaluate three different hybrid dataflow models, identify their advantages and shortcomings, and motivate further research on their characteristics.		Vladimir Gajinov;Srdjan Stipic;Igor Eric;Osman S. Unsal;Eduard Ayguadé;Adrián Cristal	2015	Parallel Computing	10.1016/j.parco.2015.03.005	dataflow architecture;shared memory;computer architecture;transactional memory;parallel computing;real-time computing;computer science;operating system;dataflow;programming paradigm;programming language	HPC	-6.332910441979369	45.16608759957603	118446
d2f13becfc20c3b2c6bbaee80db4b726dfa1a5a6	modeling and analysis of a parallel nested loop join on cluster architectures	modelizacion;distributed system;largeur bande;systeme reparti;nested loops;modelisation;sistema repartido;boucle imbriquee;anchura banda;bucle imbricado;bandwidth;cost effectiveness;modeling;nested loop;analytical model;modeling and analysis	We develop a concise but comprehensive analytical model for the well-known Nested Loop Join algorithm on cost effective cluster architectures. We concentrate on a limited number of characteristic parameters to keep the analytical model clear and focused. We believe that a meaningful model can be built upon only three characteristic parameter sets, describing main memory size, the I/O bandwidth and the disk bandwidth. We justify our approach by a practical implementation and a comparison of the theoretical and real performance values.	nested loop join	Erich Schikuta	2005		10.1007/11576235_7	real-time computing;simulation;nested loop join;computer science;database;distributed computing;algorithm	HPC	-17.488127575185707	44.30201342423464	118502
487e4d2109eaefa87d51f4c4919500c0ee44d082	representing linear algebra algorithms in code: the flame application program interfaces	linear algebra;lenguaje programacion;algoritmo paralelo;codage lineaire;code lineaire;operator algebra;additional key words and phrases application program interfaces;haute performance;computacion informatica;parallel algorithm;langage c;programming language;high performance libraries;incendie;metodo formal;methode formelle;grupo de excelencia;interface programme application;classroom;spectrum;application program interface;algorithme parallele;formal method;linear coding;c language;ciencias basicas y experimentales;algebre lineaire;linear code;matematicas;application program interfaces;aula clase;alto rendimiento;incendio;langage programmation;algebre operateur;algebra lineal;parallel implementation;enseignement;c programming language;formal linear algebra methods environment;formal derivation;fire;salle cours;high performance;algebra operador;lenguaje c;teaching;codificacion lineal;codigo lineal;ensenanza	In this article, we present a number of Application Program Interfaces (APIs) for coding linear algebra algorithms. On the surface, these APIs for the MATLAB M-script and C programming languages appear to be simple, almost trivial, extensions of those languages. Yet with them, the task of programming and maintaining families of algorithms for a broad spectrum of linear algebra operations is greatly simplified. In combination with our Formal Linear Algebra Methods Environment (FLAME) approach to deriving such families of algorithms, dozens of algorithms for a single linear algebra operation can be derived, verified to be correct, implemented, and tested, often in a matter of minutes per algorithm. Since the algorithms are expressed in code much like they are explained in a classroom setting, these APIs become not just a tool for implementing libraries, but also a valuable tool for teaching the algorithms that are incorporated in the libraries. In combination with an extension of the Parallel Linear Algebra Package (PLAPACK) API, the approach presents a migratory path from algorithm to MATLAB implementation to high-performance sequential implementation to parallel implementation. Finally, the APIs are being used to create a repository of algorithms and implementations for linear algebra operations, the FLAME Interface REpository (FIRE), which already features hundreds of algorithms for dozens of commonly encountered linear algebra operations.	algorithm;application programming interface;lapack;library (computing);linear algebra;matlab;programming language	Paolo Bientinesi;Enrique S. Quintana-Ortí;Robert A. van de Geijn	2005	ACM Trans. Math. Softw.	10.1145/1055531.1055533	spectrum;application programming interface;computer science;theoretical computer science;linear algebra;linear code;mathematics;parallel algorithm;fire;numerical linear algebra;operator algebra;programming language;algorithm;algebra	PL	-11.584774863901464	35.34320859994403	118523
90d8968daa4a50c21bdd6a6c5515186854036ddb	performance modeling and analysis of a massively parallel direct - part 2	global search algorithm;performance modeling;parallel efficiency;analysis technique;performance sensitivity;parallel design;parallel direct;parallel cluster;parallel scheme;effective large-scale parallel optimization;parallel version;performance metrics	Modeling and analysis techniques are used to investigate the performance of a massively parallel version of DIRECT, a global search algorithm widely used in multidisciplinary design optimization applications. Several high-dimensional benchmark functions and real world problems are used to test the design effectiveness under various problem structures. In this second part of a two-part work, theoretical and experimental results are compared for two parallel clusters with different system scale and network connectivity. The first part studied performance sensitivity to important parameters for problem configurations and parallel schemes, using performance metrics such as memory usage, load balancing, and parallel efficiency. Here linear regression models are used to characterize two major overhead sources—interprocessor communication and processor idleness—and also applied to the isoefficiency functions in scalability analysis. For a variety of high-dimensional problems and large scale systems, the massively parallel design has achieved reasonable performance. The results of the performance study provide guidance for efficient problem and scheme configuration. More importantly, the design considerations and analysis techniques generalize to the transformation of other global search algorithms into effective large scale parallel optimization tools.	benchmark (computing);computer cluster;inter-process communication;load balancing (computing);mathematical optimization;multidisciplinary design optimization;overhead (computing);paradiseo;scalability;search algorithm;speedup	Jian He;Alex Verstak;Masha Sosonkina;Layne T. Watson	2009	IJHPCA	10.1177/1094342008098463	massively parallel;multidisciplinary design optimization;parallel computing;theoretical computer science;scalability;linear regression;performance metric;computer science;distributed computing;load balancing (computing);search algorithm;technical report	HPC	-8.95933078731605	45.910517564270535	118568
f8101fc01ded5fd002070eafb994c41f96d1c9ce	memory management algorithms for optimistic parallel simulation	simulation evenement discret;parallelisme;gestion memoire;memory management;storage management;simulation;simulacion;gestion memoria;parallelism;simulation parallele;paralelismo;parallel simulation;discrete event simulation	This paper studies the space complexity of an optimistic parallel simulation protocol called Time Warp. We evaluate four Time Warp memory management algorithms: fossil collection, message sendback, cancelback and artificial rollback. We identify two criteria in designing Time Warp memory management algorithms. Criterion 1 tests if a memory management algorithm ensures that Time Warp simulation always stops (either completes or terminates when memory is exhausted). If an algorithm does not satisfy this criterion, then the simulation may be trapped in an infinite loop. Criterion 2 tests if a memory management algorithm is independent of processor parameters (e.g., number of processors available for the parallel simulation, processor speed and interprocessor communication costs). We show that if an algorithm satisfies this second criterion, then the amount of memory consumed by Time Warp simulation is bounded by the amount consumed by sequential simulation. For algorithms that do not have full control of uncommitted objects (e.g., fossil collection and message sendback), Criterion 2 is not satisfied in general. For algorithms that have full control of uncommitted objects (e.g., cancelback and artificial rollback), special treatments are necessary to satisfy Criterion 1 (i.e., to ensure that the algorithms do not cancel future objects such that global virtual time never advances).	algorithm;memory management;simulation	Yi-Bing Lin	1994	Inf. Sci.	10.1016/0020-0255(94)90051-5	mathematical optimization;parallel computing;real-time computing;computer science;artificial intelligence;discrete event simulation;machine learning;distributed computing;algorithm;memory management	AI	-16.117887011272572	45.08190672624247	118647
56945f764b325246d995dc1cdbaf208a49f5ece9	peta-scale hierarchical hybrid multigrid using hybrid parallelization		In this article we present a performance study of our finite element package Hierarchical Hybrid Grids (HHG) on current European supercomputers. HHG is designed to close the gap between the flex- ibility of finite elements and the efficiency of geometric multigrid by using a compromise between structured and unstructured grids. A coarse input finite element mesh is refined in a structured way, resulting in semi-structured meshes. Within this article we compare and analyze the efficiencies of the stencil-based code on those clusters.		Björn Gmeiner;Ulrich Rüde	2013		10.1007/978-3-662-43880-0_50	computational science;parallel computing;computer science;theoretical computer science	HCI	-7.733627937218631	36.1136580020894	118663
f8f293221efbb22a4940f7a4e5c6ca28fc84ae89	parallelization of the euler equations on unstructured grids	unstructured grid;euler equation	Aerospace Engineering (ABSTRACT) Several different time-integration algorithms for the Euler equations are investigated on two distributed-memory parallel computers using an explicit message-passing paradigm: these are classic Euler Explicit, four-stage Jameson-style Runge-Kutta, Block Jaco-bi, Block Gauss-Seidel, and Block Symmetric Gauss-Seidel. A finite-volume formulation is used for the spatial discretization of the physical domain. Both two-and three-dimensional test cases are evaluated against five reference solutions to demonstrate accuracy of the fundamental sequential algorithms. Different schemes for communicating or approximating data that are not available on the local compute node are discussed and it is shown that complete sharing of the evolving solution to the inner matrix problem at every iteration is faster than the other schemes considered. Speedup and efficiency issues pertaining to the various time-integration algorithms are then addressed for each system. Of the algorithms considered, Symmetric Block Gauss-Seidel has the overall best performance. It is also demonstrated that using parallel efficiency as the sole means of evaluating performance of an algorithm often leads to erroneous conclusions; the clock time needed to solve a problem is a much better indicator of algorithm performance. A general method for extending one-dimensional limiter formulations to the unstructured case is also discussed and applied to Van Albada's limiter as well as Roe's Superbee limiter. Solutions and convergence histories for a two-dimensional supersonic ramp problem using these limiters are presented along with computations using the limiters of Barth & Jesperson and Venkatakrishnan — the Van Al-bada limiter has performance similar to Venkatakrishnan's. iii Dedication to my wife and children: Susan, Kristin, Justin, and Erin iv Acknowledgments I would like first to acknowledge the boundless patience and loving support of my wife Susan. Without her unending encouragement and prayers through all my academic pursuits, I could never have completed this work. I am deeply indebted to my academic advisor, Dr. Robert Walters. A very small amount of his enormous expertise and insight has (I hope) rubbed off on me, and it has been a pleasure to work under his tutelage. I would also like to thank the United States Navy, the Office of Naval Research, and the Naval Air Warfare Center for providing financial support for this work through the Long-term Training and In-house Laboratory Independent Research programs. Finally, I am tremendously grateful to Dr. Asha Varma of the Naval Air Warfare Center for believing in me and being my advocate when it seemed no one else …	automatic parallelization;bada;computation;computer;discretization;distributed memory;euler;flux limiter;gauss–seidel method;iteration;justin (robot);message passing;parallel computing;programming paradigm;ramp simulation software for modelling reliability, availability and maintainability;robert;runge–kutta methods;sequential algorithm;speedup;test case	Christopher William Stuteville Bruner	1996			mathematical optimization;theoretical computer science;computational physics	HPC	-7.004097027259916	37.16347845986983	118715
4cdb43795979e37dbb5abc09edf18fcddad10a6b	distributed stochastic discrete-event simulation in parallel time streams	parallel time stream;stochastic discrete-event simulation;stochastic approximation;optimization;discrete event simulation;simulation model;distributed processing;local area network;stochastic simulation	Quantitative stochastic simulation suffers from the fact that sound simulation studies require very long runlength to obtain the results with sufficient accuracy. In this paper we look at traditional approaches to distributed quantitative stochastic simulation and propose a new scenario, Multiple Replications in Parallel Time Streams (MRIP), that solves the problem in an efficient way. An implementation of MRIP in a simulation package AKAROA is also described. AKAROA accepts ordinary (non-parallel) simulation models and creates automatically the environment required for running MRIP on workstations of a local area network. Presented results show that MRIP offers linear speedup of simulation. Limitations of this scenario for running distributed quantitative stochastic simulation are atso discussed.	simulation;speedup;workstation	Krzysztof Pawlikowski;Victor W. C. Yau;Donald C. McNickle	1994			local area network;stochastic approximation;real-time computing;simulation;computer science;technical report;theoretical computer science;discrete event simulation;systems simulation;simulation modeling;stochastic simulation;distributed computing;network traffic simulation	Metrics	-12.735833923022327	41.85625267744402	118722
f8a5f70e978093d4924f53bdd75bbbc31b9c61e0	performance analysis on multiprocessor memory organization			multiprocessing;profiling (computer programming)	Wei C. Yen;King-Sun Fu	1980			parallel computing;multiprocessing;memory organisation;computer science	HPC	-10.173663198474342	43.35543630565404	118808
b3e35f7c63b068028b75122abddb5a74f8e10edf	special issue on dataflow and multithreaded architectures - guest editors' introduction	parallelisme;flot donnee;architecture flot donnee;flujo datos;dataflow program execution;parallel computation;dataflow architecture;parallelism;calculo paralelo;paralelismo;multithreaded architecture;execution programme flot donnee;langage parallele;parallel language;data flow;calcul parallele		dataflow;thread (computing)	Guang R. Gao;Jean-Luc Gaudiot;Lubomir F. Bic	1993	J. Parallel Distrib. Comput.	10.1006/jpdc.1993.1064	dataflow architecture;data flow diagram;computer architecture;parallel computing;computer science;programming language	HPC	-15.990281333176661	40.83329461598911	118919
00bdb8428b3ea5e6e6e653034c53413ee3bfce12	message-driven relaxed consistency in a software distributed shared memory	shared memory;lazy release consistency;memory consistency;software distributed shared memory;efficient implementation;hybrid system;message passing;relaxed consistency;distributed shared memory;memory model	Message-passing and distributed shared memory have their respective advantages and disadvantages in distributed parallel programming. We approach the problem of integrating both mechanisms into a single system by proposing a new message-driven coherency mechanism. Messages carrying explicit causality annotations are exchanged to trigger memory coherency actions. By adding annotations to standard message-based protocols, it is easy to construct efficient implementations of common synchronization and communication mechanisms. Because these are user-level messages, the set of available primitives is extended easily with language-or application-specific mechanisms. CarlOS, an experimental prototype for evaluating this approach, is derived from the lazy release consistent memory of TreadMarks. We describe the message-driven coherency memory model used in CarlOS, and we examine the performance of several applications.	causality;distributed shared memory;lazy evaluation;memory coherence;message passing;parallel computing;prototype;treadmarks;user space	Povl T. Koch;Robert J. Fowler;Eric Jul	1994			uniform memory access;distributed shared memory;shared memory;memory model;demand paging;cache coherence;interleaved memory;parallel computing;message passing;real-time computing;distributed memory;computer science;consistency model;operating system;distributed computing;overlay;extended memory;flat memory model;programming language;data diffusion machine;cache-only memory architecture;memory map;hybrid system;memory management	OS	-14.512816231492847	46.36302192952124	119158
525bc8bd58d3c0ce11c08b9e6df47e259ab65940	coupling technique for distributed high performance earth system simulation framework	coupling interaction;earth system;framework;simulation	The Earth system includes a mass of interactive physical elements which interact to cause the constant changing of the Earth, even disaster. Disaster prediction of this system is crucial, but the complexity of this system brings a great challenge to researchers. Distributed high performance Earth system simulation framework is designed to solve this problem on our previous work. This paper proposes an efficient coupling interaction technique for this framework based on PRMI (Parallel Remote Method Invocation). It could automatically implement a series of complex underlying heterogeneous physics data remapping including grid remapping and data parallel distribution remapping, and ultimately realize the process to process parallel communication between physics-model components directly with no third-party conversion tools. Experiment results showed that this coupling interaction technique has achieved desirable performance, and successfully realized the numerical simulation of the coronal mass ejections.	computer simulation;data parallelism;earth system science;interaction technique;java remote method invocation	Shanshan Li	2013	JSW		real-time computing;simulation;computer science;earth system science;software framework;distributed computing;programming language	HPC	-7.952036412539809	36.01701729293439	119197
50e7dfc8357a591b380e8a4f6ca581e3095f6295	analysis of hierarchical bus-based multicomputer architectures	multiordinateur;evaluation performance;optimisation;architecture systeme;metodologia;performance evaluation;optimizacion;canal bus;hierarchized structure;evaluacion prestacion;sistema informatico;reseau ordinateur;canal colector;structure hierarchisee;transmission message;computer system;methodologie;message transmission;computer network;red ordenador;bus channel;arquitectura sistema;optimization;systeme informatique;methodology;system architecture;estructura jerarquizada;transmision mensaje	Abstract   Hierarchical interconnection networks with cluster structure have been proposed for use in multicomputer systems for parallel and distributed processing. However, little attention has been paid to the study of the underline communication network at the message passing level. The main contribution of this paper is to present a performance model which relates the performance criteria with the architecture design and implementation, and to derive a method for optimizing the hierarchy in such systems. The proposed methodology can be easily augmented to include additional objectives and/or decision variables.	parallel computing	Andreas S. Pomportsis	1992	Inf. Process. Lett.	10.1016/0020-0190(92)90221-G	embedded system;simulation;telecommunications;computer science;methodology;systems architecture	DB	-18.547378126360513	43.32887489381898	119448
57f9e11359e3ad4831b07c7eccd55a03a1616fc7	parallel computation in atmospheric chemical modeling	atmospheric models;distributed memory;dynamic model;urban air pollution;cluster of workstations;input output;massively parallel computer;distributed memory multiprocessors;parallel computer;air quality modeling;parallel i o;multiple instruction multiple data;atmospheric modeling;air quality model;workstation cluster	The porting of atmospheric chemical dynamic models to massively parallel computers presents interesting computational challenges. Strategies for the parallelization of the transport and chemistry operators of atmospheric models are outlined. The use of parallel buffers to perform input/output operations is described. Results are given for implementation of the CIT urban air pollution model on distributed memory multiple instruction/multiple data (MIMD) machines ranging from a cluster of workstations to a 512 node Intel Paragon. A speed-up factor of 94.9 is achieved when the I/O, transport, and chemistry portions of the model are performed in parallel using 256 nodes of the Intel Paragon.	computation;parallel computing	Donald Dabdub;John H. Seinfeld	1996	Parallel Computing	10.1016/0167-8191(95)00063-1	input/output;atmospheric model;parallel computing;real-time computing;distributed memory;computer science;operating system;massively parallel;distributed computing;atmospheric models	HPC	-6.145267842943052	36.7812030211931	119487
404042c2b1c045f587f0a3b9f53e6fa6741c2c2a	a compiler extension for parallel matrix programming	generators;matrix programming;oceans;semantics;parallel programming;extensible languages;indexing;syntactics;oceans syntactics indexing instruction sets generators semantics;matrix programming extensible languages parallel programming;program compilers c language data mining formal specification matrix algebra optimisation parallel programming;high level domain specific optimization compiler extension parallel matrix programming prototype extensible c translator spatio temporal data mining matrix operation language feature semantic analysis parallel c code loop tiling technique vector processor syntax analysis c language;instruction sets	This paper describes a compiler extension to our prototype extensible C translator that adds new features for parallel execution of matrix operations and shows their application to problems in spatio-temporal data mining. The extension provides new language features for constructing new matrices, mapping functions over elements of a matrix, and accumulating operations that, for example, can sum values in a matrix. It also provides the appropriate semantic analysis to check for errors before translating the constructs down to parallel C code. The extension also provides features that let the programmer indicate how the extension translates these matrix constructs down to C code. Programmers seeking higher levels of performance can specify how the underlying for-loops are structured so that code using, for example, loop-tiling techniques or vector processors, is generated. In general, compiler extensions supported by our approach allow new domain-specific syntax and semantic analyses to be easily added to the host language. Specifications of the host C language and the extensions are composed to create a custom translator that maps extended C programs down to plain (parallel) C code, checking for domain-specific errors and applying high-level domain-specific optimizations in the process.	attribute grammar;c11 (c standard revision);central processing unit;cilk plus;compiler;computation;data mining;high- and low-level;matlab;modular connector;parallel computing;programmer;programming language specification;prototype;rewrite (programming);sac;supercomputer;the matrix;tiling window manager;unified parallel c (upc);usability;vector processor	Kevin Williams;Matthew Le;Ted Kaminski;Eric Van Wyk	2014	2014 43rd International Conference on Parallel Processing	10.1109/ICPP.2014.56	search engine indexing;first-generation programming language;compiler;parallel computing;computer science;theoretical computer science;extensible programming;operating system;compiler construction;instruction set;semantics;programming paradigm;programming language	PL	-13.838153362673268	37.08420049453872	119745
43cdb5b8658cd9c9b6dadac7dc8cebb7113ece99	parallel performance optimization of large-scale unstructured data visualization for the earth simulator	speedup performance;hybrid parallelization;large-scale unstructured data visualization;high parallel performance;dynamic load repartition;good visualization image;earth simulator;inter-smp node communication;efficient parallel performance optimization;data race;three-level hybrid parallelization;intra-smp node parallelization;data visualization;message passing;load balance	This paper describes some efficient parallel performance optimization strategies for large-scale unstructured data visualization on SMP cluster machines including the Earth Simulator in Japan. The three-level hybrid parallelization is employed in our implementation, consisting of message passing for inter-SMP node communication, loop directives by OpenMP for intra-SMP node parallelization, and vectorization for each processing element (PE). In order to improve the speedup performance for the hybrid parallelization, some techniques, such as multi-coloring for removing data race and dynamic load repartition for load balancing, are considered. Good visualization images and high parallel performance have been achieved on Hitachi SR8000 for large-scale unstructured datasets, which shows the feasibility and effectiveness of our strategies.	data visualization;earth simulator;mathematical optimization;simulation	Li Chen;Issei Fujishiro;Kengo Nakajima	2002			parallel computing;message passing;computer science;load balancing;operating system;distributed computing;programming language;data visualization	HPC	-6.641858454803889	39.447235314474234	119771
34829ef41d835716973c17c511b06e00e368e56c	a 29.5 tflops simulation of planetesimals in uranus-neptune region on grape-6	gordon bell performance prize;grape-6 system;actual performance;tflops simulation;theoretical peak performance;protoplanet-planetesimal system;pipeline processor;uranus-neptune region;outer solar system;custom pipeline chip;early evolution;clustering algorithms;scattering;web services;planets;computational modeling;chip;solar system;semantic grid;sun;astronomy;pipelines;planetary orbits	As an entry for the 2002 Gordon Bell performance prize, we report the performance achieved on the GRAPE-6 system for a simulation of the early evolution of the protoplanet-planetesimal system of the Uranus-Neptune region. GRAPE-6 is a special-purpose computer for astrophysical N-body calculations. The present configuration has 2048 custom pipeline chips, each containing six pipeline processors for the calculation of gravitational interactions between particles. Its theoretical peak performance is 63.4 Tflops. The actual performance obtained was 29.5 Tflops, for a simulation of the early evolution of outer Solar system with 1.8 million planetesimals and two massive protoplanets.	central processing unit;embedded system;flops;gordon bell;interaction;neptune;simulation	Junichiro Makino;Eiichiro Kokubo;Toshiyuki Fukushige;Hiroshi Daisaka	2002	ACM/IEEE SC 2002 Conference (SC'02)		chip;planet;web service;semantic grid;computer science;pipeline transport;solar system;cluster analysis;scattering;computational model;orbit	HPC	-5.368731218613812	37.44962212329569	119877
21b4e156771b53721dcc7311c9a820af9483161b	runtime adjustment of parallel nested loops	scientific application;nested loops;a priori information;dynamic adaptation;parallel applications	OpenMP allows programmers to specify nested parallelism in parallel applications. In the case of scientific applications, parallel loops are the most important source of parallelism. In this paper we present an automatic mechanism to dynamically detect the best way to exploit the parallelism when having nested parallel loops. This mechanism is based on the number of threads, the problem size, and the number of iterations on the loop. To do that, we claim that programmers must specify the potential application parallelism and give the runtime the responsibility to decide the best way to exploit it. We have implemented this mechanism inside the IBM XL runtime library. Evaluation shows that our mechanism dynamically adapts the parallelism generated to the application and runtime parameters, reaching the same speedup as the best static parallelization (with a priori information).	analysis of algorithms;iteration;openmp;parallel computing;programmer;runtime library;speedup	Alejandro Duran;Raúl Silvera;Julita Corbalán;Jesús Labarta	2004		10.1007/978-3-540-31832-3_12	parallel computing;nested loop join;computer science;theoretical computer science;operating system;distributed computing;data parallelism;programming language;instruction-level parallelism;scalable parallelism;implicit parallelism;task parallelism	HPC	-13.70645427906448	45.94412270151534	119955
92b28632f2c94fff6ea93c116109f14304399ac9	the solution of simultaneous equations	history;gaussian processes;application software;feeds;computer architecture;permission;information processing;production;equations costs application software permission gaussian processes information processing history feeds production computer architecture;simultaneous equations	Overhead distribution involves the transfer of costs between where T, represents the total costs for which we are solving, the overhead and production departments. This cost acI, are the initial direct costs, and a, represents the percentage counting problem is common to many businesses. As demof the total cost of department “i” which is part of the total onstrated by the IBM Type 650 Magnetic Drum Data Proccost of department “j”. essing Machine, this sample application requires the soluThe method of solution is that known to mathematition of ninety algebraic linear equations. cians as the Gauss-Seidel Method. It is an iterative proceHere (in this problem recently solved by a Philadelphia dure whereby approximate solutions are improved by rebank) total costs are determined for ninety departments peated calculations until the correct solutions are obtained. where there are six hundred and twenty-five interdepartThe correct solution is automatically determined by the mental distributions. Mathematically this is expressed as calculator and the iteration is ended when the sum of the follows: differences between the total costs on one iteration and the total costs on the previous iteration is less than one dollar. Following the solution a card for each department is punched T1 = I, + a2,1Tz + a3,1T3 + --+ a90,1T9D showing department number, total cost, distributed amount, and net cost. TS = I, + al,zT1 + a3,2T3 + --+ ago,zT90 Two hundred and ten instructions plus a few constants ______-------------~~~~~~~~~~---are loaded in less than one minute. Nine iterations are required at a process rate of forty seconds per iteration. The ______-----------_---~~~~~~~~~~-ninety answer cards are punched in less than a minute. The ____--------------~______I_______ total running time from the first card fed to the last solution	approximation algorithm;counting problem (complexity);drum memory;gauss–seidel method;iteration;linear equation;overhead (computing);time complexity	G. Truman Hunter	1986	Annals of the History of Computing	10.1109/MAHC.1986.10024	application software;real-time computing;simultaneous equations;information processing;computer science;theoretical computer science;gaussian process;database	AI	-13.728752811496108	33.514322603733426	119967
19d06232e954271c42ce95ac680ae103703686d6	building an object oriented problem solving environment for the parallel numerical solution of pdes	linear algebra;partial differential equation;numerical solution;software libraries;object oriented design;software documentation;object oriented application frameworks;object oriented;numerical computation;intelligent agent;fortran;parallel implementation;numerical linear algebra;problem solving environment;minimalist manuals	Traditionally, the development of parallel implementations of algorithms for the Numerical Solution of Partial Differential Equations (PDE) and Linear Algebra Problems is based on software libraries; typically, Fortran libraries. Due to the lack of abstraction of Fortran-like libraries, two main problems are encountered: the libraries are complex to develop and the library interfaces are difficult to use. This PhD project proposes to investigate (1) the advantages and disadvantages that object oriented design and programming can bring to the Numerical Solution of PDEs and Numerical Linear Algebra (NLA) and (2) the integration of PDE and NLA object oriented libraries with intelligent Agents to form the basis of a Problem Solving Environment (PSE) for Numerical Computation.	algorithm;computation;fortran;library (computing);numerical linear algebra;numerical partial differential equations;problem solving environment	Mikel Luján	2000		10.1145/367845.368055	computational science;computer science;theoretical computer science;linear algebra;object-oriented design;numerical linear algebra;programming language;software documentation;object-oriented programming;intelligent agent;partial differential equation	HPC	-9.678824072385769	36.217814624427305	120332
8e49974e5994e36c570c7213995ffdf38bb5fd68	towards performance portability through runtime adaptation for high-performance computing applications	gigabit ethernet network;intel em64t cluster;adaptive communication library;towards performance portability;ibm power pc cluster;ibm federation switch;ibm blue gene-l;amd opteron cluster;high-performance computing application;application level group communication;communication pattern;three-dimensional neighborhood communication lead;runtime adaptation	The Abstract Data and Communication Library (ADCL) is an adaptive communication library optimizing application level collective communication operations at runtime. The library provides for a given communication pattern a large number of implementations and incorporates a runtime selection logic in order to choose the implementation leading to the highest performance. In this paper, we demonstrate for the first time, how an application utilizing ADCL is deployed on a wide range of HPC architectures, including an IBM Blue Gene, an NEC SX8, an IBM Power PC cluster using an IBM Federation Switch, an AMD Opteron cluster utilizing an 4xInfiniBand and a Gigabit Ethernet network, and an Intel EM64T cluster using a hierarchical Gigabit Ethernet network with reduced uplink bandwidth. We demonstrate, how different implementations for the three dimensional neighborhood communication lead to the minimal execution time of the application on different architectures. ADCL gives the user the advantage of having to maintain only a single version of the source code and still have the ability to achieve close to optimal performance for the application on all architectures.	acm/ieee supercomputing conference;algorithm;blue gene;early stopping;fastest;gigabit;mathematical optimization;microsoft outlook for mac;nec sx architecture;open mpi;parallax sx;powerpc;run time (program lifecycle phase);san diego supercomputer center;simulation;software portability;symbolic execution;telecommunications link;teragrid;x86-64	Edgar Gabriel;Saber Feki;Katharina Benkert;Michael M. Resch	2010	Concurrency and Computation: Practice and Experience	10.1002/cpe.1586	parallel computing;real-time computing;computer science;operating system;database;distributed computing	HPC	-7.468225297853843	44.114030514806885	120398
4458b761c549add96407d4f9d7cac4da1ab8ee23	s-net for multi-memory multicores	component technology;shared memory;universiteitsbibliotheek;data communication;conference paper;hybrid memory architecture;software architecture;multicore programming;development environment;structural dynamics;system on chip;memory architecture;component coordination;language extension;runtime system;stream processing	S-Net is a declarative coordination language and component technology aimed at modern multi-core/many-core architectures and systems-on-chip. It builds on the concept of stream processing to structure dynamically evolving networks of communicating asynchronous components. Components themselves are implemented using a conventional language suitable for the application domain. This two-level software architecture maintains a familiar sequential development environment for large parts of an application and offers a high-level declarative approach to component coordination.  In this paper we present a conservative language extension for the placement of components and component networks in a multi-memory environment, i.e. architectures that associate individual compute cores or groups thereof with private memories. We describe a novel distributed runtime system layer that complements our existing multithreaded runtime system for shared memory multicores. Particular emphasis is put on efficient management of data communication. Last not least, we present preliminary experimental data.	application domain;complement (complexity);evolving networks;high- and low-level;manycore processor;multi-core processor;novell s-net;runtime system;shared memory;software architecture;stream processing;system on a chip;thread (computing)	Clemens Grelck;Jukka Julku;Frank Penczek	2010		10.1145/1708046.1708054	computer architecture;parallel computing;real-time computing;computer science	PL	-12.439318814025198	39.62427610595988	120679
93e713205a2db5baf19f7b011d610759feac0bc6	an error correction solver for linear systems: evaluation of mixed precision implementations	iterative refinement;hardware aware computing;linear system of equations;mixed precision;fluid flow;large sparse linear systems;linear system;finite element;gpgpu;computational fluid dynamics cfd;error correction;graphic processing unit;fluid dynamics;iterative refinement method;sparse linear system	This paper proposes an error correction method for solving linear systems of equations and the evaluation of an implementation using mixed precision techniques . While different technologies are available, graphic processing units (GPUs) have been established as particularly powerful coprocessors in recent years. For this reason, our error correction approach is focused on a CUDA implementation executing the error correction solver on the GPU. Benchmarks are performed both for artificially created matrices with preset characteristics as well as matrices obtained from finite element discretizations of fluid flow problems.	benchmark (computing);cuda;coprocessor;error detection and correction;finite element method;graphics processing unit;linear system;solver	Hartwig Anzt;Vincent Heuveline;Björn Rocker	2010		10.1007/978-3-642-19328-6_8	system of linear equations;computational science;parallel computing;error detection and correction;computer science;theoretical computer science;finite element method;linear system;general-purpose computing on graphics processing units;fluid dynamics	HPC	-5.329118484630422	36.64642961902339	120741
00954a6c7a7dd42fe90b749cfbb746d43cdb06af	direct mpi library for intel xeon phi co-processors	peripheral interfaces application program interfaces coprocessors message passing multiprocessing systems open systems;direct communication;peripheral interfaces;receivers libraries protocols kernel data transfer computer architecture computational modeling;accelerator;mpi library;coprocessors;infiniband;xeon phi;application program interfaces;message passing;accelerator mpi library co processor xeon phi infiniband direct communication;multiprocessing systems;direct mpi library threads parallelization openmp stencil computation mpi processes preproduction version mellanox infiniband hca direct internode communication direct infiniband communication functionality many core based accelerators direct communication facility pci express data transfer intel xeon phi coprocessor card dcfa mpi;open systems;co processor	DCFA-MPI is an MPI library implementation for Intel Xeon Phi co-processor clusters, where a compute node consists of an Intel Xeon Phi co-processor card connected to the host via PCI Express with InfiniBand. DCFA-MPI enables direct data transfer between Intel Xeon Phi co-processors without assistance from the host. Since DCFA, a direct communication facility for many-core based accelerators, provides direct Infini-Band communication functionality with the same interface as that on the host processor for Xeon Phi co-processor user space programs, direct InfiniBand communication between Xeon Phi co-processors could easily be developed. Using DCFA, an MPI library able to perform direct inter-node communication between Xeon Phi co-processors, has been designed and implemented. The implementation is based on the Mellanox InfiniBand HCA and the pre-production version of the Intel Xeon Phi coprocessor. DCFA-MPI delivers 3 times greater bandwidth than the 'Intel MPI on Xeon Phi co-processors' mode, and a from 2 to 12 times speed-up when compared to the 'Intel MPI on Xeon where it offloads computation to Xeon Phi co-processors' mode in communication with 2 MPI processes. It also shows from 2 to 4 times speed-up over the Intel MPI on Xeon Phi Intel MPI on Xeon where it offloads computation to Xeon Phi co-processors' mode in a five point stencil computation with an 8 processes * 56 threads parallelization by MPI + OpenMP.	central processing unit;computation;coprocessor;five-point stencil;infiniband;manycore processor;message passing interface;openmp;pci express;parallel computing;stencil (numerical analysis);user space;xeon phi	Min Si;Yutaka Ishikawa;Masamichi Takagi	2013	2013 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum	10.1109/IPDPSW.2013.179	computer architecture;parallel computing;computer science;operating system;hyper-threading;pentium	HPC	-7.566990385882757	41.70819937548624	120746
ff2405b093acbb52ee501b29adab8f47e9b635d6	performance measurement for system/38, ibm's advanced architecture system			ibm system/38	Brian E. Clark	1984			ibm;architecture;performance measurement;computer architecture;computer science	Robotics	-9.939338449946584	44.37397166414413	120775
40ac341b9fa5293cbdef7f070c42a841bffa8cc7	function level parallelism driven by data dependencies	data sharing;chip multiprocessor;data replication;cmp caches;performance modeling and projection;data flow graph;technology and engineering;data dependence;graph representation;parallel computer;stack simulation;data flow;data structure	With the rise of Chip multiprocessors (CMPs), the amount of parallel computing power will increase significantly in the near future. However, most programs are sequential in nature and have not been explicitly parallelized, so they cannot exploit these parallel resources. Automatic parallelization of sequential, non-regular codes is very hard, as illustrated by the lack of solutions after more than 30 years of research on the topic. The question remains if there is parallelism in sequential programs that can be detected automatically and if so, how much parallelism there is.  In this paper, we propose a framework for extracting potential parallelism from programs. Applying this framework to sequential programs can teach us how much parallelism is present in a program, but also tells us what the most appropriate parallel construct for a program is, e.g. a pipeline, master/slave work distribution, etc.  Our framework is profile-based, implying that it is not safe. It builds two new graph representations of the profile-data: the interprocedural data flow graph and the data sharing graph. This graphs show the data-flow between functions and the data structures facilitating this data-flow, respectively.  We apply our framework on the SPECcpu2000 bzip2 benchmark, achieving a speedup of 3.74 of the compression part and a global speedup of 2.45 on a quad processor system.	automatic parallelization;benchmark (computing);call graph;code;control flow;data compression;data dependency;data structure;dataflow;function-level programming;master/slave (technology);parallel computing;pipeline (computing);profiling (computer programming);speedup;task parallelism;bzip2	Sean Rul;Hans Vandierendonck;Koen De Bosschere	2006	SIGARCH Computer Architecture News	10.1145/1241601.1241612	data flow diagram;computer architecture;parallel computing;data structure;computer science;theoretical computer science;operating system;data-flow analysis;data parallelism;graph;programming language;instruction-level parallelism;implicit parallelism;replication;task parallelism	Arch	-6.231333680041992	46.37800704371516	120851
79530ab7f91ea5f5b6ce27f206539bfc0ae9d152	a computational model for a class of synchronized distributed memory machines	computer model		computation;computational model;distributed memory	James J. Carrig;Gerard G. L. Meyer	1995			flat memory model;data diffusion machine;parallel computing;distributed computing;memory map;distributed memory;distributed shared memory;computer science;overlay;uniform memory access;shared memory	Logic	-10.558251144980584	43.025653725783734	120872
6533175f28f934fe14f68a539c16268193be45dc	the skel-bsp global optimizer: enhancing performance portability in parallel programming	compilacion;optimisation;optimizacion;esqueleto;programacion paralela;parallel programming;optimum global;global optimum;portability;skeleton;portabilite;squelette;compilation;image analysis;global optimization;optimization;parallel programs;optimo global;portabilidad;programmation parallele	The paper describes the Skel-BSP Global Optimizer (GO), a compile-time technique tuning the structure of skeletal programs to the characteristics of the target architecture. The GO uses a set of optimization rules predicting the costs of each skeleton. The optimization rules refer to a set of implementation templates developed on top of the EdD-BSP (a variant of the BSP model). The paper describes the Program Annotated Tree representation and the set of transformation rules utilized by the GO to modify the starting program. The optimization phases: balancing, scaling and augmenting are presented and explained running the GO on a cluster of PCs for an image analysis toy-program.	mathematical optimization;parallel computing;software portability	Andrea Zavanella	2000		10.1007/3-540-44520-X_91	parallel computing;image analysis;computer science;theoretical computer science;global optimum;skeleton;algorithm;global optimization	HPC	-14.456461868071722	36.84647875877027	120949
594f9cdc236a5258d843a4a389329f703ae43b0b	a scalable framework for heterogeneous gpu-based clusters	linear algebra;distributed memory;paper;heterogeneous systems;heterogeneous cluster;hybrid cpu gpu architectures;high energy;manycore scheduling;heterogeneous clusters;gpu cluster;interconnection network;programming model;cuda;cholesky factorization;factorization;data dependence;nvidia;algorithms;distribution dynamics;mpi;task assignment;tesla m2070;runtime system;computer science;distributed runtime;high performance;dynamic scheduling	GPU-based heterogeneous clusters continue to draw attention from vendors and HPC users due to their high energy efficiency and much improved single-node computational performance, however, there is little parallel software available that can utilize all CPU cores and all GPUs on the heterogeneous system efficiently. On a heterogeneous cluster, the performance of a GPU (or a compute node) increases in a much faster rate than the performance of the PCI-Express connection (or the interconnection network) such that communication eventually becomes the bottleneck of the entire system. To overcome the bottleneck, we developed a multi-level partitioning and distribution method that guarantees a near-optimal communication volume. We have also extended heterogeneous tile algorithms to work on distributed memory GPU clusters. Our main idea is to execute a serial program and generate hybrid-size tasks, and follow a dataflow programming model to fire the tasks on different compute nodes. We then devised a distributed dynamic scheduling runtime system to schedule tasks, and transfer data between hybrid CPU-GPU compute nodes transparently. The runtime system employs a novel distributed task-assignment protocol to solve data dependencies between tasks without coordination between processing units. The runtime system on each node consists of a number of CPU compute threads, a number of GPU compute threads, a task generation thread, an MPI communication thread, and a CUDA communication thread. By overlapping computation and communication through dynamic scheduling, we are able to attain a high performance of 75 TFlops for Cholesky factorization on the heterogeneous Keeneland system using 100 nodes, each with twelve CPU cores and three GPUs. Moreover, our framework is able to attain high performance on distributed-memory clusters without GPUs, and shared-system multiGPUs.	algorithm;cuda;central processing unit;cholesky decomposition;computation;data dependency;dataflow programming;distributed memory;flops;graphics processing unit;interconnection;message passing interface;pci express;programming model;runtime system;scalability;scheduling (computing)	Fengguang Song;Jack J. Dongarra	2012		10.1145/2312005.2312025	parallel computing;real-time computing;distributed memory;dynamic priority scheduling;computer science;message passing interface;linear algebra;operating system;distributed computing;programming paradigm;factorization;cholesky decomposition;algebra	HPC	-5.02486936518532	42.020403599695314	121049
3e11dfa36f3414828a4524ea5e00eab91bbd2098	simulated performance of a data-driven database machine	data transmission;computer architecture;parallel processing		database machine	Lubomir F. Bic;Robert L. Hartmann	1986	J. Parallel Distrib. Comput.	10.1016/0743-7315(86)90025-0		DB	-9.924349306167597	42.4518299085761	121059
05e13b6a7990d99ed62ce01bc91325a6590223f5	can traditional programming bridge the ninja performance gap for parallel computing applications?	average ninja gap;processors;low programming effort;predictable performance growth;ninja performance gap;systems;parallel computing application;close-to-optimal performance;ninja code;performance gap;best-optimized code;ninja gap;modern compiler technology;traditional programming bridge;high effort;program optimization;multi core processor;topology;intel many integrated core architecture;optimization;parallel computer;parallel processing;benchmark testing;parallel programming;diameter;high performance computing;multicore processors;bandwidth;programming	"""Current processor trends of integrating more cores with wider SIMD units, along with a deeper and complex memory hierarchy, have made it increasingly more challenging to extract performance from applications. It is believed by some that traditional approaches to programming do not apply to these modern processors and hence radical new languages must be discovered. In this paper, we question this thinking and offer evidence in support of traditional programming methods and the performance-vs-programming effort effectiveness of common multi-core processors and upcoming many-core architectures in delivering significant speedup, and close-to-optimal performance for commonly used parallel computing workloads.  We first quantify the extent of the """"Ninja gap"""", which is the performance gap between naively written C/C++ code that is parallelism unaware (often serial) and best-optimized code on modern multi-/many-core processors. Using a set of representative throughput computing benchmarks, we show that there is an average Ninja gap of 24X (up to 53X) for a recent 6-core Intel® Core#8482; i7 X980 Westmere CPU, and that this gap if left unaddressed will inevitably increase. We show how a set of well-known algorithmic changes coupled with advancements in modern compiler technology can bring down the Ninja gap to an average of just 1.3X. These changes typically require low programming effort, as compared to the very high effort in producing Ninja code. We also discuss hardware support for programmability that can reduce the impact of these changes and even further increase programmer productivity. We show equally encouraging results for the upcoming Intel® Many Integrated Core architecture (Intel® MIC) which has more cores and wider SIMD. We thus demonstrate that we can contain the otherwise uncontrolled growth of the Ninja gap and offer a more stable and predictable performance growth over future architectures, offering strong evidence that radical language changes are not required."""	automatic vectorization;automation;benchmark (computing);black–scholes model;blocking (computing);c++;cuda;cell (microprocessor);central processing unit;cilk plus;compiler;computation;computer science;convolution;design closure;domain-specific language;entity–relationship model;graphics processing unit;hideki imai;high-throughput computing;intel core (microarchitecture);international parallel and distributed processing symposium;international symposium on computer architecture;itakura–saito distance;lattice boltzmann methods;list of astronomical catalogues;manycore processor;mathematical optimization;memory hierarchy;monte carlo method;multi-core processor;multiprocessing;parsec benchmark suite;parallel computing;performance evaluation;programmer;programming productivity;simd;short-rate model;sorting;speedup;springer (tank);stencil code;throughput;uncontrolled format string;volume rendering;wen-mei hwu;westmere (microarchitecture);xeon phi	Nadathur Satish;Changkyu Kim;Jatin Chhugani;Hideki Saito;Rakesh Krishnaiyer;Mikhail Smelyanskiy;Milind Girkar;Pradeep Dubey	2012	2012 39th Annual International Symposium on Computer Architecture (ISCA)	10.1145/2742910	human–computer interaction;computer science;theoretical computer science	Arch	-6.849333258891029	44.96664571238524	121080
2c8427550c1bd14c4165e736dd8f725f4779fa9d	a unified semantics for future erlang	semantics;formal semantics;erlang	The formal semantics of Erlang is a bit too complicated to be easily understandable. Much of this complication stems from the desire to accurately model the current implementations (Erlang/OTP R11-R14), which include features (and optimizations) developed during more than two decades. The result is a two-tier semantics where systems, and in particular messages, behave differently in a local and a distributed setting. With the introduction of multi-core hardware, multiple run-queues and efficient SMP support, the boundary between local and distributed is diffuse and should ultimately be removed. In this paper we develop a new, much cleaner semantics, for such future implementations of Erlang. We hope that this paper can stimulate some much needed debate regarding a number of poorly understood features of current and future implementations of Erlang.	erlang (programming language);multi-core processor;multitier architecture;semantics (computer science);symmetric multiprocessing	Hans Svensson;Lars-Åke Fredlund;Clara Benac Earle	2010		10.1145/1863509.1863514	erlang;real-time computing;computer science;theoretical computer science;formal semantics;database;operational semantics	PL	-14.710025438785182	39.997893481897364	121083
398551d488f0516f5d2ba4a0e10399467e268a3e	portable mapping of openmp to multicore embedded systems using mca apis	mca layer;posix thread;low-level apis;runtime implementation;multicore embedded system;openmp translation layer;runtime system;mca apis;portable mapping;embedded system;embedded benchmarks;embedded systems	Multicore embedded systems are being widely used in telecommunication systems, robotics, medical applications and more.While they offer a high-performance with low-power solution, programming in an efficient way is still a challenge. In order to exploit the capabilities that the hardware offers, software developers are expected to handle many of the low-level details of programming including utilizing DMA, ensuring cache coherency, and inserting synchronization primitives explicitly. The state-of-the-art involves solutions where the software toolchain is too vendor-specific thus tying the software to a particular hardware leaving no room-for portability. In this paper we present a runtime system to explore mapping a high-level programming model, OpenMP, on to multicore embedded systems. A key feature of our scheme is that unlike the existing approaches that largely rely on POSIX threads, our approach leverages the Multicore Association (MCA) APIs as an OpenMP translation layer. The MCA APIs is a set of low-level APIs handling resource management, inter-process communications and task scheduling for multicore embedded systems. By deploying the MCA APIs, our runtime is able to effectively capture the characteristics of multicore embedded systems compared with the POSIX threads. Furthermore, the MCA layer enables our runtime implementation to be portable across various architectures. Thus programmers only need to maintain a single OpenMP code base which is compatible by various compilers, while on the other hand, the code is portable across different possible types of platforms. We have evaluated our runtime system using several embedded benchmarks. The experiments demonstrate promising and competitive performance compared to the native approach for the platform.	embedded system;micro channel architecture;multi-core processor;openmp	Cheng Wang;Sunita Chandrasekaran;Peng Sun;Barbara M. Chapman;Jim Holt	2013		10.1145/2499369.2465569	embedded system;parallel computing;real-time computing;computer science;operating system;programming language	EDA	-5.9171561196069975	44.593507998839044	121318
30db55ec372422a5c37db09e3bec6b15d330f87e	the signal flow model: a novel data driven approach to parallel processing	parallel processing		parallel processing (dsp implementation)	Muhammad F. Mudawwar;C. Y. Roger Chen	1992			parallel computing;parallel processing;computer science;signal-flow graph	HPC	-9.061391811162855	42.41895475438676	121345
e98482d9b7131ee723b8197c7e60788a760839e1	large scale simulation of parallel molecular dynamics	load balancing strategies;microwave integrated circuits;biology computing;multi threading;programming environments;high performance computing;resource allocation;biological system modeling;resource allocation proteins digital simulation multi threading biology computing programming environments;biology;takakaw;large proteins;computational modeling;large scale simulation;proteins;parallel programming environment;solid modeling;multi threading parallel programming environment;load management;large scale systems microwave integrated circuits biological system modeling computational modeling equations biology computing high performance computing solid modeling proteins load management;molecular dynamic;load balance;athapascan;hydrated β galactosidase;hydrated spl beta galactosidase large scale simulation parallel molecular dynamics takakaw large proteins biology multi threading parallel programming environment athapascan load balancing strategies;parallel molecular dynamics;parallel applications;digital simulation;large scale systems	This paper aims to describe the implementation of TAKAKAW , an efficient parallel application for the simulation of molecular dynamics designed to handle large proteins in biology. The implementation is based on the multi-threading parallel programming environment, called ATHAPASCAN 1 which allows to implement and evaluate easily several load-balancing strategies. Some experiments run on one of the largest molecule ever simulated (an hydrated -galactosidase with 413039 atoms) show the interest of such a parallel programming environment. keywords. Load balancing Threads Parallel Molecular Dynamics.	algorithm;approximation;central processing unit;cray t3e;experiment;integrated development environment;interaction;load balancing (computing);molecular dynamics;numerical partial differential equations;parallel computing;recursion;simulation;thread (computing)	Pierre-Eric Bernard;Thierry Gautier;Denis Trystram	1999		10.1109/IPPS.1999.760544	computational science;computer science;bioinformatics;theoretical computer science	HPC	-9.409654655005532	37.85753516071714	121374
26e95aba7760a3fc4a953138d4325664e66d046e	code parallelization through sequential code search	databases;libraries;code sequentialization;concurrent computing;semantics;parallel programming;cloning;clone detection;java	In this paper, we propose a new technique to recommend programmers with high quality parallel code that are similar to a given sequential code. This is done by transforming well-grounded parallel code A into its sequential equivalent B, storing them (A->B) into database, given a sequential code C, search the database for syntactic or semantic similar code B and retrieve its parallel version code A, which can be used as the replacement or reference for the original code C. We also outline our solutions towards realizing this technique and present a preliminary study that shows promising results.	automatic parallelization;display resolution;outline (list);parallel computing;programmer	Bowen Cai	2016	2016 IEEE/ACM 38th International Conference on Software Engineering Companion (ICSE-C)	10.1145/2889160.2891045	dead code;code bloat;concurrent computing;canonical huffman code;object code;computer science;theoretical computer science;operating system;dead code elimination;redundant code;cloning;database;semantics;programming language;java;code generation;threaded code;unreachable code;source code	SE	-18.655839711718084	33.35752078799548	121380
37636e19b45b90dd1db0d0a6baf28d916f7262e1	automatic data and computation decomposition for distributed-memory machines	distributed system;systeme reparti;compilateur;decomposition;parallelizing compiler;data locality;data;distributed memory machine;paralelisacion;calculo automatico;compiler;computing;calcul automatique;polynomial time algorithm;sistema repartido;decomposition algorithm;parallelisation;parallelization;computation decomposition for distributed memory machines;descomposicion;linear equations;automatic loop parallelization;compilador;data and computation decomposition	In this paper, we develop an automatic compile-time computation and data decomposition technique for distributed-memory machines. Our method handles complex programs containing perfect and non-perfect loop nests with or without loop-carried dependences. Applying our algorithms, a program will be divided into collections (called clusters) of loop nests, such that data redistributions are allowed only between the clusters. Within each cluster of loop nests, decomposition and data locality constraints are formulated as a system of homogeneous linear equations which is solved by polynomial time algorithms. Our algorithm can selectively relax data locality constraints within a cluster to achieve a balance between parallelism and data locality. Such relaxations are guided by exploiting the hierarchical program nesting structures from outer to inner nesting levels to keep the communications at a outer-most level possible.	computation;distributed memory	Qi Ning;Guang R. Gao	1995	Parallel Processing Letters	10.1142/S0129626495000485	compiler;computing;parallel computing;computer science;theoretical computer science;operating system;distributed computing;decomposition;programming language;algorithm;data	HPC	-15.92180044171544	42.5471260806935	121386
b87ddd21f5a39f6cdd689bccb343528d6c17cb10	analysis of high performance applications using workload requirements		This short paper proposes two novel methodologies for analyzing scientific applications in distributed environments, using workload requirements. The first explores the impact of features such as problem size and programming language, over different computational architectures. The second explores the impact of mapping virtual cluster resources on the performance of parallel applications.	requirement	Mariza Ferro;Giacomo V. McEvoy;Bruno Schulze	2016		10.1007/978-3-319-61982-8_2	virtualization;performance prediction;workload;theoretical computer science;computer science	HPC	-8.595788029942655	44.876218617832556	121478
4a19cabfd93652904dfb7f04c7348cf15bfaafd7	support of automatic parallelization with concept comprehension	developpement logiciel;distributed system;compilacion;systeme reparti;tool support;search space;heuristic method;parallelizing compilers;retroingenierie;semantics;program transformation;metodo heuristico;paralelisacion;ingenieria logiciel;transformation programme;semantica;semantique;software engineering;parallel computation;analisis programa;transformacion programa;concept comprehension;calculo paralelo;sistema repartido;desarrollo logicial;high performance fortran;parallelisation;software development;parallelization;genie logiciel;compilation;fortran;program analysis;code restructuring;methode heuristique;analyse programme;calcul parallele;ingeniera inversa;parallel processing;automatic parallelization;semantic analysis;structure analysis;reverse engineering	Current approaches to parallelizing compilation perform a purely structural analysis of the sequential code. Conversely, a semantic analysis performing concept assignment for code sections, can support the recognition of the algorithms that the code implements. This can considerably help the parallelization process, by allowing the introduction of heuristics and an extensive pruning of the search space, and thus enabling the application of more aggressive code transformations. It can play an important role in overcoming the current limitations to Automatic Parallelization. In this paper we discuss the applicability of concept comprehension to the parallelization process, and we present a novel technique for automatic algorithmic recognition we have designed and implemented. We are currently developing a reverse engineering tool supporting the translation of sequential Fortran code into HPF, which is based on the recognition technique we have developed. Its working criteria are illustrated and discussed. Ó 1999 Elsevier Science B.V. All rights reserved.	algorithm;automatic parallelization;compiler;computation;heuristic (computer science);high performance fortran;imperative programming;mathematical optimization;parsing;program optimization;reverse engineering;structural analysis	Beniamino Di Martino;Hans P. Zima	1999	Journal of Systems Architecture	10.1016/S1383-7621(98)00016-2	program analysis;parallel processing;parallel computing;computer science;theoretical computer science;software development;operating system;semantics;structural analysis;programming language;algorithm;reverse engineering;automatic parallelization	PL	-16.700271516469872	33.87766125390435	121555
ddcb9af2edeb167568b1d2be9ee30d375b44b545	software engineering in parallel and distributed scientific computing: a case study from industrial practice	distributed scientific computing;distributed memory;portable distributed memory parallel version;unstructured hybrid grids;distributed memory systems;mechanical engineering computing;transparent checkpointing;application software;interactive users;resource manager;algebraic multigrid solver;interdisciplinary research project;resource management;par cfx tjc;parallel programming;object oriented programming;computer industry;software engineering;industrial practice;computer scientists;parallel cfd codes;computational fluid dynamics;mechanical engineering;pvm applications;fortran 77;simulation software;computational modeling;small and medium enterprises;object oriented;small and medium enterprise;network of workstation;object oriented software engineering;scientific computing;batch mode;computational fluid dynamics simulation software package;algebraic multigrid;fluid dynamics;parallel hardware platforms;fortran;scalability;networks of workstations;flow simulation;c;finite volume;finite volume discretization;process migration;high efficiency;run time efficiency;object oriented modeling;cfx tfc;digital simulation;software packages;object oriented paradigm;software engineering methods;hardware;mechanical engineers	We report on results from an interdisciplinary research project of computer scientists, mechanical engineers and numerical analysts from industry and academia. We have designed and implemented a portable distributed memory parallel version of CFX-TfC, a state of the art computational fluid dynamics simulation software package that features finite volume discretization on unstructured hybrid grids in combination with an algebraic multigrid solver. Performance results on a number of parallel hardware platforms indicate high efficiency and scalability. Systematic application of software engineering methods has been a key contribution to success and helped to avoid bottlenecks found in many other parallel CFD codes. A key module of TfC, the algebraic multigrid solver (AMG), has been re-designed according to the object oriented paradigm. The object oriented (OO) AMG solver has been implemented in C++. OO technology has increased the solver’s maintainability and readability. Run-time efficiency is acceptable (compared to the Fortran 77 version); it could still be improved by applying further optimizations. Since networks of workstations (NOWs) are of particular interest for small and medium enterprises (SMEs), we have implemented a resource manager that allows PVM applications such as Par-CFX-TfC to be executed in batch mode without interfering with interactive users. The resource manager features transparent checkpointing and process	application checkpointing;batch processing;bottleneck (software);c++;code;computational fluid dynamics;computational science;computer scientist;discretization;distributed memory;finite volume method;fortran;linear algebra;multigrid method;numerical analysis;parallel virtual machine;parallel computing;programming paradigm;scalability;simulation software;software engineering;solver;workstation	Peter Luksch;Ursula Maier;Sabine Rathmayer;Matthias Weidmann;Friedemann Unger;Peter Bastian;Volker Reichenberger;Andreas Haas	1998		10.1109/PDSE.1998.668179	computational science;computing;parallel computing;computer science;social software engineering;theoretical computer science;component-based software engineering;distributed design patterns	HPC	-8.683726817402034	37.2802355427661	121764
0b2b98c4d35a8982d2acd13f125a4d4bd351958c	comppknots: a framework for parallel prediction and comparison of rna secondary structures with pseudoknots	minimisation;parallelisme;minimization;base donnee;haute performance;structure secondaire;rna secondary structure;distributed computing;database;base dato;minimizacion;relacion maestro esclavo;relation maitre esclave;parallelism;paralelismo;rna;estructura secundaria;secondary structure;performance analysis;prediction accuracy;alto rendimiento;calculo repartido;energy minimization;rna secondary structure prediction;master slave relationship;high performance;calcul reparti	Codes for RNA structure prediction based on energy minimization are usually very time and resource intensive. For this reason several codes have been significantly simplified: in some cases they are unable to predict complex secondary structures such as pseudoknots, while at other times they are able to predict structures with reduced lengths, or they are only able to predict some elementary and simple pseudoknots. Each of the existing codes has its strengths and weaknesses. Providing scientists with tools that are able to combine the strengths of the several codes is a worthwhile objective. To address this need, we present compPknots, a parallel framework that uses a combination of existing codes such as Pknots-RE and Pknots-RG, to predict RNA secondary structures concurrently and automatically compare them with reference structures from databases or literature. In this paper compPknots is used to compare and contrast the prediction accuracies of 217 RNA secondary structures from the PseudoBase database using Pknots-RE and PknotsRG separately, or both together. Its parallel master-slave architecture allowed us to prove that combinations of prediction codes can provide scientists with higher prediction accuracies in a very short time.	code;database;energy minimization;mpich;programming paradigm;prototype;residential gateway;run time (program lifecycle phase);software framework	Trilce Estrada;Abel Licon;Michela Taufer	2006		10.1007/11942634_70	minimisation;rna;simulation;computer science;artificial intelligence;nucleic acid secondary structure;energy minimization;algorithm;protein secondary structure	NLP	-16.818432372087003	42.31534751001952	121789
89d344fc689d6f87a643eb25dd26c5eb6ec920e2	partecl: parallel testing using opencl		With the growing complexity of software, the number of test cases needed for effective validation is extremely large. Executing these large test suites is expensive and time consuming, putting an enormous pressure on the software development cycle. In previous work, we proposed using Graphics Processing Units (GPUs) to accelerate test execution by running test cases in parallel on the GPU threads. However, the complexity of GPU programming poses challenges to the usability and effectiveness of the proposed approach.  In this paper we present ParTeCL - a compiler-assisted framework to automatically generate GPU code from sequential programs and execute their tests in parallel on the GPU. We show feasibilitiy and performance achieved when executing test suites for 9 programs from an industry standard benchmark suite on the GPU. ParTeCL achieves an average speedup of 16Ã when compared to a single CPU for these benchmarks.		Vanya Yaneva;Ajitha Rajan;Christophe Dubach	2017		10.1145/3092703.3098227	parallel computing;computer science;software development process;test case;software;speedup;thread (computing);general-purpose computing on graphics processing units;embedded software;suite	SE	-5.684926519850371	43.32547170464237	121798
1e9d150c11d48ef0c5e161e59e1aff5b09cec1d8	large matrix-vector product computations on multicast bus-oriented workstation clusters	workstation cluster		multicast;workstation	Debasish Ghose;Hyoung Joong Kim	2002			parallel computing;computer science;operating system;distributed computing	HPC	-9.618919081597147	42.378806049390775	121871
fb5a7b9babab2029caa10009ccc746b084a5ca59	an offline approach for whole-program paths analysis using suffix arrays	sufijo;program behavior;algorithme rapide;lenguaje programacion;metodo adaptativo;dimensionnement;evaluation performance;economies d energie;optimisation;haute performance;compilateur;algoritmo busqueda;ahorros energia;performance evaluation;optimizacion;programming language;optimization technique;algorithme recherche;suffix;evaluacion prestacion;search algorithm;distributed computing;dimensioning;cache memory;comportamiento programa;methode adaptative;program verification;compiler;analisis programa;suffix array;antememoria;antememoire;analisis desplazamiento;verificacion programa;path analysis;fast algorithm;adaptive method;alto rendimiento;langage programmation;calculo repartido;energy savings;comportement programme;optimization;program analysis;suffixe;analyse programme;analyse piste causale;verification programme;dimensionamiento;high performance;calcul reparti;algoritmo rapido;compilador;energy saving	Software optimization techniques are highly reliant on program behavior to deliver high performance. A key element with these techniques is to identify program paths that are likely to achieve the greatest performance benefits at runtime. Several approaches have been proposed to address this problem. However, many of them fail to cover larger optimization scope as they are restricted to loops or procedures. This paper introduces a novel approach for representing and analyzing complete program paths. Unlike the whole-program paths (WPPs) approach that relies on a DAG to represent program paths, our program trace is processed into a suffix-array that can enable very fast searching algorithms that run with time O(ln(N)), N being the length of the trace. This allows to process reasonable trace sizes offline, avoiding the high runtime overhead incurred by WPPs, while accurately characterizing hot paths. Our evaluation shows impressive performance results, with almost 48% of the code being covered by hot paths. We also demonstrate the effectiveness of our approach to optimize for power. For this purpose, an adaptive cache resizing scheme is used that shows energy savings in the order of 12%.	directed acyclic graph;mathematical optimization;online and offline;optimizing compiler;overhead (computing);program optimization;programmer;run time (program lifecycle phase);search algorithm;suffix array;text editor;tracing (software)	Gilles Pokam;François Bodin	2004		10.1007/11532378_26	program analysis;path analysis;compiler;real-time computing;simulation;cpu cache;computer science;programming language;dimensioning;algorithm;search algorithm	Arch	-18.761762309264252	36.35899312529465	121959
1c856b68cba9a23663867bf822699c838ec10b25	distributing evolutionary computation in a networked multi-agent environment	multi agent system;personal computer;distributed computing;parallel models;evolutionary robotics;parallel computer;evolutionary algorithm;mobile agent;gene regulatory network;autonomic computing;evolutionary computing	It has become increasingly popular to employ evolutionary algorithms to solve problems in different domains, and parallel models have been widely used for performance enhancement. Instead of using parallel computing facilities or public computing systems to speed up the computation, we propose to implement parallel evolutionary computation models on networked personal computers (PCs) that are locally available and manageable. To realize the parallelism, a multi-agent system is presented in which mobile agents play the major roles to carry the code and move from machine to machine to complete the computation dynamically. To evaluate the proposed approach, we use our multi-agent system to solve two types of time-consuming applications. Different kinds of experiments were conducted to assess the developed system, and the preliminary results show its promise and efficiency. © 2010 Elsevier Ltd. All rights reserved.	agent-based model;autonomy;computer architecture;distributed computing;evolutionary algorithm;evolutionary computation;experiment;fault tolerance;intelligent agent;interactivity;internet;machine to machine;mobile agent;multi-agent system;parallel computing;personal computer;reactive programming;speedup	Wei-Po Lee;Hong-Yi Ke	2011	Mathematical and Computer Modelling	10.1016/j.mcm.2010.11.084	evolutionary programming;natural computing;gene regulatory network;real-time computing;interactive evolutionary computation;human-based evolutionary computation;computer science;theoretical computer science;evolutionary algorithm;mobile agent;distributed computing;evolutionary robotics;autonomic computing	AI	-10.977384747962743	38.719965972433336	122006
752a33ec7b250ed8439172ffe0ac77c05aaa06be	conceptual modeling of multicore high performance computing systems	conceptual model		multi-core processor	Abu Asaduzzaman	2009			computer architecture;conceptual model;computer engineering;multi-core processor;supercomputer;computer science	HPC	-8.96602249559239	43.48057179190185	122269
417cd2b1318150003fa60d232c6b6307f97dcf04	volunteer computing simulation using repast and mason	volunteer computing;agent based simulation;mason;repast	Volunteer environments usually consist of a large number of computing nodes, with highly dynamic characteristics, therefore reliable models for a planning of the whole computing are highly desired. An easy to implement approach to modelling and simulation of such environments may employ agent-based universal simulation frameworks, such as RePast or MASON. In the course of the paper the above-mentioned simulation frameworks are adapted to support simulation of volunteer computing. After giving implementation details, selected results concerning computing time and speedup are given and are compared with the ones obtained from an actual volunteer environment.	agent-based model;complex network;experiment;java;load balancing (computing);mason;maxima and minima;repast (modeling toolkit);security testing;simulation;speedup;test case;virtual reality;volunteer computing	Aleksander Byrski;Michal Felus;Jakub Gawlik;Rafal Jasica;Pawel Kobak;Grzegorz Jankowski;Edward Nawarecki;Michal Wroczynski;Przemyslaw Majewski;Tomasz Krupa;Jacek Strychalski	2013	Computer Science (AGH)	10.7494/csci.2013.14.1.153	simulation;human–computer interaction;computer science;distributed computing	HPC	-10.78477011032945	38.686305425844346	122290
785c2ffd2cdb429e56158bd7f0a3df276972ec5b	bit-tree, a data structure for fast file processing	information retrieval;sistema informatico;gestion fichier;index;computer system;file management;distinction bit;bit tree;branch;arbol binario;recherche information;arbre bit;indexation;estructura datos;manejo archivos;arbre binaire;root;structure donnee;systeme informatique;b tree;recuperacion informacion;information system;isam;trie;data structure;leaf;random access;mode;systeme information;sistema informacion;binary tree		data structure	David E. Ferguson	1992	Commun. ACM	10.1145/129888.129896	b-tree;isam;torrent file;data structure;indexed file;device file;computer file;binary tree;leaf;computer science;trie;operating system;root;branch;database;data file;programming language;file system fragmentation;mode;design rule for camera file system;information system;algorithm;random access;file control block	OS	-17.792139071899598	45.16520615438749	122421
1d07258fefa33009cb3c83fe9f70796b5d9a1825	automatic tuning of a parallel pattern library for heterogeneous systems with intel xeon phi	databases;libraries;kernel;intel xeon phi coprocessors automatic tuning parallel pattern library heterogeneous systems high productivity application development user provided code execution automatic software tuning automatic online parameter tuning hyphi hybrid pattern library;runtime;intel xeon phi automatic software tuning parallel pattern libraries;software engineering;coprocessors;computer architecture;parallel pattern libraries;tuning;tuning libraries coprocessors runtime kernel databases computer architecture;software libraries coprocessors parallel programming;automatic software tuning;intel xeon phi	Pattern libraries are important tools for high productivity application development. Their struggle for best performance is complicated by the fact that they are used to execute user-provided code, which is not known during their creation. This makes pattern libraries good candidate for automatic software tuning. In this paper, we deal with automatic online parameter tuning of the HyPHI hybrid pattern library for heterogeneous systems equipped with the Intel Xeon Phi coprocessors. We propose a framework that can be used to combine a pattern library with an existing tuning library in a practical and efficient way. Our experiments show that tuning can noticeably improve the performance of the library and it introduces very little overhead.	best practice;coprocessor;experiment;interference (communication);library (computing);loss function;mathematical optimization;overhead (computing);owner-free file system;performance tuning;peripheral;principle of good enough;server (computing);xeon phi	Jirí Dokulil;Siegfried Benkner	2014	2014 IEEE International Symposium on Parallel and Distributed Processing with Applications	10.1109/ISPA.2014.15	computer architecture;parallel computing;kernel;computer science;operating system;xeon phi;coprocessor	HPC	-6.441486970573419	45.37817854899037	122498
2975096baee45f14149fda05ff3b9021f5ab3f4d	high-resolution mesh convergence properties and parallel efficiency of a spectral element atmospheric dynamical core	mesh convergence;distributed memory;atmospheric circulation;high resolution;domain decomposition;dynamical core;parallel scalability;atmospheric modeling;spectral elements	We first demonstrate the parallel performance of the dynamical core of a spectral element atmospheric model. The model uses continuous Galerkin spectral elements to discretize the surface of the Earth, coupled with finite differences in the radial direction. Results are presented from two distributed memory, mesh interconnect supercomputers (ASCI Red and BlueGene/L), using a two-dimensional space filling curve domain decomposition. Better than 80% parallel efficiency is obtained for fixed grids on up to 8938 processors. These ∗Scientific Computing Division, National Center for Atmospheric Research, Boulder Colorado †Department of Meteorology, College of Computer, Mathematical, Physical Sciences, University of Maryland at College Park ‡Computation, Computers, Information and Mathematics, Sandia National Laboratories, Albuquerque NM §Corresponding author. email: mataylo@sandia.gov	atmospheric model;blue gene;central processing unit;discretization;distributed memory;domain decomposition methods;dynamical system;email;finite difference;galerkin method;lithosphere;mesh networking;radial (radio);space-filling curve;speedup;supercomputer	John M. Dennis;Aimé Fournier;William F. Spotz;Amik St.-Cyr;Mark A. Taylor;Stephen J. Thomas;Henry M. Tufo	2005	IJHPCA	10.1177/1094342005056108	atmospheric model;parallel computing;simulation;atmospheric circulation;distributed memory;image resolution;computer science;theoretical computer science;domain decomposition methods	HPC	-7.274019965407509	38.56759811158421	122677
862307bba81d904a806b8c30d2385ef336582947	backtracking and re-execution in the automatic debugging of parallelized programs	debugging;manuals;concurrent computing;distributed memory programs relative debugging serial program parallel program backtracking program debugging;program verification computers;prototypes;distributed computing;parallel programming;relative debugging;distributed memory programs;backups;serial program;debugging concurrent computing nasa prototypes computer bugs manuals distributed computing parallel processing information analysis performance analysis;performance analysis;backtracking;parallel computer;program debugging;static analysis;checkout;parallel programs;computer bugs;nasa;information analysis;parallel program;parallel processing;backtracking program debugging parallel programming;computation	ht this work we describe a new app-oach using relative debugging to find differences in compmation between a serial program and a parallel version of tl at program. We use a combination of re-execution and backtracking in order to find the first difference in computation that may ultimately lead to an incorrect value that the um r has indicated. In our protoO'pe implementation We use ._,alic analysis information from a parallelization tool in _,rder to perform the backtracking as well as the mapping r,'quired between serial and parallel computations.	backtracking;computation;debugging;finite difference;parallel computing;unified model	Gregory Matthews;Robert Hood;Stephen Johnson;P. F. Leggett	2002		10.1109/HPDC.2002.1029913	parallel processing;computer architecture;parallel computing;software bug;concurrent computing;computer science;computation;distributed computing;prototype;data analysis;programming language;debugging;static analysis;backtracking	PL	-16.30211685446462	37.530661652109515	122793
54a95029f0dc3d93255c4607383c27acb8403c84	optimizing locationing of multiple masters for master-worker grid applications	graphe non oriente;modelizacion;distributed system;algoritmo paralelo;optimisation;haute performance;systeme reparti;non directed graph;parallel algorithm;optimizacion;heterogeneous computing;grid applications;resource allocation;localization;distributed computing;optimal location;localizacion;algorithme parallele;grid;modelisation;large scale;sistema repartido;localisation;grafo no orientado;rejilla;alto rendimiento;grille;calculo repartido;optimization;profitability;asignacion recurso;allocation ressource;modeling;high performance;calcul reparti	The problem of allocating a large number of independent tasks to a heterogeneous computing platform is considered. A non oriented graph is used to model a Grid, where resources can have different speeds of computation and communication. We claim that the use of multiple masters is necessary to achieve good performance on large-scale platforms. The problem considered is to find the most profitable master locations in order to optimize the platform throughput.	optimizing compiler	Cyril Banino-Rokkones	2004		10.1007/11558958_126	parallel computing;real-time computing;simulation;systems modeling;internationalization and localization;resource allocation;computer science;distributed computing;parallel algorithm;grid;symmetric multiprocessor system;profitability index	HPC	-17.796208433337448	43.72738520253904	122837
05a8efd96d60ad83b4505ac8dd4328cadcf72645	collectionswitch: a framework for efficient and dynamic collection selection		Selecting collection data structures for a given application is a crucial aspect of the software development. Inefficient usage of collections has been credited as a major cause of performance bloat in applications written in Java, C++ and C#. Furthermore, a single implementation might not be optimal throughout the entire program execution. This demands an adaptive solution that adjusts at runtime the collection implementations to varying workloads.   We present CollectionSwitch, an application-level framework for efficient collection adaptation. It selects at runtime collection implementations in order to optimize the execution and memory performance of an application. Unlike previous works, we use workload data on the level of collection allocation sites to guide the optimization process. Our framework identifies allocation sites which instantiate suboptimal collection variants, and selects optimized variants for future instantiations. As a further contribution we propose adaptive collection implementations which switch their underlying data structures according to the size of the collection.   We implement this framework in Java, and demonstrate the improvements in terms of time and memory behavior across a range of benchmarks. To our knowledge, it is the first approach which is capable of runtime performance optimization of Java collections with very low overhead.	benchmark (computing);c++;data structure;java collections framework;mathematical optimization;overhead (computing);run time (program lifecycle phase);software bloat;software development	Diego Costa;Artur Andrzejak	2018		10.1145/3168825	workload;real-time computing;implementation;software development;computer science;data structure;java collections framework;java	PL	-18.198290628877743	36.93912508913921	122852
f0e35b10e392a3f0ea37b5505e1d14ccdb2cbe40	a fast, memory-efficient register allocation framework for embedded systems	register allocation;code generation;performance comparison;dynamic compilation;graph coloring;linear complexity;embedded system;compilers;embedded systems;just in time compiler;compiler optimization;code size;just in time;compiler optimizations;embedded device;interval analysis	"""In this work, we describe a """"just-in-time,"""" <i>usage density-based register allocator</i> geared toward embedded systems with a limited general-purpose register set wherein speed, code size, and memory requirements are of equal concern. The main attraction of the allocator is that it does not make use of the traditional live range and interval analysis nor does it perform advanced optimizations based on range <i>splitting</i> but results in very good code quality. We circumvent the need for traditional analysis by using a measure of <i>usage density</i> of a variable. The usage density of a variable at a program point represents both the frequency and the density of the uses. We contend that by using this measure we can capture both <i>range</i> and <i>frequency</i> information which is essentially used by the good allocators based on <i>splitting</i>. We describe a framework based on this measure which has a linear complexity in terms of the program size. We perform comparisons with the static allocators based on graph coloring and the ones targeted toward just-in-time compilation systems like linear scan of live ranges. Through comparisons with graph coloring (Brigg's style) and live range-based (linear scan) allocators, we show that the memory footprint and the size of our allocator are smaller by 20% to 30%. The speed of allocation is comparable and the speed of the generated code is better and its size smaller. These attributes make the allocator an attractive candidate for performing a fast, memory-efficient register allocation for embedded devices with a small number of registers."""	active window;algorithm;allocator (c++);chow–liu tree;compiler;computation;embedded system;general-purpose markup language;graph coloring;interval arithmetic;just-in-time compilation;lazy evaluation;mathematical optimization;memory footprint;memory management;processor register;register allocation;requirement;software quality	Sathyanarayanan Thammanur;Santosh Pande	2004	ACM Trans. Program. Lang. Syst.	10.1145/1034774.1034776	parallel computing;real-time computing;computer science;theoretical computer science;optimizing compiler;programming language	PL	-18.257273157197908	36.629814362235535	122854
d4ed19cc87694f3314a7bc1f36129e306e9c77e1	probing biomolecular machines with graphics processors	graphics processors;analysis technique;gpu processor;biomedical scientist;advanced simulation;programming tool;biomolecular machines	The evolution of GPU processors and programming tools is making advanced simulation and analysis techniques accessible to a growing community of biomedical scientists.	central processing unit;graphics processing unit;programming tool;simulation	James C. Phillips;John E. Stone	2009	ACM Queue	10.1145/1626135.1629155	computational science;parallel computing;computer science;operating system;biomolecule;computer graphics (images)	HPC	-8.339615617355465	38.24409464633018	123048
097c4d062e0e1e3832f95b426fe1d1c0efc386e4	multi-way streams in scheme	lenguaje programacion;gestion memoire;imperative stream;programming language;implementation;storage management;tratamiento lenguaje;reseau;red;ejecucion;gestion memoria;interpreteur;language processing;traitement langage;langage programmation;interpreter;interprete;scheme;network	We present a mechanism for the maintenance of streams based on the Scheme facility of call-with-current-continuation or call/cc. The mechanism supports stream sharing and has overhead cost which is independent of top-level program parameters if call/cc is implemented in heap-based systems. It is shown how the control structure of call/cc can save programming eeort in cases where multiple procedures output to the same stream in irregular order.	call-with-current-continuation;continuation;control flow;overhead (computing)	John V. Franco;Daniel P. Friedman;Steven D. Johnson	1990	Comput. Lang.	10.1016/0096-0551(90)90014-G	parallel computing;scheme;interpreter;computer science;artificial intelligence;programming language;implementation;algorithm	AI	-16.821674747414292	41.17819400095753	123122
50a37bd3349cccd48684ec974f74cad37460b023	seekable compressed traces	compression algorithm;program diagnostics;data compression;program tracing;harmonic mean compression rate;data stream;harmonic mean;spec2000 memory address trace program tracing processor simulation program slicing seekable compressed trace value prediction harmonic mean compression rate;processor simulation;spec2000 memory address trace;program diagnostics data compression;compression algorithms sampling methods instruments computer science computational modeling computer simulation random access memory system testing optimizing compilers scheduling;seekable compressed trace;program slicing;value prediction	Program traces are commonly used for purposes such as profiling, processor simulation, and program slicing. Uncompressed, these traces are often too large to exist on disk. Although existing trace compression algorithms achieve high compression rates, they sacrifice the accessibility of uncompressed traces; typical compressed traces must be traversed linearly to reach a desired position in the stream. This paper describes seekable compressed traces that allow arbitrary positioning in the compressed data stream. Furthermore, we enhance existing value prediction based techniques to achieve higher compression rates, particularly for difficult-to-compress traces. Our base algorithm achieves a harmonic mean compression rate for SPEC2000 memory address traces that is 3.47 times better than existing methods. We introduce the concept of seekpoints that enable fast seeking to positions evenly distributed throughout a compressed trace. Adding seekpoints enables rapid sampling and backwards traversal of compressed traces. At a granularity of every 10 M instructions, seekpoints only increase trace sizes by an average factor of 2.65.	accessibility;algorithm;c file input/output;data compression;digital footprint;memory address;profiling (computer programming);program slicing;sampling (signal processing);simulation;tracing (software);tree traversal	Tipp Moseley;Dirk Grunwald;Ramesh Peri	2007	2007 IEEE 10th International Symposium on Workload Characterization	10.1109/IISWC.2007.4362189	data compression;data compression ratio;parallel computing;real-time computing;computer science;theoretical computer science;operating system;statistics	Arch	-18.118994936588	37.57939984619957	123223
6da3962b1948f06718d42cb825535514ebe214d7	computation of heat transfer with methods of high performance scientific computing	numerical solution;numerical technique;multigrid method;navier stokes;three dimensional;heat transfer;heat exchanger;scientific computing;parallel computer;conjugate heat transfer;finite volume;high performance	Scientific computing enhances our understanding of such diverse topics as the cosmos, genomics, the atmosphere and oceans, biodiversity, aerodynamics, forest fires, and the weather. The increased use of computational methods in the sciences presents us with three challenges: the need for powerful hardware, efficient software, and the expertise in numerical methods. The Interdisciplinary Center for Scientific Computing will meet these challenges by creating an interdisciplinary environment for scientists and computational mathematicians to collaborate on scientific problems requiring computational tools, and providing high quality computational resources and software.	computation;computational resource;computational science;computer hardware;display resolution;numerical method	M. Hortmann;M. Pophal;Michael Schaefer;Klaus Wechsler	1995		10.1007/BFb0046643	three-dimensional space;mathematical optimization;heat exchanger;computer science;finite volume method;heat transfer;multigrid method	HPC	-7.2937072147330095	36.741977323410254	123237
85109ec6d5f603ff5cb5b51199ea259bbf77c0d6	programming framework for clusters with heterogeneous accelerators	distributed application;application development;tesla;reconfigurable systems;paper;finance;heterogeneous systems;dynamic system;hardware accelerator;fpga;physics;performance improvement;programming techniques;multitasking;runtime support;computer science;high performance;data transfer;physical simulation	We describe a programming framework for high performance clusters with various hardware accelerators. In this framework, users can utilize the available heterogeneous resources productively and efficiently. The distributed application is highly modularized to support dynamic system configuration with changing types and number of the accelerators. Multiple layers of communication interface are introduced to reduce the overhead in both control messages and data transfers. Parallelism can be achieved by controlling the accelerators in various schemes through scheduling extension. The framework has been used to support physics simulation and financial application development. We achieve significant performance improvement on a 16-node cluster with FPGA and GPU accelerators.	computer cluster;distributed computing;dynamical simulation;dynamical system;field-programmable gate array;graphics processing unit;hardware acceleration;heterogeneous computing;load balancing (computing);mathematical optimization;overhead (computing);scheduling (computing);supercomputer;system configuration	Kuen Hung Tsoi;Anson H. T. Tse;Peter R. Pietzuch;Wayne Luk	2010	SIGARCH Computer Architecture News	10.1145/1926367.1926377	embedded system;computer architecture;parallel computing;real-time computing;hardware acceleration;human multitasking;computer science;operating system;dynamical system;rapid application development;field-programmable gate array	HPC	-7.312561960544786	43.75904781039737	123535
6754c6fbd0892350de2879bc0db51266a69b9b00	fpga based acceleration of computational fluid flow simulation on unstructured mesh geometry	high performance microprocessor fpga based acceleration computational fluid flow simulation unstructured mesh geometry numerical simulation dynamical systems field programmable gate array complex physical spatio temporal phenomena simulation unstructured spatial discretization irregular memory access patterns data locality mesh node renumbering technique sequential memory access pattern cell centered state window floating point data path generation arithmetic unit control structure euler equations unstructured mesh finite volume technique;finite volume methods;geometry;computational fluid dynamics;microprocessors field programmable gate arrays face bandwidth equations memory management;field programmable gate arrays;mesh generation;mesh generation computational fluid dynamics field programmable gate arrays finite volume methods geometry	Numerical simulation of complex computational fluid dynamics problems evolving in time plays an important role in scientific and engineering applications. Accurate behavior of dynamical systems can be understood using large scale simulations which traditionally requires expensive super-computing facilities. In the paper a Field Programmable Gate Array (FPGA) based framework is described to accelerate simulation of complex physical spatio-temporal phenomena. Simulating complicated geometries requires unstructured spatial discretization which results in irregular memory access patterns severely limiting computing performance. Data locality is improved by mesh node renumbering technique which results in a sequential memory access pattern. Additionally storing a small window of cell-centered state values in the on-chip memory of the FPGA can increase data reuse and decrease memory bandwidth requirements. Generation of the floating-point data path and control structure of the arithmetic unit containing dozens of operators is a very challenging task when the goal is high operating frequency. Efficiency and use of the framework is described by a case study solving the Euler equations on an unstructured mesh using finite volume technique. On the currently available largest FPGA the generated architecture contains three processing elements working in parallel providing 75 times speedup compared to a high performance microprocessor.	adjacency matrix;algorithm;arithmetic logic unit;central processing unit;clock rate;computation;computational fluid dynamics;control flow;discretization;dynamical system;euler;field-programmable gate array;finite volume method;locality of reference;memory access pattern;memory bandwidth;mesh networking;microprocessor;numerical linear algebra;requirement;simulation;speedup;supercomputer;unstructured grid;vhdl	Zoltán Nagy;Csaba Nemes;Antal Hiba;András Kiss;Árpád Csík;Péter Szolgay	2012	22nd International Conference on Field Programmable Logic and Applications (FPL)	10.1109/FPL.2012.6339276	embedded system;mesh generation;parallel computing;computer hardware;computational fluid dynamics;computer science;theoretical computer science;field-programmable gate array	HPC	-5.475424400225653	38.50274963186308	123559
734a77645932f626ab879a7789c3c9bac7507c15	functional realization of coordination environments for mixed parallelism	libraries;formal specification parallel machines parallel programming message passing programming environments;data parallel;parallel processing programming profession concurrent computing parallel machines programming environments libraries program processors computer applications distributed computing scientific computing;programming environments;formal specification;concurrent computing;programming environment;data parallelism;distributed computing;parallel programming;computer applications;computation intensive applications;programming profession;scientific computing;message passing;parallel machines;mpi;functional coordination specification;task parallelism;distributed address space;program processors;program development;parallel processing;task parallelism data parallelism computation intensive applications parallel machines distributed address space programming environment program development mpi functional coordination specification	Summary form only given. The simultaneous exploitation of task and data parallelism is often beneficial for the execution of computation-intensive applications on large parallel machines with a distributed address space, since the concurrent execution of independent program parts may significantly reduce the communication overhead. This article outlines the realization of a programming environment to support the development of programs with mixed task and data parallelism, emphasising the use of transformations for generating efficient target programs using MPI. We explore the characteristics of several approaches for such an environment, and discuss their strengths and weaknesses. We discuss an approach based on a functional coordination specification, and show how the final imperative target program can be generated by several transformation steps.	address space;compiler;computation;data parallelism;data structure;executable;functional programming;haskell;imperative programming;integrated development environment;library (computing);message passing interface;object code;overhead (computing);parallel computing;program transformation;programmer	John O'Donnell;Thomas Rauber;Gudula Rünger	2004	18th International Parallel and Distributed Processing Symposium, 2004. Proceedings.	10.1109/IPDPS.2004.1303183	parallel processing;computer architecture;parallel computing;message passing;concurrent computing;computer science;message passing interface;operating system;formal specification;distributed computing;data parallelism;computer applications;programming language;instruction-level parallelism;implicit parallelism;task parallelism	HPC	-13.025350983446884	38.73639154270675	123713
15162dc5403eefc04e203fa0324d1fc16e625851	a prolog implementation of an instruction-level processor simulator	eficacia sistema;architecture systeme;simulator performance;executable specification;concepcion sistema;prolog;performance systeme;system performance;simulator;prototipo;simulador;langage description materiel;system design;simulateur;rapid protoyping;arquitectura sistema;procesador;hardware description language;processeur;system architecture;prototype;instruction level simulator;conception systeme;processor	Abstract#R##N##R##N#This paper describes the implementation of a Prolog-based, instruction-level simulator used in the design of a new processor. The adaptability of Prolog as a hardware description language is reported. Prolog was a good choice for purposes of rapid prototyping and as a means to derive high-level executable specifications for the instruction set. The rapid software development strategy entailed a price to be paid in the form of a relatively slow performance. Methods to improve the speed of Prolog-based simulators are suggested.	computer architecture simulator;prolog	Ariel Pashtan	1987	Softw., Pract. Exper.	10.1002/spe.4380170502	embedded system;computer architecture;simulation;computer science;operating system;prototype;computer performance;hardware description language;programming language;prolog;systems architecture;systems design	EDA	-16.77410101349945	39.64574511631771	123756
28fd41450e893b395af66cbdefdeeb40d12d9c8f	fast high-level simulation of shared-memory multiprocessor systems			multiprocessing;shared memory;simulation	Jiajen M. Lin;Santosh G. Abraham	1992	Int. Journal in Computer Simulation		symmetric multiprocessor system;parallel computing;distributed memory;distributed computing;advanced programmable interrupt controller;multiprocessing;concurrent data structure;computer science;shared memory	Arch	-10.187712752782513	43.078636810097414	123781
b6199cfbfc75726e7266805c9c097578b09233c7	the joins concurrency library	distributed application;modelizacion;lenguaje programacion;distributed system;optimisation;systeme reparti;optimizacion;programming language;langage declaratif;simultaneidad informatica;sistema reactivo;synchronisation;modelisation;concurrency;visual languages;sistema repartido;visual basic;synchronization;langage visuel;declarative languages;algorithme reparti;declarative language;reactive system;langage programmation;systeme reactif;multithread;coordinacion;algoritmo repartido;optimization;sincronizacion;multitâche;distributed algorithm;modeling;simultaneite informatique;lenguaje declarativo;multitarea;power modeling;coordination	Cω extended C 1.x with a simple, declarative and powerful model of concurrency join patterns applicable both to multithreaded applications and to the orchestration of asynchronous, event-based distributed applications. With Generics available in C 2.0, we can now provide join patterns as a library rather than a language feature. The Joins library extends its clients with an embedded, type-safe and mostly declarative language for expressing synchronization patterns. The library has some advantages over Cω: it is language neutral, supporting other languages like Visual Basic; its join patterns are more dynamic, allowing solutions difficult to express with Cω; its code is easy to modify, fostering experimentation. Although presenting fewer optimization opportunities, the implementation is efficient and its interface makes it trivial to translate Cω programs to C. We describe the interface and implementation of Joins which (ab)uses almost every feature of Generics.	ada;application programming interface;barrier (computer science);benchmark (computing);blocking (computing);combinator library;compiler;concurrency (computer science);context switch;continuation;continuation-passing style;declarative programming;delegate (cli);distributed computing;embedded system;error message;event loop;functional programming;generic programming;graphical user interface;haskell;indirection;infinite loop;iterator;jocaml;join-calculus;join-pattern;joins (concurrency library);linear search;mask (computing);mathematical optimization;non-blocking algorithm;nonlinear system;overhead (computing);pattern matching;powerpc 600;precomputation;scheduling (computing);software transactional memory;thread (computing);thread pool;type safety;visual basic	Claudio V. Russo	2007		10.1007/978-3-540-69611-7_17	synchronization;distributed algorithm;computer science;database;programming language;join-pattern;algorithm	PL	-17.429587256814937	40.638938417861084	123821
528fbc05f8b4cd52b23d7080ab4546f895649064	divide: distributed visual display of the execution of asynchronous, distributed algorithms on loosely-coupled parallel processors	algoritmo paralelo;eficacia sistema;interfase usuario;network display;affichage;architecture systeme;parallel algorithm;tarea concurrente;visualizacion;user interface;asynchrone;computer graphics;buffer graphs;sistema informatico;performance systeme;computer system;system performance;algorithme parallele;display;algorithme reparti;arquitectura sistema;interface utilisateur;algoritmo repartido;systeme informatique;procesador;tâche concurrente;processeur;system architecture;distributed algorithm;grafico computadora;concurrent task;infographie;processor;asincrono;asynchronous	The issue of monitoring the execution of asynchronous, distributed algorithms on loosely-coupled parallel processor systems, is important for the purposes of (i) detecting inconsistencies and flaws in the algorithm, (ii) obtaining important performance parameters for the algorithm, and (iii) developing a conceptual understanding of the algorithm's behavior, for given input stimulus, through visualization. For a particular class of asynchronous distributed algorithms [1,5] that may be characterized by independent and concurrent entities that execute asynchronously on multiple processors and interact with one another through explicit messages, the following reasoning applies. Information about the flow of messages and the activity of the processors may contribute significantly towards the conceptual understanding of the algorithm's behavior and the functional correctness of the implementation. The computation and subsequent display of important parameters, based upon the execution of the algorithm, is an important objective of DIVIDE. For instance, the mean and standard deviation values for the propagation delay of ATM cells between any two given Broadband-ISDN (BISDN) nodes in a simulation of BISDN network under stochastic input stimulus[36], as a function of time, are important clues to the degree of congestion in the Broadband-ISDN network. Although the execution of the algorithm typically generates high resolution data, often, a coarse-level visual representation of the data may be useful in facilitating the conceptual understanding of the behavior of the algorithm. DIVIDE permits a user to specify a resolution less than that of the data from the execution of the algorithm, which is then utilized to coalesce the data appropriately. Given that this process requires significant computational power, for efficiency, DIVIDE distributes the overall task of visual display into a number of user specified workstations that are configured as a loosely-coupled parallel processor. DIVIDE has been implemented on a heterogeneous network of SUN sparc 1+, sparc 2, and 3/60 workstations and performance measurements indicate significant improvement over that of a uniprocessor-based visual display.	atm turbo;central processing unit;computation;correctness (computer science);distributed algorithm;entity;integrated services digital network;loose coupling;network congestion;norm (social);null (sql);parallel computing;propagation delay;sparc;sensor;simulation;software propagation;uniprocessor system;workstation	Tom M. Morrow;Sumit Ghosh	1993		10.1016/0097-8493(94)90012-4	distributed algorithm;parallel computing;real-time computing;computer science;artificial intelligence;operating system;asynchronous communication;distributed computing;parallel algorithm;programming language;computer graphics;user interface;algorithm;computer graphics (images)	HPC	-18.716344684600244	41.640536600243095	123962
78321eb326a4f979315f430539e840ccf3337862	molecule: a language construct for layered development of parallel programs	tratamiento paralelo;developpement logiciel;lenguaje programacion;array processing;high level languages;sequential;traitement parallele;programming language;multiprocessor;multiprocessing;language construct;programacion paralela;application flexibility;computation mode;pal;sistema informatico;flot donnee;distributed computing;parallel programming;computer system;flujo datos;ingenieria logiciel;supercomputer;software engineering;molecule type;simultaneite;supercomputador;layered development;concurrency;dataflow;simultaneidad;efficient implementation;desarrollo logicial;concurrent computing parallel processing pipeline processing parallel programming distributed computing array signal processing application software human computer interaction multitasking concrete;software development;parallel computer;genie logiciel;langage programmation;ipsc;algorithms;parallel computers;systeme informatique;layered software development;pipelining;multiprocesador;data flow;parallel programs;user friendliness language construct layered development parallel programs algorithms parallel computers molecule type computation mode sequential pipelining array processing dataflow multiprocessing procedural language pal layered software development multicomputer ipsc high level languages application flexibility;high level language;multicomputer;user friendliness;parallel processing;superordinateur;procedural language;programmation parallele;multiprocesseur	A new language construct, called molecule, is described for the efficient implementation of algorithms on parallel computers. A molecule can be considered a procedure associated with a molecule type. Each molecule type characterizes a particular computation mode (sequential, pipelining, array processing, dataflow, multiprocessing, etc.). Basic concepts of molecule are introduced with a procedural language, called PAL. A concrete example is presented to illustrate layered software development using PAL on a multicomputer (the iPSC). It is concluded that high-level languages, augmented with the molecule construct, offer application flexibility, user friendliness, and efficiency in implementing parallel programs. >	language construct	Zhiwei Xu;Kai Hwang	1989	IEEE Trans. Software Eng.	10.1109/32.24708	parallel processing;computer architecture;supercomputer;parallel computing;multiprocessing;computer science;operating system;software engineering;programming language;high-level programming language	SE	-15.398187686257927	40.079285640017524	123969
55b74dadf44cec435536a70cb50b45e837f07b46	comparative evaluation of latency-tolerating and -reducing techniques for hardware-only and software-only directory protocols	circuit declenchement;focusing;software;latencia;programa paralelo;circuito desenganche;evaluation performance;architecture systeme;migrateur;shared memory;storage access;performance evaluation;focalizacion;execution time;logiciel;multiprocessor;focalisation;latence;migratory;memoria compartida;reduction;evaluacion prestacion;prefetching;cache memory;tiempo acceso;latency tolerance;software only directory protocols;software engineering;experimental result;antememoria;memory access;repertoire;software only directory protocol;antememoire;hardware only directory protocol;shared memory multiprocessors;tolerancia;memory consistency models;migratorio;relative efficiency;acces memoire;cache coherence;resultado experimental;acceso memoria;trigger;logicial;temps execution;temps acces;arquitectura sistema;directory;reduccion;repertorio;tolerance;latency;computer hardware;programvaruteknik;multiprocesador;tiempo ejecucion;resultat experimental;system architecture;migratory sharing;parallel programs;distributed shared memory;materiel informatique;parallel program;memory consistency model;material informatica;memoire partagee;access time;programme parallele;shared memory multiprocessor;multiprocesseur	We study in this paper how effective latency-tolerating and -reducing techniques are at cutting the memory access times for shared-memory multiprocessors with directory cache protocols managed by hardware and software. A critical issue for the relative efficiency is how many protocol operations such techniques trigger. This paper presents a framework that makes it possible to reason about the expected relative efficiency of a latencytolerating or -reducing technique by focusing on whether the technique increases, decreases, or does not change the number of protocol operations at the memory module. Since software-only directory protocols handle these operations in software they will perform relatively worse unless the technique reduces the number of protocol operations. Our experimental results from detailed architectural simulations driven by six applications from the SPLASH-2 parallel program suite confirm this expectation. We find that while prefetching performs relatively worse on software-only directory protocols due to useless prefetches, there are examples of protocol optimizations, e.g., optimizations for migratory data, that do relatively better on doi:10.1006 jpdc.1999.1606, available online at http: www.idealibrary.com on	cpu cache;directory (computing);directory service;hypertext transfer protocol;interrupt latency;mathematical optimization;memory module;online transaction processing;overhead (computing);prefetch input queue;release consistency;run time (program lifecycle phase);shared memory;simulation	Håkan Grahn;Per Stenström	2000	J. Parallel Distrib. Comput.	10.1006/jpdc.1999.1606	distributed shared memory;shared memory;cache coherence;latency;parallel computing;real-time computing;multiprocessing;cpu cache;reduction;access time;computer science;efficiency;operating system;distributed computing;programming language;systems architecture	Arch	-16.703553577263452	43.79473988928913	124116
c356860bc8d4dbe37d699f4db8332f291762abb3	a parallel software toolkit for statistical 3-d virus reconstructions from cryo electron microscopy images using computer clusters with multi-core shared-memory nodes	statistical approach;software tools image reconstruction electron microscopy concurrent computing biomedical computing viruses medical biomedical engineering signal to noise ratio three dimensional displays software reusability;computer clusters;concurrent computing;shared memory;cryo electron microscopy;storage complexity;statistical 3d virus reconstructions;parallel software toolkit;viruses medical;prior information;parallel programming;maximum likelihood estimation;storage complexity parallel software toolkit statistical 3d virus reconstructions cryo electron microscopy images computer clusters multicore shared memory nodes virus particles;medical computing;virus particles;shared memory systems;electron microscopy;biomedical engineering;electron microscope;three dimensional displays;image reconstruction;software reusability;cryo electron microscopy images;pc cluster;software tools;workstation clusters electron microscopy maximum likelihood estimation medical computing microorganisms parallel programming shared memory systems software tools;workstation clusters;signal to noise ratio;microorganisms;biomedical computing;multicore shared memory nodes;software implementation	A statistical approach for computing 3-D reconstructions of virus particles from cryo electron microscope images and minimal prior information has been developed which can solve a range of specific problems. The statistical approach causes high computation and storage complexity in the software implementation. A parallel software toolkit is described which allows the construction of software targeted at commodity PC clusters which is modular, reusable, and user-transparent while at the same time delivering nearly linear speedup on practical problems.	computation;computer cluster;electron;multi-core processor;shared memory;speedup	Yili Zheng;Peter C. Doerschuk	2008	2008 IEEE International Symposium on Parallel and Distributed Processing	10.1109/IPDPS.2008.4536242	parallel computing;concurrent computing;computer science;theoretical computer science;operating system;electron microscope;computer graphics (images)	Arch	-7.843281979718694	35.11718767990204	124339
04378da13e4aee305f957bff8dff0634d4dccae9	using automatic persistent memoization to facilitate data analysis scripting	programming language;information retrieval;scientific workflow;data mining;scientific workflows;data analysis;dependency management;machine learning	Programmers across a wide range of disciplines (e.g., bioinformatics, neuroscience, econometrics, finance, data mining, information retrieval, machine learning) write scripts to parse, transform, process, and extract insights from data. To speed up iteration times, they split their analyses into stages and write extra code to save the intermediate results of each stage to files so that those results do not have to be re-computed in every subsequent run. As they explore and refine hypotheses, their scripts often create and process lots of intermediate data files. They need to properly manage the myriad of dependencies between their code and data files, or else their analyses will produce incorrect results.  To enable programmers to iterate quickly without needing to manage intermediate data files, we added a set of dynamic analyses to the programming language interpreter so that it automatically memoizes (caches) the results of long-running pure function calls to disk, manages dependencies between code and on-disk data, and later re-uses memoized results, rather than re-executing those functions, when guaranteed safe to do so. We created an implementation for Python and show how it enables programmers to iterate faster on their data analysis scripts while writing less code and not having to manage dependencies between their code and datasets.	bioinformatics;coupling (computer programming);data mining;domain-specific language;information retrieval;iteration;machine learning;memoization;open-source software;parsing;programmer;programming language;pure function;python;usability	Philip J. Guo;Dawson R. Engler	2011		10.1145/2001420.2001455	computer science;software engineering;data mining;database;data analysis;programming language	SE	-19.022175841373382	33.68287702241586	124383
bbe5a5feb4d93657beb8e86d961b4608fdca1a1d	static prediction of recursion frequency using machine learning to enable hot spot optimizations	program diagnostics learning artificial intelligence optimisation;hot paths static prediction recursion frequency hot spot optimizations machine learning based approach real world application domains pure static analyses	Recursion poses a severe problem for static optimizations because its execution frequency usually depends upon runtime values, hence being rarely predictable at compile time. As a consequence, optimization potential of programs is sacrificed since possible hot paths where most of the execution time is spent and where optimization would be beneficial might be undiscovered. In this paper, we propose a sophisticated machine learning based approach to statically predict the recursion frequency of functions for programs in real-world application domains, which can be used to guide various hot spot optimizations. Our experiments with 369 programs of 25 benchmark suites from different domains demonstrate that our approach is applicable to a wide range of programs with different behavior and yields more precise heuristics than those generated by pure static analyses. Moreover, our results provide valuable insights into recursive structures in general, when they appear and how deep they are.	algorithm;application domain;approximation error;benchmark (computing);compile time;compiler;experiment;heuristic (computer science);iteration;machine learning;mathematical optimization;overhead (computing);profile-guided optimization;profiling (computer programming);recursion;requirement;run time (program lifecycle phase);scalability;static program analysis	Dirk Tetzlaff;Sabine Glesner	2012	2012 IEEE 10th Symposium on Embedded Systems for Real-time Multimedia	10.1109/ESTIMedia.2012.6507027	embedded system;real-time computing;computer science;theoretical computer science;operating system;machine learning;programming language;algorithm	PL	-17.74600292297926	37.25382887621827	124634
ddb3168b3a952bbf0045440c6e3f00b4d9d3f8c9	new ideas in parallel lisp: language design, implementation, and programming tools	storage management;parallel computer;exception handling;data structure;language design;programming tool	A Lisp-based approach is attractive for parallel computing since Lisp languages and systems assume significant clerical burdens, such as storage management. Parallel Lisps thus enable programmers to focus on the new problems introduced by using concurrency. Parallel Lisps now exist that can execute realistic applications with “industrial-strength” performance, but there are applications whose requirements they do not handle elegantly. Recent work has contributed new, elegant ideas in the areas of speculative computation, continuations, exception handling, aggregate data structures, and scheduling. Using these ideas, it should be possible to build “second generation” parallel Lisp systems that are as powerful and elegantly structured as sequential Lisp systems.		Robert H. Halstead	1989		10.1007/BFb0024149	fourth-generation programming language;first-generation programming language;computer architecture;very high-level programming language;interpreter;language primitive;programming domain;computer science;programming language implementation;extensible programming;functional logic programming;lisp;database;*lisp;programming paradigm;symbolic programming;inductive programming;fifth-generation programming language;programming language theory;programming language;control flow;high-level programming language;parallel programming model	PL	-17.468709527102632	33.23224938007719	124674
65f10461e83d88fae776196048807978bb56eba7	parallel execution of social simulation models in a grid environment		The exploration of agent-based social simulation models with a systematic analysis over its parameter space leads to a common problem. It takes too much time to get enough results for a significant analysis of the data generated by the simulation runs over those models. In this paper we show how one can minimise this problem by using grid computing. That is, constructing a social simulation model, designing an experiment and distributing the experiment over a computer grid, running a social simulation model with di↵erent parameter combinations in parallel. We supply a working example using the MASON framework and the JPPF framework.	agent-based model;agent-based social simulation;experiment;grid computing;job (computing);library (computing);mason;parallel computing;run time (program lifecycle phase);scalability	Davide Nunes;Luis Antunes	2012		10.1007/978-3-642-38859-0_9	real-time computing;simulation;computer science;distributed computing	HPC	-10.596963696768828	38.72667636700846	124706
193c5bb1ee93db70e09e78f9ae22c2dd82f7603e	data flow fusion with series expressions in haskell	fusion;arrays;haskell	Existing approaches to array fusion can deal with straight-line producer consumer pipelines, but cannot fuse branching data flows where a generated array is consumed by several different consumers. Branching data flows are common and natural to write, but a lack of fusion leads to the creation of an intermediate array at every branch point. We present a new array fusion system that handles branches, based on Waters's series expression framework, but extended to work in a functional setting. Our system also solves a related problem in stream fusion, namely the introduction of duplicate loop counters. We demonstrate speedup over existing fusion systems for several key examples.	dataflow architecture;haskell;pipeline (computing);speedup	Ben Lippmeier;Manuel M. T. Chakravarty;Gabriele Keller;Amos Robinson	2013		10.1145/2503778.2503782	parallel computing;fusion;computer science;theoretical computer science;algorithm	PL	-15.546414278942777	35.40303430996765	124714
9437eb548d98051295988e6c18317099fda750cd	an optimizing precompiler for finite-difference computations on a vector computer	finite difference	Abstract   This paper is concerned with techniques for translating array expressions, as found in FORTRAN 8X, into very efficient vector expressions on a machine in which long vectors are needed for high performance. It describes the application of these techniques in a precompiler for the CYBER 205 which requires a vector length of 1000 to achieve 90% of the asymptotic speed. The precompiler does not vectorize FORTRAN 77 DO loops, instead it vectorizes and optimizes programs written in the explicit array syntax of the proposed FORTRAN standard (FORTRAN 8X).  The optimization of the vector code is intended to be most effective for algorithms commonly used in finite-difference approximations of partial differential equations. Finite-difference schemes frequently evaluate the same expression over the interior of a multidimensional rectangular array. In these computations the precompiler is able to vectorize arithmetic operations over the entire array, rather than over individual dimensions, thus generating relatively long vectors. This vectorization is done, whenever possible, without using expensive gather operations. When gather operations must be used the precompiler attempts to minimize them by making one gather serve for several operands through the use of masks and offsets.	computation;finite difference;optimizing compiler;preprocessor;vector processor	J. Gary;L. Fosdick	1989	Parallel Computing	10.1016/0167-8191(89)90077-X	finite difference;parallel computing;computer science;theoretical computer science;operating system;mathematics;programming language;algorithm	HPC	-12.271840945282548	35.17956621024122	124721
b259aa0d6ddf7ebec2fee681d497ece2eba0f0d3	efficient applicative data types	data type	Applicative programming has long been advocated on theoretical grounds because the formal properties of such programs are simple and elegant. Recently, there has been a trend to use the applicative approach in software development tools [3] and programming languages [2,7]. Unfortunately, the requirement that operations be free of side-effects makes it difficult to achieve efficient implementations [7]. To date, there are only two published algorithms [5,8], which treat the applicative manipulation of queues and stacks.	algorithm;applicative programming language;programming tool;software development	Eugene W. Myers	1984		10.1145/800017.800517	data type;computer science;programming language	PL	-17.809346508783317	32.713349410952226	124865
d6c8d16f880cca9f10902ab198a0f06c3e977c20	software framework for parallel bem analyses with h-matrices		We developed a software framework for boundary element analyses. The software supports a hybrid parallel programming model and is equipped with a hierarchical matrix (H-matrix) library to accelerate the BEM analysis.	boundary element method;parallel computing;parallel programming model;software framework	Takeshi Iwashita;Akihiro Ida;Takeshi Mifune;Yasuhito Takahashi	2016	2016 IEEE Conference on Electromagnetic Field Computation (CEFC)	10.1016/j.procs.2017.05.263	computational science;mathematical optimization;computer science;theoretical computer science	HPC	-6.509119073114849	37.97272132560508	124878
747979df0527b2e72a1a69374eaa8567dca56999	more on bit processing with fortran	fortran	"""The routines presented by Mr. Yucel and Mr. Pinar are adequate for those machines which will compile their code. However, they are severely limited in their portability. Assumptions that """"most machines"""" use 8-bit bytes, are able to do bit-by-bit operations on logical variables, and will handle Z-type hexadecimal constants simply do not hold water. For example, not one of these is true in either CDC's 3000 series or the FORTRAN-oriented Cyber series, both of which are popular scientific computers. Therefore, I began working on doing the same functions (converting a number into an array of bits and back again) in ANSI standard FORTRAN. Both of these routines meet both the 1966 and 1977 ANSI standards."""	8-bit;ansi escape code;byte;compiler;computer;fortran;hexadecimal;software portability	T. N. Roberts	1982	SIGPLAN Notices	10.1145/947902.947907	computer science	Arch	-14.65396188151079	34.012367253017835	125030
5cda14291ce68766cb7b0133fce755989096a46e	nimfa: a python library for nonnegative matrix factorization	python;nonnegative matrix factorization;initialization methods;quality measures;scripting	NIMFA is an open-source Python library that provides a unifie d interface to nonnegative matrix factorization algorithms. It includes implementations of state-of-the-art factorization methods, initialization approaches, and quality scoring. It supports b o h dense and sparse matrix representation. NIMFA’s component-based implementation and hierarchical design should help the users to employ already implemented techniques or design and code new s trategies for matrix factorization tasks.	algorithm;component-based software engineering;matrix representation;non-negative matrix factorization;open-source software;python;sparse matrix	Marinka Zitnik;Blaz Zupan	2012	Journal of Machine Learning Research		mathematical optimization;python;computer science;theoretical computer science;machine learning	HPC	-9.427004267926481	35.341252249903086	125040
c6acfe23d4cba12e55148db80d3fd9963197df09	machines and models for parallel computing	parallel computing;processor architecture;microprocessor;shared memory;memoria compartida;flot donnee;memory coherence;conception;flujo datos;multithreaded dataflow;calculo automatico;functional programming;parallel computation;computing;calcul automatique;synchronisation;computer architecture;semantic model;calculo paralelo;multithreaded;architecture ordinateur;synchronization;parallel computer;diseno;design;programmation fonctionnelle;microprocesseur;arquitectura ordenador;sincronizacion;model of computation;data flow;programacion funcional;calcul parallele;microprocesador;semantic models;memoire partagee;memory latency	It is widely believed that superscalar and superpipelined extensions of RISC style architecture will dominate future processor design, and that needs of parallel computing will have little effect on processor architecture. This belief ignores the issues of memory latency and synchronization, and fails to recognize the opportunity to support a general semantic model for parallel computing. Efforts to extend the shared-memory model using standard microprocessors have led to systems that implement no satisfactory model of computing, and present the programmer with a difficult interface on which to build parallel computing applications. A more satisfactory model for parallel computing may be obtained on the basis of functional programming concepts and the principles of modular software construction. We recommend that designs for computers be built on such a general semantic model of parallel computation. Multithreading concepts and dataflow principles can frame the architecture of these new machines.	cas latency;computation;computer;dataflow;functional programming;instruction pipelining;microprocessor;modular programming;multithreading (computer architecture);parallel computing;processor design;programmer;shared memory;software construction;superscalar processor;thread (computing)	Jack B. Dennis	1994	International Journal of Parallel Programming	10.1007/BF02577792	synchronization;computer architecture;parallel computing;embarrassingly parallel;computer science;theoretical computer science;operating system;programming language;functional programming;algorithm	Arch	-15.004029242883396	40.332026624963596	125792
2c5d80969c4e39b98744f08b4bad57e074fb69ec	accelerating particle identification for high-speed data-filtering using opencl on fpgas and other architectures	hardware design languages;photonics;acceleration;computer architecture;computational modeling;graphics processing units;field programmable gate arrays	The upgrade of the LHCb experiment at CERN envisions a Data Acquisition and Event Filtering system that captures 100% of the data generated by the various sub-detectors, which measure with great precision the 40 million collisions per second of protons in CERN's Large Hadron Collider. The sensor readings result in about 40 Tbit/s of data, which need to be processed on a large computer farm. Since the computation on CPUs, as it is currently done, does not scale well, it is necessary to accelerate a good portion of the code to meet the computational demands of the proposed system. We are therefore looking for means to accelerate the most time-consuming parts of the event-filtering code. The Ring Imaging Cherenkov (RICH) detectors are one of the component detectors of the overall LHCb experiment. The Cherenkov photon that hits the detector are processed to determine the track of the original particle that caused these photons. The particle velocity and mass, derived from the Cherenkov angle, is used to identify the particle. The entire RICH photon reconstruction algorithm accounts for 50% of the second High Level Trigger (HLT) process and Cherenkov angle reconstruction comprises about 20% of the RICH and is a good candidate for acceleration. An OpenCL implementation of Cherenkov angle reconstruction algorithm that calculates the trajectory of Photons in the RICH detector was developed. The paper looks at the results of the OpenCL implementation of the algorithm on the Nallatech 385 card with Altera Stratix V FPGA, Nvidia GeForce GTX 690 GPU card and the Intel Xeon processor for comparison. While the two GPUs are 3.6× faster than a single FPGA, the FPGA is 3.4× better than two GPUs and 6.6× better than two multicore CPUs when energy efficiency is factored. Although significant speedup of computation was achieved on all the above architectures by using OpenCL, a good portion of the gain was lost due to the overhead of data transfer and parallelism. Different strategies are put forth for improving the speedup. Some optimizations currently possible, low latency links that can replace PCIe and some possible changes to the OpenCL execution model itself are discussed.	algorithm;amdahl's law;central processing unit;compiler;complex system;computation;data acquisition;field-programmable gate array;geforce 600 series;graphics processing unit;iteration;large hadron collider;mission critical;multi-core processor;nallatech;opencl api;overhead (computing);pci express;parallel computing;pipeline (computing);scalability;sensor;speedup;stratix;terabit;vhdl;velocity (software development);verilog	Srikanth Sridharan;Paolo Durante;Christian Faerber;Niko Neufeld	2016	2016 26th International Conference on Field Programmable Logic and Applications (FPL)	10.1109/FPL.2016.7577351	acceleration;embedded system;parallel computing;real-time computing;photonics;computer hardware;computer science;operating system;computational model;field-programmable gate array	HPC	-4.99609036914659	42.89274090847099	125798
90d089123a7ca50e871abba73ca8af91f55a3712	server-side design principles for scalable internet systems	distribution;asynchrony;encapsulation;design principle;partitioning;software engineering;software engineering internet;scalable internet systems server side design principles;internet concurrent computing hardware encapsulation scalability geography asynchronous communication buildings maintenance engineering;concurrency;parsimony;internet;load balancing;optimization;scalability;architecture;design principles	0 7 4 0 7 4 5 9 / 0 2 / $ 1 7 . 0 0 © 2 0 0 2 I E E E Any application can essentially be characterized by its consumption of four primary system resources: CPU, memory, file system bandwidth, and network bandwidth. Scalability is achieved by simultaneously optimizing the consumption of these resources and designing an architecture that can grow modularly by adding more resources. This article looks at the underlying principles needed to achieve such designs and discusses some specific strategies that exploit these principles.	central processing unit;emoticon;scalability;server-side	Colleen Roe;Sergio Gonik	2002	IEEE Software	10.1109/52.991330	distribution;asynchrony;real-time computing;scalability;concurrency;encapsulation;computer science;load balancing;theoretical computer science;architecture;software engineering;distributed computing;programming language	OS	-14.486821509566878	40.936689819805466	125830
154db38c75b66d2a87e2794706fdd341d4663687	parallelization of quantifier elimination on a workstation network	quantifier elimination;network of workstation;cylindrical algebraic decomposition	This paper reports our eeort to parallelize on a network of workstations the quantiier elimination algorithm over the reals which was devised by Collins and improved by the author. The preliminary experiments show both sub-linear and super-linear speedups due to speculative parallelism. On the problems we have tested so far, the eeciencies range between 70% and 320%.	algorithm;automatic parallelization;computer cluster;experiment;parallel computing;quantifier (logic);speculative execution;workstation	Hoon Hong	1993		10.1007/3-540-56686-4_42	discrete mathematics;quantifier elimination;cylindrical algebraic decomposition;theoretical computer science;mathematics;algebra	AI	-11.383780360848398	36.38668454416675	125977
cc37e66b0c0f098db20ee53c9b10ece1c7d5b5bf	parallel generalized lr parser based on logic programming	logic programs	Tomita's algorithm [Tomita 85] which treats context free grammars makes use of the breadth-first strategy to handle conflicts occurring in a LR parsing table. Considering the compatibility of a breadth-first strategy with parallel processing, we developed a parallel generalized LR parser called PLR, whose algorithm is based on Tomita's algorithm. PLR is implemented in GIIC[Ueda 85] that is a concurrent logic programming language developed by the Japanese 5th generation computer project. We made two kinds of implementations of PLR. One implementation does not uses the Graph Structured Stacks (GSSs) developed by Tomita, and the other implementation uses them. In this paper, we describe two implementations of PLR. Then to evaluate the ability of PLR, we compare the parsing time of PLR with that of PAX[Matsumoto 87] which is an efficient parallel parser implemented in GHC. The experiment revealed that PLR with no GSSs runs faster than PAX.		Hiroaki Numazaki;Naoyoshi Tamura;Hozumi Tanaka	1989		10.1007/3-540-53919-0_7	lalr parser;canonical lr parser;horn clause;computer science;theoretical computer science;functional logic programming;glr parser;programming language;recursive descent parser;prolog;logic programming;algorithm;lr parser;simple lr parser	AI	-16.06555482027148	33.824256577395325	126115
c36d7648c6666d8bbf27ffee4a4838dcdb02bffb	optical link in the delft parallel processor—an example of momi-connection in mimd-supercomputers		Much attention is given to the problem how to avoid transfer-bound processing in M I M D supercomputers. The interactivity between processing tasks is compared with the interconnectability that exists between processors in the case of a multi-bus communication system. For this purpose quantitative measures are introduced for both the task interact&ity and the processor interconnectability. For a M I M D computer with p processors and p busses the asymptotic speed-up is proportional to p both for tightly and loosely coupled tasks. For tightly coupled tasks a still larger speed-up can be achieved by taking more than p busses. For a M I M D computer with p processors in the case of 2-level parallelization considerably more speed-up can be obtained, but that requires at the 2nd level of parallelization p powerful interconnects (one per processor). Full processor interconnectability is ideal in the sense that no queueing problems can arise. In case of 1-level parallelization with p processors full interconnectability requires pe (oneword wide) interconnections. In the Delft Parallel Processor (DPP), instead of using a p2-tuple bus communication system, for this purpose a multibroadcast system with p data channels has been applied, where each data channel has p taps (one per processor) and each processor has a p-tuple accessible input memory (one input per channel). In the DPP84 (with maximally 16 processors) electric data channels have been applied. But for technical reasons for large p full interconnectability is only feasible by the way of optical data channels. This optical interconnect must be provided with electro-to-optic ( E / O) and opto-to-electric ( O / E) transducers as long as optical computing is not yet practically possible. The resulting Electro-Optic Communication System (EOCS) will be implemented in the DPP8X. The EOCS will consist of a combination of guided-wave and a p-tuple way starcoupler technique. Special E / O and O / E transducers have to be developed as well. An intelligent Opto-Electric logic element, the P O W E R R A M , is realized as a prototype p-tuple accessible input memory IC, capable to accept the multidata stream at the input of a processor in one clock cycle.	automatic parallelization;bus (computing);central processing unit;channel (communications);clock signal;digital photo professional (dpp);electrical connection;interactivity;loose coupling;mimd;optical computing;optical interconnect;parallel computing;prototype;supercomputer;transducer	Len Dekker;Edward E. E. Frietman;Wim Smit;Jan C. Zuidervaart	1988	Future Generation Comp. Syst.	10.1016/0167-739X(88)90003-9	parallel computing;real-time computing;computer science;theoretical computer science;operating system;database;distributed computing;programming language	Arch	-8.640247688514824	41.564618465470716	126126
7422d51863331a5e5b30201fb689ae7df5c0fe58	managing the terascale: lessons from a 750-node supercomputer			supercomputer;terascale (microarchitecture)	Esther Filderman;Kevin J. Sullivan	2001			computer science;computational science;literature;supercomputer	HPC	-8.065364309276452	39.265066907665364	126304
7697ba2e969fbe39d7416837d9f4be3602542e20	developer productivity in hpc application development: an overview of recent techniques	verification;simd;refactoring;reusability;parallel programming;gpgpu	Increasing computing power with evolving hardware architectures has lead to change in programming paradigm from serial to parallel. Unlike the sequential counterpart, application building for High Performance Computing (HPC) is extremely challenging for developers. In order to improve the programmer productivity, it is necessary to address the challenges such as: i) How to abstract the hardware and low level complexities to make programming easier? ii) What features should a design assistance tool have to simplify application development? iii) How should the programming languages be enhanced for HPC? iv) What sort of prediction techniques can be developed to assist programmers to predict potential speedup? v) Can refactoring techniques solve the issue of parallelizing existing serial code? In this talk we make an attempt to present a landscape of the existing approaches to assist the software building process in HPC from a developer's point of view, and highlight some important research questions. We also discuss the state of practice in the industry and some of the application specific tools developed for HPC.	automatic parallelization;code refactoring;emoticon;programmer;programming language;programming paradigm;programming productivity;speedup	Santonu Sarkar	2016		10.1145/2916026.2916034	parallel computing;real-time computing;computer science;programming language	HPC	-6.690973843267307	44.758029910391635	126370
99e0c97254b5472df601c53f7fc30cc7a7ab76a3	evaluation of the parallel performance of the java and pcj on the intel knl based systems		In this paper, we present performance and scalability of the Java codes parallelized on the Intel KNL platform using Java and PCJ Library. The parallelization is performed using PGAS programming model with no modification to Java language nor Java Virtual Machine. The obtained results show good overall performance, especially for parallel applications. The microbenchmark results, compared to the C/MPI, show that PCJ communication efficiency should be improved.	java	Marek Nowicki;Lukasz Górski;Piotr Bala	2017		10.1007/978-3-319-78054-2_27	parallel computing;programming paradigm;partitioned global address space;scalability;computer science;virtual machine;multi-core processor;java	HPC	-7.528835203354501	43.54703995847309	126598
44e6713ebeb7ddf4e41fc75128a2c5e1eedfa8fb	from the theory to the tools: parallel dynamic programming		Dynamic programming is an important paradigm that has been widely used to solve problems in various areas such as control theory, operation research, biology and computer science. We generalize the finite automaton formal model for dynamic programming deriving pipeline parallel algorithms. The optimality of these algorithms is established for the new class of non-decreasing finite automata. As an intermediate step for the construction of a skeleton for the automatic parallelization of dynamic programming, we have developed a tool for the implementation of pipeline algorithms. The tool maps the processes in the pipeline in the target architecture following a mix of block and cyclic policies adapted to the grain of the machine. Based on the former tool, the automatic parallelization of dynamic programming is straightforward. The use of the model and its associated tools is illustrated with the Single Resource Allocation Problem. The performance and portability of these tools is compared with specific ‘hand made’ code written by experienced programmers. The experimental results on distributed memory and shared distributed memory architectures prove the scalability of the proposed paradigm and its associated tools. Copyright  2000 John Wiley & Sons, Ltd.	automata theory;automatic parallelization;automaton;computation;computer science;control theory;distributed memory;dynamic programming;experiment;finite-state machine;formal language;john d. wiley;map;multistage amplifier;operations research;parallel algorithm;parallel computing;programmer;programming paradigm;scalability;software portability	Daniel González;Francisco Almeida;José Luis Roda García;Casiano Rodríguez	2000	Concurrency - Practice and Experience	10.1002/(SICI)1096-9128(200001)12:1%3C21::AID-CPE452%3E3.0.CO;2-2	dynamic compilation;programming domain;reactive programming;computer science;symbolic programming;inductive programming	PL	-13.695052144784313	36.9713713835819	126651
6e571ed42f9bacd26c57608b1cce08f11f415626	a decomposition method for efficient use of distributed supercomputers for finite element applications	finite element methods;supercomputers finite element methods laboratories large scale systems wide area networks visualization delay distributed computing network topology virtual prototyping;uses;finite element applications;distributed processing;performance;local network performance;distributed computing;distributed processing parallel machines finite element analysis;large scale scientific applications;finite element method;nonlinear problems;processor speed;finite element;computer networks;wide area topology;network topology;decomposition method;large scale;visualization;virtual prototyping;wide area topology decomposition method distributed supercomputers finite element applications highspeed networks large scale scientific applications processor speed local network performance wide area network performance;wide area network performance;parallel machines;finite element analysis;distributed data processing;distributed supercomputers;supercomputers;geographic distribution;wide area networks;large scale systems;highspeed networks;mathematics computers information science management law miscellaneous	The interconnection of geographically distributed supercomputers via highspeed networks makes available the needed compute power for large-scale scientific applications, such as finite element applications. In this paper we propose a two-level data decomposition method for efficient execution of finite element applications on a network of supercomputers. Our method exploits the following features that may be different for each supercomputer in the system: processor speed, number of processors used from each supercomputer, local network performance, wide area network performance and wide area topology. Preliminary experiments involving a nonlinear, finite element application executed on a network of two supercomputers, one located at Argonne National Laboratory and the other one at the Cornell Theory Center, demonstrate a 20% reduction in execution time when the proposed decomposition is used as compared with naively applying conventional decompositions that are applicable to single supercomputers.	finite element method;supercomputer	Valerie E. Taylor;Jian Chen;Thomas Canfield;Rick L. Stevens	1996		10.1109/ASAP.1996.542797	parallel computing;computer science;theoretical computer science;finite element method;distributed computing	HPC	-6.952463966783405	39.604260852995786	126718
933de92210d4fdfc4bd2e9967e90d753f01f4694	a similarity-based analysis tool for porting openmp applications		Exascale computers are expected to exhibit an unprecedented level of complexity, thereby posing significant challenges for porting applications to these new systems. One of the ways to support this transition is to create tools that allow their users to benefit from prior successful porting experiences. The key to such an approach is the manner in which we define source code similarity, and whether similar codes can be ported in the same way to a given system. In this paper, we propose a novel approach based on the notion of similarity that uses static and dynamic code features to check if two serial subroutines can be ported with the same OpenMP strategy. Our approach creates an annotated family distance tree based on the syntactic structure of subroutines, where subroutines that belong to the same syntactic family and share the similar code features have a greater potential to be optimized in the same way. We describe the design and implementation of a tool, based upon a compiler and performance tool, that is used to gather the data to build this porting planning tree. We then validate our approach by analyzing the similarity in subroutines of the serial version of the NAS benchmarks and comparing how they were ported in the OpenMP version of the suite.	benchmark (computing);code;compiler;computer;graphics processing unit;mathematical optimization;multi-core processor;nas parallel benchmarks;openmp;parallel computing;software metric;subroutine;symmetric multiprocessing;syntactic predicate	Wei Ding;Oscar R. Hernandez;Barbara M. Chapman	2012		10.1007/978-3-642-35893-7_2	parallel computing	HPC	-5.8544941249598805	44.51162725264839	126935
3517a16b721a4ca021770174a647ce026702b065	assist demo: a high level, high performance portable, structured parallel programming environment at work	estensibilidad;distributed system;algoritmo paralelo;assist;systeme unix;estacion trabajo;haute performance;systeme reparti;parallel algorithm;esqueleto;programming environment;programacion paralela;implementation;unix system;station travail;parallel programming;coordination language;skeleton;algorithme parallele;medio ambiente programacion;workstation;sistema repartido;parallel programming environment;structured programming;alto rendimiento;squelette;compilation;fortran;extensibilite;scalability;sistema unix;structured parallel programming;programmation structuree;c;demo;high level language;high performance;environnement programmation;programmation parallele;programacion estructurada	This work summarizes the possibilities offered by parallel programming environment ASSIST by outlining some of the features that will be demonstrated at the conference demo session. We’ll substantially show how this environment can be deployed on a Linux workstation network/cluster, how applications can be compiled and run using ASSIST and eventually, we’ll discuss some ASSIST scalability and performance features. We’ll also outline how the ASSIST environment can be used to target GRID architectures.	assist (computing);compiler;integrated development environment;linux;parallel computing;scalability;workstation	Marco Aldinucci;Sonia Campa;Pierpaolo Ciullo;Massimo Coppola;Marco Danelutto;Paolo Pesciullesi;Roberto Ravazzolo;Massimo Torquati;Marco Vanneschi;Corrado Zoccolo	2003		10.1007/978-3-540-45209-6_176	embedded system;parallel computing;scalability;workstation;computer science;operating system;database;distributed computing;parallel algorithm;programming language;implementation;structured programming;skeleton;high-level programming language	HPC	-17.644766070141454	42.02589298414742	127131
8995e2b642761b2efe02562adb65ba929be162a2	high performance computing — hipc 2000		Charon is a library, callable from C and Fortran, that aids the conversion of structured-grid legacy codes—such as those used in the numerical computation of fluid flows—into parallel, high-performance codes. Key are functions that define distributed arrays, that map between distributed and non-distributed arrays, and that allow easy specification of common communications on structured grids. The library is based on the widely accepted MPI message passing standard. We present an overview of the functionality of Charon, and some representative results.	array data structure;code;computation;fortran;international conference on high performance computing;message passing interface;numerical analysis;regular grid	Jan van Leeuwen;Mateo Valero;Viktor K. Prasanna;Sriram Vajapeyam	2000		10.1007/3-540-44467-X	parallel computing;supercomputer;computer science	HPC	-8.544627612065309	36.9176615778049	127255
387c8d19f901887fbbd6e1251f1565f5386d14cf	incorporating application dependent information in an automatic code generating environment	automatic code generation;routing;product code;code generation;weather forecasting;automatic generation;parallel computer architecture;high level language;data structure;routers;multicomputer networks	In this paper, we demonstrate the necessity of including high-level information for automatic generation of efficient codes for serial, vector, and parallel computer architectures with the CTADEL code generation tool. The CTADEL Codegeneration Tool for Applications based on Differential Equations using high-level Language specifications is a programming environment developed for the generation of efficient codes for PDEbased problems. The tool has been adopted as an application driver for the HIRLAM numerical weather forecast system. More specifically, we present a framework for high-level code restructuring based on monotonicity information about the data structures used. This information is not available in state-of-the-art vectorizing and parallelizing compilers but it is of vital importance for the generation of efficient architecture-specific codes. The performance of the generated codes for a typical example problem encountered in the so-called physics routines of the HIRLAM system are compared to the hand-written production code. The performance results demonstrate the usefulness of the presented technique.	automatic parallelization;code generation (compiler);compiler;computer architecture;data structure;fortran;hirlam;high- and low-level;high-level programming language;integrated development environment;iteration;numerical analysis;numerical weather prediction;parallel computing;programmer;software portability	Robert A. van Engelen;Ilja Heitlager;Lex Wolters;Gerard Cats	1997		10.1145/263580.263627	kpi-driven code analysis;dead code;routing;computer architecture;parallel computing;data structure;weather forecasting;computer science;theoretical computer science;redundant code;universal product code;programming language;high-level programming language;code generation;unreachable code;source code	HPC	-11.235961772118618	35.94129752116693	127261
4da2998b56083e90ca0870360e037a68131cddf4	resilient parallel computing on volunteer pc grids			parallel computing	Jaspal Subhlok;Hien Nguyen;Edgar Gabriel;Mohammad Tanvir Rahman	2018	Concurrency and Computation: Practice and Experience	10.1002/cpe.4478	distributed computing;parallel computing;volunteer;computer science	HPC	-9.098210035176134	42.033487309343066	127390
5c9d7e1bfc9409d2cf2925e6f227bb6e095e1d9b	efficient broadcasts and simple algorithms for parallel linear algebra computing in clusters	linear algebra;matrix factorization;ethernet based clusters;cluster computing;parallel algorithm;mathematics computing;concurrent computing;performance test;heterogeneous cluster;high performance computing;heterogeneous computing;performance tests parallel linear algebra computing broadcast message passing routine performance optimisation ethernet based clusters parallel matrix multiplication parallel algorithm scalapack library lu matrix factorization;testing;performance tests;linear algebra applications;lan interconnection;general methods;efficient implementation;parallel computer;message passing;performance optimisation;clustering algorithms;broadcast message passing routine;matrix multiplication;scalapack library;parallel linear algebra computing;lu matrix factorization;broadcasting;lan interconnection parallel algorithms linear algebra mathematics computing;broadcasting clustering algorithms linear algebra concurrent computing ethernet networks parallel algorithms testing message passing algorithm design and analysis parallel processing;system of equations;parallel matrix multiplication;heterogeneous parallel computing;ethernet networks;cluster communication performance;algorithm design and analysis;parallel processing;parallel algorithms	This paper presents a natural and efficient implementation for the classical broadcast message passing routine which optimizes performance of Ethernet based clusters. A simple algorithm for parallel matrix multiplication is specifically designed to take advantage of both, parallel computing facilities (CPUs) provided by clusters, and optimized performance of broadcast messages on Ethernet based clusters. Also, this simple parallel algorithm proposed for matrix multiplication takes into account the possibly heterogeneous computing hardware and maintains a balanced workload of computers according to their relative computing power. Performance tests are presented on a heterogeneous cluster as well as on a homogeneous cluster, where it is compared with the parallel matrix multiplication provided by the ScaLAPACK library. Another simple parallel algorithm is proposed for LU matrix factorization (a general method to solve dense systems of equations) following the same guidelines used for the parallel matrix multiplication algorithm. Some performance tests are presented over a homogeneous cluster.	central processing unit;computer hardware;heterogeneous computing;linear algebra;matrix multiplication algorithm;message passing;parallel algorithm;parallel computing;scalapack;turing reduction	Fernando Tinetti;Emilio Luque	2003		10.1109/IPDPS.2003.1213364	parallel processing;parallel computing;concurrent computing;computer science;theoretical computer science;linear algebra;operating system;distributed computing;parallel algorithm	HPC	-7.72092042553622	41.42997809867193	127416
01313192fb0081dbbbc7699d345a5af61cfd4e5d	the study and handling of program inputs in the selection of garbage collectors	selection of garbage collectors;modelizacion;analisis estadistico;profiling;performance;ramasse miettes;langage java;aprendizaje probabilidades;program verification;classification;analisis programa;recogemigas;modelisation;performance programme;verificacion programa;statistical learning;statistical analysis;predictability;cross input program analysis;execution environment;garbage collector;analyse statistique;apprentissage probabilites;minimum possible heap size;lenguaje java;eficacia programa;predictabilidad;program analysis;program performance;input specific selection;analyse programme;experimentation;verification programme;predictabilite;modeling;clasificacion;probability learning;java language	Many studies have shown that the best performer among a set of garbage collectors tends to be different for different applications. Researchers have proposed applicationspecific selection of garbage collectors. In this work, we concentrate on a second dimension of the problem: the influence of program inputs on the selection of garbage collectors. We collect tens to hundreds of inputs for a set of Java benchmarks, and measure their performance on Jikes RVM with different heap sizes and garbage collectors. A rigorous statistical analysis produces four-fold insights. First, inputs influence the relative performance of garbage collectors significantly, causing large variations to the top set of garbage collectors across inputs. Profiling one or few runs is thus inadequate for selecting the garbage collector that works well for most inputs. Second, when the heap size ratio is fixed, one or two types of garbage collectors are enough to stimulate the top performance of the program on all inputs. Third, for some programs, the heap size ratio significantly affects the relative performance of different types of garbage collectors. For the selection of garbage collectors on those programs, it is necessary to have a cross-input predictive model that predicts the minimum possible heap size of the execution on an arbitrary input. Finally, by adoptingstatistical learning techniques, we investigate the cross-input predictability of the influence. Experimental results demonstrate that with regression and classification techniques, it is possible to predict the best garbage collector (along with the minimum possible heap size) with reasonable accuracy given an arbitrary input to an application. The exploration opens the opportunities for tailoring the selection of garbage collectors to not only applications but also their inputs.	garbage collection (computer science);java;jikes;profiling (computer programming)	Xipeng Shen;Feng Mao;Kai Tian;Eddy Z. Zhang	2009	Operating Systems Review	10.1145/1618525.1618531	program analysis;garbage;parallel computing;real-time computing;systems modeling;predictability;performance;biological classification;computer science;operating system;profiling;data pre-processing;garbage collection;programming language	PL	-18.20236431802887	38.31002658210152	127754
13960cd52f532dd94f8eb2ecef7302967abeb00b	shasta: a low overhead, software-only approach for supporting fine-grain shared memory	tratamiento paralelo;distributed memory;distributed system;eficacia sistema;optimisation;lenguaje ensamblador;systeme reparti;compilateur;shared memory;storage access;systeme multiprocesseur memoire repartie;traitement parallele;shared miss check;optimizacion;numerical technique;memoria compartida;simulacion numerica;performance systeme;instruction;instruccion;addressing;compiler;system performance;memory access;software distributed shared memory;sistema repartido;cache coherence protocol;langage assembleur;scheduling;sistema multiprocesador memoria distribuida;reecriture;relaxed memory model;simulation numerique;acces memoire;memory chanel;adressage;acceso memoria;ordonamiento;optimization;polling;distributed memory multiprocessor system;assembler;rewriting;direccionamiento;data structure;parallel processing;ordonnancement;compilador;memoire partagee;reescritura;numerical simulation;workstation cluster;memory model	This paper describes Shasta, a system that supports a shared address space in software on clusters of computers with physically distributed memory. A unique aspect of Shasta compared to most other software distributed shared memory systems is that shared data can be kept coherent at a fine granularity. In addition, the system allows the coherence granularity to vary across different shared data structures in a single application. Shasta implements the shared address space by transparently rewriting the application executable to intercept loads and stores. For each shared load or store, the inserted code checks to see if the data is available locally and communicates with other processors if necessary. The system uses numerous techniques to reduce the run-time overhead of these checks. Since Shasta is implemented entirely in software, it also provides tremendous flexibility in supporting different types of cache coherence protocols. We have implemented an efficient cache coherence protocol that incorporates a number of optimizations, including support for multiple communication granularities and use of relaxed memory models. This system is fully functional and runs on a cluster of Alpha workstations.The primary focus of this paper is to describe the techniques used in Shasta to reduce the checking overhead for supporting fine granularity sharing in software. These techniques include careful layout of the shared address space, scheduling the checking code for efficient execution on modern processors, using a simple method that checks loads using only the value loaded, reducing the extra cache misses caused by the checking code, and combining the checks for multiple loads and stores. To characterize the effect of these techniques, we present detailed performance results for the SPLASH-2 applications running on an Alpha processor. Without our optimizations, the checking overheads are excessively high, exceeding 100% for several applications. However, our techniques are effective in reducing these overheads to a range of 5% to 35% for almost all of the applications. We also describe our coherence protocol and present some preliminary results on the parallel performance of several applications running on our workstation cluster. Our experience so far indicates that once the cost of checking memory accesses is reduced using our techniques, the Shasta approach is an attractive software solution for supporting a shared address space with fine-grain access to data.	address space;cpu cache;cache coherence;central processing unit;coherence (physics);computer;dec alpha;data structure;distributed memory;distributed shared memory;electrical connection;executable;instruction scheduling;instrumentation (computer programming);interrupt latency;memory map;optimizing compiler;overhead (computing);rewriting;scheduling (computing);visual intercept;workstation	Daniel J. Scales;Kourosh Gharachorloo;Chandramohan A. Thekkath	1996		10.1145/237090.237179	distributed shared memory;shared memory;memory model;parallel processing;polling;compiler;parallel computing;real-time computing;distributed memory;addressing mode;data structure;rewriting;computer science;operating system;computer performance;programming language;scheduling	Arch	-15.880731085442566	43.641228830464925	127787
28e3856f760e6f624cbdb9e1421ba3a479486a58	opencl-based design methodology for application-specific processors	optimising compilers;instruction level parallel;konferenssijulkaisu conference paper;kernel;application specific processor;hand tailored rtl design;programming language;learning curve;transport triggered architectures opencl application specific processors hardware accelerators instruction level parallelism vliw;opencl extension mechanism;parallel processing application specific integrated circuits c language microprocessor chips multiprocessing systems optimising compilers;design flow;transport triggered architectures;hardware accelerator;hardware accelerators;program optimization;vliw;kernel program processors registers hardware parallel processing computer architecture programming;computer architecture;custom hardware operation design methodology application specific processor programming language standard opencl compiler c programming language learning curve kernel code hand tailored rtl design opencl extension mechanism;c language;registers;application specific integrated circuits;opencl compiler;programming language standard;application specific processors;kernel code;multiprocessing systems;c programming language;transport triggered architecture;instruction level parallelism;opencl;programming;program processors;parallel processing;microprocessor chips;hardware;custom hardware operation;design methodology	OpenCL is a programming language standard which enables the programmer to express the application by structuring its computation as kernels. The OpenCL compiler is given the explicit freedom to parallelize the execution of kernel instances at all the levels of parallelism. In comparison to the traditional C programming language which is sequential in nature, OpenCL enables higher utilization of parallelism naturally available in hardware constructs while still having a feasible learning curve for engineers familiar with the C language. This paper describes methodology and compiler techniques involved in applying OpenCL as an input language for a design flow of application-specific processors. At the core of the methodology is a whole program optimizing compiler that links together the host and kernel codes of the input OpenCL program and parallelizes the result on a customized statically scheduled processor. The OpenCL vendor extension mechanism is used to provide clean access to custom operations. The methodology is studied with a design case to verify the scalability of the implementation at the instruction level and to exemplify the use of custom operations. The case shows that the use of OpenCL allows producing scalable application-specific processor designs and makes it possible to gradually reach the performance of hand-tailored RTL designs by exploiting the OpenCL extension mechanism to access custom hardware operations of varying complexity.	apl;algorithm;central processing unit;code;computation;datapath;exemplification;experiment;instruction-level parallelism;kernel (operating system);multi-core processor;opencl api;optimizing compiler;parallel computing;programmer;programming language;scalability;scheduling (computing);task parallelism	Pekka Jääskeläinen;Carlos S. de La Lama;Pablo Huerta;Jarmo Takala	2010	2010 International Conference on Embedded Computer Systems: Architectures, Modeling and Simulation	10.1109/ICSAMOS.2010.5642061	computer architecture;parallel computing;computer science;programming language	EDA	-14.041347105618982	38.00086603147543	127805
03bf4c20d8d83aac7798e237527cc115709f0cd4	simulative analysis of a multidimensional torus-based reconfigurable cluster for molecular dynamics	high performance computing;reconfigurable architectures;field programmable gate arrays high performance computing computer simulation reconfigurable architectures;fpga simulative analysis reconfigurable cluster molecular dynamics md high performance computing 3d fft kernel fast fourier transform anton machine field programmable gate array;acceleration;computational modeling;three dimensional displays computational modeling delays field programmable gate arrays solid modeling acceleration mathematical model;three dimensional displays;solid modeling;mathematical model;field programmable gate arrays;computer simulation;delays;reconfigurable architectures biocomputing fast fourier transforms field programmable gate arrays parallel processing	Molecular dynamics (MD) is a large-scale, communication-intensive problem that has been the subject of high-performance computing research and acceleration for years. Not surprisingly, the most success in accelerating MD comes from specialized systems such as the Anton machine. Our goal is to design a reconfigurable system that can accelerate MD while also being amenable to other communication-intensive applications. In this paper, we present a performance model for the 3D FFT kernel that forms the core of MD simulation on Anton. We validate the model against published Anton performance data and use the data to design and evaluate a similar interconnect for our existing Novo-G reconfigurable supercomputer. Through simulation studies, we predict that the upgraded machine will achieve nearly double the performance of Anton and fifty times that of established clusters like BlueGene/L for the 3D FFT kernel.	anton (computer);blue gene;computation;computational science;fast fourier transform;kernel (operating system);molecular dynamics;routing;simulation;stratix;supercomputer	Abhijeet Lawande;Hanchao Yang;Alan D. George;Herman Lam	2014	2014 43rd International Conference on Parallel Processing Workshops	10.1109/ICPPW.2014.58	computer simulation;acceleration;parallel computing;computer hardware;reconfigurable computing;computer science;theoretical computer science;operating system;mathematical model;solid modeling;computational model;field-programmable gate array	HPC	-5.321445241450509	37.67508889999734	127926
387f5c9d3d6c134567bc8043002fdf93f66ad03f	iterators in chapel	concurrent computing;software engineering data structures parallel algorithms parallel languages parallel programming program compilers;parallel programming;software engineering;parallel programming language;complex loop nests;data structures;programming profession;data structures programming profession concurrent computing parallel programming multidimensional systems computer science software engineering software algorithms parallel processing robustness;chapel iterator;software algorithms;robustness;chapel parallel programming language;scientific languages;computer science;program compilers;chapel compiler chapel iterator software engineering data structures parallel codes scientific languages complex loop nests chapel parallel programming language;parallel codes;parallel languages;algorithms and data structure;parallel processing;multidimensional systems;chapel compiler;parallel algorithms	A long-held tenet of software engineering is that algorithms and data structures should be specified orthogonally in order to minimize the impact that changes to one will have on the other. Unfortunately, this principle is often not well-supported in scientific and parallel codes due to the lack of abstractions for factoring iteration away from computation in traditional scientific languages. The result is a fragile situation in which complex loop nests are used to express parallelism and maximize performance, yet must be maintained individually as the algorithm and data structures evolve. In this paper, we introduce the iterator concept in the Chapel parallel programming language, designed to address this problem and provide a means for factoring iteration away from computation. The paper illustrates iterators using several examples, compares our approach with those taken in other languages, and describes our implementation in the Chapel compiler	algorithm;chapel;code;compiler;computation;data structure;integer factorization;iteration;iterator;multithreading (computer architecture);overhead (computing);parallel computing;parallel programming model;programmer;programming language;software engineering;static variable;thread (computing)	Mackale Joyner;Bradford L. Chamberlain;Steven J. Deitz	2006	Proceedings 20th IEEE International Parallel & Distributed Processing Symposium	10.1109/IPDPS.2006.1639499	parallel processing;parallel computing;concurrent computing;multidimensional systems;computer science;theoretical computer science;operating system;distributed computing;parallel algorithm;programming language;algorithm;robustness;parallel programming model	SE	-13.464943891579196	38.75589064579436	128081
49c709d18bc3d950a1d3a009d2981048284c931d	enhancing pvm with threads in distributed programming	distributed programs	Orchid [1] is a parallel and portable software platform that uses light weight processes as the basic unit of parallelism. The aim of this work is to exploit the portable features of Orchid to implement a thread-oriented PVM environment, enhanced with the DSM and synchronization mechanisms provided by Orchid. This results in enhancing PVM with all the inherent facilities of Orchid and in making Orchid more robust by using the well established operations of PVM.	distributed computing;parallel virtual machine	George Manis;C. Voliotis;Panayiotis Tsanakas;George K. Papakonstantinou	1996		10.1007/3-540-61142-8_687	computer science	PL	-12.489979903517861	43.947275922023564	128160
6f7842bf5daef5b419d470076cb644e387dc78e6	optimal interconnection network bandwidth for ring-based multiprocessor systems			interconnection;multiprocessing	Sung Woo Chung;Chu Shik Jhon	1999			symmetric multiprocessor system;computer science;parallel computing;interconnection;distributed computing;multiprocessing;bandwidth (signal processing)	Arch	-10.003892129353718	43.22178460005489	128166
44efef85d56e61fb304f27010cc0d1bd80283a69	automatic feature generation for machine learning based optimizing compilation	grammar;machine learning algorithms;genetic program;optimizing compiler;workload reduction;compiler writer;predictive modeling;machine learning optimizing compilers machine learning algorithms humans program processors informatics learning systems genetic programming predictive models tree data structures;feedback directed optimization;general techniques;genetic programming;data mining;feature space;program compilers genetic algorithms grammars learning artificial intelligence;compilers;feature generation technique automatic feature generation machine learning compilation compiler writer grammar genetic programming predictive modeling loop unrolling pentium 6;grammars;loop unrolling;automatic feature generation;machine learning;feature generation technique;clustering;feature extraction;compiler optimization;compilation;genetic algorithms;prediction model;learning artificial intelligence;program compilers;program processors;benchmark testing;pentium 6	Recent work has shown that machine learning can automate and in some cases outperform hand crafted compiler optimizations. Central to such an approach is that machine learning techniques typically rely upon summaries or features of the program. The quality of these features is critical to the accuracy of the resulting machine learned algorithm; no machine learning method will work well with poorly chosen features. However, due to the size and complexity of programs, theoretically there are an infinite number of potential features to choose from. The compiler writer now has to expend effort in choosing the best features from this space. This paper develops a novel mechanism to automatically find those features which most improve the quality of the machine learned heuristic. The feature space is described by a grammar and is then searched with genetic programming and predictive modeling. We apply this technique to loop unrolling in GCC 4.3.1 and evaluate our approach on a Pentium 6. On a benchmark suite of 57 programs, GCC's hard-coded heuristic achieves only 3% of the maximum performance available, while a state of the art machine learning approach with hand-coded features obtains 59%. Our feature generation technique is able to achieve 76% of the maximum available speedup, outperforming existing approaches.	algorithm;benchmark (computing);data structure;feature vector;for loop;gnu compiler collection;genetic programming;hard coding;heuristic;loop unrolling;machine learning;optimizing compiler;predictive modelling;speedup	Hugh Leather;Edwin V. Bonilla;Michael F. P. O'Boyle	2009	2009 International Symposium on Code Generation and Optimization	10.1109/CGO.2009.21	computer science;theoretical computer science;operating system;online machine learning;machine learning;optimizing compiler;programming language;active learning;algorithm	AI	-16.943729245981203	37.62094403263772	128186
a55e5551a88140dfb2e33d292aa46e09b77d4180	special issue on applied reconfigurable computing			reconfigurable computing	Christos-Savvas Bouganis;Marek Gorgon;Vanderlei Bonato	2017	Microprocessors and Microsystems - Embedded Hardware Design	10.1016/j.micpro.2017.05.010	parallel computing;theoretical computer science;reconfigurable computing;computer science	EDA	-8.058086136619764	37.65787003907111	128218
d4efc4d39ec40f3aa3d88529b9908d5a873bf39f	seismic wave field modeling with graphics processing units	oil and gas;seismic waves;graphic processing unit	GPGPU - general-purpose computing on graphics processing units is a very effective and inexpensive way of dealing with time consuming computations. In some cases even a low end GPU can be a dozens of times faster than a modern CPUs. Utilization of GPGPU technology can make a typical desktop computer powerful enough to perform necessary computations in a fast, effective and inexpensive way. Seismic wave field modeling is one of the problems of this kind. Some times one modeled common shot-point gather or one wave field snapshot can reveal the nature of an analyzed wave phenomenon. On the other hand these kinds of modelings are often a part of complex and extremely time consuming methods with almost unlimited needs of computational resources. This is always a problem for academic centers, especially now when times of generous support from oil and gas companies have ended.		Tomasz Danek	2009		10.1007/978-3-642-01973-9_48	seismic wave;real-time computing;simulation;computer science;electrical engineering;artificial intelligence;operating system;algorithm;computer graphics (images)	Graphics	-6.591311596932932	35.72953131587536	128415
004f584b5013028bbd0e1f22a1719ea5b74d2167	supporting a flexible parallel programming model on a network of workstations	parallel programming parallel processing workstations functional programming software systems software prototyping concurrent computing computer architecture memory management distributed computing;network of workstations;dynamic load balancing;programming environments;concurrent computing;shared memory;memory management;fault tolerant;parallel architectures parallel programming shared memory systems programming environments;software prototyping;fault tolerance parallel programming model workstations network of workstations compositional c divide and conquer shared memory management bottlenecks scalability dependability dynamic load balancing;distributed computing;software systems;parallel programming;compositional c;shared memory management;functional programming;bottlenecks;programming model;computer architecture;shared memory systems;parallel architectures;workstations;fault tolerance;dependability;network of workstation;scalability;parallel programming model;divide and conquer;parallel processing;dynamic behavior	We introduce a shared memory software prototype system for executing programs with nested parallelism on a network of workstations. This programming model exhibits a very convenient and natural programming style and provides functionality similar to a subset of Compositional C++. Such programming model is especially suitable for computations whose complexity and parallelism emerges only during their execution, as in divide and conquer problems. To both support and take advantage of the flexibility inherent in the programming model, we develop an architecture, which distributes both the shared memory management and the computation, removing bottlenecks inherent in centralization, thus also providing scalability and dependability. The system supports also dynamic load balancing, and fault tolerance—both transparently to the programmer. The prototype performs well using the realistic platforms of non-dedicated network of workstation. We describe encouraging performance experiments on a network in which some of the machines became slow unpredictably (to the application program). The system coped well with such dynamic behavior. 1. Background and key characteristics In this paper, we present a system that utilize nondedicated networks of workstations for dependable parallel computation. Relying on some of the mechanisms in [11] and [3], we developed a prototype software environment with additional properties beyond those in [3]: Enhanced programmer’s model, supportinga very flexible syntax and semantics for parallelism, equivalent in its fundamental aspects to a subset of the Compositional This research was partially supported by the National Science Foundation under grant numbers CCR-94-11590 and CCR-94-21935. C++ (CC++) model [10]. Arbitrary parallelism depth is provided (by explicit definition and/or by recursion). Execution environment in which in the computational and memory management functionality is almost fully distributed. Thus, the execution environment supports: high degree of scalability, more flexible and adaptive load balancing, and higher degree of fault masking. In consequence, our prototype can be specifically targeted towards the efficient execution of of unpredictably evolving and possibly inherently unbalanced parallel computations. We thus provide integrated set of capabilities that are not available in any existing system for parallel computing on distributed platforms. 2. The programmer’s model To ease the work of application programmers, we provide them with a virtual shared memory parallel machine. The machine supports globally shared memory and has an unbounded number of non-failing sequential processors. The processors do not operate in lockstep, but can be synchronized by a variant of a barrier construct as needed. The programmer is not concerned with fault tolerance, load balancing, etc. We provide an execution environment in which programs with rich parallel constructs written for such an “ideal” machine, can be executed dependably on unreliable distributed platforms.	c++;central processing unit;complexity;computation;computer cluster;dependability;distributed computing;emergence;experiment;failure;fault tolerance;load balancing (computing);lockstep (computing);memory management;parallel computing;parallel programming model;programmer;programming style;prototype;recursion;scalability;shared memory;software prototyping;unbalanced circuit;workstation	Shih-Chen Huang;Zvi M. Kedem	1996		10.1109/ICDCS.1996.507903	parallel processing;fault tolerance;computer architecture;parallel computing;concurrent computing;computer science;operating system;distributed computing;programming paradigm;programming language;functional programming	HPC	-13.564786080984206	43.25323482727684	128652
be2ba7b712a22af770d0f857d3bf01df84a62c7c	combining different models of computation for cosimulation of heterogeneous systems	model of computation		model of computation	Christian Kreiner;Christian Steger;Reinhold Weiss	1999			computer science;theoretical computer science;model of computation	HPC	-9.063545811527211	42.535668826949994	128680
a1244bd3e1a6d209d3a052c85faa212a2a9c6101	an improvement of the \logn distributed algorithm for mutual exclusion.	mutual exclusion;distributed algorithm		distributed algorithm;mutual exclusion	Mohamed Naimi;Michel Tréhel	1987			ricart–agrawala algorithm;maekawa's algorithm;distributed algorithm;parallel computing;mutual exclusion;computer science;distributed computing;suzuki-kasami algorithm;programming language	ML	-10.39741088689078	42.33268835671597	128786
3c837a89f55fb76f252ee80460bfff3f4cc611bb	solving pdes with intrepid	data analysis;numerical method;comprehensive set;cell-based construction;trilinos package;partial differential equations pdes;advanced discretizations;mathematical idea;numerical pdes;general context;differential equation	Intrepid is a Trilinos package for advanced discretizations of Partial Differential Equations (PDEs). The package provides a comprehensive set of tools for local, cell-based construction of a wide range of numerical methods for PDEs. This paper describes the mathematical ideas and software design principles incorporated in the package. We also provide representative examples showcasing the use of Intrepid both in the context of numerical PDEs and the more general context of data analysis. The mathematical roots of Intrepid are in the abstract framework for compatible discretizations [5]. This framework prompted a reevaluation of traditional software designs for PDE discretizations, which usually target a single discretization paradigm such as Finite Element Methods (FEM), Finite Volume Methods (FVM) or Finite Difference Methods (FDM). Intrepid aims to translate these mathematical similarities into software-based similarities. Finding software abstractions that unify these disparate families of methods differentiates Intrepid from existing PDE software. Software packages such as Chombo (seesar.lbl.gov/anag/chombo), Overture (computation.llnl.gov/casc/Overture) and ClawPack (www.clawpack.org) target FDM and FVM on adaptive block structured meshes, whereas deal.ii (www.dealii.org), HERMES (hpfem.org/hermes), Sundance (www.math.ttu.edu/ ̃kelong/Sundance/html/), and FEniCS (www.fenicsproject.org) support primarily FEM, based on weak variational forms of the PDEs. Additionally, such packages attempt to integrate the entire user experience, providing tools for meshes, global assembly, and interfaces to linear algebra. Some packages, such as FEniCS and Sundance, even provide an embedded description language of weak forms and automate the construction of stiffness matrices. Intrepid expresses a much lower level of abstraction, targeting the elementwise aspects of discretization via stateless methods on flat data structures. Existing large-scale application codes, such as the multiphysics simulation environments Drekar [30] and Albany [25], currently use Intrepid, but one could also envision Intrepid as a back-end for FEniCS or Sundance. As such, Intrepid represents a kind of middleware between higher-level software architecture and lower-level numerics that provides basis functions, transformations, and integration to diverse client codes. We organize the paper as follows. Section 2 briefly reviews the key mathematical concepts incorporated in Intrepid. Section 3 explains the basic design principles adopted by Intrepid, and	algorithm;attribute-value system;basis function;code;data structure;discretization;embedded system;finite difference method;finite element method;finite volume method;linear algebra;middleware;multiphysics;numerical method;pde surface;programming paradigm;simulation;software architecture;software design;stateless protocol;stiffness matrix;trilinos;user experience;variational principle	Pavel B. Bochev;H. Carter Edwards;Robert C. Kirby;Kara Peterson;Denis Ridzal	2012	Scientific Programming	10.3233/SPR-2012-0340	programming;mathematical optimization;computer science;software design;theoretical computer science;finite element method;differential equation	HPC	-9.646303631076524	35.810673819087626	128900
b45855e150d653786b42998909864ccffc1a097b	infrastructures and compilation strategies for the performance of computing systems	jit;performance;dynamic binary optimization;compilation;optimization;interpreter	This document presents our main contributions to the field of compilation, and more generally to the quest of performance of#R##N#computing systems.#R##N##R##N#It is structured by type of execution environment, from static compilation (execution of native code), to JIT compilation, and purely#R##N#dynamic optimization. We also consider interpreters. In each chapter, we give a focus on the most relevant contributions.#R##N##R##N#Chapter 2 describes our work about static compilation. It covers a long time frame (from PhD work 1995--1998 to recent work on real-time#R##N#systems and worst-case execution times at Inria in 2015) and various positions, both in academia and in the industry.#R##N##R##N#My research on JIT compilers started in the mid-2000s at STMicroelectronics, and is still ongoing. Chapter 3 covers the results we obtained on various aspects of JIT compilers: split-compilation, interaction with real-time systems, and obfuscation.#R##N##R##N#Chapter 4 reports on dynamic binary optimization, a research effort started more recently, in 2012. This considers the optimization of a native binary (without source code), while it runs. It incurs significant challenges but also opportunities.#R##N##R##N#Interpreters represent an alternative way to execute code. Instead of native code generation, an interpreter executes an infinite loop that#R##N#continuously reads a instruction, decodes it and executes its semantics. Interpreters are much easier to develop than compilers,#R##N#they are also much more portable, often requiring a simple recompilation. The price to pay is the reduced performance. Chapter 5#R##N#presents some of our work related to interpreters.#R##N##R##N#All this research often required significant software infrastructures for validation, from early prototypes to robust quasi products, and#R##N#from open-source to proprietary. We detail them in Chapter 6.#R##N##R##N#The last chapter concludes and gives some perspectives.		Erven Rohou	2015			parallel computing;real-time computing;native image generator;computer science;just-in-time compilation;programming language	HPC	-19.07718982446477	35.05721639500322	128964
92883677b59c42bc25993ecf63cd39c0020e5d0d	a spill code minimization technique—application in the metrowerks starcore c compiler	register allocation;spill code;graph coloring;rematerialization;code size;optimization;data flow;optimal algorithm	Graph coloring algorithms have been shown to be an efficient and effective means of performing register allocation. The power of these algorithms lies in their strong coloring heuristics and their ability to abstract away disparate allocation problems such as data-flow constraints, conforming to calling conventions, and target machine restrictions. However, even optimal algorithms cannot color every graph, and often some live ranges must be spilled to memory to make room for others. In this paper, we present a new approach of reducing spill code, which can be used to complement virtually any register allocation algorithm, and provides a good support to implement cheaper spill methods like spilling to another register (from a different class) and rematerialization (reloading the register from a constant or expression). This algorithm was partially implemented into the Metrowerks StarCore C compiler where it has proven its efficiency in terms of both cycle count and code size.	algorithm;calling convention;compiler;control flow;cycle count;dataflow;graph coloring;heuristic (computer science);interference (communication);memory management;register allocation;rematerialization;splitting circle method;strong coloring;test case	Virgil Palanciuc;Dragos Badea	2004	International Journal of Parallel Programming	10.1023/B:IJPP.0000042083.16504.5e	data flow diagram;parallel computing;loop-invariant code motion;computer science;theoretical computer science;graph coloring;register allocation;rematerialization;algorithm	PL	-17.171410801580087	37.10643201655851	129105
6805b49d9db2ca97d8dda731a1af098fc253a984	operating system kernel for a reconfigurable multiprocessor system	operating system		multiprocessing;operating system	Geoffrey M. Brown;Chuan-lin Wu	1986			parallel computing;distributed computing;symmetric multiprocessor system;kernel (linear algebra);multiprocessing;real-time operating system;operating system;computer science;embedded operating system	HPC	-9.804987218966286	43.24979015851585	129246
9f9dda5ff0db4a928cce29da7ac8d40e5d38a758	amm: scalable memory reuse model to predict the performance of physics codes		As the US Department of Energy (DOE) invests in exascale computing, scalable performance modeling of physics codes on CPUs remains a hard challenge in computational codesign due to advanced design features of processors such as the memory hierarchy, instruction pipelining, and speculative execution. Reuse distance is a powerful (but unscalable) characteristic that helps to predict cache hit-rates. We propose, Analytical Memory Model (AMM), a novel hardware model based on cache memory hierarchies. AMM efficiently computes close approximations of reuse distance distributions through a combination of static analysis of basic code blocks and sampling from very small code instances. The results show that AMM accurately predicts reuse profiles of scientific mini-applications (for example, matrix multiplication). Coupling AMM with the Performance Prediction Toolkit (PPT), we further show a scalable runtime prediction of scientific codes on Intel Xeon.	approximation;cache (computing);central processing unit;code;code::blocks;coupling (physics);instruction pipelining;matrix multiplication;memory hierarchy;peres–horodecki criterion;performance prediction;pipeline (computing);sampling (signal processing);scalability;smart meter;speculative execution;static program analysis	Gopinath Chennupati;Nandakishore Santhi;Stephan Eidenbenz;Sunil Thulasidasan	2017	2017 IEEE International Conference on Cluster Computing (CLUSTER)	10.1109/CLUSTER.2017.77	xeon;performance prediction;memory model;cache;real-time computing;cpu cache;parallel computing;computer science;memory management;speculative execution;memory hierarchy	HPC	-5.2162945339380355	45.48811701641888	129405
1b1f3dd9f84b99816473854968e3b7c2e6d1edd5	on the computing power of arrays of processors with optical pipelined buses	optical interconnection;bus optique;interconexion optica;sistema informatico;pipelined optical buses;barra colectora optica;computer system;procesador panel;array processor;parallel computation;processeur tableau;computer architecture;calculo paralelo;architecture ordinateur;procesador oleoducto;oleoducto;systeme informatique;arquitectura ordenador;systeme parallele;parallel system;processeur pipeline;pram models;calcul parallele;optical bus;parallel random access machine pram;pipeline;sistema paralelo;pipeline processor;optical interconnections;interconnexion optique	This paper examines the computing power of optical parallel computer systems. We consider the proposed Array of Processors with optical Pipelined Buses (APPB) in particular, where processors communicate with each other via a spanning optical bus. APPB allow simultaneous access by multiple processors to the optical bus through message pipelining, thus overcoming the bottlenecks caused by exclusive access when employing electronic buses. We give an overview of this model of parallel computation, and then examine the computing power of APPB by demonstrating its capability to efficiently emulate the CRCW PRAM model. We show that an APPB is almost as powerful as a CRCW PRAM. That is, an APPB can emulate a CRCW PRAM with only a small degradation in time performance.		Mounir Hamdi;Chunming Qiao;Yi Pan	1998	Parallel Processing Letters	10.1142/S0129626498000493	embedded system;parallel computing;computer hardware;computer science;operating system;pipeline	HPC	-12.499860142624108	45.00875126127992	129523
18a0cf2c974567ddbad2e401c0aa6ef43faba5cf	sustained petaflop and beyond: can parallel computing systems meet the challenges?	biology computing;concurrent computing;system software;application software;high performance computing;storage management;biological system modeling;parallel processing biological system modeling computer architecture biology computing computer science concurrent computing high performance computing system software application software bioinformatics;parallel programming;memory consistency;synchronisation;computer architecture;system software design petascale parallel computing system high end computing system multithreading synchronization memory consistency parallel programming dynamic compilation model;dynamic compilation model;synchronization;parallel computer;system software design;computer science;natural sciences computing;program compilers;program compilers parallel processing natural sciences computing synchronisation storage management;petascale parallel computing system;parallel processing;multithreading;bioinformatics;high end computing system	Breakthrough-quality scientific discoveries in the new millennium (such as those expected in computation biology and others), along with optimal engineering designs, have created a demand for High-End Computing (HEC) systems with sustained performance requirements at a petaflop scale and beyond. Despite the very pessimistic (if not negative) views on parallel computing systems that have prevailed in 1990s, there seems to be no other viable alternatives for such HEC systems. In this talk, we present a fresh look at the problems facing the design of petascale parallel computing systems. We review several fundamental issues that such HEC parallel computing systems must resolve. These issues include: execution models that support dynamic and adaptive multithreading, fine-grain synchronization, and global name-space and memory consistency. Related issues in parallel programming, dynamic compilation models, and system software design will also be discussed. Present solutions and future direction will be discussed based on (1) application demand (e.g. computation biology and others), (2) the recent trend as demonstrated by the HTMT, HPCS, and the Blue-Gene Cyclops (e.g. Cyclops-64) architectures, and (3) a historical perspective on influential models such as dataflow, along with concepts learned from these models. Biographical Sketch: Professor Gao's main research interests include high-performance architectures and systems, their programming models, system software (particularly compilers), and applications such as computational biology and bioinformatics. He has devoted most of his time in searching for a scalable parallel program execution/architecture model that can serve as a basis for high-end parallel supercomputers. To this end, Professor Gao has many research publications in these fields. He is an active participant in professional activities. Dr. Guang R. Gao received his Ph.D. degrees in Electrical Engineering and Computer Science from the Massachusetts Institute of Technology. Currently, he is a Professor in the Department of Electrical and Computer Engineering at University of Delaware, where he has been the founder and director of the Computer Architecture and Parallel Systems Lab, and the Director of the Bioinformatics Center at Delaware Biotechnology Institute (2001-2004). Prior to the above, he has been a faculty member of the School of Computer Science at McGill University, Montreal, Canada. Born in Beijing, Gao is among the first wave of graduate students from People's Republic of China to attend graduate school in the U.S. in the early 1980s. In fact, he is the first student from PRC to receive a MS and Ph.D. degree in Computer Science from MIT. Proceedings of the 19th IEEE International Parallel and Distributed Processing Symposium (IPDPS’05) 1530-2075/05 $ 20.00 IEEE	bioinformatics;blue gene;crc-based framing;compiler;computation;computational biology;computer architecture;computer engineering;computer science;consistency model;dataflow;dynamic compilation;flops;high productivity computing systems;international parallel and distributed processing symposium;multithreading (computer architecture);parallel computing;petascale computing;requirement;scalability;sketch;software design;supercomputer	Guang R. Gao	2005		10.1109/IPDPS.2005.415	parallel processing;synchronization;computer architecture;parallel computing;concurrent computing;computer science;theoretical computer science;operating system;distributed computing;programming language	HPC	-8.48117910904774	33.64088569745615	129672
361ddad9516449260b027a9891780aac1c136a6b	architectural considerations for next-generation file systems	integrated systems;evaluation performance;architecture systeme;performance evaluation;systeme multimedia;evaluacion prestacion;reseau ordinateur;resource management;menu;systeme integre;sistema integrado;system performance;multimedia systems;network file system;computer network;gestion recursos;operating system;file system;scheduling;integrated services networks;red ordenador;multimedia workloads;next generation;gestion ressources;arquitectura sistema;ordonamiento;serveur fichier;system architecture;integrated system;ordonnancement;file server;file systems	We evaluate two architectural alternatives—partitioned and integrated—for designing next generation file systems. Whereas a partitioned server employs a separate file system for each application class, an integrated file server multiplexes its resources among all application classes; we evaluate the performance of the two architectures with respect to sharing of disk bandwidth among the application classes. We show that although the problem of sharing disk bandwidth in integrated file systems is conceptually similar to that of sharing network link bandwidth in integrated services networks, the arguments that demonstrate the superiority of integrated services networks over separate networks are not applicable to file systems. Furthermore, we show that: (i) an integrated server outperforms the partitioned server in a large operating region and has slightly worse performance in the remaining region, (ii) the capacity of an integrated server is larger than that of the partitioned server, and (iii) an integrated server outperforms the partitioned server by up to a factor of 6 in the presence of bursty workloads.	file server;integrated services;multiplexing;next-generation network;server (computing)	Prashant J. Shenoy;Pawan Goyal;Harrick M. Vin	1999	Multimedia Systems	10.1007/s005300100048	shared resource;self-certifying file system;embedded system;file server;real-time computing;network file system;computer science;resource management;operating system;unix file types;open;scheduling;computer network;server farm	OS	-19.11388659567576	45.867737525443154	129784
f6ec503bc446a0b6badf6274f654314657906564	a unified resource management and execution control mechanism for data flow machines	resource manager;cache memory;executive control;first order;load balance;data flow;register transfer level	This paper presents a unified resource management and execution control mechanism for data flow machines. The mechanism integrates load control, depth-first execution control, cache memory control and a load balancing mechanism. All of these mechanisms are controlled by such basic information as the number of active state processes, Na. In data flow machines, synchronization among processes is an essential hardware function. Hence, Na can easily be detected by the hardware. Load control and depth-first execution control make it possible to execute a program with a designated degree of parallelism, and depth-first order. A cache memory of data flow processors in multiprocessing environments can be realized by using load and depth-first execution controls together with a deterministic replacement algorithm, i.e. replacement of only waiting state processes. A new load balancing method called group load balancing is also presented to evaluate the above mentioned mechanisms in multiprocessor environments. These unified control mechanisms are evaluated on a register transfer level simulator for a list-processing oriented data flow machine.	breadth-first search;cpu cache;central processing unit;content-control software;control flow;control system;dataflow architecture;degree of parallelism;depth-first search;design for manufacturability;high-level programming language;load balancing (computing);load management;multiprocessing;numerical aperture;page replacement algorithm;parallel computing;process (computing);register-transfer level;simulation;software system;working set size	Masaru Takesue	1987		10.1145/30350.30361	data flow diagram;computer architecture;parallel computing;real-time computing;cpu cache;computer science;load balancing;resource management;operating system;first-order logic;distributed computing;register-transfer level	OS	-15.101602705391631	41.25185260751551	129808
1ab7dc189f295eb5c976c876b7c00b5f6bbb26c7	multicore and accelerator development for a leadership-class stellar astrophysics code	openacc;gpu;openmp;supernovae;stellar astrophysics	We describe recent development work on the core-collapse supernova code CHIMERA. CHIMERA has consumed more than 100 million cpu-hours on Oak Ridge Leadership Computing Facility (OLCF) platforms in the past 3 years, ranking it among the most important applications at the OLCF (1). Most of the work described has been focused on exploiting the multicore nature of the current platform (Jaguar) via, e.g., multithreading using OpenMP. In addition, we have begun a major effort to marshal the computational power of GPUs with CHIMERA. The impending upgrade of Jaguar to Titan --- a 20+ PF machine with an NVIDIA GPU on many nodes --- makes this work essential.	multi-core processor;stellar (payment network)	O. E. Bronson Messer;James Austin Harris;Suzanne Parete-Koon;Merek A. Chertkow	2012		10.1007/978-3-642-36803-5_6	parallel computing;computer hardware;supernova;operating system	EDA	-7.790887775900858	40.280200518881124	129835
b226008c33ab1fe1930764f7ece793255e4c948b	massively parallel simulations of spread of infectious diseases over realistic social networks		Controlling the spread of infectious diseases in large populations is animportant societal challenge. Mathematically, the problem is best captured as acertain class of reaction-diffusion processes (referred to as contagionprocesses) over appropriate synthesized interaction networks. Agent-basedmodels have been successfully used in the recent past to study such contagionprocesses. We describe EpiSimdemics, a highly scalable, parallel code writtenin Charm++ that uses agent-based modeling to simulate disease spreads overlarge, realistic, co-evolving interaction networks. We present a new parallelimplementation of EpiSimdemics that achieves unprecedented strong and weakscaling on different architectures – Blue Waters, Cori and Mira. EpiSimdemicsachieves five times greater speedup than the second fastest parallel code inthis field. This unprecedented scaling is an important step to support the longterm vision of real-time epidemic science. Finally, we demonstrate the capabilities of EpiSimdemics by simulating thespread of influenza over a realistic synthetic social contact network spanningthe continental United States (~280 million nodes and 5.8 billion social contacts).	agent-based model;blue waters;computer simulation;fastest;image scaling;köppen climate classification;parallel computing;population;real-time clock;scalability;social network;speedup;synthetic intelligence	Abhinav Bhatele;Jae-Seung Yeom;Nikhil Jain;Chris J. Kuhlman;Yarden Livnat;Keith R. Bisset;Laxmikant V. Kalé;Madhav V. Marathe	2017	2017 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)		scaling;scalability;massively parallel;discrete event simulation;newsql;speedup;social network;computer science;distributed computing	HPC	-6.519930579992565	34.56510151693898	129897
ab75d9f2b13fdc62d0202f8b44e642bf6c636bf7	risc-based architectures for multiple robot systems		Several approaches to multiple robot system control a r e discussed. In order to simplify the study a multilayered model is proposed: a control layer which directly acts on the dynamics of the manipulators, a coordination/ communication layer which makes all the manipulators work together and a programming layer which interfaces with the user. For the first layer two architectural altematives are studied: a centralized single processor system and a distributed multiprocessor with static task assignmenL For the second case an implementation based on the i960 family of RISC processors is introduced. For the second layer three possibilities are considered: serial interface, parallel bus and local area network. The latter is carefully studied and a low cost alternative to the standard deterministic network MAP is introduced. This cell network is based on the CSMA/DCR protocol implemented on the i82596 coprocessor. Two alternatives are discussed for the programming layer: a parallel programming language based on a scene approach and a C extended language used to program elementary tasks in a robot independent way coupled with an intelligent scheduler used to assign these tasks to the robot arms at run time.	central processing unit;centralized computing;coat of arms;coprocessor;intel i960;multiprocessing;parallel computing;parallel port;parallel programming model;programming language;robot;run time (program lifecycle phase);scheduling (computing);serial communication	Gabriel Jiménez-Moreno;José Luis Sevillano;Antonio Abad Civit Balcells;Fernando Díaz del Río;Antón Civit-Breu	1992	Microprocessors and Microsystems - Embedded Hardware Design	10.1016/0141-9331(92)90020-T	embedded system;parallel computing;real-time computing;telecommunications;computer science;operating system;distributed computing;programming language;algorithm;computer network	Robotics	-11.755898016837703	45.43456188933587	129941
a724da58aa5df7731d94497bd764a599f44009c5	icnc international conference on parallel processing in neural systems and computers	parallel processing			Patrick Thomas	1990	KI		theoretical computer science;parallel processing;computer science	Robotics	-9.386541052260295	41.48710122835428	129953
61340bbbd9765de7b46ce1a545ab253c86fd954c	parallel solution of high speed low order fdtd on 2d free space wave propagation	distributed memory;fdtd method;parallel algorithm;numerical method;finite difference time domain;finite difference method;distributed memory multiprocessor;message passing interface;wave propagation;high speed	Finite Difference Time-Domain (FDTD) is one of the most widely used numerical method for solving electromagnetic problems. Solutions for these problems are computationally expensive in terms of processing time. Recently, we develop a method, High Speed Low Order FDTD (HSLO-FDTD) that is proven to solve one dimensional electromagnetic problem with a reduction of 67% of processing time from the FDTD method. In this paper, we extend the method to solve two dimensional wave propagation problem. Since the problem is large, we develop the parallel version of HSLO-FDTD method on distributed memory multiprocessor machine using message-passing interface. We examine the parallelism efficiency of the algorithm by analyzing the execution time and speed-up.		Mohammad Khatim Hasan;Mohamed Othman;Zulkifly Abbas;Jumat Sulaiman;Fatimah Ahmad	2007		10.1007/978-3-540-74477-1_2	finite-difference time-domain method;parallel computing;distributed memory;numerical analysis;wave propagation;computer science;finite difference method;message passing interface;theoretical computer science;distributed computing;parallel algorithm	HPC	-4.613641862756394	36.93974305246709	129969
2e7735636ff79a765ee4656c073d30b68a7c445e	replication, load balancing and efficient range query processing in dhts	tratamiento datos;tolerancia falta;hachage;distributed system;replication;base donnee;sobrecarga;systeme reparti;range query;localite;fault tolerant;query processing;distributed hash table;distribucion carga;geometrie algorithmique;equilibrio de carga;par a par;traitement requete;interrogation base donnee;computational geometry;equilibrage charge;database;interrogacion base datos;base dato;data processing;locality;traitement donnee;data replication;replicacion;busquedas dentro de un rango;hashing;sistema repartido;requete a intervalle;poste a poste;surcharge;replicated data;fault tolerance;data access;load balancing;distribution charge;load distribution;geometria computacional;load balance;tratamiento pregunta;hash function;overload;peer to peer;database query;tolerance faute	We consider the conflicting problems of ensuring data-access load balancing and efficiently processing range queries on peer-to-peer data networks maintained over Distributed Hash Tables (DHTs). Placing consecutive data values in neighboring peers is frequently used in DHTs since it accelerates range query processing. However, such a placement is highly susceptible to load imbalances, which are preferably handled by replicating data (since replication also introduces fault tolerance benefits). In this paper, we present HotRoD, a DHT-based architecture that deals effectively with this combined problem through the use of a novel locality-preserving hash function, and a tunable data replication mechanism which allows trading off replication costs for fair load distribution. Our detailed experimentation study shows strong gains in both range query processing efficiency and data-access load balancing, with low replication overhead. To our knowledge, this is the first work that concurrently addresses the two conflicting problems using data replication.	load balancing (computing)	Theoni Pitoura;Nikos Ntarmos;Peter Triantafillou	2006		10.1007/11687238_11	fault tolerance;real-time computing;hash function;data processing;computational geometry;computer science;load balancing;operating system;database;distributed computing	DB	-18.798125641914293	45.7519403271843	130462
019cdbdd612d39510f7720c977a16657d5c999e4	synchronizing shared memory in the sequoia fault-tolerant multiprocessor	shared memory;fault tolerant		multiprocessing;shared memory	Philip A. Bernstein	1985			synchronizing;distributed computing;parallel computing;computer science;distributed memory;fault tolerance;multiprocessing;sequoia;shared memory;distributed shared memory	HPC	-10.440795086072306	42.95405502698602	130488
ed871a6d918ff8bc0d03e61bf7171a58427a10a5	zoltan data management services for parallel dynamic applications	application development;software libraries;resource allocation;object based interface zoltan library data management services parallel dynamic applications unstructured applications adaptive applications open source software load balancing data movement unstructured communication memory usage adaptive finite element methods particle methods crash simulations;storage management;data management;parallel algorithms resource allocation storage management software libraries;particle method;algorithm theory;data structures;load balance;computer software;data handling;adaptive finite element method;data structure;open source software application software software libraries packaging machines parallel programming partitioning algorithms memory management testing educational institutions;open source software;parallel algorithms	The Zoltan library is a collection of data management services for parallel, unstructured, adaptive, and dynamic applications that is available as open-source software. It simplifies the load-balancing, data movement, unstructured-communication, and memory usage difficulties that arise in dynamic applications such as adaptive finite-element methods, particle methods, and crash simulations. Zoltan's data-structure-neutral design also lets a wide range of applications use it without imposing restrictions on application data structures. Its object-based interface provides a simple and inexpensive way for application developers to use the library and researchers to make new capabilities available under a common interface.		Karen D. Devine;Erik G. Boman;Robert T. Heaphy;Bruce Hendrickson;Courtenay T. Vaughan	2002	Computing in Science and Engineering	10.1109/5992.988653	computational science;parallel computing;simulation;data structure;resource allocation;computer science;load balancing;theoretical computer science;operating system;group method of data handling;data mining;database;parallel algorithm;programming language;rapid application development;management	DB	-10.02735551422746	37.668038538117436	130594
4a6f767f663c6958c2023511f5e0a7d7ff6597a6	a network of microprocessors to execute reduction languages, part i	processor architecture;linear array;interconnection network;computer architecture;tree structure;high level language;functional programming language;parallel processing	This paper describes the architecture of a cellular processor capable of directly and efficiently executing reduction languages as defined by Backus. The processor consists of two interconnected networks of microprocessors, one of which is a linear array of identical cells, and the other a tree-structured network of identical cells. Both kinds of cells have modest processing and storage requirements. The processor directly interprets a high-level language, and its efficient operation is not restricted to any special class of problems. Memory space permitting, the processor accommodates the unbounded parallelism allowed by reduction languages in any single user program; it is also able to execute many user programs simultaneously.	computational resource;high- and low-level;high-level programming language;microprocessor;parallel computing;requirement	Gyula A. Magó	1979	International Journal of Computer & Information Sciences	10.1007/BF00995174	parallel processing;computer architecture;parallel computing;microarchitecture;computer science;operating system;tree structure;programming language;high-level programming language;algorithm	Arch	-13.329215902240293	40.729681074446766	130627
cbfa51583e43019c03f29c201bdd4079977a997c	parallel simulation of orography influence on large-scale atmosphere motion on apemille	atmospheric motions;data distribution;large scale;parallel computer;atmospheric physics;communication cost;parallel machines;register file;fortran;apemille;porting;parallel simulation	The experience described in this paper relates to the implementation on the parallel computer APEmille of a model for large-scale atmosphere motion, originally developed in Fortran for a conventional architecture. The most critical aspects of this work are described: the mapping of a bidimensional problem on the tridimensional thoroidal architecture of the parallel machine, the choice of a data distribution strategy that minimizes the internode communication needs, the definition of an algorithm for internode communication that minimizes communication costs by performing only first neighbour communications, and the implementation of machine dependant optimizations that allowed to exploit the pipelined architecture of the APEmille processing node and the large register file. An analysis of the performances is reported, compared to both the APEmille peak performance and to the performance on other conventional sequential architectures. Finally, a comparison with the original physical results is presented.	algorithm;fortran;parallel computing;performance;register file;simulation	M. Francia;E. Panizzi;A. Petricola;G. Visconti	2004		10.1145/977091.977137	parallel computing;simulation;computer science;theoretical computer science	HPC	-5.751695812093815	36.97471650773513	130669
d7aaec00a48082454519fa5af1a5178ae640270a	compiling atr probing codes for execution on fpga hardware	optimising compilers;image recognition;computer languages;reconfigurable system;optimizing compiler;application software;reconfigurable architectures;probes;fpga hardware atr reconfigurable system optimizing compiler sa c programming language highlevel language automatic target recognition;c language;target recognition;field programmable gate arrays hardware probes optimizing compilers application software target recognition table lookup circuit testing computer languages image recognition;automatic target recognition;atr;sa c programming language;circuit testing;c programming language;field programmable gate arrays;table lookup;optimizing compilers;reconfigurable architectures optimising compilers c language field programmable gate arrays;highlevel language;fpga hardware;hardware	"""This paper describes the implementation of an automatic target recognition (ATR) Probing algorithm on a reconfigurable system, using the SA-C programming language and optimizing compiler. The reconfigurable system is 800 times faster than a comparable Pentium running a a implementation of the same probing task. The reasons for this are analyzed. ues exceeds a threshold, answering the question: """"Does this pixel straddle a boundry?"""" A probeset depicts the silhouette of an object viewed from a particular viewpoint. When a probeset is placed in the correct image location over an object, most of its probes should return true. When a probing algorithm is applied to an image to recognize targets, each probeset is evaluated at every image position, and the location and identity of the highest scoring probeset is returned. The exhaustive application of probesets for all possible objects, viewing angles, and image positions is a computation that it is ripe for optimization. It is therefore both an algorithm of considerable practical interest and a powerful demonstration of what can be done using FPGAs and the SA-C compiler. Here is a pseudo code version of the Probing algorithm. 1. SA-C and Probing for each yindoy in image { best-score, probe-set-index = for all probe-sets { hit-count = for each probe in probe-set return(sum(threshold(probe))) score = hit-count/probe-set-size } return(max(score),probe-set-index) } return(array(best-score),array(probe-set-index)) The two inner loops computing the scores and probeset indices can be fully unrolled, because the probesets are statically known. This turns the code into a singly nested loop driven by one window generator. The loop body becomes an expression consisting of threshold operators computing hits, sum trees adding the hits for each probeset, division operators computing the scores for each probeset, and max trees selecting the winner. This giant expression allows for standard and temporal CSE. The computation of the score of a probeset in a window requires the hit count to be divided by the probeset size. Floating point division is replaced by a table lookup that maps hit counts and probeset sizes onto ranks. Scores below a threshold (e.g. 80%) can be given rank zero. This reduces the number of bits in the rank, and therefore the size of the lookup table. The test suite for the probing application consists of three vehicles (an M60 tank, an Ml13 armored perThe goal of the Cameron project is to make application development on FPGAs easier by raising the abstraction level from hardware circuits to software algorithms. To this end, we have developed a highlevel language, similar to C, called SA-C, and an optimizing compiler that maps SA-C programs directly onto FPGA configurations. More information on SAC, its compiler, and other applications can be found at www .cs.colostate.edu/ cameron. SA-C is a single assignment language with data parallel loop constructs allowing for allowing easy detection of expression level and loop level parallelism. The SA-C compiler performs both conventional and FPGA-specific optimizations. Full or partial loop unrolling spreads iterations in code space rather than in time. Array value propagation replaces array references with constant indices with the array elements. The SA-C compiler not only performs standard common sub-espression elimination (CSE), but also tempoml CSE, replacing a computation in one loop iteration with a result computed in a previous iteration. This paper compares the timing of the probing algorithm written in SA-C and running on an AMS WildStar board with a C code version of the same algorithm running on a Pentium PC. A probe is a pair of pixels and an associated true/false question. Typically, a probe returns true when the absolute value of the difference in pixel val*This work is supported by DARPA under US Air Force Research Laboratory contract F33615-98-C-1319. Proceedings of the 10 th Annual IEEE Symposium on Field-Programmable Custom Computing Machines (FCCM’02) 1082-3409/02 $17.00 © 2002 IEEE Table 1. DFG level statistics: Probes, Additions, Window sizes before and after optimization For the configuration generated by the SA-C compiler for the probing algorithm, the FPGAs run at 41.1 MHz. The program is completely memory 10 bound: every clock cycle each FPGA reads one 32 bit word, containing two 12 bit pixels. As there are {512 -13 + 1) * {1024) 13 pixel columns to be read {see table 1), the FPGAs perform {51213 + 1) * {1024) * {13/2) = 3, 328,000 reads. At 41.1 MHz this takes 80.8 milliseconds. The Pentium performs {512-13+ 1)*{1024-34+1) window accesses. Each of these window accesses involves 7573 threshold operations. Hence the inner loop that performs one threshold operation is executed {512 -13 + 1) * {102434 + 1) * 7573 = 3,752, 421, 500 times. Using the optimizing VC++ compiler, the inner loop takes 16 instructions {much better than the 22 instructions gcc -06 produces). The total number of instructions executed in the inner loop is therefore 3, 752,421, 500 * 16 = 60, 038,744,000. If one instruction were executed per cycle,this would bring the execution time to about 75 seconds. As the execution time of the whole program is 65 seconds, the Pentium {a super scalar architecture) is actually executing more than one instruction per cycle! The factors contributing to the speed difference between the Wildstar and the Pentium can be broken down as follows. {1) Analysis and optimization: the compiler has reduced the number of probes nineteen fold. {2) Coarse grain parallelism: the Wildstar executes three processes, each process corresponding to a vehicle, in parallel without any interference. {3) Massive fine grain parallelism: each FPGA performs all its threshold operations, hit summations, table lookups, and comparisons in parallel, whereas the Pentium performs slightly more than one instruction per cycle. {4) Clock frequency: the Pentium runs at a 20 times higher clock rate than the FPGAs. It can be argued that an optimizing and parallelizing compiler for a parallel von Neumann machine could achieve the same improvements in terms of the first two factors: analysis and optimization, and coarse grain parallelism. However, the largest factor, the fine grain parallelism, is a defining FPGA characteristic."""	12-bit;32-bit;abstraction layer;algorithm;answer to reset;assignment (computer science);automatic target recognition;clock rate;clock signal;column (database);computation;control flow;data parallelism;field-programmable gate array;inner loop;instructions per cycle;interference (communication);iteration;like button;lookup table;loop unrolling;loop-level parallelism;map;mathematical optimization;optimizing compiler;parallel computing;pixel;programming language;pseudocode;reconfigurable computing;run time (program lifecycle phase);sa-c (programming language);sac;software propagation;test suite;ues (cipher);vhdl-ams;von neumann architecture;window function;world wide web	A. P. Wim Böhm;J. Ross Beveridge;Bruce A. Draper;Charlie Ross;Monica Chawathe;Walid A. Najjar	2002		10.1109/FPGA.2002.1106693	embedded system;computer architecture;application software;parallel computing;computer science;operating system;optimizing compiler;programming language;field-programmable gate array;automatic target recognition	Arch	-13.978496944980488	34.74563453425796	130688
960084839cf9f6bf9cdf2c3e71cf9e6334335d10	concurrent maintenance of data structures in a distributed environment	distributed system;evaluation performance;systeme reparti;performance evaluation;multiprocessor;maintenance;implementation;evaluacion prestacion;sistema informatico;computer system;sistema n niveles;algorithme;algorithm;ejecucion;algorritmo;sistema repartido;distributed environment;systeme n niveaux;estructura datos;concurrency control;multilevel system;mantenimiento;structure donnee;systeme informatique;controle concurrence;control concurrencia;multiprocesador;data structure;multiprocesseur	Developpement d'un code pour les processus en premier plan et en arriere-plan faisant intervenir l'approche «concurrence grossiere-concurrence finie» de Dijkstra et les conditions de Jones		Farokh B. Bastani;S. Sitharama Iyengar;I-Ling Yen	1988	Comput. J.	10.1093/comjnl/31.2.165	multiprocessing;data structure;computer science;artificial intelligence;concurrency control;programming language;implementation;algorithm;distributed computing environment	Theory	-18.814388802541536	41.92443372339124	130695
04e8857f580e81a52b6e379e57e862d323d8d7f9	parallel networking and visualization on the connection machine cm-5	multiprocessor interconnection networks;data parallel;unix compatible networking architecture;interprocess communication;bandwidth computer networks hardware process control data visualization multiprocessor interconnection networks network interfaces communication system control broadcasting throughput;graphical user interfaces computer networks data visualisation;ethernet;computer networks;data visualisation;visualization;network interfaces;fddi;graphical user interfaces;hippi;data visualization;parallel x window parallel networking unix compatible networking architecture visualization connection machine cm 5 hippi fddi ethernet interprocess communication system;connection machine cm 5;process control;parallel x window;bandwidth;network architecture;parallel networking;broadcasting;communication system control;throughput;hardware;interprocess communication system	The Connection Machine CM-5 supports a Unix-compatible, data-parallel, transparent networking architecture to send parallel data over HIPPI, FDDI and Ethernet. CM-5 and serial computer processes can now all commulzicate simply and efficiently with each othel: This interprocess communication system has been proven useful for parallel X Kndow drawing support and parallel data visualization systems such as AVS.	advanced visualization studio;connection machine;data visualization;hippi;inter-process communication;serial computer;transparent network substrate;unix	Gary Oberbrunner	1992		10.1109/HPDC.1992.246485	embedded system;throughput;parallel computing;network architecture;visualization;computer science;network interface;operating system;graphical user interface;distributed computing;ethernet;broadcasting;data visualization;bandwidth;computer network;fiber distributed data interface;inter-process communication	HPC	-12.007621667281684	44.731858175256214	130711
32fd46d9c1a4bbb52dcf515af16dc5c424729ed6	sequential file processing in fortran	dos;sequential files;fortran	Abstract#R##N##R##N#The standard I/O facility for sequential disk/tape file handling in a Fortran IV IBM 360/370 Disk Operating System environment has some marked shortcomings, the most serious of which is that blocking of records is not provided for.#R##N##R##N##R##N##R##N#This paper describes SAMFOR4 (Sequential Access Method in Fortran IV), a set of Fortran callable subprograms and a file declaration facility that enables the Fortran programmer to access and create ‘standard’ sequential files. Thus inter language compatibility of files is obtained. A manyfold increase in effectiveness may also be achieved.	fortran	Oddur Benediktsson	1977	Softw., Pract. Exper.	10.1002/spe.4380070510	parallel computing;disk operating system;computer science;operating system;programming language	HPC	-18.64093624086146	40.462211938844526	130720
cf772ffaa91d3ace50ad23dff53379fe05891ed3	performance analysis and optimization of a parallel carbon molecular dynamic code on a cray t3e	load sharing techniques;processing element;performance analysis concurrent computing physics chromium computer science astronomy microwave integrated circuits identity based encryption electronic switching systems nanotubes;microwave integrated circuits;cray t3e;concurrent computing;performance evaluation;nanotubes;identity based encryption;collective communication;physics;molecular dynamics method;chromium;performance evaluation molecular dynamics method parallel algorithms;performance analysis;load sharing;quantitative analysis;electronic switching systems;molecular dynamic;optimization;amdahl s law;parallel implementation;mpi collective communications implementation performance analysis optimization parallel carbon molecular dynamic code cray t3e load sharing techniques amdahl s law quantitative analysis;astronomy;computer science;parallel carbon molecular dynamic code;mpi collective communications implementation;parallel algorithms	An analysis of the primary factors influencing the performance of a parallel implementation on a Cray T3E of a Carbon Molecular Dynamics code developed at Department of Physics and Astronomy at Michigan State University is presented. We show that classical load-sharing techniques combined with careful analysis of Amdahl's law can be successfully used to significantly increase the performance of the code. This report describes the quantitative analysis of these factors and the solutions used to diminish or eliminate their effects. By slightly modifying the code we reduced its sequential portion to less than 0.1%. We also demonstrate that the MPI collective communications implementation on the Cray T3E dramatically reduces the communication overhead for our code. In the end, a speedup of 170 was obtained using 256 Cray T3E processing elements. These results create the prospect of simulating the dynamics of 1,000-atom nanotubes in the microsecond regime (/spl ap/1,000,000 time steps).		Mihai Horoi;Richard J. Enbody	1998		10.1109/ICPP.1998.708464	computational science;chromium;parallel computing;concurrent computing;computer science;quantitative analysis;theoretical computer science;operating system;programming language	HPC	-5.321831160911624	37.26946287821346	130751
22044846c77ed073c18cdad326bd443df048d4fe	divided we stand: parallel distributed stack memory management	memory management	"""We present an overview of the stack-based memory management techniques that we used in our non-deterministic and-parallel Prolog systems: &-Prolog and DASWAM. We believe that the problems associated with non-deterministic and-parallel systems are more general than those encountered in or-parallel and deterministic and-parallel systems, which can be seen as subsets of this more general case. We develop on the previously proposed """"marker scheme"""", lifting some of the restrictions associated with the selection of goals while keeping (virtual) memory consumption down. We also review some of the other problems associated with the stack-based management scheme, such as handling of forward and backward execution, cut, and roll-backs."""	deterministic algorithm;lambda lifting;memory management;nondeterministic algorithm;parallel computing;prolog;stack-oriented programming language;stacking;warren abstract machine	Kish Shen;Manuel V. Hermenegildo	1993			stack trace;real-time computing;region-based memory management;call stack;computer science;theoretical computer science;algorithm	OS	-18.567709879315007	32.81055365371898	130972
b4296b19f9f5bc10c9b6a9500aa8daeee167b21f	interfacing computer aided parallelization and performance analysis	interfaces;prototypes;cycles;performance analysis;parallel computer;reliability analysis;parallel computers;computer techniques;source code;architecture computers;program development;sequential computers	When porting sequential application_ to parallel computer architectures, the program developer will typically go through several cycles of source code optimization and performance analysis. We have started a project to develop an environment where the user can jointly navigate through program structure and performance data information in order to make efficient optimization decisions. In a prototype implementation we have interfaced the CAPO computer aided parallelization tool with the Pazaver performance analysis too[. We describe both tools and their interface and give an example for how the interface helps within the program development cycle of a benchmark code.	automatic parallelization;benchmark (computing);computer architecture;mathematical optimization;parallel computing;profiling (computer programming);program optimization;prototype;software development process;structured programming	Gabriele Jost;Haoqiang Jin;Jesús Labarta;Judit Giménez	2003		10.1007/3-540-44864-0_19	computational science;computer architecture;human–computer interaction;computer science;operating system;interface;prototype;programming language;source code	HPC	-11.402548039034999	37.56711961583484	131016
324c03b0e2c9f8c16747c1e988b1b16f3acb442e	parallelization of adaptive grid domain mappings	adaptive grid domain mappings		adaptive mesh refinement;automatic parallelization;parallel computing	Calvin J. Ribbens	1987			parallel computing;grid;computer science	HPC	-6.591762113686189	38.66005414418128	131125
58ea6a2614f5e194607cbf08c942e93f5d6478f7	performance analysis of the cache conscious-generalized search tree	arbre recherche;evaluation performance;cache conscious tree;performance evaluation;pointer compression;evaluacion prestacion;index structure;cache memory;key compression;antememoria;search trees;antememoire;marcador;pointer;arbol investigacion;generalized search tree;performance analysis;arbre minimal;pointeur;arbol minimo;search tree;minimal tree	Recently, a main memory index structure called the cache conscious-generalized search tree (CC-GiST) was proposed. The CC-GiST is such a novel index structure that it can be used for implementing all the existing cache conscious trees with the minimal efforts. It incorporates the pointer compression and the key compression techniques, which were adopted by the existing cache conscious trees to reduce the cache misses, in a single framework. In this paper, we formally analyze the performance of the CC-GiST. We compare the performance of the CC-GiST with the existing cache conscious trees. The result shows that the CC-GiST has the negligible overhead for supporting all the existing cache conscious trees in a single framework, and the performance of the tree is almost unaffected.	gist;profiling (computer programming);search tree	Won-Sik Kim;Woong-Kee Loh;Wook-Shin Han	2006		10.1007/11758532_85	bus sniffing;least frequently used;cache-oblivious algorithm;parallel computing;cache coloring;pointer;cpu cache;cache;computer science;write-once;theoretical computer science;cache invalidation;database;smart cache;search tree;programming language;cache algorithms;cache pollution	Logic	-16.929704703289882	45.40663447037438	131162
2d0059b098e96f26f2e744b798468b64cc80e70d	porting applications with openmp using similarity analysis		Computer architecture has undergone dramatic changes due to technology innovation. Some emerging architectures, such as GPUs and MICs also have been successfully used for parallel computation in the today’s HPC field. Nowadays, people frequently have to port application to a new architecture or system and to expand its functionality for a better performance while in the meantime to meet the new hardware environment need. However, many scientific application legacy codes have a relative large size and long development cycle,so it’s a very challenging job to port legacy codes to a new environment. And current codes porting process is a manual, time-consuming, expensive and error-prone process, which requires a team of people work together. Barely any useful tools can be used to ease the porting process in High Performance Computing (HPC). In this paper, we present a tool called Klonos, which is designed for assisting scientific application porting. Based on similarity analysis of code syntax and cost-model provided metrics, we are able to find codes which can be optimized similarly without the need of profiling the codes. The proposed porting plan can systematically guide users for selecting subroutines in a way which maximizes the reuse of similar porting strategy. We evaluate Klonos by applying it to a real scientific application porting to a shared memory environment using OpenMP. According to our experiment result, which shows that Klonos is very accurate to detect similar codes which can be ported similarly.	code;cognitive dimensions of notations;computation;computer architecture;data mining;directive (programming);graphical user interface;graphics processing unit;openacc;openmp;parallel computing;sensor;shared memory;subroutine	Wei Ding;Oscar R. Hernandez;Tony Curtis;Barbara M. Chapman	2013		10.1007/978-3-319-09967-5_2	computational science;parallel computing;programming language	HPC	-5.878130797511757	43.812072676334864	131411
0540e8629eb8079344b149c5a89c438dc8dddbf5	characterizing i/o performance using the tau performance system.		TAU is an integrated toolkit for performance instrumentation, measurement, and analysis. It provides a flexible, portable, and scalable set of technologies for performance evaluation on extreme-scale HPC systems. This paper describes alternatives for I/O instrumentation provided by TAU and the design and implementation of a new tool, tau_gen_wrapper, to wrap external libraries. It describes three instrumentation techniques preprocessor based substitution, linker based instrumentation, and library preloading based replacement of routines. It demonstrates this wrapping technology in the context of intercepting the POSIX I/O library and its application to profiling I/O calls for the Global Cloud Resolution Model (GCRM) application on the Cray XE6 system. This scheme allows TAU to track I/O using linker level instrumentation for statically linked executables and attribute the I/O to specific code regions. It also addresses issues encountered in collecting the performance data from large core counts and representing this data to correctly identify sources of poor I/O	cray xe6;executable;ibm websphere extreme scale;input/output;library (computing);linker (computing);posix;performance evaluation;preprocessor;profiling (computer programming);scalability;static build;static library;wrapping (graphics)	Sameer Shende;Allen D. Malony;Wyatt Spear;Karen Schuchardt	2011		10.3233/978-1-61499-041-3-647	linker;cloud computing;scalability;parallel computing;computer science;profiling (computer programming);input/output;executable;preprocessor;posix	HPC	-18.398684639806707	39.17176111639814	131476
0ca6aa60e5e6635e7311b2df48ee4d9df6b4e1bc	overture: an object-oriented software system for solving partial differential equations in serial and parallel environments	curvilinear coordinates;finite volume method;partial differential equation;o codes;adaptive mesh refinement;differential equation;informing science;object oriented software;finite difference;finite element method;finite difference method;partial differential equations;object oriented;99 mathematics computers information science management law miscellaneous;parallel implementation;parallel architecture;mesh generation;data structure;parallel processing;mathematics computers information science management law miscellaneous	The OVERTURE Framework is an ob ject-oriented environment for solving PDEs on serial and parallel architectures. It is a collection of C++ libraries that enables the use of finite difference and finite volume methods at a level that hides the details of the associated data structures, as well its the details of the parallel implementation. It is based on the A++/P++ array class library and is designed for solving problems on a structured grid or a collection of structured grids. In particular, it can use curvilinear grids, adaptive mesh refinement and the composite overlapping grid method to represent problems with complex moving geometry. 1 htroduction The OVERTURE Framework is an object-oriented C++ library for solving partial differential equations (PDEs) on serial and parallel architectures. It supports finite difference and finite volume computations on a structured grid, or on a collection of structured grids. Collections of structured grids are used, for example, in the method of composite overlapping grids, with block-structured adaptive mesh refinement (AMR) algorithms, and for patched-based domain decomposition methods. This paper concentrates on the implementation of support for two of the higher-level application environments, which are the method of composite overlapping grids 17,141 and the AMR method [I, 3,171. A composite overlapping grid consists of a set of logically rectangular (in 2-D) or hexahedral (in 3-D) curvlinear computational grids that overlap where they meet and together are used to describe a computational region of arbitrary complexity. This method has been used successfully over the last decade and a half, primarily to solve problems involving fluid flow in complex, often dynamically moving, geometries [3, 5, 9, 10, 211. The data structures associated with a flexible overlapping grid solver can be quite complex. Mathematically, each component grid can be described in terms of a transformation from the unit square or cube to the coordinate space of that grid. In order to complete the description of the computational geometry, the overall composite grid also requires information specifying how the component grids communicate with each other e.g. through interpolation formulas. It is also possible for component grids to move with respect to each other as part of a time-dependent simulation. Thus, tools are required to efficiently 'This work supported by the U.S. Department of Energy through Contract W-7405-ENG-36. +Computing, Information and Communications Division, Los Aiamos National Laboratory, Los Aiamos, NM. Web site: http://wv.c3.lanl.gov/cicl9/teams/napc/	adaptive multi-rate audio codec;adaptive mesh refinement;algorithm;c++;computation;computational geometry;data structure;domain decomposition methods;finite difference;finite volume method;glossary of sudoku;hexahedron;interpolation;library (computing);log-structured file system;numerical partial differential equations;refinement (computing);regular grid;simulation;software system;solver	David L. Brown;Geoffrey S. Chesshire;William D. Henshaw;Daniel J. Quinlan	1997			mathematical optimization;computer science;theoretical computer science	HPC	-8.507662457194407	36.68012162620443	131620
2ac70a0f98f266732366c217bbc7c6fc1ac2e052	using load information in work-stealing on distributed systems with non-uniform communication latencies	irregular d;adaptive cluster-aware random stealing;hierarchical stealing;random stealing;highly-irregular d;non-uniform communication latency;load information;cluster-aware random stealing;irregular divide-and-conquer;dynamic load information;c application	irregular d;adaptive cluster-aware random stealing;hierarchical stealing;random stealing;highly-irregular d;non-uniform communication latency;load information;cluster-aware random stealing;irregular divide-and-conquer;dynamic load information;c application	distributed computing;work stealing	Vladimir Janjic;Kevin Hammond	2012		10.1007/978-3-642-32820-6_17	parallel computing;computer science;theoretical computer science;distributed computing	Theory	-13.165184596338012	43.82302371996013	131641
06520597b383263a2e0c56147d65ff4dc13a1f9a	data base processor mage	hierarchical db access method;mage db access method;head disk;processor requirement;data base processor mage;dbp framework;particular emphasis;design decision;disk processor;access method	In this paper, we present the design of data base processor MAGE. This DBP is based on a hierarchical DB access method. It is composed of two microprocessors, a disk processor and a moving head disk. The processor requirements, design decisions, and architecture are discussed.  We start with an overview of DBP framework. The MAGE DB access method is then summarized. Finally, we present the design and implementation of the DBP, with a particular emphasis on the disk processor.	database;decibel;digital back-propagation;microprocessor;requirement	Gilles Berger-Sabbatel;Philippe Olivier Alexandre Navaux	1980		10.1145/800083.802693	parallel computing;real-time computing;computer hardware;computer science;access method	DB	-12.701812344541235	45.746895365818936	131658
545f755fa8ef82d81cc92e620eb384c7d8ce0f52	the development of the cross8 and hc16-186 parallel (database) computers	parallel databases;parallel systems	The development of the database computer HC16-186 is a follow up on the CROSS8 database computer. HC16-186 has a hypercube communication topology where dual port RAM modules play an important role. They are used in communication between nodes and for communication between nodes and the host computer. Each node is complete with a disk for storing database relations. Each node is programmed as if it was an independant machine. However, everything is controlled from the host computer which has a special program for controlling parallel systems.	parallel database	Kjell Bratbergsengen;Torgrim Gjelsvik	1989		10.1007/3-540-51324-8_47	massively parallel;data-intensive computing	NLP	-11.660073716811887	43.81340871055329	131826
4d131d82254b600bcee144b0e8ec3264e220696c	verifying the correctness of compiler transformations on basic blocks using abstract interpretation	compiler transformation;abstract interpretation;basic block;register allocation	We seek to develop thorough and reliable methods for testing compiler transformations by systematically generating a set of test cases, and then for each case, automatically proving that the transformation preserves correctness. We have implemented a specialized program equivalence prover for the domain of assembly language programs emitted by the Connection Machine Fortran compiler and targeted for the CM-2 massively parallel SIMD computer. Using abstract interpretation, the prover removes details such as register and stack usage, as well as explicit evaluation order within functional blocks, thereby reducing the problem to a trivial tree comparison. By performing limited loop unrolling, the prover also verifies that the compiler transformation preserves the inductive properties of simple loops. We have used this prover to successfully validate the register allocation phase of our compiler, uncovering numerous bugs without running a single test program, and without preparing sample data and expected results, which would be necessary for validation by means of running the test pro grams.	abstract interpretation;assembly language;compiler;connection machine;correctness (computer science);fortran;grams;loop unrolling;register allocation;simd;software bug;test case;turing completeness	Timothy S. McNerney	1991		10.1145/115865.115877	computer architecture;parallel computing;compiler correctness;computer science;programming language;register allocation	PL	-16.581915784075928	34.90800729759916	131845
0452aad25a8141ed781b52fd9a5acf8d14bb55d4	multiprocessing ocean circulation: modeling, implementation, and performance on the intel paragon	partial differential equation;ocean circulation;collective communication;high performance computing;partitioning;partial differential equations;high performance computer;continental shelf;scientific computing;numerical algorithms;parallel computer;parallel implementation;numerical ocean circulation;scientific computation;parallel applications	In this paper we present the modeling and implementation of a grand challenge problem in the field of scientific computation: the primitive-equation numerical ocean circulation model. We present the mathematical formulation of the model and propose a scheme for its parallel implementation. Optimizations are made through collective communications and various partitioning schemes. In our experiments, which use up to 100 processors on the Intel Paragon parallel computer, the proposed strategy yields an encouraging speedup and exhibits a sustained scalability with increasing problem and machine sizes. We consider barotropic continental shelf waves in a periodic channel as a test problem. The model has numerous applications in environmental studies and ocean sciences.	central processing unit;computation;computational science;experiment;grand challenges;intel paragon;köppen climate classification;list of ocean circulation models;multiprocessing;numerical analysis;ocean general circulation model;parallel computing;scalability;speedup	Ishfaq Ahmad;Ka-Cheong Leung;Hsiao-Ming Hsu	1997	The Journal of Supercomputing	10.1007/BF00227863	supercomputer;parallel computing;simulation;computer science;theoretical computer science;distributed computing;partial differential equation	HPC	-5.9707633005705825	38.31113458534029	131963
19fbde06c6df15bc45e2a3d4c0820f1efd4d80be	evaluating a scientific spmd application on a computational grid with different load balancing techniques	distributed system;evaluation performance;carga dinamica;haute performance;systeme reparti;regime dynamique;computational grid;performance evaluation;equilibrio de carga;evaluacion prestacion;equilibrage charge;distributed computing;charge dynamique;dynamic conditions;dynamic load;grid;dynamic environment;performance programme;sistema repartido;porous media;rejilla;load balancing;alto rendimiento;regimen dinamico;grille;calculo repartido;eficacia programa;load balance;program performance;dispersion;high performance;calcul reparti;parallel applications;dynamic loading	The performance of SPMD programs is strongly affected by dynamic load imbalancing factors. The use of a suitable load balancing algorithm is essential for overcoming the effects of these imbalancing factors. In this work, we evaluate the performance of a scientific SPMD parallel application when executed on a computational grid, with different kinds of load balancing strategies. The developed SPMD application computes the macroscopic thermal dispersion in porous media. A set of experiments was conducted on a computational grid composed by two geographically separated clusters. The main contribution of this work is the performance evaluation and comparison of a large variety of load balancing techniques under dynamic environment conditions. The experimental results showed the importance of choosing appropriate load balancing strategies when developing SPMD applications on a grid environment.		André Oliveira;Gabriel Argolo;Pablo Iglesias;Simone L. Martins;Alexandre Plastino	2005		10.1007/11533962_27	embedded system;parallel computing;real-time computing;computer science;load balancing;distributed computing;computer security	HPC	-17.2321235419041	43.462912488492975	131991
1e307b692237706d7c36556d28e5a96edc58dd44	implementing a time-driven simulation on a mimd computer using a simd language.				Michael J. Quinn;Bradley K. Seevers;Philip J. Hatcher	1992	Int. Journal in Computer Simulation		computer architecture;parallel computing;mimd;computer science;misd;programming language	Arch	-9.650565990609204	42.08571549775018	132057
a5aec39855ff1c8323efeda091b609e864954906	optimization and evaluation of parallel i/o in bips3d parallel irregular application	bips3d parallel irregular scientific application;graph theory;parallel file operations parallel i o bips3d parallel irregular scientific application 3 dimensional simulation bjt hbt bipolar devices metis graph partitioning finite element meshes sparse matrices interval data grouping data replication scheduling;software libraries;parallel file operations;interval data grouping;network operating systems;input output programs;metis;data replication;3 dimensional simulation;interval data;file systems poisson equations charge carrier processes merging application software computer science heterojunction bipolar transistors libraries finite element methods concurrent computing;electrical engineering computing;finite element mesh;graph partitioning;finite element meshes;software libraries digital simulation electrical engineering computing graph theory heterojunction bipolar transistors input output programs natural sciences computing network operating systems scheduling;scheduling;hbt bipolar devices;parallel i o;3 dimensional;natural sciences computing;heterojunction bipolar transistors;bjt;sparse matrices;digital simulation	This paper presents the optimization and evaluation of parallel I/O for the BIPS3D parallel irregular application, a 3-dimensional simulation of BJT and HBT bipolar devices. The parallel version of BIPS3D employs Metis, a library for partitioning graphs, finite element meshes, or sparse matrices. First, we show how the partitioning information provided by Metis can be used in order to improve the performance of parallel I/O. Second, we propose a novel technique, called interval data grouping (IDG), which exploits the data replication of mesh nodes for optimizing the scheduling of the parallel file operations. Finally, we evaluate the parallel I/O version of BIPS3D for various existing parallel I/O techniques and present an in-depth analysis of the IDG performance.	finite element method;input/output;load balancing (computing);locality of reference;metis;mathematical optimization;parallel i/o;parallel computing;replication (computing);scheduling (computing);simulation;sparse matrix	Rosa Filgueira;David E. Singh;Florin Isaila;Jesús Carretero;Antonio Garcia Loureiro	2007	2007 IEEE International Parallel and Distributed Processing Symposium	10.1109/IPDPS.2007.370585	three-dimensional space;parallel computing;sparse matrix;computer science;graph partition;graph theory;theoretical computer science;operating system;distributed computing;programming language;scheduling;bipolar junction transistor;algorithm;replication	HPC	-6.803985831239655	39.85253016214313	132094
6aba60624c379b63d702864d6ce61df2f0f319c7	comparing runtime systems with exascale ambitions using the parallel research kernels		We use three Parallel Research Kernels to compare performance of a set of programming models(We employ the term programming model as it is commonly used in the application community. A more accurate term is programming environment, which is the collective of abstract programming model, embodiment of the model in an Application Programmer Interface (API), and the runtime that implements it.): MPI1 (MPI two-sided communication), MPIOPENMP (MPI+OpenMP), MPISHM (MPI1 with MPI-3 interprocess shared memory), MPIRMA (MPI one-sided communication), SHMEM, UPC, Charm++ and Grappa. The kernels in our study – Stencil, Synch_p2p and Transpose – underlie a wide range of computational science applications. They enable direct probing of properties of programming models, especially communication and synchronization. In contrast to mini- or proxy applications, the PRK allow for rapid implementation, measurement and verification. Our experimental results show MPISHM the overall winner, with MPI1, MPIOPENMP and SHMEM performing well. MPISHM and MPIOPENMP outperform the other models in the strong-scaling limit due to their effective use of shared memory and good granularity control. The non-evolutionary models Grappa and Charm++ are not competitive with traditional models (MPI and PGAS) for two of the kernels; these models favor irregular algorithms, while the PRK considered here are regular.	runtime system	Rob F. Van der Wijngaart;Abdullah Kayi;Jeff R. Hammond;Gabriele Jost;Tom St. John;Srinivas Sridharan;Timothy G. Mattson;John Abercrombie;Jacob S Nelson	2016		10.1007/978-3-319-41321-1_17	simulation;computer science;computer graphics (images)	HPC	-6.779988907749612	43.05249984798163	132172
6dc531eaa77744544c86baa823f7368878b4e55c	a fully digital real-time power system simulator based on pc-cluster	engineering;systeme temps reel;electric machine;maquina electrica;power system simulation;simulateur electroenergetique;electric machinery;high speed networks;machine electrique;real time;simulacion numerica;simulation;real time simulation;supercomputer;sistema complejo;electrical machine;gran sistema;hardware architecture;ingenierie;input output;supercomputador;power electronics;synchronisation;hypersim;systeme complexe;complex system;large system;synchronization;power system;simulation numerique;pc cluster;power system simulator;ingenieria;real time system;sistema tiempo real;sincronizacion;systeme parallele;parallel system;cluster pc;simulation tool;off the shelf;sistema paralelo;parallel simulation;superordinateur;grand systeme;numerical simulation	Many benefits come with the real-time simulation of electric machinery and drives. HYPERSIM, a fully digital real-time power system simulator, originally based on large parallel supercomputer, is now adapted to a new hardware platform, in order to increase its flexibility and accessibility. This paper presents a new hardware architecture, called PC-cluster, for real-time simulation of complex power system networks, including power electronics. A PC-cluster consists of several commodity PC interconnected with high-speed network. This new hardware platform for the HYPERSIM simulator is completely based on components-off-the-shelf (COTS), such as commercial motherboard, PCI input/output (I/O) board and communication board. The general implementation of the real-time parallel simulator is introduced in this paper. All aspects of the simulation, such as communication, calculation, synchronization, I/O access and acquisition, are presented in detail. To evaluate the performance of the new hardware platform in a real simulation, a complete application of electric machine drive is presented. This new hardware technology is bringing interesting benefits to power system engineers. It is now easier to have access to powerful simulation tools, in order to perform precise and complete power system studies. © 2003 Published by Elsevier B.V. on behalf of IMACS. Subj. Class. Electric machinery; HYPERSIM; PC-cluster; Power system simulator; Real-time; Simulation	accessibility;computation;computer cluster;input/output;motherboard;power electronics;programming tool;real-time clock;real-time transcription;simulation;supercomputer	C. Larose;Sylvain Guerette;F. Guay;A. Nolet;Tatsuya Yamamoto;H. Enomoto;Y. Kono;Yasuhisa Hasegawa;H. Taoka	2003	Mathematics and Computers in Simulation	10.1016/S0378-4754(03)00071-5	computer simulation;embedded system;synchronization;supercomputer;computer architecture simulator;simulation;hardware architecture	Embedded	-14.124886803521536	42.32529252756597	132409
e24a1d0ce1a00808010e37edd2c8c73d81c1d8ec	a new parallel environment for interactive simulations implementing safe multithreading with mpi	multi threading;user interface;multithreading visualization engines computational modeling user interfaces runtime environment yarn sockets software libraries solid modeling;molecular dynamic simulation;high performance distributed computing interactive simulation multithreading mpi based parallel simulation visualization module user interface python environment udp socket mpi library function adks simulator molecular dynamics simulation nonblocking communication;high performance distributed computing;data visualisation;application program interfaces;interactive simulation;message passing;digital simulation multi threading message passing application program interfaces user interfaces interactive systems data visualisation;interactive systems;user interfaces;parallel simulation;digital simulation	This work presents a new parallel environment for interactive simulations. This environment integrates a MPI-based parallel simulation engine, a visualization module, and a user interface that supports modification of simulation parameters and visualization at runtime. This requires multiple threads, one to execute the simulation or the visualization, and other to receive user input. Since many MPI implementations are not thread-safe, it is proposed a new parallel extension of the Python environment that uses UDP sockets in addition to the calls to the MPI library functions. This approach preserves interactivity, which is required to allow researchers to modify simulation parameters and to visualize results at runtime. The ADKS simulator was chosen as a case study. It is a sequential interactive software for molecular dynamics simulations used in the study of defects in solid materials. The simulation engine was parallelized using non-blocking communication and speedups very close to linear were obtained in the test cases. The proposed approach can be extended to be employed in high performance distributed computing.	blocking (computing);distributed computing;interactivity;message passing interface;molecular dynamics;multithreading (computer architecture);non-blocking algorithm;parallel computing;python;run time (program lifecycle phase);simulation;test case;thread (computing);thread safety;user interface	Eduardo Rocha Rodrigues;Airam Jonatas Preto;Stephan Stephany	2005	17th International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD'05)	10.1109/CAHPC.2005.7	computer architecture;parallel computing;computer science;operating system;distributed computing;user interface;data visualization	HPC	-9.96955389624096	37.52769308425719	132527
288041ed2e6722f8b9e7700433b043aaa450e7f7	a unified platform for data driven web applications with automatic client-server partitioning	declarative programming;programming model;client server;declarative languages;declarative language;web 2 0;data driven application;technical report;computer science;hilda;client server partitioning	Data-driven web applications are usually structured in three tiers with different programming models at each tier. This division forces developers to manually partition application functionality across the tiers, resulting in complex logic, suboptimal partitioning, and expensive re-partitioning of applications. In this paper, we introduce a unified platform for automatic partitioning of data-driven web applications. Our approach is based on Hilda[41, 46], a high-level declarative programming language with a unified data and programming model for all the layers of the application. Based on run-time properties of the application, Hilda's run time system automatically partitions the application between the tiers to improve response time while adhering to memory and/ or processing constraints at the clients. We evaluate our methodology with traces from a real application and with TPC-W, and our results show that automatic partitioning outperforms manual partitioning without the associated development overhead.	binary space partitioning;client–server model;declarative programming;high- and low-level;multitier architecture;overhead (computing);programming language;programming model;response time (technology);run time (program lifecycle phase);runtime system;server (computing);tpc-w;tracing (software);web application	Fan Yang;Nitin Gupta;Nicholas Gerner;Xin Qi;Alan J. Demers;Johannes Gehrke;Jayavel Shanmugasundaram	2007		10.1145/1242572.1242619	declarative programming;computer science;theoretical computer science;database;fifth-generation programming language;programming language;world wide web	OS	-6.991190821485791	43.93830087816986	132529
abdb6a01b9cb8efaecba434f44de1b5212b46ce9	blue gene/q: by co-design	system software;blue gene;floor-space efficient system;application team;core system software;supercomputer system;p system;overall system;ibm blue gene line;q installation	Blue Gene/Q represents the third generation in the IBM Blue Gene line of supercomputer systems. Architecturally, BG/Q installations can scale to over 100 PetaFLOPS. Blue Gene/Q follows the same philosophy as the earlier Blue Gene/L and Blue Gene/P systems, namely to build a massively parallel and highly reliable High Performance Computing (HPC) system out of power-efficient processor chips. Such power-efficient chips, in turn, allow dense packaging, which consequently results in power efficient, cost efficient, and floor-space efficient systems. A focus on reliability in the design of each component contributes to the ability to run a single application across even the largest configurations. Because of the tight interaction between the hardware, system software, and application teams, the machine was truly co-designed. The intended characteristics of architecture were presented early to the system software and application teams, and those teams requested specific features that were then incorporated into the hardware. The contributions of this paper are a description of the overall system and packaging of Blue Gene/Q, a description of the core system software, and a detailed description of the software’s needs that drove the co-design process, in turn affecting the hardware.	blue gene;cost efficiency;flops;job control (unix);multi-core processor;multithreading (computer architecture);p system;supercomputer		2012	Computer Science - Research and Development	10.1007/s00450-012-0215-3	parallel computing;gene;computer science;co-design	HPC	-8.332392124656367	44.04539777370422	132593
0ca0d7ca6f4660acc6cf1e4c9e66b74681c44d9f	c++ programming language for an abstract massively parallel simd architecture	programming language;programming paradigm;c programming language	The aim of this work is to define and implement an extended C++ language to support the SIMD programming paradigm. The C++ programming language has been extended to express all the potentiality of an abstract SIMD machine consisting of a central Control Processor and a N-dimensional toroidal array of Numeric Processors. Very few extensions have been added to the standard C++ with the goal of min-imising the effort for the programmer in learning a new language and to keep very high the performance of the compiled code. The proposed language has been implemented as a porting of the GNU C++ Compiler on a SIMD supercomputer.	exception handling;gnu compiler collection;maxima and minima;programmer;programming paradigm;run time (program lifecycle phase);run-time type information;simd;supercomputer;the c++ programming language;toroidal graph	Alessandro Lonardo;Emanuele Panizzi;Benedetto Proietti	2000	CoRR		fourth-generation programming language;first-generation programming language;computer architecture;parallel computing;very high-level programming language;c++;language primitive;programming domain;computer science;programming paradigm;low-level programming language;policy-based design;programming language;high-level programming language;c99	PL	-13.904179756955624	36.989621932583596	132599
a2a973436d67139939cd670fd5afccb451664678	poster reception - engineering the 100 terabyte turbulence database (or how to track particles at home)	high resolution;experimental analysis;space time;large scale;network traffic;scientific applications;load balance;data intensive computing;overlapping communication and computation;performance modeling	We describe a new environment for large-scale turbulence simulations that uses a cluster of database nodes to store the complete space-time history of fluid velocities. This allows for rapid access to high resolution data that were traditionally too large to store and too computationally expensive to produce on demand.We perform the actual experimental analysis inside the database nodes, which allows for data-intensive computations to be performed across a large number of nodes with relatively little network traffic.We currently have a limited-scale prototype system running actual turbulence simulations and are in the process of establishing a production cluster with high-resolution data. We will discuss our design choices and initial results with load balancing a data-intensive, migratory workload.	analysis of algorithms;computation;data-intensive computing;image resolution;load balancing (computing);network traffic control;prototype;simulation;terabyte;the 100;turbulence	Eric A. Perlman;Randal C. Burns	2006		10.1145/1188455.1188625	parallel computing;real-time computing;simulation;image resolution;computer science;load balancing;operating system;space time;data-intensive computing;database;experimental analysis of behavior	HPC	-7.4433048528709875	35.89490792116579	132956
4a8d064ab93a424908ae215f3234a7c18404b454	hierarchical distributed simulation for 300mm wafer fab	production engineering computing;high fidelity simulation;hierarchical approach;wafer fabs;large-scale simulation;large-scale simulations;semiconductor device manufacture;hierarchical distributed simulation;model execution time;digital simulation;significant reduction;wafer-scale integration;wafer fab simulation;distributed processing;wafer fab	Distributed simulation promises benefits in large-scale simulations, such as in high fidelity simulation of 300mm wafer fabs, although these benefits have been hard to achieve in practice. This paper examines the fundamentals of distributed simulation, and proposes a hierarchical approach to distributed wafer fab simulation, which has the potential to achieve significant reduction in model execution time.	distributed computing;run time (program lifecycle phase);semiconductor fabrication plant;simulation;wafer (electronics)	Sheng Xu;Leon F. McGinnis	2007	2007 Winter Simulation Conference		wafer fabrication;simulation;computer science;engineering;manufacturing engineering;computer engineering	HPC	-5.245272142400178	32.92083116735951	133059
34c14ce56cb5a283b591621f32c30580f897e2e5	comparing performance and energy efficiency of fpgas and gpus for high productivity computing	field programmable gate array;cpu instruction set architecture;kernel;heterogeneous systems;reconfigurable computing;energy efficient;reconfigurable architectures;reconfigurable architectures computer graphic equipment coprocessors field programmable gate arrays;gpu based system high productivity computing system field programmable gate array graphics processing unit cuda system high productivity reconfigurable computer approach fpga programming cpu instruction set architecture fpga based hybrid core system;computer graphic equipment;high productivity computing systems;high productivity reconfigurable computer approach;instruction set architecture;coprocessors;programming model;high productivity computing system;memory access;performance improvement;benchmark testing field programmable gate arrays coprocessors graphics processing unit programming kernel instruction sets;fpga programming;fpga based hybrid core system;graphic processing unit;gpu based system;field programmable gate arrays;cuda system;graphics processing unit;programming;memory bandwidth;benchmark testing;instruction sets	This paper provides the first comparison of performance and energy efficiency of high productivity computing systems based on FPGA (Field-Programmable Gate Array) and GPU (Graphics Processing Unit) technologies. The search for higher performance compute solutions has recently led to great interest in heterogeneous systems containing FPGA and GPU accelerators. While these accelerators can provide significant performance improvements, they can also require much more design effort than a pure software solution, reducing programmer productivity. The CUDA system has provided a high productivity approach for programming GPUs. This paper evaluates the High-Productivity Reconfigurable Computer (HPRC) approach to FPGA programming, where a commodity CPU instruction set architecture is augmented with instructions which execute on a specialised FPGA co-processor, allowing the CPU and FPGA to co-operate closely while providing a programming model similar to that of traditional software. To compare the GPU and FPGA approaches, we select a set of established benchmarks with different memory access characteristics, and compare their performance and energy efficiency on an FPGA-based Hybrid-Core system with a GPU-based system. Our results show that while GPUs excel at streaming applications, high-productivity reconfigurable computing systems outperform GPUs in applications with poor locality characteristics and low memory bandwidth requirements.	benchmark (computing);cuda;central processing unit;coprocessor;fast fourier transform;field-programmable gate array;gddr sdram;graphics processing unit;high productivity computing systems;locality of reference;memory bandwidth;monte carlo method;multi-core processor;programmer;programming model;programming productivity;reconfigurable computing;requirement;server (computing)	Brahim Betkaoui;David B. Thomas;Wayne Luk	2010	2010 International Conference on Field-Programmable Technology	10.1109/FPT.2010.5681761	embedded system;computer architecture;parallel computing;computer hardware;reconfigurable computing;computer science;operating system;instruction set;field-programmable gate array	HPC	-5.122927473844357	44.3195004920331	133155
302ae724ef04c37bf34ffffd31d30ac17446a8a7	library support for hierarchical multi-processor tasks	decomposition of processor sets;distributed memory;hierarchical;library support;mixed task and data parallelism;multi-processor tasks;multilevel group spmd;decomposition of processor sets;distributed memory;hierarchical;library support;mixed task and data parallelism;multi-processor tasks;multilevel group spmd	The paper considers the modular programming with hierarchically structured multi-processor tasks on top of SPMD tasks for distributed memory machines. The parallel execution requires a corresponding decomposition of the set of processors into a hierarchical group structure onto which the tasks are mapped. This results in a multi-level group SPMD computation model with varying processor group structures. The advantage of this kind of mixed task and data parallelism is a potential to reduce the communication overhead and to increase scalability. We present a runtime library to support the coordination of hierarchically structured multi-processor tasks. The library exploits an extended parallel group SPMD programming model and manages the entire task execution including the dynamic hierarchy of processor groups. The library is built on top of MPI, has an easy-to-use interface, and leads to only a marginal overhead while allowing static planning and dynamic restructuring.	central processing unit;data parallelism;distributed memory;marginal model;message passing interface;model of computation;modular programming;multiprocessing;overhead (computing);parallel computing;programming model;runtime library;spmd;scalability	Thomas Rauber;Gudula Rünger	2002	ACM/IEEE SC 2002 Conference (SC'02)		computer simulation;computer architecture;parallel computing;real-time computing;distributed memory;computer science;operating system;programming paradigm;programming language;spmd;hierarchy	HPC	-12.193747288364127	39.37251250901346	133322
01ec87ad46208658787fc9d85bc5ab8912a11f69	context-sensitive interprocedural points-to analysis in the presence of function pointers	bit vector data flow analyses;assignment motion;partial redundancy elimination;program optimization;data flow analysis;generating function;code motion;dead code elimination;points to analysis	This paper reports on the design, implementation, and empirical results of a new method for dealing with the aliasing problem in C. The method is based on approximating the points-to relationships between accessible stack locations, and can be used to generate alias pairs, or used directly for other analyses and transformations. Our method provides context-sensitive interprocedural information based on analysis over invocation graphs that capture all calling contexts including recursive and mutually-recursive calling contexts. Furthermore, the method allows the smooth integration for handling general function pointers in C. We illustrate the effectiveness of the method with empirical results from an implementation in the McCAT optimizing/parallelizing C compiler.	aliasing;automatic parallelization;compiler;context-sensitive grammar;function pointer;mutual recursion	Maryam Emami;Rakesh Ghiya;Laurie J. Hendren	1994		10.1145/178243.178264	generating function;parallel computing;interprocedural optimization;computer science;theoretical computer science;data-flow analysis;dead code elimination;program optimization;programming language;partial redundancy elimination	PL	-17.37107317067697	34.28527940061045	133374
feb64384b5bf8678fc9b21a84f5c71b3d573eb36	massively parallel computation of atmospheric neutrino oscillations on cuda-enabled accelerators		Abstract The computation of neutrino flavor transition amplitudes through inhomogeneous matter is a time-consuming step and thus could benefit from optimization and parallelization. Next to reliable parameter estimation of intrinsic physical quantities such as neutrino masses and mixing angles, these transition amplitudes are important in hypothesis testing of potential extensions of the standard model of elementary particle physics, such as additional neutrino flavors. Hence, fast yet precise implementations are of high importance to research. In the recent past, massively parallel accelerators such as CUDA-enabled GPUs featuring thousands of compute units have been widely adopted due to their superior memory bandwidth, vast compute capability, and highly competitive compute-to-energy ratio in comparison to traditional multi-core architectures with a few tens of monolithic cores. In this paper, we introduce two scalable multi-GPU extensions of common neutrino oscillation frameworks – namely Prob3++ and ν SQuIDS –allowing for the acceleration of oscillation dynamics computation by one to three orders-of-magnitude while preserving numerical accuracy. Our software is licensed under LGPLv3 and can be accessed at https://github.com/fkallen/CUDAProb3 and https://github.com/fkallen/CUDAnuSQuIDS . Program summary Program Title: CUDAProb3++ and CUDA ν SQuIDS Program Files doi: http://dx.doi.org/10.17632/j54yymmg5h.1 Licensing provisions: LGPLv3 Programming language: CUDA, C and C++ Nature of problem: Fast computation of neutrino oscillation probabilities in inhomogeneous matter using constant-coefficient or variable-coefficient ODE solvers. Solution method: Solving ordinary differential equations on CUDA-enabled GPUs.	cuda;computation;parallel computing	A. Cofield;Christian Hundt;Sebastian Böser;Bertil Schmidt	2019	Computer Physics Communications	10.1016/j.cpc.2018.07.022	computational physics;mathematical optimization;massively parallel;neutrino;neutrino oscillation;mathematics;computation;elementary particle;memory bandwidth;standard model;cuda	Theory	-5.128550603320017	35.857742175168546	133405
6e700f83deb5d55c88eee11f5c5a587208c04484	scheduling in or-parallel prolog systems: survey and open problems	lenguaje programacion;partition method;observational equivalence;programming language;multiprocessor;programacion paralela;implementation;prolog;sistema informatico;multiple solution;parallel programming;computer system;logical programming;ejecucion;methode partition;side effect;programmation logique;parallel systems;scheduling;langage programmation;scheduling problem;ordonamiento;systeme informatique;metodo particion;systeme parallele;parallel system;multiprocesador;programacion logica;high efficiency;ordonnancement;sistema paralelo;programmation parallele;multiprocesseur;memory model	Implementation of or-parallel Prolog systems offers a number of interesting scheduling problems. The main issues are the interaction between memory models and scheduling, ordering of multiple solutions, and scheduling of speculative work. The problems occur partly because of the design choices (e.g. the choice of a memory model), and partly because of the desire to maintain observational equivalence between parallel and sequential implementations of Prolog, while achieving high efficiency. In the first part of this paper a common framework for discussing scheduling in or-parallel systems is introduced, and also a collection of issues that must be addressed in such systems is presented. In the second part of the paper we survey a number of solutions to these problems comparing their efficiency whenever possible. We close the survey with a short discussion of open problems.	graph coloring;memory model (programming);observational equivalence;prolog;scheduling (computing);speculative execution;turing completeness	Andrzej Ciepielewski	1991	International Journal of Parallel Programming	10.1007/BF01547894	memory model;job shop scheduling;parallel computing;multiprocessing;dynamic priority scheduling;computer science;theoretical computer science;operating system;two-level scheduling;programming language;implementation;prolog;scheduling;side effect;algorithm	Arch	-16.794329863291857	40.78248259491772	133984
847fc627db4df666aa40b7b6d6091f42b7e71da7	efficient sorting using registers and caches	evaluation performance;gestion memoire;theoretical model;algorithm performance;performance evaluation;algorithm analysis;sorting;storage management;evaluacion prestacion;cache memory;tria;registre;antememoria;memory access;random access machine;gestion memoria;antememoire;resultado algoritmo;system design;triage;performance algorithme;memory systems;data intensive computing;sorting algorithm;machine model;algorithm design;registro;register	Modern computer systems have increasingly complex memory systems. Common machine models for algorithm analysis do not reflect many of the features of these systems, e.g., large register sets, lockup-free caches, cache hierarchies, associativity, cache line fetching, and streaming behavior. Inadequate models lead to poor algorithmic choices and an incomplete understanding of algorithm behavior on real machines. A key step toward developing better models is to quantify the performance effects of features not reflected in the models. This paper explores the effect of memory system features on sorting performance. We introduce a new cache-conscious sorting algorithm, R-merge, which achieves better performance in practice over algorithms that are superior in the theoretical models. Rmerge is designed to minimize memory stall cycles rather than cache misses by considering features common to many system designs.	algorithm design;analysis of algorithms;cpu cache;central processing unit;computation;data structure;merge sort;processor register;register file;sorting algorithm	Lars Arge;Jeffrey S. Chase;Jeffrey Scott Vitter;Rajiv Wickremesinghe	2000		10.1007/3-540-44691-5_5	algorithm design;cache-oblivious algorithm;parallel computing;real-time computing;cache coloring;cpu cache;computer science;sorting;artificial intelligence;theoretical computer science;operating system;sorting algorithm;data-intensive computing;database;distributed computing;cache algorithms;cache pollution;computer security;algorithm;systems design	HPC	-16.045612688306694	44.66236776794878	134032
b0eb6a13f3da1c15a0a67acedf2c98055c71f54c	high performance prolog on a risc	lenguaje programacion;evaluation performance;estacion trabajo;compilateur;performance evaluation;programming language;station travail;prolog;evaluacion prestacion;optimizacion compiladora;logical programming;compiler;workstation;programmation logique;compiler optimization;risc;langage programmation;abstract interpretation;programacion logica;high performance;optimisation compilateur;compilador;global analysis	This paper presents some benchmark timings from an optimising Prolog compiler using global analysis for a RISC workstation, the MIPS R2030. These results are extremely promising. For example, the infamous naive reverse benchmark runs at 2 mega LIPS. We compare these timings with those for other Prolog implementations running on the same workstation and with published timings for the KCM, a recent piece of special purpose Prolog hardware. The comparison suggests that global analysis is a fruitful source of information for an optimising Prolog compiler and that the performance of special purpose Prolog hardware can be at least matched by the code from a compiler using such information. We include some analysis of the sources of the improvement global analysis yields. An overview of the compiler is given and some implementation issues are discussed. This paper is an extended version of Ref. 15)	benchmark (computing);compiler;information source;prolog;workstation	Andrew Taylor	1991	New Generation Computing	10.1007/BF03037163	reduced instruction set computing;computer architecture;compiler;parallel computing;workstation;computer science;artificial intelligence;optimizing compiler;global analysis;programming language;prolog	Arch	-16.83407654323213	34.42883161161043	134115
2e67ad8b1a143a940f83c4b0b6e84ce8b375c2df	detecting patterns in mpi communication traces	communication behavior analysis;random access memory;complexity theory;convolution;communication behavior analysis mpi traces pattern detection;memory constraints;memory constraints mpi communication pattern detection supercomputers interprocessor communication communication debugging;communication debugging;pattern detection;message passing application program interfaces;pattern matching;application program interfaces;interprocessor communication;mpi communication;message passing;pattern matching complexity theory program processors algorithm design and analysis convolution random access memory optimization;optimization;behavior analysis;performance optimization;program processors;algorithm design and analysis;supercomputers;communication pattern;mpi traces	Since processor counts in supercomputers are increasing dramatically, efficient interprocessor communication is becoming even more important for the applications that run on them. A high level, abstract understanding of an application's communication behavior would not only simplify debugging of that communication but would also support more directed performance optimization. We explore automated identification of communication patterns to provide that high level abstraction. We introduce an algorithm to extract communication patterns from MPI traces automatically. Our algorithm first finds locally repeating sequences and then iteratively grows them into global patterns. We demonstrate our technique on three realistic codes using traces from up to 128 processors. Our results show that our approach detects the underlying communication pattern within reasonable time and memory constraints, even for large trace sizes.	algorithm;bottleneck (software);central processing unit;code;debugging;digital footprint;high-level programming language;inter-process communication;list of algorithms;mathematical optimization;message passing interface;parallel computing;pattern recognition;run time (program lifecycle phase);sensor;static program analysis;suffix tree;supercomputer;tracing (software)	Robert Preissl;Thomas Köckerbauer;Martin Schulz;Dieter Kranzlmüller;Bronis R. de Supinski;Daniel J. Quinlan	2008	2008 37th International Conference on Parallel Processing	10.1109/ICPP.2008.71	algorithm design;parallel computing;message passing;computer science;theoretical computer science;operating system;pattern matching;distributed computing;convolution;programming language	HPC	-7.837171965805286	45.98953707388237	134131
9615f2b5db9840fa38daa14d23832ca0b071050d	design of assembly level language for horizontal encoded microprogrammed control unit	design automation;programming language;logic design;register transfer;control system;instruction generator;digital systems;macro generation;control line;address control;fortran;microprogramming;architecture;time constraint	Microprogramming in its most elementary form involves determination of the required bit patterns for a set of control words which express some desired computer instruction. The bit patterns, stored as words in a control word memory, selectively and in time sequence activate the control lines of a computing element. In its simplest form, each control line for the computing element corresponds to a bit in the control word. In addition the control word may contain bit fields to determine the sequence of execution of control words. The first proposals for microprogrammed control systems [1,2,3] were essentially of this type. Specification of these bit patterns was exceedingly tedious since the number of control lines runs to over one hundred for a typical computing element and several hundreds of control words must be specified.  The first step to alleviate this situation was the development of encoded [4] control where groups of control lines which are never activated simultaneously, e.g., the controls to an adder/subtractor unit, are encoded where k bits in the control word selectively activate one of up to 2Kcontrol lines. While this reduces the number of bits that must be specified for each control word, it doesn't reduce the number of control words that must be generated and microprogramming is still an error prone procedure.  Because of this situation, microprogramming is considered by most programmers to be analogous to or worse than machine language programming. The development of assemblers and compilers to simplify the process of coding microprograms has proceeded slowly in contrast to the situation for conventional application programming. Available design systems [5,6] for microprogrammers feature simple languages composed of orders or operations which are associated with specific encoded control word bit patterns. There are three principal causes for this situation. First, most microprogrammers have a design engineering background and are not familiar with assemblers and compilers and do not request such facilities from the design automation developers. Second, logic design of digital systems involves largely register to register transfers and bit manipulations with associated timing constraints which are not efficiently expressed in terms of programming languages like FORTRAN. Third, user microprogrammable computers have not been widely available until recently, therefore fewer people have been concerned about the situation.  To address the problem of designing a language to simplify the specification of microprograms for horizontally encoded control units, an assembly level language, HALL (HYRMAN Assembly Level Language), was designed. A brief description of the language and a two pass translator is presented with special emphasis on the design of the control sequence technique. As background, the major features of the HYRMAN [7] simulator are presented along with a sample case of simulation to illustrate the usage of HALL. The paper concludes with some comparisons of this approach to other attempts [8,9,10,11] of a similar nature.	adder (electronics);bit field;cognitive dimensions of notations;compiler;computer;control system;control unit;digital electronics;elementary function;fortran;machine code;microcode;programmer;programming language;simulation;subtractor;time series	R. H. Evans;Laird H. Moffett;Richard E. Merwin	1974		10.1145/800118.803865	parallel computing;real-time computing;bit manipulation;computer science;control system;theoretical computer science;architecture;operating system;programming language	Arch	-14.507150428156462	32.874674292239995	134148
a229d590cff5125a43862e495a61aa300344c2bb	perforining data flow testing in parallel	distributed memory;distributed memory systems parallel processing program testing parallel architectures parallel programming parallel machines shared memory systems;distributed memory systems;shared memory;parallel programming;machines architectures data flow testing parallel testing software development workload partitioning granularity static workload scheduling dynamic workload scheduling shared memory environment distributed memory environment uniprocessor version multiprocessor version c implementation data general aviion 5000 machine speedup;shared memory systems;parallel architectures;program testing;software development;parallel machines;performance evaluation system testing automatic testing software testing dynamic scheduling data analysis performance analysis costs computer science computer architecture;data flow;parallel processing	Testing is Q critical and expensive part of software deuelopment. One testing methodology, data flow testing, uses the flow of data in Q program t o determine whether the program is adequately tested. W e present a new approach that partitions the data flow testing workload into an appropriately sized granularity. The workload can be scheduled either statically or dynamically, and can be adapted t o either Q shared memory or a distributed memory environment. W e implemented both uniprocessor and multiprocessor versions of our data flow tester an C f o r the Data General Corporation’s AVi iON 5000 machine, experimented with Q V Q riety of programs, and obtained good speedup using the multiprocessor version over the uniprocessor version. Currently, we are expanding OUT tester to handle larger programs, and experimenting on machines with different architectures and a greater number of processors.	central processing unit;dataflow architecture;distributed memory;experiment;multiprocessing;norm (social);shared memory;speedup;uniprocessor system	Mary Jean Harrold	1994		10.1109/IPPS.1994.288300	uniform memory access;distributed shared memory;shared memory;computer architecture;parallel computing;real-time computing;fuzz testing;distributed memory;software performance testing;computer science;software testing;data diffusion machine;supercomputer architecture	SE	-11.737949882361331	44.744263393521564	134231
c2a9cd87b981a692f1124a003e714a678b9ca952	a preliminary speedup comparison between two scope consistency dsm systems: jiajia and nautilus	lu benchmark;sigio signals;multi threading;performance evaluation;matmul benchmark;jiajia;performance;distributed computing;sor benchmark;sor benchmark jiajia nautilus multithreaded distributed shared memory system scope consistency sigio signals context switch performance is benchmark lu benchmark matmul benchmark;nautilus;context switch;computer networks;multithreaded distributed shared memory system;computational modeling;is benchmark;signal processing;distributed shared memory systems;character generation;sun;dsm;switches;distributed shared memory;computer simulation;operating systems computer networks switches computational modeling computer simulation distributed computing signal processing character generation hardware sun;scope consistency;operating systems;hardware;performance evaluation distributed shared memory systems multi threading	Nautilus is a Multithreaded Distributed Shared Memory system based on scope consistency. The multithread implementation disallows the use of SIGIO signals in order to minimize the context switch of traditional processes. This paper shows the speedups of some benchmarks submitted to Nautilus. To have an accurate and correct evaluation of Nautilus, it is compared with other scope consistency DSM system: JIAJIA. The benchmarks evaluated in this study are: IS (from NAS), LU (kernel from SPLASH II), Matmul (matrix multiplication) and SOR (from Rice University).	applicative programming language;benchmark (computing);computer;consistency model;context switch;distributed shared memory;matrix multiplication;multithreading (computer architecture);operating system;sim lock;speedup;thread (computing);treadmarks;unix signal	Mario Donato Marino;Geraldo Lino de Campos	1999		10.1109/ICPPW.1999.800080	parallel computing;real-time computing;computer science;distributed computing	Arch	-11.350385725312433	45.169903297470015	134273
73b7b7d25759f24bd096cbb9d12b7affdfeb8286	managing operational business intelligence workloads	workload;gestion integrada;sistema operativo;gestion integree;compilacion;evaluation performance;cardinal number;performance evaluation;business intelligence databases;measurement;criterio resultado;maintenance;equilibrio de carga;database performance prediction;evaluacion prestacion;performance;interrogation base donnee;equilibrage charge;milisegundo;database;interrogacion base datos;base dato;performance requirement;integrated management;critere performance;almacen dato;intelligence economique;milliseconde;nombre cardinal;numero cardinal;operating system;charge travail;base de donnees;load balancing;database workload managment;mantenimiento;compilation;competitive intelligence;systeme exploitation;performance prediction;business intelligence;entrepot donnee;data warehouse;carga trabajo;inteligencia economica;experimentation;management;database query;millisecond	We explore how to manage database workloads that contain a mixture of OLTP-like queries that run for milliseconds as well as business intelligence queries and maintenance tasks that last for hours. As data warehouses grow in size to petabytes and complex analytic queries play a greater role in day-to-day business operations, factors such as inaccurate cardinality estimates, data skew, and resource contention all make it notoriously difficult to predict how such queries will behave before they start executing. However, traditional workload management assumes that accurate expectations for the resource requirements and performance characteristics of a workload are available at compile-time, and relies on such information in order to make critical workload management decisions. In this paper, we describe our approach to dealing with inaccurate predictions. First, we evaluate the ability of workload management algorithms to handle workloads that include unexpectedly long-running queries. Second, we describe a new and more accurate method for predicting the resource usage of queries before runtime. We have carried out an extensive set of experiments, and report on a few of our results.	algorithm;compile time;compiler;experiment;online transaction processing;petabyte;requirement;resource contention	Umeshwar Dayal;Harumi A. Kuno;Janet L. Wiener;Kevin Wilkinson;Archana Ganapathi;Stefan Krompass	2009	Operating Systems Review	10.1145/1496909.1496927	cardinal number;competitive intelligence;millisecond;performance;computer science;load balancing;operating system;data warehouse;data mining;database;business intelligence;measurement	DB	-18.699244463210785	44.75185519589844	134418
5edecdb0387ae4e3e92307bbbd35c12a4f3e7cbe	performance analysis of a cluster file system	single system image;multimedia application;file system;performance analysis;scientific computing;high performance	Design of cluster file system is very important for building a general-purpose cluster with commodity components. To provide scalable high I/O performance needed in the scientific computing, engineering computing, Internet/Intranet services, I/O intensive commercial database and multimedia application, we designed a high-performance cluster file system named COSMOS. This paper presents the basic characteristics of the cluster file system and its performance analysis. The performance of the COSMOS file system is evaluated on the platform of Dawning/2000 superserver, using standard I/O performance benchmarks. Our tests show satisfactory bandwidth and overall performance of COSMOS, and the system scales well. Based on implementation experience and the raw data, we discuss the bottleneck of the existing system and propose methods to improve the system.	asynchronous i/o;clustered file system;computational science;daemon (computing);data rate units;dawning information industry;general-purpose markup language;input/output;intranet;linearizability;megabit;message passing;multithreading (computer architecture);overhead (computing);profiling (computer programming);regular language description for xml;scalability;super-server;thread (computing);unix;user space	Cong Du;Zhiwei Xu	2000			self-certifying file system;parallel computing;device file;network file system;computer science;operating system;ssh file transfer protocol;database;distributed computing;distributed file system;world wide web;virtual file system	HPC	-11.089515522833665	44.23751562897199	134435
aa7d20bb538fcf9c3cab2b484198e297c5ea5454	blue gene system software - design and implementation of a one-sided communication interface for the ibm eserver blue gene® supercomputer	genes;multiprocessor interconnection networks;kernels;protocols;time scale;communications;software libraries;implementation;software libraries application program interfaces message passing multiprocessor interconnection networks parallel machines protocols;global arrays;development process;mpich2 library one sided communication interface ibm eserver blue gene supercomputer armci library global arrays toolkit blue gene l software stack blue gene l torus network;design and implementation;application program interfaces;supercomputers software libraries kernel hardware application software bandwidth coprocessors message passing distributed computing laboratories;message passing;design;parallel machines;basic biological sciences;communities;open source	This paper discusses the design and implementation of a one-sided communication interface for the IBM Blue Gene/L supercomputer. This interface facilitates ARMCI and the Global Arrays toolkit and can be used by other one-sided communication libraries. New protocols, interrupt driven communication, and compute node kernel enhancements were required to enable these libraries. Three possible methods for enabling ARMCI on the Blue Gene/L software stack are discussed. A detailed look into the development process shows how the implementation of the one-sided communication interface was completed. This was accomplished on a compressed time scale with the collaboration of various organizations within IBM and open source communities. In addition to enabling the one-sided libraries, bandwidth enhancements were made for communication along a diagonal on the Blue Gene/L torus network. The maximum bandwidth improved by a factor of three. This work will enable a variety of one-sided applications to run on Blue Gene/L	blue gene;ibm eserver;supercomputer	Michael Blocksome;Charles Archer;Todd Inglett;Patrick McCarthy;Michael Mundy;Joe Ratterman;A. Sidelnik;Brian E. Smith;George Almási;José G. Castaños;Derek Lieber;José E. Moreira;Sriram Krishnamoorthy;Vinod Tipparaju;Jarek Nieplocha	2006		10.1109/SC.2006.22	computer architecture;parallel computing;computer science;operating system	HPC	-11.298586179455334	45.4334255862863	134437
9538c2b72113f929b63bfd88403a4d95c2ee284f	application of sequential staging of tasks to petroleum reservoir modeling	digital simulation;geophysics computing;parallel programming;ibm 3090-600e;compositional reservoir simulation;compositional simulation;parallel supercomputers;parallel-vector processing;petroleum reservoir modeling;sequential staging of tasks	A large-scale compositional reservoir simulation (>1,000 cells) is not often run on a conventional mainframe computer due to excessive turn-around times. This paper presents programming and computational techniques that fully exploit the capabilities of parallel supercomputers for a large-scale compositional simulation. A novel algorithm called Sequential Staging of Tasks (SST) that can take full advantage of parallel-vector processing to speed-up the solution of a large linear system is introduced. The effectiveness of SST is illustrated with results from computer experiments conducted on an IBM 3090-600E.	algorithm;computer experiment;disk staging;ibm 3090;linear system;mainframe computer;simulation;supercomputer;vector processor	Frederic J. L. Briens;Ching H. Wu	1990			computational science;parallel computing;computer experiment;computer science;theoretical computer science;linear system;programming language	HPC	-9.272951835815414	38.610281000427676	134466
203c02405b5d69c12287291f05ce5798019f8a89	on the implementation of bytecode compression for interpreted languages	code space optimizationfor;compress executable program code;program code;haskell executables runfaster;java bytecode;java isdescribed;java programs isbetween;lzw-cc tonhc98 haskell result;bytecode instructionsare;bytecode size reduction;bytecode compression	This paper describes a new method for code space optimization for interpreted languages called LZW-CC. The method is based on a well-known and widely used compression algorithm, LZW, which has been adapted to compress executable program code represented as bytecode. Frequently occurring sequences of bytecode instructions are replaced by shorter encodings for newly generated bytecode instructions. The interpreter for the compressed code is modified to recognize and execute those new instructions. When applied to systems where a copy of the interpreter is supplied with each user program, space is saved not only by compressing the program code but also by automatically removing the unused implementation code from the interpreter. The method’s implementation within two compiler systems for the programming languages Haskell and Java is described and implementation issues of interest are presented, notably the recalculations of target jumps and the automated tailoring of the interpreter to program code. Applying LZW-CC to nhc98 Haskell results in bytecode size reduction by up to 15.23% and executable size reduction by up to 11.9%. Java bytecode is reduced by up to 52%. The impact of compression on execution speed is also discussed; the typical speed penalty for Java programs is between 1.8 and 6.6%, while most compressed Haskell executables run faster than the original. Copyright © 2008 John Wiley & Sons, Ltd.	algorithm;compiler;executable;haskell;interpreted language;java bytecode;jikes;john d. wiley;kaffe;lempel–ziv–welch;library (computing);machine code;mathematical optimization;programming language	Ekaterina Stefanov;Anthony M. Sloane	2009	Softw., Pract. Exper.	10.1002/spe.888	parallel computing;interpreter;computer science;theoretical computer science;operating system;common intermediate language;programming language;functional programming;interpreted language;threaded code;source code	PL	-18.780470381743353	33.85805176597441	134533
343e31c1d60613bbf366c35c3fd909e6ad62b348	probabilistic memory disambiguation and its application to data speculation	performance improvement;conservative treatment;critical path;profitability;cost model	Memory references in an instruction stream often pose a challenge for performance improvements on high-performance microprocessors. One common scenario is that a load and a sequence of dependent instructions are on a critical path, but scheduling these instructions early to reduce the critical path length is often hindered by a preceding store, which may write to the same memory location as the load. A traditional memory disambiguation approach employed by a compiler may break such a potential dependence only if it can successfully disambiguate the memory locations referenced by the store and the load. This conservative treatment in memory disambiguation is greatly alleviated by a recent architectural support for data speculation. With such a support, a load can be freely moved up across an aliasing store, and if the alias does occur, it is detected by a run time check and a recovery code will be invoked to re-execute the speculated instructions. Data speculation opens up exciting new opportunities for performance improvements, but it also demands a new memory disambiguation technique to guide this transformation with aliasing probabilities as the performance of unguided speculations will be greatly penalized by the cost of running recovery code. This paper presents a probabilistic memory disambiguation (PMD) framework to statically derive the symbolic probabilities of the aliases among array references in application programs. We show how to apply this framework to build a profitability cost model to guide data speculation in a compiler. We also provide a set of heuristics to quickly approximate the aliasing probabilities in many common cases. Experimental results show that data speculation can often give a 1.1 to 1.2 performance speedup, but unguided data speculation may also cause a two to three fold slowdown. Therefore, it is important to guide data speculation with a cost model like the PMD framework to maximize program performance.	aliasing;analysis of algorithms;analysis of parallel algorithms;approximation algorithm;compiler;critical path method;heuristic (computer science);ku band;memory address;memory disambiguation;microprocessor;pmd;run time (program lifecycle phase);scheduling (computing);speedup;word-sense disambiguation	Roy Dz-Ching Ju;Jean-Francois Collard;Karim Oukbir	1999	SIGARCH Computer Architecture News	10.1145/309758.309769	computer science;artificial intelligence;critical path method;data mining;profitability index	Arch	-17.939062281345347	37.60224487693471	134631
ede11ea146da4f49060299674711ef477817daec	reusable object-oriented solutions for numerical simulation of pdes in a high performance environment	generic numerical algorithm;support extensibility;numerical method;reusable object-oriented solution;physical model;data storage facility;run-time flexibility;parallel computing;numerical simulation;built-in support;high performance environment;parallel simulation;numerical solution;object oriented	Object-oriented platforms developed for the numerical solution of PDEs must combine flexibility and reusability, in order to ease the integration of new functionalities and algorithms. While designing similar frameworks, a built-in support for high performance should be provided and enforced transparently, especially in parallel simulations. The paper presents solutions developed to effectively tackle these and other more specific problems (data handling and storage, implementation of physical models and numerical methods) that have arisen in the development of COOLFluiD, an environment for PDE solvers. Particular attention is devoted to describe a data storage facility, highly suitable for both serial and parallel computing, and to discuss the application of two design patterns, Perspective and Method-Command-Strategy, that support extensibility and run-time flexibility in the implementation of physical models and generic numerical algorithms respectively.	computer simulation;numerical analysis	Andrea Lani;Tiago Quintino;Dries Kimpe;Herman Deconinck;Stefan Vandewalle;Stefaan Poedts	2006	Scientific Programming		computer simulation;parallel computing;simulation;computer science;theoretical computer science;operating system;object-oriented programming	HPC	-9.551564076852848	36.12956167066347	134688
fbe264fefbc3c4181b4d5c3a328832c416c166a3	managing session performance using the netview performance monitor	performance monitoring;gestion;performance;reseau ordinateur;computer network;red ordenador;rendimiento;management	Managing the performance of network devices and their interaction with host applications is a complex task that entails the collection and reduction of information related to the underlying session. Depending on the specific management task at hand, differing types, correlations, and formattings of session performance measurements are required. The NetView™ Performance Monitor has a flexible set of facilities that can be used to provide the information needed to manage session performance. Its facilities to collect, correlate, and present session performance measurement are discussed in relation to typical network management tasks.		Leo Temoshenko	1992	IBM Systems Journal	10.1147/sj.312.0286	real-time computing;performance;telecommunications;computer science;engineering;operating system;management;computer network	HPC	-18.947199057272652	45.0623981166433	134840
677a0714e4b41f86513f55a3ed8a9c887f1ba3ae	porting a distributed operating system to a shared memory parallel computer	computer systems digital parallel processing;thesis abstract;computer operating systems		distributed operating system;parallel computing;shared memory	G. S. Atukorala	1990			embedded operating system;computer architecture;parallel computing;memory management;distributed memory;computer science;distributed computing;process state;computer network programming	HPC	-10.743625957473938	43.038336999736345	134962
b0fd0c6d614cdddb837f3856ebd5454d24caf5eb	radiative signature of the relativistic kelvin-helmholtz instability	particle mesh method particle in cell simulation relativistic kelvin helmholtz instability angular resolved radiation spectra particle dynamics angular resolution spectral resolution spatial resolution astrophysical jet formation plasma phenomena particle motion particle in cell algorithm graphic processing units;sc13 proceedings;relativistic plasmas kelvin helmholtz instability plasma simulation;graphics processing units instruction sets kernel plasmas computational modeling spatial resolution magnetic fields;gordon bell prize categories scalability and time to solution	We present a particle-in-cell simulation of the relativistic Kelvin-Helmholtz Instability (KHI) that for the first time delivers angularly resolved radiation spectra of the particle dynamics during the formation of the KHI. This enables studying the formation of the KHI with unprecedented spatial, angular and spectral resolution. Our results are of great importance for understanding astrophysical jet formation and comparable plasma phenomena by relating the particle motion observed in the KHI to its radiation signature.  The innovative methods presented here on the implementation of the particle-in-cell algorithm on graphic processing units can be directly adapted to any many-core parallelization of the particle-mesh method. With these methods we see a peak performance of 7.176 PFLOP/s (double-precision) plus 1.449 PFLOP/s (single-precision), an efficiency of 96% when weakly scaling from 1 to 18432 nodes, an efficiency of 68.92% and a speed up of 794 (ideal: 1152) when strongly scaling from 16 to 18432 nodes.	algorithm;angularjs;double-precision floating-point format;graphics processing unit;image scaling;instability;manycore processor;parallel computing;particle mesh;particle-in-cell;plasma active;simulation;single-precision floating-point format	Michael Bussmann;Heiko Burau;Thomas E. Cowan;Alexander Debus;Axel Huebl;Guido Juckeland;Thomas Kluge;Wolfgang E. Nagel;Richard Pausch;Felix Schmitt;Ulrich Schramm;Joseph Schuchart;René Widera	2013	2013 SC - International Conference for High Performance Computing, Networking, Storage and Analysis (SC)	10.1145/2503210.2504564	relativistic particle	HPC	-5.014313708225436	37.74484821150592	135014
1eab69b7a85f87eb265945bebddd6ac0e1e08be3	a type-based compiler for standard ml	new jersey;code generation;standard ml;data representation;functional language	Compile-time type information should be valuable in efficient compilation of statically typed functional languages such as Standard ML. But how should type-directed compilation work in real compilers, and how much performance gain will type-based optimizations yield? In order to support more efficient data representations and gain more experience about type-directed compilation, we have implemented a new type-based middle end and back end for the Standard ML of New Jersey compiler. We describe the basic design of the new compiler, identify a number of practical issues, and then compare the performance of our new compiler with the old non-type-based compiler. Our measurement shows that a combination of several simple type-based optimizations reduces heap allocation by 36%; and improves the already-efficient code generated by the old non-type-based compiler by about 19% on a DECstation 500.	compiler;decstation;memory management;standard ml of new jersey;type system	Zhong Shao;Andrew W. Appel	1995		10.1145/207110.207123	manifest expression;single compilation unit;computer architecture;compiler;parallel computing;dynamic compilation;compiler correctness;interprocedural optimization;computer science;compiler construction;dead code elimination;optimizing compiler;external data representation;compilation error;programming language;functional programming;static single assignment form;inline expansion;intrinsic function;functional compiler;code generation	PL	-18.374315800119845	34.89345491447796	135076
298b43c0ef53ecdb387dfe3480d5be5a650a1320	initializing memory shared by several processors	parallelisme;shared memory;multiprocessor;memoria compartida;sistema informatico;computer system;synchronisation;parallelism;paralelismo;synchronization;systeme informatique;sincronizacion;multiprocesador;memoire partagee;multiprocesseur	We examine the use of atomic instructions in implementing barriers that do not require previously initialized memory. We show hown identical processes can use uninitialized shared memory to elect a leader that then initialized the shared memory. The processes first use the uninitialized memory to obtain unique identifiers in the range 0 ton−1 and then meet at a barrier. After passing the barrier, the leader initializes the shared memory. Whenn is not a power of 2 this barrier implementation, a tournament algorithm, avoids extra work by taking advantage of information implicit in the algorithm for obtaining the unique identifiers. The only atomic instruction that we require is one that complements a bit.	algorithm;central processing unit;linearizability;memory corruption;power of two;shared memory;unique identifier	David Hemmendinger	1989	International Journal of Parallel Programming	10.1007/BF01407858	uniform memory access;distributed shared memory;shared memory;synchronization;interleaved memory;parallel computing;real-time computing;distributed memory;computer science;operating system;distributed computing;data diffusion machine;algorithm;memory map;memory management	Arch	-15.664883268401537	45.560423106906605	135305
86833d9308f4fa43002e1b9fbfa659f683a7ed24	a heuristic rule of partitioning irregular loop for parallelizing compilers	distributed memory;optimal solution;parallelizing compilers;community computing;communication cost	For irregular applications on distributed-memory systems, computation partition is an important issue on parallel compiling techniques of parallelizing compilers. In this paper, we propose a local optimal solution, called heuristic computes rule (HCR), which could be used for irregular loop partitioning. This rule considers both the iteration being partitioned and the iterations partitioned, which ensures that iterations are assigned so as to produce less communication costs. And HCR rule proposes that irregular loop partitioning should trade off the maximum message degrees of processors, the number of messages, the message sizes, and workload balance. In our experiments, we compare HCR with almost owner computes rule and least communication computes rule. The results show that the executing of irregular loop partitioned by HCR rule has much less communication cost and achieve better performance.	automatic parallelization;compiler;heuristic	Changjun Hu;Yali Liu;Jue Wang;Jianjiang Li	2009		10.1007/978-3-642-11842-5_23	parallel computing;distributed memory;computer science;theoretical computer science;operating system;distributed computing;programming language	HPC	-13.723486742965857	46.25918780182529	135392
4783b18581eaabb9c5daa1dab706e151265ae482	scheduling and process migration in partitioned multiprocessors	tratamiento paralelo;sistema operativo;general and miscellaneous mathematics computing and information science;planificacion integral;traitement parallele;multiprocessor;sistema informatico;integrated planning;computer system;computer architecture;architecture ordinateur;operating system;quantum mechanics;computer calculations;array processors;mechanics;programming 990200 mathematics computers;systeme exploitation;systeme informatique;arquitectura ordenador;multiprocesador;process scheduling;process migration;memory devices;parallel processing;ordonnancement;multiprocesseur	A partitioned multiprocessor (PM) has a shared global bus and nonshared local memories. This paper studies a process scheduler, called the two-tier scheduler (TTS), for a PM. In a PM local scheduling amortizes the cost of loading processes in local memory. Global scheduling migrates processes to balance load. A tunable time quantum is adjusted so the average process completes execution on the processor on which it is first scheduled, and only relatively long lived processes are rescheduled globally.		Jason Gait	1990	J. Parallel Distrib. Comput.	10.1016/0743-7315(90)90102-U	fixed-priority pre-emptive scheduling;embedded system;parallel processing;parallel computing;real-time computing;multiprocessing;process migration;telecommunications;computer science;operating system;distributed computing;integrated business planning;scheduling;algorithm	HPC	-16.26863037948498	44.45362637478794	135490
005119da2729eb0cdef446f67e47747465c38156	shared-files parallel simulation framework for dynamic multi-domains networks using omnet++ (wip)	multidomain networks;network simulator;omnet;parallel simulation	Parallel discrete event simulation (PDES) has been recognized as a challenging research field bridging between modeling and simulation and high-performance computing. It tackles the problem of executing discrete event simulations on parallel processors. OMNeT++ [1] is a powerful and open-source simulation tool which is basically intended to model discrete-event systems. According to its authors, the OMNeT++ PDES implementation has a modular and extensible architecture, allowing new synchronization protocols and new communication mechanisms to be added easily, which makes it a particularly attractive platform for PDES research. Unfortunately, some constraints should be verified first in order that parallel simulation under OMNeT++ works properly. The most important one is that the topology of the network should be static. In this paper, we propose a new parallel simulation approach for OMNeT++ based on socket communication and shared files that allows dynamic models to work without any of the existing problems.	simulation	Abdelhakim Hamzi;Saud Albarrak	2015			parallel computing;real-time computing;computer science;distributed computing	Robotics	-12.59679805514037	41.97406042568001	135641
b80cecb265b4bf812dac8e7fc89f7f256965821a	cooperative gpgpu scheduling for consolidating server workloads				Yusuke Suzuki;Hiroshi Yamada;Shinpei Kato;Kenji Kono	2018	IEICE Transactions		computer vision;artificial intelligence;computer science;operating system;cloud computing;scheduling (computing);general-purpose computing on graphics processing units	Arch	-9.23527148645195	43.82471867234428	135698
290940421da5ea1fca37ec8efddf272b2ba37798	neural compiler technology for a parallel architecture	software development environment;source code;data transfer	This paper presents a software development environment which extracts the ne-grain parallelism implicit in an algorithm (in particular, from neural network descriptions) in order to generate a parallel program from conventional source code for MIMD architectures with distributed memory. The resulting programs are scheduled at compile time so that every data transfer is expected by its recipient at the same moment it is posted to the inter-processor communication network. Initial empirical results are very promising.	algorithm;artificial neural network;compile time;compiler;distributed memory;integrated development environment;mimd;parallel computing;software development;telecommunications network	Ronald Charles Moore;Stefan Zickenheiner;Bernd Klauer;Frank Henritzi;Andreas Bleck;Klaus Waldschmidt	1996			enterprise architecture framework;parallel computing;architecture;computer science;computer architecture;compiler;data architecture;reference architecture;applications architecture;space-based architecture;cellular architecture	HPC	-10.707878864148467	41.06118081997212	135822
c178a12824333a54bdf7224ee5e4168e5d35e6e2	an architecture for prolog extensions	scaling up;efficient implementation;partial evaluation	We address the task of an efficient implementation of Prolog extensions. Prolog is a very good language for prototyping and almost any extension can be quickly written in Prolog using a Prolog interpreter and tested on small examples. It is harder to find out if the results scale up to large, real life problems, though. A Prolog interpreter, even if partially evaluated with respect to a given problem, quickly hits the space and time limitations and so more elaborate approaches to the implementation are necessary. In this article we describe an architecture of a Prolog system that gives the user enough support to quickly prototype new extensions and at the same time to implement them efficiently and incrementally. This architecture has been used to build the SEPIA and ECLiPSe systems.	eclipse;interpreter (computing);partial evaluation;prolog;prototype;real life	Micha Meier;Joachim Schimpf	1992		10.1007/3-540-56454-3_16	computer architecture;parallel computing;computer science;theoretical computer science	PL	-17.691147899561944	33.352580970837664	135825
1d481eb6bdbb04e3b8dd86cab4a0c321359d58e2	performance and scalability of mpi on pc clusters	mpi performance;linux cluster;pc cluster;pc clusters;mpi	Abstract. The purpose of this paper is to compare the communication performance and scalability of MPI communication routines on an NT cluster, a Myrinet Linux cluster, an Ethernet Linux cluster, a Cray T3E-600, and an SGI Origin 2000. All tests in this paper were run for the various numbers of processors and 2 message sizes. For most of the MPI tests used in this paper, the T3E-600 and Origin 2000 outperform the NT cluster, the Myrinet and Ethernet Linux clusters. In spite of the fact that the Cray T3E-600 is about 5 years old, it performs best of all machines for most of the tests. For mpi_bcast, mpi_allgather, and mpi_alltoall, the Myrinet Linux cluster outperforms the NT cluster. For all other MPI collective routines, the NT cluster outperforms the Myrinet Linux cluster. For all MPI collective routines, the Myrinet Linux cluster performs significantly better than the Ethernet Linux cluster.	central processing unit;computer cluster;linux;message passing interface;scalability	Glenn R. Luecke;Marina Kraeva;Jing Yuan;Silvia Spanoyannis	2004	Concurrency and Computation: Practice and Experience	10.1002/cpe.749	parallel computing;computer hardware;computer cluster;computer science;message passing interface;operating system	HPC	-10.694259663244669	45.68423149467827	135832
4905da3619406256dd29b547abf93a5fec4d336d	efficient techniques for fast nested barrier synchronization	parallel programs;software implementation;large data	Two hardware barrier synchronization schemes are presented which can support deep levels of control nesting in data parallel programs. Hardware barriers are usually an order of magnitude faster than software implementations. Since large data parallel programs often have several levels of nested barriers, these schemes provide significant speedups in the execution of such programs on MIMD computers. The first scheme performs code transformations and uses two single-bit-trees to implement unlimited levels of nested barriers. However, this scheme increases the code size. The second scheme uses a more expensive integer-tree to support an exponential number of nested barriers without increasing the code size. Using hardware already available on commercial MIMD computers, this scheme can support more than four billion levels of nesting.	barrier (computer science);computer;data parallelism;mimd;synchronization (computer science);time complexity	Vara Ramakrishnan;Isaac D. Scherson;Raghu Subramanian	1995		10.1145/215399.215436	parallel computing;real-time computing;computer science;distributed computing	Arch	-6.634188163128018	42.674105536269785	135896
267199071e71d1581e97a7a82edecb7fa99748aa	efficient detection of large-scale redundancy in enterprise file systems	estensibilidad;hachage;extraction information;sistema operativo;entreprise;gestion memoire;measurement;analisis datos;information extraction;redundancia;gestion archivos;storage management;localization;performance;empresa;min hashing;gestion fichier;localizacion;file management;data mining;data analysis;large scale;gestion memoria;hashing;localisation;redundancy;operating system;fouille donnee;file system;directory similarity and de duplication;duplication;firm;set sketches;duplicacion;algorithms;analyse donnee;systeme exploitation;extensibilite;scalability;busca dato;extraccion informacion;redondance;file systems	In order to catch and reduce waste in the exponentially increasing demand for disk storage, we have developed very efficient technology to detect approximate duplication of large directory hierarchies. Such duplication can be caused, for example, by unnecessary mirroring of repositories by uncoordinated employees or departments. Identifying these duplicate or near-duplicate hierarchies allows appropriate action to be taken at a high level. For example, one could coordinate and consolidate multiple copies in one location.	approximation algorithm;data mining;directory (computing);disk mirroring;disk storage;high-level programming language;scalability;software repository;supervised learning;unsupervised learning	George Forman;Kave Eshghi;Jaap Suermondt	2009	Operating Systems Review	10.1145/1496909.1496926	scalability;hash function;internationalization and localization;performance;computer science;operating system;data mining;database;redundancy;data analysis;world wide web;computer security;information extraction;gene duplication;measurement	OS	-18.998333280757947	44.81927714678327	135943
925ac5da627789451f1d71266e55fe52f213e1c8	an openacc-based unified programming model for multi-accelerator systems	openacc;heterogeneous computing;accelerators;programming models	This paper proposes a novel SPMD programming model of OpenACC. Our model integrates the different granularities of parallelism from vector-level parallelism to node-level parallelism into a single, unified model based on OpenACC. It allows programmers to write programs for multiple accelerators using a uniform programming model whether they are in shared or distributed memory systems. We implement a prototype of our model and evaluate its performance with a GPU-based supercomputer using three benchmark applications.	benchmark (computing);distributed memory;graphics processing unit;openacc;parallel computing;programmer;programming model;prototype;spmd;supercomputer;unified model	Jungwon Kim;Seyong Lee;Jeffrey S. Vetter	2015		10.1145/2688500.2688531	computer architecture;parallel computing;computer science;programming paradigm;programming language;symmetric multiprocessor system	HPC	-6.797345066242541	43.7996604552362	135975
63f1c5ed64d12511a04a91e35f86ba13ab826952	a guide to fortran iv programming (2. ed.)	fortran		fortran	Daniel D. McCracken	1972			computational science;computer science;programming language	Robotics	-9.076872549764346	37.11898318435358	136172
8f1119019420f4e7dfb1531bdadbe27d0ad9db15	gpu accelerated molecular docking with parallel genetic algorithm	drugs;interpolation;chemical engineering computing;genetic algorithm molecular docking cuda gpu;parallel programming;gpu;drntu engineering computer science and engineering;cuda;conference paper;parallel architectures;cpu version gpu accelerated molecular docking parallel genetic algorithm computer aided drug design and discovery highly accelerated molecular docking programs hardware enabled texture interpolation energy evaluation parallel genetic algorithms cuda computing architecture optimal docking result cpu implementation gpu accelerated docking program;graphics processing units;genetic algorithm;genetic algorithms;molecular docking;parallel programming chemical engineering computing drugs genetic algorithms graphics processing units interpolation parallel algorithms parallel architectures;parallel algorithms;graphics processing units genetic algorithms sociology statistics acceleration genetics drugs	Molecular docking is a widely used tool in Computer-aided Drug Design and Discovery. Due to the complexity of simulating the chemical events when two molecules interact, highly accelerated molecular docking programs are of great interest and importance for practical use. In this paper, we present a GPU accelerated docking program implemented with CUDA. The hardware-enabled texture interpolation is employed for fast energy evaluation. Two types of parallel genetic algorithms are mapped to the CUDA computing architecture and used for the search of optimal docking result. Comparing to the CPU implementation, the GPU accelerated docking program achieved significant speedup while producing comparable results to the CPU version. The source code is made public at http://code.google.com/p/cudock/.	cuda;central processing unit;computer architecture;docking (molecular);genetic algorithm;graphics processing unit;interpolation;simulation;speedup	Xuchang Ouyang;Chee Keong Kwoh	2012	2012 IEEE 18th International Conference on Parallel and Distributed Systems	10.1109/ICPADS.2012.99	computational science;parallel computing;genetic algorithm;computer science;theoretical computer science	HPC	-5.424749429381151	37.53206971295989	136232
1ed51b76147438e3c4fe58ef023914c9f0e1087e	rcpparmadillo: accelerating r with high-performance c++ linear algebra	linear algebra;software;c;r	The R statistical environment and language has demonstrated particular strengths for interactive development of statistical algorithms, as well as data modelling and visualisation. Its current implementation has an interpreter at its core which may result in a performance penalty in comparison to directly executing user algorithms in the native machine code of the host CPU. In contrast, the C++ language has no built-in visualisation capabilities, handling of linear algebra or even basic statistical algorithms; however, user programs are converted to highperformance machine code, ahead of execution. A new method avoids possible speed penalties in R by using the Rcpp extension package in conjunction with the Armadillo C++ matrix library. In addition to the inherent performance advantages of compiled code, Armadillo provides an easy-to-use template-based meta-programming framework, allowing the automatic pooling of several linear algebra operations into one, which in turn can lead to further speedups. With the aid of Rcpp and Armadillo, conversion of linear algebra centered algorithms from R to C++ becomes straightforward. The algorithms retains the overall structure as well as readability, all while maintaining a bidirectional link with the host R environment. Empirical timing comparisons of R and C++ implementations of a Kalman filtering algorithm indicate a speedup of several orders of magnitude.	algorithm;armadillo;c++;central processing unit;comparison of linear algebra libraries;compiler;computational statistics;data modeling;interpreter (computing);kalman filter;linear algebra;machine code;metaprogramming;r language;speedup;the australian;usability	Dirk Eddelbuettel;Conrad Sanderson	2014	Computational Statistics & Data Analysis	10.1016/j.csda.2013.02.005	parallel computing;c++;speed of light;computer science;rhodopsin;theoretical computer science;linear algebra;mathematics;distributed computing;statistics	PL	-16.312964961075025	35.838531209532675	136248
c57d9f87047fb513adc03000aa07234b1929eac2	improving communication patterns for distributed cluster-based individual-oriented fish school simulations	data clustering	Parallel discrete event simulation (PDES) have shown to be an useful paradigm for simulating complex and large-scale models. An individual-oriented approach allows modelers capture complex emerging global behaviors generated by simple local interaction, like observed in self-organized systems. Usually, this type of simulations are highly expensive in terms of computing and communications. One one hand, we can reduce the computing involved in individual interactions by means of developing a robust partitioning method. On the other hand, we have to be able to efficiently handle a huge number of individuals interacting with other individuals stored in memory of remote processors. In this work we will analyze and compare three communication strategies: synchronous and asynchronous message passing (via MPI) and bulk-synchronous parallel (BSP) for our distributed cluster-based individual-oriented fish school simulator. In this type of simulations, the main contributions of our work are: a) we showed that distributed time-driven simulations do not always improve the performance when using synchronous communication strategies, b) we show asynchronous communications strategies are more efficient. In addition, we have verified that the bulk-synchronous parallel method is a scalable.	algorithm;bulk synchronous parallel;central processing unit;communications protocol;computer cluster;computer simulation;ecology;emoticon;experiment;interaction;message passing interface;message passing;openmp;programming paradigm;run time (program lifecycle phase);scalability;self-organization;speedup	Roberto Solar;Francisco Borges;Remo Suppi;Emilio Luque	2013		10.1016/j.procs.2013.05.234	real-time computing;computer science;artificial intelligence;theoretical computer science;operating system;machine learning;distributed computing;algorithm	HPC	-10.929917113490541	39.05789738155152	136365
7ae9143f0d4b694532095d5fe673d2ae86dad7e6	gph and eden: comparing two parallel functional languages on a beowulf cluster	symbolic computation;language use;beowulf cluster;process model;coarse grained;glasgow haskell compiler;functional language;high performance;language design;distributed architecture	We investigate two similar but contrasting parallel functi onal language designs: Eden and G PH. Both languages use the non-strict functional language Haskell as a core expression language, both are implem ent d as extensions of the high performance Glasgow Haskell Compiler (GHC), and both implementations are available on the same distributed architecture : a Beowulf cluster. This allows an exceptionally pure comparison of the language des ign characteristics and their impact on parallel performance. The comparison is illustrated by two parallel symbolic comp utation benchmarks which expose differences in the communication, proce ss creation, and work distribution mechanisms employed by Eden and G PH. Our results show that the explicit process model favoured by Eden gives good p arallel performance for coarse-grained applications running on the Beowulf clu ster. In comparison, the current GPH implementation of implicit parallelism yields poorer abs olute speedup for these two applications. Further work is needed t o determine whether this difference is an implementation artefact or a conseque nce of the different models employed in each case, though excessively fine thread g anularity appears to be a contributing factor. 1Department of Computing and Electrical Engineering, Herio t-Watt University, Scotland; Email:fhwloidl,trinderg@cee.hw.ac.uk 2Department of Computer Science, Marburg University, Germa ny; Email: fklusik,loogeng@mathematik.uni-marburg.de 3School of Computer Science, University of St Andrews, Scotl and; Email: kh@dcs.st-andrews.ac.uk	beowulf cluster;compiler;computer science;distributed computing;electrical engineering;email;functional programming;implicit parallelism;parallel computing;process modeling;speedup;strict function;the glorious glasgow haskell compilation system;unified expression language;visual artifact	Hans-Wolfgang Loidl;Ulrike Klusik;Kevin Hammond;Rita Loogen;Philip W. Trinder	2000			parallel computing;computer science;theoretical computer science;programming language	PL	-14.901770376112522	39.042529763770446	136467
9be2e315fabd498430938b34b014c34a078d8cac	runtime support for replicated parallel simulators of an atm network on workstation clusters	grain size;atm networks;digital communication;parallel simulation;workstation cluster	An eeective approach of speeding up the simulation of an ATM network on workstation clusters is presented. In this approach, multiple simulation runs are performed by replicated parallel simulators (RPSs) concurrently. Since the execution platform of the simulation is in a shared-network environment, the RPSs must compete with other applications for resources. The RPSs support adaptive execution by reconnguring the grain-size of their logical processes dynamically. In addition, scheduling policies are proposed to facilitate eecient allocation of workstations to the RPSs. Experiments are conducted to evaluate the performance of three proposed scheduling policies in the scenarios of homogeneous and heterogeneous workstation clusters.	atm turbo;computer cluster;scheduling (computing);simulation;workstation	Kam Hong Shum;Shuo-Yen Robert Li	1996		10.1007/3-540-61626-8_107	computer architecture;parallel computing;computer science;distributed computing;grain size	HPC	-13.191433882713357	44.12814458927787	136503
57358c229cf622e7d9c0fa04b02ffd295ae9bd8e	performance of a cluster of pci based ultrasparc workstations interconnected with sci	tratamiento paralelo;evaluation performance;performance evaluation;traitement parallele;point to point;evaluacion prestacion;reseau ordinateur;interconnection network;interface reseau;computer network;chip;network interfaces;operating system;reseau informatique;red ordenador;parallel processing;red interconexion;reseau interconnexion	SCI is based on unidirectional point-to-point links formin g ringlets that can be connected with switches to allow further scaling . This paper presents performance results from running on a number of differently configured SCI clusters. The SCI technology used is Dolphin’s second generatio n PCI/SCI adapter based on the LC-2 LinkController chip as well as a new 4 port, L C-2 based switch. Nodes are UltraSparcs running Solaris 2.5.1 as the o perating system. Results show latencies down to 2.9μs for remote stores, and ban widths up to 80 Mbytes/s into a single system. Network throughput of more th an 270 Mbytes/s (8 node system) is demonstrated. Results indicate that the n ew LC-2 eliminates a number of problems with the earlier LC-1 chip in addition to increasing peak performance. With its flexible building blocks this technol ogy should also make it possible to construct systems with a large number of nodes , pushing I/O adapter based SCI interconnects forward as a promising system area n etwork technology.	algorithm;benchmark (computing);data recovery;device driver;dolphin;electrical connection;end system;fast fourier transform;image scaling;informatics;lock (computer science);message passing interface;mutual exclusion;network switch;period-doubling bifurcation;point-to-point (telecommunications);protocol stack;retry;sbus;scalability;throughput;ultrasparc t1;web application;workstation	Knut Omang	1998		10.1007/BFb0052220	chip;embedded system;parallel processing;computer hardware;telecommunications;point-to-point;computer science;network interface;operating system	HPC	-11.200671095486246	46.31935277258891	136520
fe0001215256832662b3a804f94a494aa0cd15b0	simulating pram with a msimd model (asc)	processing element;data parallel;msimd model;parallel algorithm;concurrent computing;associative simd computers;asc;application software;pram simulation;computer model;data parallelism;parallel programming;instruction streams;phase change random access memory;parallel computation;processing elements;associative processing;parallel models;phase change random access memory concurrent computing computational modeling inference algorithms application software computer science parallel programming parallel processing ear partitioning algorithms;computational modeling;ear;computational complexity;numerical algorithm;parallel computer;converting algorithms pram simulation msimd model asc parallel computation associative simd computers data parallelism instruction streams control parallelism processing elements;inference algorithms;digital simulation parallel algorithms computational complexity associative processing;computer science;converting algorithms;control parallelism;parallel processing;digital simulation;partitioning algorithms;parallel algorithms	The ASC (MSIMD) model for parallel computation supports a generalized version of an associative style of computing that has been used since the introduction of associative SIMD computers in the early 1970's. In particular, this model supports data parallelism, constant time maximum and minimum operations, one or more instruction streams (ISs) which are sent to an equal number of partition sets of processors, assignment of tasks to the ISs using control parallelism. ASC also allows a network to interconnect the processing elements (PEs). This paper shows how ASC can be simulated with synchronous PRAM, and the converse. These results provide an important step in de ning the power of associative model in terms of PRAM which is the most well studied parallel model. Also, these simulations will provide numerous algorithms for ASC by providing an automatic method of converting algorithms from PRAM to ASC.	algorithm;associative model of data;central processing unit;compiler;computation;computer simulation;concurrent computing;data parallelism;loose coupling;maxima and minima;microprocessor;parallel computing;programmer;simd;shared memory;simulation;ti advanced scientific computer;task parallelism;time complexity	Darrell R. Ulm;Johnnie W. Baker	1998		10.1109/ICPP.1998.708456	parallel processing;computer architecture;parallel computing;concurrent computing;computer science;theoretical computer science;operating system;parallel algorithm;programming language	HPC	-9.13271857384113	39.25876319575335	136641
044c8cca807969a85cdb9c7470782badca57971c	a parallel pde-based numerical algorithm for computing the optical flow in hybrid systems	high performance computing;partial differential equations;graphic processor units;hybrid architectures;optical flow	In this paper, we propose a fine-to-coarse parallelization strategy in order to exploit, in a case study, a parallel hybrid architecture. We consider the Optical Flow numerical problem, modelled by partial differential equations, and implement a parallel multilevel software. Our hybrid software solution is a smart combination between codes on Graphic Processor Units (GPUs) and standard scientific parallel computing libraries on a cluster. Numerical experiments, on real satellite image sequences coming from a large dataset in a big data scenario, together with application profiling, highlight good results in terms of performance for the proposed approach.	algorithm;hybrid system;numerical analysis;optical flow	Salvatore Cuomo;Pasquale De Michele;Ardelio Galletti;Livia Marcellino	2017	J. Comput. Science	10.1016/j.jocs.2017.03.011	theoretical computer science;software;architecture;parallel computing;mathematical optimization;profiling (computer programming);big data;hybrid system;computer science;exploit;algorithm;optical flow;supercomputer	Logic	-6.628508797539159	38.19380187667241	136708
e441af362f1f0254f6f5fbff95bfc4ed1188a90b	self-adaptive hints for collective i/o	distributed memory;distributed system;sistema operativo;virtual machine;topology;dimensionnement;adaptability;adaptabilite;entrada salida;systeme reparti;image segmentation;gestion archivos;memoria compartida;communicating process;topologie;distributed computing;dimensioning;gestion fichier;interface programme application;file management;supercomputer;machine virtuelle;buffer system;adaptabilidad;topologia;self adaptation;sistema amortiguador;proceso comunicante;input output;supercomputador;sistema repartido;collective operations;message passing interface;operating system;file system;envoi message;application program interfaces;processus communicant;comportement utilisateur;segmentation image;courbe niveau;message passing;mpi io;calculo repartido;systeme exploitation;mpi;user behavior;information system;curva nivel;memoire repartie;systeme tampon;dimensionamiento;maquina virtual;calcul reparti;file hints;systeme information;comportamiento usuario;contour line;superordinateur;entree sortie;sistema informacion	• File hints are used to tell the MPI-IO library – which kind of access pattern to expect (high-level) – which feature to use with which parameter (low-level) • File hints are are passed to the library as MPI_Info objects: <key, value> tuple • Some file hints are defined in the standard: – High level (only one!):	high- and low-level;message passing interface	Joachim Worringen	2006		10.1007/11846802_32	self-certifying file system;supercomputer;parallel computing;real-time computing;computer science;class implementation file;message passing interface;versioning file system;operating system;unix file types;distributed computing;open;file system fragmentation;file control block	HPC	-18.018628973709713	42.46471575632741	136881
7dfc6b081bb40eeb553b98e39b9d3592699574a9	dynamic repartitioning of adaptively refined meshes	multilevel diffusion;multilevel graph repartitioning;scratch-remap;wavefront diffusion;data migration;numerical simulation	One ingredient which is viewed as vital to the successful conduct of many large-scale numerical simulations is the ability to dynamically repartition the underlying adaptive finite element mesh among the processors so that the computations are balanced and interprocessor communication is minimized. This requires that a sequence of partitions of the computational mesh be computed during the course of the computation in which the amount of data migration necessary to realize subsequent partitions is minimized, while all of the domains of a given partition contain a roughly equal amount of computational weight. Recently, parallel multilevel graph repartitioning techniques have been developed that can quickly compute high-quality repartitions for adaptive and dynamic meshes while minimizing the amount of data which needs to be migrated between processors. These algorithms can be categorized as either schemes which compute a new partition from scratch and then intelligently remap this partition to the original partition (hereafter referred to as scratch-remap schemes), or multilevel diffusion schemes. Scratch-remap schemes work quite well for graphs which are highly imbalanced in localized areas. On slightly to moderately imbalanced graphs and those in which imbalance occurs globally throughout the graph, however, they result in excessive vertex migration compared to multilevel diffusion algorithms. On the other hand, diffusion-based schemes work well for slightly imbalanced graphs and for those in which imbalance occurs globally throughout the graph. However, these schemes perform poorly on graphs that are highly imbalanced in localized areas, as the propagation of diffusion over long distances results in excessive edge-cut and vertex migration results. In this paper, we present two new schemes for adaptive repartitioning: Locally-Matched Multilevel Scratch-Remap (or LMSR) and Wavefront Diffusion. The LMSR scheme performs purely local coarsening and partition remapping in a multilevel context. In Wavefront Diffusion, the flow of vertices move in a wavefront from overbalanced to underbalanced domains. We present experimental evaluations of our LMSR and Wavefront Diffusion algorithms on synthetically generated adaptive meshes as well as on some application meshes. We show that our LMSR algorithm decreases the amount of vertex migration required to balance the graph and produces repartitionings of similar quality compared to state-of-the-art scratch-remap schemes. Furthermore, we show that our LMSR algorithm is more scalable in terms of execution time compared to state-of-the-art scratch-remap schemes. We show that our Wavefront Diffusion algorithm obtains significantly lower vertex migration requirements, while maintaining similar edge-cut results compared to state-of-the-art multilevel diffusion algorithms, especially for highly imbalanced graphs. Furthermore, we compare Wavefront Diffusion with LMSR and show that the former will result in lower vertex migration requirements and the later will result in higher quality edge-cut results. These results hold true regardless of the distance which diffusion is required to propagate in order to balance the graph. Finally, we discuss the run times of our schemes which are both capable of repartitioning an eight million node graph in under three seconds on a 128-processor Cray T3E.	adaptive filter;algorithm;anisotropic diffusion;categorization;central processing unit;computation;cray t3e;disk partitioning;false diffusion;finite element method;inter-process communication;numerical analysis;requirement;run time (program lifecycle phase);scalability;scratch (programming language);simulation;software propagation;wavefront .obj file	Kirk Schloegel;George Karypis;Vipin Kumar	1998	Proceedings of the IEEE/ACM SC98 Conference		computer simulation;parallel computing;data migration;computer science;theoretical computer science;distributed computing	HPC	-5.625268274716396	40.79647586576973	136926
1187b03579929c2dec13b7a5dcda47bcfc40ff49	a buffering approach to manage i/o in a normalized cross-correlation earthquake detection code for large seismic datasets		Continued advances in high-performance computing architectures constantly move the computational performance forward widening performance gap with I/O. As a result, I/O plays an increasingly critical role in modern data-intensive scientific applications.  We have developed a high-performance GPU-based software called cuNCC, which is designed to calculate seismic waveform similarity for subjects like hypocenter estimates and small earthquake detection. GPU's acceleration greatly reduced the compute time and we are currently investigating I/O optimizations, to tackle this new performance bottleneck.  In order to find an optimal I/O solution for our cuNCC code, we had performed a series of I/O benchmark tests and implemented buffering in CPU memory to manage the output transfers. With this preliminary work, we were able to establish that buffering improves the I/O bandwidth achieved, but is only beneficial when I/O bandwidth is limited, since the cost of the additional memory copy may exceed improvement in I/O. However, in realistic environment where I/O bandwidth per node is limited, and small I/O transfers are penalized, this technique will improve overall performance. In addition, by using a large memory system, the point at which computing has to stop to wait for I/O is delayed, enabling fast computations on larger data sets.	benchmark (computing);central processing unit;clustered file system;computation;cross-correlation;data compression;data-intensive computing;dynamic random-access memory;graphics processing unit;input/output;lustre;pci express;supercomputer;waveform	Dawei Mu;Pietro Cicotti;Yifeng Cui;En-Jui Lee;Po Chen	2017		10.1145/3093338.3093382	acceleration;cross-correlation;computational science;software;real-time computing;computation;input/output;waveform;bottleneck;computer science;bandwidth (signal processing)	HPC	-4.9546016460339315	41.72922051733908	136959
0a3bd2c643c92ac7399562c1c34a31af1d3ee47f	teaching parallel programming using java	paper;parallel programming education;parallel programming;gpgpu parallel programming teaching applied parallel computing course software engineering undergraduate students parallel programming tools distributed memory concurrent systems principle programming language shared memory systems multicore system symmetric multiprocessor smp systems java threads api computer clusters computer networks mpj express java mpi library mapreduce programming model hadoop general purpose computing on graphics processing units;software engineering;computing;cuda;laplace equations;programming techniques;games;mpj express;java mpi;nvidia;mpi;teaching computer aided instruction computer science education educational courses educational institutions java parallel programming software engineering;mapreduce;computer science;java instruction sets games parallel programming parallel processing laplace equations;hadoop;parallel processing;instruction sets;java	"""This paper presents an overview of the """"Applied Parallel Computing"""" course taught to final year Software Engineering undergraduate students in Spring 2014 at NUST, Pakistan. The main objective of the course was to introduce practical parallel programming tools and techniques for shared and distributed memory concurrent systems. A unique aspect of the course was that Java was used as the principle programming language. The course was divided into three sections. The first section covered parallel programming techniques for shared memory systems including multicore and Symmetric Multi-Processor (SMP) systems. In this section, Java threads API was taught as a viable programming model for such systems. The second section was dedicated to parallel programming tools meant for distributed memory systems including clusters and network of computers. We used MPJ Express---a Java MPI library---for conducting programming assignments and lab work for this section. The third and the final section introduced advanced topics including the MapReduce programming model using Hadoop and the General Purpose Computing on Graphics Processing Units (GPGPU)."""	apache hadoop;application programming interface;computer cluster;concurrency (computer science);distributed memory;general-purpose computing on graphics processing units;java;mapreduce;message passing interface;multi-core processor;parallel computing;programming language;programming model;programming tool;shared memory;software engineering;symmetric multiprocessing	Aamir Shafi;Aleem Akhtar;Ansar Javed;Bryan Carpenter	2014	2014 Workshop on Education for High Performance Computing	10.1109/EduHPC.2014.7	games;parallel processing;first-generation programming language;computer architecture;protocol;computing;parallel computing;java concurrency;programming domain;reactive programming;computer science;extensible programming;operating system;strictfp;real time java;programming paradigm;procedural programming;symbolic programming;inductive programming;programming language;java;system programming;concurrent object-oriented programming	HPC	-11.096940153123292	39.945871179019285	136969
55a54f6594958a7cf95a8ebc07b04713fb6a7282	design and implementation of gxp make -- a workflow system based on make	make;distributed computing;workflow systems	This paper describes the rational behind designing workflow systems based on the Unix make by showing a number of idioms useful for workflows comprising many tasks. It also demonstrates a specific design and implementation of such a workflow system called GXP make. GXP make supports all the features of GNU make and extends its platforms from single node systems to clusters, clouds, supercomputers, and distributed systems. Interestingly, it is achieved by a very small code base that does not modify GNU make implementation at all. While being not ideal for performance, it achieved a useful performance and scalability of dispatching one million tasks in approximately 16,000 seconds (60 tasks per second, including dependence analysis) on an 8 core Intel Nehalem node. For real applications, recognition and classification of protein-protein interactions from biomedical texts on a supercomputer with more than 8,000 cores are described.	data-intensive computing;dependence analysis;distributed computing;embedded system;gnu;interaction;make;nehalem (microarchitecture);scalability;scripting language;supercomputer;unix	Kenjiro Taura;Takuya Matsuzaki;Makoto Miwa;Yoshikazu Kamoshida;Daisaku Yokoyama;Nan Dun;Takeshi Shibata;Choi Sung Jun;Jun'ichi Tsujii	2010	2010 IEEE Sixth International Conference on e-Science	10.1016/j.future.2011.05.026	parallel computing;real-time computing;computer science;operating system;database;distributed computing;programming language	HPC	-7.970317101813099	43.51698716888968	137128
1347937863d315613e4a82833faee118f5deeca8	poster: a top-20 supercomputing facility rethinks its cooling efficiency with fluid-submersion cooling	high density;fluid submersion cooling;data center;dielectric fluid cooling;over clocking	Texas Advanced Computing Center (TACC) and Green Revolution Cooling (GRC) partnered to solve two common data center inefficiencies: the amount of energy spent cooling servers (relative to powering loads) and the inability to cool efficiently high-density, high-output devices such as blades, GPUs, and servers with over-clocked CPUs.  Using Green Revolution Cooling's liquid-submersion cooling solution, the CarnotJet system, TACC and GRC have been conducting efficiency and reliability studies with OEM servers for the past fifteen months with 100% uptime. Since April 2010, the self-contained system has demonstrated an 85% reduction in overall cooling energy while using 6 Watts or less per 100 Watts of IT. During over-clocking trials, the system successfully dissipated more than 200 Watts per socket while clocking current-generation Intel Xeon processors 35-60% over the base rate.	base rate;central processing unit;clock rate;computer cooling;data center;global variable;governance, risk management, and compliance;graphics processing unit;output device;overclocking;supercomputer;uptime;watts humphrey	David Banys;Aaron Dubrow	2011		10.1145/2148600.2148631	embedded system;data center;overclocking;parallel computing;simulation;computer hardware;computer science;operating system	HPC	-7.307477709718246	39.82773733785132	137148
4d382eea1b8e7a5b9565d177b6ee95ea1f83fe69	parallel programming with interacting processes	proceso secuencial comunicante;distributed memory systems;programacion paralela;programmation modulaire;communicating sequential process;distributed programs;simultaneidad informatica;parallel programming;programacion modular;parallel and distributed computing;programming model;systeme memoire repartie;concurrency;shared memory systems;processus sequentiel communicant;modular programming;parallel programs;simultaneite informatique;systeme memoire partagee;programmation parallele	In this paper, we argue that interacting processes (IP) with multiparty interactions are an ideal model for parallel programming. The IP model with multiparty interactions was originally proposed by N. Francez and I. R. Forman [1] for distributed programming of reactive applications. We analyze the IP model and provide the new insights into it from the parallel programming perspective. We show through parallel program examples in IP that the suitability of the IP model for parallel programming lies in its programmability, high degree of parallelism and support for modular programming. We believe that IP is a good candidate for the mainstream programming model for the both parallel and distributed computing in the future.	degree of parallelism;distributed computing;interaction;modular programming;parallel computing;programming model	Peiyi Tang;Yoichi Muraoka	1999		10.1007/3-540-44905-1_13	parallel computing;declarative programming;concurrency;programming domain;reactive programming;functional reactive programming;computer science;artificial intelligence;operating system;modular programming;database;distributed computing;programming paradigm;inductive programming;programming language;algorithm;concurrent object-oriented programming;parallel programming model	HPC	-15.269729945909106	39.95295969641207	137159
6f36ef911d243d856530340e56d22f6c0eab9254	co-design of a particle-in-cell plasma simulation code for intel xeon phi: a first look at knights landing	computational physics;paper;publikationer;plasma physics;konferensbidrag;physics;artiklar;rapporter;openmp;intel xeon phi;particle in cell methods	Three dimensional particle-in-cell laser-plasma simulation is an important area of computational physics. Solving state-of-the-art problems requires large-scale simulation on a supercomputer using specialized codes. A growing demand in computational resources inspires research in improving efficiency and co-design for supercomputers based on manycore architectures. This paper presents first performance results of the particle-in-cell plasma simulation code PICADOR on the recently introduced Knights Landing generation of Intel Xeon Phi. A straightforward rebuilding of the code yields a 2.43 x speedup compared to the previous Knights Corner generation. Further code optimization results in an additional 1.89 x speedup. The optimization performed is beneficial not only for Knights Landing, but also for high-end CPUs and Knights Corner. The optimized version achieves 100 GFLOPS double precision performance on a Knights Landing device with the speedups of 2.35 x compared to a 14-core Haswell CPU and 3.47 x compared to a 61-core Knights Corner Xeon Phi.	central processing unit;code;computation;computational physics;computational resource;double-precision floating-point format;flops;haswell (microarchitecture);knights;manycore processor;mathematical optimization;multi-core processor;particle-in-cell;plasma active;program optimization;simulation;speedup;supercomputer;xeon phi	Igor Surmin;Sergey Bastrakov;Zakhar Matveev;Evgeny Efimenko;Arkady Gonoskov;Iosif Meyerov	2016		10.1007/978-3-319-49956-7_25	plasma;computational science;parallel computing;computer hardware;computer science;xeon phi	HPC	-5.244666109269069	39.29939819537087	137171
1734b60ad74f6970283635b24270c5bc376b3c26	partial value number redundancy elimination	algorithme rapide;instruction level parallel;lenguaje programacion;paralelismo instruccion;haute performance;storage access;programming language;optimizing compiler;redundancia;efficient algorithm;distributed computing;redundancy elimination;optimizacion compiladora;memory access;redundancy;parallelisme instruction;numerotation;data dependence;fast algorithm;compiler optimization;acces memoire;path dependence;data flow analysis;alto rendimiento;langage programmation;acceso memoria;calculo repartido;numbering;analyse flux donnee;resource availability;compilateur optimisation;numerotacion;data flow;instruction level parallelism;optimizing compilers;high performance;calcul reparti;algoritmo rapido;optimisation compilateur;redondance	When exploiting instruction level parallelism in a runtime optimizing compiler, it is indispensable to quickly remove redundant computations and memory accesses to make resources available. We propose a fast and efficient algorithm called Partial Value Number Redundancy Elimination (PVNRE), which completely fuses Partial Redundancy Elimination (PRE) and Global Value Numbering (GVN). Using value numbers in the data-flow analyses, PVNRE can deal with datadependent redundancy, and can quickly remove path-dependent partial redundancy by converting value numbers at join nodes on demand during the data-flow analyses. Compared with the naive combination of GVN, PRE, and copy propagation, PVNRE has a maximum 45% faster analyses speed, but the same optimizing power on SPECjvm98.	algorithm;computation;copy propagation;data dependency;dataflow;exception handling;experiment;global value numbering;instruction-level parallelism;iteration;java;just-in-time compilation;numerical analysis;optimizing compiler;overhead (computing);parallel computing;partial redundancy elimination;path dependence;software propagation	Rei Odaira;Kei Hiraki	2004		10.1007/11532378_29	parallel computing;computer science;global value numbering;theoretical computer science;operating system;optimizing compiler;database;distributed computing;programming language;algorithm;partial redundancy elimination	PL	-17.66896423261198	40.01061574866788	137321
b4cf89b5d813fff6d552042b061c037856d75a11	lessons learned about one-way, dataflow constraints in the garnet and amulet graphical toolkits	graphical interface;programming environment;constraint usage;lazy evaluation;constraint satisfaction;design and implementation;lessons learned;constraint experience;eager evaluation;one way dataflow constraints	One-way, dataflow constraints are commonly used in graphical interface toolkits, programming environments, and circuit applications. Previous papers on dataflow constraints have focused on the design and implementation of individual algorithms. In contrast, this article focuses on the lessons we have learned from a decade of implementing competing algorithms in the Garnet and Amulet graphical interface toolkits. These lessons reveal the design and implementation tradeoffs for different one-way, constraint satisfaction algorithms. The most important lessons we have learned are that (1) mark-sweep algorithms are more efficient than topological ordering algorithms; (2) lazy and eager evaluators deliver roughly comparable performance for most applications; and (3) constraint satisfaction algorithms have more than adequate speed, except that the storage required by these algorithms can be problematic.	amulet microprocessor;algorithm;constraint satisfaction;dataflow;graphical user interface;lazy evaluation;list of toolkits;one-way function;topological sorting	Bradley T. Vander Zanden;Richard L. Halterman;Brad A. Myers;Richard G. McDaniel;Rob Miller;Pedro A. Szekely;Dario A. Giuse;David S. Kosbie	2001	ACM Trans. Program. Lang. Syst.	10.1145/506315.506318	real-time computing;constraint satisfaction;computer science;theoretical computer science;eager evaluation;lazy evaluation;graphical user interface;programming language	PL	-17.83066118126156	33.391295502927925	137433
5af5b1a084ff363acba0b6ca87d0836af6a5c89a	domain-based mapreduce programming model for complex scientific applications	runtime;computational modeling;data structures;programming computational modeling adaptation models runtime data models mathematical model data structures;mathematical model;adaptation models;programming;data models	The MapReduce programming model has introduced simple interfaces to a large class of applications. Its easy-to-use APIs and autonomic parallelization are attracting attentions from scientific community. However, current MapReduce-style scientific frameworks focus more on the most popular MapReduce applications that can be easily partitioned and involve little communication across map or reduce tasks. They typically lack adequate support for more complex applications that involve iterative communication and dynamic domain partitioning. In this paper, via abstraction of numerical domains of many applications, we present a domain-based MapReduce programming model for iterative and dynamic scientific applications. Using real-world applications, we introduce a general methodology to adapt APIs of legacy scientific codes into the more developer-friendly MapReduce-like programming model.	application programming interface;autonomic networking;code;computation;computational science;iterative method;mapreduce;numerical analysis;parallel computing;programming model;requirement	Min Li;Xin Yang;Xiaolin Li	2013	2013 IEEE 10th International Conference on High Performance Computing and Communications & 2013 IEEE International Conference on Embedded and Ubiquitous Computing	10.1109/HPCC.and.EUC.2013.87	data modeling;computational science;programming;parallel computing;data structure;reactive programming;computer science;theoretical computer science;operating system;mathematical model;distributed computing;inductive programming;computational model	HPC	-9.788717984446558	38.270022989850325	137467
0568f22101655784732ce5e65ce6491ee89c9b45	logical organization of the pact i compiler	pact i compiler;logical organization	"""LOGICAL ORGANIZATION 281 locations used for the variables in the target machine. A minimal requirement is that all arrays have their maximum dimensions specified by variable definition sentences. Translation of PACT I Language into 701 Language 701 storage assignments for target language One of the most striking things we notice about the abstract language is that it is hierarchical and hence invites a hierarchical form of storage assignment. First, we note that regions may be referred to only in tote and hence can be completely addressed in our target language provided only that we know the origin. The variables can be assigned as a universal form of storage for a given program and the numbers can be compacted and assigned as universal storage also. We also note that according to the rules of our abstract language we are permitted to overlap between regions any """"Result of Step"""" storage we desire into a pool we shall call temporary storage. FinMly if we establish the rule that all library programs are independent then we know that we can overlap any temporary storage of these programs in a special pool we shall call perishable storage. A schematic diagram of our storage appears on following page. Subscripts, we note on the other hand, are defined only within a specific region and in our compiler we shall associate our temporary storage and constant storage necessary for array storage generation directly with the region involved. This is not the only way in which the subscript storage problem might be solved. We might also associate some of the constants with the arrays or in a special array definition storage. Our decision in this respect is somewhat arbitrary; however, the alternative method of generation may require more intercommunication between the variable definition and loop generation stages of the compiler, something which we wish to avoid in the interest of independence of stages."""	array data structure;compiler;diagram;requirement;schematic;tote board	Owen R. Mock	1956	J. ACM	10.1145/320843.320846	computer architecture;parallel computing;computer science;programming language	PL	-14.553086300539983	32.80790625712418	137553
18ee467234b8c19cb93d9b7cfb520db699fb72c8	a distributed parallel resampling algorithm for large images	algoritmo paralelo;entrada salida;cluster;parallel algorithm;storage access;amas;data locality;algorithme parallele;input output;estructura datos;algorithme reparti;cluster system;acces memoire;acceso memoria;algoritmo repartido;structure donnee;monton;distributed algorithm;data structure;entree sortie	Image resampling is an important and computation-intensive task in many fields. In order to improve its efficiency, a distributed parallel resampling algorithm with good data locality is provided, in which each processor entirely localizes its computation through getting and resampling the corresponding area in output image for local sub input image. A data structure is put forward to save the information of irregular sub output image, and a method is presented to compute local output area. At last, all of the sub output images are gathered and stitched into the integrated target image. By implementing the algorithm on a cluster system, the results show that, for large images, this parallel algorithm improves the efficiency of resampling greatly.	computation;data structure;image scaling;image stitching;locality of reference;parallel algorithm;pixel;resampling (statistics);scalability;speedup	Yan-Huang Jiang;Xuejun Yang;Huadong Dai;Huizhan Yi	2003		10.1007/978-3-540-39425-9_71	input/output;distributed algorithm;parallel computing;data structure;computer science;theoretical computer science;parallel algorithm;programming language;algorithm;cluster	ML	-16.034878042946577	42.58036653471659	137768
a9939a582fbad83f0e2080bef19cbbcab1abe3f4	code generation: a strategy for neural network simulators	simulation;code generation;computer algebra system;python;simulation software;spiking neural network;numerical integration;graphics processing units;mathematical model;graphic processing unit;computer algebra systems;spiking neural networks;c;high performance;neural network	We demonstrate a technique for the design of neural network simulation software, runtime code generation. This technique can be used to give the user complete flexibility in specifying the mathematical model for their simulation in a high level way, along with the speed of code written in a low level language such as C+ +. It can also be used to write code only once but target different hardware platforms, including inexpensive high performance graphics processing units (GPUs). Code generation can be naturally combined with computer algebra systems to provide further simplification and optimisation of the generated code. The technique is quite general and could be applied to any simulation package. We demonstrate it with the ‘Brian’ simulator ( http://www.briansimulator.org ).	c++;code generation (compiler);computer algebra system;computer graphics;graphics processing unit;high-level programming language;low-level programming language;mathematical model;mathematical optimization;neural network simulation;self-modifying code;simulation software;simulators;symbolic computation	Dan F. M. Goodman	2010	Neuroinformatics	10.1007/s12021-010-9082-x	computational science;computer architecture;neuroscience;python;simulation software;numerical integration;computer science;theoretical computer science;machine learning;mathematical model;code generation;source code;spiking neural network	Arch	-11.222018257879588	35.430429007081464	137790
302df761300bf80a1fda74c5f1aa214d8e5b2384	a compilation scheme for macro-dataflow computation on hierarchical multiprocessor systems			computation;dataflow;multiprocessing;reactive programming	Hironori Kasahara;Hiroki Honda;Masahiko Iwata;Morihiko Hirota	1990			distributed computing;symmetric multiprocessor system;parallel computing;dataflow;computation;multiprocessor scheduling;multiprocessing;macro;computer science	Embedded	-9.683260599307097	42.945334097093074	137935
5ed69305db9c6cf38536490a1b82339cf6ff7725	high-speed routing in a distributed memory parallel computer system: a simulation study.	distributed memory;parallel computer;simulation study;high speed		distributed memory;linc;parallel computing;routing;simulation	Patrick W. Dowd	1991	Int. Journal in Computer Simulation		cuda pinned memory;uniform memory access;shared memory;interleaved memory;computer architecture;parallel computing;distributed memory;computer science;computer data storage;distributed computing;overlay;flat memory model;non-uniform memory access;supercomputer architecture	HPC	-10.637860786581193	43.39004825833271	138017
1c999a442b0ad64e627d476dc0f271f2588d01ca	compiling data intensive applications with spatial coordinates	distributed memory;distributed system;algoritmo paralelo;data intensive application;satellite data;compilacion;distribution donnee;systeme reparti;parallel algorithm;compilateur;shared memory;localite;memoria compartida;distributed memory machine;locality;langage java;cluster of workstations;compiler;application intensive;data distribution;algorithme parallele;sistema repartido;medical image;intensive application;compilation;lenguaje java;memoire repartie;scientific research;compilador;memoire partagee;java language	Processing and analyzing large volumes of data plays an increasingly important role in many domains of scienti c research. We are developing a compiler which processes data intensive applications written in a dialect of Java and compiles them for e cient execution on cluster of workstations or distributed memory machines. In this paper, we focus on data intensive applications with two important properties: 1) data elements have spatial coordinates associated with them and the distribution of the data is not regular with respect to these coordinates, and 2) the application processes only a subset of the available data on the basis of spatial coordinates. These applications arise in many domains like satellite data-processing and medical imaging. We present a general compilation and execution strategy for this class of applications which achieves high locality in disk accesses. We then present a technique for hoisting conditionals which further improves e ciency in execution of such compiled codes. Our preliminary experimental results show that the performance from our proposed execution strategy is nearly two orders of magnitude better than a naive strategy. Further, up to 30% improvement in performance is observed by applying the technique for hoisting conditionals.	code;compiler;computer cluster;data-intensive computing;distributed memory;iteration;java;locality of reference;medical imaging;workstation	Renato A. C. Ferreira;Gagan Agrawal;Ruoming Jin;Joel H. Saltz	2000		10.1007/3-540-45574-4_22	shared memory;compiler;parallel computing;real-time computing;scientific method;distributed memory;computer science;artificial intelligence;operating system;database;distributed computing;parallel algorithm;programming language;algorithm	HPC	-16.342491897822853	42.32010196042541	138130
b9bb319facb65e545ba03288835bab1729405c40	design and implementation of pvm-based portable distributed shared memory system on the workstation cluster environment	distributed memory;distributed memory systems;performance problem;concurrent computing;shared memory;performance evaluation;personal computer;active messages;high speed networks;distributed computing;workstation cluster environment;parallel programming;cluster of workstations;portability;software performance;computer networks;computer architecture;parallel programming workstations microcomputers high speed networks computer architecture memory architecture computer networks concurrent computing distributed computing software performance;workstations distributed memory systems shared memory systems virtual machines performance evaluation;pvm based portable distributed shared memory system;shared memory systems;virtual machines;design and implementation;parallel systems;memory architecture;workstations;parallel computer;portability pvm based portable distributed shared memory system workstation cluster environment cluster of workstations performance problem;shared memory system;distributed shared memory;microcomputers;workstation cluster	Cluster of workstations or personal computers connected with high speed network has become one of major architectures of distributed memory parallel computers. However, software on the cluster environment is still not improved in performance. In particular, there has not been proposed a standard distributed shared memory mechanism on the cluster environment. The distributed shared memory can be a solution of programming style on distributed memory parallel system including clusters because we know from experiences that shared memory model makes programming easy. It must be implemented with care for the performance problem because we cannot assume any hardware support for shared memory system in the cluster environment. Another, but serious problem is the portability. In this paper, we discuss the design and implementation of portable distributed shared memory system. Our shared memory system is based on PVM in consideration of portability. Our contribution in this paper is the design and implementation of portable shared memory system on the cluster environment using faithful implementation of active messages fully in software, together with an enhancement of PVM to support active messages.	distributed shared memory;parallel virtual machine;workstation	Hiroyuki Sato;Takeshi Nanri;Masaaki Shimasaki	1997		10.1109/ICPADS.1997.652602	shared disk architecture;uniform memory access;distributed shared memory;shared memory;computer architecture;parallel computing;distributed memory;workstation;concurrent computing;software performance testing;computer cluster;memory geometry;computer science;virtual machine;operating system;microcomputer;distributed computing;overlay;conventional memory;extended memory;flat memory model;spmd;data diffusion machine;memory map;memory management;supercomputer architecture	HPC	-11.64299603823812	44.641080229254385	138243
0c0f2ddb75bd919dedc9919d1c8745a71e4a2a11	exploiting distributed and shared memory hierarchies with hitmap	programming topology layout indexes synchronization computational modeling libraries;parallel programming distributed shared memory systems message passing;pure mpi models distributed memory hierarchy shared memory hierarchy hitmap multicomputers shared memory multicore computers programming approach message passing paradigm highly parallel multicore systems programming paradigm program design distributed computing communication structure synchronization structure openmp models	Current multicomputers are typically built as interconnected clusters of shared-memory multicore computers. A common programming approach for these clusters is to simply use a message-passing paradigm, launching as many processes as cores available. Nevertheless, to better exploit the scalability of these clusters and highly-parallel multicore systems, it is needed to efficiently use their distributed- and shared-memory hierarchies. This implies to combine different programming paradigms and tools at different levels of the program design. This paper presents an approach to ease the programming for mixed distributed and shared memory parallel computers. The coordination at the distributed memory level is simplified using Hitmap, a library for distributed computing using hierarchical tiling of data structures. We show how this tool can be integrated with shared-memory programming models and automatic code generation tools to efficiently exploit the multicore environment of each multicomputer node. This approach allows to exploit the most appropriate techniques for each model, easily generating multilevel parallel programs that automatically adapt their communication and synchronization structures to the target machine. Our experimental results show how this approach mimics or even improves the best performance results obtained with manually optimized codes using pure MPI or OpenMP models.	automatic programming;code generation (compiler);computer;data dependency;data structure;distributed computing;distributed memory;heterogeneous system architecture;memory hierarchy;message passing interface;model transformation;multi-core processor;openmp;parallel computing;polyhedron;polytope model;programming paradigm;scalability;shared memory;sparse matrix;tiling window manager	Ana Moreton-Fernandez;Arturo González-Escribano;Diego R. Llanos Ferraris	2014	2014 International Conference on High Performance Computing & Simulation (HPCS)	10.1109/HPCSim.2014.6903696	uniform memory access;distributed shared memory;shared memory;memory model;computer architecture;parallel computing;distributed memory;computer science;distributed computing;overlay;spmd;data diffusion machine;memory map;supercomputer architecture	HPC	-11.888128766267815	39.55681234277197	138416
b05a4cce9e9265496ddb0c1451e11bdd7dc288c1	performance evaluation of a simulated data-flow computer with low-resolution act	computers;processing element;directed acyclic graph;digital computers;graph theory;processor architecture;cycle time;computer aided design;resolution;general and miscellaneous mathematics computing and information science;run time computers;performance evaluation;programming language;simulation 990210 supercomputers 1987 1989;multiprocessor systems;computer systems simulation;performance;low resolution;mathematical logic;interconnection network;computer networks;multiprocessing computers;data structures;array processors;data flow processing;computerized simulation;associative processing computers;data flow analysis;communication cost;parallel processing computers;associative memory;algorithms;logic programs;data flow;architecture computers;computer systems performance;modes of operation;programming;supercomputers;programming languages	In the ambition to go beyond a single-processor architecture, to enhance programmability, and to take advantage of the power brought by VLSI devices, data-flow systems and languages were devised. Indeed, due to their functional semantics, these languages offer promise in the area of multiprocessor systems design and will possibly enable the development of computers comprising large numbers of processors with a corresponding increase in performance. Several important design problems have to be surmounted and are described here. The authors thus present a ''variable-resolution'' scheme, where the level of primitives can be selected so that the overhead due to the data-flow mode of operation is reduced. A deterministic simulation of a data-flow machine with a variable number of processing elements was undertaken and is described here. The tests were performed using various program structures such as directed acyclic graphs, vector operations, and array handling. The performance results observed confirm the advantage of actors with variable size and indicate the presence of a trade-off between overhead control and the need to control parallelism in the program. The authors also look at some of the communication issues and examine the effect of several interconnection networks (dual counter-rotating rings, daisy chain, and optimal doublemore » loop network) on the performance. It is shown how increasing communication costs induce a performance degradation that can be masked when the size of the basic data-flow actor is increased. The associative memory cycle time is also changed with similar conclusions. Finally, the lower-resolution scheme is applied to the array handling case; the observations confirm the advantage of a more complex actor at the array level.« less		Jean-Luc Gaudiot;Milos D. Ercegovac	1985	J. Parallel Distrib. Comput.	10.1016/0743-7315(85)90018-8	data flow diagram;programming;computer architecture;mathematical logic;parallel computing;resolution;image resolution;performance;microarchitecture;cycle time variation;computer science;graph theory;theoretical computer science;operating system;data-flow analysis;distributed computing;programming language;directed acyclic graph;algorithm	HPC	-13.668844255903524	40.726768806781095	138444
13168ec3af2f79c976337e1096e7a03f6d693a2d	an experimental evaluation of processor pool-based scheduling for shared-memory numa multiprocessors	tratamiento paralelo;evaluation performance;shared memory;performance evaluation;traitement parallele;multiprocessor;memoria compartida;evaluacion prestacion;operating system;scheduling;ordonamiento;systeme parallele;parallel system;experimental evaluation;multiprocesador;system architecture;parallel applications;parallel processing;ordonnancement;sistema paralelo;memoire partagee;multiprocesseur	In this paper we describe the design, implementation and e xperimental evaluation of a technique for operating system schedulers called processor pool-based scheduling [51]. Our technique is designed to assign processes (or kernel threads) of parallel applications to processors in multiprogrammed, shared-memory NUMA multiprocessors. The results of the experiments conducted in this research demonstrate that: 1) Pool-based scheduling is an ef fective method for localizing application execution and reducing mean response times. 2) Although application parallelism should be considered, the optimal pool size is a function of the the system architecture. 3) The strategies of placing ne w applications in a pool with the largest potential for inpool growth ( i.e., the pool containing the fewest jobs) and of isolating applications from each other are desirable properties of algorithms for operating system schedulers executing on NUMA architectures. The ‘ ‘Worst-Fit’’ policy we examine incorporates both of these properties.	algorithm;central processing unit;experiment;job stream;non-uniform memory access;operating system;parallel computing;scheduling (computing);shared memory;systems architecture	Tim Brecht	1997		10.1007/3-540-63574-2_20	shared memory;parallel processing;parallel computing;real-time computing;multiprocessing;computer science;operating system;distributed computing;scheduling	Arch	-16.449750929476465	44.070973812986836	138529
afcee14fa931094b157bbdf616352fd248dccbc2	improvements in multiprocessor system design	multiprocessor system design;system design;limiting factor	Three Factors have limited the commercial success of multiprocessor systems: entrg level cost, range of performance, and ease of application. Recentlg, the confluence of several streams of development in computer system design has removed these limiting Factors making possible a new class of multiproces-sot systems based on VLSI components offering mainframe performance at microcomputer prices in traditional timeshar-ing environments and holding the promise of supercomputer performance at one-hundredth the cost in specialized applications. Multiprocessors have been of interest to computer scientists and designers from the time of the very First electronic computers to the present. A number of commerciallg available multiprocessors have appeared over that span and some have enjoyed modest success. Three Factors have limited the commercial success of multiprocessor sgstems: entry level cost, range of performance, and ease of application. In first, second and third generation technologies, each processor in a dual processor sgstem required as much ~upporting power, packaging, cooling and service as two independent uniprocessor systems making the cost of a minimum multiprocessor sgstem high and susceptible to price-performance eclipse bg relatively small advances in technology for uniprocessors. When applied to multiprocessors, the hardware and software system design practices which yield good uniprocessor performance lead to performance bottlenecks due to memory bandwidth and system service resource starvation. These bottlenecks limit the range of cost-effective multiprocessing to at most four processors. Exploitation oF concurrent program execution by applications software requires understanding of and technology For problem decomposition, load distribution, sgn-chronization and hazard avoidance. These ave difficult areas, traditionally left to practitioners of real-time mul-titasking, for which there have been few tools and little operating sgstem and language support. Recentlg, the confluence of several streams of development in computer ~gs-tem design has removed these limiting Factors making possible a new class of multiprocessor systems based on VLSI components offering mainframe performance at microcomputer prices in traditional timesharing environments and holding the promise of supercomputer performance at one-hundredth the cost in specialized applications. Recognizing this potential, a number of computer manufacturers are reducing these developments to practice in the for o£ multiprocessor computer sgstems.	bsd;central processing unit;computer cooling;computer scientist;concurrent computing;confluence;dynix;eclipse;focus;hardware description language;load balancing (computing);mainframe computer;memory bandwidth;microcomputer;microprocessor;multiprocessing;multiprocessor scheduling;real-time clock;scheduling (computing);semiconductor;sion's minimax theorem;small-outline transistor;software system;starvation (computer science);supercomputer;systems design;time-sharing;uniprocessor system;unix;ver (command);very-large-scale integration	David P. Rodgers	1985		10.1145/327010.327215	limiting factor;symmetric multiprocessor system;systems design	Arch	-12.448373138525673	40.70599630175339	138609
f210085f0d69cf0233d9e774a0f9ffa87ff21b44	autotuning skeleton-driven optimizations for transactional worklist applications	concurrent computing;concurrent programming;optimization space static exhaustive search skeleton driven optimization autotuning transactional worklist application pattern based programming parallel programs generic communication computation patterns structured programs code generation hierarchical autotuning mechanism stamp benchmark;parallel patterns and application transparent adaptation;prefetching;parallel programming;runtime;skeleton programming;transaction processing multiprocessing systems parallel programming program compilers;skeleton programming optimization prefetching runtime parallel programming concurrent computing;optimization;multiprocessing systems;parallel patterns and application transparent adaptation concurrent programming transactional memory;transaction processing;transactional memory;program compilers	Skeleton or pattern-based programming allows parallel programs to be expressed as specialized instances of generic communication and computation patterns. In addition to simplifying the programming task, such well structured programs are also amenable to performance optimizations during code generation and also at runtime. In this paper, we present a new skeleton framework that transparently selects and applies performance optimizations in transactional worklist applications. Using a novel hierarchical autotuning mechanism, it dynamically selects the most suitable set of optimizations for each application and adjusts them accordingly. Our experimental results on the STAMP benchmark suite show that our skeleton autotuning framework can achieve performance improvements of up to 88 percent, with an average of 46 percent, over a baseline version for a 16-core system and up to 115 percent, with an average of 56 percent, for a 32-core system. These performance improvements match or even exceed those obtained by a static exhaustive search of the optimization space.	auto-tune;basic stamp;baseline (configuration management);benchmark (computing);brute-force search;code generation (compiler);cognitive dimensions of notations;compiler;computation;cross-validation (statistics);mathematical optimization;parallel computing;programmer;run time (program lifecycle phase);software transactional memory;straight skeleton	Luís Fabrício Wanderley Góes;Nikolas Ioannou;Polychronis Xekalakis;Murray Cole;Marcelo Cintra	2012	IEEE Transactions on Parallel and Distributed Systems	10.1109/TPDS.2012.140	computer architecture;transactional memory;parallel computing;real-time computing;concurrent computing;transaction processing;computer science;operating system;database;distributed computing;programming language	HPC	-6.580783035396418	46.137039709812896	138611
1859570fdb4a0d1b55cf594e79fca31908c6cbe8	distributed network computing over local atm networks	distributed application;distributed system;partial differential equation;protocols;estacion trabajo;interface programmation application;systeme reparti;red local;parallel matrix multiplication local atm network distributed network computing processors high speed local area networks asynchronous transfer mode high speed network standards performance characteristics end to end communication workstations fore systems asx 100 atm switch communication performance application programming interfaces atm api bsd socket programming interface remote procedure call parallel virtual machine message passing library distributed programming communication protocol layer;performance evaluation;distributed networks;high speed networks;station travail;telecommunication network;distributed programs;application program interface;satisfiability;atm networks;remote procedure call;transmision asincronica;local network;workstation;sistema repartido;partial differential equations;computer networks distributed computing asynchronous transfer mode communication switching switches protocols local area networks high speed networks communication standards workstations;red telecomunicacion;application program interfaces;reseau telecommunication;performance evaluation local area networks asynchronous transfer mode application program interfaces pipeline processing matrix multiplication partial differential equations remote procedure calls protocols;message passing;communication protocol;asynchronous transmission;transmission asynchrone;matrix multiplication;parallel virtual machine;network interface;reseau local;remote procedure calls;high speed;device driver;local area networks;local area network;network computing;asynchronous transfer mode;pipeline processing	Communication between processors has long been the bottleneck of distributed network computing. However, recent progress in switch-based high-speed Local Area Networks (LANs) may be changing this situation. Asynchronous Transfer Mode (ATM) is one of the most widely-accepted and emerging high-speed network standards which can potentially satisfy the communication needs of distributed network computing. In this paper, we investigate distributed network computing over local ATM networks. We first study the performance characteristics involving end-to-end communication in an environment that includes several types of workstations interconnected via a Fore Systems' ASX-100 ATM Switch. We then compare the communication performance of four different Application Programming Interfaces (APIs). The four APIs were Fore Systems ATM API, BSD socket programming interface, Sun's Remote Procedure Call (RPC), and the Parallel Virtual Machine (PVM) message passing library. Each API represents distributed programming at a different communication protocol layer. We evaluate parallel Matrix Multiplication over the local ATM network. The experimental results show that network computing is promising over local ATM networks.	atm turbo;alternating turing machine;application programming interface;bsd;berkeley sockets;central processing unit;communications protocol;computer network programming;distributed computing;end-to-end principle;matrix multiplication;message passing;parallel virtual machine;protocol stack;remote procedure call;workstation	Mengjou Lin;Jenwei Hsieh;David Hung-Chang Du;Joseph P. Thomas;James A. MacDonald	1994		10.1109/49.382163	local area network;embedded system;real-time computing;network architecture;telecommunications;computer science;atm adaptation layer;asynchronous transfer mode;distributed computing;distributed-queue dual-bus;computer network	HPC	-18.320005597925118	43.090360901712344	138727
8d1ed9a5a2252b904c78d065c9733fab85127305	scalability analysis and parallel execution of unstructured problems		Unstructured parallelism is the hardest problem to analyze and to program. In this paper we present a generic approach TGEX for analyzing and executing unstructured problems. It separates the speciication of a computational problem from the control of the parallel execution. A computational problem is rst partitioned in terms of a computation task graph which serves as a machine-independent representation of the parallel program. This allows fast and accurate performance simulation with the Pamela tool and eecient parallel execution. Experimental results of using Pamela and TGEX for scalability analysis and parallel execution of unstructured problems are reported. 1	computation;computational problem;implicit parallelism;parallel computing;performance prediction;scalability;simulation	Hai-Xiang Lin;Arjan J. C. van Gemund;Johan Meijdam	1996			parallel computing;scalability;distributed computing;computer science	HPC	-10.461976662295548	39.4257232060281	138821
0b872ffc18b60d532abac7249b25014373c906e8	classification of thread profiles for scaling application behavior		Exascale applications will exploit a massive amount of parallelism. The analysis of computation and communication requirements at thread-level provides important insight into the application behavior useful to optimize the design of the exascale architecture. Performing such an analysis is challenging because the exascale system is not available yet. The target applications can be profiled only on existing machines, processing a significantly smaller amount of data and exploiting significantly less parallelism.#R##N##R##N#To tackle this problem we propose a methodology that couples a) unsupervised machine-learning techniques to consistently classify threads in different program runs, and b) extrapolation techniques to learn how thread classes behave at scale. The main contribution of this work is the classification methodology that assigns a class to each thread observed during a set of experimental runs carried out by varying the parallelism and the processed data size. Based on this classification we generate extrapolation models per thread class to predict the profile at a scale significantly larger than the initial experiments. The availability of per-thread-class extrapolation models simplifies the analysis of exascale systems because we manage a small number of thread classes rather than a huge number of individual threads.#R##N##R##N#We apply the methodology to different computing domains including: large-scale graph analytics, fluid dynamics, and radio astronomy. The proposed approach accurately classifies threads, whereas state-of-the-art techniques fail. The resulting extrapolation models have prediction errors of less than 10% for a real-life radio-astronomy case study.	image scaling	Giovanni Mariani;Andreea Anghel;Rik Jongerius;Gero Dittmann	2017	Parallel Computing	10.1016/j.parco.2017.04.006	theoretical computer science;extrapolation;parallel computing;profiling (computer programming);cluster analysis;architecture;computer science;small number;exploit;thread (computing);analytics	HPC	-4.748982419202541	45.030577667331336	138846
0c240cae443b9428d2962e2fed0e9797b9485199	parallel simulation of timed petri-nets	petri nets;discrete event simulation;graphical user interfaces;intel ipsc/2 distributed memory multiprocessor;discrete-event simulation;graphics-based front-end;parallel computer;synchronization;timed petri-nets	This paper considers the problem of using a parallel computer to execute discrete-event simulations of timed Petri-nets. We first develop synchronization and simulation algorithms for this task, and discuss a parallelized Petri-net simulator which has been implemented on an Intel iPSC/2 distributed memory multiprocessor. Next we describe a graphics-based frontend for the simulator, used to build timed Petri-net models. Finally, we discuss empirical studies of the simulator’s performance on a variety of timed Petrinet models.	algorithm;consistency model;distributed memory;graphics;multiprocessing;parallel computing;petri net;simulation	David M. Nicol;Subhas C. Roy	1991			computer simulation;parallel computing;real-time computing;computer architecture simulator;simulation;computer science;distributed computing;petri net	HPC	-10.700220150133884	40.42671496875508	138947
91c28af8fa7fd9f8afb621eb322c0edf27fc2781	cache related pre-emption delays in embedded real-time systems		.......................................................................................................................... 3 List of Tables .................................................................................................................. 9 List of Figures .............................................................................................................. 10 Acknowledgements .................................................................................................... 13 Declaration ................................................................................................................... 15 Chapter	declaration (computer programming);embedded system;real-time clock;real-time computing	Will Lunniss	2014			parallel computing;real-time computing;computer science;distributed computing	EDA	-9.903229271813638	44.351698616752465	139001
da4f0b77e96f458e74301bd2dbb56e95cff6059b	advanced architecture for java universal message passing (aa-jump)		The Architecture for Java Universal Message Passing (A-JUMP) is a Java based message passing framework. AJUMP offers flexibility for programmers in order to write parallel applications making use of multiple programming languages. There is also a provision to use various network protocols for message communication. The results for standard benchmarks like ping-pong latency, Embarrassingly Parallel (EP) code execution, Java Grande Forum (JGF) Crypt etc. gave us the conclusion that for the cases where the data size is smaller than 256K bytes, the numbers are comparative with some of its predecessor models like Message Passing Interface CHameleon version 2 (MPICH2), Message Passing interface for Java (MPJ) Express etc. But, in case, the packet size exceeds 256K bytes, the performance of the A-JUMP model seems to be severely hampered. Hence, taking that peculiar behaviour into account, this paper talks about a strategy devised to cope up with the performance limitation observed under the base A-JUMP implementation, giving birth to an Advanced A-JUMP (AAJUMP) methodology while keeping the basic workflow of the original model intact. AA-JUMP addresses to improve performance of A-JUMP by preserving its various traits like portability, simplicity, scalability etc. which are the key features offered by flourishing High Performance Computing (HPC) oriented frameworks of now-a-days. The head-to-head comparisons between the two message passing versions reveals 40% performance boost; thereby suggesting AAJUMP a viable approach to adopt under parallel as well as distributed computing domains.	apache activemq;byte;communications protocol;crypt (unix);dna binding site;distributed computing;embarrassingly parallel;expectation propagation;inter-process communication;java version history;kilobyte;mpich;message passing interface;middleware;network packet;overhead (computing);programmer;programming language;scalability;software portability;throughput;zeromq	Adeel-ur-Rehman;Naveed Riaz	2018	Int. Arab J. Inf. Technol.		message passing;machine learning;artificial intelligence;computer science;architecture;java;distributed computing;jump	HPC	-10.032015671538513	45.76536987738991	139156
7608ac7e7249d4c202609e37373f422cd0b59689	scalability analysis of scsi connected io systems.				Hari Sivaraman;Swami Ramany	1998			parallel computing;real-time computing;distributed computing	Logic	-10.176782802561943	43.39110217646291	139225
eb80df7b0e5ce5669fb493cb447ed806a6d6b238	parallelization of gsl: architecture, interfaces, and programming models	linear algebra;modelizacion;parallelisme;distributed system;algoritmo paralelo;virtual machine;systeme reparti;parallel algorithm;shared memory;mathematiques discretes;multiprocessor;design and development;matematicas discretas;memoria compartida;communicating process;discrete mathematics;paralelisacion;machine virtuelle;algorithme parallele;proceso comunicante;programming model;modelisation;parallelism;sistema repartido;paralelismo;algebre lineaire;envoi message;parallelisation;processus communicant;parallelization;message passing;algebra lineal;multiprocesador;parallel programs;maquina virtual;modeling;memoire partagee;multiprocesseur	In this paper we present our efforts towards the design and development of a parallel version of the Scientific Library from GNU using MPI and OpenMP. Two well-known operations arising in discrete mathematics and sparse linear algebra illustrate the architecture and interfaces of the system. Our approach, though being a general high-level proposal, achieves for these two particular examples a performance close to that obtained by an ad hoc parallel programming implementation.	automatic parallelization;discrete mathematics;gnu scientific library;high- and low-level;hoc (programming language);lu decomposition;linear algebra;list of code lyoko characters;message passing interface;openmp;parallel computing;problem solving environment;sampling (signal processing);sorting;sparse matrix;subroutine	José Ignacio Aliaga;Francisco Almeida;José M. Badía;Sergio Barrachina;Vicente Blanco Pérez;María Isabel Castillo;U. Dorta;Rafael Mayo;Enrique S. Quintana-Ortí;Gregorio Quintana-Ortí;Casiano Rodríguez;Francisco de Sande	2004		10.1007/978-3-540-30218-6_31	shared memory;parallel computing;message passing;multiprocessing;systems modeling;computer science;virtual machine;theoretical computer science;linear algebra;operating system;distributed computing;parallel algorithm;programming paradigm;programming language;algorithm	HPC	-9.263729160317679	37.15491507220233	139264
6e1b9f8e4c1ca7c992a29861d1b87aca2b5c39a0	a petsc parallel-in-time solver based on mgrit algorithm				Valeria Mele;Emil M. Constantinescu;Luisa Carracciuolo;Luisa D'Amore	2018	Concurrency and Computation: Practice and Experience	10.1002/cpe.4928	computer science;parallel computing;solver	Logic	-6.825560816867173	38.19567760472472	139342
18422d0eca8b06e98807e2663a2d9aed683402b6	epifast: a fast algorithm for large scale realistic epidemic simulations on distributed memory systems	distributed memory;social contact network;decision support;parallel algorithm;shared memory;computer model;simulation;large scale;fast algorithm;high performance computer;seir;public health policy;epidemics;simulation tool	Large scale realistic epidemic simulations have recently become an increasingly important application of high-performance computing. We propose a parallel algorithm, EpiFast, based on a novel interpretation of the stochastic disease propagation in a contact network. We implement it using a master-slave computation model which allows scalability on distributed memory systems.  EpiFast runs extremely fast for realistic simulations that involve: (i) large populations consisting of millions of individuals and their heterogeneous details, (ii) dynamic interactions between the disease propagation, the individual behaviors, and the exogenous interventions, as well as (iii) large number of replicated runs necessary for statistically sound estimates about the stochastic epidemic evolution. We find that EpiFast runs several magnitude faster than another comparable simulation tool while delivering similar results.  EpiFast has been tested on commodity clusters as well as SGI shared memory machines. For a fixed experiment, if given more computing resources, it scales automatically and runs faster. Finally, EpiFast has been used as the major simulation engine in real studies with rather sophisticated settings to evaluate various dynamic interventions and to provide decision support for public health policy makers.	decision support system;distributed memory;interaction;master/slave (technology);model of computation;parallel algorithm;population;scalability;shared memory;simulation;software propagation;supercomputer	Keith R. Bisset;Jiangzhuo Chen;Xizhou Feng;V. S. Anil Kumar;Madhav V. Marathe	2009		10.1145/1542275.1542336	shared memory;parallel computing;simulation;distributed memory;decision support system;computer science;theoretical computer science;operating system;distributed computing;parallel algorithm	HPC	-6.5884767932938875	34.37175707035418	139436
17de62c37d9e658403a5fa888f88dd834582855c	the doom system and its applications: a survey of esprit 415 subproject a, philips research laboratries	object oriented language;programming language;packet switched;abstract machine;operating system;object oriented;parallel computer	This paper surveys the concepts of the Parallel Object-Oriented Language POOL and a highly parallel, general purpose computer system for execution of programs in this language: the Decentralized Object-Oriented Machine, DOOM. It reports on the approach to highly parallel computers and applications followed at Philips Research Laboratories, Eindhoven, as subproject A of Esprit project 415. The first sections present a short overview of the goals and premises of the subproject. In Section 3 the programming language POOL and its characteristics are introduced. Section 4 presents an abstract machine model for the execution of POOL programs. Section 5 describes the architecture of the DOOM-system. It is a collection of self contained computers, connected by a direct, packet-switching network. The resident operating system kernels facilitate the execution of a multitude of communicating objects, perform local management and cooperate to perform system wide resource management. In Section 6 we introduce the applications that are being designed to demonstrate the merits of the system. These symbolic applications will be shown to incorporate a high degree of parallelism. In the last section some conclusions will be drawn.	doom;estimation of signal parameters via rotational invariance techniques;hirst research centre	Eddy Odijk	1987		10.1007/3-540-17943-7_145	computer science;theoretical computer science;programming language	EDA	-15.809188452537473	39.48193674949632	139476
635c919e52fd4b066f89377fc7a092d904ec41b6	handling pointers and unstructured statements in the forward computed dynamic slice algorithm	dynamic slicing;program slicing;reverse engineering	Different program slicing methods are used for debugging, testing, reverse engineering and maintenance. Slicing algorithms can be classified as a static slicing or dynamic slicing type. In applications such as debugging the computation of dynamic slices is more preferable since it can produce more precise results. In a recent paper [5] a new so-called “forward computed dynamic slice” algorithm was introduced. It has the great advantage compared to other dynamic slice algorithms that the memory requirements of this algorithm are proportional to the number of different memory locations used by the program, which in most cases is much smaller than the size of the execution history. The execution time of the algorithm is linear in the size of the execution history. In this paper we introduce the handling of pointers and the jump statements (goto, break, continue) in the C language.	a new kind of science;algorithm;array data structure;branch (computer science);categorization;computation;debugging;duckduckgo;goto;pointer (computer programming);program slicing;requirement;reverse engineering;run time (program lifecycle phase);the c programming language;vertex (graph theory)	Csaba Faragó;Tamás Gergely	2002	Acta Cybern.		program slicing;parallel computing;real-time computing;computer science;database;programming language;reverse engineering	SE	-18.461246583202847	32.57422054914134	139535
36b3b84dfc93a5048599949871588bf134a1f92b	an efficient gpu-based implementation of the r-msf-algorithm for remote sensing imagery		This paper presents an efficient real time implementation of the regularized matched spatial filter algorithm (R-MSF-Algorithm) for remote sensing (RS) imagery that employs the robust descriptive experiment design (DED) approach, using a graphics processing unit (GPU) as parallel architecture. The achieved performance is significantly greater than initial requirement of two image per second. The performance results are reported in terms of metrics as: number of operations, memory requirements, execution time, and speedup, which show the achieved improvements by the parallel version in comparison with the sequential version of the algorithm.	algorithm;graphics processing unit;microsoft solutions framework	David Castro-Palazuelos;Daniel Robles-Valdez;Deni Torres Román	2014		10.1007/978-3-319-12568-8_125	earth remote sensing;remote sensing application	EDA	-5.418646664403072	41.80981194401086	139777
575c3fb17c53044a456c54463a70000149433c65	a software framework for fine grain parallelization of cellular models with openmp: application to fire spread	multi core processor;computational grid;object oriented framework;cellular model;discrete event system;environment;design pattern;present day;software framework;symmetric multiprocessors smp;devs open multiprocessing openmp;fire spread physical model;physical model;devs;cellular automata;modular architecture;open multiprocessing openmp;models;directives	We are dealing here with the parallelization of fire spreading simulations following detailed physical experiments. The proposal presented in this paper has been tested and evaluated in collaboration with physicists to meet their requirements in terms of both performance and precision. For this purpose, an object-oriented framework using two abstraction levels has been developed. A first level considers the simulation as a global phenomenon which evolves in space and time. A local level describes the phenomena occurring on elementary parts of the domain. In order to develop an extensible and modular architecture, the cellular automata paradigm, the DEVS discrete event system formalism and design patterns have been used. Simulation treatments are limited to a set of active elements to improve execution times. A new kind of model, called Active-DEVS is then specified. The model is computed with a fine grain parallelization very efficient for present day multi-core processors which are elementary units of modern computing clusters and computing grids. In this paper, the parallelization with Open MultiProcessing (OpenMP) standard directives on Symmetric MultiProcessing (SMP) architectures is discussed and the efficiency of the retained solution is studied. 2008 Published by Elsevier Ltd. Software availability Name of software: The Cþþ code is freely available with a simple request to Eric Innocenti ino@univ-corse.fr.	automata theory;automatic parallelization;cellular automaton;central processing unit;complex systems;computation;computational model;computer cluster;devs;design pattern;distributed shared memory;elementary;experiment;grid computing;lu decomposition;map;mathematical optimization;message passing interface;multi-core processor;openmp;ork;parallel computing;programming paradigm;requirement;semantics (computer science);simulation;software framework;software portability;spatial analysis;speedup;symmetric multiprocessing;workstation;eric	Eric Innocenti;Xavier Silvani;Alexandre Muzy;David R. C. Hill	2009	Environmental Modelling and Software	10.1016/j.envsoft.2008.11.014	cellular automaton;multi-core processor;computer architecture;parallel computing;real-time computing;physical model;computer science;cellular model;software framework;devs;design pattern;natural environment;automatic parallelization	HPC	-8.69070879469071	37.960910927491476	140155
19dff3c9d4eabbb4f1461973eb7a37b4004c1647	a static data dependence analysis approach for software pipelining	modelizacion;algoritmo paralelo;naming;paralelismo instruccion;parallel algorithm;analyse statique;analisis datos;espace lineaire;proceso irreversible;boucle programme;espacio lineal;distributed computing;contrainte inegalite;inequality constraint;dependence;dependance;probabilistic approach;program verification;satisfiability;linear system;analisis estatica;analisis programa;bucle programa;algorithme parallele;desambiguisacion;modelisation;multi dimensional;data analysis;verificacion programa;marcador;pointer;parallelisme instruction;data dependence;constrenimiento desigualdad;enfoque probabilista;approche probabiliste;processus irreversible;denomination;disambiguation;denominacion;calculo repartido;initiation interval;pointeur;program loop;procesador oleoducto;analyse donnee;program analysis;software pipelining;desambiguisation;analyse programme;static analysis;processeur pipeline;instruction level parallelism;verification programme;discriminacion;linear space;modeling;calcul reparti;pipeline processor;discrimination;dependencia;irreversible process	This paper presents a run-time pointer aliasing disambiguation method for software pipelining techniques. By combining hardware with software, the method is better than run-time checking method or run-time compensation method, which is capable of dealing with irreversible code, and has limited compensation code space without serious rerollability problem. The new method solves pointer aliasing problem efficiently and makes it possible to obtain potential instruction-level parallel speedup. In this paper instructionlevel parallel speedups of the new method are analyzed in detail. Three theoretical speedups, i.e., general speedup, probabilistic speedup and mean speedup with probability, are given, which will be helpful for studying and evaluating instruction-level parallelism of the new method.	data dependency;dependence analysis;instruction-level parallelism;parallel computing;pipeline (computing);pointer (computer programming);pointer aliasing;run time (program lifecycle phase);runtime error detection;software pipelining;speedup;word-sense disambiguation	Lin Qiao;Weitong Huang;Zhizhong Tang	2005		10.1007/11577188_28	program analysis;software pipelining;irreversible process;parallel computing;discrimination;pointer;systems modeling;loop dependence analysis;computer science;theoretical computer science;mathematics;parallel algorithm;linear system;data analysis;programming language;instruction-level parallelism;static analysis;algorithm;linear space;dependence analysis;satisfiability	HPC	-17.97331678414936	34.58874332963294	140352
194ffa9f2ffd4467da7446c3b313a29aeee2d6be	a performance model for allocating the parallelism in a multigrid-in-time solver		The traditional way to numerically solve time-dependent problems is to sequentially march through time, solving for one time step and then the next. The parallelism in this approach is limited to the spatial dimension, which is quickly exhausted, causing the gain from using more processors to solve a problem to diminish. One approach to overcome this barrier is to use methods that are parallel in time. These methods have the potential to achieve dramatically better performance compared to time-stepping approaches, but achieving this performance requires carefully choosing the amount of parallelism devoted to space versus the amount devoted to time. Here, we present a performance model that, for a multigrid-in-time solver, makes the decision on when to switch to parallel-in-time and on how much parallelism to devote to space vs. time. In our experiments, the model selects the best parallel configuration in most of our test cases and a configuration close to the best one in all other cases.	central processing unit;euler;experiment;finite difference;finite element method;multigrid method;numerical analysis;parallel computing;performance tuning;regular expression;runge–kutta methods;simulation;solver;stepping level;test case	Hormozd Gahvari;Veselin A. Dobrev;Robert D. Falgout;Tzanio V. Kolev;Jacob B. Schroder;Martin Schulz;Ulrike Meier Yang	2016	2016 7th International Workshop on Performance Modeling, Benchmarking and Simulation of High Performance Computer Systems (PMBS)		parallel processing;parallel computing;real-time computing;network architecture;convergence;fat tree;computer science;theoretical computer science;operating system;distributed computing;data parallelism;predictive modelling;network performance;programming language;computational model;instruction-level parallelism;task parallelism;computer network	HPC	-4.772707368968253	39.1462103297766	140370
08e443ad159622863d9b61e221b009dbb77490ab	conditions for incremental iteration: examples and counterexamples	iterative process;algorithm analysis;etude theorique;programming environment;flot donnee;flujo datos;ingenieria logiciel;software engineering;medio ambiente programacion;proceso iterativo;processus iteratif;iteraccion;estudio teorico;genie logiciel;iteration;analyse algorithme;theoretical study;data flow;analisis algoritmo;environnement programmation	Iterative algorithms for fixed points of systems of equations are of importance in graph algorithms, data flow analysis and other areas of computer science. One commonly-sought extension is an incremental update procedure, which responds to small changes in problem parameters by obtaining the new fixed point from perturbation of the previous solution. One approach which has been suggested is to iterate for the new fixed point beginning at that previous solution, possibly after some small modifications. Our results show that this procedure is not in general correct. We give sufficient conditions for correctness, and give counterexamples in Boolean algebra and data flow analysis showing that difficulties with the proposed algorithms can occur in practice.	algorithm;boolean algebra;computer science;correctness (computer science);data-flow analysis;dataflow;fixed point (mathematics);graph theory;incremental backup;iteration;iterative method	Barbara G. Ryder;Thomas J. Marlowe;Marvin C. Paull	1988	Sci. Comput. Program.	10.1016/0167-6423(88)90061-5	data flow diagram;iteration;computer science;artificial intelligence;iterative and incremental development;algorithm	PL	-12.256895906092495	32.73282188402818	140411
b40d6ae61ac2002f39dfcbf4b51286a10a7c64a4	grid-enabled parallel divide-and-conquer: theory and practice	distributed memory;cluster grid computing;computational grid;parallel algorithm;theory and practice;graph algorithm;distributed shared memory;grid computing;divide and conquer;hamiltonian path	This paper presents a general methodology for the communication-efficient parallelization of graph algorithms using the divide-and-conquer approach. The algorithm is communication-free in the conquer stage and uses only a small amount of messages while partitioning the input. Specifically, a practical parallel algorithm with full scalability, based on the BSP model, for finding Hamiltonian paths in tournaments is presented.Experiments have been carried out on two architecturally different systems, which stand for the possible site variety of a computational grid. These include a distributed-memory system: a Solaris cluster of 32 Sun Ultra5 computers on Myrinet network and a distributed shared-memory system: an SGI Origin 2000 with 32 R10000 processors, using MPICH-GM and MPT, respectively. Both implementations are compatible with the grid-enabled MPI implementation, MPICH-G2.	central processing unit;computer;distributed memory;distributed shared memory;graph theory;grid computing;mpich;message passing interface;modern portfolio theory;parallel algorithm;parallel computing;r10000;scalability;solaris cluster	Chun-Hsi Huang	2002		10.1145/508791.508959	hamiltonian path;distributed shared memory;parallel computing;divide and conquer algorithms;distributed memory;computer science;theoretical computer science;distributed computing;parallel algorithm;grid computing	HPC	-9.23148475520977	41.88086205466954	140543
a4cdfa3db8b72261ec62ab8448ad1c8ce4cdb7c0	a parallel implementation of the push-relabel algorithm for the maximum flow problem	tratamiento paralelo;algorithme rapide;shared memory;maximum flow;traitement parallele;multiprocessor;implementation;memoria compartida;heuristic method;simultaneidad informatica;metodo heuristico;paralelisacion;etiquetage;etiquetaje;ejecucion;concurrency;fast algorithm;parallelisation;analyse performance;performance analysis;parallelization;labelling;parallel implementation;methode heuristique;multiprocesador;parallel programs;simultaneite informatique;algoritmo rapido;parallel processing;memoire partagee;shared memory multiprocessor;analisis eficacia;multiprocesseur	"""Abstract   We describe an efficient parallel implementation of the push-relabel maximum flow algorithm for a shared-memory multiprocessor. Our main technical innovation is a method that allows the """"global relabeling"""" heuristic to be executed concurrently with the main algorithm; this heuristic is essential for good performance in practice. We present performance results from a Sequent Symmetry for five input distributions. On these five input distributions we achieve speedups in the range 6.2-8.8 with 16 processors, relative to the parallel program with 1 processor (4.1-7.2 when compared to our best sequential program). We consider these speedups very good and we provide evidence that hardware effects and insufficient parallelism in certain inputs are the main obstacles to achieving better performance."""	maximum flow problem;push–relabel maximum flow algorithm	Richard J. Anderson;João Carlos Setubal	1995	J. Parallel Distrib. Comput.	10.1006/jpdc.1995.1103	shared memory;maximum flow problem;parallel processing;parallel computing;multiprocessing;concurrency;computer science;theoretical computer science;operating system;implementation;algorithm	HPC	-16.299299518772205	44.1258712624018	140569
58aced7b5e3a271c31ac0e9c7e140f5ff969cec2	assessing the effects of flow-sensitivity on pointer alias analyses	gestion memoire;algorithm performance;alias analysis;algorithm analysis;langage c;implementation;storage management;flot donnee;flujo datos;ingenieria logiciel;software engineering;algorithme;algorithm;ejecucion;gestion memoria;c language;resultado algoritmo;performance algorithme;genie logiciel;analyse algorithme;data flow;analisis algoritmo;lenguaje c;algoritmo	This paper describes an empirical comparison of four contex tinsensitive pointer alias analysis algorithms that use var ying degrees of flow-sensitivity: a flow-insensitive algorithm t hat tracks variables whose addresseswere taken and stored; a flo winsensitive algorithm that computes a solution for each fun ction; a variant of this algorithm that uses precomputed kill information; and a flow-sensitive algorithm. In addition to co ntrasting the precision and efficiency of these analyses, we d escribe implementation techniques and quantify their analy sistime speed-up. Lastly, it illustrates the object-oriented approach used in the design of the system, which provides a natural example of multiple inheritance.	algorithm;alias analysis;control flow;multiple inheritance;pointer (computer programming);pointer aliasing;precomputation	Michael Hind;Anthony Pioli	1998		10.1007/3-540-49727-7_4	data flow diagram;parallel computing;alias analysis;computer science;programming language;implementation;algorithm	PL	-18.025277149118192	34.51790277603796	140603
081dfc7d9deb03fbc265ffbdd1c6986d67348ef3	fenzi: gpu-enabled molecular dynamics simulations of large membrane regions based on the charmm force field and pme	biology computing;gpu enabled molecular dynamics simulation;multi threading;membrane simulation;conditionally convergent electrostatic component;membrane patch;multithreading gpu architecture;lattices;biological system modeling;proteins biology computing biomembranes coprocessors molecular dynamics method multi threading;multicore platform;particle mesh ewald;charmm force field;molecular dynamics community;graphics processing unit computational modeling biomembranes lattices computer architecture force biological system modeling;coprocessors;force;molecular dynamic simulation;multithreading gpu architecture gpu enabled molecular dynamics simulation membrane region charmm force field membrane bound protein receptor membrane patch multicore platform membrane simulation gpu algorithm particle mesh ewald pme method conditionally convergent electrostatic component gpu architecture molecular dynamics community fenzi code large scale gpu enabled simulation multinanosecond md simulation;biomembranes;molecular dynamics method;computer architecture;computational modeling;proteins;pme method;force field;membrane region;fenzi code;large scale gpu enabled simulation;graphics processing unit;gpu architecture;membrane bound protein receptor;multinanosecond md simulation;gpu algorithm	When studying membrane-bound protein receptors, it is necessary to move beyond the current state-of-the-art simulations that only consider small membrane patches and implicit solvent. Limits of traditional computer platforms negatively impact the model's level of realism and the computational scales achievable. On the other hand, multi-core platforms such as GPUs offer the possibility to span length scales in membrane simulations much larger and with higher resolutions than before. To this end, this paper presents the design and implementation of an advanced GPU algorithm for Molecular Dynamics (MD) simulations of large membrane regions in the NVT, NVE, and NPT ensembles using explicit solvent and Particle Mesh Ewald (PME) method for treating the conditionally-convergent electrostatic component of the classical force field. A key component of our algorithm is the redesign of the traditional PME method to better fit on the multithreading GPU architecture. This has been considered a fundamentally hard problem in the molecular dynamics community working on massively multithreaded architecture. Our algorithm is integrated in the code FENZI (textit{yun dong de FEN ZI} in Mandarin or textit{moving molecules} in English). The paper analyzes both the performance and accuracy of large-scale GPU-enabled simulations of membranes using FENZI, showing how our code can enable multi-nanosecond MD simulations per day, even when using PME.	algorithm;charmm;central processing unit;computation;computer cluster;electron;ewald summation;force field (chemistry);graphics processing unit;implicit solvation;molecular dynamics;multi-core processor;multithreading (computer architecture);particle mesh;prospective search;simulation;super robot monkey team hyperforce go!;thread (computing);water model	Narayan Ganesan;Michela Taufer;Brad A. Bauer;Sandeep Patel	2011	2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum	10.1109/IPDPS.2011.187	computational science;parallel computing;computer science;theoretical computer science	HPC	-5.6919605799361745	37.824876683848366	140900
48b17ca36c42e20872a3a03da8881fd48f0d2d09	pwrake: a parallel and distributed flexible workflow management tool for wide-area data intensive computing	workflow management;performance evaluation;programming language;data analysis;scheduling algorithm;design and implementation;file system;pc cluster;domain specific language;workflow;location awareness;data intensive computing	This paper proposes Pwrake, a parallel and distributed flexible workflow management tool based on Rake, a domain specific language for building applications in the Ruby programming language. Rake is a similar tool to make and ant. It uses a Rakefile that is equivalent to a Makefile in make, but written in Ruby. Due to a flexible and extensible language feature, Rake would be a powerful workflow management language. The Pwrake extends Rake to manage distributed and parallel workflow executions that include remote job submission and management of parallel executions. This paper discusses the design and implementation of the Pwrake, and demonstrates its power of language and extensibility of the system using a practical e-Science data-intensive workflow in astronomical data analysis on the Gfarm file system as a case study. Extending a scheduling algorithm to be aware of file locations, 20% of speed up is observed using 8 nodes (32 cores) in a PC cluster. Using two PC clusters located in different institutions, the file location aware scheduling shows scalable speedup. The extensible Pwrake is a promising workflow management tool even for wide-area data analysis.	algorithm;apache ant (another neat tool);computer cluster;data-intensive computing;domain-specific language;e-science;extensibility;extensible programming;gfarm file system;location awareness;makefile;programming language;rake;ruby;scalability;scheduling (computing);speedup	Masahiro Tanaka;Osamu Tatebe	2010		10.1145/1851476.1851529	workflow;parallel computing;real-time computing;computer science;operating system;database;distributed computing;windows workflow foundation;programming language;workflow management system;workflow engine;workflow technology	HPC	-12.321213853638376	42.67142588531628	141180
cd52f420d9562542b6d38094fd52f7c131baaa15	opencl c++	parallel programming;gpu;gpgpu;c;opencl	With the success of programming models such as Khronos' OpenCL, heterogeneous computing is going mainstream. However, these models are low-level, even when considering them as systems programming models. For example, OpenCL is effectively an extended subset of C99, limited to the type unsafe procedural abstraction that C has provided for more than 30 years. Computer systems programming has for more than two decades been able to do a lot better. One successful case in point is the systems programming language C++, known for its strong(er) type system, templates, and object-oriented abstraction features.  In this paper we introduce OpenCL C++, an object-oriented programming model (based on C++11) for heterogeneous computing and an alternative for developers targeting OpenCL enabled devices. We show that OpenCL C's address space qualifiers, and by implication Embedded C's, can be lifted into C++'s type system. A novel application of C++11's new type inference features (auto/decltype) with respect to address space qualifiers allows natural and generic use of the this pointer. We qualitatively show that OpenCL C++ is a simpler and a more expressive development platform than its OpenCL C counter part.	address space;c++11;c99;cuda;compiler;computer programming;decltype;embedded c;embedded system;graphics processing unit;hardware description language;heterogeneous computing;high- and low-level;opencl api;pointer (computer programming);programmer;programming model;system programming language;type inference;type system	Benedict R. Gaster;Lee W. Howes	2013		10.1145/2458523.2458532	parallel computing;run-time type information;blocks;computer science;operating system;programming language	PL	-15.005741706106896	38.39668459573912	141271
36f008e9c0134fa0c261ef503a62dd36847a96c5	solving banded systems on a parallel processor	computers;digital computers;computer program;general and miscellaneous mathematics computing and information science;parallel algorithm;testing 990210 supercomputers 1987 1989;performance test;programming language;computer and information science;distributed storage;distributed storage architectures;performance testing;matrices;performance measurements;dense banded systems;benchmarks;computer codes;alliant fx 8;fortran;data och informationsvetenskap;solving large;programming;supercomputers;parallel processing;cray computers;sequent balance 21000;parallel processors;programming languages;l codes	Ways of solving dense, banded systems on different parallel processors are examined. Processors with vector instructions are considered, and then various algorithms for the solution of large, dense, banded systems on a parallel processor are discussed. The behavior of the parallel algorithms on distributed-storage architectures configured as rings, two dimensional meshes with end-around connections (tori), boolean n-cube configured architectures, and bus-based and switch-based machines with shared storage is discussed. Measurements are presented for two bus-based architectures with shared storage, namely, the Alliant FX/8 and the Sequent Balance 21000. 43 refs.		Jack J. Dongarra;S. Lennart Johnsson	1987	Parallel Computing	10.1016/0167-8191(87)90020-2	parallel processing;programming;parallel computing;software performance testing;computer science;theoretical computer science;operating system;distributed computing;parallel algorithm;programming language;algorithm;matrix	HPC	-9.030731588693996	40.664381972998584	141331
24d3e4b265dc217e32cee74c5e6c728430423915	rdfpro: an extensible tool for building stream-oriented rdf processing pipelines		We present RDFPRO (RDF Processor), an open source Java command line tool and embeddable library that offers a suite of stream-oriented, highly optimized processors for common tasks such as data filtering, RDFS inference, smushing and statistics extraction. RDFPRO processors are extensible by users and can be freely composed to form complex pipelines to efficiently process RDF data in one or more passes. We show how RDFPRO model and multi-threaded design allow processing billions of triples in few hours in a typical Linked Open Data integration scenario, and discuss relevant implementation aspects and lessons learnt.	central processing unit;command-line interface;java;linked data;open-source software;pipeline (computing);pipeline (software);rdf schema;resource description framework;thread (computing)	Francesco Corcoglioniti;Marco Rospocher;Marco Amadori;Michele Mostarda	2014				DB	-12.775491421228756	35.47869031024147	141374
11436c42b5e158747b70c563d3973d37f64c8b18	modular matrix computations on multi-linear vlsi arrays	linear algebra;processing element;rectangular matrix;multi linear array;producto matriz;programmation modulaire;linear array;circuit vlsi;matriz rectangular;programacion modular;modular algorithm;vlsi circuit;matrix computation;algebre lineaire;almacenamiento;stockage;vlsi technology;modular programming;algebra lineal;matrix multiplication;circuito vlsi;produit matrice;clock skew;storage;matrix product;matrice rectangulaire	This paper describes the synthesis of modularly extensible matrix algorithms on multi-linear VLSI arrays with application to rectangular matrix multiplication. Multi-linear arrays differ from two-dimensional (2D) arrays in that one of the dimensions in the arrays is independent of the size of the problem and depends only on the I/O bandwidth of the host computer. They feature bounded clock skew (unlike 2D arrays) and higher throughput and communication bandwidth than linear arrays. A significant feature of the algorithms discussed in this paper is that they exhibit an interdependence between the number of processing elements (PEs) per row in the multi-linear array, the storage inside each PE, and the size of the problem. This interrelationship permits changes in one of these measures to be accommodated by altering one or more of the other measures. One particular benefit of this feature is that it enables the design of modularly extensible algorithms which can accommodate changes in the problem size by only changing the number of PEs per row in the array. Therefore, for a given host I/O bandwidth, larger problem sizes can be handled by cascading smaller multi-linear arrays, all of which have the same number of rows and are comprised of PEs with a fixed amount of local storage. A second feature of our algorithms is that their performance is also a function of the number of rows of PEs in the array which is in turn a function of the I/O bandwidth of the host. A third feature of our design is that the algorithms are controlled by tag bits inserted with the data and no control memory is required inside the PEs.	algorithm;analysis of algorithms;clock skew;computation;host (network);input/output;interdependence;matrix multiplication;microprocessor;modular programming;multi-core processor;multiplication algorithm;tagged architecture;thread-local storage;throughput;turned a;very-large-scale integration	Hassan R. Barada	1995	Parallel Computing	10.1016/0167-8191(95)00020-O	parallel computing;matrix multiplication;computer science;theoretical computer science;linear algebra;operating system;mathematics;algorithm;algebra	Theory	-12.669789014594533	44.62816281329661	141516
ab5d60b2967d4ae23445c6acc047989a8f900fda	auto-tuning of computation kernels from an fdm code with ppopen-at	libraries;static code generation;kernel;auto tuning;ppopen at;directive;ppopen at auto tuning directive static code generation loop transformation;libraries kernel optimization frequency division multiplexing supercomputers syntactics;loop fusion auto tuning function computation kernels fdm code ppopen at at language dedicated numerical library supercomputers loop transformation techniques loop split statement reordering;loop transformation;syntactics;frequency division multiplexing;optimization;software libraries program control structures;supercomputers	In this paper, we propose an Auto-tuning (AT) function with an AT language for a dedicated numerical library with respect to supercomputers in operation. The AT function is based on well-known loop transformation techniques, such as loop split, fusion, and re-ordering of statements. However, loop split with copies or increase of computations, and loop fusion to the split loop are taken into account by utilizing user knowledge.	computation;finite difference method;loop optimization;numerical analysis;phase-locked loop;supercomputer	Takahiro Katagiri;Satoshi Ohshima;Masaharu Matsumoto	2014	2014 IEEE 8th International Symposium on Embedded Multicore/Manycore SoCs	10.1109/MCSoC.2014.22	loop tiling;loop fusion;loop inversion;parallel computing;real-time computing;loop fission;loop interchange;loop dependence analysis;computer science;loop nest optimization;theoretical computer science;loop unrolling;loop splitting	Arch	-14.063052177074303	36.38830573909331	141723
c067b12d10609c16446b0bf3e5811d35e0b0f0b3	performance evaluation of a 3d-stencil library for distributed memory array accelerators	libraries kernel memory management computers arrays optimization data communication;storage management distributed processing partial differential equations;accelerator;cgra;高性能計算;optimization cgra coarse grained reconfigurable architecture accelerator library stencil;ライブラリ;optimization;ステンシル計算;general purpose processor 3d stencil library distributed memory array accelerators energy aware multimode accelerator extension distributed single port local memory ring formed interconnection scientific computation big data image processing hardware organization library support stencil computation partial differential equation pde solver emax system configuration emax features emax mnemonics instruction mapping techniques performance evaluation;stencil;library;coarse grained reconfigurable architecture	EMAX: Energy-aware Multimode Accelerator Extension is equipped with distributed single-port local memories and ring-formed interconnections. The accelerator is designed to achieve extremely high throughput for scientific computations, big data and image processing and also to achieve low power consumption. However, before mapping algorithms on the accelerator, application developers should have sufficient knowledge of the hardware organization and specially designed instructions. They will, furthermore, need to make significant efforts to tune the code for improving execution efficiency, in the case that no well-designed compiler or library is available. To address this problem, we focus especially on library support for the stencil (nearest-neighbor) computations, which represent a class of algorithms popularly used in many partial differential equation (PDE) solvers. In this research, we take up the following topics: (1) System configuration, features and mnemonics of EMAX, (2) Instruction mapping techniques that can reduce the amount of data to be read from the main memory, (3) Performance evaluation of the library for PDE solvers. With the features of the library that can reuse the local data across the outer loop iterations and can map many instructions by unrolling outer loops, the amount of data to be read from main memory is significantly reduced to a minimum of 1/7 compared with a hand-tuned code. In addition, the stencil library was found capable of reducing 23% of the execution time compared with a general purpose processor.	algorithm;big data;compiler;computation;computer data storage;distributed memory;image processing;iteration;performance evaluation;run time (program lifecycle phase);system configuration;throughput	Yoshikazu Inagaki;Shinya Takamaeda-Yamazaki;Jun Yao;Yasuhiko Nakashima	2014	2014 Second International Symposium on Computing and Networking	10.1109/CANDAR.2014.100	parallel computing;computer hardware;computer science;theoretical computer science	HPC	-4.708946862468802	41.52111565230676	141733
e8ea50e54fae267efcf9cdf6e916f014ce32a60f	concept and design of sdn-enhanced mpi framework	parallel distributed computing message passing interface software defined networking;parallel distributed computing;software defined networking;message passing interface;message passing application program interfaces;computer architecture tagging computers kernel conferences high performance computing;application aware network control mechanism sdn enhanced mpi framework modern high performance computing systems cluster systems mpi communications dynamic network control	In general, modern high-performance computing systems are built as cluster systems. We have been investigating the feasibility of optimizing MPI communications by integrating the dynamic network control realized by SDN. In this paper, we present a concept of a generic SDN enhanced MPI framework, an application-aware network control mechanism specifically for MPI applications.	clustered file system;message passing interface;software-defined networking;supercomputer	Keichi Takahashi;Khureltulga Dashdavaa;Baatarsuren Munkhdorj;Yoshiyuki Kido;Susumu Date;Hiroaki Yamanaka;Eiji Kawai;Shinji Shimojo	2015	2015 Fourth European Workshop on Software Defined Networks	10.1109/EWSDN.2015.72	computer architecture;parallel computing;computer science;message passing interface;distributed computing	HPC	-11.011035256354369	45.525943582217614	142320
1f520fd6443677cac104af20b4eec1de883e1a97	massively parallel quantum computer simulations: towards realistic systems	working group;ion trap;juser websearch publications database;rotating wave approximation;search algorithm;error threshold;critical system;quantum fourier transform;quantum computer;trapped ion;grover s algorithm;critical parameter	c © 2007 by John von Neumann Institute for Computing Permission to make digital or hard copies of portions of this work for personal or classroom use is granted provided that the copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise requires prior specific permission by the publisher mentioned above.	computer simulation	Marcus Richter;Guido Arnold;Binh Trieu;Thomas Lippert	2007			quantum simulator;ion trap;quantum fourier transform;grover's algorithm;working group;computer science;error threshold;theoretical computer science;quantum computer;quantum algorithm for linear systems of equations;quantum algorithm;one-way quantum computer;rotating wave approximation;quantum phase estimation algorithm;search algorithm;quantum error correction	Theory	-4.664258935719596	34.50540103516711	142348
8af50af87c261f5c4f532869b1a46a03558971bf	program generation techniques for the development and maintenance of numerical weather forecast grid models	weather forecasting;finite difference;automatic generation;program generation;language extension;fortran;computer algebra;high performance;knowledge base	This article presents computer-algebra based techniques for the automatic generation and maintenance of numerical codes based on finite difference approximations. The various generation phases — specification, discretization, implementation and translation — as well as their respective knowledge bases, are discussed and specific attention is given to data mappings in the implementation phase and to high-performance language extensions in the Fortran translation phase. The generation of Fortran source for the dynamics part of a limited area weather forecasting grid-point model is discussed and is illustrated by showing the production of a few variants of the surface-pressure tendency code using the present prototype. Finally, we indicate briefly how adjoints can be obtained using the present methodology.	numerical weather prediction	Victor V. Goldman;Gerard Cats	1995		10.1007/3-540-60902-4_30	computational science;knowledge base;finite difference;simulation;weather forecasting;computer science;theoretical computer science	HPC	-10.272161544966787	35.51663563504979	142395
46d4192ee0506779b311ecb5a0229737acd1d09e	scalability of communicators and groups in mpi	parallel programming;group communication;multicore;message passing interface;operating system;parallel programs	As the number of cores inside compute clusters continues to grow, the scalability of MPI (Message Passing Interface) is important to ensure that programs can continue to execute on an ever-increasing number of cores. One important scalability issue for MPI is the implementation of communicators and groups. Communicators and groups are an integral part of MPI and play an essential role in the design and use of libraries. It is challenging to create an MPI implementation to support communicators and groups to scale to the hundreds of thousands of processes that are possible in today's clusters. In this paper we present the design and evaluation of techniques to support the scalability of communicators and groups in MPI.  We have designed and implemented a fine-grain version of MPI (FG-MPI) based on MPICH2, that allows thousands of full-fledged MPI processes inside an operating system process. Using FG-MPI we can create hundreds and thousands of MPI processes, which allowed us to implement and evaluate solutions to the scalability issues associated with communicators. We describe techniques to allow for sharing of group information inside processes, and the design of scalable operations to create the communicators. A set plus permutation framework is introduced for storing group information for communicators and a set, instead of map, representation is proposed for MPI group objects. Performance results are given for the execution of a MPI benchmark program with upwards of 100,000 processes with communicators created for various groups of different sizes and types.	algorithm;benchmark (computing);computer cluster;floor and ceiling functions;job control (unix);library (computing);location awareness;mpich;map;message passing interface;operating system;requirement;scalability;succinct data structure;wavelet tree	Humaira Kamal;Seyed M. Mirtaheri;Alan Wagner	2010		10.1145/1851476.1851507	multi-core processor;parallel computing;communication in small groups;computer science;message passing interface;theoretical computer science;operating system;distributed computing	HPC	-7.7108369940566	42.97528775008374	142523
a0f31f236772b3189e9a2842b93ad246d213d01f	introduction to the modern trends in parallel computing minitrack	computer languages;parallel programming;functional programming;computational modeling;supercomputers;parallel processing;hardware	"""This is the introduction to the """"Modern Trends in Parallel Computing""""."""	parallel computing	Peter Salhofer	2016	2016 49th Hawaii International Conference on System Sciences (HICSS)	10.1109/HICSS.2016.709	computational science;parallel processing;computer architecture;computer science;theoretical computer science;data-intensive computing;programming language;functional programming;computational model;parallel programming model	HPC	-9.553353079306872	40.587127262808	142527
16ccf8532dc78aaa811425daa18d1f1276a6709f	systematic serialisation of array-based architectures	red sistolica;correctness preserving transformations;concepcion circuito;circuito convolucion;etude theorique;implementation;systolic arrays;circuit design;circuit vlsi;partitioning;program transformation;transformation conservant exactitude;procesador panel;parametrization;seriation;space time;transformation programme;exactitude programme;array processor;parametrizacion;ruby;processeur tableau;ejecucion;computer architecture;transformacion programa;vlsi circuit;serialization;exactitud programa;architecture ordinateur;systolic network;seriacion;estudio teorico;reseau systolique;parametrized design;conception circuit;arquitectura ordenador;circuito vlsi;theoretical study;parametrisation;convolution circuit;circuit convolution;program correctness	This paper describes the use of Ruby, a language of functions and relations, to develop serialised implementations of array-based architectures. Our Ruby expressions contain parameters which can be varied to produce a wide range of designs with diierent space-time trade-oos. Such expressions can be obtained by applying correctness-preserving transformations to an initial simple description. This approach provides a uniied treatment of serialisation schemes similar to LPGS (Locally Parallel Globally Sequential) and LSGP (Locally Sequential Globally Parallel) partitioning methods, and will be illustrated by the development of a variety of circuits for convolution.	convolution;correctness (computer science);ruby;serialization	W. W. C. Luk	1993	Integration	10.1016/0167-9260(93)90014-4	parametrization;embedded system;parallel computing;computer science;theoretical computer science;operating system;mathematics;programming language;algorithm	PL	-13.276332677243628	34.492022975613374	142620
4bce007f055be4d14d16172b28ea0c7cf6d52e93	checkpoint-restart for a network of virtual machines	multi threading;checkpointing;virtual machines;virtual machining checkpointing kernel optimization computers image restoration;virtual machines checkpointing multi threading;incremental btrfs based snapshots virtual machine network common productivity software simulink matlab parallel r r statistical modelling language parallel blast py blast bioinformatics software ipython parallel gnu parallel parallel shells dmtcp checkpoint restart package kvm qemu operates lguest qemu virtual filesystem btrfs filesystem forked checkpointing mmap based restart	The ability to easily deploy parallel computations on the Cloud is becoming ever more important. The first uniform mechanism for checkpointing a network of virtual machines is described. This is important for the parallel versions of common productivity software. Potential examples of parallelism include Simulink for MATLAB, parallel R for the R statistical modelling language, parallel blast.py for the BLAST bioinformatics software, IPython.parallel for Python, and GNU parallel for parallel shells. The checkpoint mechanism is implemented as a plugin in the DMTCP checkpoint-restart package. It operates on KVM/QEMU, and has also been adapted to Lguest and pure user-space QEMU. The plugin is surprisingly compact, comprising just 400 lines of code to checkpoint a single virtual machine, and 200 lines of code for a plugin to support saving and restoring network state. Incremental checkpoints of the associated virtual filesystem are accommodated through the Btrfs filesystem. Experiments demonstrate checkpoint times of a fraction of a second by using forked checkpointing, mmap-based restart, and incremental Btrfs-based snapshots.	application checkpointing;blast;bioinformatics;cloud computing;computation;copy-on-write;fork (software development);gnu;linux;matlab;map (parallel pattern);mmap;modeling language;parallel computing;plug-in (computing);python;r language;simulink;source lines of code;statistical model;transaction processing system;user space;virtual machine	Rohan Garg;Komal Sodha;Zhengping Jin;Gene Cooperman	2013	2013 IEEE International Conference on Cluster Computing (CLUSTER)	10.1109/CLUSTER.2013.6702626	parallel computing;real-time computing;multithreading;computer science;virtual machine;operating system;programming language	HPC	-6.424600647483391	43.34367073084223	142906
b88d899aa08631927152dee627c5cd9743c722cd	load balancing: toward the infinite network and beyond	dynamic load balancing;peer to peer network;object oriented;active objects;distributed parallel computing;load balance;peer to peer;parallel applications	We present a contribution on dynamic load balancing for distributed and parallel object-oriented applications. We specially target peer-to-peer systems and their capability to distribute parallel computation. Using an algorithm for active-object load balancing, we simulate the balance of a parallel application over a peer-to-peer infrastructure. We tune the algorithm parameters in order to obtain the best performance, concluding that our IFL algorithm behaves very well and scales to large peer-to-peer networks (around 8,000 nodes).	active object;algorithm;computation;desktop computer;integrated facility for linux;list of code lyoko characters;load balancing (computing);network topology;parallel computing;peer-to-peer;simulation	Javier Bustos-Jiménez;Denis Caromel;José M. Piquer	2006		10.1007/978-3-540-71035-6_9	network load balancing services;parallel computing;real-time computing;computer science;load balancing;distributed computing;object-oriented programming	HPC	-13.238838934861027	43.41115783415764	142975
02590040353afde24510554de3aec05fad1c9c2d	scalable parallel formulations of the barnes-hut method for n-body simulations	domain decomposition;collective communication;n body simulations;n body simulation;partitioning;spectrum;scaling up;large scale;high energy physics;molecular dynamic;fluid dynamics;load balance;experimental evaluation;communication;experimental results;parallel processing;hierarchical tree code	In this paper, we present two new parallel formulations of the Barnes-Hut method. These parallel formulations are especially suited for simulations with irregular particle densities. We first present a parallel formulation that uses a static partitioning of the domain and assignment of subdomains to processors. We demonstrate that this scheme delivers acceptable load balance, and coupled with two collective communication operations, it yields good performance. We present a second parallel formulation which combines static decomposition of the domain with an assignment of subdomains to processors based on Morton ordering. This alleviates the load imbalance inherent in the first scheme. The second parallel formulation is inspired by two currently best known parallel algorithms for the Barnes-Hut method. We present an experimental evaluation of these schemes on a 256 processor nCUBE2 parallel computer for an astrophysical simulation.	central processing unit;computational astrophysics;experiment;load balancing (computing);michael j. fischer;microsoft windows;overhead (computing);parallel algorithm;parallel computing;simulation;warren abstract machine	Ananth Grama;Vipin Kumar;Ahmed H. Sameh	1994	Parallel Computing	10.1016/S0167-8191(98)00011-8	spectrum;parallel processing;mathematical optimization;parallel computing;simulation;computer science;load balancing;theoretical computer science;operating system;n-body simulation;domain decomposition methods;algorithm;fluid dynamics	HPC	-5.559439682168714	38.41781201295438	143011
1fcd8c83012358587b4a2cec7bc0b3ec255800b1	forall: an extensible fortran system for conversationally accessing subroutine libraries	libraries;extensibility;statistics;fortran	Abstract#R##N##R##N#The implementation of a user-extensible Fortran system is described. The control syntax, in which all arrays may be referenced by name, is outlined, including language-like extensions. A summary of the algorithms implemented is tabulated. Facilities for the user to add algorithms to the system are described and the methods of handling arrays outlined. Features to facilitate portability are mentioned.	fortran;subroutine	John D. Kerr	1980	Softw., Pract. Exper.	10.1002/spe.4380101103	computational science;computer architecture;extensibility;computer science;programming language	HPC	-12.309865094905222	35.43116060792853	143056
1748363eaa4d40c2566dd9eb7e6b5f070e7a8b60	generating parallel execution plans with a partial-order planner	planning;reduction;parallel processing;resources;partial order	"""Many real-world planning problems require generating plans that maximize the parallelism inherent in a problem. There are a number of partial-order planners that generate such plans; however, in most of these planners it is unclear under what conditions the resulting plans will be correct and whether the plaltner can even find a plan if one exists. This paper identifies the underlying assumptions about when a partial plan can be executed in parallel, defines the classes of parallel plans that can be generated by different partialorder planners, and describes the changes required to turn ucPoP into a parallel execution planner. In """"addition, we describe how this planner can be applied to the problem of query access planning, where parallel execution produces ubstantial reductions in overall execution time."""	parallel computing;partial-order planning;run time (program lifecycle phase)	Craig A. Knoblock	1994			planner;real-time computing;simulation;computer science;parallel processing	AI	-13.673898586288473	45.87253696287505	143214
ded3c7af90e970ff7a51f20ce0b165f2a55947ca	implementation and evaluation of network interface and message passing services for tianhe-1a supercomputer	mainframes;protocols;kernel;optical switch;collective communication;radiation detectors;offloads collective operation network interface message passing services tianhe 1a supercomputer hybrid multicore cpu gpu computing low latency interconnect fabric computation capabilities communication capabilities user level communication;radiation detector;optical switches;receivers;large scale;low latency;collective communication user level communication rdma mpi;message passing;rdma;parallel machines;receivers optical switches protocols message passing radiation detectors kernel;mpi;user level communication;network interface;parallel machines mainframes message passing;high performance	TianHe-1A, a large scale supercomputer features hybrid multi-core CPU and GPU computing, utilizes a proprietary high-bandwidth, low-latency interconnect fabric to achieve the optimized balance of computation and communication capabilities. In this paper, we describe the design of the network interface in TianHe-1A which supports user-level communication and offloads collective operation to deliver communication performance close to the hardware limits. Scalable and high performance message passing services are implemented on this interface and preliminary performance results are provided.	algorithm;central processing unit;collective operation;computation;connectionless communication;general-purpose computing on graphics processing units;graphics processing unit;message passing interface;message passing;multi-core processor;network interface;network interface controller;partitioned global address space;programming model;remote direct memory access;scalability;supercomputer;switched fabric;user space;zero-copy	Min Xie;Yutong Lu;Lu Liu;Hongjia Cao;Xuejun Yang	2011	2011 IEEE 19th Annual Symposium on High Performance Interconnects	10.1109/HOTI.2011.20	parallel computing;real-time computing;telecommunications;computer science;operating system;distributed computing;particle detector;optical switch;computer network	HPC	-10.672747594546687	46.20647691313371	143229
383ab72038f3a87abb6faf1b0cd4e149b6319f37	support tools for porting legacy applications to multicore	software portability;software maintenance;graphics processing units benchmark testing kernel multicore processing registers estimation computational complexity;software tools multiprocessing systems parallel programming public domain software software maintenance software portability;parallel programming;public domain software;multicore processor support tools legacy application porting pemap automated performance estimation tool project performance hand parallelized program bemap benchmark suite autoparallelizer machine performance open source project code explanations sequential program performance handtuned parallelized opencl code auto parallelizer tool;software tools;multiprocessing systems	This paper presents PEMAP, an automated performance estimation tool to project performance of hand-parallelized programs from sequential programs and BEMAP, a benchmark suite to measure an auto-parallelizer or even a machine's performance. BEMAP is an open-source project, and the documentations on code explanations and experimental results are also provided. Our experiments on PEMAP shows we can estimate performance of hand-parallelized programs in an error of 0.44% of sequential program's performance on average, while using BEMAP shows that the ability of an auto-parallelizer can be measured by comparing the compiled code to the handtuned parallelized OpenCL code, and therefore assisting the development of the auto-parallelizer tool.	benchmark (computing);code;compiler;debugger;documentation;dummy variable (statistics);experiment;graphical user interface;multi-core processor;open-source software;opencl api;parallel computing;parallel programming model;performance;run time (program lifecycle phase)	Yuri Ardila;Natsuki Kawai;Takashi Nakamura;Yosuke Tamura	2013	2013 18th Asia and South Pacific Design Automation Conference (ASP-DAC)	10.1109/ASPDAC.2013.6509658	software portability;computer architecture;parallel computing;software sizing;computer science;backporting;software framework;software development;operating system;software construction;software testing;programming language;software maintenance;public domain software;static program analysis	EDA	-5.975815206844409	44.993320944825335	143372
3e104c92436040c69c042dbd9e9ffd27b99bfaf7	integrating fpgas in high-performance computing: introduction	reconfigurable computing;high performance computing;compute acceleration;high performance computer;co processor	The move to parallel computation creates interesting new challenges for software programmers, operating system and compiler developers to adapt their sequential way of thinking to a parallel world. However, as with any disruptive technology, this also opens the door to other ways of organizing computation. A number of the major supercomputing vendors such as Cray and SRC, traditional high-end computing servers from IBM, SGI, Sun and more recent companies such as Linux Networx have begun to re-cast vast farms of commodity blade servers into FPGA-based hybrid systems. Startups XtremeData and DRC have developed interface cards to bring high-performance computing to the masses, with methodologies to add an FPGA directly on a commodity PC motherboard. Orthogonal to these technological drivers, the vast amount of information being generated in today’s world is putting greater pressures on computation, and driving new applications for highperformance computing in medical and other image processing and analysis, bio-informatics and gene sequencing, database and text search, financial analytics – all new problems to the supercomputing world. Various start-ups have proposed applianced HW/SW solutions to these vertical markets while others have built custom systems.	bioinformatics;british informatics olympiad;compiler;computation;field-programmable gate array;hybrid system;image processing;linux;motherboard;operating system;organizing (structure);parallel computing;programmer;semiconductor research corporation;shattered world;supercomputer	Paul Chow;Mike Hutton	2007		10.1145/1216919.1216940	computer architecture;piperench;supercomputer;parallel computing;reconfigurable computing;computer science;fpgac;coprocessor;computing with memory;unconventional computing	HPC	-7.805014375040473	40.70030847795586	143486
7bb7ec62b5a004520e3f102e33451e8df615bfd1	targeting heterogeneous architectures via macro data flow	heterogenous architectures;programming model;structured parallelism;run time system;heterogeneous architectures;parallel design patterns;design pattern;algorithmic skeletons;data flow;parallel applications	We propose a data flow based run time system as an efficient tool for supporting execution of parallel code on heterogeneous architectures hosting both multicore CPUs and GPUs. We discuss how the proposed run time system may be the target of both structured parallel applications developed using algorithmic skeletons/parallel design patterns and also more “domain specific” programming models. Experimental results demonstrating the feasibility of our approach are presented.	algorithmic skeleton;central processing unit;computation;crew scheduling;data parallelism;dataflow architecture;design pattern;graphics processing unit;heterogeneous system architecture;high-level programming language;job scheduler;multi-core processor;parallel algorithm;parallel computing;processor affinity;programmer;runtime system;scheduling (computing)	Marco Aldinucci;Marco Danelutto;Peter Kilpatrick;Massimo Torquati	2012	Parallel Processing Letters	10.1142/S0129626412400063	data flow diagram;computer architecture;parallel computing;real-time computing;computer science;design pattern;programming paradigm;programming language	HPC	-7.025700497077235	43.82388336728351	143559
063cbf86daf97aebab8e84cf420e7c8f69797636	a structured approach to parallel programming: methodology and models	distributed memory systems;formal specification;theory and practice;programacion paralela;sistema informatico;testing and debugging;parallel programming;computer system;specification programme;specification formelle;programming model;especificacion formal;systeme memoire repartie;shared memory systems;parallel machines;systeme informatique;parallel programs;program specification;especificacion programa;systeme memoire partagee;programmation parallele	Parallel programming continues to be difficult, despite substantial and ongoing research aimed at making it tractable. Especially dismaying is the gulf between theory and the practical programming. We propose a structured approach to developing parallel programs for problems whose specifications are like those of sequential programs, such that much of the work of development, reasoning, and testing and debugging can be done using familiar sequential techniques and tools. The approach takes the form of a simple model of parallel programming, a methodology for transforming programs in this model into programs for parallel machines based on the ideas of semantics-preserving transformations and programming archetypes (patterns), and an underlying operational model providing a unified framework for reasoning about those transformations that are difficult or impossible to reason about using sequential techniques. This combination of a relatively accessible programming methodology and a sound theoretical framework to some extent bridges the gulf between theory and practical programming. This paper sketches our methodology and presents our programming model and its supporting framework in some detail.	cobham's thesis;correctness (computer science);debugging;gulf of evaluation;gulf of execution;operational semantics;parallel computing;process calculus;programming model;software development process;unified framework	Berna L. Massingill	1999		10.1007/BFb0098008	constraint programming;declarative programming;programming domain;reactive programming;functional reactive programming;computer science;artificial intelligence;theoretical computer science;extensible programming;operating system;jackson structured programming;formal specification;database;distributed computing;programming paradigm;procedural programming;symbolic programming;inductive programming;programming language theory;programming language;algorithm;concurrent object-oriented programming;parallel programming model	PL	-17.229290276058972	33.152949958686015	143612
41f474879e4fa61b3b7d32ea0c89a260151516d4	nonintrusive amr asynchrony for communication optimization		Adaptive Mesh Refinement (AMR) is a well known method for efficiently solving partial differential equations. A straightforward AMR algorithm typically exhibits many synchronization points even during a single time step, where costly communication often degrades the performance. This problem will be even more pronounced on future supercomputers containing billion way parallelism, which will raise the communication cost further. Re-designing AMR algorithms to avoid synchronization is not a viable solution due to the large code size and complex control structures. We present a nonintrusive asynchronous approach to hiding the effects of communication in an AMR application. Specifically, our approach reasons about data dependencies automatically using domain knowledge about AMR applications, allowing asynchrony to be discovered with only a modest amount of code modification. Using this approach, we optimize the synchronous AMR algorithm in the BoxLib software framework without severely affecting the productivity of the application programmer. We observe around 27–31% performance improvement for an advection solver on the Hazel Hen supercomputer using 12288 cores.	adaptive multi-rate audio codec;asynchrony (computer programming)	Muhammed Nufail Farooqi;Didem Unat;Tan Nguyen;Weiqun Zhang;Ann S. Almgren;John Shalf	2017		10.1007/978-3-319-64203-1_49	software framework;synchronization;distributed computing;domain knowledge;computer science;programmer;asynchronous communication;solver;supercomputer;adaptive mesh refinement	EDA	-5.785601681380649	42.347887402144195	143667
8e9fd0940e92fbc2d0bd21d0bbd03d81b345ab00	very high resolution simulation of compressible turbulence on the ibm-sp system	energy resolution computational modeling chemicals combustion us department of energy acceleration laboratories production systems radio access networks clocks	Understanding turbulence and mix in compressible flows is of fundamental importance to real-world applications such as chemical combustion and supernova evolution. The ability to run in three dimensions and at very high resolution is required for the simulation to accurately represent the interaction of the various length scales, and consequently, the reactivity of the intermixin species. Toward this end, we have carried out a very high resolution (over 8 billion zones) 3-D simulation of the Richtmyer-Meshkov instability and turbulent mixing on the IBM Sustained Stewardship TeraOp (SST) system, developed under the auspices of the Department of Energy (DOE) Accelerated Strategic Computing Initiative (ASCI) and located at Lawrence Livermore National Laboratory. We have also undertaken an even higher resolution proof-of-principle calculation (over 24 billion zones) on 5832 processors of the IBM system, which executed for over an hour at a sustained rate of 1.05 Tflop/s, as well as a short calculation with a modified algorithm that achieved a sustained rate of 1.18Tflop/s. The full production scientific simulation, using a further modified algorithm, ran for 27,000 timesteps in slightly over a week of wall time using 3840 processors of the IBM system, clockin a sustained throughput of roughly 0.6 teraflop per second (32-bit arithmetic). Nearly 300,000 graphics files comprising over three terabytes of data were produced and post-processed. The capability of running in 3-D at high resolution enabled us to get a more accurate and detailed picture of the fluid-flow structure - in particular, to simulate the development of fine scale structures from the interactions of long-and short-wavelength phenomena, to elucidate differences between two-dimensional and three-dimensional turbulence, to explore a conjecture regarding the transition from unstable flow to fully developed turbulence with increasing Reynolds number, and to ascertain convergence of the computed solution with respect to mesh resolution.	simulation;turbulence	Arthur A. Mirin;Ron H. Cohen;Bruce C. Curtis;William P. Dannevik;Andris M. Dimits;M. A. Duchauneau;Don E. Eliason;Daniel R. Schikore;Sarah E. Anderson;David H. Porter;Paul R. Woodward;L. J. Shieh;Steven W. White	1999		10.1109/SC.1999.10039	simulation;electrical engineering;physics;mechanical engineering	EDA	-5.462444105922651	35.882482207263756	143854
5fb646b498224ca196cdfe91fa95fae4e176a49c	64-bit and 128-bit dx random number generators	calcul scientifique;software;multiple recursive generator mrg;analisis numerico;random number generator;high resolution;logiciel;stochastic method;65c10;implementation;sistema informatico;equidistribution;random number generation;computer system;combined generators;65c 10 random number generation;analyse numerique;computing;algorithme;algorithm;computacion cientifica;large scale simulation;numerical analysis;empirical tests;generation nombre aleatoire;methode stochastique;logicial;systeme informatique;mt19937;issn 0010 485x;scientific computation;implementacion;article;computer simulation;generacion numero aleatorio;software implementation;linear congruential generator lcg;algoritmo;metodo estocastico	Extending 32-bit DX generators introduced by Deng and Xu (ACM Trans Model Comput Simul 13:299–309, 2003), we perform an extensive computer search for classes of 64-bit and 128-bit DX generators of large orders. The period lengths of these high resolution DX generators are ranging from 101915 to 1058221. The software implementation of these generators can be developed for 64-bit or 128-bit hardware. The great empirical performances of DX generators have been confirmed by an extensive battery of tests in the TestU01 package. These high resolution DX generators can be useful to perform large scale simulations in scientific investigations for various computer systems.	128-bit;32-bit;64-bit computing;computer;image resolution;performance;random number generation;search algorithm;simulation;testu01	Lih-Yuan Deng;Henry Horng-Shing Lu;Tai-Been Chen	2010	Computing	10.1007/s00607-010-0097-9	computer simulation;computing;random number generation;numerical analysis;computer science;theoretical computer science;implementation;algorithm	Theory	-4.617571966497375	34.86075219638204	144004
b06470243254a0d8ce12b179ad9291c88d413222	task superscalar: an out-of-order task pipeline	task pipeline;benchmarking;intertask data dependency;task level parallelism;kernel;paper;decoding;programming model task pipeline instruction level abstraction sequential instruction stream task superscalar sequential thread intuitive programmer annotations intertask data dependency task level parallelism tasks out of order distributed task superscalar pipeline nonspeculative task;performance;sequential thread;cell processor;cmp manycore;parallel programming;runtime;sequential instruction stream;pipelines registers program processors kernel runtime programming decoding;programming model;out of order execution;programming techniques;task analysis data structures parallel programming;intuitive programmer annotations;registers;data structures;task analysis;pipelines;conference report;instruction level abstraction;nonspeculative task;computer science;tasks out of order;distributed task superscalar pipeline;parallel programming out of order execution cmp manycore task superscalar;programming;program processors;task superscalar	We present \emph{Task Super scalar}, an abstraction of instruction-level out-of-order pipeline that operates at the task-level. Like ILP pipelines, which uncover parallelism in a sequential instruction stream, task super scalar uncovers task-level parallelism among tasks generated by a sequential thread. Utilizing intuitive programmer annotations of task inputs and outputs, the task super scalar pipeline dynamically detects inter-task data dependencies, identifies task-level parallelism, and executes tasks out-of-order. Furthermore, we propose a design for a distributed task super scalar pipeline front end, that can be embedded into any many core fabric, and manages cores as functional units. We show that our proposed mechanism is capable of driving hundreds of cores simultaneously with non-speculative tasks, which allows our pipeline to sustain work windows consisting of tens of thousands of tasks. We further show that our pipeline can maintain a decode rate faster than 60ns per task and dynamically uncover data dependencies among as many as \tilde 50,000 in-flight tasks, using 7MB of on-chip eDRAM storage. This configuration achieves speedups of 95–255x (average 183x) over sequential execution for nine scientific benchmarks, running on a simulated CMP with 256 cores. Task super scalar thus enables programmers to exploit many core systems effectively, while simultaneously simplifying their programming model.	analysis of algorithms;cpu cache;certificate management protocol;data dependency;edram;embedded system;experiment;exploit (computer security);manycore processor;microsoft windows;out-of-order execution;parallel computing;pipeline (computing);pipeline (software);programmer;programming model;speculative execution;superscalar processor;task parallelism	Yoav Etsion;Felipe Cabarcas;Alejandro Rico;Alex Ramírez;Rosa M. Badia;Eduard Ayguadé;Jesús Labarta;Mateo Valero	2010	2010 43rd Annual IEEE/ACM International Symposium on Microarchitecture	10.1109/MICRO.2010.13	programming;computer architecture;parallel computing;kernel;real-time computing;data structure;performance;computer science;out-of-order execution;operating system;task analysis;pipeline transport;programming paradigm;processor register;programming language;benchmarking	Arch	-6.139293493216557	46.12957388084777	144023
b11b8e7f2d39372aaa0e293d8e39626e768f0468	parallel computation and supercomputers and applications	parallel computation;parallel computer	Without Abstract	computation;parallel computing;supercomputer	U. Schendel	1988		10.1007/3-540-50647-0_109	computational science;embarrassingly parallel	HPC	-7.470391565559043	38.535613763008364	144168
08855dc0905d1db468eeca100f3dc57433f7517b	survey on parallel programming model	application development;distributed memory;shared memory;fortress;upc;cuda;openmp;pthreads;mpi;parallel programming model;qualitative evaluation	The development of microprocessors design has been shifting to multi-core architectures. Therefore, it is expected that parallelism will play a significant role in future generations of applications. Throughout the years, there has been a myriad number of parallel programming models proposed. In choosing a parallel programming model, not only the performance aspect is important, but also qualitative the aspect of how well parallelism is abstracted to developers. A model with a well abstraction of parallelism leads to a higher application-development productivity. In this paper, we propose seven criteria to qualitatively evaluate parallel programming models. Our focus is on how parallelism is abstracted and presented to application developers. As a case study, we use these criteria to investigate six well-known parallel programming models in the HPC community.	computer cluster;debugging;microprocessor;multi-core processor;norm (social);parallel computing;parallel programming model;performance evaluation	Henry Kasim;Verdi March;Rita Zhang;Simon See	2008		10.1007/978-3-540-88140-7_24	shared memory;computer architecture;parallel computing;distributed memory;reactive programming;computer science;message passing interface;posix threads;operating system;database;distributed computing;data parallelism;universal product code;fortress;programming paradigm;inductive programming;programming language;rapid application development;instruction-level parallelism;implicit parallelism;task parallelism;parallel programming model	HPC	-6.848166203922483	44.374525465963686	144239
9380bf721985e03cb517291d1a4a78247aaa3fa1	towards a grid applicable parallel architecture machine	virtual machine;grid applications;parallel models;natural language;parallel architecture;parallel programs	An approach towards defining a flexible, commonly programmable, efficient multi-user Virtual Infrastructural Machine (VIM) is proposed. A VIM is a software infrastructure which enables programming a Grid infrastructure scalable at the lowest possible level. This shall be attained by a Virtual Machine with inherent parallel execution, executing compiled and interpreted computer languages on a very complex p-code level. Based on this interactive deformalized (i.e. natural language like) human-Grid interaction languages should be developed, enabling parallel programming to be done by inherently parallel model description of the given problem.		Karolj Skala;Zorislav Sojat	2004		10.1007/978-3-540-24688-6_18	parallel computing;embarrassingly parallel;computer science;virtual machine;theoretical computer science;operating system;natural language;programming language;parallel programming model	HPC	-12.817157518876073	39.04937001461321	144433
e431cc9264e446368ce4d0f404c6cddc63c92b36	flux interconnection networks on demand	processing element;programming paradigm;multiprocessor parallel systems;interconnection network;parallel systems;network configuration;interconnection networks;parallel programs	In this paper, we introduce the FLUX interconnection networks, a scheme where the interconnections of a parallel system are established on demand before or during program execution. We present a programming paradigm which can be utilized to make the proposed solution feasible. We perform several experiments to show the viability of our approach and the potential performance gain of using the most suitable network configuration for a given parallel program. We experiment on several case studies, evaluate different algorithms, developed for meshes or trees, and map them on ''grid''-like or reconfigurable physical interconnection networks. Our results clearly show that, based on the underlying network, different mappings are suitable for different algorithms. Even for a single algorithm different mappings are more appropriate, when the processing data size, the number of utilized nodes or the hardware cost of the processing elements changes. The implication of the above is that changing interconnection topologies/mappings (dynamically) on demand depending on the program needs can be beneficial.	interconnection	Stamatis Vassiliadis;Ioannis Sourdis	2007	Journal of Systems Architecture	10.1016/j.sysarc.2007.01.006	embedded system;parallel computing;real-time computing;computer science;operating system;distributed computing;programming paradigm;programming language	Arch	-8.474428045993372	44.66932763915599	144522
5aa1f8d2fd654d79f4676bd0ce397eb9b2c14cd1	expressing direct simulation monte carlo methods in high performance fortran	efficiency;monte carlo method;translators;parallel processing;programming languages;mathematics computers information science management law miscellaneous	High Performance Fortran (HPF) can readily express a broad spectrum of scientific applications and may achieve efficient parallel execution on most of them. However, the current language contains little support for programs whose data structures rely heavily on irregular or pointer-based data structures. In this paper, we look at Direct Simulation Monte Carlo methods, an important scientific application in this category. We focus first on an explicitly parallel implementation of this algorithm and then examine possible HPF expressions of this algorithm. The goal is to use HPF to achieve effective performance, while requiring as little reprogramming as possible.		David Middleton;Piyush Mehrotra;John Van Rosendale	1995			computational science;parallel computing;computer science;theoretical computer science	HPC	-12.505342955222575	38.25510167003588	144539
a70d49058b8565a94360c57043544b9969f70956	a scalable interactive parallel computing environment for python	parallel computer	Modern open source high-level languages such as R and Python are.increasingly playing an important role in increasing programmer productivity when programming high-performance computers. In this article, we describe Python Star-P, a high-level interactive parallel programming environment in Python. We discuss the architecture of the environment and the programming model along with a number of examples. We also describe the performance of the examples on .a cluster of multi-core machines. Finally, we compare our environment with that of other existing parallel computing tools for Python and describe the advantages of our model over others.	parallel computing;python	S. Raghunathan	2008	Computing and Informatics		computational science;computer architecture;python;computer science;programming language	HPC	-9.735906613048016	40.061546536014006	144567
0d8bf7213f95f99049375e8c50ad0192ba539735	parallel colt: a high-performance java library for scientific computing and image processing	image processing;pet;image deblurring;performance comparison;fft;regularization;chip;iterative methods;development tool;inverse problem;motion correction;scientific computing;deconvolution;brain imaging;graphic processing unit;multicore processors;software design;iteration method;high performance;inverse problems;multithreading	Major breakthroughs in chip and software design have been observed for the last nine years. In October 2001, IBM released the world’s first multicore processor: POWER4. Six years later, in February 2007, NVIDIA made a public release of CUDA SDK, a set of development tools to write algorithms for execution on Graphic Processing Units (GPUs). Although software vendors have started working on parallelizing their products, the vast majority of existing code is still sequential and does not effectively utilize modern multicore CPUs and manycore GPUs.  This article describes Parallel Colt, a multithreaded Java library for scientific computing and image processing. In addition to describing the design and functionality of Parallel Colt, a comparison to MATLAB is presented. Two ImageJ plugins for iterative image deblurring and motion correction of PET brain images are described as typical applications of this library. Performance comparisons with MATLAB, including GPU computations via AccelerEyes’ Jacket toolbox are also given.	algorithm;automatic parallelization;cuda;central processing unit;computation;computational science;deblurring;graphics processing unit;image processing;imagej;iterative method;java;matlab;manycore processor;multi-core processor;power4;parallel colt;plug-in (computing);software design;software development kit;thread (computing)	Piotr Wendykier;James G. Nagy	2010	ACM Trans. Math. Softw.	10.1145/1824801.1824809	parallel computing;image processing;computer science;inverse problem;theoretical computer science;mathematics;iterative method;programming language;computer graphics (images)	HPC	-7.082684235062035	38.814739225586656	144578
7bbfcbf2259c053183a90f81829a575543288b78	monitoring finite state properties: algorithmic approaches and their relative strengths	monitor instance;relative strength;future work;monitoring complex application;finite state monitoring;different monitoring algorithm;large number;basic algorithmic approach;runtime overhead;last decade;monitoring finite state property;non-trivial difference	Monitoring complex applications to detect violations from specified properties is a promising field that has seen the development of many novel techniques and tools in the last decade. In spite of this effort, limiting, understanding, and predicting the cost of monitoring has been a challenge. Existing techniques primarily target the overhead caused by the large number of monitor instances to be maintained and the large number of events generated by the program that are related to the property. However, other factors, in particular, the algorithm used to process the sequence of events can significantly influence runtime overhead. In this work, we describe three basic algorithmic approaches to finite state monitoring and distill some of their relative strengths by conducting preliminary studies. The results of the studies reveal non-trivial differences in runtime overhead when using different monitoring algorithms that can inform future work.		Rahul Purandare;Matthew B. Dwyer;Sebastian G. Elbaum	2011		10.1007/978-3-642-29860-8_31	real-time computing;simulation;management science	Theory	-18.854446748200843	38.563157950698105	144648
8d053d7ad2474afbf4ac5a4e0d02dd3c49f224a6	sigma 5 fortran language processor for the computer design language, fit version i	generalized inverses;regularization;minimization of functionals;normal equations;linear operators;least squares splines;fortran;interpolating splines;generalized splines;random access;projection methods	The Computer Design Language (CDL) proposed by Dr. Yaohan Chu1 can be used to provide a precise description of digital computer elements and their sequential operations. This thesis presents a Fortran language processor for the CDL with complete documentation. The program has been implemented on the SIGMA 5 Computer with 32K words of core memory and a 3 megabyte random access disk. The processor has three major parts, an Executive main program, a Translator and a Simulator. The Executive program provides the communication link between the processor and the outside world, and synchronizes the operations of the Translator and Simulator. The Translator constructs the tables and Polish string needed to implement the system. The Simulator executes programs on this system.	compiler description language;computer;documentation;entry point;fortran;magnetic-core memory;megabyte;natural language processing;random access;sds sigma series	Victoria Gehman Evans	1973		10.1145/800192.805756	computer science;theoretical computer science;algorithm	Arch	-13.788369642208112	33.665467185367504	144680
cf1deb45dd783f760983f5427ed9f114b4bdd1ec	an effective iterative compilation search algorithm for high performance computing applications	optimising compilers;program diagnostics;nelder mead simplex algorithm iterative compilation search algorithm high performance computing high level program transformation loop unrolling static analytical model complex computer architecture code behavior optimizing compiler search strategy;genetic algorithm program transformation optimization parameter compiler optimization iterative compilation simplex algorithm;complex computer architecture;optimizing compiler;high performance computing;search algorithm;high level program transformation;simplex algorithm;program transformation;search strategy;optimization gallium algorithm design and analysis reflection search problems biological cells high performance computing;optimization parameter;computer architecture;loop unrolling;biological cells;iterative compilation;code behavior;parallelising compilers;static analytical model;nelder mead simplex algorithm;compiler optimization;iterative compilation search algorithm;high performance computer;nelder mead;genetic algorithm;optimization;search problems;program diagnostics optimising compilers parallel processing parallelising compilers;high performance;algorithm design and analysis;reflection;parallel processing;analytical model;gallium	The performance gap for high performance applications has been widening over time. High level program transformations are critical to improve the applications' performance, many of which concern the determination of optimal values for transformation parameters, such as loop unrolling and blocking. Traditional compilers select these parameters based on static analytical models. However, complex computer architectures and code behaviors greatly limit the strength of optimizing compilers. Iterative compilation approach determines these parameter values by executing the program with different parameter values and selects the one with the shortest runtime, outperforming static compilation approaches significantly, which makes it a hot research topic in the high performance computing research community. But itpsilas quite time consuming because of the huge optimization space. Therefore, an effective search strategy is crucial for iterative compilation. This paper investigates the Nelder-Mead simplex algorithm for iterative compilation optimization parameter search. Experimental results indicate Nelder-Mead simplex based search strategy can produce parameter values with better performance and lower cost.	blocking (computing);computer architecture;iteration;iterative method;loop unrolling;mathematical optimization;nelder–mead method;optimizing compiler;program transformation;run time (program lifecycle phase);search algorithm;simplex algorithm;static library;supercomputer	Pingjing Lu;Yonggang Che;Zhenghua Wang	2008	2008 10th IEEE International Conference on High Performance Computing and Communications	10.1109/HPCC.2008.8	parallel processing;parallel computing;real-time computing;computer science;theoretical computer science;optimizing compiler;programming language	HPC	-15.0314591651595	36.69266446619209	144763
e094b2512e0eb5b6390e91bbff3998cef0c4abd7	designing matrix multiplication algorithms on a multi-tier cluster	matrix multiplication		algorithm;computer cluster;matrix multiplication;multitier architecture	Eunice E. Santos;John Korah	2004			parallel computing;computer science;distributed computing;theoretical computer science;matrix multiplication;matrix chain multiplication	HPC	-9.520862963920077	42.67895373215159	144774
